id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
5b0c9e236220e1d7e9144b4d292a3802ecf37bf6	a spatial analysis of the relationship between vegetation and poverty		The goal of this paper was to investigate poverty and inequities that are associated with vegetation. First, we performed a pixel-level linear regression on time-series and Normalized Difference Vegetation Index (NDVI) for 72 United States (U.S.) cities with a population ≥250,000 for 16 years (1990, 1991, 1995, 1996, 1997, 1998, and 2001 to 2010) using Advanced Very High Resolution Radiometer 1-kilometer (1-km). Second, from the pixel-level regression, we selected five U.S. cities (Shrinking: Chicago, Detroit, Philadelphia, and Growing: Dallas and Tucson) that were one standard deviation above the overall r-squared mean and one standard deviation below the overall r-squared mean to show cities that were different from the typical cities. Finally, we used spatial statistics to investigate the relationship between census tract level data (i.e., poverty, population, and race) and vegetation for 2010, based on the 1-km grid cells using Ordinary Least Squares Regression and Geographically Weighted Regression. Our results revealed poverty related areas were significantly correlated with positive high and/or negative high vegetation in both shrinking and growing cities. This paper makes a contribution to the academic body of knowledge on U.S. urban shrinking and growing cities by using a comparative analysis with global and local spatial statistics to understand the relationship between vegetation and socioeconomic inequality.		Teddy Dawson;J. S. Onésimo Sandoval;Vasit Sagan;Thomas Crawford	2018	ISPRS Int. J. Geo-Information	10.3390/ijgi7030083	statistics;poverty;normalized difference vegetation index;vegetation;ordinary least squares;standard deviation;spatial analysis;geography;population;linear regression	ML	-12.403587765732771	-24.957638681465685	57979
4051ac1bedf1d0e7f0d59c0e0b185e372c87fc66	a rough set approach to the treatment of continuous-valued attributes in multi-concept classification for mechanical diagnosis	multi-concept classification;novel approach;fault diagnosis;rough set approach;manufacturing system;mechanical fault diagnosis;rough set theory;continuous-valued attribute;knowledge extraction;knowledge acquisition;inconsistent data;mechanical diagnosis;rough sets;rough set	The efficient use of critical machines or equipment in a manufacturing system requires reliable information about their current operating conditions. This information is often used as a basis for machine condition monitoring and fault diagnosis—which essentially is an endeavor of knowledge extraction. Rough set theory provides a novel way to knowledge acquisition, especially when dealing with vagueness and uncertainty. It focuses on the discovery of patterns in incomplete and/or inconsistent data. However, rough set theory requires the data analyzed to be in discrete manner. This paper proposes a novel approach to the treatment of continuous-valued attributes in multi-concept classification for mechanical diagnosis using rough set theory. Based on the proposed approach, a prototype system called RClass-Plus has been developed. RClass-Plus is validated using a case study on mechanical fault diagnosis. Details of the validation are described.	rough set	Li Pheng Khoo;Lian-Yin Zhai	2001	AI EDAM		rough set;computer science;artificial intelligence;machine learning;data mining	AI	-7.560104367254791	-24.528580449228976	58583
1be067fac0d8bfcd8c1146dd599c4355efe0ba72	microscopic estimation of freeway vehicle positions from the behavior of connected vehicles	mobile communication systems;intelligent transportation systems;positioning;trajectory prediction;estimating;freeways;connected vehicles	Given the current connected vehicles program in the United States, as well as other similar initiatives in vehicular networking, it is highly likely that vehicles will soon wirelessly transmit status data, such as speed and position, to nearby vehicles and infrastructure. This will drastically impact the way traffic is managed, allowing for more responsive traffic signals, better traffic information, and more accurate travel time prediction. Research suggests that to begin experiencing these benefits, at least 20% of vehicles must communicate, with benefits increasing with higher penetration rates. Because of bandwidth limitations and a possible slow deployment of the technology, only a portion of vehicles on the roadway will participate initially. Fortunately, the behavior of these communicating vehicles may be used to estimate the locations of nearby non-communicating vehicles, thereby artificially augmenting the penetration rate and producing greater benefits. We propose an algorithm to predict the locations of individual noncommunicating vehicles based on the behaviors of nearby communicating vehicles by comparing a communicating vehicle's acceleration with its expected acceleration as predicted by a carfollowing model. Based on analysis from field data, the algorithm is able to predict the locations of 30% of vehicles with 9-meter accuracy in the same lane, with only 10% of vehicles communicating. Similar improvements were found at other initial penetration rates of less than 80%. Because the algorithm relies on vehicle interactions, estimates were accurate only during or downstream of congestion. The algorithm was applied to an existing ramp metering algorithm, and was able to significantly improve its performance at low connected vehicle penetration rates, and maintain performance at high penetration rates. INTRODUCTION In 2010, American drivers wasted 4.8 billion hours and 1.9 billion gallons of fuel due to traffic congestion (Schrank, Lomax, & Eisele, 2011). Several strategies have been proposed to reduce congestion, including dynamic signal timing, ramp metering, and dynamic speed limits. These strategies often rely on historical data supplemented with real-time point detection such as inpavement loop or video detectors. Because point detection cannot cover the entire roadway, these data are often aggregated over time and space. The high installation and maintenance costs of point detection also prevent wide-scale deployment. Even when detectors are deployed, they are often spread far apart and the conditions between detectors must be estimated. Noah J. Goodall, Research Scientist, Virginia Center for Transportation Innovation and Research, 530 Edgemont Road, Charlottesville, VA 22903-2454. Email: noah.goodall@vdot.viginia.gov Brian L. Smith, Professor, Department of Civil and Environmental Engineering, University of Virginia, P.O. Box 400742, Charlottesville, VA, 22904-4742. Email: briansmith@virginia.edu Byungkyu “Brian” Park, Associate Professor, Department of Civil and Environmental Engineering, University of Virginia, P.O. Box 400742, Charlottesville, VA, 22904-4742. Email: bpark@virginia.edu	algorithm;brian;connected car;downstream (software development);email;freeway;interaction;network congestion;penetration test;ramp simulation software for modelling reliability, availability and maintainability;real-time locating system;sensor;software deployment	Noah J. Goodall;Brian L. Smith;Byungkyu Brian Park	2016	J. Intellig. Transport. Systems	10.1080/15472450.2014.889926	embedded system;estimation;intelligent transportation system;simulation;computer science;engineering;traffic conflict;mathematics;transport engineering;computer security;statistics	HCI	-18.605402504183107	-28.865171068223724	58853
ba6e409d6a10b33ea7d332f9ea1a55b7a156c96b	the research on aggregate analysis of the regulatory detailed planning by considering the traffic capacity	forecasting methods;macroscopic traffic flows;road traffic planning;land use and transportation interaction;regulatory detailed planning;land use intensity;road network planning;trunk road networks;detailed planning;traffic engineering;traffic distributions	The regulatory detailed planning is substantive legal planning stage of urban planning in China. The first problem is the need to check and inheritance the indicators of total planning land about construction in the process of compiling. According to city zoning rules establishment work reality, the basic thought of the system analysis, the traffic engineering and urban planning in the related theory and method on the basis of macroscopic traffic flow classification, using the road network capacity calculation method and traffic distribution forecasting method proposed with interregional channel planning level of service and the internal road network planning level of service as the control target, proposes the method by using the master planning road network control to inversely calculate the total amount for the construction of district land use. The calculation example is also given. Studies show that the presented control rules compiled for checking algorithm can play check function about the amount of land used for construction master planning achieve under the premise of the control overall situation trunk road network level of service, to avoid the amount of unnecessary in the subsequent units, neighbourhood planning adjustments.	aggregate function;amortized analysis	Xiangqiang Lou;Quanhua Hou	2015	IJCINI	10.4018/IJCINI.2015010101	traffic engineering;network planning and design;simulation;forecasting;statistics;transportation planning	ML	-12.825249778976213	-24.161194440028968	58873
aae15e4508b0130475d673736605f324169d00bb	multi-modal sequence to sequence learning with content attention for hotspot traffic speed prediction		Traffic speed prediction is a crucial and fundamental task of the intelligent transportation systems (ITS). Due to the dynamic and non-linear nature of the traffic, this task is difficult. Nonetheless, the collection of crowd map queries data brings new ways to solve this problem. Generally speaking, in a short period of time, a large amount of crowd map queries aiming at the same destination may lead to traffic congestion. For instance, large queries for Family Restaurant during the dinner time lead to traffic jams around it. However, traffic speed prediction with crowd map queries is challenging due to the complexity and scale of the map queries, as well as their modalities. To bridge the gap, we propose Multi-Seq2Seq-Att for hotspot traffic speed prediction. Multi-Seq2Seq-Att is a multi-modal sequence learning model that deals with two sequences in different modalities, namely, the query sequence and the traffic speed sequence. The main idea of Multi-Seq2Seq-Att is to learn to fuse the multi-modal sequence with content attention. With this method, Multi-Seq2Seq-Att addresses the modality gap between queries and the traffic speed. Experiments on real-world datasets from Baidu Map demonstrates a 24% relative boost over other state-of-the-art methods.	modal logic	Binbing Liao;Siliang Tang;Shengwen Yang;Wenwu Zhu;Fei Wu	2018		10.1007/978-3-030-00776-8_20	computer science;machine learning;hotspot (wi-fi);pattern recognition;sequence learning;intelligent transportation system;traffic congestion;artificial intelligence	ML	-15.059179449890053	-34.98954701469241	58884
ac74ac265164db7b5fe52e8384586dd7cd52b196	on frequency estimation and detection of frequent items in time faded streams		We deal with the problem of detecting frequent items in a stream under the constraint that items are weighted, and recent items must be weighted more than older ones. This kind of problem naturally arises in a wide class of applications in which recent data is considered more useful and valuable with regard to older, stale data. The weight assigned to an item is, therefore, a function of its arrival timestamp. As a consequence, whilst in traditional frequent item mining applications we need to estimate frequency counts, we are instead required to estimate decayed counts. These applications are said to work in the time fading model. Two sketch-based algorithms for processing time-decayed streams have been recently published independently near the end of 2016. The Filtered Space Saving with Quasi-Heap (FSSQ) algorithm, besides a sketch, also uses an additional data structure called quasi-heap to maintain frequent items. Forward Decay Count-Min Space Saving (FDCMSS), our algorithm, cleverly combines key ideas borrowed from forward decay, the Count-Min sketch and the Space Saving algorithm. Therefore, it makes sense to compare and contrast the two algorithms in order to fully understand their strengths and weaknesses. We show, through extensive experimental results, that FSSQ is better for detecting frequent items than for frequency estimation. The use of the quasi-heap data structure slows down the algorithm owing to the huge number of maintenance operations. Therefore, FSSQ may not be able to cope with high-speed data streams. FDCMSS is better suitable for frequency estimation; moreover, it is extremely fast and can be used in the context of high-speed data streams and for the detection of frequent items as well, since its recall is always greater than 99%, even when using an extremely tiny amount of space. Therefore, FDCMSS proves to be an overall good choice when considering jointly the recall, precision, average relative error and the speed.	algorithm;approximation error;count–min sketch;data structure;heap (data structure);sensor;spectral density estimation;while	Massimo Cafaro;Italo Epicoco;Marco Pulimeno;Giovanni Aloisio	2017	IEEE Access	10.1109/ACCESS.2017.2757238	fading;timestamp;streams;algorithm design;data stream mining;real-time computing;computer science;data structure;approximation error;sketch	ML	-7.636335805729876	-35.074793023636566	59410
4b3642f75da706ad939d718e6dcf7d90554a6d82	similarity assessment mechanism for spatiotemporal data sets in case-based reasoning			case-based reasoning;spatiotemporal database	Osman M. Hegazy;Ibrahim H. Hemeida;Mohamed Nour Eldein;Jihan Elhusseiny	2012			data mining;case-based reasoning;data set;computer science	AI	-12.01724028904207	-28.200365630255945	59421
1a4ea95a8df0b091453359da55c0dbee247109ca	a frequent itemset reduction algorithm for global pattern mining on distributed data streams		In present scenario, extracting global frequent itemsets from big data, distributed across multiple data streams, with its real time requirements is a complex problem. In this article, we propose an algorithm that reduces number of local frequent itemsets communicated to root node to extract global patterns from distributed multiple data streams. Here, the algorithm sends only local frequent itemsets to the root node instead of sending summary of local data streams. We compress sets of local frequent itemsets and send them to the root node using algorithm called Frequent Itemset Reduction (FIR) algorithm. We present two indexing structures known as I-list and Modified Seg-tree (MsegT) to store all local frequent itemsets at root node. Our experimental study exhibits that the FIR algorithm reduces communication cost in a good extent and MsegT produces substantial good results compared to I-list and few state-of-the-art techniques.	algorithm;apriori algorithm;association rule learning;big data;centralized computing;computational complexity theory;data mining;experiment;finite impulse response;hierarchical database model;iterative and incremental development;iterative method;requirement;time complexity;tree (data structure)	Shalini;Sanjay Kumar Jain	2017	2017 Tenth International Conference on Contemporary Computing (IC3)	10.1109/IC3.2017.8284320	fold (higher-order function);artificial intelligence;big data;data stream mining;search engine indexing;pattern recognition;algorithm;computer science	ML	-5.733319148220168	-37.505493317331805	59563
10d864e816b0e7785794a12132d532ad86df4aff	the case for temporal transparency: detecting policy change events in black-box decision making systems		Bringing transparency to black-box decision making systems (DMS) has been a topic of increasing research interest in recent years. Traditional active and passive approaches to make these systems transparent are often limited by scalability and/or feasibility issues. In this paper, we propose a new notion of black-box DMS transparency, named, temporal transparency, whose goal is to detect if/when the DMS policy changes over time, and is mostly invariant to the drawbacks of traditional approaches. We map our notion of temporal transparency to time series changepoint detection methods, and develop a framework to detect policy changes in real-world DMS’s. Experiments on New York Stop-questionand-frisk dataset reveal a number of publicly announced and unannounced policy changes, highlighting the utility of our framework.	black box;scalability;sensor;time series	Miguel Ferreira;Muhammad Bilal Zafar;Krishna P. Gummadi	2016	CoRR		simulation;data mining	ML	-12.10613015103083	-31.7302020414642	59597
6686bae5d494505f33a73a5c9c0a2fa7386246c2	dctp: data collecting based on trajectory prediction in smart environment	hidden markov models trajectory data collection wireless sensor networks educational institutions algorithm design and analysis prediction algorithms;hidden markov model;binary motion sensor;human trajectory prediction;wireless sensor networks data mining hidden markov models knowledge based systems mobile computing probability;hidden markov model dctp data collection based on trajectory prediction smart environment data mining transition probability sensor node wireless sensor network wsn hmm algorithm;binary motion sensor human trajectory prediction wireless sensor networks smart environments hidden markov model;smart environments;wireless sensor networks	In this paper, we have proposed and designed a real-time distributed predicted data collection system-DCTP (Data Collection based on Trajectory Prediction according to Knowledge mined from trajectories) to solve the congestion and data loss caused by too many connections to sink node in indoor Smart Environment scenarios (like Smart Home, Smart Wireless Healthcare and so on). DCTP predicts and sends predicted data of the sensor nodes which people is going to pass at one time instead of sending the triggered data in several times. Firstly, our system applies data mining to get the knowledge of transition probability among sensor nodes from the historical binary motion data. Secondly, each sensor node stores the corresponding knowledge based on a special storage mechanism. Thirdly, each triggered sensor node predicts the next destinations people will arrive at according to the received message using HMM algorithm. At last, the sensor node sends its triggered data and the predicted data to the sink node. The significances of DCTP are as follows: (a) the procedure of DCTP is distributed; (b) it effectively reduces the connection between sensor nodes and sink node. The time complexities of the proposed algorithms are analyzed and the performance is evaluated by some designed experiments in a Smart Environment.	algorithm;data mining;emoticon;experiment;hidden markov model;markov chain;mined;network congestion;real-time clock;sensor node;smart environment	Chengliang Wang;Debraj De;Ya-Yun Peng;Wen-Zhan Song	2014	2014 International Conference on Smart Computing Workshops	10.1109/SMARTCOMP-W.2014.7046673	real-time computing;computer science;machine learning;data mining;key distribution in wireless sensor networks;mobile wireless sensor network;visual sensor network	Robotics	-14.130267645964365	-34.16469234837313	59605
09feeb02e6ad8df6ac899a9fbc4e5f49fe7a5435	a linear-complexity reparameterisation strategy for the hierarchical bootstrapping of capabilities within perception-action architectures	perception action architectures;optimisation;action learning;subsumption architecture;linear complexity;machine learning;cognitive vision;symbol grounding;machine learning unsupervised	Please cite this article in press as: M. Shevc Comput. (2009), doi:10.1016/j.imavis.2008 Perception–action (PA) architectures are capable of solving a number of problems associated with artificial cognition, in particular, difficulties concerned with framing and symbol grounding. Existing PA algorithms tend to be ‘horizontal’ in the sense that learners maintain their prior percept–motor competences unchanged throughout learning. We here present a methodology for simultaneous ‘horizontal’ and ‘vertical’ perception–action learning in which there additionally exists the capability for incremental accumulation of novel percept–motor competences in a hierarchical fashion. The proposed learning mechanism commences with a set of primitive ‘innate’ capabilities and progressively modifies itself via recursive generalising of parametric spaces within the linked perceptual and motor domains so as to represent environmental affordances in maximally-compact manner. Efficient reparameterising of the percept domain is here accomplished by the exploratory elimination of dimensional redundancy and environmental context. Experimental results demonstrate that this approach exhibits an approximately linear increase in computational requirements when learning in a typical unconstrained environment, as compared with at least polynomially-increasing requirements for a classical perception–action system. 2008 Elsevier B.V. All rights reserved.	algorithm;ampersand;cognition;framing (world wide web);recursion;requirement;tree accumulation	Mikhail Shevchenko;David Windridge;Josef Kittler	2009	Image Vision Comput.	10.1016/j.imavis.2008.12.002	computer vision;error-driven learning;subsumption architecture;computer science;artificial intelligence;machine learning;action learning;symbol grounding	AI	-9.890701336232045	-28.969207755202138	59794
57f43bea6caa798fde71b2c2fc372070da9db316	an approach for removing redundant data from rfid data streams	radio frequency identification device;database management systems;data filtering;automatic identifications;time factors;duplicate reading;statistics as topic;rfid;algorithms	Radio frequency identification (RFID) systems are emerging as the primary object identification mechanism, especially in supply chain management. However, RFID naturally generates a large amount of duplicate readings. Removing these duplicates from the RFID data stream is paramount as it does not contribute new information to the system and wastes system resources. Existing approaches to deal with this problem cannot fulfill the real time demands to process the massive RFID data stream. We propose a data filtering approach that efficiently detects and removes duplicate readings from RFID data streams. Experimental results show that the proposed approach offers a significant improvement as compared to the existing approaches.	algorithm;bloom filter;correctness (computer science);deploy;gene duplication abnormality;microsoft windows;queueing theory;radio frequency identification device;radio-frequency identification;reading (activity);relevance;run time (program lifecycle phase);software deployment	Hairulnizam Mahdin;Jemal H. Abawajy	2011		10.3390/s111009863	radio-frequency identification;embedded system;computer science;data mining;database;world wide web	DB	-8.341139566357823	-35.50494076895408	60316
a9df7e084590bac00c51d1eb453c49dc2f2c5b9f	a compressive sensing scheme of frequency sparse signals for mobile and wearable platforms	motion recognition;compressive sensing;signal processing;data acquisition	In selected scenarios, sensor data capturing with mobile devices can be separated from the data processing step. In these cases, Compressive Sensing allows a significant reduction of the average sampling rate below the Nyquist rate, if the signal has a sparse frequency representation. This can be motivated in order to increase the energy efficiency of the mobile device and extend its runtime. Since many signals, especially in the field of motion recognition, are time-dependent, we propose a corresponding general sampling algorithm for time-dependent signals. It even allows a declining average sampling rate if the data acquisition is extended beyond a projected acquisition end. The presented approach is testified for the purpose of motion recognition by evaluating real acceleration sensor data acquired with the proposed algorithm.	algorithm;automatic identification and data capture;compressed sensing;computation;data acquisition;mobile device;nyquist rate;online and offline;sampling (signal processing);sparse matrix	Stephan da Costa Ribeiro;Martin Kleinsteuber;Andreas Möller;Matthias Kranz	2011		10.1007/978-3-642-27579-1_66	computer vision;computer science;machine learning;signal processing;data acquisition;compressed sensing	Mobile	-13.199204521067244	-32.98649147995907	61060
73e2ec3ee0cb403f42ebaa2e698436f23d2c86ac	pattern-oriented inverse simulation for agent-based modeling: an analysis of family strategies	bottom up;agent based simulation;agent based;agent based model;pattern oriented inverse simulation;time series;complex system;simulation technique;family strategy;civil service examination;inverse simulation	Pattern Oriented Modeling (POM) is an approach to bottom-up complex system analysis, which was developed in ecology and for agent-based complex systems. This paper proposes a pattern-oriented inverse simulation (PIS) to analyze agent-based complex systems. We apply PIS to a history simulation domain, which aims to analyze a particular family line with more successful candidates in the civil service examination in imperial China. Two relevant patterns observed in the real family system are employed to decode family strategies along such an elite family line. We implement PIS through inverse simulation techniques, by fitting the simulated results to the real genealogical data arranged in time-series as patterns. Intensive experiments show a practical applicability of PIS in agent-based complex systems.	agent-based model;bottom-up proteomics;complex system;complex systems;ecology;experiment;pattern-oriented modeling;simulation;system analysis;time series	Chao Yang;Setsuya Kurahashi;Isao Ono;Takao Terano	2010		10.1145/1830761.1830806	complex systems;simulation;artificial intelligence;time series;top-down and bottom-up design;operations research;statistics	Robotics	-14.032721863807861	-24.949975386647697	61386
0c10fe7b36a9a41aa46f4337eeaa4ceb104cf520	test and evaluation of data association algorithms in hard+soft data fusion	sensor fusion military computing;hard soft fusion;data association;sunni criminal thread of the synthetic counterinsurgency data association algorithms hard plus soft data fusion coin operations counter insurgency operation soft data hard data hard processing techniques soft processing techniques relational graph cumulative evidence syncoin dataset;test and evaluation;deduplication;deduplication data association test and evaluation hard soft fusion entity resolution;entity resolution;sun gallium nitride message systems sensors algorithm design and analysis measurement cameras	The information gathered by sources during counter insurgency (COIN) operations can be classified into two types. The data gathered by humans and recorded in the textual format such as field reports is referred to as soft data. Data gathered with the help of physical sensors such as video cameras, LIDAR, acoustic sensors, etc. is referred to as hard data. To process this information, various hard and soft processing techniques are used, which convert these data into relational graphs. Many times this hard and soft data contains duplicate references of the same entities, events and relationships, caused by multiple sources reporting on the same entity, event or relationship or due to successive reports on an entity, event or relationship. The role of data association is to identify these duplicate references across the different observations and merge them into fused (cumulative) evidence. This cumulative evidence will contain more information about the real world than offered by any single observation. We want the cumulative evidence to describe the real world as accurately as possible, so as to draw satisfactory conclusions on the state of the real world. This calls for development of an objective strategy for evaluating the performance of data association processes. In this paper, we describe in detail the testing and evaluation strategy developed for this task. This strategy was deployed for the evaluation of three different data association algorithms on the Sunni Criminal (SUN) Thread of the Synthetic Counterinsurgency (SYNCOIN) dataset. The SUN thread consists of 114 soft messages and 13 hard messages. This test and evaluation strategy can also help in selecting the best data association algorithm to deploy based on the different properties of the input dataset and processing time permissible.	acoustic cryptanalysis;algorithm;correspondence problem;counterfactual conditional;entity;sensor;thread pool	Ketan Date;Geoff A. Gross;Rakesh Nagi	2014	17th International Conference on Information Fusion (FUSION)		computer science;data mining;database;computer security	DB	-7.152839175478292	-30.648641078256333	61463
1cc0e8657b2c84605b03464af1998304e274f175	realtime traffic speed estimation with sparse crowdsourced data		Realtime traffic speed estimation is an important issue in urban computation. Existing approaches usually focus on exploiting the periodicity properties of the traffic speed and utilize crowdsourcing techniques to facilitate real-time estimation. The quality of such estimation is limited in real world: 1) the accuracy of existing estimation over-relies on the probed data; 2) the accidental traffic variance is ignored; 3) existing strategies incur exhaustive usage of human workers to get fine-grained estimation results. Thus, a more intelligent RTSE approach is desired. In this paper, we propose the framework of CrowdRTSE (Crowdsourcing-based Real-time Traffic Speed Estimation), which adopts a hybrid offline-online process to collaboratively exploit the historical and real-time data to produce high-quality RTSE. To accomplish such a framework, we devise effective algorithms to judiciously select the best group of human workers with a constant approximation ratio, and effectively propagate the crowdsourced data with high efficiency. Comprehensive evaluations have been conducted on both synthetic and real world datasets. The experimental results verify the effectiveness and efficiency of our proposed methods.	approximation algorithm;computation;crowdsourcing;error-tolerant design;experiment;graphical model;graphical user interface;guardian service processor;online and offline;original chip set;quasiperiodicity;real-time data;real-time transcription;sparse;sparse matrix;synthetic intelligence	Zheng Liu;Lei Chen;Yongxin Tong	2018	2018 IEEE 34th International Conference on Data Engineering (ICDE)	10.1109/ICDE.2018.00038	data mining;urban computing;computation;computer science;exploit;crowdsourcing	DB	-16.372776040078687	-32.247355124772184	61692
5eccc9de3d7fce260757369e5f7e17a59ac364a3	the spatio-temporal modeling for criminal incidents	data mining and knowledge discovery;information systems and communication service	Law enforcement agencies monitor criminal incidents. With additional geographic and demographic data, law enforcement analysts look for spatio-temporal patterns in these incidents in order to predict future criminal activity. When done correctly these predictions can inform actions that can improve security and reduce the impact of crime. Effective prediction requires the development of models that can find and incorporate the important associative and causative variables available in the data. This paper describes a new approach that uses spatio-temporal generalized additive models (ST-GAMs) to discover underlying factors related to crimes and predict future incidents. In addition, the paper shows extensions of the ST-GAM approach to produce local spatio-temporal generalized additive models (LST-GAMs). These local models can better predict criminal incidents conditioned on regions. Both models can fully utilize a variety of data types, such as spatial, temporal, geographic, and demographic data, to make predictions. We describe how to estimate the parameters for ST-GAM using iteratively re-weighted least squares and maximum likelihood and show that the resulting estimates provide for model interpretability. This paper also discusses methods to generate regions for LST-GAM. Lastly the paper discusses the evaluation of LST-GAM and ST-GAM with actual criminal incident data from Charlottesville, Virginia. The evaluation results show that both models from this new approach outperform previous spatial models in predicting future criminal incidents.	generalized additive model;iteratively reweighted least squares	Xiaofeng Wang;Donald E. Brown	2011	Security Informatics	10.1186/2190-8532-1-2	simulation;computer science;data science;machine learning;data mining;world wide web;computer security;statistics	AI	-14.619789620753133	-27.780315772894486	62178
ac3edd9b6413525e5d9dca0cf34bfa71ef72d070	web access pattern algorithms in education domain	web accessibility	Sequential pattern mining discovers frequent user access patterns from web logs. Apriori-like sequential pattern mining techniques requires expensive multiple scans of database. So, now days, WAP (Web Access Pattern) tree based algorithm is used. It is faster than traditional techniques. However, the use of conditional search strategies in WAP-tree based mining algorithms requires re-construction of large numbers of intermediate conditional WAP-trees, which is also very costly. In this paper, Kongu Arts and Science College (KASC) web logs are taken for mining. Here, we propose an efficient sequential pattern mining techniques for KASC web log access sequences known as CS-WAP Tree. This proposed algorithm modifies the WAP tree approach for improving efficiency. The proposed algorithm totally eliminates the need to engage in numerous reconstructions of intermediate WAP trees and considerable reduces execution time. The results of experiments show the efficiency of the improved algorithm. The next key aim is to compare WAP algorithms.	apriori algorithm;blog;data mining;experiment;run time (program lifecycle phase);sequential pattern mining	C. Gomathi;M. Moorthi;K. Duraiswamy	2008	Computer and Information Science		computer science;machine learning;web accessibility;data mining;database;world wide web	ML	-5.675215967541419	-37.511208329661244	62625
d909bcb7b0ee010e10f64c301b65b1fa035fd5f5	traffic flow prediction based on cascaded artificial neural network		The prediction of traffic flow is of great significance for the prevention of accidents, the avoidance of congestion and the dispatch of command center. Considering the complexity of traffic data in reality, it is an extraordinarily challenging task to forecast accurately from historical patterns. In this paper, we propose a method based on the cascaded artificial neural network (CANN) to predict traffic flow at positions. In order to express the spatial correlation of traffic data, the actual road network distance is introduced in our model. The realworld data derived from video surveillance cameras in Xiamen is used in the experiment which is compared with five baselines. To the best of our knowledge, this is the first time that CANN is applied to forecast traffic flow. The experimental results demonstrate that the CANN method has superior performance. In addition, We also discuss the impact of some external factors such as temperature, weather and holidays on the prediction results.	artificial neural network;baseline (configuration management);closed-circuit television;dynamic dispatch;network congestion;operations room	Shaokun Zhang;Zejian Kang;Zhiyou Hong;Zhemin Zhang;Cheng Wang;Jonathan Li	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8518853	computer vision;spatial correlation;artificial intelligence;artificial neural network;traffic flow;data modeling;machine learning;computer science	Robotics	-16.111852664582898	-31.867690519085713	62653
389f03e88bc0c3774f99c87d8dd9b9a82dae91a1	stagger: periodicity mining of data streams using expanding sliding windows	data streams mining;measurement and monitoring of information;tree data structures data mining;sensors;online incremental approach;mining;data stream;real time;mining data;generated sensor data streams;data accuracy;data type;tree data structures;periodicity rates discovering;periodicity mining;data mining;data streams;tree like data structure stagger periodicity mining data streams mining expanding sliding windows sensor devices online incremental approach periodicity rates discovering;periodicity rate of data;stagger;periodic patterns;data mining windows frequency history tree data structures telephony inspection hysteresis pervasive computing computerized monitoring;expanding sliding windows;data stream mining;life sciences;health science;incremental algorithm;tree like data structure;synthetic data;short period;data structure;sensor devices;sliding window	Sensor devices are becoming ubiquitous, especially in measurement and monitoring applications. Because of the real-time, append-only and semi-infinite natures of the generated sensor data streams, an online incremental approach is a necessity for mining stream data types. In this paper, we propose STAGGER: a one-pass, online and incremental algorithm for mining periodic patterns in data streams. STAGGER does not require that the user pre-specify the periodicity rate of the data. Instead, STAGGER discovers the potential periodicity rates. STAGGER maintains multiple expanding sliding windows staggered over the stream, where computations are shared among the multiple overlapping windows. Small-length sliding windows are imperative for early and real-time output, yet are limited to discover short periodicity rates. As streamed data arrives continuously, the sliding windows expand in length in order to cover the whole stream. Larger-length sliding windows are able to discover longer periodicity rates. STAGGER incrementally maintains a tree-like data structure for the frequent periodic patterns of each discovered potential periodicity rate. In contrast to the Fourier/Wavelet-based approaches used for discovering periodicity rates, STAGGER not only discovers a wider, more accurate set of periodicities, but also discovers the periodic patterns themselves. In fact, experimental results with real and synthetic data sets show that STAGGER outperforms Fourier/Wavelet-based approaches by an order of magnitude in terms of the accuracy of the discovered periodicity rates. Moreover, real-data experiments demonstrate the practicality of the discovered periodic patterns.	algorithm;append;computation;data structure;experiment;imperative programming;microsoft windows;pin grid array;quasiperiodicity;real-time clock;real-time locating system;semiconductor industry;streaming media;synthetic data;wavelet	Mohamed G. Elfeky;Walid G. Aref;Ahmed K. Elmagarmid	2006	Sixth International Conference on Data Mining (ICDM'06)	10.1109/ICDM.2006.153	sliding window protocol;real-time computing;mining;data type;computer science;sensor;data science;data mining;data stream mining;tree;synthetic data	DB	-8.192104015138666	-35.16086922532947	62691
1d66f26ac570274e9b29e8dde857e40200ad2848	real-time traffic incident detection using probe-car data on the tokyo metropolitan expressway	real time system anomaly detection automatic incident detection probe car data real data;probe car data;automatic incident detection;anomaly detection;real data;real time system;real time systems probes trajectory monitoring detectors roads detection algorithms;batch processing real time traffic incident detection probe car data tokyo metropolitan expressway;traffic information systems batch processing computers data analysis real time systems	We have developed a real-time traffic incident detection system for the Tokyo Metropolitan Expressway. This system monitors current traffic using probe-car data and compares actual traffic in real time with the usual traffic, which is estimated in advance using batch processing.	algorithm;batch processing;real-time clock;real-time transcription	Akira Kinoshita;Atsuhiro Takasu;Jun Adachi	2014	2014 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2014.7004488	simulation;telecommunications;engineering;computer security	Robotics	-17.41432002701057	-29.522974752258975	62810
375e40b6198f6c670f4c29b11e3f42b7be923e92	tracking entities in the dynamic world: a fast algorithm for matching temporal records		Identifying records referring to the same real world entity over time enables longitudinal data analysis. However, difficulties arise from the dynamic nature of the world: the entities described by a temporal data set often evolve their states over time. While the state of the art approach to temporal entity matching achieves high accuracy, this approach is computationally expensive and cannot handle large data sets. In this paper, we present an approach that achieves equivalent matching accuracy but takes far less time. Our key insight is “static first, dynamic second.” Our approach first runs an evidence-collection pass, grouping records without considering the possibility of entity evolution, as if the world were “static.” Then, it merges clusters from the initial grouping by determining whether an entity might evolve from the state described in one cluster to the state described in another cluster. This intuitively reduces a difficult problem, record matching with evolution, to two simpler problems: record matching without evolution, then “evolution detection” among the resulting clusters. Experimental results on several temporal data sets show that our approach provides an order of magnitude improvement in run time over the state-of-the-art approach while producing equivalent matching accuracy.	algorithm;analysis of algorithms;blocking (computing);cluster analysis;entity;experiment;run time (program lifecycle phase)	Yueh-Hsuan Chiang;AnHai Doan;Jeffrey F. Naughton	2014	PVLDB	10.14778/2732279.2732284	computer science;machine learning;data mining;algorithm	DB	-9.640105447557396	-37.39137508099806	62960
d5b2c328d2d1a9718b9d1bcea60727b841f02174	combination of spatio-temporal correction methods using traffic survey data for reconstruction of people flow	reconstruction of people flow;large scale spatio temporal analysis;traffic survey data	Data on people flow has become increasingly important in various fields, including marketing and public services. Although mobile phones enable the user’s position to be located with a certain degree of accuracy from a large number of people and become one of the most promising devise, unwillingness to share related with privacy issues still remain. Therefore, it is also important to establish a practical method for reconstructing people flow from various kinds of existing fragmentary spatio-temporal data, such as public traffic survey data, from a view of complementariness with mobile phone data. In this study, we propose a combination of spatio-temporal correction processes to a previously published method, to generate continuous spatio-temporal people flow data sets at chosen intervals in selected cities. The correction methods include temporal smoothing of departure time using kernel density estimation, network data correction in OpenStreetMap data, and spatial smoothing in geocoding with MODIS data. We also compare the reconstruction accuracy by deriving correlation coefficients for different combinations of correction methods. Such reconstructed people flow data can potentially be used as infrastructure data in various fields, including emergency planning and related events in areas where data collection and real-time awareness are weak.		Yoshihide Sekimoto;Atsuto Watanabe;Toshikazu Nakamura;Hiroshi Kanasugi;Tomotaka Usui	2013	Pervasive and Mobile Computing	10.1016/j.pmcj.2012.10.005	data science;data mining;computer security;statistics	HCI	-18.839305657618887	-32.953835973756554	63555
99cf59db2013e9c5a5f636346ca1becdd7fafd7c	a blackboard architecture for data-intensive information fusion using locality-sensitive hashing	blackboard architecture;data analysis;file organisation;pattern recognition;sensor fusion;bayesian knowledge sources;blackboard-based algorithms;twitter news feed monitoring;blackboard architecture;data-intensive information fusion;high-level patterns;locality-sensitive hashing;noise;pattern identification;bayesian network fragments;blackboard architecture;data intensive computing;information fusion;locality sensitive hashing;mining twitter feeds;stream computing	The problem of identifying patterns in large data sets arises in applications such as the analysis of surveillance data as well as for more general situational awareness needs. Often input data arrives in bits and pieces, in random order from multiple sensors. Conjecturing high-level patterns from such data is often referred to as information fusion. Blackboard-based algorithms have been used to automatically identify such patterns. However, when the volume of data is large and includes noise, a naive blackboard-based algorithm can be inefficient due to the large number of combinations of inputs that a knowledge source could be applied on. Here we present an approach to improve the performance of blackboard-based algorithms under the assumption that each knowledge source is ‘locally-selective’. The number of combinations to explore can then be pruned using locality sensitive hashing (LSH) We formally define a generic Blackboard architecture using Bayesian knowledge sources, with which we model three problems including a real-life example of monitoring Twitter news feeds. We also present experimental results demonstrating the advantage of LSH over a naïve blackboard algorithm.	algorithm;bayesian network;blackboard system;data-intensive computing;high- and low-level;locality of reference;locality-sensitive hashing;naivety;problem domain;real life;run time (program lifecycle phase);scalability;sensor;stream (computing);zobrist hashing;lsh	Gautam Shroff;Saurabh Sharma;Puneet Agarwal;Shefali Bhat	2011	14th International Conference on Information Fusion		blackboard system;computer science;data science;machine learning;data mining	DB	-11.047668860662483	-33.6175391856762	63692
a04ced1692debe55965ed9efb1c2901b581bdac5	gap filling of missing streaming data in a network of intelligent surveillance cameras		The growth of video surveillance devices increases the rate of streaming data. However, even working in the Fog Computing environment, these smart devices may fail collecting information, producing missing or invalid data. This issue can affect the user quality of experience, because the PTZ-controller may lose the target object tracking. Therefore, this paper presents the Singular Spectrum Analysis - (SSA), as the method to replace missing values in this complex environment of intelligent surveillance cameras. SSA is characterized within time series field by performing a non-parametric spectral estimation with spatial-temporal correlations. The values not correctly monitored, were estimated by SSA with accuracy, allowing the tracking of a suspect object.	closed-circuit television;digital camera;fog computing;missing data;pan–tilt–zoom camera;smart device;spectral density estimation;stream (computing);streaming media;time series	Gabriel Lecomte;Vinícius Hipolito;Bruno G. Batista;Bruno Tardiole Kuehne;Dionisio Machado Leite Filho;José A. C. Martins;Maycon L. M. Peixoto	2017		10.1145/3126858.3131585	singular spectrum analysis;missing data;smart city;video tracking;data mining;computer science;quality of experience;invalid data;spectral density estimation;streaming data	HCI	-12.066385753582985	-32.890642517571855	63704
fdb9faeb20a96e25fa98fb1179398dbfc2d9ffad	activity patterns mining in wi-fi access point logs		This article proposes a methodology to mine valuable information about the usage of a facility (e.g. building, open public spaces, etc.), based only on Wi-Fi network connection history. Data are collected at Concordia University in Montréal, Canada. Using the Wi-Fi access log data, we characterize activities taking place within a building without any additional knowledge of the building itself. The methodology is based on identification and generation of pertinent variables derived by Principal Component Analysis (PCA) for clustering (i.e. PCA-guided clustering) and time-space activity identification. K-means clustering algorithm is then used to identify 7 activity types associated with buildings in the context of a campus. Based on the activity clusters’ centroids, a search algorithm is proposed to associate activities of the same types over multiple days. The spatial distribution of the computed activities and building plans are then compared, which shows a more than 85% match for the weekdays. © 2017 Published by Elsevier Ltd.	attachments;big data;cluster analysis;information theory;iteration;k-means clustering;mathematical optimization;maxima and minima;pattern recognition;principal component analysis;relevance;search algorithm;space–time tradeoff;usage analysis;wireless access point	Guilhem Poucin;Bilal Farooq;Zachary Patterson	2018	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2017.09.004	data mining;geography;centroid;principal component analysis;cluster analysis;multiple days;search algorithm	HCI	-18.628861461840632	-34.53261268286944	63798
856f69749860ddb8f628a82a1d40e2fef7fbee39	monitoring system for a single aged person on the basis of electricity use — prototype by using smart meter		The number of persons 65 years of age or older are increasing in Japan. Among them the number of living alone not in nursing home but in his or her own home is predicted to increase more and more. On the other hand smart meters have been prevailing in recent years. Therefore we have been developing the monitoring system for watching them by using the smart meters. We prepared two algorithms of “average method” and “fluctuation estimate method” for this purpose. We applied them to actual five households of single-aged persons and evaluated their performance.	algorithm;newton's method;prototype;quantum fluctuation;smart meter	Koki Katori;Yukio Nakano;Takashi Nose;Kazutaka Hotta;Hideki Kawarai;Tsuyoshi Ueno	2017	2017 IEEE 6th Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2017.8229213	computer security;electricity;smart meter;business	Robotics	-8.318543767424742	-27.630685310929362	63813
f0bf63eda9bdaa7624bfe307021dd9e621dccec7	top-k frequent items and item frequency tracking over sliding windows of any sizes	electronic mail;upper bound twitter real time systems data structures time frequency analysis windows electronic mail;windows;upper bound;data structures;twitter;time frequency analysis;real time systems	Many big data applications today require querying highly dynamic and large-scale data streams for top-k frequent items in the most recent window of any specified size at any time. This is a challenging problem. We show that our novel solution is not only accurate, but it also one to two orders of magnitude faster than previous approaches. Moreover, its memory footprint grows only logarithmically with the window size, rather than linearly as in previous work. Our comprehensive experiments over real-world datasets show that our solution is very effective and scalable. In addition, we devise a concise and efficient solution to a related problem of tracking the frequency of selected items, improving upon previous work by twenty to thirty times in model conciseness while providing the same accuracy and efficiency.	big data;experiment;memory footprint;microsoft windows;scalability	Chunyao Song;Xuanming Liu;Tingjian Ge	2017	2017 IEEE 33rd International Conference on Data Engineering (ICDE)	10.1109/ICDE.2017.74	real-time computing;time–frequency analysis;data structure;computer science;data mining;database;upper and lower bounds;programming language;world wide web	DB	-8.09843518537864	-35.43596609995504	63980
b258b176d7c0562bb0bd11b541782fa252de094c	isochrones, traffic and demographics	fcd;isochrones;demographics;traffic;geormaketing	Catchment area and reachability analysis, i.e., the area from which a location attracts visitors and the minimum distance to a target location, respectively, are interesting problems when studied in the context of time-parameterized networks, such as road networks affected by traffic. This work utilizes live-traffic assessment results produced by Floating Car Data and their application to such crucial geomarketing test cases. We combine state-of-the-art isochrone computation utilizing live-traffic and demographics data to provide efficient catchment area and reachability calculations. The online demo presented here, showcases the critical impact of live-traffic assessment on business intelligence decisions related to space.	computation;geomarketing;reachability;test case	Alexandros Efentakis;Nikos Grivas;George Lamprianidis;Georg Magenschab;Dieter Pfoser	2013		10.1145/2525314.2525325	simulation;operations research;computer security;cartography	AI	-17.83646445648844	-31.778394446381522	64412
89ff145a815f400ea56c450a6bd28f6fc82296fb	top-k spatio-textual similarity join	top k;similarity join;internet mobile handsets global positioning system tuning upper bound computer science australia;spatial textual database	"""With the development of location-based services (LBS), LBS users are generating more and more spatio-textual data, e.g., checkins and attraction reviews. Since a spatio-textual entity may have different representations, possibly due to GPS deviations or typographical errors, it calls for effective methods to integrate the spatio-textual data from different data sources. In this paper, we study the problem of top-<inline-formula><tex-math>$k$</tex-math> <alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""li-ieq1-2485213.gif""""/></alternatives></inline-formula> spatio-textual similarity join (<sc>Topk-STJoin</sc>), which identifies the <inline-formula><tex-math>$k$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""li-ieq2-2485213.gif""""/></alternatives></inline-formula> most similar pairs from two spatio-textual data sets. One big challenge in <sc>Topk-STJoin</sc> is to efficiently identify the top-<inline-formula> <tex-math>$k$</tex-math><alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""li-ieq3-2485213.gif""""/></alternatives></inline-formula> similar pairs by considering both textual relevancy and spatial proximity. Traditional join algorithms that consider only one dimension (textual or spatial) are inefficient because they cannot utilize the pruning ability on the other dimension. To address this challenge, we propose a signature-based top-<inline-formula><tex-math>$k$</tex-math> <alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""li-ieq4-2485213.gif""""/></alternatives></inline-formula> join framework. We first generate a spatio-textual signature set for each object such that if two objects are in the top-<inline-formula> <tex-math>$k$</tex-math><alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""li-ieq5-2485213.gif""""/></alternatives></inline-formula> similar pairs, their signature sets must overlap. With this property, we can prune large numbers of dissimilar pairs without common signatures. We find that the order of accessing the signatures has a significant effect on the performance. So, we compute an upper bound for each signature and propose a best-first accessing method that preferentially accesses signatures with large upper bounds while those pairs with small upper bounds can be pruned. We prove the optimality of our best-first accessing method. Next, we optimize the spatio-textual signatures and propose progressive signatures to further improve the pruning power. Experimental results on real-world datasets show that our algorithm achieves high performance and good scalability, and significantly outperforms baseline approaches."""	algorithm;antivirus software;baseline (configuration management);global positioning system;join (sql);location-based service;relevance;scalability;text corpus;type signature;xlink	Huiqi Hu;Guoliang Li;Zhifeng Bao;Jianhua Feng;Yongwei Wu;Zhiguo Gong;Yaoqiang Xu	2016	2016 IEEE 32nd International Conference on Data Engineering (ICDE)	10.1109/ICDE.2016.7498433	computer science;data mining;database;world wide web	DB	-15.32410450037479	-37.07945369842478	64608
72f2d2411ebd3ceb8fe4b2a9b89d927aeba02a9d	dbminer: a system for data mining in relational databases and data warehouses	spectrum;relational database;data mining;statistical analysis;data warehouse	A data mining system, DBMiner, has been developed for interactive mining of multiple-level knowledge in large relational databases and data warehouses. The system implements a wide spectrum of data mining functions, including characterization, comparison, association, classi cation, prediction, and clustering. By incorporating several interesting data mining techniques, including OLAP and attribute-oriented induction, statistical analysis, progressive deepening for mining multiple-level knowledge, and meta-rule guided mining, the system provides a user-friendly, interactive data mining environment with good performance.	cluster analysis;data mining;online analytical processing;relational database;usability	Jiawei Han;Jenny Chiang;Sonny Han Seng Chee;Jianping Chen;Shan Cheng;Wan Gong;Micheline Kamber;Krzysztof Koperski;Gang Liu;Yijun Lu;Nebojsa Stefanovic;Lara Winstone;Betty Xia;Osmar R. Zaïane;Shuhua Zhang;Hua Zhu	1997		10.1145/782010.782018	concept mining;spectrum;web mining;text mining;relational database;computer science;data science;database model;data warehouse;data mining;database;knowledge extraction;data stream mining	ML	-9.496737149444833	-31.98488426434859	65275
2dcf1a02a2d936dba1ec3d7e5c916597c1a699fb	maximal sequential pattern mining based on simultaneous monotone and anti-monotone constraints	database management systems data mining;database management systems;efficient algorithm;data mining;sequence database maximal sequential pattern mining simultaneous monotone anti monotone constraints;sequential pattern mining;sequential pattern;databases itemsets educational institutions information science iterative algorithms sun costs data mining filters iterative methods	The main challenge of mining sequential patterns is the high processing cost of support counting for large amount of candidate patterns, and a lot of patterns are not interesting to users. In this paper, a novel algorithm MSMA (maximal sequential pattern mining based on simultaneous monotone and anti-monotone constraints) incorporating both maximal and constraint-based sequential pattern mining in mining process is proposed. It allows the efficient mining of sequential patterns when both monotone and anti-monotone constraints are simultaneously pushed in mining process at different strategic stages. Our experiment shows that MSMA is an efficient algorithm for handling simultaneous monotone and anti-monotone constraints.	algorithm;data mining;maximal set;sequential pattern mining;monotone	Jia-Dong Ren;Ya-Fei Sun;Sheng Guo	2007	Third International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP 2007)	10.1109/IIH-MSP.2007.220	sequential pattern mining;computer science;pattern recognition;data mining;database	ML	-4.766276981162412	-36.45675837226854	65317
918414977d520e4044b653f5ee99c98ac32478b1	an algorithm to mine general association rules from tabular data	generalized association rule;frequent pattern;memory management;time complexity;data mining;association rule;tree structure;signature;general association rules;tabular data;equality operators	Mining association rules is a major technique within data mining and has many applications. Most methods for mining association rules from tabular data mine simple rules which only represent equality in their items. Limiting the operator only to “=” results in many interesting frequent patterns that may exist not being identified. It is obvious that where there is an order between objects, greater than or less than a value is as important as equality. This motivates extension, from simple equality, to a more general set of operators. We address the problem of mining general association rules in tabular data where rules can have all operators } , , , { = ≠ > ≤ in their antecedent part. The proposed algorithm, Mining General Rules (MGR), is applicable to datasets with discrete-ordered attributes and on quantitative discretized attributes. The proposed algorithm stores candidate general itemsets in a tree structure in such a way that supports of complex itemsets can be recursively computed from supports of simpler itemsets. The algorithm is shown to have benefits in terms of time complexity, memory management and has great potential for parallelization.	algorithm;association rule learning;auxiliary memory;data mining;detailed balance;discretization;experiment;hard disk drive;memory management;parallel computing;recursion;relational operator;requirement;table (information);time complexity;tree structure	Siyamand Ayubi;Maybin K. Muyeba;Ahmad Baraani-Dastjerdi;John A. Keane	2009	Inf. Sci.	10.1016/j.ins.2009.06.021	time complexity;association rule learning;computer science;machine learning;table;data mining;mathematics;signature;tree structure;algorithm;memory management	DB	-5.076683595490336	-37.7354279128261	65681
3d787a11646c1ebe30f2e18d23c1ef37738495e5	security checkpoint optimizer (sco): an application for simulating the operations of airport security checkpoints	airports;discrete event simulation;national security;airport security checkpoints;discrete event simulation tool;security checkpoint optimizer;security planners;transportation security administration	"""For most security planners, a key challenge is to continuously evaluate how changes or additions to their facilities or procedures impact security effectiveness, operational costs, and passenger throughput. Each change must be analyzed to ensure negative effects do not outweigh the benefits. This paper presents Security Checkpoint Optimizer (SCO), a 2-D spatially aware discrete event simulation tool developed by Northrop Grumman for the Transportation Security Administration (TSA), a part of the U.S. Department of Homeland Security. SCO is designed to allow security analysts to graphically build a simulation model and layout a series of screening activities to take place. Once the model is defined, SCO simulates passenger movement using both path-based and pathless movement algorithms to mimic a semi-autonomous passenger traversal of a 2-D space. The software is designed to allow analysts to perform multiple """"what-if"""" analyses to balance benefits and tradeoffs."""	airport security;algorithm;application checkpointing;autonomous robot;mathematical optimization;semiconductor industry;simulation;throughput	Diane Wilson;Eric K. Roe;S. Annie So	2006	Proceedings of the 2006 Winter Simulation Conference		computer security model;homeland security;technological change;simulation;security information and event management;computer science;engineering;national security;discrete event simulation;simulation modeling;computer security	EDA	-18.021710201676267	-26.317783359462176	65956
5868024fd97f71d61405380c4b9009aa02e42b64	a novel model for mining frequent patterns based on embedded granular computing		For mining frequent patterns, it is very expensive for the Apriori mining model to read the database repeatedly, and a highly condensed data structure made the FP-growth mining model cost larger memory. In order to avoid the disadvantages of these data mining model, this paper proposes a novel data mining model for discovering frequent patterns, called a data mining model based on embedded granular computing, which is different from the Apriori model and the FP-growth model. The data mining model adopts efficiently dividing and conquering from granular computing, which can construct adaptively different hierarchical granules. To form the data mining model, an embedded granular computing model is proposed in this paper. The granular computing model is used in discovering frequent patterns, on the one hand, it avoids reading the database repeatedly via constructing the extended information granule, and lessen the calculated amount of support; on the other hand, it reduces the memory requirements by the attr...	granular computing	Gang Fang;Jiale Wang;Hong Ying	2018	International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems	10.1142/S0218488518500344	a priori and a posteriori;artificial intelligence;machine learning;mathematics;data mining;division (mathematics);association rule learning;granular computing;data structure	DB	-5.05756175212334	-37.119399927392855	66020
8b5d1401d2c1e7b3a570918bbbbaf883462cf02f	the identification of cellular automata for spatio-temporal systems			automata theory;cellular automaton	Sheng Song Mei	2005				Logic	-12.522439974250782	-28.92868878611721	66113
a08b4887fae060bdc7dd196307a81af63d48b00f	laser-and-vision based probe car system toward realtime lane-based traffic data collection	automobiles;automated highways;simultaneous localization and mapping lasers vehicles probes global positioning system cameras;computer vision;road traffic control;global positioning system;object tracking advanced probe car lane based traffic data collection fusion between laser and camera image recognition;mobile handsets;multiple sensors mining laser and vision based probe car system real time lane based traffic data collection functional traffic control system intelligent traffic control system static information real time dynamic information roadside sensors in vehicle devices mobile phones road link based information gps signal urban areas vehicle sensors precision localization multisensor based positioning system;sensor fusion;laser beam applications;sensor fusion automated highways automobiles computer vision global positioning system laser beam applications mobile handsets object detection real time systems road traffic control;object detection;real time systems	A more functional and intelligent traffic control system needs not only static information about road, but also real-time dynamic information such as volume, speeds, queue lengths, and incident occurrences. Due to this reason, collecting traffic data methods have been evolving considerably and the access to real-time traffic data is becoming routine worldwide. The traditional collection methods using roadside sensors are necessary but not sufficient because of their limited coverage and expensive costs of implementation and maintenance. To solve the limit of roadside sensors, the popular probe car system can collect real-time traffic data from in-vehicle devices through mobile phones or GPS, BUT only road-link based information can be collected due to poor GPS signal in urban areas. In addition, traffic data (e.g. speed, density of vehicle) surround vehicle are not captured at all, because only the location of probe car itself is observed. In this paper, we consider localization and surround traffic data collection together to develop an advanced probe car system with various vehicle sensors, which can get not only more precision localization with multi-sensor-based positioning system, but also traffic information surround vehicle coming from and mining from multiple sensors.	control system;gps signals;global positioning system;mobile phone;point cloud;real-time clock;real-time locating system;real-time transcription;sensor;simultaneous localization and mapping	Yun Shi;Yulin Duan;Zhongchao Shi;Xiaowei Shao	2012	2012 12th International Conference on ITS Telecommunications	10.1109/ITST.2012.6425253	embedded system;computer vision;simulation;floating car data;engineering	Robotics	-18.60759586156135	-29.60237309746557	66125
ad07929222db3e406a86b60b31c3a53425710a55	trust estimation of sources over correlated propositions		This work analyzes the impact of correlated propositions when estimating the reporting behavior of information sources. These behavior estimates are critical for fusion, and traditional methods assume the propositions are statistically independent. A new source behavior estimation methods is presented that accounts for statistical dependencies between the training propositions. Simulations seem to indicate that the potential performance gains for accounting for the correlations is small relative to the increased computational complexity. One may conclude that the traditional independence assumption in source behavior estimation methods is reasonable even in cases where it is actually violated.	algorithmic efficiency;bayesian network;computation;computational complexity theory;computer simulation;ground truth;information source;natural deduction	Lance M. Kaplan;Murat Sensoy	2018	2018 21st International Conference on Information Fusion (FUSION)	10.23919/ICIF.2018.8455400	econometrics;computer science;machine learning;independence (probability theory);artificial intelligence;computational complexity theory;statistical assumption	Robotics	-7.569449080341849	-26.22131118047521	66303
ab79dbb7ce6ee36ac009d0405d59dab153888b41	an association rules algorithm based on kendall-τ	kendall τ;association rules;apriori;ontrary rules;k apriori;synchronous rules	The disadvantages of apriori algorithm are firstly discussed. Then, a new measure of kendall-τ is proposed and treated as an interest threshold. Furthermore, an improved Apriori algorithm called K -apriori is proposed based on kendall-τ correlation coefficient. It not only can accurately find the relations between different products in transaction databases and reduce the useless rules but also can generate synchronous positive rules, contrary positive rules and negative rules. Experiment has been carried out to verify the effectiveness of the algorithm. The result shows that the algorithm is effective at discovering the association rules in a sales management system.	apriori algorithm;association rule learning;coefficient;data mining;database;experiment;useless rules	Anping Zeng;Yongping Huang	2011		10.1007/978-3-642-24553-4_22	a priori and a posteriori;association rule learning;computer science;machine learning;data mining;mathematics;fsa-red algorithm;apriori algorithm;algorithm	DB	-4.758625483702051	-35.47089486649339	66900
4bde3ed119c458e506047854a85f8fd67aa30829	information-theoretic tools for mining database structure from large data sets	design tool;similarity enhancement;semantic integration of heterogeneous data;large data sets;physical design;information content;ranking function;ontologies;missing values;information theoretic;categorical data;xml databases	Data design has been characterized as a process of arriving at a design that maximizes the information content of each piece of data (or equivalently, one that minimizes redundancy). Information content (or redundancy) is measured with respect to a prescribed model for the data, a model that is often expressed as a set of constraints. In this work, we consider the problem of doing data redesign in an environment where the prescribed model is unknown or incomplete. Specifically, we consider the problem of finding structural clues in an instance of data, an instance which may contain errors, missing values, and duplicate records. We propose a set of information-theoretic tools for finding structural summaries that are useful in characterizing the information content of the data, and ultimately useful in data design. We provide algorithms for creating these summaries over large, categorical data sets. We study the use of these summaries in one specific physical design task, that of ranking functional dependencies based on their data redundancy. We show how our ranking can be used by a physical data-design tool to find good vertical decompositions of a relation (decompositions that improve the information content of the design). We present an evaluation of the approach on real data sets.	algorithm;categorical variable;cluster analysis;constraint (mathematics);data modeling;data redundancy;design tool;functional dependency;information theory;missing data;physical design (electronics);self-information	Periklis Andritsos;Renée J. Miller;Panayiotis Tsaparas	2004		10.1145/1007568.1007650	physical design;data modeling;self-information;categorical variable;computer science;ontology;data mining;xml database;database;information retrieval	DB	-6.198794919080395	-32.31699171491224	67056
ca7b350ecc0620cd391ef5ac45769dd44e9705ed	new fast algorithm for incremental mining of association rules	association rule	Mining association rules is a well-studied problem, and several algorithms were presented for finding large itemsets. In this paper we present a new algorithm for incremental discovery of large itemsets in an increasing set of transactions. The proposed algorithm is based on partitioning the database and keeping a summary of local large itemsets for each partition based on the concept of negative border technique. A global summary for the whole database is also created to facilitate the fast updating of overall large itemsets. When adding a new set of transactions to the database, the algorithm uses these summaries instead of scanning the whole database, thus reducing the number of database scans. The results of applying the new algorithm showed that the new technique is quite efficient, and in many respects superior to other incremental algorithms like Fast Update Algorithm (FUP) and Update Large Itemsets (ULI).	algorithm;association rule learning;dynamic problem (algorithms);windows update	Yasser El-Sonbaty;Rasha Kashef	2004			data mining;population-based incremental learning;association rule learning;computer science;fsa-red algorithm	DB	-5.5427448196523885	-37.2242054918738	67206
13d303a3536a550ad617130c5695075f8b6c1a40	deciphering dynamics of recent epidemic spread and outbreak in west africa: the case of ebola virus	transcritical bifurcation;basic reproduction number;ebola epidemic model;turing instability	Recently, the 2014 Ebola virus (EBOV) outbreak in West Africa was the largest outbreak to date. In this paper, an attempt has been made for modeling the virus dynamics using an SEIR model to better understand and characterize the transmission trajectories of the Ebola outbreak. We compare the simulated results with the most recent reported data of Ebola infected cases in the three most affected countries Guinea, Liberia and Sierra Leone. The epidemic model exhibits two equilibria, namely, the disease-free and unique endemic equilibria. Existence and local stability of these equilibria are explored. Using central manifold theory, it is established that the transcritical bifurcation occurs when basic reproduction number passes through unity. The proposed Ebola epidemic model provides an estimate to the potential number of future cases. The model indicates that the disease will decline after peaking if multisectorial and multinational efforts to control the spread of infection are maintained. Possible implication of the results for disease eradication and its control are discussed which suggests that proper control strategies like: (i) transmission precautions, (ii) isolation and care of infectious Ebola patients, (iii) safe burial, (iv) contact tracing with follow-up and quarantine, and (v) early diagnosis are needed to stop the recurrent outbreak.	bifurcation theory;care-of address;computer virus;emoticon	Ranjit Kumar Upadhyay;Parimita Roy	2016	I. J. Bifurcation and Chaos	10.1142/S021812741630024X	basic reproduction number;transcritical bifurcation;simulation;mathematics;operations research	ML	-11.602533864880192	-23.95715442326621	67973
104a7831f15a17f85e056d8ffbe8554998bf3d03	structuring the personal multimedia collection of a mobile device user based on geolocation	content based retrieval multimedia communication mobile communication radionavigation bayes methods maximum likelihood estimation information retrieval;mobile device;information retrieval;bayes methods;maximum likelihood estimation;radionavigation;map approach personal multimedia collection mobile device user geolocation multimedia data analysis automatic annotation electronic diaries content based retrieval wearable computing multimedia content information overflow time oriented meaningful episodes geographical location audiovisual material model based temporal structuring bayesian approach;multimedia data;multimedia communication;mobile communication;wearable computer;information retrieval content based retrieval wearable computers personal digital assistants mobile computing multimedia computing data analysis trajectory bayesian methods mobile handsets;content based retrieval	"""This paper addresses a still original issue at the crossroads of multimedia data analysis for content-based retrieval, and wearable computing. As users are acquiring multimedia content personal mobile devices, they are getting also undergoing information overflow. The problem of structuring the content into time-oriented meaningful episodes is addressed, and we argue that geographical location processing is crucial, as a complement to processing audiovisual material. A technique for model-based temporal structuring of one’s trajectory during a day is presented, based on a Bayesian/MAP approach, that generates one or several summaries. Experimental results illustrate the applicative interest of the problem addressed and validates the proposed solution. 1. CONTEXT AND OBJECTIVE The work exposed in the present paper addresses needs related to information retrieval in personal mobile devices, especially aiming at those which purpose is to be continuously carried by their user, such as mobile phones and PDAs. Indeed, such small wireless terminals are undergoing considerable progress in their ability to capture, store, process and transmit data, notably of the multimedia form. Several models that incorporate image and audio acquisition, as well as geolocation of the users and that are targeting the general public, are currently being released, or are soon to be on the market. As multimedia content is gathered, it progressively builds up a valuable memory of ones’s life, which can be later searched, whether for practical, emotional, or much-sought fun pass-time purposes. A means of access that could prevail is the familiar time management software available on PDAs, with calendar-like views on which multimedia content could be “annotated”. Yet, for the owner to quickly, reliably and comfortably retrieve a well-defined piece of information in a large collection, or merely browse in it to get an overall idea, the content ought to be organized, at least partly automatically. More precisely, bearing in mind the the stringent input and display constraints of mobile devices, we believe a crux is the ability to generate compact summaries of one’s activities during a given period, that suit visualization and browsing needs, including the abovementioned need with the straying-type of browsing. Our focus is on proposing techniques for structuring the collection along the time-axis, via analysis of the multimedia data. Although the more general problem of content-based retrieval of audiovisual material has largely being addressed for several years (e.g. TV summaries[l, 2]), understanding of needs and working out of solutions dedicated to the the particular context tackled here 0-7803-7304-9/02/$17.00 C2002 IEEE 241 remains rather open. Early exploration of the automated diary concept was proposed in [3,4], yet leaving out multimedia. Recently, proposals have been made towards organizing one’s personal image collection, based on image features [5]. Towards organization of video collected from a wearable computer, a summarization technique was presented in [6], which rates the interest of video shots via measurements on brain waves. The structures that are extracted from the personal data collection (e.g. through statistical leaming) are utilized here for navigating within the collection, but they may also benefit other purposes : context-awareness [7] and prediction [8]. For instance in [9], the authors propose automatic discovery of the user’s frequented places and assignement of location-sensitive reminders. Alternatively, a technique to leam and infer location from image sequences acquired from a worn camera is presented in [lo], so as to avoid the difficulties of accurate indoor localization. In [l 11, we proposed to determine, from wearable video, periods when the user had met people, by coupling probabilistic face detection with HMM, leading to visual time-oriented summaries. In the present paper, we examine the unsupervised generation of summaries from geographical position sequence recordings. The results section shows how these contributions may be combined. We advocate the use of location because it appears realistic and useful. Indeed, it is not restricted to wearable computing platforms, but is also to be available on less intrusive, lower-price, ordinary mobile phones, whether with audio-visual capabilities of not. Further, it is relatively reliable, compared to most information that may be extracted from wearable images and audio. With time and identity of people the user met, it is likely to be the major searchhowse criterion for searching one’s data collection, and it is indeed quite easy to express for the user (e.g. compared to image-based queries). Also, from our experiments, location accuracy fades more slowly in one’s memory than altemative searchhrowse criteria, especially in the long run. Finally, the use of positioning only places modest storage and processing requirements. Positioning technologies, surveyed in [12], may be GPS (possibly GSM network-assisted GPS), GSM basestation triangulationbased techniques such as E-OTD or its WCDMA successor, or cell identifier ; there is likely to be time-switching or fusion among these sensors, depending on local availability, reliability or subscription. Besides, indoor performance is under encouraging R&D [13] and post-processing is likely to be performed (e.g. in the form of enhanced Kalman filtering). Due to this improving and unstable situation, the present work is not dedicated to a particular technology or noise characteristics, but remains on the white Gaussian noise assumption (whereas actual corruption on measurements is likely to be time-correlated and its variance would be time-varying). Still, the statistical framework employed is flexible enough to introduce more elaborate noise models. Let us finally mention that in our application, the sampling rate would typically be a few seconds. In the remainder of the paper, we formalize the problem and outline its solution (section 2), providing developments in sections (2.1) and (2.2). Section 3 presents experimental results, while section 4 summarizes the contribution and suggests further work. 2. STATISTICAL TRAJECTORY SEGMENTATION The general problem may be stated as summarizing the observed spatio-temporal trajectory o = {ot = (zt, yt)}, t = 1, .., T of the user. In fact, the sub-goal tackled in this paper consists in partitioning the time-series into time segments, represented by the sequence s = { s t } , t = 1, .., T of hidden state labels, in which st indicates to which of the M models ot is assigned. The process should be as data-driven (unsupervised) as possible, regarding M the number of segments. With [14], and in contrast to [15], we consider that the degree of homogeneity within a segment should also be as much as possible estimated from the data, rather than be set a priori. Besides, we conjecture that segmentation of the trajectory according to a piece-wise parametric model provides a reasonnably meaningful account of the episodes that compose the period to be processed, at least for short periods (e.g. a day). Let 8 = { e h , k E (1,. . . M } } denote the set of parameters vectors. Linear models are assumed in the remainder of the paper. We consider batch processing (that would occur e.g. every evening), but the technique proposed can be made incremental. Given these requirements, the problem comprises the two following aspects : the classical interwoven issues of unsupervised data clustering are gathered : estimating rhe model parameters, associating the data to the models, and determining the adequate number of models. the sequentiality of measurements should be introduced, so as to guarantee time-connexity of data assigned to a model, and limit spurious models due to very noisy measurements. Denoting by S be the set of possible partitions, the chosen optimality criterion is the maximum a posteriori (MAP) label configuration, defined by (1). A = """"gyEy PQ(sl0) wgmm PS(o(s )P(s ) (1) S € S The MAP criterion is a Bayesian estimator that transforms the search into an optimization problem. In our case, the search is conducted as follows : the search space is partitionned into subspaces {sk}, 1 5 k 5 T, where sk contains all segmentations composed of k segments. Search within each subspace is conducted independently, as detailled in section 2.1. The solutions obtained for these various segmentation complexities are compared (section 2.2) and one or several global solutions are finally selected. For our application, we might not be only interested in a single, but in extracting several pertinent segmentations of the trajectory, especially if they can all summarize well the data, with various degrees of granularity, so as to supply the user with several alternative visual representations at multiple temporal scales. 2.1. Search for an optimal segmentation within a subspace s k The search for a maximum likelihood estimate of 0 is conducted by means of the Expectation-Maximization (EM) algorithm [16]. It is a well-known iterative scheme which, provided with some initialization for 8, replaces the (ignored) data-to-model assignments by their statistical expectation ( E step), given the current parameter values. Therefrom, new parameter values may be computed (M-step), until (garanteed, but possibly slow) convergence. In our case, still, the data-to-model assignments are more restricted as in common clustering situations, as data assigned to a model should be connected in time. In terms of our model, the probabilities of assigning a data element to a model are not independent among the data set. This structural constraint on the search space is dealt with by setting a hidden Markov model structure on the label sequence that constraints, via the transition matrix, connectivity of identical labels. Conditionally to models parameters 8 and segmentation complexity k, the MAP sequence is straightforwardly e"""	apache axis;applicative programming language;assisted gps;batch processing;bayesian network;browsing;cluster analysis;context awareness;control theory;data element;expectation–maximization algorithm;experiment;face detection;geolocation;global positioning system;hidden markov model;identifier;information overload;information retrieval;iteration;iterative method;kalman filter;linear model;location (geography);markov chain;mathematical optimization;mobile device;mobile phone;neural oscillation;optimality criterion;optimization problem;organizing (structure);parametric model;personal digital assistant;personally identifiable information;relevance;requirement;sampling (signal processing);sensor;statistical machine translation;statistical model;stochastic matrix;time series;unsupervised learning;video post-processing;wearable computer	Marc Gelgon;Kevin Tilhou	2002		10.1109/ICME.2002.1035561	mobile search;mobile telephony;wearable computer;computer science;operating system;mobile device;multimedia;maximum likelihood;world wide web;information retrieval;statistics	Web+IR	-17.043713889083595	-36.57266847092435	67990
8360d6bca6555a381567830d067256a33c59db1e	joint top-k spatial keyword query processing	google;electronic mail;query processing;textual databases;joints;journal article;textual databases spatial databases;indexes;indexes query processing spatial databases mobile communication google electronic mail;spatial databases;mobile communication;journal magazine article	Web users and content are increasingly being geopositioned, and increased focus is being given to serving local content in response to web queries. This development calls for spatial keyword queries that take into account both the locations and textual descriptions of content. We study the efficient, joint processing of multiple top-k spatial keyword queries. Such joint processing is attractive during high query loads and also occurs when multiple queries are used to obfuscate a user's true query. We propose a novel algorithm and index structure for the joint processing of top-k spatial keyword queries. Empirical studies show that the proposed solution is efficient on real data sets. We also offer analytical studies on synthetic data sets to demonstrate the efficiency of the proposed solution.	algorithm;synthetic data	Dingming Wu;Man Lung Yiu;Gao Cong;Christian S. Jensen	2012	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2011.172	database index;mobile telephony;computer science;data mining;database;world wide web;spatial database;information retrieval;query language;spatial query	DB	-14.979120870858916	-36.85348774494997	68078
629a75d9734cd723209bb8dcb009021f9b07a93b	robust discovery of positive and negative rules in knowledge bases		"""We present RUDIK, a system for the discovery of declarative rules over knowledge-bases (KBs). RUDIK discovers rules that express positive relationships between entities, such as """"if two persons have the same parent, they are siblings"""", and negative rules, i.e., patterns that identify contradictions in the data, such as """"if two persons are married, one cannot be the child of the other"""". While the former class infers new facts in the KB, the latter class is crucial for other tasks, such as detecting erroneous triples in data cleaning, or the creation of negative examples to bootstrap learning algorithms. The system is designed to: (i) enlarge the expressive power of the rule language to obtain complex rules and wide coverage of the facts in the KB, (ii) discover approximate rules (soft constraints) to be robust to errors and incompleteness in the KB, (iii) use disk-based algorithms, effectively enabling rule mining in commodity machines. In contrast with traditional ranking of all rules based on a measure of support, we propose an approach to identify the subset of useful rules to be exposed to the user. We model the mining process as an incremental graph exploration problem and prove that our search strategy has guarantees on the optimality of the results. We have conducted extensive experiments using real-world KBs to show that RUDIK outperforms previous proposals in terms of efficiency and that it discovers more effective rules for the application at hand."""	approximation algorithm;association rule learning;discovery system;entity;experiment;exploration problem;machine learning;plasma cleaning;scalability;sensor	Stefano Ortona;Venkata Vamsikrishna Meduri;Paolo Papotti	2018	2018 IEEE 34th International Conference on Data Engineering (ICDE)	10.1109/ICDE.2018.00108	data mining;expressive power;knowledge base;exploration problem;computer science;ranking;data quality;graph	DB	-10.178152529872165	-32.58185465301552	68228
a5408975e18c9d255a3e1a3df0baf1fb560a29bb	a multi-dimensional indexing approach for timestamped event sequence matching	time window;index structure;timestamped event sequence matching;multi dimensional;indexation;sequence database;similar sequence matching;multi dimensional index;matching method;event sequence	This paper addresses the problem of timestamped event sequence matching, a new type of similar sequence matching that retrieves the occurrences of interesting patterns from timestamped sequence databases. The sequential-scan-based method, the trie-based method, and the method based on the iso-depth index are well-known approaches to this problem. In this paper, we point out their shortcomings, and propose a new method that effectively overcomes these shortcomings. The proposed method employs an R*-tree, a widely accepted multi-dimensional index structure that efficiently supports timestamped event sequence matching. To build the R*-tree, this method extracts time windows from every item in a timestamped event sequence and represents them as rectangles in n-dimensional space by considering the first and last occurring times of each event type. Here, n is the total number of disparate event types that may occur in a target application. To resolve the dimensionality curse in the case when n is large, we suggest an algorithm for reducing the dimensionality by grouping the event types. Our sequence matching method based on the R*-tree performs with two steps. First, it efficiently identifies a small number of candidates by searching the R*-tree. Second, it picks out true answers from the set of candidates. We prove its robustness formally, and also show its effectiveness via extensive experiments. 2007 Elsevier Inc. All rights reserved.	algorithm;curse of dimensionality;database;dimensionality reduction;elegant degradation;experiment;microsoft windows;r* tree;speedup;trie;trusted timestamping;xslt/muenchian grouping	Sanghyun Park;Jung-Im Won;Jeehee Yoon;Sang Wook Kim	2007	Inf. Sci.	10.1016/j.ins.2007.06.020	computer science;pattern recognition;sequence database;data mining;mathematics;algorithm	DB	-8.049400913049157	-36.935815487044884	68395
284dd4baeb9fb01acb5651ad38fddefcf937cf6d	d-aid - an app to map disasters and manage relief teams and resources		Abstract   Natural or man-made disasters cause damage to life and property. Lack of appropriate emergency management increases the physical damage and loss of life. D-Aid, the smartphone App proposed by this article, intends to help volunteers and relief teams to quickly map and aid victims of a disaster. Anyone can put an occurrence after a disaster on a web map streamlining and decentralizing the information access. Through visualization techniques like heat maps and voronoi diagrams on a map implemented in the D-Aid app and also on a web map everyone can easily get information about amount of victims, their necessities and eminent dangers after disasters.		Luana Carine Schunke;Luiz Paulo Luna de Oliveira;Mauricio Cardoso;Marta Becker Villamil	2015		10.1016/j.procs.2015.05.469	simulation;computer security	NLP	-18.429917123280976	-24.143106712933818	68458
b2c439f5b31add5e5448dba0cffaca2e3201c55c	hidden markov models for abnormal event processing in transportation data streams	hidden markov models training real time systems engines computational modeling noise measurement computers;traffic information systems cloud computing data handling hidden markov models;hidden markov models;traffic information systems;public transport hidden markov models big data metadata event processing event driven architecture;cloud hidden markov models abnormal event processing transportation data streams metadata computationally intensive algorithms public transport time consuming algorithms hmm;data handling;cloud computing	Making sense of big data and big metadata remains a challenge as more and more data are churned out every day. The problem of adding value to unstructured data requires the application of computationally intensive algorithms to discover useful patterns in the data. In terms of data streams from public transport such as buses, we address the problem of performing time-consuming algorithms to model the data while still being able to process abnormal events in real-time. We propose using Hidden Markov Models (HMMs) for identifying conditions for an abnormal event in bus journeys and methods for isolating HMM computations from real-time event processing. Results show that training HMMs with even noisy metadata can generate models that can recognize an abnormal event in a parallel and distributed manner in the cloud.	apache hadoop;big data;cloud computing;complex event processing;computation;forward algorithm;hidden markov model;image scaling;mapreduce;markov chain;real-time clock;real-time locating system;sensor	John Kah Soon Lau;Chen-Khong Tham	2012	2012 IEEE 18th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2012.133	cloud computing;computer science;data science;operating system;group method of data handling;data mining;database;markov model;hidden markov model	HPC	-12.228274110724204	-34.009090040488275	68509
1855fb59a0d11cb6671bf70c6b73ee8610b8e837	climate alteration in the metropolitan area of bari: temperatures and relationship with characters of urban context	urban morphology;gis;urban heat island	Urban planning exerts influences on environmental, social and economic system related with the city. Processes of land transformation and city growth determine radical changes in urban landscape morphology and as a consequence they affect air temperature and energy exchange. The urbanization can bear on local climate more intensively than the global warming does. This is due to the rapidity of human made changes related to natural ones. The present work analyzes the state of the art of studies involved in studying urban climate anomalies – Urban Heat Islands (UHI) – in order to explore relationship between urban planning morphology and urban climate. The research aim wants to indentify how urban geometry can be related with climate alterations in order to provide guidelines for planners to frame urban form planning and environmental quality. The case study is the city of Bari, located on the coast of the Mediterranean sea, in Apulia, one of the regions in Italy.	galaxy morphological classification;urban computing	Pierangela Loconte;Claudia Ceppi;Giorgia Lubisco;Francesco Paolo Mancini;Claudia Piscitelli;Francesco Selicato	2012		10.1007/978-3-642-31075-1_39	urban density;urban climate;geomatics;urban ecosystem;urban climatology;urban heat island	HCI	-12.837313255149036	-24.21333480470308	68626
d558e4abb0b1cc0dee0afaf1cbd72f6c2dca88f6	coupled dynamic data-driven framework for forest fire spread prediction		Predicting the potential danger of a forest fire is an essential task of wildfire analysts. For that reason, many scientists have focused their efforts on developing propagation models that predict forest fire evolution to mitigate the consequences of such hazards. These propagation models require a precise knowledge of the whole environment where the fire is taking place. In the context of natural hazards simulation, it is well known that, part of the final forecast error comes from the uncertainty in the input data. In this work, we use a Dynamic Data-driven methodology to overcome such problem. The core of the methodology is a calibration stage previous to the forecast where complementary models, data injection and intelligent systems are working in a symbiotic way to reduce the forecast errors at real time. This approach has been tested using a forest fire that took place in Arkadia (Greece) in 2011.		Carlos Brun;Ana Carolina Castro Côrtes;Tomàs Margalef	2014		10.1007/978-3-319-25138-7_6	forestry	ML	-13.145701893023782	-25.646907234794472	68693
0037ba1976b53d543a94d7f07e5a3085c43ba694	customer behavior modelling using radio frequency identification data and the hidden markov model	hidden markov model;stop behavior customer behavior modelling radio frequency identification data hidden markov model rfid technology customer movement paths supermarkets hmm sales areas shopping momentum pass by behavior;hidden markov models marketing and sales radiofrequency identification data models registers mathematical model computational modeling;hidden markov models;radiofrequency identification consumer behaviour hidden markov models;customer behavior model;consumer behaviour;radio frequency identification;shopping momentum effect;shopping momentum effect radio frequency identification customer behavior model supermarket shopping hidden markov model;supermarket shopping;radiofrequency identification	"""Developments in radio frequency identification (RFID) technology have made data on customer movement paths in supermarkets available. In this paper, we propose a method for customer behavior modeling by using RFID data and the hidden Markov model (HMM). In this method, """"Stop"""" and """"Pass by"""" behavior are estimated and the proposed method is evaluated by predicting the sales areas where customers actually purchased items. Using this method, we also demonstrate the shopping momentum. This effect, however, is experienced by only some customers, not all."""	behavior model;hidden markov model;markov chain;radio frequency;radio-frequency identification	Katsutoshi Yada;Natsuki Sano	2012	2012 Annual SRII Global Conference	10.1109/SRII.2012.63	simulation;marketing;advertising;business	Robotics	-12.971564328713509	-30.749867420290038	68714
bc8d419c7356c65f5537733cf74d5b715f33c6b7	a fast algorithm for mining sequential patterns from large databases	set operation;data mining;set opera tion;fast algorithm;sequential pattern;knowledge discovery	Mining sequential patterns from large databases has been recognized by many researchers as an attractive task of data mining and knowledge discovery. Previous algorithms scan the databases for many times, which is often unendurable due to the, very large amount of databases. In this paper, the authors introduce an effective algorithm for mining sequential patterns from large databases. In the algorithm, the original database is not used at all for counting the support of sequences after the first pass. Rather, a tidlist structure generated in the previous pass is employed for the purpose based on set intersection operations, avoiding the multiple scans of the databases.	algorithm;data mining and knowledge discovery;database	Ning Chen;An Chen;Longxiang Zhou;Liu Lu	2001	Journal of Computer Science and Technology	10.1007/BF02948984	computer science;data science;data mining;database;knowledge extraction	ML	-5.217664974800318	-37.07785414979536	68799
dcd1d013765846ea9793f1b2316060de059002c2	intuitionistic fuzzy reasoning with cognitive maps	decision support fuzzy cognitive maps intuitionistic fuzzy sets reasoning;intuitionistic fuzzy set;cognitive map;pragmatics;decision support;steady state cognition pragmatics diseases lungs numerical models computer aided software engineering;cognitive systems;fuzzy reasoning;intuitionistic fuzzy sets;lungs;fuzzy set theory cognitive systems computational linguistics formal logic fuzzy reasoning;fuzzy set theory;computer aided software engineering;fuzzy cognitive maps;numerical model;cognition;formal logic;reasoning process intuitionistic fuzzy reasoning fuzzy cognitive map decision support hesitancy aware reasoning intuitionistic fuzzy logic intuitionistic fuzzy set linguistic representation human hesitancy cognitive model;diseases;fuzzy cognitive map;computational linguistics;reasoning;numerical models;steady state	Fuzzy cognitive maps have proven an exceptional means to reasoning for decision support. In this paper we propose a novel approach to hesitancy-aware reasoning based on cognitive maps and intuitionistic fuzzy logic. Intuitionistic fuzzy sets are considered for the linguistic representation of both the concepts of a cognitive map and the relations defined between them. A comparative advantage of this approach over the state of the art is an intrinsic mechanism of modeling human hesitancy, as introduced in the construction of a cognitive model, and propagated through the reasoning process to a final decision. A numerical example demonstrates its effectiveness which can extend to a variety of real-world applications.	approximation algorithm;cognitive model;decision support system;fuzzy cognitive map;fuzzy logic;fuzzy set;intuitionistic logic;numerical analysis;risk assessment;semantics (computer science)	Dimitrios K. Iakovidis;Elpiniki I. Papageorgiou	2011	2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)	10.1109/FUZZY.2011.6007640	discrete mathematics;fuzzy cognitive map;computer science;artificial intelligence;computational linguistics;machine learning;mathematics;pragmatics	Robotics	-5.486560921890489	-24.293986114935347	68850
c3ebf71bbb3bc3b81768d2b32bfef7602f3b48e2	big data gis analytics towards efficient waste management in stockholm	other environmental engineering;big data analytics;annan naturresursteknik;smart cities;gis;transportation;waste management	This paper presents preliminary findings from a big data analysis and GIS to identify the efficiency of waste management and transportation in the City of Stockholm. The aim of this paper is to ide ...	big data;geographic information system	Hossein Shahrokni;Bram Van der Heijde;David Lazarevic;Nils Brandt	2014		10.2991/ict4s-14.2014.17	environmental engineering;engineering;civil engineering;waste management	DB	-15.190590835472065	-24.263364020702063	69108
e27ad51052ffdd720b8744a5a321ae2d8469044f	aster servers: how to make aster more widely available.				A. Hashmi;B. Barry;R. Lundquist;M. Krishnamoorthy	1996			remote sensing;aster (genus);computer science;server	Logic	-11.065460021553355	-27.321968201539953	69860
ac0347dfc725408bd5f5967c68da91b9dbe8d077	coincidence detection: a fast method for discovering higher-order correlations in multidimensional data	multidimensional data;coincidence detection;higher order	"""We present a novel, fast method for associationmining ill high-dimensional datasets. Our Coincidence Detection method, which combines random sampling and Chernoff-Hoeffding bounds with a novel coding/binning scheme, avoids the exhaustive search, prior limits on the order k of discovered associations, and exponentially large parameter space of other methods. Tight theoretical bounds on the complexity of randomized algorithms are impossible without strong input distribution assumptions. However, we observe sublineal"""" time, space and data complexity in tests on constructed artificial datasets and in real application to important problems in bioinformatics and drug discovery. After placing the method in historical and mathematical context, we describe the method, and present theoretical and empirical results on its complexity and error. Getting information from a table is like extracting sunlight from a cucumber. (H. Farquhar, """"Economic and Industrial Delusions"""", 1891)"""	bioinformatics;brute-force search;chernoff bound;complexity;cucumber;product binning;randomized algorithm;sampling (signal processing)	Evan W. Steeg;Derek A. Robinson;Ed Willis	1998			mathematical optimization;higher-order logic;computer science;theoretical computer science;machine learning;data mining;mathematics;coincidence detection in neurobiology;statistics	ML	-7.268388691198265	-33.157768495769005	69972
42d2d85065a59b042557adf369f762e2b1d3b815	alice: an information-rich autonomous vehicle for high-speed desert navigation	architectural design;autonomous vehicle;real time;contingency management;trajectory optimization;rapid assessment;networked control system;high performance;high speed	This paper describes the implementation and testing of Alice, the California Institute of Technology’s entry in the 2005 DARPA Grand Challenge. Alice utilizes a highly networked control system architecture to provide high performance, autonomous driving in unknown environments. Innovations include a vehicle architecture designed for efficient testing in harsh environments, a highly sensory-driven approach to fuse sensor data into speed maps used by real-time trajectory optimization algorithms, health and contingency management algorithms to manage failures at the component and system level, and a software logging and display environment that enables rapid assessment of performance during testing. The system successfully completed several runs in the National Qualifying Event, but encountered a combination of sensing and control issues in the Grand Challenge Event that led to a critical failure after traversing approximately 8 miles.	algorithm;autonomous car;autonomous robot;control system;darpa grand challenge (2007);map;mathematical optimization;real-time transcription;reliability engineering;systems architecture;trajectory optimization	Lars B. Cremean;Tully B. Foote;Jeremy H. Gillula;George H. Hines;Dmitriy Kogan;Kristopher L. Kriechbaum;Jeffrey C. Lamb;Jeremy Leibs;Laura Lindzey;Christopher E. Rasmussen;Alexander D. Stewart;Joel W. Burdick;Richard M. Murray	2006	J. Field Robotics	10.1002/rob.20135	embedded system;trajectory optimization;real-time computing;simulation;computer science;networked control system;engineering;artificial intelligence;contingency management	Robotics	-13.989729128305976	-28.148570067894106	70050
500bc610c51c461734933d2a4763274e083f38e0	mining recent frequent itemsets in sliding windows over data streams	data stream;frequent itemset;sliding window	This paper considers the problem of mining recent frequent itemsets over data streams. As the data grows without limit at a rapid rate, it is hard to track the new changes of frequent itemsets over data streams. We propose an efficient one-pass algorithm in sliding windows over data streams with an error bound guarantee. This algorithm does not need to refer to obsolete transactions when 316 C. Han, L. Xu, G. He they are removed from the sliding window. It exploits a compact data structure to maintain potentially frequent itemsets so that it can output recent frequent itemsets at any time. Flexible queries for continuous transactions in the sliding window can be answered with an error bound guarantee.	data structure;han unification;microsoft windows;one-pass algorithm;scalability	C. Han;L. Xu;G. He	2008	Computing and Informatics		sliding window protocol;real-time computing;computer science;data mining;database	ML	-7.9117008361179	-35.316747248466534	70264
dbca74176f3c22a4476ea16dfe5751d62d9c41e3	virtual apple tree pruning in horticultural education	stochastic process;computer model;fruit set;visualization;malus domestica;heading;apple tree malus domestica;growth model;model simulation;markov chain	A computer model of branching responses of apple trees ( Malus domestica  ) with different levels of pruning schemes is presented. The model simulates the number and distributions of the axillary production along one-year-old parent branches using the Hidden Semi-Markov Chain (HSMC). Results show that (a) simulation system efficiently provides the required information at the desired level of accuracy, and (b) the branch growth model is extremely well calibrated against real apple trees and (c) the system can simulate many interesting growth situations with direct feedback from the different levels of pruning schemes presenting the parent branches' characteristics, such as, location of flower, fruit setting, and so on. The method used in this paper aims at providing a quantitative tool for orchard management in horticultural education, particularly with regard to pruning practices.		Ning Xia;Ai-Shuang Li;Dan-Feng Huang	2009		10.1007/978-3-642-03364-3_4	stochastic process;markov chain;simulation;visualization;statistics	NLP	-14.309785013268243	-25.327707815599158	70283
a0829e168ed446bd7584ab0aa1883c8bc40bd8db	developing a transportation support system for vulnerable road users in local community	ride sharing transportation support vulnerable road users;vulnerable road users;automobiles urban areas public transportation roads aging schedules;ride sharing;public transportation transportation support system vulnerable road users local community urban area delta region suburban slope residential estates living environment elderly people traffic attitude survey itsukaichi district hiroshima city;transportation support;traffic information systems assisted living public transport	Hiroshima City is surrounded by mountains on its three sides, the east, north, and west, except the south facing the sea, and besides, its urban area places delta region. For this reason, the population of Hiroshima City is concentrated in the slope residential estates at the surrounding mountains of the city. However, the living environment of the suburban slope residential estates doesn't seem so suitable for vulnerable road users, mainly elderly people. Thus in this paper, based on the traffic attitude survey results for residents in the slope residential estates at Itsukaichi district, Hiroshima City, previously conducted by our previous works, we examine an effective way to support vulnerable road users and to enrich their life. Especially, we develop a prototype system to support the transportation for residents living in a place where public transportation is not sufficiently developed.	prototype	Shimpei Matsumoto;Nobuyuki Ohhigashi;Takashi Hasuike	2016	2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)	10.1109/IIAI-AAI.2016.30	environmental engineering;geography;civil engineering;transport engineering	HCI	-16.886500326062162	-28.05124754499429	70436
59475e7a3a517634e37c1a36e993dd3e88a36bca	inferring the cause of errors for a scalable, accurate, and complete constraint-based data cleansing		In real-world dirty data, errors are often not randomly distributed. Rather, they tend to occur only under certain conditions, such as when the transaction is handled by a certain operator, or the weather is rainy. Leveraging such common conditions, or “cause conditions”, the proposed data-cleansing algorithm resolves multi-tuple conflicts with high speed, achieves higher completeness, and runs with high accuracy in realistic settings. We first present complexity analyses of the problem, pointing out two subproblems that are NP-complete. We then introduce, for each subproblem, heuristics that work in sub-polynomial time. We also raise the issue that some previous studies overlook the notion of repair-completeness, which means, having less number of unsolved conflicts in the resulting repairs. The proposed method is capable of obtaining a complete repair if we are allowed to preprocess the input set of constraints. The algorithms are tested with three sets of data and rules. The experiments show that, compared to the state-of-the-art methods for conditional functional dependencies-based and FD-based data cleansing, the proposed algorithm scales better with respect to the data size, is the only method that outputs complete repairs, and is more accurate especially when the error distribution is skewed.	algorithm;dirty data;experiment;functional dependency;heuristic (computer science);np-completeness;polynomial;preprocessor;randomness;scalability;time complexity	Ayako Hoshino;Hiroki Nakayama;Chihiro Ito;Kyota Kanno;Kenshi Nishimura	2015	Vietnam Journal of Computer Science	10.1007/s40595-015-0052-y	theoretical computer science;machine learning;data mining;algorithm	DB	-7.969598510328186	-35.895488415181674	70607
73c6472e86e4a3ac551f29c6fa7a0329f02f9928	interrogating feature learning models to discover insights into the development of human expertise in a real-time, dynamic decision-making task	tetris;methods;cross entropy reinforcement learning;cognitive skill;machine learning;perceptual learning;expertise;strategies;experts	Tetris provides a difficult, dynamic task environment within which some people are novices and others, after years of work and practice, become extreme experts. Here we study two core skills; namely, (a) choosing the goal or objective function that will maximize performance and (b)a feature-based analysis of the current game board to determine where to place the currently falling zoid (i.e., Tetris piece) so as to maximize the goal. In Study 1, we build cross-entropy reinforcement learning (CERL) models (Szita & Lorincz, 2006) to determine whether different goals result in different feature weights. Two of these optimization strategies quickly rise to performance plateaus, whereas two others continue toward higher but more jagged (i.e., variable) heights. In Study 2, we compare the zoid placement decisions made by our best CERL models with those made by 67 human players. Across 370,131 human game episodes, two CERL models picked the same zoid placements as our lowest scoring human for 43% of the placements and as our three best scoring experts for 65% of the placements. Our findings suggest that people focus on maximizing points, not number of lines cleared or number of levels reached. They also show that goal choice influences the choice of zoid placements for CERLs and suggest that the same is true of humans. Tetris has a repetitive task structure that makes Tetris more tractable and more like a traditional experimental psychology paradigm than many more complex games or tasks. Hence, although complex, Tetris is not overwhelmingly complex and presents a right-sized challenge to cognitive theories, especially those of integrated cognitive systems.	accidental falls;artificial intelligence;choose (action);clinical act of insertion;cobham's thesis;codependency (psychology);cross entropy;feature learning;height;learning disorders;loss function;mathematical optimization;optimization problem;plato (computer system);performance tuning;programming paradigm;real-time transcription;reinforcement learning;score;tetris;theory;weight;strategy	Catherine Sibert;Wayne D. Gray;John K. Lindstedt	2017	Topics in cognitive science	10.1111/tops.12225	psychology;cognitive psychology;robot learning;cognitive skill;error-driven learning;strategy;computer science;artificial intelligence;machine learning;pattern recognition;perceptual learning;social psychology	ML	-9.70058680654097	-28.39851571295681	70697
a378f039986800e7a16c3189684c4baead14ebce	analyzing civic complaints for proactive maintenance in smart city	bounding box urban computing civic complaints data mining dynamic grid based clustering;urban planning;data mining;civic complaints;town and country planning pattern clustering smart cities;smart cities;merging smart cities clustering algorithms heuristic algorithms data preprocessing urban planning;heuristic algorithms;dynamic grid based clustering;merging;clustering algorithms;urban computing;quality of life civic complaints proactive maintenance smart city civic issues street condition traffic proactive decisions city authority urban computing urban planning urban areas segregation two phase clustering dynamic grid based clustering spatial attribute location based clusters complaint category complaint behavior new york usa bangalore india inhabitant satisfaction rate;data preprocessing;bounding box	To transform a city into a smart city it is important to focus on civic issues faced by the inhabitants. Civic complaints incorporate problems related to street condition, traffic, noise, water etc. Their analysis can contribute to proactive decisions to be taken by the city authority. Urban Computing is applied in many areas like transportation, environment, and security etc. but there is a need to explore more on urban planning from the perspective to analyze root cause of civic issues and reducing their concentration. In the present work, segregation of different urban areas is done and issues critical in a region are determined. Primarily, two phase clustering has been performed. In first phase, a dynamic grid based clustering is done on the basis of spatial attribute to analyze complaints that may have strong inter-dependency. In second phase, the location based clusters are further clustered based on complaint category which helps in determining regions of city imitating similar complaint behavior. The analysis is done on real world data acquired for two cities New York (USA) and Bangalore (India). Experimental results are visualized to show better interpretation. The results will help in planning strategies to improve inhabitant's satisfaction rate and consequently improving their quality of life.	algorithm;cluster analysis;computation;cosine similarity;euclidean distance;interpretation (logic);self-organized criticality;smart city;sparse matrix;urban computing	Preeti Bansal;Durga Toshniwal	2016	2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)	10.1109/ICIS.2016.7550747	computer science;minimum bounding box;marketing;operations management;data mining;urban planning;data pre-processing;cluster analysis;computer security	Vision	-18.17793128377732	-32.552175176270545	70763
56588cc107013a62c42f734501512ec8afc695c5	bayeswipe: a scalable probabilistic framework for improving data quality	offline and online cleaning;statistical data cleaning;data quality	Recent efforts in data cleaning of structured data have focused exclusively on problems like data deduplication, record matching, and data standardization; none of the approaches addressing these problems focus on fixing incorrect attribute values in tuples. Correcting values in tuples is typically performed by a minimum cost repair of tuples that violate static constraints like Conditional Functional Dependencies (which have to be provided by domain experts or learned from a clean sample of the database). In this article, we provide a method for correcting individual attribute values in a structured database using a Bayesian generative model and a statistical error model learned from the noisy database directly. We thus avoid the necessity for a domain expert or clean master data. We also show how to efficiently perform consistent query answering using this model over a dirty database, in case write permissions to the database are unavailable. We evaluate our methods over both synthetic and real data.	baseline (configuration management);bayesian network;clean;data deduplication;data quality;end-to-end encryption;experiment;functional dependency;generative model;image rectification;mapreduce;online and offline;open-source software;plasma cleaning;probabilistic database;probabilistic semantics;quality of results;rewriting;signal-to-noise ratio;subject-matter expert;synthetic intelligence;type class	Sushovan De;Yuheng Hu;Venkata Vamsikrishna Meduri;Yi Chen;Subbarao Kambhampati	2016	J. Data and Information Quality	10.1145/2992787	data quality;computer science;data mining;database;world wide web;information retrieval;database design;statistics	DB	-8.254285133404794	-32.269596706109205	71102
c68d38cc72f17ccc9bff711c95e6eb5e494212b7	motion pattern analysis enabling accurate travel mode detection from gps data only	transportation modes;european areas motion pattern analysis accurate travel mode detection gps data machine learning gps based features gps trajectories gis real time information multilayer perceptrons logistic model trees c4 5 decision trees evolutionary feature selection gps trajectory;multilayer perceptrons;detection and identification;motion;real time systems decision trees global positioning system learning artificial intelligence multilayer perceptrons;accuracy trajectory global positioning system decision trees training feature extraction hidden markov models;urban areas;trajectory;machine learning;global positioning system;travel behavior;travel patterns;europe;learning artificial intelligence;decision trees;rural areas;real time systems	Travel modes are one of the crucial pieces of information to characterize one's travel behavior. In recent years several approaches of mode detection from GPS data have been proposed. The approach presented in this paper uses machine learning to evaluate a set of GPS-based features for their ability to recognize the common modes walk, bicycle, car, bus, and train. The proposed features describe motion characteristics from GPS-trajectories by relative frequencies. Compared to previous work the proposed feature set leads to higher average recognition rates around 92% without relying on additional GIS or real-time information. The evaluation compares detection rates from multilayer perceptrons, logistic model trees, and C4.5 decision trees and is complemented by an evolutionary feature selection for selecting the most beneficial feature subsets leading to the best quality gain. In contrast to other research, this study uses a comparatively large set of 400 GPS trajectories which have been recorded in rural and urban European areas. Results contribute to a higher reliability as well as a broader applicability of GPS-only travel mode detection.	angularjs;c4.5 algorithm;decision tree;dimensionality reduction;feature selection;geographic information system;global positioning system;linear classifier;linear separability;logistic regression;machine learning;memory-level parallelism;multilayer perceptron;nonlinear system;pattern recognition;real-time data	Richard Brunauer;Michael Hufnagl;Karl Rehrl;Andreas Wagner	2013	16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)	10.1109/ITSC.2013.6728265	computer vision;simulation;geography;machine learning	Robotics	-17.222530160705876	-32.62785476613704	71121
a14d586cbf3c873525975cebe5ed0f2ceb56f6c3	visual role mining: a picture is worth a thousand roles	mining methods and algorithms;itemsets;probability;authorisation;probabilistic algorithm;role based access control;data mining;data visualisation;np hard problem;visualization;data and knowledge visualization;access controls;sound theory visual role mining role engineering approach role based access control user permission assignments visualization quality np hard problem adviser algorithm extract algorithm probabilistic algorithm role visual elicitation;computational complexity;mining methods and algorithms access controls data and knowledge visualization;data mining visualization data visualization algorithm design and analysis access control itemsets business;business;data visualization;access control;probability authorisation computational complexity data mining data visualisation;role engineering;algorithm design;algorithm design and analysis	This paper offers a new role engineering approach to Role-Based Access Control (RBAC), referred to as visual role mining. The key idea is to graphically represent user-permission assignments to enable quick analysis and elicitation of meaningful roles. First, we formally define the problem by introducing a metric for the quality of the visualization. Then, we prove that finding the best representation according to the defined metric is a NP-hard problem. In turn, we propose two algorithms: ADVISER and EXTRACT. The former is a heuristic used to best represent the user-permission assignments of a given set of roles. The latter is a fast probabilistic algorithm that, when used in conjunction with ADVISER, allows for a visual elicitation of roles even in absence of predefined roles. Besides being rooted in sound theory, our proposal is supported by extensive simulations run over real data. Results confirm the quality of the proposal and demonstrate its viability in supporting role engineering decisions.	heuristic;np-hardness;randomized algorithm;role-based access control;simulation	Alessandro Colantonio;Roberto Di Pietro;Alberto Ocello;Nino Vincenzo Verde	2012	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2011.37	algorithm design;computer science;artificial intelligence;data science;theoretical computer science;machine learning;data mining;database;programming language;world wide web;data visualization;algorithm	DB	-6.5014030674182814	-31.386383910505653	71151
142a51f57f3066efbb52d84ba1c43b068dc585b9	crowdsourced top-k queries by confidence-aware pairwise judgments	top k;confidence aware;pairwise judgments;crowdsourcing	Crowdsourced query processing is an emerging processing technique that tackles computationally challenging problems by human intelligence. The basic idea is to decompose a computationally challenging problem into a set of human friendly microtasks (e.g., pairwise comparisons) that are distributed to and answered by the crowd. The solution of the problem is then computed (e.g., by aggregation) based on the crowdsourced answers to the microtasks. In this work, we attempt to revisit the crowdsourced processing of the top-k queries, aiming at (1) securing the quality of crowdsourced comparisons by a certain confidence level and (2) minimizing the total monetary cost. To secure the quality of each paired comparison, we employ two statistical tools, Student's t-distribution estimation and Stein's estimation, to estimate the confidence interval of the underlying mean value, which is then used to draw a conclusion to the comparison. Based on the pairwise comparison process, we attempt to minimize the monetary cost of the top-k processing within a Select-Partition-Rank framework. Our experiments, conducted on four real datasets, demonstrate that our stochastic method outperforms other existing top-k processing techniques by a visible difference.	crowdsourcing;database;experiment;object composition	Ngai Meng Kou;Yan Li;Hao Wang;U Hou LeongHou;Zhiguo Gong	2017		10.1145/3035918.3035953	speech recognition;computer science;data science;machine learning;crowdsourcing	DB	-7.383368008740674	-32.19440978634872	71209
85e84505a9de7733de0e8c1627144f0ffe5dcff0	reinforcing records for improving the quality of data integration	data mining computer science software engineering statistics web pages xml filling null value;web pages;data integrity;quality reinforce data integration;sorting;reinforcing dataset;data mining;functional dependency;force;distance measurement;data integration quality;reinforce;quality;feature extraction;web sites;sources heterogeneity;missing values;reinforcing dataset data integration quality functional dependency sources heterogeneity;quality of data;experience base;data integration	In the data integration, the heterogeneity of sources leads to missing value and various expressions of the same value in records, which reduces the quality of data. In this paper, we propose a novel approach to reinforce records for the integrated data. By studying the functional dependency of attribute in schema of data integration, we discover the related attribute that determines the attribute with uncertain value. Then our approach exploits matching algorithms on the value of related attribute to associate different records. And the uncertain value will be reinforced with the consistent value in a certain record. We also propose algorithms for reinforcing dataset of data integration. The experiments based on the data of conference paper demonstrate the effectiveness and performance of our approach on improving the quality of data.	algorithm;attribute–value pair;database schema;experiment;functional dependency;missing data	Tiezheng Nie;Derong Shen;Ge Yu;Yue Kou	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.626	feature extraction;computer science;sorting;data science;data integration;web page;data integrity;data mining;database;functional dependency;force	DB	-7.151176406156152	-31.07738152597106	71254
7b24cc63e819cfc962c928ecbb76115099219961	a hybrid index model for efficient spatio-temporal search in hbase		With advances in geo-positioning technologies and geo-location services, there are a rapidly growing massive amount of spatio-temporal data collected in many applications such as location-aware devices and wireless communication, in which an object is described by its spatial location and its timestamp. Consequently, the study of spatio-temporal search which explores both geo-location information and temporal information of the data has attracted significant concern from research organizations and commercial communities. This work study the problem of spatio-temporal k -nearest neighbors search (STkNNS), which is fundamental in the spatial temporal queries. Based on HBase, a novel index structure is proposed, called Hybrid Spatio-Temporal HBase Index (HSTI for short), which is carefully designed and takes both spatial and temporal information into consideration to effectively reduce the search space. Based on HSTI, an efficient algorithm is developed to deal with spatio-temporal k -nearest neighbors search. Comprehensive experiments on real and synthetic data clearly show that HSTI is three to five times faster than the state-of-the-art technique.		Chengyuan Zhang;Lei Zhu;Jun Long;Shuangqiao Lin;Zhan Yang;Wenti Huang	2018		10.1007/978-3-030-04503-6_9	timestamp;computer science;data mining;wireless;synthetic data	DB	-15.450035739257759	-35.480318149848955	71383
42b46a498ee00d70ffc828c05ec56a7947a5051c	mining compressing sequential patterns	sequence data;complexity;compressing patterns mining;minimum description length;compression based pattern mining	Pattern mining based on data compression has been successfully applied in many data mining tasks. For itemset data, the Krimp algorithm based on the minimumdescription length MDL principle was shown to be very effective in solving the redundancy issue in descriptive pattern mining. However, for sequence data, the redundancy issue of the set of frequent sequential patterns is not fully addressed in the literature. In this article, we study MDL-based algorithms for mining non-redundant sets of sequential patterns from a sequence database. First, we propose an encoding scheme for compressing sequence data with sequential patterns. Second, we formulate the problem of mining the most compressing sequential patterns from a sequence database. We show that this problem is intractable and belongs to the class of inapproximable problems. Therefore, we propose two heuristic algorithms. The first of these uses a two-phase approach similar to Krimp for itemset data. To overcome performance issues in candidate generation, we also propose GoKrimp, an algorithm that directly mines compressing patterns by greedily extending a pattern until no additional compression benefit of adding the extension into the dictionary. Since checks for additional compression benefit of an extension are computationally expensive we propose a dependency test which only chooses related events for extending a given pattern. This technique improves the efficiency of the GoKrimp algorithm significantly while it still preserves the quality of the set of patterns. We conduct an empirical study on eight datasets to show the effectiveness of our approach in comparison to the state-of-the-art algorithms in terms of interpretability of the extracted patterns, run time, compression ratio, and classification accuracy using the discovered patterns as features for different classifiers. © 2013 Wiley Periodicals, Inc. Statistical Analysis and Data Mining, 2013		Hoang Thanh Lam;Fabian Mörchen;Dmitriy Fradkin;Toon Calders	2014	Statistical Analysis and Data Mining	10.1002/sam.11192	complexity;minimum description length;computer science;data science;machine learning;pattern recognition;data mining;mathematics	ML	-5.812911705631427	-36.53391032624365	71565
090cc1ae772c165a2d637b23ce30453b52e1db32	a hybrid approach to rule discovery in databases	stochastic process;search space;noisy data;transition matrix;hybrid approach;background knowledge;rule discovery;value of information	This paper introduces a hybrid approach for rule discovery in databases in an environment with uncertainty and incompleteness. We first create an appropriate relationship between deductive reasoning and stochastic process, and extend the relationship for including abduction. Then, we define a Generalization Distribution Table (GDT), which is a variant of transition matrix in stochastic process, as a hypothesis search space for generalization, and describe that the GDT can be represented by  knowledge-oriented  networks. Furthermore, we describe a discovery process based on the network representation. Finally, we introduce some extension for making our approach more useful, and discuss some problems for real applications. We discuss inductive methods from the viewpoint of the value of information, and describe that the main features of our approach are: (1) the uncertainty of a rule, including its ability to predict possible instances, can be explicitly represented in the strength of the rule, (2) noisy data and data change can be handled effectively, (3) biases can be flexibly selected and background knowledge can be used in the discovery process for constraint and search control, and (4)  if-then  rules can be discovered in an evolutionary, parallel-distributed cooperative mode.	association rule learning;database	Ning Zhong;Juzhen Dong;Setsuo Ohsuga	2000	Inf. Sci.	10.1016/S0020-0255(00)00012-8	stochastic process;mathematical optimization;artificial intelligence;machine learning;value of information;data mining;stochastic matrix;mathematics;algorithm;statistics	DB	-4.619821839540617	-28.597044476504205	71707
2811a3222f345d3ed9141fdb446cacd6062086f7	mining intelligent solution to compensate missing data context of medical iot devices		When gathering experimental data generated by medical IoT devices, the perennial problem is missing data due to recording instruments, errors introduced which cause data to be discarded, or the data is missed and lost. When faced with this problem, the researcher has several options: (1) insert what appears to be the best replacement for the missing element, (2) discard the entire instance, (3) use one of the algorithms that will consider the data and then suggest viable candidate values for replacement. We discuss the options and introduce another mining intelligent technique based upon Markov models.	algorithm;beye;markov chain;markov model;missing data;non-deterministic turing machine;stationary process;traction substation	Paul S. Fisher;Jimmy James;Jinsuk Baek;Cheonshik Kim	2017	Personal and Ubiquitous Computing	10.1007/s00779-017-1106-1	human–computer interaction;missing data;computer science;experimental data;data mining;markov model;internet of things	DB	-11.821791417099998	-32.912225830448186	71822
84d6b85fcf7e47665ef8b953f6a9a139f7c578a9	a fuzzy petri net-based expert system and its application to damage assessment of bridges	fuzzy set theory petri nets expert systems civil engineering computing;fpnes;uncertain transitions;damage assessment;fuzzy reasoning;expert systems;hybrid intelligent systems;truth qualified fuzzy facts;fuzzy rule based reasoning;uncertainty;uncertain fuzzy tokens;fuzzy rules;da shi bridge;logic;bridges;indexing terms;aggregation;fuzzy set theory;civil engineering computing;truth qualified fuzzy rules;approximate;fuzzy rule base;duplication;fuzzy propositions;aggregation duplication transitions;fuzzy petri net;fuzzy places;petri nets;power system modeling;knowledge representation;petri net;hybrid intelligent systems fuzzy systems expert systems bridges fuzzy reasoning petri nets knowledge representation algorithm design and analysis java power system modeling;algorithm design and analysis;integrated expert systems;da shi bridge fuzzy petri net rule based reasoning fuzzy reasoning fuzzy rule based reasoning fuzzy propositions truth qualified fuzzy rules truth qualified fuzzy facts fuzzy places uncertain transitions uncertain fuzzy tokens aggregation duplication transitions inference aggregation duplication integrated expert systems fuzzy petri net based expert system fpnes;fuzzy systems;rules;inference;rule based reasoning;java;expert system;fuzzy petri net based expert system	In this paper, a fuzzy Petri net approach to modeling fuzzy rule-based reasoning is proposed to bring together the possibilistic entailment and the fuzzy reasoning to handle uncertain and imprecise information. The three key components in our fuzzy rule-based reasoning-fuzzy propositions, truth-qualified fuzzy rules, and truth-qualified fuzzy facts-can be formulated as fuzzy places, uncertain transitions, and uncertain fuzzy tokens, respectively. Four types of uncertain transitions-inference, aggregation, duplication, and aggregation-duplication transitions-are introduced to fulfil the mechanism of fuzzy rule-based reasoning. A framework of integrated expert systems based on our fuzzy Petri net, called fuzzy Petri net-based expert system (FPNES), is implemented in Java. Major features of FPNES include knowledge representation through the use of hierarchical fuzzy Petri nets, a reasoning mechanism based on fuzzy Petri nets, and transformation of modularized fuzzy rule bases into hierarchical fuzzy Petri nets. An application to the damage assessment of the Da-Shi bridge in Taiwan is used as an illustrative example of FPNES.	base;ephrin type-b receptor 1, human;expert system;fuzzy rule;gene duplication abnormality;inference;java;knowledge representation and reasoning;logic programming;petri net;rule (guideline)	Jonathan Lee;Kevin F. R. Liu;Weiling Chiang	1999	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/3477.764869	fuzzy logic;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;data mining;fuzzy associative matrix;petri net;expert system;fuzzy set operations;fuzzy control system	SE	-6.873137032364387	-24.39912379544234	71842
e1c581345422cf54a4a632a1a46e6667911ac5d4	effective course-of-action determination to achieve desired effects	effects based operations;belief networks;evolutionary computation;constraint specification language;timed influence nets tins;timed influence nets tins course of action coa dynamic bayesian networks dbns effects based operations evolutionary algorithms eas optimization;course of action;timed influence nets;decision maker;causal constraint specification;mission planning;evolutionary algorithm based approach causal constraint specification temporal constraint specification system analysis decision making parallel adaptive search procedure constraint specification language trial and error based manual technique dynamic bayesian network timed influence nets course of action determination;evolutionary algorithm based approach;course of action determination;course of action coa;systems analysis;dynamic bayesian network;parallel adaptive search procedure;system analysis;optimization;search problems;trial and error based manual technique;dynamic bayesian networks dbns;evolutionary algorithm;systems analysis decision making evolutionary computation parallel algorithms search problems;evolutionary computation bayesian methods tin knowledge acquisition inference algorithms manuals time factors computer architecture information technology uncertainty;temporal constraint specification;evolutionary algorithms eas;parallel algorithms	An evolutionary algorithm-based approach to identify effective courses of action (COAs) in dynamic uncertain situations is presented. The uncertain situation is modeled using timed influence nets, an instance of dynamic Bayesian networks. The approach makes significant enhancements to the current trial-and-error-based manual technique, which is not only labor intensive but also not capable of modeling constraints among actionable events. The proposed approach is an attempt to overcome these limitations. It automates the process of COA identification. It also allows a system analyst to capture certain types of constraints among actionable events. Because of its parallel search nature, the approach produces multiple COAs that have a similar fitness value. This feature not only gives more flexibility to a decision maker during mission planning, but it can also be used to generalize the COAs if there exists a pattern among them. This paper also discusses a heuristic that further enhances the performance of the approach.	approximation algorithm;basic stamp;causal filter;dynamic bayesian network;electronic design automation;evolutionary algorithm;heuristic;np-hardness;pareto efficiency;specification language;universal instantiation	Sajjad Haider;Alexander H. Levis	2007	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2007.904771	systems analysis;decision-making;mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;data mining;parallel algorithm;system analysis;dynamic bayesian network;evolutionary computation	SE	-7.304373073071005	-29.35044315188687	71845
1b91b3a0af4521439dec5a3d0e71233ed1adc93b	a fast algorithm for detecting second paths in database inference analysis	fast algorithm	This paper presents an approach for detecting potential second-path inference problems in a way that is significantly faster than previous approaches. The algorithm uses a relational database schema and functional dependencies to detect the potential for second-path inferences. The second-path inference problem involves the ability to infer higher classified data from lower classified data within a relational database system using joins. In previous research, this type of inference vulnerability was detected by actually finding a path. The approach presented in this paper does not find the path, but detects the existence of a path by adapting a well known algorithm used in database design to test a relational decomposition for the lossless join property. The original lossless join algorithm has been extended to include subtypes. The paper compares the performance of the new algorithm with that of a conventional path-finding algorithm and shows that the new algorithm is 10 to 14 times faster than the path-finding approach using schemas that range from 33 to 48 relations. The final contribution of the paper is the presentation of an algorithm for automatically classifying the discovered paths into various groups, based on their potential for indicating a significant potential security vulnerability.	algorithm	Thomas H. Hinke;Harry S. Delugach;Asha Chandrasekhar	1995	Journal of Computer Security	10.3233/JCS-1994/1995-32-304	computer science;fsa-red algorithm	Security	-7.385188744653685	-36.627061925597104	71864
6efbd723c9c4be5b4645bbddc2a756cd9ed45fec	the dynamics mechanism study on interactive development of industry clusters and urbanization	system dynamics;industry cluster;complex system	Industry clusters with urbanization interactive development is a multi-factor complex system. In this research, we present a system dynamics methodology to construct an industrial clustering and urbanization interactive dynamics model, and further to make its simulation computation and analysis. The simulation results show that the development of industrial clusters stimulates the rise of urbanization level, and the level of urbanization and the growth of industrial clusters promote the development of industrial clusters. Also, a case study for Yiwu City, P.R.China is conducted. It shows that the urbanization of Yiwu City is a fairly advanced virtuous circle.		Weixiang Xu;Ye Jiang;Bin Yu;Gennian Tang	2006		10.1007/11816171_129	complex systems;simulation;biological classification;computer science;artificial intelligence;dynamical system;machine learning;business cluster;system dynamics;cluster analysis	HCI	-13.84535552941968	-25.128393594734803	71917
fbc22fde9a469e669ae515c475b28c17d8d8c9ec	adapting travel time estimates to current traffic conditions		The paper demonstrates drifts in travel time estimates of a floating car data based car navigation system. The operation of such a navigation system starts with collecting floating car data, i.e. multi-channel stream data sent in from moving cars. These dynamic data are then processed in an elaborate, multistage procedure, aimed at estimating the travel time and constituting an essential component of optimal route planning, which can effectively find not only the shortest, but also the fastest road connections, always taking into account the current traffic conditions. The experiments present the ability of the navigation system to detect and handle unusual traffic situations, like unexpected jams caused by sudden road accidents, which manifest themselves in the drifts of travel time estimates. All experiments were conducted on exclusively real-life data, provided by NaviExpert, a Polish car navigation company.		Przemyslaw Gawel;Krzysztof Dembczynski;Robert Susmaga;Przemyslaw Wesolek;Piotr Zielniewicz;Andrzej Jaszkiewicz	2012		10.1007/978-3-642-32518-2_8	meteorology;simulation;transport engineering	Theory	-17.069560667593155	-30.678338126129756	71992
afca61641494efbecd2208ed7a312b196ea3f783	a novel algorithm of mining maximal frequent pattern based on projection sum tree	frequent pattern;efficient algorithm;projection sum tree;data mining;itemsets data mining testing frequency test pattern generators databases information technology project management technology management association rules;frequent itemset;data mining mining maximal frequent pattern projection sum tree fpmax algorithm;mining maximal frequent pattern;fpmax algorithm	In this paper, a novel algorithm for mining maximal frequent patterns is proposed based on projection sum frequent items tree. This algorithm projects the transaction base into a projection sum tree and it can store the frequent itemsets in the tree in a compact manner. The algorithm builds frequent patterns tree directly as FPMax algorithm does. However, all the nodes of PSFIT are sorted and ordered, the children of which are also sorted and ordered. It doesn 't need to generate conditional FP-tree dynamically and recursively and it can take advantage of computational result that has been done. The experiment shows that PSFIT is an efficient algorithm, it has comparable performance with FPMax, and in most cases it outperforms FPMax.	algorithm;computation;maximal set;recursion	Chuanyao Yang;Yuqin Li;Chenghong Zhang;Yunfa Hu	2007	Fourth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2007)	10.1109/FSKD.2007.95	computer science;machine learning;pattern recognition;data mining;mathematics	ML	-4.861841297617766	-36.800560981253845	72036
269d73552390ecee8141b1bb0037946f6f1ece7b	deploying real time big data analytics in cloud ecosystem for hazmat stochastic risk trajectories		Abstract: The transport of hazardous materials (HazMat) is regulated by a legal framework in line with international standards, in particular the European Agreement concerning the international Accord for Dangerous goods by Road (ADR) which entered in Morocco in June 2011- BO 5956 bis, 30.6.2011. In this work, we propose a model for calculating the risk exposure of the transport of hazardous materials (THM) trajectories using the Gaussian stochastic travel time. The THD trajectory meta-model is extended to take into account the risk management dimension. The storage of the TMD trajectories is used for discovering risk patterns on the urban space by means of the mesh of Voronoi. The proposed analytical solution is deployed in an interoperable infrastructure using intelligent transport systems architecture.	ecosystem	Lamia Karim;Azedine Boulmakoul;Aziz Mabrouk;Ahmed Lbath	2017		10.1016/j.procs.2017.05.322	data mining;architecture;risk management;simulation;hazardous waste;computer science;interoperability;dangerous goods;big data;cloud computing;intelligent transportation system	ML	-15.445944547313436	-24.46708885804492	72048
d3e9898d111d5c34baae14026c120867efd4ddcd	predicting next location of twitter users for surveillance	digital forensics;video surveillance;geographical location twitter users predicting next location social networks technical surveillance digital forensics law enforcement officers foursquare users artificial neural networks;information security;video surveillance digital forensics internet law neural nets social networking online;neural nets;information security social networks location based social networks location prediction technical surveillance digital forensics;law;artificial neural networks social network services surveillance training law enforcement predictive models prediction algorithms;internet;social networks;social networking online;technical surveillance;location prediction;location based social networks	In this study a novel approach that uses location based social networks for next location prediction in the field of technical surveillance and digital forensics is proposed. With the help of proposed methodology, search area for the potential criminals will be narrowed so that the spent time, money and effort by the law enforcement officers will be minimized. After collecting enough past location information for Foursquare users, the whole data is trained by means of Artificial Neural Networks. After training process, predicting the next location of the wanted personis carried out. Prediction process is made region-based, so it is tried to predict the region of the potential criminals' next geographical location. The experimental results have shown that the proposed approach and developed system might achieve the prediction goal with only 3% error rate, and proposed methodology can be used by law enforcement officers for forensic surveillance and similar criminal acts.	artificial neural network;bit error rate;dvd region code;location (geography);money;neural networks;social network	Sedef Gunduz;Uraz Yavanoglu;Seref Sagiroglu	2013	2013 12th International Conference on Machine Learning and Applications	10.1109/ICMLA.2013.134	the internet;computer science;information security;digital forensics;data mining;internet privacy;computer security;artificial neural network;social network	AI	-17.935540316671133	-33.80241654594768	72604
ea134c88ac7c57bf314527a47891948a317f17a7	building road segments and detecting turns from gps tracks		Abstract With the wide spreading of geo-aware mobile applications, huge amounts of user-contributed GPS trajectories become available with different levels of accuracy. Constructing road maps from such datasets is one important benefit from this data, and it is required for many applications. There are some challenges related to the inaccuracies incurred on real datasets, such as missing GPS signals, low sampling rate and bad driving behaviour. In this paper, we present a new preprocessing algorithm to address the problems of GPS data. Additionally, we present a clustering-based technique to extract the road map from GPS tracks. Firstly, the tracks are simplified in order to extract road turns and remove the noise data. Then, we adjust the points of the simplified tracks to solve the problems caused by the low sampling rate by moving them closer to the positions of the real turns. Afterwards, a progressive clustering is applied to extract turns and intersections. Finally, we connect them to build the road segments. To ensure the accuracy of our results, we compare the proposed technique with two of the best state-of-the-art methods using a small-scale dataset with inconsistent sampling rate. Another experiment is conducted by extracting a part of the road segments of Egypt using a large-scale dataset with more than 12 million GPS points that are captured with high sampling rate. Experimental results show that our proposed technique exceeds the other methods with regard to F-measure.		M. Ezzat;Mahmoud Sakr;Rania Elgohary;Mohammed Essam Khalifa	2018	J. Comput. Science	10.1016/j.jocs.2018.09.011	theoretical computer science;gps signals;sampling (signal processing);global positioning system;computer vision;cluster analysis;road map;computer science;artificial intelligence	Theory	-15.881365237463339	-34.22920990362675	72670
3b112088d075f62c642e6495829e6067d7e71f80	sparse particle filtering for modeling space-time dynamics in distributed sensor networks	filtering;kernel;wearable ecg sensor network sparse particle filtering space time dynamics modeling distributed sensor networks wireless sensor network space time dynamics monitoring complex systems environmental sensor network battlefield surveillance network body area sensor network distributed sensing spatially temporally big data signal measurement substantial complexity spatial correlation temporal correlation spatially varying time series model temporally varying spatial model compact kernel weighted regression model reduced dimension space recursive bayesian estimation;kernel filtering data models mathematical model spatiotemporal phenomena electrocardiography correlation;electrocardiography;wireless sensor networks bayes methods big data body area networks correlation methods electrocardiography medical signal processing particle filtering numerical methods regression analysis time series;spatiotemporal phenomena;mathematical model;correlation;data models	Wireless sensor network has emerged as a key technology for monitoring space-time dynamics of complex systems, e.g., environmental sensor network, battlefield surveillance network, and body area sensor network. As a result, distributed sensing gives rise to spatially-temporally big data. Realizing the full potentials of distributed sensing calls upon the development of space-time modeling of measured signals in the dynamically-evolving physical environment. However, space-time interactions bring substantial complexity in the scope of the modeling, due to the need to investigate spatial correlation, temporal correlation, as well as how space and time interact. Most of previous research considers either spatially-varying time series model or temporally-varying spatial model. This paper presents a new approach of sparse particle filtering to model spatiotemporal dynamics of big data in distributed sensor network. Notably, we developed a compact kernel-weighted regression model of spatial patterns. Further, the parameters of spatial model are transformed into a reduced-dimension space, and thereby sequentially updated with the recursive Bayesian estimation when new sensor observations are available. As such, spatial and temporal processes closely interact with each other. Experimental results on real-world data from wearable ECG sensor network showed that the proposed methodology outperforms traditional methods and effectively models space-time dynamics in distributed sensor networks.	big data;code;complex systems;curse of dimensionality;greedy algorithm;informatics;interaction;lazy evaluation;nonlinear system;occam's razor;overfitting;particle filter;recursion;sensor;sparse matrix;time series;wearable computer;well-posed problem	Yun Chen;Gang Liu;Hui Yang	2014	2014 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2014.6899393	electronic engineering;computer science;machine learning;data mining	Robotics	-13.112960855636851	-32.95946665280957	72999
4ee5b64b6b5c569b3222ab537acf519b7c14ebf7	interpretable classifier for identifying high-value child support cases	decision support;predictive scoring systems;social aspects of automation data analysis pattern classification;interpretable modeling;case management systems interpretable classifier high value child support cases accurate data analytics periodic child support payments noncustodial parent child support agencies accurate scoring models;data analytics;case management;child support;predictive models numerical models logistics data analysis buildings analytical models data models;interpretable modeling child support case management decision support data analytics predictive scoring systems	This work brings interpretable and accurate data analytics to child support agencies with the goal of substantially increasing their effectiveness. In the realm of child support, a custodial parent may be entitled to periodic child support payments from the noncustodial parent. In order to analyze this process, we have gathered case data from several child support agencies. The objective of the work is to develop analytical models that characterize and predict high-value child support cases. High-value cases are those that result in successful payments and require far fewer resources for enforcement. We create interpretable and accurate scoring models to identify these cases so that the key attributes driving their prediction are easily understood by the caseworkers. This information may be integrated with case management systems to schedule and prioritize the caseload.	predictive modelling;statistical classification	Bryan Dolan;Kirk Ocke;Eric Gross;Yasmine Charif	2015	2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2015.39	decision support system;computer science;data science;machine learning;data mining;management science;data analysis	DB	-8.315005766918299	-30.335838516582193	73097
94a66f580d7dc1ae20505af4d1a4cd7e87fda2ea	crowdsourced pedestrian map construction for short-term city-scale events	spatial databases and gis;mobility mining;crowd sourcing;pedestrian networks;data mining	This paper targets the construction of pedestrian maps for city-scale events from GPS trajectories of visitors. Incomplete data with a short lifetime, varying localisation accuracy, and a high variation of walking behaviour render the extraction of a pedestrian map from crowd-sourced data a difficult task. Traditional network or map construction methods lean on accurate GPS trajectories typically obtained over longer time periods from vehicles at high speeds with less variation in locomotion. Not designed to operate under mobility conditions of pedestrians at large scale events they cannot be directly applied. We present an algorithm based on a crowd-sensing scheme to construct the pedestrian network during city scale events. In a thorough evaluation, we investigate the effect of trajectory quality and quantity on the map construction. To this end, we use a real world dataset with 25M GPS points obtained from 28.000 users during a three-day public festival event. Results indicate that with a short observation window of 30min the estimated pedestrian network can represent previously unseen trajectories with a median map-matching deviation in matching of only 5m and a map accuracy of more than 85%.	algorithm;crowdsourcing;data quality;global positioning system;map matching;routing	Ulf Blanke;Robin Guldener;Sebastian Feese;Gerhard Tröster	2014			simulation;geography;transport engineering;cartography	HCI	-16.243119559041745	-33.964755703062735	73534
922b368975a75163e10936d6f37d3c2050c981b2	predictive queries algorithm based on probability model over data streams	state transition disgraph;graph theory;markov chain predictive queries algorithm probability model data streams decision making state transition disgraph state transactions;state transactions;prediction algorithms predictive models history sensor systems and applications decision making statistics computer science technology forecasting application software monitoring;query processing;data stream;data mining;data streams;simulation experiment;predictive queries algorithm;query processing data mining graph theory markov processes;markov processes;probability model;state transition;markov chain	Mining the evolving trends of an online data stream and forecasting the data values in the future can provide important support for the decision-making in many time-sensitive applications. This paper models an online data stream as a continuous state transitions process by mapping the possibly infinite stream data into finite states, and uses state transition disGraph (STG) to maintain the track of the state transactions. By studying the statistic information of the history state transitions, the future values can be predicted based on the theory of Markov chain. Extensive simulation experiments are conducted and show that the predictive performance of our method is preferable to that of the existing analogous algorithms.	algorithm;experiment;markov chain;microsoft windows;predictive modelling;simulation;star trek generations;state transition table	Guohui Li;Hui Chen;Bing Yang;Gang Chen;Jun Xiang	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.566	computer science;data science;machine learning;data mining;data stream mining	DB	-6.898422047898315	-34.6820885947132	73735
b27d969a8b07c2c8d22fb7de523d947d8dc70c87	study and design of traffic management decision support system based on grid	decision support;data mining traffic management decision support system grid computing intelligent transportation system;system modeling;intelligent transport system;decision support systems middleware intelligent transportation systems traffic control data mining resource management engineering management information analysis grid computing high performance computing;road traffic;traffic information systems automated highways data mining decision support systems grid computing road traffic;automated highways;traffic management;data mining;decision support system;traffic information systems;decision support systems;grid computing	The traffic management decision support is the key points of intelligent transportation system. Because of the deficiencies of decision support system at present, a system model of decision support is proposed based on analyzing the concept of grid and data mining. It is easier to identify the useful information in the data and provide valuable advice with this system, and this system makes the decision support intelligent by using the grid and data mining technologies.	data mining;decision support system	Liu Chong;Lu Huapu	2005	2005 First International Conference on Semantics, Knowledge and Grid	10.1109/SKG.2005.117	executive information system;active traffic management;systems modeling;decision support system;intelligent decision support system;decision engineering;computer science;management information systems;data mining;database;computer security;advanced traffic management system;information system;grid computing	Robotics	-15.826745736618049	-26.027235014450046	73975
815e92343fd9c18f95157f234fab3120ac2f8b8c	searchlight: context-aware predictive continuous querying of moving objects in symbolic space	graph theory;query processing;ubiquitous computing;cqp;cqpf;slg model;slql;context aware predictive continuous querying;indoor-outdoor spaces;location-object context annotation;moving objects;novel query processing algorithms;object-specific edge costs;predicted object movement;real-time location based services;searchlight continuous query processing framework;searchlight graph;searchlight query language;symbolic space;biology	Increasingly, streaming positions from moving objects in blended indoor/outdoor spaces are used to deliver new types of real-time location-based services. To support such scenarios, this paper presents the Searchlight Graph (SLG) model and the associated Searchlight Continuous Query Processing Framework (CQPF) for (predictive) Continuous Query Processing (CQP) in symbolic indoor/outdoor spaces. The model captures both actual and predicted object movement, object-specific edge costs, and location/object context annotation with keywords, enabling context-aware (predictive) querying of both locations and objects. Furthermore, the paper proposes several types of continuous spatio-temporal queries, expressed in the declarative Searchlight Query Language (SLQL), along with novel query processing algorithms, and describes their implementation in the Searchlight CQPF. Finally, a novel location prediction algorithm is proposed. Extensive experimental studies show that Searchlight is scalable, efficient, and outperforms its main competitor.	algorithm;database;location-based service;query language;real-time locating system;scalability;searchlight bbs;streaming media	Kenneth Fuglsang Christensen;Lasse Linnerup Christiansen;Torben Bach Pedersen;Jeppe Pihl	2015	2015 IEEE 31st International Conference on Data Engineering	10.1109/ICDE.2015.7113325	computer vision;computer science;graph theory;theoretical computer science;data mining;database;ubiquitous computing	DB	-16.72797318622361	-35.63654231485782	74051
6c21658615fe955fbcd8a1fb801d42fa33d96304	visual fusion of mega-city big data: an application to traffic and tweets data analysis of metro passengers	data visualization heating accidents smart cards media transportation visualization;visualization environment visual mega city big data fusion traffic data analysis tweets data analysis metro passengers public gatherings transportation systems visual integration traffic analysis social media analysis tokyo metro social media data smart card data situational explanations abnormal situations;traffic information systems big data data analysis data visualisation smart cards social networking online	Transportation systems in mega-cities are often affected by various kinds of events such as natural disasters, accidents, and public gatherings. Highly dense and complicated networks in the transportation systems propagate confusion in the network because they offer various possible transfer routes to passengers. Visualization is one of the most important techniques for examining such cascades of unusual situations in the huge networks. This paper proposes visual integration of traffic analysis and social media analysis using two forms of big data: smart card data on the Tokyo Metro and social media data on Twitter. Our system provides multiple coordinated views to visually, intuitively, and simultaneously explore changes in passengers' behavior and abnormal situations extracted from smart card data and situational explanations from real voices of passengers such as complaints about services extracted from social media data. We demonstrate the possibilities and usefulness of our novel visualization environment using a series of real data case studies about various kinds of events.	big data;situational application;smart card;social media;software propagation;traffic analysis	Masahiko Itoh;Daisaku Yokoyama;Masashi Toyoda;Yoshimitsu Tomita;Satoshi Kawamura;Masaru Kitsuregawa	2014	2014 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2014.7004260	engineering;advertising;internet privacy;computer security	Visualization	-16.987306956387652	-31.22703560039839	74269
27942130e23aae9e4997d13ea6d57683aa65dbcf	ensemble-based method for task 2: predicting traffic jam	nearest neighbor searches;data gathering;training;traffic simulation framework;icdm 2010 contest;jamming;conference paper;ensemble;servers;roads;traffic simulation framework ensemble based method traffic jam icdm 2010 contest;nearest neighbor;roads jamming training nearest neighbor searches servers data models driver circuits;driver circuits;traffic engineering computing;ensemble based method;cross validation;cross validation ensemble nearest neighbor;traffic jam;data models	In this paper, we describe our solution for ICDM 2010 Contest Task 2 (Jams), where the task is to predict future where the next traffic jams will occur in morning rush hour, given data gathered during the initial phase of this peak period. Our solution, which is based on an ensemble approach, finished Second in the final evaluation.	cross-validation (statistics);jam;test set	Jingrui He;Qing He;Grzegorz Swirszcz;Yiannis Kamarianakis;Rick Lawrence;Wei Shen;Laura Wynter	2010	2010 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2010.54	ensembl;data modeling;simulation;computer science;machine learning;data mining;k-nearest neighbors algorithm;cross-validation;server;statistics;data collection	Robotics	-16.442938673526882	-30.71770554026766	74273
c297b902558274745cb7e204345719f8a324dc35	game theoretic analysis of road user safety scenarios involving autonomous vehicles		Interactions between pedestrians, cyclists, and human-driven vehicles have become a major concern for traffic safety over the years. The upcoming age of autonomous vehicles will further raise major problems on whether self-driving cars can accurately avoid accidents; on the other hand, usability issues arise on whether human-driven cars and pedestrians can dominate the road at the expense of the autonomous vehicles that will be programmed to avoid accidents. This paper proposes some game theoretical models applied to traffic scenarios, where the strategic interaction between a pedestrian and an autonomous vehicle is analyzed. The games have been simulated to demonstrate the theoretical analysis and the predicted behaviors. These investigations can shed new lights on how urban traffic regulations and inter-vehicle communications could be required to allow for a general improved management of traffic in the presence of autonomous vehicles.		Umberto Michieli;Leonardo Badia	2018	2018 IEEE 29th Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)	10.1109/PIMRC.2018.8580679	game theory;real-time computing;simulation;pedestrian;usability;computer science	Robotics	-18.988570663101765	-25.855540291362434	74306
438a4d33c9dd39800b572793652bba02d77e25ee	correlation-model-based reduction of monitoring data in data centers		Nowadays, in order to observe and control data centers in an optimized way, people collect a variety of monitoring data continuously. Along with the rapid growth of data centers, the increasing size of monitoring data will become an inevitable problem in the future. This paper proposes a correlation-based reduction method for streaming data that derives quantitative formulas between correlated indicators, and reduces the sampling rate of some indicators by replacing them with formulas predictions. This approach also revises formulas through iterations of reduction process to find an adaptive solution in dynamic environments of data centers. One highlight of this work is the ability to work on upstream side, i.e., it can reduce volume requirements for data collection of monitoring systems. This work also carried out simulated experiments, showing that our approach is capable of data reduction under typical workload patterns and in complex data centers.	anomaly detection;data center;experiment;fault tolerance;feedback;iteration;kerrison predictor;requirement;sampling (signal processing);streaming media	Xuesong Peng;Barbara Pernici	2016	2016 5th International Conference on Smart Cities and Green ICT Systems (SMARTGREENS)		workload;time series;data collection;data modeling;complex data type;data reduction;sampling (signal processing);data mining;data center;computer science	HPC	-13.928249972509718	-30.25348730522045	74315
099f97aa8cd4abda9b7382f1a2ffd00c823225cb	afopt: an efficient implementation of pattern growth approach		In this paper, we revisit the frequent itemset mining (FIM) problem and focus on studying the pattern growth approach. Existing pattern growth algorithms differ in several dimensions: (1) item search order; (2) conditional database representation; (3) conditional database construction strategy; and (4) tree traversal strategy. They adopted different strategies on these dimensions. Several adaptive algorithms were proposed to try to find good strategies for general situations. In this paper, we described the implementation techniques of an adaptive pattern growth algorithm, called AFOPT, which demonstrated good performance on all tested datasets. We also extended the algorithm to mine closed and maximal frequent itemsets. Comprehensive experiments were conducted to demonstrate the efficiency of the proposed algorithms.	adaptive algorithm;association rule learning;bottom-up parsing;database;experiment;lexicographical order;lexicography;maximal set;top-down and bottom-up design;tree traversal	Guimei Liu;Hongjun Lu;Jeffrey Xu Yu;Wei Wang;Xiangye Xiao	2003			machine learning;tree traversal;artificial intelligence;computer science	DB	-5.487014684485093	-37.84630692889684	74460
79277d98f02a92fcf60bbacf7b2e0f5b9e1e8e2b	user interface support for a big etl data processing pipeline an application scenario on highway toll charging models		Urban and national road networks in many countries are severely congested, resulting in increased travel times and number of stops, unexpected delays, greater travel costs, inconvenience to drivers and passengers, increased air pollution and noise level and number of traffic accidents. Expanding traffic network capacities by building more roads is extremely costly as well as environmentally damaging. More efficient usage of the existing network is vital in order to sustain the growing travel demand. Congestion pricing has been advocated by transport economists and traffic planners for a long time as an efficient means to reduce road congestion, however such practices have not been widely adopted. Portugal has a good and underused toll highway network that is close to congested free urban/national road networks. Portuguese drivers choose to use free roads disregarding safety, travel time and other aspects, basing their decision only toll prices. Therefore, urban/national road network has been suffering from a more intensive use than it was projected for, increasing maintenance costs and reducing safety and comfort for users. The main objective of the application scenario presented is to transfer traffic from urban / national roads to highways, through the adoption of congestion pricing technologies. To this end, innovative Big Data processing and mining as well as optimization techniques need to be developed and applied so as to support real-time decision-making capabilities for congestion pricing. This paper presents an ETL (extract, transform and load) architecture for intelligent transportation systems, addressing an application scenario on dynamic toll charging for highways, supported by a novel Web User Interface.	apache storm;big data;mathematical optimization;network congestion;noise (electronics);plasma cleaning;real-time clock;real-time transcription;upload;user interface;world wide web	Paulo Figueiras;Ruben Costa;Guilherme Guerreiro;Hugo Antunes;Antonio Rosa;Ricardo Jardim-Gonçalves	2017	2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)	10.1109/ICE.2017.8280052	architecture;business;big data;transport engineering;intelligent transportation system;data modeling;data processing;congestion pricing;user interface	Robotics	-16.625318680125353	-28.83065182383665	74504
436074899446737bcd2afed185c359f884db180f	identifying travel mode with gps data using support vector machines and genetic algorithm	travel mode;global positioning system gps;support vector classification;travel survey;genetic algorithm	Travel mode identification is one of the essential steps in travel information detection with Global Positioning System (GPS) survey data. This paper presents a Support Vector Classification (SVC) model for travel mode identification with GPS data. Genetic algorithm (GA) is employed for optimizing the parameters in the model. The travel modes of walking, bicycle, subway, bus, and car are recognized in this model. The results indicate that the developed model shows a high level of accuracy for mode identification. The estimation results also present GA’s contribution to the optimization of the model. The findings can be used to identify travel mode based on GPS survey data, which will significantly enhance the efficiency and accuracy of travel survey and data processing. By providing crucial trip information, the results also contribute to the modeling and analyzing of travel behavior and are readily applicable to a wide range of transportation practices.	full scale;genetic algorithm;geographic information system;global positioning system;high-level programming language;mathematical optimization;sampling (signal processing);software release life cycle;support vector machine	Fang Zong;Yu Bai;Xiao Wang;Yixin Yuan;Yanan He	2015	Information	10.3390/info6020212	simulation;genetic algorithm;computer science;artificial intelligence;machine learning;data mining	Robotics	-17.241873138493503	-32.61734926950347	74630
0265ade13fbfc8f5ffa158fed1238c8591f36f19	parallel incremental frequent itemset mining for large data	incremental parallel fpgrowth;data mining;frequent itemset mining;mapreduce	Frequent itemset mining (FIM) is a popular data mining issue adopted in many fields, such as commodity recommendation in the retail industry, log analysis in web searching, and query recommendation (or related search). A large number of FIM algorithms have been proposed to obtain better performance, including parallelized algorithms for processing large data volumes. Besides, incremental FIM algorithms are also proposed to deal with incremental database updates. However, most of these incremental algorithms have low parallelism, causing low efficiency on huge databases. This paper presents two parallel incremental FIM algorithms called IncMiningPFP and IncBuildingPFP, implemented on the MapReduce framework. IncMiningPFP preserves the FP-tree mining results of the original pass, and utilizes them for incremental calculations. In particular, we propose a method to generate a partial FP-tree in the incremental pass, in order to avoid unnecessary mining work. Further, some of the incremental parallel tasks can be omitted when the inserted transactions include fewer items. IncbuildingPFP preserves the CanTrees built in the original pass, and then adds new transactions to them during the incremental passes. Our experimental results show that IncMiningPFP can achieve significant speedup over PFP (Parallel FPGrowth) and a sequential incremental algorithm (CanTree) in most cases of incremental input database, and in other cases IncBuildingPFP can achieve it.	algorithm;association rule learning;data mining;database;dynamic problem (algorithms);log analysis;mapreduce;parallel computing;speedup;structure mining;web search engine	Yu-Geng Song;Hui-Min Cui;Xiaobing Feng	2017	Journal of Computer Science and Technology	10.1007/s11390-017-1726-y	computer science;data science;data mining;database;incremental heuristic search	DB	-5.367221958410714	-37.70203353719756	74761
29cb794f94a14827cc9872888570b4d518847739	a quick incremental updating algorithm for computing core attributes	rough set theory;theoretical analysis;incremental updating;rough sets;rough set;discernibility matrix;decision table;core attributes	Computing core attributes is one of key problems of rough set theory. Many researchers proposed lots of algorithms for computing core. Unfortunately, most of them are designed for static databases. However, many real datasets are dynamic. In this paper, a quick incremental updating core algorithm is proposed, which only allies on the updating parts of discernibility matrix and does not need to store, re-compute and re-analyze discernibility matrix, when new objects are added to decision table. Both of theoretical analysis and experimental results show that the algorithm is effective and efficient.	algorithm	Hao Ge;Chuanjian Yang;Wanlian Yuan	2010		10.1007/978-3-642-16248-0_38	rough set;computer science;machine learning;data mining;mathematics;algorithm;dominance-based rough set approach	DB	-4.960492784195567	-37.112119857366025	74808
f2182651360a119580ee613debefbf748c7dbd1b	interpretation of image segmentation in terms of justifiable granularity		The principle of justifiable granularity, as formulated in [1], defines intuitively motivated requirements for an information granule to be meaningful. In the paper, granulation of images obtained by their segmentation is considered. In this context, such concepts as representation of granules and their relations, representation of concepts, consideration of context, detection and treatment of outliers, and recognition method, are of importance. The granular approach is related to intelligent analysis of all kinds of data, not only the computer images.	image segmentation	Piotr S. Szczepaniak	2015		10.1007/978-3-319-19324-3_57	computer vision;segmentation-based object categorization;scale-space segmentation	Vision	-6.3233192041756645	-27.75372415910164	74830
a685bb4397fbb3a77d27d2d780f4339356105ea6	matching consecutive subpatterns over streaming time series		Pattern matching of streaming time series with lower latency under limited computing resource comes to a critical problem, especially as the growth of Industry 4.0 and Industry Internet of Things. However, against traditional single pattern matching model, a pattern may contain multiple subpatterns representing different physical meanings in the real world. Hence, we formulate a new problem, called “consecutive subpatterns matching”, which allows users to specify a pattern containing several consecutive subpatterns with various specified thresholds. We propose a novel representation Equal-Length Block (ELB) together with two efficient implementations, which work very well under all Lp-Norms without false dismissals. Extensive experiments are performed on synthetic and real-world datasets to illustrate that our approach outperforms the brute-force method and MSM, a multi-step filter mechanism over the multi-scaled representation by orders of magnitude.		Rong Kang;Chen Wang;Peng Wang;Yuting Ding;Jianmin Wang	2018		10.1007/978-3-319-96893-3_8	implementation;artificial intelligence;machine learning;computer science;latency (engineering);pattern matching;orders of magnitude (numbers);internet of things	DB	-9.20955945915149	-37.919317029250884	74878
1c48efc908ec75843a6e5a750c5ab8a76f21bb8b	asynchronous periodic patterns mining in temporal databases.	frequent pattern;generic model;data mining;pattern mining;temporal database;knowledge discovery	Mining periodic patterns in temporal database is an important data mining problem with many applications. Previous studies have considered synchronous periodic patterns where misaligned occurrences are not allowed. However, asynchronous periodic pattern mining has received less attention and was only been discussed for a sequence of symbols where each time point contains one event. In this paper, we propose a more general model of asynchronous periodic patterns from a sequence of symbol sets where a time slot can contain multiple events. Three parameters min rep, max dis, and global rep are employed to specify the minimum number of repetitions required for a valid segment of non-disrupted pattern occurrences, the maximum allowed disturbance between two successive valid segments, and the total repetitions required for a valid sequence. A four-phase algorithm is devised to discover periodic patterns from a temporal database presented in vertical format. The experiments demonstrate good performance and scalability with large frequent patterns.	algorithm;data mining;experiment;limbo;maxima and minima;quasiperiodicity;scalability;sequential pattern mining;software design pattern;string (computer science);temporal database	Kuo-Yu Huang;Chia-Hui Chang	2004			data science;data mining;database;data stream mining;k-optimal pattern discovery	DB	-7.48980215696645	-37.05371344494436	75287
97c62eb50140aaec18fd5e8048842a38abdeac78	learning logic rules for the tower of knowledge using markov logic networks	scene interpretation;pattern recognition;markov logic networks	In this paper, we propose a novel logic-rule learning approach for the Tower of Knowledge (ToK) architecture, based on Markov logic networks, for scene interpretation. This approach is in the spirit of the recently proposed Markov logic networks for machine learning. Its purpose is to learn the soft-constraint logic rules for labeling the components of a scene. In our approach, FOIL (First Order Inductive Learner) is applied to learn the logic rules for MLN and then gradient ascent search is utilized to compute weights attached to each rule for softening the rules. This approach also benefits from the architecture of ToK, in reasoning whether a component in a scene has the right characteristics in order to fulfil the functions a label implies, from the logic point of view. One significant advantage of the proposed approach, rather than the previous versions of ToK, is its automatic logic learning capability such that the manual insertion of logic rules is not necessary. Experiments of labeling the identified components in buildings, for building scene interpretation, illustrate the promise of this approach.	markov chain;markov logic network	Mai Xu;Maria Petrou;Jianhua Lu	2011	IJPRAI	10.1142/S0218001411008610	computer vision;linear temporal logic;description logic;computer science;artificial intelligence;bunched logic;machine learning;pattern recognition;mathematics;proof calculus;multimodal logic;algorithm;autoepistemic logic	Logic	-7.25093362020401	-28.576029603367004	75336
024059f6bd531cc413f86e43e680eca595f3a489	enabling glosa for adaptive traffic lights	transition graph glosa green light optimized speed advisory system ideal target speed recommendations semiadaptive traffic lights fully adaptive traffic lights traffic light controller state graph;graph theory driver information systems;detectors vehicles prognostics and health management equations probability cities and towns conferences	Green Light Optimized Speed Advisory (GLOSA) systems aim at giving ideal target speed recommendations to the driver when approaching a traffic light to lower CO2 emissions (and fuel consumption) and to reduce the number of unnecessary stops. These systems have been shown to work well with static traffic light programs, unfortunately, a large portion of traffic lights in inner cities are adaptive and can change their behaviour with almost no lead time. This paper presents and validates (using field tests and simulation) a method to help overcome this problem and forecast fully and semi-adaptive traffic lights. First, we transformed the state graph of the traffic light controller into a transition graph focusing on signal changes and their occurrence probability. We then reduced routing possibilities within the graph using real life observations and recorded detector data of the traffic light. We further optimized our system in terms of needed storage and computationally efficiency. Our results show that in 80% of all cases we could predict signal changes 15s in the future with a high enough accuracy to enable GLOSA for adaptive traffic lights.	real life;routing;semiconductor industry;simulation	Bobby Bodenheimer;Alexej Brauer;David Eckhoff;Reinhard German	2014	2014 IEEE Vehicular Networking Conference (VNC)	10.1109/VNC.2014.7013336	simulation;telecommunications;computer security	Arch	-14.690412555533578	-30.25469593237213	75482
6a107d02ec3f325e397c59fbee78f1951601c2af	real-time public transport service-level monitoring using passive wifi: a spectral clustering approach for train timetable estimation		A new area in which passive WiFi analytics have promise for delivering value is the real-time monitoring of public transport systems. One example is determining the true (as opposed to the published) timetable of a public transport system in real-time. In most cases, there are no other publicly-available sources for this information. Yet, it is indispensable for the real-time monitoring of public transport service levels. Furthermore, this information, if accurate and temporally fine-grained, can be used for very low-latency incident detection. In this work, we propose using spectral clustering based on trajectories derived from passive WiFi traces of users of a public transport system to infer the true timetable and two key performance indicators of the transport service, namely public transport vehicle headway and in-station dwell time. By detecting anomalous dwell times or headways, we demonstrate that a fast and accurate real-time incidentdetection procedure can be obtained. The method we introduce makes use of the advantages of the highfrequency WiFi data, which provides very low-latency, universally-accessible information, while minimizing the impact of the noise in the data.	cluster analysis;digital footprint;image noise;modal logic;real-time clock;real-time locating system;real-time transcription;schedule;sensor;spectral clustering;tracing (software)	Baoyang Song;Laura Wynter	2017	CoRR		simulation;telecommunications;computer security	ML	-17.84336200736978	-31.151798895547604	75486
0279e88eb2c72dba9c5aeff275e9095c791b64d2	summarizing order statistics over data streams with duplicates	statistics monitoring stock markets tail high speed networks data analysis data mining histograms data structures ip networks;order statistic;rank queries approximation order statistics summarization data streams rank queries processing duplicated data elements;query processing;data stream;rank queries processing;data streams;approximation theory;relative error;statistics approximation theory query processing;statistics;duplicated data elements	In this paper, we investigated the problem of approximately processing rank queries against distinct data elements in a data stream with the presence of duplicated data elements. Novel space and time efficient techniques are developed for continuously maintaining order statistics so that rank queries can be answered with a relative error guarantee. This is the first work providing the space and time efficient data stream techniques to process approximate rank queries with relative error guarantees against distinct data elements.	approximation algorithm;approximation error	Xuemin Lin;Yidong Yuan;Masaru Kitsuregawa;Xiaofang Zhou;Jeffrey Xu Yu	2007	2007 IEEE 23rd International Conference on Data Engineering	10.1109/ICDE.2007.369004	approximation error;order statistic;computer science;data mining;database;data stream mining;information retrieval;statistics;approximation theory	DB	-7.544203654965293	-34.389112935393314	75800
6f314d4eaa32906b4b73a4518cd30989798bafa8	probabilistic reverse nearest neighbor queries on uncertain data	databases;modelizacion;nearest neighbor searches;approximate algorithm;probability;spatial data;query processing;reverse nearest neighbor queries;query processing data handling probability;reverse nearest neighbor;pruning tree;information retrieval;efficient algorithm;probability density function;echantillonnage;interrogation base donnee;interrogacion base datos;rnn query;probabilistic approach;indexing terms;poda;sampling based approximate algorithm probabilistic reverse nearest neighbor query rnn query object retrieval pruning approaches multidimensional uncertain data;object retrieval;spatial database;sampling;modelisation;vecino mas cercano;data analysis;systeme incertain;data privacy;pruning approaches;enfoque probabilista;approche probabiliste;sampling based approximate algorithm;nearest neighbor searches recurrent neural networks databases information retrieval multidimensional systems data analysis delay data privacy probability density function;traitement de la requete;spatial data query processing reverse nearest neighbor queries uncertain data;plus proche voisin;nearest neighbour;spatial data structures;base dato especial;tratamiento pregunta;probabilistic reverse nearest neighbor query;recurrent neural networks;data handling;base de donnees spatiale;muestreo;sistema incierto;uncertain data;elagage;modeling;uncertain system;database query;multidimensional systems;multidimensional uncertain data;structure donnee spatiale	Uncertain data are inherent in various important applications and reverse nearest neighbor (RNN) query is an important query type for many applications. While many different types of queries have been studied on uncertain data, there is no previous work on answering RNN queries on uncertain data. In this paper, we formalize probabilistic reverse nearest neighbor query that is to retrieve the objects from the uncertain data that have higher probability than a given threshold to be the RNN of an uncertain query object. We develop an efficient algorithm based on various novel pruning approaches that solves the probabilistic RNN queries on multidimensional uncertain data. The experimental results demonstrate that our algorithm is even more efficient than a sampling-based approximate algorithm for most of the cases and is highly scalable.	approximation algorithm;computation;nearest neighbor search;random neural network;sampling (signal processing);scalability;synthetic intelligence;time complexity;uncertain data	Muhammad Aamir Cheema;Xuemin Lin;Wei Wang;Wenjie Zhang;Jian Pei	2010	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2009.108	sampling;probability density function;systems modeling;index term;multidimensional systems;information privacy;computer science;probabilistic database;recurrent neural network;machine learning;group method of data handling;pattern recognition;probability;data mining;database;spatial analysis;data analysis;spatial database;statistics	DB	-8.396988619257428	-33.225318691642926	75804
91f4a7c7afbd95a8a27cceef59a2792b2e1de5d1	spatio-temporal estimation of mobile-phone call demand in the kumamoto earthquakes		Due to the increasing importance of mobile communications in disaster mitigation and relief, it is very critical to be able to communicate and share critical information with others anytime and anywhere during natural disasters such as earthquakes. However, the mobile network infrastructures are usually not only physically damaged by the disasters but also congested by a tremendous traffic of mobile-phone calls. Therefore, being able to estimate the mobile-phone call demand is a key for mobile network operators to better prepare for and respond to the network congestion before and during the disasters. In this paper, we propose a data-driven approach to estimate the spatio-temporal mobile-phone call demand by leveraging the big data collected from the operational mobile network. Specifically, we develop a model that shows how the mobile-phone call demand varies with population based on the collected data from public industrial surveys and reports. We apply it to the live population distribution big data during the Kumamoto earthquakes to demonstrate the mobile-phone call demand changes spatially and temporally on the geographical map. In addition, we also demonstrate the estimation of mobile-phone call demand during the worst-case — a hypothetical earthquake occurs in the daytime. Finally, we discuss the important factors that affect of mobile-phone call demand and the trend of future mobile networks and services that have great potential to alleviate the network congestions in future disasters.	anytime algorithm;best, worst and average case;big data;cartography;mobile phone;network congestion	Lei Zhong;Kiyoshi Takano;Kunikazu Yoda;Yusheng Ji;Shigeki Yamada	2017	2017 4th International Conference on Information and Communication Technologies for Disaster Management (ICT-DM)	10.1109/ICT-DM.2017.8275686	big data;network congestion;mobile phone;telecommunications;mobile computing;mobile telephony;population;cellular network;natural disaster	ML	-17.772916243687774	-31.377914895639528	76175
6fe0c9c181710d4290adca04130bca052f5db4b2	research on automated modeling algorithm using association rules for traffic accidents		The study of Influencing factors of traffic accidents is an important research direction in the field of traffic safety. In this paper, the traffic accidents of Shanghai Expressway from April to June 2014 were excavated using association rule mining which generated lots of frequent item sets. The strong rules hidden in these frequent item sets often uncover the association between influencing factors of accidents, which can be used to reduce the occurrence of accidents by breaking them. The rules can also be used to probe usual scenes of accidents, and some corresponding security improvement measures can be taken to prevent the accidents, and ultimately improve the city's traffic safety level. General speaking, association rule mining can produce tons of weak rules, the study first designed a method to calculate minimal Support value of training parameters, and further put forward a way to extract strong rules automatically. The results of the experiments showed that these methods proposed in the paper are effective. Therefore, an automatic modeling algorithm using association rules was finally established to promote the effective application of association rule mining on intelligent transportation system.	algorithm;association rule learning;experiment	Zhen Gao;Ruifeng Pan;Rongjie Yu;Xuesong Wang	2018	2018 IEEE International Conference on Big Data and Smart Computing (BigComp)	10.1109/BigComp.2018.00027	association rule learning;intelligent transportation system;algorithm;computer science	DB	-17.522691569198994	-32.57238772388115	76770
359a7fc271cfa4a1f8d94957e2ed8a799789642a	modeling the propagation of forest insect infestation using machine learning techniques		Infestations caused by the mountain pine beetle (MPB) can be seen as complex spatio-temporal process with severe ecological impacts on the forest environment. In order to manage and prevent the insect infestation and reduce significant forest loss it is necessary to improve knowledge about the infestation process. The main objective of this research study is to design and implement a model based on decision trees (DT) mashie learning (ML) technique to forecast the spatial propagation of MPB infestation. The study is implemented in the Bulkley-Nechako region of British Columbia, Canada using data sets for the three time points 2004, 2008 and 2012. The results indicate that the derived DT can accurately characterize the relationships between the considered factors and MPB propagation. The developed DT method can be used to estimate future spread patterns of MPB infestations.	machine learning;software propagation	Mileva Samardzic-Petrovic;Suzana Dragicevic	2015		10.1007/978-3-319-21470-2_47	insect infestation;infestation;mathematical optimization;agricultural engineering;mountain pine beetle;geographic information system;decision tree;computer science	HCI	-13.13531345267301	-25.591620804785812	77279
389a804dfd9c49f62f7fc208db0c711300af8898	dbccom: density based clustering with constraints and obstacle modeling		Spatial data clustering groups similar objects based on their distance, connectivity, or their relative density in space whereas in the real world, there exist many physical constraints e.g. highways, rivers, hills etc. that may affect the result of clustering. Therefore, these obstacles when taken into consideration render the cluster analysis a hopelessly slow exercise. In this paper, a clustering method is being proposed that considers the presence of physical obstacles and uses obstacle modeling as a preprocessing step. With a view to prune the search space and reduce the complexity at search levels, the work further incorporates the hierarchical structure into the existing clustering structure. The clustering algorithm can detect clusters of arbitrary shapes and sizes and is insensitive to noise and input order.	algorithm;cluster analysis;dbscan;existential quantification;hierarchical clustering;preprocessor;scalability	Neelam Duhan;A. K. Sharma	2011		10.1007/978-3-642-22606-9_24	correlation clustering	DB	-13.247160512249552	-37.55458921696942	77283
0c62161a3a368e0407ca0835e05b9302cb78042f	a multi-scale method of mapping urban influence	urban development;scale;multiple scales;urban pattern;cluster analysis;gis;urban area;ecosystem service;ecosystem services;environmental quality;environmental planning	Urban development can impact environmental quality and ecosystem services well beyond urban extent. Many methods to map urban areas have been developed and used in the past, but most have simply tried to map existing extent of urban development, and all have been single-scale techniques. The method presented here uses a clustering approach to look beyond the extant urban area at multiple scales. The result is a single, synoptic multi-scale map of urban influence that should be useful in urban, regional and environmental planning efforts. Published by Elsevier Ltd.	cluster analysis;ecosystem services	Timothy G. Wade;James D. Wickham;Nicola Zaccarelli;Kurt H. Riitters	2009	Environmental Modelling and Software	10.1016/j.envsoft.2009.03.006	ecosystem services;urban density;biology;geomatics;environmental engineering;computer science;environmental resource management;urban planning;ecology	HCI	-12.767686036626808	-24.06675572451515	77372
97d0f7cb78762c428718e544f8a4ccb0e157fe5a	the autonomous detection of tree position with different gps devices for the need of early apple yield forecast		The accuracy of different GPS devices for sampling of trees required for the early yield forecast was studied in two years’ campaign. In our experiment March II, PDA ASUS P565 and Nokia 5800 XpressMusic were used. To determine the positions and their accuracy, 245 randomly trees were selected from 245 orchards. We found out that the measurements made in two years with MARCH II deviated in average in diagonal for 16.72 m, in ASUS P565 for 15.41 m and in Nokia 5800 XpressMusic for 46.14 m. ASUS P565 was found to be the most accurate device because the two season’s measurements deviated in average in diagonal only for 1.31 m from MARCH II, but there was no significant difference. Despite the fact that discrepancies in individual trees were minimal (0.33 m) in particular measurement, those two devices are not precise sufficiently to identify unequivocally the position of sample trees.	asus eee pc;attack tree;gps navigation device;global positioning system;nokia 5800 xpressmusic;personal digital assistant;randomness;sampling (signal processing)	Denis Stajnko;Miran Lakota	2011			statistics;global positioning system;real-time computing;sampling (statistics);diagonal;engineering	Metrics	-16.50257471949531	-33.79178281850127	77781
9a13990982c17d38a1dbf2317c25c68c39f09154	assessing reliable human mobility patterns from higher-order memory in mobile communications	cs si;cond mat dis nn;physics soc ph	Understanding how people move within a geographical area, e.g. a city, a country or the whole world, is fundamental in several applications, from predicting the spatio-temporal evolution of an epidemic to inferring migration patterns. Mobile phone records provide an excellent proxy of human mobility, showing that movements exhibit a high level of memory. However, the precise role of memory in widely adopted proxies of mobility, as mobile phone records, is unknown. Here we use 560 million call detail records from Senegal to show that standard Markovian approaches, including higher order ones, fail in capturing real mobility patterns and introduce spurious movements never observed in reality. We introduce an adaptive memory-driven approach to overcome such issues. At variance with Markovian models, it is able to realistically model conditional waiting times, i.e. the probability to stay in a specific area depending on individuals' historical movements. Our results demonstrate that in standard mobility models the individuals tend to diffuse faster than observed in reality, whereas the predictions of the adaptive memory approach significantly agree with observations. We show that, as a consequence, the incidence and the geographical spread of a disease could be inadequately estimated when standard approaches are used, with crucial implications on resources deployment and policy-making during an epidemic outbreak.	advance directive - proxy;deploy;entity name part qualifier - adopted;geographic coordinate system;high-level programming language;incidence matrix;mobile phone;movement;sample variance	Manlio De Domenico;Joan T. Matamalas;Alexandre Arenas	2016	Journal of the Royal Society, Interface	10.1098/rsif.2016.0203	simulation;telecommunications;mobility model;ecology;statistics	Web+IR	-19.03848342447211	-34.200409702921334	78003
7f861306a8e56f4a0727d553684aaa281615ec54	negfin: an efficient algorithm for fast mining frequent itemsets		Abstract Frequent itemset mining is a basic data mining task and has numerous applications in other data mining tasks. In recent years, some data structures based on sets of nodes in a prefix tree have been presented. These data structures store essential information about frequent itemsets. In this paper, we propose another efficient data structure, NegNodeset . Similar to other such data structures, the basis of NegNodeset is sets of nodes in a prefix tree. NegNodeset employs a novel encoding model for nodes in a prefix tree based on the bitmap representation of sets. Based on the NegNodeset data structure, we propose negFIN, which is an efficient algorithm for frequent itemset mining. The efficiency of the negFIN algorithm is confirmed by the following three reasons: (1) the NegNodeset s of itemsets are extracted using bitwise operators, (2) the complexity of calculating NegNodeset s and counting supports is reduced to O ( n ), where n is the cardinality of NegNodeset , and (3) it employs a set-enumeration tree to generate frequent itemsets and uses a promotion method to prune the search space in this tree. Our extensive performance study on a variety of benchmark datasets indicates that negFIN is the fastest algorithm, compared with previous state-of-the-art algorithms. However, our algorithm runs with the same speed as dFIN on some datasets.	algorithm	Nader Aryabarzan;Behrouz Minaei-Bidgoli;Mohammad Teshnehlab	2018	Expert Syst. Appl.	10.1016/j.eswa.2018.03.041	machine learning;cardinality;trie;bitmap;artificial intelligence;computer science;algorithm;data structure;bitwise operation	ML	-5.637948966523183	-37.85452233796164	78019
5c90fc361bf120eec6bcd4af4df745bbd62e7ed7	analysis of mining waste dump site stability based on multiple remote sensing technologies				Lianhuan Wei;Yun Zhang;Zhanguo Zhao;Xiaoyu Zhong;Shanjun Liu;Yachun Mao;Jiayu Li	2018	Remote Sensing	10.3390/rs10122025		HCI	-11.485583460365014	-27.325792375691275	78156
7267bb2e799e0de908a64db29bca835690f25016	building fp-tree on the fly: single-pass frequent itemset mining		The FP-Growth algorithm has been studied extensively in the field of frequent pattern mining. The algorithm offers the advantage of avoiding costly database scans in comparison with Apriori-based algorithms. However, since it still requires two database scans, it cannot be used on streaming data. Also, the algorithm is designed for static datasets, where the input transactions are fixed and thus cannot be used for incremental or interactive mining. Existing incremental mining algorithms are not easily adoptable for on-the-fly, fast, and memory efficient FP-tree mining. In this paper we propose a novel SPFP-tree (single pass frequent pattern tree) algorithm that scans the database only once and provides the same tree as FP-Growth. Our algorithm changes the tree structure dynamically to create a highly compact frequency-ordered tree on the fly. With the insertion of each new transaction our algorithm dynamically maintains a tree identical to an FP-tree. Experimental results show the efficiency of the SPFP-tree algorithm in both incremental and interactive mining of frequent patterns.	association rule learning;on the fly	Nima Shahbazi;Rohollah Soltani;Jarek Gryz;Aijun An	2016		10.1007/978-3-319-41920-6_30	artificial intelligence;computer science;on the fly;pattern recognition;tree structure;association rule learning;streaming data;database transaction	ML	-6.215978149490292	-37.10675207655449	78283
30773e34f091c8aadbc9bfc56c85515e5bf02651	pattern mining in pos data using a historical tree	evolutionary computation;decision tree;tree data structures;data mining;multiobjective evolutionary algorithm;pattern mining;computer experiment;data extraction;tree structure;decision tree model pattern mining pos data historical tree multiobjective evolutionary algorithm;decision trees;data mining decision trees tree graphs evolutionary computation intrusion detection customer relationship management tree data structures performance analysis alcoholic beverages dairy products;tree data structures data mining decision trees evolutionary computation	In this paper, we propose a pattern mining method using POS data. Firstly, we transform raw POS data into tree structured data, extract some promising patterns from it by using a multiobjective evolutionary algorithm (MOEA), and construct a decision tree model using these patterns and customer attributes. From our computational experiments using practical POS data obtained from a supermarket chain in Japan, we show that our method can mine some promising patterns. Further, these patterns are useful for constructing a better decision tree model to identify target customers	computation;data mining;decision tree model;evolutionary algorithm;experiment;moea framework;purchasing	Takanobu Nakahara;Hiroyuki Morita	2006	Sixth IEEE International Conference on Data Mining - Workshops (ICDMW'06)	10.1109/ICDMW.2006.129	decision tree model;decision tree learning;computer science;order statistic tree;machine learning;decision tree;tree rearrangement;pattern recognition;incremental decision tree;data mining;id3 algorithm;tree traversal;evolutionary computation	Robotics	-4.606500982718531	-35.39380557144313	78779
2becd4b52208c3640d0bdecd38d634194c5393f6	organisation of indoor navigation data from a data query perspective	indoor navigation;gis database indoor navigation data data query;performance evaluation;query processing;indoor communication;position measurement image edge detection performance evaluation navigation accuracy;gis database;accuracy;navigation;handicapped aids;geospatial information;geospatial information indoor navigation;image edge detection;data query;geographic information systems;position measurement;data handling;indoor navigation data;query processing data handling geographic information systems handicapped aids indoor communication navigation	Indoor Navigation is becoming a more and more important topic. It is a key tool for the integration of disabled people into environments which they are not familiar with. With this paper we want to address the problem of indoor navigation being much more complex than outdoor navigation with a thorough modelling of queries which a indoor navigation GIS database shall be able to answer quickly and present an organisation of indoor navigation data tailored to scalable and flexible indoor navigation.	gps navigation device;geographic information system;scalability	Martin Werner;Moritz Kessel	2010	2010 Ubiquitous Positioning Indoor Navigation and Location Based Service	10.1109/UPINLBS.2010.5653981	turn-by-turn navigation;computer vision;geography;multimedia;mobile robot navigation;remote sensing	HCI	-17.430576733052103	-36.805086178485936	78801
dbce0ff97a3e8a3e3022e292988760a4a8bf2d24	a comparative analysis of artificial immune network models	comparative analysis;artificial immune system;generic model;network model;artificial immune network	This paper presents a review of different artificial immune network models, which have been published during the last years. A general model of artificial immune network is presented, which provides a common notation that allows the comparison of different models. A descriptive and comparative analysis is presented emphasizing similarities, differences and relationships between models. Finally, some conclusions and suggestions for improving existent models are presented.	qualitative comparative analysis	Juan Carlos Galeano;Angélica Veloza-Suan;Fabio A. González	2005		10.1145/1068009.1068066	qualitative comparative analysis;computer science;artificial intelligence;network model;machine learning;operations research;artificial immune system	AI	-7.5198015312787545	-27.012579478363772	78828
0aa604673591a2f8e433df9a404084222056d012	predicting future locations using prediction-by-partial-match	wireless access;wifi positioning;prediction by partial match;ucsd;data compression;supervised learning;topology discovery;first order;success rate;data consistency;prediction	We implemented the Prediction-by-Partial-Match data compression algorithm as a predictor of future locations. Positioning was done using IEEE 802.11 wireless access logs. Several experiments were run to determine how to divide the data for training and testing and how to best represent the data as a string of symbols. Our test data consisted of 198 datasets containing over 28,000 <time, location> pairs, obtained from the UCSD Wireless Topology Discovery project. Tests of a first-order PPM model revealed a 90% success rate in predicting a user's location given the time. The third-order model, which is given the previous time and location and asked to predict the location at a given time, is correct 92% of the time.	algorithm;data compression;experiment;first-order predicate;kerrison predictor;string (computer science);test data;ucsd pascal/p-system	Ingrid Burbey;Thomas L. Martin	2008		10.1145/1410012.1410014	data compression;prediction;computer science;data science;machine learning;first-order logic;data mining;supervised learning;data consistency;statistics	Visualization	-13.661732577271541	-34.960111279707306	78871
b035efdcfa8576b8d8ab7c116b79a505be13038d	comprehensiveness and interpretability of linguistic data summaries: a natural language focused perspective	databases;natural language based method natural language focused perspective linguistic data summary interpretability linguistic data summary comprehensiveness data mining machine learning fuzzy rule base comprehensiveness fuzzy rule base interpretability structural complexity semantical complexity fuzzy querying interface human consistent hci human computer interface psychological aspect cognitive aspect interpretability analysis comprehensibility human consistent method quantitative evaluation linguistic dynamic data summarization linguistic static data summarization web log analysis innovation analysis formal language based method;pragmatics;linguistic summaries;human computer interaction;fuzzy rule base interpretability;natural language based method;fuzzy reasoning;psychological aspect;fuzzy querying interface;query processing;remuneration;pragmatics data mining natural languages context abstracts databases remuneration;fuzzy rules;formal languages;natural languages;psychology;data mining;fuzzy logic;structural complexity;semantical complexity;internet;machine learning;comprehensiveness interpretability;abstracts;linguistic data summary comprehensiveness;web log analysis;comprehensibility;linguistic data summary interpretability;linguistic dynamic data summarization;computational linguistics;fuzzy rule base comprehensiveness;learning artificial intelligence;formal language based method;natural language focused perspective;interpretability analysis;innovation analysis;cognitive aspect;natural language processing;fuzzy rules comprehensiveness interpretability fuzzy logic linguistic summaries;context;knowledge based systems;quantitative evaluation;human consistent hci;linguistic static data summarization;human computer interface;human consistent method	We consider the important problem of comprehensiveness of linguistic data summaries equated with linguistically quantified propositions in Zadeh's sense. Motivated by Michal-ski's [29] seminal approach to the comprehensiveness of data mining and machine learning results, with a clear emphasis on natural language, we advocate the use of linguistic summaries which provide a new quality and an exceptional human consistency and comprehensiveness. Extending our previous works, we first relate our approach to some related results on the interpretability and comprehensiveness of fuzzy rule bases, both with respect to structural and semantical complexity. We show the use of a fuzzy querying interface as not only an approach that is effective and efficient but which provides an exceptional comprehensiveness through its highly human consistent HCI (human computer interface). We emphasize a psychological and cognitive aspect of comprehensibility and interpretability analyses. We advocate the use of human consistent methods based on natural language. We indicate a possibility of using quantitative evaluations. We illustrate our analysis by two examples related to the linguistic summarization of both static and dynamic data in the area of innovation and Web log analyses, and justify the results obtained by domain experts positive assessments. In general, we propose a synergistic combination of formal and natural language based methods to solve the inherently human specific problem of comprehensiveness and interpretability.	data mining;dynamic data;fuzzy rule;human computer;human–computer interaction;machine learning;natural language;synergy;world wide web	Janusz Kacprzyk;Slawomir Zadrozny	2013	2013 IEEE Symposium on Computational Intelligence for Human-like Intelligence (CIHLI)	10.1109/CIHLI.2013.6613262	natural language processing;computer science;artificial intelligence;data mining	AI	-5.168681700554035	-24.59441224891147	79119
12305763d29e45b1216172588d61f2c98bdeb3a1	querying and extracting timeline information from road traffic sensor data	pedestrian safety;poison control;injury prevention;safety literature;traffic safety;injury control;traffic sensor data;home safety;injury research;safety abstracts;human factors;occupational safety;safety;safety research;accident prevention;violence prevention;bicycle safety;poisoning prevention;tq index;historical traffic sensor data;falls;timeline model;ergonomics;suicide prevention;traffic data query processing	The escalation of traffic congestion in urban cities has urged many countries to use intelligent transportation system (ITS) centers to collect historical traffic sensor data from multiple heterogeneous sources. By analyzing historical traffic data, we can obtain valuable insights into traffic behavior. Many existing applications have been proposed with limited analysis results because of the inability to cope with several types of analytical queries. In this paper, we propose the QET (querying and extracting timeline information) system-a novel analytical query processing method based on a timeline model for road traffic sensor data. To address query performance, we build a TQ-index (timeline query-index) that exploits spatio-temporal features of timeline modeling. We also propose an intuitive timeline visualization method to display congestion events obtained from specified query parameters. In addition, we demonstrate the benefit of our system through a performance evaluation using a Busan ITS dataset and a Seattle freeway dataset.	cns disorder;database;freeway;genetic heterogeneity;imagery;network congestion;performance evaluation;privilege escalation;question (inquiry);sensor;silo (dataset);timeline fluoride releasing resin;algorithm;tocopherylquinone	Ardi Imawan;Fitri Indra Indikawati;Joonho Kwon;Praveen R. Rao	2016		10.3390/s16091340	engineering;suicide prevention;human factors and ergonomics;injury prevention;data mining;transport engineering;computer security	ML	-17.05448661925364	-31.68520672701141	79288
8b3ea26302703986967b33f4928e5790c1e0508a	profiling urban activity hubs using transit smart card data		Understanding why and where people travel by public transport is a key enabler for smart cities because it informs city planning, daily operations, and sustainable city growth. This article introduces a data-driven approach using transit smart card data to discover where activities are concentrated and why people travel to those regions. Our approach is based on the idea of stays between passenger trips. A stay has an arrival time and a period of time spent in a certain region. The regions where stays are concentrated are called hubs. Coherent clusters of stays indicate human activities such as going to work or short errands. An efficient and robust algorithm is proposed for learning hubs and their activities. Triangulation with points of interest and ticket data validates that activity stays and hub activities satisfy common sense expectations. The utility of the activity hub profiles for urban planners and transport managers is demonstrated by use cases for operational, tactical and strategic goals.	algorithm;coherent;ethernet hub;institute for operations research and the management sciences;point of interest;profiling (computer programming);smart card;smart city;time of arrival;usb hub	Rachel Cardell-Oliver;Travis Povey	2018		10.1145/3276774.3276778	computer science;sustainable city;public transport;urban computing;smart card;trips architecture;control engineering;ticket;enabling;transport engineering;urban planning	HCI	-18.495576280458693	-31.759510926715077	79425
789baed7fd783c134ad8c573768f7cdcb0061fdd	building a dynamic data driven application system for hurricane forecasting	time scale;dynamic data driven application systems;real time;coastal modeling;hurricane forecasting;dddas;control system;dynamic data driven application system;priority computing;ecological model;computational frameworks;coastal area;event driven computing	The Louisiana Coastal Area presents an array of rich and urgent scientific problems that require new computational approaches. These problems are interconnected with common components: hurricane activity is aggravated by ongoing wetland erosion; water circulation models are used in hurricane forecasts, ecological planning and emergency response; environmental sensors provide information for models of different processes with varying spatial and time scales. This has prompted programs to build an integrated, comprehensive, computational framework for meteorological, coastal, and ecological models. Dynamic and adaptive capabilities are crucially important for such a framework, providing the ability to integrate coupled models with real-time sensor information, or to enable deadline based scenarios and emergency decision control systems. This paper describes the ongoing development of a Dynamic Data Driven Application System for coastal and environmental applications (DynaCode), highlighting the challenges of providing accurate and timely forecasts for hurricane events.	computation;control system;dynamic data driven applications systems;real-time web;sensor	Gabrielle Allen	2007		10.1007/978-3-540-72584-8_136	simulation;control system;data mining;operations research;social ecological model	AI	-13.196772438061648	-26.588300526339744	79518
b29e41d6fab9a936f81a26f454a8b2f8ec1b9e3f	research on estimation method of gross registered tonnage of ships in grand canal	gross registered tonnageregression analysissize of shipsspss	  In this paper, the author uses the method of mathematical statistics to analyze several statistical samples, finds the relationship  between the Gross Registered Tonnage of ships with the size of them and finally gets a fitted equation. Subsequently, according  to the specification of “The standard ships’ main dimensions in Grand Canal”, the equation is used to point out the relationship  between the Gross Registered Tonnage of common type Grand Canal ships with the size of them.    		Xu Peng;Hou Lei;Wu Zhong	2011		10.1007/978-3-642-18387-4_12	simulation;geography;operations research;cartography	Vision	-10.888950535865188	-24.73684998191132	79593
d27eae5929e3cdf1fb3fa9d798c7653092200ee7	development of data collecting system for forecasting with meteorological sensors	databases;forecasting;observers;data communication;mechanical sensors;meteorology	As one of sensor applications, meteorological service collects information for weather and uses it for preventing disaster risk. To achieve this, data from sensor networks must be integrated with communication and data processing system. In this paper, we present a specific web-based application with mobile networks to transmit weather data timely by introducing forecasting system. We implement central database for remote weather stations and make use of it in a preventive way, to recognize the occurrence of natural disasters by external geo-dynamics.	algorithmic efficiency;database;information sensitivity;risk management;sensor;web application	Ever Enrique Castillo Osorio;SeokYoon Kang;Bum-Su Kim;JoHo Lim;Kyong Hoon Kim;Ki-Il Kim	2017	2017 International Conference on Information Networking (ICOIN)	10.1109/ICOIN.2017.7899534	forecasting;data mining;statistics	Mobile	-15.915049133438938	-30.63453584789619	79873
6c33b059b36179e9cfe516b0be71924659a968c5	ancient maya regional settlement and inter-site analysis: the 2013 west-central belize lidar survey	settlement patterns;f1201 latin america general;landscape archaeology;gn anthropology;maya archaeology;lidar	During April and May 2013, a total of 1057 km2 of LiDAR was flown by NCALM for a consortium of archaeologists working in West-central Belize, making this the largest surveyed area within the Mayan lowlands. Encompassing the Belize Valley and the Vaca Plateau, West-central Belize is one of the most actively researched parts of the Maya lowlands; however, until this effort, no comprehensive survey connecting all settlement had been conducted. Archaeological projects have investigated at least Remote Sens. 2014, 6 8672 18 different sites within this region. Thus, a large body of archaeological research provides both the temporal and spatial parameters for the varied ancient Maya centers that once occupied this area; importantly, these data can be used to help interpret the collected LiDAR data. The goal of the 2013 LiDAR campaign was to gain information on the distribution of ancient Maya settlement and sites on the landscape and, particularly, to determine how the landscape was used between known centers. The data that were acquired through the 2013 LiDAR campaign have significance for interpreting both the composition and limits of ancient Maya political units. This paper presents the initial results of these new data and suggests a developmental model for ancient Maya polities.	autodesk maya	Arlen F. Chase;Diane Z. Chase;Jaime J. Awe;John F. Weishampel;Gyles Iannone;Holley Moyes;Jason Yaeger;M. Kathryn Brown;Ramesh L. Shrestha;William E. Carter;Juan Carlos Fernandez Diaz	2014	Remote Sensing	10.3390/rs6098671	lidar;landscape archaeology;physics;remote sensing	AI	-13.340314140815552	-24.308437803097707	80051
4316aaafb0a9675698c19d1f41db7697cf0da50e	interpretable associations over datacubes: application to hospital managerial decision making		The world concern about the costs of the health care systems has raised the importance of counting on precise and interpretable tools, that help the health care institution's managers to make decisions to optimize the use of health resources. In this paper we propose a new Classification based on Association Rules (CAR) algorithm that improves the interpretability of the results, making it specially useful for decision making. Changing the usual way to obtain the rules we follow four goals: first to improve the interpretability of the result by obtaining rules meaningful and interpretable by themselves, secondly to reduce the complexity of the result obtaining a lower number of rules; thirdly, to obtain simpler rules, with less size in number of antecedents; and finally to avoid the usual over-fitting problem of the classification methods by obtaining a generic final result set, where specific rules for specific cases are avoided unless they are necessary. To prove the utility of our proposal we have used it in an example of decision support regarding the planning of the surgery rooms.	data cube;decision making;decision support system;generic drugs;health care;mental association;overfitting;result set;rule (guideline);algorithm	Miguel A. Prados de Reyes;Carlos Molina;Belén Prados-Suárez;Maria Carmen Peña Yáñez	2014	Studies in health technology and informatics	10.3233/978-1-61499-432-9-131	knowledge management;data mining;medicine	AI	-5.239773029801775	-29.598215205577052	80400
01f5226d73ec9a7ad22ae05aea8e67af73c2649e	study on social relations between individuals based on graph theory	activity degree;graph theory;activity degree social relations graph theory tolerance relation social activity maximum tolerance class;maximum tolerance class;social sciences;set theory;tolerance relation;social sciences graph theory;social relation;social relations;average cost;social activity;graph theory costs rough sets set theory information science educational institutions humans fuzzy set theory spine artificial intelligence	A formulated framework of tolerance relation in the applications of social activities is presented. The formulation can not only describe the activity degree of entities in a society, but also the average cost and the maximum cost at which one completes a task through various social relations. The algorithms for computing the maximum tolerance classes, the activity degree, the average cost and the maximum cost are given. Examples show the algorithms are effective. This is a very preliminary formulation, which need further study.	algorithm;entity;graph theory	Jinping Li	2007	Fourth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2007)	10.1109/FSKD.2007.545	social relation;discrete mathematics;machine learning;mathematics;set theory	DB	-5.750851183767131	-24.61327457994742	80434
533eadd4ee3d710f08ca843b4f53b8d6acafa0d0	simulation optimization for emergency department resources allocation	national emergency department overcrowding scale;system simulation;optimisation;new human resources allocation;emergency department resource allocation;simul8;emergency department resources allocation;patient waiting time;emergency department;resource allocation;simulation optimization;results analysis;patient satisfaction;overall performance;optquest;system time;optimal allocation;ed flow;national emergency department overcrowding;actual situation;patient treatment;aging;computational modeling;resource manager;computer model;diagnostic imaging;resource management;human resource	The objective of this paper is to find out an optimal allocation of resources in emergency department (ED) via system simulation to smoothen the flow of ED. The construction of model that based on actual situation can demonstrate the waiting time and system time of patients in ED. Then, study the model and apply compatible with National Emergency Department Overcrowding Scale (NEDOCS) and OptQuest in Simul8 to increase the performance in ED and management of treated patients and thus increase the degree of satisfactions of patients. The results analysis shows that the overall performance in ED can be increased by 8% by new human resources allocation studied.	mathematical optimization;simulation;system time	Shao-Jen Weng;Bing-Chuin Cheng;Shu Ting Kwong;Lee-Min Wang;Chun-Yueh Chang	2011	Proceedings of the 2011 Winter Simulation Conference (WSC)		simulation;resource allocation;resource management;computational model	EDA	-16.60177938783558	-24.606567845736237	80977
ce50530f7794b03f19ea72c096585fa12584c982	batch incremental processing for fp-tree construction using fp-growth algorithm		In the present scenario of global economy and World Wide Web, large sets of evolving and distributed data can be handled efficiently by incremental data mining. Frequent patterns are very important in knowledge discovery and data mining process, such as mining of association rules, correlations. FP-tree is a very versatile data structure used for mining of frequent patterns in knowledge discovery and data mining process. FP-tree is a compact representation of transaction database that contains frequency information of all relevant frequent patterns (FP) of the database. All of the existing incremental frequent pattern mining algorithms, such as AFPIM, CATS, CanTree, CP-tree, and SPO-tree, perform incremental mining by processing one transaction of the incremental part of database at a time and updating it to the FP-tree of initial (original) database. Here, in this paper, we propose a novel method that takes advantage of FP-tree representation of incremental transaction database for incremental mining. We propose a batch incremental processing algorithm BIT_FPGrowth that restructures and merges two small consecutive duration FP-trees to obtain a FP-tree of the FP-Growth algorithm. Our BIT_FPGrowth uses FP-tree as preprocessed data repository to get transactions (i.e., item-sets), unlike other sequential incremental algorithms that read transactions from database. BIT_FPGrowth algorithm takes less time for constructing FP-tree. Our experimental results show that, as the size of the database increases, increase in runtime of BIT_FPGrowth is much less and is least of all the other algorithms.	apriori algorithm;association rule learning;data mining;data structure;distributed computing;distributed database;dynamic problem (algorithms);list of algorithms;pareto efficiency;polynomial;polynomial-time reduction;research data archiving;run time (program lifecycle phase);sorting;terabyte;time complexity;world wide web	Shashikumar G. Totad;R. B. Geeta;P. V. G. D. Prasad Reddy	2012	Knowledge and Information Systems	10.1007/s10115-012-0514-9	gsp algorithm;computer science;data science;machine learning;data mining;database;data stream mining	DB	-6.021873955245657	-36.823302398959115	81181
ce9f6972c8d1eff0a03a09b58e5182d240882948	ontology-based multimode information fusion method	hierarchical structure;fuzzy neural network;fuzzy neural nets;multimode information;fuzzy neural network ontology multimode information information fusion;continuous learning ontology multimode information fusion method database data file fuzzy neural network algorithm;ontologies artificial intelligence;ontologies classification algorithms engines databases clustering algorithms sensors fuzzy neural networks;information fusion;sensor fusion;learning artificial intelligence;ontology;sensor fusion fuzzy neural nets learning artificial intelligence ontologies artificial intelligence	In order to better use with massive, heterogeneous, multimode and other characteristics of information, eliminate redundancy, the formation of the system environment is relatively complete and consistent description. It can ensure rapid and correct decision-making, planning and reflection. In this paper, a multimode information fusion method is proposed aimed at the shortcomings of hierarchical structure. Different databases and data files between different formats can be shielded, while the fuzzy neural network algorithm, make text, images and video seamless fusion by continuous learning. Experimental results show that the method of this paper is better than exist on fusion algorithms at the right rate, leakage pick up rate and false acceptance rata.	academy;algorithm;artificial neural network;automated planning and scheduling;database;environment variable;faceted classification;information processing;neuro-fuzzy;reflection (computer programming);seamless3d;spectral leakage	Chunjiang Zhao;Huarui Wu;Ronghua Gao	2011	2011 IEEE International Conference on Cloud Computing and Intelligence Systems	10.1109/CCIS.2011.6045031	computer science;artificial intelligence;neuro-fuzzy;machine learning;ontology;data mining;sensor fusion	Robotics	-6.353704029596534	-26.733132737211843	81424
d582f1253a0f557ab8200f99836f42a750b45444	experience from 17 years of public transport priority in poznań, poland	road traffic;traffic engineering computing road traffic;cities;traffic signal priority;poznan poland;detection cost reduction public transport priority evolution poznan poland priority differentiation information aggregation priority quality incident warnings;public transit;algorithms;traffic engineering computing;bus priority;detection and identification systems;junctions vehicles detectors delays cities and towns turning companies	Every city has a specific character, character of traffic included, therefore available public transport priority schemes should not be adapted directly in new locations, but should take into account local conditions. On the other hand, locally prepared applications might face significant problems. A presented in this paper example of a public transport priority evolution in Poznań, Poland might give some insight into problems with defining priority levels, local administration, detection and algorithms. Experience gained through 17 years of observing the priority development in Poznań shows further possibilities of improvement such as differentiating priority according to direction or time. A strong improvement of priority quality can be done by aggregation of information from local controls, allowing for incident warnings and reductions of detection cost.	algorithm	Jeremi Rychlewski	2013	16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)	10.1109/ITSC.2013.6728503	geography;civil engineering;transport engineering;computer security	Robotics	-16.469156387037337	-27.40699760827128	81469
8bdf6f03bde08c424c214188b35be8b2dec7cdea	inference attacks against collaborative learning		Collaborative machine learning and related techniques such as distributed and federated learning allow multiple participants, each with his own training dataset, to build a joint model. Participants train local models and periodically exchange model parameters or gradient updates computed during the training. We demonstrate that the training data used by participants in collaborative learning is vulnerable to inference attacks. First, we show that an adversarial participant can infer the presence of exact data points in others’ training data (i.e., membership inference). Then, we demonstrate that the adversary can infer properties that hold only for a subset of the training data and are independent of the properties that the joint model aims to capture. We evaluate the efficacy of our attacks on a variety of tasks, datasets, and learning configurations, and conclude with a discussion of possible defenses.	adversary (cryptography);data point;gradient;inference attack;machine learning	Luca Melis;Congzheng Song;Emiliano De Cristofaro;Vitaly Shmatikov	2018	CoRR		adversarial system;theoretical computer science;adversary;data point;computer science;machine learning;collaborative learning;inference;training set;artificial intelligence	ML	-8.705544833764725	-28.99991196034067	81586
bf9b57ac08e98bea0dfea0f785eaff4e98e9bef4	analysis of time- and space-domain sampling for probe vehicle-based traffic information system	traffic situation;sample size;information systems;traffic information systems data analysis road traffic road vehicles signal sampling;traffic situation time domain sampling space domain sampling probe vehicle traffic information system nyquist sampling theorem signal processing theory traffic information collecting simulation platform traffic flow simulation road network;road network;information science;signal sampling;traffic information system;road traffic;real time traffic;traffic flow;information analysis sampling methods probes information systems traffic control signal sampling telecommunication traffic vehicle detection analytical models signal processing;time domain analysis;traffic surveys;sampling;vehicle locating systems;conference paper;nyquist sampling theorem;data analysis;traffic information systems;signal processing theory;signal processing;intelligent vehicle highway systems;intelligent systems;motor transportation;space domain sampling;highway traffic control;probe vehicle;vehicles;information system;traffic flow simulation;traffic information collecting simulation platform;time domain sampling;road vehicles;sampling theorem	Using vehicles as probes is a flexible and low-cost way to obtain real-time traffic information. A key problem of using probe vehicles is to determine vehicle's sampling period and probe sample size. This paper addresses the sampling issue of using probe vehicles for detecting traffic information. An extended Nyquist sampling theorem based on signal processing theory is proposed to derive bounds on the sampling period and probe sample size. We also develop a Traffic & Information-collecting Simulation Platform (TISP), to simulate the traffic flows in a road network and generate probe vehicle data for analysis. We demonstrate through simulations that the traffic situations can be reconstructed from the samples without distortion according to the designed sampling period and sample size. The methods proposed in this paper can be a valuable tool for designers on planning parameters in the probe vehicle-based traffic information system.	distortion;information system;nyquist–shannon sampling theorem;real-time clock;sampling (signal processing);sensor;signal processing;simulation	Jun Hong;Xuedan Zhang;Jianshu Chen;Zhongya Wei;Jiannong Cao;Yong Ren	2007	2007 IEEE Intelligent Transportation Systems Conference	10.1109/ITSC.2007.4357698	control engineering;simulation;telecommunications;engineering	Robotics	-18.20713933852772	-29.068393232959192	81619
73fdce236a8e12fdb0f4c7b3f8b3e3a8bdc7135b	an approach to increase fuel economy with traffic signals	exhaust systems;road traffic;cost reduction;vehicle fuel economy traffic signal un social problem ecological problem economical driving problem fuel consumption greenhouse effect fuel efficient driving fuel cost reduction environmental pollution minimization exhaust gas minimization;air pollution control;fuel economy;urbanization economical speed traffic signals economical driving fuel economy urban traffic;vehicles fuels time measurement measurement units velocity measurement acceleration engines;road vehicles air pollution control cost reduction exhaust systems fuel economy road traffic;road vehicles	The UNs projected that half of the world's population would live in urban areas at the end of 2018. By 2050 it is predicted that 64.1% and 85.9% of the developing and developed world respectively will be urbanized. This incredibly rapid growth of megacities causes severe ecological, economical and social problems. The rapid growth of megacities and vehicles are causing a severe fuel consumption and the greenhouse effect in the intersection. In this paper we present an approach for more fuel-efficient driving with traffic signals to avoid unnecessary acceleration in the intersection. The proposed method is capable of informing economical speed of vehicle between intersections. It is an object of this paper to allow for economical driving by reducing the fuel cost, and minimize environmental pollution by minimizing the exhaust gas of vehicle.	device driver;real-time transcription;velocity (software development)	Myunghee Son;Sung-Kyong Un;Sung Hoon Baek	2013	2013 13th International Conference on ITS Telecommunications (ITST)	10.1109/ITST.2013.6685520	environmental engineering;engineering;automotive engineering;transport engineering;green vehicle	Robotics	-17.04258799817185	-28.346516943953766	81815
74a5abb62abbc8b7b76c128dfb98cf459f1335e0	an integrated framework to predict bus travel time and its variability using traffic flow data	dynamic change;travel time prediction;travel time;neural networks;temporal variability;data collection;traffic flow;artificial neural networks;bus transit;gps;traffic congestion;global positioning system;bus travel times;prediction accuracy;bus transit operations;mathematical prediction;prediction interval;australia;artificial neural network;traffic measurement	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;heart rate variability;primary source	Ehsan Mazloumi;Geoff Rose;Graham Currie;Majid Sarvi	2011	J. Intellig. Transport. Systems	10.1080/15472450.2011.570109	real-time computing;simulation;floating car data;global positioning system;computer science;engineering;machine learning;transport engineering;artificial neural network;statistics	Robotics	-16.63992752397917	-29.894804876398197	81960
d75deb13da392bd35234f40d4994c308c882aeaf	trajectory network assessment based on analysis of stay points cluster		The popularization of GPS has generated a massive amount of geographic data organized in trajectories. Trajectories are ordered sequences of geographic points that represent a path of any moving object, which provides information on the mobility behavior of this moving objects. To improve the understanding of trajectories, places of greater importance are referred to as stay points and indicate that a user has remained in this correspondent place for a significant time. In the literature, stay points are commonly represented through networks to facilitate trajectory mining. Nonetheless, to the best of our knowledge, there is a lack of studies addressing the quality of these networks. This article addresses this gap and presents a network construction analysis through stay points by using external validity criteria.		Diego Minatel;Alan Valejo;Alneu A. Lopes	2018	2018 7th Brazilian Conference on Intelligent Systems (BRACIS)	10.1109/BRACIS.2018.00103	data mining;cluster analysis;global positioning system;knowledge engineering;trajectory;computer science;external validity	Robotics	-18.802503900360893	-35.269273986377335	82407
7d9dfe25a5a37236238a61b1b54528c45fbe8920	radar: research of anomalous data through association rules	association rule		radar	Giulia Bruno;Paolo Garza;Elisa Quintarelli;Rosalba Rossato	2007			data mining;radar;association rule learning;computer science	DB	-11.834826256274038	-27.82230812750084	82479
ed05019e3997564dd5304deb1e719a45394d3c1e	a new efficient approach for mining uncertain frequent patterns using minimum data structure without false positives	existential probability;frequent pattern mining;data mining;correctness;uncertain pattern	The concept of uncertain pattern mining was recently proposed to fulfill the demand for processing databases with uncertain data, and various relevant methods have been devised. However, previous approaches have the following limitations. State-of-the-art methods based on tree structure can cause fatal problems in terms of runtime and memory usage according to the characteristics of uncertain databases and threshold settings because their own tree data structures can become excessively large and complicated in their mining processes. Various approximation approaches have been suggested in order to overcome such problems; however, they are methods that increase their own mining performance at the cost of accuracy of the mining results. In order to solve the problems, we propose an exact, efficient algorithm for mining uncertain frequent patterns based on novel data structures and mining techniques, which can also guarantee the correctness of the mining results without any false positives. The newly proposed list-based data structures and pruning techniques allow a complete set of uncertain frequent patterns to be mined more efficiently without pattern losses. We also demonstrate that the proposed algorithm outperforms pervious state-of-the art approaches in both theoretical and empirical aspects. Especially, we provide analytical results of performance evaluation for various types of datasets to show efficiency of runtime, memory usage, and scalability in our method.	algorithm;approximation;correctness (computer science);data mining;data structure;database;mined;performance evaluation;scalability;tree structure;uncertain data	Gangin Lee;Unil Yun	2017	Future Generation Comp. Syst.	10.1016/j.future.2016.09.007	correctness;computer science;machine learning;data mining;database;programming language	DB	-7.296593907023275	-36.12827974098896	82540
8438e0bf0cd6ec74b3fa27184df83666d3a471c1	mapping data sets to concepts using machine learning and a knowledge based approach		Machine learning techniques have a huge potential to take some tasks of humans, e.g. anomaly detection or predictive maintenance, and thus support operators of cyber physical systems (CPSs). One challenge is to communicate algorithms results to machines or humans, because they are on a sub-symbolical level and thus hard to interpret. To simplify the communication and thereby the usage of the results, they have to be transferred to a symbolic representation. Today, the transformation is typically static which does not satisfy the needs for fast changing CPSs and prohibit the usage of the full machine learning potential. This work introduces a knowledge based approach of an automatic mapping between the sub-symbolic results of algorithms and their symbolic representation. Clustering is used to detect groups of similar data points which are interpreted as concepts. The information of clusters are extracted and further classified with the help of an ontology which infers the current operational state. Data from wind turbines is used to evaluate the approach. The achieved results are promising, the system can identify its operational state without an explicit mapping.	algorithm;anomaly detection;artificial intelligence;cluster analysis;computer cluster;data point;data pre-processing;database normalization;knowledge-based systems;machine learning;map;mental representation;ontology (information science);operational definition;preprocessor;semantic reasoner;xeon phi	Andreas Bunte;Peng Li;Oliver Niggemann	2018		10.5220/0006590204300437	data mapping;artificial intelligence;computer science;machine learning;data mining	AI	-10.854919367559855	-32.586006647378575	82550
ee85a5118d694d987044e8a68402ace99936deb1	discovering triggering events from longitudinal data	atmospheric measurements;event detection data mining conferences time measurement manufacturing systems input variables frequency air pollution meteorology atmospheric measurements;repeated measures;original data mining task;evolving data methods and algorithms for mining complex data discovering events;event detection;data mining;discovering events;discrete states sequence discovering triggering events longitudinal data domain knowledge usage data mining approach original data mining task;domain knowledge;evolution biology;methods and algorithms for mining complex data;complex data;fuels;air pollution;domain knowledge usage;merging;evolving data;discovering triggering events;data mining approach;longitudinal data;discrete states sequence	Longitudinal data consist of the repeated measurements of some variables which describe the dynamics of a domain(process or phenomenon) over time. They can be analyzed in order to explain what event may cause the transition from a state into the next one during the evolution of the domain. Generally, approaches to this explanation problem rely on the exclusive usage of domain knowledge, while an analysis driven from only data is still lacking. In this paper we describe a data mining approach to discover events which may have triggered a transition during the evolution of the domain. The original data mining task is decomposed into two consecutive subtasks. First, the sequence of discrete states which represents the dynamics of the domain is determined. Second, the triggering events for two successive states are found out. Computational solutions to both problems are presented. Their application to two real scenarios is presented and results are discussed.	computation;data (computing);data mining;data point	Corrado Loglisci;Donato Malerba	2008	2008 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2008.136	repeated measures design;computer science;bioinformatics;artificial intelligence;data science;data mining;domain knowledge;air pollution;complex data type	DB	-6.413912134535682	-34.1838515642514	82570
157bc0473d3fd333f59d2b1dc7891dd665ed853d	finding skyline paths in road networks	location based services;location based service;travel time;query processing;road network;search algorithm;skyline query;path search	This paper presents a research study on skyline path queries. Given a source s and a destination d on a road network and multiple path search criteria (e.g., short distance and short travel time), a skyline query returns a set of non-dominated paths from s to d. These non-dominated paths are called skyline paths. Efficient computation of skyline path queries is very challenging due to expensive network traversals and extensive path comparisons in dominance tests. In this paper, we explore the characteristics of skyline paths, based on which a novel skyline path search algorithm called SkyPath is proposed. To narrow down the search scope for result skyline paths, partial dominance test and full path dominance test are devised as two components of SkyPath. Evaluation results show the superiority of the SkyPath algorithm over the state-of-the-art approaches.	computation;pareto efficiency;search algorithm;web search engine	Yuan Tian;Ken C. K. Lee;Wang-Chien Lee	2009		10.1145/1653771.1653840	any-angle path planning;geography;computer science;location-based service;data mining;database;world wide web;remote sensing	DB	-14.451080866856179	-36.911978476696554	82688
5a9e84b5b7c32f9273f646ab9ca02020576b6802	raq–a random forest approach for predicting air quality in urban sensing systems	random forest;traffic;air quality prediction;point of interest	Air quality information such as the concentration of PM2.5 is of great significance for human health and city management. It affects the way of traveling, urban planning, government policies and so on. However, in major cities there is typically only a limited number of air quality monitoring stations. In the meantime, air quality varies in the urban areas and there can be large differences, even between closely neighboring regions. In this paper, a random forest approach for predicting air quality (RAQ) is proposed for urban sensing systems. The data generated by urban sensing includes meteorology data, road information, real-time traffic status and point of interest (POI) distribution. The random forest algorithm is exploited for data training and prediction. The performance of RAQ is evaluated with real city data. Compared with three other algorithms, this approach achieves better prediction precision. Exciting results are observed from the experiments that the air quality can be inferred with amazingly high accuracy from the data which are obtained from urban sensing.	algorithm;decision trees;decision tree;experiment;inference;information privacy;internet;logistic regression;meteorology;naive bayes classifier;online machine learning;point of interest;random forest;real-time clock;real-time computing;real-time data;real-time locating system;scientific publication;travel	Ruiyun Yu;Yu Kyung Yang;Leyou Yang;Guangjie Han;Oguti Ann Move	2016		10.3390/s16010086	random forest;point of interest;simulation;environmental engineering;computer science;remote sensing	HCI	-16.352300712162634	-32.10184626307653	82962
3c525e5b93d6e870e8547d3c4d10ceb754c25e4a	random forest based bus operation states classification using vehicle sensor data		In bus companies, it is important for an operation manager to grasp operation states of vehicles from a viewpoint of safety management and improving an operation efficiency. Currently, for allowing operation managers to grasp operation states of vehicles, drivers should record operation states by man- ually operating a recorder called ”Digital-tachograph.” However, operating the digital tachograph is a heavy burden to the driver. In addition, the records may have driver’s human error. In order to solve these problems and to realize efficient operation, we propose a method for automatic classification of operation states using sensor data obtained from buses. We implemented a classifier using Random Forest with the sensor data. As a results of experiments, the correct answer rate was 0.92 or more in each condition unless it was irregular operation.	digital camera;experiment;human error;operation payback;random forest;sensor	Takuya Yonezawa;Ismail Arai;Toyokazu Akiyama;Kazutoshi Fujikawa	2018	2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)	10.1109/PERCOMW.2018.8480291	real-time computing;distributed computing;human error;computer science;data modeling;hidden markov model;random forest;tachograph;grasp	Robotics	-17.63884640362176	-29.932353080462278	83072
fcd6c7572661b60904d11e5ae8554a1620165e32	preprocessing: a prerequisite for discovering patterns in web usage mining process	log files;web accessibility;data format;pattern discovery;data mining application;web usage mining;data cleaning;quality of data;data preprocessing	Web log data is usually diverse and voluminous. This data must be assembled into a consistent, integrated and comprehensive view, in order to be used for pattern discovery. Without properly cleaning, transforming and structuring the data prior to the analysis, one cannot expect to find meaningful patterns. As in most data mining applications, data preprocessing involves removing and filtering redundant and irrelevant data, removing noise, transforming and resolving any inconsistencies. In this paper, a complete preprocessing methodology having merging, data cleaning, user/session identification and data formatting and summarization activities to improve the quality of data by reducing the quantity of data has been proposed. To validate the efficiency of the proposed preprocessing methodology, several experiments are conducted and the results show that the proposed methodology reduces the size of Web access log files down to 73-82% of the initial size and offers richer logs that are structured for further stages of Web Usage Mining (WUM). So preprocessing of raw data in this WUM process is the central theme of this paper.		C. Ramya;G. Kavitha;K. S. Shreedhara	2013	CoRR	10.7763/IJIEE.2013.V3.297	web mining;computer science;web accessibility;data mining;database;data pre-processing;data stream mining;world wide web	ML	-6.18217088878556	-33.503044222487674	83133
420e64dfc1931da33e379381f10158219199be94	an arc orienteering algorithm to find the most scenic path on a large-scale road network	arc orienteering problem;scenic path;trip routing;geo tagging	Traditional route planning problems mainly focus on finding the shortest path considering the travel distance or time. In this paper, we aim to find the most scenic path that offers the most beautiful sceneries on the arcs of a path while the total travel cost (distance or time) is within a user-specified budget. This is a challenging problem as the optimization objective is to maximize the value of the path (i.e., its scenic value) instead of minimizing its cost (distance or time). The problem can be formulated as a variant of the Arc Orienteering Problem (AOP), which is a well-known NP-hard combinatorial optimization problem. Due to the fast response-time requirements of interactive mobile and online applications (e.g., within 300 milliseconds) and the large scale of real-world road networks, existing heuristic algorithms for AOP fail to solve the most scenic road problem. Therefore, unlike the existing approaches for AOP where they treat the road network as a traditional graph in which all-pair distances are pre-computed a priori, in this work, we treat the road network as a spatial network, utilizing the techniques from the field of spatial database: ellipse pruning and spatial indexing. Experiments on two real-world datasets demonstrate the efficiency and accuracy of our proposed algorithms, which can achieve over 95% accuracy within 300 milliseconds on large-scale datasets (over 100K network nodes).	algorithm;combinatorial optimization;experiment;heuristic;mathematical optimization;np-hardness;optimization problem;precomputation;requirement;shortest path problem;spatial database;spatial network	Ying Lu;Cyrus Shahabi	2015		10.1145/2820783.2820835	simulation;geography;computer science;operating system;machine learning;geotagging	DB	-14.218772427388332	-37.072578265470966	83651
e8c4a1ca313ad386f2916d0bf9f4a8467a881643	the effect of pokémon go on the pulse of the city: a natural experiment	pokémon;mobile phone data;call detail records;floating population;urban informatics	Pokémon Go, a location-based game that uses augmented reality techniques, received unprecedented media coverage due to claims that it allowed for greater access to public spaces, increasing the number of people out on the streets, and generally improving health, social, and security indices. However, the true impact of Pokémon Go on people’s mobility patterns in a city is still largely unknown. In this paper, we perform a natural experiment using data from mobile phone networks to evaluate the effect of Pokémon Go on the pulse of a big city: Santiago, capital of Chile. We found significant effects of the game on the floating population of Santiago compared to movement prior to the game’s release in August 2016: in the following week, up to 13.8% more people spent time outside at certain times of the day, even if they do not seem to go out of their usual way. These effects were found by performing regressions using count models over the states of the cellphone network during each day under study. The models used controlled for land use, daily patterns, and points of interest in the city. Our results indicate that, on business days, there are more people on the street at commuting times, meaning that people did not change their daily routines but slightly adapted them to play the game. Conversely, on Saturday and Sunday night, people indeed went out to play, but favored places close to where they live. Even if the statistical effects of the game do not reflect the massive change in mobility behavior portrayed by the media, at least in terms of expanse, they do show how ‘the street’ may become a new place of leisure. This change should have an impact on long-term infrastructure investment by city officials, and on the drafting of public policies aimed at stimulating pedestrian traffic.	augmented reality;location-based game;mobile phone;point of interest;software regression	Eduardo Graells-Garrido;Leo Ferres;Diego Caro;Loreto Bravo	2017	EPJ Data Science	10.1140/epjds/s13688-017-0119-3	land use;simulation;point of interest;mobile phone;natural experiment;computer science;floating population;augmented reality;urban informatics	HCI	-18.970367180189594	-33.89056714838491	83791
f2a6aeda9a4299ac0c5942f58d987895fa5c0838	doppler analysis based fall detection using array antenna	array antenna;doppler analysis;fall detection	The number of elderly people who live alone is increasing in many countries. Furthermore, many of their accidents occur at home. Hence, it is an urgent demand for a system monitoring their activities to detect accidents indoor such as falling. In conventional systems of fall detection using array antennas, falling after standing still can be detected with high accuracy by leveraging the features indicating the change of radio wave propagation. However, it is difficult to detect falling after walking correctly. In this paper, to improve fall detection accuracy including falling after walking, we propose an accurate fall detection system by leveraging the features indicating the change of Doppler signals during human activities in detail. Analyzing Doppler signals is useful to detect falling since they are observed when a radio wave reflects by moving objects. We conducted experiments in actual rooms to demonstrate that the proposed method can detect falling after both standing and walking with high accuracy.	doppler effect;experiment;fast fourier transform;loss function;radio wave;software propagation;system monitoring	Yugo Agata;Tomoaki Ohtsuki;Kentaroh Toyoda	2018	2018 IEEE International Conference on Communications (ICC)	10.1109/ICC.2018.8422793	real-time computing;radio wave;doppler effect;computer science;feature extraction;system monitoring;radio propagation	Robotics	-18.973877912114634	-30.209750117369044	83948
36635d286069217fbd13177eab003d55e5ba42ae	implementation of web-based fault diagnosis using improved fuzzy petri nets	concurrent reasoning algorithm;web based fault diagnosis;computer program;expert systems;maintenance situation;computer programming web based fault diagnosis fuzzy petri nets maintenance situation numerical control equipment online real time monitoring fuzzy expert system concurrent reasoning algorithm decision making;real time monitoring;inference mechanisms;maintenance engineering;fault diagnosis petri nets computer numerical control diagnostic expert systems real time systems remote monitoring hybrid intelligent systems fuzzy reasoning concurrent computing decision making;data mining;fuzzy set theory;computer programming;fuzzy petri nets numerical control equipment remote fault diagnosis expert system;numerical control equipment;internet;fuzzy expert system;online real time monitoring;decision making process;cognition;fault diagnosis system;programming computerised monitoring decision making expert systems fault diagnosis fuzzy set theory inference mechanisms internet numerical control petri nets;fuzzy petri nets;remote fault diagnosis;numerical control;petri nets;computerised monitoring;petri net;programming;fault diagnosis;expert system;automation	According to the current application and maintenance situation of numerical control equipment (NCE), a novel remote fault diagnosis expert system is designed to prevent fault occurrence and quicken the recovering process by online real-time monitoring the working state of NCEs. The article addresses the overall framework and relevant application technology of fault diagnosis system (FDS) and emphasizes on the establishment of Fuzzy Expert System (FES). Improved Fuzzy Petri Nets (FPNs) model and concurrent reasoning algorithm are applied to handle the fuzziness and concurrency of fault and inadequate and uncertain information. Utilization of simple matrix operation to realize complicated reasoning process that simplifies the diagnostic reasoning decision-making process. Meanwhile, it can be realized easily by computer programming. Finally, a practical fault instance is presented to demonstrate the feasibility and validity of this method.	algorithm;computer programming;concurrency (computer science);expert system;family computer disk system;numerical analysis;petri net;real-time transcription;shin megami tensei: persona 3	Li Chen;Hongyu Tan;Shujiang Li	2009	2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2009.565	real-time computing;computer science;artificial intelligence;petri net;expert system	Robotics	-7.612339621313801	-24.53635561119473	83981
bfda23bcc2baf3082e9b9979b19f808755294cff	accident reproduction system for the identification of human factors involved on traffic accidents	professional drivers accident reproduction system identification human factors traffic accidents wireless in vehicle electronic data recorder traffic safety road truck simulator;wireless communication;human factors;monitoring;accidents;roads;road safety accidents driver information systems human factors;safety;vehicles accidents roads wireless communication safety data acquisition monitoring;vehicles;road safety;data acquisition;driver information systems	In this paper, a novel accident reproduction system for the identification of the main human factors involved on traffic accidents is presented. The system is based on a wireless in-vehicle Electronic Data Recorder that could be easily installed in any vehicle's cabin for the monitoring of the three basic elements of traffic safety: driver, road and vehicle. The system has been tested in a highly realistic truck simulator with a group of professional drivers. The data, collected with the system at the moments before traffic accidents, were used to generate a novel database that was carefully analyzed by a group of traffic safety experts. The validation process shows the reliability of the developed system as a tool for the identification of the main causes of the monitored traffic accidents.	accident analysis;cognition;computer data storage;data logger;device driver;human factors and ergonomics;simulation;traffic analysis	Oscar Sánchez Siordia;Isaac Martín de Diego;Cristina Conde;Enrique Cabello	2012	2012 IEEE Intelligent Vehicles Symposium	10.1109/IVS.2012.6232126	vehicle information and communication system;engineering;automotive engineering;transport engineering;forensic engineering	Embedded	-18.66247072684422	-28.321219942857482	84070
7659830298e41a8796a6f76ab5d283ba9f75772f	minimal infrequent pattern based approach for mining outliers in data streams	minimal infrequent pattern;data mining;data streams;outlier detection	Minimal Infrequent Pattern based Outlier Detection.An algorithm for mining minimal infrequent patterns in data streams.Three simple factors deciding outliers.An algorithm for detecting outliers based on mined minimal infrequent patterns.Experimental results with real time sensor data and publically available UCI data set. Outlier detection is an important task in data mining which aims at detecting patterns that are unusual in a dataset. Though several techniques are proved to be useful in solving some outlier detection problems, there are certain issues yet to be resolved. Most of the existing methods compute distance of points in full dimensional space to detect outliers. But in high dimensional space, the concept of proximity may not be qualitatively meaningful due to the curse of dimensionality and incurs high computational cost. Moreover, the existing methods focus on discovering outliers but do not provide the interpretability of different subspaces that cause the abnormality. Frequent pattern mining based approaches resolve the aforementioned issues. Recently, infrequent pattern mining has attracted the attention of data mining research community which aims at discovering rare associations and researches in this area motivated to propose a new method to detect outliers in data streams. Infrequent patterns are more interesting than frequent patterns in some domains such as fraudulent credit transactions, anomaly detection, etc. In such applications, mining infrequent patterns facilitates detecting outliers. Minimal infrequent patterns are generators of family of infrequent patterns. In this paper, a novel method is presented to detect outliers by mining minimal infrequent patterns from data streams. Three measures namely Transaction Weighting Factor (TWF), Minimal Infrequent Deviation Factor (MIPDF) and Minimal Infrequent Pattern based Outlier Factor (MIFPOF) are defined. An algorithm called Minimal Infrequent Pattern based Outlier Detection (MIFPOD) method is proposed for detecting outliers in data streams based on mined minimal infrequent patterns. The effectiveness of the proposed method is demonstrated on synthetic dataset obtained from vital dataset collected from body sensors and a publicly available real dataset. The experimental results have shown that the proposed method outperforms the existing methods in detecting outliers.		C. Sweetlin Hemalatha;Vijay Vaidehi;R. Lakshmi	2015	Expert Syst. Appl.	10.1016/j.eswa.2014.09.053	anomaly detection;computer science;data science;machine learning;pattern recognition;data mining;data stream mining	ML	-10.709054175431833	-35.21490579655023	84539
0223e757de4a348e6b1335cc667aa8c2908ebc2b	service and management oriented traffic information grid	optimum dynamic path;traffic information service;application grid;route status forecasting;data integration	Traffic information service plays an important role in one's daily life. However, traffic information processing is very complicated because of its dynamic, cooperative and distributed features. This paper presents the Service and Monitoring Oriented Traffic Information Grid. In this system, it is a remarkable characteristic to provide real-time, dynamic information services for travelers and traffic managers by grid technology. The system provides travelers with services of optimized route scheme, bus arrival prediction based on real-time route status, and route status forecast. For traffic managers, the system can provide vehicle tracing, traffic monitoring, history data analysis, and decision making on traffic control strategy. In this regard, key research includes large multi-source traffic data integration, route status forecast, and optimum dynamic travel scheme implementation based on massive GPS data.		Yu Fang;Dongliang Zhang;ChunGang Yan;Hongzhong Chen;Changjun Jiang	2010	IJDST	10.4018/jdst.2010100102	simulation;floating car data;vehicle information and communication system;computer science;data integration;database;traffic shaping;computer security;computer network	HPC	-15.821618150408511	-26.093984265919175	84720
b0641a11f2c16c6f9629eb79a629be58784c844c	the meta-geography of the open society: an auto-cm ann approach		Abstract This paper presents an innovative operationalization of world-system analysis through attributional data, and makes use of an innovative Artificial Neural Network computational tool, the Auto-Contractive Map (AutoCM), to analyze the core-periphery structure of a database including five well-known, publicly available indicators that can jointly be considered an empirical proxy of an open society formulation of Western governmentality: World Competitiveness Index; Freedom of Press Index; Economic Freedom Index; Corruption Perception Index; and UNDP Human Development Index. We find clear evidence of a core-periphery structure in the data, which is largely coherent with a benchmark version obtained through an alternative computational method, the Self-Organizing Map (SOM). Moreover, we find that the resulting meta-geography of the world-system is still shaped by the colonialist geopolitics of the British Commonwealth as the key organizational backbone.		Paolo Massimo Buscema;Guido Ferilli;Pier Luigi Sacco	2018	Expert Syst. Appl.	10.1016/j.eswa.2018.01.017	open society;data mining;artificial neural network;human development index;corruption;freedom of the press;operationalization;index of economic freedom;computer science	DB	-13.02180078872831	-24.654395150244106	84870
16b375c42650e8f43511ebbadf6f319b50c098e2	mining closed high utility itemsets in uncertain databases	uncertain database;data mining;high utility itemset;closed high utility item set	In order to reduce the number of high-utility itemsets (HUIs), closed high-utility itemsets (CHUIs) have been proposed. However, most techniques for mining CHUIs require certain databases; i.e., there are no probabilities. However, in many real-world applications, an item or itemset may have a probability. Actual data can be affected by the use of noisy sensors. Many algorithms have been proposed to effectively mine frequent itemsets from uncertain databases; however, there are no algorithms for mining CHUIs from uncertain databases. This paper proposes an algorithm called CPHUI-List (closed potential high-utility itemset PEU-List-based mining algorithm) for mining closed potential high-utility itemsets (CPHUIs) from uncertain databases without generating candidates. CPHUI-List performs a depth-first search of the search space, and uses the downward closure property of high transaction-weighed probabilistic and utilization itemsets to prune non-closed potential high-utility itemsets. Experiments show that the runtime and memory consumption of CPHUI-List are lower than those of CHUI-Miner.	algorithm;database;depth-first search;sensor	Nguyen Bui;Bay Vo;Van-Nam Huynh;Chun-Wei Lin;Loan T. T. Nguyen	2016		10.1145/3011077.3011124	computer science;data science;data mining;database	DB	-6.754965635490304	-36.44061055717271	84957
183ad1c312e734c05d44fbff371c98ed65f3fe29	safety evaluation of long-range monitoring of bridge health based on internal force envelope theory	equivalent node load;structure resistance;safety evaluation;internal force envelope	The safety evaluation model, the resistant internal force diagram and realtime internal force diagram based on the real-time monitoring of a bridge as well as the application are expounded. The internal force envelope method in bridge design is app lied to the remote monitoring of bridge health, and a kind of safety evaluation method based on internal force envelope theory is proposed. Comparing with the current method, this method solves the problems that the measuring points are limited and can’t reflect the state of unmeasured location and the overall bridge. Therefore, this method is advantageous to be more intuitive and more objective, at the same time, it does better in overcoming environmental and operational conditions and has a promising application potential.	diagram;envelope theorem;real-time clock	Jianxi Yang;Shaolin Fang;Juan Yang;Bing Jun Luo	2012	Intelligent Automation & Soft Computing	10.1080/10798587.2012.10643278	structural engineering;control engineering;engineering;forensic engineering	Robotics	-18.775129215551754	-26.31500776497246	85065
d0ce0ec854ef097cc79adea351b9c1c9d4b675a1	mixed spatial-temporal characteristics based crime hot spots prediction	security predictive models input variables space heating law enforcement economics;input variables;public security prevention mixed spatial temporal characteristics crime hot spots prediction crime rates knn dimensionality reduction linear discriminant analysis lda histogram based statistical methods rotational invariance neighborhood features holidays temporal distance time sequence multiclass classification problem heat levels area specific crime incidents public security control;spatial temporal analysis hot spots public security linear discriminant analysis;law enforcement;space heating;predictive models;statistical analysis classification criminal law national security public administration;economics;security	Crime Hot Spots refer to the areas in which the crime rates are above the average level, therefore the Hot Spots Prediction is the primary mission of the Public Security Prevention and Control. By encoding the area-specific crime incidents, the crime hot spots has been classified them into different heat levels, rendering the conversion of Hot Spots prediction into a multi-class classification problem. The new prediction model uses time sequence of area-specific heat levels, temporal distance of important holidays, and neighborhood features to establish the crude mixed spatial-temporal characteristics. As with rotational invariance, we use histogram-based statistical methods to design neighborhood features of heat levels. Finally LDA (Linear Discriminant Analysis) is adopted for dimensionality reduction of mixed spatial-temporal characteristics, and KNN is adopted for prediction. Experimental results show that when crime statistics are conducted on a “Weekly” basis, the new prediction model can achieve optimal performance.	curse of dimensionality;data mining;dimensionality reduction;image processing;k-nearest neighbors algorithm;linear discriminant analysis;multiclass classification;scalability;time series	Qiang Zhang;Pingmei Yuan;Qiyun Zhou;Zhiming Yang	2016	2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2016.7565970	computer science;information security;data mining;predictive modelling;computer security	Visualization	-13.649143479415331	-29.86886260685078	85293
1d58943c4195f9353b5783ec73ae95a2eaee145f	intertrasm - a depth first search algorithm for mining intertransaction association rules	association rule;depth first search	In this paper we propose an efficient method for mining frequent intertransaction itemsets. Our approach consists in mining maximal frequent itemsets (MFI) by extending the SmartMiner algorithm for the intertransaction case. We have called the new algorithm InterTraSM (Inter Transaction Smart Miner). Because it uses depth first search the memory needed by the algorithm is reduced; a strategy for passing tail information for a node combined with a dynamic reordering heuristic lead to improved speed. Experiments comparing InterTraSM to other existing algorithms for mining frequent intertransaction itemsets have revealed a significant gain in performance. Further development ideas are also discussed.	association rule learning;database;depth-first search;heuristic;maximal set;mined;search algorithm	Dan Ungureanu;Alexandru Boicea	2008			association rule learning;breadth-first search;computer science;data mining	ML	-5.440622110279519	-37.32203851859135	85756
ffa4dab8055adc9ef27a5442c1f5531ae37c6c0e	application of kohonen self-organizing map for urban structure analysis	kohonen self organizing map;topology;cities and towns environmental economics satellites remote sensing principal component analysis linear discriminant analysis topology geography pattern analysis hurricanes;urban structure;linear discriminate analysis;enhanced thematic mapper;real world application;normalized difference vegetation index;principal component analysis;remote sensing;satellites;environmental economics;hurricanes;cities and towns;new orleans;satellite imagery;pattern analysis;linear discriminant analysis;environmental quality;geography	Kohonen Self-organizing Map (SOM) has been widely used to discover clusters in datasets of various real world applications. Urban structure, as characterized by various social, economic, and environmental features, can be explored with SOM. In this paper, we present a case study of applying SOM for urban structure analysis to the city of New Orleans. One novel aspect of this work is the inclusion of environmental data from satellite imagery for clustering. Ten social-economic variables from Census 2000 data and Normalized Difference Vegetation Index (NDVI) from Landsat 7 Enhanced Thematic Mapper Plus (ETM+) imagery were used as inputs to SOM to group 482 census block groups of New Orleans into 9 clusters. The clustering results show that block groups with high economic status and environmental quality tended to cluster at 3 major outer locations, while block groups with low economic status and environmental quality were concentrated in the mid-city area, which is a well known pattern due to the suburbanization process. Three major components were extracted by a principal component analysis, and they were compared with the clustering results from SOM. Fisher’s linear discriminant analysis shows a good separability result among 9 clusters discovered by the SOM.	cluster analysis;linear discriminant analysis;linear separability;organizing (structure);principal component analysis;self-organization;self-organizing map	Wenxue Ju;Nina Siu-Ngan Lam;Jianhua Chen	2006	2006 IEEE International Conference on Granular Computing	10.1109/GRC.2006.1635769	environmental quality;normalized difference vegetation index;tropical cyclone;computer science;machine learning;linear discriminant analysis;satellite;principal component analysis	Robotics	-12.355744978369737	-24.713401010579673	85935
84b74980111e961f1da65d75725bd0e518875903	a design of in-car multi-layer communication network with bluetooth and can bus	computers;communication networks;bluetooth logic gates communication networks electric vehicles computers wheels;logic gates;electric vehicles;bluetooth;wheels;can bus electric vehicles independent drive and independent steering tablet pc bluetooth	This paper presents a novel design for tablet controlled 4-Wheel Independent Drive and Independent Steering (4-WIDIS) Electric Vehicle (EV) with multilayer communication network. The tablet acts as a human machine interface (HMI) and the host computer of the EV operation control computation for individual wheel-units via Bluetooth, CAN bus, and a gateway that connects the two interfaces. An experimental prototype demonstrates that Bluetooth 4.0 communication rate is insufficient to maintain absolute control required of an EV travelling at high speed. Therefore, it is recommended to designate the tablet as an auxiliary HMI, and upgrade the gateway to a powerful central controller. Such a system structure requires further examination.	bluetooth;can bus;chimeric antigen receptor;computation;electroconvulsive therapy;extended validation certificate;host (network);human–computer interaction;incontinentia pigmenti achromians;interface device component;layer (electronics);numerous;prototype;tablet dosage form;tablet computer;telecommunications network;user interface	Ziming Qi;Ping Dong;Kuang Ma;Nicholas Sargeant	2016	2016 IEEE 14th International Workshop on Advanced Motion Control (AMC)	10.1109/AMC.2016.7496370	embedded system;electronic engineering;real-time computing;engineering	Robotics	-10.798273247789579	-29.817916533340846	86371
e8e5b4bbd2e4326a03b469aca68ee500450a8532	good practice in bayesian network modelling	bayesian networks bns;environmental systems;data and information;conditional probabilities;conceptual model;evaluation results;integration;journal article;model evaluation;ecological models;keywords bayes networks;good modelling practice;bayesian belief network;bayesian network models;bayes network;good practices;decision supports	Bayesian networks (BNs) are increasingly being used to model environmental systems, in order to: integrate multiple issues and system components; utilise information from different sources; and handle missing data and uncertainty. BNs also have a modular architecture that facilitates iterative model development. For a model to be of value in generating and sharing knowledge or providing decision support, it must be built using good modelling practice. This paper provides guidelines to developing and evaluating Bayesian network models of environmental systems, and presents a case study habitat suitability model for juvenile Astacopsis gouldi, the giant freshwater crayfish of Tasmania. The guidelines entail clearly defining the model objectives and scope, and using a conceptual model of the system to form the structure of the BN, which should be parsimonious yet capture all key components and processes. After the states and conditional probabilities of all variables are defined, the BN should be assessed by a suite of quantitative and qualitative forms of model evaluation. All the assumptions, uncertainties, descriptions and reasoning for each node and linkage, data and information sources, and evaluation results must be clearly documented. Following these standards will enable the modelling process and the model itself to be transparent, credible and robust, within its given limitations.		Serena H. Chen;Carmel A. Pollino	2010	Environmental Modelling and Software	10.1016/j.envsoft.2012.03.012	econometrics;computer science;machine learning;bayesian network;data mining;mathematics;statistics	AI	-6.95172229521791	-25.553263367740588	86670
214505914d86cc1f7c4fa208941dacaf3442461c	leveraging attention focus for effective reinforcement learning in complex domains	reinforcement learning;learning from demonstration;dimensionality reduction;dissertation	IONS FOR REINFORCEMENT LEARNING Abstraction is one of the most common ways of scaling up reinforcement learning, along with function approximation and often overlapping with it. There is a rich and varied literature on the topic, going from state-space abstractions that clump similar states together to hierarchical approaches that define either temporally-extended actions or task subdivisions. This chapter reviews previous RL abstraction approaches so we can later position our attention focus algorithms with respect to the existing literature.ion is one of the most common ways of scaling up reinforcement learning, along with function approximation and often overlapping with it. There is a rich and varied literature on the topic, going from state-space abstractions that clump similar states together to hierarchical approaches that define either temporally-extended actions or task subdivisions. This chapter reviews previous RL abstraction approaches so we can later position our attention focus algorithms with respect to the existing literature. 4.1 Hierarchical Abstractions Hierarchical RL attacks a learning problem by dividing it into different levels of complexity. To this end, the MDP is partially or completely divided into different subtasks that are easier to solve, and a higher-level process controls which subtask should be carried out at each moment. For example, an autonomous indoor vacuum cleaner could define subtasks such as go to next room and clean current room, and each subtask would be defined in terms of primitive actions: move forward, turn, suck dirt, etc. MAXQ [17] is one of the best known hierarchical RL algorithms. In MAXQ, a system designer engineers a task hierarchy, and decomposes the reward to indicate which levels of the hierarchy are potentially responsible for the reward. MAXQ cannot find globally optimal policies, but hierarchically optimal ones, this is, the best policies that are consistent with the imposed hierarchy. However, it can speed up learning significantly by dramatically reducing the complexity of the policy that must be learned at each level of the hierarchy. HEXQ [31] extends MAXQ by using a heuristic,	algorithm;approximation;autonomous robot;goto;hexq;heuristic;image scaling;maxima and minima;rl (complexity);reinforcement learning;state space;systems design;vacuum cleaner	Luis Carlos Cobo Rus	2013			psychology;cognitive psychology;error-driven learning;artificial intelligence;machine learning	ML	-9.68410781777101	-28.43859609250835	86676
595d50745c57f0d3e66aedd7bf3e4a9aa3f84e46	development of a health geomatics analysis framework to evaluate cardiac arrests in lombardy: new information for decision-making		Cardiac arrest (CA) is an unpredictable event whose deleterious consequences can be minimized only by an immediate medical intervention in the first six minutes from the event, including cardiac defibrillation with automated external defibrillator (AED). Knowledge of AED distribution on a specific territory is functional to potentially provide immediate assistance while waiting for ambulance arrival. Our aim was to apply a health geomatic framework to map CAs occurred in Lombardy region in Italy along the year 2015, and known AED locations to retrospectively obtain new information that could be used to optimize AED placement over the considered territory. Results showed 10686 CAs and 6212 AED in all Lombardy region, with CA incidence in the range 0.7–1.27% and AED availability in the range 0.4–1.24% of inhabitants in the 15 healthcare districts in which Lombardy was divided. For the city of Milan, connected points reached within the same time (i.e., isochrones) were created starting from the position of each known AED and considering the distance traveled in a 6 min roundtrip at different walk speeds, showing 14% of potential territory coverage. A retrospective analysis of the 4005 CAs occurred in 2015 in the city of Milan showed that, despite an AED was within a 3-min range of a CA in 55% of the cases, only in less than 2% an AED was utilized. Health geomatics approaches provide new ways to look at existing information that could be used in decision-making processes to guide resources distribution on the Lombardy territory, while improving CA emergency care.	geomatics;incidence matrix;maxima and minima	Enrico G. Caiani;Giulia Marelli;Maria A. Brovelli;Carolina Arias Muñoz;Pietro M. Brambilla;Andrea Pagliosa;Giovanni Cesana	2017	2017 IEEE 3rd International Forum on Research and Technologies for Society and Industry (RTSI)	10.1109/RTSI.2017.8065921	medical emergency;geomatics;health care;automated external defibrillator;operations research;geography;defibrillation	Robotics	-14.80691867302164	-29.052495890448252	86952
96748dbf11a4768661c17c92cb7d6ef156e4acc1	influence of the urban morphology on the urban heat island intensity: an approach based on the local climate zone classification			galaxy morphological classification;urban computing	Nathalie Long;Thomas Gardes;Julia Hidalgo;Valéry Masson;Robert Schoetter	2018	PeerJ PrePrints	10.7287/peerj.preprints.27208v1		Vision	-12.77019942245696	-24.6896160960744	87469
bd68a38678140ff8f544d026786422ea616366b5	knowledge representation in learning classifier systems: a review		Knowledge representation is a key component to the success of all rule based systems including learning classifier systems (LCSs). This component brings insight into how to partition the problem space what in turn seeks prominent role in generalization capacity of the system as a whole. Recently, knowledge representation component has received great deal of attention within data mining communities due to its impacts on rule based systems in terms of efficiency and efficacy. The current work is an attempt to find a comprehensive and yet elaborate view into the existing knowledge representation techniques in LCS domain in general and XCS in specific. To achieve the objectives, knowledge representation techniques are grouped into different categories based on the classification approach in which they are incorporated. In each category, the underlying rule representation schema and the format of classifier condition to support the corresponding representation are presented. Furthermore, a precise explanation on the way that each technique partitions the problem space along with the extensive experimental results is provided. To have an elaborated view on the functionality of each technique, a comparative analysis of existing techniques on some conventional problems is provided. We expect F. Shoeleh Computer Science and Engineering Dept. Shiraz University, Shiraz, Iran. E-mail: shoeleh@cse.shirazu.ac.ir M. Majd E-mail: majd@cse.shirazu.ac.ir A. Hamzeh E-mail: ali@cse.shirazu.ac.ir S. Hashemi E-mail: s hashemi@shirazu.ac.ir this survey to be of interest to the LCS researchers and practitioners since it provides a guideline for choosing a proper knowledge representation technique for a given problem and also opens up new streams of research on this topic.	computer engineering;data mining;knowledge representation and reasoning;learning classifier system;mail (macos);problem domain;qualitative comparative analysis;rule-based system	Farzaneh Shoeleh;Mahshid Majd;Ali Hamzeh;Sattar Hashemi	2015	CoRR		computer science;artificial intelligence;body of knowledge;machine learning;data mining	ML	-5.505054796379902	-28.757525480511678	87857
173dd6686b028a2118a1d830f78af8af6acf4674	a spatiotemporal data model for river basin-scale hydrologic systems	spatiotemporal data model;river basin-scale hydrologic system;flux coupler;fluid flow;data model;overall system;control volume;hydrologic system;gis data model;large-scale river basin system;hydrologic simulation model;geographic information system;geographic information science;simulation;simulation models;data integration;space time;river basin;hydrology;simulation model;data integrity	Despite a long history of synergy, current techniques for integrating Geographic Information System (GIS) software with hydrologic simulation models do not fully utilize the potential of GIS for modeling hydrologic systems. Part of the reason for this is a lack of GIS data models appropriate for representing fluid flow in space and time. Here we address this challenge by proposing a spatiotemporal data model designed specifically for large-scale river basin systems. The data model builds from core concepts in geographic information science and extends these concepts to accommodate mathematical representations of fluid flow at a regional scale. Space–time is abstracted into three basic objects relevant to hydrologic systems: a control volume, a flux and a flux coupler. A control volume is capable of storing mass, energy or momentum through time, a flux represents the movement of these quantities within space– time and a flux coupler insures conservation of the quantities within an overall system. To demonstrate the data model, a simple case study is presented to show how the data model could be applied to digitally represent a river basin system.	acoustic coupler;aggregate data;data model;geographic information science;geographic information system;simulation;software system;spatial analysis;spatiotemporal database;synergy	Jonathan L. Goodall;David R. Maidment	2009	International Journal of Geographical Information Science		geography;computer science;simulation modeling;data mining;database;geographic information system;ecology	DB	-13.236291244415964	-26.45150816116643	88030
bf1e94ba685418c30683996fa166137b402a68bd	a compressive sensing approach to urban traffic estimation with probe vehicles	estimation theory;compressed sensing;spatiotemporal phenomena compressed sensing data analysis estimation theory principal component analysis road traffic road vehicles;road traffic;error estimation compressive sensing approach urban road traffic estimation probe vehicle metropolitan scale traffic estimation traffic monitoring center road link road segment time slot spatiotemporal vacancy missing data problem data set principal component analysis pca road network hidden structure traffic model knn mssa;traffic estimation;probes;data analysis;estimation;monitoring;roads;compressive sensing;principal component analysis;probes roads vehicles estimation monitoring compressed sensing principal component analysis;spatiotemporal phenomena;probe vehicles;vehicles;traffic condition matrix;compressive sensing probe vehicles traffic estimation traffic condition matrix;road vehicles	Traffic estimation is crucial to a number of tasks such as traffic management and road engineering. We propose an approach for metropolitan-scale traffic estimation with probe vehicles that periodically send location and speed updates to a monitoring center. In our approach, we use the flow speed on a road link within a time slot to indicate the traffic condition of the road segment at the given time slot, which is approximated by the average value of probe speeds. By analyzing a large data set of two-year probe data collected from a fleet of around 4,000 taxis in Shanghai, China, we find that a set of probe data may contain a lot of spatiotemporal vacancies over both time and space. This raises a serious missing data problem for road traffic estimation, which results from the naturally uneven distribution of probe vehicles over both time and space. Through empirical study based on the data set of real probe data using principal component analysis (PCA), we have observed that there are hidden structures within the traffic conditions of a road network. Inspired by this observation, we propose a compressive sensing-based algorithm for solving the missing data problem, which exploits the hidden structures for computing estimates for road traffic conditions. Different from existing approaches, our algorithm does not rely on complicated traffic models, which usually require costly training with field study and large data sets. With extensive experiments based on the data set of real probe data, we demonstrate that our proposed algorithm performs significantly better than other completing algorithms, including KNN and MSSA. Surprisingly, our algorithm can achieve an estimate error of as low as 20 percent even when more than 80 percent of probe data are missing.	approximation algorithm;compressed sensing;experiment;field research;k-nearest neighbors algorithm;missing data;principal component analysis	Yanmin Zhu;Zhi Li;Hongzi Zhu;Minglu Li;Qian Zhang	2013	IEEE Transactions on Mobile Computing	10.1109/TMC.2012.205	simulation;floating car data;computer science;compressed sensing;statistics	Visualization	-15.464049438616469	-33.36831434825624	88120
a4be1f49deff8ed0f4fff104aef3e531e853bdc6	optimization of mobile radioactivity monitoring networks	high resolution;mobile device;high density;real time;false negative;geostatistics;sampling design;simulated annealing;decision maker;emergency;spatial simulated annealing;spatial correlation;spatial distribution;deterministic trend;atmospheric dispersion;false positive	In case of a nuclear accident, decision makers rely on high resolution and accurate information about the spatial distribution of the radioactivity levels in the surroundings of the acc ident site. Static nuclear monitoring networks are th refore employed in many countries in Europe. However, these networks were d signed to cover the whole country and are usually too course to reach a high density in the local environment around the acciden t site. Therefore a strategy is considered in which the measurement density is increased during emergencies by adding measurements from mobile measuring devices. This raises the que stion where the mobile devices should be placed. This paper proposes a geo statistical methodology to optimize the allocation f the mobile devices, such that the expected weighed sum of false negative and f lse positive areas, i.e., false classification i nto safe and unsafe zones is minimized. The radioactivity concentration was mode lled as the sum of a deterministic trend and a zero -mean spatially correlated stochastic residual, whereby the deterministic tren d was defined as the outcome of a spatially explici t physical atmospheric dispersion model (NPK-PUFF model). The NPK-PUFF mod el used meteorological data and the characteristics of the radioactive release as input. The residual was characterized by a semivariogram that was estimated from the differ ences between outputs from various NPK-PUFF runs with input settings reflectin g the uncertainty in the NPK-PUFF inputs (e.g., win d speed, wind direction). Spatial simulated annealing was used to obtain the optimal monitoring design, whereby accessibility an d openness of sampling sites was also included. The method was computationally d emanding but results were promising and the computa tion l speed may be considerably improved to compute the optimal monito ring network in nearly real-time. * corresponding author	accessibility;atmospheric dispersion modeling;mobile device;openness;puff model;real-time clock;ring network;sampling (signal processing);simulated annealing	Gerard B. M. Heuvelink;Zhen Jiang;Sytze de Bruin;Chris J. W. Twenhöfel	2007	International Journal of Geographical Information Science	10.1080/13658810802646687	decision-making;sampling design;spatial correlation;simulation;image resolution;atmospheric dispersion modeling;simulated annealing;type i and type ii errors;emergency;computer science;data mining;mobile device;mathematics;statistics;geostatistics	ML	-15.381466073240004	-29.448574682150912	88574
e34d747ab805f84a163d6699bb6ff0fff517aaff	methods used to develop hydrogeological model of latvia				Aivars Spalvins;Janis Slangens;Inta Lace;Kaspars Krauklis;Olgerts Aleksans	2013		10.7148/2013-0136	environmental science;hydrogeology;hydrology	Logic	-11.431744928425895	-26.917647262879825	88625
5022c75672a2606489a3ca9311db9b0ef62032db	using spatial data support for reducing uncertainty in geospatial applications	spatial data mining;data support;sensor networks;time series data;mutual information	Widespread use of GPS devices and ubiquity of remotely sensed geospatial images along with cheap storage devices have resulted in vast amounts of digital data. More recently, with the advent of wireless technology, a large number of sensor networks have been deployed to monitor many human, biological and natural processes. This poses a challenge in many data rich application domains now: how to best choose the datasets to solve specific problems? In particular, some of the datasets may be redundant and their inclusion in analysis may not only be time consuming, but also lead to erroneous conclusions. On the other hand, excluding some of the datasets hastily might skew the observations drawn. We propose the concept of data support as the basis for efficient, cost-effective and intelligent use of geospatial data in order to reduce uncertainty in the analysis and consequently in the results. Data support is defined as the process of determining the information utility of a data source to help decide which one to include or exclude to improve cost-effectiveness in existing data analysis. In this paper we use mutual information--a concept popular in information theory as a measure to compute information gain or loss between two datasets--as the basis of computing data support. The flexibility and effectiveness of the approach are demonstrated using an application in the hydrological analysis domain, specifically, watersheds in the state of Nebraska.		T. Hong;K. Hart;Leen-Kiat Soh;Ashok Samal	2014	GeoInformatica	10.1007/s10707-013-0177-z	wireless sensor network;computer science;data science;machine learning;time series;data mining;database;mathematics;mutual information;statistics;remote sensing	HCI	-5.522626356192497	-29.849298060564752	88712
21f6c1862ae4894f1796786fb660c4c66d0dfb71	spatial rules generate urban patterns: emergence of the small-world network	spatial prediction;small world network;urban design;simulation model	Objective explanation of urban patterns requires regeneration of these patterns. We defined eight simple spatial rules for  locating a building in space and used these rules to simulate re-generation of the small-world network pattern, which is an  archetype in structures of cities. We provided a spatial description of how these rules act generating the mentioned pattern.  The description is based on using local spatial predictability of the physical reality, incorporating basic spatial global  rules, and reducing the indeterminacy of the simulation model. The results show that following the spatial rules derived from  the physical reality, it is difficult to avoid generating the small-world network. This clarifies problem of the urban design  approaches damaging the small-world network patterns in contemporary cities. The results also propose the small-world network  characteristics for cities that are not pre-planned, or more properly organic cities, settled on flat lands.  	emergence	Hani Rezayan;Mahmoud Reza Delavar;Andrew U. Frank;A. Mansouri	2008		10.1007/978-3-540-68566-1_31	simulation;geography;machine learning;data mining	DB	-13.058366651628715	-24.174983007441142	88839
1db03d5ebae9e5e656aa42307618f8ce6816ce5c	cost-aware rank join with random and sorted access	top k;context awareness;sorted access;query processing;search engines;information retrieval;nickel;upper bound context awareness optimization search engines relational databases information retrieval;upper bound;random access top k rank join sorted access;top;web services query processing search engines;aggregates;web services;parameter estimation cost aware rank join cost aware with random and sorted access pulling strategy web services join attribute value rank join operators bounding schemes pulling strategy cars pulling strategy query dependent score distributions optimization problem real data sets synthetic data sets oracle based optimal strategy;optimization;relational databases;rank join;random access;context	In this paper, we address the problem of joining ranked results produced by two or more services on the web. We consider services endowed with two kinds of access that are often available: 1) sorted access, which returns tuples sorted by score; 2) random access, which returns tuples matching a given join attribute value. Rank join operators combine objects of two or more relations and output the k combinations with the highest aggregate score. While the past literature has studied suitable bounding schemes for this setting, in this paper we focus on the definition of a pulling strategy, which determines the order of invocation of the joined services. We propose the Cost-Aware with Random and Sorted access (CARS) pulling strategy, which is derived at compile-time and is oblivious of the query-dependent score distributions. We cast CARS as the solution of an optimization problem based on a small set of parameters characterizing the joined services. We validate the proposed strategy with experiments on both real and synthetic data sets. We show that CARS outperforms prior proposals and that its overall access cost is always within a very short margin from that of an oracle-based optimal strategy. In addition, CARS is shown to be robust w.r.t. the uncertainty that may characterize the estimated parameters.	aggregate data;compile time;compiler;experiment;mathematical optimization;optimization problem;random access;synthetic data	Davide Martinenghi;Marco Tagliasacchi	2012	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2011.161	web service;nickel;relational database;computer science;theoretical computer science;machine learning;data mining;database;upper and lower bounds;world wide web;random access	DB	-12.677442327178268	-37.022878882280615	88914
f775070792c6bb69e7e98d17896098e944987dc5	a framework of mining semantic regions from trajectories	moving object;cluster algorithm;sequential clustering and spatialtemporal mining;mobile device;high density;trajectory pattern mining;pattern mining;sequential clustering and spatial temporal mining;nearest neighbor;article	With the pervasive use of mobile devices with location sensing and positioning functions, such as Wi-Fi and GPS, people now are able to acquire present locations and collect their movement. As the availability of trajectory data prospers, mining activities hidden in raw trajectories becomes a hot research problem. Given a set of trajectories, prior works either explore density-based approaches to extract regions with high density of GPS data points or utilize time thresholds to identify users’ stay points. However, users may have different activities along with trajectories. Prior works only can extract one kind of activity by specifying thresholds, such as spatial density or temporal time threshold. In this paper, we explore both spatial and temporal relationships among data points of trajectories to extract semantic regions that refer to regions in where users are likely to have some kinds of activities. In order to extract semantic regions, we propose a sequential clustering approach to discover clusters as the semantic regions from individual trajectory according to the spatial-temporal density. Based on semantic region discovery, we develop a shared nearest neighbor (SNN) based clustering algorithm to discover the frequent semantic region where the moving object often stay, which consists of a group of similar semantic regions from multiple trajectories. Experimental results demonstrate that our techniques are more accurate than existing clustering schemes.	algorithm;artificial neural network;cluster analysis;data point;global positioning system;mobile device;pervasive informatics;spiking neural network	Chun-Ta Lu;Po-Ruey Lei;Wen-Chih Peng;Ing-Jiunn Su	2011		10.1007/978-3-642-20149-3_16	computer science;machine learning;pattern recognition;data mining;mobile device;k-nearest neighbors algorithm	ML	-16.57619581729294	-35.118704927296385	89331
90a6bbf8408915d306184b4a8955677ff280d5f6	inferring drivers behavior through trajectory analysis		Several works have been proposed for both collective and individual trajectory behavior discovery, as flocks, outliers, avoidance, chasing, etc. In this paper we are especially interested in abnormal behaviors of individual trajectories of drivers, and present an algorithm for finding anomalous movements and categorizing levels of driving behavior. Experiments with real trajectory data show that the method correctly finds driving anomalies.	algorithm;application domain;categorization;device driver;experiment;flocking (behavior);sensor	Eduardo M. Carboni;Vania Bogorny	2014		10.1007/978-3-319-11313-5_73	flock;mathematics;outlier;artificial intelligence;trajectory;pattern recognition	ML	-15.222612670997538	-33.34111106753515	89895
dbc5f24f2aad3b0982b8c81e0a8e11659c03b3f2	fuzzy anp - a analytical network model for result merging for metasearch using fuzzy linguistic quantifiers	network model	Search Engines are tools for searching the World Wide Web or any other large data collection. Search engines typically accept a user query and returns a list of relevant documents. These documents are generally returned as a result list for the user to see. A metasearch engine is a tool that allows an information seeker to search information on the world wide web through multiple search engines. A key function of a metasearch engine is to aggregate search results returned by many search engines. Result aggregation is an important task for a metasearch engine. In this paper we propose a model for result aggregation for metasearch, Fuzzy ANP, that employs fuzzy linguistic quantifier guided approach to result merging using Saty's Analytical Network Process. We compare our model to two existing result merging models, the Borda Fuse model and the OWA model for metasearch. Our results show that our model outperforms the OWA model and Borda-Fuse model significantly.	aggregate data;document;experiment;information retrieval;learning to rank;network model;ordered weighted averaging aggregation operator;quantifier (logic);web search engine;world wide web	Arijit K De;Elizabeth D. Diaz	2010			fuzzy classification;fuzzy number;neuro-fuzzy;machine learning;data mining;database;fuzzy set operations	Web+IR	-5.877796282871502	-26.53384403222631	89928
f2f6f9a6647243982f3b8217cf06b73b9c33e42d	development of a model-based digital and visual wheat growth system	real time;net framework;data management;component based software;management strategy;visual modeling;visualization technique;dynamic simulation;farming system;spatial analysis;growth process;simulation model;3d graphics;growth model	Driven by soil, variety, weather and management databases and integrating process-based growth simulation model, morphological model and visualization model, a model-based digital and visual wheat growth system (MDVWGS) was developed using component-based software and visualization techniques. The system was programmed by the .Net framework with the language of C# and CsGL Library was used for realizing 2D and 3D graphics application and visualization. The implemented system could be used for predicting growth processes and visualizing morphological architecture of wheat plant under various environments, genotypes and management strategies, and has the functions as data management, dynamic simulation, strategy evaluation, real-time prediction, temporal and spatial analysis, visualization output, expert consultation and system help. The MDVWGS should be useful for construction and application of digital farming system and provide a precise and scientific tool for cultivar design, cultural regulation and productivity evaluation under different growing conditions.	.net framework;3d computer graphics;component-based software engineering;database;dynamic simulation;graphics software;real-time clock;spatial analysis;strategic management	Liang Tang;Hui Liu;Yan Zhu;Weixing Cao	2007		10.1007/978-0-387-77253-0_45	computer vision;simulation;computer science;computer graphics (images)	Visualization	-14.12073869412281	-25.841112881036935	90779
5b34a36220a49dc6bfd2ed5e409c341b1a48c8ca	filled: video data based fill level detection of agricultural bulk freight				Fabian Graefe;Walter Schumacher;Raul Queiroz Feitosa;Diogo Menezes Duarte	2005				Vision	-11.995975681255938	-26.13462934279026	91225
5ecc91e9e701a7a1ef793b434603dcf5e96caaa6	prediction of high resolution spatial-temporal air pollutant map from big data sources		In order to better understand the formation of air pollution and assess its influence on human beings, the acquisition of high resolution spatial-temporal air pollutant concentration map has always been an important research topic. Existing air-quality monitoring networks require potential improvement due to their limitations on data sources. In this paper, we take advantage of heterogeneous big data sources, including both direct measurements and various indirect data, to reconstruct a high resolution spatial-temporal air pollutant concentration map. Firstly, we predict a preliminary 3D high resolution air pollutant concentration map from measurements of both ground monitor stations and mobile stations equipped with sensors, as well as various meteorology and geography covariates. Our model is based on the Stochastic Partial Differential Equations (SPDE) approach and we use the Integrated Nested Laplace Approximation (INLA) algorithm as an alternative to the Markov Chain Monte Carlo (MCMC) methods to improve the computational efficiency. Next, in order to further improve the accuracy of the predicted concentration map, we model the issue as a convex and sparse optimization problem. In particular, we minimize the Total Variant along with constraints involving satellite observed low resolution air pollutant data and the aforementioned measurements from ground monitor stations and mobile platforms. We transform this optimization problem to a Second-Order Cone Program (SOCP) and solve it via the log-barrier method. Numerical simulations on real data show significant improvements of the reconstructed air pollutant concentration map.	big data;high-resolution scheme	Yingyu Li;Yifang Zhu;Wotao Yin;Yang Liu;Guangming Shi;Zhu Han	2015		10.1007/978-3-319-22047-5_22	meteorology;environmental engineering	ML	-15.601889036094022	-32.20175475392169	91276
484115e1df6466a2b8c1bd2b7cb3beb3670ab504	a decomposition-based probabilistic framework for estimating the selectivity of xml twig queries	modelizacion;base donnee;analisis estadistico;interrogation base donnee;database;interrogacion base datos;base dato;probabilistic approach;modelisation;statistical analysis;enfoque probabilista;approche probabiliste;analyse statistique;selectividad;selectivity;query answering;selectivite;modeling;database query	In this paper we present a novel approach for estimating the selectivity of XML twig queries. Such a technique is useful for answering approximate queries as well as for determining an optimal query plan for complex queries based on said estimates. Our approach relies on a summary structure that contains the occurrence statistics of small twigs. We rely on a novel probabilistic approach for decomposing larger twig queries into smaller ones. We then show how it can be used to estimate the selectivity of the larger query in conjunction with the summary information. We present and evaluate different strategies for decomposition and compare this work against a state-of-the-art selectivity estimation approach on synthetic and real datasets. The experimental results show that our proposed approach is very effective in estimating the selectivity of XML twig queries.	approximation algorithm;global serializability;markov chain;markov model;online and offline;query plan;recursion;selectivity (electronic);synthetic intelligence;twig;xml	Chao Wang;Srinivasan Parthasarathy;Ruoming Jin	2006		10.1007/11687238_33	selectivity;systems modeling;computer science;data mining;database;information retrieval	DB	-8.703862227579291	-32.97158513197106	91467
8b63b39d454c5bc9c95bc45a67e21293879614cf	a performance analysis framework for reso urce scavenging systems			profiling (computer programming)	David Dewolfs;Gunther Stuer;Frederic Hancke;Peter Hellinckx;Jan Broeckhove;Frans Arickx;Tom Dhaene	2004			environmental chemistry;environmental science;scavenging	Logic	-11.326356710257238	-27.0283459776682	91757
8ce54524c51513fa90c1b26b0500ce182f8fd1ad	compressing the set of frequent sequential patterns	databases;pattern clustering;fuzzy systems educational institutions computer science explosives greedy algorithms clustering algorithms databases itemsets proposals;data compression;approximation algorithms;pattern clustering data compression data mining greedy algorithms;greedy algorithms;usa councils;data mining;distance measurement;candidate based algorithm frequent sequential pattern compression frequent sequential pattern mining greedy algorithm;clustering algorithms;greedy algorithm;representative sequential pattern;frequent sequential pattern mining;sequential pattern;candidate based algorithm;algorithm design and analysis;representative sequential pattern data mining sequential pattern;frequent sequential pattern compression	Compressing the set of frequent sequential patterns is a method in order to address the problem of explosive number of output sequential patterns. In order to get high-quality compression, it first clusters frequent sequential patterns, and then select and output only a representative sequential pattern for each cluster such that the number of these representative sequential patterns is minimized. A greedy algorithm and an efficient candidate-based algorithm are proposed. The set of representative sequential patterns is a kind of subset of frequent sequential patterns. Experimental results show that it can achieve very good compression effect.	greedy algorithm	Tao Wang	2008	2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2008.168	greedy algorithm;computer science;machine learning;pattern recognition;data mining;mathematics;approximation algorithm	ML	-4.694382109818637	-37.00562015114563	91872
b34562f7b12623cfc1c12d1066708a096053b04d	fast frequent pattern mining in real-time	real time;association rule mining	Finding frequent patterns from databases has been the most time consuming process of the association rule mining. Till date, a large number of algorithms have been proposed in the area of frequent pattern generation. However, all of these algorithms produce output only at the completion and are not amenable to the real-time need. The need for real-time frequent pattern mining for online tasks and real-time decision-making is increasingly being felt. In this paper, we describe BDFS(b), an algorithm to perform real-time frequent pattern mining using limited computer memory. Empirical evaluations show that our algorithm can make a fair estimation of the probable frequent patterns and reaches some of the longest frequent patterns much faster than the existing algorithms.	algorithm;association rule learning;computer memory;data mining;database;real-time clock;real-time locating system;real-time transcription;real-time web	Rajanish Dass;Ambuj Mahanti	2005			data mining;k-optimal pattern discovery;association rule learning;computer science	ML	-5.920811829526293	-36.00748801232927	92400
0da9889983e81fbc946f29eae5a71684f8701cc7	a study on the network stability measurement based on an articulation nodes with weight value		The concept of network stability has been introduced to ensure the easy management of the actual complex networks. The network stability is a concept that allows the network administrator to easily provide the network management. There have been relevant advanced studies, which were meaningful in that they measured the network stability, but they did not address the subject deeply enough. In this study, a new network stability calculation method was proposed using the weight of the articulation node based on the existing studies. The method proposed in this study offers more precise information about the weakness of the network, and is expected to provide more accurate stability and weakness information than those from the existing method.	biconnected component	Myung-Ki Jung;Seongjin Ahn	2012		10.1007/978-94-007-5860-5_16	control engineering;transport engineering;communication	ECom	-9.245767371756786	-25.795014972918096	92414
a140bbbb81deb7fe1781104b455560264af4d204	developing spatial indicators using a uniform tessellation to measure urban transformation		South Africa’s largest cities are subjected to high rates of urbanization with a projected 8 million people migrating to these urban spaces by 2030 [1]. Managing and guiding this growth is made more difficult due to the countries ‘apartheid city’ past - a segregated city form inherited from the pre-democratic order in 1994 where towns and cities were spatially engineered along racial divides. With the advent of a democratic order in South Africa in 1994 a number of policy frameworks have seen the light all of which have indicated the need to spatially transform cities and settlements – to break from the pre-1994 apartheid city. Measuring the progress made in spatial and socio-economic transformation has proven difficult as some information have only been provided at city or Local Municipal scale. To measure spatial outcomes, city performance, quality of life etc. a series of local and international city scale indicators has been developed. These however are only useful when comparing cities; it does not convey sub-city scale change or transformation. This paper profiles an approach that uses a single-sized uniform tessellation to create demographic and economic indicators for nine cities and explores the utilisation of this tessellated framework to analyse and depict demographic and economic change over time.		Johan Maritz;Alize le Roux;Gerbrand Mans	2017		10.1007/978-3-319-62401-3_30	uniform tessellation;discrete mathematics;mathematical optimization;computer science;human settlement;tessellation;economic growth;economic indicator;quality of life;urbanization	HCI	-12.431238029244428	-24.021951554075557	92475
fdaa3abd0a73a3db7578a1e3a4dd85acbbb35b43	development of a real-time model of the occupancy of short-term parking zones		The lack of reliable information about the occupancy of on-street parking places in the inner districts of large cities causes an unnecessarily high amount of parking search traffic. Previous attempts to solve the problem rely on accurate information systems that navigate drivers to the next available parking space. They have failed due to high costs for roadside sensors and are also controversial, because they indirectly support car use. A service that informs road users early about the situation at the destination would support a shift towards public transport modes and reduce parking search traffic particularly at times of unexpectedly high parking pressure. The real-time occupancy model presented in this article does not aim to indicate the occupancy of single parking lots, but to provide a sufficiently accurate description and reliable prediction of the occupancy at the destination. Three existing realtime indicators were tested for their predictive power: (i) location data of mobile-phone parking; (ii) counts of car parks in the vicinity; and (iii) traffic flow volumes. Experimental results indicated that models using mobile-phone parking data have the potential to improve predictions of the occupancy rate by detecting exceptional deviations from the average day curve.	information system;institute for operations research and the management sciences;mobile payment;mobile phone;real-time clock;real-time transcription;sensor	Reinhard Hössinger;Peter Widhalm;Michael Ulm;Klaus Heimbuchner;Eike Wolf;Roland Apel;Tina Uhlmann	2014	Int. J. Intelligent Transportation Systems Research	10.1007/s13177-013-0069-5	simulation;parking guidance and information;transport engineering;computer security	Mobile	-17.742928794286822	-28.994310436612516	92582
503dfc6d4ee8115b9e4dfdd02f3e29fec4fe39bb	comparisons of statistical methods in analyzing clinical data through systematically using historical data		With increasing requirements, from both regulatory and scientific community, for pre-specification of details of all analyses prior tounblinding of data in clinicaltrials, itis criticalthatone selects the most appropriate statisticalmodel. Selectinga model based on assumption checking either inflates type I error or compromises the statistical power. Previous research is mainly focused on comparing various analysis models through either simulation or case studies. Simulation does provide a flexible way to compare models but requires assumptions on models for generating simulation data. On the other hand, although results based on case studies are close to the real situations, it is difficult to draw a definite conclusion due to lack of replication. These two approaches ignore the fact that for most variables, large amount of data may be available from historical studies. We propose a procedure that systematically utilizes the historical data, evaluates various models of interest, and provides a powerful choice for model pre-specification for subsequent studies. Based on the comparisons on the generated data from a historical data base, one can pre-specify the particular model for the purpose of controlling the type I error and power of prospective studies, or ease of interpretation when they all have similar performance.		Lei Xu;Yongming Qu;Pandurang M. Kulkarni	2012	MASA	10.3233/MAS-2011-0217	econometrics;computer science;data mining;statistics	HCI	-6.305838705535071	-29.290712300325122	92592
50cde7854f51d98a42ebaef7279435c37f14bd38	macroscopic patterns in sparse location data: identifying mobility prototypes		Ubiquitous computing and location-based services are key enablers for gaining novel insights into human movement behavior on a large scale. When searching for patterns in movement behavior, several approaches have been proposed to compare location trajectories or semantic overlaps. This paper introduces the notion of mobility prototypes, which describe human mobility behavior at a macroscopic level and express its most significant characteristics. Based on a dataset of coarse spatiotemporal data from almost 4000 mobile users of a location-based service over a period of 14 days, we outline a comprehensive and systematic pipeline for processing and exploiting mobility traces and provide insights into the mobility behavior in the city of Berlin. We present a framework to characterize individual users precisely by employing a novel combination of discriminative features capturing the macroscopic mobility behavior, without revealing their identity or actual whereabouts, and define mobility prototypes by constructing clusters of users. The results yield valuable insights into the variety of human mobility and open up new possibilities for future mobile services.	location-based service;sparse;tracing (software);ubiquitous computing;weatherstar	Bianca Katharina Luders;Peter Ruppel	2018	2018 IEEE Fourth International Conference on Big Data Computing Service and Applications (BigDataService)	10.1109/BigDataService.2018.00027	data mining;artificial intelligence;machine learning;computer science;ubiquitous computing;discriminative model	Mobile	-17.837763318198583	-35.45889991864839	92768
26e4aee66a66abf056aa6b8619c5d4794960d4e6	creation of semantic location profiles using bayes, rule-based, trees and meta classification approaches		Travel recommender systems are gaining a higher popularity in the society due to their capability of planning trips in a short time period. The challenge of providing the most accurate recommendations has become a complex and difficult task due to the numerous variations in user preferences. In order to provide the most accurate recommendations, it is necessary to consider additional parameters like the prevailing weather condition, which has a direct influence on the user preference to a particular location. Therefore, when providing travel recommendations considering the weather context, it was identified that the ability to correctly identify a location as an indoor or outdoor attraction plays a vital role in improving the accuracy of the recommendations. Considering the millions of locations available in Google Places, it is difficult to manually tag the location status as indoor or outdoor. This paper provides a novel approach to determine the status of a particular location based on the identified attributes of the location. Moreover, the experimental results and the accuracy of the predicted outputs have been discussed by using different classifiers under the Bayes, Rule-Based, Trees and Meta classification approaches.	logic programming;recommender system;user (computing)	Sachini Ganiachchi;S. S. Wijenayake;Janitha Wijekoon;Supunmali Ahangama	2017	2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2017.8393005	recommender system;trips architecture;machine learning;location status;artificial intelligence;decision tree;computer science;data modeling;popularity;bayes' theorem	ML	-17.711845428612605	-33.780075084096495	92829
0a7f5c4306e3f70642aad1826eb28de0e0131aed	measuring the effects of transportation infrastructure location on real estate prices and rents: investigating the current impact of a planned metro line	residential location;land use models;urban development;property values;econometric models;economic impacts;rapid transit;thessaloniki greece	The importance of modeling the interactions between transportation infrastructure and land use has been demonstrated through a large number of studies. The aim of this paper is, on the one hand, to measure the effect of transportation infrastructure and land-use characteristics on dwelling prices and rents in Thessaloniki, Greece, and, on the other, to investigate the current impact of a future metro line on the area. The results reveal a negative effect of the proximity to port and railway station on property prices and rents, and a positive impact of the proximity to the airport. The metro line, which is still under construction, has a negative impact on the purchase prices, while it does not significantly affect the rents. In the first case, this can be attributed to the negative externalities generated by the construction, which is generally not expected to be completed within the next 5 years, a fact that keeps the expected demand in low levels. This conclusion comes in accordance with other research works based on surveys in the area. In the second case, the variable is insignificant since rents are often short term which means the future implementation of the metro does not affect the candidate tenants’ decision. For the purpose of this research, spatial econometric models are applied. Such models have been neglected from inclusion in the existing Integrated Land-Use and Transport Models (LUTI), which are used for predicting the effects of transportation policies. The results indicate that such models are able to capture the existing spatial autocorrelation (unlike the linear regression) and the authors suggest their use in LUTI models.		Dimitrios Efthymiou;Constantinos Antoniou	2014	EURO J. Transportation and Logistics	10.1007/s13676-013-0030-4	geography;civil engineering;economy;economic growth	HCI	-14.741324677311638	-26.636680162546718	93146
17202aa0c0eb7895b66b145da4f60268d8c40668	nsim: a robust method to discover similar trajectories on cellular network location data		Trajectory analysis is crucial and has been more and more widely used in various fields, such as location-based services, urban traffic control, route plan, etc. The existing methods have certain limitations when applied to cellular network location data. In this paper, we propose NSIM, a novel approach that can effectively discover similar trajectories. In NSIM, we first design an algorithm that can discover all the common moving patterns among trajectories, and then we adopt a vectorization method to abstract each trajectory as a summary vector that composed of specific common moving patterns. Finally we measure the similarity of trajectories by computing the distance between the summary vectors. Extensive experiments on real-world dataset show that, compared with three other approaches, NSIM achieves good effectiveness in most test cases and achieves better efficiency when applied to small or medium length trajectories.	algorithm;automatic vectorization;experiment;location-based service;test case	Yupeng Tuo;Xiaochun Yun;Yongzheng Zhang	2017	2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)	10.1109/PIMRC.2017.8292237	real-time computing;machine learning;trajectory;test case;vectorization (mathematics);location-based service;computer science;cellular network;artificial intelligence	SE	-16.65349628449213	-35.4953860650528	93189
73a49770a2459f8d47ff606a13c2cf58efb88857	on exploiting the power of time in data mining	incremental mining;data mining;data distribution	We introduce the new paradigm of Change Mining as data mining over a volatile, evolving world with the objective of understanding change. While there is much work on incremental mining and stream mining, both focussing on the adaptation of patterns to a changing data distribution, Change Mining concentrates on understanding the changes themselves. This includes detecting when change occurs in the population under observation, describing the change, predicting change and pro-acting towards it. We identify the main tasks of Change Mining and discuss to what extent they are already present in related research areas. We elaborate on research results that can contribute to these tasks, giving a brief overview of the current state of the art and identifying open areas and challenges for the new research area.	data mining;programming paradigm;sensor;volatile memory	Mirko Böttcher;Frank Höppner;Myra Spiliopoulou	2008	SIGKDD Explorations	10.1145/1540276.1540278	text mining;computer science;data science;machine learning;data mining;data stream mining	ML	-11.95080527665816	-34.05891226913055	93263
1177be3f04fdb323a6009e21b1cc1d5b3e8c34fd	fuzzy expert system for solving lost circulation problem	monotone operator;fuzzy algebra fuzzy expert system lost circulation problem distributed hybrid intelligent system smartdrill fuzzy logic web services petroleum engineering;expert systems;oil drilling;field test;petroleum industry expert systems fuzzy logic internet process algebra fuzzy systems oil drilling;web service;hybrid intelligent system;fuzzy logic;internet;fuzzy expert system;petroleum industry;hybrid intelligent systems drilling diagnostic expert systems fuzzy logic web services algebra petroleum industry software tools expert systems computer science;system architecture;process algebra;fuzzy systems;expert system	Lost circulation is the most common problem encountered when drilling. This paper describes a distributed hybrid intelligent system, called SmartDrill, using fuzzy logic, expert system framework and Web services for helping petroleum engineers to diagnose and solve lost circulation problems. The fuzzy algebra of strict monotonic operations is used as an underlying model for expert system development. Its realization in inference procedures of expert systems is simpler than for expert systems based on lexicographic operations. Overall, the system architecture is discussed and implementation details are provided. The system is aimed to help in making decisions at the operational level and is at field testing phase in PEMEX, Mexican Oil Company.	circulation problem;expert system	Leonid Sheremetov;Ildar Z. Batyrshin;Jorge Martínez Muñoz;Hector Rodriguez;Dmitry Filatov	2005		10.1109/ICHIS.2005.50	control engineering;legal expert system;systems engineering;engineering;operations management	AI	-7.740743226834583	-24.36049347465892	93599
41bfa8a8c8f0a6b955ab88f8c66edea0637a3eb9	optimal kd-partitioning for the local outlier detection in geo-social points		Coupling social media with geographic location has boosted the worth of understanding the real-world situations. In particular, event detection based on clustering algorithms or bursty detection aims to find more specific topics that represent real-world events from geo-tagged social media. However, it is also necessary to identify unusual and seemingly inconsistent patterns in data, namely outliers. For example, it is difficult to obtain social media posted by residents of the places where a disaster is happening for quite some while. In this paper, we focus on a problem in partitioning a space to find a meaningful local outlier pattern by using a genetic algorithm (GA). We first describe a model of local patterns based on spatio-temporal neighbors and a normal distribution test. Then we propose our optimization process to maximize the number of patterns. Finally, we show results of the performance simulation with a real dataset related to a landslide disaster.	anomaly detection	Teerawat Kumrai;Kyoung-Sook Kim;Mianxiong Dong;Hirotaka Ogawa	2017		10.1007/978-3-319-59072-1_13	machine learning;anomaly detection;artificial intelligence;genetic algorithm;cluster analysis;spatio-temporal analysis;outlier;local outlier factor;computer science;social media;normal distribution	Vision	-15.94407673161663	-32.641187986632126	93667
78384d8a676343516cfae56443daf624118d7aa2	probabilistic frequent itemset mining algorithm over uncertain databases with sampling			algorithm;association rule learning;gibbs sampling	Haifeng Li;Ning Zhang;Yuejin Zhang;Yue Wang	2016		10.3233/978-1-61499-722-1-159	sampling (statistics);data mining;probabilistic logic;computer science;pattern recognition;artificial intelligence	ML	-8.731377868161125	-33.31932241139103	93791
2262ae2b57b1ef8196799880c9594ced33cfd83f	"""advanced data mining method for discovering regions and trajectories of moving objects: """"ciconia ciconia"""" scenario"""	moving object;fuzzy c mean;clustering techniques;data mining;trajectories;regions;gaussian mixture model;spatial pattern;analytical method;spatial patterns;moving objects;patterns;cumulant;spatio temporal dataset	Trajectory data is of crucial importance for a vast range of applications involving analysis of moving objects behavior. Unfortunately, the extraction of relevant knowledge from trajectory data is hindered by the lack of semantics and the presence of errors and uncertainty in the data. This paper proposes a new analytical method to reveal the behavioral characteristics of moving objects through the representative features of migration trajectory patterns. The method relies on a combination of Fuzzy c-means, Subtractive and Gaussian Mixture Model clustering techniques. Besides, this method enables splitting the analysis into sections in order to differentiate the whole migration into i) migration-to-destination, ii) reverse-migration. The method also identifies places where moving objects' cumulate and increase in number during the moves (bottleneck points). It also computes the degree of importance for a given point or probability of existence of an object at a given coordinate within a certain confidence degree, which in turn determines certain zones having different degrees of importance for the move, i.e. critical zones of interest. As shown in this paper, other techniques are not capable to elaborate similar results. Finally, we present experimental results using a trajectory dataset of migrations of white storks (Ciconia ciconia).	data mining	Cláudio Carneiro;Arda Alp;José Antônio Fernandes de Macêdo;Stefano Spaccapietra	2008		10.1007/978-3-540-78946-8_11	geography;machine learning;data mining;statistics	ML	-11.307880720171005	-35.20821096526405	93826
05332a4b807cf6f2d1288bca186692b6b67a7e59	mining high utility episodes in complex event sequences	complex event sequences;episode mining;utility mining;high utility episodes	Frequent episode mining (FEM) is an interesting research topic in data mining with wide range of applications. However, the traditional framework of FEM treats all events as having the same importance/utility and assumes that a same type of event appears at most once at any time point. These simplifying assumptions do not reflect the characteristics of scenarios in real applications and thus the useful information of episodes in terms of utilities such as profits is lost. Furthermore, most studies on FEM focused on mining episodes in simple event sequences and few considered the scenario of complex event sequences, where different events can occur simultaneously. To address these issues, in this paper, we incorporate the concept of utility into episode mining and address a new problem of mining high utility episodes from complex event sequences, which has not been explored so far. In the proposed framework, the importance/utility of different events is considered and multiple events can appear simultaneously. Several novel features are incorporated into the proposed framework to resolve the challenges raised by this new problem, such as the absence of anti-monotone property and the huge set of candidate episodes. Moreover, an efficient algorithm named UP-Span (Utility ePisodes mining by Spanning prefixes) is proposed for mining high utility episodes with several strategies incorporated for pruning the search space to achieve high efficiency. Experimental results on real and synthetic datasets show that UP-Span has excellent performance and serves as an effective solution to the new problem of mining high utility episodes from complex event sequences.	algorithm;data mining;finite element method;hereditary property;span and div;synthetic intelligence;monotone	Cheng-Wei Wu;Yu-Feng Lin;Philip S. Yu;Vincent S. Tseng	2013		10.1145/2487575.2487654	simulation;data science;data mining	ML	-9.127781989365191	-37.17475005198328	93951
753ffafa7748d5c8551637f084e63a15bb0e7518	making pattern mining useful	ethnoclassification;generic model;folk taxonomy;distributed classification;satisfiability;folksonomy;data mining;pattern mining;bookmarking;folk classification;social indexing;social classification;compression ratio;minimum description length principle;social tagging;collaborative tagging;tagging	Generally speaking, finding a pattern is easy. Discovering interesting patterns, that's where things get complicated. My dissertation 1 is about finding interesting patterns, and, more boldly, about making pattern mining useful. It is about how to discover few, but highly interesting patterns. And, prominently , it is about how to put these patterns to good use, solving a number of data mining problems. But, before we discuss the actual content, let us first informally discuss pattern mining and identify why it is not yet as useful as it could be. Let us consider an example how pattern mining could be used, e.g. in medicine, for gaining insight in the causes of a particular disease. Normally, following the scientific method, a doctor would build a hypothesis. In other words, a pattern. For this hypothesis not to be a shot in the dark, the doctor needs to be able to oversee the symptoms, behaviours , etc, that the patients exhibit. That is, he or she must be able to 'see' the pattern. The hypothesis can then be tested, and so shown to be correct or not. This works very well, up till the point where the problem at hand becomes too complicated, when there exists such a gigantic number of possible combinations of causes, that it becomes impossible for the doctor to gain sufficient overview. Yet, in those situations, we can apply pattern mining to discover important regularities. We simply mine for patterns in the gathered data, and return those that pass certain interestingness criteria. In this case, such a pattern could be a combination of factors with a strong relation to the disease. The doctor then selects the most promising patterns, and uses these to build a promising hypothesis. So far, so good. However, not in practice, as the poor doctor will be swamped in patterns. From being unable to overview the data, the problem becomes that it is impossible to overview the potentially interesting patterns. Perhaps even worse, many of the discovered patterns are variations of the same theme, and convey the same information. So, while pattern mining holds great promise, I dare say it collapses under its own weight: it finds patterns too easily. This is particularly due to the difficulty in using interesting-ness measures in practice: if we set the constraints too tight, only few but commonly known patterns are returned; and when we use more loose constraints …	data mining;earthbound	Jilles Vreeken	2009	SIGKDD Explorations	10.1145/1882471.1882483	computer science;data science;folk taxonomy;machine learning;compression ratio;data mining;data stream mining;world wide web;statistics;bookmarking;satisfiability	ML	-9.962122587023876	-34.984201113425016	93958
eb849f4471d265b08e8a3b21f555e7fb57a0e4dc	web traffic anomaly detection using c-lstm neural networks		Abstract Web traffic refers to the amount of data that is sent and received by people visiting online websites. Web traffic anomalies represent abnormal changes in time series traffic, and it is important to perform detection quickly and accurately for the efficient operation of complex computer networks systems. In this paper, we propose a C-LSTM neural network for effectively modeling the spatial and temporal information contained in traffic data, which is a one-dimensional time series signal. We also provide a method for automatically extracting robust features of spatial-temporal information from raw data. Experiments demonstrate that our C-LSTM method can extract more complex features by combining a convolutional neural network (CNN), long short-term memory (LSTM), and deep neural network (DNN). The CNN layer is used to reduce the frequency variation in spatial information; the LSTM layer is suitable for modeling time information; and the DNN layer is used to map data into a more separable space. Our C-LSTM method also achieves nearly perfect anomaly detection performance for web traffic data, even for very similar signals that were previously considered to be very difficult to classify. Finally, the C-LSTM method outperforms other state-of-the-art machine learning techniques on Yahoou0027s well-known Webscope S5 dataset, achieving an overall accuracy of 98.6% and recall of 89.7% on the test dataset.		Tae-Young Kim;Sung-Bae Cho	2018	Expert Syst. Appl.	10.1016/j.eswa.2018.04.004	machine learning;raw data;convolutional neural network;anomaly detection;spatial analysis;artificial intelligence;artificial neural network;computer science;web traffic	ML	-14.96952850100581	-31.401555737135343	94154
b7a21bfa941a67ac474bf9eb16bfdf52d2dccab0	the effectiveness of satisfying the assumptions of predictive modelling techniques: an exercise in predicting the fifa world cup 2010		The assumptions of statistical procedures are enforced more rigorously in some disciplines than in others. Previous research into the accuracy of predictive modelling techniques has provided examples where models based on data that violate the relevant assumptions is greater than that of models where the assumptions were satisfied. The purpose of this investigation was to develop two sets of 4 models; one set being based on untransformed data that violated the assumptions of the modelling techniques and a second set where the data were transformed in order to satisfy the assumptions of the modelling techniques. Data from 153 pool matches and 54 knock out matches from international soccer tournaments from July 2006 to February 2010 were used to produce predictive models of match outcomes (win, draw or lose) or goal difference with respect to the higher ranked teams within matches according to the FIFA World rankings. The independent variables used were difference between the teams FIFA World ranking points, difference between distance from capital city to capital city of the host nation and difference in recovery days from previous match within the tournament. The two sets of models were used to predict the 2010 FIFA World Cup, 119 human predictions and 20 weighted random predictions were also produced. An evaluation process marked the predictions with respect to the actual outcomes of matches in the 2010 FIFA World Cup out of a total possible score of 64 points. The mean accuracy of the models where the assumptions were satisfied was 33.50 points which was similar to the 35.13 points for those where the assumptions were violated. The accuracy score of the 8 model based predictions was 34.31+2.70 compared to 33.75+3.86 for the human predictions and 35.55+2.50 for the weighted random predictions. There was no significant difference in the accuracy of the three types of prediction (p = 0.116). These results provide evidence that challenges the value of satisfying the assumptions of discriminant function analysis, binary logistic regression and multiple linear regression.	discriminant;logistic regression;predictive modelling;statistical model	Peter G. O'Donoghue	2010	Int. J. Comp. Sci. Sport		predictive modelling;simulation;engineering	ML	-10.026000558443828	-29.51268845374744	94818
43aa66edc9946ae6ad08aa7142201b9d80ab65b6	a personalized approach for detecting unusual sleep from time series sleep-tracking data	switching circuits;data mining;time series analysis;entropy;sociology	Nowadays emerging sleep-tracking technologies such as Fibit make it possible for individuals to collect personal sleep data. However, people find it difficult to gain insights from these data without proper analysis. The objective of this study was to investigate the possibility of establishing a sleep analysis approach that helps people detect their unusual sleep pattern by considering their own sleep baselines instead of the population average. The proposed approach was consisted of two steps. In the first step, the dimension of time series sleep data was reduced using permutation entropy. Following that, univariate outlier detection techniques were applied to detect unusual sleep patterns. We tested our approach on a real sleep tracking data set consisting of 35 days of time series data tracked using a Fitbit Charge HR. Depending on the univariate outlier detection technique used, the identified unusual sleep differed. We found that permutation entropy of a sleep time series was strongly correlated to the time that the user went to bed and weekly correlated to minutes asleep, but was not correlated to minutes awake, awakening count and sleep efficiency. Based on the analysis results, we pointed out the directions for future study on personal sleep data analysis.	anomaly detection;data quality;dimensionality reduction;ground truth;personalization;sensor;time series	Zilu Liang;Mario Alberto Chapa Martell;Takuichi Nishimura	2016	2016 IEEE International Conference on Healthcare Informatics (ICHI)	10.1109/ICHI.2016.99	simulation;engineering;artificial intelligence;data mining	SE	-10.913235758437171	-34.467337056982245	94956
6ba730c9ed13ee843cfcf1d8ec5bea1e9cd6e3bf	predicting medical resources required to be dispatched after earthquake and flood, using historical data and machine learning techniques: the concorde emergency medical service use case		This﻿article﻿presents﻿a﻿method﻿to﻿predict﻿the﻿medical﻿resources﻿required﻿to﻿be﻿dispatched﻿after﻿large-scale﻿ disasters﻿to﻿satisfy﻿the﻿demand.﻿The﻿historical﻿data﻿of﻿past﻿incidents﻿(earthquakes,﻿floods)﻿regarding﻿the﻿ number﻿of﻿victims﻿requested﻿emergency﻿medical﻿services﻿and﻿hospitalisation,﻿simulation﻿tools,﻿web﻿services﻿ and﻿machine﻿learning﻿techniques﻿have﻿been﻿combined.﻿The﻿authors﻿adopted﻿a﻿twofold﻿approach:﻿a)﻿use﻿ of﻿web﻿services﻿and﻿simulation﻿tools﻿to﻿predict﻿the﻿potential﻿number﻿of﻿victims﻿and﻿b)﻿use﻿of﻿historical﻿ data﻿and﻿self-trained﻿algorithms﻿to﻿“learn”﻿from﻿these﻿data﻿and﻿provide﻿relative﻿predictions.﻿Comparing﻿ actual﻿and﻿predicted﻿victims﻿needed﻿hospitalisation﻿showed﻿that﻿ the﻿proposed﻿models﻿can﻿predict﻿ the﻿ medical﻿resources﻿required﻿to﻿be﻿dispatched﻿with﻿acceptable﻿errors.﻿The﻿results﻿are﻿promoting﻿the﻿use﻿of﻿ electronic﻿platforms﻿able﻿to﻿coordinate﻿an﻿emergency﻿medical﻿response﻿since﻿these﻿platforms﻿can﻿collect﻿ big﻿heterogeneous﻿datasets﻿necessary﻿to﻿optimise﻿the﻿performance﻿of﻿the﻿suggested﻿algorithms. KEywORDS Deep Learning, Earthquake, Flood, Historical Data, Linear Regression Models, Medical Resources Prediction, NLP	deep learning;machine learning;natural language processing	Homer Papadopoulos;Antonis Korakis	2018	IJICST		simulation;flood myth;business	ML	-13.447253628228712	-29.18013613127699	95087
41a329c7e2a5c50616618a83e9dc8a0456a13943	a data mining system for distributed abnormal event detection in backbone networks	unsupervised learning;supervised learning;backbone networks;anomaly detection;network data mining;journal;期刊论文;distributed correlated abnormal event	Detecting distributed abnormal events has become an increasingly significant task for efficient network management and operation. However, it is still challenging to uncover these distributed behaviors in backbone networks because of the voluminous amount of noisy, high-dimensional traffic data. In this paper, we present a novel system for detecting distributed abnormal events in backbone networks. The proposed system emphasizes on detecting distributed correlated abnormal events, which are caused by the same reason. In contrast, existing methods are not able to distinguish correlated abnormal events from the independent abnormal events. In our proposed system, a set of data mining techniques is used for modeling and detecting distributed correlated abnormal events by analyzing the traffic features. Specifically, traffic behavior representation is constructed to define and select traffic features for describing the traffic behaviors of interest, feature clustering is performed to group together similar transformations in each feature, behavioral data mining is employed to discover the most significant patterns in network interactions with respect to typical behavior, and behavior classification is used to expose the behaviors of interest. Experiment results using real traffic data present the effectiveness of our proposed methods for detecting distributed correlated abnormal events in the backbone network. Copyright © 2013 John Wiley & Sons, Ltd.	cluster analysis;data mining;entity–relationship model;holographic principle;interaction;internet backbone;john d. wiley;sensor	Yingjie Zhou;Guangmin Hu;Dapeng Wu	2014	Security and Communication Networks	10.1002/sec.801	unsupervised learning;anomaly detection;computer science;data science;machine learning;data mining;supervised learning	ML	-12.089452545923725	-31.827408064641126	95299
6b1d8f1a94c1a774c96a2b15edcb36e1d306cab2	accurate traffic matrix completion based on multi-gaussian models	network measurement;traffic matrix;compressive sensing;matrix completion;multi-gaussian models	Traffic matrix (TM) describes the volumes of traffic between a set of sources and destinations in a network. As an important parameter, TMs are used in a variety of network engineering tasks, such as traffic engineering, capacity planning and anomaly detection. However, it is a challenge to reliably measure TMs in practice. For example, due to flaws in the measurement systems and possible failure in data collection systems, missing values are unavoidable. It is important to recover the missing data from the partial direct measurements. Existing matrix completion methods do not fully consider network traffic behavior and traffic hidden characteristic. Their completion accuracy tends to be significantly worse when the data loss rate is high. In this paper, we perform a study on intrinsic characteristics of network traffic by analyzing real-world traffic trace data, which reveals that traffic has the features of temporal stability and spatial affinity. According to traffic spatial feature, we model TM as multi-Gaussian distributions, which describes the actual network traffic more accurately. Furthermore, we propose a novel matrix completion method based on multi-Gaussian models to estimate the missing traffic data. Finally, we utilize traffic temporal characteristic to further optimize traffic matrix completion for the missing data interpolation. Our proposed approach has been evaluated utilizing real-world traffic trace data. The extensive experiments demonstrate that our method achieves significantly better performance compared with the state-of-the-art interpolation methods.		Huibin Zhou;Dafang Zhang;Kun Xie	2017	Computer Communications	10.1016/j.comcom.2016.11.011	traffic generation model;simulation;computer science;machine learning;data mining	Metrics	-14.643691694551137	-33.622962384751204	95325
a804ac67d7e79a235eec81a23db35d967ab7887d	top (k1, k2) distance-based outliers detection in an uncertain dataset	social network services;probability;probability big data dynamic programming;semantics;acceleration;uncertain dataset big data data objects pruning strategies approximate outliers detection local neighbor region dynamic programming technique top k 1 k 2 distance based outlier detection top k 1 probability tuple outlier score world semantics x tuple model social network;mathematical model;algorithm design and analysis probability social network services semantics data models acceleration mathematical model;algorithm design and analysis;data models	In this paper, we focus on distance-based outliers detection in an uncertain dataset, which is very useful in large social network. Based on the x-tuple model and the possible world semantics, we propose the concept of tuple outlier score, top k1 probability and top (k1, k2) distance-based outlier. We then design an algorithm using dynamic programming technique to calculate tuple outlier scores and detect top (k1, k2) distance-based outliers. The local neighbor region is proposed to detect approximate outliers with high precision efficiently. We also propose two pruning strategies to avoid additional computation overhead and prune data objects that cannot be outliers. After theory analysis, we conduct experiments in two real datasets to verify good performance of our method.	approximation algorithm;computation;dynamic programming;experiment;overhead (computing);possible world;social network;uncertain data	Fei Liu;Yan Jia	2015	2015 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2015.7364018	computer science;machine learning;pattern recognition;data mining	DB	-7.192053625398991	-36.57011606569897	95444
177f749a62cdbba64533413802f61a5ed368540e	improving the performance of identifying contributors for xml keyword search	xml database;keyword search;indexation	Keyword search is a friendly mechanism for users to identify desired information in XML databases, and LCA is a popular concept for locating the meaningful subtrees corresponding to query keywords. Among all the LCA-based approaches, MaxMatch [9] is the only one which could achieve the property of monotonicity and consistency, by outputting only contributors instead of the whole subtree. Although the MaxMatch algorithm performs efficiently in some cases, there is still room for improvement. In this paper, we first propose to improve its performance by avoiding unnecessary index accesses. We then speed up the process of subset detection, which is a core procedure for determining contributors. The resultant algorithm is called MinMap and MinMap+, respectively. At last, we analytically and empirically demonstrate the efficiency of our methods. According to our experiments, our two algorithms work better than the existing one, and MinMap+ is particularly helpful when the breadth of the tree is large and the number of keywords grows.	computation;experiment;resultant;search algorithm;speedup;tree (data structure);xml database	Rung-Ren Lin;Ya-Hui Chang;Kun-Mao Chao	2011	SIGMOD Record	10.1145/2007206.2007208	computer science;data mining;xml database;database;keyword density;information retrieval	Web+IR	-6.346775315086624	-37.61294809137505	95548
f11b91c70e78b8bf2f9808dfe26264029a27aba7	getting off the goldvarb standard: introducing rbrul for mixed‐effects variable rule analysis	linguistic variable;data analysis;mixed effects	The variable rule program is one of the predominant data analysis tools used in sociolinguistics, employed successfully for over three decades to quantitatively assess the influence of multiple factors on linguistic variables. However, its most popular current version, GoldVarb, lacks flexibility and also isolates its users from the wider community of quantitative linguists. A new version of the variable rule program, Rbrul, attempts to resolve these concerns, and with mixed-effects modelling also addresses a more serious problem whereby GoldVarb overestimates the significance of effects. Rbrul’s superior performance is demonstrated on both simulated and real data sets.	simulation	Daniel Ezra Johnson	2009	Language and Linguistics Compass	10.1111/j.1749-818X.2008.00108.x	psychology;computer science;artificial intelligence;data mining;data analysis;algorithm	ML	-6.414238917518797	-29.117783813442504	95551
3b0cedffc02fbcfddebf6ca7bbe8915c3013d1c5	the segment support map: scalable mining of frequent itemsets	data mining;frequent itemset;association rule;frequent sets;scalable data mining	Since its introduction, frequent set mining has been generalized to many forms, including online mining with Carma, and constrained mining with CAP. Regardless, scalability is always an important aspect of the development. In this paper, we propose a novel structure called segment support map to help mining of frequent itemsets of the various forms. A light-weight structure, the segment support map improves the performance of frequent-set mining algorithms by: (i) obtaining sharper bounds on the support of itemsets, and/or (ii) better exploiting properties of constraints. Our experimental results show the effectiveness of the segment support map.	algorithm;scalability	Laks V. S. Lakshmanan;Carson Kai-Sang Leung;Raymond T. Ng	2000	SIGKDD Explorations	10.1145/380995.381005	association rule learning;computer science;data mining	ML	-5.977931223538572	-37.84745523109999	95567
e767ff92df4f72d06e0f79e3ee3ddc4f2220cb5c	an accurate model for hurricane trajectory prediction		Hurricanes have caused billions of dollars' worth of damage due to property destruction, personal danger, and civil unrest. This catastrophic impact of hurricanes has motivated extensive research in hurricane forecasting, within which is the subfield of hurricane trajectory prediction. Traditionally, meteorological analysis was used in determining the future path of a given hurricane. In this paper, we present an alternative approach. Specifically, we measure realistic hurricane trajectories by their haversine distances. We train our prediction model exclusively with data from years 1950 to 2000. Moreover, we weigh the training data to favor recent hurricane trends when determining a trajectory prediction. Evaluation results show that our model led to a prediction-correctness ratio up to 10.0% higher than the current state-of-the-art, which is at 75.0%.	association rule learning;best, worst and average case;correctness (computer science);data mining;hilbert's tenth problem;unrest	Taylor S. Cox;Calvin S. H. Hoi;Carson Kai-Sang Leung;Caden R. Marofke	2018	2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)	10.1109/COMPSAC.2018.10290	real-time computing;simulation;data modeling;training set;trajectory;computer science;haversine formula;unrest	DB	-17.828646717133633	-24.98379202796387	95662
8213c4a0b8a75dcb96d19db83903d233bb3300a8	construction equipment activity recognition for simulation input modeling using mobile sensors and machine learning classifiers	big data analytics;construction equipment action recognition;supervised machine learning;data driven simulation;smartphone sensors;accelerometer	Although activity recognition is an emerging general area of research in computer science, its potential in construction engineering and management (CEM) domain has not yet been fully investigated. Due to the complex and dynamic nature of many construction and infrastructure projects, the ability to detect and classify key activities performed in the field by various equipment and human crew can improve the quality and reliability of project decision-making and control. In particular to simulation modeling, process-level knowledge obtained as a result of activity recognition can help verify and update the input parameters of simulation models. Such input parameters include but are not limited to activity durations and precedence, resource flows, and site layout. The goal of this research is to investigate the prospect of using built-in smartphone sensors as ubiquitous multi-modal data collection and transmission nodes in order to detect detailed construction equipment activities which can ultimately contribute to the process of simulation input modeling. A case study of front-end loader activity recognition is presented to describe the methodology for action recognition and evaluate the performance of the developed system. In the designed methodology, certain key features are extracted from the collected data using accelerometer and gyroscope sensors, and a subset of the extracted features is used to train supervised machine learning classifiers. In doing so, several important technical details such as selection of discriminating features to extract, sensitivity analysis of data segmentation window size, and choice of the classifier to be trained are investigated. It is shown that the choice of the level of detail (LoD) in describing equipment actions (classes) is an important factor with major impact on the classification performance. Results also indicate that although decreasing the number of classes generally improves the classification output, considering other factors such as actions to be combined as a single activity, methodologies to extract knowledge from classified activities, computational efficiency, and end use of the classification process may as well influence one's decision in selecting an optimal LoD in describing equipment activities (classes).	activity recognition;algorithm;angularjs;canonical account;confusion matrix;contingency (philosophy);data point;electronic signature;ensemble learning;futures studies;gyroscope;machine learning;modal logic;oversampling;sampling (signal processing);sensor;simulation;smartphone;statistical classification;velocity (software development);window function	Reza Akhavian;Amir H. Behzadan	2015	Advanced Engineering Informatics	10.1016/j.aei.2015.03.001	simulation;big data;computer science;engineering;artificial intelligence;machine learning;data mining;accelerometer;statistics	HCI	-10.635444801015169	-30.352799308774788	95845
096d6bfd73cd9114181da561fa019b70ebb07a4d	shape reconstruction of meshed smooth surfaces equipped with inertial sensors. (reconstruction de surfaces lisses maillées à partir de capteurs inertiels)			sensor	Tibor Stanko	2017				Vision	-8.97308859557132	-28.03681384845156	96295
eef42d623c76377769a083bffbc30810421fd07e	hybrid temporal mining for finding out frequent itemsets in temporal databases using clustering and bit vector methods		Hybrid Temporal Pattern Mining was designed to address the problem of discovering frequent patterns of point and interval-based events or both and it is essential in many applications, including market analysis, decision support and business management. Such methodology cannot deal with Clustering, Bit Vector and Variable Threshold. In this paper, we propose a new algorithm called RHTPM (Revised Hybrid Temporal Pattern Mining) to find the frequent temporal pattern based on Clustering, Bit Vector and Variable Threshold. The experiments demonstrate that the proposed algorithm is capable of mining frequent hybrid temporal pattern for effective decision making and has been proved to be significantly good.	algorithm;bit array;cluster analysis;computation;dspace;data mining;decision support system;experiment	M. Krishnamurthy;Arputharaj Kannan;Ramachandran Baskaran;G. Bhuvaneswari	2011		10.1007/978-3-642-19423-8_26	decision support system;temporal database;cluster analysis;artificial intelligence;market analysis;bit array;pattern recognition;computer science	ML	-4.957307150379647	-36.82767253936631	96646
ccc93e61effd518982b83516b78682428a2f9a8c	exploring the urban region-of-interest through the analysis of online map search queries		Urban Region-of-Interest (ROI) refers to the integrated urban areas with specific functionalities that attract people's attentions and activities, such as the recreational business districts, transportation hubs, and city landmarks. Indeed, at the macro level, ROI is one of the representatives for agglomeration economies, and plays an important role in urban business planning. At the micro level, ROI provides a useful venue for understanding the urban lives, demands and mobilities of people. However, due to the vague and diversified nature of ROI, it still lacks of quantitative ways to investigate ROIs in a holistic manner. To this end, in this paper we propose a systematic study on ROI analysis through mining the large-scale online map query logs, which provides a new data-driven research paradigm for ROI detection and profiling. Specifically, we first divide the urban area into small region grids, and calculate their PageRank value as visiting popularity based on the transition information extracted from map queries. Then, we propose a density-based clustering method for merging neighboring region grids with high popularity into integrated ROIs. After that, to further explore the profiles of different ROIs, we develop a spatial-temporal latent factor model URPTM (Urban Roi Profiling Topic Model) to identify the latent travel patterns and Point-of-Interest (POI) demands of ROI visitors. Finally, we implement extensive experiments to empirically evaluate our approaches based on the large-scale real-world data collected from Beijing. Indeed, by visualizing the results obtained from URPTM, we can successfully obtain many meaningful travel patterns and interesting discoveries on urban lives.	cluster analysis;experiment;holism;pagerank;point of interest;profiling (computer programming);programming paradigm;region of interest;topic model;vagueness;venue (sound system);web mapping	Ying Sun;Hengshu Zhu;Fuzhen Zhuang;Jingjing Gu;Qing He	2018		10.1145/3219819.3220009	computer science;data mining;topic model;region of interest;cluster analysis;pagerank;multi-task learning;popularity;economies of agglomeration;urban area	ML	-18.94533358730256	-35.11912396783327	96683
ee0be626463ccabca505f0e20d4268131d9d6d30	[regular paper] mechanical testing methods for body-powered upper-limb prostheses: a review		New manufacturing and rapid prototyping technologies have fueled the creation of affordable and easy to replicate upper-limb prostheses. In this matter, many types and designs of 3D-printed upper-limb prostheses have been created over the last years. However, there is no consensus in the testing methodology for these devices regarding their mechanical capabilities and the comparisons authors can make are limited to their own metrics, which could be considered as a subjective approach. In order to tackle this issue, this work revises the existing methods for testing both the mechanical resistance and the mechanical performance or efficiency of upper-limb prostheses; specifically, the ones that are relevant for 3D-printed body-powered prostheses. Then, the adaptations needed to apply these methods to 3D-printed prostheses are discussed. Finally, recommendations are given for prosthetists and researchers in order to execute reliable tests that can be compared across different hand prosthesis designs.		Renato Mio;Midori Sanchez;Quino Valverde	2018	2018 IEEE 18th International Conference on Bioinformatics and Bioengineering (BIBE)	10.1109/BIBE.2018.00040	reliability engineering;replicate;machine learning;artificial intelligence;computer science;hand prosthesis;3d printing;rapid prototyping;benchmark (computing)	Robotics	-9.163134911614707	-26.757271533172265	97007
bde8d44d7f05bba4b398b78cb0283b1bd4d6718a	intrusion alert prediction using a hidden markov model		Intrusion detection is only a starting step in securing IT infrastructure. Prediction of intrusions is the next step to provide an active defense against incoming attacks. Current intrusion prediction methods focus mainly on prediction of either intrusion type or intrusion category and do not use or provide contextual information such as source and target IP address. In addition most of them are dependant on domain knowledge and specific scenario knowledge. The proposed algorithm employs a bag-of-words model together with a hidden Markov model which not depend on specific domain knowledge. Since this algorithm depends on a training process it is adaptable to different conditions. A key advantage of the proposed algorithm is the inclusion of contextual data such as source IP address, destination IP range, alert type and alert category in its prediction, which is crucial for an eventual response. Experiments conducted using a public data set generated over 2500 alert predictions and achieved accuracy of 81% and 77% for single step and five step predictions respectively for prediction of the next alert cluster. It also achieved an accuracy of prediction of 95% and 92% for single step and five step predictions respectively for prediction of the next alert category. The proposed methods achieved a prediction accuracy improvement of 5% for alert category over existing variable length Markov chain intrusion prediction methods, while providing more information for a possible defense.	algorithm;bag-of-words model;cpu cache;cluster analysis;emoticon;experiment;hidden markov model;ipv4 subnetting reference;information privacy;internet protocol suite;intrusion detection system;markov chain;snort;state transition table;test set	Udaya Sampath K. Perera Miriya Thanthrige;Jagath Samarabandu;Xianbin Wang	2016	CoRR		computer science;machine learning;data mining;computer security	ML	-13.806366550713486	-34.296084537986616	97142
2ecd50af06afebdd4dc08a5a30ae07a3ec4a1f89	load shedding for temporal queries over data streams	load shedding;data streams;algorithms;temporal query processing	Enhancing continuous queries over data streams with temporal functions and predicates enriches the expressive power of those queries. While traditional continuous queries retrieve only the values of attributes, temporal continuous queries retrieve the valid time intervals of those values as well. Correctly evaluating such queries requires the coalescing of adjacent timestamps for value-equivalent tuples prior to evaluating temporal functions and predicates. For many stream applications, the available computing resources may be too limited to produce exact query results. These limitations are commonly addressed through load shedding and produce approximated query results. There have been many load shedding mechanisms proposed so far, but for temporal continuous queries, the presence of coalescing makes theses existing methods unsuitable. In this paper, we propose a new accuracy metric and load shedding algorithm that are suitable for temporal query processing when memory is insufficient. The accuracy metric uses a combination of the Jaccard coefficient to measure the accuracy of attribute values and PQI interval orders to measure the accuracy of the valid time intervals in the approximate query result. The algorithm employs a greedy strategy combining two objectives reflecting the two accuracy metrics (i.e., value and interval). In the performance study, the proposed greedy algorithm outperforms a conventional random load shedding algorithm by up to an order of magnitude in its achieved accuracy. Categories: Ubiquitous computing	approximation algorithm;baseline (configuration management);central processing unit;coefficient;dspace;database;greedy algorithm;jaccard index;load shedding;polynomial;query optimization;semantic similarity;snapshot (computer storage);time complexity;ubiquitous computing;valid time	Mohammed Al-Kateb;Byung Suk Lee	2011	JCSE	10.5626/JCSE.2011.5.4.294	computer science;theoretical computer science;data mining;database	DB	-8.606752039825327	-35.802859861730475	97383
d7fc89f61ab074a2cc44d36fdb921aac7c0cf8b7	real-time continuous feature extraction in large size satellite images	image processing;feature extraction;remote sensing	Real-time continuous feature extraction.Remote sensing.Image processing.Satellite image. Remotely sensed imagery is being increasingly used for the development of the earth observation satellites to investigate human activities, to monitor environmental changes and to update existing geospatial data. The ordinary pictures are difficult to process automatically by computers but can be easily interpreted by humans. The most significant step is how to get anticipated information from the images and how to convert these images into useful data for further studies. The key objective is to satisfy an algorithm claiming to be efficient in large size image processing includ enhanced processing efficiency, finding correlation among data, and extracting continuous features. To achieve these objectives in the setting mentioned above, we propose a real-time approach for continuous feature extraction and detection in remote sensory earth observatory satellite images to find rivers, roads, and main highways. Deep analysis is made on the ENVISAT satellite missions datasets and based on this analysis the algorithm is proposed using statistical measurements, RepTree machine learning classifier, and Euclidean distance. The system is developed using Hadoop ecosystem to improve the efficiency of the system. The designed system consists of various steps including collection, filtration, load balancing, processing, merging, and interpretation. The system is implemented on Apache Hadoop system using MapReduce programming with higher efficiency results in a massive volume of satellite ASAR/ ENVISAT mission datasets.	feature extraction;real-time clock	M. Mazhar Rathore;Awais Ahmad;Anand Paul;Jiaji Wu	2016	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2015.11.006	computer vision;image processing;feature extraction;computer science;data mining	EDA	-13.140139735708132	-27.955579445672686	97672
c05299bf97699ba3daaa9b24cb793365fc45f42f	decentralized recommender systems.		This paper proposes a decentralized recommender system by formulating the popular collaborative filleting (CF) model into a decentralized matrix completion form over a set of users. In such a way, data storages and computations are fully distributed. Each user could exchange limited information with its local neighborhood, and thus it avoids the centralized fusion. Advantages of the proposed system include a protection on user privacy, as well as better scalability and robustness. We compare our proposed algorithm with several state-of-the-art algorithms on the FlickerUserFavor dataset, and demonstrate that the decentralized algorithm can gain a competitive performance to others.	algorithm;centralized computing;computation;recommender system;scalability	Zhangyang Wang;Xianming Liu;Shiyu Chang;Jiayu Zhou;Guo-Jun Qi;Thomas S. Huang	2015	CoRR		data mining;matrix completion;recommender system;robustness (computer science);computer science;computation;scalability;distributed computing	ML	-8.786346426434344	-29.1688904831941	97709
d7137b63e4b7a7ba4895c8b80e56d807e84b23e6	publishing spatial histograms under differential privacy		Studying trajectories of individuals has received growing interest. The aggregated movement behaviour of people provides important insights about their habits, interests, and lifestyles. Understanding and utilizing trajectory data is a crucial part of many applications such as location based services, urban planning, and traffic monitoring systems. Spatial histograms and spatial range queries are key components in such applications to efficiently store and answer queries on trajectory data. A spatial histogram maintains the sequentiality of location points in a trajectory by a strong sequential dependency among histogram cells. This dependency is an essential property in answering spatial range queries. However, the trajectories of individuals are unique and even aggregating them in spatial histograms cannot completely ensure an individualu0027s privacy. A key technique to ensure privacy for data publishing ϵ -differential privacy as it provides a strong guarantee on an individualu0027s provided data. Our work is the first that guarantees ϵ -differential privacy for spatial histograms on trajectories, while ensuring the sequentiality of trajectory data, i.e., its consistency. Consistency is key for any database and our proposed mechanism, PriSH , synthesizes a spatial histogram and ensures the consistency of published histogram with respect to the strong dependency constraint. In extensive experiments on real and synthetic datasets, we show that (1) PriSH is highly scalable with the dataset size and granularity of the space decomposition, (2) the distribution of aggregate trajectory information in the synthesized histogram accurately preserves the distribution of original histogram, and (3) the output has high accuracy in answering arbitrary spatial range queries.	aggregate data;approximation error;best, worst and average case;differential privacy;emoticon;essence;experiment;heuristic;image scaling;kullback–leibler divergence;location-based service;range query (data structures);scalability;social inequality;spatial reference system;synthetic intelligence;website monitoring	Soheila Ghane;Lars Kulik;Kotagiri Ramamohanarao	2018		10.1145/3221269.3223039	data mining;scalability;data publishing;computer science;differential privacy;histogram;range query (data structures);granularity;location-based service;trajectory	DB	-16.51571211268342	-36.041552556376864	97801
5b8935afdef3d5fb01a6547031eb7a283f5587c9	a semantic similarity measure for objects described with multi-valued categorical attributes			semantic similarity;similarity measure	Antonio Moreno;Aïda Valls;Ferran Mata;Sergio Martínez;Lucas Marin;Carlos Vicient	2013		10.3233/978-1-61499-320-9-263	semantic similarity;categorical variable;pattern recognition;artificial intelligence;computer science	DB	-4.958777043127571	-26.318116099669236	97900
c38dfacff27afe25bc822d60f6df2ff372ee9425	using the golden rule of sampling for query estimation	database system;query estimation;range query;approximation error;random sampling;query optimization;cumulative frequency distribution;a priori knowledge;sampling technique;cumulant;frequency domain	Query size estimation is crucial for many database system components. In particular, query optimizers need efficient and accurate query size estimation when deciding among alternative query plans. In this paper we propose a novel sampling technique based on the golden rule of sampling, introduced by von Neumann in 1947, for estimating range queries. The proposed technique randomly samples the frequency domain using the cumulative frequency distribution and yields good estimates without any a priori knowledge of the actual underlying distribution of spatial objects. We show experimentally that the proposed sampling technique gives smaller approximation error than the Min-Skew histogram based and wavelet based approaches for both synthetic and real datasets. Moreover, the proposed technique can be easily extended for higher dimensional datasets.	approximation error;database;experiment;randomness;range query (data structures);sampling (signal processing);synthetic intelligence;wavelet	Yi-Leh Wu;Divyakant Agrawal;Amr El Abbadi	2001		10.1145/375663.375724	online aggregation;sampling;query optimization;pattern recognition;data mining;database	DB	-7.76513097168327	-33.42435008950418	98168
6d9643b0e940dc2f19821c553913ce9bfb6f9663	trajectory event cleaning for mobile rfid objects	trajectory events;computational cost reduction radio frequency identification readers mobile rfid object location uncertainty trajectory event noise cleaning moving object trajectory data mining missing detection event cross detection event false detection event neighboring physical region unified cleaning framework probabilistic region connection graph adjacent detection region transition probability interpolating missing event path based probabilistic interpolating strategy most likely path strategy mlp strategy highest weighting probability path strategy hwpp strategy candidate paths;data cleaning mobile objects rfid trajectory events;rfid;radiofrequency identification cost reduction data communication data mining interference suppression interpolation mobile radio probability;data cleaning;trajectory interpolation cleaning radiofrequency identification mobile communication probabilistic logic image edge detection;mobile objects	With the rapid development of Radio Frequency Identification (RFID), sensor and wireless technologies, a large amount of trajectory data of moving objects are emerging, and trajectory data mining has received more and more attentions recently. However, since the data collected by sensors and RFID readers are usually noisy, it is necessary and meaningful to clean up the noise, including missing detection events and cross detection events, so as to provide high quality data for various applications using trajectory data. Cleaning up the trajectory events should take into account of uncertainty of location and unreliability of event detection at the same time. In the paper, we first discuss the rules to distinguish between normal detection events and false detection events in the trajectories, using constraints on continuous motion between adjacent detection regions and direct moving time between neighboring physical regions. Then, as a unified cleaning framework, we establish a probabilistic region connection graph to represent region detection features, region connection relationships, and region transition probabilities of neighboring physical regions. Focusing on interpolating missing events, we suggest two path-based probabilistic interpolating strategies, namely, the Most Likely Path (MLP) strategy and the Highest Weighting Probability Path (HWPP) strategy. Also, we discuss pruning rules of candidate paths for reducing computational cost. Finally, we conduct experiments over simulation data to demonstrate the effectiveness and efficiency of the proposed methods.	algorithmic efficiency;data mining;display resolution;experiment;factor graph;interpolation;markov chain;memory-level parallelism;mobile rfid;plasma cleaning;radio frequency;radio-frequency identification;sensor;simulation;sputter cleaning	Guoqiong Liao;Philip S. Yu;Qianhui Zhong;Sihong Xie;Zhen Shen;Changxuan Wan;Dexi Liu	2014	2014 IEEE 15th International Conference on Mobile Data Management	10.1109/MDM.2014.23	radio-frequency identification;computer vision;computer science;machine learning;data mining;database	DB	-15.758691778460042	-35.29901372204089	98196
75a905ed55bcb769e939eeeed2c3809999be6b1f	the augmented itemset tree: a data structure for online maximum frequent pattern mining	maximal frequent itemsets;incremental pattern mining	This paper introduces an approach for incremental maximal frequent pattern (MFP) mining in sparse binary data, where instances are observed one by one. For this purpose, we propose the Augmented Itemset Tree (AIST), a data structure that incorporates features of the FP-tree into the itemset tree. In the given setting, we assume that just the data structure is maintained in main memory, and each instance is observed only once. The AIST not only stores observed frequent patterns, but also allows for quick frequency updates of relevant subpatterns. In order to quickly identify the current set of exact MFPs, potential candidates are extracted from former MFPs and patterns that occur in the new instance. The presented approach is evaluated concerning the runtime and memory requirements depending on the number of instances, minimum support and different settings of pattern properties. The obtained results suggest that AISTs are useful for mining maximal frequent itemsets in an online setting whenever larger patterns can be expected.	data mining;data structure	Jana Schmidt;Stefan Kramer	2011		10.1007/978-3-642-24477-3_23	computer science;machine learning;pattern recognition;data mining;mathematics	ML	-6.063720378018028	-36.926534061267986	98377
c6dac8cbcc7b46959e9867740e25f6dc0a439cb5	crashzam: sound-based car crash detection		Connected vehicles, combined with embedded smart computation capabilities, will certainly lead to a new generation of services and opportunities for drivers, car manufacturers, insurance and service companies. One of the main challenges remaining in this field is how to detect key triggering events. One of these crucial moments is a car accident, for which not only smart connected vehicles can improve drivers’ safety as car accidents are still one of the main causes of fatalities worldwide, but also help them during minor, but very stressful moments. In this paper, we present Crashzam which is an innovative way to detect any type car accidents based on sound produced by car impact, while, so far, crash detection is only a prerogative of accelerometer sensor time series analysis, or its proxy: activation of the airbag. We describe the system design, the sound detection model, and the results based on a dataset with in-car cabin sounds of real crashes. We have beforehand built such dataset with real car accident sounds. Classification is built upon features extracted from the time and frequency domain of the audio signal and from its spectrogram image. Results show that the proposed model is able to easily identify crash sounds from other sounds reproduced in-car cabins. Moreover, considering that Crashzam can run on smartphones, it is a low cost and energy solution, contributing to the spreading of such a car safety feature and reducing delays in providing assistance when an	computation;embedded system;proxy server;smart tv;smartphone;spectrogram;systems design;time series	Matteo Sammarco;Marcin Detyniecki	2018		10.5220/0006629200270035	automotive engineering;crash;computer science	Mobile	-15.936360834068317	-29.225455465852498	98545
9689045607077a859240774fa93584da9d4f14ef	efficient compression and indexing of trajectories		We present a new compressed representation of free trajectories of moving objects. It combines a partial-sums-based structure that retrieves in constant time the position of the object at any instant, with a hierarchical minimum-bounding-boxes representation that allows determining if the object is seen in a certain rectangular area during a time period. Combined with spatial snapshots at regular intervals, the representation is shown to outperform classical ones by orders of magnitude in space, and also to outperform previous compressed representations in time performance, when using the same amount of space.	time complexity	Nieves R. Brisaboa;Travis Gagie;Adrián Gómez-Brandón;Gonzalo Navarro;José R. Paramá	2017		10.1007/978-3-319-67428-5_10	snapshot (computer storage);combinatorics;discrete mathematics;mathematics;theoretical computer science;search engine indexing;compression (physics);instant	DB	-8.444852144820159	-37.73465456692779	98550
e57191c60be8c2555de20a02acdef72cc6fe804e	crowdsensing framework for monitoring bridge vibrations using moving smartphones		Cities are encountering extensive deficits in infrastructure service while they are experiencing rapid technological advancements and overhauls in transportation systems. Standard bridge evaluation methods rely on visual inspections, which are infrequent and subjective, ultimately affecting the structural assessments on which maintenance plans are based. The operational behavior of a bridge must be observed more regularly and over an extended period in order to sufficiently track its condition and avoid unexpected rehabilitation. Mobile sensor networks are conducive to monitoring bridges vibrations routinely, with benefits that have been demonstrated in recent structural health monitoring (SHM) research. Though smartphone accelerometers are imperfect sensors, they can contribute valuable information to SHM, especially when aggregated, e.g., via crowdsourcing. In an application on the Harvard Bridge (Boston, MA), it is shown that acceleration data collected using smartphones in moving vehicles contained consistent and significant indicators of the first three modal frequencies of the bridge. In particular, the results became more precise when informatics from several smartphone datasets were combined. This evidence is the first to support the hypothesis that smartphone data, collected within vehicles passing over a bridge, can be used to detect several modal frequencies of the bridge. The result defines an opportunity for local governments to make partnerships that encourage the collection of low-cost bridge vibration data, which can contribute to more effective management and informed decision-making.	crowdsensing;crowdsourcing;informatics;modal logic;sensor;smartphone;super high material cd	Thomas J. Matarazzo;Paolo Santi;Shamim N. Pakzad;Kristopher Carter;Carlo Ratti;Babak Moaveni;Chris Osgood;Nigel Jacob	2018	Proceedings of the IEEE	10.1109/JPROC.2018.2808759	wireless sensor network;building automation;simulation;structural health monitoring;accelerometer;public infrastructure;informatics;engineering;vibration;crowdsourcing	Mobile	-17.355376812851294	-26.377617987698887	98618
ebf19f11f8e0de0f6d4d5c95f0a8db71cf6f8948	aggregating and sampling methods for processing gps data streams for traffic state estimation	heuristic method aggregating methods sampling methods gps data streams traffic state estimation mobile devices sliding window sampling method;weighting;automated highways;traffic estimation;heuristic methods;global positioning system;mobile handsets automated highways global positioning system;data aggregation;statistical sampling;mobile handsets;global positioning system mobile communication sampling methods state estimation;traffic state estimation aggregating global positioning system gps data streams heuristic sampling time decay	Because of significant improvements in cost, accuracy, and coverage over dedicated traffic infrastructures, GPS-enabled mobile devices are preferred for continuous collection of traffic data. Estimating traffic states accurately from the obtained GPS data streams has great potential to increase efficiency of the existing traffic systems and to help reduce commuting time and fuel consumption. In this paper, first we propose a novel method to reasonably process GPS data by increasing weights of recent records and high velocity, rather than employing the current two extreme and popular approaches: the naive method aggregating all records with equal weights and the sliding-window (SW) sampling method preserving only the most recent records. Then, in line with the existing works, the proposed weighted approach is explored in two ways: aggregate-based and sampling-based ways. The aggregate-based way is classical but somewhat specific to the particular goal of traffic state estimation, whereas the sampling-based way is somewhat complicated but provides a universal set of samples for performing a variety of analyses. In the sampling-based way, a heuristic method is proposed to accurately estimate traffic states using preserved samples. Both ways are leveraged to evaluate performance of the novel weighed method and the heuristic method for estimating traffic states using samples. Finally, the feasibility and effectiveness of these methods is experimentally validated using a field-experiment data set (Mobile Century) and three simulated data sets.	aggregate data;experiment;global positioning system;heuristic;mobile device;sampling (signal processing);velocity (software development);window function	Jiadong Zhang;Jin S. Y. Xu;Stephen Shaoyi Liao	2013	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2013.2264753	data aggregator;sampling;real-time computing;simulation;global positioning system;engineering;data mining;weighting	DB	-16.4334392960822	-33.793973152362064	98646
31df7abaf13a66150ce8be9d73364cdf28f4c43c	inferring human mobility patterns from anonymized mobile communication usage	call detail records;data mining;human mobility;mobile computing	Anonymized Call Detail Records (CDRs) contain positional information of large populations and therefore have been extensively analyzed to understand human mobility. Due to the temporally sparse and spatially coarse nature of the data, most of these studies have focused on primitive aspects of movements such as travel distance and speed. Incorporating underlying geographic information in these analyses would allow analysts to put these movements into context and to gain deeper insight into how metropolitan areas function. In this paper, we present a set of procedures for inferring mobile users' mobility patterns while retaining the context of underlying geography. We apply these methods to our case study on New York City anonymized CDRs. We find that our methods verify current areal semantics and commuting rush-hour patterns, and we also derive further implications regarding geographic, demographic, and other effects on human mobility.	mobile phone;population;sparse matrix	Yuzuru Tanahashi;James R. Rowland;Stephen C. North;Kwan-Liu Ma	2012		10.1145/2428955.2428988	computer science;operating system;data mining;internet privacy;mobility model;mobile computing;world wide web;computer security	HCI	-18.979199086611782	-35.01894688951991	98655
74b8f37c2caeaf5ded90dceff12f0eaa4a81067c	modeling of vehicle driving conditions using transition probability models	dynamic programming;probability;transition probability;biological system modeling;vehicles acceleration cities and towns roads sparse matrices biological system modeling;acceleration;roads;transportation;transportation dynamic programming probability road vehicles;cities and towns;kl divergence vehicle driving conditions transition probability models dynamic optimization vehicle speed vehicle acceleration road grade experimental vehicle data analysis;vehicles;sparse matrices;dynamic optimization;road vehicles	This paper considers modeling of vehicle driving conditions using transition probability models (TPMs) for applications of dynamic optimization. The properties of transition probabilities for vehicle speed, vehicle acceleration, and road grade are discussed based on the analysis and experimental vehicle data. The KL-divergence is shown to provide an effective metric that can differentiate similar driving conditions from dissimilar ones.	dynamic programming;kullback–leibler divergence;markov chain;mathematical optimization	Kevin McDonough;Ilya V. Kolmanovsky;Dimitar Filev;Diana Yanakiev;Steven Szwabowski;John Michelini;Mahmoud Abou-Nasr	2011	2011 IEEE International Conference on Control Applications (CCA)	10.1109/CCA.2011.6044388	simulation;engineering;automotive engineering;transport engineering	Robotics	-13.556975145782456	-30.619814722489416	98876
80a855924fbb2205f7319033f51ad3c818e38f11	on the study of the geometric properties of historical cartographic representations	ptolemy cartography;keywords;heritage cartographique;approche optimale;mots cles;cartographie de ptolemee;cartographic heritage;portulan;optimal fitting;deformations cartographiques;portolan maps;map comparison;cartographic deformations;comparaison des cartes	Abstract The long but partial and still open question of the geometric and projective characteristics and properties of early cartographic representations is revisited in view of the advancements in digital analytical and visual technologies that are now offered in a “part and parcel” operational environment, allowing a level of interactivity almost unthinkable even in the recent past. In this new technology frame, the geometric study of early maps is treated analytically via a typical two-dimensional comparison with relevant modern map counterparts or georeference. By bringing in the early map with a one-to-one correspondence to its modern reference, the comparison retains all those proper transformational steps that result in the visualization of map differences and, thus, the study of the geometric and projective properties of early maps. To illustrate the proposed process, two indicative examples are treated, related to two distinct schematic typologies of early maps: (1) a georeferenced map of the Pt...		Evangelos Livieratos	2006	Cartographica	10.3138/RM86-3872-8942-61P4	geography;artificial intelligence;mathematics;cartographic generalization;cartography	Robotics	-9.50473313518266	-24.28155503344403	99125
a259c57646400bafab69fae79f7ef03c76743f79	urban water quality prediction based on multi-task multi-view learning		Urban water quality is of great importance to our daily lives. Prediction of urban water quality help control water pollution and protect human health. In this work, we forecast the water quality of a station over the next few hours, using a multitask multi-view learning method to fuse multiple datasets from different domains. In particular, our learning model comprises two alignments. The first alignment is the spaio-temporal view alignment, which combines local spatial and temporal information of each station. The second alignment is the prediction alignment among stations, which captures their spatial correlations and performs copredictions by incorporating these correlations. Extensive experiments on real-world datasets demonstrate the effectiveness of our approach.	computer multitasking;experiment;sequence alignment	Ye Liu;Yu Zheng;Yuxuan Liang;Shuming Liu;David S. Rosenblum	2016			artificial intelligence;machine learning;computer science;data mining;water quality	AI	-15.652379437289973	-32.21611042260338	99178
b635a4158b45d18c88a52241e7f8a2304bb9e15b	determining the criteria for setting input parameters of the fuzzy inference model of p&r car parks locating		The paper presents the fuzzy inference model of evaluation of Pu0026R facilities location. In such a system there are car parks where travellers can change from car to public transport. Recognising proper locations of the Pu0026R facilities is a key aspect for the system. On the basis of previous studies it was found that developing algorithms supporting the determination of input parameters to the model is necessary. The authors created recurrent algorithm for determining the parameter of the road quality. For the parameters of quantity of public transport means and the distance to the city centre the algorithm based on the exponential function was made. For determining the parameter describing the connection to the main road the fuzzy inference model was built. Thanks to the developed methodology the model of Pu0026R locating has become more universal and possible to use for a broader group of experts.		Michal Lower;Anna Lower	2016		10.1007/978-3-319-45243-2_22	machine learning;data mining	NLP	-9.3373134993247	-24.71050436250176	99418
a86e44d8cf147c526965b5f548733d99eb3a5854	a life cycle impact assessment method based on the multi-environmental spatial dimension	space characteristic coefficient;environmental impact;life cycle;life cycle impact assessment lcia;multi environmental spatial dimension;impact categories;life cycle impact assessment;indexation;environmental science;life cycle assessment	As the most important and controversial phase of life cycle assessment, life cycle impact assessment (LCIA) has drawn the most attention. How to reflect the spatial characteristics of environmental impacts have become a significant problem, which is urgently needed to be solved to improve the transparency and the reliability of LCIA, especially for the distinct diversity of environments in China. Based on the multi-environmental spatial dimension, this paper proposes a new LCIA method under the framework of ISO14040. First, pollutants released or materials consumed in the life cycle of a product are related to spatial characteristics in order to reflect the diversity of the regional environment. The calculation method of the space characteristic coefficient is presented by analysing the endurance capacity of the regional environment and environmental standards. Second, midpoint and endpoint categories are combined and their relationships are discussed according to the environmental mechanism. Third, norma...		Xiaowei Wang;Fangyi Li;Jianfeng Li;Liming Wang	2014	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2012.665181	biological life cycle;operations management;operations research;environmental impact assessment	EDA	-11.831572320729817	-24.437701868066405	100009
d2be22e50067b6ac13ccbafb3f7ece2a96988c9d	inverted index compression and query processing with optimized document ordering	search engine;web pages;query processing;inverted index;search engines;index compression;web search engine;document ordering;ir query processing;indexation	Web search engines use highly optimized compression schemes to decrease inverted index size and improve query throughput, and many index compression techniques have been studied in the literature. One approach taken by several recent studies first performs a renumbering of the document IDs in the collection that groups similar documents together, and then applies standard compression techniques. It is known that this can significantly improve index compression compared to a random document ordering. We study index compression and query processing techniques for such reordered indexes. Previous work has focused on determining the best possible ordering of documents. In contrast, we assume that such an ordering is already given, and focus on how to optimize compression methods and query processing for this case. We perform an extensive study of compression techniques for document IDs and present new optimizations of existing techniques which can achieve significant improvement in both compression and decompression performances. We also propose and evaluate techniques for compressing frequency values for this case. Finally, we study the effect of this approach on query processing performance. Our experiments show very significant improvements in index size and query processing speed on the TREC GOV2 collection of 25.2 million web pages.	data compression;database;experiment;index register;inverted index;performance;query optimization;query throughput;text retrieval conference;web page;web search engine	Hao Yan;Shuai Ding;Torsten Suel	2009		10.1145/1526709.1526764	sargable;query optimization;query expansion;web query classification;inverted index;web search engine;computer science;database;web search query;world wide web;information retrieval;search engine	Web+IR	-15.754605131901736	-37.463952692188144	100132
f0edc4346b5a8c47da5a5d9707112550035d6cbf	exploration of complex growth mechanics of city traffic jam for the adaptive signal control			jam	Kouhei Hamaoka;Mitsuo Wada	2006			simulation;computer science	ML	-16.176899073591052	-26.055624204569245	100727
c6713ad584bf297f90d4e5dfe682178ca65263f0	intelligent tecnology of information analysis and quantitative evaluation of condition with preliminary and inaccurate data of current observations		The article presents an approach to design of data processing systems of ecological monitoring based on modern information technologies: data mining, genetic algorithms and geoinformatics.	data mining;ecosystem;genetic algorithm;geoinformatics;relative change and difference;velocity (software development)	Yuri B. Savva	1999	The Computer Science Journal of Moldova		computer science;data science;data mining;management science	ML	-13.241466232730593	-27.18787463522603	101052
33853f08b4fe6abd13d3720adebbbc1ba148cadf	dynamic multidimensional histograms	nearest neighbor queries;spatio temporal databases;data stream;large data sets;query optimization;data distribution;dynamic data structure;data visualization;experimental evaluation;query answering;data structure	Histograms are a concise and flexible way to construct summary structures for large data sets. They have attracted a lot of attention in database research due to their utility in many areas, including query optimization, and approximate query answering. They are also a basic tool for data visualization and analysis.In this paper, we present a formal study of dynamic multidimensional histogram structures over continuous data streams. At the heart of our proposal is the use of a dynamic summary data structure (vastly different from a histogram) maintaining a succinct approximation of the data distribution of the underlying continuous stream. On demand, an accurate histogram is derived from this dynamic data structure. We propose algorithms for extracting such an accurate histogram and we analyze their behavior and tradeoffs. The proposed algorithms are able to provide approximate guarantees about the quality of the estimation of the histograms they extract.We complement our analytical results with a thorough experimental evaluation using real data sets.	approximation algorithm;data structure;data visualization;dynamic data;mathematical optimization;query optimization	Nitin Thaper;Sudipto Guha;Piotr Indyk;Nick Koudas	2002		10.1145/564691.564741	succinct data structure;query optimization;data structure;computer science;data mining;database;programming language;information retrieval;data visualization	DB	-8.0425188492956	-34.742197713928576	101111
415c3e6679d3b44972574adbe5c50d74f1cb43ae	poster abstract: measuring traffic in short-term construction work zones	construction work zones sensornet traffic measurement;design engineering;road traffic;intelligent transportation systems;magnetic sensors;construction work zones;construction industry;sensornet;traffic recording;urban areas;trajectory;monitoring;permission;traffic recording intelligent sensors road traffic;batteries;area measurement;urban area;vehicles;road transportation;monitoring intelligent sensors area measurement road transportation intelligent transportation systems costs permission educational institutions design engineering urban areas;intelligent sensors;traffic measurement	We describe the design of sensornet systems to measure traffic in short-term work zones in urban areas.		Manohar Bathula;Mehrdad Ramezanali;Ishu Pradhan;Nilesh Patel;Joe Gotschall;Nigamanth Sridhar	2009	2009 International Conference on Information Processing in Sensor Networks	10.1145/1602165.1602198	embedded system;intelligent transportation system;computer science;trajectory;intelligent sensor	Robotics	-18.589545945319525	-29.163298365459852	101214
22f73b19ada5bfd15acdc4a61f13eb060ea6df08	theory of spatial similarity relations and its applications in automated map generalization	automated map generalization;multi scale vector map databases;formulae;doctoral thesis;spatial similarity transformation;spatial similarity relations;multi scale map spaces;models		cartographic generalization	Haowen Yan	2014			combinatorics;discrete mathematics;machine learning;mathematics;cartographic generalization	ML	-5.387725252419095	-26.980499290968126	101217
672abf6ba8c59cd958dc99019be9948ab0b863fc	a novel method on incremental mining of spatial co-locations	data mining spatial databases algorithm design and analysis indexes atmospheric measurements particle measurements;atmospheric measurements;particle measurements;data mining;maximal prevalent patterns spatial data mining incremental mining of spatial co locations;spatial data mining;indexes;maximal prevalent patterns;spatial databases;incremental mining of spatial co locations;plant protection recommendations incremental mining spatial co locations pruning strategy geographic space plant distribution datasets plant geography phytosociology studies;algorithm design and analysis;geography data mining	Spatial co-locations represent the subsets of spatial features which are frequently located together in a geographic space. Discovering co-locations has many useful applications. For example, co-located plant species discovered from plant distribution datasets can contribute to the analysis of plant geography, phytosociology studies, and plant protection recommendations. This paper focuses on incremental mining of co-locations. Because of the speed of updated data and the difficulty of incremental mining of co-locations, incremental mining of co-locations should be given more attention. In this paper, a novel method of incremental mining is proposed, which begins with maximal prevalent co-locations in old database, to search the dividing line that partitions the prevalent and non-prevalent co-locations in updated database. For a co-location candidate, the new measure, updated participation ratio (index), is used to evaluate its prevalence in the updated database. This can be easily done by using the old co-location instances, querying the disappeared co-location instances, and generating the added co-location instances. Next, a pruning strategy can prune part of co-locations for improving the efficiency. At last, the experiments evaluate the efficiency of proposed methods.	experiment;maximal set;spatial reference system	Junli Lu;Lizhen Wang;Yuan Fang;Xuguang Bao	2016	2016 International Conference on Big Data and Smart Computing (BigComp)	10.1109/BIGCOMP.2016.7425803	geography;bioinformatics;data science;data mining;data stream mining	DB	-9.94335377460107	-36.2245413649532	101659
0e949feb60d96bec7ea1edfa42ad7d177f2e1d99	an introduction to duplicate detection	object matching;duplicate detection;etl;similarity measures;data cleaning;entity matching;data cleansing;data quality;record linkage	With the ever increasing volume of data, data quality problems abound. Multiple, yet different representations of the same real-world objects in data, duplicates, are one of the most intriguing data quality problems. The effects of such duplicates are detrimental; for instance, bank customers can obtain duplicate identities, inventory levels are monitored incorrectly, catalogs are mailed multiple times to the same household, etc. Automatically detecting duplicates is difficult: First, duplicate representations are usually not identical but slightly differ in their values. Second, in principle all pairs of records should be compared, which is infeasible for large volumes of data. This lecture examines closely the two main components to overcome these difficulties: (i) Similarity measures are used to automatically identify duplicates when comparing two records. Well-chosen similarity measures improve the effectiveness of duplicate detection. (ii) Algorithms are developed to perform on very large volumes of data in search for duplicates. Well-designed algorithms improve the efficiency of duplicate detection. Finally, we discuss methods to evaluate the success of duplicate detection.	algorithm;data quality;sensor	Felix Naumann;Melanie Herschel	2010		10.2200/S00262ED1V01Y201003DTM003	computer science;data mining;database;data cleansing;information retrieval	ML	-8.495986120316616	-36.70100334697861	101695
beb6a87d85eef949573e4372c886f6f1a82ace5e	pedestrian network map generation approaches and recommendation	collaborative mapping;image processing;location based social networking;map generation;pedestrian network	With the advanced capabilities of mobile devices and the success of car navigation systems, interest in pedestrian navigation systems is on the rise. A critical component of any navigation system is a map database, which represents a network e.g., road networks for car navigation and supports key functionality such as map display, geocoding, and routing. Road networks, mainly due to the popularity of car navigation systems, are well defined and publicly available. However, in pedestrian navigation systems, as well as other applications including urban planning and physical activity studies, road networks do not adequately represent the paths that pedestrians usually travel. Currently, there is a void in literatures discussing the challenges, methods, and best practices for pedestrian network map generation. This coupled with the increased demand for pedestrian networks is the prime motivation for development of new approaches and algorithms to automatically generating pedestrian networks. Three approaches, network buffering, using existing road networks, collaborative mapping, using Global Positioning System GPS traces collected by volunteers, and image processing, using high-resolution satellite and laser imageries, were implemented and evaluated with a pedestrian network baseline as a ground truth. The results of the experiments indicate that these three approaches, while differing in complexity and outcome, are viable for automatic pedestrian network map generation. The recommendation of a suitable approach for generating pedestrian networks for a given set of sources and requirements is provided.		Hassan A. Karimi;Piyawan Kasemsuppakorn	2013	International Journal of Geographical Information Science	10.1080/13658816.2012.730148	collaborative mapping;simulation;geography;image processing;computer science;cartography	Robotics	-18.024040867948766	-31.99786136289317	102070
b73908664ec970d420d9cfaa37c88d48cf97e947	fast and memory efficient mining of periodic frequent patterns		Periodic frequent pattern mining, the process of finding frequent patterns which occur periodically in databases, is an important data mining task for various decision making. Though several algorithms have been proposed for their discovery, most employ a two stage process to evaluate the periodicity of patterns. That is, by firstly deriving the set of periods of a pattern from its coverset, and subsequently evaluating the periodicity from the derived set of periods. This two step process thus make algorithms for discovering periodic frequent patterns both time and memory inefficient in the discovery process. In this paper, we present solutions to reduce both runtime and memory consumption in periodic frequent pattern mining. We achieve this by evaluating the periodicity of patterns without deriving the set of periods from their coversets. Our experimental results show that our proposed solutions are efficient both in reducing the runtime and memory consumption in the discovery of periodic frequent patterns.		Vincent Mwintieru Nofong	2018		10.1007/978-3-319-76081-0_19	machine learning;business process discovery;periodic graph (geometry);artificial intelligence;derived set;computer science	ML	-6.117817445140004	-36.289130791986196	102325
ec5500096c1b884939b2d7580def239f70567df3	privacy preserving association rule mining over distributed databases using genetic algorithm	information and communication technology	Privacy preservation in distributed database is an active area of research. With the advancement of technology, massive amounts of data are continuously being collected and stored in distributed database applications. Indeed, temporal associations and correlations among items in large transactional datasets of distributed database can help in many business decision-making processes. One among them is mining frequent itemset and computing their association rules, which is a nontrivial issue. In a typical situation, multiple parties may wish to collaborate for extracting interesting global information such as frequent association, without revealing their respective data to each other. This may be particularly useful in applications such as retail market basket analysis, medical research, academic, etc. In the proposed work, we aim to find frequent items and to develop a global association rules model based on the genetic algorithm (GA). The GA is used due to its inherent features like robustness with respect to local maxima/minima and domain-independent nature for large space search technique to find exact or approximate solutions for optimization and search problems. For privacy preservation of the data, the concept of trusted third party with two offsets has been used. The data are first anonymized at local party end, and then, the aggregation and global association is done by the trusted third party. The proposed algorithms address various types of partitions such as horizontal, vertical, and arbitrary.	affinity analysis;aggregate data;approximation algorithm;association rule learning;computation;data mining;distributed database;fitness function;genetic algorithm;genetic operator;information privacy;iteration;mathematical optimization;maxima and minima;privacy;refinement (computing);transaction processing;trusted third party	Bettahally N. Keshavamurthy;Asad Khan;Durga Toshniwal	2013	Neural Computing and Applications	10.1007/s00521-013-1343-9	information and communications technology;computer science;machine learning;data mining;database;apriori algorithm;world wide web	DB	-5.449374516939559	-34.701696779178924	102346
1362ee689f3744aee4f58e108d17385ffbf19968	data fusion algorithms for density reconstruction in road transportation networks	density measurement;time measurement;sensors;rocade sud data fusion algorithms density reconstruction road transportation networks traffic networks heterogeneous information sources density estimation future intelligent transportation systems navigation purposes grenoble traffic lab fixed sensor network inrix floating car data;floating car data road transportation systems dynamical flow network density reconstruction;observers;roads;sensor fusion automobiles intelligent transportation systems road traffic;vehicles;velocity measurement;vehicles sensors roads density measurement velocity measurement time measurement observers	This paper addresses the problem of density reconstruction in traffic networks with heterogeneous information sources. The network is partitioned in cells in which vehicles flow from their origin to their destination. The state of the network is represented by the densities of vehicles in each cell. Density estimation is of crucial importance in future Intelligent Transportation Systems for monitoring, control, and navigation purposes. However, deploying fixed sensors for this purpose can be very expensive. Therefore, most of fixed sensors networks are rather sparse. On the contrary, recent technologies have enormously increased the availability of relatively inexpensive Floating Car Data. A data fusion algorithm is then proposed to incorporate the two sources of information into a single observer of density of vehicles. The efficiency of the proposed algorithm is shown in a real scenario using data from the Grenoble Traffic Lab fixed sensor network and INRIX Floating Car Data on the Rocade Sud in Grenoble.	algorithm;diagram;numerical analysis;sensor;sparse matrix;the matrix	Enrico Lovisari;Carlos Canudas de Wit;Alain Y. Kibangou	2015	2015 54th IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2015.7402641	simulation;floating car data;telecommunications;engineering;sensor;transport engineering;time	Robotics	-18.051564436664314	-29.637793168286098	102439
7df23adcfac2b5bc1327d755fc09fcd326f4049f	multi-level relationships between satellite-derived nighttime lighting signals and social media-derived human population dynamics			population dynamics;social media	Ting Ma	2018	Remote Sensing	10.3390/rs10071128		HCI	-12.211556332369794	-26.257381097673548	102763
79d1617234b84bb29e6da3d5f3507a2ea5f32738	methodology for identifying car following events from naturalistic data	vehicles algorithm design and analysis instruments radar tracking sensors visualization;road vehicle radar automobiles automotive electronics braking driver information systems inspection road safety;visual inspection car following event identification naturalistic driving studies nds data driver assistance systems forward collision warning systems fcw systems braking behavior population distributions warning threshold design heuristic algorithm forward looking radar vehicle dynamics	Naturalistic Driving Studies (NDS) are becoming an integral tool for development of driver assistance systems. Because of its large volume, one challenge with working with NDS data is identifying driving scenarios of interest automatically. This study introduces a methodology for identifying situations where the driver of the instrumented vehicle applied the brakes while following another vehicle. These car following events are of interest for designers of Forward Collision Warning (FCW) systems. This algorithm could be used in conjunction with a large scale NDS, such as the Virginia Tech Transportation Research Institute's 100-Car database, to generate population distributions of braking behavior during car following. These population distributions could be used to inform the design of warning thresholds for FCW. The heuristic algorithm developed in this study identifies car following events using forward looking radar (object range and range rate) and vehicle dynamics (speed, vehicle yaw rate). The proposed algorithm identified the same car following scenario as a visual inspection of the data in 91.8% of brake applications, suggesting it can automatically identify car following events.	algorithm;device driver;heuristic (computer science);radar;visual inspection;yaws	Kristofer D. Kusano;Jade Montgomery;Hampton C. Gabler	2014	2014 IEEE Intelligent Vehicles Symposium Proceedings	10.1109/IVS.2014.6856406	simulation;advanced driver assistance systems;engineering;automotive engineering;computer security	Robotics	-18.243622872483606	-26.949123232285476	103041
52b0ad7d06cb5e6774ce92096dfee85a0544f6ca	a location prediction algorithm with daily routines in location-based participatory sensing systems	期刊论文	Mobile node location predication is critical to efficient data acquisition and message forwarding in participatory sensing systems. This paper proposes a social-relationship-based mobile node location prediction algorithm using daily routines (SMLPR). The SMLPR algorithm models application scenarios based on geographic locations and extracts social relationships of mobile nodes from nodes' mobility. After considering the dynamism of users' behavior resulting from their daily routines, the SMLPR algorithm preliminarily predicts node's mobility based on the hidden Markov model in different daily periods of time and then amends the prediction results using location information of other nodes which have strong relationship with the node. Finally, the UCSD WTD dataset are exploited for simulations. Simulation results show that SMLPR acquires higher prediction accuracy than proposals based on the Markov model.	algorithm;participatory sensing	Ruiyun Yu;Xingyou Xia;Shiyang Liao;Xingwei Wang	2015	IJDSN	10.1155/2015/481705	simulation;computer science;artificial intelligence;data mining	HCI	-17.046206325942315	-34.48058738292027	103226
8d2eda0d7ced017aff078b044e06b0472b41a3ae	a risk assessment and alerting system for maritime attacks	adaptive information fusion;maritime piracy;security of data data protection knowledge based systems marine engineering risk management;coherence checks risk assessment alerting system maritime attacks maritime security algorithmic module rule based risk model abnormal behaviour detection nonkinematic analysis;marine vehicles radar tracking measurement radar detection kinematics sensors;adaptive information fusion maritime piracy abnormal behaviour detection;abnormal behaviour detection	The impact of piracy on the maritime economy has been increasing dramatically over the last decade, which encouraged actors of maritime security to support research works on detection and protection against this threat. However, providing automated support for attacks in the maritime domain is highly dependent on the context and on the information available to the system. In this paper, we present an algorithmic module and its underlying rule-based risk model, designed to detect abnormal behaviours such as maritime attacks from heterogeneous sources of information. The module uses a combination of kinematic and non-kinematic analysis coupled with coherence checks to reach acceptable operational performance, and has been tested on simulations, field tests and real traffic recordings.	database;financial risk modeling;logic programming;radar;risk assessment;sensor;simulation	Simon Fossier	2014	2014 IEEE 26th International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2014.84	simulation;computer security	Embedded	-18.26351798798243	-24.755956742568628	103777
6bd9ce7842f58a795ce6371c551022f8acdd80f0	traffic flow classification using traffic cameras				Mohammad Shokrolah Shirazi;Brendan Tran Morris	2018		10.1007/978-3-030-03801-4_66	computer vision;computer science;artificial intelligence;traffic flow	Vision	-10.722859467359537	-28.550734025638796	103985
36a4946da0a5fe199ba76baa44149d5541645f8f	navisoc: a socially enhanced real-time navigator	databases;navigation path navisoc socially enhanced real time navigator social networks social streams navigation system location based recommendation system context aware recommendation system social events;event detection social navigation context awareness social networks;servers;global positioning system;context databases servers real time systems global positioning system twitter;ubiquitous computing computerised navigation recommender systems social networking online traffic engineering computing;twitter;context;real time systems	As the usage of social networks becomes more and more ubiquitous and people commute more often today, social streams have become a valuable source for many kinds of applications. For example, the various social streams could be exploited for choosing the optimal path (e.g., The shortest and/or the fastest) to reach a desired destination. To this direction, we present a novel navigation system, called NaviSoc. NaviSoc is a location-based, context-aware recommendation system proposing dynamically and in real-time, the best route according to the user's context (e.g., Preferences and budget). The system takes advantage of social streams in order to identify unprecedented (e.g., Traffic jam, protest) or social events occurring in a specific place. Then, using this knowledge, the system dynamically readjusts the proposed navigation path. An initial evaluation, performed on the Greek island of Crete, demonstrates the feasibility of our solution and the benefits of our system.	algorithm;database;emoticon;fastest;geoplanet;google search;jam;location-based service;machine learning;real-time locating system;real-time transcription;recommender system;routing;semantic interpretation;sensor;server (computing);smartphone;social network;web service	Nikolaos Louloudakis;Vasileios Theodosiadis;Haridimos Kondylakis;Kostas Stefanidis	2014	2014 IEEE International Conference on Data Mining Workshop	10.1109/ICDMW.2014.77	turn-by-turn navigation;simulation;global positioning system;computer science;data mining;internet privacy;world wide web;server	DB	-17.967878033583837	-34.68957393389306	104457
514bf00bdf9d39afb388dd3b624ef3f15ebfdc1e	simulating pirate behavior to exploit environmental information	commercial shipping;pirate behavior;limited survival;agent model;maritime safety;commercial shipping billion;east africa;asymmetric threat;environmental information;oceanographic forecast;high wind;recent year;design of experiment;meteorology;atmospheric modeling;national security;oceanography;relative risk;intelligence;multiagent systems;ocean currents;predictive models;behavior;weather forecasting;risk;forecasting;transportation;design of experiments;ocean waves;wind	Recent years have seen an upsurge in piracy, particularly off the Horn of Africa. Piracy differs from other asymmetric threats, such as terrorism, in that it is economically motivated. Pirates operating off East Africa have threatened maritime safety and cost commercial shipping billions of dollars paid in ransom. Piracy in this region is conducted from small boats which can only survive for a few days away from their base of operations, have limited survival in severe weather, and cannot perform boarding operations in high wind or sea state conditions. In this study we use agent models and statistical design of experiments to gain insight into how meteorological and oceanographic forecasts can used to dynamically predict relative risks for commercial shipping.	agent-based model;design of experiments;experiment	Leslie Esher;Stacey Hall;Eva Regnier;Paul J. Sanchez;James A. Hansen;Dashi Singham	2010	Proceedings of the 2010 Winter Simulation Conference		simulation;computer science;engineering;multi-agent system;mathematics;design of experiments;operations research;statistics	HCI	-17.72980971915843	-24.91004413018978	104758
d8f7696e8b4e05eb73fb6f075498bca4b8abcecb	towards a frugal framework for monitoring road quality	travel speed road quality monitoring city urbanization city infrastructure road capacity surface transportation road network road infrastructure pavement roughness traffic infrastructure management frugal innovation frugal approach nairobi kenya;pavement management systems;global positioning system;loop detectors;probe vehicles;pavement maintenance;roads vehicles global positioning system data collection intelligent sensors cities and towns;pavement distress;cameras;traffic engineering computing data handling road traffic;nairobi kenya	Rapid urbanization of developing cities creates challenges for governments to update and maintain the city infrastructure. One particular challenge is to plan for road capacities that will sustain the growing demand for surface transportation on the road network. For these cities, a sophisticated road infrastructure that includes sensors (e.g., loop detectors and traffic cameras) and/or probe vehicles equipped to detect pavement roughness are ideal for traffic infrastructure management. However, the cost of such tools for developing cities is often prohibitively expensive. For these reasons, road infrastructure management strategies that are able to leverage low-cost technologies and data resources are highly sought after in these areas. We refer to these strategies as frugal innovations. In this paper we explore a frugal approach for monitoring road quality in Nairobi, Kenya. Our aim is to use characteristics of speed distributions to detect the presence of pavement distresses (including speed bumps) for Nairobi, Kenya's road network. We first derive link speeds from mobile GPS traces, and then perform graphical as well as quantitative distributional comparisons of the speed distributions on travel network links with speed bumps present, compared to links without speed bumps present. Our results support our hypotheses that distributional comparisons on travel speeds can indeed serve as useful tools to detect the presence of speed bumps and other road distresses.	global positioning system;graphical user interface;mobile phone;sensor;statistical model;tracing (software)	Tierra Bills;Reginald E. Bryant;Aisha Walcott-Bryant	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6958175	simulation;floating car data;engineering;civil engineering;transport engineering	Mobile	-17.733958373235	-30.222437400552526	104855
d25646bbda30b037150046175b9a258e67243472	time-aware multivariate nearest neighbor regression methods for traffic flow prediction	nearest neighbor searches;context awareness;road traffic data analysis intelligent transportation systems regression analysis;multivariate analysis;bayes methods;prediction algorithms;bayes theorem;bayesian networks traffic flow prediction nearest neighbor regression multivariate analysis context awareness pattern recognition algorithm;traffic flow;artificial neural networks;pattern recognition;traffic models;regression analysis;bayes methods prediction algorithms nearest neighbor searches artificial neural networks context awareness regression analysis pattern recognition;pattern recognition systems;urban network time aware multivariate nearest neighbor regression method traffic flow prediction intelligent transportation system data driven algorithm multivariate approach time of the day awareness tam nnr algorithm traffic data california highway context elements traffic prediction weather condition road topology	Traffic flow prediction is a fundamental functionality of intelligent transportation systems. After presenting the state of the art, we focus on nearest neighbor regression methods, which are data-driven algorithms that are effective yet simple to implement. We try to strengthen their efficacy in two ways that are little explored in literature, i.e., by adopting a multivariate approach and by adding awareness of the time of the day. The combination of these two refinements, which represents a novelty, leads to the definition of a new class of methods that we call time-aware multivariate nearest neighbor regression (TaM-NNR) algorithms. To assess this class, we have used publicly available traffic data from a California highway. Computational results show the effectiveness of such algorithms in comparison with state-of-the-art parametric and non-parametric methods. In particular, they consistently perform better than their corresponding standard univariate versions. These facts highlight the importance of context elements in traffic prediction. The ideas presented here may be further investigated considering more context elements (e.g., weather conditions), more complex road topologies (e.g., urban networks), and different types of prediction methods.	australian bibliographic network;autoregressive integrated moving average;bayesian network;computation;k-nearest neighbors algorithm;pattern recognition;response time (technology);scalability;seasonality;semantic network;sensor web;software deployment;test case;time series;total functional programming	Pietro Dell'Acqua;Francesco Bellotti;Riccardo Berta;Alessandro De Gloria	2015	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2015.2453116	prediction;computer science;machine learning;traffic flow;pattern recognition;data mining;mathematics;multivariate analysis;bayes' theorem;artificial neural network;regression analysis;statistics	Visualization	-16.434267091019798	-31.92187356228168	104917
2dfda6f0d79ea3cddbceaf3a32f3238a228804bd	cleansing indoor rfid data using regular expressions	rfid;matching;data cleansing;indoor spaces	RFID (Radio Frequency Identification)-based object tracking is increasingly deployed and used in indoor environments such as airports, shopping malls, etc. However, the inherent noise in the raw RFID data makes it difficult to support queries and analyses on the data. In this paper, we propose an RFID data cleansing based on regular expressions. We generate the regular expressions in an automaton that captures all possible indoor paths from the spatial and temporal aspects of indoor space and deployed readers. Given the raw data of an object, the proposed matching algorithm finds all the matching paths using the automaton. We evaluate the proposed approach by conducting experimental studies using real dataset. The results demonstrate the effectiveness of the propose approach.	algorithm;automaton;radio frequency;radio-frequency identification;regular expression	Asif Iqbal Baba;Hua Lu;Wei-Shinn Ku;Torben Bach Pedersen	2016		10.1145/2996913.2996979	radio-frequency identification;matching;computer science;data cleansing	DB	-16.253788543250522	-35.281997038381974	105206
7a70b276285d89a921acca4e51c2073244fddc7a	multiple hierarchical reasoning in uncertain situations for complex device fault diagnosis	sql2005 database multiple hierarchical reasoning complex device fault diagnosis rule based reasoning retrieving strategy diagnostic tree fuzzy multi attribute group decision making method;rule based reasoning inexact reasoning multiple hierarchical diagnosis fuzzy multi attribute group decision making method;inference mechanisms;inexact reasoning;fault diagnosis decision making intelligent control control systems mechatronics intelligent systems deductive databases instruments laser theory fuzzy reasoning;fault diagnosis system;fuzzy multi attribute group decision making method;multiple hierarchical diagnosis;group decision making;knowledge based systems decision making fault diagnosis inference mechanisms;knowledge based systems;fault diagnosis;rule based reasoning;diagnostic method	An efficient diagnostic method is proposed for complex device fault diagnosis. In rule-based reasoning, an efficient retrieving strategy is crucial. The generic retrieving method is based on a diagnostic tree built according to the hierarchical decomposition of devices, but it is difficult to achieve such diagnostic tree for some complex devices. So a multiple hierarchical diagnosis method based on fault categories is proposed. And then, the retrieving priorities of rules in a certain diagnostic level are determined based on a fuzzy multi-attribute group decision-making method, which can more effectively work out the priority factors. Based on this diagnostic method, a fault diagnosis system for intelligent instruments was developed based on SQL2005 database. And comparison between two systems is presented to validate the diagnostic method.	logic programming;rule-based system	Yushu Lai;Xunbo Li;Yan Xiong	2007	2007 IEEE 22nd International Symposium on Intelligent Control	10.1109/ISIC.2007.4450942	computer science;artificial intelligence;model-based reasoning;machine learning;data mining	Robotics	-7.468264283792144	-24.533532183143446	105436
376350cd8d04cc80087e5a86ab4d4dfa7a20c3b9	modeling financial time series with s - plus			time series	Thomas L. Burr	2007	Technometrics	10.1198/tech.2007.s460		DB	-11.654118057306864	-28.14082210882884	105814
3c9743af41595f80549c740cd8b5ff59560ce41b	a matrix approach for association mining	on-line query processing.;data mining;parallel association mining;association mining;parallel computer	Association Mining, a class of data mining techniques, is one of the most researched field in data mining, where algorithms are designed to discover rules that reflect dependencies among values of an attribute. Because of the vast amounts of data that businesses store, most association mining algorithms are computationally expensive, where many passes over data are performed. Besides working on the sequential processing environment, the implementation of data mining ideas should consider parallel computing environments. In this paper, a new technique is presented to perform association mining based on the matrix approach. The new technique can be applied on the sequential and parallel environments. In the proposed technique, the data records are only scanned once to construct a frequency vector and a binary association matrix. Two algorithms, one for generating only maximal large item-sets and the other for generating all large item-sets, are presented. The number of disk accesses, CPU time, and memory space needed for generating large item-sets are O(n), O(N 2 ) , and O(N), respectively, where n is the number of input transactions, and N is the number of transaction groups.	algorithm;analysis of algorithms;association rule learning;central processing unit;dspace;data mining;maximal set;parallel computing;the matrix	Alaaeldin M. Hafez;Vijay V. Raghavan	2001			cpu time;data stream mining;matrix (mathematics);data mining;computer science;binary number;database transaction;text mining	ML	-5.398918529399396	-37.41785985005958	105937
d23f0bcd02ef28dcbc2bf440f9c18307ab84c79f	a driver behavior-based lane-changing model for urban arterial streets	gap acceptance;pedestrian safety;poison control;vehicle interactions;injury prevention;microscopic simulation;safety literature;traffic safety;injury control;home safety;injury research;safety abstracts;computer models;urban areas;human factors;arterial highways;occupational safety;safety;safety research;accident prevention;drivers;violence prevention;bicycle safety;microsimulation;corsim corrider simulation;behavior;poisoning prevention;falls;focus group study;lane changing;ergonomics;suicide prevention	Lane-changing algorithms have attracted increased attention during recent years. However, limited research has been conducted to address the probability of changing lanes as a function of driver characteristics and lane-changing scenarios. This study contributes to the development of a comprehensive framework for modeling drivers' lane-changing maneuver on arterials by using driver behavior-related data. Focus group studies and “in-vehicle” driving tests were performed to investigate the effects of driver type under various lane changes on urban arterials and to collect microscopic vehicular data. With these field collected values, a model was developed to estimate the probability of changing lanes under various lane-changing scenarios and to estimate the corresponding gap acceptance characteristics. The lane-changing probability for each scenario was modeled as a function of the factors identified from the focus group discussions, as well as the driver types. In the gap acceptance modeling, a sequence of “hand-shaking negotiations” was introduced to describe vehicle interactions that may occur during lane-changing maneuvers. The proposed lane-changing model was implemented in the CORSIM CORrider SIMulation micro-simulator. The simulation capabilities of the newly developed model were compared to the original lane-changing algorithm in CORSIM and to the field observations. The validation results indicated that the new model better replicates the observed traffic under various levels of flow.		Daniel Sun;Lily Elefteriadou	2014	Transportation Science	10.1287/trsc.1120.0435	simulation;engineering;suicide prevention;human factors and ergonomics;injury prevention;transport engineering;computer security;behavior	Vision	-18.647420723316564	-26.103705667705334	106137
38b612c12e4a6d5441dc841da3e7f1db59ed4c4d	comparative regional gdp analysis: case study of croatia	croatian counties;cluster analysis;multiple regression model;regional development indicators;monte carlo simulations	The focus of this paper is the regional GDP analysis of Croatian Counties. It is a part of an extensive on-going scientific research about Croatian economic challenges within the global recession environment. Although, as EU accession country, Croatia is divided into three NUTS 2 regions, twenty one Croatian Counties show significant economic and social disproportions. In multiple regression model it is researched to what extent regional GDP per capita depends on a set of regional variables (employment, gross investment, production of more important agricultural products, GVA per person employed, construction works value, exports, imports, foreign tourists arrivals, foreign tourist nights, ecology...). Subsequently parameters are evaluated by Monte Carlo simulations which are used for the first time in comparative regional analysis. Also Croatian Counties are classified using Cluster analysis to make a comparative analysis with official spacing into three NUTS 2 regions which are geographical and political areas rather than real and homogenous socio-economic areas.		Elza Jurun;Snjezana Pivac	2011	CEJOR	10.1007/s10100-010-0163-6	computer science;operations management;mathematics;economy;cluster analysis;economic growth;monte carlo method	NLP	-11.573735277530442	-24.25397579866732	106543
68aad99c00eba8ff39db5c1f6e94dc489fc24fa7	weather data analysis and sensor fault detection using an extended iot framework with semantics, big data, and machine learning	internet of things;machine learning;framework;big data analytics;weather data analysis;anomaly detection;fault detection;clustering	In recent years, big data and Internet of Things (IoT) implementations started getting more attention. Researchers focused on developing big data analytics solutions using machine learning models. Machine learning is a rising trend in this field due to its ability to extract hidden features and patterns even in highly complex datasets. In this study, we used our Big Data IoT Framework in a weather data analysis use case. We implemented weather clustering and sensor anomaly detection using a publicly available dataset. We provided the implementation details of each framework layer (acquisition, ETL, data processing, learning and decision) for this particular use case. Our chosen learning model within the library is Scikit-Learn based k-means clustering. The data analysis results indicate that it is possible to extract meaningful information from a relatively complex dataset using our framework.	algorithm;anomaly detection;big data;cluster analysis;data logger;data retrieval;fault detection and isolation;internet of things;k-means clustering;köppen climate classification;machine learning;node.js;sensor;unsupervised learning;scikit-learn	Aras Can Onal;Omer Berat Sezer;Ahmet Murat Ozbayoglu;Erdogan Dogdu	2017	2017 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2017.8258150	rdf;data mining;anomaly detection;implementation;machine learning;artificial intelligence;computer science;big data;feature extraction;cluster analysis;fault detection and isolation;data processing	ML	-10.891134109909338	-32.49171987314118	106868
0c9b1ccb11fd537317715d5a64bc937f24fd1b85	urban area vehicle number estimation based on rtms data	rtms data;roads vehicles estimation sensors urban areas microwave sensors correlation;human behaviors urban area vehicle number estimation rtms data vehicle ownership traffic congestion traffic planning traffic management arterial roads remote traffic microwave sensor data avn area vehicle number inflow traffic outflow traffic estimation accuracy road traffic correlation hangzhou city;estimation;urban area vehicle;rtms data urban area vehicle estimation;road vehicles number theory road traffic	Along with the increase of vehicle ownership, the traffic problem has a serious impact on people's daily life. Not only the traffic congestion, but also the parking problem troubles urban daily traveling. Therefore it is important to obtain the parking demand to help the government to make a rational decision on traffic planning and management. This paper focuses on estimating the vehicle number in a certain area (i.e., the spaces surrounded by the arterial roads) in each time slot to analyze the area parking demand, using RTMS (Remote Traffic Microwave Sensor) data. We first propose a basic method to calculate the AVN (Area Vehicle Number) based on the inflow and outflow traffic of the area. In order to correct the error caused by minor roads without RTMS data, we propose an advanced method to improve the estimation accuracy by exploiting the road traffic correlation from a network perspective. Comprehensive evaluation is conducted to verify our design based on large amount of RTMS data from the Hangzhou city during one month. The estimation results also demonstrate interesting human behaviors among various urban areas.	approximation error;automated planning and scheduling;flow network;microwave;network congestion;rationality;transcranial magnetic stimulation;vii	Yue Hu;Yuanchao Shu;Peng Cheng;Jiming Chen	2016	2016 IEEE International Congress on Big Data (BigData Congress)	10.1109/BigDataCongress.2016.59	simulation;floating car data;environmental engineering;geography;vehicle information and communication system;traffic congestion reconstruction with kerner's three-phase theory;transport engineering;traffic optimization	EDA	-15.885434374819617	-28.83945866442005	107251
f00fa286f7992580cf47a17483d3a10910342123	crime rate inference using tensor decomposition		"""Crime is one of the most important social problems in the country, affecting economics, children development, and public safety. Modeling the whole crime situation of a city is critical for policy makers in their efforts to reduce crime and increase citizens' life quality. Chicago has a data platform containing relatively complete crime records from 2001 to present. As each crime record is associated with a location, a timestamp, and a fine-grained crime category, such as """"Theft"""" or """"Narcotics"""", the data is actually a result of """"human as a sensor"""" and """"crowd sensing"""", containing rich information and human intelligence that can help diagnose urban crime situations. In this paper we infer the fine-grained crime situation of different times in a year for each community of Chicago, IL in the USA, by using the Chicago crime datasets. We model the crime situation of Chicago with a three dimension tensor, where the three dimensions stand for communities, crime categories, and time slots, respectively. Filling the missing entries of the tensor through a tensor decomposition approach, we recover the overall crime situation throughout Chicago, which is helpful for community crime rate inference, thus influencing officials' decision making to reduce crime."""		Liang Ge;Junling Liu;Aoli Zhou;Hang Li	2018	2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)	10.1109/SmartWorld.2018.00138	timestamp;urban computing;data mining;computer science;distributed computing;tensor;social issues;inference;human intelligence	HCI	-18.22540473144385	-32.922061463185244	107326
6201133ccbf877984cdf5548db6cbc45a4fbfd77	spatial access method for urban geospatial database management: an efficient approach of 3d vector data clustering technique	3d urban data management;building modification spatial access method urban geospatial database management 3d vector data clustering technique 3d spatial database system 3d spatial index structure data retrieval 3d r tree spatial data handling 3d geospatial data clustering 3d urban dataset urban infill development building infill building demolition;3d spatial index;information management;visual databases data handling information retrieval pattern clustering;three dimensional displays buildings geospatial analysis urban areas indexes spatial databases geometry;3d spatial index spatial access method 3d urban data management information management urban data clustering;urban data clustering;spatial access method	In the last few years, 3D urban data and its information are rapidly increased due to the growth of urban area and urbanization phenomenon. These datasets are then maintain and manage in 3D spatial database system. However, performance deterioration is likely to happen due to the massiveness of 3D datasets. As a solution, 3D spatial index structure is used as a booster to increase the performance of data retrieval. In commercial database, commonly and widely used index structure for 3D spatial database is 3D R-Tree. This is due to its simplicity and promising method in handling spatial data. However, 3D R-Tree produces serious overlapping among nodes. The overlapping factor is important for an efficient 3D R-Tree to avoid replicated data entry in a different node. Thus, an efficient and reliable method is required to reduce the overlapping nodes in 3D R-Tree nodes. In this paper, we proposed a 3D geospatial data clustering to be used in the construction of 3D R-Tree and respectively could reduce the overlapping among nodes. The proposed method is tested on 3D urban dataset for the application of urban infill development. By using several cases of data updating operations such as building infill, building demolition and building modification, the proposed method indicates that the percentage of overlapping coverage among nodes is reduced compared with other existing approaches.	booster (electric power);cluster analysis;data retrieval;r-tree;spatial database	Suhaibah Azri;Uznir Ujang;Alias Abdul-Rahman;François Anton;Darka Mioc	2014	Ninth International Conference on Digital Information Management (ICDIM 2014)	10.1109/ICDIM.2014.6991400	spatial data infrastructure;computer science;data science;data mining;database;information management;spatial database	DB	-10.0987135578316	-36.08372435382781	107540
c8516c85c041348c1d009309f06b14f924237dfe	multiple time series anomaly detection based on compression and correlation analysis: a medical surveillance case study	computer communication networks;respubid25935;anomaly detection;0801 artificial intelligence and image processing;multiple time series;data mining;database management;080109 pattern recognition and data mining;college of science and engineering;centre for applied informatics;pattern recognition;correlation;0806 information systems;knowledge discovery	In this paper, we present a novel anomaly detection framework for multiple heterogeneous yet correlated time series, such as the medical surveillance series data. In our framework, we propose an anomaly detection algorithm from the viewpoint of trend and correlation analysis. Moreover, to efficiently process huge amount of observed time series, a new clustering-based compression method is proposed. Experimental results indicate that our framework is more effective and efficient than its peers.		Zhi Qiao;Jing He;Jie Cao;Guangyan Huang;Peng Zhang	2012		10.1007/978-3-642-29253-8_25	anomaly detection;computer science;data science;machine learning;data mining;correlation	ML	-12.081102368408107	-32.15665781484416	107559
e9e3406f2ce536b0ee66d5b4d9219177518d6de1	modeling and simulation for natural disaster contingency planning driven by high-resolution remote sensing images	dynamic data driven application systems;modeling and simulation;dynamic data driven application systems dddas;contingency planning;natural disasters;期刊论文;high resolution remote sensing image	Natural disasters occur unexpectedly and usually result in huge losses of life and property. How to effectively make contingency plans is an intriguing question constantly faced by governments and experts. Human rescue operations are the most critical issue in contingency planning. A natural disaster scenario is, in general, highly complicated and dynamic. Modeling and simulation technologies have been gaining considerable momentum in investigating natural disaster scenarios to enable contingency planning. However, existing MS and (2) the absence of methods and platforms to describe the collective behaviors of people in disaster situations. Considering these problems, an M&S framework for human rescue operations in a typical natural disaster, i.e., a landslide, has been developed in this study. The framework consists of three modules: (1) remote sensing information extraction, (2) landslide simulation, and (3) crowd simulation. The crowd simulation module is driven by the real/virtual data provided by the former modules. A number of simulations (using the Zhouqu landslide as an example) have been performed to study human relief operations spontaneously and under manipulation, with the effect of contingency plans highlighted. The experimental results demonstrate that  (1) the simulation framework is an effective tool for contingency planning, and (2) real data can make the simulation outputs more meaningful.		Minggang Dou;Jingying Chen;Dan Chen;Xiaodao Chen;Ze Deng;Xuguang Zhang;Kai Xu;Jian Wang	2014	Future Generation Comp. Syst.	10.1016/j.future.2013.12.018	simulation;natural disaster;computer science;artificial intelligence;data mining;modeling and simulation;contingency plan;operations research;computer security	ML	-18.98685919475789	-24.012270440282478	107656
8ad71b72d947d796126240190fbf7b3829fac210	using trend clusters for spatiotemporal interpolation of missing data in a sensor network	interpolation;trend discovery;sampling;clustering;time series regression;spatiotemporal data mining	Ubiquitous sensor stations continuously measure several geophysical fields over large zones and long (potentially unbounded) periods of time. However, observations can never cover every location nor every time. In addition, due to its huge volume, the data produced cannot be entirely recorded for future analysis. In this scenario, interpolation, i.e., the estimation of unknown data in each location or time of interest, can be used to supplement station records. Although in GIScience there has been a tendency to treat space and time separately, integrating space and time could yield better results than treating them separately when interpolating geophysical fields. According to this idea, a spatiotemporal interpolation process, which accounts for both space and time, is described here. It operates in two phases. First, the exploration phase addresses the problem of interaction. This phase is performed on-line using data recorded from a network throughout a time window. The trend cluster discovery process determines prominent data trends and geographicallyaware station interactions in the window. The result of this process is given before a new data window is recorded. Second, the estimation phase uses the inverse distance weighting approach both to approximate observed data and to estimate missing data. The proposed technique has been evaluated using two large real climate sensor networks. The experiments empirically demonstrate that, in spite of a notable reduction in the volume of data, the technique guarantees accurate estimation of missing data.	approximation algorithm;experiment;geographic information science;interaction;interpolation;missing data;online and offline;sensor web	Annalisa Appice;Anna Ciampi;Donato Malerba;Pietro Guccione	2013	J. Spatial Information Science	10.5311/JOSIS.2013.6.102	sampling;econometrics;geography;interpolation;time series;data mining;mathematics;cluster analysis;statistics	ML	-13.766377287735503	-32.885229534851774	107767
08c876b7afcff0ae011c10a0ed2fcff274400155	ict activities for air quality monitoring: an example of network stations of the city of zagreb				Silvije Davila;Ivan Beslic;Jadranka Pecar-Ilic;Kresimir Sega	2012			air quality index;civil engineering;geography;information and communications technology	HCI	-14.48653322458273	-24.1360110117236	108064
aee7072c8db7502c1b69fa54f356dbaea40838cf	pattern mining in ultra-high frequency order books with self-organizing maps		This paper addresses the issue of discovering frequent patterns in order book shapes, in the context of the stock market depth, for ultra-high frequency data. It proposes a computational intelligence approach to building frequent patterns by clustering order book shapes with Self-Organizing Maps. An experimental evaluation of the approach proposed on the London Stock Exchange Rebuild Order Book database succeeded with providing a number of characteristic shape patterns and also with estimating probabilities of some typical transitions between shape patterns in the order book.	data mining;map;organizing (structure);ultra high frequency	Piotr Lipinski;Anthony Brabazon	2014		10.1007/978-3-662-45523-4_24	computer science;data science;data mining;information retrieval	ML	-4.9604897169468485	-34.90740252931235	108072
9100aef7406ca92bdf241acfd691c3e59481fa47	mining at most top-k% spatio-temporal outlier based context: a summary of results	top k;spatio temporal outliers	Discovering STCOD is an important problem with many applications such as geological disaster monitoring, geophysical exploration, public safety and health etc. However, determining suitable interest measure thresholds is a difficult task. In the paper, we define the problem of mining at most top-K% STCOD patterns without using user-defined thresholds and propose a novel at most top-K% STCOD mining algorithm by using a graph based random walk model. Analytical and experimental results show that the proposed algorithm is correct and complete. Results show the proposed method is computationally more efficient than naive algorithms. The effectiveness of our methods is justified by empirical results on real data sets. It shows that the algorithms are effective and validate.		Zhanquan Wang;Chunhua Gu;Tong Ruan;Chao Duan	2011		10.1007/978-3-642-23887-1_87	computer science;data science;machine learning;data mining;statistics	DB	-10.638983329567255	-34.91844632901277	108362
d04ad372bcc55f5202bc3524f2f0847d9ac30600	exploring links between crime and disadvantage in north-west england: an analysis using geographical information systems	pedestrian safety;geographic information system;poison control;injury prevention;safety literature;traffic safety;injury control;home safety;injury research;safety abstracts;human factors;occupational safety;safety;safety research;accident prevention;violence prevention;bicycle safety;poisoning prevention;falls;ergonomics;suicide prevention	This paper reports some of the findings from a two-year study into crime and disadvantage on Merseyside in north-west England. Particular attention is paid to how a GIS has been used in conjunction with crime pattern analysis software to explore relations between crime and the distribution of different types of disadvantaged, middle income and affluent residential neighbourhood. The GIS has also been used to examine crime incidents in relation to the distribution of residential properties, community facilities, administrative boundaries and the street network. Discussion is focused on the utility of combining disaggregate information with aggregate statistics in crime pattern analysis.	geographic information system	Kate Bowers	1999	International Journal of Geographical Information Science	10.1080/136588199241409	suicide prevention;human factors and ergonomics;injury prevention;computer security	HPC	-16.51255481844281	-27.872938506134478	108852
eef3db6b1cf4438ebf6a2ad5e0c043081db7fd3a	efficient multi-attribute analysis for trajectories: a case study for aircraft		The recent proliferation of positioning devices has boosted the requirement for efficient methods of processing and analyzing large amounts of recorded movement data. Besides the geographic position, for many application domains there is more relevant time-dependent information such as speed, elevation, street names, or transportation modes, depending on the kind of moving object and on the evaluation purpose. In this paper, we present an application of a new framework that efficiently analyzes datasets with several time-dependent attributes of different types, using a highly flexible and expressive pattern language. In contrast to previous variants, the semantics of the language has been changed to make it more expressive and flexible, and the efficiency has been improved.  For a fast processing, we apply a multi-index consisting of several single indexes whose types depend on the attribute types. The flexibility and efficiency of our approach are demonstrated by identifying flights with certain properties among a dataset from Aircraft Traffic Control with the help of a sophisticated pattern.	pattern language;single-index model	Fabio Valdés;Ralf Hartmut Güting	2017		10.1145/3139958.3139977	machine learning;elevation;artificial intelligence;pattern matching;semantics;search engine indexing;computer science;pattern language	ML	-16.286657309402475	-35.78228929586481	108858
b75767c4ba112339c2d537414e2fa08fff68a4fa	crowd-sourced carpool recommendation based on simple and efficient trajectory grouping	public transportation information system;origin destination;data storage;recommender system;technology adoption;digital divide;mobile user	We propose a novel carpool recommendation method that is based on simplifying a user's movement traces. An effective carpool recommendation system requires that users following the most similar driving routes be identified and that these routes then be consolidated into one or more 'recommended' optimal carpool driving route options that users' can choose from. Currently mobile users generate a high volume of detailed trajectory data, making it difficult to efficiently derive optimal recommendations. We devise a simple method for building a user's trajectory profile, which is then used in deriving the recommendation(s). Unlike an origin-destination based analysis, which matches up riders with drivers, our method creates feature points along a simplified path that has been derived from the mobile user's moving trace. This maintains the sequence of movements and preserves feature points, including intersections and common places. Feature points are mapped using quad-keys as part of a tile map system that enables a membership of feature points within the range of a given area. Using this membership, recommendations for optimal carpool routes are made by measuring how users share common quad-keys along their trajectories. We tested our proposed method using historical traces of two crowd-sourced projects: TrafficPulse and GeoLife. The results show the advantage of the proposed method for dealing with a high volume of detailed mobile trajectory data, both in terms of requiring reduced data storage space and requiring reduced computational cost.	algorithmic efficiency;computation;computer data storage;crowdsourcing;feature recognition;recommender system;tile-based video game;tracing (software);traffic.com	DongWoo Lee;Steve H. L. Liang	2011		10.1145/2068984.2068987	digital divide;simulation;computer science;operating system;computer data storage;data mining;world wide web;computer security;recommender system	ML	-16.019501752506947	-34.58882241387346	108918
317408580e7a472a5791935a111a8bc88023356f	validation of capacity reductions in traffic monitoring systems	roadways;road traffic;data collection;traffic control;capacity reduction estimation traffic monitoring system roadways normal capacity reduction short term capacity reduction long term capacity reduction traffic control centre;he transportation and communications;short term capacity reduction;capacity reduction estimation;long term capacity reduction;traffic monitoring;traffic monitoring system;monitoring road transportation delay traffic control temperature road accidents;normal capacity reduction;traffic control centre;ta engineering general civil engineering general	Both planned and unplanned events can reduce the capacities on roadways and result in congestion and delay. Currently, there are no complete and reliable sources which can be used by traffic operators to estimate capacity reductions. On many occasions, operators have to estimate capacity reductions using a large degree of subjectivity. This paper describes a methodology developed to validate capacity reductions from data collected within the traffic monitoring system. Methods for the determination of normal capacity, short-term and long-term capacity reductions are introduced. The proposed method has been successfully applied to derive capacity reductions using operational data. The results obtained are encouraging. It is believed that the method could be implemented in many traffic control centres to improve capacity reduction estimations	many-one reduction;network congestion;website monitoring	Pengjun Zheng;Mike McDonald;David Jeffery	2006	2006 IEEE Intelligent Transportation Systems Conference	10.1109/ITSC.2006.1707429	degree of saturation;environmental engineering;engineering;transport engineering;forensic engineering	Embedded	-15.499536642649725	-27.610534364013265	109769
c141021243229dc591594d2c24cd3b921c4100f8	efficient top-k spatial locality search for co-located spatial web objects	object recognition;top k spatial locality search generic approximate algorithm greedy strategy real life datasets ranking function exact algorithms np hard problem spatial distance locality search spatial proximity query keywords textual description geographical location local intent search user location co located spatial web objects;barium;search problems equations barium mobile communication educational institutions indexing object recognition;indexing;query processing computational complexity greedy algorithms internet;mobile communication;search problems	In step with the web being used widely by mobile users, user location is becoming an essential signal in services, including local intent search. Given a large set of spatial web objects consisting of a geographical location and a textual description (e.g., Online business directory entries of restaurants, bars, and shops), how can we find sets of objects that are both spatially and textually relevant to a query? Most of existing studies solve the problem by requiring that all query keywords are covered by the returned objects and then rank the sets by spatial proximity. The needs for identifying sets with more textually relevant objects render these studies inapplicable. We propose locality Search, a query that returns top-k sets of spatial web objects and integrates spatial distance and textual relevance in one ranking function. We show that computing the query is NP-hard, and we present two efficient exact algorithms and one generic approximate algorithm based on greedy strategies for computing the query. We report on findings from an empirical study with three real-life datasets. The study offers insight into the efficiency and effectiveness of the proposed algorithms.	approximation algorithm;directory (computing);greedy algorithm;locality of reference;location (geography);np-hardness;principle of locality;ranking (information retrieval);real life;relevance;scalability;spatial query	Qiang Qu;Siyuan Liu;Bin Yang;Christian S. Jensen	2014	2014 IEEE 15th International Conference on Mobile Data Management	10.1109/MDM.2014.39	search engine indexing;object-based spatial database;query expansion;web query classification;mobile telephony;computer science;theoretical computer science;cognitive neuroscience of visual object recognition;data mining;database;barium;web search query;information retrieval;spatial query	DB	-14.881951045147305	-36.855260619898445	109779
e496cb0778c32295495ce38f08b0dc8f174c7372	hyper-structure mining of frequent patterns in uncertain data streams	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	Data uncertainty is inherent in many real-world applications such as sensor monitoring systems, location-based services, and medical diagnostic systems. Moreover, many real-world applications are now capable of producing continuous, unbounded data streams. During the recent years, new methods have been developed to find frequent patterns in uncertain databases; nevertheless, very limited work has been done in discovering frequent patterns in uncertain data streams. The current solutions for frequent pattern mining in uncertain streams take a FP-tree-based approach; however, recent studies have shown that FP-tree-based algorithms do not perform well in the presence of data uncertainty. In this paper, we propose two hyper-structure-based false-positive-oriented algorithms to efficiently mine frequent itemsets from streams of uncertain data. The first algorithm, UHS-Stream, is designed to find all frequent itemsets up to the current moment. The second algorithm, TFUHS-Stream, is designed to find frequent itemsets in an uncertain data stream in a time-fading manner. Experimental results show that the proposed hyper-structure-based algorithms outperform the existing tree-based algorithms in terms of accuracy, runtime, and memory usage.	algorithm;data mining;database;etoposide/ifosfamide/mesna/mitoxantrone;experiment;hyperactive behavior;location-based service;secure digital;stream cipher;structure mining;synthetic data;uncertain data;uncombable hair syndrome	Chandima H. Nadungodage;Yuni Xia;Jaehwan John Lee;Yi-Cheng Tu	2012	Knowledge and Information Systems	10.1007/s10115-012-0581-y	medical research;computer science;data science;data mining;database	ML	-8.70238282840065	-35.29637834320213	110043
c0fa133de3d8e56128a9ebbce25c9eaf852fe546	real time change point detection by incremental pca in large scale sensor data	robustness vectors principal component analysis hardware real time systems temperature sensors clustering algorithms;k means clustering algorithm change point detection incremental pca temperature sensor network data harvesting framework real time analysis system data center dc sensor data stream;sensor fusion computer centres pattern clustering principal component analysis real time systems	The article describes our work with the deployment of a 600-piece temperature sensor network, data harvesting framework, and real time analysis system in a Data Center (hereinafter DC) at the Johns Hopkins University. Sensor data streams were processed by robust incremental PCA and K-means clustering algorithms to identify outlier and changepoint events. The output of the signal processing system allows us to better understand the temperature patterns of the DataCenter's inner space and make possible the online detection of unusual transient and changepoint events, thus preventing hardware breakdown, optimizing the temperature control efficiency, and monitoring hardware workloads.	algorithm;cluster analysis;complex systems;data center;k-means clustering;principal component analysis;real life;sensor;signal processing;software deployment;sonification;streaming media	Dmitry Mishin;Kieran Brantner-Magee;Ferenc Czako;Alexander S. Szalay	2014	2014 IEEE High Performance Extreme Computing Conference (HPEC)	10.1109/HPEC.2014.7040959	real-time computing;computer science;machine learning;data mining	Visualization	-7.952004923760603	-28.55513506334721	110294
de789ef5682be83baf5f0ad5223bf29471d3b1d9	aerial threat perception architecture using data mining	confidence level;decision tree;data mining;design framework;pattern classification;knowledge base	This paper presents a design framework based on a centralized scalable architecture for effective simulated aerial threat perception. In this framework data mining and pattern classification techniques are incorporated. This paper focuses on effective prediction by relying on the knowledge base and finding patterns for building the decision trees. This framework is flexibly designed to seamlessly integrate with other applications. The results show the effectiveness of selected algorithms and suggest that more the parameters are incorporated for the decision making for aerial threats; the better is our confidence level on the results. To delve into accurate target prediction we have to make decisions on multiple factors. Multiple techniques used together helps in finding the accurate threat classification and result in better confidence on our results.	aerial photography;algorithm;centralized computing;control system;data mining;database;decision tree;knowledge base;scalability	M. Anwar-ul-Haq;Asad Waqar Malik;Shoab Ahmed Khan	2010		10.1007/978-3-642-14292-5_31	knowledge base;confidence interval;decision tree learning;computer science;data science;machine learning;decision tree;pattern recognition;data mining	ML	-10.662918053331872	-31.062409528844	110571
595eaa7871251f9c9dbb3d9cf10baf9ffeab5cda	rfid based vehicular networks for smart cities	graph theory;roads vehicles cities and towns rfid tags monitoring xml;road traffic;graph centrality measures rfid based vehicular networks smart cities traffic related problems mobile vehicles smart traffic management solutions business analytics rfid tags reader based traffic monitoring systems rfid readers road network analysis traffic data;road traffic graph theory mobile radio radiofrequency identification radiotelemetry;radiotelemetry;mobile radio;radiofrequency identification	Monitoring the activities of vehicles in modern cities and urban areas has become imperative for solving the traffic related problems. Latest information about mobile vehicles, such as their identification (number plate), position, speed, and so on, are very important for smart traffic management solutions and business analytics. To that end, RFID tags (installed on vehicles) and readers (installed on roads) based traffic monitoring systems have gained a lot of attention due to their cost effectiveness. Usually the RFID readers are much costlier than the RFID tags, therefore, there is always a constraint on the number of RFID readers that can be deployed. This work explores the particular problem of locating suitable places in a road network for RFID readers that can capture the maximum amount of traffic data. To that end, the graph centrality measures are used to find the nodes with most connectivity. The underlying assumption is that the most connected nodes experience the most traffic flow. A new centrality measure is also proposed that is more suitable for analyzing the road networks than the existing graph centrality measures. The experimental results on real maps and data reveal that the newly proposed measure is very effective for analyzing the road networks.	business analytics;centrality;eigenvector centrality;imperative programming;map;openstreetmap;radio-frequency identification;requirement;smart city;user requirements document;vertex (geometry);vertex (graph theory);website monitoring	Joydeep Paul;Baljeet Malhotra;Simon Dale;Meng Qiang	2013	2013 IEEE 29th International Conference on Data Engineering Workshops (ICDEW)	10.1109/ICDEW.2013.6547439	floating car data;telecommunications;graph theory;computer security;computer network	DB	-18.508357393183637	-30.532468831174917	110593
bec6af81b99e3254d49bed9d5c9ebe941cf13c4d	efficient calibration for rssi-based indoor localization by bayesian experimental design on multi-task classification	indoor localization;bayesian optimization;rssi;information gathering;multi task learning	RSSI-based indoor localization is getting much attention. Thanks to a number of researchers, the localization accuracy has already reached a sufficient level. However, it is still not easy-to-use technology because of its heavy installation cost. When an indoor localization system is installed, it needs to collect RSSI data for training classifiers. Existing techniques need to collect enough data at each location. This is why the installation cost is very heavy. We propose a technique to gather data efficiently by using machine learning techniques. Our proposed algorithm is based on multi-task learning and Bayesian optimization. This algorithm can remove the need to collect data of all location labels and select location labels to acquire new data efficiently. We verify this algorithm by using a Wi-Fi RSSI dataset collected in a building. The empirical results suggest that the algorithm is superior to an existing algorithm applying single-task learning and Active Class Selection.	algorithm;bayesian experimental design;bayesian optimization;computer multitasking;design of experiments;indoor positioning system;internationalization and localization;machine learning;mathematical optimization;multi-task learning	Masamichi Shimosaka;Osamu Saisho	2016		10.1145/2971648.2971710	embedded system;multi-task learning;computer science;machine learning;data mining	HCI	-13.256113290984361	-35.12013557032079	110820
a499a23004b0a6a179e98ef1be195ec4f6259fa6	nearest close friend search in geo-social networks		The proliferation of GPS-enabled devices has led to the development of location-based social network services such as Facebook, Twitter, and Foursquare. Users of these services not only make new friends but also post various content that contains their location. Although the existing services have continued to improve, they are still weak in handling some situations. If some users want to make a new friend, for example, they could manually search for the potential friends among the acquaintances of their friends by considering both spatial proximity and social closeness one by one. However, conventional studies have insufficiently tackled this problem yet. In this paper, we define a novel type of geo-social query called the k-Nearest `-Close Friends query, which retrieves the k nearest data objects from among the `-hop friends of the query user. We also propose three approaches for processing a k`-NCF query: Neighboring Cell Search, Friend-Cell Search, and Personal-Cell Search. In addition, we develop an efficient method of index update for supporting dynamic environments. We conduct a variety of experiments on synthetic and real data sets to evaluate and compare our methods.	centrality;experiment;geosocial networking;global positioning system;social network;synthetic intelligence	Changbeom Shim;Wooil Kim;Wan Heo;Sungmin Yi;Yon Dohn Chung	2018	Inf. Sci.	10.1016/j.ins.2017.09.049	mathematics;web query classification;data mining;hop (networking);social network;data set;closeness;location-based service	Web+IR	-14.544671867451257	-37.390791744942966	110833
de7a880f38db5dca60f2eafc1e73217d679fe998	an approach for mining the causation of heat island effect based on decision tree	urban environment;decision tree;causation mining;thermal pollution;shanghai;data mining;uhi effect urban heat island effect causation mining decision tree urban thermal environment land surface temperature;geographic information systems data mining decision trees;land surface temperature thermal pollution decision trees cities and towns land surface remote sensing thermal factors;geographic information systems;remote sensing;land surface temperature;cities and towns;uhi effect;land surface;heat island;environmental pollution;urban heat island;nonlinear system;thermal factors;influencing factor;decision trees;thermal environment;urban heat island effect;urban thermal environment;causation of heat island effect;shanghai causation of heat island effect influencing factor decision tree	Urban thermal environment is a complicated nonlinear system, which is affected by the integration of various influencing factors inside the city. To explore the mechanism of urban heat island (UHI) effect formation in the city of Shanghai, China, decision tree is applied to establishing the quantitative relationships between urban thermal environment and its influencing factors, which reflect ecological condition, built-up density and intensity, and human heat. The results indicate that it is feasible to simulate the intensity and distribution of land surface temperature (LST) field and predict the tendency of UHI effect in the future by decision tree. This research will help to take effective measures to alleviate heat island effect, and consequently reduce environmental pollution and improve urban entironment.	causality;decision tree;nonlinear system;simulation	Xiaoyan Dai;Zhongyang Guo;Xia Liu;Xiaodong Li;Yanling Zhu	2010	2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2010.5569514	nonlinear system;computer science;machine learning;urban heat island	HCI	-13.434262010188831	-25.0203379975116	110854
990cba2b411482e622f6c881556862439f8d3e46	a time and energy efficient routing algorithm for electric vehicles based on historical driving data		A routing algorithm that leads to extended driving range and battery longevity of electric vehicles (EV) is proposed. In addition to locating the time and energy efficient routes, the proposed algorithm provides a desired speed profile to be tracked by the driver. Data mining techniques are employed for extracting the desired speed profile for the goal driver from a set of historical driving data. In order to select data with strong analogy to those of the goal driver's vehicle and driving conditions, driving and vehicle attributes are defined. The historical driving data are clustered and the class of the goal driver among clustered data is determined through classification. Eventually, the required travel time and energy consumption corresponding to historical speed profiles are evaluated and the time and/or energy efficient route along with the desired speed profile are determined. The proposed method is tested on a set of data gathered in the Warrigal project, which provides real vehicle state information. Since the consumed energy data are not available in this dataset, a detailed EV model is adopted to estimate the energy consumption. The obtained results verify the effectiveness of the proposed routing algorithm in locating the time and/or energy efficient routes.	algorithm;cluster analysis;data mining;extended validation certificate;routing	Amir Masoud Bozorgi;Mehdi Farasat;Anas Mahmoud	2017	IEEE Transactions on Intelligent Vehicles	10.1109/TIV.2017.2771233	algorithm design;efficient energy use;energy consumption;vehicle routing problem;statistical classification;analogy;driving range;algorithm;engineering	Robotics	-16.32760572139888	-33.21959810389668	110943
ffc040c7ef1d67c8f123b1111d15a2312850031a	impact of driving context on stochastic driver-behavior model: quantitative analysis of car following task	dirichlet process mixture modeling driving context car following task driving behavior driving performance contextual information driving activity behavior prediction context recognition performance stochastic driver behavior models;vehicles context context modeling road transportation cities and towns data models predictive models;stochastic processes;traffic engineering computing;traffic engineering computing stochastic processes	Driving context plays an essential role in driving behavior and driving performance of a driver. The contextual information surrounding a driving activity involves several factors and dimensions that influence a driver's behavior. However, a driver may or may not need to adopt a particular driving pattern for every distinct driving context conditions. In this paper, we statistically investigate the impact of various driving context conditions on the behavior prediction and context recognition performance of stochastic driver-behavior models. We employed a Dirichlet process mixture modeling framework to capture the underlying distributions of observed driving parameters under different driving context conditions. Experimental validation was conducted using the on-the-road car-following behavior of sixty-four drivers. The results showed that under two particular context conditions, drivers demonstrated distinct driving characteristics that could be efficiently recognized by stochastic driver-behavior models, and yet, some context-specific models could be exploited to predict driving behavior in other driving contexts.	adaptive system;behavior model;device driver;mixture model	Pongtep Angkititrakul;Chiyomi Miyajima;Kazuya Takeda	2012	2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012)	10.1109/ICVES.2012.6294301	simulation;engineering;automotive engineering;transport engineering	Robotics	-13.467975926319065	-30.680223487763534	111026
675b3d36b7613e3582f7a7b7484ea07b53b5daf5	remote sensing classification based on improved ant colony rules mining algorithm	ant colony;association rule;remote sensing	Data mining can uncover previously undetected relationships among data items using automated data analysis techniques. In data mining, association rule mining is a prevalent and well researched method for discovering useful relations between variables in large databases. This paper investigates the principle of traditional rule mining, which will produce more non-essential candidate sets when it reads data into candidate items. Particularly when it deals with massive data, if the minimum support and minimum confidence are relatively small, combinatorial explosion of frequent item sets will occur and computing power and storage space required are likely to exceed the limits of machine. A new ant colony algorithm based on conventional Ant-Miner algorithm is proposed and is used in rules mining. Measurement formula of effectiveness of the rules is improved and pheromone concentration update strategy is also carried out. The experiment results show that execution time of proposed algorithm is lower than traditional algorithm and has better execution time and accuracy.	ant colony optimization algorithms;apriori algorithm;association rule learning;coefficient;data mining;database;evaporation;image processing;intrusion detection system;run time (program lifecycle phase)	Shuying Liu	2014	Journal of Multimedia	10.4304/jmm.9.9.1105-1112	association rule learning;computer science;data science;ant colony;machine learning;data mining;fsa-red algorithm;data stream mining	ML	-5.313539612636702	-36.3389095647612	111217
298c8f6f6ecbaaa63e3efde82cba08c24e955fa6	predicting urban water quality with ubiquitous data		Urban water quality is of great importance to our daily lives. Prediction of urban water quality help control water pollution and protect human health. However, predicting the urban water quality is a challenging task since the water quality varies in urban spaces non-linearly and depends on multiple factors, such as meteorology, water usage patterns, and land uses. In this work, we forecast the water quality of a station over the next few hours from a data-driven perspective, using the water quality data and water hydraulic data reported by existing monitor stations and a variety of data sources we observed in the city, such as meteorology, pipe networks, structure of road networks, and point of interests (POIs). First, we identify the influential factors that affect the urban water quality via extensive experiments. Second, we present a multi-task multi-view learning method to fuse those multiple datasets from different domains into an unified learning model. We evaluate our method with real-world datasets, and the extensive experiments verify the advantages of our method over other baselines and demonstrate the effectiveness of our approach.	baseline (configuration management);computer multitasking;experiment	Ye Liu;Yuxuan Liang;Shuming Liu;David S. Rosenblum;Yu Zheng	2016	CoRR		data mining	AI	-15.697969818221186	-32.20275317565112	111267
fcbb968f85557fe6faa9ccc508aae8656db6423b	frequent pattern mining from time-fading streams of uncertain data	frequent pattern;frequent pattern mining;data mining techniques;data stream;probabilistic data;data mining;data streams;frequent itemset;frequent itemsets;stream processing;uncertain data;sliding window;knowledge discovery	Nowadays, streams of data can be continuously generated by sensors in various real-life applications such as environment surveillance. Partially due to the inherited limitation of the sensors, data in these streams can be uncertain. To discover useful knowledge in the form of frequent patterns from streams of uncertain data, a few algorithms have been developed. They mostly use the sliding window model for processing and mining data streams. However, for some applications, other stream processing models such as the time-fading model are more appropriate. In this paper, we propose mining algorithms that use the time-fading model to discover frequent patterns from streams of uncertain data.	data mining;lazy evaluation;mined;real life;sensor;stream processing;streaming algorithm;text mining;time-utility function;uncertain data	Carson Kai-Sang Leung;Fan Jiang	2011		10.1007/978-3-642-23544-3_19	sliding window protocol;stream processing;computer science;data science;data mining;database;knowledge extraction;data stream mining	DB	-8.69226452483423	-35.25672129525272	111282
b8cc92eec9ce29fb0f765c79692e1bdc167ecdb5	mining compressed repetitive gapped sequential patterns efficiently	empirical study;frequent pattern;data mining;frequent itemset;sequential pattern mining;synthetic data;sequential pattern;repetitive gapped sequential pattern;compressing frequent patterns	Mining frequent sequential patterns from sequence databases has been a central research topic in data mining and various efficient mining sequential patterns algorithms have been proposed and studied. Recently, in many problem domains (e.g, program execution traces), a novel sequential pattern mining research, called mining repetitive gapped sequential patterns, has attracted the attention of many researchers, considering not only the repetition of sequential pattern in different sequences but also the repetition within a sequence is more meaningful than the general sequential pattern mining which only captures occurrences in different sequences. However, the number of repetitive gapped sequential patterns generated by even these closed mining algorithms may be too large to understand for users, especially when support threshold is low. In this paper, we propose and study the problem of compressing repetitive gapped sequential patterns. Inspired by the ideas of summarizing frequent itemsets, RPglobal, we develop an algorithm, CRGSgrow (Compressing Repetitive Gapped Sequential pattern grow), including an efficient pruning strategy, SyncScan, and an efficient representative pattern checking scheme, dominate sequential pattern checking. The CRGSgrow is a two-step approach: in the first step, we obtain all closed repetitive sequential patterns as the candidate set of representative repetitive sequential patterns, and at the same time get the most of representative repetitive sequential patterns; in the second step, we only spend a little time in finding the remaining the representative patterns from the candidate set. An empirical study with both real and synthetic data sets clearly shows that the CRGSgrow has good performance.	algorithm;covering problems;data mining;p (complexity);problem domain;repetitive strain;sequence database;sequential pattern mining;set cover problem;synthetic data;tracing (software)	Yongxin Tong;Zhao Li;Dan Yu;Shilong Ma;Ke Xu	2009		10.1007/978-3-642-03348-3_68	sequential pattern mining;computer science;machine learning;pattern recognition;data mining;empirical research;synthetic data	ML	-5.891117080179514	-36.44285130999302	111382
fb740cdc9cbd6d920e90691620309281c6282eff	geospatial analytics to improve the safety of autonomous vehicles		Finding﻿the﻿costs﻿and﻿risks﻿associated﻿with﻿highway﻿traffic﻿routes﻿would﻿allow﻿companies﻿and﻿people﻿ alike﻿to﻿find﻿routes﻿that﻿offer﻿a﻿comfortable﻿amount﻿of﻿risk.﻿With﻿the﻿amount﻿of﻿traffic﻿data﻿being﻿ collected﻿at﻿a﻿more﻿granular﻿level﻿the﻿ability﻿to﻿find﻿costs﻿and﻿risks﻿associated﻿with﻿traffic﻿routes﻿ given﻿real﻿time﻿circumstances﻿is﻿plausible.﻿Weighing﻿these﻿data﻿and﻿finding﻿the﻿areas﻿that﻿are﻿most﻿ accident-prone﻿allows﻿for﻿an﻿assessment﻿of﻿the﻿probability﻿that﻿an﻿accident﻿happens﻿and﻿what﻿the﻿ cost﻿of﻿that﻿accident﻿would﻿be﻿for﻿any﻿given﻿route.﻿This﻿information﻿is﻿very﻿valuable﻿for﻿both﻿safety﻿ and﻿cost﻿saving﻿for﻿drivers﻿and﻿insurance﻿companies. KeywORdS Autonomous Vehicles, Data Analytics, Data Visualization, Geospatial Data, Insurance Industry, Risk Analysis, Road Safety, Self-Driving Cars	data visualization	Robert Hipps;Tushar Chopra;Peng Zhao;Edward Kwartler;Sylvain Jaume	2017	IJKBO	10.4018/IJKBO.2017070104	geospatial analysis;data mining;computer science	Robotics	-15.50630846715615	-24.546614336331416	111758
91d3a0c2ef36f0c2c1fed77f146fe9228f732138	discovering routine behaviours in smart water meter data	water use activities;approximation algorithms;smart metering;water meters smart meters;time series;water meters;time series analysis clustering algorithms smart meters australia approximation algorithms shape cities and towns;shape;time series analysis;recurrent routine behaviours smart water meter water use activities kalgoorlie boulder western australia;sensor data;smart water meter;clustering algorithms;kalgoorlie boulder;cities and towns;western australia;recurrent pattern;smart meters;australia;recurrent routine behaviours;sensor data smart metering recurrent pattern time series	Smart water meters are being used on a large scale by water providers to record hourly water use of households. The time series data recorded by smart water meters provide real-time information about water use activities. This paper proposes an algorithm to automatically discover recurrent routine behaviours in smart water meter data. The recurrent routine behaviours characterize regular water use activities during consecutive hours, which occur multiple times in a period. Our algorithm differs from previous exact motif discovery algorithms because we discover frequently occurring short subsequences with variable length. Experiment on a real-world dataset collected from an inland town of Kalgoorlie-Boulder in Western Australia demonstrates that the proposed algorithm discovers useful recurrent routine behaviours of different lengths, which are relevant for domain experts.	algorithm;motif;real-time data;real-time locating system;recurrent neural network;smartwater;time series	Jin Wang;Rachel Cardell-Oliver;Wei Liu	2015	2015 IEEE Tenth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)	10.1109/ISSNIP.2015.7106899	simulation;geography;hydrology;data mining	Robotics	-13.499392941463583	-34.08638691020581	111871
77cd410583a44600c084bb8b511f12959203ad02	association rule mining using treap		The analytical process designed to mine data became more difficult with the rapid information explosion. This in-turn created completely distributed and un-indexed data. Thus assessing and finding relations between variables from large database became a tedious task. There are various association rule mining algorithms available for this process, but a powerful association algorithm which runs in reduced time and space complexity is hard to find. In this work, we propose a new rule mining algorithm which works in a priority model for finding interesting relations in a database using the data structure Treap. While comparing with Apriori’s O (en) and FP growth’s O (n2), the proposed algorithm finishes mining in O (n) in its best case analysis and in O (n log n) in its worst case analysis. This was found to be much better when compared to other algorithms of its kind. The results were evaluated and compared with the existing algorithm.		Hareendran S. Anand;S. S. Vinodchandra	2018	Int. J. Machine Learning & Cybernetics	10.1007/s13042-016-0546-7	time complexity;information explosion;association rule learning;data mining;case analysis;data structure;treap;fsa-red algorithm;computer science	ML	-5.779177341711169	-36.23329635767065	111887
4c2045c64a02ce24e61a64f42281218f674336e2	optimal installation locations for automated external defibrillators in taipei 7-eleven stores: using gis and a genetic algorithm with a new stirring operator	health services accessibility;models theoretical;cities;out of hospital cardiac arrest;commerce;defibrillators;taiwan;emergency medical services;geographic information systems;electric countershock;algorithms;urban population;geography	Immediate treatment with an automated external defibrillator (AED) increases out-of-hospital cardiac arrest (OHCA) patient survival potential. While considerable attention has been given to determining optimal public AED locations, spatial and temporal factors such as time of day and distance from emergency medical services (EMSs) are understudied. Here we describe a geocomputational genetic algorithm with a new stirring operator (GANSO) that considers spatial and temporal cardiac arrest occurrence factors when assessing the feasibility of using Taipei 7-Eleven stores as installation locations for AEDs. Our model is based on two AED conveyance modes, walking/running and driving, involving service distances of 100 and 300 meters, respectively. Our results suggest different AED allocation strategies involving convenience stores in urban settings. In commercial areas, such installations can compensate for temporal gaps in EMS locations when responding to nighttime OHCA incidents. In residential areas, store installations can compensate for long distances from fire stations, where AEDs are currently held in Taipei.	allocation;automated external defibrillators;cardiac arrest;chromosomes;community;defibrillators, external;distance;emergency medical service;gallium;genetic algorithm;geographic information systems;location-allocation;mathematical optimization;patients;premature convergence;software release life cycle;subgroup;teradata warehouse miner;interest	Chung-Yuan Huang;Tzai-Hung Wen	2014		10.1155/2014/241435	simulation;medicine;geographic information system;emergency medical services;medical emergency;computer security;algorithm	HCI	-14.416734413883056	-28.823948577753946	111964
6609bd955b79be417656474af2d471e6382932cf	an alignment approach for context prediction tasks in ubicomp environments	time series estimation;discrete event simulation pervasive computing pattern recognition algorithms location dependent and sensitive;pervasive computing;alignment prediction;prediction algorithms;time series;context prediction accuracy;accuracy;ubiquitous computing environment context prediction task ubicomp environment alignment prediction time series estimation context prediction accuracy;location dependent and sensitive;ubiquitous computing time series;principal component analysis;prediction accuracy;context prediction task;pattern recognition;ubiquitous computing;ubicomp environment;markov processes;numerical models;pattern recognition algorithms;context;pervasive computing context awareness sequences accuracy prediction algorithms principal component analysis ubiquitous computing computational modeling predictive models independent component analysis;discrete event simulation;ubiquitous computing environment	The authors detail the alignment prediction approach-a time-series-estimation technique applicable to both numeric and nonnumeric data-and compare it to four other prediction approaches to determine context-prediction accuracy in ubiquitous computing environments.	time series;ubiquitous computing	Stephan Sigg;Sandra Haseloff;Klaus David	2010	IEEE Pervasive Computing	10.1109/MPRV.2010.23	real-time computing;prediction;computer science;discrete event simulation;machine learning;time series;data mining;accuracy and precision;markov process;ubiquitous computing;principal component analysis	Visualization	-13.382857079051814	-30.971552574158803	112101
dbed9f5ea8e9709b908557f5fa82ec247741cf72	integrated spatio-temporal data mining for forest fire prediction	elman neural network;ucl;dynamic recurrent neural network;discovery;spatio temporal data mining;theses;conference proceedings;digital web resources;ucl discovery;forest fire;open access;ucl library;book chapters;open access repository;forest fire prevention;spatio temporal forecasting;local moran s index;ucl research	Forests play a critical role in sustaining the human environment. Most forest fires not only destroy the natural environment and ecological balance, but also seriously threaten the security of life and property. The early discovery and forecasting of forest fires are both urgent and necessary for forest fire control. This article explores the possible applications of Spatio-temporal Data Mining for forest fire prevention. The research pays special attention to the spatio-temporal forecasting of forest fire areas based upon historic observations. An integrated spatio-temporal forecasting framework – ISTFF – is proposed: it uses a dynamic recurrent neural network for spatial forecasting. The principle and algorithm of ISTFF are presented, and are then illustrated by a case study of forest fire area prediction in Canada. Comparative analysis of ISTFF with other methods shows its high accuracy in short-term prediction. The effect of spatial correlations on the prediction accuracy of spatial forecasting is also explored.	algorithm;artificial neural network;data mining;recurrent neural network;spatial analysis	Tao Cheng;Jiaqiu Wang	2008	Trans. GIS	10.1111/j.1467-9671.2008.01117.x	geography;artificial intelligence;data science;data mining;operations research;cartography	ML	-12.888454952694067	-25.646798966917956	112117
565a55ecd94713cedc7fdef0cc3c7577941a8756	traffic modeling and prediction using sensor networks: who will go where and when?	image matching;traffic modeling and prediction;pedestrian detection;smart cameras;camera sensor network	We propose a probabilistic framework for modeling and predicting traffic patterns using information obtained from wireless sensor networks. For concreteness, we apply the proposed framework to a smart building application in which traffic patterns of humans are modeled and predicted through human detection and matching of their images taken from cameras at different locations. Experiments with more than 100,000 images of over 40 subjects demonstrate promising results in traffic pattern prediction using the proposed algorithm. The algorithm can also be applied to other applications, including surveillance, traffic monitoring, abnormality detection, and location-based services. In addition, the long-term deployment of the network can be used for security, energy conservation, and utilization improvement of smart buildings.	algorithm;location-based service;smart tv;software deployment;website monitoring	Zaihong Shuai;Sangseok Yoon;Songhwai Oh;Ming-Hsuan Yang	2012	TOSN	10.1145/2379799.2379805	smart camera;computer vision;simulation;floating car data;computer science;computer security;visual sensor network	Mobile	-14.661571539592867	-32.30653765375551	112143
5f2c6eacb745b579b9b0595b8a5c60483a6a04c3	measuring road network topology vulnerability by ricci curvature		Describing the basic properties of road network systems, such as their robustness, vulnerability, and reliability, has been a very important research topic in the field of urban transportation. Current research mainly uses several statistical indicators of complex networks to analyze the road network systems. However, these methods are essentially node-based. These node-based methods are more concerned with the number of connections between nodes, and lack of consideration for interactions. So, this leads to the well-known node paradox problem, and their ability of characterizing the local and intrinsic properties of a network is weak. From the perspective of network intrinsic geometry, this paper proposes a method for measuring road network vulnerability using a discrete Ricci curvature, which can identify the key sections of a road network and indicate its fragile elements. The results show that our method performs better than complex network statistics on measuring the vulnerability of a road network. Additionally, it can characterize the evolution of the road network vulnerability among different periods of time in the same city through our method. Finally, we compare our method with the previous method of centrality and show the different between them. This article provides a new perspective on a geometry to analyze the vulnerability ∗Corresponding author Email address: lihaifeng@csu.edu.cn (Haifeng Li) Preprint submitted to Journal Name November 15, 2018 ar X iv :1 81 1. 05 74 3v 1 [ cs .S I] 1 4 N ov 2 01 8 of a road network and describes the inherent nature of the vulnerability of a road system from a new perspective. It also contributes to enriching the analytical methods of complex road networks.	centrality;complex network;email;interaction;network topology;robustness (computer science);vulnerability (computing);whole earth 'lectronic link	Lei Gao;Xingquan Liu;Yu Liu;Pu Wang;Min Deng;Qing Zhu;Haifeng Li	2018	CoRR			ML	-9.318336005186032	-25.950696074867842	112263
249303a0aee10ea7f0cd84b7c721fad600dc1605	mining fault tolerant frequent patterns using pattern growth approach	pattern clustering;pattern growth approach;frequent pattern;frequent pattern mining;fault tolerant;fault tolerant frequent patterns mining;search space;tree data structures data mining fault tolerance pattern clustering relational databases;fault tolerance data mining itemsets frequency space exploration data structures association rules intrusion detection gene expression pattern matching;tree data structures;data mining;frequent itemset;association rule;fault tolerance;transactional datasets;bit vector representation and association rules fault tolerant frequent patterns mining maximal frequent patterns mining;bit vector representation and association rules;relational databases;data structure;ft fp tree;maximal frequent patterns mining;data structure fault tolerant frequent patterns mining pattern growth approach transactional datasets ft fp tree	Mining fault tolerant (FT) frequent patterns from transactional datasets are very complex than mining all frequent patterns (itemsets), in terms of both search space exploration and support counting of candidate FT-patterns. Previous studies on mining FT frequent patterns adopt Apriori-like candidate set generation- and-test approach, in which a number of dataset scans are needed to declare a candidate FT-pattern frequent. First for checking its FT-pattern support, and then for checking its individual items support present in its FT- pattern which depends on the cardinality of pattern. Inspired from the pattern growth technique for mining frequent itemsets, in this paper we present a novel algorithm for mining FT frequent patterns using pattern growth approach. Our algorithm stores the original transactional dataset in a highly condensed, much smaller data structure called FT-FP-tree, and the FT-pattern support and item support of all the FT- patterns are counting directly from the FT-FP-tree, without scanning the original dataset multiple times. While costly candidate set generations are avoided by generating conditional patterns from FT-FP-tree. Our extensive experiments on benchmark datasets suggest that, mining FT frequent patterns using our algorithm is highly efficient as compared to Apriori-like approach.	anti-pattern;apriori algorithm;benchmark (computing);bit array;data mining and knowledge discovery;data structure;experiment;fault tolerance;financial times;han unification;knowledge representation and reasoning	Shariq Bashir;Zahid Halim;Abdul Rauf Baig	2008	2008 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2008.4493532	fault tolerance;data structure;computer science;pattern recognition;data mining;database;programming language	DB	-5.595211394106924	-37.11208146871795	112625
e9ce7853fd1f1227a719f754dc3b70e728da47d6	an analytical evaluation of a real-time traffic information system using probe vehicles	wireless communication systems;feasibility analysis;global positioning satellite;real time traffic;traffic model;real time information;traffic probes;traffic modeling;traffic congestion;roads;global positioning system;probe vehicles;design;evaluation;freeways;real time traffic measurement;information system;driver information systems;analytical model;traffic measurement;vehicle miles traveled	Abstract As the number of vehicle miles traveled each year continues to increase, traffic congestion only worsens, and the need for accurate, timely traffic information becomes stronger. With recent advances in technology, a growing number of vehicles are now equipped with wireless communication systems and global positioning satellite (GPS) sensors. Using such vehicles as mobile traffic probes has the promise of accurate and timely information without large infrastructure and construction expenses. To address some of the basic design and feasibility questions for the concept of using probe vehicles to provide real-time traffic information, an analytical model was developed that examines the relationships between key system parameters. The results of this modeling show that a real-time traffic information system based on probe vehicles is very feasible, and should work for freeways at penetrations over 3%, while surface roads would require more than 5%. With the increased use of in-vehicle telematics, the...	information system;real-time transcription	Martin A. Ferman;Dennis Blumenfeld;Xiaowen Dai	2005	J. Intellig. Transport. Systems	10.1080/15472450590912547	feasibility study;design;simulation;floating car data;global positioning system;vehicle information and communication system;engineering;evaluation;traffic conflict;transport engineering;computer security;information system	Embedded	-17.946898827893566	-28.72598701801331	112631
451cf417ba915150b651c220dcff91d642eed3a9	an analysis method of traveling-time patterns between rooms from entry and exit data of office workers		IC card systems have become popular in recent years, and their log data are used for analyzing human behavior. In this paper, we propose a method for analyzing workers' travel-between-rooms time patterns using log data in an entry and exit management system. We express workers using features representing travel time, extract a set of workers with similar travel time patterns using clustering, and confirm the relationship between travel time patterns and workers' attributes using actual data.		Seidai Kojima;Hayato Ishigure;Miwa Sakata;Atsuko Mutoh;Koichi Moriyama;Nobuhiro Inuzuka	2018	2018 IEEE 7th Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2018.8574752	data mining;smart card;cluster analysis;management system;time patterns;computer science	DB	-17.733011912654177	-32.49219308351848	112718
bd7b55d6c4d5f60a777e7f76d1b80b0c74aa6a16	an indoor trajectory frequent pattern mining algorithm based on vague grid sequence		Abstract Trajectory frequent pattern mining is an important branch of data mining. The constraint of indoor space is between Euclid space and road network space, which makes it difficult to represent the approximate positions. Grid partition method is a feasible way to solve this problem, but it will lead to a sharp problem of grid boundary. Considering the indoor trajectory frequent pattern mining, this paper proposes a grid partition method based on vertical projection distance ( VGS ) and a trajectory frequent pattern mining algorithm based on vague grid sequence ( VGS-PrefixSpan ). At first, each grid is divided into explicit zones and vague zones according to vertical projection distance. Then the trajectories are transformed into vague grid sequences. At last, VGS-PrefixSpan is a PrefixSpan -like algorithm to mine trajectory frequent patterns from vague grid sequences. Experimental results show that VGS-PrefixSpan has better performance than VSP-PrefixSpan under the same area ratio of explicit zones and covered zones, and has better mining results than VSP-PrefixSpan and GS-PrefixSpan under any value of Min _ Support . In terms of mining efficiency, the total time of VGS-PrefixSpan is close to GS-PrefixSpan and less than VSP-PrefixSpan about two orders of magnitude. Therefore, VGS-PrefixSpan is an effective and efficient algorithm in mining frequent patterns of indoor trajectories. As a research hotspot in Location Based Services (LBS), mining frequent patterns of indoor trajectories can protect the trajectory privacy of users from being leaked or mitigating the risk of leakage. Therefore, the study of trajectory frequent patterns is of great significance to public security and personal information protection.		Yi Chen;Peisen Yuan;Ming Qiu;Dechang Pi	2019	Expert Syst. Appl.	10.1016/j.eswa.2018.08.053	grid;vertical projection;data mining;partition (number theory);location-based service;trajectory;pound (mass);hotspot (wi-fi);algorithm;personally identifiable information;computer science	ML	-15.31052085998518	-36.090194087895384	112961
f5a45180a3f76e33d73ca70fb2c3eb9d35108c6f	development and validation of a 3d rbf-spectral model for coastal wave simulation				Cécile Raoult;Michel Benoit;Marissa L. Yates	2019	J. Comput. Physics	10.1016/j.jcp.2018.11.002		Theory	-11.377607849667449	-26.913556880131278	113111
a49dbab0216d0f9e839375545480f732761a15d5	inferring transportation mode and human activity from mobile sensing in daily life		In this paper, we focus on simultaneous inference of transportation modes and human activities in daily life via modelling and inference from multivariate time series data, which are streamed from off-the-shelf mobile sensors (e.g. embedded in smartphones) in real-world dynamic environments. The transportation mode will be inferred from the structured hierarchical contexts associated with human activities. Through our mobile context recognition system, an accurate and robust solution can be obtained to infer transportation mode, human activity and their associated contexts (e.g. whether the user is in moving or stationary environment) simultaneously. There are many challenges in analysing and modelling human mobility patterns within urban areas due to the ever-changing environments of mobile users. For instance, a user could stay at a particular location and then travel to various destinations depending on the tasks they carry within a day. Consequently, there is a need to reduce the reliance on location-based sensors (e.g. GPS), since they consume a significant amount of energy on smart devices, for the purpose of intelligent mobile sensing (i.e. automatic inference of transportation mode, human activity and associated contexts). Nevertheless, our system is capable of outperforming the simplistic approach that only considers independent classifications of multiple context label sets on data streamed from low-energy sensors.		Jonathan Liono;Zahraa Said Abdallah;A. Kai Qin;Flora Dilys Salim	2018		10.1145/3286978.3287006	time series;ubiquitous computing;human–computer interaction;global positioning system;computer science;multivariate statistics;distributed computing;inference	Mobile	-17.64596602898079	-34.17460353410675	113205
3d68fc54b53ee8b229da5a95467b918b234f4952	distributed autonomous online learning: regrets and intrinsic privacy-preserving properties	distributed data;topology;data privacy computer aided instruction data handling;communication networks;computer aided instruction;distributed computing;privacy preservation;online learning;privacy sensitive applications distributed autonomous online learning intrinsic privacy preserving properties local data sources local parameters privacy preservation malicious learner massive data handling;artificial intelligent;convex functions;network topology;vectors;science learning;data privacy;community networks;convex function;distributed databases;data handling;vectors distributed databases convex functions network topology communication networks privacy topology;privacy;privacy preservation online learning distributed computing	Online learning has become increasingly popular on handling massive data. The sequential nature of online learning, however, requires a centralized learner to store data and update parameters. In this paper, we consider online learning with distributed data sources. The autonomous learners update local parameters based on local data sources and periodically exchange information with a small subset of neighbors in a communication network. We derive the regret bound for strongly convex functions that generalizes the work by Ram et al. for convex functions. More importantly, we show that our algorithm has intrinsic privacy-preserving properties, and we prove the sufficient and necessary conditions for privacy preservation in the network. These conditions imply that for networks with greater-than-one connectivity, a malicious learner cannot reconstruct the subgradients (and sensitive raw data) of other learners, which makes our algorithm appealing in privacy-sensitive applications.	algorithm;autonomous robot;centralized computing;convex function;internet privacy;linear system;malware;online machine learning;random-access memory;regret (decision theory);telecommunications network	Feng Yan;Shreyas Sundaram;S. V. N. Vishwanathan;Yuan Qi	2013	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2012.191	convex function;information privacy;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;database;distributed computing;world wide web;distributed database	ML	-8.644295891543816	-29.06149934507485	113290
0e7474b1a11167f01bd3e69abda283db20df0cab	approximate sensory data collection: a survey	internet of things;sensory data collection;approximate computation;wireless sensor networks	With the rapid development of the Internet of Things (IoTs), wireless sensor networks (WSNs) and related techniques, the amount of sensory data manifests an explosive growth. In some applications of IoTs and WSNs, the size of sensory data has already exceeded several petabytes annually, which brings too many troubles and challenges for the data collection, which is a primary operation in IoTs and WSNs. Since the exact data collection is not affordable for many WSN and IoT systems due to the limitations on bandwidth and energy, many approximate data collection algorithms have been proposed in the last decade. This survey reviews the state of the art of approximatedatacollectionalgorithms. Weclassifythemintothreecategories: themodel-basedones, the compressive sensing based ones, and the query-driven ones. For each category of algorithms, the advantages and disadvantages are elaborated, some challenges and unsolved problems are pointed out, and the research prospects are forecasted.	approximation algorithm;categories;compressed sensing;data collection;internet of things;petabyte;question (inquiry);review [publication type];waisman syndrome	Siyao Cheng;Zhipeng Cai;Jianzhong Li	2017		10.3390/s17030564	embedded system;wireless sensor network;telecommunications;computer science;data mining;computer security;internet of things	Mobile	-11.5254646737311	-33.13282045209821	113710
dc41a773f11f03b2324278c38ce930da0c2b6d02	accessing and extending the utility of united states forest inventory data	internet;fires;forestry;geographic information systems;inventory management;visual databases;forest vegetation simulator;internet;united states forest inventory data;fire hazard;forest inventory mapmaker web-application;fuel treatment evaluator web-application;socio-economic geo-spatial data;spatial resource support system	The Forest Inventory and Analysis program of the United States Forest Service has been operational since the 1930's. Data collected prior to 1977 is unavailable in electronic format. More recent data is available for downloading from the Internet. Reporting tools such as the forest inventory mapmaker Web-application have been developed to generate population estimates of forest area, numbers of trees, timber volume, growth, removals and mortality for a wide variety of stand and/or tree characteristics. The fuel treatment evaluator (FTE) Web-application links forest inventory data to both fire hazard and socio-economic geo-spatial data. Linking this information aids planners in identifying potential fire hazard hotspots and evaluating alternative fuel treatment options. The FTE program can also generate inputs to systems such as the spatial resource support system and growth and yield programs such as the Forest Vegetation Simulator.	download;hotspot (wi-fi);internet;interpreter (computing);the forest;web application	Patrick D. Miles;Wayne D. Shepperd;Ronald E. McRoberts;John S. Vissage;Kenneth E. Skog;Bryce J. Stokes	2004	Proceedings. 15th International Workshop on Database and Expert Systems Applications, 2004.	10.1109/DEXA.2004.1333537	the internet;simulation;forest inventory;spatial analysis;geographic information system;data collection	Metrics	-14.767379962008816	-27.398974466623297	114311
6a86e78b19f8069e0d4326aed5ce6731e258e567	urban road optimization based on safety and cyclists' effort required by bike tracks	routing;bike tracks urban road optimization sustainable mobility brazilian government bicycles public transportation mobile application urban roads physical stress;traffic information systems bicycles graphical user interfaces mobile computing road safety smart phones sustainable development;mobile applications;urban areas;roads;safety;brazil;mobile handsets sensors bicycles cities and towns global positioning system roads;bikeways	Sustainable mobility is becoming the main goal of several researches due to the significant problems caused by present day transportation means. For instance, vehicles powered by fossil or sugar cane derived fuels bring about negative impacts to the environment as well as to society. A solution proposed by Brazilian Government is to encourage the use of bicycles on tracks, which can be either interspersed or not with public transportation. On this assumption, the project described in this paper aims at developing a mobile application for capturing data about urban roads in order to define a route exerting less physical stress on the rider and that is safe.	android;fossil;microsoft windows;mobile app;mobile device;operating system;point of view (computer hardware company);program optimization;smart city;traverse;windows phone;ios	Henrique Dezani	2015	2015 IEEE 18th International Conference on Intelligent Transportation Systems	10.1109/ITSC.2015.184	simulation;engineering;civil engineering;transport engineering	Robotics	-17.079756996387417	-28.27892894288192	114336
f17942092e61e3091dfd4afe2e327f5fbdb2d3aa	scalable detection of traffic congestion from massive floating car data streams	trajectory data mining;geodesy and geoinformatics;fcd;systemvetenskap informationssystem och informatik;information systems;congestion detection;transportvetenskap;transport science;datalogi;datavetenskap datalogi;computer science;intelligent transport systems;geodesi och geoinformatik	Motivated by the high utility and growing availability of Floating Car Data (FCD) streams for traffic congestion modeling and subsequent traffic congestion-related intelligent traffic management tasks, this paper proposes a grid-based, time-inhomogeneous model and method for the detection of congestion from large FCD streams. Furthermore, the paper proposes a simple but effective, high-level implementation of the method using off-the-shelf relational database technology that can readily be ported to Big Data processing frameworks. Empirical evaluations on millions of real-world taxi trajectories show that 1) the spatio-temporal distribution and clustering of the detected congestions are reasonable and 2) the method and its prototype implementation scale linearly with the input size and the geographical level of detail / spatio-temporal resolution of the model.	big data;cluster analysis;family computer disk system;high- and low-level;information;level of detail;network congestion;prototype;relational database	Gyözö Gidófalvi;Can Yang	2015		10.1145/2835022.2835041	simulation;floating car data;engineering;data mining;computer security	DB	-17.900076458431098	-31.72057606505747	114498
9ef23e3472a8e0b3d9f940767a5792aa69a3c54e	spatial itemset mining: a framework to explore itemsets in geographic space		Driven by the major adoption of mobile devices, user contributed geographic information has become ubiquitous. A typical example is georeferenced and tagged social media, linking a location to a set of features or attributes. Mining frequent sets of discrete attributes to discover interesting patterns and rules of attribute usage in such data sets is an important data mining task.#R##N##R##N#In this work we extend the frequent itemset mining framework to model the spatial distribution of itemsets and association rules. For this, we expect the input transactions to have an associated spatial attribute, as, for example, present in georeferenced tag sets. Using the framework, we formulate interestingness measures that are based on the underlying spatial distribution of the input transactions, namely area, spatial support, location-conditional support, and spatial confidence. We show that describing the spatial characteristics of itemsets cannot be handled by existing approaches to mine association rules with numeric attributes, and that the problem is different from co-location pattern mining and spatial association rules mining. We demonstrate the usefulness of our proposed extension by different mining tasks using a real-world data set from Flickr.		Christian Sengstock;Michael Gertz	2013		10.1007/978-3-642-40683-6_12	data science;data mining;database	ML	-18.603461981814544	-35.51726905091493	114775
b8debffde76c0f0cd2451d0ce7ee68fd9556b756	fpnes: fuzzy petri net based expert system for bridges damage assessment	damage assessment;expert systems;inference mechanisms;uncertainty handling;fuzzy set theory;civil engineering computing;knowledge representation civil engineering computing expert systems petri nets fuzzy set theory uncertainty handling inference mechanisms;taiwan fpnes fuzzy petri net based expert system bridge damage assessment integrated expert systems reasoning imprecise information knowledge representation hierarchical fuzzy petri nets reasoning mechanism explanation reasoning process uncertain information rule based reasoning rule activation tokens da shi bridge;hybrid intelligent systems fuzzy systems expert systems bridges fuzzy reasoning petri nets knowledge representation civil engineering computer science uncertainty;petri nets;knowledge representation;petri net;rule based reasoning;expert system	A framework of integrated expert systems based on fuzzy Petri net, called fuzzy Petri net based expert system (FPNES) are proposed for bridge damage assessment. Major features of FPNES include: reasoning for uncertain and imprecise information; knowledge representation through the use of hierarchical fuzzy Petri nets; reasoning mechanism based on fuzzy Petri nets; and explanation of reasoning process through the use of hierarchical fuzzy Petri nets. FPNES offer several important benefits: (1) providing reasoning mechanism for uncertain and fuzzy information, (2) improving the efficiency of rule based reasoning by constructing relationship of concurrency among rule activation, and (3) explaining how to reach conclusions through the movements of tokens in fuzzy Petri nets. An application to the damage assessment of the Da-Shi bridge in Taiwan is used as an illustrative example of FPNES.	concurrency (computer science);expert system;knowledge representation and reasoning;petri net	Kevin F. R. Liu;Jonathan Lee;Weiling Chiang;Stephen J. H. Yang	1998		10.1109/TAI.1998.744858	legal expert system;computer science;artificial intelligence;neuro-fuzzy;model-based reasoning;machine learning;data mining;process architecture;petri net;expert system;fuzzy set operations	AI	-6.952519541811583	-24.32013514636173	114850
7d69fc9163ad42564063bebc3d1cbdca99cd09a5	mc1: a bespoke analysis tool for spatio-temporal park traffic data		This paper describes a web-based traffic data analysis tool developed for the VAST 2017 Mini Challenge 1. The tool consists of two linked heat maps which allow for the inspection of daily activity for vehicles, as well as a histogram which allows for the analysis of total time spent by vehicles in the park. Combined, these views allow for the analysis of both spatial and temporal patterns in the park preserve.		Dimitar Kirilov;Isabel Lindmae;Andrew Burks;Chihua Ma;G. Elisabeta Marai	2017	2017 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2017.8585624	computer science;data mining;bespoke	Visualization	-17.64953184747726	-31.87682119956338	115080
1467e45c2cbe5cd7aec1655af0b9a6975f9cd5d5	space-efficient estimation of statistics over sub-sampled streams	frequency moments;data streams;sub sampling	In many stream monitoring situations, the data arrival rate is so high that it is not even possible to observe each element of the stream. The most common solution is to sample a small fraction of the data stream and use the sample to infer properties and estimate aggregates of the original stream. However, the quantities that need to be computed on the sampled stream are often different from the original quantities of interest and their estimation requires new algorithms. We present upper and lower bounds (often matching) for estimating frequency moments, support size, entropy, and heavy hitters of the original stream from the data observed in the sampled stream.	algorithm;matching (graph theory);queueing theory;sampling (signal processing);stream cipher;streaming algorithm	Andrew McGregor;A. Pavan;Srikanta Tirthapura;David P. Woodruff	2012	Algorithmica	10.1007/s00453-015-9974-0	data stream clustering;computer science;pattern recognition;data mining;data stream mining;statistics	DB	-7.399882562282586	-34.13163847549984	115402
dde8408bfa83157a5ccab2e18df00f960ae7646f	sliding-window filtering with constraints of compactness and recency in incremental database	databases;filtering;databases itemsets data mining partitioning algorithms algorithm design and analysis filtering association rules;itemsets;frequent pattern;sliding window filtering;database management systems data mining;frequent pattern mining;database management systems;incremental database;compactness frequency recency pattern sliding window filtering incremental database incremental mining technique knowledge discovery frequent patterns mining time vertical bitmap representation;time vertical bitmap representation;association rules;incremental mining;data mining;frequent patterns mining;incremental mining technique;constraint;compactness frequency recency pattern;algorithm design and analysis;incremental mining sliding window filtering constraint;sliding window;partitioning algorithms;knowledge discovery	In true-life the database is changed continually in many applications. Incremental mining technique has been developed to avoid rescanning database for knowledge discovery. Recent and compact constraints also are developed for frequent patterns mining. We store the database with a time-vertical bitmap representation, therefore the supports of frequent pattern and recent pattern can be computed fast. Link and bitmap are adopted, so a mass of running time can be saved during incremental mining process. Besides, to mine more efficiently in the incremental database, two concepts of recency and compactness are introduced into sliding-window filtering (denoted as SWF). In essence, an incremental database is divided into several partitions, and a filtering threshold is employed in each partition to handle candidate itemsets generation under constraints of recency and compactness. By employing SWF with constraints of compactness and recency, user satisfactory CFR-patterns (compactness, frequency and recency) can be discovered. Experimental result shows that the running time can be reduced.	bitmap;kinetic data structure;reduction (complexity);swf;time complexity	Jiadong Ren;Haiyan Tian;Shiyong Lv	2008	2008 Fourth International Conference on Networked Computing and Advanced Information Management	10.1109/NCM.2008.78	filter;sliding window protocol;algorithm design;association rule learning;computer science;pattern recognition;data mining;database;knowledge extraction;constraint	DB	-5.178553259973199	-37.077839653197124	115563
bb8011a7631968b7b3b6ee2978faf5e1f8f4d1f8	a fuzzy search engine weighted approach to result merging for metasearch	search engine;owa;metasearch engines;data fusion;metasearching;ordered weighted average;igowa;owa operator	Each search engine queried by a metasearch engine returns results in the form of a result list of documents. The key issue is to combine these lists to achieve the best performance. The salient contribution of this paper is a result merging model that applies Yager's fuzzy aggregation Ordered Weight Average, OWA, operator in combination with the concept of importance guided aggregation to extend the OWA-based result merging model proposed by Diaz. Our result merging model, IGOWA, (Importance Guided OWA) improves upon the OWA model proposed by Diaz so as to allow weights to be applied to search engine result lists. To support our model we also explore a scheme for computing search engine weights. We call the weights obtained from our scheme Query-System Weights and we compare this with the scheme for computing search engine weights proposed by Aslam and Montague. We refer to Aslam's scheme as System Weights.	web search engine	Arijit K De;Elizabeth D. Diaz;Vijay V. Raghavan	2007		10.1007/978-3-540-72530-5_11	metasearch engine;computer science;machine learning;data mining;mathematics;sensor fusion;information retrieval;search engine	Theory	-5.836596069575194	-26.511462891010435	115623
47a5a5c175553a82e242e1dbcac5d36caccf65dd	assessing the effect of temporal interval length on the blending of landsat-modis surface reflectance for different land cover types in southwestern continental united states	landsat;spatial temporal image fusion;temporal interval;surface reflectance;modis	1 State Key Laboratory of Remote Sensing Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing 100101, China; E-Mails: fudongjie@gmail.com (D.F.); chenhao91@radi.ac.cn (H.C.); sunxuejian1@163.com (X.S.); wutx@radi.ac.cn (T.W.) 2 Urban Science Department, College of Applied Arts and Science of Beijing Union University, Beijing 100191, China; E-Mails: juaner1020@gmail.com	academy;alpha compositing;köppen climate classification	Dongjie Fu;Lifu Zhang;Hao Chen;Juan Wang;Xuejian Sun;Taixia Wu	2015	ISPRS Int. J. Geo-Information	10.3390/ijgi4042542	meteorology;geography;hydrology;remote sensing	ML	-10.28004988161912	-26.284228267613134	115688
62f1acc01cebefd6379beeee8e019447f6ef57eb	transportation mode detection using mobile phones and gis information	transportation networks;context awareness;context aware;decision tree;mobile device;real time;multilayer perceptron;mobile phone;gps;gis;random forest;classification system;pattern recognition;mobile phones	The transportation mode such as walking, cycling or on a train denotes an important characteristic of the mobile user's context. In this paper, we propose an approach to inferring a user's mode of transportation based on the GPS sensor on her mobile device and knowledge of the underlying transportation network. The transportation network information considered includes real time bus locations, spatial rail and spatial bus stop information. We identify and derive the relevant features related to transportation network information to improve classification effectiveness. This approach can achieve over 93.5% accuracy for inferring various transportation modes including: car, bus, aboveground train, walking, bike, and stationary. Our approach improves the accuracy of detection by 17% in comparison with the GPS only approach, and 9% in comparison with GPS with GIS models. The proposed approach is the first to distinguish between motorized transportation modes such as bus, car and aboveground train with such high accuracy. Additionally, if a user is travelling by bus, we provide further information about which particular bus the user is riding. Five different inference models including Bayesian Net, Decision Tree, Random Forest, Naïve Bayesian and Multilayer Perceptron, are tested in the experiments. The final classification system is deployed and available to the public.	bayesian network;decision tree;experiment;geographic information system;global positioning system;mobile device;mobile phone;multilayer perceptron;random forest;stationary process	Leon Stenneth;Ouri Wolfson;Philip S. Yu;Bo Xu	2011		10.1145/2093973.2093982	random forest;embedded system;simulation;geomatics;global positioning system;computer science;machine learning;decision tree;mobile device;multilayer perceptron;computer security	AI	-17.3645219973748	-32.938547000477264	115761
80b1aa181d1d7aacbb6e2c072e60271406158492	mining urban passengers' travel patterns from incomplete data with use cases	data mining;public transit system;transit demands;urban analysis;closed transit chains	Abstract The rapid development of the Internet of Things (IoT) and Intelligent and Connected Transportation Systems (ICTS) are making our city smarter and greener. For large cities with millions of population, their public transit systems are of great significance to mitigating the road congestion along with reducing the emission of greenhouse gases. One critical problem transit authorities encounter is that they can not clearly understand the actual behavioral preference and travel demand of their passengers, worse even, nowadays, the passively collected data from IoT devices do not guarantee the integrity of information and make it more difficult. To address these problems, in this research, we first propose a novel framework to derive passengers’ closed transit chains along with their home and work locations from incomplete travel records using an information enrichment and probabilistic inference approach. We then leverage both evaluation and volunteers’ records to evaluate the usability and theoretical boundaries of our methods. We finally apply our proposed framework to mine a series of useful information about the city and behavioral preferences of our passengers. Our proposed methods are applicable to mining individuals’ behavioral patterns from sparsely collected crowdsourcing data in future.		Xiaoxiong Weng;Yongxin Liu;Houbing Song;Shushen Yao;Pengfei Zhang	2018	Computer Networks	10.1016/j.comnet.2018.01.048	computer science;distributed computing;public transport;probabilistic logic;usability;transport engineering;use case;behavioral pattern;inference;crowdsourcing;population	HCI	-17.656193949876055	-32.41736948118326	115770
679b992bcea0be3407107485d8ee66b646acb9d1	"""anomaly detection at """"supersonic"""" speed"""			anomaly detection	Cristian Grozea;Pavel Laskov	2012	it - Information Technology	10.1524/itit.2012.0667		Robotics	-11.459073525108659	-27.557646598419872	115771
d325c7d167e514cb8653e9be08f6b59e361efaf3	multivariate spatial outlier detection	outlier detection;spatial data mining;algorithm	A spatial outlier is a spatially referenced object whose non-spatial attribute values are significantly different from the values of its neighborhood. Identification of spatial outliers can lead to the discovery of unexpected, interesting, and useful spatial patterns for further analysis. Previous work in spatial outlier detection focuses on detecting spatial outliers with a single attribute. In the paper, we propose two approaches to discover spatial outliers with multiple attributes. We formulate the multi-attribute spatial outlier detection problem in a general way, provide two effective detection algorithms, and analyze their computation complexity. In addition, using a real-world census data, we demonstrate that our approaches can effectively identify local abnormality in large spatial data sets.	algorithm;anomaly detection;computation;sensor;spatial reference system	Chang-Tien Lu;Dechang Chen;Yufeng Kou	2004	International Journal on Artificial Intelligence Tools	10.1142/S021821300400182X	anomaly detection;computer science;pattern recognition;data mining	ML	-11.157626997425409	-35.208504461477936	115908
e8ea804cfaab56686be1c389f6496acfa933d645	an information theoretic technique to design belief network based expert systems	belief networks;design tool;expert systems;financial distress;knowledge acquisition;network structure;information theoretic;weak dependence;information theory;probabilistic reasoning;belief network;expert system	Abstract   This paper addresses the problem of constructing belief network based expert systems. We discuss a design tool that assists in the development of such expert systems by comparing alternative representations. The design tool uses information theoretic measures to compare alternative structures. Three important capabilities of the design tool are discussed: (i) evaluating alternative structures based on sample data; (ii) finding optimal networks with specified connectivity conditions; and (iii) eliminating weak dependencies from derived network structures. We have examined the performance of the design tool on many sets of simulated data, and show that the design tool can accurately recover the important dependencies across variables in a problem domain. We illustrate how this program can be used to design a belief network for evaluating the financial distress situation for banks.	bayesian network;expert system;information theory	Sumit Sarkar;Ram S. Sriram;Shibu Joykutty;Ishwar Murthy	1996	Decision Support Systems	10.1016/0167-9236(95)00020-8	computer science;artificial intelligence;machine learning;bayesian network;data mining;management science;probabilistic logic;expert system	AI	-6.23903170247381	-25.628508398386433	115936
f22ec8403fda313e9ee5051999bc495049b6b85e	structural simulation of tree growth and response	natural phenomena;trees;l-systems- statics;forest management;forest succession;computer graphic	Each tree is unique because of the physical environment it experiences over the course of its life. Environmental factors shape a tree within the bounds of its genotype. Only by modeling the environmental influences can we create realistic models of trees.  To this end, we constructed a structural simulation that calculates the mass of each branch of the tree to emulate the mechanisms the tree uses to balance its weight, and that estimates the photosynthesis return of the leaves to simulate phototropism.  Our effort is motivated by a desire to construct a predictive tool that can be used by both those in computer graphics and forest management, with applications in image synthesis, dendrochronology, mensuration and the simulation of forest succession.	simulation	John C. Hart;Brent Baker;Jeyprakash Michaelraj	2003	The Visual Computer	10.1007/s00371-002-0189-4152	forest restoration;ecological succession;forest management	Graphics	-14.293826934381975	-25.42263917928049	116071
f702328eaa9ab0ca2b5e562a5f51fa67f0c33bac	fuzziness vs. probability in a data mining application for soil classification	fuzzy classification;statistical measures;probability;fuzziness;cognitive psychology;probabilistic method;uncertainty;bayes methods;fuzzy models;knowledge discovery fuzziness probability data mining application knowledge extraction spatial entity fuzzy boundary fuzzy soil classifications cognitive psychology statistical measures fuzzy models probabilistic methods bayesian method fuzzy method;knowledge extraction;bayesian methods;probabilistic methods;data mining;cognitive;fuzzy set theory;bayesian method;hybrid model;soil classification;fuzzy soil classifications;fuzzy logic;hybrid approach;boosting;geophysics computing;data mining application;statistical analysis;fuzzy method;model uncertainty;spatial entity;fuzzy boundary;pattern classification;soil data mining uncertainty bayesian methods decision trees boosting;probability cognitive data mining soil classification fuzzy logic;decision trees;soil;statistical analysis bayes methods data mining fuzzy set theory geophysics computing pattern classification probability soil;fuzzy model;knowledge discovery	Data mining methods have been proven effective in extracting knowledge from existing data sources for the classification of soils. Previous studies have suggested that soils are spatial entities with fuzzy boundaries and prompted the development of data mining methods to extract knowledge that allows for fuzzy classifications of soils. This paper first looks at the nature of soil classification from the perspective of cognitive psychology. It then examines data mining methods used for fuzzy soil classification. It notes that some of the methods are inherently hybrids that combine statistical measures with fuzzy models on sound cognitive bases. This paper reflects upon the long lasting debate on fuzziness versus probability for modeling uncertainties and suggests that hybrid models are valid both practically and cognitively. At last, some preliminary results are reported in comparing pure probabilistic methods (Bayesian), a fuzzy method, and two hybrid approaches to knowledge discovery for soil classification that supports the suggestion.	approximation;complex systems;data mining;entity;fuzzy concept;fuzzy logic;fuzzy set;mathematical model;membership function (mathematics);pattern recognition;randomness;set theory;soil classification;statistical classification;two-hybrid screening;vagueness	Feng Qi	2010	2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2010.5569853	bayesian probability;computer science;probabilistic method;machine learning;pattern recognition;data mining;mathematics;knowledge extraction;statistics	ML	-4.750824193003658	-26.145171785257304	116193
2aeac1b67fa2ce65ee905c0ee9e23bdcb96dc1d1	mining sequential pattern using df2ls	databases;pruning strategies;itemsets;spam;dynamic sequence extension pruning;unsolicited electronic mail;lattice theory;sequences itemsets databases unsolicited electronic mail frequency costs data mining electronic mail space exploration testing;search space;large dataset;iep;spam sequential pattern mining dynamic frequent 2 sequence lists sep iep pruning strategies dynamic sequence extension pruning dynamic item extension pruning apriori like sequence mining algorithms lattice theory;data mining;sequence mining;heuristic algorithms;sep;sequential pattern mining;sequential pattern;dynamic frequent 2 sequence lists;tin;apriori like sequence mining algorithms;algorithm design and analysis;dynamic item extension pruning	In this paper, based on SEP and IEP proposed in our previous work, we present two novel pruning strategies, DSEP (dynamic sequence extension pruning) and DIEP (dynamic item extension pruning), which can be used in all Apriori-like sequence mining algorithms or lattice-theoretic approaches. DSEP/DIEP uses DF2Ls (Dynamic Frequent 2-Sequence Lists), which is built by previous enumerations, to prune out infrequent candidate sequences during mining process. With a little more memory overhead, proposed pruning strategies can prune invalidated search space and decrease the total cost of frequency counting effectively. For effectiveness testing reason, we optimize SPAM by using proposed pruning strategies and present the improved algorithm, SPAM+, which uses DSEP and DIEP to prune the search space of SPAM by sharing dynamic frequent 2-sequences lists. A comprehensive performance experiments study shows that SPAM+ outperforms SPAM by a factor of 10 on small datasets and better than 35% to 58% on reasonably large dataset.	algorithm;decade (log scale);experiment;overhead (computing);sequential pattern mining;symantec endpoint protection;theory	Xu Yusheng;Zhang Lanhui;Zhixin Ma;Li Lian;Xiaoyun Chen;Tharam S. Dillon	2008	2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2008.29	sequential pattern mining;computer science;machine learning;pattern recognition;data mining	DB	-5.82667712580325	-36.917912882352915	116288
1dcd4bf5e8d7c8d7f7f99fb17996e7cb573b5715	exact discovery of the most interesting sequential patterns		This paper presents a framework for exact discovery of the most interesting sequential patterns. It combines (1) a novel definition of the expected support for a sequential pattern – a concept on which most interestingness measures directly rely – with (2) SkOPUS: a new branch-and-bound algorithm for the exact discovery of top-k sequential patterns under a given measure of interest. We carry out experiments on both synthetic data with known patterns and realworld datasets; both experiments confirm the consistency and relevance of our approach.	4000 series;algorithm;bayesian network;branch and bound;computation;experiment;heuristic (computer science);relevance;synthetic data;the australian	Tao Li;Geoffrey I. Webb;François Petitjean	2015	CoRR			ML	-9.652160057880383	-37.59435607665423	116360
0f7527a81602db01c432c8cf3961b1fb1e620362	predictive modeling of forecast uncertainty in the route availability planning tool (rapt).	bayesian prediction;air traffic control;modeling technique;decision tree;attribute selection;model generation;rule based;data mining;multi layer perceptron;prediction model;real time computing;air traffic management	MIT Lincoln Laboratory has developed the Route Availability Planning Tool (RAPT), which provides automated convective weather guidance to air traffic managers of the NYC metro region. Prior studies of RAPT have shown high-accuracy guidance from forecast weather, but further refinements to prevent forecast misclassification is still desirable. An attribute set of highly correlated predictors for forecast misclassification is identified. Using this attribute set, a variety of prediction models for forecast misclassification are generated and evaluated. Rule-based models, decision trees, multi-layer perceptrons, and Bayesian prediction model techniques are used. Filtering, resampling, and attribute selection methods are applied to refine model generation. Our results show promising accuracy rates for multi-layer perceptrons trained on full attribute sets.	decision tree;multilayer perceptron;predictive modelling;resampling (statistics);route availability planning tool;rule 90	John Hayward;Ngaire Underhill;Richard DeLaura	2010			rule-based system;simulation;computer science;air traffic control;machine learning;decision tree;data mining;predictive modelling;multilayer perceptron	ML	-14.782787776065506	-27.897813520723	116369
c26faafa08d221d840e0bb8ed027c30c11138959	providing consistent opinions from online reviews: a heuristic stepwise optimization approach	stepwise optimization;approximation algorithm;opinion consistency;business intelligence;online reviews	The consistency between review summaries and review ranking lists is important for consumers so they can utilize online reviews effectively and efficiently in their purchase decisions. This paper examines this consistency issue and formulates it as an optimization problem. Based on consumers’ reading behaviors, all possible sets of reviews that consumers would read from ranking lists are considered; the objective is to maximize the expected consistency. Because of the NP-hardness of the problem, exact methods that search for the optimal ranking lists are generally not acceptable in practice. Hence, a heuristic approach (the enhanced stepwise optimization procedure) is proposed. This approach is an effective and efficient approximation that selects reviews iteratively to add to the ranking lists in light of expected consistency value, superiority , and execution time . Intensive experiments on both synthetic and real data are conducted, with various environments and settings, along with a relevant user study, revealing that the proposed approach outperforms other related methods.	algorithm;computation;control theory;esop;experiment;fo (complexity);heuristic;iteration;material design;mathematical optimization;nl (complexity);resultant;run time (program lifecycle phase);sentiment analysis;stepwise regression;synthetic intelligence;time complexity;usability testing;gcov	Zunqiang Zhang;Guoqing Chen;Jin Zhang;Xunhua Guo;Qiang Wei	2016	INFORMS Journal on Computing	10.1287/ijoc.2015.0672	mathematical optimization;computer science;data science;machine learning;data mining;business intelligence;approximation algorithm	AI	-11.136347522439438	-37.30263672111046	116581
46f54223cb381d5eb09b558821dcda3f065517f7	effective privacy preservation over composite events with markov correlations	uncertainty;data privacy;markov processes;radiofrequency identification;privacy;data models;steady state	With the rapid development of radio frequency identification (RFID) and sensor networks, complex event processing (CEP) has attracted extensive attention. Meanwhile, privacy preservation techniques towards composite events are becoming increasingly important. However, practical applications may generate a large number of uncertain data due to inaccurate reading and missing reading. An effective method to model such uncertain data is leveraging the Markov model while conducting CEP over it may cause severe privacy leakage. In this paper, we focus on the privacy preservation on the composite events modeled by Markov chains. Due to the inherent uncertainty and correlations of the data, traditional techniques for privacy preservation fail to support the problem. Specifically, we propose two methods (Type_S and Instance_S) with different optimization goals in processing efficiency and the published result amount. The empirical evaluation verifies the efficiency and applicability of our proposed methods.	algorithm;complex event processing;effective method;entropy maximization;markov chain;markov model;mathematical optimization;privacy;radio frequency;radio-frequency identification;spectral leakage;uncertain data	Fangfang Li;Ning Wang;Yu Gu;Zhe Chen	2016	2016 13th Web Information Systems and Applications Conference (WISA)	10.1109/WISA.2016.50	computer science;data mining;internet privacy;world wide web	DB	-8.978784846565384	-35.44491824333008	116688
79e282aede1f69c7d3292fec955c1dfbdd0b17da	an analysis of factors influencing metro station ridership: insights from taipei metro		Travel demand analysis at the planning stage is important for metro system development. In practice, travel demand can be affected by various factors. This paper focuses on investigating the factors influencing Taipei metro ridership at station level over varying time periods. Ordinary Least Square (OLS) multiple regression models with backward stepwise feature selection are employed to identify the influencing factors, including land use, social economic, accessibility, network structure information, etc. Network structure factors are creatively quantified based on complex network theory to accurately measure the related information. To enhance goodness-of-fit, the dummy variable distinguishing transportation hub is incorporated in the modeling. The main findings in this paper are three-fold: First, there is no distinct difference between influencing factors of boarding and those of alighting; Second, ridership is significantly associated with the number of nearby shopping malls, distance to city center, days since opening, nearby bus stations and dummy variable for transportation hub; Finally, the ridership on weekdays is mainly affected by commuting activities, while the ridership on weekends is driven by commercial access.		Yuxin He;Yang Zhao;Kwok Leung Tsui	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569948		Robotics	-14.985457700207405	-26.785277749182768	116756
174cf38cc5734bc846d5492c7b463dcbdfea1020	towards efficient knn joins on data streams	data stream;maintenance engineering;indexes;k nearest neighbor join high dimensional data data stream;big data;principal component analysis;high dimensional data;clustering algorithms;index structures knn joins processing high dimensional data streams big data applications k nearest neighbor queries time window main memory structure high dimensional r tree hdr tree maintenance cost clustering principle component analysis pca technique;indexes educational institutions principal component analysis big data maintenance engineering algorithm design and analysis clustering algorithms;algorithm design and analysis;tree data structures big data indexing pattern clustering principal component analysis query processing;k nearest neighbor join	We study the problem of efficient processing of kNN joins over high-dimensional data streams, which is an operation required by many big data applications. Specifically, we are concerned with the continuous evaluation of a set of k nearest neighbor queries Q on streams of high-dimensional items at consecutive snapshots of those streams. While one possible solution is to evaluate the kNN joins starting from scratch at each snapshot, it is too expensive for large volumes of data we encounter in big data applications. We consider the data stream on a time window and maintain the join results for Q at every snapshot in main memory. Our approach to this problem is to build indexes on Q, and only update the results of the queries affected by the changes in the streams at each snapshot. We propose a main-memory structure called the High-dimensional R-tree (HDR-tree) to index the queries, which is efficient in finding affected queries with reasonable maintenance cost. HDR-tree takes advantage of the benefit of clustering and the principle component analysis (PCA) technique. Preliminary experimental results show that our index structures significantly outperform baseline methods.	baseline (configuration management);big data;cluster analysis;computer data storage;k-nearest neighbors algorithm;principal component analysis;r-tree;snapshot (computer storage)	Chong Yang;Xiaohui Yu;Yang Liu	2014	2014 IEEE International Congress on Big Data	10.1109/BigData.Congress.2014.121	computer science;pattern recognition;data mining;database	DB	-5.241616407694122	-37.236500627810905	116867
301d9842c2f937b6af9dc5c637e110da8c13adf2	locating mapped resources in web 2.0	mashups;geographical resources;tag centric query processing strategy;embedded semantic;query processing;search engines;videos tagging blogs spatial databases search engines data models context modeling mashups query processing scalability;search algorithm;synthetic data sets mapped resources location web 2 0 mapping mashups apis online mapping solutions embedded semantic geographical resources tag centric query processing strategy search algorithm geographical context sensitive geo tf idf ranking mechanism;search strategy;scaling up;synthetic data sets;geographical context sensitive geo tf idf ranking mechanism;search problems internet query processing;internet;engines;indexing;mapped resources location;online mapping solutions;spatial databases;apis;web 2 0;mapping mashups;search problems;scalability;synthetic data;context modeling;blogs;context;videos;data models;tagging	Mapping mashups are emerging Web 2.0 applications in which data objects such as blogs, photos and videos from different sources are combined and marked in a map using APIs that are released by online mapping solutions such as Google and Yahoo Maps. These objects are typically associated with a set of tags capturing the embedded semantic and a set of coordinates indicating their geographical locations. Traditional web resource searching strategies are not effective in such an environment due to the lack of the gazetteer context in the tags. Instead, a better alternative approach is to locate an object by tag matching. However, the number of tags associated with each object is typically small, making it difficult for an object to capture the complete semantics in the query objects. In this paper, we focus on the fundamental application of locating geographical resources and propose an efficient tag-centric query processing strategy. In particular, we aim to find a set of nearest co-located objects which together match the query tags. Given the fact that there could be large number of data objects and tags, we develop an efficient search algorithm that can scale up in terms of the number of objects and tags. Further, to ensure that the results are relevant, we also propose a geographical context sensitive geo-tf-idf ranking mechanism. Our experiments on synthetic data sets demonstrate its scalability while the experiments using the real life data set confirm its practicality.	blog;database;embedded system;experiment;inverted index;real life;relevance;scalability;search algorithm;synthetic data;synthetic intelligence;tag (metadata);tag cloud;tf–idf;web 2.0;web mapping;web resource;world wide web	Dongxiang Zhang;Beng Chin Ooi;Anthony K. H. Tung	2010	2010 IEEE 26th International Conference on Data Engineering (ICDE 2010)	10.1109/ICDE.2010.5447897	data modeling;search engine indexing;scalability;the internet;application programming interface;computer science;data mining;database;context model;web 2.0;world wide web;information retrieval;mashup;search algorithm;synthetic data	DB	-15.039301738618951	-36.924618197853675	116900
1c1d26d84f0834b931d39ffe1b69f665b91b7d95	a new platform for time-series analysis of remote sensing images in a distributed computing environment		Time series analysis of remote sensing images is essential for the detection of patterns, trends and changes to allow the modeling and prediction of events in the earth’s surface. Users of geographic information systems (GIS) are often involved in spatio-temporal remote sensing analysis. In case of applications with large volumes of data, this analysis should be carried out in an automated manner and allow spatiotemporal filtering in the image database. This work proposes a new platform, DistSensing, that can enable these analyses to be conducted with the aid of distributed indices. We show how this DistSensing platform outperforms the solutions found in the literature when there is the need to run queries on the database using temporal and spatial filters.	distributed computing environment;geographic information system;time series	Sávio Salvarino Teles de Oliveira;Marcelo de Castro Cardoso;Wisllay M. V. dos Santos;Paulo C. P. Costa;Vagner Jose do Sacramento Rodrigues;Wellington Santos Martins	2016			computer science;time series;remote sensing application;remote sensing;distributed computing environment	HCI	-13.041684032038573	-27.981662837011946	117057
df42598483aea372e92848a3ce59656b3729c972	cloud model-based spatial data mining	uncertain reasoning;spatial data;data mining;spatial data mining;data cleaning;data reduction;task complexity;knowledge discovery	Abstract In spatial data mining, we have to deal with uncertainties in data and mining process. The nature of the uncertainties can be, for example, fuzziness and randomness. This paper proposed a cloud model-based data mining method that may simultaneously deal with randomness and fuzziness. First, cloud model is presented, which is described by using three numerical characteristics. Ex, En and He. Furthermore, three visualization methods on cloud model are further proposed, which can be produced by the cloud generators. Second, cloud model-based knowledge discovery is further developed. In cloud model context, spatial data preprocessing pays more attention to data cleaning, transform between qualitative concepts and quantitative data, data reduction, and data discretization. Spatial uncertain reasoning is in the form of linguistic antecedents and linguistic consequences, both of which are implemented by X-conditional and Y-conditional cloud generators. Spatial knowledge is represented with qualitative c...	data mining	Shuliang Wang;Deren Li;Wenzhong Shi;Deyi Li;Xinzhou Wang	2003	Annals of GIS	10.1080/10824000309480589	data reduction;computer science;data science;data mining;database;spatial analysis;knowledge extraction;data stream mining	ML	-4.610042878998144	-27.104036569848144	117572
1202e9842c029e085ca046ac8c800b09f1b6269d	predictive trip planning - smart routing in smart cities		Smart route planning gathers increasing interest as cities become crowded and jammed. We present a system for individual trip planning that incorporates future traffic hazards in routing. Future traffic conditions are computed by a Spatio-Temporal Random Field based on a stream of sensor readings. In addition, our approach estimates traffic flow in areas with low sensor coverage using a Gaussian Process Regression. The conditioning of spatial regression on intermediate predictions of a discrete probabilistic graphical model allows to incorporate historical data, streamed online data and a rich dependency structure at the same time. We demonstrate the system and test model assumptions with a real-world use-case from Dublin city, Ireland.	graphical model;kriging;routing;smart city;streaming media	Thomas Liebig;Nico Piatkowski;Christian Bockermann;Katharina Morik	2014			simulation;geography;operations management;transport engineering	AI	-16.58862849591422	-31.71871741140172	118545
8e61a9ee37d2b63fda5ea03d0c2f637f9f4d4f4b	a bayesian network model for interesting itemsets		Mining itemsets that are the most interesting under a statistical model of the underlying data is a commonly used and well-studied technique for exploratory data analysis, with the most recent interestingness models exhibiting state of the art performance. Continuing this highly promising line of work, we propose the first, to the best of our knowledge, generative model over itemsets, in the form of a Bayesian network, and an associated novel measure of interestingness. Our model is able to efficiently infer interesting itemsets directly from the transaction database using structural EM, in which the E-step employs the greedy approximation to weighted set cover. Our approach is theoretically simple, straightforward to implement, trivially parallelizable and retrieves itemsets whose quality is comparable to, if not better than, existing state of the art algorithms as we demonstrate on several real-world datasets.	approximation;association rule learning;bayesian network;database;expectation propagation;generative model;greedy algorithm;network model;set cover problem;statistical model;synthetic intelligence	Jaroslav M. Fowkes;Charles A. Sutton	2016		10.1007/978-3-319-46227-1_26	machine learning;pattern recognition;data mining;mathematics	ML	-9.606615553100724	-37.54926803433592	119020
8ba8be4054981c6aeb55e2728a4dfc13bcf32100	automatic user identification method across heterogeneous mobility data sources	trajectory urban areas buildings noise measurement mobile communication navigation education;automatic user identification method heterogeneous mobility data sources location based services mobility data volume mapreduce based framework aui signal based similarity measure sig measure mobility data integration problem data quality;data quality automatic user identification method heterogeneous mobility data sources location based services mobility data volume mapreduce based framework aui signal based similarity measure sig measure mobility data integration problem;data integration information retrieval mobile computing;mobile computing data integration information retrieval	With the ubiquity of location based services and applications, large volume of mobility data has been generated routinely, usually from heterogeneous data sources, such as different GPS-embedded devices, mobile apps or location based service providers. In this paper, we investigate efficient ways of identifying users across such heterogeneous data sources. We present a MapReduce-based framework called Automatic User Identification (AUI) which is easy to deploy and can scale to very large data set. Our framework is based on a novel similarity measure called the signal based similarity (SIG) which measures the similarity of users' trajectories gathered from different data sources, typically with very different sampling rates and noise patterns. We conduct extensive experimental evaluations, which show that our framework outperforms the existing methods significantly. Our study on one hand provides an effective approach for the mobility data integration problem on large scale data sets, i.e., combining the mobility data sets from different sources in order to enhance the data quality. On the other hand, our study provides an in-depth investigation for the widely studied human mobility uniqueness problem under heterogeneous data sources.	attachment unit interface;data quality;embedded system;experiment;global positioning system;location-based service;mapreduce;mobile app;rejection sampling;sampling (signal processing);similarity measure	Wei Cao;Zhengwei Wu;Jian Li;Haishan Wu	2016	2016 IEEE 32nd International Conference on Data Engineering (ICDE)	10.1109/ICDE.2016.7498306	computer science;data mining;database;mobility model;world wide web	DB	-17.525686371155604	-36.32333100496305	119565
e835e109cde3a3e0a21e85f9495ecae5e7e42018	environmental and human risk assessment of the prehistoric and historic archaeological sites of western crete (greece) with the use of gis, remote sensing, fuzzy logic and neural networks	geographic information system;neural networks;cultural heritage;global position system;crete;fuzzy logic;gis;land use;remote sensing;natural disaster;risk assessment;archaeological sites;neural network	The island of Crete is an area with continuous habitation for more than 6 thousand years consisting of a variety of archaeological sites. The vulnerability of those archaeological sites is extremely high due to the changing land-use practices and various natural disasters. The use of modern technologies such as Geographical Information Systems (GIS), Remote Sensing (RS), and Global Positioning Systems is considered to provide a valuable tool for the protection of cultural heritage from human and environmental threats. Additionally, sophisticated classification methods based on fuzzy and neural networks theory contribute to a more detailed and precise mapping of the archaeological regime of the island.	fuzzy logic;geographic information system;neural networks;risk assessment	Dimitrios D. Alexakis;Apostolos Sarris	2010		10.1007/978-3-642-16873-4_25	geography;archaeology;cartography	ML	-12.774588331379439	-25.72042343387737	119661
1b6dbfa984a75096f7c0ea1889b8fbda6e160c35	similarity measurement of moving object trajectories	trajectory similarity;moving objects;semantic trajectories	To study the similarity between moving object trajectories is important in many applications, e.g., to find the clusters of moving objects which share the same moving pattern, and infer the future locations of a moving object from its similar trajectories. To define the similarity between moving objects is a challenging task, since not only their locations change but also their speed and semantic features vary. In this paper, we propose a novel approach to measure the similarity between trajectories. The similarity is defined based on both geographic and semantic features of movements. Our approach can be used to detect trajectory clusters and infer future locations of moving objects.	semantic similarity	Hechen Liu;Markus Schneider	2012		10.1145/2442968.2442971	computer vision;machine learning;data mining	AI	-16.31838551065672	-35.5515881391624	119791
0570b4c2b5dd744804d7a3d30a667723e288a269	agent-based modeling for evacuation traffic analysis in megaregion road networks	traffic simulation;transims computer model;regional planning;gulf coast united states;hurricane katrina;disaster preparedness;multi agent systems;hurricane gustav;evacuation;hurricanes;2005;2008	Numerous recent catastrophic disasters have underscored the need to better plan and manage regional traffic associated with mass evacuations. Over the past three decades, traffic simulation has been applied to evaluate traffic management options and to forecast regional traffic patterns associated with evacuations. As the level of sophistication of simulation systems has increased, so have expectations for ever more detailed assessments of larger and more complex road networks, especially for evacuations. Historically, traffic modeling has required a fundamental trade-off between wide area analyses with low resolution or high resolution analyses over comparatively small areas. Recent advancements in agent-based traffic modeling, however, now permit very large areas to be simulated at high resolution. In this paper, results from a series of projects in which the TRANSIMS agent- based traffic simulation system was applied to assess and evaluate traffic conditions associated with various threat conditions and the regional traffic management approaches are summarized. These findings are valuable to enhance the understanding of the mass emergency movement of traffic and can be applied more-practically for wide-scale, regional, and even multi-state evacuation planning.		Brian Wolshon;Zhao Zhang;Scott Parr;Brant Mitchell;John Pardue	2015		10.1016/j.procs.2015.05.164	simulation;regional planning;tropical cyclone;computer science;artificial intelligence;multi-agent system;operations research	EDA	-17.790841876995703	-24.615421352200354	119821
fd02ea328823cc3bb2ac85e068442b861453fc1a	statistical methods for predicting and improving cohesion using information flow: an empirical study	ordinal cohesion scales;external validity;cohesion prediction systems;empirical study;statistical method;logistic regression;information flow;information flow measures;cohesion;empirical relations;binary and ordinal logistic regression;cross validation	We consider the difficulty in deriving and validating new scales of measurement for modular cohesion. We show that currently derived objective measures cannot predict, or measure, a scale of cohesion that has an empirical relation system, for which a “high degree of interpersonal agreement” exists. However, we demonstrate empirically that it is feasible to predict low levels of a cohesion scale with an observed empirical relation. For this scale there exists agreement to make the observational distinctions that form the empirical relation system. Our statistically derived prediction systems use information flow measures and are available at architectural and detailed design. These prediction systems have been validated and we have determined their predictive capability using cross-validation. Within the limits of their external validity, we discuss how these and future prediction systems can be used to improve modular cohesion. For example, improvements may be achieved by using a simple cut-off value for fanout to predict modules that lack cohesion.	cohesion (computer science);cross-validation (statistics);external validity;fan-out;information flow;level of measurement	John Moses;Malcolm Farrow;Peter Smith	2002	Software Quality Journal	10.1023/A:1015720832562	econometrics;information flow;external validity;computer science;cohesion;data mining;logistic regression;empirical research;cross-validation	SE	-6.741822308677223	-28.922228826919877	119825
17e908cf820bae988d63d7a5345a9b5f4f239d6c	importance of information collection and dissemination for evacuation modeling and management	dynamic traffic assignment;policy making;transportation networks;intelligent transportation system information collection information dissemination evacuation modeling emergency management long term planning policy making real time information flow cell transmission model system optimal dynamic traffic assignment;inventory management;disaster management;capacity planning;information collection;intelligent transportation systems;real time;intelligent transportation system;traffic control;network performance;system optimal dynamic traffic assignment;fluid flow measurement;cell transmission model;emergency management;telecommunication traffic;information flow;real time information flow;traffic information systems;traffic control telecommunication traffic intelligent transportation systems capacity planning disaster management environmental management inventory management road transportation fluid flow measurement hurricanes;traffic information systems data acquisition emergency services;information dissemination;weather condition;hurricanes;long term planning;road transportation;environmental management;data acquisition;evacuation modeling;emergency services	Information collection and dissemination for emergency management can be in different forms and nature, such as pre/post evacuation surveys, evacuation order from the officials during an emergency, pre-trip or en-route routing information evacuee departure counts, weather conditions, prevailing traffic conditions in the transportation network, and tracking of shelter information etc. Some of these may be more valuable if collected in real time, e.g. weather, traffic and demand conditions. However all evacuation related information can also be used for the long term planning and policy making as well. In this study, evacuation network performance measures and the reliability of an evacuation plan are discussed in terms of the impacts of available collected data and real-time information flow. Uncertainties in demand profile and the link capacities in the traffic network are tackled by employing a cell transmission model (CTM) based system optimal dynamic traffic assignment (SO DTA) model.	digital television adapter;information flow (information theory);network performance;real-time data;routing	M. Anil Yazici;Kaan Özbay	2007	2007 IEEE Intelligence and Security Informatics	10.1109/ISI.2007.379504	intelligent transportation system;simulation;computer science;computer security;emergency management	Metrics	-16.853449354067358	-28.714801804859942	120086
d54eba30995fcb2a5e8fcb2eb515d92da5b85b41	introduction to the risk visualization as a service		This paper introduces the Risk Visualization as a Service (RVaaS) and presents the motivation, rationale, methodology, Cloud APIs used, operations and examples of using RVaaS. Risks can be calculated within seconds and presented in the form of Visualization to ensure that unexploited areas are exposed. RVaaS operates in two phases. The first phase includes the risk modeling in Black Scholes Model (BSM), creating 3D Visualization and Analysis. The second phase consists of calculating key derivatives such as Delta and Theta for financial modeling. Risk presented in visualization allow the potential investors and stakeholders to keep track of the status of risk with regard to time, prices and volatility. Results in experiments show that RVaaS can perform up to 500,000 simulations and complete all simulations within 22 seconds. RVaaS provides a structured way to deploy low cost, high quality risk assessment and support real-time calculations.	black–scholes model;cloud computing;design rationale;display resolution;experiment;financial modeling;financial risk modeling;numerical analysis;openbsm;real-time clock;real-time locating system;risk assessment;simulation;visualization (graphics);volatility	Victor Chang	2014		10.5220/0004979200300037	simulation;engineering;operations management;operations research	Visualization	-16.695176562599247	-26.542700565436437	120192
6d3c114bf3ff4b4ad278a376b3787ff116f7e479	extracting patterns from socioeconomic databases to characterize small farmers with high and low corn yields in mozambique: a data mining approach	information systems		data mining;database	Constantino Sotomane;Jordi Gallego-Ayala;Lars Asker;Henrik Boström;Venâncio Massingue	2012				ML	-10.40198388840909	-27.091289787636335	120399
10611c5d86a13c095bf8e8872eba446f3e594122	mining frequent patterns with counting inference	frequent pattern;large data sets;data mining;parallelism;kdd	In this paper, we propose the algorithm PASCAL which introduces a novel optimization of the well-known algorithm Apriori. This optimization is based on a new strategy called pattern counting inference that relies on the concept of key patterns. We show that the support of frequent non-key patterns can be inferred from frequent key patterns without accessing the database. Experiments comparing PASCAL to the three algorithms Apriori, Close and Max-Miner, show that PASCAL is among the most efficient algorithms for mining frequent patterns.	apriori algorithm;mathematical optimization;whole earth 'lectronic link	Yves Bastide;Rafik Taouil;Nicolas Pasquier;Gerd Stumme;Lotfi Lakhal	2000	SIGKDD Explorations	10.1145/380995.381017	computer science;data science;data mining;database;apriori algorithm	DB	-5.44143851635484	-37.81404532031626	120536
534b242188b668c507f119f1f3cf609b6e2586a1	topological relations between fuzzy regions	fuzzy set;fuzzy geographic regions;fuzzy sets;gis;topological relations;spatial objects;topological relation	"""The clevelolmmnt of formal models of spatial relations is a topic of great importance in spatial reasoning , geographic information systems (GIS) and computer vision, and has gained nmch attention from researchers across these disciplines during the past two decades or so. In recent years significant achievements have been rnade on the developnmnt of models of spatial relations between spatial objects with precisely, defined boundaries. However. these models catmot be directly applied to spatial objects with indeterminate boundaries which are found in many al)plications in geographic analysis and image understanding. This pal)er develops a method for approxinmtely analyzing binary topological relations I)~,tween spatial objects with indeterminate bomldaries based upon previous work on topological spatial relations anti fuzzy sets. It is shown that tile eight topological relations between two regions in a two-dimensional space can be easily deternfined by the method. 1 INTRODUCTION The developnmnt of general theories of spatial relations has received much attention [br more than two decades in the literature of artili-cial intelligence, eontputer vision, GIS and image """"'Permission to makc digital or hard copies of part or all of this ~ork for personal or classroom usc is granted without fee provided that copies arc not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first pagc. Copyrights for components of this work owned by othcrs than ACM must be honored. Abstracting with credit is permitted. To cop5' otherwise, to republish, to post on servers or to redistribute to lists, rcquircs prior specific permission and/or a tee.'"""" Up to date, significant achievements have been made in the development of models of metrtcal spatial relations [18, 11], mathematical models of topological relations [9, 5], and the cognitive aspects of these models [15]. However, reported research on theories of spatial relations thus far have mainly concentrated on spatial relations of objects with precisely defined boundaries (hereafter called crisp regions). In ninny areas of geographic data handling, particularly in the management of natural resource data, spatial objects tend to have indeterminate boundaries [3}. These objects with indeterminate boundaries are called fuzzy regions in this paper. In the GIS community there has been a wide recognition of the exhibition of fltzziness in geographic data and a general consensus that current GIS are not capable of handling fuzzy geographic data directly (see. e.g.. [3]. ['22]. and the relerences therein). Although there have …"""	computer vision;fuzzy set;geographic information system;indeterminacy in concurrent computation;mathematical model;spatial–temporal reasoning;theory	F. Benjamin Zhan	1997		10.1145/331697.331738	geomatics;fuzzy classification;computer science;artificial intelligence;fuzzy set	DB	-6.270615737738539	-27.57262450068899	120560
4197a67584538f3cf5b12d3c8e94788b8274dd43	detecção de anomalias frequentes no transporte rodoviário urbano		The growth of urban population and, consequently, the number of vehicles causes the increase of traffic jams and emission of polluting gases. In this context, we observe the intensification of papers that aim to identify bottlenecks and their causes. These papers propose methodologies that use trajectory data model and aim to explain systemic behaviors. This article proposes the identification and classification of anomalies in the urban road transport system from space-time aggregations to permanent objects. The methodology consists of pre-processing of data, identification of anomalies, identification, and classification of frequent patterns. Through it, we can identify the systemic and specific behaviors on the urban transit of Rio de Janeiro. Resumo. O crescimento da população urbana e, consequentemente, do número de veı́culos provoca o aumento de engarrafamentos e da emissão de gases poluentes. Nesse contexto, observa-se a intensificação de pesquisas que buscam identificar engarrafamentos e suas causas. Estas pesquisas propõem metodologias que usam modelo de dados de trajetória e visam explicar comportamentos sistêmicos. Este artigo propõe a identificação e a classificação de anomalias no sistema de transporte rodoviário urbano a partir de agregações espaço-temporais a objetos permanentes. A metodologia consiste do pré-processamento dos dados, identificação de anomalias, identificação e classificação de padrões frequentes. Por meio dela, é possı́vel identificar comportamentos sistêmicos e pontuais do trânsito urbano do Rio de Janeiro.	bottleneck (software);data model;power-on reset;preprocessor;winsock	Ana Beatriz Cruz;João Ferreira;Diego Carvalho;Eduardo Mendes;Esther Pacitti;Rafaelli Coutinho;Fábio Porto;Eduardo S. Ogasawara	2018				ML	-12.68819036956074	-26.349830515143847	120627
9346e6c0559a7fd2033309ee01590f3f7bba36e0	new monitoring scheme for persons with dementia through monitoring-area adaptation according to stage of disease		In this paper, we propose a new monitoring scheme for a person with dementia (PwD). The novel aspect of this monitoring scheme is that the size of the monitoring area changes for different stages of dementia, and the monitoring area is automatically generated using global positioning system (GPS) data collected by the PwD. The GPS data are quantized using the GeoHex code, which breaks down the map of the entire world into regular hexagons. The monitoring area is defined as a set of GeoHex codes, and the size of the monitoring area is controlled by the granularity of hexagons in the GeoHex code. The stages of dementia are estimated by analyzing the monitoring area to determine how frequently the PwD wanders. In this paper, we also examined two aspects of the implementation of the proposed scheme. First, we proposed an algorithm to estimate the monitoring area and evaluate its performance. The experimental results showed that the proposed algorithm can estimate the monitoring area with a precision of 0.82 and recall of 0.86 compared with the ground truth. Second, to investigate privacy considerations, we showed that different persons have different preferences for the granularity of the hexagons in the monitoring systems. 1The results indicate that the size of the monitoring area also should be changed for PwDs.	algorithm;code;global positioning system;ground truth;quantization (signal processing)	Shigeki Kamada;Yuji Matsuo;Sunao Hara;Masanobu Abe	2017		10.1145/3148150.3148151	global positioning system;ground truth;granularity;location-based service;data mining;geography;dementia	EDA	-16.93782544756131	-34.605502054420654	120866
6be566c316c84a61b13f7c79087f985a44fa372e	finding localized associations in market basket data	market basket data;association rules;data mining;clustering;target marketing localized associations discovery clustering aggregate behavior;aggregates algorithm design and analysis clustering algorithms	In this paper, we discuss a technique for discovering localized associations in segments of the data using clustering. Often the aggregate behavior of a data set may be very di erent from localized segments. In such cases, it is desirable to design algorithms which are e ective in discovering localized associations, because they expose a customer pattern which is more speci c than the aggregate behavior. This information may be very useful for target marketing. We present empirical results which show that the method is indeed able to nd a signi cantly larger number of associations than what can be discovered by analysis of the aggregate data.	aggregate data;algorithm;categorical variable;cluster analysis;rock (processor)	Charu C. Aggarwal;Cecilia M. Procopiuc;Philip S. Yu	2002	IEEE Trans. Knowl. Data Eng.	10.1109/69.979972	association rule learning;computer science;data science;machine learning;data mining;cluster analysis	DB	-4.680296054904609	-33.846457858130215	120986
d8636d8a40f943114b15ef527bad3492235096c2	an intelligent monitoring system for the safety of building structure under the w2t framework		Monitoring systems for the safety of building structure (SBS) can provide people with important data related to main supporting points in a building and then help people to make a reasonable maintenance schedule. However, more and more data bring a challenge for data management and data mining. In order to meet this challenge, under the framework of Wisdom Web of Things (W2T), we design a monitoring system for the SBS by using the semantic and the multisource data fusion technologies. This system establishes a dynamical data cycle among the physical world (buildings), the social world (humans), and the cyber world (computers) and provides various services in the monitoring process to alleviate engineers' workload. Furthermore, all data in the cyber world are organized as the raw data, the semantic information, and the multisource knowledge. Based on this organization, we can concentrate on the data fusion from the view points of time, space, and multisensor. At last, a prototype system powered by the semantic platform LarKC is tested fromthe aspects of sample performance and time consumption. In particular, noisy data (i.e., inconsistent, abnormal, or error data) are detected through the fusion of multisource knowledge, and some rule-based reasoning is conducted to provide personalized service.		Haiyuan Wang;Zhisheng Huang;Ning Zhong;Jiajin Huang;Yuzhong Han;Feng Zhang	2015	IJDSN	10.1155/2015/378694	embedded system;simulation;data science;data mining	Robotics	-8.493439631024092	-25.30435643845987	121350
01dbd527846c8bb14378488249ba835ef9b610c5	efim-closed: fast and memory efficient discovery of closed high-utility itemsets	algorithms	Discovering high-utility temsets in transaction databases is a popular data mining task. A limitation of traditional algorithms is that a huge amount of high-utility itemsets may be presented to the user. To provide a concise and lossless representation of results to the user, the concept of closed high-utility itemsets was proposed. However, mining closed high-utility itemsets is computationally expensive. To address this issue, we present a novel algorithm for discovering closed high-utility itemsets, named EFIM-Closed. This algorithm includes novel pruning strategies named closure jumping, forward closure checking and backward closure checking to prune non-closed high-utility itemsets. Furthermore, it also introduces novel utility upper-bounds and a transaction merging mechanism. Experimental results shows that EFIM-Closed can be more than an order of magnitude faster and consumes more than an order of magnitude less memory than the previous state-of-art CHUD algorithm.	alain fournier;algorithm;analysis of algorithms;apple developer tools;data mining;database;lossless compression;online transaction processing	Philippe Fournier-Viger;Souleymane Zida;Chun-Wei Lin;Cheng-Wei Wu;Vincent S. Tseng	2016		10.1007/978-3-319-41920-6_15	machine learning;merge (version control);artificial intelligence;computer science;order of magnitude;database transaction;lossless compression	ML	-6.128499253204445	-37.20157539214525	121559
779a20d1099751a376e11f2ab4aaa01442fd3d6b	statistical modelling and analysis of sparse bus probe data in urban areas	financial loss;traffic speed;travel time;bus stops;public transport;real time arrival time estimates;real time;sparse bus probe data;statistical modelling;real time information;measurement infrastructure;probes;speed information;visualization;traffic conditions;statistical analysis;logic gates;traffic information systems;sparse movement data;roads;global positioning system;urban area congestion;time of arrival estimation;automatic data collection systems;public transport vehicles;cities and towns;urban area;algorithms;probe vehicles;vehicles;free flowing traffic;roads educational institutions probes logic gates cities and towns vehicles global positioning system;traffic information systems road vehicles statistical analysis time of arrival estimation;sparse movement data statistical modelling statistical analysis sparse bus probe data urban area congestion financial loss free flowing traffic traffic conditions measurement infrastructure public transport vehicles real time arrival time estimates speed information;road vehicles;qa76 computer software	Congestion in urban areas causes financial loss to business and increased use of energy compared with free-flowing traffic. Providing citizens with accurate information on traffic conditions can encourage journeys at times of low congestion and uptake of public transport. Installing the measurement infrastructure in a city to provide this information is expensive and potentially invades privacy. Increasingly, public transport vehicles are equipped with sensors to provide real-time arrival time estimates, but these data are sparse. Our work shows how these data can be used to estimate journey times experienced by road users generally. In this paper we describe (i) what a typical data set from a fleet of over 100 buses looks like; (ii) describe an algorithm to extract bus journeys and estimate their duration along a single route; (iii) show how to visualise journey times and the influence of contextual factors; (iv) validate our approach for recovering speed information from the sparse movement data.	algorithm;network congestion;privacy;real-time clock;sensor;sparse matrix;time of arrival	Andrei Iu. Bejan;Richard J. Gibbens;David Evans;Alastair R. Beresford;Jean Bacon;Adrian Friday	2010	13th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2010.5625144	simulation;geography;transport engineering;computer security	Robotics	-17.506303703938592	-30.53334901113796	121731
8ae8712feec683c70eb340b08732d0bc65395ffe	transportation mode recognition algorithm based on bayesian voting		Nowadays, accurate identification of peopleu0027s ways of transportation plays a major role in understanding usersu0027 mobility, analyzing and predicting traffic conditions as well as exploring new patterns of social activity. With regard to low power consumption, complex environment and other challenges, we propose a traffic model based on Bayesian detection algorithm in this paper. To cope with these challenges, we propose a Bayesian-based traffic pattern detection algorithm. This algorithm leverages variety of sensors embedded on smartphones to analyze and explores the different characteristics of various sensors to identify different traffic patterns. The results of massive experiments show that the traffic pattern recognition algorithm based on Bayesian algorithm has better universality and accuracy, with accuracy rate being over 91.5%.	algorithm	Yanjun Qin;Mengling Jiang;Weichao Yuan;Shaomeng Chen;Haiyong Luo	2017		10.1109/ES.2017.50	traffic model;voting;airfield traffic pattern;machine learning;algorithm;artificial intelligence;bayesian probability;computer science;pattern recognition	Robotics	-14.369484263737325	-32.3701657610359	121914
9d5218e0cefedb9e22af09a6a41a29a677fd62ec	an intelligent driver guidance tool using location based services	social network services;visual databases automated highways decision making decision support systems decision trees driver information systems mobile computing mobile handsets road traffic social networking online target tracking;decision tree;location based service;social networking services;a search algorithm;road traffic;search algorithm;automated highways;data mining;a search algorithm decision tree spatio temporal data spatial data mining social networks m2m platform;vehicles servers driver circuits roads decision trees data mining social network services;information presentation;mobile phone;spatial data mining;support system;social network;servers;spatio temporal data;roads;social networks;decision support systems;dynamic vehicular environment intelligent driver guidance tool location based service decision support system vehicle driver mobile phone traffic vehicle tracking time dimension decision tree based classification model decision making spatio temporal data distributed architecture social network vehicular context intelligent system;social networking online;intelligent system;mobile handsets;driver circuits;vehicles;m2m platform;target tracking;mobile computing;decision trees;driver information systems;distributed architecture;visual databases	This paper suggests a decision support system for vehicle drivers, accessible via mobile phone. Concept behind the system is to help drivers to schedule their activities, best utilizing their time along the way, minimizing the impacts of traffic. This is in contrast to existing approaches focused on controlling traffic in highways. Vehicle is continuously tracked along the journey and information presented to user is adapted according his location and time dimensions. System is based on a decision tree based classification model to predict the future traffic and use those results for decision making. System mines spatio-temporal data to build the decision tree, therefore developed in a distributed architecture to avoid load for a single server. System is exposed to community via existing social networks, bringing social networks into vehicular context. Decision trees to predict traffic are periodically rebuilt using most recent data, therefore this is an intelligent system which learns through empirical data, and best suited for dynamic vehicular environment.	artificial intelligence;capability maturity model;dfa minimization;data mining;decision support system;decision tree;distributed computing;location awareness;location-based service;loose coupling;m2m (eclipse);mobile phone;server (computing);social network;web service	Kushani Perera;Dileeka Dias	2011	Proceedings 2011 IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services	10.1109/ICSDM.2011.5969041	simulation;decision support system;computer science;decision tree;data mining;mobile computing;computer security;social network	Robotics	-18.417143276437418	-31.220661750668928	122030
1a00eb4d0dc5a67bf152185e47f8a7e5d3ab636a	data quality for temporal streams		Temporal data pose unique data quality challenges due to the presence of autocorrelations, trends, seasonality, and gaps in the data. Data streams are a special case of temporal data where velocity, volume and variety present additional layers of complexity in measuring the veracity of the data. In this paper, we discuss a general, widely applicable framework for data quality measurement of streams in a dynamic environment that takes into account the evolving nature of streams. We classify data quality anomalies using four types of constraints, identify violations that could be potential data glitches, and use statistical distortion as a metric for measuring data quality in a near real-time fashion. We illustrate our framework using commercially available streams of NYSE stock prices consisting of aggregates of prices and trading volumes collected every minute over a one year period from November 2011 to November 2012.	binocular disparity;data dependency;data quality;distortion;glitch;real-time clock;real-time computing;seasonality;software framework;subject-matter expert;velocity (software development);veracity	Tamraparni Dasu;Rong Duan;Divesh Srivastava	2016	IEEE Data Eng. Bull.		data mining;streams;computer science;data quality	DB	-10.725625038580313	-33.393825752066725	122136
c85b7a12e516f9221f47a805f1c47a41a9b1b49d	multifractals in rainforest ecosystems: modelling and simulation	ecosystem modelling		ecosystem;multifractal system;simulation	Ricard V. Solé;Susanna C. Manrubia;Bartolome Luque	1993			soil science;forestry;ecology	EDA	-11.13797012945377	-26.76656624586001	122744
deb95cba6dd4ae8b5bd492190c3ba0763aca6b3b	mobility data disaggregation: a transfer learning approach	manganese;urban areas;statistics;high temperature superconductors;context;sociology;data models	In this paper we present a machine learning approach to derive temporal disaggregated origin-destination matrices from static censuses on population mobility data. A better understanding of the displacements over a land is an issue for decision making and territorial planning. The primary objective of this paper is to transform census data towards a disaggregated form, allowing its merging with other mobility data. Most of Human displacements are linked to Home and Work locations, and these commuting patterns regularly generate road congestion problems. Knowing the temporality of commuting patterns eases the decision making processes from local authorities. Mobility censuses often contain these Home and Work information, but are temporally aggregated. We thus propose a machine learning model that learns the temporal distribution of displacements from other mobility sources and allows to temporally disaggregate the displacements of such censuses. This model have been validated and showed its efficiency in a real context. The main advantage of our approach is that the resulting matrices inherit all the attributes contained in the aggregated census. Finally, the model is optimized so that it can be applied to other places wherever censuses on mobility data are available, and without additional computations.	computation;machine learning;network congestion;performance;temporal logic	Mehdi Katranji;Etienne Thuillier;Sami Kraiem;Laurent Moalic;Fouad Hadj-Selem	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795783	simulation;geography;data mining;cartography	Robotics	-16.521733446239203	-31.174307485441627	122886
5d2c53f3e53790425587bd1957d7982612f83a85	mining deviants in time series data streams	data mining temporal databases statistical databases time series data analysis computational complexity;data stream;standard deviation;statistical databases;time series;data mining;multivariate time series;heuristic solution deviant mining time series data streams outlier identification statistics standard deviation variance representation sparsity metric compressed representation local aberration time series databases polylogarithmic data size network traffic data snmp data management data mining data monitoring univariate time series multivariate time series near optimal solutions;data analysis;computational complexity;network traffic;data mining databases monitoring telecommunication traffic history statistics aggregates temperature road transportation internet telephony;time series data;temporal databases;synthetic data	"""One of the central tasks in managing, monitoring and mining data streams is that of identifying outliers. There is a long history of study of various outliers in statistics and databases, and a recent focus on mining outliers in data streams. Here, we adopt the notion of """"deviants"""" from Jagadish et al. (1999) as outliers. Deviants are based on one of the most fundamental statistical concept of standard deviation (or variance). Formally, deviants are defined based on a representation sparsity metric, i.e., deviants are values whose removal from the dataset leads to an improved compressed representation of the remaining items. Thus, deviants are not global maxima/minima, but rather these are appropriate local aberrations. Deviants are known to be of great mining value in time series databases. We present first-known algorithms for identifying deviants on massive data streams. Our algorithms monitor streams using very small space (polylogarithmic in data size) and are able to quickly find deviants at any instant, as the data stream evolves over time. For all versions of this problem - uni- vs multivariate time series, optimal vs near-optimal vs heuristic solutions, offline vs streaming - our algorithms have the same framework of maintaining a hierarchical set of candidate deviants that are updated as the time series data gets progressively revealed. We show experimentally using real network traffic data (SNMP aggregate time series) as well as synthetic data that our algorithm is remarkably accurate in determining the deviants."""	aggregate data;algorithm;database;experiment;heuristic;maxima and minima;network packet;online and offline;polylogarithmic function;simple network management protocol;sparse matrix;synthetic data;time series	S. Muthukrishnan;Rahul Shah;Jeffrey Scott Vitter	2004	Proceedings. 16th International Conference on Scientific and Statistical Database Management, 2004.	10.1109/SSDBM.2004.51	computer science;data science;machine learning;time series;data mining;database;data stream mining;statistics	DB	-7.601653546825443	-35.23010773924839	122976
b4bc30bdb6c3e2009ece1b66c48b57ef8f632fde	framework for horizontal scaling of map matching: using map-reduce	horizontal scalable map matching big data map reduce hbase;geometry;horizontal scalable;trajectory;big data;roads;global positioning system;pattern matching;traffic information systems big data distributed processing global positioning system graph theory mobile computing;hbase;map reduce;st matching based map matching algorithm map matching horizontal scaling framework map reduce raw time stamped location traces road network graph gps mobile signals travel pattern mining route prediction vehicle turn prediction resource prediction grid computing vertical scalable frameworks hbase data storage big data technology stack;vehicles;map matching;algorithm design and analysis;roads algorithm design and analysis global positioning system vehicles geometry trajectory pattern matching	Map Matching is a well-established problem which deals with mapping raw time stamped location traces to edges of road network graph. Location data traces may be from devices like GPS, Mobile Signals etc. It has applicability in mining travel patterns, route prediction, vehicle turn prediction and resource prediction in grid computing etc. Existing map matching algorithms are designed to run on vertical scalable frameworks (enhancing CPU, Disk storage, Network Resources etc.). Vertical scaling has known limitations and implementation difficulties. In this paper we present a framework for horizontal scaling of map-matching algorithm, which overcomes limitations of vertical scaling. This framework uses Hbase for data storage and map-reduce computation framework. Both of these technologies belong to big data technology stack. Proposed framework is evaluated by running ST-matching based map matching algorithm.	2.5d;algorithm;apache hbase;big data;central processing unit;computation;computer data storage;disk storage;global positioning system;grid computing;image scaling;map matching;mapreduce;scalability;solution stack;tracing (software)	Vishnu Shankar Tiwari;Arti Arya;Sudha Chaturvedi	2014	2014 International Conference on Information Technology	10.1109/ICIT.2014.70	algorithm design;big data;global positioning system;computer science;trajectory;theoretical computer science;machine learning;pattern matching;data mining;database;programming language	HPC	-14.62315780874689	-35.31547402621589	122978
122d36fc8e0436149847b39b18b25280048e0d84	a dynamic, architectural model of sabina vulgaris growth	topology;microstate;fractals;dual scale automaton model;s vulgaris shrubs;forestry;topological architecture;drought environment;macrostate;biological system modeling;ecology;sabina vulgaris;automata;computer architecture;feasibility study;topology automata theory botany ecology physiological models;computational modeling;dual scale automaton;automata biological system modeling mathematical model educational institutions geometry solid modeling biomass information science fractals visualization;sabina vulgaris growth;mathematical model;automata theory;eco physiological characteristics;growth rules;drought environment sabina vulgaris growth eco physiological characteristics topological architecture growth rules dual scale automaton model s vulgaris shrubs;physiological models;botany;macrostate dual scale automaton sabina vulgaris microstate	Thanks to its significant value in anti-drought, Sabina vulgaris is becoming more and more important. But much of past research work was primarily focused on its eco-physiological characteristics while ignoring its basic topological architecture and growth rules. In this work, a dual-scale automaton model is presented to investigate the topological architecture of S. vulgaris shrubs. In comparison with the fractal approach, this model is a simpler and visually more effective method from agro-ecological, and is easier to understand and implement in programming. The result provides a feasible study on the dynamics of S. vulgaris growth, architecture and geometry in various drought environments.	automaton;effective method;fractal	Zhen-jie Jiang;Zhao-feng Geng;Wen-hua Zhou	2008	2008 Second International Conference on Future Generation Communication and Networking	10.1109/FGCN.2008.191	simulation;engineering;artificial intelligence;ecology	SE	-14.048249853416495	-25.87984527979053	123084
85d730809106b60a7f10ed06efc06bb4561b1f7e	a real-time user mobility pattern modeling and similarity measurement for mobile social networks	social networking online data mining mobile computing;trajectory global positioning system data models clustering algorithms real time systems mobile communication mobile computing;trajectory;global positioning system;mobile communication;clustering algorithms;mobility pattern modeling method realtime user mobility pattern modeling user similarity measurement mobile social networks location acquisition technologies mobile computing techniques spatial temporal trajectory data diversification mobility location based services lbs data driven framework spatial information temporal information;mobile computing;data models;real time systems	The increasingly extensive availability of location- acquisition technologies (such as GPS and GSM networks) and mobile computing techniques have generated a lot of spatial-temporal trajectory data which represents the mobility of diversification of moving objects such as people, vehicles, and animals. This brings new opportunities to understand the movement behaviors of moving objects in mobile social networks, which can become valuable for location-based services (LBS). However, the explosive growth of users' trajectory data has brought a lot of troubles to online real-time processing. In this paper, we focus on this direction and develop a complete data-driven framework involving real-time user mobility pattern modeling and a novel user similarity measurement based on both spatial and temporal information. Through experimental evaluation, it is verified that the proposed mobility pattern modeling method and similarity measurement can deliver excellent performance.	algorithm;diversification (finance);experiment;geosocial networking;global positioning system;location-based service;mobile computing;mobile social network;real life;real-time clock;real-time locating system;real-time transcription;region of interest;requirement	Feng Ding;Jian Wang;Naitong Zhang;Wenfeng Li;Kanglian Zhao	2016	2016 IEEE 83rd Vehicular Technology Conference (VTC Spring)	10.1109/VTCSpring.2016.7504099	data modeling;mobile search;simulation;mobile telephony;global positioning system;computer science;trajectory;operating system;data mining;cluster analysis;mobility model;mobile computing;world wide web	Visualization	-17.488083427852022	-35.247907135078634	123139
333a19e76233ee14f5d2e4f07a86557d6330a998	sensing danger: innate immunology for intrusion detection	intrusion detection;evolutionary computing	The immune system provides an ideal metaphor for anomaly detection in general and computer security in particular. Based on this idea, artificial immune systems have been used for a number of years for intrusion detection, unfortunately so far with little success. However, these previous systems were largely based on immunological theory from the 1970s and 1980s and over the last decade our understanding of immunological processes has vastly improved. In this paper we present two new immune inspired algorithms based on the latest immunological discoveries, such as the behaviour of Dendritic Cells. The resultant algorithms are applied to real world intrusion problems and show encouraging results. Overall, we believe there is a bright future for these next generation artificial immune algorithms.	algorithm;anomaly detection;artificial immune system;computer security;intrusion detection system;next-generation network;resultant	Uwe Aickelin;Julie Greensmith	2007	Inf. Sec. Techn. Report	10.1016/j.istr.2007.10.003	intrusion detection system;computer science;artificial intelligence;operations research;computer security	Security	-8.709087681602947	-26.605443833544843	123549
de962b5af24bd05944242d7ca5b77237c7e83f65	practical ways to accelerate delaunay triangulations. (méthodes pour accélérer les triangulations de delaunay)			delaunay triangulation	Pedro Machado Manhães de Castro	2010				Theory	-8.995975573631345	-28.022435540522572	123823
8268e1fe160d8c5e787a8d230bc30e1299be1b1f	a general railway data model for simulations and simulators	training simulator;extensible markup language;openrailway;simulation;railway modeling	According to new regulations, railway employees require computer-based training before they get a driver license. Training with simulators is now a must to increase the safety and efficiency of railway transportation. In this study, a train driving simulator with full cab and motion platform, called TRENSIM, was developed for Turkish State Railways. It was realized that constructing a data model of the railway was one of the most important aspects of the project. Many modules of TRENSIM make use of this data model in real time. We developed a general railway data model, called OpenRailway, expressed in Extensible Markup Language for logical description of railway networks. OpenRailway includes a railway model, which consists of signals, railway elements (catenaries, switches, etc.), road properties, surroundings near the railway road and their parameters. OpenRailway can also be modified to be used in the development of other vehicle training simulators.Data from real trains was collected in 4 ms periods for the validation of the dynamic and visualization models (about 200 GB). It was seen that data generated by models are appropriate to the collected real data.	data model;simulation	Veysi Öztürk;Ferhat Sükrü Rende;Onur Ince;Burak Selçuk Soyer	2014	Simulation	10.1177/0037549714537878	simulation;license;xml;real-time computing;train;data model;visualization;computer science;catenary;driving simulator	DB	-18.648363724700715	-28.197385418600135	123873
6fda173649f55f842f3e33425b1b3282ee262a9b	a prototype towards modeling visual data using decentralized generative adversarial networks		Decentralized computation is crucial for training on large data sets, which are stored in various locations. This paper proposes a method for collaboratively training generative adversarial networks (GANs) on several nodes to approach this problem. Each node has access to its local private dataset and model, but can influence and can be influenced by neighboring nodes. Such an approach avoids the need of a fusion center, offers better network load balance and improves data privacy. This work proposes an initial approach for decentralized GAN network optimization which is based on discriminator exchange among neighbors using an information gain criterion. The initial experiments are presented to verify whether such a decentralized architecture can provide useful results.		Dimitrios Kosmopoulos	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451471	generative grammar;discriminator;computation;pattern recognition;architecture;machine learning;data modeling;computer science;information privacy;load balancing (computing);data set;artificial intelligence	Robotics	-8.796786166998652	-29.18226858272695	124140
6066bf3fac8e3ae004c7b0f952c3e093b4a040a8	mobhet: predicting human mobility using heterogeneous data sources	human mobility prediction;georeferenced data;mobile phone data	The literature is rich in mobility models that aim at predicting human mobility. Yet, these models typically consider only a single kind of data source, such as data from mobile calls or location data obtained from GPS and web applications. Thus, the robustness and effectiveness of such data-driven models from the literature remain unknown when using heterogeneous types of data. In contrast, this paper proposes a novel family of data-driven models, called MobHet, to predict human mobility using heterogeneous data sources. Our proposal is designed to use a combination of features capturing the popularity of a region, the frequency of transitions between regions, and the contacts of a user, which can be extracted from data obtained from various sources, both separately and conjointly. We evaluate the MobHet models, comparing them among themselves and with two single-source data-driven models, namely SMOOTH and Leap Graph, while considering different scenarios with single as well as multiple data sources. Our experimental results show that our best MobHet model produces results that are better than or at least comparable to the best baseline in all considered scenarios, unlike the previous models whose performance is very dependent on the particular type of data used. Our results thus attest the robustness of our proposed solution to the use of heterogeneous data sources in predicting human mobility.		Lucas Maia Silveira;Jussara M. Almeida;Humberto Torres Marques-Neto;Carlos Sarraute;Artur Ziviani	2016	Computer Communications	10.1016/j.comcom.2016.04.013	simulation;computer science;data mining;mobility model	AI	-17.534976533334817	-35.657423081397845	124875
49c43a631e3f2964155519104cccd777fd3a9adc	software for journey-planning with public transport in skopje	global positioning system device;journey planning;internet based application;new technology;transportation data visualisation global positioning system information retrieval internet mobile computing public administration;skopje;macedonia;journey planning gps google earth;information retrieval;public transport;risk and uncertainty;global position system;information visualization;data visualisation;gps;google earth;internet;web application;global positioning system;timetable data;transportation;timetable data journey planning public transport skopje global positioning system device gps information visualization web application internet based application macedonia trip planning;schedules;elderly people;gps information visualization;mobile computing;trip planning;public administration	The increasing popularity of GPS (Global Positioning System) device has boosted many applications, especially those for GPS information visualization. Information visualization techniques are invaluable tools in numerous applications. The goal of this work is to provide visual access to GPS information through the proposed trip planning web application. The main focus is on visualization, organization, fast retrieval, and effective understanding of GPS data mainly for public use, and the simplest way to plan the journey through the city. The main objective is to introduce this internet-based application to the users of the public transport services. The GPS technology is a new technology in Macedonia and trip planning is not implemented yet, although it has been used in many countries remarkably within the last years. Combining the collected GPS and timetable data in order to bring passengers to a desired location, the goal of journey planner is to reduce travel related risks and uncertainties for passengers who want to travel to an unknown part of the city, or tourists, elderly people or people who usually do not use public transport service.	global positioning system;information visualization;internet;journey planner;schedule;web application	Natasa Petrovska	2010	2010 Ubiquitous Positioning Indoor Navigation and Location Based Service	10.1109/UPINLBS.2010.5654305	simulation;geography;transport engineering;advertising	HCI	-18.75889223168255	-32.08190347459939	124929
5cb0dea6b45c18c8411ce7c4e13cf8705f89876c	erminer: sequential rule mining using equivalence classes		Sequential rule mining is an important data mining task with wide applications. The current state-of-the-art algorithm (RuleGrowth) for this task relies on a pattern-growth approach to discover sequential rules. A drawback of this approach is that it repeatedly performs a costly database projection operation, which deteriorates performance for datasets containing dense or long sequences. In this paper, we address this issue by proposing an algorithm named ERMiner (Equivalence class based sequential Rule Miner) for mining sequential rules. It relies on the novel idea of searching using equivalence classes of rules having the same antecedent or consequent. Furthermore, it includes a data structure named SCM (Sparse Count Matrix) to prune the search space. An extensive experimental study with five real-life datasets shows that ERMiner is up to five times faster than RuleGrowth but consumes more memory.	algorithm;data mining;data structure;experiment;real life;sparse;turing completeness	Philippe Fournier-Viger;Ted Gueniche;Souleymane Zida;Vincent S. Tseng	2014		10.1007/978-3-319-12571-8_10	artificial intelligence;machine learning;equivalence class;matrix (mathematics);computer science;pattern recognition;data structure;projection (relational algebra)	ML	-5.550827112369917	-37.86290739860169	125221
d0db440b448c9611cf6d04e6142dfdda69f184f2	collaborative data analysis in hyperconnected transportation systems		Taxi trip duration affects the efficiency of operation, the satisfaction of drivers, and, mainly, the satisfaction of the customers, therefore, it is an impor‐ tant metric for the taxi companies. Especially, knowing the predicted trip duration beforehand is very useful to allocate taxis to the taxi stands and also finding the best route for different trips. The existence of hyperconnected network can help to collect data from connected taxis in the city environment and use it collabora‐ tively between taxis for a better prediction. As a matter of fact, the existence of high volume of data, for each individual taxi, several models can be generated. Moreover, taking into account the difference between the data collected by taxis, this data can be organized into different levels of hierarchy. However, finding the best level of granularity which leads to the best model for an individual taxi could be computationally expensive. In this paper, the use of metalearning for addressing the problem of selection of the right level of the hierarchy and the right algorithm that generates the model with the best performance for each taxi is proposed. The proposed approach is evaluated by the data collected in the DriveIn project. The results show that metalearning helps the selection of the algorithm with the best performance.	algorithm;analysis of algorithms;apollonian network;baseline (configuration management);device driver;experiment;machine learning;semantic network	Mohammad Nozari Zarmehri;Carlos Soares	2016		10.1007/978-3-319-45390-3_2	operations research;knowledge management;trips architecture;granularity;matter of fact;city environment;hierarchy;computer science;metalearning;intelligent transportation system;taxis	AI	-16.59997053945021	-32.70752276076684	125489
a0d395e1e6ece81c85eea2bb08de0a4eda81d63b	compact data structures for temporal graphs	trees mathematics query processing set theory tree data structures;query processing;tree data structures;set theory;trees mathematics;ttk 2 tree compact data structures temporal graphs time ordered graph sequence internal node time instants query processing dynamic k 2 tree ltg index direct neighbor queries reverse neighbor queries differential k 2 tree;data structures educational institutions proposals data compression query processing time measurement ieee computer society	Summary form only given. In this paper we propose three compact data structures to answer queries on temporal graphs. We define a temporal graph as a graph whose edges appear or disappear along time. Possible queries are related to adjacency along time, for example, to get the neighbors of a node at a given time point or interval. A naive representation consists of a time-ordered sequence of graphs, each of them valid at a particular time instant. The main issue of this representation is the unnecessary use of space if many nodes and their connections remain unchanged during a long period of time. The work in this paper proposes to store only what changes at each time instant. The ttk2-tree is conceptually a dynamic k2-tree in which each leaf and internal node contains a change list of time instants when its bit value has changed. All the change lists are stored consecutively in a dynamic sequence. During query processing, the change lists are used to expand only valid regions in the dynamic k2-tree. It supports updates of the current or past states of the graph. The ltg-index is a set of snapshots and logs of changes between consecutive snapshots. The structure keeps a log for each node, storing the edge and the time where a change has been produced. To retrieve direct neighbors of a node, the previous snapshot is queried, and then the log is traversed adding or removing edges to the result. The differential k2-tree stores snapshots of some time instants in k2-trees. For the other time instants, a k2-tree is also built, but these are differential (they store the edges that differ from the last snapshot). To perform a query it accesses the k2-tree of the given time and the previous full snapshot. The edges that appear in exactly one of these two k2-trees will be the final results. We test our proposals using synthetic and real datasets. Our results show that the ltg-index obtains the smallest space in general. We also measure times for direct and reverse neighbor queries in a time instant or a time interval. For all these queries, the times of our best proposal range from tens of μs to several ms, depending on the size of the dataset and the number of results returned. The ltg-index is the fastest for direct queries (almost as fast as accessing a snapshot), but it is 5-20 times slower in reverse queries. The differential k2-tree is very fast in time instant queries, but slower in time interval queries. The ttk2-tree obtains similar times for direct and reverse queries and different time intervals, being the fastest in some reverse interval queries. It has also the advantage of being dynamic.	data structure;database;fastest;graph (discrete mathematics);graph theory;inverted index;snapshot (computer storage);synthetic intelligence;the times;tree (data structure);version control	Guillermo de Bernardo;Nieves R. Brisaboa;Diego Caro;M. Andrea Rodríguez	2013	2013 Data Compression Conference	10.1109/DCC.2013.59	segment tree;computer science;theoretical computer science;range tree;data mining;k-ary tree;interval tree;mathematics;tree;range query;algorithm;set theory	DB	-8.322999769651513	-37.79049285608649	125669
dbbb1df4e9a12a88ce9c53a0b203dc53b3ffe917	probabilistic range querying over gaussian objects	range queries;gaussian distribution	Probabilistic range query is an important type of query in the area of uncertain data management. A probabilistic range query returns all the data objects within a specific range from the query object with a probability no less than a given threshold. In this paper, we assume that each uncertain object stored in the database is associated with a multi-dimensional Gaussian distribution, which describes the probability distribution that the object appears in the multi-dimensional space. A query object is either a certain object or an uncertain object modeled by a Gaussian distribution. We propose several filtering techniques and an R-treebased index to efficiently support probabilistic range queries over Gaussian objects. Extensive experiments on real data demonstrate the efficiency of our proposed approach. key words: uncertain data, probabilistic databases, Gaussian distribution, range queries	experiment;filter (signal processing);probabilistic database;range query (data structures);range query (database);uncertain data	Tingting Dong;Chuan Xiao;Yoshiharu Ishikawa	2014	IEICE Transactions		normal distribution;range query;probabilistic database;machine learning;pattern recognition;data mining;statistics	DB	-7.996625732333745	-33.39130750222032	125757
21bd4eccd1e973343c7f00e7c7993d6dad89c1e7	ranges of human mobility in los angeles and new york	poles and towers;human movement;text messaging acivity;cell phones;personal devices;new york;human mobility;springs;text messaging acivity human mobility los angeles new york ubiquitous devices mobile devices personal devices human movement cell phones;aggregates;business;cities and towns springs humans cellular phones poles and towers business aggregates;mobile handsets;cities and towns;humans;mobile devices;ubiquitous devices;cellular phones;los angeles	The advent of ubiquitous, mobile, personal devices creates an unprecedented opportunity to improve our understanding of human movement. In this work, we study human mobility in Los Angeles and New York by analyzing anonymous records of approximate locations of cell phones belonging to residents of those cities. We examine two data sets gathered six months apart, each representing hundreds of thousands of people, containing hundreds of millions of location events, and spanning two months of activity. We present, compare, and validate the daily range of travel for people in these populations. Our findings include that human mobility changes with the seasons: both Angelenos and New Yorkers travel less in the winter, with New Yorkers showing a greater decrease in mobility during the cold months. We also show that text messaging activity does not by itself accurately characterize daily range, whereas voice calling alone suffices. Finally, we show that our methodology is accurate by comparing our results to ground truth obtained from volunteers.	approximation algorithm;file spanning;ground truth;mobile phone;population	Sibren Isaacman;Richard A. Becker;Ramón Cáceres;Stephen G. Kobourov;Margaret Martonosi;James M Rowland;Alexander Varshavsky	2011	2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops)	10.1109/PERCOMW.2011.5766977	embedded system;telecommunications;computer science;operating system;mobile device;computer security	Mobile	-19.116113531805006	-34.33378395249819	125938
393b99cd389253a9193151c29a02b63404c0b5cd	using cloud iot for disease prevention in precision agriculture		Abstract The application of decision support system (DSS) for potato late blight disease prevention has proven its benefit. In fact the DSS permits efficiency, minimizes cost and environment impact by estimating the exact requirement fungicide quantity to apply. This prediction using weather condition based late blight forecast model. The required weather information is collected from costly weather station or imprecise historical data. However, with the emergence of the IOT, huge number of low cost and low power sensors nodes can easily be deployed in farmlands in order to gather a precise climate data. Moreover, the collected data can be forwarded by Internet connection to the so called cloud IOT framework. In this paper we present a new prototype of late blight prevention decision support system based on sensor network and cloud IOT.		Karim Foughali;Karim Fathallah;Ali Frihida	2018		10.1016/j.procs.2018.04.106	data mining;internet access;wireless sensor network;precision agriculture;computer science;cloud computing;decision support system;weather station;internet of things	DB	-15.160585738120318	-29.961889798220028	126178
940bc1ca5e8cc277ee7a2640a17a8b212eb73dc3	using machine learning to predict the driving context whilst driving	context awareness;in car communication system;weka;machine learning;distraction level;driving context;intelligent systems;driving events;accident prevention;driver distraction	This paper discusses how the driving context (driving events and distraction level) can be determined using a mobile phone equipped with several sensors. The majority of existing in-car communication systems (ICCS) available today are built-in and do not use the driving context. This creates two issues: firstly, the use of an ICCS is limited to specific cars and secondly, the driver's safety remains an issue, as the driving context is not taken into account. This paper discusses two experiments in which data are collected, trained and tested in order to create a model that predicts driving events and distraction level. A mobile, context-aware application was built using the MIMIC (Multimodal Interface for Mobile Info-communication with Context) Framework. The Inference Engine uses information from several sources, namely mobile sensors, GPS and weather information, to infer both the driving event and the distraction level. The results obtained showed that the driving events and the distraction level can be accurately predicted. The driving events were predicted using the IB1 technique with an accuracy of 92.25%. In the second experiment, the distraction level was predicted with 95.16% accuracy, using the KStar (decision tree) technique. An analysis of the decision tree showed that some variables were more important than others in predicting the driving context. These variables included the speed and direction, as well as acceleration, magnetic field and orientation.	decision tree;experiment;global positioning system;inference engine;mimic;machine learning;mobile phone;multimodal interaction;sensor;while	Patrick Tchankue;Janet Wesson;Dieter Vogts	2013		10.1145/2513456.2513472	embedded system;simulation;engineering;computer security	HCI	-17.40784105633733	-33.03434791352891	126267
aad463674f2622f3af476af787cccd11d23432f1	review of the methods of delimitation for the spatial scope of urban agglomeration	analytical models;radiant ability;spatial correlation analysis;delimitation;town and country planning;model analysis;biological system modeling;gravity;qualitative analysis;network urban agglomeration;cities and towns biological system modeling analytical models geographic information systems gravity mathematical model economics;central city based analysis;modeling analysis;urban agglomeration;spatial correlation;statistical analysis;gis;gis urban agglomeration spatial scope delimitation;multifactor overlay analysis;geographic information systems;mathematical model;data flow analysis;quantitative analysis;cities and towns;spatial scope;polycentric urban agglomeration;economics;flow data analysis;urban agglomeration region delimitation;town and country planning data flow analysis geographic information systems statistical analysis;spatial statistics;spatial statistical analysis;flow data analysis urban agglomeration region delimitation key indicator distribution analysis radiant ability central city based analysis modeling analysis multifactor overlay analysis spatial correlation analysis polycentric urban agglomeration network urban agglomeration spatial statistical analysis gis;key indicator distribution analysis	The delimitation of urban agglomeration region is a critical issue in urban studies. But there are no standard methods so far for the delimitation. Starting with the concept of urban agglomeration, this paper reviews the methods of the delimitation of urban agglomeration region. We sum up two types of the methodology of the delimitation of urban agglomeration region. We compare and analyze a variety of promising and representative methods such as the key indicators distribution analysis, radiant ability of central city-based analysis, modeling analysis, multi-factor overlay analysis and spatial correlation analysis. Based on such, the common characteristics of the existing methods are abstracted and further developments are discussed. Finally we conclude that the analysis based on the functional zones, emphasizing the relations between the cities and the mode of combining qualitative analysis with quantitative analysis are the developing trends of the method. Facing to the more emergences of the polycentric urban agglomeration and the network urban agglomeration, the method combining spatial statistical analysis based on GIS with the analysis of the flow data among cities would be a better choice for the delimitation of urban agglomeration region.	geographic information system;radiant ai	Jian Liang;Feixue Li;Liang Mao	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5567776	environmental engineering;geography;regional science	Visualization	-12.140501348098766	-24.416597551822807	126329
787d2171efb755c29f7a9d952e4906e407451920	creating probabilistic databases from information extraction models	information extraction;best approximation;efficient algorithm;statistical model;data model;probabilistic database;probability distribution	Many real-life applications depend on databases automatically curated from unstructured sources through imperfect structure extraction tools. Such databases are best treated as imprecise representations of multiple extraction possibli-ties. State-of-the-art statistical models of extraction provide a sound probability distribution over extractions but are not easy to represent and query in a relational framework. In this paper we address the challenge of approximating such distributions as imprecise data models. In particular, we investigate a model that captures both row-level and column-level uncertainty and show that this representation provides significantly better approximation compared to models that use only row or only column level uncertainty. We present efficient algorithms for finding the best approximating parameters for such a model: our algorithm exploits the structure of the model to avoid enumerating the exponential number of extraction possibilities.	approximation algorithm;data model;information extraction;probabilistic database;real life;statistical model;time complexity	Rahul Gupta;Sunita Sarawagi	2006			probability distribution;statistical model;data model;computer science;probabilistic database;machine learning;pattern recognition;data mining;database;information extraction	DB	-8.731497983182116	-33.050961467571895	126461
e51c6a9dc99f8ed36b60c6c40dd98f1ad72b2ae7	privacy-protected statistics publication over social media user trajectory streams		An increasing amount of user location information is being generated due to the widespread use of social network applications and the ubiquitous adoption of mobile and wearable technologies. This data can be analysed to identify precise trajectories of individuals — where they went and when they were there. This is an obvious privacy issue, yet publication of real-time aggregate over such location streams can provide valuable resources for researchers and government agencies, e.g., in case of pandemics it would be very useful to identify who might have come into contact with an infected individual at a given time. Differential privacy techniques have become popular and widely adopted to address privacy concerns. However, there are three key issues that limit the application of existing differential privacy approaches to user trajectory data: (a) the heterogeneous nature of the trajectories, (b) uniform sliding window mechanisms do not meet individual privacy requirements and (c) limited privacy budgets and impact on data utility when applied to infinite data streams. To tackle these problems, this paper proposes a private real-time trajectory stream statistics publication mechanism utilizing differential privacy (DP-PSP). To relieve the heterogeneity issues, anchor point discovery (e.g., fixed locations like museums, parks, etc.) and road segmentingmechanisms are proposed.Weprovide an adaptivew-step slidingwindowapproach that allows users to specify their own dynamic privacy budget distribution to optimize their own privacy budget. To preserve the data utility, we presentmulti-timestamp predictionmodels and private k-nearest neighbour selection and perturbation algorithms to reduce the amount of perturbation distortion induced through the differential privacy mechanism. Comprehensive experiments over real-life location-based social network user trajectories show that DP-PSP provides private data aggregate over infinite trajectory streams and boosts the utility and quality of the perturbed aggregation without compromising individual privacy. © 2017 Elsevier B.V. All rights reserved.		Shuo Wang;Richard O. Sinnott;Surya Nepal	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.08.002	streams;differential privacy;market segmentation;privacy by design;privacy software;data mining;distributed computing;statistics;data stream mining;government;social network;computer science	DB	-17.23026435925541	-35.22063627882808	126479
7e57f765b6606f3567ac1400156920d8cb31c5c7	association rule mining using time series data for malaysia climate variability prediction		Many studies have been conducted to determine how data mining can be used in predicting climate change. Previous studies showed many data mining methods have been used in related to climate prediction, however classification and clustering methods are widely used to generate the climate prediction model. In this study, Association Rule Mining (ARM) is used to discover hidden rules in time series climate data from previous years and to analyze the relationship between the discovered rules. The dataset used in this study is a set of weather data from the Petaling Jaya observation station in Selangor for the year 2013 to 2015. This paper aims to utilize ARM for extracting behavioural patterns within the climate data that can be used to develop the prediction model for climate variability. The proposed framework is developed to provide a better approach in understanding how ARM can be used to find meaningful patterns in the climate data and generate rules that can be used to build a prediction model.	association rule learning;heart rate variability;time series	Rabiatul A. A. Rashid;Puteri N. E. Nohuddin;Zuraini Zainol	2017		10.1007/978-3-319-70010-6_12	data science;time series;data mining;cluster analysis;association rule learning;geography;climate change	ML	-16.846369907978964	-32.61276162970425	126535
c6776614b0e8baa5e25d765a760abbd32c48d0ad	likelihood inference for small area estimation using data cloning	prediction interval and exponential family;random effect;bayesian computation;hierarchical model	Motivation County estimates of agriculture products assist the agriculture authorities in local agriculture decision making. But in some areas, we do not have enough sample size to find reliable direct estimates? Motivation County estimates of agriculture products assist the agriculture authorities in local agriculture decision making. But in some areas, we do not have enough sample size to find reliable direct estimates? Having the information about income of households (or e.g., poor school-age children) for small places are very useful for government to determine fund allocations to local government units Motivation In small area estimation, there are many situations where observations are proportions or counts. Motivation In small area estimation, there are many situations where observations are proportions or counts. Widely used mapping of regional mortality (or incidence) rates of disease, such as cancer, in public health research Motivation In small area estimation, there are many situations where observations are proportions or counts. Widely used mapping of regional mortality (or incidence) rates of disease, such as cancer, in public health research Study geographical variation of these maps for formulating and assessing aetiological hypotheses, resource allocation, and identify regions of unusually high risk warranting intervention Motivation In small area estimation, there are many situations where observations are proportions or counts. Widely used mapping of regional mortality (or incidence) rates of disease, such as cancer, in public health research Study geographical variation of these maps for formulating and assessing aetiological hypotheses, resource allocation, and identify regions of unusually high risk warranting intervention Direct estimate of ratios, called standardized mortality ratios (SMR), can be very unreliable. A major difficulty in modeling small area models in the class of generalized linear mixed models (GLMMs) has been computational. A major difficulty in modeling small area models in the class of generalized linear mixed models (GLMMs) has been computational. Conventionally used Bayesian analysis as a convenient way for GLMM, but they may be dependent to the choice of priors and possibly of improper posterior distribution may be involved	incidence matrix;map;mixed model;shingled magnetic recording	Mahmoud Torabi;Subhash R. Lele;Narasimha G. N. Prasad	2015	Computational Statistics & Data Analysis	10.1016/j.csda.2015.03.013	econometrics;computer science;data mining;mathematics;hierarchical database model;statistics;random effects model	Metrics	-10.286992997848348	-25.158282976500033	126568
fc359530f1d6579e0de6727568a5a56d677414de	near duplicate detection in relational databases		While data amount increases, number of duplicate records in relational databases increase gradually. The duplicate records might cause inconsistency on reports and analyzes. To reduce the effects of this problem, we aim to detect duplicate records using machine learning algorithms with features that are produced by similarity of the records. We achieved to detect 28412 duplicate records in 9301467 records. The detected duplicate rows are removed from the data source and the data become more consistent.	algorithm;machine learning;relational database	Ahmet Tugrul Bayrak;Aykut Inan Yilmaz;Kemal Burak Yilmaz;Remzi Düzagaç;Veri Bilimi;Analitik Bolumu;Olcay Taner Yildiz	2018	2018 26th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2018.8404678	data mining;feature extraction;computer science;knowledge extraction;artificial intelligence;pattern recognition;row;relational database	DB	-6.1871604577546035	-34.0185185565847	126652
324fd86fbab55dbde39adf3d421b2c22dce99cef	data, mining time series data			data mining;time series	Eamonn J. Keogh	2011		10.1007/978-3-642-04898-2_19	data stream mining	ML	-9.709680425607733	-33.53811150211178	126665
1a653258c095759809f7d2d388435e557e0faced	system specification and validation of a noseband pressure sensor for measurement of ruminating and eating behavior in stable-fed cows	rumiwatch;dairy cow;health monitoring;chewing activity;precision dairy farming	http://dx.doi.org/10.1016/j.compag.2017.02.021 0168-1699/ 2017 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/). ⇑ Corresponding author. E-mail addresses: nils.zehner@agroscope.admin.ch (N. Zehner), christina. umstaetter@agroscope.admin.ch (C. Umstätter), joel.niederhauser@innoclever.com (J.J. Niederhauser), matthias.schick@agroscope.admin.ch (M. Schick). Nils Zehner a,⇑, Christina Umstätter , Joël J. Niederhauser , Matthias Schick a	requirement;sensor web;software versioning;switzerland	Nils Zehner;Christina Umstätter;Joel J. Niederhauser;Matthias Schick	2017	Computers and Electronics in Agriculture	10.1016/j.compag.2017.02.021	simulation;engineering;forensic engineering	ECom	-9.711821968626248	-27.67925694340038	126730
34d8c0ab8082f76f4fe1831d7e19d80dc7f0dbf9	parallel control and management for high-speed maglev systems	control systems safety complex systems vehicles rail transportation power supplies;control systems;agent based modeling parallel control and management high speed maglev system artificial system;magnetic levitation vehicles;simulation;shanghai china;high speed rail;intelligent agents;railroad traffic control;routes and routing;parallel processing	This paper puts forward a systems approach for the parallel control and management of the high-speed maglev system (HMS). An artificial HMS is first established by using a multiagent-based technique, and we demonstrate its consistence with the actual HMS. We then conduct some computational experiments and summarize some operational rules for the artificial HMS. Finally, the parallel control and management for the HMS are achieved by parallel execution of the artificial and actual HMSs with parallel interactions between them. We evaluate our approach overall by ensuring the safety and reliability of the HMS through parallel control and management. The solutions and recommendations for the safety control and effective management of the HMS can be provided by the proposed approach.	agent-based model;experiment;health management system;human factors and ergonomics;interaction;mathematical model;real-time transcription	Dewang Chen;Jiateng Yin;Long Chen;Hongze Xu	2017	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2016.2577037	control engineering;parallel processing;computer science;engineering;automotive engineering;transport engineering	SE	-18.807466051523864	-25.734338609784132	126933
c483b8f8c50d5503d6daa0f3c73ed8c4f1550d32	quantitative network analysis for passenger pattern recognition: an analysis of railway stations	rikov;passenger pattern recognition;quantitative networks;network analysis;re h strain	As recent attacks in trains and train stations show, the protections of such critical infrastructure plays a major role for public decision makers. Thereby, security installations in the railway network are a frequently discussed topic. Especially the need for an open system demands for technologies that do not influence or delay passenger flows. This also leads to the question of optimal placement of security installations such as smart camera systems or stand-off detectors. For answering this question we observed passenger flows in the Munich central station. The observation data was transferred into a quantitative network and analyzed using various measures. With its help, critical parameter constellations can be identified and investigated in detail. Furthermore we are able to identify special groups of passengers and the differences in their behavior.	critical infrastructure protection;network theory;pattern recognition;real life;sensor;simulation;smart camera;social network analysis	Martin Zsifkovits;Marian Sorin Nistor;Silja Meyer-Nieberg	2015	2015 7th International Conference of Soft Computing and Pattern Recognition (SoCPaR)	10.1109/SOCPAR.2015.7492815	network analysis;computer science;artificial intelligence;computer security	Vision	-16.596653096888442	-29.677798112930766	127372
b01ebb4bc83c1ec8727fbd1bc096d9839916cd9f	building a time series action network for earthquake disaster		Since there is 87% of chance of an approximately 8.0-magnitude earthquake occurring in the Tokai region of Japan within the next 30 years; we are trying to help computers to recommend suitable action patterns for the victims if this massive earthquake happens. For example, the computer will recommend “ what should do to go to a safe place ”, “ how to come back home ”, etc. To realize this goal, it is necessary to have collective intelligence of action patterns, which relate to the earthquake . It is also important to let the computers make a recommendationin time, especially in this kind of emergency situation. This means these action patterns should to be collected in real-time. Additionally, to help the computers understand the meaning of these action patterns, we should build the collective intelligence based on web ontology language (OWL). However, the manual construction of the collective intelligence will take a large cost, and it is difficult in the emergency situation. Therefore, in this paper, we first design a time series action network. We then introduce a novel approach, which can automatically collects the action patterns from Twitter for the action network in realtime. Finally, we propose a novel action-based collaborative filtering, which predicts missing activity data, to complement this action network.	action potential;collaborative filtering;collective intelligence;computer;goto;ontology (information science);real-time clock;real-time computing;semantic network;time series;web ontology language	The-Minh Nguyen;Takahiro Kawamura;Yasuyuki Tahara;Akihiko Ohsuga	2012			computer science;urban seismic risk;data mining	AI	-15.789528882592165	-31.557298928519295	127404
1c2ca6bdb23fec3d5c33467e84b4a660752dd829	index-maxminer: a new maximal frequent itemset mining algorithm	data mining;set enumeration tree;association rule;indexation;frequent itemset mining;maximal frequent itemset;index array	Because of the inherent computational complexity, mining the complete frequent itemset in dense datasets remains to be a challenging task. Mining Maximal Frequent Itemset (MFI) is an alternative to address the problem. Set-Enumeration Tree (SET) is a common data structure used in several MFI mining algorithms. For this kind of algorithm, the process of mining MFI’s can also be viewed as the process of searching in set-enumeration tree. To reduce the search space, in this paper, a new algorithm, IndexMaxMiner, for mining MFI is proposed by employing a hybrid search strategy blending breadth-first and depth-first. Firstly, the index array is proposed, and based on bitmap, an algorithm for computing index array is presented. By adding subsume index to frequent items, Index-MaxMiner discovers the candidate MFI’s using breadth-first search at one time, which avoids first-level nodes that would not participate in the answer set and reduces drastically the number of candidate itemsets. Then, for candidate MFI’s, depth-first search strategy is used to generate all MFI’s. Thus, the jumping search in SET is implemented, and the search space is reduced greatly. The experimental results show that the proposed algorithm is efficient especially for dense datasets.	algorithm;alpha compositing;association rule learning;bitmap;breadth-first search;computational complexity theory;data structure;depth-first search;global variable;maximal set;mined;stable model semantics	Wei Song;Bingru Yang;Zhangyan Xu	2008	International Journal on Artificial Intelligence Tools	10.1142/S021821300800390X	association rule learning;computer science;data science;data mining;database	ML	-6.151041829806203	-37.77202246301666	127557
78d0129b0307896b6e0388e29aca868c9d39c6dc	measuring the quality of queries in the fuzzy relational databases		In this paper, we develop a new method to measure the quality of each tuple as an Ž . answer with respect to Select-Project-Join SPJ queries so that we can determine which answers are better answers to the given query in a fuzzy relational database. The quality of an answer is viewed as how much sure information is provided, and how much extra information is needed so that it will be a sure answer to the query. The less extra information that is required and the more sure information that is provided by an answer, the higher the quality of that answer is, and in consequence, it will be more reliable. 2001 John Wiley & Sons, Inc.	john d. wiley;query language;relational database	Nan-Chen Hsien;Ding-An Chiang;Rick Chu-Tai Chiang	2001	Int. J. Intell. Syst.	10.1002/1098-111X(200102)16:2%3C191::AID-INT30%3E3.0.CO;2-J	fuzzy logic;relational database;computer science;artificial intelligence;data mining;database;mathematics;fuzzy set;information extraction;query language;set theory	DB	-4.567197416773982	-27.617151873329256	127738
895a4be46dcfe71a8de1d5b0466d28d4b4eeab0e	a framework for change diagnosis of data streams.	hardware acceleration;spatial join;data stream;density estimation;transaction data;spatio temporal data;batch process;spatial selection;velocity profile	In recent years, the progress in hardware technology has made it possible for organizations to store and record large streams of transactional data. This results in databases which grow without limit at a rapid rate. This data can often show important changes in trends over time. In such cases, it is useful to understand, visualize and diagnose the evolution of these trends. When the data streams are fast and continuous, it becomes important to analyze and predict the trends quickly in online fashion. In this paper, we discuss the concept of velocity density estimation, a technique used to understand, visualize and determine trends in the evolution of fast data streams. We show how to use velocity density estimation in order to create both temporal velocity profiles and spatial velocity profiles at periodic instants in time. These profiles are then used in order to predict three kinds of data evolution: dissolution, coagulation and shift. Methods are proposed to visualize the changing data trends in a single online scan of the data stream, and a computational requirement which is linear in the number of data points. In addition, batch processing techniques are proposed in order to identify combinations of dimensions which show the greatest amount of global evolution. The techniques discussed in this paper can be easily extended to spatio-temporal data, changes in data snapshots at fixed instances in time, or any other data which has a temporal component during its evolution.	batch processing;data point;database;dynamic data;velocity (software development)	Charu C. Aggarwal	2003		10.1145/872757.872826	density estimation;hardware acceleration;computer science;data science;transaction data;data mining;database;batch processing	DB	-9.864007307544611	-33.82197035606467	127759
1a07b2822cb6a02e17aa1e1081194f2992ca0da8	road traffic prediction by incorporating online information	traffic prediction;rfid;hierarchical bayesian network	Road traffic conditions are typically affected by events such as extreme weather or sport games. With the advance of Web, events and weather conditions can be readily retrieved in real-time. In this paper, we propose a traffic condition prediction system incorporating both online and offline information. RFID-based system has been deployed for monitoring road traffic. By incorporating data from both road traffic monitoring system and online information, we propose a hierarchical Bayesian network to predict road traffic condition. Using historical data, we establish a hierarchical Bayesian network to characterize the relationships among events and road traffic conditions. To evaluate the model, we use the traffic data collected in Western Massachusetts as well as online information about events and weather. Our proposed prediction achieves an accuracy of 93% overall.	bayesian network;online and offline;radio-frequency identification;real-time locating system	Tian Zhou;Lixin Gao;Daiheng Ni	2014		10.1145/2567948.2580072	traffic generation model;radio-frequency identification;simulation;floating car data;computer science;data mining;computer security	AI	-16.377891110808136	-31.29973802923477	127804
22198e64c792eb6aa78cca009370f5295c218eed	triangle counting approach for graph-based association rules mining	graph search;np hard problem triangle counting approach graph based association rules mining graph based arm transactional database graph structure search optimization frequent item sets subgraph search search pruning process connected graphs data representation triangle construction bit vector representation triangle integration execution time reduction method rules generation;graph theory;data representation triangle counting association rules mining graph based;graph theory computational complexity computational geometry data mining data structures database management systems;database management systems;computational geometry;association rules vectors algorithm design and analysis itemsets social network services;data mining;data representation;association rule mining;connected graph;triangle counting;computational complexity;data structures;graph based;association rules mining	Graph-based Association Rules Mining (ARM) is a research area that represents a transactional database into a graph structure to optimize the search for frequent item sets. Sub-graph search is the process of pruning the search by looking for the best representation of connected nodes in a graph to represent the fully connected graphs. Triangle Counting Approach is one of the sub-graph search approaches to find the most represented graph. This study aims to employ the Triangle Counting Approach for graph-based association rules mining. A triangle counting method for graph-based ARM is proposed to prune the graph in the search for frequent item sets. The triangle counting is integrated with one of the graph-based ARM methods. It consists of four important phases; data representation, triangle construction, bit vector representation, and triangle integration with the graph-based ARM method. The performance of the proposed method is compared with the original graph-based ARM. Experimental results show that the proposed method reduces the execution time of rules generation and produces less number of rules with higher confidence.	association rule learning;bit array;data (computing);database transaction;graph traversal;run time (program lifecycle phase)	Yazan Alaya Jameel Al-Khassawneh;Azuraliza Abu Bakar;Suhaila Zainudin	2012	2012 9th International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2012.6233981	graph power;factor-critical graph;combinatorics;association rule learning;graph bandwidth;null graph;computational geometry;computer science;clique-width;connectivity;graph theory;simplex graph;machine learning;aperiodic graph;cubic graph;data mining;mathematics;voltage graph;distance-hereditary graph;external data representation;graph;computational complexity theory;butterfly graph;quartic graph;complement graph;intersection graph;line graph;string graph;strength of a graph	ML	-5.294022242444723	-37.52156061168308	128080
c1563a2cc5b8eff1322a93c531c0eaa0947a322b	structure-based inference of xml similarity for fuzzy duplicate detection	multiple representation;bayesian network;relational data;duplicate detection;data integrity;complex structure;xml database;hierarchical data;data mining;xml;data cleaning;data warehouse;computational efficiency;similarity measure;bayesian networks	Fuzzy duplicate detection aims at identifying multiple representations of real-world objects stored in a data source, and is a task of critical practical relevance in data cleaning, data mining, or data integration. It has a long history for relational data stored in a single table (or in multiple tables with equal schema). Algorithms for fuzzy duplicate detection in more complex structures, e.g., hierarchies of a data warehouse, XML data, or graph data have only recently emerged. These algorithms use similarity measures that consider the duplicate status of their direct neighbors, e.g., children in hierarchical data, to improve duplicate detection effectiveness. In this paper, we propose a novel method for fuzzy duplicate detection in hierarchical and semi-structured XML data. Unlike previous approaches, it not only considers the duplicate status of children, but rather the probability of descendants being duplicates. Probabilities are computed efficiently using a Bayesian network. Experiments show the proposed algorithm is able to maintain high precision and recall values, even when dealing with data containing a high amount of errors and missing information. Our proposal is also able to outperform a state-of-the-art duplicate detection system on three different XML databases.	algorithm;bayesian network;data mining;experiment;hierarchical database model;plasma cleaning;precision and recall;relevance;semiconductor industry;xml database	Luís Leitão;Pável Calado;Melanie Herschel	2007		10.1145/1321440.1321483	computer science;data warehouse;bayesian network;data mining;database;information retrieval	DB	-6.648569251850459	-38.009344214658164	128173
6f41f15425c9d30536bd531115e616aad9853061	analysis of potential co-benefits for bicyclist crash imminent braking systems		In the US, the number of traffic fatalities has had a long term downward trend as a result of advances in the crash worthiness of vehicles. However, these improvements in crash worthiness do little to protect other vulnerable road users such as pedestrians or bicyclists. Several manufacturers have developed a new generation of crash avoidance systems that attempt to recognize and mitigate imminent crashes with non-motorists. While the focus of these systems has been on pedestrians where they can make meaningful contributions to improved safety [1], recent designs of these systems have recognized mitigating bicyclist crashes as a potential co-benefit. This paper evaluates the performance of one system that is currently available for consumer purchase. Because the vehicle manufacturer does not claim effectiveness for their system under all crash geometries, we focus our attention on the crash scenario that has the highest social cost in the US: the cyclist and vehicle on parallel paths being struck from behind. Our analysis of co benefits examines the ability to reduce three measures: number of crashes, fatalities, and a comprehensive measure for social cost that incorporates morbidity and mortality. Test track simulations under realistic circumstances with a realistic surrogate bicyclist target are conducted. Empirical models are developed for system performance and potential benefits for injury and fatality reduction. These models identify three key variables in the analysis: vehicle speed, cyclist speed and cyclist age as key determinants of potential co-benefits. We find that the evaluated system offers only limited benefits for any but the oldest bicycle riders for our tested scenario.	controlled image base;crash (computing);simulation	David H. Good;Kerry Krutilla;Stanley Y. P. Chien;Lingxi Li;Yaobin Chen	2017	2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2017.8317877	simulation;social cost;engineering;crash	SE	-19.115284026534226	-27.000953162409477	128322
0ab8a713167efc86d43765e842723d8be7cf0576	discovering congestion propagation patterns in spatio-temporal traffic data	sensors;bayes methods;hidden markov models;roads heuristic algorithms hidden markov models big data data models bayes methods sensors;big data;roads;heuristic algorithms;data models;urban computing and planning congestion propagation spatio temporal causal dynamic bayesian network	Traffic congestion is a condition of a segment in the road network where the traffic demand is greater than the available road capacity. The detection of unusual traffic patterns including congestions is a significant research problem in the data mining and knowledge discovery community. However, to the best of our knowledge, the discovery of propagations, or causal interactions among detected traffic congestions has not been appropriately investigated before. In this research, we introduce algorithms which construct causality trees from congestions and estimate their propagation probabilities based on temporal and spatial information of the congestions. Frequent sub-structures of these causality trees reveal not only recurring interactions among spatio-temporal congestions, but potential bottlenecks or flaws in the designs of existing traffic networks. Our algorithms have been validated by experiments on a travel time data set recorded from an urban road network.	algorithm;causality;data mining and knowledge discovery;experiment;interaction;network congestion;norm (social);software propagation;traffic analysis	Hoang Duy Nguyen;Wei Liu;Fang Chen	2017	IEEE Transactions on Big Data	10.1109/TBDATA.2016.2587669	data modeling;big data;computer science;sensor;data science;machine learning;data mining	ML	-16.344924035872353	-32.015384569124485	128362
703d88c87109a01650bda6a6234b2d4de5540edf	an experimental evaluation of aggregation algorithms for processing top-k queries	databases;performance evaluation;query processing;approximation algorithms;buffer storage;会议论文;probes;approximation algorithms middleware buffer storage computer science probes performance evaluation databases;data resources aggregation algorithms top k query processing monotone aggregation functions ta like algorithms;middleware;computer science	For processing top-K queries with monotone aggregation functions, the threshold algorithm (TA) and its family are important methods in many scenarios. From 1996 to 2003, Fagin et al. proposed a variety of TA-like algorithms such as the FA, TA, TAz, NRA and CA algorithms for different access methods as well as various data resources, but they did not report the experimental results of the TA-like algorithms in their seminal papers. Since then, some of the original TA-like algorithms have been implemented, improved or adapted in different situations and/or applications, however, the original algorithms have not been thoroughly compared and analyzed under the same experimental framework. To address this problem, in this paper, we carry out extensive experiments to measure the performance of the original aggregation algorithms and the slight adaptations of TA, TAz and NRA, and then we provide comprehensive surveys on the natures of the TA-like algorithms based on our experimental results.	aggregate function;algorithm;baseline (configuration management);certificate authority;cinema 4d;emoticon;experiment;fagin's theorem;heuristic;online aggregation;performance;monotone	Liang Zhu;Qin Ma;Weiyi Meng;Mingqian Yang;Fang Yuan	2015	2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing	10.1109/CIT/IUCC/DASC/PICOM.2015.47	probabilistic analysis of algorithms;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;middleware;data mining;database;approximation algorithm	DB	-8.453111732229438	-34.302996861984724	128365
12274a442c19ab88d4d93d8326e9af110e9ed4fa	big data and potential traffic information applications	big data mobile communication government mobile computing accuracy cloud computing;government;accuracy;big data;proceedings paper;mobile communication;mobile computing;traffic information systems big data cloud computing competitive intelligence computer animation government data processing marketing real time systems statistics;animation traffic information applications historical big data real time big data business value business intelligence marketing strategies traffic information cloud taiwan government cloud services lin chang huangfu scheme lch scheme standard statistics cloud computing;cloud computing	The comprehensive analysis on historical and real-time big data delivers huge business value, explores business intelligence, and assists in developing marketing strategies. This talk uses traffic information cloud as an example to show how big data is used to improve the accuracy and coverage of traffic information. Taiwan government is investing Traffic Info. cloud services to bring new business opportunities. It is proved that the Traffic Info. Cloud can effectively provide traffic information in terms of accuracy and large information coverage area. However, to execute the plan of Traffic Info. cloud service, our government is facing the challenges of big data: to extract traffic information from high-velocity data, and to store and analyze high-volume historical data. We show how these issues can be addressed through cloud computing platform and describe the Lin-Chang-Huangfu (LCH) Scheme that takes the advantage of the standard statistics available in mobile switching centers for vehicle speed analysis. We also show how cloud computing techniques are utilized for animation visual effect and passenger movement prediction.	big data;cloud computing;real-time transcription;traffic exchange;velocity (software development);visual effects	Yi-Bing Lin	2015	2015 IEEE 39th Annual Computer Software and Applications Conference	10.1109/COMPSAC.2015.341	cloud computing security;big data;cloud computing;computer science;operating system;software engineering;cloud testing;data mining;database;internet privacy;mobile computing;world wide web;computer security;government	Metrics	-18.264415323270146	-31.3310304099398	129658
a1fb540f890f9aac3fa3f340afdb32340c5605dd	advanced matrix algorithm (ama): reducing number of scans for association rule generation	association rules;association rule mining;transaction databases;association rule;ama;arm;advanced matrix algorithm;database scanning	Existing Association Rules Mining (ARM) algorithms basically use multiple scans to extract a rule from a transaction database. Sometime ARM algorithms exit without a rule in the desktop environment due to the high volume of transactions. Matrix Algorithm (MA) is proposed to minimise this issue. However, it is a computational expensive solution. In this paper, we propose Advanced Matrix Algorithm (AMA), to generate an efficient rule by a single scan using the Boolean matrix concept. AMA is comparatively effective and efficient than traditional approaches in terms of computational cost for database scan and frequently candidate sets generation.	algorithm;association rule learning	Marghny H. Mohamed;Mohammed M. Darwieesh;A. B. M. Shawkat Ali	2011	IJBIDM	10.1504/IJBIDM.2011.039412	association rule learning;computer science;artificial intelligence;machine learning;data mining	NLP	-4.692620234808296	-37.398494094532865	130156
a01e213a68e550aa7be2abf8f4e623dd0bb49963	an example of decision support for trypanosomiasis control using a geographical information system in eastern zambia	animal diseases;decision support;environmental variables;information systems;multivariate analysis;geographic information system;maximum likelihood;trypanosomiasis;disease control;journal article;decision support framework;geographical information system;environmental variables digital coverage;environmental sustainability;weighted linear combination;high priority;tsetse control;trypanosomiasis control;zambia;article;physical geography;tsetse transmitted trypanosomiasis	In many African countries where both Government resources and donor aid for the control of tsetse-transmitted trypanosomiasis are declining, there is an increasing need to identify areas where intervention is most likely to be technically, economically, socially and environmentally sustainable. Activities then can be focused so that the maximum bene ts are obtained from limited resources. We describe a decision-support framework based on a geographical information system to identify areas of high priority for the control of tsetse and trypanosomiasis in the common  y belt of eastern Zambia. Digital coverages were generated for six environmental variables: (1) cattle density, (2) human density, (3) land designation, (4) relative arable potential, (5) crop-use intensity and (6) proximity to existing control operations. The distribution of tsetse in the area was predicted using a multivariate (maximum likelihood) analysis of areas of known presence and absence and a series of environmental data. Experienced Zambian veterinarians and biologists working in the region established criteria weights for the input variables and the data were integrated in a geographical information system (GIS), using weighted linear combinations to prioritize areas for trypanosomiasis control. The results of this exercise and estimates of the errors involved are discussed.	decision support system;geographic information system	T. P. Robinson;R. S. Harris;J. S. Hopkins;B. G. Williams	2002	International Journal of Geographical Information Science	10.1080/13658810110095057	geography;computer science;mathematics;geographic information system;maximum likelihood;multivariate analysis;operations research;sustainability;information system;statistics	ML	-10.371478785379916	-25.131274486840397	130305
0bab124ba6f9b80643e4dd73cd7d9fcd34995d7b	ieee icdm 2010 contest: tomtom traffic prediction for intelligent gps navigation	traffic simulation;warsaw contest tomtom tunedit traffic simulation prediction data mining;contest;simulation;traffic prediction;roads data mining driver circuits cities and towns global positioning system usa councils prediction algorithms;data mining;tunedit;tomtom;navigation;traffic simulation framework ieee icdm 2010 contest tomtom traffic prediction intelligent gps navigation interactive online competition tunedit platform icdm contest series;traffic information systems;global positioning system;traffic;traffic information systems data mining global positioning system navigation;prediction;warsaw	In this foreword, we summarize the IEEE ICDM 2010 Contest: “TomTom Traffic Prediction for Intelligent GPS Navigation”. The challenge was held between Jun 22, 2010 and Sep 7, 2010 as an interactive on-line competition, using the TunedIT platform (http://tunedit.org). We present the scope of the ICDM contest series in general, the scope of this year’s contest, description of its tasks, statistics about participation, details about the TunedIT platform and the Traffic Simulation Framework. A detailed description of winning solutions is part of this proceeding series.	gps navigation device;online and offline;simulation	Marcin Wojnarski;Pawel Góra;Marcin S. Szczuka;Hung Son Nguyen;Joanna Swietlicka;Demetrios Zeinalipour-Yazti	2010	2010 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2010.51	navigation;simulation;global positioning system;prediction;computer science;data mining;mathematics;computer security;statistics	Robotics	-16.659057553961333	-30.48449237971591	130671
590f2c64d425c4f948f8dae817ebe60d6d673b53	composition of simulation data for large-scale disaster estimation	spatio temporal database;disaster management;spatio temporal similarity search	When a large-scale natural disaster occurs, it is necessary to quickly collect damage information so that disaster-relief operations and wide-area support in accordance with the scale of the natural disaster can be initiated. Previously, we proposed a fast spatio-temporal similarity search method (called the STSim method) that searches a database storing many scenarios of disaster simulation data represented by time-series grid data for scenarios similar to insufficient observed data sent from sensors. When the STSim method is naively applied for estimating disasters occurring at multiple locations, e.g., fire spreading after a large-scale earthquake, it must prepare a huge number of combinations consisting of scenarios that represent disasters at multiple locations.  This paper presents a combination method of simulation data in order to apply the STSim method for estimating disasters occurring at multiple locations. This proposed method stores scenarios, each of which represents a disaster occurring at a single location, to a database; thus, reducing the number of scenarios. After a disaster occurs, it extracts and composes scenarios similar to observed data, resulting in efficient disaster estimation in any situation. We conducted performance evaluations under the assumption that an earthquake occurs below the Tokyo metropolitan region and estimating the spread of fire in the initial response. These results of the processing time for estimating the spread of fire show that the processing time is within 10 minutes, which is practical.	database;sensor;similarity search;simulation;time series	Hideki Hayashi;Akinori Asahara;Natsuko Sugaya;Yuichi Ogawa;Hitoshi Tomita	2016		10.1145/3017611.3017615	simulation;geography;data mining;computer security	DB	-15.284284973084752	-30.968072954508553	130718
e8f73a813a014add30d8d448476f656b67b0b044	statistical analysis of hotel plan popularity in regional tourist areas	tourism;hotel plan popularity;purchase rate	The tourism industry admitted by World Tourism Organization is one of the greatest growth industry. In Japan, this industry has big influence for economics, employments and regional activations. In 2003, Japanese government regarded own country as tourism country and has been doing various policies to makes Japan tourism country. According to the statistical data from home page of Japan Tourism Agency, the number of foreign tourists visiting Japan reached 24.04 million in 2016, marking a 21.8% increase over the previous record of 19.74 million set in 2015 and setting a new record high for a fourth consecutive year. Against this backdrop, the national average guest room occupancy rate of lodging facilities in Japan was 60.0% in 2016. However, it is noteworthy that a major disparity in guest room occupancy rates has occurred between urban areas and regional areas. The guest room occupancy rates in Tokyo and Osaka Prefecture were 79.4% and 84.1%, respectively, whereas in ten prefectures, they were below 50%, with Nagano Prefecture having the lowest rate: 35.5%. In these circumstances, regional tourism promotion is essential for implementing the Japanese government's regional revitalization policies. Accordingly, in the present study, for the purpose of considering the increase of guest room occupancy rates of the lodging facilities in regional areas, we performed analysis of the popularity of hotel plans in Yamanashi Prefecture, which is located near Tokyo, and in Okinawa Prefecture, where the number of tourists from overseas has increased in recent years. To ascertain hotel plan options, we used morphological analysis of plan names. And We created plan groups by cluster analysis. We defined the purchase rate as an indicator for measuring hotel plan popularity. For the purpose of ascertaining hotel plan popularity, we use multiple regression analysis. As a result, we obtained new knowledge about hotel plan popularity.	backdrop cms;binocular disparity;cluster analysis;home page;item unique identification	Hiroshi Tsuda;Masakazu Ando;Yu Ichifuji	2017	2017 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2017.8258451	data mining;occupancy;economic growth;tourism;popularity;computer science;government	DB	-16.108398845444516	-27.471956513252778	130806
5b00bafa6c6a5bca2d575561de0e9026e93de096	spatiotemporal data mining with cellular automata	bayes estimation;extraction information;biological model;traitement flux donnee;analisis datos;information extraction;base donnee temporelle;flux donnee;flujo datos;modelo biologico;probabilistic approach;data mining;spatial database;data analysis;estimacion bayes;vie artificielle;modele biologique;fouille donnee;enfoque probabilista;approche probabiliste;automate cellulaire;data flow processing;analyse donnee;spatial data structures;temporal databases;base dato especial;modele donnee;base de donnees spatiale;data flow;cellular automata;busca dato;cellular automaton;extraccion informacion;artificial life;historical data;data models;estimation bayes;automata celular;structure donnee spatiale	In this paper, we describe a cellular automata model for predicting biological spatiotemporal dynamics in an imagery data flow. The Bayesian probability-based algorithm is used to estimate the algal formation in a two-dimensional space. The dynamics of the cellular artificial life is described with diffusion, transport, collision and deformation. We tested the model with the historical data, including parameters, such as time, position and temperature.	cellular automaton;data mining;spatiotemporal database	Karl Fu;Yang Cai	2006		10.1007/11758501_158	cellular automaton;data modeling;data flow diagram;continuous spatial automaton;computer science;artificial intelligence;models of abnormality;data mining;database;temporal database;data analysis;spatial database;algorithm;artificial life	ML	-5.028498204692868	-31.645164047399348	130917
28ac24ac0be8308ff9432671c0ebfcedd0240460	lattice histograms: a resilient synopsis structure	memory sparing approach;maximum error metric;lattices histograms compaction informatics computer science quality management decision support systems query processing indexing data mining;generalization error;very large data sets lattice histograms resilient synopsis structure data reduction arbitrary data hierarchy maximum error metric memory sparing approach;conference_paper;lattice histograms;construction industry;large data sets;wavelet transforms;accuracy;indexes;resilient synopsis structure;compaction;very large data sets;approximation methods;data reduction;very large databases data reduction;data reduction techniques;very large databases;arbitrary data hierarchy;algorithm design and analysis	Despite the surge of interest in data reduction techniques over the past years, no method has been proposed to date that can always achieve approximation quality preferable to that of the optimal plain histogram for a target error metric. In this paper, we introduce the lattice histogram: a novel data reduction method that discovers and exploits any arbitrary hierarchy in the data, and achieves approximation quality provably at least as high as an optimal histogram for any data reduction problem. We formulate LH construction techniques with approximation guarantees for general error metrics. We show that the case of minimizing a maximum-error metric can be solved by a specialized, memory-sparing approach; we exploit this solution to design reduced-space heuristics for the general- error case. We develop a mixed synopsis approach, applicable to the space-efficient high-quality summarization of very large data sets. We experimentally corroborate the superiority of LHs in approximation quality over previous techniques with representative error metrics and diverse data sets.	approximation;approximation algorithm;computation;data structure;experiment;heuristic (computer science);lh (complexity);video synopsis;whole earth 'lectronic link	Panagiotis Karras;Nikos Mamoulis	2008	2008 IEEE 24th International Conference on Data Engineering	10.1109/ICDE.2008.4497433	database index;compaction;algorithm design;data reduction;computer science;theoretical computer science;data mining;database;accuracy and precision;statistics;wavelet transform;generalization error	DB	-7.95893294062859	-34.361235417833804	130953
de25096241546db8c47d7653ca8faa664606745b	exploration and comparison of geographic information sources using distance statistics	geographic information;distance statistics;spatial data mining;large scale;association rule;clustering;geographic features;feature selection;exploratory data analysis	Given the steadily increasing amount of geographic information on the Web, there is a strong need for suitable methods in exploratory data analysis that can be used to efficiently describe the characteristics of such large-scale, often noisy datasets. Existing methods in spatial data mining focus primarily on mining patterns describing spatial proximity relationships such as co-location patterns or spatial associations rules.  In this paper, we present a novel approach to describe the spatial characteristics of geographic information sources comprised of instances of geographic features. Using the concept of interaction characteristics of geographic features, similarities in how features are distributed in space can be computed and interesting patterns of similar features in the datasets regarding their geographic semantics (landmark, local, regional, global) can be determined. For this, we employ clustering techniques of spatial distance statistics.  We discuss the properties of our method and detail a comprehensive evaluation using publicly available datasets (Flickr, Twitter, OpenStreeMap). We demonstrate the feasibility of identifying groups of geographic features with distinct geographic semantics, which then can be used to select subsets of features for subsequent learning tasks or to compare different datasets.	categorization;cluster analysis;data mining;feature selection;flickr;geographic information system;mined;world wide web	Christian Sengstock;Michael Gertz	2011		10.1145/2093973.2094017	local information systems;association rule learning;geography;computer science;data science;geospatial analysis;machine learning;pattern recognition;data mining;spatial analysis;cluster analysis;exploratory data analysis;feature selection	DB	-18.509569811143948	-36.600190072558696	131288
097d6b26dceef9af1203b94ee4a6302aeb35af58	emergent future situation awareness: a temporal probabilistic reasoning in the absence of domain experts	hidden markov model;book chapter;dynamic bayesian networks;artificial intelligent;probabilistic model;multivariate time series;natural computing algorithms;dynamic bayesian network;situation awareness;artificial intelligence;prediction;temporal probabilistic reasoning;logistic regression model;probabilistic reasoning	Dynamic Bayesian networks (DBNs) are temporal probab ilistic models for reasoning over time which are rapidly ga ining popularity in modern Artificial Intelligence (AI) for planning. A number of Hidden Markov Model (HMM) representations of dynamic Bayesian networks w ith different characteristics have been developed. However, the v arieties of DBNs have obviously opened up challenging problems of how to ch ose the most suitable model for specific real life applications especiall y by non-expert practitioners. Problem of convergence over wider time steps is als o challenging. Finding solutions to these challenges is difficult. In this paper, we propose a new probabilistic modeling called Emergent Future Situa t on Awareness (EFSA) which predicts trends over future time steps to mit igate the worries of choosing a DBN model type and avoid convergence problems when pr dicting over wider time steps. Its prediction strategy is based on the automatic emergence of temporal models over two dimensional (2D) time step from historical Multivariate Time Series (MTS). Using real life pub licly available MTS data on a number of comparative evaluations, our experiment al results show that EFSA outperforms popular HMM and logistic regression mod els. This excellent performance suggests its wider application in resea rch nd industries.	artificial intelligence;dynamic bayesian network;emergent;enea ose;hidden markov model;logistic regression;markov chain;real life;time series	Isaac Olusegun Osunmakinde;Antoine B. Bagula	2009		10.1007/978-3-642-04921-7_35	probabilistic relevance model;computer science;artificial intelligence;machine learning;data mining;hidden markov model;dynamic bayesian network;statistics	AI	-11.78014281268089	-29.441290511566137	131441
131064322bc93838b8a66fb44d3b9e0e9fe375af	position prediction system based on spatio-temporal regularity of object mobility		Abstract With the accumulation of the vast amount of location data acquired by positioning devices embedded in mobile phones and cars, position prediction of moving objects has been an important research direction for many location-based services such as public transit forecasting and tourist behavior analysis. In this paper, a position prediction system has been proposed, which utilizes not only spatial but also temporal regularity of object mobility. Historical trajectory data of the object is used to extract personal trajectory patterns to obtain candidate next positions. Each of the candidate next positions is scored by the proposed Spatio-Temporal Regularity-based Prediction (STRP) algorithm according to time components of patterns and current time. The position with the highest score is considered as the predicted next position. Furthermore, a hybrid B/S and C/S architecture is employed to perform the real-time prediction and results display. An evaluation based on two different public trajectory data sets demonstrates that the proposed STRP algorithm achieves highly accurate position prediction. Moreover, the average accuracy rate of our prediction algorithm with one known position is about 86.8%, which is 43.9% better than the Markov-based algorithm.		Xin Li;Chongsheng Yu;Lei Ju;Jian Qin;Yu Zhang;Lei Dou;Yuqing Sun	2018	Inf. Syst.	10.1016/j.is.2018.02.004	architecture;data mining;computer science;trajectory;artificial intelligence;data set;markov chain;pattern recognition	DB	-16.629443897842584	-34.44584878721136	131468
2b384e14ad90186d9f639a0e401b14208616a15d	st-copot: spatio-temporal clustering with contour polygon trees		Nowadays, growing effort has been put to develop spatio-temporal clustering approaches that are capable of discovering interesting patterns in large spatio-temporal data streams. In this paper, we propose a 3-phase serial, density-contour based clustering algorithm called ST-COPOT, which can identify spatio-temporal cluster at multiple levels of density granularity. ST-COPOT takes the point cloud data as input and divides it into batches, next, it employs a non-parametric kernel density estimation approach and contouring algorithms to obtain spatial clusters; at last, spatio-temporal clusters are formed by identifying continuing relationships between spatial clusters in consecutive batches. Moreover, a novel data structure called contour polygon tree is introduced as a compact representation of the spatial clusters obtained for each batch for different density thresholds, and a family of novel distance functions that operate on contour polygon trees are proposed to identify continuing clusters. The experimental results on NYC taxi trips data show that ST-COPOT can effectively discover interesting spatio-temporal patterns in taxi pickup location streams.	algorithm;cluster analysis;contour line;data structure;kernel density estimation;point cloud	Yongli Zhang;Christoph F. Eick	2017		10.1145/3139958.3140051	streams;machine learning;point cloud;artificial intelligence;data stream mining;computer science;cluster analysis;granularity;kernel density estimation;polygon;data structure	ML	-11.894412698389878	-35.90244333384801	131535
c81660984bfa543148eede7acd797fb04bcc7c94	dci closed: a fast and memory efficient algorithm to mine frequent closed itemsets.	perforation;efficient algorithm;general techniques;frequent closed itemset;experimental evaluation	One of the main problems raising up in the frequent closed itemsetsmining problem is the duplicate detection. In this paper we propose a general technique for promptly detecting and discarding duplicate closed itemsets, without the need of keeping in the main memory the whole set of closed patterns. Our approach can be exploited with substantial performance benefits by any algorithm that adopts a vertical representation of the dataset. We implemented our technique within a new depth-first closed itemsets mining algorithm. The experimental evaluation demonstrates that our algorithm outperforms other state of the art algorithms like CLOSET+ and FPCLOSE.	algorithm;bitmap;computer data storage;depth-first search;digitally controlled impedance;sensor	Claudio Lucchese;Salvatore Orlando;Raffaele Perego	2004			computer science;data mining;database;algorithm	ML	-6.685029186400628	-36.83405219628921	131937
a57371c7e96533739ea4a0be48b7355b1ba07324	quality analysis of urban transit system in st. petersburg		A constant problem in big cities is the necessity to develop and enhance urban transit systems at a good pace. The main task is to improve the comfort of passengers using public transport. There are a number of indicators by which to value the convenience of the transport system of the metropolis. To compute these indicators, we analyzed the data obtained from the municipal information systems: the public transport payment system and transport tracking system. We evaluated the following indicators: rush hours during the day, average amount of trips made by passengers of each group per month, transportation comfort index, most and least comfortable districts of the city, interchange coefficient for regular trips and ordinary multimodal trips (average number of single trips within multimodal trip), average regular trip time consumption etc.		Natalia Grafeeva;Innokenty Tretyakov;Elena Mikhailova	2018		10.1007/978-3-319-77712-2_84	public transport;trips architecture;operations management;payment system;information system;business;tracking system	ML	-16.184018698955054	-27.62592558004026	132304
e5fd14f90c1debb922f1f8e2d941233b616e6480	impact of smartphone-delivered real-time multi-modal information	commuters;seat availability;driving frequency;rail transit;usage experience;travel time;travel delays;real time information;shanghai;usual commute mode;smartphones;driver access;gender;transport modes;generalised estimating equations;dynamic information;park and ride;road conditions;multi modal information;education level;stated preferences;china;commuting drivers;en trip mode switch	En-trip mode switch decisions under the smartphone-delivered multi-modal information (SMMI) seem to have been rarely explored. This study investigated the impact on commute drivers’ en-trip mode switch behaviour of SMMI. This was based on a stated preference (SP) survey in Shanghai which collected over 2000 observations of the choice between ‘auto’ and ‘park-and-ride’ (P+R) under SMMI. SMMI provides travel time for auto and P+R, delay for auto, cause of delay, P+R cost and comfort level of rail transit. A generalised estimating equations (GEEs)-based analysis was conducted to address the potential correlations between repeated observations from the same individual. Among the tested candidate GEEs models, the model with the ‘unstructured’ working correlation structure leads to the best fit for our SP data. Results showed that SMMI can significantly influence mode switch. Statistically significant explanatory variables in the model are gender, education level, usual commute mode, the number of sources of dynamic information of a driver access, frequency of driving, P+R use experience, seat availability in subway car, real time road condition, auto delay and P+R cost.	curve fitting;modal logic;real-time transcription;smartphone	Hongcheng Gan;Yafei Zhao;June Wei	2016	IJMC	10.1504/IJMC.2016.076282	simulation;telecommunications;china	HCI	-16.102873873750973	-27.395281690858702	132472
027771a4901e984e107259db73bc56a8d2c2cf2c	top-k temporal keyword search over social media data	social media;temporal keyword query;top-;k;query	Social media services have already become main sources for monitoring emerging topics and sensing real-life events. A social media platform manages social stream consisting of a huge volume of timestamped user generated data, including original data and repost data. However, previous research on keyword search over social media data mainly emphasizes on the recency of information. In this paper, we first propose a problem of top-k most significant temporal keyword query to enable more complex query analysis. It returns top-k most popular social items that contain the keywords in the given query time window. Then, we design a temporal inverted index with two-tiers posting list to index social time series and a segment store to compute the exact social significance of social items. Next, we implement a basic query algorithm based on our proposed index structure and give a detailed performance analysis on the query algorithm. From the analysis result, we further refine our query algorithm with a piecewise maximum approximation (PMA) sketch. Finally, extensive empirical studies on a real-life microblog dataset demonstrate the combination of two-tiers posting list and PMA sketch achieves remarkable performance improvement under different query settings.	experiment;inverted index;logical connective;multimedia framework;polynomial-time approximation scheme;profiling (computer programming);real life;scalability;search algorithm;social media;time series;phpmyadmin	Fan Xia;Chengcheng Yu;Linhao Xu;Weining Qian;Aoying Zhou	2016	World Wide Web	10.1007/s11280-016-0430-0	sargable;query optimization;query expansion;web query classification;computer science;machine learning;data mining;database;web search query;world wide web;information retrieval;query language	DB	-13.72191686818572	-36.074220273837334	132600
617b3dc73c3a92bf49ec1a7d907ee2c79dda15f3	measuring service accessibility in telephone nurse triage services	telephone nurse triage services;outbound calls;bayesian inference;service accessibility;overdispersion	Li Zeng Assistant Professor The University of Texas at Arlington Arlington, TX 76019 Ronnie Peterson Manager of Clinical Support University of Wisconsin Medical Foundation Middleton, WI 53563 Abstract Telephone nurse triage (TNT) services is an important component of the health care delivery system. Thanks to the advancement of telephone/information technologies, abundant data on the daily operations of telephone triage centers are now readily available which can be used to assess their performance. However, the current way to use such data is very primitive, which mainly focuses on simple descriptive statistics of the data. This study provides an approach to mine information from count data from the TNT service, including the daily inbound and outbound call volumes. A class of overdispersed generalized linear models (OGLMs) is proposed to model the outbound-inbound relationship and Bayesian algorithms for model estimation and comparison are provided. The established model reveals the variation in the accessibility of the triage service and the effect of weekday/weekend, which will provide significant information for performance assessment and improvement in such services. In the case study, the proposed approach is applied to a dataset from a triage call center in Wisconsin to demonstrate its use in practice. A numerical study is also done to examine the properties of the proposed model and accuracy of parameter estimation.	accessibility;count data;estimation theory;futures studies;generalized linear model;inbound marketing;numerical analysis;performance;peterson's algorithm	Li Zeng;Ronnie Peterson	2014	Quality and Reliability Eng. Int.	10.1002/qre.1632	simulation;operations management;data mining;mathematics;bayesian inference;operations research;overdispersion;statistics	HCI	-8.659863438641942	-26.179600071279484	132679
e7f2fd5ae34b8f6bbd82ed063dbccf357f50978d	iceberg-cube algorithms: an empirical evaluation on synthetic and real data	iceberg cube;data cube;bottom up computation;data mining;top down computation;empirical evaluation;knowledge discovery	The Iceberg-Cube problem is to identify the combinations of values for a set of attributes for which a specified aggregation function yields values over a specified aggregate threshold. We implemented bottom-up and top-down methods for this problem and performed extensive experiments featuring a variety of synthetic and real databases. The bottom-up method included pruning. Results show that in most cases the top-down method, with or without pruning, was slower than the bottom-up method, because of less effective pruning. However, below a crossover point, the top-down method is faster. This crossover point occurs at a relatively low minimum support threshold, such as 0.01% or 1.5%. The bottom-up method is recommended for cases when a minimum support threshold higher than the crossover point will be selected. The top-down method is recommended when a minimum support threshold lower than the crossover point will be used or when a large number of results is expected.	algorithm;synthetic data	Leah Findlater;Howard J. Hamilton	2003	Intell. Data Anal.	10.3233/ida-2003-7202	computer science;machine learning;data mining;mathematics;knowledge extraction;algorithm;data cube	AI	-5.5139256182791545	-36.79028666580864	132772
7230df5d8feb0b9be45a0def5730c7650ee634f2	towards estimation error guarantees for distinct values	random sampling;functional dependency;information dependency;multivalued dependency;armstrong s axioms;indexation;entropy;estimation error;synthetic data;error bound	We consider the problem of estimating the number of distinct values in a column of a table. For large tables without an index on the column, random sampling appears to be the only scalable approach for estimating the number of distinct values. We establish a powerful negative result stating that no estimator can guarantee small error across all input distributions, unless it examines a large fraction of the input data. In fact, any estimator must incur a significant error on at least some of a natural class of distributions. We then provide a new estimator which is provably optimal, in that its error is guaranteed to essentially match our negative result. A drawback of this estimator is that while its worst-case error is reasonable, it does not necessarily give the best possible error bound on any given distribution. Therefore, we develop heuristic estimators that are optimized for a class of typical input distributions. While these estimators lack strong guarantees on distribution-independent worst-case error, our extensive empirical comparison indicate their effectiveness both on real data sets and on synthetic data sets.	best, worst and average case;heuristic;monte carlo method;sampling (signal processing);scalability;synthetic data;table (database)	Moses Charikar;Surajit Chaudhuri;Rajeev Motwani;Vivek R. Narasayya	2000		10.1145/335168.335230	sampling;econometrics;entropy;mathematical optimization;estimator;armstrong's axioms;computer science;error bar;database;mathematics;functional dependency;multivalued dependency;statistics;synthetic data	DB	-7.384512778238385	-33.04530985223611	132903
a0be68809a15f5237da0e6118b9e58215ba8d297	antourage: mining distance-constrained trips from flickr	flickr;satisfiability;graph mining;max min ant system;photo collections;photo sharing;photo collection;geolocation;trip planning	We study how to automatically extract tourist trips from large volumes of geo-tagged photographs. Working with more than 8 million of these photographs that are publicly available via photo- sharing communities such as Flickr and Panoramio, our goal is to satisfy the needs of a tourist who specifies a starting location (typically a hotel) together with a bounded travel distance and demands a tour that visits the popular sites along the way. Our system, named ANTOURAGE, solves this intractable problem using a novel adaptation of the max-min ant system (MMAS) meta-heuristic. Experiments using GPS metadata crawled from Flickr show that ANTOURAGE can generate high-quality tours.	ant colony optimization algorithms;computational complexity theory;flickr;global positioning system;heuristic;maxima and minima	Saral Jain;Stephan Seufert;Srikanta J. Bedathur	2010		10.1145/1772690.1772834	computer science;geolocation;database;multimedia;internet privacy;world wide web;satisfiability	ML	-14.34240961455534	-37.206200631244634	133690
b948862b939e9c261d38c2f5763bcad41f418ebe	factors influencing two-way referral between hospitals and the community in china: a system dynamics simulation model		Background:Two-way referrals between hospitals and community healthcare systems (CHSs) are important for optimizing the distribution of medical resources and enabling resource sharing, but referrals are always from CHSs to hospitals. A referral from the hospital to the community is rare in China; this has a highly negative impact on the long-term development of the Chinese health services. The aim of this study was to address influence factors in hospital–community referrals.Methods:We constructed a system dynamics model to address the problem of the two-way referral between hospitals and CHSs and identified potential countermeasures and possible solutions. The Vensim DSS program was used to construct a system dynamics model to represent the problem through model description, causal loop diagrams, and stock and flow diagrams.Results:The model was used to perform intervention experiments, in which the influence on all the sectors of referrals could be observed by changing the system parameters. The experim...	simulation;system dynamics	Meina Li;Yi Zhang;Yang Lu;Wenya Yu;Xin Nong;Lulu Zhang	2018	Simulation	10.1177/0037549717741349	management science;simulation;china;referral;system dynamics;health care;shared resource;computer science	ECom	-16.685729511731196	-24.068828822693874	133760
85062124fce3388202e025010f2fec7d6500fb2b	gridwave: a grid-based clustering algorithm for market transaction data based on spatial-temporal density-waves and synchronization		The notion of density has been widely used in many spatial-temporal (ST) clustering methods. This paper proposes the novel notion of an ST density-wave, which is an extension of the notion of density. It also presents a new grid-based ST clustering algorithm called Gridwave based on the notion of ST density-waves and ST synchronization. The proposed algorithm can be used to discover synchronized changes in density among various locations as well as distinguish ST events and noise from market transaction data. Based on the theory of small-world networks, our algorithm can be used to evaluate ST synchronized correlations among regions with respective to the ST density over the whole network. To improve its performance, the proposed algorithm was implemented using parallel computing. To verify its feasibility, a real large-scale market transaction dataset was used to demonstrate the ST synchronized correlations and the final clustering results. Although our algorithm is applied in a domain-specific case, we suggest that the clustering notion and method could be generalized for other domain applications with similar ST data.	algorithm;big data;cluster analysis;experiment;parallel computing;requirements analysis;smart city;social network analysis;time complexity;transaction data	Chao Deng;Jinwei Song;Ruizhi Sun;Saihua Cai;Yinxue Shi	2017	Multimedia Tools and Applications	10.1007/s11042-017-5441-z	computer science;grid;artificial intelligence;synchronization;cluster analysis;machine learning;transaction data;pattern recognition;database transaction	ML	-11.778038808840424	-36.05492750806241	133881
fa9947b2ca045a58ad6e337066d124d0fd8a111e	on preprocessing multi-channel sensor data for online process monitoring	online monitoring;quality control data handling inference mechanisms injection moulding process monitoring production engineering computing;anomaly detection;data processing;inference mechanisms;production engineering computing;proof of concept;production process;multi channel sensor data;injection moulding;process monitoring;injection moulding process multichannel sensor data online process monitoring production processes online monitoring transient detection anomaly detection reasoning engine;process monitoring multi channel sensor data;data handling;quality control;engines time measurement production injection molding fuzzy logic laboratories condition monitoring heating temperature sensors humidity	This paper discusses online monitoring production processes based on multi-channel sensor data. Particularly the problem of transient and anomaly detection is addressed for which a processing framework consisting of a preprocessing module and a reasoning engine is outlined. While there is much theory available in the literature for the reasoning engine this is not the case for the preprocessing which massively depends on the physical interpretation and semantics of the data. The paper addresses these problems and proposes new normalization concepts based on regularization especially for making transients of multi-channel data comparable and adequate for further processing by a reasoning engine. A proof of concept is demonstrated by means of real data from an injection moulding process.	anomaly detection;preprocessor;semantic reasoner	Holger Schöner;Bernhard Moser;Edwin Lughofer	2008	2008 International Conference on Computational Intelligence for Modelling Control & Automation	10.1109/CIMCA.2008.91	quality control;anomaly detection;real-time computing;data processing;computer science;machine learning;group method of data handling;data mining;scheduling;proof of concept	Robotics	-7.803326088270955	-24.66590764411166	133887
17de4c14ed1b00e9222d6801839f42e519129bcf	modeling growth dynamics of juvenile loblolly pine plantations				Olga B. Avila	1993			agroforestry;juvenile;environmental science	Vision	-11.19937662927571	-26.76308340870308	134592
3a154e8ca4be327ab5a1a1582df6228574e29045	integrating game theory and data mining for dynamic distribution of police to combat crime		This paper proposes a framework that provides a strategy for police to allocate resources to tackle crime, by integrating data mining models for dynamic crime prediction with a game theoretical approach to recognize the adversarial nature of the problem. The proposed framework is applied to a real case study from Santiago (Chile), and compared to other strategies involving game theory or data mining alone. The hybrid approach is demonstrated to lead to improved payoffs for the police and reduced payoffs for the criminals. A robustness analysis explores how accuracy of the data mining models affects the outcomes of the game, showing that the proposed approach can absorb significant forecasting errors while still producing superior outcomes for the police.		Carolina Segovia;Kate Smith-Miles	2018	2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)	10.1109/WI.2018.00016	data mining;adversarial system;game theory;robustness (computer science);computer science;data modeling;law enforcement	ML	-12.62772697231606	-29.91027829308842	134623
21f8bd95933619d0f0dba41d48928631a2456251	study on simulation of exotic plant invasion based on a ca model	spatial spreading;analytical models;plant invasion system;landscape model;history;model for plant invasion system biological invasion celluar automata ca neutral landscape model nlm;dispersal mechanism;diverse life history strategy;biological invasion;biological system modeling;neutral landscape modeling;celluar automata ca;invasive plant;plant invasion;fecundity;neutral landscape model nlm;plants biology;spatial pattern;biological system modeling communities plants biology mathematical model history analytical models;cellular automata artificial life botany;exotic plant invasion;invasion mechanism;ca model;mathematical model;species traits;exotic plants;abiotic factors;communities;model for plant invasion system;cellular automata;land management;life history strategy;artificial life;botany;dispersal mechanism exotic plant invasion ca model invasion mechanism cellular automata neutral landscape modeling plant invasion system abiotic factors spatial spreading diverse life history strategy fecundity	Models play an important role in studying invasion mechanism of exotic plants. By integrating Cellular Automata and Neutral Landscape Modeling, the model for plant invasion system was built to study the effects of biotic and abiotic factors on the spatial spreading of exotic plant. The invasion processes of plant with diverse life history strategies in varied landscapes were simulated, and related factors were analyzed. The results showed that invasion rate and final area occupied were affected by species traits, e.g. fecundity, dispersal mechanism, spatial pattern of available habitats, and resistance of native community. The author implied that land managers should consider the different stages during an invasion and take suitable measures against the invasive plants, and prevention was the first priority than control after the invasion happened.	cellular automaton;habitat;simulation;spatiotemporal pattern	Jinxing Zhou;Qing Zhang;Jingming Zheng;Ming Cui;Xiaoming Li	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5583412	biology;botany;ecology	Robotics	-13.99193946582227	-25.400690473198996	134797
5d8191a35d1a7a3e16b4479a6eb5f85ae7fc295a	an efficient algorithm for top-k queries on uncertain data streams	probability center;top k queries;databases probability algorithm design and analysis educational institutions heuristic algorithms software algorithms complexity theory;query processing;set theory computational complexity data mining query processing;slidingwindow uncertain data streams top k queries;time complexity top k query algorithm uncertain data streams maximum probabilistic top k tuple set query answering sliding window model sliding window query processing space complexity;会议论文;set theory;data mining;grid;computational complexity;uncertain stream;slidingwindow;uncertain data streams	We tackle the problem of answering maximum probabilistic top-k tuple set queries. We use a sliding-window model on uncertain data streams and present an efficient algorithm for processing sliding-window queries on uncertain streams. In each sliding window, the algorithm selects the k tuples with the highest probabilities from sets of different numbers of the tuples with the highest scores. Then, the algorithm computes existential probability of the top-k tuples, and chooses the set with the highest probability as the top-k query result. We theoretically prove the correctness of the algorithm. Our experimental results show that our algorithm requires lower time and space complexity than other existing algorithms.	algorithm;correctness (computer science);dspace;microsoft windows;streaming media;uncertain data	Caiyan Dai;Ling Chen;Yixin Chen;Keming Tang	2012	2012 11th International Conference on Machine Learning and Applications	10.1109/ICMLA.2012.57	computer science;theoretical computer science;data mining;database;computational complexity theory;grid;set theory	DB	-6.593847379227953	-36.61423506205677	134987
9ec4ccca09377df87bcd607c37a67488da4d2be4	deepwitraffic: low cost wifi-based traffic monitoring system using deep learning		A traffic monitoring system (TMS) is an integral part of Intelligent Transportation Systems (ITS) for traffic analysis and planning. This paper addresses the endemic cost issue of deploying a large number of TMSs to cover huge miles of two-lane rural highways (119,247 miles in U.S.). A low-cost and portable TMS called DeepWiTraffic based on COTs WiFi devices and deep learning is proposed. DeepWiTraffic enables accurate vehicle detection and classification by exploiting the unique WiFi Channel State Information (CSI) of passing vehicles. Spatial and temporal correlations of preprocessed CSI amplitude and phase data are identified and analyzed using deep learning to classify vehicles into five different types: motorcycle, passenger vehicle, SUV, pickup truck, and large truck. A large amount of CSI data of passing vehicles and the corresponding ground truth video data are collected for about 120 hours to validate the effectiveness of DeepWiTraffic. The results show that the average detection accuracy of 99.4%, and the average classification accuracy of 91.1% (Motorcycle: 97.2%, Passenger Car: 91.1%, SUV:83.8%, Pickup Truck: 83.3%, and Large Truck: 99.7%) are achieved at a very small cost of about $1,000.		Myounggyu Won;Sayan Sahu;Kyung-Joon Park	2018	CoRR			Mobile	-17.45860272437795	-30.10454821575548	135232
2d67b3af3e2afced9e8159d4ce642bb44d22b085	detecting social signals of flu symptoms	social signal detection;influenza-like illness datasets;diseases;flu symptoms;event detection;flu infection prevention;flu forecasting;vaccination;hand washing;flu impact minimization;korea;cold infection prevent;social signals;cold carriers;weather factors;tweet corpus;respiratory illnesses;medical computing;social networking (online);flu epidemic disease detection;flu epidemics;flu carriers;tweets	A cold and the flu are both respiratory illnesses and they are very common to us. Vaccination is the most effective way to prevent infection of the flu, but there is no way for a cold. Thus, the best strategy for individuals is to stay away from the flu or cold carriers and to wash their hands often. Early detection of flu epidemics and a quick response to that can minimize the impact of the flu. We observed tweets as social signals of flu symptoms to detect the flu epidemics in early stage. We compared a tweet corpus from nine cities in Korea to the weather factors, flu forecast, and Influenza-like Illness datasets. The results show the possibility of using social signals to detect epidemic diseases.	sensor	Bum-Suk Lee;Jinyoung Yoon;Seokjung Kim;Byung-Yeon Hwang	2012	8th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom)		simulation	HCI	-8.340059974349522	-27.675572317950266	135457
cb02e32d7d5c36a616ee413c963488b48064c589	connecting mobility, online behavior and urban structure from cellular network data		Due to the accelerating rate of development of Mobile Internet, the role of mobile phone becomes increasingly vital in peopleu0027s life. Through the data generated by mobile phones, usersu0027 mobility characteristic and online interests can be roundly mined. By connecting human mobility and online behavior, many achievements have been proposed and then applied in many services to improve the quality of peopleu0027s life. In this paper, by using the cellular network data collected from certain urban city in northeast China over a month, we first extract usersu0027 important locations. Based on this, we apply the topic model to extract mobility topics of users and explore usersu0027 application usage. We observe that different user mobility properties accompanied with different online behavior tendencies of users. Besides, we extract cross-town events based on usersu0027 important locations to explore the macroscopical organization of the city. The results of our research provide a comprehensive understanding of user behavior in Mobile Internet and city structure, which are valuable for the practitioners in the fields of Location-Based Services (LBS) and urban planning.	cluster analysis;k-means clustering;location-based service;mined;mobile phone;topic model;towns	Bo Wen;Yuanyuan Qiao;Wenhui Lin;Jie Yang	2017	2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)	10.1109/PIMRC.2017.8292739	topic model;computer network;internet privacy;mobile phone;the internet;urban structure;computer science;urban planning;cellular network	Mobile	-19.08925074035534	-35.05177137039384	135501
a1eceed402a2165bab187b8a129bb0a0addacc9c	exploration of collective pattern to improve location prediction of mobile phone users	silicon;spontaneous communication;call detail records;global positioning system;synchronization;mobile handsets;predictive models;location prediction;collective mobility;decision trees;context	Location prediction based on cellular network traces is a very challenging task due to the randomness of the human mobility patterns. With the help of the abundant social interaction data contained in the cellular network, this paper focuson this question: How can knowing the location and the assembled and dismissed behavior of my friends be used to more accurately predict my location? In this paper, we focus on how the collective effect users' mobility. We notice an interesting rule that users tend to stay around the places where their friends are denser. Those places where friends are more crowned is chosen for a reason, either they are having a meeting there or they gathered spontaneously because of sharing office building or other resources. With known locations of friends, we established a location prediction model to make full use of those social information. In this model, we also introduced a measure of the ability of each location that weather a gathering of friends here can attract the user. The result shows that this model did improve location prediction at the average of 4.91%, and max improvement up to about 42.9%. And we summarize the feature and the difference between the kinds of users whose behavior is following his friends a lot from those user who move around more independently.	mobile phone;randomness;tracing (software)	Chen Zhou;Benxiong Huang	2015	2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)	10.1109/SmartCity.2015.47	simulation;engineering;world wide web;computer security	Robotics	-18.99484022976001	-35.21587027017546	135582
6d2c68c9428aca11d5cb7d40b0c98840c6ea3995	sample size analysis of gps probe vehicles for urban traffic state estimation	traffic state estimation;estimation theory;sample size;road traffic;road vehicles curve fitting global positioning system probes road traffic;shanghai china;traffic flow;probes;vehicles probes global positioning system roads state estimation computational modeling;sampling;shanghai sample size analysis gps probe vehicles urban traffic state estimation global position system real time traffic information curve fitting estimation model traffic flow state probe vehicles cfem road network;global positioning system;algorithms;probe vehicles;traffic characteristics;curve fitting;road vehicles	Nowadays, probe vehicles equipped with Global Position System (GPS) are an effective way of collecting real-time traffic information. This paper first briefly introduces the Curve-Fitting Estimation Model (CFEM), which is one of the typical methods using GPS data to estimate the traffic flow state. After that, it is detailedly analyzed how many probe vehicles the CFEM requires in order to ensure enough estimated accuracy. Furthermore, a sample size algorithm is developed to calculate the minimum sample size of the CFEM. In the algorithm, the road type, the length of road section, and sample frequency are taken into account. Finally, the proposed algorithm of sample size analysis are tested by the experiments using the data collected from the road network of the whole center region of Shanghai.	algorithm;curve fitting;experiment;global positioning system;real-time transcription;sampling (signal processing)	Qiankun Zhao;Qing-Jie Kong;Yingjie Xia;Yuncai Liu	2011	2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2011.6082829	simulation;geography;transport engineering;cartography	Robotics	-18.04362010653052	-29.54011168915901	135643
0328f7da346d6b06295f407bb4e23029b2e7b807	incremental transitivity applied to cluster retrieval		Many problems have emerged while building accurate and efficient clusters of documents; such as the inherent problems of the similarity measure, and document logical view modeling. This research is an attempt to minimize the effect of these problems by using a new definition of transitive relevance between documents; i.e., adding more conditions on transitive relevance judgment through incrementing the relevance threshold by a constant value at each level of transitivity. Proving the relevance relation to be transitive, will make it an equivalence relation that can be used to build equivalence classes of relevant documents. The main contribution of this paper is to use this definition to partition a set of documents into disjoint subsets as equivalence classes (clusters). Another contribution is by using the incremental transitive relevance relation; the traditional vector space model can be made incrementally transitive.	computer cluster;incremental backup;noise reduction;refinement (computing);relevance;similarity measure;turing completeness;vertex-transitive graph;viable system model	Yaser Hasan;Muhammah Hassan;Mick J. Ridley	2008	Int. Arab J. Inf. Technol.		stateless protocol;artificial intelligence;machine learning;computer network;computer science;transitive relation;login;authentication;server	Web+IR	-6.920179904863392	-27.05744306719349	136081
c33df7744b14d14e9501d26fcb6dd5cc132ed6ae	a quest for affordable personalized atmospheric exposure estimates				Michael Kobernus;Denis Havlik;Hylke van der Schaaf;Jasmin Pielorz;Markus Falgenhauer	2012			environmental health;environmental science	NLP	-11.38881278371585	-26.890284647373047	136085
845067be5ce40ff2e82257b834c6dff02e2d193c	random sampling for histogram construction: how much is enough?	information retrieval;random sampling;query optimization;data distribution;object relational database systems;adaptive algorithm;user defined functions;aggregates;parallel query processing;error bound	Random sampling is a standard technique for constructing (approximate) histograms for query optimization. However, any real implementation in commercial products requires solving the hard problem of determining “How much sampling is enough?” We address this critical question in the context of equi-height histograms used in many commercial products, including Microsoft SQL Server. We introduce a conservative error metric capturing the intuition that for an approximate histogram to have low error, the error must be small in all regions of the histogram. We then present a result establishing an optimal bound on the amount of sampling required for pre-specified error bounds. We also describe an adaptive page sampling algorithm which achieves greater efficiency by using all values in a sampled page but adjusts the amount of sampling depending on clustering of values in pages. Next, we establish that the problem of estimating the number of distinct values is provably difficult, but propose a new error metric which has a reliable estimator and can still be exploited by query optimizers to influence the choice of execution plans. The algorithm for histogram construction was prototyped on Microsoft SQL Server 7.0 and we present experimental results showing that the adaptive algorithm accurately approximates the true histogram over different data distributions.	adaptive algorithm;approximation algorithm;cluster analysis;mathematical optimization;microsoft sql server;query optimization;sampling (signal processing)	Surajit Chaudhuri;Rajeev Motwani;Vivek R. Narasayya	1998		10.1145/276304.276343	sampling;query optimization;computer science;histogram matching;theoretical computer science;user-defined function;data mining;database	DB	-7.419615806118697	-33.086335636558836	136338
77aeac51977db50d7405d1a8958eb7f3812fae2b	a survey of semantic methods in genetic programming	genotype phenotype;semantics;genetic programming;survey	Several methods to incorporate semantic awareness in genetic programming have been proposed in the last few years. These methods cover fundamental parts of the evolutionary process: from the population initialization, through different ways of modifying or extending the existing genetic operators, to formal methods, until the definition of completely new genetic operators. The objectives are also distinct: from the maintenance of semantic diversity to the study of semantic locality; from the use of semantics for constructing solutions which obey certain constraints to the exploitation of the geometry of the semantic topological space aimed at defining easy-to-search fitness landscapes. All these approaches have shown, in different ways and amounts, that incorporating semantic awareness may help improving the power of genetic programming. This survey analyzes and discusses the state of the art in the field, organizing the existing methods into different categories. It restricts itself to studies where semantics is intended as the set of output values of a program on the training data, a definition that is common to a rather large set of recent contributions. It does not discuss methods for incorporating semantic information into grammar-based genetic programming or approaches based on formal methods. The objective is keeping the community updated on this interesting research track, hoping to motivate new and stimulating contributions.	formal methods;genetic operator;genetic programming;locality of reference;organizing (structure)	Leonardo Vanneschi;Mauro Castelli;Sara Silva	2013	Genetic Programming and Evolvable Machines	10.1007/s10710-013-9210-0	genetic programming;genotype-phenotype distinction;semantic similarity;semantic computing;computer science;artificial intelligence;theoretical computer science;machine learning;genetic representation;data mining;semantics	AI	-6.058585861039775	-28.770884903416846	136532
a8dcb274ccb65160558f7679853029f78478a398	finding spatio-temporal patterns in multidimensional data streams	fractals;multi resolution spatial structure;spatio temporal data	In the last few decades, advances in data acquisition technology have contributed to generation of huge volumes of data in diverse application areas, creating new research challenges in knowledge discovery. The analysis of these data has become an important task in several domains such as sensor networks, web-logs, financial transactions and climate change monitoring. In this article, we propose the Spatio-Temporal Behavior Meter (STB-meter) method to identify spatio-temporal patterns in multidimensional evolving data streams. Our approach combines a multi-resolution hierarchical structure to deal with spatial information with fractal-based analysis to monitor non spatial information of the multidimensional data stream. Experimental evaluation on real climate data shows that our method allows finding relevant spatio-temporal patterns in evolving data at different spatial and temporal resolutions and therefore it can be a useful tool to assist domain specialists in climate change researches.	algorithmic efficiency;application domain;chassis air guide;computation;data acquisition;data mining;data structure;experiment;feature selection;fractal;fractal dimension;jacek m. zurada;john d. wiley;joão pavão martins;multiresolution analysis;next-generation network;petabyte;rare events;set-top box;social network aggregation;synthetic data	Santiago Augusto Nunes;Luciana A. S. Romani;Ana Maria Heuminski de Ávila;Priscila P. Coltri;Agma J. M. Traina;Elaine P. M. de Sousa	2013	JIDM		computer science;data science;data mining;database	ML	-12.988434287130918	-28.146730105284327	136814
7c0de16d23616b9fc8c034048ebc994c9127d8b7	design of a decision support system for classification of natural risk in maritime construction based on temporal windows	data mining;artificial intelligent;support system;temporal windows;inductive learning;artificial intelligence;risk prevention;decision making support;building of maritime works	The objective of this paper is to present an improvement of a decision-making support system based in inductive learning, applied to risk prevention in maritime works. The improvement shown here is based on the redefinition of training examples structured as temporal windows over certain attribute values.	decision support system;microsoft windows	Marco Antonio García Tamargo;Alfredo S. Alguero García;Andrés Alonso Quintanilla;Amelia Bilbao-Terol;Víctor Castro Amigo	2009		10.1007/978-3-642-02481-8_69	computer science;artificial intelligence;machine learning;data mining	ML	-6.173987250014711	-25.800930708245673	136891
4cfc433ffebafcc56fe33cf42fc0af1caa3878c4	constraint-based sequential pattern mining: a pattern growth algorithm incorporating compactness, length and monetary		Sequential pattern mining is advantageous for several applications for example, it finds out the sequential purchasing behavior of majority customers from a large number of customer transactions. However, the existing researches in the field of discovering sequential patterns are based on the concept of frequency and presume that the customer purchasing behavior sequences do not fluctuate with change in time, purchasing cost and other parameters. To acclimate the sequential patterns to these changes, constraint are integrated with the traditional sequential pattern mining approach. It is possible to discover more user-centered patterns by integrating certain constraints with the sequential mining process. Thus in this paper, monetary and compactness constraints in addition to frequency and length are included in the sequential mining process for discovering pertinent sequential patterns from sequential databases. Also, a CFML-PrefixSpan algorithm is proposed by integrating these constraints with the original PrefixSpan algorithm, which allows discovering all CFML sequential patterns from the sequential database. The proposed CFML-PrefixSpan algorithm has been validated on synthetic sequential databases. The experimental results ensure that the efficacy of the sequential pattern mining process is further enhanced in view of the fact that the purchasing cost, time duration and length are integrated with the sequential pattern mining process.	aggregate data;algorithm;data mining;dhrystone;kinetic data structure;mined;purchasing;recursion;relevance;sequence database;sequential pattern mining;user-centered design	Bhawna Mallick;Deepak Garg;P. S. Grover	2014	Int. Arab J. Inf. Technol.		computer science;data mining	ML	-5.875453567691765	-35.972018050638894	137287
478907baa6b675db7729defa015d8394952cef44	authentication of moving top-k spatial keyword queries	outsourcing;query processing authorisation data structures;query processing;authentication;verification object query authentication moving top k spatial keyword query mksk query continuously moving query location mobile client top k spatial web object location relevance text relevance geo positioning spatial keyword search authentication techniques authentication data structure mir tree data structure mir tree data structure;public key;data structures;spatial databases;mobile communication;authentication mobile communication algorithm design and analysis query processing data structures outsourcing public key;article;algorithm design and analysis;spatial keyword search	A moving top-k spatial keyword (MkSK) query, which takes into account a continuously moving query location, enables a mobile client to be continuously aware of the top-k spatial web objects that best match a query with respect to location and text relevance. The increasing mobile use of the web and the proliferation of geo-positioning render it of interest to consider a scenario where spatial keyword search is outsourced to a separate service provider capable at handling the voluminous spatial web objects available from various sources. A key challenge is that the service provider may return inaccurate or incorrect query results (intentionally or not), e.g., due to cost considerations or invasion of hackers. Therefore, it is attractive to be able to authenticate the query results at the client side. Existing authentication techniques are either inefficient or inapplicable for the kind of query we consider. We propose new authentication data structures, the MIR-tree and MIR*-tree, that enable the authentication of MkSK queries at low computation and communication costs. We design a verification object for authenticating MkSK queries, and we provide algorithms for constructing verification objects and using these for verifying query results. A thorough experimental study on real data shows that the proposed techniques are capable of outperforming two baseline algorithms by orders of magnitude.	authentication;baseline (configuration management);client-side;computation;data structure;experiment;outsourcing;relevance;search algorithm;spatial anti-aliasing;verification and validation	Dingming Wu;Byron Choi;Jianliang Xu;Christian S. Jensen	2015	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2014.2350252	algorithm design;sargable;query optimization;query expansion;web query classification;mobile telephony;data structure;computer science;data mining;authentication;database;rdf query language;public-key cryptography;web search query;world wide web;query language;outsourcing;spatial query	DB	-15.020653475960142	-36.889037920823675	137407
3c8c19abf1746ddb35df4aa621dde486147b7ab1	power in silence: revealing the stationarity of private-owned vehicle in urban vehicular ad hoc networks	vanets;private owned vehicle;luv;realistic trace date;stability model	The essential features of vehicle are the foundation of vehicular ad-hoc networks (VANETs). However, behavior of private-owned vehicles, which occupy a majority in a city's transportation system, remains uncertain due to the lack of real life traces of private-owned vehicles. In this paper, the trace data of 8,900 private cars in 3 months in Changsha, China, is studied to reveal the internal features of private-owned vehicle in a city environment and provide a deeper insight into urban VANETS. To achieve this goal, we introduce a model and a range of metrics to evaluate the behavior of private-owned vehicle. The empirical results suggest that the traditional presupposition, which assumes that vehicles are constantly in motion, turns out to be incorrect for private-owned vehicles. Moreover, the results indicate that in a realistic urban scenario, the demands of VANETs for steady connections between vehicles would always be satisfied in places by private-owned parking vehicles. The outcomes thus provide fundamental guidelines and relevant parameters on design of a reliable and scalable VANET based on location in urban scenarios.	hoc (programming language);real life;scalability;stationary process;tracing (software)	Heng Li;Yonghe Liu;Siwang Zhou	2016		10.1145/2989275.2989290	simulation;geography;transport engineering;computer security	Robotics	-17.730268885679234	-28.27602347764655	137454
708241fc983aec7d08c87b1371cd8f4c5e3e9d7e	safety benefits of forward collision warning, brake assist, and autonomous braking systems in rear-end collisions	rear end crashes;road vehicles automated highways belts brakes probability road accidents road safety;crash imminent braking;probability;road accidents;safety systems crash imminent braking intelligent transportation systems itss precollision system pcs rear end collisions;automated highways;safety systems;precollision system pcs;crash avoidance systems;belts;collision avoidance systems;rear end collisions;braking;intelligent transportation systems itss;brakes;vehicle crash testing;warning systems;vehicle safety vehicle crash testing algorithm design and analysis collision avoidance;collision avoidance;vehicle safety;methodology;road safety;active safety systems;highway crash innovative safety benefits methodology forward collision warning precrash brake assist autonomous braking systems rear end collisions precollision system algorithm pcs algorithm autonomous precrash brake rear end crash united states precollision system equipped vehicle probability based framework variable driver reaction seat belts collision mitigating algorithms intelligent vehicle technologies highway safety active safety technologies;algorithm design and analysis;road vehicles	This paper examines the potential effectiveness of the following three precollision system (PCS) algorithms: 1) forward collision warning only; 2) forward collision warning and precrash brake assist; and 3) forward collision warning, precrash brake assist, and autonomous precrash brake. Real-world rear-end crashes were extracted from a nationally representative sample of collisions in the United States. A sample of 1396 collisions, corresponding to 1.1 million crashes, were computationally simulated as if they occurred, with the driver operating a precollision-system-equipped vehicle. A probability-based framework was developed to account for the variable driver reaction to the warning system. As more components were added to the algorithms, greater benefits were realized. The results indicate that the exemplar PCS investigated in this paper could reduce the severity (i.e., ΔV) of the collision between 14% and 34%. The number of moderately to fatally injured drivers who wore their seat belts could have been reduced by 29% to 50%. These collision-mitigating algorithms could have prevented 3.2% to 7.7% of rear-end collisions. This paper shows the dramatic reductions in serious and fatal injuries that a PCS, which is one of the first intelligent vehicle technologies to be deployed in production cars, can bring to highway safety when available throughout the fleet. This paper also presents the framework of an innovative safety benefits methodology that, when adapted to other emerging active safety technologies, can be employed to estimate potential reductions in the frequency and severity of highway crashes.	algorithm;autonomous robot;crash (computing)	Kristofer D. Kusano;Hampton C. Gabler	2012	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2012.2191542	simulation;engineering;automotive engineering;computer security;statistics;brake	Robotics	-18.961385335483445	-27.12603158532866	137480
44c6c6ea038ee8fcc3faf83f622633428c76b9a3	summarizing probabilistic frequent patterns: a fast approach	pattern summarization;uncertain data;conference proceeding	Mining probabilistic frequent patterns from uncertain data has received a great deal of attention in recent years due to the wide applications. However, probabilistic frequent pattern mining suffers from the problem that an exponential number of result patterns are generated, which seriously hinders further evaluation and analysis. In this paper, we focus on the problem of mining probabilistic representative frequent patterns (P-RFP), which is the minimal set of patterns with adequately high probability to represent all frequent patterns. Observing the bottleneck in checking whether a pattern can probabilistically represent another, which involves the computation of a joint probability of the supports of two patterns, we introduce a novel approximation of the joint probability with both theoretical and empirical proofs. Based on the approximation, we propose an Approximate P-RFP Mining (APM) algorithm, which effectively and efficiently compresses the set of probabilistic frequent patterns. To our knowledge, this is the first attempt to analyze the relationship between two probabilistic frequent patterns through an approximate approach. Our experiments on both synthetic and real-world datasets demonstrate that the APM algorithm accelerates P-RFP mining dramatically, orders of magnitudes faster than an exact solution. Moreover, the error rate of APM is guaranteed to be very small when the database contains hundreds transactions, which further affirms APM is a practical solution for summarizing probabilistic frequent patterns.	advanced power management;approximation algorithm;computation;data mining;experiment;request for proposal;synthetic intelligence;time complexity;uncertain data	Chunyang Liu;Ling Chen;Chengqi Zhang	2013		10.1145/2487575.2487618	computer science;data science;machine learning;data mining;statistics	ML	-8.789028014025169	-35.58047070020468	137604
23c73c4600ee6b1b026408a182e0f0f5f0c3d807	application of xgboost algorithm in fingerprinting localisation task		An Indoor Positioning System (IPS) issues regression and classification challenges in form of an horizontal localisation and a floor detection. We propose to apply the XGBoost algorithm for both tasks. The algorithm uses vectors of Received Signal Strengths from Wi–Fi access points to map the obtained fingerprints into horizontal coordinates and a current floor number. The original application schema for the algorithm to create IPS was proposed. The algorithm was tested using real data from an academic building. The testing data were split into two datasets. The first data set contains signals from all observed access points. The second dataset consist of signals from the academic network infrastructure. The second dataset was created to eliminate temporary hotspots and to improve a stability of the positioning system. The tested algorithm got similar results as reference methods on the wider set of access points. On the limited set the algorithm obtained the best results.	algorithm;fingerprint (computing);xgboost	Marcin Luckner;Bartosz Topolski;Magdalena Mazurek	2017		10.1007/978-3-319-59105-6_57	positioning system;original application;artificial intelligence;computer science;indoor positioning system;regression;schema (psychology);test data;algorithm;pattern recognition	NLP	-13.433518301528105	-34.997594934267674	137672
a8d5775282d5e1fdc579288b38cc27074c6b77c8	durable queries over historical time series	spatiotemporal databases;information technology and systems;query processing;database management systems;durable query;data engineering;time series;indexing methods;nn queries historical time series database durable top k queries dtop k queries nearest neighbor queries dknn queries snapshot top k queries scalable algorithms query evaluation techniques indexing techniques timestamped sequences;spatiotemporal databases durable query time series historical data;time series database management systems indexing query processing;information storage;trajectory;time series analysis;indexing;search problems;article;information storage and retrieval;information search and retrieval;content analysis and indexing;historical data;time series analysis indexing trajectory knowledge discovery data engineering search problems;knowledge discovery	This paper studies the problem of finding objects with durable quality over time in historical time series databases. For example, a sociologist may be interested in the top 10 web search terms during the period of some historical events; the police may seek for vehicles that move close to a suspect 70 percent of the time during a certain time period and so on. Durable top-k (DTop-k) and nearest neighbor (DkNN) queries can be viewed as natural extensions of the standard snapshot top-k and NN queries to timestamped sequences of values or locations. Although their snapshot counterparts have been studied extensively, to our knowledge, there is little prior work that addresses this new class of durable queries. Existing methods for DTop-k processing either apply trivial solutions, or rely on domain-specific properties. Motivated by this, we propose efficient and scalable algorithms for the DTop-k and DkNN queries, based on novel indexing and query evaluation techniques. Our experiments show that the proposed algorithms outperform previous and baseline solutions by a wide margin.	baseline (configuration management);database;experiment;k-nearest neighbors algorithm;scalability;snapshot (computer storage);synthetic data;time series;trusted timestamping;web search engine;weight function	Hao Wang;Yilun Cai;Yin David Yang;Shiming Zhang;Nikos Mamoulis	2014	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2013.10	information engineering;computer science;time series;data mining;database;knowledge extraction;information retrieval;statistics	DB	-7.85243685669418	-34.6356461465291	137809
870bcfa64b5f2e6758151ed61291d1c110ed489a	visualization and classification of power system frequency data streams	global situational awareness;mining;data stream;real time;performance;interactive visualization;power systems;datasets;power transmission and distribution;datasets power system frequency data streams smart grid technology global situational awareness spatially distributed high speed power system frequency measurements decision making process k median approach interactive visualization model;velocity smart grid;frequency measurement;time series;detection;power system measurement;data mining;classification;visualization;monitoring;spatial distribution;spatially distributed high speed power system frequency measurements;power system;decision making process;data visualization;k median approach;situation awareness;interactive visualization model;smart grid technology;power system analysis computing;evaluation;experimental evaluation;power system frequency data streams;rendering computer graphics;high speed sensor data;data visualization power systems power system measurements power system modeling frequency measurement smart grids event detection displays decision making performance analysis;time frequency analysis;high speed;data streaming;power system measurement decision making frequency measurement power system analysis computing	Two challenges in the realization of the smart grid technology are the ability to visualize the deluge of expected data streams for global situational awareness; as well as the ability to detect disruptive and classify such events from spatially-distributed high-speed power system frequency measurements. This paper presents an interactive visualization model for high speed power system frequency data streams that displays both local and global views of the data streams for decision making process. It also presents a K-Median approach for clustering and identifying disruptive events in spatially distributed data streams. The results from experimental evaluation on a variety of datasets show that K-Median achieve better performance and empowers analysts with the ability to make sense of a deluge of frequency measurements in a real-time situation.	anomaly detection;cluster analysis;google earth;interactive visualization;k-medians clustering;median filter;real-time transcription;rendering (computer graphics);sensor	Jason N. Bank;Olufemi A. Omitaomu;Steven J. Fernandez;Yong Liu	2009	2009 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2009.104	real-time computing;interactive visualization;computer science;data science;data mining;electric power system;data visualization;statistics	DB	-14.025839462849186	-30.086934623492066	137976
c759ac73ea4238fafc66a1e0c0970361d49715da	predicting time-sensitive user locations from social media	quality of experience;data analysis;social networking online;location based data analytics time sensitive user location prediction social media microblogging services location based recommendation advertising services sparse user profile information geo coordinate information location detection techniques content based machine learning techniques user location categorization;logic gates media cities and towns;multimedia content production and delivery;learning artificial intelligence;mobile computing;social media;recommender systems;social networking online advertising data analysis learning artificial intelligence mobile computing recommender systems;advertising	Access to massive real-time user generated personal information from micro blogging services, such as Twitter and Facebook, has the potential to enable new location-based recommendation and advertising services. However, sparse user profile information and low adoption of per-message geo-coordinate information necessitates development of location detection techniques that exposes a user's location from message content. We propose and evaluate content-based machine learning techniques to a) identify tweets containing a user's location, and, b) categorize a user location into the author's present or future location. Such an approach is advantageous because it a) relies purely on message content, b) can be used to predict a user's future presence at a location, c) relates user locations to some context (activities, trip plans, etc.), and, d) can be used to profile users constantly evolving location. Our experimental evaluation shows that the proposed techniques can identify and categorize user locations from message content with high accuracy. We also extract the time entities associated with a user's future location to show when the user would be at that location. Finally we illustrate the location-based data analytics potential of these techniques on two real-world datasets.	blog;categorization;compiler;context-aware pervasive systems;emoticon;entity;location awareness;machine learning;personally identifiable information;privacy;randomness extractor;real-time locating system;social media;sparse matrix;user profile	Anuj Jaiswal;Wei Peng;Tong Sun	2013	2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)	10.1145/2492517.2500229	social media;computer science;data mining;multimedia;internet privacy;data analysis;mobile computing;world wide web	HCI	-18.305789313745397	-36.30156372322556	137988
a9e35644d72ad9c8b48ce8ada559d0bd8460b7b2	rough qualitative spatial reasoning based on rough topology	topology;relational data;spatial reasoning;rough set theory;qualitative spatial reasoning;incomplete data;gis;qualitative reasoning;rough set;land cover	In order to derive information based on captured data, some analysis methods are implemented. These methods reduce our need to have all the related data. One of the most important devices to extract information from incomplete data is the reasoning method. Spatial reasoning is one of fields of reasoning whose implementation relies on spatial objects. An ordinary method of qualitative reasoning suffers from not considering fuzziness and vagueness. In order to extract qualitative information from uncertain spatial objects, this paper proposes a new method based on rough set theory. Based on rough topological relationships, reasoning rules were developed. Application of paper is to do with land cover areas as rough objects.	rough set;spatial–temporal reasoning	Anahid Bassiri;Mohammad Reza Malek;Ali A. Alesheikh	2009		10.1007/978-3-642-02454-2_34	geomatics;rough set;qualitative reasoning;computer science;artificial intelligence;machine learning;data mining;mathematics;reasoning system;dominance-based rough set approach	AI	-4.842509911597536	-26.236815881552015	138075
aeb631582659ef80e3a0ac74ea4e305ab2085816	a tree-based contrast set-mining approach to detecting group differences	contrast set mining;group difference detection;data mining	U differences between groups in a data set is one of the fundamental tasks in data analysis. As relevant applications accumulate, data-mining methods have been developed to specifically address the problem of group difference detection. Contrast set mining discovers group differences in the form of conjunction of feature-value pairs or items. In this paper, we incorporate absolute difference, relative difference, and statistical significance in our definition of a group difference, and develop a novel method named DIFF that uses the prefix-tree structure to compress the search space, follows a tree traversal procedure to discover the complete set of significant group differences, and employs efficient pruning strategies to expedite the search process. We conducted comprehensive experiments to compare our method with existing methods on completeness of results, pruning efficiency, and computational efficiency. The experiments demonstrate that our method guarantees completeness of results and achieves higher pruning efficiency and computational efficiency compared to STUCCO. In addition, our definition of group difference is more general than STUCCO. Our method is more effective than traditional approaches, such as classification trees, in discovering the complete set of significant group differences.	computation;data mining;decision tree;diff utility;discretization;experiment;koutetsu no kishi;material design;maxima and minima;naivety;offline reader;online and offline;random forest;relative change and difference;rough set;sensor;tree structure;tree traversal	Hongyan Liu;Yinghui Yang;Zhuohua Chen;Yong Zheng	2014	INFORMS Journal on Computing	10.1287/ijoc.2013.0558	computer science;theoretical computer science;data mining;mathematics;algorithm	ML	-6.067902759967171	-35.8486342731827	138157
f581f86d8667c16fb9083f8f091af1ac26269bcf	linguistic aggregation functions using the mapreduce paradigm	fuzzy logic;big data;computing with perceptions	We explore the possible benefit that provides a linguistic approach to Big Data. The proposal illustrates how implement Linguistic Aggregation Functions using the MapReduce paradigm. The best known paradigm applied to Big Data. The proposal allows several benefits to Big Data e.g., it allows to interpret data in a more intuitive way, reduce data size into different levels of granularity, and manage the imprecision and incompleteness of data. We show the usefulness of the proposed approach with an illustrative example.	aggregate function;big data;distributed computing;fold (higher-order function);map (higher-order function);mapreduce;programming paradigm	Patricia Conde Clemente;Gracián Triviño;José M. Alonso	2015		10.2991/ifsa-eusflat-15.2015.98	computer science;data science;data mining;database	ML	-4.845141655457793	-24.847098683613225	138530
2fa6b4f2bba2706bbf7158ff7da9a2c8d45a625a	design patterns in the computer simulation studies of pumped storage systems on river nile	storage system;computer simulation;design pattern		computer simulation	Parabrahma Chary Samanthapudi;Solomon Tesfamariam Teferi;Ravinder Chindam	2010			systems engineering;software design pattern;design pattern;hydrology;engineering;computer data storage	Arch	-11.449034278143687	-26.667108095044945	138564
b82b247c94f509309850f2d72cc1a9f80c8550b2	peer-to-peer data quality improvement in the daquincis system	p2p system;query processing;quality improvement;cooperative information system;data quality;peer to peer;quality of data;quantitative evaluation	Data quality improvement is becoming an increasingly important issue. In contexts where data are replicated among different sources, data quality improvement is possible through extensive data comparisons: whereas copies of same data are different because of data errors, comparisons help to reconcile such copies. Record matching algorithms can support the task of linking different copies of the same data in order to engage reconciliation activities; for instance, a periodical running of record matching algorithms can be performed in order to reconcile copies with different quality. Nevertheless, the extensive running of such algorithms is typically performed in fixed instants. This allows for periods in which the quality of data can deteriorate, while no quality improvement action is performed on data. In this paper, we describe the DaQuinCIS (DataQuality in CooperativeInformationSystems) approach for data quality improvement in contexts where data are replicated among heterogeneous and distributed sources. The DaQuinCIS strategy complements a periodical record matching activity with an “on-line” quality improvement, performed at query processing time. We experimentally show the feasibility and effectiveness of our approach by applying it to real databases; we also quantitatively evaluate the efficiency of our system.	algorithm;data quality;database;experiment;online and offline;peer-to-peer	Diego Milano;Monica Scannapieco;Tiziana Catarci	2005	JDIM		quality management;data quality;computer science;data mining;database;information quality;world wide web;information retrieval	DB	-9.041186960093073	-36.37162392960543	138752
0088d33f3e250f651659df1138007d0820984b53	modeling urban road risky driving behaviors in china with multi-agent microscopic traffic simulation	traffic simulation;driving;risk management;multi agent systems;microscopic traffic flow;behavior;china	Typical driving behaviors such as car-following and lane-changing can be described based on common concepts. But these behaviors could be different from driver to driver, from nation to nation due to different individual influencing factors (e.g. age, gender, driving age, mood) and situational influencing factors (e.g. weather, congestion, respect for law). Studies show that drivers who have higher level of “driving discourtesy” (i.e rudeness and aggressiveness) have higher probability of performing risky driving behaviors including traffic rule violations. In this paper, we propose a model named Driving Discourtesy Model (DDM). In this model, a new indicator is defined to measure the “driving discourtesy”. With a probability distribution method, we are able to estimate the probability of performing risky driving behaviors of each vehicle based on a vehicle's individual influencing factors and situational factors. A multi-agent traffic simulation is developed to test DDM. The experiment results show that risky driving behaviors including speeding, lane-changing for taking speed advantages and driving on hard shoulder can be simulated effectively using DDM.	multi-agent system;network congestion;simulation	Xia Li;Ruibin Bai;Peer-Olaf Siebers;Christian Wagner	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6957944	simulation;engineering;forensic engineering;computer security	Robotics	-18.28991430110099	-23.975285104928847	138817
d9f30182e51ad2af9fa7085ed0c1cda5a83f5273	city users' classification with mobile phone data	spatio temporal profile city users classification mobile phone data social life urban dynamics sociometer call habits;electronic mail;big data;mobile handsets;cities and towns;robustness;iterative closest point algorithm;cities and towns mobile handsets labeling iterative closest point algorithm robustness big data electronic mail;semi automatic methods mobile phone data individual profiles classification;labeling;social sciences computing data mining mobile computing	Nowadays mobile phone data are an actual proxy for studying the users' social life and urban dynamics. In this paper we present the Sociometer, and analytical framework aimed at classifying mobile phone users into behavioral categories by means of their call habits. The analytical process starts from spatio-temporal profiles, learns the different behaviors, and returns annotated profiles. After the description of the methodology and its evaluation, we present an application of the Sociometer for studying city users of one small and one big city, evaluating the impact of big events in these cities.	data mining;mobile phone;semiconductor industry	Lorenzo Gabrielli;Barbara Furletti;Roberto Trasarti;Fosca Giannotti;Dino Pedreschi	2015	2015 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2015.7363852	mobile search;geography;data mining;internet privacy;world wide web	Robotics	-18.590599442882382	-35.104940983786406	139480
e3ae51feb846466370562793395c6f02e6838562	investigating potentials of artificial ants when exposed to new solid waste collection constraints	solid waste		artificial ants	Oomesh Gukhool;Chandradeo Bokhoree	2010			waste management;artificial ants;environmental science;environmental engineering;municipal solid waste	ML	-11.365630384355855	-26.979684145956977	139983
c958b1888e379beaf651a8d01072370d798741b0	modeling human genetic radiation risks around nuclear facilities in germany and five neighboring countries: a sex ratio study	shifted gaussian function;rayleigh function;radiation induced genetic effects;variogram analysis;sex odds;big data;nuclear facilities;environmental health risk modeling;change point	Ionizing radiation causes genetic mutations, and nuclear facilities, research reactors, and power reactors discharge radionuclides and neutrons. On the basis of exhaustive municipality data, we considered the human birth sex ratio in 78 million births in Austria, France, Germany, Luxembourg, Switzerland, and The Netherlands (1957e2013). We present a novel environmental health modeling concept expressing the spatiotemporal association of the sex ratio with minimum distance from operating or decommissioned nuclear facilities. Spatial correlation of the sex ratio is assessed by directional and omnidirectional semivariogram analyses. We detected elevated human sex ratios near nuclear facilities, whether we analyzed comprehensive groups of nuclear installations, or looked at individual facilities in a descriptive and exploratory manner. The sex ratio increases are typically between a few per mill and a few percent, and they occur in regions of up to 40 km around the nuclear installations. Intensifying research in the field of radiation induced genetic effects is recommended. © 2015 Elsevier Ltd. All rights reserved.	discharger;omnidirectional treadmill;switzerland	Hagen Scherb;Ralf Kusmierz;Magdalena Sigler;Kristina Voigt	2016	Environmental Modelling and Software	10.1016/j.envsoft.2015.10.019	big data;environmental engineering;computer science;forensic engineering;ecology	HCI	-11.441901894017914	-24.95197931878558	140027
0e52a83a7fe5d588e4c9691c94cd5e6649c5e7b9	digital design and implementation of soybean growth process based on l-system	dynamical processes;plant morphology;plant growth;digital design;soybean;logistic equation;growth process;growth model	Aiming at the Present Condition of Research on soybean growth model, in order to recur the overall dynamic process of soybean growth, we parameterized the main factors that can affect the plants’ physical development and built the soybean plant growth model by adopting the classical biologic plant growth logistic equation and the Self-similarity of plant morphology. In VC6.0 environment, we applied OpenGL technology and L-system to simulate the soybean plant type topological structure and the plant leaves in computer to simulate the whole process of soybean plant type growth more factually which creates advantaged conditions to research on high yield soybean plant shape.	l-system;mathematical morphology;opengl;population dynamics;self-similarity;simulation	Hongmin Sun;Leqiang Ai;Xinzhong Tang	2007		10.1007/978-0-387-77253-0_7	simulation;engineering;process engineering;agronomy	Graphics	-14.088835551321814	-25.785195296871485	140413
73f8bd5be3937b11ec133c72fec02edb898bd357	to stay or to leave: churn prediction for urban migrants in the initial period		In China, 2.6 billion people migrate to cities to realize their urban dreams every year. Despite the fact that these migrants play an important role in the rapid urbanization process, many of them fail to settle down and eventually leave the city. The integration process of migrants is thus an important issue both for scholars and policymakers. In this paper, we use Shanghai as an example to investigate migrants’ behavior in their first weeks and in particular, how their behavior relates to early departure. We employ a one-month complete dataset of telecommunication metadata in Shanghai with 54 million users and 698 million call logs, plus a novel housing price dataset for 20K real estates in Shanghai. This dataset allows us to identify new migrants to Shanghai because it is uncommon for a temporary visitor to apply for a local number in China. We find that migrants who end up leaving early tend to neither develop diverse connections in their first weeks nor move around the city. Their active areas also have higher housing prices than that of staying migrants. We formulate classification tasks to predict whether a migrant is going to leave based on her behavior in the first few days. The prediction performance improves as we include data from more days. Interestingly, when using the same features, the classifier trained from only the first few days is already as good as the classifier trained using full data, suggesting that the performance difference mainly lies in the difference between features.	dreams	Yang Yang;Zongtao Liu;Chenhao Tan;Fei Wu;Yueting Zhuang;Yafeng Li	2018		10.1145/3178876.3186144	data mining;computer science;visitor pattern;china;metadata;classifier (linguistics);commerce;urbanization	Web+IR	-9.48939614165432	-30.99685555976346	140580
1bc24f2a59dd3f9198be8c5e8c8ed006c571177c	from pressure to path: barometer-based vehicle tracking	algorithms;experimentation;security;pressure	Pervasive mobile devices have enabled countless context- and location-based applications that facilitate navigation, life-logging, and more. As we build the next generation of smart cities, it is important to leverage the rich sensing modalities that these numerous devices have to offer. This work demonstrates how mobile devices can be used to accurately track driving patterns based solely on pressure data collected from the device's barometer. Specifically, by correlating pressure time-series data against topographic elevation data and road maps for a given region, a centralized computer can estimate the likely paths through which individual users have driven, providing an exceptionally low-power method for measuring driving patterns of a given individual or for analyzing group behavior across multiple users. This work also brings to bear a more nefarious side effect of pressure-based path estimation: a mobile application can, without consent and without notifying the user, use pressure data to accurately detect an individual's driving behavior, compromising both user privacy and security. We further analyze the ability to predict driving trajectories in terms of the variance in barometer pressure and geographical elevation, demonstrating cases in which more than 80% of paths can be accurately predicted.	centralized computing;eighty;lifelog;low-power broadcasting;map;mobile app;mobile device;multi-user;next-generation network;power iteration;sample variance;smart city;time series;topography;vehicle tracking system	Bo-Jhang Ho;Paul D. Martin;Prashanth Swaminathan;Mani B. Srivastava	2015	BuildSys'15 : proceedings of the 2nd ACM International Conference on Embedded Systems for Energy-Efficient Buildings : November 4-5, 2015, Seoul, South Korea. ACM Conference on Embedded Systems for Energy-Efficient Buildings (2nd : 2015...	10.1145/2821650.2821665	simulation;engineering;world wide web;computer security	Mobile	-18.237360439205126	-34.42809239674271	140618
94d94ac23d94f007f1f2c6ee225c115ea72e04fd	efficient similar region search with deep metric learning		With the proliferation of mobile devices and location-based services, rich geo-tagged data is becoming prevalent and this offer great opportunities to understand different geographical regions (e.g., shopping areas). However, the huge number of regions with complicated spatial information are expensive for people to explore and understand. To solve this issue, we study the problem of searching similar regions given a user specified query region. The problem is challenging in both similarity definition and search efficiency. To tackle the two challenges, we propose a novel solution equipped by (1) a deep learning approach to learning the similarity that considers both object attributes and the relative locations between objects; and (2) an efficient branch and bound search algorithm for finding top-N similar regions. Moreover, we propose an approximation method to further improve the efficiency by slightly sacrificing the accuracy. Our experiments on three real world datasets demonstrate that our solution improves both the accuracy and search efficiency by a significant margin compared with the state-of-the-art methods.	approximation;baseline (configuration management);branch and bound;deep learning;experiment;image noise;location-based service;moe;mobile device;newton's method;rose;search algorithm;search problem	Yiding Liu;Kaiqi Zhao;Gao Cong	2018		10.1145/3219819.3220031	computer science;machine learning;deep learning;spatial analysis;branch and bound;search algorithm;mobile device;artificial intelligence;nearest neighbor search	ML	-14.539688884650776	-36.88210633813138	140833
82609597f970dc21557610603616e5f7b002047f	bayesian networks for supporting query processing over incomplete autonomous databases	data cleaning;query rewriting;autonomous database;bayesian networks	As the information available to naïve users through autonomous data sources continues to increase, mediators become important to ensure that the wealth of information available is tapped effectively. A key challenge that these information mediators need to handle is the varying levels of incompleteness in the underlying databases in terms of missing attribute values. Existing approaches such as QPIAD aim to mine and use Approximate Functional Dependencies (AFDs) to predict and retrieve relevant incomplete tuples. These approaches make independence assumptions about missing values—which critically hobbles their performance when there are tuples containing missing values for multiple correlated attributes. In this paper, we present a principled probabilistic alternative that views an incomplete tuple as defining a distribution over the complete tuples that it stands for. We learn this distribution in terms of Bayesian networks. Our approach involves mining/“learning” Bayesian networks from a sample of the database, and using it to do both imputation (predict a missing value) and query rewriting (retrieve relevant results with incompleteness on the query-constrained attributes, when the data sources are autonomous). We present empirical studies to demonstrate that (i) at higher levels of incompleteness, when multiple attribute values are missing, Bayesian networks do provide a significantly higher classification accuracy and (ii) the relevant possible answers retrieved by the queries reformulated using Bayesian networks provide higher precision and recall than AFDs while keeping query processing costs manageable.	active format description;autonomous robot;bayesian network;central processing unit;commitment ordering;database;functional dependency;generative model;geo-imputation;missing data;naivety;precision and recall;rewriting;test data;throughput	Rohit Raghunathan;Sushovan De;Subbarao Kambhampati	2013	Journal of Intelligent Information Systems	10.1007/s10844-013-0277-0	computer science;machine learning;bayesian network;data mining;database	DB	-7.964820253883579	-32.20983509729911	141088
390b80847b3b6b09c9eb9d6cb62ac27a53cad112	detection and analysis algorithms of punctual road events from vehicular data in the search for the optimal route an overview of the amnam platform		Beaconing in vehicular networks (VANETs) is a greatly developed research field able to support safety applications like warning the drivers of potential dangers. Nevertheless, service messages, that uses different channels than beaconing, are also a core part to improve worldwide driving conditions and to minimizing traffic. This paper provides data analysis tools and algorithms for the detection and the analysis of road events. In particular, we develop a Java platform called “AMNAM” [1]. Its purpose is transposing and obfuscating raw simulation data into realistic information to, ultimately, detect the real world position of these events e.g., potholes, roadblocks, etc. Additionally, AMNAM computes the optimal route according to the detected events. Through extensive simulations, we demonstrate the efficiency of our proposed algorithms for the detection of punctual events. We also propose a new heuristic called “DirectionnalWeight” (DW) which adds a supplementary weight to the edges guiding the search towards the destination. Moreover, AMNAM’s modified A* algorithm enforced by DW outperforms classic pathfinding algorithms found in the literature in terms of required iterations for its completion.	a* search algorithm;computation;dreamwidth;heuristic;iteration;java;pathfinding;raw image format;real-time computing;simulation	Jihene Rezgui;Pascal Dally-Belanger;Philippe Rivest	2018	2018 14th International Wireless Communications & Mobile Computing Conference (IWCMC)	10.1109/IWCMC.2018.8450535	vehicular ad hoc network;data modeling;cluster analysis;heuristic;algorithm;distributed computing;communication channel;java;pathfinding;computer science	Mobile	-15.275087573063562	-34.774306665156004	141111
e656447e2af78d70d75bbbb80cf062341e070f77	intelligent agricultural forecasting system based on wireless sensor	agricultural application;wsn;sensor data stream;intelligent diagnosis;fuzzy inference	In order to provide more precise decision-makings for agricultural producers, an intelligent forecasting system is proposed for agricultural applications in this paper, which processes data stream collected from agricultural environment applying WSN (Wireless Sensor Network) technology. Sensor data stream is different from other traditional stream, the former is characterized by real-time, sequential, missing and imprecise. In the proposed system, the sliding window is used to model the sensor data stream, some fuzzy rules are constructed based on expert knowledge, and the fuzzy inference is used to collect different environmental parameter data stream to provide intelligent services for guiding irrigation control, disease prevention or other applications. The proposed forecasting system takes the sensor data stream as research objects and provides quantitative prediction services instead of vague judgments, which is the most useful for agricultural manager.	fuzzy logic;fuzzy rule;real-time clock;real-time computing;sensor;vagueness	Liang Zhao;Liyuan He;Wong Harry;Xing Jin	2013	JNW	10.4304/jnw.8.8.1817-1824	real-time computing;machine learning;data mining;data stream mining	Robotics	-8.394407425411533	-25.291402786719928	142046
6f811b641dfe6d5bdbd7a85cc2825394c0ee2b09	characterization of driving behaviors based on field observation of intersection left-turn across-path scenarios	esquiva colision;technologie communication;driving;dato observacion;road traffic driver information systems road safety;intersections;pedestrian safety;difference operator;poison control;behavioral analysis;securite;conduccion vehiculo;driving behaviors;intersection crashes;injury prevention;road traffic;safety systems;conduite vehicule;safety literature;field observation;vehicle driving;riesgo accidente;traffic safety;injury control;risque accidentel;home safety;collision avoidance systems;injury research;safety abstracts;research and development;human factors;intersection crashes collision avoidance driving behaviors field observation;analyse comportementale;collision avoidance driving behaviors intersection left turn across path scenarios intersection safety solutions road traffic;occupational safety;decision support systems;safety;systeme securite;safety research;accident prevention;analisis conductual;violence prevention;collision avoidance;bicycle safety;donnee observation;communication technology;behavior;esquive collision;road safety;poisoning prevention;seguridad;falls;driver information systems;ergonomics;hazard;observation data;suicide prevention;tecnologia comunicacion;intrusion detection vehicle safety vehicle crash testing intelligent sensors road accidents road safety vehicles signal processing vehicle driving sensor phenomena and characterization;left turns	There have been significant research and developments in recent years for intersection-safety solutions that are intended to alert drivers of hazardous situations by utilizing sensing, computing, and communication technologies. Since the effectiveness of intersection-safety systems depends strongly on driver perception and acceptance of the provided warning signal, the understanding of driver actions under the targeted scenario is a central research topic. One significant safety concern at intersections is the left-turn crossing-path scenarios, where a left-turning vehicle is confronted by oncoming traffic. This paper describes the analysis and synthesis of real-world data for such scenarios observed in field observations. Specifically, traffic interactions in left-turn across-path situations are evaluated to compare data from various intersections with different operation and traffic attributes. The analyzed data were characterized to gain insight into a time gap acceptance exhibited by a population of drivers. The knowledge of driving behaviors can provide the guidelines for future investigation as well as a knowledge basis for the selection of warning criteria to allow timely alerts to drivers in the intended safety applications	baseline (configuration management);countermeasure (computer);device driver;futures studies;hoc (programming language);interaction;linkage (software)	Ching-Yao Chan	2006	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2006.880638	simulation;hazard;computer science;engineering;suicide prevention;human factors and ergonomics;injury prevention;transport engineering;computer security;behavior	Visualization	-19.009920104459066	-26.564834329955005	142082
52f55debe53c59f306ca14ee7ddd838967054d50	bayesian multi-sensor data fusion for target identification - applications in naval and ground based command and control systems		Military Command and Control Systems have to deal with a wide range of different sensors and sources. Besides traditional information sources like IFF, Tactical Data Links and ESM sensors additional sources like AIS, Blue Force Tracking and GMTI Radar become important sources for target identification and classification. A correct identification is an important prerequisite to prevent fratricide and civilian collateral damages and to complete the Situational Awareness. This paper gives an overview of our solution for the extension of the Bayesian identification process in order to establish a tactical picture for naval but also for air and ground targets. For some sensors and important identification source like Automatic Identification System (AIS), Automatic Target Recognition (ATR) and GMTI Radar our solution approach will be	algorithm;automatic identification and data capture;automatic target recognition;control system;daylight;management system;moving target indication;sensor;simulation;statistical classification;streaming media	Albert Bodenmüller	2018		10.5220/0006629401070114	command and control;distributed computing;computer science;sensor fusion;bayesian probability	Embedded	-7.173397058831078	-30.24516215418703	142259
9008ce3d2945bd6bddf4fa185c108ca0a4032bfc	understanding the interplay between bus, metro, and cab ridership dynamics in shenzhen, china				Mengxue Yue;Chaogui Kang;Clio Andris;Kun Qin;Yu Liu;Qingxiang Meng	2018	Trans. GIS	10.1111/tgis.12340	remote sensing;china;computer science;transport engineering	ECom	-15.40811950292431	-25.19395275497448	142353
5c30c6f95ad0c1bcd1a223b236b6320a56833b73	quantifying heterogeneous causal treatment effects in world bank development finance projects		The World Bank provides billions of dollars in development finance to countries across the world every year. As many projects are related to the environment, we want to understand the World Bank projects impact to forest cover. However, the global extent of these projects results in substantial heterogeneity in impacts due to geographic, cultural, and other factors. Recent research by Athey and Imbens has illustrated the potential for hybrid machine learning and causal inferential techniques which may be able to capture such heterogeneity. We apply their approach using a geolocated dataset of World Bank projects, and augment this data with satellite-retrieved characteristics of their geographic context (including temperature, precipitation, slope, distance to urban areas, and many others). We use this information in conjunction with causal tree (CT) and causal forest (CF) approaches to contrast ‘control’ and ‘treatment’ geographic locations to estimate the impact of World Bank projects on vegetative cover.	causal filter;causality;inferential theory of learning;machine learning;persistent vegetative state;random forest	Jianing Zhao;Daniel M. Runfola;Peter Kemper	2017		10.1007/978-3-319-71273-4_17	finance;business	SE	-12.458301736297772	-25.293663629924723	142457
88eddc29ebebba34ad4115a87a037a0b3fccebfd	relevance feedback based on n-tuplewise comparison and the electre methodology and an application in content-based image retrieval	multiple criteria analysis;relational mcdm;preference elicitation;electre iii;content based image retrieval	In this article we propose a method for information retrieval based on relational Multi-Criteria Decision Making. We assume that a user cannot define precise search criteria so that these criteria must be found based on the user’s assessment of several sample alternatives (‘alternatives’ here are database records, e.g. images). This situation is common in Content-based Image Retrieval, where it is easier for a user to indicate relevant images than to describe a proper query, especially in formal language. The proposed algorithm for the elicitation of criteria is based on ELECTRE III—a method originally designed for ranking a set of alternatives according to defined criteria. In our algorithm, however, the direction of reasoning is reversed: we start with several sample alternatives that have been assigned a rank by the user and then we select criteria that are compatible (in the sense of ELECTRE methodology) with the user’s preferences expressed on a sample set. Then, having determined the user’s criteria, we apply classical ELECTRE III to retrieve the relevant solutions from the database. We implemented the method in Matlab and tested it on the Microsoft Cambridge Image Database.	algorithm;byte;content-based image retrieval;formal language;image scaling;information retrieval;matlab;prototype;relevance feedback;web search engine	Pawel Rotter	2013	Multimedia Tools and Applications	10.1007/s11042-013-1384-1	computer science;data mining;database;information retrieval	AI	-5.622384611879074	-26.407673113665876	142482
553befc020e21b5b1d6f1a87fe788bafad3048c8	taking it for a test drive: a hybrid spatio-temporal model for wildlife poaching prediction evaluated through a controlled field test		Worldwide, conservation agencies employ rangers to protect conservation areas from poachers. However, agencies lack the manpower to have rangers effectively patrol these vast areas frequently. While past work has modeled poachers’ behavior so as to aid rangers in planning future patrols, those models’ predictions were not validated by extensive field tests. In this paper, we present a hybrid spatio-temporal model that predicts poaching threat levels and results from a five-month field test of our model in Uganda’s Queen Elizabeth Protected Area (QEPA). To our knowledge, this is the first time that a predictive model has been evaluated through such an extensive field test in this domain. We present two major contributions. First, our hybrid model consists of two components: (i) an ensemble model which can work with the limited data common to this domain and (ii) a spatio-temporal model to boost the ensemble’s predictions when sufficient data are available. When evaluated on real-world historical data from QEPA, our hybrid model achieves significantly better performance than previous approaches with either temporally-aware dynamic Bayesian networks or an ensemble of spatially-aware models. Second, in collaboration with the Wildlife Conservation Society and Uganda Wildlife Authority, we present results from a five-month controlled experiment where rangers patrolled over 450 sq km across QEPA. We demonstrate that our model successfully predicted (1) where snaring activity would occur and (2) where it would not occur; in areas where we predicted a high rate of snaring activity, rangers found more snares and snared animals than in areas of lower predicted activity. These findings demonstrate that (1) our model’s predictions are selective, (2) our model’s superior laboratory performance extends to the real world, and (3) these predictive models can aid rangers in focusing their efforts to prevent wildlife poaching and save animals.	dynamic bayesian network;machine learning;predictive modelling;test drive	Shahrzad Gholami;Benjamin J. Ford;Fei Fang;Andrew J. Plumptre;Milind Tambe;Margaret Driciru;Fred Wanyama;Aggrey Rwetsiba;Mustapha Nsubaga;Joshua Mabonga	2017		10.1007/978-3-319-71273-4_24	data mining;environmental science;dynamic bayesian network;poaching;wildlife;wildlife conservation;ensemble forecasting;graphical model;protected area	AI	-15.098099849092092	-28.243584236950202	142549
65e0af9e5b57faeb2c1065eb84677c9de1d83386	zoom-svd: fast and memory efficient method for extracting key patterns in an arbitrary time range		Given multiple time series data, how can we efficiently find latent patterns in an arbitrary time range? Singular value decomposition (SVD) is a crucial tool to discover hidden factors in multiple time series data, and has been used in many data mining applications including dimensionality reduction, principal component analysis, recommender systems, etc. Along with its static version, incremental SVD has been used to deal with multiple semi-infinite time series data and to identify patterns of the data. However, existing SVD methods for the multiple time series data analysis do not provide functionality for detecting patterns of data in an arbitrary time range: standard SVD requires data for all intervals corresponding to a time range query, and incremental SVD does not consider an arbitrary time range.  In this paper, we propose Zoom-SVD, a fast and memory efficient method for finding latent factors of time series data in an arbitrary time range. Zoom-SVD incrementally compresses multiple time series data block by block to reduce the space cost in storage phase, and efficiently computes singular value decomposition (SVD) for a given time range query in query phase by carefully stitching stored SVD results. Through extensive experiments, we demonstrate that Zoom-SVD is up to 15x faster, and requires 15x less space than existing methods. Our case study shows that Zoom-SVD is useful for capturing past time ranges whose patterns are similar to a query time range.		Jun-Gi Jang;Dongjin Choi;Jinhong Jung;U. Kang	2018		10.1145/3269206.3271682	time series;mathematical optimization;recommender system;dimensionality reduction;range query (data structures);principal component analysis;zoom;computer science;image stitching;singular value decomposition;artificial intelligence;pattern recognition	DB	-7.706061175840911	-36.997603351825575	142632
be21afa5fa4736ec98f49883069f23fd50b75d25	application of simulation in the pollution and purification for the marine ecosystem	marine ecosystem		marine ecosystem;purification of quantum state;simulation	M. C. Xie;T. Hieda	2004			environmental engineering;pollution;environmental science;marine ecosystem	Metrics	-11.3713460253818	-26.901015857643234	142681
13817574851369acc79885694304d88033d3f723	using probabilistic relational models to generate synthetic spatial or non-spatial databases		When real datasets are difficult to obtain for tasks such as system analysis, or algorithm evaluation, synthetic datasets are commonly used. Techniques for generating such datasets often generate random data for single-table datasets. Such datasets are often inapplicable when it comes to evaluating data mining or machine learning algorithms dealing with relational data. To address this, our earlier works have dealt with the task of generating relational datasets from Probabilistic Relational Models (PRMs), a framework for dealing with probabilistic uncertainties in relational domains. In this article, we extend this work by proposing to use more efficient data sampling algorithms, and by using a spatial extension of PRMs to generate synthetic spatial datasets. We also present our experimental analysis on three different data sampling algorithms applicable in our method, and the quality of the datasets generated by them.	algorithm;burn-in;data mining;database schema;experiment;gibbs sampling;go-back-n arq;http 404;machine learning;randomness;relational database;relational model;remote file sharing;run time (program lifecycle phase);sampling (signal processing);spatial database;statistical relational learning;synthetic data;synthetic intelligence;system analysis	Rajani Chulyadyo;Philippe Leray	2018	2018 12th International Conference on Research Challenges in Information Science (RCIS)	10.1109/RCIS.2018.8406645	computer science;data modeling;data mining;skeleton (computer programming);probabilistic logic;relational database;random variable;gibbs sampling	DB	-8.636701718214825	-33.31474399762275	142862
d629483a3cba60e00f017acf94c0a0c9365de3f3	privacy-preserving data cube for electronic medical records: an experimental evaluation	data cube;anonymization;electronic medical records;medical privacy	INTRODUCTION The aim of this study is to evaluate the effectiveness and efficiency of privacy-preserving data cubes of electronic medical records (EMRs). An EMR data cube is a complex of EMR statistics that are summarized or aggregated by all possible combinations of attributes. Data cubes are widely utilized for efficient big data analysis and also have great potential for EMR analysis. For safe data analysis without privacy breaches, we must consider the privacy preservation characteristics of the EMR data cube. In this paper, we introduce a design for a privacy-preserving EMR data cube and the anonymization methods needed to achieve data privacy. We further focus on changes in efficiency and effectiveness that are caused by the anonymization process for privacy preservation. Thus, we experimentally evaluate various types of privacy-preserving EMR data cubes using several practical metrics and discuss the applicability of each anonymization method with consideration for the EMR analysis environment.   METHODS We construct privacy-preserving EMR data cubes from anonymized EMR datasets. A real EMR dataset and demographic dataset are used for the evaluation. There are a large number of anonymization methods to preserve EMR privacy, and the methods are classified into three categories (i.e., global generalization, local generalization, and bucketization) by anonymization rules. According to this classification, three types of privacy-preserving EMR data cubes were constructed for the evaluation. We perform a comparative analysis by measuring the data size, cell overlap, and information loss of the EMR data cubes.   RESULTS Global generalization considerably reduced the size of the EMR data cube and did not cause the data cube cells to overlap, but incurred a large amount of information loss. Local generalization maintained the data size and generated only moderate information loss, but there were cell overlaps that could decrease the search performance. Bucketization did not cause cells to overlap and generated little information loss; however, the method considerably inflated the size of the EMR data cubes.   CONCLUSIONS The utility of anonymized EMR data cubes varies widely according to the anonymization method, and the applicability of the anonymization method depends on the features of the EMR analysis environment. The findings help to adopt the optimal anonymization method considering the EMR analysis environment and goal of the EMR analysis.		Soohyung Kim;Hyukki Lee;Yon Dohn Chung	2017	International journal of medical informatics	10.1016/j.ijmedinf.2016.09.008	computer science;data mining;database;world wide web;data cube	ML	-6.395937906041944	-31.88480410379211	142928
78ef08e1a9470abf852768143085869c90dce07e	mining frequent itemsets from noisy data	data mining itemsets data engineering probability data privacy transaction databases systems engineering and theory data models proposals conferences;itemsets;probability;noisy data;data engineering;data mining;systems engineering and theory;frequent itemset;transaction databases;data privacy;proposals;conferences;data models	As we face huge amounts of varied information, data mining, which helps us discover hidden features or rules from voluminous data systematically, has become more important [3, 4, 6, 10]. However, real world data is often dirty, including noise such as missing or irrelevant values. The information mined from such noisy data may be incorrect. We model noisy data with probabilities, assuming that noise is mixed with data statistically. We also propose a way to find frequent itemsets [2] by estimating supports on noiseless data from noisy data. An algorithm using FP-tree [6, 10] is also presented to mine frequent itemsets efficiently.	algorithm;data mining;information theory;mined;relevance;signal-to-noise ratio	Kazuyo Narita;Hiroyuki Kitagawa	2006	22nd International Conference on Data Engineering Workshops (ICDEW'06)	10.1109/ICDEW.2006.90	data modeling;information engineering;information privacy;computer science;data science;probability;data mining;database;data stream mining	DB	-5.6890112084742634	-33.82277004438013	142936
bf8959796614849f6d77e513a6e11c5cb4a61e15	an early event detection technique with bus gps data		The analysis and study of the relationship between a geo-spatial event and human mobility in an urban area is very significant for improving productivity, mobility, and safety. In particular, in order to alleviate serious road congestions, traffic jams, and stampedes, it is essential to predict and be informed about the occurrence of an event as soon as possible. When we know an event occurrence in advance, some of those who are not interested in the event might change their plans and/or might take a detour to avoid to get involved in a heavy congestion. In this context, this paper presents an early event detection technique using GPS trajectories collected from periodic-cars, which are vehicles periodically traveling on a pre-scheduled route with a pre-determined departure time, such as a transit bus, shuttle, garbage truck, or municipal patrol car. Using these trajectories, which provide the real-time and continuous traffic flow and speed, our technique detects large-scale events in advance, without incurring any privacy invasion. The behavior of periodic-cars shows a certain sign of a large-scale event before attendees gather around a venue because traffic can be slowed around the venue before the event occurrence. We evaluated our method using over 7,000-bus data from January to May in 2015 in Beijing, which we compared with the check-in data collected from a social network service.	garbage collection (computer science);global positioning system;network congestion;prospective search;real-time transcription;social network;venue (sound system)	Shunsuke Aoki;Kaoru Sezaki;Nicholas Jing Yuan;Xing Xie	2017		10.1145/3139958.3139959	real-time computing;urban computing;global positioning system;data mining;computer science;garbage;beijing;truck;jams;transit bus;traffic flow	HCI	-17.86012934837046	-28.889860438707665	143118
abd595bd65947501cb89e6ac3174349484bda1b5	transforming speed sequences into road rays on the map with elastic pathing		Advances in technology have provided ways to monitor and measure driving behavior. Recently, this technology has been applied to usage-based automotive insurance policies that offer reduced insurance premiums to policy holders who opt-in to automotive monitoring. Several companies claim to measure only speed data, which they further claim preserves privacy. However, we have developed an algorithm elastic pathing that successfully tracks drivers’ locations from speed data. The algorithm tracks drivers by assuming a start position, such as the driver’s home address (which is typically known to insurance companies), and then estimates the possible routes by fitting the speed data to map data. To demonstrate the algorithm’s real-world applicability, we evaluated its performance with driving datasets from central New Jersey and Seattle, Washington, representing suburban and urban areas. We are able to estimate destinations with error within 250 meters for 17% of the traces and within 500 meters for 24% of the traces in the New Jersey dataset, and with error within 250 and 500 meters for 15.5% and 27.5% of the traces, respectively, in the Seattle dataset. Our work shows that these insurance schemes enable a substantial breach of privacy.	algorithm;amazon elastic block store;pathfinding;privacy law;ray (optics);tracing (software)	Xianyi Gao;Bernhard Firner;Shridatt Sugrim;Victor Kaiser-Pendergrast;Yulong Yang;Janne Lindqvist	2017	CoRR		simulation;insurance policy;elasticity (economics);geodesy;geography;automotive industry	HCI	-16.962135361307244	-30.170351261828923	143157
32bad9bca6da56158235bfd9aab25e4ee5145d21	study of bird's nest habit based on variance analysis	bird nest;statistics with r;tree species;variable coefficient;variance analysis	Using variance analysis and variable coefficient theory, this paper study the nest habit of three kind of birds: Ficedula zanthopygia, Parus major and Sitta auropaea in the two status of natural nest and artificial nest-box. For Ficedula zanthopygia the effect of factors A (status) on indicators (birds entered number) is significant, B (tree species, a total of 13) on them is more significant. For Parus major tree species is significant, but for Sitta auropaea status is significant. In nesting, Ficedula zanthopygia and Sitta auropaea give priority to tree height, then tree DBH, but Parus major give priority to tree DBH, then tree height. All the calculation is completed by statistics with R. © Springer-Verlag 2010.		Yong-quan Dong;Cui-lan Mi	2010		10.1007/978-3-642-16336-4_63		Logic	-11.666518815333784	-24.887129192043602	143411
fde5108ab5ba90f3f97bda86aec1245d27d56631	towards an acoustic environmental observatory	sensors;acoustics;training;acoustic signal processing;observatories acoustic sensors environmental management remote monitoring large scale systems biodiversity biosensors data analysis atmospheric measurements soil measurements;ecology;sensor network;environmental science computing;sensor management;acoustics sensor network environmental monitoring;large scale;birds;monitoring;management utility acoustic environmental observatory large scale environmental monitoring environmental change ecology hardware sensors;observatories;data visualization;acoustic transducer arrays;environmental change;environmental science computing acoustic signal processing acoustic transducer arrays ecology;environmental monitoring	The need for large scale environmental monitoring to manage environmental change is well established. Ecologists have long used acoustics as a means of monitoring the environment in their field work, and so the value of an acoustic environmental observatory is evident. However, the volume of data generated by such an observatory would quickly overwhelm even the most fervent scientist using traditional methods. In this paper we present our steps towards realising a complete acoustic environmental observatory - i.e. a cohesive set of hardware sensors, management utilities, and analytical tools required for large scale environmental monitoring. Concrete examples of these elements, which are in active use by ecological scientists, are also presented.	acoustic cryptanalysis;ecology;field research;sensor	Richard Mason;Paul Roe;Michael W. Towsey;Jinglan Zhang;Jennifer Gibson;Stuart Gage	2008	2008 IEEE Fourth International Conference on eScience	10.1109/eScience.2008.16	environmental science;hydrology;remote sensing	Robotics	-12.510025263675459	-28.182697836418075	143621
43019bac0188cd24f4b36a379055a6003acddc3c	mining dependent patterns in probabilistic databases	database system;search space;journal article;probabilistic database;normal form;conditional probability	Today's database systems must deal with uncertainty in the data they store. Consequently, there is a strong need for mining probabilistic databases. Because probabilistic data in first normal form relations is redundant, existing mining techniques are inadequate for discovering probabilistic databases. This paper designs a new strategy for identifying potentially useful patterns in probabilistic databases. A dependent rule is thus identified in a probabilistic database, represented in the form X → Y with conditional probability matrix MY|X . This method uses an instance selection to increase efficiency, enabling us to reduce the search space. We evaluated the proposed technique, and our experimental results demonstrate that the approach is effective and efficient.		Shichao Zhang;Chengqi Zhang;Jeffrey Xu Yu	2004	Cybernetics and Systems	10.1080/01969720496443390	database theory;probabilistic analysis of algorithms;joint probabilistic data association filter;conditional probability;probabilistic relevance model;computer science;probabilistic database;method of conditional probabilities;data mining;database;mathematics;probabilistic logic;information retrieval;divergence-from-randomness model	DB	-7.458016998622683	-35.810157109436794	143884
c59b03c148d813c3bae7b7ff24aabe12704bb827	dynamic sorted neighborhood indexing for real-time entity resolution	braided tree;journal article;data matching;real time query;dynamic indexing;record linkage	Real-time Entity Resolution (ER) is the process of matching query records in subsecond time with records in a database that represent the same real-world entity. Indexing techniques are generally used to efficiently extract a set of candidate records from the database that are similar to a query record, and that are to be compared with the query record in more detail. The sorted neighborhood indexing method, which sorts a database and compares records within a sliding window, has been successfully used for ER of large static databases. However, because it is based on static sorted arrays and is designed for batch ER that resolves all records in a database rather than resolving those relating to a single query record, this technique is not suitable for real-time ER on dynamic databases that are constantly updated. We propose a tree-based technique that facilitates dynamic indexing based on the sorted neighborhood method, which can be used for real-time ER, and investigate both static and adaptive window approaches. We propose an approach to reduce query matching times by precalculating the similarities between attribute values stored in neighboring tree nodes. We also propose a multitree solution where different sorting keys are used to reduce the effects of errors and variations in attribute values on matching quality by building several distinct index trees. We experimentally evaluate our proposed techniques on large real datasets, as well as on synthetic data with different data quality characteristics. Our results show that as the index grows, no appreciable increase occurs in both record insertion and query times, and that using multiple trees gives noticeable improvements on matching quality with only a small increase in query time. Compared to earlier indexing techniques for real-time ER, our approach achieves significantly reduced indexing and query matching times while maintaining high matching accuracy.	b+ tree;cluster analysis;data quality;database;erdős–rényi model;experiment;link/cut tree;real-time clock;real-time transcription;real-time web;sorting;synthetic data;window function	Banda Ramadan;Peter Christen;Huizhi Liang;Ross W. Gayler	2015	J. Data and Information Quality	10.1145/2816821	sargable;query optimization;record linkage;computer science;data mining;database;world wide web;information retrieval	DB	-8.242568723663496	-36.84283406051689	143902
ad4f5dc0fc8533a8b86bc830dad159d636ebafba	behavioural pattern identification and prediction in intelligent environments	health monitoring;narx;intelligent environments;occupancy monitoring;recurrent neural networks;binary time series;institutional repository research archive oaister;elman network	In this paper, the application of soft computing techniques in prediction of an occupant’s behaviour in an inhabited intelligent environment is addressed. In this research, daily activities of elderly people who live in their own homes suffering from dementia are studied. Occupancy sensors are used to extract the movement patterns of the occupant. The occupancy data is then converted into temporal sequences of activities which are eventually used to predict the occupant behaviour. To build the prediction model, different dynamic recurrent neural networks are investigated. Recurrent neural networks have shown a great ability in finding the temporal relationships of input patterns. The experimental results show that non-linear autoregressive network with exogenous inputs model correctly extracts the long term prediction patterns of the occupant and outperformed the Elman network. The results presented here are validated using data generated from a simulator and real environments.	algorithm;artificial neural network;autoregressive model;behavioral pattern;binary data;data (computing);data compression;epoch (reference date);intelligent environment;nonlinear autoregressive exogenous model;nonlinear system;pattern recognition;recurrent neural network;sensor;simulation;soft computing;sparse matrix;time series	Sawsan M. Mahmoud;Ahmad Lotfi;Caroline S. Langensiepen	2013	Appl. Soft Comput.	10.1016/j.asoc.2012.12.012	simulation;computer science;artificial intelligence;recurrent neural network;machine learning;data mining;nonlinear autoregressive exogenous model	AI	-16.690388135940687	-34.372317430288994	144198
c0320b94fb16221fcfb8ff7d19e2cc867fee0845	extracting regular mobility patterns from sparse cdr data without a priori assumptions		In this work we present two methods that can extract habitual movement patterns and reconstruct the underlying movement of users from their call detail records (CDR) in a way that works for users with only moderate numbers of CDRs and that does not make any prior assumptions on the behaviour of the users. The methods allow for a more comprehensive user base in large-scale studies due to the fact that users that might otherwise have to be discarded can also be analysed. The first one is computationally not overly intense and is based on association mining. The second one, which we named DAMOCLES, is based on extracting idiosyncratic daily patterns from clustered daily activities. The methods are evaluated on real data of 140 users over an average of 200 days against benchmarks using assumptions commonly found in the literature such as a work week from Monday to Friday on GPS ground truth. Both methods clearly outperform the benchmarks and for many users retrieve similar regularities. Additionally a simulation study is performed that allows to evaluate the methods in a more controlled environment. DOI: https://doi.org/10.1080/17489725.2017.1333638 Posted at the Zurich Open Repository and Archive, University of Zurich ZORA URL: https://doi.org/10.5167/uzh-142018 Accepted Version Originally published at: Burkhard, Oliver; Ahas, Rein; Saluveer, Erki; Weibel, Robert (2017). Extracting regular mobility patterns from sparse CDR data without a priori assumptions. Journal of Location Based Services:Epub ahead of print. DOI: https://doi.org/10.1080/17489725.2017.1333638 May 17, 2017 Journal of Location Based Services main To appear in the Journal of Location Based Services Vol. 00, No. 00, Month 20XX, 1–19 Extracting Regular Mobility Patterns From Sparse CDR Data Without a priori Assumptions Oliver Burkharda,†, Rein Ahasb,‡, Erki Saluveerc,§, Robert Weibela,¶ a Department of Geography, University of Zürich, Winterthurerstrasse 190, 8057 Zürich, Switzerland; b Department of Geography, University of Tartu, Vanemuise 46, 51014 Tartu, Estonia; c Positium Ltd., Õpetaja 9, 51003 Tartu, Estonia (Received 00 Month 20XX; final version received 00 Month 20XX; accepted 00 Month 20XX) In this work we present two methods that can extract habitual movement patterns and reconstruct the underlying movement of users from their call detail records (CDR) in a way that works for users with only moderate numbers of CDRs and that does not make any prior assumptions on the behaviour of the users. The methods allow for a more comprehensive user base in large scale studies due to the fact that users that might otherwise have to be discarded can also be analysed. The first one is computationally not overly intense and is based on association mining. The second one, which we named DAMOCLES is based on extracting idiosyncratic daily patterns from clustered daily activities. The methods are evaluated on real data of 140 users over an average of 200 days against benchmarks using assumptions commonly found in the literature such as a work week from Monday to Friday on GPS ground truth. Both methods clearly outperform the benchmarks and for many users retrieve similar regularities. Additionally a simulation study is performed that allows to evaluate the methods in a more controlled environment.	20xx;archive;association rule learning;benchmark (computing);epub;global positioning system;ground truth;location-based service;simulation;sparse matrix;switzerland	Oliver Burkhard;Rein Ahas;Erki Saluveer;Robert Weibel	2017	J. Location Based Services	10.1080/17489725.2017.1333638	data mining;computer science;activities of daily living;ground truth;global positioning system;a priori and a posteriori;machine learning;artificial intelligence	HCI	-17.855643420747416	-35.53291048995671	144324
73b85f4ed79f5f5329f2db47714c680833036d52	temporal performance of advanced driver assistance systems vis-á-vis human driving behavior in dense traffic	behavioral research;dense traffics;mobility;adaptive control systems;automatic braking;ts technical sciences;temporal requirement advanced driver assistance systems human driving behavior adas automotive sector adaptive cruise control system automated emergency braking system;advanced driver assistance systems;driver information systems behavioural sciences computing;ivs integrated vehicle safety;fluid solid mechanics;traffic congestion;vehicles radar pipelines brakes acceleration lead cameras;intelligent systems;traffic;emergency traffic control;intent communication;human driving behavior;adas;drivers;autonomous intelligent cruise control;braking system;driver support systems	Advanced Driver Assistance Systems (ADAS) are becoming ubiquitous, and gradually take over the role of human drivers in the vision of the automotive sector. Humans are different from most systems: while in general humans exhibit a much higher error rate when performing specific functions, they are also unmatched in their adaptability, and their ability to recognize patterns and anticipate on these. In this paper we derive temporal requirements on future ADAS operation, needed to at least match human driving behavior in dense traffic. We examine Adaptive Cruise Control and Automated Emergency Braking systems at highway speeds, derive temporal requirements, and show that in dense traffic situations intent communication has a significant benefit to improve systems operation. The resulting requirements will challenge ADAS developments in the coming years.	architecture design and assessment system;bit error rate;humans;radar;requirement;sampling (signal processing);visual instruction set	Roelof Hamberg;Teun Hendriks;Tjerk Bijlsma	2015	2015 IEEE 18th International Conference on Intelligent Transportation Systems	10.1109/ITSC.2015.247	embedded system;simulation;advanced driver assistance systems;engineering;automotive engineering	Robotics	-19.085614996716973	-26.845200716741658	144797
1de87e6941f10672098041d6ab49bd5437a97ef4	sensitivity analysis of an icu simulation model	digital simulation;health care;resource allocation;icu simulation model;inpatient healthcare system modeling;inpatient healthcare system simulation;patient flow;patient movement modeling;patient movement rule;resource allocation task;sensitivity analysis;tertiary facility	The modeling and simulation of inpatient healthcare systems comprising of multiple interconnected units of monitored care is a challenging task given the nature of clinical practices and procedures that regulate patient flow. Therefore, any related study on the properties of patient flow should (i) explicitly consider the modeling of patient movement rules in face of congestion, and (ii) examine the sensitivity of simulation output, expressed by patient delays and diversions, over different patient movement modeling approaches. In this work, we use a high fidelity simulation model of a tertiary facility that can incorporate complex patient movement rules to investigate the challenges inherent in its employment for resource allocation tasks.	international components for unicode;network congestion;simulation	Theologos Bountourelis;David Eckman;K. Louis Luangkesorn;Andrew J. Schaefer;Spencer G. Nabors;Gilles Clermont	2012	Proceedings Title: Proceedings of the 2012 Winter Simulation Conference (WSC)		simulation;resource allocation;health care	HPC	-16.681607271627215	-24.455816982662633	144800
85880ba09b6775676e93c35e30b9c6014c61340c	visualization and analysis of interacting occurences in a smart city	georeferenced data social network participatory city data visualizing voronoi diagram;police computational geometry data visualisation global positioning system;data visualization cities and towns generators vectors government registers;interacting occurrence visualization police catch crime occurrence police actions quantitative analysis criminal occurrence reduction critical zone police runaway crime occurrence police crime runway size area interaction modelling voronoi diagrams gps point city map information insertion police occurrences criminal occurrences simulation tool data analysis resource management information and communication technologies smart city interacting occurrence analysis	New information and communication technologies enable a better management of the available resources in a smart city. Leaders need tools to analyze data for better decisions, anticipate problems and resolve them proactively. In this context, this article proposes a simulation tool to analyze the interaction of typical cities occurrences like criminal and police. The information of both occurrences, including their densities, are inserted and visualized on a city map. Each record is marked on the GPS point where it happened. From these inputs data, the interactions are modeled by Voronoi Diagrams. The occurrences change their position according to the size area of the opposite event. In this way, crimes runway from police and police catch crimes occurrences. As results, we show that a large increase of police actions will not influence quantitatively in the reduction of criminal occurrences out of a critical zone.	autostereogram;color;global positioning system;graph (discrete mathematics);information visualization;interaction;mobile device;simulation;smart city;social network;voronoi diagram	Luana Carine Schunke;Luiz Paulo Luna de Oliveira;Marta Becker Villamil	2014	2014 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2014.6912490	simulation;data mining;computer security	Embedded	-18.74040133667947	-31.758689748770554	144953
69d7925a9a3ff628b839dd7aaa8da3472f1228dc	traffic congestion analysis visualisation tool	road traffic management traffic congestion analysis visualisation tool urban population private cars urgent transportation problem road traffic congestion delays time loss human stress energy consumption environmental pollution traffic control historical patterns google maps traffic layer real time congestion calculation interactive visualization tool;traffic mitigation;road traffic congestion;image processing;image processing road traffic congestion google maps traffic layer visualization;roads google data visualization real time systems vehicles sensors image color analysis;real time information;visualization;road traffic control data visualisation delays energy consumption geographic information systems interactive systems pollution control real time systems;traffic congestion;traffic surveillance;highway traffic control;google maps traffic layer;google maps	The rapid growth of urban population and numbers of private cars in this modern era, results in increasingly urgent transportation problem in cities throughout the world. Road traffic congestion is an omnipresent problem, which leads to delays, time loss, human stress, energy consumption, environmental pollution e.c.t. In order to decrease traffic congestion, there is a need for simulating and optimizing traffic control and improving traffic management. There are different ways for traffic congestion monitoring and analysis such as using video monitoring and surveillance systems, or static and dynamic sensors which allow traffic management in real time. There are also other methods using non real time analysis where traf?c congestion can be extracted from historical patterns of traf?c congestion. The historical patterns can be gained from the stored travel time and speed data. The goal of enhancing driver convenience is achieved by providing applications based on road traffic condition that mainly identifies congestion status. This paper presents a web application which uses live traffic congestion data from Google Maps traffic layer for real time congestion calculation. A technique utilized for estimating the level of congestion is image processing. The main objective is to provide an automated and yet interactive visualization tool for congestion analysis in real time. The aim is reducing the traffic congestion on roads which will lead to decrease in the number of accidents. It can provide important data which can help road traffic management. Thus, it is mainly dedicated to traffic managers, operators and analysts. Nevertheless it can be implemented also by road users. Unlike most sensor based applications, it makes quantified congestion data available even in regions with limited traffic data information.	image processing;interactive visualization;network congestion;sensor;simulation;tcp congestion control;transportation theory (mathematics);web application	Natasha Petrovska;Aleksandar Stevanovic	2015	2015 IEEE 18th International Conference on Intelligent Transportation Systems	10.1109/ITSC.2015.243	traffic generation model;traffic engineering;network traffic control;simulation;floating car data;geography;vehicle information and communication system;traffic congestion reconstruction with kerner's three-phase theory;traffic flow;traffic conflict;transport engineering;traffic bottleneck;traffic shaping;computer security;slow-start;traffic optimization	HPC	-16.75400024478488	-28.974030905735397	145386
04d0f47fc482dc594540efa442c3abce2d636680	an initial study of predictive machine learning analytics on large volumes of historical data for power system applications	big data predictive machine learning analytics historical data power system applications industrial data intelligent machine learning tools predictive knowledge extraction very large data volumes data processing power systems forecasting substations fault events power load machine learning algorithm mapreduce paradigm;apache spark;machine learning;big data;machine learning algorithms big data sparks data models libraries analytical models distributed databases;hadoop;apache spark big data machine learning hadoop;power systems big data knowledge acquisition learning artificial intelligence	Nowadays large volumes of industrial data are being actively generated and collected in various power system applications. Industrial Analytics in the power system field requires more powerful and intelligent machine learning tools, strategies, and environments to properly analyze the historical data and extract predictive knowledge. This paper discusses the situation and limitations of current approaches, analytic models, and tools utilized to conduct predictive machine learning analytics for very large volumes of data where the data processing causes the processor to run out of memory. Two industrial analytics cases in the power systems field are presented. Our results indicated the feasibility of forecasting substations fault events and power load using machine learning algorithm written in MapReduce paradigm or machine learning tools specific for Big Data.	algorithm;artificial intelligence;autonomous robot;big data;computer;ibm power systems;industrial robot;library (computing);lisp machine;machine learning;mapreduce;mobile device;naive bayes classifier;norm (social);out of memory;programming paradigm;sensor;traction substation	Jiang Zheng;Aldo Dagnino	2014	2014 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2014.7004327	analytics;computer science;data science;machine learning;data mining;computational learning theory;active learning	DB	-10.739142435000758	-31.510599687246994	145930
fc3c9cf313a147ee5758745fd76c5c37bae74906	intrusion diagnosis and prediction with expert system	certainty factor;intrusion diagnosis;attack prediction;attack graph	Abstract#R##N##R##N#Network diagnosis and attack prediction can help the network administrator to take timely actions to defend against well-planned attacks that exploit a chain of vulnerabilities. One important data source for such analysis is the alerts generated by intrusion detection systems (IDS) deployed over the network. However, IDS typically generates overwhelming amount of alerts, where one cannot simply aggregate or discard. In addition, the chance of a successful exploit depends on many hidden factors such as system status and attacker power, and thus the dependencies among exploits and conditions are typically too complicated to analyze under probability framework. In this paper, we employ expert system to deal with such uncertainties and conduct certainty factor inference. We show that analysis in fuzzy system is tractable and we propose an algorithm to analyze the network status and predict the potential attacks. Finally, we give a case study to illustrate our algorithm and evaluate the effectiveness of our approach on the DARPA data sets. Copyright © 2011 John Wiley & Sons, Ltd.	expert system	Xuejiao Liu;Chengfang Fang;Debao Xiao	2011	Security and Communication Networks	10.1002/sec.293	computer science;artificial intelligence;data mining;computer security	AI	-12.327278994280805	-29.90545556862646	146086
982374b612b5dcd50d244bafbdf8795e277582ad	intelligent bio-environments: exploring fuzzy logic approaches to the honeybee crisis	anfis;honeybee hive;smart;conference;intelligent environment;fuzzy logic;sensor fusion;colony collapse disorder	This paper presents an overview of how fuzzy logic can be employed to model intelligent bio-environments. It explores how non-invasive monitoring techniques, combined with sensor fusion, can be used to generate a warning signal if a critical event within the natural environment is on the horizon. The honeybee hive is presented as a specific example of an intelligent bio-environment that unfortunately, under certain indicative circumstances, can fail within the natural world. This is known as Colony Collapse Disorder (CCD). The paper describes the design of a fuzzy logic methodology that utilizes input from non-invasive beehive monitoring systems, combining data from dedicated sensors and other disparate sources. An overview is given of two fuzzy logic approaches that are being explored in the context of the beehive, a fuzzy logic system and an Adaptive Neuro-Fuzzy Inference System (ANFIS).	adaptive neuro fuzzy inference system;apache hive;british informatics olympiad;charge-coupled device;fuzzy logic;neuro-fuzzy;sensor web	Marie Bassford;Birgit Painter	2016	2016 12th International Conference on Intelligent Environments (IE)	10.1109/IE.2016.45	fuzzy electronics;adaptive neuro fuzzy inference system;engineering;artificial intelligence;neuro-fuzzy;machine learning;data mining	Robotics	-11.861213970802678	-28.870792233101522	146108
ef8e343413f430aed839db18d97c3cba4233015d	on the even-out effect of probabilistic sampling	computers;sampling methods telecommunication traffic internet distortion measurement volume measurement data engineering memory size measurement area measurement statistical distributions;network measurement;probability density function;sampling methods data analysis internet pareto distribution;data analysis;data storage;size distribution;internet;pareto distribution;data storage processing;pareto distribution probabilistic sampling data storage processing lorenz curve real internet data;lorenz curve;ip networks;economics;probabilistic logic;sampling methods;real internet data;probabilistic sampling;data models	Sampling is widely used in social investigations and network measurements since it can significantly reduce the expense of data storage and processing. However, sampling will inevitably miss or even distort the original data characteristics to some extent. This paper studies the effect of probabilistic sampling on a set of data with unbalanced size distribution. We introduce the Lorenz curve, widely used in economics, associated with the crossover split, a recently proposed quantifier, to measure the deviation of size distribution before and after sampling. By using simulation and real Internet data, we observe that as the sampling probability decreases, the size distribution becomes less unbalanced. We call this phenomenon the even-out effect. The relations among the probability sampling, the crossover split and Pareto distribution are also revealed	computer data storage;distortion;gibbs sampling;pareto efficiency;quantifier (logic);sampling (signal processing);simulation;unbalanced circuit	Ziqian Liu;Changjia Chen	2006	First International Multi-Symposiums on Computer and Computational Sciences (IMSCCS'06)	10.1109/IMSCCS.2006.245	sampling error;econometrics;simple random sample;importance sampling;computer science;slice sampling;data mining;sampling distribution;statistics	Metrics	-7.50664984028755	-33.24520807450284	146308
812c2fb0696f0a31f1b724e3c3a013e0fa6f804f	evaluating top-k queries over incomplete data streams	multiple instance;approximate algorithm;top k queries;nccr mics;skyline;data streams;nccr mics esdm;incomplete streams;dominating set;incomplete data;exact algorithm;dominance set;sliding window	We study the problem of continuous monitoring of top-k queries over multiple non-synchronized streams. Assuming a sliding window model, this general problem has been a well addressed research topic in recent years. Most approaches, however, assume synchronized streams where all attributes of an object are known simultaneously to the query processing engine. In many streaming scenarios though, different attributes of an item are reported in separate non-synchronized streams which do not allow for exact score calculations. We present how the traditional notion of object dominance changes in this case such that the k dominance set still includes all and only those objects which have a chance of being among the top-k results in their life time. Based on this, we propose an exact algorithm which builds on generating multiple instances of the same object in a way that enables efficient object pruning. We show that even with object pruning the necessary storage for exact evaluation of top-k queries is linear in the size of the sliding window. As data should reside in main memory to provide fast answers in an online fashion and cope with high stream rates, storing all this data may not be possible with limited resources. We present an approximate algorithm which leverages correlation statistics of pairs of streams to evict more objects while maintaining accuracy. We evaluate the efficiency of our proposed algorithms with extensive experiments.	approximation algorithm;computer data storage;database;exact algorithm;experiment;streaming media;window function	Parisa Haghani;Sebastian Michel;Karl Aberer	2009		10.1145/1645953.1646064	sliding window protocol;dominating set;computer science;theoretical computer science;machine learning;data mining;database;data stream mining	DB	-7.918975696244759	-36.107213858133036	146634
7c3211d1a37231f0d86f817f141e48ac10f441c1	integration of structural health monitoring and intelligent transportation systems for bridge condition assessment: current status and future direction	intelligent transportation systems;data collection;bridges;maintenance engineering;data fusion;inspection;monitoring;feature extraction;remote sensing;bridges inspection monitoring vehicles feature extraction maintenance engineering;vehicle dynamics bridges structures condition monitoring inspection intelligent transportation systems real time systems road traffic structural engineering computing;vehicles;structural health monitoring;real time traffic management structural health monitoring intelligent transportation systems bridge condition assessment catastrophic bridge failures interval based bridge inspection shm vehicle characteristics traffic operational conditions;intelligent transportation system bridge condition assessment condition based monitoring techniques integrated shm its;condition surveys	Recent catastrophic bridge failures clearly indicate the urgent need for improving interval-based bridge inspection procedures that are qualitative and subjective in nature. Structural Health Monitoring (SHM) can mitigate the deficiencies of interval-based inspection techniques and provide real-time diagnostic information regarding the bridge structural health. SHM is not flawless however; the variability in the vehicle characteristics and traffic operational conditions makes it prone to false diagnosis. Recent advancements in the integration of SHM with intelligent transportation systems (ITS) demonstrate the successful use of ITS devices (e.g., traffic cameras, traffic detectors) in the analysis of bridge responses to multimodal traffic with varying loads or during the critical events that cause excess vibration beyond the normal limit. In an ITS-informed SHM system, the ITS device collected data can be integrated with SHM to increase the reliability and accuracy of the SHM system. This integration would reduce the possibility of false diagnosis of damages detected by the SHM system (e.g., vibrations caused by heavy vehicles on a bridge could be read by a SHM sensor as a structural health problem of the bridge), which would eventually decrease the bridge maintenance costs. Similarly, in SHM-informed ITS system, SHM sensors can provide data on bridge health condition for ITS applications, where ITS uses this bridge health condition information for real-time traffic management. In this paper, literature related to both ITS-informed SHM and SHM-informed ITS is reviewed. Based on the literature review, potential challenges and future research directions associated with ITS-SHM integration are also discussed.	bridge management system;data infrastructure;heart rate variability;multimodal interaction;offset binary;onset (audio);real-time clock;real-time locating system;real-time transcription;sandy bridge;sensor;software diagnosis;super high material cd;visual inspection	Sakib Mahmud Khan;Sez Atamturktur;Mashrur Chowdhury;Mizanur Rahman	2016	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2016.2520499	maintenance engineering;structural engineering;intelligent transportation system;inspection;feature extraction;computer science;engineering;machine learning;sensor fusion;transport engineering;forensic engineering;statistics;data collection	AI	-17.200415448818116	-26.316620035292644	146738
9811d8e1890f7813c8db98f0646a4c1166420462	a segment-based trajectory similarity measure in the urban transportation systems	gps trajectory;gps sensor;spatial temporal data;trajectory similarity measure	With the rapid spread of built-in GPS handheld smart devices, the trajectory data from GPS sensors has grown explosively. Trajectory data has spatio-temporal characteristics and rich information. Using trajectory data processing techniques can mine the patterns of human activities and the moving patterns of vehicles in the intelligent transportation systems. A trajectory similarity measure is one of the most important issues in trajectory data mining (clustering, classification, frequent pattern mining, etc.). Unfortunately, the main similarity measure algorithms with the trajectory data have been found to be inaccurate, highly sensitive of sampling methods, and have low robustness for the noise data. To solve the above problems, three distances and their corresponding computation methods are proposed in this paper. The point-segment distance can decrease the sensitivity of the point sampling methods. The prediction distance optimizes the temporal distance with the features of trajectory data. The segment-segment distance introduces the trajectory shape factor into the similarity measurement to improve the accuracy. The three kinds of distance are integrated with the traditional dynamic time warping algorithm (DTW) algorithm to propose a new segment-based dynamic time warping algorithm (SDTW). The experimental results show that the SDTW algorithm can exhibit about 57%, 86%, and 31% better accuracy than the longest common subsequence algorithm (LCSS), and edit distance on real sequence algorithm (EDR) , and DTW, respectively, and that the sensitivity to the noise data is lower than that those algorithms.	algorithm;bluetooth;canonical account;cluster analysis;computation (action);data mining;drug vehicle;dynamic time warping;edit distance;edrophonium;exhibits as topic;global positioning system;gray platelet syndrome;handheld game console;human activities;longest common subsequence problem;mandibular right second molar tooth;nearest-neighbor interpolation;physical object;sampling (signal processing);sampling - surgical action;shape factor (image analysis and microscopy);similarity measure;smart device;sensor (device);statistical cluster	Yingchi Mao;Haishi Zhong;Xianjian Xiao;Xiaofang Li	2017		10.3390/s17030524	computer vision;machine learning;data mining	ML	-16.271183158115722	-34.94838326278924	146740
144d517c266a8c7e8a78f8b6722ab3b0f5ccaa45	identification of warning signs in truck driving behavior before safety-critical events	discriminant analysis;behavior	This research effort aims to distinguish between safety critical event behavior and normal car-following behavior. The Naturalistic Truck Driving Study conducted by the Virginia Tech Transportation Institute collected very useful data in this regard. By instrumenting trucks and allowing them to be used in normal daily routines, the data collected included normal driving as well as safety critical events. This allows the two to be compared to find any differences. A discriminant analysis was used for this task which resulted in interesting results when analyzing the data immediately before safety critical events for two drivers. The discriminant analysis resulted in a way to “predict” events as the discriminant scores of the data immediately before a safety critical event show a deviation from normal car following behavior.	instrumentation (computer programming);linear discriminant analysis	Montasir Abbas;Bryan Higgs;Alejandra Medina;C. Y. David Yang	2011	2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2011.6083093	simulation;engineering;transport engineering;computer security	Robotics	-17.999754662298827	-27.106189435925266	146789
f6b2c4c9e90e3d8d733131922f5a1d0e3f657bf8	relating aircraft altitude with pilot's physiological variables: towards increasing safety in light-sport aviation		Several applications require humans to be in high-altitude environments, whether for recreational purposes, like mountaineering or light sport aviation, or for labour, as miners. Although in these conditions the monitoring of physiological variables is, per se, of interest, the direct correlation of these variables with altitude itself is not usually explored towards the development of decision-support systems and/or critical event alarms. This paper proposes two neural networks approaches to assess and explore this correlation. One, based on dynamic SISO models, estimates physiological variables using the aircraft pressure altitude as input. A second approach uses static MISO networks to classify the flight stage (and therefore the altitude variation) from physiological variables. Both models were developed and validated using real data acquired in hypobaric chamber tests simulating a real flight. The good results obtained indicate the viability of the approach.	artificial neural network;simulation interoperability standards organization;system analysis	Susana M. Vieira;Alexandra Moutinho;Margarida Solas;José F. Loureiro;Maria B. Silva;Sara Zorro;Luís Patrão;Joaquim Gabriel;Jorge Silva	2017		10.5220/0006476903590364	engineering;aerospace engineering;aviation;automotive engineering;altitude	AI	-16.09972199135275	-25.341689242830757	147052
d28cf31e707e55561336755083c37fb1a0201078	em-gis2017 workshop report: the 3rd acm sigspatial international workshop on the use of gis in emergency management		Emergency management involves four stages: Planning and Mitigation, Preparedness, Response and Recovery. Geospatial applications (including GIS) have been extensively used in each stage of emergency management. Decision-makers can utilize the geospatial information to develop planning and mitigation strategies. GIS models and simulation capabilities are used to exercise response and recovery plans during non-disaster times. They help the decision-makers understand near real-time possibilities during an event. Once disaster occurs, GIS will take effect in real time response and recovery activities	geographic information system;real-time clock;real-time computing;simulation	Hui Zhang;Jean-Claude Thill;Yan Huang;Danhuai Guo;Yi Liu;Rui Yang	2017	SIGSPATIAL Special	10.1145/3178392.3178404	data science;emergency management;computer science	HCI	-16.727664975263078	-26.735060317512286	147649
18ead8effcb93f547e55e4d80ac4067c842a3924	efficient bitmap-based indexing of time-based interval sequences	bitmap based feature extraction;indexing and approximate query processing;t interval sequences;t;similarity search	In this paper, we discuss similarity searches for time series data represented as interval sequences. For instance, the time series of phone call records can be represented by time-based interval sequences, or T -interval sequences, which consist of the start and end times of the call records. To support an efficient similarity search for such sequences, we address the desirable semantics for similarity measures for the T -interval sequences, observe how existing measures fail to address such semantics, and propose a new measure that satisfies all our semantics. We then propose approximate encoding methods for T interval sequences. More specifically, we propose two bitmap-based feature extraction methods: (1) a bin-bitmap encoding method that transforms the T -interval sequences into bitmaps of fixed length, and (2) a segmented feature extraction method that takes the longest bitmap sequences of consecutive ‘1’ elements. Finally, we propose two query processing schemes using these bitmap-based approximate representations. We validate the efficiency and effectiveness of our proposed solutions empirically. 2011 Elsevier Inc. All rights reserved.	approximation algorithm;bitmap;database;fits;feature extraction;search algorithm;similarity measure;similarity search;synthetic data;time series	Jong-Won Roh;Seung-won Hwang;Byoung-Kee Yi	2012	Inf. Sci.	10.1016/j.ins.2011.08.013	teaspoon;computer science;data mining;database;information retrieval	DB	-8.502581162152069	-36.792037261559535	147695
7a365011424e2805661f2ecfbd8f25712f1cfd6c	prediction-based task assignment in spatial crowdsourcing	performance evaluation;data engineering;mobile handsets;crowdsourcing optimization mobile handsets performance evaluation conferences data engineering videos;optimization;crowdsourcing;conferences;videos	With the rapid advancement of mobile devices and crowdsourcing platforms, spatial crowdsourcing has attracted much attention from various research communities. A spatial crowdsourcing system periodically matches a number of locationbased workers with nearby spatial tasks (e.g., taking photos or videos at some specific locations). Previous studies on spatial crowdsourcing focus on task assignment strategies that maximize an assignment score based solely on the available information about workers/tasks at the time of assignment. These strategies can only achieve local optimality by neglecting the workers/tasks that may join the system in a future time. In contrast, in this paper, we aim to improve the global assignment, by considering both present and future (via predictions) workers/tasks. In particular, we formalize a new optimization problem, namely maximum quality task assignment (MQA). The optimization objective of MQA is to maximize a global assignment quality score, under a traveling budget constraint. To tackle this problem, we design an effective grid-based prediction method to estimate the spatial distributions of workers/tasks in the future, and then utilize the predictions to assign workers to tasks at any given time instance. We prove that the MQA problem is NPhard, and thus intractable. Therefore, we propose efficient heuristics to tackle the MQA problem, including MQA greedy and MQA divide-and-conquer approaches, which can efficiently assign workers to spatial tasks with high quality scores and low budget consumptions. Through extensive experiments, we demonstrate the efficiency and effectiveness of our approaches on both real and synthetic datasets.	assignment problem;crowdsourcing;display resolution;experiment;greedy algorithm;heuristic (computer science);local optimum;mathematical optimization;mobile device;np-hardness;optimization problem;synthetic intelligence	Peng Cheng;Xiang Lian;Lei Chen;Cyrus Shahabi	2017	2017 IEEE 33rd International Conference on Data Engineering (ICDE)	10.1109/ICDE.2017.146	simulation;information engineering;computer science;data science;data mining;database;crowdsourcing	DB	-14.372269071429425	-37.24446166305108	147936
0cae79b9c7fc1a86ff4f46e9ba603d128328fc52	iot based road travel time detection		Traffic congestion is not uniform across the metropolitan cities like Bengaluru, in India. Road travel time becomes unpredictable many a times. In this aspect, several prediction models have been built. All these models require data on a daily basis for training. IoT based model to collect the input data using sensors can be the best choice. The model can be placed on all vehicles easily with minimum or no modification. This paper presents four varieties of approaches to measure the time taken for the journey. The timestamp is calculated based on engine run time. The collected data is stored in a file as well as synchronized to cloud storage. In the case of the problem with internet connectivity, the data written down in the file would serve as a backup. Travel time modelling is constructed using various sensors. This also helps advanced traveller information systems. Inevitably there is need to combine and make the best out of the available. GPS can be used to identify the source, destination, and few cardinal values even in the absence of internet connectivity.		Roopa Ravish;Prajwal Nadagouda;Kiran Hombal;Lavanya Ramkumar;Priya Nayak;Preet Shah;R Jayakumar;P. Suresh;Shanta Rangaswamy	2018	2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2018.8554804	control engineering;timestamp;computer science;cloud storage;global positioning system;information system;computer network;cloud computing;internet access;backup;traffic congestion	Robotics	-17.43543344599423	-30.766263237382145	148073
1d8fdf0779b633e0875cea68214b77eac6fdcfe7	predicting urban problems: a comparison of graph-based and image-based methods				Shusaku Egami;Takahiro Kawamura;Akihiko Ohsuga	2018				Vision	-14.047127241946948	-29.03509818862811	148237
bb56d4e71c11947ca031d92dca36f3a23d484c3c	atomic wedgie: efficient query filtering for streaming time series	envelope based lower bounding atomic wedgie query filtering time series streaming;query processing;data stream;time series;data mining;filtering insects patient monitoring cardiology space technology computerized monitoring xml matched filters costs computer science;data mining query processing time series;intensive care;lower bound	In many applications, it is desirable to monitor a streaming time series for predefined patterns. In domains as diverse as the monitoring of space telemetry, patient intensive care data, and insect populations, where data streams at a high rate and the number of predefined patterns is large, it may be impossible for the comparison algorithm to keep up. We propose a novel technique that exploits the commonality among the predefined patterns to allow monitoring at higher bandwidths, while maintaining a guarantee of no false dismissals. Our approach is based on the widely used envelope-based lower bounding technique. Extensive experiments demonstrate that our approach achieves tremendous improvements in performance in the offline case, and significant improvements in the fastest possible arrival rate of the data stream that can be processed with guaranteed no false dismissal.	algorithm;brute-force search;concept drift;experiment;fastest;filter (signal processing);online and offline;population;queueing theory;scalability;time series	Li Wei;Eamonn J. Keogh;Helga Van Herle;Agenor Mafra-Neto	2005	Fifth IEEE International Conference on Data Mining (ICDM'05)	10.1109/ICDM.2005.28	real-time computing;computer science;machine learning;time series;data mining;database;mathematics;upper and lower bounds;statistics	DB	-7.957505467167379	-35.03348810625832	148361
cc5640b7efa3b7826e98483654ba58f93a508987	bayesian classifier for route prediction with markov chains		We present here a general framework and a specific algorithm for predicting the destination, route, or more generally a pattern, of an ongoing journey, building on the recent work of [1]. In the presented framework, known journey patterns are modelled as stochastic processes, emitting the road segments visited during the journey, and the ongoing journey is predicted by updating the posterior probability of each journey pattern given the road segments visited so far. In this contribution, we use Markov chains as models for the journey patterns, and consider the prediction as final, once one of the posterior probabilities crosses a predefined threshold. Despite the simplicity of both, examples run on a synthetic dataset demonstrate high accuracy of the made predictions.		Jonathan P. Epperlein;Julien Monteil;Mingming Liu;Yingqi Gu;Sergiy Zhuk;Robert Shorten	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569895	machine learning;naive bayes classifier;mathematics;posterior probability;artificial intelligence;stochastic process;markov chain	Robotics	-14.529015601794857	-31.278830455077664	148651
dfbe0c30772ec8927825586e1663e5d8cff08150	estimation of traffic flow using passive cell-phone data	financial stress diagnostics;financial stress indicators;fibo;snomed ct;big data;information governance ontologies	In this paper we present preliminary results for estimating traffic flow using passive cell-phone network information. Two datasets are considered: (a) passive cell-phone data and (b) information provided by the English Highways Agency. Our proposed method identifies cell phone users that are traveling by car and using a linear regression model, estimates the flow for each of the links in which the road network is divided. Initial results indicate, that, under certain conditions, traffic flow can be effectively approximated with passive network data.	approximation algorithm;emoticon;mobile phone	Vanessa Frías-Martínez;Benyounes Moumni;Enrique Frías-Martínez	2014		10.1145/2630729.2630739	engineering;data science;data mining;computer security	Mobile	-17.510077619586426	-31.076103165538253	148725
52032bb1547b859bc4e74f671a74869173c7b1c4	improving data quality: consistency and accuracy	statistical method;satisfiability;functional dependency;automatic generation;integrity constraints;data quality;data consistency;user interaction	Two central criteria for data quality are consistency and ac curacy. Inconsistencies and errors in a database often emerge as vio l tions of integrity constraints. Given a dirty database D, one needs automated methods to make it consistent , i.e., find a repairD that satisfies the constraints and “minimally” differs from D. Equally important is to ensure that the automatically-generated re pai D is accurate, or makes sense, i.e.,D differs from the “correct” data within a predefined bound. This paper studies effective meth ods for improving both data consistency and accuracy. We employ a cl ass of conditional functional dependencies (CFDs) proposed in [6] to specify the consistency of the data, which are able to captur e inconsistencies and errors beyond what their traditional cou nterparts can catch. To improve the consistency of the data, we propose two algorithms: one for automatically computing a repair D that satisfies a given set of CFDs, and the other for incrementally finding a repair in response to updates to a clean database. We show tha t bo problems are intractable. Although our algorithms are nece ssarily heuristic, we experimentally verify that the methods are ef f ctive and efficient. Moreover, we develop a statistical method tha t gu rantees that the repairs found by the algorithms are accurate above a predefined ratewithout incurring excessive user interaction.	algorithm;call of duty: black ops;data integrity;data quality;experiment;functional dependency;heuristic;np-completeness;plasma cleaning;real life;referential integrity	Gao Cong;Wenfei Fan;Floris Geerts;Xibei Jia;Shuai Ma	2007			weak consistency;data quality;computer science;theoretical computer science;consistency model;data integrity;data mining;database;functional dependency;data consistency;sequential consistency;satisfiability	DB	-7.723668640164155	-32.71277757784986	148738
649530b47c40c06cbad4fe8cf823874be1f5468c	reusability of the output of map-matching algorithms across space and time through machine learning	gps error map matching algorithm spatial temporal pattern machine learning;global positioning system machine learning algorithms encoding training satellites receivers	A map-matching algorithm outputs a vector per GPS point, projecting the moving object on one of the segments of the transportation network. Although developing more sophisticated map-matching algorithms for vehicle and pedestrian navigation systems have been the focus of research in this field, reusability of the historical information already provided by map-matching algorithms has not been addressed yet. In other words, although researchers have been attempting to improve the accuracy of the aforementioned vector to correctly project GPS points on the transportation network, no research has exploited the spatial-temporal pattern in the arrangement of these projection vectors. This pattern, if properly detected, can be used as a rough surrogate for map-matching algorithms, in addition to other applications that require better positional accuracy for moving objects in smart cities. This paper detects and validates the spatial-temporal pattern in projection vectors produced by map-matching algorithms via machine learning. Projection vectors showed a strong spatial-temporal pattern in Chicago, IL, USA, which was captured best via a local nonlinear regressor, K-nearest neighbors, and helped double the positional accuracy of unseen GPS points. While a global nonlinear regressor, multilayer Perceptron was able to slightly improve the positional accuracy of GPS points, the linear least squares had an exacerbating effect on the positional accuracy.	global positioning system;k-nearest neighbors algorithm;linear least squares (mathematics);machine learning;map matching;multilayer perceptron;nonlinear system;smart city;spatiotemporal pattern	Mahdi Hashemi	2017	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2017.2669085	spacetime;flow network;simulation;computer vision;global positioning system;nonlinear system;multilayer perceptron;algorithm;map matching;machine learning;linear least squares;computer science;reusability;artificial intelligence	ML	-15.8081236349947	-33.08513312616624	148764
6d537e3fac64a1c30b7c24d747e19af7d975186c	mapreduce and semantics enabled event detection using social media		Social media is playing an increasingly important role in reporting major events happening in the world. However, detecting events from social media is challenging due to the huge magnitude of the data and the complex semantics of the language being processed. This paper proposes MASEED (MapReduce and Semantics Enabled Event Detection), a novel event detection framework that effectively addresses the following problems: 1) traditional data mining paradigms cannot work for big data; 2) data preprocessing requires significant human efforts; 3) domain knowledge must be gained before the detection; 4) semantic interpretation of events is overlooked; 5) detection scenarios are limited to specific domains. In this work, we overcome these challenges by embedding semantic analysis into temporal analysis for capturing the salient aspects of social media data, and parallelizing the detection of potential events using the MapReduce methodology. We evaluate the performance of our method using real Twitter data. The results will demonstrate the proposed system outperforms most of the state-of-the-art methods in terms of accuracy and efficiency.	algorithm;big data;data mining;data pre-processing;distributed computing;graphical user interface;mapreduce;parallel computing;preprocessor;scalability;semantic interpretation;sensor;social media;time series	Peng Yan	2017	J. Artif. Intell. Soft Comput. Res.	10.1515/jaiscr-2017-0014	computer science;social media;semantics;distributed computing	AI	-11.67911445078724	-34.7840243271821	148920
550aa0ccf873541eb46fdf7dab344dc74009ce77	mining extremes: severe rainfall and climate change		Theoretical developments for the analysis and modeling of extreme value data have tended to focus on limiting cases and assumptions of independence. However, massive datasets from models and sensors, space-time dimensionality, complex dependence structures, long-memory, long-range and low frequency processes all motivate the need for sophisticated methods for correlated and finite data that follow complex processes. The importance of extremes has been rapidly growing in areas ranging from climate change and critical infrastructures to insurance and financial markets. Here we briefly discuss the stateof-the-art and key gaps, through the case of rainfall extremes under climate change. Preliminary analysis suggests new directions and points to research areas that deserve further attention.	maxima and minima;sensor	Debasish Das;Evan Kodra;Zoran Obradovic;Auroop R. Ganguly	2012		10.3233/978-1-61499-098-7-899	computer science;artificial intelligence;machine learning;financial market;agricultural economics;precipitation;curse of dimensionality;extreme value theory;limiting;ranging;climate change	ML	-17.56860181599395	-25.317734190713075	148932
243bf15a9d7b2b1bd59ea39b525f42452b5d24b2	online segmentation algorithm for time series based on birch clustering features	birch clustering features;pattern clustering;complexity theory;time complexity;osbc algorithm online segmentation algorithm time series birch clustering features data representation data mining pattern clustering;approximation algorithms;time series analysis clustering algorithms complexity theory merging approximation algorithms presses partitioning algorithms;time series data mining;online segmentation algorithm time series birch clustering features;presses;time series;data mining;data representation;time series analysis;data structures;very large databases data structures pattern clustering time series;merging;space complexity;clustering algorithms;time series data;online segmentation algorithm;very large databases;partitioning algorithms;osbc algorithm	Online time series data representation is one of important problems of time series data mining. The adjacent points of time series are inherently depended and hence have similar clustering features. Based on BIRCH clustering features, we present a new kind of OSBC algorithm for time series segmentation in this paper. Using cluster features, OSBC algorithm can find easily the changing patterns of time series and achieve better segmentation results. The time complexity of OSBC algorithm is linear and its space complexity is also much smaller. The experiment results on time series benchmark show the effectiveness of our method.	algorithm;birch;benchmark (computing);cluster analysis;dspace;data (computing);data mining;time complexity;time series	Yu Tu;Yubao Liu;Zhijie Li	2010	2010 International Conference on Computational Intelligence and Security	10.1109/CIS.2010.19	data structure;computer science;machine learning;time series;pattern recognition;data mining;approximation algorithm;statistics	ML	-4.617973253483853	-37.31281482037892	148974
dc1c537f9cd7647c46587db47954890121732dda	anomaly detection models for iot time series data		Insitu sensors and Wireless Sensor Networks (WSNs) have become more and more popular in the last decade, due to their potential to be used in various applications of many different fields. As of today, WSNs are pretty much used by any monitoring system: from those that are health care related, to those that are used for environmental forecasting or surveillance purposes. All applications that make use of insitu sensors, strongly rely on their correct operation, which however, is quite difficult to guarantee. These sensors in fact, are typically cheap and prone to malfunction. Additionally, for many tasks (e.g. environmental forecasting), sensors are also deployed under potentially harsh weather condition, making their breakage even more likely. The high probability of erroneous readings or data corruption during transmission, brings up the problem of ensuring quality of the data collected by sensors. Since WSNs have to operate continuously and therefore generate very large volumes of data every day, the quality control process has to be automated, scalable and fast enough to be applicable to streaming data. The most common approach to ensure the quality of sensors data, consists in automated detection of erroneous readings or anomalous behaviours of sensors. In the literature, this strategy is known as anomaly detection and can be pursued in many different ways.	anomaly detection;capsule endoscopy;health care;projections and predictions;reading (activity);scalability;stream (computing);time series;sensor (device)	Federico Giannoni;Marco Mancini;Federico Marinelli	2018	CoRR			Security	-11.944633272742376	-32.86644545059652	149089
e34e470f493ec0818f5f2dca3a2764b4c641e62b	analysing health risks from air pollution effects in saxony, germany		This article presents the approach and current findings of the EO2HEAVEN project, in particular from the Saxony Case Study. The aim of the Case Study is the conceptual design of a Spatial Information Infrastructure for better understanding the complex relationship between ambient air quality and its influence on the human health. This includes air quality modelling and a statistical analysis of health datasets as well as the development of a service infrastructure offering access, analysis and visualization of environmental and health information.	atmospheric dispersion modeling;international standard book number;linkage (software);real-time clock;risk assessment	Silke Richter;Stefan Wiemann;Pierre Karrasch;Daniel Kadner;Johannes Brauner;Joachim Siegert;Julia Rossmann;Bernhard Elsner;Jana Arloth	2012			environmental planning;geography;environmental protection;environmental resource management	HCI	-14.684309070749839	-24.181690317370535	149197
18ec275d53f9de60ec8dcb77d6e9ca36aeba3761	an improved data cleaning algorithm based on snm		The basic sorted-neighborhood method (SNM) is a classic algorithm to detect approximately duplicate records in data cleaning, but the drawback is that the size of sliding window is hard to select and the attribute matching is too frequent so the detection efficiency is unfavorable. An optimized algorithm is proposed based on SNM By setting the size and speed of the sliding window variable to avoid missing record comparisons and reduce unnecessary ones, also it uses cosine similarity algorithm in attribute matching to improve precision of detection, and the Top-k effective weight filtering algorithm is proposed to reduce the number of attribute matching and improve the detection efficiency. The experiment results show that the improved algorithm is better than SNM in recall rate, precision rate and execution time efficiency.		Miao Li;Qiang Xie;Qiulin Ding	2015		10.1007/978-3-319-27051-7_22	computer science;sliding window protocol;algorithm;cosine similarity;filter (signal processing)	DB	-7.012938747675255	-36.37904717048018	149384
f4a480acd76d9d5d5ec0f5435a7e194b823e0d4e	comparing predictive ability of classifiers in forecasting online buying behaviour: an empirical study	support vector machines;online buying;logistic regression;random forest;artificial neural network;predicting buying behaviour	With Internet invading geographic boundaries and diverse demographic strata, online shopping is growing at exponential rate. Expected to grow by 45 per cent to $7.69 billion by the end of 2015, India's ecommerce market has emerged as one of the most anticipated destinations for both multinational and domestic retailers. Since their success will depend on their ability to attract shoppers to buy online, it becomes relevant for them to decipher Indian consumers' attitude and behaviour towards online shopping and to predict online buying potential in India. The effectiveness of marketing and promotional strategies and action plans also will have to be pivoted around the potential available in the market. This empirical study explores the accuracy, precision and recall of four different classifying techniques used in predicting online buying. The forecasting ability of logistic regression LR, artificial neural network ANN, support vector machines SVM and random forest RF in the context of willingness of shoppers' to buy online has been compared. Analysis of the data supported most of the predictions albeit with varying level of accuracy. The outcome of the study reflects the superiority of artificial neural network over the other three models in terms of the predicting power. This paper adds to the knowledge body for online retailers in reducing their vulnerability with respect to market demand and improves their preparedness to handle the market response. Managerial implications of the findings and scope for future research have been deliberated.		Sanjeev Prashar;S. K. Mitra	2015	IJSDS	10.4018/IJSDS.2015100104	random forest;support vector machine;computer science;artificial intelligence;marketing;operations management;machine learning;data mining;logistic regression;advertising;operations research;artificial neural network	ML	-9.387316334196717	-30.547744277817777	149427
809c582754293aaa8e2eab394a326262f40af15c	utilizing multilevel models and reasoning for diagnosis of a complex electro-mechanical system	qualitative modeling;qualitative reasoning;multilevel model;mechanical systems;control strategy	A multi-level system which utilizes both an evidential and a qualitative model for diagnosing fault symptoms in complex electro-mechanical systems is presented. The operation of both models, enhancement by a historical database, and the global control strategy are all discussed. In addition, the constraining of qualitative reasoning with information from the evidential session and the enhancement of the evidential model with information from the qualitative model is demonstrated.	control theory;multilevel model	John A. Smith;Gautam Biswas	1989		10.1145/66617.66638	qualitative reasoning;computer science;knowledge management;artificial intelligence;multilevel model;machine learning;evidential reasoning approach;mechanical system	AI	-7.1162901600751525	-24.144492313242726	149792
5aec6d6b29fa245e9c1ef813b68a645afc3bb237	investors' attention and overpricing of ipo: an empirical study on china's growth enterprise market		In China, the Growth Enterprise Market (GEM) is a brand new market that provides an additional way of financing for firms with good growth potential. Whereas there has been a massive amount of stocks breaking on the first trading day since 2010, the risk of IPO’s overpricing in China’s GEM has drawn more and more attention in recent years. Based on the theory of behavioral finance and limited attention, investors’ attention may be a quite indicative determinant to the IPO overpricing. Accordingly, we collected data from Internet including online stock forums and search engines, then built multiple investors’ attention metrics that were distinct to the traditional metrics from the offline stock market. In the empirical study, we built regression models to dig out the determinants of IPO’s overpricing and found that the hybrid model containing both online metrics and financial metrics outperformed the others considerably. The adjusted R-square of the hybrid model containing both online metrics and financial metrics is as high as 82.8%, in contrast to 18.2% for the model containing only the financial metrics and 59.3% for that containing only investors’ attention.		Hailiang Huang;Yanhong Li;Yingying Zhang	2018	Inf. Syst. E-Business Management	10.1007/s10257-017-0351-1	empirical research;computer science;marketing;the internet;initial public offering;china;behavioral economics;stock market;text mining	DB	-9.278915860793408	-30.7324739456626	150041
bf6a696d3901e8dcecc7bcd2a19b1e0a6aff9289	detecting trajectory outliers based on spark		Detecting outliers in massive trajectory data is helpful to discover anomalous events and understand human mobility. Traditional trajectory outlier detection methods are inadequate in dealing with massive data. Researchers have studied several ways to introduce distributed solutions to outlier detecting, trying to enhance massive data process efficiency. But most of these methods employ MapReduce model. Spark, on the other hand, is proven to be better in terms of time. So, in this paper, Spark platform is utilized to present a trajectory outlier detection method. The key technologies focus on trajectory data management, preprocessing, and the parallel strategies of trajectory outlier detection in a global perspective of the procedure. An experiment is further conducted to test the proposed approach. The result indicates that the suggested method is valid to detect trajectory outlier in terms of the accuracy and efficiency.	anomaly detection;experiment;mapreduce;preprocessor;sensor	Yuanyuan Chen;Jingyi Yu;Yong Gao	2017	2017 25th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2017.8090919	data mining;big data;computer science;outlier;anomaly detection;spark (mathematics);data management;trajectory;data processing	DB	-11.513939348580664	-34.90325009138893	150194
0b5ea622e249f27aaeecf4200fb6e10943828ce6	data quality in data warehouses	data quality;data warehouse	Fayyad and Uthursamy (2002) have stated that the majority of the work (representing months or years) in creating a data warehouse is in cleaning up duplicates and resolving other anomalies. This paper provides an overview of two methods for improving quality. The first is record linkage for finding duplicates within files or across files. The second is edit/imputation for maintaining business rules and for filling-in missing data. The fastest record linkage methods are suitable for files with hundreds of millions of records (Winkler, 2004a, 2008). The fastest edit/imputation methods are suitable for files with millions of records (Winkler, 2004b, 2007a).	data quality;fastest;geo-imputation;linkage (software);missing data;plasma cleaning	William E. Winkler	2009			data mining;data warehouse;business;data quality	DB	-6.316789406945436	-33.87982876985992	150519
4b2329cc2def72d94ae28731f2c19aa2016d1609	a novel group ranking model for revealing sequence and quantity knowledge	data mining;linguistic terms;group ranking;quantitative data;sequential data	The aggregation of individuals’ preferences into a consensus ranking is a group ranking problem which has been widely utilized in various applications, such as decision support systems, recommendation systems, and voting systems. Gathering the comparison of preferences and aggregate them to gain consensuses is a conventional issue. For example, b > c P d P a indicates that b is favorable to c, and c (d) is somewhat favorable but not fully favorable to d (a), where > and P are comparators, and a, b, c, and d are items. Recently, a new type of ranking model was proposed to provide temporal orders of items. The order, b&c ? a, means that b and c can occur simultaneously and are also before a. Although this model can derive the order ranking of items, the knowledge about quantity-related items is also of importance to approach more real-life circumstances. For example, when enterprises or individuals handle their portfolios in financial management, two considerations, the sequences and the amount of money for investment objects, should be raised initially. In this study, we propose a model for discovering consensus sequential patterns with quantitative linguistic terms. Experiments using synthetic and real datasets showed the model’s computational efficiency, scalability, and effectiveness. 2013 Elsevier B.V. All rights reserved.	aggregate data;algorithm;cesg claims tested mark;coffee meets bagel;comparator;computation;decision support system;dhrystone;experiment;futures and promises;guardian service processor;internet;money;performance;real life;recommender system;run time (program lifecycle phase);scalability;synthetic intelligence	Tony Cheng-Kui Huang	2013	European Journal of Operational Research	10.1016/j.ejor.2013.06.054	quantitative research;computer science;data science;machine learning;data mining;mathematics	AI	-5.472005426196371	-34.28544840578781	150613
2ffa0a370d4be120b9b3352d578d56fa365b0a2c	an efficient incremental mining algorithm-qsd	incremental mining;data mining;frequent itemset;association rule	The generation of frequent itemsets is an essential and time-consuming step in mining association rules. Most of the studies adopt the Apriori-based approach, which has great effort in generating candidate itemsets and needs multiple database accesses. Recent studies indicate that FP-tree approach has been utilized to avoid the generation of candidate itemsets and scan transaction database only twice, but they work with more complicated data structure. Besides, it needs to adjust the structure of FP-tree when it applied to incremental mining application. It is necessary to adjust the position of an item upward or downward in the structure of FP-tree when a new transaction increases or decreases the accumulation of the item. The process of the adjustment of the structure of FP-tree is the bottlenecks of the FP-tree in incremental mining application. Therefore, algorithms for efficient mining of frequent patterns are in urgent demand.#R##N##R##N#This paper aims to improve both time and space efficiency in mining frequent itemsets and incremental mining application. We propose a novel QSD (Quick Simple Decomposition) algorithm using simple decompose principle which derived from minimal heap tree, we can discover the frequent itemsets quickly under one database scan. Meanwhile, QSD algorithm doesn't need to scan database and reconstruct data structure again when database is updated or minimum support is varied. It can be applied to on-line incremental mining applications without any modification.#R##N##R##N#Comprehensive experiments have been conducted to assess the performance of the proposed algorithm. The experimental results show that the QSD algorithm outperforms previous algorithms.	algorithm	Jen-Peng Huang;Show-Ju Chen;Huang-Cheng Kuo	2007	Intell. Data Anal.		gsp algorithm;association rule learning;computer science;data science;data mining;database	ML	-5.451782076875264	-36.89884461449997	150614
6f0c1d8378f550ebd4d3b71fc33ed79e96bfed8e	sensing and classifying roadway obstacles: the street bump anomaly detection and decision support system	anomaly detection;smart cities classification anomaly detection machine learning;classification;smart cities;support vector machines cities and towns logistics entropy decision support systems indexes vehicles;machine learning;smart phones collision avoidance decision support systems learning artificial intelligence pattern classification road traffic smart cities;anomaly index roadway obstacle street bump anomaly detection decision support system street bump smartphone application machine learning algorithm classification algorithm	We develop an anomaly detection and decision support system based on data collected through the Street Bump smartphone application. The system is capable of effectively classifying roadway obstacles into predefined categories using machine learning algorithms, as well as identifying actionable ones in need of immediate attention based on a proposed “anomaly index.” We introduce appropriate regularization to the classification algorithms we employ, which has the effect of utilizing a sparse set of relevant features to perform the classification. Further, our novel “anomaly index” allows us to prioritize among actionable obstacles. Results on an actual data set provided by the City of Boston illustrate the feasibility and effectiveness of our system in practice.	algorithm;anomaly detection;bump mapping;decision support system;machine learning;mobile app;sparse language;sparse matrix;thermal copper pillar bump	Theodora S. Brisimi;Setareh Ariafar;Yue Zhang;Christos G. Cassandras;Ioannis Ch. Paschalidis	2015	2015 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2015.7294276	simulation;engineering;data mining;computer security	Robotics	-16.635538017038925	-31.741292267744516	150876
3e81ccdab8d4f32734e371f6ab34c3091dd607be	spatial co-location pattern mining for location-based services in road networks	location based services;network space;network analysis;spatial data mining;spatial co location patterns	With the evolution of geographic information capture and the emergency of volunteered geographic information, it is getting more important to extract spatial knowledge automatically from large spatial datasets. Spatial co-location patterns represent the subsets of spatial features whose objects are often located in close geographic proximity. Such pattern is one of the most important concepts for geographic context awareness of location-based services (LBS). In the literature, most existing methods of co-location mining are used for events taking place in a homogeneous and isotropic space with distance expressed as Euclidean, while the physical movement in LBS is usually constrained by a road network. As a result, the interestingness value of co-location patterns involving network-constrained events cannot be accurately computed. In this paper, we propose a different method for co-location mining with network configurations of the geographical space considered. First, we define the network model with linear referencing and refine the neighborhood of traditional methods using network distances rather than Euclidean ones. Then, considering that the co-location mining in networks suffers from expensive spatial-join operation, we propose an efficient way to find all neighboring object pairs for generating clique instances. By comparison with the previous approaches based on Euclidean distance, this approach can be applied to accurately calculate the probability of occurrence of a spatial co-location on a network. Our experimental results from real and synthetic data sets show that the proposed approach is efficient and effective in identifying co-location patterns which actually rely on a network. © 2015 Published by Elsevier Ltd.	context awareness;data mining;euclidean distance;information capture;location-based service;network model;synthetic data;volunteered geographic information	Wenhao Yu	2016	Expert Syst. Appl.	10.1016/j.eswa.2015.10.010	network analysis;computer science;artificial intelligence;data science;machine learning;location-based service;data mining;spatial network	DB	-16.341006515125418	-35.886455865958695	150882
9d97940e8a89005ca9970e51a74b13f67f978a74	efficient recovery of missing events	efficient recovery;existing recovery approach;top-k recovery;event data;complex event processing;minimum recovery approach;missing event;recovery problem;data quality;recovery efficiency;event sequence	For various entering and transmission issues raised by human or system, missing events often occur in event data, which record execution logs of business processes. Without recovering the missing events, applications such as provenance analysis or complex event processing built upon event data are not reliable. Following the minimum change discipline in improving data quality, it is also rational to find a recovery that minimally differs from the original data. Existing recovery approaches fall short of efficiency owing to enumerating and searching over all of the possible sequences of events. In this paper, we study the efficient techniques for recovering missing events. According to our theoretical results, the recovery problem appears to be NP-hard. Nevertheless, advanced indexing, pruning techniques are developed to further improve the recovery efficiency. The experimental results demonstrate that our minimum recovery approach achieves high accuracy, and significantly outperforms the state-of-the-art technique for up to five orders of magnitudes improvement in time performance.	backtracking;business process;complex event processing;computation;control flow;data quality;np-hardness;plasma cleaning;process (computing);programming paradigm;reachability	Jianmin Wang;Shaoxu Song;Xiaochen Zhu;Xuemin Lin	2013	IEEE Transactions on Knowledge and Data Engineering	10.14778/2536206.2536212	real-time computing;data mining;statistics	DB	-8.376619584644178	-36.5673290356987	151134
351ccdaa92b7268ae8c96bd2dec036ca65f53c9f	dual direction transmission model based on environment sensitive virtual plants	biology computing;forestry;resource competition;trees mathematics;virtual plant;virtual forest dual direction transmission model environment sensitive virtual plants resource competition binary tree l system expression logical relationship context search virtual agriculture;plant growth;agriculture;l system;virtual environment;binary tree virtual plant l system;computational modeling binary trees analytical models computer science plants biology production computer simulation agriculture context modeling helium;botany;trees mathematics agriculture biology computing botany forestry;binary tree	In this paper, dual direction transmission model is put forward to realize the simulation of environment sensitive virtual plants and the resource competition. Binary tree is introduced to store the expression of L system that make it is easer to get the logical relationship among nodes which close to each other. Experiment result shows that context search in the process of virtual plants growth is simplified and the relationship among plants in virtual environment is more natural.	binary tree;simulation;taito l system;virtual reality	Wei He;Yunfei Li	2009	2009 International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2009.236	agriculture;simulation;binary tree;computer science	HPC	-14.042680180989061	-25.612452134608642	151288
920227791a69ebb9b25a48e6ddcc6982c8ff6bf9	travel time prediction using multi-layer feed forward artificial neural network	artificial neural network travel time prediction;travel time;cellular radio;googlemap multilayer feed forward artificial neural network traffic jam bangkok gprs technologies gps data travel time prediction model ann model rush hour traffic non rush hour data;artificial neural networks;roads;global positioning system;web sites;traffic engineering computing;predictive models;feedforward neural nets;vehicles;artificial neural networks vehicles predictive models roads global positioning system data models real time systems;prediction;web sites cellular radio feedforward neural nets global positioning system traffic engineering computing;artificial neural network;data models;real time systems	Traffic jam is a major problem in Bangkok and nearby provinces in Thailand. Currently, there have been several attempts to solve this elevating problem by using GPS together with GPRS technologies in tracking and collecting traffic data from vehicles. In this work, we obtained one-month records of GPS data from 297 volunteered vehicles. Using vehicles' velocity as input, we have developed a travel time prediction model using artificial neural network. However, due to the enormous amount of database, we focus on testing our model on a certain major road, inbound of Hwy35 or Thonburi-Paktor. We applied our ANN model in predicting travel time during rush-hour traffic in the morning/evening and non-rush hour traffic on the weekday and weekend. The predicted results from the proposed model can accurately approximate the actual travel time. Furthermore, the predicted travel time during non-rush hour data set are very close to the predicted travel time provided by GoogleMap.	approximation algorithm;artificial neural network;global positioning system;inbound marketing;jam;velocity (software development)	Nawaporn Wisitpongphan;Watchareewan Jitsakul;Duangporn Jieamumporn	2012	2012 Fourth International Conference on Computational Intelligence, Communication Systems and Networks	10.1109/CICSyN.2012.67	data modeling;simulation;global positioning system;prediction;telecommunications;computer science;machine learning;predictive modelling;artificial neural network	Robotics	-17.10813019443948	-32.017157468407596	151318
312d5bc0b4fd7f04d67ae57d35549e1d3798cdac	simulation the bph spread with the impact of their natural enemies based on cellular automata and predator-prey model	green products;predator prey systems;biological system modeling;automata;humidity;agriculture;modeling	The article introduces the application of the Cellular Automata and Predator-Prey model to simulate effects of natural enemies to the growth and spread of the brown planthopper in rice fields. The article also mentions the use of GIS data for spatial simulation, thus helping the simulating results more visual and more realistic. The model can support prediction and prevention based on natural enemies hoppers without affecting the ecological environment and less costly. The results of the model is tested with real data about BPH in Dong Thap in 2010.	cellular automaton;experiment;geographic information system;prey;simulation	Ong Thi My Linh;Huong Hoang Luong;Lu Thanh Quy;Nguyen Cong Huy;Hiep Xuan Huynh	2016	2016 Eighth International Conference on Knowledge and Systems Engineering (KSE)	10.1109/KSE.2016.7758040	agriculture;simulation;computer science;humidity	Robotics	-14.024833728025026	-25.240378146956974	151422
4d8a0e116bf8cd100a632bb93df9854af72a34bb	multidimensional data model for air pollution data analysis		A large volume of data being gathered and stored in a file is a remarkable rate. The administration and handling of an enormous amount of data consume a lot of time and space. Therefore, the procedure to store, maintain, analyze with an easy and useful format is an essential task. We describe a multidimensional data model to store, group and analyze for decision making with meaningful information from historical and current data. In this paper STAR schema and SNOWFLAKE schema for the multidimensional data model is proposed for organizing the data obtained from Taiwan Air Quality Monitoring Network (TAQMN). In the data model, there is a fact table, three dimensional tables and other parameters such as Min, Max, Mean, StdDev, and coefficient variation are considered as computational measures. The measures are analyzed for an effective decision making or knowledge discovery.		Doreswamy;K.S Harishkumar	2018	2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2018.8554621	knowledge extraction;computer science;control engineering;fact table;star schema;data mining;data model;standard deviation;data warehouse;snowflake schema;data modeling	DB	-5.288325152225479	-27.708429222540612	151826
685c57658ab7ca8dc60f59a2b1838fa609f4c3fa	mining and ranking association rules in support, confidence, correlation, and dissociation framework		Existing methods in association rule mining based on traditional support-confidence framework generates huge number of frequent patterns and association rules often ignoring the dissociation among items. Moreover these procedures are unable to order the rules by comparing them to find which one is better than whom. We have introduced a new algorithm for mining frequent patterns based on support and dissociation and thereafter generating rules based on confidence and correlation. The association rules have been ranked based on a composite index computed from the four measures. The experimental results obtained after implementation of the proposed algorithm justify our approach.		Subrata Datta;Subrata Bose	2015		10.1007/978-81-322-2695-6_13	machine learning;pattern recognition;data mining	DB	-5.444858110573883	-35.961209856242675	151945
636ab687df202dc40fbd80c28aa770698405a677	a new approach to semantic computing with interval matrix decomposition for interpreting deforestation phenomenon				Irene Erlyn Wina Rachmawan;Yasushi Kiyoki	2018		10.3233/978-1-61499-933-1-353		AI	-5.472032077756304	-27.07459330243172	152989
233a83ed0d0c84b7ff5a4123ed5c3299d229ee0d	predicting travel times with context-dependent random forests by modeling local and aggregate traffic flow	intelligent gps navigation;automobiles;travel time;random forest traffic prediction;training;traffic prediction;simulation framework;automated highways;prediction algorithms;traffic flow;travel times prediction;traffic information systems automated highways automobiles global positioning system;road segments mean speed;traffic information systems;roads;global positioning system;aggregates;principal component analysis;random forest;context dependent random forests;roads global positioning system aggregates predictive models prediction algorithms principal component analysis training;context dependent;predictive models;tomtom traffic prediction;aggregate traffic flow modeling;intelligent gps navigation travel times prediction context dependent random forests aggregate traffic flow modeling road segments mean speed tomtom traffic prediction	Predicting future traffic flow has the potential to decrease travel times. This paper describes a methodology developed to predict future travel times based on GPS reports of 1% of the cars on the road in a simulation framework. Features representing local and aggregate models of traffic flow were extracted from these reports. These included the counts of moving and stopped cars in different areas, along with each road segment’s mean speed. Context-dependent Random Forests were then trained to predict traffic flow six and thirty minutes into the future. This algorithm performed best in one track of the 2010 IEEE ICDM Contest: Tom Tom Traffic Prediction for Intelligent GPS Navigation, improving 9% on the next-best algorithm and 62.5% on the baseline.	aggregate data;aggregate function;algorithm;baseline (configuration management);comefrom;context-sensitive language;gps navigation device;global positioning system;random forest;simulation;tom	Benjamin Hamner	2010	2010 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2010.128	random forest;simulation;global positioning system;prediction;computer science;machine learning;context-dependent memory;traffic flow;predictive modelling;principal component analysis	Robotics	-16.57232690755731	-30.762497944591356	153207
5e168173d8b746209ff7830f6fe7aac1c9b32388	fishing monitor system data: a naïve bayes approach		— This paper discusses the results of an applied research on the fishing activity based on a monitor system developed by a company and fishing reports produced at the end of each fishing activity. Due to economic interests combined with fishing limitations there is a natural tendency for wrong reporting. We apply Data Mining (DM) methodologies to find fishing patterns. These DM techniques in SQL tool allow to deal with the high volume of this data set and determine the major factors that influence fishing activity.	data mining;naive bayes classifier;report;sql	João C. Ferreira;Serge Lage;Iola Pinto;Nuno Antunes	2016		10.1007/978-3-319-53480-0_57	machine learning;naive bayes classifier;fishing;artificial intelligence;sql;data mining;computer science;applied research	ML	-8.895861526723387	-30.705786859073545	153254
1f558a345234a1ca791b6ea60cfe74e3dd0b63f7	towards human mobility extraction based on social media with complex event processing	urban dynamics;geo tagged document human mobility extraction social media complex event processing soft sensor iot paradigm personal mobility mining smart phone personal mobility pattern social network sites;complex event processing;twitter;social media;social networking online internet of things mobile computing smart phones;sensors media mobile communication smart phones data mining social network services servers;complex event processing social media twitter urban dynamics	Social media has enabled a new breed of soft sensors that enriches the IoT paradigm with new forms of data. The present work introduces a novel approach for personal mobility mining that combines these new data-sources with built-in sensors of a smart-phone in order to timely extract personal mobility pattens by means of the Complex Event Processing (CEP) approach. Unlike previous solutions, the present work profits from both the textual and location data of social-network sites by also dealing with the actual scarcity of geo-tagged documents in those sites. Finally, a preliminary study of the feasibility of our proposal is stated.	canonical account;complex event processing;online algorithm;programming paradigm;sensor;smartphone;social media;social network	Fernando Terroso-Saenz;Mercedes Valdés-Vela;Antonio F. Gómez-Skarmeta	2015	2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)	10.1109/WF-IoT.2015.7389094	social media;social media optimization;computer science;complex event processing;internet privacy;world wide web;computer security;computer network	HCI	-18.300955165523117	-36.28782348779871	153357
64f33ed698c1e44067fe524db99feede7ccae2af	efficient collection of connected vehicle data based on compressive sensing*		Connected vehicles (CVs) can capture and transmit detailed data like vehicle position, speed and so on through vehicle-to-vehicle and vehicle-to-infrastructure communications. The wealth of CV data provides new opportunities to improve the safety, mobility and sustainability of transportation systems. However, the potential data explosion likely will overburden storage and communication systems. To solve this issue, we design a real-time compressive sensing (CS) approach which allows CVs to collect and compress data in real-time and can recover the original data accurately and efficiently when it is necessary. The CS approach is applied to recapture 10 million CV Basic Safety Message speed samples from the Safety Pilot Model Deployment program. With a compression ratio of 0.2, it is found that the CS approach can recover the original speed data with the root mean-squared error as low as 0.05. The recovery performances of the CS approach are further explored by time-of-day and acceleration. The results show that the CS approach performs better in data recovery when CV speeds are steady or changing smoothly.		Lei Lin;Srinivas Pccta;Jian Wang	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8570007		Robotics	-15.853858413614391	-33.89183464824161	153491
c890ee7fd279ab9fef8cb7e763d6e5be6099db49	conditional log-linear models for mobile application usage prediction		Over the last decade, mobile device usage has evolved rapidly from basic calling and texting to primarily using applications. On average, smartphone users have tens of applications installed in their devices. As the number of installed applications grows, finding a right application at a particular moment is becoming more challenging. To alleviate the problem, we study the task of predicting applications that a user is most likely going to use at a given situation. We formulate the prediction task with a conditional log-linear model and present an online learning scheme suitable for resource-constrained mobile devices. Using real-world mobile application usage data, we evaluate the performance and the behavior of the proposed solution against other prediction methods. Based on our experimental evaluation, the proposed approach offers competitive prediction performance with moderate resource needs.	archive;cloud computing;definite clause grammar;gradient descent;in the beginning... was the command line;kerrison predictor;linear model;log-linear model;machine learning;microsoft outlook for mac;mobile app;mobile device;privacy;server (computing);smartphone;usage data;virtual private server	Jingu Kim;Taneli Mielikäinen	2014		10.1007/978-3-662-44848-9_43	simulation;computer science;data mining;world wide web	Mobile	-19.103404428515017	-37.26232579557759	153643
543408b3b3a6b725958fd394390d89ef3c381545	analysis of the emission of american depositary receipts of brazilian companies through the extraction of linguistic summaries	pragmatics;itemsets;itemsets companies stock markets pragmatics data mining security;data mining;companies;stock markets;security	The cross-listing mechanism enables that companies collect funds and investors invest in capital markets of foreign countries. Among the objectives are the increase in the liquidity, the reduction of the risk and of the capital cost. In this context, this paper analyses the relationship of dually listed stocks of Brazilian companies, simultaneously traded on the São Paulo stock Exchange and New York Exchange, through American Depositary Receipts (ADR). In this sense, we evaluate which of the markets has the greatest influence on the pricing of those assets. For this purpose, we extract knowledge in the form of linguistic summaries representing attribute co-variations, enriched by different types of additional information which characterize the context and describe the co-variation type.	association rule learning;attribute grammar;closing (morphology);computation;data mining;exception handling;gradual typing;relevance;time series	Amal Oudni;Marie-Jeanne Lesot;Maria Rifqi;Rosangela Ballini	2015	2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2015.7338104	computer science;pragmatics	DB	-8.967083972450956	-30.151578636639766	153803
1186cd97a3bc65f7947c5387c4df973d68e06061	personalized trajectory matching in spatial networks	spatiotemporal databases;efficiency;personalized trajectory matching;optimization;spatial networks	With the increasing availability of moving-object tracking data, trajectory search and matching is increasingly important. We propose and investigate a novel problem called personalized trajectory matching (PTM). In contrast to conventional trajectory similarity search by spatial distance only, PTM takes into account the significance of each sample point in a query trajectory. A PTM query takes a trajectory with user-specified weights for each sample point in the trajectory as its argument. It returns the trajectory in an argument data set with the highest similarity to the query trajectory. We believe that this type of query may bring significant benefits to users in many popular applications such as route planning, carpooling, friend recommendation, traffic analysis, urban computing, and location-based services in general. PTM query processing faces two challenges: how to prune the search space during the query processing and how to schedule multiple so-called expansion centers effectively. To address these challenges, a novel two-phase search algorithm is proposed that carefully selects a set of expansion centers from the query trajectory and exploits upper and lower bounds to prune the search space in the spatial and temporal domains. An efficiency study reveals that the algorithm explores the minimum search space in both domains. Second, a heuristic search strategy based on priority ranking is developed to schedule the multiple expansion centers, which can further prune the search space and enhance the query efficiency. The performance of the PTM query is studied in extensive experiments based on real and synthetic trajectory data sets.	computer user satisfaction;database;experiment;heuristic;location-based service;nonlinear system;personalization;polynomial texture mapping;relevance;sampling (signal processing);search algorithm;similarity search;spatial network;statistical model;synthetic intelligence;traffic analysis;two-phase commit protocol;urban computing	Shuo Shang;Ruogu Ding;Kai Zheng;Christian S. Jensen;Panos Kalnis;Xiaofang Zhou	2013	The VLDB Journal	10.1007/s00778-013-0331-0	sargable;query optimization;query expansion;web query classification;theoretical computer science;machine learning;data mining;database;efficiency	DB	-14.569202151287797	-36.78814538570488	154671
2b3b3b5f64c514a65eee16884e9f33321cc7c1d0	the evolution of a hierarchical partitioning algorithm for large-scale scientific data: three steps of increasing complexity	topology;spatio temporal data set;hierarchical partitioning;large scale data set;statistical data;bottom up;iterative algorithms;top down;scientific data set;scientific data;partitioning algorithms large scale systems topology iterative algorithms laboratories heuristic algorithms astrophysics spatiotemporal phenomena computational modeling spatial databases;bottom up approach;large scale scientific data;data partitioning;large scale;computational modeling;data topology;heuristic algorithms;spatial databases;spatiotemporal phenomena;cartesian grid;algorithms;spatial data structures;temporal databases visual databases data handling data models spatial data structures;temporal databases;astrophysics;data handling;top down partitioning;management;data topology hierarchical partitioning large scale scientific data scientific data set data partitioning large scale data set spatio temporal data set top down partitioning bottom up approach cartesian grid;large scale systems;data models;partitioning algorithms;visual databases	As scientific data sets grow exponentially in size, the need for scalable algorithms that heuristically partition the data increases. In this paper, we describe the threestep evolution of a hierarchical partitioning algorithm for large-scale spatio-temporal scientific data sets generated by massive simulations. The first version of our algorithm uses a simple top-down partitioning technique, which divides the data by using a four-way bisection of the spatio-temporal space. The shortcomings of this algorithm lead to the second version of our partitioning algorithm, which uses a bottom-up approach. In this version, a partition hierarchy is constructed by systematically agglomerating the underlying Cartesian grid that is placed on the data. Finally, the third version of our algorithm utilizes the intrinsic topology of the data given in the original scientific problem to build the partition hierarchy in a bottom-up fashion. Specifically, the topology is used to heuristically agglomerate the data at each level of the partition hierarchy. Despite the growing complexity in our algorithms, the third version of our algorithm builds partition hierarchies in less time and is able to build trees for larger size data sets as compared to the previous two versions. 1. Three hierarchical partitioning algorithms Scalable algorithms are needed to partition tera-scale data sets [1, 5]. This is especially true in scientific domains, where sizes of the data sets have grown exponentially in recent years. We describe the evolution of a hierarchical partitioning algorithm for large-scale scientific data sets. Specifically, large-scale simulation programs produce our data sets in mesh format. A data set in mesh format consists of interconnected grids of small zones, in which data points are stored. Figure 1 depicts the mesh produced from an astrophysics simulation of a star in its mid-life. Mesh data usually varies with time, consists of multiple dimensions (i.e., variables), and can contain irregular grids. Musick and Critchlow provide a nice introduction to scientific mesh data [4]. Figure 1. A Mesh Data Set Representing a Star The first and simplest version of our partitioning algorithm employs a top-down partitioning technique by performing a four-dimensional bisection on the spatiotemporal space. The major advantage of this approach is the generation of a global decomposition of the data. However, this global partitioning comes with three major drawbacks. First, it is computationally too expensive to scale well to tera-byte data sets. This is largely due to its need to convert a mesh data file from its original simulation-specific format into a consistent vector-based representation. Second, it is not able to capture the information stored in the topology of a mesh data set. Lastly, the bisection procedure works best when there is a uniform density of grid cells throughout the whole problem domain. Typically, however, our domains have complex structures such as non-uniform distributions of grid cells, irregular boundaries, and unusual topologies. Figure 2 shows two examples of such domains. Figure 2. Examples of Complex Domain Structures (a) L-Shaped Domain (b) Rectilinear Domain with Edges Glued Together To address the above issues, our algorithm evolves to a bottom-up approach. First, however, we remove the time dimension from the partitioning space and redefine our partitions on the three-dimensional spatial structure of the data. This new partition space allows us to produce hierarchies that can easily be parallelized for data access. The second version of our algorithm (called GRID) utilizes a grid-based bottom-up partitioning approach. GRID constructs a hierarchy by systematically agglomerating the underlying Cartesian grid that is placed on a mesh data set. Specifically, a simple coarsing strategy starts at the initial grid configuration and iteratively produces coarse level collections of cells from fine level collections of grid cells. Unlike our top-down approach, GRID scales well to large data sets, deals effectively with irregularities of the grid, and produces hierarchies with better structure than the top-down algorithm. However, it is still not able to capture the topological information (i.e., the true physical relationships of the grid cells) of a mesh data set The third version of our algorithm, called TOPOLOGY, improves on the previous bottom-up approach by utilizing the intrinsic topology of the data given in the original scientific problem to build the partition hierarchy. TOPOLOGY uses a two-pass approach. In the first pass, each coarse cell is assigned the “best” neighborhood configuration (with respect to its rectilinear cell shape). This operation is a local search on the 2 possible neighborhood configurations of a coarse cell, where N is the number of dimensions. For instance, in two dimensions, the four possible locations for a given cell (within a coarse agglomeration) are denoted by the grey boxes in Figure 3. Figure 3. Four Possible Locations for a Cell within a Coarse Agglomeration in Two Dimensions Since the first pass of TOPOLOGY is a local operation on cells, no information about the past and future agglomerations in other regions of the domain is taken into consideration when creating ancestor-descendent relationships. For this reason, some coarse agglomerations can result in trees that are non-binary, non-quad, or non-octree. For instance, it is easy to be in a situation (after the first pass) where the coarse cells are arranged as shown in Figure 4. Figure 4. A Non-Quad Tree Coarse Cell Arrangement The coarse cells (C1, C2, and C3 given by solid lines) have been arranged in such a way that indeterminate behavior for neighbors exists for the coarse cells. For example, C2 has two neighbors to its right. The second pass corrects such structural problems associated with indeterminate behavior for neighbors of coarse cells. In particular, the second pass has N-dimensional subphases. Each subphase, s, corrects the (N – s) dimensional structures, planes, lines, and points. Each subphase uses information from all the previous subphases to correctly place the coarse cells. It is important to note that in the second pass, only neighbor relations are adjusted and not the coarse cells (which were defined in the first pass). For example, in two dimensions, the problem illustrated in Figure 4 can be fixed by (i) adjusting the face neighbors so that cell C2 “slides” down half of a coarse grid cell and (ii) making sure the neighbors for all local coarse cells reflect this slide (see Figure 5). Figure 5. A Fix for a Non-Quad Tree Coarse Cell Arrangements A heuristically complex procedure is used to compute these corrections. Our correction procedure utilizes the information about the (faces, edges, and corners of) neighbors of the coarse cells’ descendents to establish neighbors at the coarse level. For instance, to find the neighbors for C2 (shown in Figure 4), we utilize the information for neighbors of cells 1, 2, 5, 6, 9, 10, 11, and 12. In our topology-based algorithm, a new coarse level is created in the first pass and neighbors of coarse cells are identified in the second pass. The second pass rearranges the grid somewhat. The degree to which the domain of coarse cells is rearranged is bounded by the fine-cell sized moves. The degree to which a coarse level “fits” a fine level can be measured by the number of ancestordescendent relationships that are established verses the number which could be established. This measure, C3 C1 C2 3 4 7 8 5 6 9 10 11 12	a* search algorithm;bottom-up parsing;box counting;byte;data access;data point;domain-specific language;emoticon;fits;face (geometry);heuristic;indeterminacy in concurrent computation;local search (optimization);mesh networking;octree;parallel computing;problem domain;quadtree;regular grid;scalability;simulation;space partitioning;top-down and bottom-up design;via c3	Chuck Baldwin;Tina Eliassi-Rad;G. Mohammed Abdulla;Terence Critchlow	2003		10.1109/SSDM.2003.1214983	partition refinement;computer science;graph partition;theoretical computer science;top-down and bottom-up design;data mining;database	HPC	-10.59698868227571	-36.37508600035551	154693
e2da01ed747d9004270473bff26f69a5ca350957	detecting arbitrarily shaped clusters in origin-destination flows using ant colony optimization		ABSTRACTAn origin-destination (OD) flow can be defined as the movement of objects between two locations. These movements must be determined for a range of purposes, and strong interactions can be visually represented via clustering of OD flows. Identification of such clusters may be useful in urban planning, traffic planning and logistics management research. However, few methods can identify arbitrarily shaped flow clusters. Here, we present a spatial scan statistical approach based on ant colony optimization (ACO) for detecting arbitrarily shaped clusters of OD flows (AntScan_flow). In this study, an OD flow cluster is defined as a regional pair with significant log likelihood ratio (LLR), and the ACO is employed to detect the clusters with maximum LLRs in the search space. Simulation experiments based on AntScan_flow and SaTScan_flow show that AntScan_flow yields better performance based on accuracy but requires a large computational demand. Finally, a case study of the morning commuting flows of Beiji...		Ci Song;Tao Pei;Ting Ma;Yunyan Du;Hua Shu;Sihui Guo;Zide Fan	2019	International Journal of Geographical Information Science	10.1080/13658816.2018.1516287	data mining;flow (psychology);cluster (physics);ant colony optimization algorithms;cluster analysis;computer science;likelihood-ratio test	Arch	-14.238362314904787	-31.393233513452817	154774
5f5f5fff49b22343e231f52de193afd2a0d7fd97	mining market data: a network approach	tratamiento datos;extraction information;graph theory;stock price fluctuations;teoria grafo;stock market;marche financier;analisis datos;information extraction;cross correlation;bolsa valores;independent set;correlation croisee;data processing;traitement donnee;data mining;theorie graphe;stock markets;bourse valeurs;stock exchange;degree distribution;marche valeurs;data analysis;stock market development;stock price;market graph;fouille donnee;clustering;power law model;financial market;analyse donnee;power law;busca dato;clique;extraccion informacion;structural properties;mercado financiero;correlacion cruzada	Weconsider a network representation of the stockmarket data referred to as themarket graph,which is constructed by calculating cross-correlations between pairs of stocks based on the opening prices data over a certain period of time. We study the evolution of the structural properties of the market graph over time and draw conclusions regarding the dynamics of the stock market development based on the interpretation of the obtained results. 2005 Elsevier Ltd. All rights reserved.	cross-correlation	Vladimir Boginski;Sergiy Butenko;Panos M. Pardalos	2006	Computers & OR	10.1016/j.cor.2005.01.027	power law;data processing;computer science;capital market line;graph theory;mathematics;information extraction	AI	-4.687722419243258	-31.70604247916091	154836
08042494aaa63b11e5e1521db22bf4aac42ca5dc	incremental stock time series data delivery and visualization	data management;time series;time series data management;multi resolution visualization;time series data;multi resolution;data structure;time series representation;binary tree;incremental data delivery	SB-Tree is a binary tree data structure proposed to represent time series according to the importance of data points. Its use in stock data management is distinguished by preserving the critical data points' attribute values, retrieving time series data according to the importance of data points and facilitating multi-resolution time series retrieval. As new stock data are available continuously, an effective updating mechanism for SB-Tree is needed. In this paper, a study of different updating approaches is reported. Three families of updating methods are proposed. They are periodic rebuild, batch update and point-by-point update. Their efficiency, effectiveness and characteristics are compared and reported.	binary tree;data point;data structure;sandy bridge;steiner tree problem;time series;tree (data structure);update (sql)	Tak-Chung Fu;Korris Fu-Lai Chung;Pui-ying Tang;Robert Wing Pong Luk;Chak-man Ng	2005		10.1145/1099554.1099626	data structure;data management;computer science;data science;time series;data mining;database;statistics	DB	-9.474765499024397	-33.962735903477345	154996
e7a877355f1cc183af439ac092f3d4c83f54cda6	methodology to describe the influence of manufacturing processes on the part functionality	magnetic properties;optical properties;value added	The performance of a value-adding process chain is significantly characterised by a stable and function orientated interaction of its manufacturing processes. To achieve this, it is necessary to define manufacturing tolerances for the significant work piece properties and to produce these tolerances safely. The allowed tolerance ranges are primarily defined by the functionality of the entire part. Thereby, not only macroand micro-geometrical work piece properties are being tolerated in dependence of the part functionality, but also properties of the rim zone, magnetical properties, optical properties (e.g., reflection) and physical material variables. Within the process chain, these properties and manufacturing processes are interacting, but not all work pieces and process properties have direct influence on the final part functionality. Rather, they are only affecting parts of the process chain. Respectively, in the following a methodology to analyse, evaluate and describe the influence of manufacturing process properties on the final part functionality is described.	interaction	Fritz Klocke;Holger Willms	2007	Production Engineering	10.1007/s11740-007-0014-z	magnetism;engineering;value added;operations management;engineering drawing;manufacturing engineering	Robotics	-9.25835363308828	-27.265228674935166	155139
8ad766a090a4725158d05c137365336f1612d88f	top-k miner: top-k identical frequent itemsets discovery without user support threshold	association rules;identical frequent itemsets ifis;candidate itemsets search tree;frequent itemsets	Frequent itemsets (FIs) mining is a prime research area in association rule mining. The customary techniques find FIs or its variants on the basis of either support threshold value or by setting two generic parameters, i.e., N (topmost itemsets) and $$K_\mathrm{{max}}$$ K max (size of the itemsets). However, users are unable to mine the absolute desired number of patterns because they tune these approaches with their approximate parameters settings. We proposed a novel technique, top-K Miner that does not require setting of support threshold, N and $$K_\mathrm{{max}}$$ K max values. Top-K Miner requires the user to specify only a single parameter, i.e., K to find the desired number of frequent patterns called identical frequent itemsets (IFIs). Top-K Miner uses a novel candidate production algorithm called join-FI algorithm. This algorithm uses frequent 2-itemsets to yield one or more candidate itemsets of arbitrary size. The join-FI algorithm follows bottom-up recursive technique to construct candidate-itemsets-search tree. Finally, the generated candidate itemsets are manipulated by the Maintain-Top-K_List algorithm to produce Top-K_List of the IFIs. The proposed top-K Miner algorithm significantly outperforms the generic benchmark techniques even when they are running with the ideal parameters settings.	approximation algorithm;association rule learning;benchmark (computing);bottom-up parsing;cluster analysis;clustering high-dimensional data;data mining;data structure;in-memory database;recursion;search tree;text mining	Saif-Ur Rehman;Jawad Ashraf;Asad Habib;Abdus Salam	2015	Knowledge and Information Systems	10.1007/s10115-015-0907-7	association rule learning;computer science;data science;machine learning;data mining;database;mathematics	ML	-5.837063609536229	-36.50690463197602	155160
50b8f73077424e92e7eb70ccc22f3492fb3688cf	mining temporal relationships with multiple granularities in time sequences		Discovering sequential relationships in a time sequence is often important to many application domains, including financial, manufacturing, etc. Indeed, a lot of work has been do e in this area (see [1, 6] for an overview). An important aspect for such a discovery process is, however, l argely missing from the literature: namely discovering temporal patterns or relationships that involve multiple t ime granularities. This paper reports the progress in this front. A more detailed study can be found in [4]. In this paper, we focus on algorithms for discovering sequen tial relationships when a rough pattern of relationships is given. The rough pattern (which we term “event s tructure”) specifies what sort of relationships a user is interested in. For example, a user may be interested in “wh ich pairs of events occur frequently one week after another”. The algorithms will find the instances that fit the e v nt structure. They can also be used when more information is filled in the structure, as in in the following example from the stock market domain: “what kind of events frequently follow within 5 trading-days from the o ccurrence of a rise in IBM stocks, when this is preceded, one week before, by the fall of another hi-tech compan y stock”. These algorithms form a core component for a data mining environment. We view the actual data mining process as being done interact ively through a user interface. Data mining requests (in terms of event structures) are issued through t he user interface and processed using the algorithms. Initially, the user will issue a request with a simple struct ure. Complicated structures may be given by the user	algorithm;application domain;data mining;effective method;experiment;heuristic (computer science);i/o controller hub;rough set;struct (c programming language);time series;user interface	Claudio Bettini;Xiaoyang Sean Wang;Sushil Jajodia	1998	IEEE Data Eng. Bull.		data mining;computer science	DB	-5.204863446162645	-34.64658260543753	155171
a588e860a0a6b6c7a710aec9fc519ed469b87d4b	event-driven anomalies in spatiotemporal taxi passseger demand		We propose a grid-based approach of mining historical taxi GPS data to study anomalous pickup patterns in spatiotemporal passenger demand caused by public events. The developed method is applied by way of example to the city of Munich on a large-scale taxi dataset. Information about occurring public events is collected from different online and offline sources. For further analysis, the data is aggregated on an equally distributed grid level based on geohashes. In a first step, an extension of robust principle component analysis (RPCA) is developed and applied to the dataset. It is shown that extended RPCA can separate anomalous pickup patterns from base demand in the given time series. Secondly, the combination of anomaly detection and knowledge about occurring public events allows the exploration of correlations in demand fluctuations. The results show that the proposed method can be used to discover the potential impact of public events on spatiotemporal passenger demand in large-scale mobility datasets.		Michael Wittmann;Michael Kollek;Markus Lienkamp	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569500		ML	-16.771994523180407	-32.049505898511825	155199
620760df98832d57164ea224f54efb26d1e66bdc	impact set: computing influence using query logs		A facility f is said to influence a user u if f is one of the k closest facilities of the user u. This is because users usually prefer to visit/use nearby facilities. The influence set of a facility f is the set of users influenced by f . The computation of the influence set has gained extensive research attention in the past decade. Note that the definition of influence set assumes that each user behaves the same, i.e. each user prefers the k closest facilities where k is a constant. However, in real-world scenarios, different users may prefer different values of k depending on, for example, the density of facilities around them, the mode of transport available to them etc. Therefore, assuming a constant value of k for each user may not be able to capture the essence of influence effectively. In this paper, we compute the influence of a facility f using the query logs that contain the k-nearest neighbors queries issued in the past and essentially represent the preferred value of k for each user. Specifically, a facility f has an impact on a user u if f is one of the facilities in the answer set of the query issued by the user. The set of such users is called impact set to avoid ambiguity with influence set. To the best of our knowledge, we are the first to study the problem of impact set computation using query logs. Although existing techniques can be extended to compute the impact set, these techniques suffer from several serious limitations. We carefully analyze these limitations and propose an algorithm to answer impact set queries for 2D location data. The proposed algorithm uses a novel access order and several non-trivial observations to address these limitations. We conduct an extensive experimental study on real and synthetic data sets and demonstrate that our algorithm significantly outperforms existing algorithms in terms of both CPU cost and I/O cost.	central processing unit;computation;experiment;input/output;k-nearest neighbors algorithm;stable model semantics;synthetic data	Shiyu Yang;Muhammad Aamir Cheema;Xuemin Lin	2015	Comput. J.	10.1093/comjnl/bxv016	query optimization;query expansion;database;web search query;world wide web;information retrieval	DB	-11.669001948990122	-36.813270129783994	155374
3ad41c15968753248ffb31a5ed48fa1890b43dc3	a novel method for mining sequential patterns in datasets	dataset sequential pattern mining;pattern recognition data mining;large dataset;sequences databases itemsets data mining computer science educational technology knowledge engineering computer science education electronic mail testing;fast sequential pattern mining algorithm;depth first traversal approach;frequent sequence searching;data mining;sequence mining;frequent itemset;pattern recognition;sequential pattern mining;sequential pattern;sequence database;sequence database dataset sequential pattern mining data mining fast sequential pattern mining algorithm sequence mining depth first traversal approach pruning mechanism frequent sequence searching;pruning mechanism	Sequential pattern mining is one of the most important fields in data mining. In this paper, we propose a novel algorithm FSPAN (Fast Sequential Pattern mining algorithm) to do the sequence mining. FSPAN can mine all the frequent sequential patterns in large datasets and it integrates a depth-first traversal approach with an effective pruning mechanism. This pruning mechanism solves the problem of searching frequent sequences in a sequence database by searching frequent items or frequent itemsets, which makes this method very efficient. Moreover, the databases scanned via FSPAN keep shrinking quickly, which makes the algorithm more efficient when the sequential patterns are longer. Experiments on standard test data show that FSPAN is very effective	algorithm;data mining;depth-first search;experiment;sequence database;sequential pattern mining;test data;tree traversal	Xiaoyu Chang;Chunguang Zhou;Zhe Wang;Ping Hu	2006	Sixth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2006.69	sequential pattern mining;gsp algorithm;computer science;data science;pattern recognition;data mining	ML	-4.898829249164616	-37.051297923110155	155415
96effae927f0381af4b0fe61f584ad830869dfd2	itraffic: a smartphone-based traffic information system	location based service;vehicle arrival rate itraffic system smartphone traffic information system traffic flow mining shockwave technique vehicle accumulation movement data shockwave identification folding heuristic traffic light cycle information client server architecture red green light transition information;road traffic;smart phones;client server systems;data mining;intelligent transportation;traffic information systems;proceedings paper;location based service crowdsourcing green computing intelligent transportation;vehicles servers roads global positioning system equations smart phones data mining;mobile computing;crowdsourcing;traffic information systems client server systems data mining mobile computing road traffic smart phones;green computing	We propose the i-Traffic system that utilizes crowd sourced data from smartphones for the traffic flow mining by shockwave techniques. Shockwave is the propagation phenomenon of vehicle accumulation or relief on roads between two traffic flows with different speeds. The movement data of vehicles in front of an intersection are collected via smartphones for the shockwave identification. To conquer the low penetration problem when the number of the movement data is low, a folding heuristic is proposed by using traffic light cycle information to virtually increase the penetration of movement data. We implement our system on a client-server architecture and perform a small scale field trial experiment to demonstrate the system capability. Our results showed that our system is able to compute traffic information, including red/green light transition information and vehicle arrival rate with mean absolute errors of 5.0/0.6 seconds and 2.43 vehicles per minute, respectively under a low penetration rate of 1.2%.	adobe shockwave;client–server model;crowdsourcing;heuristic;information system;queueing theory;server (computing);smartphone;software propagation;tree accumulation	Yi-Ta Chuang;Chih-Wei Yi;Yin-Chih Lu;Pei-Chuan Tsai	2013	2013 42nd International Conference on Parallel Processing	10.1109/ICPP.2013.109	green computing;embedded system;intelligent transportation system;simulation;floating car data;vehicle information and communication system;computer science;operating system;location-based service;mobile computing;computer security;crowdsourcing;advanced traffic management system;computer network	Mobile	-18.21717122191538	-31.041277978724878	155461
7e653df86125ddb2cfc20f6d0e4f957132d8c485	temporal database technology for air traffic flow management	decision support;large scale;temporal database;traffic flow management	The function of air traffic flow management (ATFM) is to ensure that air traffic operates within adequate margins of safety. Existing ATFM systems are manual which are over-conservative in. operation resulting in under-utilisation of available airspace. As well as being costly, such systems are unable to cope with increased demand for air travel in regions such as Europe. Attempts are currently being made to provide computer-based decision support for ATFM. Computerised decision support for ATFM ensures that safety margins are maintained while at the same time increasing the effective capacity of the airspace by more efficient flight scheduling. At the heart of such a system is active temporal database technology which aids the air traffic controllers by keeping track of airspace occupancy (a time-map of spatio-temporal trajectories of aircraft) in controlled regions of airspace, enabling flow managers to process requests for new slots for takeoff and to smoothen and optimise the flow of air traffic. The technology also aids air traffic controllers by alerting them to possible conflicts and by providing tools for re-routing aircraft to avoid mid-air collisions. The paper describes a large scale demonstrator for ATFM that has been developed at Ferranti Simulation and Training.	temporal database	Suryanarayana M. Sripada;B. L. Rosser;J. M. Bedford;Robert A. Kowalski	1994		10.1007/3-540-58183-9_39	data science;data mining;database	DB	-17.661993513291403	-27.80675176893856	155646
f6a0252150e2967e1c9659c0e0ff98909280229a	influence of clustering on network robustness against epidemic propagation			robustness of complex networks;software propagation	Yinwei Li;Zhen-Hao Zhang;Dongmei Fan;Yurong Song;Guoping Jiang	2018		10.1007/978-3-030-03026-1_2		Vision	-15.490799122016357	-25.338424145150938	155697
8426e29af2e7449ee5dc71f7ae2a268186c247b9	a hybrid markov-based model for human mobility prediction		Human mobility behavior is far from random, and its indicators follow non-Gaussian distributions. Predicting human mobility has the potential to enhance location-based services, intelligent transportation systems, urban computing, and so forth. In this paper, we focus on improving the prediction accuracy of non-Gaussian mobility data by constructing a hybrid Markov-based model, which takes the non-Gaussian and spatio-temporal characteristics of real human mobility data into account. More specifically, we (1) estimate the order of the Markov chain predictor by adapting it to the length of frequent individual mobility patterns, instead of using a fixed order, (2) consider the time distribution of mobility patterns occurrences when calculating the transition probability for the next location, and (3) employ the prediction results of users with similar trajectories if the recent context has not been previously seen. We have conducted extensive experiments on real human trajectories collected during 21 days from 3474 individuals in an urban Long Term Evolution (LTE) network, and the results demonstrate that the proposed model for non-Gaussian mobility data can help predicting people’s future movements with more than	compaq lte;experiment;individual mobility;kerrison predictor;location-based service;markov chain;urban computing	Yuanyuan Qiao;Zhongwei Si;Yanting Zhang;Fehmi Ben Abdesslem;Xinyu Zhang;Jie Yang	2018	Neurocomputing	10.1016/j.neucom.2017.05.101	artificial intelligence;machine learning;urban computing;pattern recognition;mathematics;individual mobility;mobility model;intelligent transportation system;markov chain	AI	-17.463423512872446	-34.55179598698799	156138
93f855021c9d47f23070b2f3ce6eda7914cae774	cost matters: a new example-dependent cost-sensitive logistic regression model		Connectivity and automation are evermore part of today’s cars. To provide automation, many gauges are integrated in cars to collect physical readings. In the automobile industry, the gathered multiple datasets can be used to predict whether a car repair is needed soon. This information gives drivers and retailers helpful information to take action early. However, prediction in real use cases shows new challenges: misclassified instances have not equal but different costs. For example, incurred costs for not predicting a necessarily needed tire change are usually higher than predicting a tire change even though the car could still drive thousands of kilometers. To tackle this problem, we introduce a new example-dependent cost sensitive prediction model extending the well-established idea of logistic regression. Our model allows different costs of misclassified instances and obtains prediction results leading to overall less cost. Our method consistently outperforms the state-of-the-art in example-dependent cost-sensitive logistic regression on various datasets. Applying our methods to vehicle data from a large European car manufacturer, we show cost savings of about 10%.	logistic regression	Nikou Günnemann;Jürgen Pfeffer	2017		10.1007/978-3-319-57454-7_17	econometrics;logistic regression;multinomial logistic regression;cross-sectional regression	AI	-12.313388200949843	-32.66362589933602	157096
c2295c412c6959109fe4fd9c5dbfa69b13db27bb	an attribute based storage method for speeding up clique algorithm for subspace clustering	high dimensional dataset;pattern clustering;clique subspace clustering algorithm;subspace identification;database management systems;depth first method attribute based storage method clique subspace clustering algorithm high dimensional datasets subspace identification;clustering algorithms frequency scalability databases data engineering;attribute based storage method;high dimensional datasets;subspace clustering;pattern clustering database management systems;missing values;depth first method	The subspace clustering algorithm CLIQUE finds all subspace clusters including overlapping clusters existing in high dimensional datasets. CLIQUE consists of three main steps namely - (1) identification of subspaces that contain clusters, (2) identification of clusters and (3) generation of the minimal description for the clusters obtained in step two. In this paper, we have presented a method for speeding-up the first step of the CLIQUE algorithm. The proposed method is based on accessing the data from columns instead of rows. It is very efficient when there are many missing values in the high dimensional datasets given in the form of table. We have also proposed a depth-first method to find the maximal dense units, to further improve the performance of the first step	algorithm;cluster analysis;clustering high-dimensional data;column (database);depth-first search;maximal set;missing data;row (database);table (database)	Jyoti Pawar;P. R. Rao	2006	2006 10th International Database Engineering and Applications Symposium (IDEAS'06)	10.1109/IDEAS.2006.8	correlation clustering;subclu;k-medians clustering;fuzzy clustering;missing data;computer science;canopy clustering algorithm;machine learning;pattern recognition;cure data clustering algorithm;data mining;database;clique percolation method;cluster analysis;single-linkage clustering	DB	-4.971402478047237	-37.67866650119448	157260
ac3a87fc3a30513c0d8fdbfddf7cbe54cdd3e1a9	from data to knowledge: city-wide traffic flows analysis and prediction using bing maps	traffic prediction;human mobility;visualization;analysis;urban computing	Traffic jam is a common contemporary society issue in urban areas. City-wide traffic modeling, visualization, analysis, and prediction are still challenges in this context. Based on Bing Maps information, this work aims to acquire, aggregate, analyze, visualize, and predict traffic jam. Chicago area was evaluated as case study. The flow intensity (free or congested) was analyzed to allow the identification of phase transitions (shocks in the system). Also, a prediction model was developed based on logistic regression to correct discovery future flow intensities for a target street.	aggregate data;bing maps;jam;logistic regression;map	Anna Izabel J. Tostes Ribeiro;Fatima de L. P. Duarte-Figueiredo;Renato Assunção;Juliana F. S. Salles;Antonio Alfredo Ferreira Loureiro	2013		10.1145/2505821.2505831	visualization;computer science;analysis;data mining;operations research	ML	-16.777469374885985	-31.71329534039142	157398
9b8334577aadd3ee36d2e667787db6bbd38285fb	an assessment of surface and zonal models of population	general techniques;population data	Abstract The advantages of handling population data in GIS as a raster surface rather than as zonal attributes are discussed, and a technique for creating such surfaces briefly reviewed. Existing models created by this method using the 1991 UK Census are then compared with equivalent zonal data and some weaknesses identified, in particular the poor association between enumeration districts and 200 m grid cells. A refined version of the surface generation technique is presented in which population totals are constrained within zone boundaries, while residential geography is retained with considerable success.	population	David J. Martin	1996	International Journal of Geographical Information Science	10.1080/02693799608902120	geography;computer science;data mining;cartography	Visualization	-11.866132045550504	-24.03277049325985	157461
af1b1279bb28dc24488cf3050f86257ad1cd02b3	inferring destination from mobility data		Destination prediction in a moving vehicle has several applications such as alternative route recommendations even in cases where the driver has not entered their destination into the system. In this paper a hierarchical approach to destination prediction is presented. A Discrete Time Markov Chain model is used to make an initial prediction of a general region the vehicle might be travelling to. Following that a more complex Bayesian Inference Model is used to make a fine grained prediction within that destination region. The model is tested on a dataset of 442 taxis operating in Porto, Portugal. Experiments are run on two maps. One is a smaller map concentrating specificially on trips within the Porto city centre and surrounding areas. The second map covers a much larger area going as far as Lisbon. We achieve predictions for Porto with average distance error of less than 0.6 km from early on in the trip and less than 1.6 km dropping to less than 1 km for the wider area.	hierarchical database model;high-level programming language;map;markov chain	Ali Naeem;Kenneth Brown	2017			computer science	ML	-16.583658950236078	-30.73406988343129	157638
db130fb59ef7abac32565c2a52a27ed1e32776c6	mhui-max: an efficient algorithm for discovering high-utility itemsets from data streams	efficient algorithm;data stream;utility mining;data mining;data streams;high utility itemset;data stream mining;profitability;data structure;sliding window	Online mining of utility itemsets from data streams is one of the most interesting research issues in stream data mining. Although a number of relevant approaches have been proposed in recent years, they have the drawback of producing a large number of candidate itemsets for high-utility itemset mining. In this paper, an efficient algorithm, called MHUI-max (Mining High-Utility Itemsets based on LexTree-maxHTU), is proposed for mining high-utility itemsets from data streams with fewer candidates. Based on the framework of the MHUI-max algorithm, an effective representation of item information, called TID-list, and a new lexicographical tree-based data structure, called LexTree-maxHTU, has been developed to improve the efficiency of discovering high-utility itemsets with positive profits from data streams. Experimental results show that the proposed algorithm, MHUI-max, outperforms the existing approaches, MHUI-TID and THUI-Mine, for mining high-utility itemsets from data streams over transaction-sensitive sliding windows.	algorithm	Hua-Fu Li	2011	J. Information Science	10.1177/0165551511416436	sliding window protocol;computer science;data science;data mining;database;data stream mining;profitability index	ML	-5.739502330248433	-36.74203194593518	157964
4ac4b520196619824fb6515f364b43f838daf8e1	real-time effective framework for unstructured data mining	hierarchical clustering;pattern clustering;information extraction;database management systems;sql;information retrieval;data mining;data mining databases information retrieval communities thesauri organizations clustering algorithms;big data;optimistic search real time effective framework unstructured data mining enterprise landscape data sources product delivery service delivery knowledge discovery in database activities kdd activities hierarchical clustering methodology human readability dependency structure document organization term extraction process rsenter interconnected hyperlinks nosql database search algorithms random walk pessimistic search;topics;sql data mining database management systems information retrieval pattern clustering search problems;terms;search problems;unstructured data;big data data mining hierarchical clustering unstructured data information extraction topics terms	Today, the enterprise landscape faces voluminous amount of data. The information gathered from these data sources are useful for improving on product and services delivery. However, it is challenging to perform knowledge discovery in database (KDD) activities on these data sources because of its unstructured nature. Previous studies have proposed the hierarchical clustering methodology since it enhances human readability and provides clear dependency structure through topics, term and document organization. But, the methodology can be resource intensive and time consuming. In order to improve on the terms extraction process, we propose a tool called RSenter that searches through interconnected Hyperlinks and NoSQL database (specifically, CouchDB). We evaluate the tool based on search algorithms such as parallelization, random walk (or linear search), pessimistic search, and optimistic search. The tool shows high accuracy and optimality in view of the search time.	big data;cluster analysis;data mining;hierarchical clustering;hyperlink;linear search;nosql;open-source software;parallel algorithm;parallel computing;procurement;random search;real-time web;reasoning system;requirement;search algorithm;software deployment;thesaurus	Richard K. Lomotey;Ralph Deters	2013	2013 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2013.131	computer science;data science;data mining;database	DB	-13.175037740422548	-36.50142549618763	157989
3de21068c60e65a600d0fa6f49f45eb9734b7278	mining lines in the sand: on trajectory discovery from untrustworthy data in cyber-physical system	sensor network;trajectory;cyber physical system	"""A Cyber-Physical System (CPS) integrates physical (i.e., sensor) devices with cyber (i.e., informational) components to form a context sensitive system that responds intelligently to dynamic changes in real-world situations. The CPS has wide applications in scenarios such as environment monitoring, battlefield surveillance and traffic control. One key research problem of CPS is called """"mining lines in the sand"""". With a large number of sensors (sand) deployed in a designated area, the CPS is required to discover all the trajectories (lines) of passing intruders in real time. There are two crucial challenges that need to be addressed: (1) the collected sensor data are not trustworthy; (2) the intruders do not send out any identification information. The system needs to distinguish multiple intruders and track their movements. In this study, we propose a method called LiSM (Line-in-the-Sand Miner) to discover trajectories from untrustworthy sensor data. LiSM constructs a watching network from sensor data and computes the locations of intruder appearances based on the link information of the network. The system retrieves a cone-model from the historical trajectories and tracks multiple intruders based on this model. Finally the system validates the mining results and updates the sensor's reliability in a feedback process. Extensive experiments on big datasets demonstrate the feasibility and applicability of the proposed methods."""	big data;cyber-physical system;experiment;sensor	Lu An Tang;Xiao Yu;Quanquan Gu;Jiawei Han;Alice Leung;Thomas F. La Porta	2013		10.1145/2487575.2487585	simulation;wireless sensor network;computer science;trajectory;data mining;cyber-physical system;computer security	ML	-14.724413840848753	-34.08659985869311	158034
02cda23a01143a968fda68f030db5c347cb323c8	bayesian methodology for the analysis of spatial-temporal surveillance data	markov random field;syndromic surveillance;spatio temporal;spatial statistics;conditional autoregressive process	Early and accurate detection of outbreaks is one of the most important objectives of syndromic surveillance systems. We propose a general Bayesian framework for syndromic surveillance systems. The methodology incorporates Gaussian Markov random field (GMRF) and spatio-temporal conditional autoregressive (CAR) modeling. By contrast, most previous approaches have been based on only spatial or time series models. The model has appealing probabilistic representations as well as attractive statistical properties. Based on extensive simulation studies, the model is capable of capturing outbreaks rapidly, while still limiting false positives. © 2012 Wiley Periodicals, Inc. Statistical Analysis and Data Mining 5: 194–204, 2012	autoregressive model;conditional entropy;data mining;john d. wiley;markov chain;markov random field;simulation;time series	Jian Zou;Alan F. Karr;David Banks;Matthew J. Heaton;Gauri Datta;James Lynch;Francisco Vera	2012	Statistical Analysis and Data Mining	10.1002/sam.10142	computer science;data science;data mining;mathematics;spatial analysis;statistics	ML	-13.489550752986505	-31.932709006019113	158162
f6180877b1e557f1639200b0dff187257a7b010d	parameter optimization for online change detection in activity monitoring using multivariate exponentially weighted moving average (mewma)	tecnologias	In recent years, body worn sensors have become popular for the purpose of activity recognition. The sensors used to capture a large amount of data in a short period of time which contain meaningful events. The change points in this data can be used to specify transition to a distinct event which can subsequently be used in various scenarios such as to identify changes in patient vital signs in a medical domain or to assist in the process of generating activity labels for the purposes of annotating real-world datasets. A change point can also be used to identify the transition from one activity to another. The multivariate exponentially weighted moving average (MEWMA) algorithm has been proposed to automatically detect such change points for transitions in user activity. The MEWMA approach does not require any assumptions to be made in relation to the underlying distributions to evaluate multivariate data streams and can run in an online scenario. The focus of this paper is to evaluate the performance of the MEWMA approach for change point detection in user activity and to determine the optimal parameter values by tuning and analyzing different parameters of MEWMA. Optimal parameter selection results in an algorithm to detect accurate change points and minimize false alarms. Results are presented and compared based on real world accelerometer data for standard and optimal parameters evaluated using different metrics such as accuracy, precision, G-mean and F-measures.	program optimization	Naveed Khan;Sally I. McClean;Shuai Zhang;Chris D. Nugent	2015		10.1007/978-3-319-26401-1_5	mathematical optimization;computer science;statistics	Robotics	-11.902194197562352	-34.49004510308438	158238
546dbb29c71023341b58ea2b760012ca343d8982	spatio-temporal trajectory simplification for inferring travel paths	gps trace;trajectory simplification;path inference;map matching	Mining GPS trajectories of moving vehicles has led to many research directions, such as traffic modeling and driving predication. An important challenge is how to map GPS traces to a road network accurately under noisy conditions. However, to the best of our knowledge, there is no existing work that first simplifies a trajectory to improve map matching. In this paper we propose three trajectory simplification algorithms that can deal with both offline and online trajectory data. We use weighting functions to incorporate spatial knowledge, such as segment lengths and turning angles, into our simplification algorithms. In addition, we measure the noise degree of a GPS point based on its spatio-temporal relationship to its neighbors. The effectiveness of our algorithms is comprehensively evaluated on real trajectory datasets with varying the noise levels and sampling rates. Our evaluation shows that under highly noisy conditions, our proposed algorithms considerably improve map matching accuracy and reduce computational costs compared to the state-of-the-art methods.	adaptive compression;algorithm;algorithmic efficiency;computation;experiment;global positioning system;ground truth;level of detail;map matching;online and offline;sampling (signal processing);sparse matrix;tracing (software);trajectory optimization	Hengfeng Li;Lars Kulik;Kotagiri Ramamohanarao	2014		10.1145/2666310.2666409	computer vision;machine learning;data mining	ML	-15.903104712507425	-34.31815688127655	158376
440f651126f734b9b81ada530630e2ffe2b1503e	spatiotemporal segmentation of metro trips using smart card data	smart card;data acquisition intelligent transportation systems smart cards;trip segmentation;spatiotemporal data;color;intelligent transportation systems;data collection;data mining;spatiotemporal segmentation metro trip smart card data contactless smart card system transaction data collection amount spatiotemporal segmentation information extraction large scale real system data shenzhen metro system china intelligent transportation system;time domain analysis;smart cards;smart cards data acquisition intelligent transportation systems;schedules;smart city trip segmentation intelligent transportation systems metro systems smart card;metro systems;travel patterns;methodology;intelligent transportation system spatiotemporal segmentation metro trip smart card data contactless smart card system transaction data collection amount spatiotemporal segmentation information extraction large scale real system data shenzhen metro system china;smart cards data mining color educational institutions time domain analysis schedules;smart city;trip segmentation intelligent transportation systems metro systems smart card smart city	Contactless smart card systems have gained universal prevalence in modern metros. In addition to its original goal of ticketing, the large amount of transaction data collected by the smart card system can be utilized for many operational and management purposes. This paper investigates an important problem: how to extract spatiotemporal segmentation information of trips inside a metro system. More specifically, for a given trip, we want to answer several key questions: How long does it take for a passenger to walk from the station gantry to the station platform? How much time does he/she wait for the next train? How long does he/she spend on the train? How long does it take to transfer from one line to another? This segmentation information is important for many application scenarios such as travel time prediction, travel planning, and transportation scheduling. However, in reality, we only assume that only each trip's tap-in and tap-out time can be directly obtained; all other temporal endpoints of segments are unknown. This makes the research very challenging. To the best of our knowledge, we are the first to give a practical solution to this important problem. By analyzing the tap-in/tap-out event pattern, our intuition is to pinpoint some special passengers whose transaction data can be very helpful for segmentation. A novel methodology is proposed to extract spatiotemporal segmentation information: first, for nontransfer trips, by deriving the boarding time between the gantry and the platform, and then, for with-transfer trips, by deriving the transfer time. Evaluation studies are based on large-scale real-system data of the Shenzhen metro system, which is one of the largest metro systems in China and serves millions of passengers daily. Onsite investigations validate that our algorithm is accurate and that the average estimation error is only around 15%.	algorithm;contactless smart card;mean squared error;scheduling (computing);transaction data	Fan Zhang;Juanjuan Zhao;Chen Tian;Cheng-Zhong Xu;Xue Liu;Lei Rao	2016	IEEE Transactions on Vehicular Technology	10.1109/TVT.2015.2409815	embedded system;smart card;simulation;computer science;engineering;computer security;statistics	Mobile	-17.29775228230039	-32.14875107131613	158730
48edbbba71073283c24916a3e73b66d855d86ec8	eperiodicity: mining event periodicity from incomplete observations	probabilistic model periodicity incomplete observations;sensors;probabilistic model;periodicity;nonhomogeneous media;vectors;markov processes vectors probabilistic logic random processes nonhomogeneous media sensors global positioning system;global positioning system;e periodicity analysis outlier detection real datasets synthetic datasets periodic behavior uncertainties periodic behavior noises period detection probabilistic measure hidden temporal periodic behaviors imperfect data collection problem periodic behavior prediction periodicity mining physical events data mining task facility usage human movements physical event tracking sensors gps incomplete observations periodicity event mining;random processes;probability data mining;markov processes;probabilistic logic;incomplete observations	Advanced technology in GPS and sensors enables us to track physical events, such as human movements and facility usage. Periodicity analysis from the recorded data is an important data mining task which provides useful insights into the physical events and enables us to report outliers and predict future behaviors. To mine periodicity in an event, we have to face real-world challenges of inherently complicated periodic behaviors and imperfect data collection problem. Specifically, the hidden temporal periodic behaviors could be oscillating and noisy, and the observations of the event could be incomplete. In this paper, we propose a novel probabilistic measure for periodicity and design a practical algorithm, ePeriodicity, to detect periods. Our method has thoroughly considered the uncertainties and noises in periodic behaviors and is provably robust to incomplete observations. Comprehensive experiments on both synthetic and real datasets demonstrate the effectiveness of our method.	algorithm;anomaly detection;data mining;experiment;global positioning system;quasiperiodicity;robustness (computer science);sensor;sparse matrix;statistical model;synthetic intelligence;unevenly spaced time series	Zhenhui Li;Jingjing Wang;Jiawei Han	2015	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2014.2365801	stochastic process;statistical model;global positioning system;sensor;machine learning;data mining;mathematics;probabilistic logic;markov process;statistics	DB	-14.365030071256328	-33.88789196552354	159154
0e9ab9b34760fff6884909c2f76219073691ece7	a temporal-spatial method for group detection, locating and tracking	smart computing internet of things group detection temporal spatial;smart phones;event detection;smart devices;smart devices smart phones mobile radio mobility management event detection internet of things smart computing;internet of things;target tracking global positioning system pattern clustering smart phones;smart computing;crf based event detection mechanism temporal spatial method smart device smart phone wearable equipment location based service lbs application context related research pattern clustering group detection group location group tracking;mobile radio mobility management	With the prevalence of smart devices, such as smart phones, wearable equipments, and infrastructures, location-based service (LBS) has thrived in our daily life. In those practical LBS applications, group detection and tracking is a context-related research field in many scenarios, such as school yard, office building, shopping mall and so on. In this paper, we heuristically develop a temporal-spatial method for clustering and locating the groups, and then leverage a CRF-based event detection mechanism to improve the performance of recognizing contextual behaviors. The experimental results demonstrate that our system can achieve an impressive accuracy and precision of grouping and tracking.	cluster analysis;conditional random field;heuristic;location-based service;smart device;smartphone;wearable computer	Shengnan Li;Zheng Qin;Houbing Song	2016	IEEE Access	10.1109/ACCESS.2016.2600623	embedded system;computer science;internet privacy;computer security;internet of things	Mobile	-18.154179971240985	-35.128482904895165	159159
fb290c0eb0e79cffb44b9d2ddb14c9b3a37b1f25	characterization of black spot zones for vulnerable road users in são paulo (brazil) and rome (italy)	traffic accidents;vulnerable road users;trip generator hubs;kernel density estimator;spatial analysis	Non-motorized transportation modes, especially cycling and walking, offer numerous benefits, including improvements in the livability of cities, healthy physical activity, efficient urban transportation systems, less traffic congestion, less noise pollution, clean air, less impact on climate change and decreases in the incidence of diseases related to vehicular emissions. Considering the substantial number of short-distance trips, the time consumed in traffic jams, the higher costs for parking vehicles and restrictions in central business districts, many commuters have found that non-motorized modes of transportation serve as viable and economical transport alternatives. Thus, local governments should encourage and stimulate non-motorized modes of transportation. In return, governments must provide safe conditions for these forms of transportation, and motorized vehicle users must respect and coexist with pedestrians and cyclists, which are the most vulnerable users of the transportation system. Although current trends in sustainable transport aim to encourage and stimulate non-motorized modes of transportation that are socially more efficient than motorized transportation, few to no safety policies have been implemented regarding vulnerable road users (VRU), mainly in large urban centers. Due to the spatial nature of the data used in transport-related studies, OPEN ACCESS ISPRS Int. J. Geo-Inf. 2015, 4 859 geospatial technologies provide a powerful analytical method for studying VRU safety frameworks through the use of spatial analysis. In this article, spatial analysis is used to determine the locations of regions that are characterized by a concentration of traffic accidents (black zones) involving VRU (injuries and casualties) in São Paulo, Brazil (developing country), and Rome, Italy (developed country). The black zones are investigated to obtain spatial patterns that can cause multiple accidents. A method based on kernel density estimation (KDE) is used to compare the two cities and show economic, social, cultural, demographic and geographic differences and/or similarities and how these factors are linked to the locations of VRU traffic accidents. Multivariate regression analyses (ordinary least squares (OLS) models and spatial regression models) are performed to investigate spatial correlations, to understand the dynamics of VRU road accidents in São Paulo and Rome and to detect factors (variables) that contribute to the occurrences of these events, such as the presence of trip generator hubs (TGH), the number of generated urban trips and demographic data. The adopted methodology presents satisfactory results for identifying and delimiting black spots and establishing a link between VRU traffic accident rates and TGH (hospitals, universities and retail shopping centers) and demographic and transport-related data.	coexist (image);delimiter;incidence matrix;kernel density estimation;network congestion;ordinary least squares;spatial analysis	Cláudia A. Soares Machado;Mariana A. Giannotti;Francisco Chiaravalloti Neto;Antonino Tripodi;Luca Persia;José Alberto Quintanilha	2015	ISPRS Int. J. Geo-Information	10.3390/ijgi4020858	geography;civil engineering;transport engineering;cartography	HCI	-16.63923592895414	-28.069244763127386	159534
f347110d1348b0ac4020fae2843f67d5a0366098	identification of real-world objects in multiple databases	duplicate detection;data cleansing;data quality;decision tree induction;data structure;object identification;record linkage	Object identification is an important issue for integration of data from different sources. The identification task is complicated, if no global and consistent identifier is shared by the sources. Then, object identification can only be performed through the identifying information, the objects data provides itself. Unfortunately real-world data is dirty, hence identification mechanisms like natural keys fail mostly — we have to take care of the variations and errors of the data. Consequently, object identification can no more be guaranteed to be fault-free. Several methods tackle the object identification problem, e.g. Record Linkage, or the Sorted Neighborhood Method. Based on a novel object identification framework, we assessed data quality and evaluated different methods on real data. One main result is that scalability is determined by the applied preselection technique and the usage of efficient data structures. As another result we can state that Decision Tree Induction achieves better correctness and is more robust than Record Linkage.	association rule learning;benchmark (computing);care-of address;correctness (computer science);data quality;data structure;database;decision tree;identifier;linkage (software);microsoft outlook for mac;relevance feedback;scalability;stepwise regression;unsupervised learning	Mattis Neiling	2005		10.1007/3-540-31314-1_7	computer science;pattern recognition;data mining;database	DB	-7.6881344991730645	-35.66457036784648	159636
b7603790335abef018408b2df995c570c8759c05	discovering during-temporal patterns (dtps) in large temporal databases	weather forecasting;data mining;temporal database;real world application;temporal pattern;during relationship	Large temporal Databases (TDBs) usually contain a wealth of data about temporal events. Aimed at discovering temporal patterns with during relationship (during-temporal patterns, DTPs), which is deemed common and potentially valuable in real-world applications, this paper presents an approach to finding such DTPs by investigating some of their properties and incorporating them as desirable pruning strategies into the corresponding algorithm, so as to optimize the mining process. Results from synthetic reveal that the algorithm is efficient and linearly scalable with regard to the number of temporal events. Finally, we apply the algorithm into the weather forecast field and obtain effective results.	algorithm;association rule learning;distributed transaction;mathematical optimization;overhead (computing);scalability;synthetic data;temporal database	Xiang Lin;Guoqing Chen;Tom Brijs;Xing Zhang	2008	Expert Syst. Appl.	10.1016/j.eswa.2006.12.024	weather forecasting;computer science;data science;machine learning;data mining;temporal database	ML	-8.53761097315789	-35.64388135012351	159836
136e41a36bbdb38695a725fbf5ff9d3e698ce71f	algorithms for association rule mining - a general survey and comparison	hypertext probabilistic grammars;efficient algorithm;association rule mining;usage mining;navigation patterns;general surveys	"""""""# $ % & ' #() *+ () #( , & #$ ( ,. # & / 0.() 123 4 # 5 , 6$ """".7983 ,& :; < """"# $ <$ . =) > 5 # ? >*+ @7-AB ? (& () *C < 0.( ? 2D, & $ E 2% # F , <$ """"9 & ?$ . 4 ?""""# 32 $ *C 1)7HGC > I # J 6*C . =) 4 LK ( (. ; ! # 0 ;= M() # """"3 #,. ; #$ $ # ! () & . NL 7E8+2 ' & %*C #, """"# O """" O """" + & *C > 1 3 & 6 > 6 #,. P L , $ 3 0 4 () $ 7QAR ,. #,. & < , $ 6=) & > 2% """"# $ 3 +$ , <$ ' $ % P =) M 0.() > L7"""	algorithm;association rule learning;nl (complexity)	Jochen Hipp;Ulrich Güntzer;Gholamreza Nakhaeizadeh	2000	SIGKDD Explorations	10.1145/360402.360421	association rule learning;computer science;data science;machine learning;data mining;k-optimal pattern discovery	ML	-10.289859599521712	-37.818130686589804	159861
917afa7ca338ec321f138aca493500e57fcf2cba	short-term traffic prediction using long short-term memory neural networks		Short-term traffic prediction allows Intelligent Transport Systems to proactively respond to events before they happen. With the rapid increase in the amount, quality, and detail of traffic data, new techniques are required that can exploit the information in the data in order to provide better results while being able to scale and cope with increasing amounts of data and growing cities. We propose and compare three models for short-term road traffic density prediction based on Long Short-Term Memory (LSTM) neural networks. We have trained the models using real traffic data collected by Motorway Control System in Stockholm that monitors highways and collects flow and speed data per lane every minute from radar sensors. In order to deal with the challenge of scale and to improve prediction accuracy, we propose to partition the road network into road stretches and junctions, and to model each of the partitions with one or more LSTM neural networks. Our evaluation results show that partitioning of roads improves the prediction accuracy by reducing the root mean square error by the factor of 5. We show that we can reduce the complexity of LSTM network by limiting the number of input sensors, on average to 35% of the original number, without compromising the prediction accuracy.	control system;expect;exploit (computer security);long short-term memory;mean squared error;neural networks;sensor;stockholm format	Zainab Abbas;Ahmad Al-Shishtawy;Sarunas Girdzijauskas;Vladimir Vlassov	2018	2018 IEEE International Congress on Big Data (BigData Congress)	10.1109/BigDataCongress.2018.00015	long short term memory;real-time computing;data mining;radar;computer science;artificial neural network;exploit;limiting;intelligent transportation system;mean squared error;control system	Mobile	-15.038049571762363	-31.022532812267432	160192
a119840f9a5ab23716c8c0d13d4e47c40fa9194f	real time traffic delay optimization using shadowed type-2 fuzzy rule base				Kajal Chatterjee;Arkajyoti De;Felix T. S. Chan	2019	Appl. Soft Comput.	10.1016/j.asoc.2018.10.008		EDA	-10.622685180261293	-28.52432781158627	160459
1165779debff6bb6a5b393f3eb4bb2d821d95dfb	efficient algorithms for mining frequent and closed patterns from semi-structured data	frequent pattern;efficient algorithm;pattern mining;semi structured data	In this talk, we study effcient algorithms that find frequent patterns and maximal (or closed) patterns from large collections of semi-structured data. We review basic techniques developed by the authors, called the rightmost expansion and the PPC-extension, respectively, for designing efficient frequent and maximal/closed pattern mining algorithms for large semi-structured data. Then, we discuss their applications to design of polynomial-delay and polynomial-space algorithms for frequent and maximal pattern mining of sets, sequences, trees, and graphs.	algorithm;semi-structured data;semiconductor industry	Hiroki Arimura	2008		10.1007/978-3-540-68125-0_2	semi-structured data;computer science;pattern recognition;data mining;database	ML	-7.3908851338615245	-37.779566909450935	160687
6e255d45ed3ff820ea823d86bcc8773cda10adb6	an efficient approach for mining weighted approximate closed frequent patterns considering noise constraints	noise constraints;data mining;approximate bound;weighted approximate closed pattern mining	Based on the frequent pattern mining, closed frequent pattern mining and weighted frequent pattern mining have been studied to reduce the search space and discover important patterns. In the previous definition of weighted closed patterns, supports of patterns are only considered to compute the closures of the patterns. It means that the closures of weighted frequent patterns cannot be perfectly checked. Moreover, the usefulness of weighted closed frequent patterns depends on the presence of frequent patterns that have supersets with the exactly same weighted support. However, from the errors such as noise, slight changes in items’ supports or weights by them have significantly negative effects on the mining results, which may prevent us from obtaining exact and valid analysis results since the errors can break the original characteristics of items and patterns. In this paper, to solve the above problems, we propose a concept of robust weighted closed frequent pattern mining, and an approximate bound is defined on the basis of the concept, which can relax requirements for precise equality among patterns’ weighted supports. Thereafter, we propose a weighted approximate closed frequent pattern mining algorithm which not only considers the two approaches but also suggests fault tolerant pattern mining in the noise constraints. To efficiently mine weighted approximate closed frequent patterns, we suggest pruning and subset checking methods which reduce search space. We also report extensive performance study to demonstrate the effectiveness, efficiency, memory usage, scalability, and quality of patterns in our algorithm.	academy;approximation algorithm;cartesian closed category;closure (computer programming);data mining;fault tolerance;image noise;mined;nl-complete;numerical aperture;requirement;scalability;sequential pattern mining	Unil Yun;Eunchul Yoon	2014	International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems	10.1142/S0218488514500470	computer science;machine learning;pattern recognition;data mining;mathematics	ML	-7.259945391604766	-36.01157597021481	160789
cc103a847e8fd54680ec443886d65c4886211596	fitting techniques to knowledge discovery through stochastic models		Stochastic models might be useful for creating compact representations of non-deterministic scenarios. Furthermore, simulations applied to a compact model, are faster and require fewer computational resources than the use of data mining techniques over large volumes of data. The challenge is to build such models. The accuracy as well as the time and the amount of resources used to fit such models, are the key factors related to their utility. We use machine learning techniques for the fitting of structures characterized by a Markov property; especially, complex formalisms such as Hidden Markov Models (HMM) and Stochastic Automata Networks (SAN). Regarding the accuracy, we considered the state of the art on fitting techniques and model measurements based on likelihood. Regarding the computational resources, we used time series and dimensionality reduction techniques to avoid the space state explosion. Such techniques are demonstrated in a process that embodies a set of common steps for the model fitting through time series. Similar to the knowledge discovery in databases (KDD), yet using stochastic models as a main component.		Joaquim Assunção	2016			markov property;knowledge extraction;stochastic modelling;rotation formalisms in three dimensions;machine learning;hidden markov model;data mining;dimensionality reduction;artificial intelligence;computer science	ML	-9.818844610190052	-37.228343192436604	161112
cfe201f65740655a09778843f568cdfaf7b99625	community structure based shortest path finding for social networks		With the rapid expansion of communication data, research about analyzing social networks has become a hotspot. Finding the shortest path (SP) in social networks can help us to investigate the potential social relationships. However, it is an arduous task, especially on large-scale problems. There have been many previous studies on the SP problem, but very few of them considered the peculiarity of social networks. This paper proposed a community structure based method to accelerate answering the SP problem of social networks during online queries. We devise a two-stage strategy to strike a balance between offline pre-computation and online consultations. Our goal is to perform fast and accurate online approximations. Experiments show that our method can instantly return the SP result while satisfying accuracy constraint.	shortest path problem;social network	Yale Chai;Chunyao Song;Peng Nie;Xiaojie Yuan;Yao Ge	2018		10.1007/978-3-319-98809-2_19	data mining;shortest path problem;hotspot (wi-fi);social network;computer science;community structure;distributed computing	Theory	-13.94449716463358	-36.67655146010391	161116
715258d6d0cf71c8a952ca6369fd18e2d09e3099	spatiotemporal anomaly detection in gas monitoring sensor networks	unsupervised learning;bayesian network;bayesian approach;anomaly detection;event detection;sensor network;bayesian model;coal mining	In this paper, we use Bayesian Networks as a means for unsupervised learning and anomaly (event) detection in gas monitoring sensor networks for underground coal mines. We show that the Bayesian Network model can learn cyclical baselines for gas concentrations, thus reducing false alarms usually caused by flatline thresholds. Further, we show that the system can learn dependencies between changes of concentration in different gases and at multiple locations. We define and identify new types of events that can occur in a sensor network. In particular, we analyse joint events in a group of sensors based on learning the Bayesian model of the system, contrasting these events with merely aggregating single events. We demonstrate that anomalous events in individual gas data might be explained if considered jointly with the changes in other gases. Vice versa, a network-wide spatiotemporal anomaly may be detected even if individual sensor readings were within their thresholds. The presented Bayesian approach to spatiotemporal anomaly detection is applicable to a wide range of sensor networks.	anomaly detection;bayesian network;network model;sensor;unsupervised learning	X. Rosalind Wang;Joseph T. Lizier;Oliver Obst;Mikhail Prokopenko;Peter Wang	2008		10.1007/978-3-540-77690-1_6	unsupervised learning;anomaly detection;wireless sensor network;bayesian probability;computer science;machine learning;pattern recognition;bayesian network;data mining;coal mining;bayesian inference	AI	-11.871248270132858	-31.407427276482295	161127
d0f66db2e613f45ec21795b3dd8802dbcb7e2244	mining massive-scale spatiotemporal trajectories in parallel: a survey	parallel computing;spatiotemporal;trajectory mining	With the popularization of positioning devices such as GPS navigators and smart phones, large volumes of spatiotemporal trajectory data have been produced at unprecedented speed. For many trajectory mining problems, a number of computationally efficient approaches have been proposed. However, to more effectively tackle the challenge of big data, it is important to exploit various advanced parallel computing paradigms. In this paper, we present a comprehensive survey of the state-of-the-art techniques for mining massive-scale spatiotemporal trajectory data based on parallel computing platforms such as Graphics Processing Unit (GPU), MapReduce and Field Programmable Gate Array (FPGA). This survey covers essential topics including trajectory indexing and query, clustering, join, classification, pattern mining and applications. We also give an in-depth analysis of the related techniques and compare them according to their principles and performance.	algorithm;algorithmic efficiency;apache hadoop;big data;central processing unit;cluster analysis;data mining;distributed computing;field-programmable gate array;gps navigation device;global positioning system;graphics processing unit;hardware acceleration;intel core (microarchitecture);join (sql);manycore processor;mapreduce;parallel computing;smartphone;speedup;statistical classification;terabyte	Pengtao Huang;Bo Yuan	2015		10.1007/978-3-319-25660-3_4	computer science;data science;theoretical computer science;machine learning;data mining;spatiotemporal database	DB	-14.644125109522008	-35.3294065981954	161530
67c9b9b069e973ccb42426b1d392079c3cfcf330	superseding nearest neighbor search on uncertain spatial databases	multidimensional probability density function superseding nearest neighbor search uncertain spatial databases conventional multidimensional index;nearest neighbor searches;base dato multidimensional;superseding nearest neighbor search;uncertain;uncertain spatial databases;neural networks;base de donnees multidimensionnelle;query processing;visual databases query processing search problems;uncertainty;funcion densidad probabilidad;probability density function;database;base dato;nearest neighbor searches spatial databases neural networks multidimensional systems probability density function uncertainty;probabilistic approach;multidimensional database;spatial database;conventional multidimensional index;fonction densite probabilite;vecino mas cercano;systeme incertain;multidimensional probability density function;enfoque probabilista;approche probabiliste;indexation;spatial databases;nearest neighbor;base donnee orientee objet;base de donnees;plus proche voisin;nearest neighbour;base dato especial;search problems;object oriented databases;nearest neighbor search;base de donnees spatiale;sistema incierto;uncertain system;spatial database nearest neighbor uncertain;multidimensional systems;visual databases	This paper proposes a new problem, called superseding nearest neighbor search, on uncertain spatial databases, where each object is described by a multidimensional probability density function. Given a query point q, an object is a nearest neighbor (NN) candidate if it has a nonzero probability to be the NN of q. Given two NN-candidates o1 and o2, o1 supersedes o2 if o1 is more likely to be closer to q. An object is a superseding nearest neighbor (SNN) of q, if it supersedes all the other NN-candidates. Sometimes no object is able to supersede every other NN-candidate. In this case, we return the SNN-core-the minimum set of NN-candidates each of which supersedes all the NN-candidates outside the SNN-core. Intuitively, the SNN-core contains the best objects, because any object outside the SNN-core is worse than all the objects in the SNN-core. We show that the SNN-core can be efficiently computed by utilizing a conventional multidimensional index, as confirmed by extensive experiments.	algorithm;analysis of algorithms;artificial neural network;computation;database;experiment;mathematical optimization;nearest neighbor search;overhead (computing);query optimization;spiking neural network	Sze Man Yuen;Yufei Tao;Xiaokui Xiao;Jian Pei;Donghui Zhang	2010	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2009.137	probability density function;uncertainty;multidimensional systems;computer science;machine learning;pattern recognition;data mining;database;mathematics;nearest neighbor search;k-nearest neighbors algorithm;spatial database;artificial neural network;statistics	DB	-8.307264774171859	-33.18105013986167	162369
45bed959a6a754a061480cd394f6df592f288ac8	feasibility of traveling time estimation with mutual comparison of cvp, gvp and vd technologies	number of location update traveling time estimation cvp gvp vd cellular based vehicle probe gps based vehicle probe vehicle detection etc based vehicle probe evp national highway traffic jams nlu;road traffic;cellular radio;roads vehicles availability cities and towns;automated highways;road traffic automated highways cellular radio global positioning system object detection;cvp traveling time estimation vd cms evp;global positioning system;object detection	This paper proposes a feasibility study of traveling time estimation with mutual comparison of cellular-based vehicle probe (CVP), GPS-based Vehicle Probe and vehicle detection (VD) technologies. The travel time estimation algorithms have been designed for VD, CVP, GVP and some case in EVP (ETC-based Vehicle Probe). We have compared the system performance outputs at National Highway #1, Fast way #66, local governmental road #1 at Taoyuan to Jong-Li, and Sun-Moon Lake area on specific continuous holiday or working days. The outcome of this research is to target a CVP deployment with a percentage rate of 1%, a sample interval of 10 seconds and transmission interval of 30 seconds. Such a system will accurately determine the locations of both incidents and the tail end of traffic jams. It can be used to estimate travel times with mutual comparisons for VD, CVP, GVP, and EVP especially on continuous holidays. If we select the total # of NLU (number of location update) is less than 100 at local road section, then the CVP has good condition at traveling time estimation.	algorithm;nx bit;natural language understanding;sampling (signal processing);software deployment;traffic exchange	Shing Tenqchen;Francis Chang;Kluo-Yueh Chen;Dong-Ling Wu;Shin-Hshun Huang	2012	2012 12th International Conference on ITS Telecommunications	10.1109/ITST.2012.6425210	simulation;telecommunications;engineering;transport engineering	Robotics	-18.72943040025677	-29.25910045816673	162547
2ad88a58ab19163cdd9acc9245ab875ab36b9d53	temporal pattern mining in dynamic environments	dynamic environment;temporal pattern	Dynamic scenes with many different objects and interrelations changing over time demand complex representations. The identification of frequent patterns and prediction rules in such scenes would be very valuable as associations in the data could be discovered or a system’s performance could even be improved by utilizing the new information in the behavior decision process. In this work, a novel approach to temporal pattern mining in dynamic environments has been proposed.	data mining	Andreas D. Lattner	2007			simulation;engineering;artificial intelligence;data mining	ML	-12.367215774640062	-35.020815896482254	162586
14bd3a725ae3d00627e3ed13abb238ed5a170185	fun at a department store: data mining meets switching theory	sum of products;implicants;data mining;frequent itemset;data mining application;compact representation;frequent closed itemset;blulife;frequent itemsets;sop;heuristic algorithm	In this paper we introduce new algebraic forms, SOP+ and DSOP+, to represent functions f : {0,1}n → N, based on arithmetic sums of products. These expressions are a direct generalization of the classical SOP and DSOP forms. We propose optimal and heuristic algorithms for minimal SOP+ and DSOP+ synthesis. We then show how the DSOP+ form can be exploited for Data Mining applications. In particular we propose a new compact representation for the database of transactions to be used by the LCM algorithms for mining frequent closed itemsets.	data mining;switching circuit theory	Anna Bernasconi;Valentina Ciriani;Fabrizio Luccio;Linda Pagli	2010		10.1007/978-3-642-13122-6_7	heuristic;computer science;data mining;database;mathematics;canonical normal form;algorithm	ML	-4.5778261460457115	-36.250976322807226	162624
9ab0d915b1eb9daa4bed1d682896b0fbe57cdeae	temporal event sequence rule mining		The emergence of remote sensing, scientific simulation and other survey technologies has dramatically enhanced our capabilities to collect temporal data. However, the explosive growth in data makes the management, analysis, and use of data both difficult and expensive. Methods that characterize interesting or unusual patterns from the volumes of temporal data are needed (Roddick & Spiliopoulou, 2002; Han & Kamber, 2005). The association rule mining methods described in this chapter provide the ability to find periodic occurrences of inter-sequential factors of interest, from groups of long, non-transactional temporal event sequences. Association rule mining is well-known to work well for problems related to the recognition of frequent patterns of data (Han & Kamber, 2005). Rules are relatively easy for humans to interpret and have a long history of use in artificial intelligence for representing knowledge learned from data.	artificial intelligence;association rule learning;emergence;han unification;simulation	Sherri K. Harms	2009			data mining;event type;computer science	AI	-9.884431640267286	-34.31755971772945	163071
1161020666b2627e4b55b89477a898112fa6805f	an application of the fis-crm model to the fiss metasearcher: using fuzzy synonymy and fuzzy generality for representing concepts in documents	cluster algorithm;hierarchical structure;search engine;computacion informatica;web pages;vector space model;ciencias basicas y experimentales;term weighting;grupo a	The main objective of this work is to improve the quality of the results produced by the Internet search engines. In order to achieve it, the FIS-CRM model (Fuzzy Interrelations and Synonymy based Concept Representation Model) is proposed as a mechanism for representing the concepts (not only terms) contained in any kind of document. This model, based on the vector space model, incorporates a fuzzy readjustment process of the term weights of each document. The readjustment lies on the study of two types of fuzzy interrelations between terms: the fuzzy synonymy interrelation and the fuzzy generality interrelation (so called “broader than” interrelation). The model has been implemented in the FISS metasearcher (Fuzzy Interrelations and Synonymy based Searcher) that, using a soft-clustering algorithm (based on the SISC algorithm), dinamically produces a hierarchical structure of groups of “conceptually related” documents (snippets of web pages, in this case).	algorithm;cluster analysis;internet;serial ata;web page;web search engine	José Angel Olivas;Pablo J. Garcés;Francisco P. Romero	2003	Int. J. Approx. Reasoning	10.1016/j.ijar.2003.07.008	fuzzy classification;computer science;artificial intelligence;fuzzy number;machine learning;web page;data mining;mathematics;vector space model;fuzzy set operations;algorithm;search engine	Web+IR	-5.449368320519527	-26.10464320572013	163111
baa985ec28ab345b165b5a167a62121707ea2bc1	latent variable structured bayesian network for cyanobacterial risk pre-control		Cyanobacterial blooms increasingly pose threats to ecosystems and human health. This paper is aimed to propose systematic risk pre-control schemes by understanding the complex causalities between cyanobacteria and multiple influencing variables. This research remains a challenge for three reasons. Firstly, the time-series evolution of cyanobacteria is characterized by deep uncertainties and nonlinear dynamics. Secondly, latent variables with hidden information usually exist in this kind of complex aquatic system. Thirdly, it is difficult to identify an efficient pre-control scheme that specifies variables for preferential regulation. To address these problems, we propose a latent variable structured Bayesian network model and a corresponding parameter learning algorithm. The model is tested by real-time spatio-temporal data. The computational results reveal that the proposed model demonstrates better performance in terms of inference accuracy and degree of system understanding. Based on sensitivity analysis and combination-effect analysis, a systematic risk pre-control scheme is proposed for decision-makers to prevent cyanobacterial blooms under the scenario of global warming.		Peng Jiang;Xiao Liu;Jingjie Zhang;Shu Harn Te;Karina Y. H. Gin	2018	2018 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2018.8607414		Robotics	-12.577313459526955	-29.917391940512296	163355
123995303992a2298970089fb48443f40527ff42	event stream processing for improved situational awareness in the smart grid	data mining;wide area monitoring;synchrophasor;situational awareness;stream processing	Deployment of PMUs in grid has brought a new data stream to be processed.New method of stream processing is proposed to improve awareness in power systems.Phasor data stream is mined to minimize wide spread outages and cascading failures.Synchrophasor data is processed within acceptable time, memory, and accuracy.Operators can be alerted quickly to improve the future power systems' reliability. Deployment of Phasor Measurement Units (PMU) in the United States transmission grid has brought a new data stream to be processed and an opportunity to improve situational awareness on the grid. This new data stream offers opportunity for a faster detection and response algorithm to minimize wide spread outages. High rate of data collection of PMU systems has also brought a challenge on how to extract information from fast moving PMU data stream in real time to improve situational awareness inside a control room. Despite the fact that mathematical and probabilistic methods are the most accurate methods of stability analysis, online decision making algorithms cannot afford the latency brought by those methods. Traditional batch processing Artificial Intelligence (AI) techniques have been extensively studied as potential replacements for these approaches, however conventional AI techniques do not deal with continuous streams of fast moving phasor data. This paper presented a novel application of the stream mining algorithms for synchrophasor data to meet quick decision making requirement of future situational awareness applications in power systems. To prove that the proposed methods are efficient and capable of handling huge amounts of data with reasonable accuracy and within limited resources of memory and computational power, four different experiments with different conditions (changing/unchanging the load conditions of Real Power and Reactive Power, fixing the size of memory, and comparing the performance of non-adaptive Hoeffding tree with traditional decision tree algorithms) were conducted. The algorithms discussed in this paper support decisions inside the control rooms helping stakeholders make informed decisions to improve reliability of the future smart grid.	event stream processing	N. Dahal;O. AbuOmar;Roger L. King;Vahid Madani	2015	Expert Syst. Appl.	10.1016/j.eswa.2015.05.003	situation awareness;real-time computing;stream processing;computer science;artificial intelligence;machine learning;data mining;data stream mining;computer security	DB	-14.156467342758743	-30.15971044077004	163831
ea5e756308edc547f569a942b4c81e198d0a2927	efficient association rule mining among both frequent and infrequent items	infrequent items;data mining;association rule mining;association rule;correlation;frequent items	Association rule mining among frequent items has been extensively studied in data mining research. However, in recent years, there has been an increasing demand for mining the infrequent items (such as rare but expensive items). Since exploring interesting relationship among infrequent items has not been discussed much in the literature, in this paper, we propose two simple, practical and effective schemes to mine association rules among rare items. Our algorithm can also be applied to frequent items with bounded length. Experiments are performed on the well-known IBM synthetic database. Our schemes compare favorably to Apriori and FPgrowth under the situation being evaluated. c © 2007 Elsevier Ltd. All rights reserved.	apriori algorithm;association rule learning;collision (computer science);dspace;data mining;experiment;synthetic intelligence;traverse;whole earth 'lectronic link	Ling Zhou;Stephen S.-T. Yau	2007	Computers & Mathematics with Applications	10.1016/j.camwa.2007.02.010	association rule learning;computer science;data science;data mining;database;mathematics;apriori algorithm	DB	-5.304619697043413	-37.30032037054947	163834
3f2a77da79d3a663979ec4ef18caf215bf732469	the role of planning and inference in an intelligent traffic monitor	limit distribution;artificial intelligent;decision support system;automatic detection;signal processing;traffic monitoring	Road transport informatics relies almost entirely upon conventional signal processing technology for feedback and input into decision support systems. This paper presents ongoing research into improving the quality of such feedback and enhancing the functioning of a decision support system through the application of planning techniques and inference methods commonly used within the field of artificial intelligence (AI). The impetus for this research is derived from the European Communities' DRIVE programme under whose direction a number of advanced traffic science projects are improving aspects of traffic monitoring technology. Within this latter group is AUTOPOLIS, a dual automatic monitoring and policing system whose objectives are the automatic detection and deterrence of traffic violations. An initial software simulation providing aerial views of different dynamic traffic configurations and incorporating an inference mechanism and (limited) distributed planning has been implemented.	aerial photography;artificial intelligence;computer simulation;decision support system;informatics;signal processing;website monitoring	John G. Harper	1990		10.1145/98784.98890	simulation;decision support system;intelligent decision support system;computer science;artificial intelligence;machine learning;signal processing;data mining;operations research	AI	-17.944866809149392	-24.687326956358177	163866
3a456b2933cb09bc192b390defe3e479e85ba595	regret-minimizing representative databases	database system;score function;multi criteria decision making;interest points;utility function;linear time	We propose the k-representative regret minimization query (k-regret) as an operation to support multi-criteria decision making. Like top-k, the k-regret query assumes that users have some utility or scoring functions; however, it never asks the users to provide such functions. Like skyline, it filters out a set of interesting points from a potentially large database based on the users’ criteria; however, it never overwhelms the users by outputting too many tuples. In particular, for any number k and any class of utility functions, the k-regret query outputs k tuples from the database and tries to minimize the maximum regret ratio. This captures how disappointed a user could be had she seen k representative tuples instead of the whole database. We focus on the class of linear utility functions, which is widely applicable. The first challenge of this approach is that it is not clear if the maximum regret ratio would be small, or even bounded. We answer this question affirmatively. Theoretically, we prove that the maximum regret ratio can be bounded and this bound is independent of the database size. Moreover, our extensive experiments on real and synthetic datasets suggest that in practice the maximum regret ratio is reasonably small. Additionally, algorithms developed in this paper are practical as they run in linear time in the size of the database and the experiments show that their running time is small when they run on top of the skyline operation which means that these algorithm could be integrated into current database systems.	algorithm;database;experiment;regret (decision theory);scoring functions for docking;synthetic intelligence;time complexity	Danupon Nanongkai;Atish Das Sarma;Ashwin Lall;Richard J. Lipton;Jun Xu	2010	PVLDB	10.14778/1920841.1920980	time complexity;computer science;machine learning;data mining;database;mathematics;score;statistics	DB	-6.520243959575529	-35.9141788028402	163941
d70d1c6594548a841153b638d7ff466b09f38a49	"""""""serial"""" versus """"parallel"""": a comparison of spatio-temporal clustering approaches"""		Spatio-temporal clustering, which is a process of grouping objects based on their spatial and temporal similarity, is increasingly gaining more scientific attention. Research in spatio-temporal clustering mainly focuses on approaches that use time and space in parallel. In this paper, we introduce a serial spatio-temporal clustering algorithm, called ST-DPOLY, which creates spatial clusters first and then creates spatio-temporal clusters by identifying continuing relationships between the spatial clusters in consecutive time frames. We compare this serial approach with a parallel approach named ST-SNN. Both ST-DPOLY and ST-SNN are density-based clustering approaches: while ST-DPOLY employs a density-contour based approach that operates on an actual density function, ST-SNN is based on well-established generic clustering algorithm Shared Nearest Neighbor (SNN). We demonstrate the effectiveness of these two approaches in a case study involving a New York city taxi trip dataset. The experimental results show that both ST-DPOLY and ST-SNN can find interesting spatio-temporal patterns in the dataset. Moreover, in terms of time and space complexity, ST-DPOLY has advantages over ST-SNN, while ST-SNN is more superior in terms of temporal flexibility; in terms of clustering results, results of ST-DPOLY are easier to interpret, while ST-SNN obtains more clusters which overlap with each other either spatially or temporally, which makes interpreting its clustering results more complicated.		Yongli Zhang;Sujing Wang;Amar Mani Aryal;Christoph F. Eick	2017		10.1007/978-3-319-60438-1_39	spacetime;machine learning;artificial intelligence;batch processing;probability density function;cluster analysis;computer science;k-nearest neighbors algorithm	HPC	-11.860213888185811	-35.923474982902775	163944
675240c9fb95cb882b28c525448032edd66e8ce7	initial scene configurations for highway traffic propagation	bayesian statistics;traffic engineering computing automobiles bayes methods digital simulation risk analysis road safety road traffic statistical distributions;safety evaluation;vehicles road transportation computational modeling safety atmospheric modeling bayes methods joints;data files;interstate 80 initial scene configurations highway traffic propagation automotive safety systems driving traces safety risk probability distributions highway scenes safety evaluation automated model construction bayesian statistical framework ngsim highway 101;validation;vehicle safety;active safety systems;ngsim computer model;distributions statistics	Validation of automotive safety systems can be done by simulating millions of driving traces. It is important that the distribution of initial scenes for these driving traces be as representative of reality as possible so that safety risk can be estimated accurately. This paper presents a methodology for constructing probability distributions over initial highway scenes from which samples can be drawn for safety evaluation through simulation. A method for automated model construction based on a Bayesian statistical framework is introduced and applied to the NGSIM Highway 101 and Interstate 80 datasets. Four models of increasing complexity and fidelity are developed. A complete implementation is available online.	bayesian network;bus (computing);complexity;digital footprint;download;fidelity of quantum states;risk assessment;simulation;software propagation;tracing (software)	Tim Allan Wheeler;Mykel J. Kochenderfer;Philipp Robbel	2015	2015 IEEE 18th International Conference on Intelligent Transportation Systems	10.1109/ITSC.2015.55	simulation;engineering;transport engineering;computer security	Robotics	-17.811652351193544	-27.319474929862448	164098
9d7dc9362413cd618d2d3b5cd57d20063e41be4e	road network-aware spatial alarms	optimisation client server systems directed graphs network theory graphs;spatial alarms;euclidean distance;road networks;scalability spatial alarms road networks motion behavior optimization;accuracy;servers;roads;mobile communication;roads mobile communication mobile computing servers euclidean distance accuracy subscriptions;subscriptions;optimization;mobile clients hibernation time road network aware spatial alarms time based alarms spatial dimension spatially constrained road networks mobile subscriber mobility patterns euclidian distance based spatial alarm processing techniques client energy consumption client wakeups roadalarm system road network distance measures rectangular region star like subgraph alarm target border points alarm region baseline approach spatial alarm processing subscription filter euclidean lower bound filter shortest path computation reduction alarm hibernation time alarm checks optimization techniques motion aware filters;scalability;mobile computing;motion behavior	Road network-aware spatial alarms extend the concept of time-based alarms to spatial dimension and remind us when we travel on spatially constrained road networks and enter some predefined locations of interest in the future. This paper argues that road network-aware spatial alarms need to be processed by taking into account spatial constraints on road networks and mobility patterns of mobile subscribers. We show that the Euclidian distance-based spatial alarm processing techniques tend to incur high client energy consumption due to unnecessarily frequent client wakeups. We design and develop a road network-aware spatial alarm processing system, called ROADALARM, with three unique features. First, we introduce the concept of road network-based spatial alarms using road network distance measures. Instead of using a rectangular region, a road network-aware spatial alarm is a star-like subgraph with an alarm target as the center of the star and border points as the scope of the alarm region. Second, we describe a baseline approach for spatial alarm processing by exploiting two types of filters. We use subscription filter and Euclidean lower bound filter to reduce the amount of shortest path computations required in both computing alarm hibernation time and performing alarm checks at the server. Last but not the least, we develop a suite of optimization techniques using motion-aware filters, which enable us to further increase the hibernation time of mobile clients and reduce the frequency of wakeups and alarm checks, while ensuring high accuracy of spatial alarm processing. Our experimental results show that the road network-aware spatial alarm processing significantly outperforms existing Euclidean space-based approaches, in terms of both the number of wakeups and the hibernation time at mobile clients and the number of alarm checks at the server.	a* search algorithm;baseline (configuration management);computation;euclidean distance;image scaling;mathematical optimization;scalability;server (computing);shortest path problem	Kisung Lee;Ling Liu;Balaji Palanisamy;Emre Yigitoglu	2016	IEEE Transactions on Mobile Computing	10.1109/TMC.2015.2405543	scalability;simulation;mobile telephony;telecommunications;computer science;operating system;euclidean distance;accuracy and precision;mobile computing;computer security;server;computer network	DB	-16.178999478432303	-33.92732143445074	164145
922a083d992e8c704fc990f8f1552789abbf75d2	finding the informative and concise set through approximate skyline queries		Abstract Querying databases to search for “best” objects matching users’ preferences is a fundamental problem of intelligent systems and applications. The skyline query is an important tool for solving such a best-matching problem from the concept of multi-criteria optimization. However, it has the size problem as the size of the results of a skyline query grows superlinearly with the number of criteria. Here, we propose to find both the informative and concise set of skyline, a refined skyline set without similar objects. The informativeness requires the reduced set to cover the skyline, i.e., for every skyline point in the original dataset, there exists a close point in the reduced set, which help users to understand the skyline in more detail and make a better decision. The conciseness requires the size of the reduced set that can cover the skyline is as smaller as possible, which help users to make a quick decision. Finding both the informative and concise set of skyline will boost the usability of intelligent systems. More specifically, we propose two new skyline queries to find the informative and concise set of skyline: minimum skyline query, and extended minimum skyline query. The main idea is to return the minimum number of approximation objects, in which there is an object within a predefined distance threshold for each skyline object. The difference of the two query types is that the former one selects approximation objects only from skyline set, while the latter one selects from the whole dataset. We present an exact solution which computes minimum skyline in linear time for a 2 d -space. As both minimum skyline and extended minimum skyline problems are NP-hard for dimensionality at least three, we present greedy solutions that obtain a 1 + ln R approximation of the optimums. A comprehensive performance evaluation demonstrates that the size of skyline set can be effectively reduced by using the proposed (extended) minimum skyline queries and our proposed algorithms have promising results.		Bo Yin;Xuetao Wei;Yonghe Liu	2019	Expert Syst. Appl.	10.1016/j.eswa.2018.11.004	machine learning;time complexity;artificial intelligence;skyline;intelligent decision support system;curse of dimensionality;existential quantification;usability;computer science	DB	-7.779586525270863	-36.432726303213684	164583
e55028d753aa89fb91e4dec48122e87fbd1fd995	utilizing bada (base of aircraft data) as an on-board navigation decision support system in commercial aircrafts	commercial aircrafts;air traffic control;government policy;aviation safety;aircraft navigation atmospheric modeling europe aircraft propulsion fault detection government policies trajectory;decision support systems air traffic control aircraft navigation;bayes theorem;civil aircraft;accuracy;aircraft navigational aids;decision support system;trajectory;aircraft propulsion;base of aircraft data;fuel flow;navigation systems;data files;fault detection;decision support systems;government policies;fuel flow base of aircraft data on board navigation decision support system commercial aircrafts air traffic management rate of climb or descent;atmospheric modeling;europe;rate of climb or descent;high accuracy;on board navigation decision support system;bayesian networks;aircraft navigation;air traffic management	The European organization for the Safety of Air Navigation is developing and maintaining BADA for use in trajectory simulation within the field of Air Traffic Management (ATM). There has been continuous research on using BADA for the estimation of fuel consumption and aviation global emission. In contrast, little attention has been paid to utilize BADA as an on-board navigation support system. In this research, we propose a framework using BADA's operation data to check if an aircraft is operating within a recommended speed, rate of climb or descent (ROCD), or fuel flow. Various simulated flight scenarios were introduced in a controlled deterministic environment, and the results accurately verified the concept of operation.	atm turbo;bada;decision support system;on-board data handling;simulation	Ali Hilal Ali	2011	IEEE Intelligent Transportation Systems Magazine	10.1109/MITS.2011.941332	atmospheric model;simulation;decision support system;aerospace engineering;computer science;engineering;trajectory;air traffic control;automotive engineering;bayesian network;aviation safety;accuracy and precision;data file;bayes' theorem;fault detection and isolation;statistics	Robotics	-17.993488181234707	-27.188538889421114	164766
22ac4cc073de1850da3c2e00132e61866b7a1207	a meta-analysis on the return on investment of geospatial data and systems: a multi-country perspective		The availability, quality and accessibility of Geographic Information (GI) have significant socio-economic and environmental benefits, but the collection and maintenance of GI require substantial investments. Cost-benefit assessments (CBAs) attempt to justify the costs of geospatial data investments, applying different methodologies and focusing on diverse areas. Therefore, the Returns on Investment (ROI) vary considerably across studies, regions and sectors. The objective of this study is to explain some of the variation in the average ROI of GI by conducting a meta-analysis of 82 cost-benefit assessments between 1994 and 2013. In a first step, CBAs are systematically reviewed and relevant information is extracted. Particular emphasis is given to investment conditions and study characteristics. In a second step, multivariate regression methods are used to assess the size, significance and direction of individual effects. The results suggest that regional factors have the largest impact on the profitability of GI. Returns in Australia and New Zealand, for example, are four times larger than in Europe. In addition, small-scale regional investments have a 2.5 times lower return than large-scale international investments. Overall, the expected benefits of GI investments are approximately 3.2 times larger than the costs.	accessibility;disk sector;general linear model;geographic information system;region of interest	Natalie Trapp;Uwe A. Schneider;Ian McCallum;Steffen Fritz;Christian Schill;Maria Teresa Borzacchiello;Christine Heumesser;Massimo Craglia	2015	Trans. GIS	10.1111/tgis.12091	actuarial science	Web+IR	-10.654468366411603	-24.824082152582353	164802
5bf5ea39c1c19e7815f29225cd9043837fdf1ec6	non-almost-derivable frequent itemsets mining	condensed representation nonalmost derivable frequent itemset mining apriori like algorithm;data mining;upper bound;frequent itemset;itemsets data mining upper bound information technology transaction databases association rules;frequent itemset mining;condensed representation;apriori like algorithm;lower bound;nonalmost derivable frequent itemset mining	The number of frequent itemsets is often too large to handle, so it is very necessary to work out a condensed representation of the collection of all frequent itemsets. In this paper, we propose a new condensed representation called frequent non-almost-derivable itemsets. This representation is a subset of the original collection of frequent itemsets. For any removed itemset X (which is called an frequent almost-derivable itemset), we can derive a lower and an upper bound of its support from this representation, and the lower bound and the upper bound is close enough (can be controlled by a user-defined parameter). We also propose an apriori-like algorithm, which can extract all frequent non-derivable itemsets. Extensive empirical results on real datasets show the compactness and good approximation of this representation	approximation;apriori algorithm;experiment;kinetic data structure;real-time clock;server (computing)	Xiaoming Yang;Zhibin Wang;Bing Liu;Shouzhi Zhang;Wei Wang;Baile Shi	2005	The Fifth International Conference on Computer and Information Technology (CIT'05)	10.1109/CIT.2005.144	pattern recognition;data mining;database;upper and lower bounds	ML	-6.524533118520278	-37.09221019717126	164875
ce4332e89e43e23762896f217ce44820cb0c39ab	hybrid algorithm for floor detection using gsm signals in indoor localisation task		One of challenging problems of indoor localisation based on GSM fingerprints is the detection of the current floor. We propose an off–line algorithm that labels fingerprints with the number of current floor. The algorithm uses one pass through the given route to learn the GSM fingerprints. After that the height on the testing passes of the same route can be estimated with high accuracy even for measures registered with various velocities and a month after the learning process. The two phase algorithm detects the points of a potential floor change. Next, the regression function normalises height of the change and calculates its direction. The obtained results are up to 40 % better than the results obtained by the pure regression.	hybrid algorithm	Marcin Luckner;Rafal Górak	2016		10.1007/978-3-319-32034-2_61	gsm;artificial intelligence;pattern recognition;hybrid algorithm;computer science	Vision	-13.400571181379624	-34.97060779462743	165074
0ccc08cdf6a9f4944669f0ed6fe2536fd996d9f5	learning and inferring transportation routines	modelizacion;medida informacion;rao blackwellized particle filter;rao blackwellized particle filters;hierarchical markov model;pistage;location tracking;transporte publico;cognitive impairment;modelo markov;nouveaute;public transport;parking;mesure information;localization;stationnement;systeme gps;novelty;rastreo;estacionamiento;public transportation;abstraction;mesure niveau;novedad;novelty detection;intelligence artificielle;localizacion;abstraccion;gps system;modele multiple;modelisation;captador medida;fichier log;measurement sensor;markov model;fichero actividad;capteur mesure;localisation;information measure;levels of abstraction;transport public;multimodel;comportement utilisateur;inferencia;level measurement;artificial intelligence;inteligencia artificial;user behavior;modele markov;modelo multiple;modeling;inference;comportamiento usuario;log file;tracking;historical data;sistema gps;medicion nivel;activity recognition	This paper introduces a hierarchical Markov model that can learn and infer a user’s daily movements through the community. The model uses multiple levels of abstraction in order to bridge the gap between raw GPS sensor measurements and high level information such as a user’s mode of transportation or her goal. We apply Rao-Blackwellised particle filters for efficient inference both at the low level and at the higher levels of the hierarchy. Significant locations such as goals or locations where the user frequently changes mode of transportation are learned from GPS data logs without requiring any manual labeling. We show how to detect abnormal behaviors (e.g.taking a wrong bus) by concurrently tracking his activities with a trained and a prior model. Experiments show that our model is able to accurately predict the goals of a person and to recognize situations in which the user performs unknown activities.	experiment;global positioning system;high-level programming language;markov chain;markov model;particle filter;principle of abstraction;raw image format	Lin Liao;Dieter Fox;Henry A. Kautz	2004		10.1016/j.artint.2007.01.006	simulation;user modeling;computer science;artificial intelligence;public transport;activity recognition	AI	-12.654600833260002	-31.32197994561496	165209
e5b8710c369dc1b5535784373e1d09627f78657b	up and down: mining multidimensional sequential patterns using hierarchies	soft drinks;decision maker;data mining;hierarchies;chip;multidimensional sequences;sequential pattern;data warehouse;convergent and divergent sequences	Data warehouses contain large volumes of time-variant data stored to help analysis. Despite the evolution of OLAP analysis tools and methods, it is still impossible for decision makers to find data mining tools taking the specificity of the data (e.g. multidimensionality, hierarchies, time-variant) into account. In this paper, we propose an original method to automatically extract sequential patterns with respect to hierarchies. This method extracts patterns that describe the inner trends by displaying patterns that either go from precise knowledge to general knowledge or go from general knowledge to precise knowledge. For instance, one rule exhibited could be  data contain first many sales of coke in Paris and lemonade in London for the same date, followed by a large number of sales of soft drinks in Europe , which is said to be  divergent (as precise results like coke precede general ones like soft drinks). On the opposite, rules like  data contain first many sales of soft drinks in Europe and chips in London for the same date, followed by a large number of sales of coke in Paris are said to be  convergent . In this paper, we define the concepts related to this original method as well as the associated algorithms. The experiments which we carried out show the interest of our proposal.		Marc Plantevit;Anne Laurent;Maguelonne Teisseire	2008		10.1007/978-3-540-85836-2_15	chip;decision-making;computer science;data science;machine learning;data warehouse;data mining;database;hierarchy	EDA	-5.165214614175144	-34.689959767129224	165296
24c4c20ccda15b831b199f87491813f876d4db07	assembler: efficient discovery of spatial co-evolving patterns in massive geo-sensory data	biological patents;co evolving pattern;biomedical journals;text mining;spatiotemporal data;europe pubmed central;citation search;citation networks;sensor network;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Recent years have witnessed the wide proliferation of geo-sensory applications wherein a bundle of sensors are deployed at different locations to cooperatively monitor the target condition. Given massive geo-sensory data, we study the problem of mining spatial co-evolving patterns (SCPs), i.e., groups of sensors that are spatially correlated and co-evolve frequently in their readings. SCP mining is of great importance to various real-world applications, yet it is challenging because (1) the truly interesting evolutions are often flooded by numerous trivial fluctuations in the geo-sensory time series; and (2) the pattern search space is extremely large due to the spatiotemporal combinatorial nature of SCP. In this paper, we propose a two-stage method called Assember. In the first stage, Assember filters trivial fluctuations using wavelet transform and detects frequent evolutions for individual sensors via a segment-and-group approach. In the second stage, Assember generates SCPs by assembling the frequent evolutions of individual sensors. Leveraging the spatial constraint, it conceptually organizes all the SCPs into a novel structure called the SCP search tree, which facilitates the effective pruning of the search space to generate SCPs efficiently. Our experiments on both real and synthetic data sets show that Assember is effective, efficient, and scalable.	assembly language;experiment;floods;pattern search (optimization);scalability;search tree;secure copy;stage level 1;stage level 2;synthetic data;time series;wavelet transform;sensor (device)	Chao Zhang;Yu Zheng;Xiuli Ma;Jiawei Han	2015	KDD : proceedings. International Conference on Knowledge Discovery & Data Mining	10.1145/2783258.2783394	text mining;wireless sensor network;computer science;bioinformatics;data science;machine learning;data mining	ML	-12.70620808755087	-32.954757960162965	165414
8eac36e6a13331514c45285407f97a732ec28add	efficient processing of intelligent probabilistic collision detection queries		A new type of the spatio-temporal queries is the Intelligent Probabilistic Collision Detection Query (IPCDQ for short). In this paper, we focus on efficiently processing the IPCDQ on moving objects with uncertainty. Given two sets O and Q of objects, each of which moves with uncertain speed and direction, a time instant t, and a probability threshold P, the IPCDQ returns each pair of objects (o, q) (where $$o \in O$$ o ∈ O and $$q \in Q$$ q ∈ Q ), whose probability of colliding with each other is greater than or equal to P at time t. The pairs of objects satisfying the IPCDQ are termed the collision-possible pairs (or CPPs for short). We utilize a $$R^{lsd}$$ R l s d -tree, in which the spatially proximate objects with similar uncertain speeds and directions are grouped together, to effectively manage the moving objects in O. Similarly, a $$R^{lsd}$$ R l s d -tree is used to index the moving objects in Q. Then, with the two $$R^{lsd}$$ R l s d -trees for O and Q, respectively, we develop the specialized index traversals combined with three pruning criteria, the location-pruning criterion, the angle-pruning criterion, and the speed-pruning criterion to efficiently determine the objects that may collide with each other. Besides, to provide the more useful information to the user, we propose a probability model to quantify the possibility of each object pair being the query result. Comprehensive experiments demonstrate the efficiency and the effectiveness of the proposed methods.	alpha–beta pruning;collision detection;eisenstein's criterion;experiment	Yuan-Ko Huang	2016	Computing	10.1007/s00607-016-0516-7	theoretical computer science;machine learning;data mining;mathematics	DB	-8.41966776391512	-37.61180824789795	165490
aa3ce5d4333b8396a0da06d42c1388d62a9948d3	mining frequent closed itemsets from distributed repositories	frequent itemsets;knowledge grid;distributed data mining.;closed itemsets	In this paper we address the problem of mining frequent closed itemsets in a highly distributed setting like a Grid. The extraction of frequent (closed) item-sets is a very expensive phase needed to extract from a transactional database a reduced set of meaningful association rules. We figure out an environment where different datasets are stored in different sites. We assume that, due to the huge size of datasets and privacy concerns, dataset partitions cannot be moved to a centralized site where to materialize the whole dataset and perform the mining task. Thus it becomes mandatory to perform separate mining at each site, and then merge local results for deriving global knowledge.This paper shows how frequent closed itemsets, mined independently at each site, can be merged in order to derive globally frequent closed itemsets. Unfortunately, such merging might produce a superset of all the frequent closed itemsets, while the associated supports could be smaller than the exact ones because some globally frequent closed itemsets might be not locally frequent in some partitions. To avoid an expensive post-processing phase, needed to compute exact global results, we use a method to approximate the supports of closed itemsets. The approximation is only needed for those globally (closed) frequent itemsets which are locally infrequent on some dataset partitions, and thus are not returned at all from the corresponding sites.		Claudio Lucchese;Salvatore Orlando;Raffaele Perego;Claudio Silvestri	2005		10.1007/978-0-387-37831-2_14	grid;merge (version control);data mining;association rule learning;computer science;database transaction	ML	-5.870580293156981	-35.188690198787555	165618
3123a30c48d6005230759ece3228f53d097685db	semi-supervised threshold queries on pharmacogenomics time sequences	time series;time series analysis;trend analysis;data mining;seasonality;time series data;access method;mode of action	The analysis of time series data is of capital importance for pharmacogenomics since the experimental evaluations are usually based on observations of time dependent reactions or behaviors of organisms. Thus, data mining in time series databases is an important instrument towards understanding the effects of drugs on individuals. However, the complex nature of time series poses a big challenge for effective and efficient data mining. In this paper, we focus on the detection of temporal dependencies between different time series: we introduce the novel analysis concept of threshold queries and its semi-supervised extension which supports the parameter setting by applying training datasets. Basically, threshold queries report those time series exceeding an user-defined query threshold at certain time frames. For semi-supervised threshold queries the corresponding threshold is automatically adjusted to the characteristics of the data set, the training dataset, respectively. In order to support threshold queries efficiently, we present a new efficient access method which uses the fact that only partial information of the time series is required at query time. In an extensive experimental evaluation we demonstrate the performance of our solution and show that semi-supervised threshold queries applied to gene expression data are very worthwhile.	cluster analysis;data (computing);data mining;database;semi-supervised learning;semiconductor industry;time series	Johannes Aßfalg;Hans-Peter Kriegel;Peer Kröger;Peter Kunath;Alexey Pryakhin;Matthias Renz	2006			time domain;computer science;bioinformatics;data science;machine learning;time series;data mining;database;order of integration;statistics	DB	-9.86357275886166	-34.33297716948079	166061
b98164ae9e21a5fff5011a5cb61d4dfa64fa5f5f	mining weighted erasable patterns by using underestimated constraint-based pruning technique	weighted gain;weighted pattern mining;data mining;erasable pattern mining;weight based constraints	Erasable pattern mining is one of the variations in frequent pattern mining, and its main goal is to maximize the production capacity of manufacturing industries by quickly overcoming the financial crises that can occur in industries. However, existing erasable pattern mining approaches utilize only profit information for each product, but do not consider distinct weights of items organizing the products. In addition, previous algorithms spend much time and space mining erasable patterns due to their inefficient pattern mining methods. In a real-life environment, considering weights of items in each product can be more important compared to calculating product profits only. For this reason, we propose a novel algorithm for mining weighted erasable patterns by considering the distinct weight of each item. Moreover, we discuss both discovering weighted erasable patterns and minimizing the resource availability of erasable pattern mining processes utilizing weight conditions. Especially, our approach has advantages for time and space resource consumption compared to existing approaches because our algorithm uses a pattern pruning method and stores item information included in product databases by using both compact tree and hash list structures. We present performance evaluation utilizing both real and synthetic datasets to demonstrate the efficiency of our algorithm.		Gangin Lee;Unil Yun;Heungmo Ryang	2015	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-141398	computer science;data science;machine learning;data mining	Robotics	-5.772605377584463	-35.924048953383306	166119
dddb8c3ab71fc10bac98be061f0fd9f94c2510c3	a scenario-based assessment approach for automated driving by using time series classification of human-driving behaviour	websearch;time series analysis;feature extraction;safety;classification algorithms;mathematical model;vehicles;publications database;rwth publications;automation	Automated driving functions are under intensified development by industry and academia since the last decade. Due to the large operation space and various complex scenarios automated driving functions have to cope with, assessment efforts are expected to rise dramatically. In order to quantify benefits and risks of these functions in an efficient way, this paper describes a holistic approach for the assessment of automated driving by using real world driving data. Based on a scenario definition a suitable method for identifying relevant scenarios from real world driving data is described which is able to handle scenario specific characteristics such as the temporal and spatial dependencies of all traffic participants. For quantifying the effect of automated driving within the considered driving scenarios, the statistical indicator `effect size' is applied. The basic requirement that automated driving needs to operate within mixed traffic implies that the reference for assessment needs to be human manual driving behaviour.	autonomous car;holism;simulation;test effort;time series	Christian Roesener;Felix Fahrenkrog;Axel Uhlig;Lutz Eckstein	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795734	reliability engineering;simulation;engineering;data mining	SE	-18.174329378996156	-25.87316691178364	166420
b2768810e1294e1933db1f84bafff4eea0c8c09b	gaul: gestalt analysis of unstructured logs for diagnosing recurring problems in large enterprise storage systems	recurring problem diagnosis;fuzzy match;gestalt analysis;program diagnostics;recurring problem identification;indexes search problems noise accuracy humans microprogramming hardware;storage system;gaul system;noise tolerance technique;scalable search;error codes;leveraging problem set information;search problem diagnosis whole log comparison fuzzy match index;unstructured logs;index;contextual overlap;fuzzy set theory;search;accuracy;indexes;program diagnostics business data processing fuzzy set theory pattern matching;log lines;business data processing;pattern matching;whole log comparison;indexation;large enterprise storage system;fuzzy match algorithm;human filtered log;humans;search problems;errcmp system;microprogramming;log comparison;error codes gaul system gestalt analysis unstructured logs recurring problem diagnosis large enterprise storage system log comparison recurring problem identification fuzzy match algorithm contextual overlap log lines scalable index scalable search leveraging problem set information noise tolerance technique human filtered log cosine similarity errcmp system;problem diagnosis;noise;cosine similarity;hardware;scalable index	We present GAUL, a system to automate the whole log comparison between a new problem and the ones diagnosed in the past to identify recurring problems. GAUL uses a fuzzy match algorithm based on the contextual overlap between log lines and efficiently implements this using scalable index/search. The accuracy and efficiency of the comparison is further improved by leveraging problem set information and noise tolerance techniques. We evaluate GAUL using 4339 customer problems that occurred in all field deployments of an enterprise storage system over the course of a year. Our results show that with human-filtered logs, GAUL can identify the correct problem set 66% of the time among the top10 matches, which is 15% more accurate than the VSM system that uses cosine similarity and 19% more accurate than the ERRCMP system that uses error codes for log comparison. With unfiltered logs, the top10 match accuracy of GAUL is 40%, which is 22% more accurate than VSM and 26% more accurate than ERRCMP.	algorithm;code;computer data storage;cosine similarity;gestalt psychology;index (publishing);scalability;viable system model	Pin Zhou;Binny S. Gill;Wendy Belluomini;Avani Wildani	2010	2010 29th IEEE Symposium on Reliable Distributed Systems	10.1109/SRDS.2010.25	database index;computer science;theoretical computer science;machine learning;data mining;database;distributed computing;programming language;computer security;statistics	OS	-12.45413011474154	-36.26630222872929	166438
d3e81fa7b5f87a85bdd3d0f8bd7e02e0dc8a8ed0	discovering and understanding city events with big data: the case of rome		The increasing availability of large amounts of data and digital footprints has given rise to ambitious research challenges in many fields, which spans from medical research, financial and commercial world, to people and environmental monitoring. Whereas traditional data sources and census fail in capturing actual and up-to-date behaviors, Big Data integrate the missing knowledge providing useful and hidden information to analysts and decision makers. With this paper, we focus on the identification of city events by analyzing mobile phone data (Call Detail Record), and we study and evaluate the impact of these events over the typical city dynamics. We present an analytical process able to discover, understand and characterize city events from Call Detail Record, designing a distributed computation to implement Sociometer, that is a profiling tool to categorize phone users. The methodology provides an useful tool for city mobility manager to manage the events and taking future decisions on specific classes of users, i.e., residents, commuters and tourists.	algorithm;big data;categorization;computation;data mining;digital footprint;distributed computing;microsoft windows;mobile phone;point of interest;profiling (computer programming);refinement (computing)	Barbara Furletti;Roberto Trasarti;Paolo Cintia;Lorenzo Gabrielli	2017	Information	10.3390/info8030074	computer science;categorization;data mining;census;sociometer;big data;profiling (computer programming);mobile phone	ML	-18.598384311972374	-32.72948469236439	167068
0672d1c7a8ff34d4bd7b1ae260c6aba658621978	output-sensitive pattern extraction in sequences	004;pattern extraction motif detection pattern discovery motif trie	Genomic Analysis, Plagiarism Detection, Data Mining, Intrusion Detection, Spam Fighting and Time Series Analysis are just some examples of applications where extraction of recurring patterns in sequences of objects is one of the main computational challenges. Several notions of patterns exist, and many share the common idea of strictly specifying some parts of the pattern and to don’t care about the remaining parts. Since the number of patterns can be exponential in the length of the sequences, pattern extraction focuses on statistically relevant patterns, where any attempt to further refine or extend them causes a loss of significant information (where the number of occurrences changes). Output-sensitive algorithms have been proposed to enumerate and list these patterns, taking polynomial time O(n) per pattern for constant c > 1, which is impractical for massive sequences of very large length n. We address the problem of extracting maximal patterns with at most k don’t care symbols and at least q occurrences. Our contribution is to give the first algorithm that attains a stronger notion of output-sensitivity, borrowed from the analysis of data structures: the cost is proportional to the actual number of occurrences of each pattern, which is at most n and practically much smaller than n in real applications, thus avoiding the aforementioned cost of O(n) per pattern. 1998 ACM Subject Classification E.1 Data Structures	boolean algebra;data mining;data structure;enumerated type;intrusion detection system;maximal set;output-sensitive algorithm;pattern recognition;polynomial;time complexity;time series	Roberto Grossi;Giulia Menconi;Nadia Pisanti;Roberto Trani;Søren Vind	2014		10.4230/LIPIcs.FSTTCS.2014.303	computer science;machine learning;data mining;mathematics;algorithm	ML	-6.4226029462866014	-34.69036472751565	167252
74b62e5b0295dfd99b7f6976b6478e0045d98e74	dnn-based prediction model for spatio-temporal data	spatio temporal data;deep learning;prediction	Advances in location-acquisition and wireless communication technologies have led to wider availability of spatio-temporal (ST) data, which has unique spatial properties (i.e. geographical hierarchy and distance) and temporal properties (i.e. closeness, period and trend). In this paper, we propose a <u>Deep</u>-learning-based prediction model for <u>S</u>patio-<u>T</u>emporal data (DeepST). We leverage ST domain knowledge to design the architecture of DeepST, which is comprised of two components: spatio-temporal and global. The spatio-temporal component employs the framework of convolutional neural networks to simultaneously model spatial near and distant dependencies, and temporal closeness, period and trend. The global component is used to capture global factors, such as day of the week, weekday or weekend. Using DeepST, we build a real-time crowd flow forecasting system called UrbanFlow1. Experiment results on diverse ST datasets verify DeepST's ability to capture ST data's spatio-temporal properties, showing the advantages of DeepST beyond four baseline methods.	artificial neural network;baseline (configuration management);centrality;convolutional neural network;real-time transcription;spatiotemporal database	Junbo Zhang;Yu Zheng;Dekang Qi;Ruiyuan Li;Xiuwen Yi	2016		10.1145/2996913.2997016	prediction;geography;computer science;data science;machine learning;data mining;deep learning;statistics	ML	-16.481750594589716	-32.80762944005144	167328
bb3f3ef4c1af3c70801cf35a8aac36d7736acd05	mining high utility itemsets without candidate generation	high utility itemset;mining algorithm	High utility itemsets refer to the sets of items with high utility like profit in a database, and efficient mining of high utility itemsets plays a crucial role in many real-life applications and is an important research issue in data mining area. To identify high utility itemsets, most existing algorithms first generate candidate itemsets by overestimating their utilities, and subsequently compute the exact utilities of these candidates. These algorithms incur the problem that a very large number of candidates are generated, but most of the candidates are found out to be not high utility after their exact utilities are computed. In this paper, we propose an algorithm, called HUI-Miner (High Utility Itemset Miner), for high utility itemset mining. HUI-Miner uses a novel structure, called utility-list, to store both the utility information about an itemset and the heuristic information for pruning the search space of HUI-Miner. By avoiding the costly generation and utility computation of numerous candidate itemsets, HUI-Miner can efficiently mine high utility itemsets from the utility-lists constructed from a mined database. We compared HUI-Miner with the state-of-the-art algorithms on various databases, and experimental results show that HUI-Miner outperforms these algorithms in terms of both running time and memory consumption.	algorithm;computation;data mining;database;heuristic;mined;real life;time complexity	Mengchi Liu;Jun-Feng Qu	2012		10.1145/2396761.2396773	computer science;data science;data mining;database	AI	-6.032008363552663	-36.69463576542967	167377
c0021e1e35714b54b7103d84c0c23d6cb47822a8	monitoring and prediction of convective events using data mining approaches			data mining	Cesar Strauss	2013				ML	-11.65240597591094	-27.577020037686392	167453
143d1a9fdd32e8a87572cbb4931902f63828eb82	new motor primitives through graph search, interpolation and generalization		This paper presents our proposed approach for discovering new motor primitives in a database of demonstrated example movements. Example trajectory data is usually obtained from human demonstration or by kinesthetic guiding. It is then organized and clustered into a binary tree with transition graphs at every level. Each level presents a different granularity of example data. We show that new movements (or their parts) can be discovered through graph search, by exploiting the interdependencies between the movements encoded by the graph. By combining results with optimized interpolation new series of primitives can be found. A complete representation of new, not directly demonstrated, movements can be constructed by using new series of movements with statistical generalization techniques.	interpolation	Miha Denisa;Ales Ude	2013		10.1007/978-3-642-35485-4_11	combinatorics;discrete mathematics;null graph;machine learning;mathematics;voltage graph	ML	-11.047602886680417	-30.634979337647685	167747
a6f53eddf6779b7e27e66c89cbf5c79d85905c7a	utilizing real-world transportation data for accurate traffic prediction	road accidents;transportation data;road traffic;traffic prediction;predictive models data models accuracy accidents data mining autoregressive processes transportation;time series;data mining;time series mining;accident impact real world transportation data spatiotemporal data traffic prediction transportation network data mining traffic behavior data utilization los angeles county time series mining technique rush hour traffic behavior short term prediction long term prediction prediction accuracy;traffic engineering computing;event impact analysis;transportation data traffic prediction event impact analysis time series mining;traffic engineering computing data mining road accidents road traffic time series	For the first time, real-time high-fidelity spatiotemporal data on transportation networks of major cities have become available. This gold mine of data can be utilized to learn about traffic behavior at different times and locations, potentially resulting in major savings in time and fuel, the two important commodities of 21st century. As a first step towards the utilization of this data, in this paper, we study the real-world data collected from Los Angeles County transportation network in order to incorporate the data's intrinsic behavior into a time-series mining technique to enhance its accuracy for traffic prediction. In particular, we utilized the spatiotemporal behaviors of rush hours and events to perform a more accurate prediction of both short-term and long-term average speed on road-segments, even in the presence of infrequent events (e.g., accidents). Our result shows that taking historical rush-hour behavior we can improve the accuracy of traditional predictors by up to 67% and 78% in short-term and long-term predictions, respectively. Moreover, we can incorporate the impact of an accident to improve the prediction accuracy by up to 91%.	pyrite;real-time clock;time series	Bei Pan;Ugur Demiryurek;Cyrus Shahabi	2012	2012 IEEE 12th International Conference on Data Mining	10.1109/ICDM.2012.52	time series;data mining;mathematics;computer security;statistics	ML	-16.532274286073363	-31.38972332717538	168461
53bb364ee02186b113c6480c9e8ef975db31c5fd	a new data normalization function for multibiometric contexts: a case study	hierarchical system;positive feedback;biometrics;score normalization;satisfiability;multimodal system;multimodal systems	It has been not possible yet to identify a physical or behavioural feature able by itself to identify a person in a way satisfying the acceptability and reliability constraints imposed by real applications. As a consequence the present trend is towards multimodal systems. Data normalization problem is crucial when fusing results from different subsystems. We introduce a new normalization function, the mapping function, able to overcome the limitations of commonly used techniques. In this work we also test it on a real hierarchical system obtained by the novel combination schema of the three different biometries face, ear and fingerprint. Experimental results in the final part of our work provide a positive feedback about assertions within the body of the paper.		Maria De Marsico;Daniel Riccio	2008		10.1007/978-3-540-69812-8_103	positive feedback;computer science;artificial intelligence;machine learning;data mining;hierarchical control system;biometrics;satisfiability	HCI	-5.209542518770882	-24.052499620915917	168685
3e3ad3b44c4a0fd328c6ea61095aeb6cd70a73af	discovering spatio-temporal dependencies based on time-lag in intelligent transportation data		Learning spatio-temporal dependency structure is meaningful to characterize causal or statistical relationships. In many real-world applications, dependency structure is often characterized by time-lag between variables. For example, traffic system and climate, time lag is a key feature of hidden temporal dependencies, and plays an essential role in interpreting the cause of discovered temporal dependencies. However, traditional dependencies learning algorithms only use the same time stamp data of variables. In this paper, we propose a method for mining dependencies by considering the time lag. The proposed approach is based on a decomposition of the coefficients into products of two-level hierarchical coefficients, where one represents feature-level and the other represents time-level. Specially, we capture the prior information of time lag in intelligent transportation data. We construct a probabilistic formulation by applying some probabilistic priors to these hierarchical coefficients, and devise an expectation-maximization (EM) algorithm to learn the model parameters. We evaluate our model on both synthetic and real-world highway traffic datasets. Experimental results show the effectiveness of our method.		Xiabing Zhou;Haikun Hong;Xingxing Xing;Kaigui Bian;Kunqing Xie;Mingliang Xu	2017	Neurocomputing	10.1016/j.neucom.2016.06.084	machine learning;artificial intelligence;timestamp;prior probability;probabilistic logic;dependency theory (database theory);lag;intelligent transportation system;pattern recognition;computer science	Robotics	-13.346185297940744	-31.921915356254843	168745
ecb99f66cd73af4d429a0f3c0cc5fc205add9495	extraction of ambiguous sequential patterns with least minimum generalization from mismatch clusters	artificial intelligence barium conferences bismuth;iterative refinement;pattern clustering;pattern extraction ambiguous sequential patterns extraction least minimum generalization mismatch clusters ambiguous query sequence databases iterative refinement method domain segmentation method;ambiguous sequential patterns extraction;pattern clustering database management systems iterative methods pattern classification;database management systems;bismuth;barium;sequence databases;iterative methods;ambiguous query;mismatch clusters;pattern classification;artificial intelligence;iterative refinement method;least minimum generalization;sequential pattern;domain segmentation method;pattern extraction;conferences	An ambiguous query in sequence databases returns a set of similar subsequences, called a mismatch cluster, to the user. The inherent problem is that it is difficult for users to identify the characteristics of very large similar subsequences in a mismatch cluster. In order to support user comprehension of mismatch clusters, it is important to extract a set of ambiguous sequence patterns with the least minimum generalization in the mismatch cluster. The extraction of the ambiguous sequential pattern set requires an enormous amount of computational time, since we have to discover generalized patterns with minimum covers for the mismatch cluster from candidate generalized patterns. The present paper is a proposal for an iterative refinement method to extract ambiguous sequence patterns with minimum cover for mismatch clusters selected from a sequence database. It includes a proposal to use the method with a domain segmentation method to achieve an efficient pattern extraction. Moreover, a prototype implementing the two proposed methods has been applied to three datasets included in PROSITE in order to evaluate their usefulness. The proposed methods resulted in a high capability to extract ambiguous sequential patterns from mismatch clusters that are provided by an ambiguous query in the sequence database.	computer cluster;iterative method;iterative refinement;prosite;pattern recognition;performance evaluation;prototype;refinement (computing);sequence database;time complexity;vertex cover	Kotaro Araki;Keiichi Tamura;Tomoyuki Kato;Yasuma Mori;Hajime Kitakami	2007	2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System	10.1109/SITIS.2007.104	computer science;artificial intelligence;machine learning;bismuth;pattern recognition;data mining;iterative method;barium	DB	-4.725720986819089	-37.0423340213778	168871
3038b167cc59b15af3c64cd0cf89d028c5ee87f5	toward dynamic path recommender system based on social network data	path recommender;geo tagged tweets;social networks	With the advancement of mobile technologies, more and more people are connected to social networks such as Facebook and Twitter. Social networks allow users to share diversity of information including spatio-temporal data either publicly or within their community of interest in realtime. Particularly, by analyzing social network data streams and then validating the content, one can extract knowledge about dynamic road conditions for a given city. This paper presents a dynamic path recommender system that helps users finding optimized routes in dynamic environments based on social network data. The system collects geo-tagged social network data from which relevant knowledge is extracted for identifying constraints such as accidents, weather conditions, and congestions. Moreover, by continuously collecting moving user's geo-tagged data, the system can also identify the traffic flow as well as roads' conditions. As soon as the system identifies and validates a given constraint, it can notify affected users and recommend an adapted route from their current position to the destination. A proof of concept of the system will be shown through three example scenarios.	recommender system;social network	Faizan Ur Rehman;Ahmed Lbath;Mohamed Abdur Rahman;Saleh M. Basalamah;Imad Afyouni;Akhlaq Ahmad;Syed Osama Hussain	2014		10.1145/2674918.2674927	geography;data mining;internet privacy;world wide web	Web+IR	-17.96675058192202	-34.764038704946735	168899
72f5560fecee46eeff7c1885d3bc7826a42b629b	remote sensing image information mining with hpc cluster and dryadlinq	remote sensing image;image information mining;image database;distributed computing;time series;programming model;multi dimensional;hpc;land use;remote sensing;high performance computer;dryadlinq;object oriented databases;object oriented database;support vector machine;landsat thematic mapper;land cover	Our capabilities for collecting remote sensing images have greatly outpaced our abilities to analyze and retrieve information from the image databases. This paper presents a distributed framework for information mining from multi-dimensional remotely sensed images using Windows High Performance Computing (HPC) Servers and Dryad distributed computing engine. Land cover and land use types are classified by Support Vector Machines (SVM) and stored in an object-oriented database with region quad-tree indices. DryadLINQ queries, an extended version of the LINQ programming model, are developed for retrieving land cover distribution information and detect the changes of each land cover type at multi levels. A HPC cluster with sixteen computing nodes is implemented and the experiments are conducted on a time series Landsat Thematic Mapper (TM) images. The results show the effectiveness of the framework and its potentials in other remote sensing applications.	data mining;database;distributed computing;dryad;experiment;language integrated query;mapper;microsoft windows;programming model;quadtree;support vector machine;time series	Jiang Li	2011		10.1145/2016039.2016099	computer vision;geography;data mining;remote sensing	HPC	-13.025156421664104	-28.021067398778175	168913
53de4354111e7c95f2e95764c9db3e9dccc65b2d	a battery-friendly data acquisition model for vehicular speed estimation	cellular positioning;vehicular speed estimation;traffic theory;microscopic traffic simulation;gps positioning;mobile tracking	Modeling traffic flow and gathering accurate traffic congestion information are two challenging problems in smart transportation systems. Most of the traffic flow models and velocity estimation methodologies that have been proposed so far gather the data from GPS-equipped smart phones and extract the flow model based on GPS sampling. However, these approaches tend to fail in real life scenarios due to the insufficient vehicle data and unpredictable dynamics of the flow. Furthermore, utilization of GPS sensor leads to a battery drainage and hence reduces the overall system performance. In this paper, we propose a new battery-friendly data acquisition model to obtain the raw data. We then evaluate our model under various traffic conditions to determine its feasibility in vehicle speed estimation. The proposed model results in 88% location accuracy whereas it reduces the battery consumption by half. © 2016 Elsevier Ltd. All rights reserved.	assisted gps;data acquisition;experiment;fingerprint (computing);global positioning system;mobile phone;network congestion;real life;sampling (signal processing);sensor web;simulation;smartphone;systems architecture;velocity (software development);website monitoring	Sevgi Kaya;Necati Kilic;Taskin Koçak;Vehbi Cagri Gungor	2016	Computers & Electrical Engineering	10.1016/j.compeleceng.2016.01.017	embedded system;real-time computing;simulation;floating car data;engineering;three-phase traffic theory;assisted gps;hybrid positioning system	AI	-18.330386514533608	-30.02646593736628	169123
3557d22cd663e4939a86f43d044b8cb55cd97e16	reverse k-ranks query	reverse ranking;r k ranks;ranking query	Finding matching customers for a given product based on individual user’s preference is critical for many applications, especially in e-commerce. Recently, the reverse top-k query is proposed to return a number of customers who regard a given product as one of the k most favorite products based on a linear model. Although a few “hot” products can be returned to some customers via reverse top-k query, a large proportion of products (over 90%, as our example illustrates, see Figure 2) cannot find any matching customers. Inspired by this observation, we propose a new kind of query (R-kRanks) which finds for a given product, the topk customers whose rank for the product is highest among all customers, to ensure 100% coverage for any given product, no matter it is hot or niche. Not limited to e-commerce, the concept of customer-product can be extended to a wider range of applications, such as dating and job-hunting. Unfortunately, existing approaches for reverse top-k query cannot be used to handle R-kRanks conveniently due to infeasibility of getting enough elements for the query result. Hence, we propose three novel approaches to efficiently process R-kRanks query, including one tree-based method and two batch-pruning-based methods. Analysis of theoretical and experimental results on real and synthetic data sets illustrates the efficacy of the proposed methods.	approximation algorithm;cp/m;computation;data point;e-commerce;experiment;inferring horizontal gene transfer;linear model;niche blogging;oracle bpa suite;synthetic data	Zhao Zhang;Cheqing Jin;Qiangqiang Kang	2014	PVLDB	10.14778/2732951.2732952	sargable;query optimization;web query classification;ranking;boolean conjunctive query;data mining;database;mathematics;range query;world wide web	DB	-11.689751330136518	-37.116950972424306	169129
6c2b0d5ed08079dd31c733a9f164ec3a967a0f09	towards predicting dengue fever rates using convolutional neural networks and street-level images		The ability to identify urban locations with a high risk of diseases infections is a central aspect of public policies aiming at controlling these diseases. In this paper, we investigate the use of street-level images, such as those from Google Street View, along with Convolutional Neural Networks to predict Dengue Fever (DF) and Dengue Hemorrhagic Fever (DHF) rates in urban locations. We conduct a case study in the city of Rio De Janeiro, Brazil, using the proposed methodology and DF/DHF data between the years of 2010 to 2014. We compare two Siamesebased CNNs, yielding an overall accuracy of 67% for 20,400 different locations. We conclude that street-level images are useful for the problem.	convolutional neural network;direction finding;google street view;vii;winsock	Virginia O. Andersson;Mandar Ghate;Ricardo Matsumura de Araújo	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489567	machine learning;convolutional neural network;pattern recognition;dengue fever;artificial intelligence;computer science	AI	-14.173971438387929	-29.097641538802023	169262
fc1dc82281ab4c10eaa9d578e6c8b2f5460b7e79	individual activity data collection based on mobile positioning infrastructure in beijing	urban mobility;radio receivers;remind recall approach;activity based model;individual activity;data collection;activity based model urban mobility individual activity data collection mobile positioning;radio receivers data analysis global positioning system mobile radio;data analysis;artificial neural networks;mobile positioning infrastructure;global positioning system individual activity data collection mobile positioning infrastructure beijing remind recall approach gps receiver trajectory segmentation algorithm;global positioning system;beijing;mobile radio;trajectory segmentation algorithm;mobile positioning;response rate;individual activity data collection;gps receiver	Collecting individual activity data is increasingly more challenging for researchers because of low response rate and high respondent burden. In this paper, we combine two mobile positioning technologies with a Remind Recall approach for individual activity data collection in a large city. When the users are outdoor, the phone's GPS receivers will automatically track the users' trajectories while when the users are indoor, it will automatically switch to mobile positioning and continues recording. In order to achieve the purpose of prompted recall and reduce user burden, a trajectory segmentation algorithm is proposed to generate a brief sketch which improves the responder's possibility to recall information about activities. We have implemented a data collection system and carried out an activity survey project about 500 people in Beijing. The good performance of our system in Beijing survey and the enthusiastically residents' responses give a sufficient proof of our expectation.	algorithm;database;global positioning system;mobile phone;privacy	Amory Huang;Xiujun Ma;Yanwei Chai;Yu Liu;Yunxiao Li;Dilnaryasin	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5568187	simulation;geography;telecommunications;computer security	Mobile	-18.435752850050633	-34.57776685691776	169302
8a82dee403f2fc3e93a67ef9b7c1b7c0c6ba2ae4	spatial interpolation of streaming geosensor network data in the riser system		Managing the data generated by emerging spatiotemporal data sources, such as geosensor networks, presents a growing challenge to traditional, offline GIS architectures. This paper explores the develop- ment of an end-to-end system for near real-time monitoring of environ- mental variables related to wildfire hazard, called RISER. The system is built upon a geosensor network and web-GIS technologies, connected by a stream-processing system. Aside from exploring the system archi- tecture, this paper focuses specifically on the important role of stream processing as a bridge between data capture and web GIS, and as a spatial analysis engine. The paper highlights the compromise between efficiency and accuracy in spatiotemporal stream processing that must often be struck in the stream operator design. Using the specific example of spatial interpolation operators, the impact of changes to the configu- rations of spatial and temporal windows on the accuracy and efficiency of different spatial interpolation methods is evaluated.	multivariate interpolation	Xu Zhong;Allison Kealy;Guy Sharon;Matt Duckham	2015		10.1007/978-3-319-18251-3_10	real-time computing;simulation;artificial intelligence;data mining;database;world wide web;cartography	NLP	-15.29969092300003	-30.292486243194162	169361
2d97b39025d87d774b1e377795d3e5a5e344093c	needle in a haystack: max/min online aggregation in the cloud		As the development of social network, mobile Internet, etc., an increasing amount of data are being generated, which beyond the processing ability of traditional data management tools. In many real-life applications, users can accept approximate answers accompanied by accuracy guarantees. One of the most commonly used approaches of approximate query processing is online aggregation. Most existing work of online aggregation in the cloud focuses on the aggregation functions such as Count, Sum and Avg, while there is little work on the Max/Min online aggregation in the cloud now. In this paper, we measure the accuracy of Max/Min online aggregation by using quantile which is deduced by Chebyshev’s inequality and central limit theorem. We implement our methods in a cloud online aggregation system called COLA and the experimental results demonstrate our method can deliver reasonable online Max/Min estimates within an acceptable time period.	online aggregation	Xiang Ci;Fengming Wang;Xiaofeng Meng	2015		10.1007/978-3-319-22324-7_21	cloud computing;online aggregation;computer science;data mining;the internet;chebyshev's inequality;quantile;chebyshev filter;haystack;central limit theorem	HPC	-8.12472817045301	-34.41838275158764	169465
47ac9ab4fda4557dedf0a6bca2278f79351daf07	a data-driven generative model for gps sensors for autonomous driving		Autonomous driving (AD) is envisioned to have a significant impact on people's life regarding safety and comfort. Positioning is one of the key challenges in realizing AD, where global navigation systems (GNSS) is traditionally used as an important source of information. The area of GNSS are well explored and the different sources of error are deeply investigated. However the existing modeling methods often have very comprehensive requirements for the training data where all affecting conditions such as ephemeris data should be well known. The main goal of this paper is to develop a solution to model GPS error that only requires information which is available in the vehicle without having access to detailed information about the conditions. We propose a statistical generative model using autoregression and Gaussian mixture models and develop a learning algorithm to estimate the parameters using the data collected in real traffic. The proposed model is evaluated by comparing the produced artificial data with the validation data collected at different traffic conditions and the results indicate that the model is successfully mimicking the sensor behavior.	algorithm;autonomous car;autoregressive model;experiment;finite difference;generative model;global positioning system;information source;mixture model;requirement;satellite navigation	Erik Karlsson;Nasser Mohammadiha	2018	2018 IEEE/ACM 1st International Workshop on Software Engineering for AI in Autonomous Systems (SEFAIAS)	10.1145/3194085.3194089	ephemeris;mixture model;machine learning;error analysis for the global positioning system;global positioning system;generative model;data modeling;autoregressive model;artificial intelligence;gnss applications;computer science	ML	-14.925012853789001	-32.49231705949028	169558
a223003b81b3839d7e0346316afedc8f89504d22	active learning of strict partial orders: a case study on concept prerequisite relations		Strict partial order is a mathematical structure commonly seen in relational data. One obstacle to extracting such type of relations at scale is the lack of large scale labels for building effective data-driven solutions. We develop an active learning framework for mining such relations subject to a strict order. Our approach incorporates relational reasoning not only in finding new unlabeled pairs whose labels can be deduced from an existing label set, but also in devising new query strategies that consider the relational structure of labels. Our experiments on concept prerequisite relations show our proposed framework can substantially improve the classification performance with the same query budget compared to other baseline approaches.		Chen Liang;Jianbo Ye;Han Zhao;Bart Pursel;C. Lee Giles	2018	CoRR		machine learning;artificial intelligence;active learning;mathematical structure;obstacle;relational database;mathematics	AI	-10.306927196308935	-32.51639455406738	169751
a7d8f849b422ffbffa8e4162d1e08fb6eaa3b629	time-slice density estimation for semantic-based tourist destination suggestion	density estimation	In recent years, a growing interest has been given to trajectory data mining applications that permit to support mobility prediction with the aim of anticipating or pre-fetching possible services [3]. Proposed approaches typically consider only spatio-temporal information provided by collected trajectories. However, in some scenarios, such as that of tourist supporting, semantic information which express needs and interest of the user (tourist) should be taken into account. This semantic information can be extracted from textual documents already consulted by the tourists. In this paper, we present the application of the time-slice density estimation [1] that permits to suggest/predict the next destination of the tourist. In particular, time-slice density estimation permits to measure the rate of change of tourist’s interests at a given geographical position over a user-defined time horizon. Tourist interests depend both on the geographical position of the tourist with respect to a reference system and on semantic information provided by geo-referenced documents associated to the visited sites. Our basic assumption is that a tourist moves towards a close destination which is semantically consistent with her/his current profile as much as possible. Destinations that minimize the profile drift are suggested/predicted as next destinations.	cosine similarity;data mining;preemption (computing);similarity measure	Michelangelo Ceci;Annalisa Appice;Donato Malerba	2010		10.3233/978-1-60750-606-5-1107	density estimation;computer science	ML	-16.923183811954974	-35.97161601235431	170111
1712f2cebe07c36140694437fdfa11a79acf4132	a linguistic representation method for kansei data		This paper proposes a linguistic representation method of kansei data for evaluation of traditional products. Basically, the proposed approach is based on the linguistic interpretation of kansei data and the probabilistic semantics of fuzzy sets. We first interpret a semantic differential scale used in kansei experiment as a linguistic variable and then discuss how the kansei value of products can be represented as a probability distribution on the set of kansei linguistic labels of the linguistic variable. We have also extended this kansei data modelling approach to the cases where the kansei value is imprecisely given as an interval or a fuzzy number. An example for modelling kansei data of Kutani cups is used to illustrate the proposed method.	cups;data modeling;fuzzy number;fuzzy set;probabilistic semantics;vagueness	Chanyachatchawan Sapa;Hongbin Yan;Songsak Sriboonchitta;Van-Nam Huynh	2016	2016 Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th International Symposium on Advanced Intelligent Systems (ISIS)	10.1109/SCIS-ISIS.2016.0050	natural language processing;computer science;artificial intelligence;data mining	Robotics	-4.594387027508803	-24.04420090063612	170369
b8e6019b30d739523972cc1890d39f177cef6c41	an incremental algorithm for discovering routine behaviours from smart meter data		Smart meters become increasingly popular in measuring consumption of utilities such as electricity, gas and water. Mining consumption data reveals useful behavioural patterns about the latest use activities. In this paper, we define routine behaviours to characterize recurrent activities from smart meter data. Due to routine behaviours’ special characteristics, traditional pattern discovery algorithms such as motif discovery algorithms are not applicable. Therefore, we propose an efficient algorithm to discover routine behaviours of all possible lengths by incrementally growing subsequences. To ensure systematic evaluations, we first generated synthetic datasets with known ground truth. Experiments on synthetic datasets demonstrate that the proposed algorithm has comparable accuracy with a brute-force algorithm but requires less computing time. Furthermore, we demonstrate that useful domain knowledge can be extracted from discovered routines on two real-world datasets that record water consumption in two areas.	algorithm;smart meter	Jin Wang;Rachel Cardell-Oliver;Wei Liu	2016	Knowl.-Based Syst.	10.1016/j.knosys.2016.09.016	simulation;data science;data mining	DB	-12.5836252640273	-34.32651644703222	170849
9ed07c0c20ab98773c609b61017bc5b46b5ff913	memory efficient subspace clustering for online data streams	multi dimensional subspace clustering;data stream;data mining;data streams;multi dimensional;round robin;subspace clustering;memory effect	Subspace clustering over an online multi-dimensional data stream requires to examine all the subsets of its dimensions, so that a huge amount of memory space may be required. To trace the ongoing changes of cluster patterns over an online data stream by a confined memory space, this paper proposes a grid-based subspace clustering algorithm that can utilize the confined memory space effectively. Given an n-dimensional data stream, the on-going distribution statistics of data elements in each one-dimension data space are firstly monitored by a list of grid-cells called a sibling list. Once a grid-cell of a first-level sibling list becomes a dense unit grid-cell, new second-level sibling lists are created as its child nodes in order to trace any cluster in all possible two-dimensional rectangular subspaces. In such a way, a sibling tree grows up to the nth level at most and a k-dimensional subcluster can be found at the kth level of the sibling tree. To utilize the confined space of main memory effectively, only the upper-part of a sibling tree is expanded at all times and the subtrees in the lower part are expanded in turns by various scheduling policies such as round-robin and priority-based. Furthermore, in order to confine the usage of memory space, the size of a unit grid-cell is adaptively minimized such that the result of clustering becomes as accurate as possible at all times. The performance of the proposed method is comparatively analyzed by a number of experiments to identify its various characteristics.	algorithm;cell (microprocessor);cluster analysis;clustering high-dimensional data;computer data storage;dspace;dataspaces;experiment;round-robin scheduling;scheduling (computing);tree (data structure)	Nam Hun Park;Won Suk Lee	2008		10.1145/1451940.1451968	memory effect;data stream clustering;computer science;theoretical computer science;machine learning;data mining;database;data stream mining;cluster analysis	DB	-7.751875442131982	-37.43081081823535	170985
2e2d5c560c2b129ab65720d7579477c0aa5234a6	average number of frequent (closed) patterns in bernoulli and markovian databases	frequent pattern;proportional frequency threshold data mining frequent enumeration closed patterns association rules discovery average analysis probabilistic models bernoulli model markovian model frequent patterns fixed frequency threshold;data mining;upper bound;probabilistic model;data mining association rules transaction databases frequency polynomials pathology upper bound pattern analysis information analysis sampling methods;association rule;lower bound	In data mining, enumerate the frequent or the closed patterns is often the first difficult task leading to the association rules discovery. The number of these patterns represents a great interest. The lower bound is known to be constant whereas the upper bound is exponential, but both situations correspond to pathological cases. For the first time, we give an average analysis of the number of frequent or closed patterns. Average analysis is often closer to real situations and gives more information about the role of the parameters. In this paper, two probabilistic models are studied: a Bernoulli and a Markovian. In both models and for large databases, we prove that the number of frequent patterns, for a fixed frequency threshold, is exponential in the number of items and polynomial in the number of transactions. On the other hand, for a proportional frequency threshold, the number of frequent patterns is polynomial in the number of items and does not involve the number of transactions. Finally, we prove in the Bernoulli model that the number of closed patterns, for a proportional frequency threshold, is polynomial in the number of items.	association rule learning;bernoulli polynomials;best, worst and average case;data mining;database;enumerated type;numerical analysis;polynomial;real life;time complexity	Loïck Lhote;François Rioult;Arnaud Soulet	2005	Fifth IEEE International Conference on Data Mining (ICDM'05)	10.1109/ICDM.2005.31	discrete mathematics;data mining;mathematics;upper and lower bounds;statistics	DB	-6.525866738969491	-34.69169732857622	172288
b757593dbf805a0b10e95022f1bdfa0ecfe97ebf	from routine to better network services	trajectory legged locomotion geology cities and towns global positioning system motorcycles;telecommunication services;daily lives network services routinary behavior people mobility transportation mode	In this work, we assess the routinary behavior of people and point out means to explore it in order to provide better network services. We have studied two real datasets representing together more than 6 years of trajectories from people's daily lives. The results show three behaviors on people's mobility regardless the transportation mode: tendency to take shortest paths, highly confined and repetitive trajectories. Finally, we show some network scenarios in which those behaviors might be used to benefit people.	shortest path problem;software deployment	Eduardo Mucelli Rezende Oliveira;Aline Carneiro Viana	2014	2014 7th IFIP Wireless and Mobile Networking Conference (WMNC)	10.1109/WMNC.2014.6878869	simulation;geography;operations management;transport engineering	HCI	-18.289318869526106	-30.842125373430733	172300
5812788b29bece52479567673f9bcaeb9af3f78e	a fast algorithm for mining association rules	large itemset;database;data mining;scaling up;minimum confidence;minimum support;association rule;fast algorithm;empirical evaluation	In this paper, the problem of discovering association rules between items in a lange database of sales transactions is discussed, and a novel algorithm, BitMatrix, is proposed. The proposed algorithm is fundamentally different from the known algorithms Apriori and AprioriTid. Empirical evaluation shows that the algorithm outperforms the known ones for large databases. Scale-up experiments show that the algorithm scales linearly with the number of transactions.	apriori algorithm;association rule learning;database;experiment	Liusheng Huang;Huaping Chen;Wang Xun;Guoliang Chen	2000	Journal of Computer Science and Technology	10.1007/BF02948845	gsp algorithm;association rule learning;computer science;data science;machine learning;data mining;fsa-red algorithm;apriori algorithm	DB	-5.329548952531679	-36.879012404984444	172708
c42ca0e1769c41fccd672e1320a7ba887d11b504	data mining for customer queries in erp model a case study	databases;pattern clustering;association mining;apriori algorithm customer queries erp model data mining techniques madar data customer satisfaction data clustering association mining customer relationship management crm;crm;data mining techniques;customer relationship management;customer queries;madar data;pattern clustering customer satisfaction data mining enterprise resource planning;satisfiability;data mining;erp model;customer satisfaction;data clustering;clustering;apriori;enterprise resource planning;clustering algorithms;apriori algorithm;organizations;security;clustered data;apriori crm data mining clustering;data models;data mining enterprise resource planning databases security clustering algorithms production systems computer aided software engineering investments profitability cost function	Customers always play a key role for the establishment or mean of crisis for any organization. In this paper, we applied data mining techniques on MADAR data for the perfection and development of the organization as well as making their customers more and more satisfied and contented. In the presented model we specially kept customers on the top and emphasized and highlighted the role of customers for every organization. By using their characteristics and surroundings we clustered the data on the basis of action taken against the raised question. In addition, the clustered data employed on the Apriori algorithm and finally, we discovered new rules and patterns from the database for formulating the process in adequate and satisfactory milieu. For the best implementation we used two data mining techniques; Clustering and Association Mining, to get most valuable, informative and strong results for this organization. This is the way to have the best association and gratify their customer in future.	apriori algorithm;association rule learning;cluster analysis;data mining;database;erp;information;milieu intérieur	Abdullah S. Al-Mudimigh;Zahid Ullah;Farrukh Saleem;Fahad N. Al-Aboud	2009	2009 Fifth International Joint Conference on INC, IMS and IDC	10.1109/NCM.2009.356	customer relationship management;computer science;data science;machine learning;data mining;database;cluster analysis	DB	-5.409220625074202	-33.18442235555687	172756
14b472ad95c27a31993e3e2e5c5fea0057a74b96	mining spatial-temporal semantic trajectory patterns from raw trajectories	google;electronic mail;prediction algorithms;semantics;smart phones;data mining;google location history spatial temporal semantic trajectory pattern mining raw trajectories gps smart phones wearable devices sts tps semantic trajectory sequences sequential pattern mining prefixspan based algorithm advanced sequence symbolization;trajectory;proceedings paper;trajectory semantics data mining smart phones prediction algorithms google electronic mail;mobile computing data mining global positioning system	With the development of GPS and the popularity of smart phones and wearable devices, users can easily log their daily trajectories. Prior works have elaborated on mining trajectory patterns from raw trajectories. However, trajectory patterns do not have explicit time information or semantic information. To enrich trajectory patterns, we propose STS-TPs (standing for Spatial-Temporal Semantic Trajectory Patterns) which refer to the moving patterns with spatial, temporal, and semantic attributes. Given a set of user trajectories, we aim at mining STS-TPs. Explicitly, we extract the three attributes from raw trajectories, and convert these trajectories into semantic trajectory sequences. Given a set of such semantic trajectory sequences, STS-TPs could be viewed as sequential patterns with multiple attributes. To fully explore the efficiency of PrefixSpan on sequential pattern mining, we propose a PrefixSpan-based algorithm (abbreviated as PS) to discover STS-TPs. Note that the input for PrefixSpan is a set of sequences consisting of items. However, each item of semantic trajectory sequences contains three attributes, and we need to further transform these sequences into symbolized sequences before using PrefixSpan. Therefore, we propose two algorithms of Sequence Symbolization (SS) and Advanced Sequence Symbolization (ASS) to achieve this purpose. In light of STS-TPs, we further propose query tasks to predict users' behaviors. To evaluate our proposed algorithms, we conducted experiments on the real datasets of Google Location History, and the experimental results show the effectiveness and efficiency of our proposed algorithms.	algorithm;data mining;experiment;global positioning system;sequential pattern mining;smartphone;tps report;wearable technology	Chien-Cheng Chen;Chia-Hsiang Kuo;Wen-Chih Peng	2015	2015 IEEE International Conference on Data Mining Workshop (ICDMW)	10.1109/ICDMW.2015.55	semantic computing;prediction;computer science;data science;trajectory;data mining;database;semantics;statistics	DB	-16.81010435031188	-35.54360283118525	172915
d7c7d3cf081c3d075842c5f6092aab56ae72ef96	change-point detection in time-series data by relative density-ratio estimation	relative density ratio estimation;kernel methods;time series data;distribution comparison;change point detection	The objective of change-point detection is to discover abrupt property changes lying behind time-series data. In this paper, we present a novel statistical change-point detection algorithm that is based on non-parametric divergence estimation between two retrospective segments. Our method uses the relative Pearson divergence as a divergence measure, and it is accurately and efficiently estimated by a method of direct density-ratio estimation. Through experiments on real-world human-activity sensing, speech, and Twitter datasets, we demonstrate the usefulness of the proposed method.		Song Liu;Makoto Yamada;Nigel Collier;Masashi Sugiyama	2012		10.1007/978-3-642-34166-3_40	econometrics;geography;pattern recognition;statistics	DB	-11.35229976327389	-34.63883333151928	173030
a18e991095e4bcbd4b8bfe563f85bb225c7449f3	image constrained blockmodelling: a constraint programming approach.		Blockmodelling is an important technique for detecting underlying patterns in graphs. However, existing blockmodelling algorithms do not provide the user with any explicit control to specify which patterns might be of interest. Furthermore, existing algorithms focus on finding standard community structures in graphs, and are likely to overlook informative but more complex patterns, such as hierarchical or ring blockmodel structures. In this paper, we propose a generic constraint programming framework for blockmodelling, which allows a user to specify and search for complex blockmodel patterns in graphs. Our proposed framework can be incorporated into existing iterative blockmodelling algorithms, operating as a hybrid optimization scheme that provides high flexibility and expressiveness. We demonstrate the power of our framework for discovering complex patterns, via experiments over a range of synthetic and real data sets.		Mohadeseh Ganji;Jeffrey Chan;Peter J. Stuckey;James Bailey;Christopher Leckie;Kotagiri Ramamohanarao;Ian Davidson	2018		10.1137/1.9781611975321.3	constraint programming;artificial intelligence;computer science;machine learning;expressivity;graph;data set	AI	-9.854451172645975	-37.6743812833101	173075
752f7766fdc64eb8693bf3b6e50be0b5a3ae27b6	data envelopment analysis as a tool for the exploration phase of mining	raman analysis;data envelopment analysis;principal component analysis;exploration phase of mining	The exploration of mining has often been limited by time-consuming methods of analysis. This paper introduces Data Envelopment Analysis (DEA) as a new tool for the exploration phase of mining. DEA is a non-parametric method for data fusion, and it is used alongside with the on-site Raman analysis. Ten meters of halved rock drillcore from the Kittil mine (Suurikuusikko deposit) were pulverised and homogenised, thus ensuring that each meter had a representative sample. These 10 samples, one for each meter, were subsequently measured with a grid measurement (32 32 measurement each) using the Raman setup. All the data points were analysed using the point-count method. After identifying the frequency at which potentially valuable minerals appear in the samples, this information was analysed using DEA. The study ends by presenting an efficiency score for each meter of drillcore. These efficiency scores enable geologists to judge more rapidly which parts of the drillcore must be logged more carefully. In addition, Principal Component Analysis (PCA) is discussed as an alternative for producing similar results to DEA. & 2016 Elsevier Ltd. All rights reserved.	bricx command center;data envelopment analysis;data point;principal component analysis;pyrite;raman scattering;undefined behavior	Tommi Kauppinen	2016	Computers & Geosciences	10.1016/j.cageo.2016.05.005	raman spectroscopy;computer science;data mining;data envelopment analysis;mathematics;operations research;principal component analysis	ML	-10.918736106362632	-34.18716275564585	173300
c36fba8c051e302fa3028404363393de00082e59	fiut: a new method for mining frequent itemsets	search space;frequent items ultrametric trees;frequent itemset;tree structure;frequent itemsets;fiu;ultrametric trees;fp growth	This paper proposes an efficient method, the frequent items ultrametric trees (FIUT), for mining frequent itemsets in a database. FIUT uses a special frequent items ultrametric tree (FIU-tree) structure to enhance its efficiency in obtaining frequent itemsets. Compared to related work, FIUT has four major advantages. First, it minimizes I/O overhead by scanning the database only twice. Second, the FIU-tree is an improved way to partition a database, which results from clustering transactions, and significantly reduces the search space. Third, only frequent items in each transaction are inserted as nodes into the FIU-tree for compressed storage. Finally, all frequent itemsets are generated by checking the leaves of each FIU-tree, without traversing the tree recursively, which significantly reduces computing time. FIUT was compared with FP-growth, a well-known and widely used algorithm, and the simulation results showed that the FIUT outperforms the FP-growth. In addition, further extensions of this approach and their implications are discussed.	algorithm;central processing unit;cluster analysis;database;mined;national supercomputer centre in sweden;recursion;tree structure	Yuh-Jiuan Tsay;Tain-Jung Hsu;Jing-Rung Yu	2009	Inf. Sci.	10.1016/j.ins.2009.01.010	discrete mathematics;computer science;data mining;database;mathematics;tree structure	DB	-5.736773144022119	-37.46318417122931	174085
1bac4a2a57f1a77075bf1d742533887173ca5249	a cellular automaton traffic flow model for online simulation of traffic	route guidance;travel time;road network;intelligent transport system;traffic flow model;simulation;real time traffic;traffic flow;traffic management;online simulation;temporal resolution;intelligent transportation systems its;cellular automata;high speed;cellular automaton	Spatially and temporally dissolved information about traffic states in road networks is a basic requirement for the application of intelligent transport systems (ITS). We present a concept for online simulations of traffic in road networks: real-time traffic data stemming from inductive loops serve as input for high-speed microsimulations using a cellular automaton traffic flow model. The quality of the reproduced traffic states is investigated with regard to vehicular densities and link travel times. As an example for dynamic traffic management we studied different strategies for individual en-route guidance systems and their efficiencies. For all investigations the road network of Duisburg served as the study area.	cellular automaton;web-based simulation	Joachim Wahle;L. Neubert;J. Esser;Michael Schreckenberg	2001	Parallel Computing	10.1016/S0167-8191(00)00085-5	traffic generation model;cellular automaton;simulation;intelligent driver model;microscopic traffic flow model;floating car data;vehicle information and communication system;computer science;traffic congestion reconstruction with kerner's three-phase theory;traffic flow;insync adaptive traffic control system;advanced traffic management system;algorithm;computer network;network traffic simulation	HPC	-16.63127778390653	-25.956604412381047	174110
ad6020f6689fe828532a52c3dd49eda3bd8679f0	disaster risk indicators in brazil: a case study in rio grande do norte state		The following paper provides a tool to help evaluate, visualize and communicate different levels of exposure, vulnerability and risk at a regional level in Brazil	winsock	Josiane Rodrigues Eugênio;Lutiane Queiroz de Almeida;Vinnícius Vale Dionízio França	2016				SE	-14.60810476000111	-24.10695163485931	174252
25f55e690f367701cfc11cf788b9624186a5fea2	long-lasting effects or short-term spark? on the persistence of behaviour change induced by real-time feedback on resource consumption			long short-term memory;persistence (computer science);real-time transcription	Verena Tiefenbeck;Vojkan Tasic;Samuel Schöb;Thorsten Staake	2016			control engineering;simulation;control theory	Robotics	-10.67016402418652	-29.355621254105934	174493
28e6cb55a9d8407f51993dfed8d9938d77c1ed60	a situation assessment model and its application based on data mining	blackboard model;power system simulation;hydroelectric power stations;hydroelectric generating units;digital simulation system;data mining hydroelectric power generation digital simulation appraisal sensor phenomena and characterization data engineering protection sensor fusion sensor systems application software;rough set theory;multisource data gathering;data mining;modified blackboard model;jinlin fengman hydropower plant;digital simulation system situation assessment hydroelectric generating units jinlin fengman hydropower plant china data mining multisource data gathering modified rough set algorithm modified blackboard model;bus protection information situation assessment blackboard model rough set fengman hydroelectricity digital simulation system;modified rough set algorithm;rough set theory data mining digital simulation hydroelectric power stations power system simulation;bus protection;fengman hydroelectricity digital simulation system;china;rough set;situation assessment;information;digital simulation	In order to solve effectively the issue of situation assessment of hydroelectric generating units in Jinlin FengMan hydropower plant in China, a general situation assessment model based on data mining is proposed, that is, gathering multi-source data, obtaining knowledge automatically using modified rough set algorithm, and the general situation assessment being realized by utilizing the modified blackboard model in dynamic circumstance. The model has been successfully applied in situation assessment of hydroelectricity digital simulation system of Jilin Fengman. Tests on system show that the proposed model are effective and can be applied widely. This model has solved high complexity, redundancy of rule, and lowered generality of former system	algorithm;blackboard system;data mining;heuristic;multi-source;real-time data;real-time transcription;rough set;set theory;simulation;source data	Shouzhi Wei;Ningde Jin;Xingjie Hui;Hui Liu	2006	2006 9th International Conference on Information Fusion	10.1109/ICIF.2006.301732	engineering;artificial intelligence;data mining;operations research	AI	-8.124827872536935	-24.171895063786	174502
1069d5b6bb2d426fe7c5dc16f0e6c9aa1b665c5c	a new mining algorithm based on frequent item sets	database mining algorithm frequent item sets;graph theory;association rules data mining transaction databases algorithm design and analysis data engineering knowledge engineering tv heuristic algorithms protection;database;data mining;graph theory data mining;frequent item sets;mining algorithm	A new mining algorithm has been put in this paper base on frequent item sets. When affair database and minimum support has changed, this new algorithm can get the new frequent item sets by scanning the undirected item set graph only one time. Its execute efficiency is improved distinctly compared to the traditional algorithm.	algorithm	Yun Wen	2008		10.1109/WKDD.2008.86	gsp algorithm;computer science;graph theory;data science;data mining;database;fsa-red algorithm;apriori algorithm	ML	-4.794233888606772	-36.89853005618203	174654
6980725e79c84ae7f9d7854585a81aea3394311a	prediction of rice brown planthoppers based on system dynamics	sociology statistics yttrium system dynamics drugs rivers production;anhui rice brown planthopper prediction chinese rice production long distance migratory pest descriptive model complex features causal relationship diagram flowchart discrete multivariate analysis method system dynamics simulation model;causal relationship;system dynamics;simulation model rice brown planthopper causal relationship system dynamics;rice brown planthopper;simulation model;plant diseases crops	Rice brown planthoppers are the main pest of Chinese rice production, and belong to the long distance migratory pest. The descriptive model of a rice brown planthopper has complex features, which are dynamic, continuous, nonlinear, multi-variable, multi-feedback, and so on. By using the system dynamics method, we analyze the causal relationships between the various factors that influence the emergence and development of rice brown planthoppers from the whole-local perspective. Both the causal relationship diagram of the factors and the flowchart on the emergence and development of rice brown planthoppers are drawn. Combining with the discrete multivariate analysis method, we establish and implement a system dynamics simulation model on the emergence and development of rice brown planthoppers in Anhui. The experimental results show that the model has high accuracy.	causality;diagram;emergence;flowchart;nonlinear system;simulation;system dynamics	Qingren Wang;Youhua Zhang;Fei Xie;Xindong Wu	2015	2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2015.7382359	causality;simulation modeling;system dynamics	Robotics	-13.814552763985342	-25.153160164184484	174809
9673e3d31ca408b88c84b6309594664b68f8e6c0	t-trees, vertical partitioning and distributed association rule mining	liverpool;association mining;distributed processing;tree data structures;data mining;association rule mining;repository;distributed processing tree data structures data mining;university;data structure;tree data structure data vp technique distributed apriori t algorithm vertical partitioning distributed association rule mining parallel association rule mining;association rules data mining itemsets tree data structures partitioning algorithms distributed computing indexing computer science concurrent computing computational efficiency	We consider a technique (DATA-VP) for distributed (and parallel) association rule mining that makes use of a vertical partitioning technique to distribute the input data, amongst processors. The proposed vertical partitioning is facilitated by a novel compressed set enumeration tree data structure (the T-tree), and an associated mining algorithm (Apriori-T), that allows for computationally effective distributed/parallel ARM when compared with existing approaches.	association rule learning;partition (database);t-tree	Frans Coenen;Paul H. Leng;Shakil Ahmed	2003		10.1109/ICDM.2003.1250965	distributed algorithm;association rule learning;data structure;decision tree learning;computer science;data science;data mining;database;fsa-red algorithm;data stream mining;tree	ML	-4.8834853164435295	-37.590979833429394	175058
0fe490e1deef5112b311cd84e6af408e03a15bbe	combined algorithm for data mining using association rules.	association rule;data mining	ARTICLE History Received Accepted ABSTRACT Association Rule mining is one of the most important fields in data mining and knowledge discovery. This paper proposes an algorithm that combines the simple association rules derived from basic Apriori Algorithm with the multiple minimum support using maximum constraints. The algorithm is implemented, and is compared to its predecessor algorithms using a novel proposed comparison algorithm. Results of applying the proposed algorithm show faster performance than other algorithms without scarifying the accuracy.	apriori algorithm;association rule learning;data mining and knowledge discovery	Walaa Medhat;Ahmed Hassan Yousef;Hoda Korashy Mohamed	2014	CoRR		data mining;knowledge extraction;apriori algorithm;gsp algorithm;hybrid algorithm;population-based incremental learning;association rule learning;algorithm;machine learning;weighted majority algorithm;fsa-red algorithm;pattern recognition;computer science;artificial intelligence	ML	-4.6995343903809506	-36.73305029193093	175251
2d71bf0312f4c6186994410b641a667422a93338	an approach to evaluating motion pattern detection techniques in spatio-temporal data	distribution;europa;constrained random walk;movimiento;metodo monte carlo;deteccion;political science;monte carlo experiments;suiza;simulation;evaluation method;frequence;methode monte carlo;suisse;simulacion;etude methode;detection;motion;estudio metodo;data mining;statistical properties;speed;pattern detection;frecuencia;spatio temporal data;general population;fouille donnee;random walk;pattern matching;vitesse deplacement;monte carlo experiment;monte carlo method;mouvement;velocidad desplazamiento;decouverte connaissance;descubrimiento conocimiento;switzerland;method study;marcha aleatoria;synthetic data;geografia;numerical experiment;europe;frequency;monte carlo simulation;experimentation;geographie;distribucion;busca dato;lifelines;geographic knowledge discovery;marche aleatoire;experimentacion;knowledge discovery;geography	This paper presents a method to evaluate a geographic knowledge discovery approach for exploring the motion of point objects. The goal is to provide a means of considering the significance of motion patterns, described through their interestingness. We use Monte-Carlo simulations of constrained random walks to generate populations of synthetic lifelines, using the statistical properties of real observational data as constraints. Pattern occurrence in the synthetic data is then compared with observational data to assess the potential interestingness of the found patterns. We use motion data from wildlife biology and spatialisation in political science for the evaluation. The results of the numerical experiments show that the interestingness of found motion patterns is largely dependant on the configuration of the pattern matching process, which includes the pattern extent, the temporal granularity, and the classification schema used for the motion attributes azimuth and speed. The results of the numerical experiments allow interestingness to be attached only to some of the patterns found, – other patterns were suggested to be not interesting. The evaluation method helps in estimating useful configurations of the pattern detection process. This work emphasises the need to further investigate the statistical aspects of the problem under study in (geographic) knowledge discovery.	experiment;flickr;monte carlo method;numerical analysis;pattern matching;pattern recognition;population;simulation;synthetic data;synthetic intelligence	Patrick Laube;Ross Purves	2006	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2005.09.001	simulation;geography;computer science;artificial intelligence;mathematics;knowledge extraction;cartography;statistics;monte carlo method	ML	-4.9907816933880795	-31.620688748602653	175492
0f295294ed5f9c0d9f4778572fec0b3b7330542f	a case study on epidemic disease cartography using geographic information		Research of epidemiology is one of the important components in the field of public health while spatial epidemiology combing traditional epidemiology with Geographic Information Science is often regarded as an effective way for visualization analysis. Here we conduct a disease study under the help of spatial technologies using one-year real epidemic data collected from Ningbo, Zhejiang, China where an epidemic cartography approach taking data scale into account is newly proposed and elaborated. The demonstrated experimental results indicate that the proposed method performs more flexible for analysis than that of traditional statistical methods.	cartography	Changbin Yu;Jiangang Yang;Yiwen Wang;Ke Huang;Honglei Cui;Mingfang Dai;Hongjian Chen;Yu Liu;Zhensheng Wang	2016		10.1007/978-3-319-48335-1_20	demography;geography	HCI	-13.773771223224745	-24.194657211868805	175495
bbc845a35418683ed238421aba83e2274e2cbc33	knowledge discovery: some empirical evidence and directions for future research		Large amounts of data generated by electronic commerce are becoming an increasingly important source of knowledge to support organisational decision making. An empirical study was conducted in a simulated electronic commerce environment to examine people's ability to discover varying associative patterns in transactions data, and utilise that knowledge to support product sales forecasting. The results of the study indicate that people were able to reasonably well discover valid associations among data items and consequently improved performance over naive forecasts. The results also indicate that people were more successful in recognising and using stronger rather than weaker associative patterns. However, they failed to reach optimal performance.	e-commerce;knowledge management	Meliha Handzic;Aybüke Aurum	2001			artificial intelligence;data science;machine learning;data mining;management;world wide web	DB	-5.833912895133287	-30.279285420283344	175512
7e450469f85217bea0eb7396235f002140ebd3a2	formal punctuality analysis of frequent bus services using headway data		We evaluate the performance of frequent bus services in Edinburgh using the punctuality metrics identified by the Scottish Government. We describe a methodology for evaluating each of these metrics that only requires measurements of bus ‘headways’ — the time between subsequent bus arrivals. Our methodology includes Monte Carlo simulation and time series analysis. Since one metric is given in ambiguous language, we provide a formal description of the two most plausible interpretations. The automated nature of our method allows public transport operators to continuously assess whether the performance of their network meets the targets set by government regulators. We carry out a case study using Automatic Vehicle Location (AVL) data involving two frequent services, including the AirLink service to and from Edinburgh airport.	avl tree;automatic vehicle location;bootstrapping (compilers);model checking;monte carlo method;offset binary;simulation;statistical model;time of arrival;time series	Daniël Reijsbergen;Stephen Gilmore	2014		10.1007/978-3-319-10885-8_12	simulation;computer science;operations management;transport engineering	Metrics	-9.956988895733371	-25.326375722162688	175521
8d3ab80886a6be52bd24a67dd625a7b306682f43	extensible platform for studying the behavior of drivers in urban traffic	automated vehicle control;observed behavior driver behavior urban traffic traffic management macro scale problems traffic optimization decision making process automated vehicle individual human driver urban environment;road vehicles behavioural sciences decision making driver information systems optimisation;drivers;optimization;highway traffic control;vehicles feature extraction analytical models global positioning system adaptation models data models data mining;behavior;left turns	Research on traffic management and automation focuses on macro-scale problems involving large number of vehicles. It seems that the influence of individual decisions of particular drivers has not received sufficient attention over last decades. Understanding the characteristics of particular drivers is crucial for traffic optimization and for decisions making process performed by automated vehicles. In this paper we would like to present a prototype platform for studying characteristics of individual human drivers. The platform collects data during driving in urban environment and performs analysis and classification of observed behaviors. It is extensible in terms of measured parameters and classification methods. We also present results of first experiment using the created platform - classification of drivers during the left turn maneuver.	device driver;mathematical optimization;prototype;statistical classification;steering wheel	Piotr Blaszczyk;Wojciech Turek;Krzysztof Cetnarowicz	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6957876	simulation;engineering;automotive engineering;transport engineering	Robotics	-18.216404677372854	-26.01506466224148	175924
f79172032868fca0285a7b1811eaee7f1aa5e8ac	a data-driven approach for convergence prediction on road network	taxi trajectory;data mining;convergence prediction	With the rapid development of location sensing technology such as GPS, huge amount of location data through GPS are produced every day. The flood of taxi GPS data make it possible to predict the plentitude of traffic events on road network. In this paper, we propose a data-driven approach for traffic state convergence prediction on road network. We introduce a new method predicting the future location of taxis on road network. Furthermore we propose a statistical model to predict real time convergence on road network. We experimentally demonstrated that our approach achieves high prediction precision on the real world massive taxi GPS data.		Qiulei Guo;Jun Luo;Guiqing Li;Xin Wang;Nikolas Geroliminis	2013		10.1007/978-3-642-37087-8_4	simulation;computer science;data mining	ML	-16.21644610695421	-32.40645099410018	176295
f79dd22010a80ee7ff9e17f406bc2f67e5538b76	granular computing in computer image perception: basic issues and glass box models	granular computing;algebraic models;algebraic systems;image analysis;general system theory;digital images;granules	"""The Granular Computing (GrC) emerges as a new multidisciplinary study and has received much attention in recent years. It is argued that GrC is more about the theoretical studies and a practical methodology of problem solving. By effectively using levels of granularity, GrC theory provides systematic practical way to analyze and represent the real world information. The most complicated problems are the image processing, analyze etc. Follow to very common terminology introduced by L. Zadeh we can notify the full collection of related problems in computer vision as """"visual perception"""". There are three main fulcrum to provide the effective techniques for GrC algorithms. At first, we will use the General system theory to represent and circumscribe the image models. Second, we must use the Soft Computing guide principle to achieve the computational complexity reduction. At least, we must take into consideration all uncertainty factors (clutter), presented in real world images. Like the rock-climber, we can bear on the mentioned handholds and achieve the methodology for mathematically homogeneous process of visual perception."""		Sergey A. Butenkov;Vitaly V. Krivsha;Al Dhouyani Saud	2006			simulation;computer science;artificial intelligence;theoretical computer science	Vision	-6.363560252983965	-27.70275477233853	176309
03d01a63e26ffc75b6802c06e346d4de99f355cf	case retrieval with time series features	time series		time series	Stefania Montani;Luigi Portinale;Riccardo Bellazzi;Giorgio Leonardi	2005	Intelligenza Artificiale			ML	-11.698077260886226	-28.085970976029138	176708
cc9af481fc0a125dc4c0a840f6e99b21c09bb8ab	modeling of plant growth based on juvenile energy			simulated growth of plants	Jeong-Woo Kwon;Un-Don Choi;Jong-Hee Park	2003			ecology;juvenile;biology	EDA	-11.311410180276807	-26.740144408847883	177209
79e9447ae6ae1fc4d8e96255af0d51dc38c0c96f	increasing precision of credible case-based inference	optimality criteria;similarity measure;problem solving	Credible case-based inference (CCBI) is a new and theoretically sound inferencing mechanism for case-based systems. In this paper, we formally investigate the level of precision that CCBI-based retrieval results may yield. Building upon our theoretical findings, we derive a number of optimization criteria that can be utilized for learning such similarity measures that bring about more precise predictions when used in the scope of CCBI. Our empirical experiments support the claim that, given appropriate similarity measures, CCBI can be enforced to produce highly precise predictions while its corresponding level of confidence is only marginally impaired.	benchmark (computing);experiment;mathematical optimization;tweaking	Thomas Gabel;Martin A. Riedmiller	2008		10.1007/978-3-540-85502-6_15	econometrics;data mining;mathematics;statistics	AI	-7.5787296792654	-26.272594564386456	177306
19b86cf0bfe819ef6e2a63a53f8a28f2146bc603	the market value of cultural heritage in urban areas: an application of spatial hedonic pricing	valuation methods;listed building;cultural heritage;stated preference methods;hedonic prices;historic buildings;spatial statistics;spatial autocorrelation	The current literature often values intangible goods like cultural heritage by applying stated preference methods. In recent years, however, the increasing availability of large databases on real estate transactions and listed prices has opened up new research possibilities and has reduced various existing barriers to applications of conventional (spatial) hedonic analysis to the real estate market. The present paper provides one of the first applications using a spatial autoregressive model to investigate the impact of cultural heritage—in particular, listed buildings and historic–cultural sites (or historic landmarks)—on the value of real estate in cities. In addition, this paper suggests a novel way of specifying the spatial weight matrix—only prices of sold houses influence current price—in identifying the spatial dependency effects between sold properties. The empirical application in the present study concerns the Dutch urban area of Zaanstad, a historic area for which over a long period of more than 20 years detailed information on individual dwellings, and their market prices are available in a GIS context. In this paper, the effect of cultural heritage is analysed in three complementary ways. First, we measure the effect of a listed building on its market price in the relevant area concerned. Secondly, we investigate the value that listed heritage has on nearby property. And finally, we estimate the effect of historic– cultural sites on real estate prices. We find that, to purchase a listed building, buyers are willing to pay an additional 26.9 %, while surrounding houses are worth an extra 0.28 % for each additional listed building within a 50-m radius. Houses sold within a F. Lazrak (&) P. Nijkamp (&) P. Rietveld J. Rouwendal Department of Spatial Economics, VU University Amsterdam, De Boelelaan 1105, 1081 HV Amsterdam, The Netherlands e-mail: f.lazrak@vu.nl P. Nijkamp A. Mickiewicz University, Poznan, Poland e-mail: p.nijkamp@vu.nl 123 J Geogr Syst DOI 10.1007/s10109-013-0188-1	autoregressive model;database;email;geographic information system;hedonic regression;rietveld	Faroek Lazrak;Peter Nijkamp;Piet Rietveld;Jan Rouwendal	2014	Journal of Geographical Systems	10.1007/s10109-013-0188-1	mathematics;spatial analysis;statistics	HCI	-14.737882484454753	-26.654619726566224	177318
e09a0965f72420ce0daebda1b0586cbbe850c7d4	pbe: driver behavior assessment beyond trajectory profiling		Nowadays, the increasing car accidents ask for the better driver behavior analysis and risk assessment for travel safety, auto insurance pricing and smart city applications. Traditional approaches largely use GPS data to assess drivers. However, it is difficult to fine-grained assess the time-varying driving behaviors. In this paper, we employ the increasingly popular On-Board Diagnostic (OBD) equipment, which measures semantic-rich vehicle information, to extract detailed trajectory and behavior data for analysis. We propose PBE system, which consists of Trajectory Profiling Model (PM), Driver Behavior Model (BM) and Risk Evaluation Model (EM). PM profiles trajectories for reminding drivers of danger in real-time. The labeled trajectories can be utilized to boost the training of BM and EM for driver risk assessment when data is incomplete. BM evaluates the driving risk using fine-grained driving behaviors on a trajectory level. Its output incorporated with the time-varying pattern, is combined with the driver-level demographic information for the final driver risk assessment in EM. Meanwhile, the whole PBE system also considers the real-world cost-sensitive application scenarios. Extensive experiments on the real-world dataset demonstrate that the performance of PBE in risk assessment outperforms the traditional systems by at least 21%.		Bing He;Xiaolin Chen;Dian Zhang;Siyuan Liu;Dawei Han;Lionel M. Ni	2018		10.1007/978-3-030-10997-4_31	smart city;global positioning system;ask price;machine learning;profiling (computer programming);trajectory;risk assessment;computer science;artificial intelligence	HCI	-16.122691768850125	-31.364650962146467	177454
dbfd8fc52bd982fb37d4805b85faa0f08a541af6	using random forests to diagnose aviation turbulence	biological patents;biomedical journals;weather;text mining;europe pubmed central;citation search;data fusion;citation networks;research articles;thunderstorms;abstracts;open access;random forest;life sciences;clinical guidelines;aviation;full text;air traffic;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search;turbulence	Atmospheric turbulence poses a significant hazard to aviation, with severe encounters costing airlines millions of dollars per year in compensation, aircraft damage, and delays due to required post-event inspections and repairs. Moreover, attempts to avoid turbulent airspace cause flight delays and en route deviations that increase air traffic controller workload, disrupt schedules of air crews and passengers and use extra fuel. For these reasons, the Federal Aviation Administration and the National Aeronautics and Space Administration have funded the development of automated turbulence detection, diagnosis and forecasting products. This paper describes a methodology for fusing data from diverse sources and producing a real-time diagnosis of turbulence associated with thunderstorms, a significant cause of weather delays and turbulence encounters that is not well-addressed by current turbulence forecasts. The data fusion algorithm is trained using a retrospective dataset that includes objective turbulence reports from commercial aircraft and collocated predictor data. It is evaluated on an independent test set using several performance metrics including receiver operating characteristic curves, which are used for FAA turbulence product evaluations prior to their deployment. A prototype implementation fuses data from Doppler radar, geostationary satellites, a lightning detection network and a numerical weather prediction model to produce deterministic and probabilistic turbulence assessments suitable for use by air traffic managers, dispatchers and pilots. The algorithm is scheduled to be operationally implemented at the National Weather Service’s Aviation Weather Center in 2014.	adobe air;algorithm;aviation;controllers;deploy;evaluation procedure;flight simulator;forests;geosynchronous satellite;kerrison predictor;lightning detection;numerical analysis;numerical weather prediction;projections and predictions;prototype;random forest;real-time clock;receiver operating characteristic;satellite viruses;schedule (document type);silo (dataset);test set;turbulence	John K. Williams	2013		10.1007/s10994-013-5346-7	turbulence;random forest;text mining;simulation;computer science;thunderstorm;artificial intelligence;air traffic control;machine learning;sensor fusion;operations research;aviation	ML	-14.81946664849068	-27.74101108436001	177483
39d0da01d4ce9e44b8e4222859194806603cb98d	dynamic data driven event reconstruction for traffic simulation using sequential monte carlo methods	public domain software;monte carlo methods	Simulation models are commonly used to study traffic systems. Accurate traffic predictions need proper characterization of the traffic flow and knowledge of related parameters representing the state of the traffic flow in the models. To correctly estimate the traffic flow in real time, we need to reconstruct the event by answering such critical questions as the source of the congestions. The availability of sensor data from the real traffic provides information that can be assimilated into a traffic simulation model for improving predicted results. In this paper, we use the sequential Monte Carlo methods to assimilate real time sensor data into the simulation model MovSim, an open-source vehicular-traffic simulator, to reconstruct events such as the slow vehicles that cause the traffic jam. Related experimental results are presented and analyzed.	dynamic data;jam;monte carlo method;open-source software;simulation	Xuefeng Yan;Feng Gu;Xiaolin Hu;Carl Engstrom	2013	2013 Winter Simulations Conference (WSC)		traffic generation model;real-time computing;simulation;floating car data;computer science;traffic congestion reconstruction with kerner's three-phase theory;mathematics;public domain software;computer security;statistics;monte carlo method;network traffic simulation	Metrics	-15.971429827372582	-29.9703583542231	178117
e6e0b99b165cd7b400b802c5dce6c52aa112d513	research on customer segmentation model by clustering	segmentation model;clustering analysis;customer segmentation	In the paper, we use credit card consumption data as our model-building samples and present a modeling framework for building segment-level predictive models that utilize pattern-based clustering approach and signature discovery techniques. We devise monetary matrix and fluctuate-rate matrix to study various modes. Through clustering on both matrixes, we uncover different customer characteristics. Utilizing these characteristics, we can build two-dimension Consumption-Based customer segmentation model.	cluster analysis;predictive modelling	Jing Wu;Zheng Lin	2005		10.1145/1089551.1089610	correlation clustering;fuzzy clustering;marketing;segmentation-based object categorization;data mining;advertising;business;cluster analysis;scale-space segmentation	AI	-4.5965762975203	-33.8548605059013	178594
7325957f6ff1ae314a965fa424a58673358bd5c3	coreference detection in xml metadata	integral equations;fuzzy set theory;xml data acquisition fuzzy set theory integral equations meta data pattern matching;xml metadata sugeno integral possibilistic truth values path matching xml schemas coreferent object detection duplicate object detection data collection management data quality preservation;technology and engineering;pattern matching;xml;meta data;data acquisition;xml educational institutions uncertainty context lattices q measurement databases	Preserving data quality is an important issue in data collection management. One of the crucial issues hereby is the detection of duplicate objects (called coreferent objects) which describe the same entity, but in different ways. In this paper we present a method for detecting coreferent objects in metadata, in particular in XML schemas. Our approach consists in comparing the paths from a root element to a given element in the schema. Each path precisely defines the context and location of a specific element in the schema. Path matching is based on the comparison of the different steps of which paths are composed. The uncertainty about the matching of steps is expressed with possibilistic truth values and aggregated using the Sugeno integral. The discovered coreference of paths can help for determining the coreference of different XML schemas.	aggregate data;data quality;root element;sensor;sugeno integral;xml namespace;xml schema	Marcin Szymczak;Slawomir Zadrozny;Guy De Tré	2013	2013 Joint IFSA World Congress and NAFIPS Annual Meeting (IFSA/NAFIPS)	10.1109/IFSA-NAFIPS.2013.6608598	xml validation;xml schema;computer science;document structure description;xml framework;data mining;xml database;xml schema;database;xml schema editor;information retrieval	DB	-7.160670008297889	-30.87268487075646	178671
e55f3e58dce05ae9d769ac0f6c7ec7f3386ba6a9	recommending pick-up points for taxi-drivers based on spatio-temporal clustering	hierarchical clustering;pattern clustering;gps trajectories analyses;spatio temporal clustering;recommendation pick up points;hierarchical clustering gps trajectories analyses recommendation pick up points spatio temporal clustering;recommender systems driver information systems global positioning system pattern clustering;global positioning system;global positioning system vehicles clustering algorithms real time systems trajectory data preprocessing asia;microsoft research asia pick up point recommendation taxi driver spatio temporal clustering gps trajectory global positioning system spatio temporal noise data preprocessing pick up point ranking;driver information systems;recommender systems	Using GPS trajectories to recommend pick-up points for taxi driver comes to be a promising approach of increasing profits and decreasing pollutions. In the existing methods, nearly all the GPS data of a city are computed for recommendation. However, it is time-consuming and not accurate enough owing to too much spatio-temporal noise. Therefore, we propose a novel method of recommending pick-up for taxi driver based on spatio-temporal clustering. It is made up of data preprocessing and real-time recommendation. Firstly, we capture the historical pick-up points by analyzing their intervals. These points are clustered at different time and different regions to create candidate pick-up points. Secondly, after ranking the candidate pick-up points around the taxi, the top-5 valuable pick-up points are recommended for taxi drivers. The experimental results, whose data come from Microsoft Research Asia, show that our method can effectively recommend pick-up points for taxi drivers.	algorithm;arcgis;cluster analysis;data pre-processing;global positioning system;microsoft research;preprocessor;real-time locating system;recommender system	Mingyue Zhang;Jianxun Liu;Yizhi Liu;Zhenyang Hu;Liang Yi	2012	2012 Second International Conference on Cloud and Green Computing	10.1109/CGC.2012.34	data stream clustering;simulation;geography;data science;data mining;cluster analysis	Robotics	-16.583091416898004	-33.19419048637241	178771
3932b376bba1612c4e038b1e70162f76a2192a23	mining of stock data: intra- and inter-stock pattern associative classification.	time series;data mining;association rule mining;time series analysis;majority voting;association analysis	In this paper, a pattern-based stock data mining approach which transforms the numeric stock data to symbolic sequences, carries out sequential and non-sequential association analysis and uses the mined rules in classifying/predicting the further price movements is proposed. Two formulations of the problem are considered. They are intra-stock mining which focuses on finding frequently appearing patterns for the stock time series itself and inter-stock mining which discovers the strong inter-relationship among several stocks. Three different methods are proposed for carrying out associative classification/prediction, namely, Best Confidence, Maximum Window Size and Majority Voting. They select the mined rule(s) and make the final prediction. A modified Apriori algorithm is also proposed to mine the frequent symbolic sequences in intra-stock mining and the frequent symbol-sets in inter-stock mining. Various experimental results are reported.	apriori algorithm;association rule learning;cutting stock problem;data mining;experiment;mined;statistical classification;time series;transaction time	Jo Ting;Tak-Chung Fu;Korris Fu-Lai Chung	2006			machine learning;pattern recognition;data mining	ML	-4.783992092891503	-35.28802813626477	178815
55541606f08d279cc30cb6ab93248b1f618fce10	a spanning tree-based human activity prediction system using life logs from depth silhouette-based human activity recognition	human activity prediction;hmm;lda;spanning tree;human activity recognition;ica;pca	In this work, we propose a Human Activity Prediction (HAP) system using activity sequence spanning trees constructed from a life-log created by a video sensor-based daily Human Activity Recognition (HAR) system using time-sequential Independent Component (IC)-based depth silhouette features with Hidden Markov Models (HMMs). In the daily HAR system, the IC features are extracted from the collection of the depth silhouettes containing various daily human activities such as walking, sitting, lying, cooking, eating etc. Using these features, HMMs are used to model the time sequential features and recognize various human activities. The depth silhouette-based human activity recognition system is used to recognize daily human activities automatically in real time, which creates a life-log of daily activity events. In this work, we propose a method for human activity prediction using fixed-length activity sequence spanning trees based on the life-log. Utilizing the consecutive activities recorded in an activity sequence database (i.e. life-log) for a specific period of time of each day over a period such as a month, the fixed-length spanning trees can be constructed for the sequences starting with each activity where the leaf nodes contain the frequency of the fixed-length consecutive activity sequences. Once the trees are constructed, to predict an activity after a sequence of activities, we traverse the spanning trees until a path up to the previous node of the leaf nodes is matched with the testing pattern. Finally, we can predict the next activity based on the highest frequency of the leaf nodes along the matched path. The prediction experiments over the computer simulated data which is based on the daily logs show satisfactory results. Our video sensor-based human activity recognition and prediction systems can be utilized for practical applications such as smart and proactive healthcare.	activity recognition;spanning tree	Md. Zia Uddin;Kyung Min Byun;Min Hyoung Cho;Soo Yeol Lee;Gon Khang;Tae-Seong Kim	2011		10.1007/978-3-642-23672-3_37	spanning tree;computer science;machine learning;pattern recognition;mathematics;hidden markov model;principal component analysis	HCI	-13.696965558955458	-34.1425132801466	179156
17678f9681a496aa938531e9f97883377b168720	semantic trajectory mining for location prediction	trajectory database;data mining;prediction model;location prediction;semantic prediction;mobile user;trajectory pattern	Research on predicting movements of mobile users has attracted a lot of attentions in recent years. Many of those prediction techniques are developed based only on geographic features of mobile users' trajectories. In this paper, we propose a novel approach for predicting the next location of a user's movement based on both the geographic and semantic features of users' trajectories. The core idea of our prediction model is based on a novel cluster-based prediction strategy which evaluates the next location of a mobile user based on the frequent behaviors of similar users in the same cluster determined by analyzing users' common behavior in semantic trajectories. Through a comprehensive evaluation by experiments, our proposal is shown to deliver excellent performance.	experiment;location-based service	Jia-Ching Ying;Wang-Chien Lee;Tz-Chiao Weng;Vincent S. Tseng	2011		10.1145/2093973.2093980	geography;computer science;data science;data mining;predictive modelling;world wide web	HCI	-17.008010143211493	-35.359275789275536	179485
daaf93771d317e7a195ec71fb9176812d637c9cc	transevis: a visual analytics system for transportation data sensing and exploration		With increasing availability of location-acquisition technologies, huge volumes of data tracking transportation system have been collected. These data are highly valuable for unveiling human mobility patterns, transportation system utilization, and urban planning. However, it is still highly challenging to visualize and explore transportation data. In this paper, an interactive visual analytic system, TranSeVis has been proposed. It has two visualization modules, one named region view provides geographical information and effective temporal information comparison, the other named road view provides detailed visual analysis of mobility factors along routes or congestions spots. Besides, two case studies have been used to evaluate the visualization techniques and real-world taxi data sets have been used to demonstrate TranSeVis. Based on the results, TranSeVis offers transportation researchers an easy-to-use, efficient, and scalable platform to visualize and explore transportation data.	visual analytics	Rui Gong;Zhiyao Teng;Mei Han;Lirui Wei;Yuwei Zhang;Jiansu Pu	2018		10.1007/978-3-030-00560-3_1	systems engineering;data mining;scalability;visual analytics;visualization;tracking system;computer science;data set;urban planning	Robotics	-17.84592742799784	-31.9446953534351	179548
c105d00ec5a24afd6dd83455e4b78eef4a23a7ca	freesim_mobile: a novel approach to real-time traffic gathering using the apple iphone™	vehicles probes real time systems roads accuracy global positioning system cellular phones;vehicular network;real time traffic simulator;anchorage;built in gps receiver;cellular radio;real time;v2i architecture;real time traffic;university of alaska;traffic flow;probes;accuracy;telecommunication traffic;vehicle tracking devices;traffic flow freesim_mobile real time traffic gathering apple iphone built in gps receiver v2i architecture real time traffic simulator university of alaska anchorage vehicle tracking devices cellular network;continuous flow;roads;global positioning system;freesim_mobile;cellular network;mobile handsets;real time traffic gathering;telecommunication traffic cellular radio global positioning system mobile handsets;vehicles;vehicle tracking;cellular phones;apple iphone;real time systems	In this paper, we present a preliminary application for the iPhone™ [2] that uses the built-in GPS receiver along with the web capabilities utilizing a V2I architecture to send a continuous flow of data to a central server where FreeSim [13–15], a real-time traffic simulator, applies the proportional model algorithm [18] to determine the time to traverse a roadway in order to report in real-time the current flow of traffic. At the University of Alaska, Anchorage, we currently have vehicle tracking devices installed in 80 probe vehicles that traverse the Anchorage area. The high cost associated with vehicle tracking devices makes it difficult to penetrate a large vehicular network on limited funds, so we must look towards other available technologies, such as the constantly-expanding cellular network. In this paper we look at the iPhone™ 3G capability of reporting accurate and reliable locations by describing our sample application and comparing its reported GPS accuracy to the existing vehicle probes we have. We will then present a study of its performance of calculating an accurate traffic flow where a chosen section of roadway was driven. Drivers equipped with an iPhone™ 3G cellular phone and a vehicle tracking device manually timed how long it took to travel along the test road section. The vehicle tracking devices report speed and location every 10 seconds whereas the iPhone™ is capable of reporting the location every second, though we were receiving it every eight seconds. From this data, we calculated the amount of time to traverse the test roadway section using the proportional model algorithm and compared it to the actual amount of time it took to traverse the test roadway section. We found that the vehicle tracking device had an average error factor of 4.43% from the actual time to traverse the roadway section (as determined by the stopwatch), whereas the iPhone™ was found to have an error factor of 4.18%. The outcome of the case study is used to determine that the iPhone™ is relatively as accurate as a vehicle tracking device, though it is important to note that the iPhone™ is more limited than a device attached to a vehicle in the data it can obtain to only reporting its location.	algorithm;canonical account;dataflow;global positioning system;mobile phone;real-time clock;real-time transcription;server (computing);simulation;traverse;vehicle tracking system	Timothy Menard;Jeffrey Miller	2010	2010 IEEE Vehicular Networking Conference	10.1109/VNC.2010.5698273	embedded system;cellular network;simulation;global positioning system;telecommunications;vehicle tracking system;computer science;traffic flow;accuracy and precision;ivms;computer network	Mobile	-18.68138769681526	-29.500814180183845	179690
33c9df1d5b8424a017e6ee62744cbb1fb88de50d	modeling and analysis of large-scale urban mobility for green transportation		Context-aware applications of vehicular social networks (VSNs) play a significant role to achieve the goal of green transportation by sharing driving experience to reduce gasoline consumption. One of the main challenges is to evaluate the performance of these applications, which relies on the underlying VSN mobility model. In this paper, we investigate big urban traffic data to characterize essential features of urban mobility and construct large-scale green urban mobility models. We exploit the road and traffic information to enhance the trip generation algorithm and traffic assignment technique based on the weighted segments of roads. Besides, we perform extensive observations and corrections on the OpenStreetMap imported to simulation of urban mobility to make it analogous to real-world road topology. The experimental results and validation process show that the generated mobility models reveal realistic behavior required for analysis of context-aware applications of VSNs for green transportation systems.	algorithm;openstreetmap;simulation;social network	Feng Xia;Azizur Rahim;Xiangjie Kong;Meng Wang;Yinqiong Cai;Jinzhong Wang	2018	IEEE Transactions on Industrial Informatics	10.1109/TII.2017.2785383	sustainable transport;real-time computing;computer science;transport engineering;public transport;informatics;trip generation;exploit;social network;mobility model	Mobile	-18.097836931037904	-33.496587537660844	180091
8c70f7dda57bd19376cb5f502260c72fa8ea2735	discovering debtor patterns of centrelink customers	decision tree;data mining;sequence mining;data model;data mining application;association rule;data warehouse;conference proceeding	Data mining is currently becoming an increasingly hot research field, but a large gap still remains between the research of data mining and its application in real-world business. As one of the largest data users in Australia, Centrelink has huge volume of data in data warehouse and tapes. Based on the available data, Centrelink is seeking to find underlying patterns to be able to intervene earlier to prevent or minimize debt. To discover the debtor patterns of Centrelink customers and bridge the gap between data mining research and application, we have done a project on improving income reporting to discover the patterns of those customers who were or are in debt to Centrelink. Two data models were built respectively for demographic data and activity data, and decision tree and sequence mining were used respectively to discover demographic patterns and activity sequence patterns of debtors. The project produced some potentially interesting results, and paved the way for more data mining applications in Centrelink in near future.	data mining;data model;decision tree;sequential pattern mining	Yanchang Zhao;Longbing Cao;Yvonne Morrow;Yuming Ou;Jiarui Ni;Chengqi Zhang	2006			sequential pattern mining;association rule learning;data model;computer science;data science;decision tree;data warehouse;data mining;database	ML	-9.004951875422211	-31.04452896204963	180103
0beca56d0260ffa0c68d17b7e90ccff42b820076	optimized stratified sampling for approximate query processing	workload;extraction information;outil logiciel;database system;performance random sampling;decision support;software tool;base donnee;distribution donnee;computacion informatica;analisis datos;query processing;information extraction;systeme aide decision;sql;random sampling;traitement requete;interrogation base donnee;database;interrogacion base datos;base dato;sistema ayuda decision;probabilistic approach;approximate query processing;data mining;database management;data distribution;approximation;optimization problem;data analysis;decision support system;stratified random sampling;fouille donnee;mathematical programming;ciencias basicas y experimentales;enfoque probabilista;approche probabiliste;muestreo aleatorio;charge travail;algorithms;analyse donnee;design;tratamiento pregunta;information system;carga trabajo;grupo a;experimentation;herramienta software;echantillonnage aleatoire;programmation mathematique;distribucion dato;busca dato;algorithm design;programacion matematica;database query;extraccion informacion;stratified sampling;variance;variancia	The ability to approximately answer aggregation queries accurately and efficiently is of great benefit for decision support and data mining tools. In contrast to previous sampling-based studies, we treat the problem as an optimization problem where, given a workload of queries, we select a stratified random sample of the original data such that the error in answering the workload queries using the sample is minimized. A key novelty of our approach is that we can tailor the choice of samples to be robust, even for workloads that are “similar” but not necessarily identical to the given workload. Finally, our techniques recognize the importance of taking into account the variance in the data distribution in a principled manner. We show how our solution can be implemented on a database system, and present results of extensive experiments on Microsoft SQL Server that demonstrate the superior quality of our method compared to previous work.	approximation algorithm;data mining;database;decision support system;experiment;mathematical optimization;microsoft sql server;optimization problem;sampling (signal processing);stratified sampling	Surajit Chaudhuri;Gautam Das;Vivek R. Narasayya	2007	ACM Trans. Database Syst.	10.1145/1242524.1242526	decision support system;computer science;theoretical computer science;data mining;database;stratified sampling	DB	-6.41708684954594	-33.112412136815486	180696
4ca0fd71b3447e42d9b1bf1fdc96968209d656e5	efficient evaluation of composite correlations for streaming time series	time correlation;streaming;analisis datos;correlation temporelle;time series;data analysis;correlacion temporal;transmission en continu;serie temporelle;serie temporal;analyse donnee	In applications ranging from stock trading to space mission operations, it is important to monitor the correlations among multiple streaming time series e ciently in order to make timely decisions. The challenge is that both the number of streaming time series and the number of interested correlations can be large. The straightforward way of performing the evaluation by computing the correlation value for each relevant stream pair at each time position is not e cient enough in many situations. In this paper, we introduce an e cient method for the case where we need to monitor composite correlations, i.e., conjunctions of high correlations among multiple pairs of streaming time series. We use a simple mechanism to predict the correlation values of relevant stream pairs at the next time position and rank the stream pairs carefully so that the pairs that are likely to have low correlation values are evaluated rst. We show, through experiments, that the method signi cantly reduces the total number of pairs for which we need to compute the correlation values due to the conjunctive nature of the composites.	experiment;time series	Min Wang;Xiaoyang Sean Wang	2003		10.1007/978-3-540-45160-0_37	econometrics;artificial intelligence;time series;mathematics;data analysis;statistics	DB	-7.333913377960801	-34.0480780028294	180860
d57a7fb581956de2a3b2faa8218d03e743c2253a	evaluation of predictive models for wildlife poaching activity through controlled field test in uganda.		Worldwide, conservation agencies employ rangers to protect conservation areas from poachers. However, agencies lack the manpower to have rangers effectively patrol these vast areas frequently. While past work modeled poachers behavior so as to aid rangers in planning future patrols, those models predictions were not validated by extensive field tests. We conducted two rounds of field tests in Ugandas Queen Elizabeth Protected Area to evaluate our proposed spatio-temporal model that predicts poaching threat levels. In the first round, a one-month field test was conducted to test the predictive power of the model and in the second round an eight-month test was conducted to evaluate the selectiveness power of the model. To our knowledge, this is the first time that a predictive model is evaluated through such an extensive field test in this domain. These field tests will be extended to another park in Uganda, Murchison Fall Protected Area. Once such models are evaluated in the field, they can be used to generate efficient and feasible patrol routes for the park rangers.	predictive modelling	Shahrzad Gholami;Benjamin J. Ford;Debarun Kar;Fei Fang;Milind Tambe;Andrew J. Plumptre;Margaret Driciru;Fred Wanyama;Aggrey Rwetsiba;Mustapha Nsubaga;Joshua Mabonga	2018			management science;machine learning;artificial intelligence;computer science;poaching;wildlife	HCI	-15.443634556530625	-28.417763609526155	181302
a912b41fad23e7e9a986918c8c97c890e1e79ad8	efficient mining of traversal patterns	efficient algorithm;web accessibility;data mining;suffix tree;traversal patterns;clickstream analysis	A new problem of mining traversal patterns from Web access logs is introduced. The traversal patterns are defined to keep duplicates as well as consecutive ordering in the sessions. Then an efficient algorithm is proposed. The algorithm is online, which allows the user to see the incremental results with respect to the scanned part of the database. The algorithm also adapts to large databases through dynamic compressions and effective pruning. Finally the algorithm is evaluated through experiments with real Web logs.		Yongqiao Xiao;Margaret H. Dunham	2001	Data Knowl. Eng.	10.1016/S0169-023X(01)00039-8	computer science;graph traversal;web accessibility;data mining;database;world wide web	ML	-6.57700857326618	-37.52633367957065	181742
664f53de4957849400521dc87fa106df4c48d097	density based collective spatial keyword query	query processing;text analysis;indexes spatial databases approximation algorithms clustering algorithms communities query processing semantics;internet;web services;spatial space density based collective spatial keyword query geographic objects descriptive text web services google map location information textual description top k nearest neighbours;web services internet query processing text analysis	Geographic objects with descriptive text are gaining in prevalence in many web services such as Google map. Spatial keyword query which combines both the location information and textual description stands out in recent years. Existing works mainly focus on finding top-k Nearest Neighbours where each node has to match the whole querying keywords. A collective query has been proposed to retrieve a group of objects nearest to the query object such that the group's keywords cover query's keywords and has the shortest inner-object distances. But the previous method does not consider the density of data objects in the spatial space. In practice, a group of dense data objects around a query point will be more interesting than those sparse data objects. Inner distance of data objects of a group cannot reflect the density of the group. To overcome this shortage, we proposed an approximate algorithm to process the collective spatial keyword query based on density and inner distance. The empirical study shows that our algorithm can effectively retrieve the data objects in dense areas.	approximation algorithm;sparse matrix;web service	Xiang Lin;Xiaoping Sun;Hai Zhuge	2012	2012 Eighth International Conference on Semantics, Knowledge and Grids	10.1109/SKG.2012.27	web service;sargable;query optimization;text mining;query expansion;web query classification;the internet;computer science;data mining;database;rdf query language;web search query;law;world wide web;information retrieval;query language;spatial query	DB	-15.542504096787221	-36.68948697234542	181815
8c9f23f0b5dbfdaeeb66772e77179b833c70106d	measurement of human activity using velocity gps data obtained from mobile phones		Human movement is used as an indicator of human activity in modern society. The velocity of moving humans is calculated based on position information obtained from mobile phones. The level of human activity, as recorded by velocity, varies throughout the day. Therefore, velocity can be used to identify the intervals of highest and lowest activity. More specifically, we obtained mobile-phone GPS data from the people around Shibuya station in Tokyo, which has the highest population density in Japan. From these data, we observe that velocity tends to consistently increase with the changes in social activities. For example, during the earthquake in Kumamoto Prefecture in April 2016, the activity on that day was much lower than usual. In this research, we focus on natural disasters such as earthquakes owing to their significant effects on human activities in developed countries like Japan. In the event of a natural disaster in another developed country, considering the change in human behavior at the time of the disaster (e.g., the 2016 Kumamoto Great Earthquake) from the viewpoint of velocity allows us to improve our planning for mitigation measures. Thus, we analyze the changes in human activity through velocity calculations in Shibuya, Tokyo, and compare times of disasters with normal times.	global positioning system;mobile phone;velocity (software development)	Yasuko Kawahata;Takayuki Mizuno;Akira Ishii	2017	CoRR		mathematics;global positioning system;geodesy;natural disaster	HCI	-18.94521034642665	-33.55002992788754	182020
53b4a051e8968ef9dfae2a3ab0aac749f8f400b9	approximating sliding windows by cyclic tree-like histograms for efficient range queries	computational point;cyclic tree-like histogram;bit-saving approach;range query;approximate answer;approximate arbitrary range-sum query;efficient range query;deep analysis;window size;careful experimental analysis;data stream;bit-saving strategy;experimental analysis;sliding window;histograms;range queries	The issue of providing fast approximate answers to range queries on sliding windows with a small consumption of storage space is one of the main challenges in the context of data streams. On the one hand, the importance of this class of queries is widely accepted. They are indeed useful to compute aggregate information over the data stream, allowing us to extract from it more abstract knowledge than point queries. On the other hand, the usage of techniques like synopses based on histograms, sketches, sampling, and so on, makes effective those approaches which require multiple scans on data, which otherwise would be prohibitive from the computational point of view. Among the above techniques, histogram-based approaches are considered one of the most advantageous solutions, at least in case of range queries. It is a matter of fact that histograms show a very good capability of summarizing data preserving quick and accurate answers to range queries. In this paper, we propose a novel histogram-based technique to reduce sliding windows supporting approximate arbitrary range-sum queries. Our histogram, relying on a tree-based structure, is suitable to directly support hierarchical queries and, thus, drill-down and roll-up operations. In addition, the structure well supports sliding window shifting and quick query answering, since it operates in logarithmic time in the sliding window size. A bit-saving approach to encoding tree nodes allows us to compress the sliding window with a little price in terms of accuracy. The contribution of this work is thus not only the proposal of a new specific technique to tackle an important problem but also a deep analysis of the advantages given by the hierarchical approach combined with the bit-saving strategy. A careful experimental analysis validates the method showing its superiority w.r.t. the state of the art.	aggregate data;approximation algorithm;cluster analysis;computation;data drilling;experiment;hierarchical and recursive queries in sql;keyboard technology;microsoft windows;performance;range query (data structures);range query (database);sampling (signal processing);synergy;time complexity;video synopsis;c-treeace	Francesco Buccafurri;Gianluca Lax	2010	Data Knowl. Eng.	10.1016/j.datak.2010.05.002	sliding window protocol;matter of fact;database;data mining;theoretical computer science;data stream;fold (higher-order function);data stream mining;range query (data structures);sampling (statistics);histogram;computer science	DB	-7.994788056205866	-34.788396720922364	182128
3eccb2718cdda8fa7259c65b3f098aa31f86c9a8	application oriented data cleaning for rfid middleware	probabilistic method;smoothing methods bayes methods middleware radiofrequency identification;bayes methods;bayesian methods;bayesian method application oriented data cleaning rfid middleware radiofrequency identification rfid reader rfd tag false negative minor detection region duplication spatial overlap fn s concept fn ns concept adapted smoothing method;interference;smoothing methods;monitoring;rfid;data cleaning;middleware;radiofrequency identification;cleaning;probabilistic method rfid middleware data cleaning;radiofrequency identification smoothing methods cleaning monitoring middleware bayesian methods interference	Radio Frequency Identification (RFID) technology is broadly used in many applications just like Supply Chain and Retail trade. However, owing to the working mechanism of RFID reader and RFID tag, raw RFID readings are not always reliable. False negative induced by low identifying rate in the reader's minor detect region and duplication owing to detection region's spatial overlap are the two main problems that cause unexpected consequence in upper applications of RFID Middleware. In this paper we discriminate the application scenarios by defining the concepts FN-S and “FN-NS” and propose an improved adapted smoothing method and an Bayesian method towards the two different scenarios. Both theoretically and by convincible experiment, we show the superiority of our algorithms.	algorithm;middleware;plasma cleaning;radio frequency;radio-frequency identification;smoothing	Chunkai Zhang;Yuan Li	2011	2011 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/ICSMC.2011.6083890	radio-frequency identification;real-time computing;bayesian probability;computer science;probabilistic method;middleware;data mining;database;interference	Robotics	-11.621159488095028	-31.276546530739314	182291
4ad775994eccf3c7576b071b34f359a7cbe30286	performance enhanced multiset similarity joins	plagiarism;electronic mail;data mining;hamming distance;big data;algorithm design and analysis;partitioning algorithms	The amount of data produced on a daily basis is growing at an exponential rate. One method of filtering through this data is the use of similarity joins, or methods that are used to identify similar data. Such algorithms are used for a variety of applications ranging from plagiarism detection to marketing. These methods are typically time-consuming and computationally expensive. This paper proposes an efficient three-stage MapReduce algorithm named Adept Similarity Join (ASJ) for multisets. The main novelty in ASJ is to integrate suffix filtering with positional filtering when performing similarity joins, in addition to incorporating prefix and size filtering. The proposed algorithm is compared to the state-of-the-art Strategic and Suave processing for performing similarity joins using MapReduce (SSS) algorithm, which it outperforms by lowering the number of redundant comparisons. Experimental results on a Twitter dataset demonstrate that the proposed ASJ algorithm provides about a 25% to 40% decrease in execution time and 100x reduction in memory usage compared to SSS.	algorithm;analysis of algorithms;mapreduce;run time (program lifecycle phase);time complexity	Jahnavi Yalamanchili;Robert C. Green;Kevin S. Xu;Vijay K. Devabhaktuni	2016	2016 IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom)	10.1109/BDCloud-SocialCom-SustainCom.2016.15	algorithm design;hamming distance;big data;computer science;theoretical computer science;operating system;data mining;database	DB	-5.792353853627654	-37.60554057755514	182350
ab1f37511132f41412d3cb5e30a548c3cdced687	optimized sequential pattern mining from point of sales data	databases;marketing and sales fluctuations yagi uda antennas data mining virtual colonoscopy information management itemsets databases;itemsets;fluctuations;efficient algorithm;data mining;optimization problem;information management;virtual colonoscopy;yagi uda antennas;sequential pattern mining;point of sale;sequential pattern;marketing and sales	We consider an optimization problem of sequential pattern mining. We present space efficient algorithms for computing optimized sequential pattern that maximize transitive confidence from a cause event to an effect event. Those can compute optimized sequential patterns for all cause-effect pairs of sales fluctuation events in large POS data.	algorithm;data mining;mathematical optimization;optimization problem;quantum fluctuation;sequential pattern mining	Kazumitsu Yagi;Mai Soramoto;Miho Mokuda;Yasuhiko Morimoto	2005	21st International Conference on Data Engineering Workshops (ICDEW'05)	10.1109/ICDE.2005.257	sequential pattern mining;optimization problem;computer science;data science;data mining;information management;point of sale	DB	-5.135241810303178	-35.381661418501196	182522
f95d24eb26026cf43dc0bc84cd512478d50fd0e3	a bidirectional process algorithm for mining probabilistic frequent itemsets	eclat algorithm;itemsets;support count;data mining;itemsets algorithm design and analysis probabilistic logic data mining software algorithms clustering algorithms;eclat algorithm frequent itemset support count;transaction cache bidirectional process algorithm probabilistic frequent itemset mining association rule mining frequent itemsets mining algorithms;frequent itemset;clustering algorithms;software algorithms;probabilistic logic;algorithm design and analysis	Nowadays, frequent item set mining is the major task in association rule mining. With the observation that the support plays an important role in mining frequent item sets, in this paper, we review the previous efficient algorithms and study the effect of different order of support in the performance of frequent item sets mining algorithms and propose our improved schedule. In our new algorithm, items are sorted in descending order according to the frequencies in transaction cache while item sets use ascending order of support during support count. Compared with other algorithms, the results of experiments show that the new algorithm gains better performance on on well-known benchmark data sets.	algorithm;association rule learning;benchmark (computing);computer data storage;data mining;database;entity–relationship model;experiment;han unification;j. lyons and co.;os-tan;sorting;weitao yang	Xiaomei Yu;Hong Wang;Xiangwei Zheng	2014	2014 Ninth International Conference on Broadband and Wireless Computing, Communication and Applications	10.1109/BWCCA.2014.122	algorithm design;gsp algorithm;probabilistic analysis of algorithms;computer science;pattern recognition;data mining;database;fsa-red algorithm;probabilistic logic;cluster analysis;apriori algorithm	DB	-4.98745129038917	-37.103206290255415	182553
013759c2789f6e222fa26d0eb75280fba3fa9334	anomaly detection in driving behaviour by road profiling	statistical hypothesis test;road safety;statistical testing;statistical analysis;vehicles fleet;roads;road cross-sectional profiles;anomalous driving behavior;anomaly detection;road profiling;anomalous driving behavior detection;driver information systems;data mining;road traffic;statistical method	This paper presents a statistical method for detecting anomalous driving behavior by analyzing cross-sectional profiles of the road. A profile captures the way vehicles normally traverse the road; a statistical hypothesis test determines whether the observed behavior is anomalous. Experimental results on genuine data collected by a fleet of vehicles demonstrates the potential of this new method.	anomaly detection;cross-sectional data;sensor;traverse	Gabriel Agamennoni;James R. Ward;Stewart Worrall;Eduardo Mario Nebot	2013	2013 IEEE Intelligent Vehicles Symposium Workshops (IV Workshops)	10.1109/IVS.2013.6629442	simulation;engineering;transport engineering;forensic engineering	Robotics	-18.191933408274767	-27.349880262926302	182604
db8ed838f91501fd1518d41054ce9493acbf27ed	a new attempt for pedestrian level of service in subway transfer corridor based on the physiological characteristics		Under the conditions of large population in China, the original level of service couldn't meet the needs of subway station managers. From the interdisciplinary perspective of physiology, medical science, and engineering, this study conducted a series field experiment to investigate the influence of passenger flow density on the pedestrian physiology. By quantitatively analyzing density and fluctuating rate of heart rates, a significant finding is that pedestrians' physiological characteristics are influenced by the traffic density in corridor, and the FRHR is high associated with density, presenting a linear correlation. In the end of paper, the LOS is divided into six levels, caring on the refined classification for higher density, in line with China's national conditions. Research results could provide a theoretical foundation and application reference for subway transit designer and manager.		Wei Luo;Lishan Sun;Yiqiao Li;Yajun Zhang;Jian Rong	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569477		Visualization	-15.056613750248493	-26.673995564342402	182728
6a8d5310baa36ccc06c796661655a0c040e4e75b	discovering co-located queries in geographic search logs	log mining;spatial data mining;co location pattern	"""A geographic search request contains a query consisting of one or more keywords, and a search-location that the user searches for. In this paper, we study the problem of discovering co-located queries, which are geographic search requests for nearby search-locations. One example co-located query pattern is {""""shopping mall"""", """"parking""""}. This pattern indicates that people often search """"shopping mall"""" and """"parking"""" over locations close to one another. Co-located queries have many applications, such as query suggestion, location recommendation, and local advertisement. We formally define co-located query patterns and propose two approaches to mining the patterns. Our basic approach is based on an existing spatial mining algorithm. To find more specific co-located queries that only appear in specific regions, we propose a lattice based approach. It divides the geographic space into regions and mines patterns in each region. We also define a locality measure to categorize patterns into local and global. Experimental results show that the lattice based approach outperforms the basic approach in the number of patterns, the quality of patterns, and the proportion of local patterns."""	algorithm;categorization;data mining;lattice model (finance);lattice-based cryptography;locality of reference;mathematical optimization;usability testing	Xiangye Xiao;Longhao Wang;Xing Xie;Qiong Luo	2008		10.1145/1367798.1367812	geography;data mining;database;world wide web	DB	-15.365636250909999	-36.6564581916086	182768
7bf4afe08eeed7b1181b36873aa0eef87f1a40fd	reasoning of topological relations between imprecise regions	formal model;spatial data;uncertainty propagation;statistical model;topological relation	Abstract There are inevitably some errors or uncertainties in spatial data. Such kind of uncertainty will further influence the accuracy of topological relations, which are obtained by reasoning from observation data. In this paper, a determination approach based on relative possibility for topological relations under uncertainty is proposed. First, the effect of positional uncertainty on topological relations is investigated and, statistical modeling of spatial data uncertainty is provided. Then a set of uncertain topological relations for two imprecise regions were built upon a new formal model, proposed by Chen and Deng (2003). Further, some basic functions, which are used for a valid link from positional uncertainty propagating to relation uncertainty, are derived. Finally, a simple example is provided for the illustration of the approach presented in this paper.		Min Deng;Xiaoyong Chen;Michiro Kusanagi;Huynh Ngoc Phien	2004	Annals of GIS	10.1080/10824000409480657	statistical model;discrete mathematics;uncertainty analysis;propagation of uncertainty;data mining;mathematics;spatial analysis;sensitivity analysis;statistics	Theory	-5.2609125300226225	-25.227884588311227	183064
e7bd5d3b394b9a28462d9f10bfef730727554e1e	retrospective analysis of long-term landscape evolution based on archive satellite imagery and historical maps		This study deals with the long-term retrospective analysis of the evolution of landscape features by exploiting the potential of long-term archive optical satellite imagery time series. Resulting temporal trajectories and disturbance/stability features are then used as an input to assess the current state of local ecosystems.	archive;ecosystem;map;time series	Daniel Kristof;Marta Belenyesi;Angela Olasz	2017	2017 9th International Workshop on the Analysis of Multitemporal Remote Sensing Images (MultiTemp)	10.1109/Multi-Temp.2017.8035257	time series;satellite imagery;satellite;remote sensing;cartography;geography	Vision	-12.914377385841728	-27.24633033769839	183251
eff79b6479f68fd179fd473126bed5131faf95ad	on the behavior of indexes for imprecise numerical data and necessity measured queries under skewed data sets	necessity measured queries;fuzzy databases indexing;skewed data and queries	This paper studies the influence of data distribution and clustering on the performance of currently available indexing methods, namely GT and HBPT, to solve necessity measured flexible queries on numerical imprecise data. The study of the above data scenarios lets to obtain valuable information about the expected performance of these indexes on real-world data and query sets, which are usually affected by different skew factors. Results reveal some sensibility of GT and no influence for the considered data scenarios on HBPT.	level of measurement	Carlos D. Barranco;Jesús R. Campaña;Juan Miguel Medina	2011		10.1007/978-3-642-24764-4_42	computer science;data mining;database;information retrieval	DB	-7.557357837668536	-34.59633487722983	183313
a48748a42e30f241060b47ca1fd179cc65e205ee	spatial differentiation of urban carbon emissions — an exploratory spatial data analysis in beijing	visual databases data analysis environmental economics geography;beijijg city;会议论文;data analysis;carbon dioxide cities and towns energy consumption sociology correlation economics;environmental economics;beijijg city esda carbon emissions spatial autocorrelation spatial heterogeneity;carbon emissions;esda;spatial heterogeneity;environmental impact exploratory spatial data analysis beijing fossil energy related carbon emissions spatial pattern carbon emission estimation esda urban carbon emissions spatial differentiation spatial autocorrelation spatial agglomeration spatial economic restructuring core periphery structure carbon emission centers resource utilization;visual databases;geography;spatial autocorrelations	While the fossil energy-related carbon emissions have been documented in cities, much less attention has been devoted to exploring the spatial pattern and structure of carbon emissions in urban area. On the basis of carbon emissions estimation of sub-districts in Beijng, this article performs an exploratory spatial data analysis (ESDA) to investigate the spatial differentiation of urban carbon emissions over 2000~2010. The results confirm the assumption about the spatial autocorrelation of carbon emissions based on spatial agglomeration of population and spatial restructuring of economy. The carbon emissions in sub-districts reflect a core-periphery structure in Beijing and reveal a significant presence of spatial autocorrelation with distinct spatial clusters of high and low values of carbon emissions. However, the carbon emission centers are dissimilar with population centers due to differentiation from geographical division of labor. Overall, our results shed new light on the analysis of urban spatial structure of resource utilization and environmental impact.	autocorrelation;core-periphery structure;fossil;population;spatial analysis;spatiotemporal pattern	Lijun Zhang;Yaochen Qin;Jinping Zhang;Chaojun Lu	2013	2013 21st International Conference on Geoinformatics	10.1109/Geoinformatics.2013.6626146	environmental engineering;geography;forestry	Visualization	-12.109712006639498	-24.562269732627374	183418
1e215e52577f69dbe03fe26743fc8bc3e258fb3f	taxi demand forecast using real-time population generated from cellular networks		For efficient operation of taxis, it is important to provide taxi drivers with detailed information about passenger demand. In this paper, we propose a future taxi demand prediction algorithm by using real-time population data generated from cellular networks. We evaluated the effects of real-time population data on the accuracy of taxi demand prediction by using stacked denoising autoencoders. The results of an offline experiment conducted herein indicate that when real-time population data were used, the root mean squared prediction error of the proposed algorithm was 1.370 as opposed to 1.513 when population data were not used. In addition, we conducted a field test. We implement a real-time prediction system based on realtime population data, the first such online real-world test conducted worldwide. In the trial, 26 participant drivers tried our demand forecast system. The results showed that the sales of participant drivers improved by 1,409 JPY per person per day, which represents a 3.9% increase in sales on average compared to the drivers who did not use the system.	algorithm;autoencoder;mean squared prediction error;noise reduction;online and offline;real-time clock;real-time operating system;real-time transcription	Shin Ishiguro;Satoshi Kawasaki;Yusuke Fukazawa	2018		10.1145/3267305.3274157	human–computer interaction;mean squared prediction error;computer science;intelligent transportation system;machine learning;population;taxis;demand forecasting;artificial intelligence;cellular network	HCI	-16.6780260822429	-31.81141939238912	183829
46c9043e1e423bc8e4ba86276104c725a0943355	approximately filtering redundant data for uncertain rfid data streams		Nowadays, Radio Frequency Identification (RFID) technology has been widely employed in the fields of object positioning, tracking and monitoring. However, there are a large number of redundant data generated in RFID systems due to duplicate detection and cross detection. Since RFID data is usually streaming, uncertain and mobile data, traditional static data and data stream filtering strategies cannot be applied to filter the RFID data effectively. In the paper, we first present a three-phase filtering framework under a block-based sliding window model. Aiming to filter the temporal redundant events, we propose an approximate Probability Synthesis Bloom Filter (PSBF) and discuss its filter principle, update rules and error rate in details. Comparing with the existing RFID filters, PSBF can not only filter the redundant probabilistic events, but also can calculate object existential probabilities with temporal decaying, and handle with the situations of location movement and staying at the overlapping areas among multiple readers correctly. The experiments on the simulated dataset show that the proposed filter outperforms the state-of-the-art filtering method.	approximation algorithm;bloom filter;experiment;radio frequency;radio-frequency identification;streaming media;two-phase locking	Guoqiong Liao;Jun Zhou;Ni Hui;Xiaomei Huang;Zhiwei Huang;Changxuan Wan;Xiping Liu	2017	2017 18th IEEE International Conference on Mobile Data Management (MDM)	10.1109/MDM.2017.18	computer science;filter (signal processing);data stream;radio-frequency identification;sliding window protocol;word error rate;data stream mining;probabilistic logic;real-time computing;bloom filter	DB	-7.955299736519623	-36.15286130202618	183838
657bc149a80d0701c45d272f88466046c10cab29	approximate reasoning approach to pattern recognition	vowel recognition;approximate reasoning;pattern recognition;compositional rule of inference;synthetic data	Approximate reasoning approach to pattern recognition consists of linguistic rules tied together by means of two concepts: fuzzy implications and a compositional rule of inference. In this paper, first we study the applicability of different interpretations of fuzzy implication to pattern recognition problem and subsequently compare their performances over a set of synthetic data. Finally, we use the most applicable (according to our study) interpretations of implication for vowel recognition of three different Indian languages and we obtain very promising results.	pattern recognition	Kumar S. Ray;Jayati Ghoshal	1996	Fuzzy Sets and Systems	10.1016/0165-0114(95)00095-X	natural language processing;feature;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;synthetic data	Vision	-4.953930363967726	-24.033509996938992	183852
56a4ec156b26225b5922182bacc4c5b26fd5a555	simultaneous mining of frequent closed itemsets and their generators: foundation and algorithm	closed itemset;data mining;generator;frequent itemset;association rule	Closed itemsets and their generators play an important role in frequent itemset and association rule mining. They allow a lossless representation of all frequent itemsets and association rules and facilitate mining. Some recent approaches discover frequent closed itemsets and generators separately. The Close algorithm mines them simultaneously but it needs to scan the database many times. Based on the properties and relationships of closed itemsets and generators, this study proposes GENCLOSE, an efficient algorithm for mining frequent closed itemsets and generators simultaneously. The level-wise search over an ItemsetObject–setGenerator–Tree enumerates the generators by using a necessary and sufficient condition to produce (iþ1)-item generators from i-item generators. This condition, based on transaction (object) sets that can be efficiently implemented using diffsets, is very convenient and reliably proved. In the search, pre-closed itemsets are gradually extended using three proposed extension operators. It is shown that these itemsets produce the expected closed itemsets. Extensive experiments on many benchmark databases confirm the efficiency of the proposed approach. & 2014 Elsevier Ltd. All rights reserved.	algorithm;association rule learning;benchmark (computing);database;experiment;lossless compression	Anh Tran;Tin C. Truong;Hoai Bac Le	2014	Eng. Appl. of AI	10.1016/j.engappai.2014.07.004	association rule learning;computer science;pattern recognition;data mining;database;electric generator	DB	-6.298691996068533	-36.907096230651184	184082
e0292b07a7f6a2d76f5797bc7901b487d4459134	revisiting john snow's map: network-based spatial demarcation of cholera area	clumping;department of geography;john snow;spatial distribution;analytical method;spatial demarcation;network;voronoi diagram	Dr. John Snow’s cholera map is known as one of the pioneering examples of an epidemiology map, illustrating the spatial distribution of the victims from the cholera outbreak. This article revisits his map and expands on his attempt at visualizing the distribution of the victims by focusing on spatial demarcation using the sphere of influence along the street network by applying two analytical methods that are designed for analysis of network space. First, the article generates a network-based Voronoi diagram of the water pumps in the map that encompasses Snow’s original version of the equidistance line that was drawn around a single pump. The article then presents a new, revised equidistance line that better reflects the circumstances around the time of the outbreak. This is followed by the construction of another set of boundaries derived by the application of a network-based clumping method. Comparing the demarcation lines produced with the two methods shows a sphere of influence which was unclear when using the network Voronoi diagram alone. Results from the analysis using the clumping method also confirm some of Snow’s observations on the spatial distribution of the victims.	bus bunching;demarcation point;map;voronoi diagram	Shino Shiode	2012	International Journal of Geographical Information Science	10.1080/13658816.2011.577433	voronoi diagram;geography;mathematics;geometry;cartography	Robotics	-13.067107319940565	-24.285327903113547	184298
b3c5c2e2132965b72e641002db84cc27dca29464	an effective spatio-temporal approach for predicting future semantic locations		Human mobility prediction in ubiquitous computing is the ability of a system to forecast the anticipated movement of an individual or a group of persons. This interdisciplinary problem has gained traction in fields of academic and industrial research mainly because it is fundamental to achieving system efficiency and marketing efficacy in many applications. This study seeks to develop a novel heuristic technique that predicts the actual geo-spatial locations associated with the most probable semantic tags of locations (e.g. restaurant) that individuals are likely to visit. The intuition of this work lies in the fact that, for any given probable future semantic tag there exists multiple geo-spatial locations associated with it, hence the need to disambiguate the actual destination location. We develop an algorithm ( STS _ predict ), that exploits the spatio-temporal relationships between the current location of a target individual and candidate geo-spatial locations associated with future semantic tags to predict the actual destination location. We evaluate our approach on a real world GPS trajectory dataset.		Hamidu Abdel-Fatao;Jiuyong Li;Jixue Liu;Ashfaqur Rahman	2016		10.1007/978-3-319-46922-5_22	data mining;computer science;global positioning system;semantic html;ubiquitous computing;heuristic;exploit;intuition;markov chain	AI	-18.33533061959001	-35.056062927527	184521
4ddead893d66b28049f57cf38b36d8a4ca249ffc	wavelet synopses with error guarantees	nearest neighbor queries;spatio temporal databases;random sampling;threshold scheme;approximate query processing;wavelet decomposition;data reduction techniques;synthetic data;optimal algorithm	"""Recent work has demonstrated the effectiveness of the wavelet decomposition in reducing large amounts of data to compact sets of wavelet coefficients (termed """"wavelet synopses"""") that can be used to provide fast and reasonably accurate approximate answers to queries. A major criticism of such techniques is that unlike, for example, random sampling, conventional wavelet synopses do not provide informative error guarantees on the accuracy of individual approximate answers. In fact, as this paper demonstrates, errors can vary widely (without bound) and unpredictably, even for identical queries on nearly-identical values in distinct parts of the data. This lack of error guarantees severely limits the practicality of traditional wavelets as an approximate query-processing tool, because users have no idea of the quality of any particular approximate answer. In this paper, we introduce Probabilistic Wavelet Synopses, the first wavelet-based data reduction technique with guarantees on the accuracy of individual approximate answers. Whereas earlier approaches rely on deterministic thresholding for selecting a set of """"good"""" wavelet coefficients, our technique is based on a novel, probabilistic thresholding scheme that assigns each coefficient a probability of being retained based on its importance to the reconstruction of individual data values, and then flips coins to select the synopsis. We show how our scheme avoids the above pitfalls of deterministic thresholding, providing highly-accurate answers for individual data values in a data vector. We propose several novel optimization algorithms for tuning our probabilistic thresholding scheme to minimize desired error metrics. Experimental results on real-world and synthetic data sets evaluate these algorithms, and demonstrate the effectiveness of our probabilistic wavelet synopses in providing fast, highly-accurate answers with error guarantees."""	approximation algorithm;approximation error;coefficient;data point;database;deterministic algorithm;information;mathematical optimization;probabilistic automaton;residual (numerical analysis);sampling (signal processing);synthetic data;thresholding (image processing);video synopsis;wavelet	Minos N. Garofalakis;Phillip B. Gibbons	2002		10.1145/564691.564746	sampling;theoretical computer science;pattern recognition;data mining;cascade algorithm;database;stationary wavelet transform;synthetic data	DB	-7.352061177386743	-33.103398620764935	184765
21bf9f3227a3c3223fdfd281f028858169ff017c	simulating the transmission of foot-and-mouth disease among mobile herds in the far north region, cameroon		Animal and human movements can impact the transmission of infectious diseases. Modeling such impacts presents a significant challenge to disease transmission models because these models o en assume a fully mixing population where individuals have an equal chance to contact each other. Whereas movements result in populations that can be best represented as a dynamic networks whose structure changes over time as individual movements result in changing distances between individuals within a population. We model the impact of the movements of mobile pastoralists on foot-and-mouth disease (FMD) transmission in a transhumance system in the Far North Region of Cameroon. The pastoralists in our study area move their livestock between rainy and dry season pastures. We first analyzed transhumance data to derive mobility rules that can be used to simulate the movements of the agents in our model. We developed an agent-based model coupled with a susceptible–infected–recovered (SIR) model. Each agent represents a camp of mobile pastoralists with multiple herds and households. The simulation results demonstrated that the herd mobility significantly influenced the dynamics of FMD. When the grazing area is not explicitly considered (by setting the bu er size to 100 km), all the model simulations suggested the same curves as the results using a fully mixing population. Simulations that used grazing areas observed in the field (≤ 5 km radius) resulted in multiple epidemic peaks in a year, which is similar to the empirical evidence that we obtained by surveying herders from our study area over the last four years.		Hyeyoung Kim;Ningchuan Xiao;Mark Moritz;Rebecca Garabed;Laura W. Pomeroy	2016	J. Artificial Societies and Social Simulation		epidemic model;computer science;mobile computing	ML	-14.981099071968979	-25.939108479483362	185120
c8bd4caf0fc9c8a4fbffc7e05416901d4fd7a41b	join size estimation subject to filter conditions		In this paper, we present a new algorithm for estimating the size of equality join of multiple database tables. The proposed algorithm, Correlated Sampling, constructs a small space synopsis for each table, which can then be used to provide a quick estimate of the join size of this table with other tables subject to dynamically specified predicate filter conditions, possibly specified over multiple columns (attributes) of each table. This algorithm makes a single pass over the data and is thus suitable for streaming scenarios. We compare this algorithm analytically to two other previously known sampling approaches (independent Bernoulli Sampling and End-Biased Sampling) and to a novel sketch-based approach. We also compare these four algorithms experimentally and show that results fully correspond to our analytical predictions based on derived expressions for the estimator variances, with Correlated Sampling giving the best estimates in a large range of situations.	algorithm;bernoulli polynomials;column (database);experiment;sampling (signal processing);streaming media;table (database);video synopsis	David Vengerov;Andre Cavalheiro Menck;Mohamed Zaït;Sunil Chakkappen	2015	PVLDB	10.14778/2824032.2824051	theoretical computer science;data mining;database;mathematics;statistics	DB	-7.674008271113428	-33.45904585215599	185157
8789c5d22e6c9859191b3fe68c6cfeb472589c71	analyzing urban extensions and its effects over the commercial activity of an urban network		In this paper, we present a way for analyzing and visualizing extensions or enhancements of an existing urban network, as well as the effects that cause these extensions on commercial activity taking place in the network itself. This analysis is based on an algorithm for classifying the nodes of the network, depending on the type and number of facilities allocated to each node. Using this classification, it is possible to visualize the network according to a gradient color scale, allowing us to identify the most important nodes in the network and the part of the network more influenced by the introduction of new facilities. With this classification algorithm we can simulate and evaluate the effect that produces any reform plan over an existing urban street network. To understand the process, a detailed example of an urban exten- sion is proposed and studied. Different land uses are assigned and some endowments and facilities are allocated in the new area. A comparison between the existing urban network and the new urban area created from the extension is performed, with the aim to determine the influence of the new commercial activity introduced respect to the activity taking place in the existing one.		Taras Agryzkov;José Luis Oliver;Leandro Tortosa;José-Francisco Vicent	2014		10.1007/978-3-319-09147-1_11	simulation;data mining;network simulation	HCI	-12.578311634405535	-24.113335710244964	185191
b40b1428e17fae977f4cebab04030d9d8111c1d4	zone-based living activity recognition scheme using markov logic networks		In this paper, we propose a zone-based living activity recognition method. The proposed method introduces a new concept called activity zone which represents the location and the area of an activity that can be done by a user. By using this activity zone concept, the proposed scheme uses Markov Logic Network (MLN) which integrates a common sense knowledge (i.e. area of each activity) with a probabilistic model. The proposed scheme can utilize only a positioning sensor attached to a resident with/without power meters attached to appliances of a smart environment. We target 10 different living activities which cover most of our daily lives at a smart environment and construct activity recognition models. Through experiments using sensor data collected by four participants in our smart home, the proposed scheme achieved average F-measure of recognizing 10 target activities starting from 84.14 % to 94.53 % by using only positioning sensor data.	activity recognition;commonsense knowledge (artificial intelligence);experiment;home automation;markov chain;markov logic network;overhead (computing);smart environment;software deployment;statistical model	Asaad Ahmed;Hirohiko Suwa;Keiichi Yasumoto	2015		10.1007/978-3-319-47063-4_10	machine learning;pattern recognition	HCI	-14.117182346930237	-34.175199252193394	185901
7309b22ad5a3c67f9e437a3698019079147c2efa	mining algorithm of maximal frequent itemsets based on position lattice	boolean matrix mining algorithm maximal frequent itemsets position lattice data mining gmpv depth first search algorithm transaction database;tree searching data mining matrix algebra;matrix algebra;data mining;frequent itemset;data mining application;frequent itemset mining;itemsets algorithm design and analysis data mining lattices finite element methods;depth first search;tree searching	Maximal frequent itemsets mining is a fundamental and important problem in many data mining applications. In this paper, we present GMPV, a depth first search algorithm, which accurately displays itemset based on position vector, for mining maximal frequent itemsets. In GMPV algorithm, the transaction database is mapped to a Boolean matrix. The methods superset checking and pruning based on support are also used to increase the algorithm efficiency. Our experiment results show that GMPV algorithm is very validity.	algorithmic efficiency;association rule learning;data mining;depth-first search;maximal set;search algorithm	Yuan Li;Jun Li;Ning An;Chong Han	2010	2010 IEEE International Conference on Granular Computing	10.1109/GrC.2010.22	gsp algorithm;breadth-first search;computer science;pattern recognition;data mining;database;mathematics;fsa-red algorithm	DB	-4.787686586482511	-37.05446785977671	186006
92df39b63233cd9c79826715fa2a25c80dc3dc37	flowhdbscan: a hierarchical and density-based spatial flow clustering method		Understanding the patterns and dynamics of spatial origin-destination flow data has been a long-standing goal of spatial scientists. This study aims at developing a new flow clustering method called flowHDBSCAN, which has the potential to be applied to various urban dynamics issues such as spatial movement analysis and intelligent transportation systems. Flows entail origin and destinations pairs, at the exclusion of the actual path in-between. The method combines density-based clustering and hierarchical clustering approaches and extends them to the context of spatial flows. Not only can it extract flow clusters from various situations including varying flow densities, lengths, directions, and hierarchies, but it also provides an effective way to reveal the potentially hierarchical data structure of the clusters. Common issues such as the modifiable areal unit problem (MAUP) of flow endpoints, false positive errors on short flows, and loss of spatial information are well handled. Moreover, the sole-parameter design guarantees its ease of use and practicality. Experiments are conducted with both a synthetic dataset and an eBay online trade flow dataset in the contiguous U.S.	aggregate data;cluster analysis;data structure;experiment;hierarchical clustering;hierarchical database model;hoc (programming language);modifiable areal unit problem;synthetic intelligence;usability	Ran Tao;Jean-Claude Thill;Craig Depken;Mona Kashiha	2017		10.1145/3152178.3152189	machine learning;modifiable areal unit problem;contiguity (probability theory);cluster analysis;spatial analysis;hierarchical database model;hierarchical clustering;intelligent transportation system;artificial intelligence;computer science	Visualization	-14.3762537502046	-31.54488791238272	186298
c11f314ba6a10d731ff27660351b7548182a6a04	near-future traffic evaluation based navigation for automated driving vehicles considering traffic uncertainties		Because it is difficult to find empty space in a developed city to accommodate more transportation infrastructures, the development of an effective navigation system is a low cost option for mitigating traffic jam. Regarding a future world where automated driving technologies have become mature and most vehicles follow the pre-scheduled route suggested by a navigation system, it is likely to predict the traffic jam accurately if the navigation system can know the pre-scheduled route of each vehicle. Recently, a navigation algorithm is presented for automated driving vehicles with the assumption that all the navigating query requests are processed by a single system. However, the aforementioned algorithm does not consider any kind of uncertainty originating from accidents and destination change. To get close to the real world, we propose a navigation algorithm with near-future evaluation capability that also allows some kinds of uncertainties. We compare our algorithm with a dynamic-update based conventional navigation algorithm without near-future evaluation capability. We download some metropolitan maps from OpenStreetMap and utilize the data of traffic flow from official statistics to randomly generate many sets queries. Experimental results show that the total cruising time is improved for each case.	algorithm;autonomous car;download;global positioning system;jam;openstreetmap;randomness	Kuen-Wey Lin;Masanori Hashimoto;Yih-Lang Li	2018	2018 19th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2018.8357324	real-time computing;advanced driver assistance systems;traffic flow;computer science;navigation system;official statistics;download	Robotics	-17.791185886492823	-28.37722202624687	186406
5b3eb1b9ee56f25054553943d19dd13c96eec01a	modeling traffic control agency decision behavior for multimodal manual signal control under event occurrences	manuals;control systems;intersections;traffic signal control human behavior modeling multimodal event traffic;simulation;traffic signal cycle;multimodal transportation;real world intersection traffic control agency decision behavior modeling multimodal manual signal control event occurrences pressure based human behavior model decision making behavior pedestrian queue dynamics vehicle dynamics red time duration tca behavior microscopic traffic simulation tool manual control simulator training data test data offline segment based phase prediction duration prediction online vissim based simulation;traffic control decision making pedestrians;manuals control systems vehicles data models timing predictive models;predictive models;traffic signal control systems;vehicles;behavior;article;data models;timing	Traffic control agencies (TCAs), including police officers, firefighters, or other traffic law enforcement officers, can override automatic traffic signal control and manually control the traffic at an intersection. TCA-based traffic signal control is crucial to mitigate nonrecurrent traffic congestion caused by planned and unplanned events. Understanding and predicting TCA behaviors is significant to optimize event traffic management and operations. In this paper, we propose a pressure-based human behavior model to mimic TCA's decision-making behavior. The model calculates TCA's pressure based on two attributes: vehicle and pedestrian queue dynamics and the red time duration for each phase. When TCA's pressure on each phase meet certain criteria and the minimal green is satisfied, TCA will terminate the current phase and switch to another phase. In order to study TCA behavior systematically, we first build a manual signal control simulator based on a microscopic traffic simulation tool. Supported by the manual control simulator, a series of human subject experiments have been conducted with real-world TCAs. Experiment data are divided into training data and test data. The proposed behavior model is then calibrated by training data, and the model is validated by both offline segment-based phase and duration prediction and online VISSIM-based simulation. Further, we test the model with videotaped TCA behavior data at a real-world intersection. Both validation results support the effectiveness of proposed behavior model.	advanced telecommunications computing architecture;behavior model;experiment;multimodal interaction;network congestion;online and offline;simulation;terminate (software);test data;vissim	Nan Ding;Qing He;Changxu Wu;Julie Fetzer	2015	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2015.2409174	computer vision;real-time computing;simulation;computer science;engineering;control system;artificial intelligence;computer security;behavior		-15.57658706959181	-27.74959509589977	186442
8ef7da96a4b4b0b529d8a5ea72f2f9b79cb6f559	efficient evaluation of shortest average distance query on heterogeneous neighboring objects in road networks		Recently, the research community has introduced various methods for processing the location-based queries on a single type of objects in road networks. However, in real-life applications user may be interested in obtaining information about different types of objects, in terms of their neighboring relationship. The sets of different types of objects closer to each other are termed the heterogeneous neighboring object sets (HNOSs for short). In this paper, we present a novel type of location-based queries, the shortest average distance query (SADQ for short), on the HNOSs in road networks. Given a query object q and a distance d, the SADQ retrieves a HNOS, such that the road distances between any two objects in this set are less than or equal to d and its average road distance to q is the shortest among all HNOSs. As the SADQ provides object information by preserving both the spatial closeness of objects to the query object and the neighboring relationship between objects, it is useful in many fields and application domains. A grid index is first designed to manage information of data objects and road networks, and then the SADQ algorithm is developed, which is combined with the grid index to efficiently process the SADQ. Extensive experiments using real road network datasets demonstrate the efficiency of the proposed SADQ algorithm.	algorithm;centrality;experiment;real life	Yuan-Ko Huang;Chun-Hsing Su;Chiang Lee;Chu-Hung Ho	2017		10.1145/3105831.3105848	data mining;computer science;grid;closeness;machine learning;artificial intelligence	DB	-16.26028613193935	-35.97560897162395	186567
f2095cceba07c4e7afbbc9389400a294a8cd954e	updating of association rules dynamically	incremental mining;data mining;association rule mining;association rule;incremental association rule mining algorithm association rules update apriori algorithm incremental dynamic itemset counting algorithm dynamic counting;association rules itemsets data mining transaction databases production facilities;knowledge discovery	"""Data miniiig has recently attracted n 1:irgc ntiiounl of attcntioti duc to its widr: application. In pnrlicnlar, associaticin rulc is an Iiiiportiliit type of kttowlcdgc which caii be (liscovcrcd I'roin lnrgc datnbascs. Associalirm rulcs have becn widcIy used in arcas likc marketing, dccision support and slnl-c layout rlcsign [3]. A n cxatnple of association IIIIC is UREAO + MII,JC. II it is tliscovcrerl [tom il supcrinorket trntisaction datitbnsc, it niay rncan [tiat """"whcti pcoplc huy brcnd, they usunlly also buy milk"""". ncsides binary aiitl categorical data, sninc tlatabascs inay atsi) contain qiriiiititiitivc, or nutncrical dnta. Much work has been done for discovering associaliun rulcs ~ U O I such quantitative databases [ 10, 12,71. Ii'aconccptiial hierarchy is available for Ihednta itcrris ill the dniahase, thcn gcneralixrl, or miil~iple-lcvcl assuciation rdes can be discovered [$, 6, $1. A gctieidizcrl, or rii~rltiple-lcvcl association ruic may contain iterris rrt)Ii1 different lcvels ol' the conccplual liicrarchy. Assume we tinvc a tlntabasc and soiiie association rulcs discovcrcd from tliis datnblbnsc. Now, i f soinc new tlaia comes to thc database, wc will need 10 update thc set or the discovered tlssnciation rulcs. Onc simple way is to ruii an associalion rulc niitiirig algiiritiirri ovcr thc increiiientcd dutabasc to gct thr: new scl of associatiun tulcs. How-"""	association rule learning;categorical variable;database;mii;reflow soldering;tom	King-Kwok Ng;Wai Lam	1999		10.1109/DANTE.1999.844945	gsp algorithm;association rule learning;computer science;machine learning;pattern recognition;data mining;fsa-red algorithm;apriori algorithm;population-based incremental learning	DB	-4.632197361054383	-36.29892779308465	186769
c78d2343881bdf66075f18c3a8ef4a997d567669	human mobility prediction based on individual and collective geographical preferences	forecasting;prediction error human mobility prediction collective geographical preference transportation planning collective behavior person past trajectory geographical feature prediction model massive mobile phone location dataset boston metropolitan area;prediction error;predictive models mobile handsets artificial neural networks global positioning system transportation trajectory humans;mobility;location;person past trajectory;mobility prediction;mobile phone;collective behavior;artificial neural networks;trajectory;prediction theory;land use;mathematical models;global positioning system;transportation;transportation planning;geographical feature;mobile handsets;human mobility prediction;predictive models;travel behavior;humans;prediction model;collective geographical preference;boston metropolitan area;massive mobile phone location dataset;transportation prediction theory;point of interest	Understanding and predicting human mobility is a crucial component of transportation planning and management. In this paper we propose a new model to predict the location of a person over time based on individual and collective behaviors. The model is based on the person's past trajectory and the geographical features of the area where the collectivity moves, both in terms of land use, points of interests and distance of trips. The effectiveness of the proposed prediction model is tested using a massive mobile phone location dataset available for the Boston metropolitan area. Experimental results show good levels of accuracy in terms of prediction error and prove the advantage of using the collective behavior in the prediction model.	human–computer interaction;mobile phone	Francesco Calabrese;Giusy Di Lorenzo;Carlo Ratti	2010	13th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2010.5625119	simulation;geography;advertising	Robotics	-18.244945980033208	-34.31960755897164	187051
817070510afe033a0e21a357fe2226739adac8fb	a network analysis of road traffic with vehicle tracking data		The high resolution tracking data for hundreds to thousands of urban vehicles, as well as the availability of digitized map data, provide urban planners unprecedented opportunities for better understanding urban motor vehicle transportation and for better exploiting the knowledge thereof. This paper combines the domain knowledge of traffic engineering with machine learning techniques, and gives a new approach to the problem of traffic speed estimation and travel time prediction. Introduction Human group activities are diverse. They normally involve large terabytes data sets. The mechanism explaining (the data of) a specific type of human group behavior may be very different from the mechanism explaining another type. So do the purposes of our investigations. On the one hand, we can often find out some good patterns in the data sets related to human group activities and make good use of them without understanding the underlying mechanisms. On the other hand, a good understanding of the mechanisms may enable us to get better results and to estimate the hidden variables. In other words, model-driven parametric approaches are more natural to encode the domain knowledge and to “regularize” the target functions than data-driven nonparametric approaches. Both types of approaches use statistical learning methods such as support vector methods and Bayesian networks to model human group activities. Road traffic is an important type of human behavior. This is reflected by the large number of publications and people’s everyday concerns about the road traffic. On the other hand, there does not exist a published study of nation-wide and year-long road traffic based on fine-precision tracking records (consisting of longitudes, latitudes and timestamps) for a large number of moving vehicles according to our knowledge. Studying road traffic with terabyte vehicle tracking data could naturally be benefited by distributed sensor network technologies, machine learning methods, and the physics of road traffic. This paper gives a case study of applying the statistical learning methods and the traffic theory to the problem of understanding the human behavior related to the road traffic. Copyright c © 2009, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. Our paper is the first that we know of to estimate and predict city-wide traffic speeds from vehicle tracking data. The tracking data and the map data involved for this case study are kindly provided by NavSatCR c © for our research. The tracking data contains the geographical positions, the time stamps, the speeds, and the headings of around 200 delivery vehicles operating over Costa Rica from the September of 2007 to the March of 2008 inclusive. The tracking is on a 10 second basis recorded by vehicle-mounted hardware when a vehicle is in operation (normally from 7:00 to 23:00). The heading of a vehicle ranges clockwise from 0◦ when the vehicle goes northward, to 90◦ when the vehicle goes eastward, and to 360◦ when the vehicle goes northward again. The speed of a vehicle is in km/h. It normally ranges from 5 km/h to 40 km/h on local roads, from 30 km/h to 60 km/h on arterial roads, and from 40 km/h to 100 km/h on major highways. The map data is used for GPS navigation in Costa Rica and is converted into separate ESRI Shape files and a dBase file for our data analysis. The generated shape files correspond respectively to (1) the POIs (points of interest, locations with names and attributes, such as restaurants, hotels, schools, and parking lots), (2) the unnamed points, (3) the lines defining the roads, (4) the polygons defining the lakes, parks, forests, etc, (5) the marine POIs, (6) the marine points, (7) the marine lines, and (8) the marine polygons. The generated dBase file contains the routing information, which describes how the road links are connected to one another. The map data contains 22,747 POIs and 35,369 roads. The roads form a network with 61,560 vertices (road intersections) and 78,507 edges (road links). In the following sections, we will review the literature related to the traffic theories and related to traffic speed prediction. We will then give our Viterbi decoding algorithm to map the (longitude, latitude) sequences in the tracking data into the corresponding (road segment, offset) sequences. This “map matching” has long been identified (Smith et al. 2003) as an import problem to be solved for a study like ours. We will proceed to discuss the traffic patterns at the road link level in the tracking data set. Motivated by the traffic patterns in the data set and equipped with the knowledge of road traffic physics, we will give our algorithms for estimating/predicting traffic speed and predicting travel time. We will conclude with our general opinion on understanding human or human group behavior.	algorithm;artificial intelligence;bayesian network;course (navigation);encode;emoticon;gps navigation software;hidden variable theory;image resolution;machine learning;map matching;model-driven engineering;point of interest;routing;shapefile;support vector machine;terabyte;vehicle tracking system;viterbi decoder;dbase	Wen Dong;Alex Pentland	2009			computer vision;simulation;floating car data;vehicle information and communication system	AI	-16.551961052001477	-30.986551929644822	187163
982d8b43f4b3a42496b86939953eef2772c10a2c	utilizing wireless positioning as a tracking data source	fcd;travel time;road network;area of interest;wireless positioning;position estimation;floating car data;positioning system;tools and techniques;experimental evaluation;map matching;tracking	Tracking data has become a valuable resource for establishing speed profiles for road networks, i.e., travel-time maps. While methods to derive travel time maps from GPS tracking data sources, such as floating car data (FCD), are available, the critical aspect in this process is to obtain amounts of data that fully cover all geographic areas of interest. In this work, we introduce Wireless Positioning Systems (WPS) based on 802.11 networks (WiFi), as an additional technology to extend the number of available tracking data sources. Featuring increased ubiquity but lower accuracy than GPS, this technology has the potential to produce travel time maps comparable to GPS data sources. Specifically, we adapt and apply readily available algorithms for (a) WPS (centroid and fingerprinting) to derive position estimates, and (b) map matching to derive travel times. Further, we introduce map matching as a means to improve WPS accuracy. We present an extensive experimental evaluation on real data comparing our approach to GPSbased techniques. We demonstrate that the exploitation of WPS tracking data sources is feasible with existing tools and techniques.	algorithm;crowdsourcing;emoticon;family computer disk system;fingerprint (computing);gps tracking unit;global positioning system;map matching;routing;sampling (signal processing)	Spiros Athanasiou;Panos Georgantas;George Gerakakis;Dieter Pfoser	2009		10.1007/978-3-642-02982-0_13	embedded system;simulation;floating car data;data mining;tracking	Mobile	-17.904139489148278	-29.915168247142763	187180
acc1ee592f4c1abae4aea91f1d46dd8b0fe822ab	a tutorial on simulation in health care: applications issues	health care delivery;health care delivery simulation in health care public policy patient treatment capital expenditure requirements operating policies;medical information systems;medical information systems health care patient treatment digital simulation;patient treatment;public policy;tutorial medical services computational modeling public policy analytical models medical treatment processor scheduling hospitals computer simulation mathematical model;digital simulation;health care	Simulation is an ideal tool for addressing wide rangin issues in health care delivery. These issues involve pub policy, patient treatment procedures, capital expenditu requirements, and provider operating policies. This tutorial presents example applications in each these areas. Modeling, experimentation, and other proj issues are discussed. A summary of technical issues well as issues relating to the acceptance of the use simulation in health care delivery, is presented.	requirement;simulation	Charles R. Standridge	1999		10.1145/324138.324149	public policy;health policy;hrhis;management science;health care	HCI	-16.718334087274577	-24.59235072105308	187291
bbccfea98a37b2ce7fdccc23088a491c47782e6c	trend cluster based kriging interpolation in sensor data networks	data accuracy;spatial data;data mining approach;kriging interpolation;nearby observed data;unknown data;sensor network;sensor data;real sensor data network;trend cluster;prominent data trend;spatio-temporal data	data accuracy;spatial data;data mining approach;kriging interpolation;nearby observed data;unknown data;sensor network;sensor data;real sensor data network;trend cluster;prominent data trend;spatio-temporal data	interpolation;kriging	Pietro Guccione;Annalisa Appice;Anna Ciampi;Donato Malerba	2011		10.1007/978-3-642-33684-3_7	computer science;machine learning;data mining;statistics	Robotics	-13.793903710984893	-32.84197743201761	187403
2f412e73f9643a66f4f8041166056a077fbefea3	generic driver intent inference based on parametric models	velocity;active safety driver intent inference;inference mechanisms;inference mechanisms driver information systems;right turns;visualization;eye movements;implausible observations generic driver intent inference parametric models advanced driver assistance systems automated driving right turn prediction conditional independence;drivers;behavior;driver information systems;driver support systems	Reasoning about the driver intent is fundamental both to advanced driver assistance systems as well as to highly automated driving. In contrast to the vast majority of preceding work, we investigate an architecture that can deal with arbitrary combinations of subsequent maneuvers as well as a varying set of available features. Detailed parametric models are given for the indicator, velocity and gaze direction features, all of which are parametrized from the results of extensive user studies. Evaluation is carried out for continuous right-turn prediction on a separate data set. Assuming conditional independence between the individual feature likelihoods, we investigate the contribution of each feature to the overall classification result separately. In particular, the approach is shown to work well even when faced with implausible observations of the indicator feature.	approximation algorithm;autonomous car;graphical model;naive bayes classifier;risk assessment;usability testing;velocity (software development)	Martin Liebner;Christian Ruhhammer;Felix Klanner;Christoph Stiller	2013	16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)	10.1109/ITSC.2013.6728244	computer vision;simulation;computer science;machine learning	Vision	-18.361038185954357	-26.99002526412014	187576
612da08d1dd16ac0a3b61151c6cf40b1e95b50c3	hybrid indexes to expedite spatial-visual search		Due to the growth of geo-tagged images, recent web and mobile applications provide search capabilities for images that are similar to a given query image and simultaneously within a given geographical area. In this paper, we focus on designing index structures to expedite these spatial-visual searches. We start by baseline indexes that are straightforward extensions of the current popular spatial (R*-tree) and visual (LSH) index structures. Subsequently, we propose hybrid index structures that evaluate both spatial and visual features in tandem. The unique challenge of this type of query is that there are inaccuracies in both spatial and visual features. Therefore, different traversals of the index structures may produce different images as output, some of which more relevant to the query than the others. We compare our hybrid structures with a set of baseline indexes in both performance and result accuracy using three real world datasets from Flickr, Google Street View, and GeoUGV.	baseline (configuration management);flickr;geographic coordinate system;google street view;mobile app;lsh	Abdullah Alfarrarjeh;Cyrus Shahabi	2017	CoRR		data mining;database;world wide web;information retrieval	DB	-14.94047013887594	-36.874391726881946	187647
f71b2813e51c75683272476255885212068047ac	predicting phone usage behaviors with sensory data using a hierarchical generative model	phone usage prediction;generative model	Using a sizable set of sensory data and related usage records on Android devices, we are able to give a reasonable prediction of three imporant aspects of phone usage: messages, phone calls and cellular data. We solve the problem via an estimation of a user's daily routine, on which we can train a hierarchical generative model on phone usages in all time slots of a day. The model generates phone usage behaviors in terms of three kinds of data: the state of user-phone interaction, occurrence times of an activity and the duration of the activity in each occurrence. We apply the model on a dataset with 107 frequent users, and find the prediction error of generative model is the smallest when compare with several other baseline methods. In addition, CDF curves illustrate the availability of generative model for most users with the distribution of prediction error for all test cases. We also explore the effects of time slots in a day, as well as size of training and test sets. The results suggest several interesting directions for further research.	generative model	Chuankai An;Dan Rockmore	2016		10.1007/978-3-319-42996-0_7	speech recognition;computer science;machine learning;data mining;generative model	ML	-16.91376406122458	-34.46579230231047	187719
015a36dd16f26032734f6b6aada08bf55da71278	on estimating the maximum domination value and the skyline cardinality of multi-dimensional data sets	ikee lib auth gr;βκπ;multi dimensional data sets;ικee;websearch;skyline;cardinality estimation;bkp;auth;βιβλιοθήκη και κέντρο πληροφόρησης;maximum domination value;top k dominating queries;ιδρυματικό καταθeτήριο;απθ;library and information center;aristotle university of thessaloniki ικee;ikee;institutional repository	The last years there is an increasing interest for query processing techniques that take into consideration the dominance relationship between items to select the most promising ones, based on user preferences. Skyline and top-k dominating queries are examples of such techniques. A skyline query computes the items that are not dominated, whereas a top-k dominating query returns the k items with the highest domination score. To enable query optimization, it is important to estimate the expected number of skyline items as well as the maximum domination value of an item. In this article, we provide an estimation for the maximum domination value under the distinct values and attribute independence assumptions. We provide three different methodologies for estimating and calculating the maximum domination value and we test their performance and accuracy. Among the proposed estimation methods, our method Estimation with Roots outperforms all others and returns the most accurate results. We also introduce the eliminating dimension, i.e. the dimension beyond which all domination values become zero, and we provide an efficient estimation of that dimension. Moreover, we provide an accurate estimation of the skyline cardinality of a data set.	dominating set;mathematical optimization;pareto efficiency;query optimization;roots;user (computing)	Eleftherios Tiakas;Apostolos N. Papadopoulos;Yannis Manolopoulos	2013	IJKBO	10.4018/ijkbo.2013100104	combinatorics;domination analysis;data mining;database;mathematics	DB	-7.59777673608965	-34.76721176728751	187734
9ac0b749745b697e49f498d7e7ea62a39fad256d	a graph-based algorithm for mining maximal frequent itemsets	graph theory;tree searching data mining graph theory;frequent pattern;depth first search techniques graph based algorithm mining maximal frequent itemsets association rule mining data mining frequent pattern graph breadth first search techniques;graph based algorithm;data mining itemsets iterative algorithms association rules databases computer science algorithm design and analysis iterative methods frequency;data mining;association rule mining;mining maximal frequent itemsets;frequent itemset;space complexity;depth first search techniques;breadth first search techniques;frequent pattern graph;depth first search;tree searching;breadth first search	Association rule mining is an important research branch of data mining, and computing frequent itemsets is the main problem. The paper is designed to find maximal frequent itemsets only. It presents an algorithm based on a frequent pattern graph, which can find maximal frequent itemsets quickly. A breadth-first-search and a depth-first-search techniques are used to produce all maximal frequent itemsets of a database. The paper also analyzes the complexity of the algorithm, and explains the computation procedure by examples. It has high time efficiency and less space complexity for computing maximal frequent itemsets.	algorithm;association rule learning;breadth-first search;computation;dspace;data mining;depth-first search;maximal set	Bo Liu;Jiuhui Pan	2007	Fourth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2007)	10.1109/FSKD.2007.41	breadth-first search;computer science;graph theory;machine learning;pattern recognition;data mining;mathematics	DB	-5.069438629165027	-37.20713137839035	187945
06d49d9ade2c01c0d74de0bc42c53c63495bf9a6	conditioning and aggregating uncertain data streams: going beyond expectations	data stream;data model;aggregation operator;probability distribution;randomized algorithm;uncertain data;evaluation framework	Uncertain data streams are increasingly common in real-world deployments and monitoring applications require the evaluation of complex queries on such streams. In this paper, we consider complex queries involving conditioning (e.g., selections and group by’s) and aggregation operations on uncertain data streams. To characterize the uncertainty of answers to these queries, one generally has to compute the full probability distribution of each operation used in the query. Computing distributions of aggregates given conditioned tuple distributions is a hard, unsolved problem. Our work employs a new evaluation framework that includes a general data model, approximation metrics, and approximate representations. Within this framework we design fast data-stream algorithms, both deterministic and randomized, for returning approximate distributions with bounded errors as answers to those complex queries. Our experimental results demonstrate the accuracy and efficiency of our approximation techniques and offer insights into the strengths and limitations of deterministic and randomized algorithms.	approximation algorithm;data model;randomized algorithm;sql;streaming algorithm;uncertain data	Thanh T. L. Tran;Andrew McGregor;Yanlei Diao;Liping Peng;Anna Liu	2010	PVLDB	10.14778/1920841.1921001	probability distribution;data model;computer science;theoretical computer science;data mining;database;randomized algorithm;statistics	DB	-8.201867529090945	-33.562523727212096	187971
a8d8222dd64026fff9679eed96e0be88c7991f98	anonymization on refining partition: same privacy, more utility	anonymization;refining partition;correlation loss	In privacy preserving data publishing, to reduce the correlation loss between sensitive attribute (SA) and nonsensitive attributes (NSAs), caused by anonymization methods (such as generalization, anatomy, slicing and randomization, etc.), the records with same NSAs values should be divided into same blocks with the demands of ℓ-diversity. However, there are often many blocks (of the initial partition), in which there are more than ℓ records with different SA values, and the frequencies of different SA values are uneven. So anonymization on the initial partition causes more correlation loss. To reduce the correlation loss as far as possible, in this paper, an optimizing model is first proposed. Then according to the optimizing model, the refining partition of the initial partition is generated, and anonymization is applied on the refining partition. Although anonymization on refining partition can be used on top of any existing partitioning method to reduce the correlation loss, we demonstrate that a new partitioning method tailored for refining partition can further improve data utility. An experimental evaluation shows that our approach could efficiently reduce correlation loss.	adaptive internet protocol;data anonymization;mike lesser;privacy	Hong Zhu;Shengli Tian;Genyuan Du;Meiyi Xie	2014	The 2014 2nd International Conference on Systems and Informatics (ICSAI 2014)	10.2298/CSIS141212052Z	theoretical computer science;data mining;database	Web+IR	-6.222592008659073	-32.008847979309834	188024
b3d17b5f6f40ca58400d408afc6e75418e990188	determining time to traverse road sections based on mapping discrete gps vehicle data to continuous flows	detectors;anchorage area;global positioning system road vehicles testing probes error analysis computer architecture traffic control vehicle driving time measurement intelligent vehicles;data gathering;probes;traffic engineering computing data acquisition data handling global positioning system road vehicles tracking;vehicle tracking devices;gps;continuous flow;global positioning system;mathematical model;traverse roadway section gps vehicle tracking devices anchorage area;error rate;traffic engineering computing;vehicles;vehicle tracking;data handling;data acquisition;traverse roadway section;tracking;data models;road vehicles;real time systems	In this paper, we present and analyze an algorithm for mapping discrete GPS data gathered from vehicles to a continuous flow of data to determine the time to traverse a road section. Vehicle-tracking devices are installed in 80 probe vehicles in the Anchorage area, and a specific roadway section was chosen as a test section. Drivers for this study drove from before the start of the test roadway section past the end of the test roadway section, measuring the time to travel from the start to the finish of the test roadway section. The vehicle-tracking devices report speed and location every 10 seconds. From this data, we calculated the amount of time to traverse the test roadway section using our proportional model and compared it to the actual amount of time it took to traverse the test roadway section. We performed the analysis assuming the vehicle-tracking devices were reporting location every 10 seconds, 20 seconds, 30 seconds, 40 seconds, 50 seconds, and 60 seconds. With an average actual time to traverse the test roadway section of 2 minutes 28 seconds, the error rate based on the proportional model was between 1.8%–9.2% (2.7–13.1 seconds), based on how frequently the vehicle was reporting its location. Merely taking the average speed on the edge from the vehicle reporting its speed and location during those same durations had an error rate between 14.2%–25.8% (24.7–41.1 seconds). Our results show that the proportional model has a small error rate (1.8% with 10 second reporting time) and can accurately represent the time to traverse roadway sections based on discrete readings from a small number of probe vehicles.	algorithm;dataflow;global positioning system;traverse;vehicle tracking system	Jeffrey Miller;Sun-il Kim;Muhammad Ali;Timothy Menard	2010	2010 IEEE Intelligent Vehicles Symposium	10.1109/IVS.2010.5548009	embedded system;simulation;engineering;transport engineering	Embedded	-18.61833064328567	-29.46970564058374	188165
e432de50c5a42a78efbf124ebea679eecc8bbe29	mining dependencies considering time lag in spatio-temporal traffic data		Learning dependency structure is meaningful to characterize causal or statistical relationships. Traditional dependencies learning algo- rithms only use the same time stamp data of variables. However, in many real-world applications, such as traffic system and climate, time lag is a key feature of hidden temporal dependencies, and plays an essential role in interpreting the cause of discovered temporal dependencies. In this paper, we propose a method for mining dependencies by considering the time lag. The proposed approach is based on a decomposition of the coefficients into products of two-level hierarchical coefficients, where one represents feature-level and the other represents time-level. Specially, we capture the prior information of time lag in spatio-temporal traffic data. We construct a probabilistic formulation by applying some probabilistic priors to these hierarchical coefficients, and devise an expectation-maximization (EM) algorithm to learn the model parameters. We evaluate our model on both synthetic and real-world highway traffic datasets. Experimental results show the effectiveness of our method.		Xiabing Zhou;Haikun Hong;Xingxing Xing;Wenhao Huang;Kaigui Bian;Kunqing Xie	2015		10.1007/978-3-319-21042-1_23	dependency theory;computer science;data science;machine learning;data mining	DB	-13.33539780702778	-31.937855726804873	188577
b9bf3644085d0d25b5f12b1142a6217c230d2698	tr-svd: fast and memory efficient method for time ranged singular value decomposition		Given multiple time series data, how can we efficiently find latent patterns in an arbitrary time range? Singular value decomposition (SVD) is a crucial tool to discover hidden factors in multiple time series data, and has been used in many data mining applications including dimensionality reduction, principal component analysis, recommender systems, etc. Along with its static version, incremental SVD has been used to deal with multiple semi-infinite time series data and to identify patterns of the data. However, existing SVD methods for the multiple time series data analysis do not provide functionality for detecting patterns of data in an arbitrary time range: standard SVD requires data for all intervals corresponding to a time range query, and incremental SVD does not consider an arbitrary time range. In this paper, we propose TR-SVD (Time Ranged Singular Value Decomposition), a fast and memory efficient method for finding latent factors of time series data in an arbitrary time range. TR-SVD incrementally compresses multiple time series data block by block to reduce the space cost in storage phase, and efficiently computes singular value decomposition (SVD) for a given time range query in query phase by carefully stitching stored SVD results. Through extensive experiments, we demonstrate that TR-SVD is up to 15× faster, and requires 15× less space than existing methods. Our case study shows that TR-SVD is useful for capturing past time ranges whose patterns are similar to a query time range.	algorithm;computation;data mining;dimensionality reduction;experiment;iterative and incremental development;latent variable;principal component analysis;range query (data structures);range query (database);recommender system;semiconductor industry;sensor;singular value decomposition;time series;transistor	Jun-Gi Jang;Dongjin Choi;Jinhong Jung;U. Kang	2018	CoRR		mathematical optimization;time series;recommender system;range query (data structures);mathematics;principal component analysis;dimensionality reduction;image stitching;singular value decomposition	DB	-7.706346440262061	-37.01044344228999	188748
bd5a76213e2414cc7b9687eb28fe1b59069bd0c7	learning where to inspect: location learning for crime prediction	analytical models;recommender systems law administration learning artificial intelligence pattern recognition probability;computational modeling;urban areas;roads computational modeling analytical models predictive models probabilistic logic urban areas mathematical model;roads;location recommendation location learning crime prediction spatial crime analysis crime hotspots crime tracer probabilistic model crime pattern theory;co offending networks predictive policing spatial crime analysis random walk model activity space;mathematical model;predictive models;probabilistic logic	Crime studies conclude that crime does not occur evenly across urban landscapes but concentrates in certain areas. Spatial crime analysis, primarily focuses on crime hotspots, areas with disproportionally higher crime density. Using Crime-Tracer, a personalized random walk based approach to spatial crime analysis and crime location prediction outside of hotspots, we propose here a probabilistic model of spatial behavior of known offenders within their activity space. Crime Pattern Theory states that offenders, rather than venture into unknown territory, frequently commit opportunistic crimes by taking advantage of opportunities they encounter in places they are most familiar with as part of their activity space. Our experiments on a large crime dataset show that CRIME TRACER outperforms all other methods used for location recommendation we evaluate here.	algorithm;crime mapping;cybercrime;data mining;experiment;java hotspot virtual machine;pattern theory;personalization;statistical model	Mohammad A. Tayebi;Uwe Glässer;Patricia L. Brantingham	2015	2015 IEEE International Conference on Intelligence and Security Informatics (ISI)	10.1109/ISI.2015.7165934	simulation;computer science;mathematical model;data mining;predictive modelling;probabilistic logic;computational model;computer security	SE	-18.803324036032446	-34.296758845905835	188752
36bfa608a8fbae9ab96cd01c089b706599b859c5	spatial context mining approach for transport mode recognition from mobile sensed big data		Abstract Knowledge about what transport mode people use is important information of any mobility or travel behaviour research. With ubiquitous presence of smartphones, and its sensing possibilities, new opportunities to infer transport mode from movement data are appearing. In this paper we investigate the role of spatial context of human movements in inferring transport mode from mobile sensed data. For this we use data collected from more than 8000 participants over a period of four months, in combination with freely available geographical information. We develop a support vectors machines-based model to infer five transport modes and achieve success rate of 94%. The developed model is applicable across different mobile sensed data, as it is independent on the integration of additional sensors in the device itself. Furthermore, suggested approach is robust, as it strongly relies on pre-processed data, which makes it applicable for big data implementations in (smart) cities and other data-driven mobility platforms.	big data	Ivana Semanjski;Sidharta Gautama;Rein Ahas;Frank Witlox	2017	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2017.07.004	spatial contextual awareness;implementation;support vector machine;geography;smart city;simulation;data mining;big data;geographic information system	ML	-17.795810447251224	-34.133803042814606	189888
d1e51cd408355ab6a669fea26df570f785dccd4e	activity mining: from activities to actions	impact modeling;imbalanced data;journal article;data distribution;activity pattern;pattern mining;activity mining;impact mining;social security	Activity data accumulated in real life, such as terrorist activities and governmental customer contacts, present special structural and semantic complexities. Activity data may lead to or be associated with significant business impacts, and result in important actions and decision making leading to business advantage. For instance, a series of terrorist activities may trigger a disaster to society, and large amounts of fraudulent activities in social security programs may result in huge government customer debt. Uncovering these activities or activity sequences can greatly evidence and/or enhance corresponding actions in business decisions. However, mining such data challenges the existing KDD research in aspects such as unbalanced data distribution and impact-targeted pattern mining. This paper investigates the characteristics and challenges of activity data, and the methodologies and tasks of activity mining based on case-study experience in the area of social security. Activity mining aims to discover high impact activity patterns in huge volumes of unbalanced activity transactions. Activity patterns identified can be used to prevent disastrous events or improve business decision making and processes. We illustrate the above issues and prospects in mining governmental customer contacts data to recover customer debt.		Longbing Cao;Yanchang Zhao;Chengqi Zhang;Huaifeng Zhang	2008	International Journal of Information Technology and Decision Making	10.1142/S0219622008002934	data science;data mining;computer security	Robotics	-9.25299728426997	-31.088417458670044	189948
0bff79c40cf642b5427316cff803553d3eef04ca	designing random sample synopses with outliers	database indexing;outlier indexing scheme;negative affect;outlier aware sample synopses;search space;multiple aggregation column;large dataset;random sampling;greedy algorithms;query optimization;approximate query processing;measurement uncertainty;strontium;data analysis;large scale;multiple aggregation column random sampling large dataset synopses design outlier aware sample synopses outlier indexing scheme;extreme value;aggregates;indexation;random processes;greedy algorithm;optimization;large dataset synopses design;estimation error;error bound;very large databases;very large databases database indexing random processes sampling methods;sampling methods;stream processing;aggregates estimation error sampling methods indexing query processing computer science large scale systems streaming media data analysis image databases;marketing and sales	"""Random sampling is one of the most widely used means to build synopses of large datasets because random samples can be used for a wide range of analytical tasks. Unfortunately, the quality of the estimates derived from a sample is negatively affected by the presence of """"outliers"""" in the data. In this paper, we show how to circumvent this shortcoming by constructing outlier-aware sample synopses. Our approach extends the well-known outlier indexing scheme to multiple aggregation columns."""	column (database);experiment;greedy algorithm;heuristic;monte carlo method;pseudo-random number sampling;sampling (signal processing);video synopsis;whole earth 'lectronic link	Philipp Rösch;Rainer Gemulla;Wolfgang Lehner	2008	2008 IEEE 24th International Conference on Data Engineering	10.1109/ICDE.2008.4497569	stochastic process;sampling;greedy algorithm;computer science;data science;data mining;database;statistics	DB	-7.639423167599006	-33.3438129075711	190103
cb27979292881609986cefd2b779a59d3f767f6a	geographical analysis of foreign immigration and spatial patterns in urban areas: density estimation and spatial segregation	trieste italy;geographical analysis;spatial segregation;density estimation;spatial pattern;gis;spatial distribution;foreign immigration;kernel density estimate;urban area	The paper is focused on the analysis of immigrant population with particular reference to their spatial distribution and the tendency to cluster in some parts of a city, with the risk of generating ethnic enclaves or ghettoes. Methods used in the past to measure segregation and other characteristics of immigrants have long been aspatial, therefore not considering relationships between people within a city. In this paper the attention is dedicated to methods to analyse the immigrant residential distribution spatially, with particular reference to density-based method. The analysis is focused on the Municipality of Trieste (Italy) as a case study to test different methods for the analysis of immigration, and particularly to compare traditional indices, as Location Quotients and the Index of Segregation, to different, spatial ones, both based on Kernel Density Estimation functions, as the S index and the first version of an Index of Diversity.	geospatial analysis	Giuseppe Borruso	2008		10.1007/978-3-540-69839-5_34	kernel density estimation;demography;common spatial pattern;geomatics;density estimation;computer science;statistics	ML	-11.968389683096571	-24.61173922603043	190337
8921481ad19671f7beae0db6c864ca16f93d71cb	propagating updates of residential areas in multi-representation databases using constrained delaunay triangulations	geographic information system;spatial data infrastructure;cartography;tabu search;parallel processing	Updating topographic maps in multi-representation databases is crucial to a number of applications. An efficient way to update topographic maps is to propagate the updates from large-scale maps to small-scale maps. Because objects are often portrayed differently in maps of different scales, it is a complicated process to produce multi-scale topographic maps that meet specific cartographical criteria. In this study, we propose a new approach to update small-scale maps based on updated large-scale maps. We first group spatially-related objects in multi-scale maps and decompose the large-scale objects into triangles based on constrained Delaunay triangulation. We then operate the triangles and construct small-scale objects by accounting for cartographical generalization rules. In addition, we apply the Tabu Search algorithm to search for the optimal sequences when constructing small-scale objects. A case study was conducted by applying the developed method to update residential areas at varied scales. We found the proposed method could effectively update small-scale maps while maintaining the shapes and positions of large-scale objects. Our developed method allows for parallel processing of update propagation because it operates grouped objects together, thus possesses computational advantages over the sequential updating method in areas with high building densities. Although the method proposed in this study requires further tests, it shows promise with respect to automatic updates of polygon data in the multi-representation databases.	cartography;computation;constrained delaunay triangulation;database;map;parallel computing;search algorithm;software propagation;tabu search;topography;universal generalization;windows update	Xinchang Zhang;Taisheng Guo;Jianfeng Huang;Qinchuan Xin	2016	ISPRS Int. J. Geo-Information	10.3390/ijgi5060080	theoretical computer science;data mining;database;mathematics	AI	-10.610862195009355	-36.1924489954279	190646
50a353f67a64420370517e12d67bf79247ce077a	using the tensorflow deep neural network to classify mainland china visitor behaviours in hong kong from check-in data		Over the past decade, big data, including Global Positioning System (GPS) data, mobile phone tracking data and social media check-in data, have been widely used to analyse human movements and behaviours. Tourism management researchers have noted the potential of applying these data to study tourist behaviours, and many studies have shown that social media check-in data can provide new opportunities for extracting tourism activities and tourist behaviours. However, traditional methods may not be suitable for extracting comprehensive tourist behaviours due to the complexity and diversity of human behaviours. Studies have shown that deep neural networks have outpaced the abilities of human beings in many fields and that deep neural networks can be explained in a psychological manner. Thus, deep neural network methods can potentially be used to understand human behaviours. In this paper, a deep learning neural network constructed in TensorFlow is applied to classify Mainland China visitor behaviours in Hong Kong, and the characteristics of these visitors are analysed to verify the classification results. For the social science classification problem investigated in this study, the deep neural network classifier in TensorFlow provides better accuracy and more lucid visualisation than do traditional neural network methods, even for erratic classification rules. Furthermore, the results of this study reveal that TensorFlow has considerable potential for application in the human geography field.	artificial neural network;big data;deep learning;global positioning system;lucid;mobile phone;social media;tensorflow	Shanshan Han;Fu Ren;Chao Wu;Ying Chen;Qingyun Du;Xinyue Ye	2018	ISPRS Int. J. Geo-Information	10.3390/ijgi7040158	check-in;data mining;artificial neural network;mainland china;visitor pattern;big data;deep learning;business;mobile phone tracking;social media;artificial intelligence	AI	-17.144204548121092	-33.22132116572247	190708
6ec9a9fd9d24a7a378588e2cc8156315bd1f6abc	an estimator for traffic breakdown probability based on classification of transitional breakdown events		In this paper we propose a new estimator for calculating the probability of traffic breakdown as a function of traffic demand. Traffic breakdown is a well-studied phenomena within previous literature and is of great importance to traffic planners and controllers. The proposed estimator has an appealing intuition and is able to overcome several of the problems associated with previously proposed methodology. The input to the estimator is a set of aggregated (typically five minute) traffic observations classified to either a breakdown or nonbreakdown state, and a customized and fast algorithm for this purpose is proposed. Last, we apply the classification algorithm and breakdown probability estimator to a large data set consisting of several observation sites on the Norwegian road network, and we compare our estimator to a previously defined estimator.		Petter Arnesen;Odd A. Hjelkrem	2018	Transportation Science	10.1287/trsc.2017.0776	mathematical optimization;traffic congestion reconstruction with kerner's three-phase theory;mathematics;estimator;traffic flow;intuition	ML	-14.560191048521043	-31.22437200255576	190733
b49778848a873a31f00d7b5b0baec167d0d0008b	homogeneity and activeness of crowd on aged pedestrian dynamics	pedestrian safety;juser;crowds;traffic flow;websearch;speed;pedestrians;publications database;aged	An aging population is bringing new challenges to the management of escape routes and facility design in many countries. In this paper the movement properties of middleand old-aged adults are studied with series of single-file movement experiments under laboratory conditions. The fundamental diagrams for two different groups of pedestrians and time-space diagrams are compared. For the groups with different composition and status, the fundamental diagrams are totally different but maintain the same trend. Active crowd leads to inhomogeneous pedestrian flow but higher flow rate, while inactive pedestrians prefer to keep pace with others or keep larger personal space, which leads to more jams and stop-and-go waves. Density and inhomogeneous of speed do not always play main roles on the appearance of stop-and-go. © 2016 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the Conference Program Chairs.	diagram;experiment	Jun Zhang;Shuchao Cao;Daniel Salden;Jian Ma	2016		10.1016/j.procs.2016.04.137	simulation;traffic flow;speed;quantum mechanics	HCI	-15.233248479581976	-26.488873526195313	190772
5635efaca33dddf1d282568c19d5cd29aed5b428	a general cost model for dimensionality reduction in high dimensional spaces	retrieval efficiency;range query;high dimensionality;formal model;query processing;global dimensionality reduction;general cost model;curse of dimensionality;fast similarity search;high dimensional space;local dimensionality reduction;tree index;indexation;fast similarity search general cost model high dimensional space global dimensionality reduction data dimensionality local dimensionality reduction retrieval efficiency tree index;synthetic data;dimensional reduction;similarity search;cost model;costs space technology information retrieval computational efficiency computer science image retrieval data analysis degradation indexing proposals;data dimensionality	"""Similarity search usually encounters a serious problem in the high dimensional space, known as the """"curse of dimensionality"""". In order to speed up the retrieval efficiency, previous approaches usually reduce the dimensionality of the entire data set to a fixed lower value before building indexes (referred to as global dimensionality reduction (GDR)). More recent works focus on locally reducing the dimensionality of data to different values (called the local dimensionality reduction (LDR)). However, so far little work has formally evaluated the effectiveness and efficiency of both GDR and LDR for range queries. Motivated by this, in this paper, we propose a general cost model for both GDR and LDR, in light of which we introduce a novel LDR method, PRANS. It can achieve high retrieval efficiency with the guarantee of optimality given by the formal model. Finally, a B+-tree index is constructed over the reduced partitions for fast similarity search. Extensive experiments validate the correctness of our cost model on both real and synthetic data sets, and demonstrate the efficiency and effectiveness of the proposed PRANS method."""	analysis of algorithms;b+ tree;correctness (computer science);curse of dimensionality;data dependency;dimensionality reduction;elegant degradation;experiment;formal language;heuristic;idistance;ldraw;range query (data structures);similarity search;spaces;synthetic data	Xiang Lian;Lei Chen	2007	2007 IEEE 23rd International Conference on Data Engineering	10.1109/ICDE.2007.367852	range query;curse of dimensionality;computer science;machine learning;pattern recognition;data mining;synthetic data	DB	-8.052331452004823	-34.26620066458271	190980
61bdc388e0ea3c490be961c3e2dfc9c0639dec14	set coverage problems in a one-pass data stream		Finding a maximum coverage by k sets from a given collection (Max-k-Cover), finding a minimum number of sets with a required coverage (Partial-Cover) are both important combinatorial optimization problems. Various problems from data mining, machine learning, social network analysis, operational research, etc. can be generalized as a set coverage problem. The standard greedy algorithm is efficient as an in-memory algorithm. However, when we are facing very large-scale dataset or in an online environment, we seek a new algorithm which makes only one pass through the entire dataset. Previous one-pass algorithms for the Max-k-Cover problem cannot be extended to the Partial-Cover problem and do not enjoy the prefix-optimal property. In this paper, we propose a novel onepass streaming algorithm which produces a prefix-optimal ordering of sets, which can easily be used to solve the Max-k-Cover and the Partial-Cover problems. Our algorithm consumes space linear to the size of the universe of elements. The processing time for a set is linear to the size of this set. We also show with the aid of computer simulation that the approximation ratio of the Max-k-Cover problem is around 0.3. We conduct experiments on extensive datasets to compare our algorithm with existing one-pass algorithms on the Max-k-Cover problem, and with the standard greedy algorithm on the Partial-Cover problem. We demonstrate the efficiency and quality of our algorithm. Keyword: max-k-cover problem; one-pass stream; partial-cover problem	approximation algorithm;authorization;combinatorial optimization;computer simulation;data mining;experiment;greedy algorithm;in-memory database;machine learning;mathematical optimization;one-pass algorithm;operations research;paging;social network analysis;streaming algorithm	Huiwen Yu;Dayu Yuan	2013		10.1137/1.9781611972832.84	machine learning;streaming algorithm;computer science;social network analysis;data stream;artificial intelligence;combinatorial optimization;greedy algorithm	DB	-10.794135999693298	-37.5065953370758	192503
687ce530f6d3f6c018e8f87d1e44ebfd1e50c6cb	spatial criticality - identifying cip hot-spots for german regional planning	grids transmission lines;cross sectoral;regional planning;highways;critical infrastructures;websearch;structural deterioration and defects;infrastructure resilience;germany;gis;geographic information systems;spatial criticality;pipelines;regional development;risk assessment;spatial analysis;publications database;cip hot spots;railroad tracks;rwth publications;infrastructure;critical infrastructure protection	Current strategies for infrastructure resilience in the past often focused on sector specific risk assessment and management activities. But from the regional development planner’s perspective, infrastructure sites and corridors like highways, rail tracks, transmission lines and water or gas pipelines cannot be considered as separate and independent from their environment. As damage of infrastructure components may have cascading effects, mutual influences resulting from proximity, intersections and interconnections to other infrastructures have to be considered. The proposed methodology analyses the density of infrastructures in relation to their cross-sectoral and accumulative relevance using geospatial data samples from Germany. It maps spatial criticality by defining a proximity factor which is multiplied with an indicator representing the prominence of each component. This allows the identification of hot-spots of highly accumulated critical infrastructures in a spatial (or geographical) context.	geographic information system;hazard (computer architecture);interconnectedness;map;pipeline (computing);relevance;risk management;self-organized criticality;transmission line;tree accumulation	Christoph Riegel	2015	IJCIS	10.1504/IJCIS.2015.072157	risk assessment;geomatics;track;regional planning;engineering;civil engineering;operations management;pipeline transport;spatial analysis;transport engineering;computer security	HCI	-15.303761916685463	-25.18569769921862	193016
8724d88d31b25a901cf62ee6780bb0b7f9f563fe	sensor placement with time-to-detection guarantees	detectors;expressways;sensors;traffic flow;real time information;macroscopic flow model;sensor placement;advanced traffic management systems;traffic surveillance;incident detection	We present a novel and effective method for determining the placement of sensors so as to be able to satisfy probabilistic constraints on the time-to-detection of an incident. Indeed, with the wealth of real-time traffic data available today, an important new goal of intelligent traffic management systems is incident detection with time-to-detection guarantees, in particular on expressways with large distances between sensors. This goal drives investment decisions in new sensor deployment, hence making the topic a pressing need for traffic management. The method we provide makes use of a probabilistic formulation of traffic behavior and incident localization to determine the minimum spacing of sensors needed to achieve the time-to-detection goal with a specified probability.	adobe shockwave;effective method;real-time transcription;sensor;software deployment;software propagation	Saif Eddin Jabari;Laura Wynter	2016	EURO J. Transportation and Logistics	10.1007/s13676-015-0086-4	simulation;engineering;transport engineering;computer security	ML	-18.442781271159216	-30.317359270587794	193185
ac3bb1db7bd98a8b3e1703b4b978d9e48cd3ce9c	a novel decision fusion method based on multi-sensor behavior and its application for networked target identification	multi sensor data;distributed detection;target identification;behavior functions;decision fusion	In this paper, we would focus on submitting a new decision fusion method based on multiple sensors' behaviors applying to target detection and identification in a network of distributed sensors. Each sensor has its own reliability, error rate and output data. Hence, in a processing and decision-making center in which target data are received from different sensors and sources, correctness and speed of final decision-making depend on data fusion method. The extraction, modeling and weighing of long-time and temporary behavior functions of each data source and using precise and fast decision making/fusion method are the main purpose of this article. After the introduction, we try to consider the data fusion method in decision level, such as voting schemes, rank based method and Bayesian inference. Hence, in a distributed target detection and identification system, we explain the specific and the functional features model of each source using long-time and temporary behavior functions. So we introduce the behavior based method as a new decision fusion method based on long-time and temporary behaviors of local decision makers. Therefore, we will observe that the behavior based method results, which pointed both to the temporal and the long time behaviors of the input decision makings, are very much nearer to reality and its correctness in target identification is much higher than the other methods. Examples are given corresponding to the target detection and identification systems to compare the new method with the other methods are shown that the behavior based method has its own exclusive capability in target detection, identification and producing final decision without ambiguity.		Ali J. Rashidi	2007	I. J. Information Acquisition	10.1142/S0219878907001277	artificial intelligence;machine learning;data mining	Robotics	-6.521248776921111	-29.97191751576109	193470
59c76f6857b9f71ef487aa0f9431cf7aad16e601	squish: an online approach for gps trajectory compression	compression algorithm;mobile device;smart phone;temporal information;trajectories;gps;dead reckoning;compression;applications;mobile network	GPS-equipped mobile devices such as smart phones and in-car navigation units are collecting enormous amounts spatial and temporal information that traces a moving object's path. The popularity of these devices has led to an exponential increase in the amount of GPS trajectory data generated. The size of this data makes it difficult to transmit it over a mobile network and to analyze it to extract useful patterns. Numerous compression algorithms have been proposed to reduce the size of trajectory data sets; however these methods often lose important information essential to location-based applications such as object's position, time and speed. This paper describes the Spatial QUalIty Simplification Heuristic (SQUISH) method that demonstrates improved performance when compressing up to roughly 10% of the original data size, and preserves speed information at a much higher accuracy under aggressive compression. Performance is evaluated by comparison with three competing trajectory compression algorithms: Uniform Sampling, Douglas-Peucker and Dead Reckoning.	algorithm;automotive navigation system;data compression;dead reckoning;global positioning system;heuristic;location-based service;mobile device;smartphone;text simplification;time complexity;tracing (software)	Jonathan Muckell;Jeong-Hyon Hwang;Vikram Patil;Catherine T. Lawson;Fan Ping;S. S. Ravi	2011		10.1145/1999320.1999333	embedded system;computer vision;simulation;computer science	HCI	-16.030642079244892	-34.469019098293906	193622
39b69649b828a3a752042f664c5ae35808f8dc4c	diversified spatial keyword search on road networks	conference proceeding	With the increasing pervasiveness of the geo-positioning technologies, there is an enormous amount of spatio-textual objects available in many applications such as location based services and social networks. Consequently, various types of spatial keyword searches which explore both locations and textual descriptions of the objects have been intensively studied by the research communities and commercial organizations. In many important applications (e.g., location based services), the closeness of two spatial objects is measured by the road network distance. Moreover, the result diversification is becoming a common practice to enhance the quality of the search results. Motived by the above facts, in this paper we study the problem of diversified spatial keyword search on road networks which considers both the relevance and the spatial diversity of the results. An efficient signature-based inverted indexing technique is proposed to facilitate the spatial keyword query processing on road networks. Then we develop an efficient diversified spatial keyword search algorithm by taking advantage of spatial keyword pruning and diversity pruning techniques. Comprehensive experiments on real and synthetic data clearly demonstrate the efficiency of our methods.	algorithmic efficiency;centrality;computation;database;diversification (finance);experiment;location-based service;relevance;search algorithm;social network;synthetic data	Chengyuan Zhang;Wenjie Zhang;Xuemin Lin;Muhammad Aamir Cheema;Xiaoyang Wang	2014		10.5441/002/edbt.2014.34	computer science;data mining;database;world wide web;information retrieval	DB	-14.802043601395255	-36.78361522612682	193949
84e2116d338dcb913bf9bd0cf402d6a4e4ac69d8	business intelligence through real-time tracking - using a location system towards behaviour pattern extraction	real time tracking;business intelligence	Nowadays, tracking systems constitute an important knowledge support in order to compute important measurements in companys processes efficiency. As consequence of that, this project proposes a methodology and an application, based on a tracking system to obtain, by automatic means, dynamic location data on items. This solution assumes that the client carries or drives an item of some kind. In each item there is an identifying tag attached and hidden in order to make the item at hand detectable by all the sensors that are scattered around the area. Because of the fact that the tag is light and hidden and also has no information regarding the specific person/agent this process is completely transparent to the client or robot that is being implicitly tracked. This system produces real-time shop floor visualization maps with intelligible data on online item localization; individual item complete path routes; online and historical population density rates and path routes concentration; and also item vision enabled concentration maps as emulation for item omnidirectional vision considering occlusions. This proposed system might be useful in many different areas, for instance in a traditional retail environment tracing clients through a commercial area or enabling item tracking and route analysis in a hospital.	emulator;map;pattern recognition;real-time locating system;robot;sensor;tracking system	Pedro Henriques Abreu;Vasco Vinhas;Pedro Mendes	2008			computer vision;simulation;computer science;artificial intelligence	Robotics	-17.202835453404692	-30.59128331631024	194159
5a9fe23d97f483e967cb1165c45eec2a9a45c819	ship movement anomaly detection using specialized distance measures	ships distance measurement naval engineering computing pattern clustering real time systems;gravity;data mining;trajectory;marine vehicles;clustering algorithms;trajectory data models gravity clustering algorithms data mining marine vehicles labeling;maritime surveillance anomaly detection clustering trajectory mining;labeling;data models;automatic identification system ship movement anomaly detection specialized distance measures maritime traffic domain clustering vessels vessel movements international maritime organization rules traffic separation scheme boundaries navigational behaviors real time ais surveillance	This paper provides a solution for anomaly detection in maritime traffic domain based on the clustering results presented in a previous work. That work created clusters for vessels moving close to shores by associating vessel movements with International Maritime Organization Rules (especially Traffic Separation Scheme Boundaries). In this paper, we show how three division distances with the clusters can detect anomalous navigational behaviors. The proposed method decides for each trajectory point if the vessel is anomalous, considering longitude, latitude, speed and direction. Although the approach is point-based, which is applicable for real-time AIS surveillance, it is also flexible enough for analysts to set their own threshold for labeling whole trajectories.	anomaly detection;cluster analysis;real-time clock	Bo Liu;Erico N. de Souza;Casey Hilliard;Stan Matwin	2015	2015 18th International Conference on Information Fusion (Fusion)		simulation;geography;data mining;cartography	Robotics	-17.269775147348565	-29.567416830666364	194257
29ad360c38d004bbcb0fae42e0ae2a33d723deaf	is sampling useful in data mining? a case in the maintenance of discovered association rules	tecnologia electronica telecomunicaciones;maintenance;association rules;data mining;sampling;confidence interval;sampling technique;association rule;approximate solution;update;tecnologias;grupo a;article;knowledge discovery	By nature, sampling is an appealing technique for data mining, because approximate solutions in most cases may already be of great satisfaction to the need of the users. We attempt to use sampling techniques to address the problem of maintaining discovered association rules. Some studies have been done on the problem of maintaining the discovered association rules when updates are made to the database. All proposed methods must examine not only the changed part but also the unchanged part in the original database, which is very large, and hence take much time. Worse yet, if the updates on the rules are performed frequently on the database but the underlying rule set has not changed much, then the effort could be mostly wasted. In this paper, we devise an algorithm which employs sampling techniques to estimate the difference between the association rules in a database before and after the database is updated. The estimated difference can be used to determine whether we should update the mined association rules or not. If the estimated difference is small, then the rules in the original database is still a good approximation to those in the updated database. Hence, we do not have to spend the resources to update the rules. We can accumulate more updates before actually updating the rules, thereby avoiding the overheads of updating the rules too frequently. Experimental results show that our algorithm is very efficient and highly accurate.	approximation algorithm;association rule learning;data mining;mined;sampling (signal processing);scalability	Sau Dan Lee;David Wai-Lok Cheung;Ben Kao	1998	Data Mining and Knowledge Discovery	10.1023/A:1009703019684	sampling;association rule learning;computer science;data science;data mining;database;knowledge extraction	DB	-5.415002748609289	-34.465089513183905	194281
6db40c73d2e95d86bebd4ecbdf761d37706f60d5	the role of human factor in incidence and severity of road crashes based on the cart and lr regression: a data mining approach	classification and regression tree;traffic accident;regression tree;high dimensionality;pedestrian safety;poison control;injury prevention;safety literature;traffic management;traffic safety;injury control;data mining;logistic regression;home safety;injury research;safety abstracts;human factors;health problems;occupational safety;safety;safety research;accident prevention;violence prevention;bicycle safety;poisoning prevention;falls;ergonomics;suicide prevention;public health	Accidents are one of the biggest public health problems in the world. As literature indicated, the traffic accidents were assessed to be most significant health problem in Iran. To date, no serious researches have analyzed high dimensional traffic data In Iran. This paper, therefore, aims to bridge the gap. In this study, the traffic data are analyzed by Data Mining techniques such as Logistic Regression, Classification and Regression Trees. In this paper the impact of such factors were investigated using these techniques. It is hoped that the current research findings will help governments in better road designs and traffic management.	categorization;data mining;decision tree learning;device driver;human factors and ergonomics;incidence matrix;lr parser;logistic regression	Alireza Pakgohar;Reza Sigari Tabrizi;Mohadeseh Khalili;Alireza Esmaeili	2011		10.1016/j.procs.2010.12.126	active traffic management;computer science;suicide prevention;human factors and ergonomics;injury prevention;machine learning;decision tree;logistic regression;computer security	ML	-16.661194733552794	-27.767621693347017	194282
6d26b5819ab39416590569e5af708471307c35ea	downscaling of short-term precipitation time series for climate change impact assessment		A future increase of short-term precipitation intensities may lead to problems in sewer systems, such as increased overflow volumes and flood risks. To quantify the consequences, downscaling of climate model precipitation is required to the scales relevant in urban hydrology. In the SUDPLAN project, a system where users may upload historical time series to be used as a basis for such downscaling is being developed. In this paper, the method (Delta Change) is outlined along with brief descriptions of the technical solution and result visualization.	climate model;downscaling;time series;upload	Jonas Olsson;Lars Gidhagen;Akira Kawamura	2011		10.1007/978-3-642-22285-6_67	environmental science;impact assessment;systems engineering;urban hydrology;visualization;hydrology;precipitation;climate model;upload;climate change;downscaling	HCI	-13.037075339352254	-26.999193680356186	194497
e35e18bacef5c8e3d07fe3dde1fc17aa73587ea4	graph-based analytics for decentralized online social networks		Decentralized Online Social Networks (DOSNs) have been introduced as a privacy preserving alternative to the existing online social networks. DOSNs remove the dependency on a centralized provider and operate as distributed information management platforms. The main objective behind decentralization is to preserve user privacy in both shared content and communication. Current efforts of providing DOSNs are mainly focused on designing the required building blocks for managing the distributed network and supporting the social services (e.g., search for topics or people, content delivery, etc.). However, there is a lack of reliable techniques for enabling complex analytical services (e.g., spam detection, identity validation, recommendation systems, etc.) that comply with the decentralization requirements of DOSNs. In particular, there is a need for decentralized data analytic techniques and machine learning (ML) algorithms that can successfully run on top of DOSNs. In this thesis, we empower decentralized analytics for DOSNs through a set of novel algorithms. Our algorithms allow decentralized analytics to effectively work on top of fully decentralized topology, when the data is fully distributed and nodes have access to their local knowledge only. Additionally, our algorithms follow unsupervised ML paradigm, thus removing the need for collecting labeled training data that potentially puts user privacy at risk. Furthermore, our algorithms and methods are able to extract and exploit the latent patterns in the social user interaction networks and effectively combine them with the shared content, yielding significant improvements for the complex analytic tasks. We argue that, community identification is at the core of the learning and analytical services provided for DOSNs. We show in this thesis that knowledge on community structures and information dissemination patterns, embedded in the topology of social networks has a potential to greatly enhance data analytic insights and improve results. At the heart of this thesis lies a community detection technique that successfully extracts communities in a completely decentralized manner. In particular, we show that multiple complex analytic tasks, like spam detection and identity validation, can be successfully tackled by harvesting the information from the social network structure. This is achieved by using decentralized community detection algorithm which acts as the main building block for the community-aware learning paradigm that we lay out in this thesis. To the best of our knowledge, this thesis represents the first attempt to bring complex analytical services, which require decentralized iterative computation over distributed data, to the domain of DOSNs. The experimental evaluation of our proposed algorithms using real-world datasets confirms the ability of our solutions to generate efficient ML models in massively parallel and highly scalable manner. Furthermore, our algorithms preserve user privacy and achieve better performance compared to the existing centralized and global approaches.	algorithm;anti-spam techniques;centralized computing;computation;digital distribution;embedded system;information management;iterative method;machine learning;privacy;programming paradigm;recommender system;requirement;scalability;social network;spamming	Amira Soliman	2018			social network;distributed computing;computer science;analytics;information and communications technology;graph	ML	-12.46169295618001	-37.85195084030399	194553
b9cc336c730fadc469331da72344d1c07a0b8c7f	water quality analysis using a variable consistency dominance-based rough set approach	variable consistency dominance based rough set approach;water quality;moving average filter;total dissolved solids;iran;latyan dam watershed	0198-9715/$ see front matter 2013 Elsevier Ltd. All rights reserved. http://dx.doi.org/10.1016/j.compenvurbsys.2013.09.005 ⇑ Corresponding author. Address: Tarbiat Modares University, Jalal Ale Ahmad Highway, P.O. Box 14115-111, Tehran, Iran. Tel.: +98 21 82884698; fax: +98 21 82884180. E-mail addresses: JL.karami@modares.ac.com (J. Karami), alimoh_abb@kntu.ac.ir (A. Alimohammadi), Taseifouri@yahoo.com (T. Seifouri). Jalal Karami a,⇑, Abbas Alimohammadi , Tayebeh Seifouri c,d	dominance-based rough set approach;fax	Jalal Karami;Abbas Alimohammadi;Tayebeh Seifouri	2014	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2013.09.005	environmental engineering;geography;data mining;mathematics;moving average;statistics;total dissolved solids	AI	-10.364485608432144	-26.16906499754058	194721
776fe89d26bc4551c32e4bffa8a285f4689ac150	look twice: uncover hidden information in room climate sensor data	telemetry air pollution measurement hidden markov models indoor environment meteorology sensor placement;internet of things;accuracy;hidden markov models;hidden markov model hidden information room climate sensor data sensor connection sensor deployment netatmo weather station indoor climate binary occupancy estimation co 2 measurement;estimation;other research area;information management;temperature measurement;hidden markov models meteorology estimation internet of things accuracy temperature measurement;meteorology	Connected sensors are on the march to become pervasive. While they are often deployed for a single purpose it is worth to take a second look. In this study, we show that the widespread Netatmo weather station which is intended to monitor and improve indoor climate can be used to estimate binary occupancy of individual rooms. We collected data from 11 rooms in 3 apartments including binary occupancy for several days. We show that CO2 measurements and derivatives thereof qualify as observables to be used in Hidden Markov Models and achieve accuracies well above 75% in most cases. However, we see that the accuracy metric is often misleading for such timeseries data and consider additional performance metrics as well which show varying results depending on the respective occupancy patterns of a room.	control system;ground truth;hidden markov model;home automation;machine learning;markov chain;observable;pervasive informatics;sensor web;time series;unsupervised learning;whole earth 'lectronic link	Dominic Wörner;Thomas von Bomhard;Marc Roeschlin;Felix Wortmann	2014	2014 International Conference on the Internet of Things (IOT)	10.1109/IOT.2014.7030110	estimation;simulation;temperature measurement;computer science;accuracy and precision;information management;internet of things;statistics	Mobile	-14.02468133780895	-32.77565096226243	194810
df3901755e4acc073511a5f45262af3e845d43e4	probabilistic k-nearest neighbor monitoring of moving gaussians		"""We consider a centralized server that receives streaming updates from numerous moving objects regarding their current whereabouts. However, each object always relays its location cloaked into a broader uncertainty region under a Bivariate Gaussian model of varying densities. We wish to monitor a large number of continuous queries, each seeking k objects nearest to its own focal point with likelihood above a given threshold, e.g., """"which of my friends are currently the k = 3 closest to our preferred cafe with probability over 75%"""". Since an exhaustive evaluation would be prohibitive, we develop heuristics based on spatial and probabilistic properties of the uncertainty model, and promptly issue approximate, yet reliable answers with confidence margins. We conducted a comprehensive empirical study to assess the performance and response quality of the proposed methodology, confirming that it can efficiently cope with large numbers of moving Gaussian objects under fluctuating uncertainty conditions, while also offering timely response with tolerable error to multiple queries of varying specifications."""	approximation algorithm;bivariate data;centralized computing;discretization;experiment;focal (programming language);heuristic (computer science);k-nearest neighbors algorithm;naruto shippuden: clash of ninja revolution 3;portable document format;relay;relevance;server (computing);synthetic data	Kostas Patroumpas;Christos Koutras	2017		10.1145/3085504.3085525	data mining;bivariate analysis;computer science;empirical research;database;heuristics;focal point;probabilistic logic;gaussian;machine learning;k-nearest neighbors algorithm;artificial intelligence	DB	-7.752994966999113	-33.33959711097731	194858
1b565ec8b29a2a98883c7e5995c1c8f2173a60da	efficient support counting of candidate itemsets for association rule mining	association rule mining	Association rule mining has gathered great attention in recent years due to its broad applications. Some influential algorithms have been developed in two categories: (1) candidate-generation-and-test approach such as Apriori, (2) pattern-growth approach such as FP-growth. However, they all suffer from the problems of multiple database scans and setting minimum support threshold to prune infrequent candidates for process efficiency. Reading the database multiple times is a critical problem for distributed data mining. Although more new methods are proposed, like the FSE algorithm that still has the problem of taking too much space. We propose an efficient approach by using a transformation method to perform support count of candidate itemsets. We record all the itemsets which appear at least one time in the transaction database. Thus users do not need to determine the minimum support in advance. Our approach can reach the same goal as the FSE algorithm does with better space utilization. The experiments show that our approach is effective and efficient on various datasets.		Li-Xuan Lin;Don-Lin Yang;Chia-Han Yang;Jungpin Wu	2008			association rule learning;computer science;data mining	DB	-5.388335433102624	-36.628968922457645	195083
a4320dfd8392099138cadb0750934577692d6936	advanced source separation methods with applications to spatio-temporal datasets	g5 artikkelivaitoskirja	Frequent itemsets are one of the best known concepts in data mining, and there is active research in itemset mining algorithms. An itemset is frequent in a database if its items cooccur in sufficiently many records. This thesis addresses two questions related to frequent itemsets. The first question is raised by a method for approximating logical queries by an inclusion-exclusion sum truncated to the terms corresponding to the frequent itemsets: how good are the approximations thereby obtained? The answer is twofold: in theory, the worst-case bound for the algorithm is very large, and a construction is given that shows the bound to be tight; but in practice, the approximations tend to be much closer to the correct answer than in the worst case. While some other algorithms based on frequent itemsets yield even better approximations, they are not as widely applicable. The second question concerns extending the definition of frequent itemsets to relax the requirement of perfect co-occurrence: highly correlated items may form an interesting set, even if they never co-occur in a single record. The problem is to formalize this idea in a way that still admits efficient mining algorithms. Two different approaches are used. First, dense itemsets are defined in a manner similar to the usual frequent itemsets and can be found using a modification of the original itemset mining algorithm. Second, tiles are defined in a different way so as to form a model for the whole data, unlike frequent and dense itemsets. A heuristic algorithm based on spectral properties of the data is given and some of its properties are explored. Doctoral dissertations 37 Induction of the Morphology of Natural Language: Unsupervised Morpheme Segmentation with Application to Automatic Speech Recognition	algorithm;approximation;best, worst and average case;data mining;heuristic (computer science);mathematical morphology;natural language;source separation;speech recognition;text mining	Alexander Ilin	2006			computer vision;source separation;mathematics;artificial intelligence	ML	-9.272925237850979	-36.46599248407859	195422
0f249697b697ef206fb86030b16f129c1c81cf4b	user interest acquisition by adding home and work related contexts on mobile big data analysis	mobile big data interest acquisition user behavior;user interest acquisition machine learning algorithms principle components analysis dimensionality reduction greedy strategy user mobility mobile internet mobile big data analysis;principal component analysis internet learning artificial intelligence mobile radio;context mobile communication internet big data context modeling data models context aware services	User interest acquisition facilitates customized service by figuring out user preferences in various areas, such as recommendation system and intelligence city. Mobile Internet enriches traditional user behaviors (such as who (user), when (time) and what (content)) by introducing where (mobility) into the analysis of user interest acquisition. However, user mobility is highly predictable, and user interests are constrained in a small scope. In the era of mobile big data, although several association rules and Bayesian model based approaches have been proposed to identify user interests, the impact of home and work related contexts in users' daily lives on user interest has not been fully investigated. In fact, home and work locations are anchors in user mobility and provide abundant behavior contexts to know a person. So this article proposes a framework using home and work related contexts to identify user interests. The proposed framework consists of home-work related contexts awareness based on greedy strategy, dimensionality reduction based on principle components analysis, and modeling based on various state-of-the-art machine learning algorithms. Then the proposed framework is validated on a real dataset covering 6,800 residents with more than 3.2 million records in 23 days. Results show that the proposed framework is effective, and the precision can reach more than 82% with only 7 principle components.	association rule learning;big data;computer data storage;decision tree;dimensionality reduction;greedy algorithm;k-nearest neighbors algorithm;machine learning;principal component analysis;recommender system;requirement;smart city;user (computing)	Chen Zhou;Hao Jiang;Yanqiu Chen;Lihua Wu;Shuwen Yi	2016	2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2016.7562072	mobile search;mobile web;mobile database;computer science;data mining;internet privacy;mobile computing;world wide web	ML	-17.52130901868319	-35.30565269444199	195773
88ee45a393aa33cbd9ed2735272fe8bc08ffd260	ireduct: differential privacy with reduced relative errors	privacy preservation;satisfiability;multi dimensional;relative error;differential privacy;query answering;privacy	Prior work in differential privacy has produced techniques for answering aggregate queries over sensitive data in a privacy-preserving way. These techniques achieve privacy by adding noise to the query answers. Their objective is typically to minimize absolute errors while satisfying differential privacy. Thus, query answers are injected with noise whose scale is independent of whether the answers are large or small. The noisy results for queries whose true answers are small therefore tend to be dominated by noise, which leads to inferior data utility.  This paper introduces iReduct, a differentially private algorithm for computing answers with reduced relative error. The basic idea of iReduct is to inject different amounts of noise to different query results, so that smaller (larger) values are more likely to be injected with less (more) noise. The algorithm is based on a novel resampling technique that employs correlated noise to improve data utility. Performance is evaluated on an instantiation of iReduct that generates marginals, i.e., projections of multi-dimensional histograms onto subsets of their attributes. Experiments on real data demonstrate the effectiveness of our solution.	aggregate data;algorithm;approximation error;differential privacy;experiment;resampling (statistics);universal instantiation	Xiaokui Xiao;Gabriel Bender;Michael Hay;Johannes Gehrke	2011		10.1145/1989323.1989348	approximation error;computer science;data mining;database;privacy;information retrieval;differential privacy;satisfiability	DB	-7.40894744200383	-32.75818850802633	195796
3882b057d333984b100f9061019da6ed8b5e628e	incremental environmental monitoring for revealing the ecology of endangered fish		This paper proposes a novel environmental monitoring strategy, incremental environmental monitoring, that enables scientists to reveal the ecology of wild animals in the field. We applied this strategy to the habitat of endangered freshwater fish. Specifically, we designed and implemented a network-based system using distributed sensors to continuously monitor and record the habitat of endangered fish. Moreover, we developed a set of analytical tools to exploit a variety of sensor data, including environmental time-series data such as amount of dissolved oxygen, as well as underwater video capturing the interaction of fish and their environment. We also describe the current state of monitoring the behavior and habitat of endangered fish and discuss solutions for making such environmental monitoring more efficient in the field. key words: environmental monitoring, sensor networks, annotation tools, computational ethology	ecology;freshwater ecosystem;habitat;sensor;time series	Yoshinari Shirai;Yasue Kishino;Shin Mizutani;Yutaka Yanagisawa;Takayuki Suyama;Takuma Otsuka;Tadao Kitagawa;Futoshi Naya	2018	IEICE Transactions		environmental monitoring;environmental resource management;computer science;distributed computing;endangered species	Mobile	-12.549070350352478	-28.202463079510192	196190
79a2c27937d090fc00e8dd74abadd181431f4c4e	big data processing for prediction of traffic time based on vertical data arrangement	analytical models;forecasting;market research;spatiotemporal prediction map;big traffic data;statistics analysis;traffic information systems big data forecasting theory graph theory parallel processing road traffic spatiotemporal phenomena statistical analysis time series;vertical data arrangement;predicted data;accuracy;roads;big traffic data predicted data statistics analysis vertical data arrangement spatiotemporal prediction map;roads forecasting spatiotemporal phenomena market research accuracy analytical models predictive models;spatiotemporal phenomena;predictive models;r clusters big data processing traffic time prediction vertical data arrangement traffic condition prediction spatiotemporal pattern time series forecasting methods statistical model predictive graphs traffic times big data processing tools time series variables time series forecasting method spatiotemporal prediction map two dimensional map r squared value rhive hadoop clusters	To predict future traffic conditions in each road with unique spatiotemporal pattern, it is necessary to analyze the conditions based on historical traffic data and select time series forecasting methods which can be predicting next pattern for each road according to the analyzed results. Our goal is to create a new statistical model and a new system for predictive graphs of traffic times based on big data processing tools. First, we suggest a vertical data arrangement, gathering past traffic times in the same time slot for long-term prediction. Second, we analyze each traffic pattern to select time-series variables because a time-series forecasting method for a location and a time will be selected according to the variables that are available. Third, we suggest a spatiotemporal prediction map, which is a two-dimensional map with time and location. Each element in the map represents a time-series forecasting method and an R-squared value as indicator of prediction accuracy. Finally, we introduce a new system including RHive as a middle point between R and Hadoop clusters for generating predicted data efficiently from big historical data.	apache hadoop;big data;data aggregation;protein structure prediction;r language;spatiotemporal pattern;statistical model;time series	Seungwoo Jeon;Bonghee Hong;Byungsoo Kim	2014	2014 IEEE 6th International Conference on Cloud Computing Technology and Science	10.1109/CloudCom.2014.54	market research;forecasting;computer science;data science;machine learning;data mining;accuracy and precision;predictive modelling	DB	-16.799217426983724	-32.4678134854694	196530
23fc730e9e0ccb21ac74a9221b13c28cfef615e1	a contextual fuzzy cognitive map framework for geographic information systems	cognitive map;object oriented methods;geographic information system;fuzzy cognitive maps fuzzy systems geographic information systems humans database languages data mining roads information systems communication cables network topology;qualitative data;maps contextual fuzzy cognitive map framework quantitative data qualitative data temporal information spatial information cognitive descriptions census data human expert knowledge;inference mechanisms;indexing terms;fuzzy set theory;temporal information;fuzzy logic;real world application;geographic information systems;fuzzy set theory geographic information systems knowledge representation inference mechanisms fuzzy logic object oriented methods;fuzzy cognitive map;expert knowledge;knowledge representation	Designing a system that is able to make use of quantitative and qualitative data for real world applications is a challenging problem. Traditional systems produce representational descriptions that are often not very useful to the human expert. To rectify this problem we propose a structure based on contextual fuzzy cognitive maps (CFCM’s) for geographic information systems (GIS). Our framework builds this structure using both spatial and temporal information to gain quantitative and qualitative descriptions. In addition, these cognitive maps are able to provide generalized descriptions that reflect relationships between landmarks. Such a scheme is capable of producing cognitive descriptions similar to those a human expert might derive and use. In this paper, we will illustrate the types of CFCM’s we can generate using real census data, human expert knowledge, and quantitative data in the form of maps in a GIS. For a given goal, our system structure is hierarchical by context, multilayered by variations in data over periods of time, and semi-qualitative in that the CFCM’s build causal links and relationships between landmarks and concepts.	causal filter;causality;computer vision;decision support system;expressive power (computer science);fuzzy cognitive map;geographic information system;pattern recognition;pixel;semiconductor industry	Richard M. Satur;Zhi-Qiang Liu	1999	IEEE Trans. Fuzzy Systems	10.1109/91.797974	fuzzy logic;qualitative property;fuzzy cognitive map;index term;cognitive map;computer science;knowledge management;artificial intelligence;machine learning;data mining;geographic information system;fuzzy set	AI	-5.996943321182101	-25.689248324195365	196792
6a2f81e9150df2c4ad6235c4b54245eab1624c57	efficient updating of discovered high-utility itemsets for transaction deletion in dynamic databases	pre large concept;utility mining;transaction deletion;dynamic databases;two phase approach	Most algorithms related to association rule mining are designed to discover frequent itemsets from a binary database. Other factors such as profit, cost, or quantity are not concerned in binary databases. Utility mining was thus proposed to measure the utility values of purchased items for finding high-utility itemsets from a static database. In real-world applications, transactions are changed whether insertion or deletion in a dynamic database. An existing maintenance approach for handling high-utility itemsets in dynamic databases with transaction deletion must rescan the database when necessary. In this paper, an efficient algorithm, called PRE-HUI-DEL, for updating high-utility itemsets based on the pre-large concept for transaction deletion is proposed. The pre-large concept is used to partition transaction-weighted utilization itemsets into three sets with nine cases according to whether they have large (high), pre-large, or small transaction-weighted utilization in the original database and in the deleted transactions. Specific procedures are then applied to each case for maintaining and updating the discovered high-utility itemsets. Experimental results show that the proposed PRE-HUI-DEL algorithm outperforms a batch two-phase algorithm and a FUP2-based algorithm in maintaining high-utility itemsets.	database	Chun-Wei Lin;Tzung-Pei Hong;Guo-Cheng Lan;Jia-Wei Wong;Wen-Yang Lin	2015	Advanced Engineering Informatics	10.1016/j.aei.2014.08.003	computer science;data science;data mining;database	DB	-5.724273642695812	-36.37664235212116	196833
097376df6edf0c470ad76504d25cc42166928b8b	internet map services: new portal for global ecological monitoring, or geodata junkyard?	threat assessment;wfs;web mapping service;web map service;usda forest service;web interface;data mining;arcgis server;early warning;ogc;monitoring system;wms;geodata webcrawler;natural disturbance;early detection	Systematic data mining of geospatial and other data available on the internet may provide a novel means for early detection and assessment of ecosystem change and impending natural disturbances. Exploring the possibilities and limitations of systematic geodata mining of the internet has just begun. Webcrawlers to locate, assess, and connect to these data are beginning to appear within experimental domains. In this project, we built a geodata webcrawler and post processor and then integrated it within a virtual earth viewer and a web interface to assess current data availability for several key topic areas for wildland ecological assessments. The work is part of a larger project at the Western Wildland Environmental Threat Assessment Center to build an early warning and monitoring system for specific wildland threats to human and ecological values.	bing maps platform;data mining;ecosystem;geographic information system;google earth;internet;post processor;user interface;web crawler	Alan Ager;Charlie Schrader-Patton;Ken Bunzel;Brett Colombe	2010		10.1145/1823854.1823896	geography;data mining;world wide web;computer security	ML	-13.084267810078877	-27.35442103782287	197106
d658a800276af94a83ece32b38bda1e14a5bfb2d	development of a particle number and particle mass vehicle emissions inventory for an urban fleet	040199 atmospheric sciences not elsewhere classified;ultrafine particles;motor vehicles;particle mass;ultrafine particle;vehicle emission;emission factor;motor vehicle inventory;particle emission;pm 10;particulate matter;particle emissions;transport modelling;pm 2 5;health effect;cardiovascular disease;air pollution;urban area;south east queensland;pm 1;particle number;traffic modelling;emission factors	Motor vehicles are major emitters of gaseous and particulate matter pollution in urban areas, and exposure to particulate matter pollution can have serious health effects, ranging from respiratory and cardiovascular disease to mortality. Motor vehicle tailpipe particle emissions span a broad size range from 0.003 to 10 mm, and are measured as different subsets of particle mass concentrations or particle number count. However, no comprehensive inventories currently exist in the international published literature covering this wide size range. This paper presents the first published comprehensive inventory of motor vehicle tailpipe particle emissions covering the full size range of particles emitted. The inventory was developed for urban SouthEast Queensland by combining two techniques from distinctly different disciplines, from aerosol science and transport modelling. A comprehensive set of particle emission factors were combined with transport modelling, and tailpipe particle emissions were quantified for particle number (ultrafine particles), PM1, PM2.5 and PM10 for light and heavy duty vehicles and buses. A second aim of the paper involved using the data derived in this inventory for scenario analyses, to model the particle emission implications of different proportions of passengers travelling in light duty vehicles and buses in the study region, and to derive an estimate of fleet particle emissions in 2026. It was found that heavy duty vehicles (HDVs) in the study region were major emitters of particulate matter pollution, and although they contributed only around 6% of total regional vehicle kilometres travelled, they contributed more than 50% of the region’s particle number (ultrafine particles) and PM1 emissions. With the freight task in the region predicted to double over the next 20 years, this suggests that HDVs need to be a major focus of mitigation efforts. HDVs dominated particle number (ultrafine particles) and PM1 emissions; and LDV PM2.5 and PM10 emissions. Buses contributed approximately 1–2% of regional particle emissions. 2009 Elsevier Ltd. All rights reserved.	ap 42 compilation of air pollutant emission factors;bus (computing);inventory	Diane U. Keogh;Luis Ferreira;Lidia Morawska	2009	Environmental Modelling and Software	10.1016/j.envsoft.2009.05.003	meteorology;particulates;ultrafine particle;environmental engineering;waste management	HCI	-14.940462457202774	-26.71467726585223	197366
492fede7863fdab1bebd8468a2cc2bccad4be55b	top k probabilistic skyline queries on uncertain data		Abstract Uncertainty of data is inherent in many applications, and query processing over uncertain data has gained widespread attention. The probabilistic skyline query is a powerful tool for managing uncertain data. However, the famous probabilistic skyline query, called p -skyline query, is likely to return unattractive objects which have no advantage in either their attributes or skyline probabilities with comparing to other query results. Moreover, it may return too many objects to offer any meaningful insight for customers. In this paper, we first propose a modified p -skyline (MPS) query based on a strong dominance operator to identify truly attractive results. Then we formulate a top k MPS (T k MPS) query on the basis of a new ranking criterion. We present effective approaches for processing the MPS query, and extend these approaches to process the T k MPS query. To improve the query performance, the reuse technique is adopted. Extensive experiments verify that the proposed algorithms for the MPS and T k MPS queries are efficient and effective, our MPS query can filter out 34.44% unattractive objects from the p -skyline query results at most, and although in some cases the results of the MPS and the p -skyline queries are just the same, our MPS query needs much less CPU, I/O, and memory costs.	uncertain data	ZhiBang Yang;Keqin Li;Xu Zhou;Jing Mei;Yunjun Gao	2018	Neurocomputing	10.1016/j.neucom.2018.03.052	machine learning;uncertain data;operator (computer programming);skyline;probabilistic logic;artificial intelligence;mathematics;pattern recognition;ranking	DB	-7.7592110079698084	-36.00508397025651	197526
65d6fbc5a6313c961afebbdd4eba2db0863cda69	determination of voting tendencies in turkey through data mining algorithms		Political elections can be defined as systems that contain political tendencies and voters' perceptions and preferences. The outputs of those systems are formed by specific attributes of individuals such as age, gender, occupancy, educational status, socio-economic status, religious belief, etc. Those attributes can create a data set, which contains hidden information and undiscovered patterns that can be revealed by using data mining methods and techniques. The main purpose of this study is to define voting tendencies in politics by using some of data mining methods. According to that purpose, the survey results, which were prepared and applied before 2011 elections of Turkey by KONDA Research and Consultancy Company, were used as raw data set. After Preprocessing of data, models were generated via data mining algorithms, such as Gini, C4.5 Decision Tree, Naive Bayes and Random Forest. Because of increasing popularity and flexibility in analyzing process, R language and Rstudio environment were used.	algorithm;data mining	Ali Bayir;Sebnem Özdemir;Sevinç Gülseçen	2017	IJEA	10.4018/IJEA.2017010105	data science;marketing;data mining;management;world wide web	ML	-10.276426905224511	-27.217187094494147	197670
e9914c1c4225d4683fcb1a5be208a560c6fa6636	a summary structure of data cube preserving semantics	data cube;incremental maintenance;upper bound;semantic;query answering;semantic relations	The semantic relations among cells in data cube are more important for efficient query and  OLAP . Normally the size of a data cube is very huge and relations among cells are very complicated so the semantic data cube is difficult to be realized. Based on quotient cube, Semantic Data Cube ( SDC ) structure is put forward in this paper. In  SDC the lattice of cells is expressed as tree-hierarchy structure and each cell in lattice is replaced with its upper bound. The  SDC depicts the lattice of cells concisely and preserves all the semantic relations among cells. Applying semantics to query answering and maintaining incrementally in  SDC , the time of response and the cost of updating can be reduced greatly. Algorithms of constructing  SDC , answering a query and maintaining incrementally in  SDC are given. The experimental results show that the  SDC is effective.	data cube	Zhibin Shi;Houkuan Huang	2007		10.1007/978-3-540-73451-2_55	discrete mathematics;data mining;database;mathematics	DB	-6.215853851916187	-37.6087193864956	197695
f45b589b472c2887125186ea7023144485345183	building social networks in persistent video surveillance	social network services;nearest neighbor searches;urban environment;video surveillance;terrorist activities;vehicle to vehicle interactions;vehicle detection;vehicle driving;data mining;technology management;social network;distance measurement;visualization;global positioning system;geographic information systems;social networks;social networking online;terrorist activities social networks video surveillance counter terrorism activities counterinsurgent activities vehicle to vehicle interactions vehicle to building interactions;counterinsurgent activities;social network services video surveillance global positioning system buildings vehicle driving intelligent networks visualization vehicle detection geographic information systems technology management;vehicles;intelligent networks;vehicle tracking;counter terrorism activities;vehicle to building interactions;buildings;terrorism;video surveillance social networking online terrorism	Social networks are a beneficial analysis tool in counterterrorism and counterinsurgent activities. The difficulty lies in the amount of time and resources it takes to construct a social network. By exploiting existing 24-hour overhead persistent video, we can build a social network from vehicle to vehicle and vehicle to building interactions. This paper demonstrates building a social network from vehicle tracks based on their interactions in an urban environment. From this social network we can see relationships among actors and their locations of interest. This information provides additional intelligence about terrorist activities to exploit them.	24-hour clock;closed-circuit television;interaction;overhead (computing);social network	Daniel T. Schmitt;Stuart H. Kurkowski;Michael J. Mendenhall	2009	2009 IEEE International Conference on Intelligence and Security Informatics	10.1109/ISI.2009.5137307	simulation;computer science;technology management;computer security;social network	DB	-19.068348151015112	-35.84070673797423	197875
6f325db30d5b039727715df8ee7f9f37e845c927	mlaas: machine learning as a service	supervised learning;service component architecture;power engineering computing cloud computing knowledge acquisition learning artificial intelligence load forecasting;platform as a service machine learning as a service supervised learning regression prediction service oriented architecture service component architecture;regression;machine learning as a service;platform as a service;weather data mlaas machine learning as a service knowledge extraction global data sources context specific data electricity demand forecast real world sensor data;service oriented architecture;predictive models data models machine learning algorithms adaptation models prediction algorithms computer architecture training;prediction	The demand for knowledge extraction has been increasing. With the growing amount of data being generated by global data sources (e.g., social media and mobile apps) and the popularization of context-specific data (e.g., the Internet of Things), companies and researchers need to connect all these data and extract valuable information. Machine learning has been gaining much attention in data mining, leveraging the birth of new solutions. This paper proposes an architecture to create a flexible and scalable machine learning as a service. An open source solution was implemented and presented. As a case study, a forecast of electricity demand was generated using real-world sensor and weather data by running different algorithms at the same time.	algorithm;anomaly detection;blocking (computing);cluster analysis;data mining;internet of things;machine learning;mobile app;non-blocking algorithm;open-source software;pattern recognition;predictive modelling;scalability;social media	Mauro C C Ribeiro;Katarina Grolinger;Miriam A. M. Capretz	2015	2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2015.152	instance-based learning;regression;prediction;computer science;artificial intelligence;data science;online machine learning;machine learning;service-oriented architecture;data mining;supervised learning;data as a service;computational learning theory;active learning;statistics;data architecture	ML	-10.72360069005651	-31.613865730055245	197883
2d71c7ba393ebacccbfd12ac654bcd47d4fa9648	tides - a new descriptor for time series oscillation behavior	computadora;tratamiento datos;computers;anomalies;oscillations;foyer;networks;experimental studies;ordinateur;mining;etude experimentale;anomaly detection;temporal data;exploitation miniere;data processing;traitement donnee;oscillation;segmentation;reseau;marea;time series;detection;anomalie;maree;data mining;classification;oscillation of series;sensor network;anomalia;tides;focus;time series similarity computation;multiple time scale;temporal scale;indexation;time series descriptor;oscilacion;clasificacion;similarity search;series co evolution	Sensor networks have increased the amount and variety of temporal data available, requiring the definition of new techniques for data mining. Related research typically addresses the problems of indexing, clustering, classification, summarization, and anomaly detection. There is a wide range of techniques to describe and compare time series, but they focus on series' values. This paper concentrates on a new aspect--that of describing oscillation patterns. It presents a technique for time series similarity search, and multiple temporal scales, defining a descriptor that uses the angular coefficients from a linear segmentation of the curve that represents the evolution of the analyzed series. This technique is generalized to handle co-evolution, in which several phenomena vary at the same time. Preliminary experiments with real datasets showed that our approach correctly characterizes the oscillation of single time series, for multiple time scales, and is able to compute the similarity among sets of co-evolving series.	time series	Leonardo E. Mariote;Claudia Bauzer Medeiros;Ricardo da Silva Torres;Lucas Moutinho Bueno	2011	GeoInformatica	10.1007/s10707-010-0112-5	anomaly detection;data processing;computer science;artificial intelligence;machine learning;data mining;database;mathematics;oscillation	Theory	-4.831148663694948	-31.71607762942066	198739
c55a72807b49aada4088d827f5c8b5283f2b0f6a	real time contextual summarization of highly dynamic data streams		Microblogging streams typically contain information pertaining to emerging real world events. Due to the rapid pace of messages in these data streams, short message size and many concurrent events, it is often difficult for users to understand the full context behind an arriving message. Hence, users resort to the cumbersome task of sifting through many messages to obtain the full context of the underlying event. To address this problem, we propose a novel notion – Contextual Event Summary Threads – and present a technique to extract highly meaningful yet compact event summary threads, capturing the complete context of events appearing in data stream, in real time. Our technique is unsupervised and automatically identifies different facets of live events in an unfiltered data stream in a scalable way and presents them to the users as evolving event threads. Extensive experiments over real data demonstrate that our technique -while avoiding per message processing -can summarize live data streams with high accuracy and produce compact event summary threads. The summary size of each event is dependent only on the underlying information and not on the number of messages pertaining to that event. Our technique is generic and is applicable on any chronologically ordered data stream which can be modeled in a <user: message> framework. CCS Concepts  Information systems → Information retrieval → Retrieval tasks and goals → Summarization	dynamic data;experiment;information retrieval;scalability;unsupervised learning	Manoj K. Agarwal;Krithi Ramamritham	2017		10.5441/002/edbt.2017.16	data mining;database;streams;automatic summarization;computer science;dynamic data	DB	-9.805851929715274	-37.09012888483676	198772
603a282933dd7cc2bf012df66d1a24f6d7d0c0ae	probability estimation for pedestrian crossing intention at signalized crosswalks	stochastic processes belief networks driver information systems intelligent transportation systems particle filtering numerical methods pedestrians probability road accidents road safety road traffic road vehicles;legged locomotion;bayes methods;vehicles bayes methods safety vehicle dynamics legged locomotion decision making position measurement;safety;advanced driver assistance system probability estimation pedestrian crossing intention detection signalized crosswalks autonomous driving adas intersections turning vehicles accidents pedestrian accidents pedestrian intention estimation collision avoidance risk margins pedestrian behavioral flow decision making physical movement stochastic process probabilistic model dynamic bayesian network pedestrian physical states particle filter bayesian filtering framework pedestrian state estimation signal information pedestrian position measurements;position measurement;vehicles;vehicle dynamics	With the rapid development of the techniques for autonomous driving and ADAS in the last decade, more advanced methods to understand pedestrian behavior are required. Crosswalks at intersections are the one of most hazardous where many accidents between turning-vehicles and pedestrians occur. In this paper, we present a method for estimating the pedestrian's intention to cross a signalized crosswalk or stop in front of it. The intention is crucial to not only the collision avoidance but also smooth traffic in the context of autonomous driving by reducing unnecessary risk margins. Regarding the behavioral flow of pedestrian: assessment, decision-making and physical movement, as a stochastic process, we construct a probabilistic model with the Dynamic Bayesian Network. It takes account of not only pedestrian physical states but also contextual information and integrates the relationship among them. By employing the particle filter as a Bayesian filtering framework, the model estimates the pedestrian state from signal information and pedestrian position measurements. Evaluation using experimental data collected in real traffic scene shows that the proposed model has an ability to detect the pedestrian intention to cross a crosswalk even when he/she is far from it.	architecture design and assessment system;autonomous car;autonomous robot;discriminative model;dynamic bayesian network;logistic regression;onset (audio);particle filter;semiconductor;simulation;statistical model;stochastic process	Yoriyoshi Hashimoto;Yanlei Gu;Li-Ta Hsu;Shunsuke Kamijo	2015	2015 IEEE International Conference on Vehicular Electronics and Safety (ICVES)	10.1109/ICVES.2015.7396904	simulation;engineering;transport engineering;computer security	Robotics	-18.46272384179686	-27.146899387024767	198967
19be21e31a78881d55047fe0b1becaed0455082b	short term performance forecasting in enterprise systems	performance forecasting;prediction method;bayesian network;three dimensions;data gathering;enterprise systems;time series;data mining;machine learning;hewlett packard;enterprise system;job scheduling;historical data	We use data mining and machine learning techniques to predict upcoming periods of high utilization or poor performance in enterprise systems. The abundant data available and complexity of these systems defies human characterization or static models and makes the task suitable for data mining techniques. We formulate the problem as one of classification: given current and past information about the system's behavior, can we forecast whether the system will meet its performance targets over the next hour? Using real data gathered from several enterprise systems in Hewlett-Packard, we compare several approaches ranging from time series to Bayesian networks. Besides establishing the predictive power of these approaches our study analyzes three dimensions that are important for their application as a stand alone tool. First, it quantifies the gain in accuracy of multivariate prediction methods over simple statistical univariate methods. Second, it quantifies the variations in accuracy when using different classes of system and workload features. Third, it establishes that models induced using combined data from various systems generalize well and are applicable to new systems, enabling accurate predictions on systems with insufficient historical data. Together this analysis offers a promising outlook on the development of tools to automate assignment of resources to stabilize performance, (e.g., adding servers to a cluster) and allow opportunistic job scheduling (e.g., backups or virus scans).	backup;bayesian network;ct scan;data mining;enterprise system;job scheduler;machine learning;microsoft outlook for mac;scheduling (computing);time series	Rob Powers;Moisés Goldszmidt;Ira Cohen	2005		10.1145/1081870.1081976	enterprise system;simulation;computer science;data science;machine learning;data mining;statistics	OS	-11.56921142477452	-30.480374977742112	199092
003af4d7dbae3cfefb2415da9dc499594d1f6ad1	argus invasive species spread model constructed using agent-based modeling approach and cellular automata	6-kilometer grid;daily historical weather observation;habitat quality layer;weather condition;simulated month;regional weather generator;cellular automaton;argus invasive species spread;agent-based modeling approach;weather variable;invasive species;habitat quality;weather simulation;time series;zoology;k nearest neighbor;ecology;cellular automata;multi agent systems;spatial relationships	The stochastic Argus Invasive Species Spread Model (AISSM) is constructed using an Agent-Based Modeling (ABM) approach with cellular automata (CA) to account for spatial relationships and changes in those relationships over time. The model was constructed to support a wide range of geographical locations; however, this paper focuses on its application in the state of California. A time-series of daily historical weather observations on a 6-kilometer grid was obtained for six weather variables important to insect and disease development. Weather conditions were then simulated using the K- nearest neighbor (K-nn) regional weather generator. The weather simulations were summarized into a monthly time-step and coupled with satellite land cover imagery to identify a habitat quality for each simulated month. This information was combined with the introduction of invasive species in the AnyLogic™ modeling environment. The spread of invasive species is driven by the habitat quality layer, which regulates its dispersal rate.	agent-based model;anylogic;automata theory;cellular automaton;habitat;numerical weather prediction;simulation;time series	S. Clifton Parks;Maxim Garifullin;Rainer Dronzek	2005	Proceedings of the Winter Simulation Conference, 2005.		spatial relation;cellular automaton;simulation;computer science;time series;multi-agent system;invasive species;k-nearest neighbors algorithm	Robotics	-14.104001466493521	-25.035014070525843	199243
f3980d9b0979b5dbfed10232e9cdfca8cb52dbd6	minimizing index size by reordering rows and columns	low column;high skewness;precise global optimal;minimizing index size;low skewness;accurate statistical formula;optimal order;index size;data table;reordering row;bitmap index;data record	Sizes of compressed bitmap indexes and compressed data are significantly affected by the order of data records. The optimal orders of rows and columns that minimizes the index sizes is known to be NP-hard to compute. Instead of seeking the precise global optimal ordering, we develop accurate statistical formulas that compute approximate solutions. Since the widely used bitmap indexes are compressed with variants of the run-length encoding (RLE) method, our work concentrates on computing the sizes of bitmap indexes compressed with the basic Run-Length Encoding. The resulting formulas could be used for choosing indexes to build and to use. In this paper, we use the formulas to develop strategies for reordering rows and columns of a data table. We present empirical measurements to show that our formulas are accurate for a wide range of data. Our analysis confirms that the heuristics of sorting columns with low column cardinalities first is indeed effective in reducing the index sizes. We extend the strategy by showing that columns with the same cardinality should be ordered from high skewness to low skewness.	columns	Elaheh Pourabbas;Arie Shoshani;Kesheng Wu	2012		10.1007/978-3-642-31235-9_31	computer science;theoretical computer science;data mining;algorithm	Theory	-7.09624734149189	-34.86547368513125	199354
17f4e40ccabc903772cf1869680f14f747e599fb	networks as a tool to save energy while keeping up general user comfort in buildings	energy conservation;artificial intelligence energy saving user comfort building smartphone tablet notebook desktop computer smart television anomaly detection routing scheme network traffic analysis;schedules manuals approximation algorithms data mining monitoring power demand computers;telecommunication traffic artificial intelligence buildings structures energy conservation power engineering computing;telecommunication traffic;power engineering computing;artificial intelligence;buildings structures	Devices, like Smartphones, tablets, notebooks, desktop computers, smart televisions are all connected to our home network. Analyzing the traffic on a network has already been widely studied in order to be able to detect anomalies in the network such as broken hardware, bad routing schemes or intrusions. We claim that network traffic analysis however can also bring forward valuable information about the users of that network. In this paper we demonstrate with a practical applications how we can save energy by analysing the usage on the network, as network activity informs us about the activity of the user.	algorithm;control theory;desktop computer;institute for operations research and the management sciences;laptop;network traffic control;reinforcement learning;routing;sap business one;shutdown (computing);smartphone;tablet computer;television;traffic analysis;usage data	Yann-Michaël De Hauwere;Kristof Van Moffaert;Paul-Armand Verhaegen;Ann Nowé	2013	2013 19th IEEE Workshop on Local & Metropolitan Area Networks (LANMAN)	10.1109/LANMAN.2013.6528280	embedded system;network traffic control;simulation;engineering;network simulation;computer security	Networks	-16.675352859392156	-28.749280488867377	199485
743ed2cf5bfadb7434aff6a6d21e02eb42cec62f	e-tail product return prediction via hypergraph-based local graph cut		Recent decades have witnessed the rapid growth of E-commerce. In particular, E-tail has provided customers with great convenience by allowing them to purchase retail products anywhere without visiting the actual stores. A recent trend in E-tail is to allow free shipping and hassle-free returns to further attract online customers. However, a downside of such a customer-friendly policy is the rapidly increasing return rate as well as the associated costs of handling returned online orders. Therefore, it has become imperative to take proactive measures for reducing the return rate and the associated cost. Despite the large amount of data available from historical purchase and return records, up until now, the problem of E-tail product return prediction has not attracted much attention from the data mining community.  To address this problem, in this paper, we propose a generic framework for E-tail product return prediction named HyperGo . It aims to predict the customer's intention to return after s/he has put together the shopping basket. For the baskets with a high return intention, the E-tailers can then take appropriate measures to incentivize the customer not to issue a return and/or prepare for reverse logistics. The proposed HyperGo is based on a novel hypergraph representation of historical purchase and return records, effectively leveraging the rich information of basket composition. For a given basket, we propose a local graph cut algorithm using truncated random walk on the hypergraph to identify similar historical baskets. Based on these baskets, HyperGo is able to estimate the return intention on two levels: basket-level vs. product-level, which provides the E-tailers with detailed information regarding the reason for a potential return (e.g., duplicate products with different colors). One major benefit of the proposed local algorithm lies in its time complexity, which is linearly dependent on the size of the output cluster and polylogarithmically dependent on the volume of the hypergraph. This makes HyperGo particularly suitable for processing large-scale data sets. The experimental results on multiple real-world E-tail data sets demonstrate the effectiveness and efficiency of HyperGo .	a/b testing;color;data mining;dust: an elysian tail;e-commerce payment system;graph cuts in computer vision;imperative programming;local algorithm;logistics;online shopping;strategic management;tails;time complexity	Jianbo Li;Jingrui He;Yada Zhu	2018		10.1145/3219819.3219829	computer science;data mining;time complexity;e-commerce;local algorithm;cluster analysis;rate of return;reverse logistics;cut;graph partition	ML	-11.883118019681813	-37.23773079112126	199669
36297bf22c0c8a77b5cf497e0c75d8d1b03a9026	a study on the improvement of public bicycle services - focused on south korean cases		This study analyzes public bicycle service trends in Korea. First, several cases of small Korean cities with the highest number of public bicycles were researched. The research results showed that bicycles were used 2,152 times a day with an average of 69 min spent on using the vehicle. Second, the public bicycle service in Daejeon, a metropolitan in Korea, was analyzed. Factors considered in the utilization rate of bicycles were neighboring schools, subway stations, and parks. When calculating the expected utilization rate, ten stations with low usage were assumed to be relocated. In this case, it was confirmed that the utilization rate increased by 34.00%.	maxima and minima	Yong-Wook Kim;Tea-Seong Lim	2016		10.5220/0006058400440050	marketing;operations management;advertising;business	Mobile	-16.138028896636264	-27.528635447041353	199800
7a7bc5fd0babcbf3312e0e6acd04d4f5e436c0b6	optimal decision rules for constrained record linkage: an evolutionary approach	decision rule;record linkage	Record Linkage (RL) aims at identifying pairs of records coming from different sources and representing the same real-world entity. Probabilistic RL methods assume that the pairwise distances computed in the record-comparison process obey a well defined statistical model, and exploit the statistical inference machinery to draw conclusions on the unknown Match/Unmatch status of each pair. Once model parameters have been estimated, classical Decision Theory results (e.g. the MAP rule) can generally be used to obtain a probabilistic clustering of the pairs into Matches and Unmatches. Constrained RL tasks (arising whenever one knows in advance that either or both the data sets to be linked do not contain duplicates) represent a relevant exception. In this paper we propose an Evolutionary Algorithm to find optimal decision rules according to arbitrary objectives (e.g. Maximum complete-Likelihood) while fulfilling 1:1, 1:N and N:1 matching constraints. We also present some experiments on real-world constrained RL instances, showing the accuracy and efficiency of our approach.	linkage (software)	Diego Zardetto;Monica Scannapieco	2013		10.1007/978-3-319-00032-9_44	machine learning;pattern recognition;data mining	AI	-4.650910447935592	-28.644689151479405	199989
