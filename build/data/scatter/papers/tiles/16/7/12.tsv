id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
9360b8eedefef05701bb1ee341f4710d62c99d51	dynamic load balancing scheduling model based on multi-core processor	multi core processor;dynamic load balancing;generic model;resource allocation multiprocessing systems parallel architectures processor scheduling;multiprocessor systems;processor scheduling;resource allocation;processing cores;computer industry;load management multicore processing dynamic scheduling processor scheduling load modeling heuristic algorithms;dynamic load balancing scheduling;chip;large scale multicore processors;large scale;task scheduling dynamic load balancing multi core processor;parallel architectures;cmp dynamic load balancing scheduling computer industry large scale multicore processors processing cores multiprocessor system multicore architecture;heuristic algorithms;multicore processing;load management;scheduling problem;load balance;chip multi processor;multiprocessing systems;multicore architecture;task scheduling;cmp;load modeling;multiprocessor system;dynamic scheduling	As the computer industry moves toward large-scale multi-core processors (also called Chip Multi-Processor, CMP) ,the quantity of cores on a chip increases dramatically. In order to fully utilize these processing cores, load balancing has become one of the most important factors that affect the performance of multi-cores. Based on further research on dynamic load balancing scheduling model of multiprocessor system, and considered the characteristics of multi-core architecture, this paper gave some detailed analysis concerning major influencing factors about multi-core load balancing, so that a general model of dynamic load balancing based on CMP is built. This model represents the dynamic load balancing scheduling problem as a quintuple, which gives a formal description about all factors that affect multi-core processors load balancing.	algorithm;central processing unit;intel core (microarchitecture);load balancing (computing);multi-core processor;multiprocessing;scheduling (computing);throughput	Xiaozhong Geng;Gaochao Xu;Yuan Zhang	2010	2010 Fifth International Conference on Frontier of Computer Science and Technology	10.1109/FCST.2010.54	multi-core processor;job shop scheduling;network load balancing services;computer architecture;parallel computing;real-time computing;computer science;load balancing;operating system	HPC	-14.796248269317239	60.810285803094565	71161
f1e43244ec66e0fc3df638117dfd43fb8d0430a7	efficient load balancing techniques for self-organizing content addressable networks	multi rings content addressable network;multidimensional data;content addressable network;multiple random choices;load balancing;self organization;load balance;peer to peer	Balancing the load in a decentralized P2P system is a challenging problem due to the dynamic nature of such environment and the absence of global knowledge about the actual composition of the system.In this paper, we address the problem of load balancing in large scale and selforganizing P2P systems managing multidimensional data. We propose simple and efficient decentralized mechanisms to evenly distribute the data load among the participating nodes in Content Addressable Networks. The basic idea is to enable a new node that joins the system to share the load with a heavily loaded node which is already in the system, such that the load is still evenly distributed among all the participating nodes. In the multiple random choices method, the new node probes the load of some existing nodes selected uniformly at random, then chooses the heaviest node among them to share the load with. In this paper, we extend this method in three ways. First, the new node probes a pool of nodes proportional to the network size and composition. Specifically, the number of probed nodes is logarithmic to the network size. This property enables to achieve a constant load imbalance factor which is very small without the need to estimate the network size. Second, the probed nodes are not selected at random, but they are well spread over the key space; which enables a good estimation of the actual data distribution and network composition, which enables to cope well with large-scale data imbalance. Third, the selection of nodes to probe is restricted to the immediate and distant neighbors of a randomly chosen node. The cost incurred by our join-based load balancing method is very small, since all load information is piggybacked to periodic maintenance messages exchanged between nodes and their neighbors. Unlike other methods, we do not make use of external index nor assume any global knowledge. We also generalize the first method to enable locating a heavily loaded node through a sequential walk starting from a randomly selected node. This new method incurs additional overhead, however it achieves much smaller load imbalance. We also study the robustness of our join-based load balancing method against adversarial attacks. Using simulation, we analyze the impact of the number of entry points on load balancing. To the best of our knowledge we are the first to address this problem. We conduct an experimental study using uniform and nonuniform data distributions to demonstrate the effectiveness and the scalability of our proposals.	content-addressable memory;load balancing (computing);organizing (structure)	Djelloul Boukhelef;Hiroyuki Kitagawa	2010	JNW	10.4304/jnw.5.3.321-334	round-robin dns;network load balancing services;parallel computing;real-time computing;computer science;load balancing;distributed computing;computer security;computer network	Theory	-11.51154900999179	73.28837101815262	71205
e911d838b6b4abab3512ccf1e8734e08f438e25d	a difference in efficiency between synchronous and asynchronous systems	time dependent;clocks;efficiency;asynchronous systems;multiprocessors;complexity;synchronous system;parallel computation;asynchronous system;computer architecture;time dependence;mathematical models;data rate;mathematical model;branching operations;parallel processing;parallel processors;knapsack;synchronization electronics	A system of parallel processes is said to be <underline>synchronous</underline> if all processes run using the same clock, and it is <underline>asynchronous</underline> if each process has its own independent clock. For any s, n, a particular distributed problem is defined involving system behavior at n “ports”. This problem can be solved in time s by a synchronous system but requires time at least (s-1) log n on any asynchronous system.	asynchronous circuit;asynchronous system;synchronous circuit	Eshrat Arjomandi;Michael J. Fischer;Nancy A. Lynch	1981		10.1145/800076.802466	asynchronous system;parallel processing;real-time computing;proactor pattern;asynchronous circuit;clock domain crossing;computer science;theoretical computer science;asynchronous communication;mathematical model;mathematics;distributed computing;timing failure;synchronous circuit;algorithm;statistics;synchronizer	Logic	-10.100669634539084	61.905369607919575	71283
574265b8c6dd7ea00e4ab28cd24a02a724e4bd16	pheft: pessimistic image processing workflow scheduling for dsp clusters		We address image processing workflow scheduling problems on a multicore digital signal processor cluster. We present an experimental study of scheduling strategies that include task labeling, prioritization, resource selection, and digital signal processor scheduling. We apply these strategies in the context of executing the Ligo and Montage applications. To provide effective guidance in choosing a good strategy, we present a joint analysis of three conflicting goals based on performance degradation. A case study is given, and experimental results demonstrate that a pessimistic scheduling approach provides the best optimization criteria trade-offs. The Pessimistic Heterogeneous Earliest Finish Time scheduling algorithm performs well in different scenarios with a variety of workloads and cluster configurations.	algorithm;coefficient;computation;computer cluster;critical path method;data rate units;digital signal processor;elegant degradation;experiment;heterogeneous earliest finish time;image processing;job scheduler;job shop scheduling;job stream;makespan;mathematical optimization;maximal set;montagejs;multi-core processor;performance evaluation;real-time clock;scheduling (computing);signal processing;simulation;test case;time complexity;windows nt processor scheduling	Alexander Yu. Drozdov;Andrei Tchernykh;Sergey V. Novikov;Victor E. Vladislavlev;Raul Rivera-Rodriguez	2018	Algorithms	10.3390/a11050076	resource management;image processing;machine learning;digital signal processor;artificial intelligence;real-time computing;mathematics;scheduling (computing);digital signal processing;multi-core processor;workflow;prioritization	HPC	-12.366981579294082	61.72591855375841	71286
67d3cba7f38aed299d728f1031eb145f45aa966b	efficient algorithms for slot-scheduling and cycle-scheduling of video streams on clustered video servers	full duplex scheduling;video streaming;conflict free scheduling;efficient algorithm;clustered video servers;video server	The granularity of scheduling video streams can be categorized as cycle-scheduling and slot-scheduling where a time cycle is further divided into time slots. To avoid resource conflict and thereby increase throughput of clustered video servers, slot-scheduling using conflict-free scheduling and especially cycle-scheduling using full-duplex scheduling and ordered scheduling are presented in the paper. Also, the analysis of the pros and cons of applying slot-scheduling and cycle-scheduling on clustered video servers are discussed.	algorithm;categorization;data retrieval;duplex (telecommunications);overhead (computing);read-only memory;response time (technology);schedule (computer science);scheduling (computing);server (computing);streaming media;throughput;video file format	Chow-Sing Lin;Min-You Wu;Wei Shu	2001	Multimedia Tools and Applications	10.1023/A:1009697328962	fair-share scheduling;real-time computing;computer science;two-level scheduling;distributed computing;computer network	Arch	-14.952923655672873	70.48323174973739	71290
c821aa6971defbfd75fb88e57af4c9deadf47cdd	suez: a cluster-based scalable real-time packet router	routing hardware real time systems scheduling algorithm personal communication networks computer architecture parallel processing clustering algorithms sorting measurement;performance evaluation;processor scheduling;400 mhz cluster based scalable real time packet router high performance real time packet router fast best effort packet routing scalable qos guaranteed packet scheduling hardware platform pc cluster system area network cache conscious routing table search algorithm cpu caching hardware fast lookup ip addresses virtual addresses real time connections fixed granularity fluid fair queuing algorithm weighted fair queuing algorithms performance measurements linux based suez prototype pentium ii machines myrinet;real time;qos guarantee;best effort;high performance networks;telecommunication network routing;performance evaluation processor scheduling real time systems quality of service workstation clusters telecommunication network routing virtual storage;parallel computer;cost effectiveness;packet scheduling;workstation clusters;quality of service;high performance;virtual storage;real time systems	Suez is a high-performance real-time packet router that supports fast best-eeort packet routing and scalable QoS-guaranteed packet scheduling, and is built on a hardware platform consisting of a cluster of commodity PCs connected by a gigabit/sec system area network. The major goal of the Suez project is to demonstrate that the PC cluster architecture can be as cost-eeective a platform for high-performance network packet routing as for parallel computing. Suez features a cache-conscious routing-table search algorithm that exploits CPU caching hardware for fast lookup by treating IP addresses directly as virtual addresses. To scale the number of real-time connections supportable with the link speed, Suez implements a xed-granularity uid fair queuing (FGFFQ) algorithm that completely eliminates the per-packet sorting overhead associated with conventional weighted fair queuing algorithms. With the use of general-purpose CPU as the main processing engine, Suez is inherently a programmable network device that could be dynamically extended with functionalities important to end user applications or to the eeciency of the entire network. This paper describes in detail the architectural features of Suez, and reports the performance measurements of the initial Suez prototype, which is built on four Pentium-II 400MHz machines and Myrinet, running the Linux operating system.	cpu cache;central processing unit;computer cluster;data recovery;fair queuing;gigabit;linux;lookup table;network packet;networking hardware;operating system;overhead (computing);parallel computing;processor register;prototype;real-time transcription;router (computing);routing table;scalability;scheduling (computing);search algorithm;sorting;weighted fair queueing	Tzi-cker Chiueh;Prashant Pradhan	2000		10.1109/ICDCS.2000.840915	best-effort delivery;parallel computing;real-time computing;cost-effectiveness analysis;quality of service;computer science;operating system;distributed computing;computer network	Networks	-5.918838508260995	66.46908248164961	71356
0daa6ff9b3bbdf03c59793dd6f2a98ca1885a74f	a simulation analysis of dynamic server selection algorithms for replicated web services	aempa twotowers dynamic server selection algorithms responsive web services redundancy service implementation replicated web services internet perceived performance network congestion server load requested web page;web pages;telecommunication congestion control;client server systems;web service;telecommunication congestion control internet redundancy client server systems;server selection;internet;redundancy;analytical models algorithm design and analysis heuristic algorithms network servers web server web pages web services web and internet services guidelines probes;simulation analysis;geographic distribution	A practical approach to the provision of responsive Web services is based on introducing redundancy in the service implementation by replicating the service across a number of servers geographically distributed over the Internet. I n this paper we compare the user perceived performance of three dynamic server selection algorithms operating at the client side, in order to provide some guidelines for adopting an algorithm that is appropriate for a given scenario. All the three algorithms use small probes to assess the network congestion and the server load before making a decision. The first algorithm downloads the whole requested Web page from a single server, while the other two algorithms concurrently download different pieces of the same requested Web page from different servers. The analysis is conducted via simulation with ÆMPA/TwoTowers.	algorithm;client-side;correctness (computer science);download;fabio paternò;load balancing (computing);network congestion;overhead (computing);perceived performance;responsiveness;semantics (computer science);server (computing);simulation;verification and validation;web page;web service	Marco Bernardo	2001		10.1109/MASCOT.2001.948889	client;web service;round-robin dns;web application security;static web page;web development;the internet;clickstream;computer science;web api;appleshare;web log analysis software;web page;database;redundancy;world wide web;web server;application server;client–server model;server;computer network;server farm	Metrics	-18.42780393405722	70.30132446328885	71381
bb427dacce2ead2847028938368be137ae372cce	incorporating security constraints into mixed-criticality real-time scheduling			mixed criticality;real-time computing;real-time transcription;scheduling (computing);self-organized criticality	Hyeongboo Baek;Jinkyu Lee	2017	IEICE Transactions		computer science;dynamic priority scheduling;fair-share scheduling;scheduling (computing);earliest deadline first scheduling;round-robin scheduling;real-time computing;two-level scheduling;fixed-priority pre-emptive scheduling;rate-monotonic scheduling	Embedded	-10.280354320166758	60.93200191437087	71602
3876bb309e6b0a0331bede6da7de619fc28d395f	autonomous mobile programs	autonomous mobile programs;multiagent system;agent based simulation;homogeneous network;mobility control autonomous mobile programs load management dynamic networks cost model homogeneous network decentralised approach;mobility control;costs load management mobile agents mobile computing computer networks computer network management mathematical model scalability information analysis delay;load management;scalability;distributed systems;mobile computing;cost model;dynamic networks;decentralised approach;bioinformatics	To manage load on large and dynamic networks we propose Autonomous Mobile Programs (AMPs) that periodically use a cost model to decide where to execute in the network. Unusually this form of autonomous mobility affects only where the program executes and not what it does. We present a generic AMP cost model, together with a validated instantiation and comparative performance results for two AMPs. Experiments on a homogeneous network show that collections of AMPs quickly obtain and maintain optimal or near-optimal balance. The advantages of our decentralised approach are scalability to very large and dynamic networks, improved balance, and guaranteed maximum overhead. The disadvantages are higher overheads and the necessity of both a cost model and explicit mobility control.	analysis of algorithms;autonomous agent;autonomous robot;experiment;overhead (computing);scalability;universal instantiation	Xiao Yan Deng;Philip W. Trinder;Greg J. Michaelson	2006	2006 IEEE/WIC/ACM International Conference on Intelligent Agent Technology	10.1109/IAT.2006.42	real-time computing;simulation;computer science;distributed computing;mobility model	Robotics	-11.740857902574552	72.15800555116535	71622
b7f42b4dc6644cf88ac4ef7f0fafba4a570b2184	the utilization bound of non-preemptive rate-monotonic scheduling in controller area networks is 25%	computers;control systems;job shop scheduling;processor scheduling;distributed computing;controller area networks;distributed computer system can controller area network bus nonpreemptive rate monotonic scheduling;controller area network;computer networks;distributed computer system;scheduling algorithm;distributed computing system;can;processor scheduling job shop scheduling scheduling algorithm computer networks control systems distributed computing real time systems algorithm design and analysis communication system control terminology;nonpreemptive rate monotonic scheduling;rate monotonic scheduling;terminology;controller area network bus;communication system control;article;titanium;algorithm design and analysis;rate monotonic;processor scheduling controller area networks;real time systems	Consider a distributed computer system comprising many computer nodes, each interconnected with a Controller Area Network (CAN) bus. We prove that if priorities to message streams are assigned using rate-monotonic (RM) and if the requested capacity of the CAN bus does not exceed 25% then all deadlines are met.	can bus;computer;distributed computing;quantum;rate-monotonic scheduling;scheduling (computing)	Björn Andersson;Eduardo Tovar	2009	2009 IEEE International Symposium on Industrial Embedded Systems	10.1109/SIES.2009.5196186	titanium;job shop scheduling;algorithm design;parallel computing;real-time computing;can bus;computer science;control system;rate-monotonic scheduling;operating system;distributed computing;terminology;scheduling;bus network	Arch	-11.168435455427884	61.00725034163194	71771
48086a4558403a46adaaaf3fe3cc10fc822e6a00	stepwise fair-share buffering for gossip-based peer-to-peer data dissemination	estensibilidad;distributed system;ley uniforme;evaluation performance;loi puissance;reliability;systeme reparti;performance evaluation;distribucion carga;ley poder;par a par;estudio comparativo;evaluacion prestacion;reseau ordinateur;gossiping;simulation;buffer management;performance of systems;metric;simulacion;buffer system;computer network;partage des ressources;sistema amortiguador;etude comparative;large scale;sistema repartido;poste a poste;link failure;resource sharing;comparative study;defaillance;particion recursos;distribution charge;red informatica;load distribution;metrico;temps retard;extensibilite;scalability;failures;delay time;power law;buffering;distributed systems;systeme tampon;mechanical systems;peer to peer;tiempo retardo;loi uniforme;fallo;metrique;data dissemination;epidemic;uniform distribution	We consider buffer management in support of large-scale gossip-based peer-to-peer data dissemination protocols. Coupled with an efficient buffering mechanism, system-wide buffer usage can be optimized while providing reliability and scalability in such protocols. We propose a novel approach, Stepwise Fair-share Buffering, that provides uniform load distribution and reduces the overall buffer usage where every peer has a partial view of the system. We report and discuss the comparative performance results with existing buffering approaches as well as random buffering which serves as a benchmark. We present separate evaluations of bufferer selection and gossip-based data dissemination. Reliability, content dissemination time, message delay, buffering delay, and minimum buffer requirements are considered as the key metrics investigated through simulations. The performance of our approach in the case of multiple senders, link failures with multiple bufferers, and scalability to larger networks are investigated. Several power-law and hierarchical overlay topologies are considered. Analytical bounds for reliability of dissemination are also	benchmark (computing);load balancing (computing);peer-to-peer;requirement;scalability;simulation;stepwise regression	Öznur Özkasap;Mine Çaglar;Emrah Çem;Emrah Ahi;Emre Iskender	2009	Computer Networks	10.1016/j.comnet.2009.03.021	gossip;shared resource;power law;scalability;metric;telecommunications;computer science;data buffer;bicarbonate buffering system;weight distribution;comparative research;reliability;distributed computing;uniform distribution;mechanical system;computer security;dissemination;statistics	DB	-11.448235377822128	70.54581861262648	71795
5a8ef0003f59d2e50bab08db0bbd730c67e93ba4	on reducing dynamic web page construction times	tiempo respuesta;site web;feedback mechanism;reponse temporelle;anticipacion;anticipation;web pages;red www;reseau web;customization;personnalisation;response time;cache memory;antememoria;temps reponse;antememoire;feedback;internet;time response;personalizacion;presupuesto;normal operator;school of automation;world wide web;simulation study;budget;sitio web;boucle reaction;retroalimentacion;respuesta temporal;computer science automation formerly;web site	Many web sites incorporate dynamic web pages to deliver customized contents to their users. However, dynamic pages result in increased user response times due to their construction overheads. In this paper, we consider mechanisms for reducing these overheads by utilizing the excess capacity with which web servers are typically provisioned. Specifically, we present a caching technique that integrates fragment caching with anticipatory page pre-generation in order to deliver dynamic pages faster during normal operating situations. A feedback mechanism is used to tune the page pre-generation process to match the current system load. The experimental results from a detailed simulation study of our technique indicate that, given a fixed cache budget, page construction speedups of more than fifty percent can be consistently achieved as compared to a pure fragment caching approach.	cache (computing);dynamic web page;feedback;load (computing);load profile;offset binary;page cache;server (computing);simulation;web design;web server	Suresha;Jayant R. Haritsa	2004		10.1007/978-3-540-24655-8_78	real-time computing;simulation;computer science;artificial intelligence;operating system;feedback;database;distributed computing;law;world wide web	DB	-17.445625951793456	70.94701859620122	71810
317ca9c4f438ce5d8588bd3a005a6a63f78582d5	discovering network topology in the presence of byzantine faults	public key cryptography;graph theory;cluster computing;fault tolerant;weak topology discovery problem;graph connectivity bounds;routing;topology discovery;digital signatures;communication complexity;fault tolerant routing;polynomials;telecommunication network topology communication complexity fault tolerant computing graph theory telecommunication network routing;network topology;graph connectivity;fault tolerant computing;public key;telecommunication network routing;operating system;network connectivity;byzantine robust topology discovery;digital signature;fault detection;fault tolerance;weak topology;byzantine faults fault tolerance topology discovery;arbitrary asynchronous network;robustness;peer to peer computing;byzantine faults;telecommunication network topology;data structure;message complexity network topology byzantine faults byzantine robust topology discovery arbitrary asynchronous network fault tolerant routing noncryptographic solutions weak topology discovery problem graph connectivity bounds;message complexity;noncryptographic solutions;network topology peer to peer computing routing public key cryptography fault tolerance fault detection digital signatures polynomials robustness public key	We pose and study the problem of Byzantine-robust topology discovery in an arbitrary asynchronous network. The problem is an abstraction of fault-tolerant routing. We formally state the weak and strong versions of the problem. The weak version requires that either each node discovers the topology of the network or at least one node detects the presence of a faulty node. The strong version requires that each node discovers the topology regardless of faults. We focus on non-cryptographic solutions to these problems. We explore their bounds. We prove that the weak topology discovery problem is solvable only if the connectivity of the network exceeds the number of faults in the system. Similarly, we show that the strong version of the problem is solvable only if the network connectivity is more than twice the number of faults. We present solutions to both versions of the problem. The presented algorithms match the established graph connectivity bounds. The algorithms do not require the individual nodes to know either the diameter or the size of the network. The message complexity of both programs is low polynomial with respect to the network size. We describe how our solutions can be extended to add the property of termination, handle topology changes, and perform neighborhood discovery.	byzantine fault tolerance;network topology	Mikhail Nesterenko;Sébastien Tixeuil	2009	IEEE Trans. Parallel Distrib. Syst.	10.1109/TPDS.2009.25	digital signature;fault tolerance;data structure;computer science;graph theory;theoretical computer science;distributed computing;extension topology;public-key cryptography;computer security;computer network;logical topology	Arch	-7.453065252788664	72.24109554422984	72421
47654793a67c49dcf8acb105b0ecb2046a6b3aab	dynamic real-time scheduling strategies for interactive continuous media servers	systeme temps reel;multimedia;video a peticion;continuous media;real time;sistema informatico;video a la demande;menu;computer system;multimedia application;buffer system;dynamic control;sistema amortiguador;scheduling;real time scheduling;video on demand;variable bit rate;ordonamiento;real time system;systeme informatique;serveur fichier;multimedia scheduling;sistema tiempo real;continuous media file server;quality of service;systeme tampon;buffer capacity;ordonnancement;file server;admission control	In this paper, we propose and study a dynamic approach to schedule real-time requests in a video-on-demand (VOD) server. Providing quality of service in such servers requires uninterrupted and on-time retrieval of motion video data. VOD services and multimedia applications further require access to the storage devices to be shared among multiple concurrent streams. Most of the previous VOD scheduling approaches use limited run-time,0 information and thus cannot exploit the potential capacity of the system fully. Our approach improves throughput by making use of run-time information to relax admission control. It maintains excellent quality of service under varying playout rates by observing deadlines and by reallocating resources to guarantee continuous service. It also reduces start-up latency by beginning service as soon as it is detected that deadlines of all real-time requests will be met. We establish safe conditions for greedy admission, dynamic control of disk read sizes, fast initial service, and sporadic services. We conduct thorough simulations over a wide range of buffer capacities, load settings, and over varying playout rates to demonstrate the significant improvements in quality of service, throughput and start-up latency of our approach relative to a static approach.	greedy algorithm;playout;quality of service;real-time clock;real-time transcription;scheduling (computing);server (computing);simulation;throughput;versant object database;video	Tsun-Ping J. To;Babak Hamidzadeh	1999	Multimedia Systems	10.1007/s005300050113	embedded system;file server;real-time computing;real-time operating system;quality of service;telecommunications;computer science;bicarbonate buffering system;operating system;variable bitrate;scheduling;computer network	Embedded	-14.851328366217649	70.84631235363385	72751
55226e580f89248e91c62deb71dd8169e4d61b30	cpu schedule in programmable routers: virtual service queuing with feedback algorithm	cpu scheduling;and forward;time use;process model	Parallel Express Forwarding (PXF) is a powerful, adaptive network-processing technology that maximizes both forwarding performance and services to build more powerful, scalable networks. PXF on the Cisco ® 10000 Series Routers helps enable multiple millions of packets per second (mpps) forwarding rates while allowing customers to continually add features to their solution using existing network hardware. Summary PXF is implemented in a programmable application-specific integrated circuit (ASIC) that manages forwarding decisions and per-subscriber packet processing including access control lists (ACLs), quality of service (QoS), flow accounting, and traffic shaping. The PXF ASIC allows the addition of new features without an incremental penalty in packet performance. Each packet is processed by the PXF engine in a deterministic fashion, unlike CPU forwarding platforms where the number of CPU cycles required depends largely on the features applied. PXF makes use of the expedited IP lookup and forwarding algorithms introduced with Cisco Express Forwarding, while offering expanded functionality and accelerated performance through the implementation of a parallel architecture. The PXF forwarding engine applies the combination of parallel processing and pipelining techniques to the Cisco Express Forwarding algorithms to efficiently manage a variety of complex services and operations. The Cisco 10000 Series Performance Routing Engine 2 (PRE2) uses a Versatile Time Management Scheduler (VTMS) scheduling algorithm to provide a single level of queuing. The Cisco 10000 Series PRE3 uses the latest PXF architecture for improved forwarding and feature scalability. The PRE3 implements the Hierarchal Queuing Framework (HQF) with up to three levels of hierarchy to deliver the most demanding triple-play services. Challenge Service providers require scalable networks to profitably meet their customers' requirements for better performance, more services, and higher reliability. Edge routers, such as the Cisco 10000 Series, will be needed to manage higher-bandwidth requirements, more subscribers, and multiple service levels ranging from best-effort consumer Internet data services to high-priority business applications, voice, and video. Historically, routers have been optimized for feature flexibility at the edge and fast packet forwarding at the core of networks. Edge router packet forwarding architectures based on general purpose CPU components have offered the highest level of flexibility to quickly program new features, but often with the penalty of degrading performance and scalability. Core routing designs have been optimized for fast and consistent performance with a fixed feature set by using ASIC components. To address the needs of growing service providers and their customers, a solution is needed that …	access control list;algorithm;application-specific integrated circuit;best-effort delivery;central processing unit;lookup table;network packet;networking hardware;noise shaping;parallel computing;pipeline (computing);quality of service;requirement;router (computing);routing;scalability;scheduling (computing);throughput;traffic shaping	Tieying Zhu	2003		10.1007/978-3-540-24680-0_33	bogomips;fair-share scheduling;embedded system;parallel computing;real-time computing;computer science;cpu modes;operating system;cpu time;process modeling;scheduling;cpu shielding	Networks	-4.803003022332227	65.52042425243913	72767
524e67d5bd26a208aedff8b0e7c2328ac9196d61	fast vector quantization algorithm based on vector features	greedy effect;commodity market;continuous double auction;workflow management;biological system modeling computational modeling pricing grid computing resource management supply and demand;electronic commerce;agent oriented model continuous double auction grid computing heterogeneous computer resources data storage cpu commodity market contract net protocol economic models distributed computer resources agent technology heterogeneous resources human intervention agent oriented double auction economic model;agent based;heterogeneous computing;pricing;contract net protocol;storage management;agent oriented model;resource management;biological system modeling;distributed computing;heterogeneous computer resources;storage management electronic commerce grid computing multi agent systems;economic model;heterogeneous resources;data storage;multi agent systems;autonomous mobile program;computational modeling;scheduling;human intervention;agent technology;load balancing;contract net protocol economic models;mobile computation;profitability;mobile agent;cpu;grid computing;double auction;distributed computer resources;agent oriented double auction economic model;supply and demand	Economic models are found efficient in managing heterogeneous computer resources such as storage, CPU and memory for grid computing. Commodity market, double auction and contract-net-protocol economic models have been widely discussed in the literature. These models are suitable for sharing distributed computer resources that belong to different owners. Agent technology can be used to manage these heterogeneous resources without human intervention, since agents are autonomous and intelligent in behavior. In this paper, we develop and simulate an agent-oriented double auction economic model. We compare the performance of our agent-oriented model with traditional double auction model, and show that the agent-oriented model is good in maximizing profit for providers.	algorithm;autonomous robot;central processing unit;contract net protocol;distributed computing;grid computing;simulation;vector quantization	S. M. Aminul Haque;Saadat M. Alhashmi;Rajendran Parthiban	2010	2010 International Conference on Electrical and Control Engineering	10.1109/WI-IAT.2010.105	pricing;auction algorithm;workflow;simulation;computer science;economic model;load balancing;resource management;central processing unit;multi-agent system;computer data storage;mobile agent;supply and demand;double auction;contract net protocol;computational model;scheduling;auction theory;symmetric multiprocessor system;grid computing;profitability index	Robotics	-17.670078163486405	64.630456555295	72891
91646b922890a64f1decbef1e8b27eea549c28a9	power proportional computing for “green” servers	decision support systems	Achieving energy-efficient “Green” operations within data centers used for applications such as Cloud Computing requires matching the power consumed to the data processed at each server in real-time. Beyond having a high efficiency in the server power supplies, it is vitally important to only draw power when the server is actually processing data. To operate at maximum energy efficiency, in the times when a server is idle it needs to draw no power for the server farm. By matching power draw to actual data processing activity at logic speeds, the average energy draw of the server farm drops by 50% or more with no reduction in throughput. Drawing on technology developed for efficient radio transmitters, an agile power supply, able to provide tight voltage regulation and still transition between power-off and power-on (or the other way) in nanoseconds without transition overshoot is described. With this nanosecond agility, this also solves the objective for elastic computing. Additionally, the supply pin pairing required by this energy management method provides benefits toward reducing electromagnetic interference (EMI). Proportional reduction in processor operating temperature improves reliability, along with reducing facility cooling loads.	agile software development;cloud computing;computer cooling;data center;emi;elasticity (cloud computing);ic power-supply pin;interference (communication);overshoot (signal);power supply;real-time clock;server (computing);server farm;shutdown (computing);the times;throughput;transmitter;voltage regulation	Earl W. McCune	2016	2016 12th International Conference on Network and Service Management (CNSM)	10.1109/CNSM.2016.7818450	embedded system;real-time computing;decision support system;computer science;operating system;computer security;server farm	Arch	-16.817937152210714	65.1128799601363	72897
f74dd20070c85780067cd86de87cf696cad09eaf	an activity-based genetic algorithm approach to multiprocessor scheduling	directed graphs;distributed system;multiprocessor scheduling;scheduling computational complexity directed graphs genetic algorithms multiprocessing systems;distributed system task scheduling genetic algorithm heterogeneous;scheduling algorithm;heterogeneous;computational complexity;optimal scheduling;scheduling;heuristic algorithms;mutation operator activity based genetic algorithm multiprocessor scheduling parallel computing distributed computing directed acyclic graph static task scheduling problem np complete problem list scheduling algorithm operation sequence coding space crossover operator;schedules;genetic algorithm;genetic algorithms;multiprocessing systems;task scheduling;program processors;heuristic algorithm;program processors schedules genetic algorithms optimal scheduling scheduling algorithm heuristic algorithms	In parallel and distributed computing, development of an efficient static task scheduling algorithm for directed acyclic graph (DAG) applications is an important problem. The static task scheduling problem is NP-complete in its general form. The complexity of the problem increase when task scheduling is to be done in a heterogeneous environment, where the processors in the network may not be identical and take different amounts of time to execute the same task. This paper presents an activity-based genetic task scheduling algorithm for the tasks run on the network of heterogeneous systems and represented by Directed Acyclic Graphs (DAGs). First, a list scheduling algorithm is incorporated in the generation of the initial population of a GA to represent feasible operation sequences and diminish coding space when compared to permutation representation. Second, the algorithm assigns an activity to each task which is assigned on the processor, and then the quality of the solution will be improved by adding the activity and the random probability in the crossover and mutation operator. The performance of the algorithm is illustrated by comparing with the existing effectively scheduling algorithms.	central processing unit;directed acyclic graph;distributed computing;genetic algorithm;iterative method;list scheduling;multiprocessing;multiprocessor scheduling;np-completeness;procedural generation;pseudorandom number generator;scheduling (computing);software release life cycle;windows task scheduler	Yan Kang;Zhenchao Zhang;Pengwu Chen	2011	2011 Seventh International Conference on Natural Computation	10.1109/ICNC.2011.6022236	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;open-shop scheduling;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;foreground-background;two-level scheduling;distributed computing;least slack time scheduling;instruction scheduling;lottery scheduling;round-robin scheduling;interval scheduling;multiprocessor scheduling;proportionally fair	HPC	-13.523742314319739	61.8388143069783	72903
226f928e3db643ec93a6dfb42da18921e3a81e98	sequential pattern-based cache replacement in servlet container	sequential patterns;intrinsic factor;markov model;first order;cache replacement;servlet cache;sequential pattern	Servlet cache can effectively improve the throughput of Servlet container and reduce the response time experienced by the users. But the cache effect is dependent on the hit rate determined by the cache replacement algorithms. Servlets represent some business functions, so mining the business association among Servlets can improve the hit rate of cache replacement algorithms which in turn exhances the performance of Servlet container consequently. However existing literatures such as LRU (least recently used), LFU (least frequently used), GDSF (greedy dual size frequency) rarely take into account the relationships between the Servlets. This paper denotes the business associations as sequential patterns of Servlet container, and presents a k-steps transfer probability graph to denote the access sequential patterns of Servlet container and designs a sequential patterns discovery algorithm KCTPG_Discovery. Two cache replacement algorithms KP-LRU and KP-GDSF are introduced based on the research of the sequential patterns of the Servlets. Comparing with the traditional algorithms such as LRU and GDSF, the experimental results confirm that the hit radio of the cache can be enhanced by using the above algorithms, the two algorithms effectively improve the performance of Servlet container.	greedy algorithm;java servlet;least frequently used;pixel;pseudo-lru;response time (technology);speedup;throughput;web container	Yang Li;Lin Zuo;Jun Wei;Hua Zhong;Tao Huang	2007		10.1007/978-3-540-73597-7_9	cache-oblivious algorithm;parallel computing;real-time computing;cache coloring;cache;computer science;cache invalidation;first-order logic;database;smart cache;markov model;cache algorithms;cache pollution	Metrics	-17.405986021339412	69.60558505292794	72933
a188d19425690a6aa22c5fb84a2ec1fe24046854	efficient load balancing by adaptive bypasses for the migration on the internet	dynamic load balancing;distributed computing;adaptive method;parallel computer;load balance;spanning tree	Overview We present • a problem setting for dynamic load balancing on the Internet as Grid, • an adaptive method according to initial load: the optimal flow is directly obtained, the conditions of migration for the bottleneck edges are relaxed by bypasses, • simulation results show the number of rounds of the migration is decreased by adaptive bypasses on a cactus.	internet;load balancing (computing);simulation	Yukio Hayashi	2003		10.1007/3-540-44862-4_28	parallel computing;real-time computing;spanning tree;computer science;load balancing;distributed computing	HPC	-12.626187961849114	68.63650187514168	73158
4a67a5fc9958db0e044abcb6c60ed679eacc0554	extending response-time analysis of controller area network (can) with fifo queues for mixed messages	hagglunds controller area network response time analysis controller area network fifo queues mixed messages priority queues high level protocols canopen;queueing theory;response time analysis;computer and information science;controller area networks;controller area network;queueing analysis manganese time factors real time systems protocols analytical models equations;queueing theory controller area networks;priority queue;data och informationsvetenskap	Existing response-time analysis for Controller Area Network (CAN) messages in networks where some nodes implement FIFO queues while others implement priority queues, assumes that at every node, CAN messages are queued for transmission periodically or sporadically. However, there are a few high level protocols for CAN such as CANopen and Hägglunds Controller Area Network (HCAN) that support the transmission of mixed messages as well. A mixed message can be queued for transmission both periodically and sporadically. The existing analysis of CAN with FIFO queues does not support the analysis of mixed messages. We extend the existing response-time analysis of mixed-type CAN messages. The extended analysis can compute the response-times of mixed (periodic/ sporadic) messages in the CAN network where some nodes use FIFO queues while others use priority queues.	can bus;canopen;component-based software engineering;computation;event-driven programming;fifo (computing and electronics);fully qualified name;high- and low-level;high-level programming language;priority queue;real-time clock;real-time computing;shortest seek first	Saad Mubeen;Jukka Mäki-Turja;Mikael Sjödin	2011	ETFA2011	10.1109/ETFA.2011.6059188	real-time computing;can bus;computer science;distributed computing;programming language;queueing theory;priority queue;computer network	Networks	-7.826190029780475	63.3953693563985	73167
d3ad059191f9686a60e2cac16bb1166e2803027c	erasure code replication revisited	file organisation;peer-to-peer computing;asymptotic analysis;communication systems;erasure code replication;storage systems;switchover point;whole-file replication	Erasure coding is a technique for achieving high availability and reliability in storage and communication systems. We revisit the analysis of erasure code replication and point out some situations when whole-file replication is preferred. The switchover point (from preferring whole-file replication to erasure code replication) is studied, and characterized using asymptotic analysis. We also discuss the additional considerations in building erasure code replication systems.	erasure code;high availability;switchover	W. K. Lin;D. M. Chiu;Y. B. Lee	2004	Proceedings. Fourth International Conference on Peer-to-Peer Computing, 2004. Proceedings.	10.1109/PTP.2004.1334935	erasure code;real-time computing;asymptotic analysis;computer science;theoretical computer science;distributed computing;high availability;communications system;computer network	HPC	-10.619522115083834	71.16952421185577	73303
9f0083b3751f03259556289a53e1c31195a04774	real-time design in a distributed control network application layer environment	application layer environment;time critical control applications;software tools controller area networks distributed control distributed object management process control real time systems;can application layer;transmission delays;real time;distributed event flows;can messaging service;periodic system;controller area networks;controller area network;communicating distributed tasks;distributed information flows;real time design;event driven system;transmission delays real time design distributed control network application layer environment time critical control applications response times communicating distributed tasks structured analysis design approach controller area network can application layer can messaging service distributed information flows distributed event flows real time analysis approach event driven system periodic system worst case delays computational delays queuing delays;computational delays;distributed object management;process control;worst case delays;queuing delays;software tools;response times;structured analysis design approach;real time analysis approach;distributed control;distributed control network;real time systems	The use of communication networks in time-critical control applications presents designers with special problems in the determination of response times for communicating distributed tasks. Application layers have been developed to allow designers to abstract away from the implementation details of the network protocol but little effort has gone into the problem of attempting to define real-time bounds for tasks, at design time, in a generalised application laycr environment. In this paper, using a ‘structured analysis’ design approach, a real-timc distributed application can be mapped to an application layer of a control network and guaranteed to meet its real-time requirements. The CAN (Controller Area Network) along with the CAN Application Layer (CAL) has been chosen as the experimental network. CAN is a popular control network used extensively in automotive and automation environments. The ‘CAN Messaging Service’ (CMS) elements of CAL are carefully selected to iinplenient the ‘distributed’ inforination flows and event flows produced by the ‘structured design’ methodology. A real-time analysis approach for CALk CMS service elements is developed. Intelligent use of CALs inhibit times allow modelling of an event-driven system with properties inherent to a periodic system. Combining thc worst-case computational, queuing and transmission delays, the response time for each distributed task can then be evaluated. This allows ‘fine tuning’ of the distributed tasks until they can be guaranteed to meet their deadlines.	best, worst and average case;cal;can bus;cp/cms;communications protocol;distributed computing;distributed control system;event-driven programming;real-time clock;real-time transcription;requirement;response time (technology);structured analysis;telecommunications network;window of opportunity	Donal Heffernan;A. Bohannon	2001	IEE Proceedings - Software	10.1049/ip-sen:20010631	control engineering;real-time computing;network architecture;can bus;computer science;operating system;process control;distributed computing	Embedded	-9.042901873337861	65.05659130348359	73376
e5e109688b1f70be7605482b493cfbc60717d35b	task scheduling for heterogeneous multicore systems		In recent years, as the demand for low energy and high performance computing has steadily increased, heterogeneous computing has emerged as an important and promising solution. Because most w orkloads can typically run most eff iciently on certain types of cores, mapping tasks on the best available resources can not only save energy but also deliver high performance. How ever, optimal task scheduling for performance and/or energy is yet to be solved for heterogeneous platforms. The w ork presented herein mathematically formulates the optimal heterogeneous system task scheduling as an optimization problem using queueing theory. We analytically solve for the common case of tw o processor types, e.g., CPU+GPU, and give an optimal policy (CAB). We design the GrIn heuristic to eff iciently solve for near-optimal policy for any number of processor types (within 1.6% of the optimal). Both policies w ork for any task size distribution and processing order, and are therefore, general and practical. We extensively simulate and validate the theory, and implement the proposed policy in a CPU-GPU real platform to show the optimal throughput and energy improvement. Comparing to classic policies like load-balancing, our results range from 1.08x~2.24x better performance or 1.08x~2.26x better energy ef f iciency in simulations, and 2.37x~9.07x better performance in experiments.	central processing unit;experiment;graphics processing unit;heterogeneous computing;heuristic;load balancing (computing);mathematical optimization;multi-core processor;optimization problem;ork;queueing theory;schedule (project management);scheduling (computing);simulation;supercomputer;throughput	Zhuo Chen;Diana Marculescu	2017	CoRR		symmetric multiprocessor system;parallel computing;computer science;scheduling (computing);queueing theory;multi-core processor;efficient energy use;heuristic;supercomputer;optimization problem	HPC	-17.081268218612163	61.595753395525406	73392
7a0feb67c6a4c48b18a3a46fbb5f114c8bc1e198	membership management based on a hierarchical ring for large grid environments	membership overlay;hierarchical ring;membership management;p2p	Grid environments provide the mechanism to share heterogeneous resources among nodes. Because of the similarity between grid environments and P2P networks, the structures of P2P networks can be adapted to enhance scalability and efficiency in deployment and to search for services. In this paper, we present a membership management based on a hierarchical ring which constructs P2P-like Grid environments. The proposed approach uses only a limited number of connections, reducing communication cost. Also, it only keeps local information for membership, which leads to a further reduction in management cost. This paper analyzes the performance of the approach by simulation and compares it with other approaches.	grid computing;peer-to-peer;scalability;simulation;software deployment	Taewan Gu;Seong-Jun Hong;Saangyong Uhmn;Kwang-Mo Lee	2007	JIPS		real-time computing;computer science;peer-to-peer;database;distributed computing;computer network	HPC	-12.22423407726144	73.07666981151004	73533
90a33d8b998632b58a755b99219ffe34b99105c9	optimal synchronizing sequences for machines with timing constraints				Ariel Stulman;Simon Bloch;H. G. Mendelbaum	2005			synchronizing;time constraint;computer science;distributed computing	EDA	-10.634025941167868	62.2794291190071	73675
712a97694d6c08324d2e1c50279e609f66153159	an approach to investigating reliability indices for tree topology network	tree topology;sensitivity;networking;mathematical modeling;node failures	ABSTRACTDue to advance technology, rapidly emergent complexity of networks and perseverance on network quality, reliability, and maintainability are progressively significant issues, and hence, the job of reliability analysts is becoming more challenging. A network’s optimum design is required for maintaining the reliability of a sophisticated network at a high level. Reliability of tree topology plays a key role in the measurement of quality of a network and in the performance of a network. Large-scale distributed networks are subject to frequent interruptions due to resource contention and failure. Failure of any component or subsystem affects the performance of the network. This research work has two significant goals: to design a mathematical model of a tree network using the Markov process and supplementary variable technique, and to determine the reliability characteristics such as availability, reliability, and mean time to failure (MTTF). The authors also seek the sensitivity analysis for reliabil...	network topology;tree network	Nupur Goyal;Mangey Ram;Ayush Kumar Dua	2016	Cybernetics and Systems	10.1080/01969722.2016.1209378	reliability engineering;availability;real-time computing;sensitivity;computer science;machine learning;mathematical model;network simulation;distributed computing;network topology	Logic	-10.443256812568839	71.75342643656903	73705
bdce342099a97b643bcbdd3e8ed3d7fe17c3d959	efficient cooperative caching for file systems in cluster-based web servers	cache storage;file servers;cooperative caching;cooperative algorithms file systems cluster based web servers cooperative caching schemes remote users network file systems content based request distribution high disk accesses large block access latency cache replacement duplicate first copy replacement unnecessary data remote client requests disk accesses block access latency file block cooperative cache content based web server architecture trace driven simulation cooperating caching disk access ratio;client server systems;client server systems file servers internet workstation clusters cache storage;network file system;internet;cache replacement;cooperative caching file systems web server load management delay clustering algorithms network servers service oriented architecture workstations personal communication networks;file system;workstation clusters;trace driven simulation	Most of the traditional cooperative caching schemes were developed so that remote users may share files in network file systems, but were not designed for supporting recent cluster based Web servers with content based request distribution. For this reason, although the schemes are applied to the Web servers, their performance suffers from high disk accesses and large block access latency. The paper proposes and evaluates a new cooperative caching suitable for file systems in the Web servers. By exploiting the characteristics of the Web servers, it performs a cache replacement, called Duplicate First copy Replacement (DFR) to avoid caching unnecessary data produced during serving remote client requests, and thus minimizes disk accesses. Also, it reduces the overhead and block access latency required to fetch a file block (or page) in the cooperative cache with regard to both the content based Web server architecture and characteristics. Trace-driven simulation shows that our cooperating caching decreases the disk access ratio by 29%, and reduces block access latency by about 26% more than the existing cooperative algorithms.	cache (computing)	Woo Hyun Ahn;Sang Ho Park;Daeyeon Park	2000		10.1109/CLUSTR.2000.889086	self-certifying file system;file server;parallel computing;real-time computing;the internet;page cache;computer file;network file system;cache;computer science;stub file;operating system;unix file types;database;open;smart cache;file system fragmentation;file area network;server;computer network	OS	-17.38525300806854	69.39231369994866	73752
d8109fa28a99274dc8cdf7f862e0d6284d5b8646	a greedy approach for dynamic control of diffusion processes in networks	social network services;software packages computer network security greedy algorithms minimisation;networks;resource allocation;resource management;diffusion processes;resource allocation epidemics diffusion processes networks control greedy;process control;diseases;control;greedy;epidemics;resource management diffusion processes real time systems dynamic scheduling diseases process control social network services;dynamic scheduling;software package greedy approach diffusion processes real time information network administrator control resource allocation infected nodes dynamic control strategies largest reduction in infectious edges lrie control strategy greedy minimization;real time systems	This paper investigates the control of a diffusion process by utilizing real-time information. More specifically, we allow the network administrator to adjust the allocation of control resources, a set of treatments that increase the recovery rate of infected nodes, according to the evolution of the diffusion process. We first present a novel framework for describing a large class of dynamic control strategies. These strategies rely on sorting the nodes according to a priority score in order to treat more sensitive regions first. Then, we propose the Largest Reduction in Infectious Edges (LRIE) control strategy which is based on a greedy minimization of the cost associated to the undesired diffusion, and has the benefits of being efficient and easy to implement. Our simulations, which were conducted using a software package that we developed and made available to the community, show that the LRIE strategy substantially outperforms its competitors in a wide range of scenarios.	approximation;computer simulation;control theory;dynamic resolution adaptation;greedy algorithm;procedural generation;real-time data;simulation;simulation software;social network;sorting	Kevin Scaman;Argyris Kalogeratos;Nicolas Vayatis	2015	2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)	10.1109/ICTAI.2015.99	simulation;dynamic priority scheduling;resource allocation;computer science;resource management;process control;distributed computing;scientific control	Robotics	-18.203124542177214	67.77257112837627	74069
d83253377c0ddc9e4aaa1181a825d15e98a5a3ce	efficient range queries and fast lookup services for scalable p2p networks	distributed system;systeme reparti;range query;geometrie algorithmique;equilibrio de carga;par a par;interrogation base donnee;computational geometry;equilibrage charge;interrogacion base datos;p2p;simulator;sistema repartido;simulador;poste a poste;indexing;indexation;indizacion;load balancing;simulateur;geometria computacional;load balance;p2p networks;peer to peer;database query	In this paper we propose a Peer-To-Peer (P2P) architecture using a tree based indexing scheme which allows for efficient lookup and range query services on documents in the network. We also present a basic load balancing technique by assigning a new node that joins the network to a heavily loaded area to take on some of load of its peers. Given a query, we need to search only a small number of nodes to locate matching documents hence making the architecture scalable. We also take into account the fact that nodes in a P2P environment need not have the same capability. We implemented a simulator and performed experiments to study to the performance of our proposed architecture. The results show that our proposed architecture is scalable and highly efficient when handling range queries.	electronic circuit simulation;experiment;load balancing (computing);lookup table;peer-to-peer;range query (data structures);range query (database);scalability	Chu Yee Liau;Wee Siong Ng;Yanfeng Shu;Kian-Lee Tan;Stéphane Bressan	2004		10.1007/978-3-540-31838-5_7	computational geometry;computer science;load balancing;theoretical computer science;operating system;database;world wide web;computer security	DB	-10.942763313063692	69.85983094283317	74196
c2c435d4208712a109ccbeac352cabfc93323fd5	a content-based publish/subscribe over two-tier dht utilizing domain ontology	rendezvous nodes;domain ontology content based publish subscribe dht;peer to peer computing message passing meta data ontologies artificial intelligence;two tier dht;metadata;peer to peer network;distributed hash table;routing;semantics;acm;popular content caching;ontologies artificial intelligence;subscriptions peer to peer computing ontologies programming proposals semantics routing;content based publish subscribe communication infrastructure;notification delivery;subscription installation;efficient implementation;publish subscribe;message passing;subscriptions;content based publish subscribe;popular content caching domain ontology two tier dht peer to peer networks distributed hash table metadata acm content based publish subscribe communication infrastructure subscription specification notification delivery publication installation subscription installation rendezvous nodes neighborhood overlay;meta data;ontologies;subscription specification;peer to peer computing;publication installation;peer to peer networks;proposals;neighborhood overlay;domain ontology;dht;programming	Several design alternatives have been advocated for content-based publish subscribe communication infrastructure over structured peer to peer networks. These efforts have contributed significantly towards efficient implementations of subscription specification, installation of publications and subscriptions and notification delivery. There are some design issues which need to be addressed. These issues include semantic expressiveness of subscriptions, loss of notifications under high churn and the amount of routing traffic generated for installation of publications and subscriptions. In this paper, we propose a content-based publish/subscribe framework over DHT (Distributed Hash Table) based peer to peer networks to address above design issues. We have utilized the heterogeneity of nodes in terms of computing resources and uptime to construct a two-tier DHT. The nodes in the upper tier are termed as super nodes that have high computing resources and better uptime. Only these super nodes are used to store subscription and publication metadata and act as rendezvous nodes for them. We construct a domain ontology based concept neighborhood overlay of these rendezvous nodes. Further, these nodes are also used to cache popular contents and metadata for improved lookup efficiency. Our proposal has limited effect of high churn conditions as rendezvous nodes have considerably higher uptime. We demonstrate our scheme based on an ontology used by ACM for classification of its publications. We compared our approach with Ferry, a popular content-based publish subscribe framework over DHT with respect to performance under churn, routing traffic and notification efficiency. Simulation results indicate that our scheme performs well compared to Ferry in these aspects.	code;distributed hash table;experiment;expressive power (computer science);lookup table;multitier architecture;ontology (information science);peer-to-peer;publish–subscribe pattern;routing;simulation;uptime	Mayank Pandey;Banshi Dhar Chaudhary	2011	2011 IEEE International Conference on Advanced Information Networking and Applications	10.1109/AINA.2011.58	computer science;database;semantics;metadata;world wide web;computer network	HPC	-12.556267698731014	74.0987241680394	74367
f1ad54f0465dc022c5ac16478c9b53c845db2071	distributed multimedia content analysis with mapreduce	parallel computing mapreduce distributed video analysis face detection;video signal processing;parallel programming;node cluster distributed multimedia content analysis content based video analysis mapreduce programming model apache hadoop mapreduce framework job scheduling analysis video data distribution face detection visual content analysis task performance evaluation video content processing video data distribution method;video signal processing parallel programming public domain software scheduling;public domain software;scheduling;streaming media face detection multimedia communication distributed databases benchmark testing computational modeling face	This paper introduces a scalable solution for distributing content-based video analysis tasks using the emerging MapReduce programming model. Scalable and efficient solutions are needed for this type of tasks, as the number of multimedia content is growing at an increasing rate. We present a novel implementation utilizing the popular Apache Hadoop MapReduce framework for both analysis job scheduling and video data distribution. We employ face detection as a case example because it represents a popular visual content analysis task. The main contribution of this paper is the performance evaluation of distribution models for video content processing in various configurations. In our experiments, we have compared the performance of our video data distribution method against two alternatives solutions on a seven node cluster. Hadoop's performance overhead in video content analysis was also evaluated. We found Hadoop to be a data efficient solution with minimal computational overhead for the face detection task.	apache hadoop;digital video;experiment;face detection;job scheduler;mapreduce;overhead (computing);performance evaluation;programming model;scalability;scheduling (computing);video content analysis	Arto Heikkinen;Jouni Sarvanko;Mika Rautiainen;Mika Ylianttila	2013	2013 IEEE 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)	10.1109/PIMRC.2013.6666755	real-time computing;computer science;theoretical computer science;operating system;distributed computing;public domain software;scheduling	Arch	-15.827677088338477	62.025079398638916	74860
59d1de258825c37ef8e10404aebb527995a42f06	autonomous data replication using q-learning for unstructured p2p networks	data sharing;resource discovery;peer to peer network;autonomous data replication;availability;routing;resource allocation;search algorithm;q learning;data replication;data engineering;peer to peer system;peer to peer computing availability routing educational institutions data engineering bandwidth robustness redundancy computer applications computer networks;computer applications;computer networks;redundancy;network connectivity;indexation;resource allocation peer to peer computing replicated databases;bandwidth;robustness;data sharing autonomous data replication q learning resource discovery unstructured peer to peer network resource allocation;p2p networks;peer to peer computing;replicated databases;unstructured peer to peer network	Resource discovery is an important problem in unstructured peer-to-peer networks as there is no centralized index where to search for information about resources. The solution for the problem is to use a search algorithm that locates the resources based on the local information about the network. Efficient data sharing in a peer-to-peer system is complicated by uneven node failure, unreliable network connectivity and limited bandwidth. A well-known technique for improving availability is replication. If multiple copies of data exist on independent nodes, then the chances of at least one copy being accessible are increased. Replication increases robustness. In this paper, we present a novel technique based on Q-learning for replicating objects to other nodes.	centralized computing;peer-to-peer;q-learning;replication (computing);robustness (computer science);search algorithm	Sabu M. Thampi;K. Chandra Sekaran	2007	Sixth IEEE International Symposium on Network Computing and Applications (NCA 2007)	10.1109/NCA.2007.11	availability;routing;information engineering;resource allocation;computer science;distributed computing;redundancy;computer applications;world wide web;bandwidth;q-learning;replication;robustness;computer network;search algorithm	Embedded	-12.596458925850122	73.19752134296417	74870
04a49d5deb9711d285f1464f41a279b63e58d68a	the utilization bound of static-priority preemptive partitioned multiprocessor scheduling is 50%	preemptive scheduling;multiprocessors;partitioning;static priority scheduling;real time scheduling;bin packing algorithms;article	This paper studies static-priority preemptive scheduling on a multiprocessor using partitioned scheduling. We propose a new scheduling algorithm and prove that if the proposed algorithm is used and if less than 50% of the capacity is requested then all deadlines are met. It is known that for every static-priority multiprocessor scheduling algorithm, there is a task set that misses a deadline although the requested capacity is arbitrary close to 50%.	algorithm;multiprocessing;multiprocessor scheduling;scheduling (computing)	Björn Andersson	2011	J. Embedded Computing	10.3233/JEC-2009-0107	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;foreground-background;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;preemption;least slack time scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling;i/o scheduling;proportionally fair	Embedded	-10.87389875383764	61.02003539059502	74911
a8f2a473ece4d4a5fae3b66dd2954e7f82762d96	tractable real-time schedulability analysis for mode changes under temporal isolation	analytical models;protocols;complexity theory;scheduling computational complexity multimedia computing;real time systems servers concrete complexity theory analytical models protocols timing;real time;schedulability analysis;multimedia computing;servers;computational complexity;scheduling;real time scheduling;polynomial time;analytical model;pseudo polynomial time complexity tractable real time schedulability analysis temporal isolation real time multimedia subsystem resource execution mode application execution mode timing constraints time efficient multimode schedulability analysis technique application only mode changes;concrete;real time systems;timing;time constraint	Real-time multimedia subsystems often require support for switching between different resource and application execution modes. To ensure that timing constraints are not violated during or after a subsystem changes mode, real-time schedulability analysis is required. However, existing time-efficient multi-mode schedulability analysis techniques for application-only mode changes are not appropriate for subsystems that require changes in the resource execution behavior (e.g., processors with dynamic power modes). Furthermore, all existing multi-mode schedulability analysis that handles both resource and application mode changes is highly exponential and not scalable for subsystems with a moderate or large number of modes. We address the lack of tractable schedulability analysis for such subsystems by proposing a model for characterizing multiple resource and application modes and by deriving a sufficient schedulability test that has pseudo-polynomial time complexity. Simulation results show that our proposed schedulability test, when compared with previously-proposed approaches, requires significantly less time and is just as precise.	algorithm;central processing unit;change request;cobham's thesis;control system;modal logic;polynomial;pseudo-polynomial time;reachability;real-time clock;real-time transcription;scalability;scheduling (computing);scheduling analysis real-time systems;simulation;temporal isolation;time complexity	Nathan Fisher;Masud Ahmed	2011	2011 9th IEEE Symposium on Embedded Systems for Real-Time Multimedia	10.1109/ESTIMedia.2011.6088519	time complexity;communications protocol;parallel computing;real-time computing;concrete;computer science;operating system;distributed computing;computational complexity theory;scheduling;server;worst-case execution time	Embedded	-8.890010646826978	61.08536309859496	74963
02895cf5831ea755e18752512349a25be389cab6	addressing resource fragmentation in grids through network-aware meta-scheduling in advance	computers;resource utilization;heterogeneous computing;heterogeneous computing resource;processor scheduling;resource allocation;resource management;usa councils;task analysis grid computing quality of service resource allocation scheduling;qos;task scheduling grid resource fragmentation network aware meta scheduling heterogeneous computing resource quality of service qos job scheduling job allocation resource utilization rescheduling;computer architecture;smoothing methods;scheduling;task analysis;network aware meta scheduling;rescheduling;task scheduling;quality of service;grid computing;job scheduling;quality of service resource management processor scheduling usa councils smoothing methods computer architecture computers;grid resource fragmentation;job allocation	Grids are made of heterogeneous computing resources geographically dispersed where providing Quality of Service (QoS) is a challenging task. One way of enhancing the QoS perceived by users is by performing scheduling of jobs in advance, since reservations of resources are not always possible. This way, it becomes more likely that the appropriate resources are available to run the job when needed. One drawback of this scenario is that fragmentation appears as a well known effect in job allocations into resources and becomes the cause for poor resource utilization. So, a new technique has been developed to tackle fragmentation problems, which consists of rescheduling already scheduled tasks. To this end, some heuristics are implemented to calculate the intervals to be replanned and to select the jobs involved in the process. Moreover, another heuristic is implemented to put rescheduled jobs as close together as possible to minimize the fragmentation. This technique has been tested using a real test bed.	fork (software development);fragmentation (computing);heterogeneous computing;heuristic (computer science);job stream;meta-scheduling;quality of service;scheduling (computing);testbed;windows task scheduler	Luis Tomás;Carmen Carrión;María Blanca Caminero;Agustín C. Caminero	2011	2011 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing	10.1109/CCGrid.2011.75	parallel computing;real-time computing;quality of service;computer science;resource management;operating system;distributed computing	HPC	-17.885577201841585	61.97165810470156	75147
72ed40fac2f1394c6b078dfac9a5d4d910d05f0c	an adaptive scheduler framework for complex workflow jobs on grid systems	job rank jr backfilling;resource allocation;job rank jr match making;grid computing;job scheduling;job workflow	Grid Computing provides sharing of geographically distributed resources among large scale complex applications. Due to dynamic nature of resources in grid, there is a need of highly efficient job scheduling and resource management policies in grid. A novel Grid Resource Scheduler GRS is proposed to effectively utilize the available resources in Grid. Proposed GRS contributes, an optimal job scheduling algorithm on Job Rank-Backfilling policy and a resource matching algorithm based on ranking of resources with best fit allocation model. Performance of GRS is measured by considering a web based BLAST algorithm-a bioinformatics application. GRS aims in reducing; Makespan of the job workflow, execution time of varied size jobs, response time of the submitted jobs and overhead of using the system. It also considers improving the utilization factor and throughput of the available heterogeneous resources in grid. The experimental results prove that proposed grid scheduler framework performs better when evaluated against widely used First Come First Serve FCFS, Shortest Job First SJF and Minimum Time to Due Date MTTD scheduling strategies.	scheduling (computing)	G. M. Siddesh;K. G. Srinisas	2012	IJDST	10.4018/jdst.2012100106	real-time computing;resource allocation;computer science;job scheduler;operating system;database;distributed computing;job queue;grid computing	HPC	-17.848701519219198	62.12482918409719	75339
b65891300934d12a3832576166441ed126834731	linear loss networks	linear loss networks;60k25;asymptotic properties;critical load;throughput	This paper investigates theoretical properties of throughput and cost in linear loss networks. The maximum throughput of the network with exponential service times is derived and the arrival process that maximizes throughput, given a fixed arrival rate, is established. For general service times, an asymptotically critical loading regime is identified such that the probability of an arbitrary customer being lost is strictly within (0,1) as the network size increases. This regime delivers throughput comparable to the maximum at a relatively low network cost. The paper establishes the asymptotic throughput and network cost under this critical loading.	maximum throughput scheduling;queueing theory;time complexity	Petar Momcilovic;Mark S. Squillante	2011	Queueing Syst.	10.1007/s11134-011-9230-5	mathematical optimization;throughput;real-time computing;computer science;maximum throughput scheduling;distributed computing	Metrics	-7.163938655171545	73.43926054191398	75399
279f304e267d9c361f273225ae25515e4b44a6e5	resource allocation to conserve energy in distributed computing	sensibilidad contexto;energy conservation;gestion energia;distributed system;economies d energie;haute performance;systeme reparti;context aware;ahorros energia;economic sciences;nova;resource allocation;simulation;distributed computing;node performance;research repository;university of newcastle;grid;ciencias economicas;sistema repartido;gestion energie;energy consumption;rejilla;consommation energie;alto rendimiento;grille;calculo repartido;energy savings;sciences economiques;asignacion recurso;sensibilite contexte;allocation ressource;grid computing;high performance;calcul reparti;institutional repository;node power;consumo energia;energy management;research online	Energy consumption is an issue in grid computing. There has been substantial research into grid resource allocation, but little research on energy aware resource allocation. We propose that altering the resource allocation mechanism to incorporate node power and performance data can make a substantial difference to both the time taken to execute tasks and the energy consumed by the grid. This paper examines the use of three simple economic resource allocation mechanisms through simulation. We discover that different mechanisms perform better under different circumstances, and that changing the resource allocation mechanism to incorporate the power and performance information of individual nodes can result in a substantial difference to the time taken to execute tasks, and over time can make a marked difference to the total energy consumption of the grid resource.	distributed computing;grid computing;simulation	Timothy M. Lynar;Ric D. Herbert;Simon;William J. Chivers	2011	IJGUC	10.1504/IJGUC.2011.039976	simulation;energy conservation;telecommunications;resource allocation;computer science;distributed computing;resource allocation;nova;grid;grid computing;time allocation;energy management	HPC	-13.390048165520668	64.42218421191225	75446
ca3e6e965ce5b9e8660f002e2f4d8aed07d9df6a	protecting clock synchronization	elektroteknik och elektronik;electrical engineering electronic engineering information engineering	Nowadays, industrial networks are often used for safety-critical applications with real-time requirements. Such applications usually have a time-triggered naturewithmessage scheduling as a core property. Scheduling requires nodes to share the samenotion of time, that is, to be synchronized. Therefore, clock synchronization is a fundamental asset in real-time networks. However, since typical standards for clock synchronization, for example, IEEE 1588, do not provide the required level of security, it raises the question of clock synchronization protection. In this paper, we identify a way to break synchronization based on the IEEE 1588 standard, by conducting a man-in-the-middle (MIM) attack followed by a delay attack. A MIM attack can be accomplished through, for example, Address Resolution Protocol (ARP) poisoning. Using the AVISPA tool, we evaluate the potential to perform a delay attack using ARP poisoning and analyze its consequences showing both that the attack can, indeed, break clock synchronization and that some design choices, such as a relaxed synchronization condition mode, delay bounding, and using knowledge of environmental conditions, can make the network more robust/resilient against these kinds of attacks. Lastly, a Configuration Agent is proposed to monitor and detect anomalies introduced by an adversary performing attacks targeting clock synchronization.		Elena Lisova;Marina Gutiérrez;Wilfried Steiner;Elisabeth Uhlemann;Johan Åkerberg;Radu Dobrin;Mats Björkman	2016	J. Electrical and Computer Engineering	10.1155/2016/6297476	clock synchronization;real-time computing;telecommunications;computer science;engineering;distributed computing;data synchronization;synchronization;computer security;computer network	Embedded	-6.594613883900052	69.96175083764558	75884
b97bdbd33ac62637de81381bf403a9146f5864fe	performance characterization on handling large-scale partitionable workloads on heterogeneous networked compute platforms		Multi-installment scheduling (MIS) has shown great effectiveness in minimizing the processing time for large-scale partitionable workloads. To derive an optimal MIS strategy, one has to explicitly determine optimal numbers of installments and processors. Existing studies tend to solve this problem by treating the influence of number of installments (and processors) w.r.t processing time as time-continuous functions and taking the derivative of these functions to determine the optimal values, which may lead to invalid solutions. In this paper, we employ periodic multi-installment scheduling (P-MIS) models for homogeneous and heterogeneous single-level tree networks. Using these models we make the following significant contributions. First, we derive a closed-form solution for an optimal number of installments based on a given network size and a fixed load distribution sequence. Second, we propose a heuristic algorithm for determining an optimal number of processors by first proving several important intermediate lemmas and theorems. Third, for heterogeneous systems, we propose a genetic algorithm to determine an optimal load distribution sequence. Finally, we conduct various experiments to illustrate the effectiveness of the proposed algorithms and perform rigorous analysis on the influence of load distribution sequence on processing time, on the basis of which a practical advice for determining a near-optimal load distribution sequence is given.	central processing unit;disk partitioning;experiment;genetic algorithm;heuristic (computer science);load balancing (computing);multi-level cell;scheduling (computing)	Xiaoli Wang;Bharadwaj Veeravalli	2017	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2017.2693149	real-time computing;computer science;periodic graph (geometry);genetic algorithm;scheduling (computing);homogeneous;heuristic (computer science);distributed computing	DB	-13.12503375097943	61.366949224004905	76313
fbbcd63bb0526f31617dc2da1c65c5e25a1703aa	fault tolerance task execution through cooperative computing in grid	resource scheduling;fault tolerance;grid service;cooperative computing;service reliability	To achieve fault tolerant task execution in grid, cooperative computing system (CCS) is proposed in this paper. Grid resources with similar statistical characteristics constitute the computing nodes in CCS. CCS executes the allocated task, considered as its primary task, by organizing the computing nodes as active and active-standby. At a moment of time, one of the node acts as active node to execute the task whereas rest of the nodes act as active-standby to provide execution backup to the task. Computing nodes in CCS may fail during task execution due to the failure/exit of their corresponding resources. To maintain the fault tolerant ability of CCS, a failed node is repaired dynamically by replacing its corresponding resource with alternative matching resource from grid. The number of computing nodes in CCS is decided by optimizing the service reliability with respect to the execution overhead of the primary task. Resource usage is optimized in CCS by overloading the primary task at each active-standby node with a low priority secondary task. Active-standby nodes execute their low priority secondary tasks concurrently to providing execution backup to the primary task. Service reliability, system throughput and task delay is observed in the simulation experiments to explore the fault tolerant ability of CCS. A task set of 500 grid tasks is repeatedly executed by varying task duration and rate of resource failure. Simulation results show that CCS outperforms the existing fault tolerant approaches being used in grid. In CCS, fault tolerant task execution is achieved without compromising on account of resource utilization as well.	fault tolerance	Major Singh Goraya;Lakhwinder Kaur	2013	Parallel Processing Letters	10.1142/S0129626413500035	fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing	HPC	-17.284782603046647	60.818995711032585	77281
233c7b2aa05ed9b5e18302bad6bf2425766a51f1	delay-tolerant bulk data transfers on the internet	and forward;95 percentile pricing;scientific data;data center;delay tolerant networks;col;content distribution;delay tolerant network;industrial application;distributed work;high definition;data transfer	Many emerging scientific and industrial applications require transferring multiple Tbytes of data on a daily basis. Examples include pushing scientific data from particle accelerators/colliders to laboratories around the world, synchronizing data-centers across continents, and replicating collections of high definition videos from events taking place at different time-zones. A key property of all above applications is their ability to tolerate delivery delays ranging from a few hours to a few days. Such Delay Tolerant Bulk (DTB) data are currently being serviced mostly by the postal system using hard drives and DVDs, or by expensive dedicated networks. In this work we propose transmitting such data through commercial ISPs by taking advantage of already-paid-for off-peak bandwidth resulting from diurnal traffic patterns and percentile pricing. We show that between sender-receiver pairs with small time-zone difference, simple source scheduling policies are able to take advantage of most of the existing off-peak capacity. When the time-zone difference increases, taking advantage of the full capacity requires performing store-and-forward through intermediate storage nodes. We present an extensive evaluation of the two options based on traffic data from 200+ links of a large transit provider with PoPs at three continents. Our results indicate that there exists huge potential for performing multi Tbyte transfers on a daily basis at little or no additional cost.	byte;daisy digital talking book;delay-tolerant networking;hard disk drive;internet transit;postal;scheduling (computing);store and forward;transmitter	Nikolaos Laoutaris;Georgios Smaragdakis;Pablo Rodriguez;Ravi Sundaram	2009	IEEE/ACM Transactions on Networking	10.1145/1555349.1555376	data center;real-time computing;simulation;computer science;operating system;delay-tolerant networking;statistics;computer network;data		-15.049796333779025	72.20609387356123	77291
2c4bcd1a9063440c33999947bedc4494baacaeaf	kstreams: kernel support for efficient data streaming in proxy servers	cpu scheduling;forward model;data stream;resource manager;network capacity;data distribution;media proxy;content delivery;media streaming;overlay network;quality of service;proxy server	Growth in broadband connectivity is making media streaming applications increasingly popular. For scalability, media is streamed across sets of proxy servers embedded in overlay networks, where the quality of delivered content depends both on available network capacities across overlay nodes and the capabilities of proxy servers. This paper addresses proxy server performance for media streaming and for the delivery of live media content. Our approach to efficient content delivery is to develop a set of kernel-level data streaming abstractions, termed KStreams. Compared to user-level solutions, KStreams (1) offers improved performance for the multiple data forwarding models commonly used in data distribution networks, (2) reduces per stream overheads by eliminating unnecessary system calls and memory copying, and (3) offers improved levels of predictability for the Quality of Service (QoS) experienced by media streams due to its use of non-preemptable kernel-level threads and its ability to directly interact with the CPU scheduler and other kernel-level resource managers. (4) Once initiated, KStreams operates without further involvement of and asynchronously to applications, permitting them to carry out other tasks.	central processing unit;digital distribution;embedded system;kernel (operating system);operand forwarding;overlay network;proxy server;quality of service;scalability;scheduling (computing);server (computing);streaming media;system call;user space	Jiantao Kong;Karsten Schwan	2005		10.1145/1065983.1066020	reverse proxy;real time streaming protocol;real-time computing;overlay network;quality of service;computer science;resource management;operating system;scheduling;world wide web;computer network	OS	-17.63712586742667	73.25187274161196	77356
25db6fd23c9935b9b3eb4e1d56d26865a1859e98	dds: distributed decision strategy based on switch migration towards sdn control plane		The introduction of distributed control plane has improved the scalability and reliability of software defined networking (SDN), and multi-controller could divide the entire network into several subdomains. However, dynamic traffic could cause uneven load distribution among individual controllers. Furthermore, the static configuration between switch and controller exacerbates this imbalance. Real-time migration of switches from controllers that are overloaded to those that are underutilized could be a solution to deal with the unbalanced distribution of traffic. Therefore, such migration must be performed with a well-defined strategy to fully utilize the available resource of controllers. In this paper, we propose Distribution Decision Strategy (DDS) based on switch migration in the multi-domain SDN network. Firstly, we collect network information and construct distributed migration decision domains based on the load condition of controllers. Then, we choose the migrating switches according to the selection probability, and the target controller is determined by optimizing three network costs, including data collection, switch migration and controller state synchronization. Finally, we set the migrating countdown to ensure the ordered switch migration. Results are demonstrated by several numerical simulations.	computer simulation;control plane;decision theory;disk controller;distributed control system;load balancing (computing);network switch;numerical analysis;real-time transcription;scalability;software-defined networking;unbalanced circuit	Jianhui Zhang;Tao Hu;Wei Zhao;Dan Qiao	2017	2017 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)	10.1109/CyberC.2017.43	process control;real-time computing;data collection;scalability;control theory;software-defined networking;routing control plane;synchronization;computer science;load management	HPC	-18.147485042802305	67.85497238006893	77592
5f94cb050c690e8588367c7738749d93217525f7	efficient fitting of long-tailed data sets into hyperexponential distributions	internet long tailed data sets data set partitioning network capacity planning queueing system analysis expectation maximization algorithm hyperexponential distribution fitting results data set fitting analytic tools queueing systems em algorithm;exponential distribution;telecommunication network planning;queueing theory;long tail;internet distribution functions queueing analysis maximum likelihood estimation optimization methods computer science educational institutions process design capacity planning design engineering;internet;expectation maximization;queueing system;em algorithm;queueing theory exponential distribution telecommunication network planning internet;divide and conquer	We propose a new technique for fitting long-tailed data sets into hyperexponential distributions. The approach partitions the data set in a divide and conquer fashion and uses the Expectation-Maximization (EM) algorithm to fit the data of each partition into a hyperexponential distribution. The fitting results of all partitions are combined to generate the fitting for the entire data set. The new method is accurate and efficient and allows one to apply existing analytic tools to analyze the behavior of queueing systems that operate under workloads that exhibit long-tail behavior, such as queues in Internet-related systems.	expectation–maximization algorithm;long tail	Alma Riska;Vesselin Diev;Evgenia Smirni	2002		10.1109/GLOCOM.2002.1189083	mathematical optimization;expectation–maximization algorithm;computer science;theoretical computer science;layered queueing network;statistics	ML	-10.137949623708073	67.8671025335711	77712
191d6eeaa18ad73fd55c38cbc3873596a4690a8d	parallel scheduling algorithm based on complex coloring for input-queued switches		This paper explores the application of a new algebraic method of edge coloring, called complex coloring, to the scheduling problems of input queued switches. The proposed distributed parallel scheduling algorithm possesses two important features: optimality and rearrangeability. Optimality ensures that the algorithm always returns a proper coloring with the minimum number of required colors, and rearrangeability allows partially re-coloring the existing connection patterns if the underlying graph only changes slightly. The running time of the proposed scheduling algorithm is on the order of O(log N) per frame, and the amortized time complexity, the time to compute a matching per timeslot, is only O(logN). The scheduling algorithm is highly robust in the face of traffic fluctuations. Since the higher the variable density, the higher the efficiency of the variable elimination process, complex coloring provides a natural adaptive solution to non-uniform input traffic patterns. The proposed scheduling algorithm for packet switching can achieve nearly 100% throughput.	algorithm;amortized analysis;color;directed graph;edge coloring;graph coloring;network packet;network switch;packet switching;scheduling (computing);throughput;time complexity;variable elimination	Lingkang Wang;Tong Ye;Tony T. Lee;Weisheng Hu	2016	CoRR		fair-share scheduling;mathematical optimization;dynamic priority scheduling;rate-monotonic scheduling;theoretical computer science;mathematics;distributed computing	Embedded	-5.038718522149845	71.10181324771382	77761
a5ebba40a4a4983ca2199c7301d2358cd0ebbbe1	handling timing constraints violations in soft real-time applications as exceptions	multimedia;soft real time;exception handling	In this paper, an exception-based programming paradigm is envisioned to deal with timing constraints violations occurring in soft real-time and multimedia applications written in the C language. In order to prove viability of the approach, a mechanism allowing to use such paradigm has been designed and implemented as an open-source library of C macros making use of the standard POSIX API (a few Linuxspecific optimizations are also briefly discussed). The proposed approach has been validated by modifying mplayer, one of the most widely used multimedia player for Linux, so as to use the introduced library. An extensive experimental evaluation has been made, both when running the player alone and when mixing it with a workload of other synthetic real-time applications. In the latter case, different scheduling policies have been used, including both standard prioritybased ones as available on the mainline Linux, and an experimental deadline-based one available as a separate patch. The shown results demonstrate how the exception-based paradigm is effective in improving the audio/video delay exhibited by the player achieving a superior performance and a dramatically better Quality of Experience as compared to the original heuristic frame-dropping mechanism of the player.	application programming interface;control flow;earliest deadline first scheduling;embedded system;exception handling;heuristic;linux;mplayer;oml;open-source software;posix;performance evaluation;programming paradigm;real-time clock;real-time computing;real-time transcription;requirement;scheduling (computing);synthetic intelligence;the times;user experience	Tommaso Cucinotta;Dario Faggioli	2012	Journal of Systems and Software	10.1016/j.jss.2011.11.1021	exception handling;real-time computing;simulation;computer science;operating system;software engineering;programming language	Embedded	-10.690378267476456	64.4275399814908	78394
406d8d5faf102876bdbd7a11a8ef70922c68f5e1	cuckoo bags for exploring multikey data	network monitoring;behavior modeling;situational awareness;network traffic;indexation;situation awareness;hash function;data structure;communication pattern	As the transition from IPv4 to hybrid IPv4/IPv6 networks begins, our structures for representing IP addresses for analysis are lagging behind. There is a need for tools that can develop behavioral models of network traffic that include communications patterns among hosts. This work introduces the CuBag data structure and tools for maintaining sets indexed by IPv4 and IPv6 addresses in the same structure. The current tools, rwset and rwbag, in the SiLK tool suite use pointer structures developed for IPv4 but have no support for IPv6 addresses. CuBag keys can contain multiple SiLK record fields, including IPv4 and IPv6 addresses. They use multiple hash functions for key insertion and lookup in constant time. We describe CuBags and illustrate their use with two small case studies.	central processing unit;cobham's thesis;cuckoo hashing;data structure;hash function;lookup table;multi-core processor;network packet;network traffic control;pointer (computer programming);silk;the cuckoo's egg;time complexity	John McHugh;Teryl Taylor;Jeff Janies	2010		10.1145/1852666.1852687	computer science;data mining;world wide web;computer security	Metrics	-7.950589317202281	66.8118795259108	78554
3f668741f6fe97dce74e8666b382a5fa69665f7d	optimization of flow record handling by applying a decentralized cooperative semantic caching approach	p2p system;cache storage;protocols;groupware;netflow based range queries flow record handling optimization decentralized cooperative semantic caching approach ip traffic cisco s netflow system data access data transfers centralized flow based storage solution nmcoopsc network management coopsc;range query;semantics servers probes indexes protocols time factors;cooperative caching;query processing;semantics;probes;telecommunication traffic cache storage computer network management groupware ip networks query processing;database caching;indexes;telecommunication traffic;servers;time factors;indexation;computer network management;time factor;ip networks;netflow records;network management;data transfer;p2p systems;p2p systems netflow records database caching	Analyzing IP traffic is an important task on which many network management applications are based. Cisco's Net-Flow system is one of the most widely used approaches for accomplishing a measurement and collection of flow records, needed to analyze traffic. Working with NetFlow means to involve very large amounts of data, while the collection, storing, and enabling of analyzers demands the access to this data in the fastest possible manner. Thus, this paper addresses this challenging task and presents a newly developed cooperative caching approach (CoopSC) that can be used to improve access time and data transfers between the centralized flow-based storage solution and those analyzers in operation. Such an improvement can positively influence the performance of flow-based solutions. Therefore, this approach NMCoopSC (Network Management CoopSC) has been validated, and experiments show that NMCoopSC improves the performance of NetFlow-based range queries.	access time;cache (computing);centralized computing;database server;experiment;fastest;peer-to-peer;range query (data structures);response time (technology);sql;server (computing)	Andrei Vancea;Laurent d'Orazio;Burkhard Stiller	2012	2012 IEEE Network Operations and Management Symposium	10.1109/NOMS.2012.6211905	network management;database index;communications protocol;range query;computer science;operating system;database;semantics;world wide web;computer security;server;computer network	Metrics	-16.778765748904597	68.54362099211959	79427
a3383c3988a08d85d0a8e1d40b3c2362422b80c4	a fast regular expression matching engine for nids applying prediction scheme	regular expression matching engine throughput xilinx virtex 7 fpga chip nids rule sets prediction success rate dfa matching circuit dfa matching engine next state prediction strategy dfa states memory bandwidth matching speed dfa memory storage space compression state blowup problem memory consumption deterministic finite automata algorithm networking intrusion detection systems dpi techniques deep packet inspection techniques nids;clocks clustering algorithms sparse matrices engines compression algorithms pipelines encoding;internetworking computer network security data compression field programmable gate arrays	Regular expression matching is considered important as it lies at the heart of many networking applications using deep packet inspection (DPI) techniques. For example, modern networking intrusion detection systems (NIDSs) typically accomplish regular expression matching using deterministic finite automata (DFA) algorithm. However, DFA suffers from the high memory consumption for the state blowup problem. Many algorithms have been proposed to compress the DFA memory storage space, meanwhile, they usually pay the price of low matching speed and high memory bandwidth. In this paper, we first propose an effective DFA compression algorithm by exploiting the similarity between DFA states. Then, we apply a next-state prediction strategy and present a fast DFA matching engine. Carefully designing the DFA matching circuit, we keep the prediction success rate by more than 99,5%, thus get a comparable matching speed with original DFA algorithm. On the side of memory consumption, experimental results show that with typical NIDS rule sets, our algorithm compressed the original DFA by more than 99%. Mapping this algorithm on Xilinx Virtex-7 FPGA chip, we get a throughput of more than 200Gbps.	algorithm;automata theory;bro;data compression;deep packet inspection;deterministic finite automaton;field-programmable gate array;finite-state machine;high memory;intrusion detection system;memory bandwidth;network packet;regular expression;snort;state transition table;throughput	Lei Jiang;Qiong Dai;Qiu Tang;Jianlong Tan;Binxing Fang	2014	2014 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2014.6912600	parallel computing;real-time computing;computer science;theoretical computer science;operating system	Embedded	-6.7526989210888155	66.64803663902357	79445
c7f710a6eac02a4827cd3acdca9d959c58eef2b0	efficient packet classification with a hybrid algorithm	packet forwarding;qos;hybrid algorithm;tuple space;search algorithm;quality of service	Packet classification categorizes incoming packets into multiple forwarding classes based on pre-defined filters. This categorization makes information accessible for quality of service or security handling in the network. In this paper, we propose a scheme which combines the Aggregate Bit Vector algorithm and the Pruned Tuple Space Search algorithm to improve the performance of packet classification in terms of speed and storage. We also present the procedures of incremental update. Our scheme is evaluated with filter databases of varying sizes and characteristics. The experimental results demonstrate that our scheme is feasible and scalable. key words: packet classification, network intrusion detection systems, firewalls, QoS, packet forwarding	aggregate function;bit array;categorization;database;firewall (computing);hybrid algorithm;incremental backup;intrusion detection system;network packet;quality of service;scalability;search algorithm;tuple space	Pi-Chung Wang	2009	IEICE Transactions		embedded system;quality of service;telecommunications;computer science;computer security;computer network	Metrics	-6.874160762451317	67.29120831288962	79576
b2e55f2260962817d0ef2fbf4c22c51743ac1555	tcam-based dfa deflation: a novel approach to fast and scalable regular expression matching	pattern matching deterministic automata finite automata;ternary content addressable memory regular expression matching intrusion detection worm detection traffic analysis worm fingerprints network traffic network system development nondeterministic finite automaton deterministic finite automaton;dangling nodes;ternary content addressable memory;worm fingerprints;random access memory;fiber amplifier;deterministic automata;minimum steiner tree;nondeterministic finite automaton;deterministic finite automaton;ions;distributed multicast;intrusion detection;worm detection;delay bounded multicast routing;the tree setup break problem;network traffic;pattern matching;regular expression matching;finite automata;traffic analysis;explosions;doped fiber amplifiers random access memory encoding pattern matching ions solids explosions;network system development;encoding;regular expression;doped fiber amplifiers;solids	Regular expression matching is the foundation of many network functions including intrusion detection, worm detection, traffic analysis and so on, where known patterns such as worm fingerprints are characterized using regular expressions and searched in network traffic for pattern match. As the quantity and diversity of known patterns keep increasing, regular expression pattern sets have rapidly grown in both size and complexity, while having to be matched in network traffic at accelerating wire speeds. Fast and scalable regular expression matching, therefore, is fundamental to the development of practical network systems.	fingerprint;intrusion detection system;network packet;network traffic control;pattern matching;regular expression;scalability;telecommunications access method;traffic analysis	Kunyang Peng;Qunfeng Dong;Min Chen	2011	2011 IEEE Nineteenth IEEE International Workshop on Quality of Service	10.1109/IWQOS.2011.5931323	intrusion detection system;redos;nondeterministic finite automaton;computer science;theoretical computer science;deterministic finite automaton;pattern matching;solid;distributed computing;finite-state machine;regular expression;encoding;computer network;ion	Visualization	-7.159748380946342	66.8612844263541	79725
aabb7b51a50443dc5cc0a58a13e920376f729512	on stability and performance of parallel processing systems	sistema fila espera;modelizacion;parallelisme;distributed system;systeme attente;database concurrency control;queueing network;systeme reparti;subadditive ergodic theory;multiprocessor;queuing system;queueing theory;sistema informatico;queueing networks;internal structure;computer system;asymptotic behavior;modelisation;computer architecture;parallelism;concurrency;sistema repartido;simultaneidad;paralelismo;architecture ordinateur;flexible manufacturing system;concurrency control;operating characteristic;precedence constraint;parallel computer;systeme informatique;arquitectura ordenador;queuing networks;point of view;multiprocesador;modeling;simultaneite informatique;concurrent process;stability theory;parallel processing;ergodic theory;multiprocesseur	The general problem of parallel (concurrent) processing is investigated from a queuing theoretic point of view. As a basic simple model, consider infinitely many processors that can work simultaneously, and a stream of arriving jobs, each carrying a processing time requirement. Upon arrival, a job is allocated to a processor and starts being executed, unless it is blocked by another one already in the system. Indeed, any job can be randomly blocked by any preceding one, in the sense that it cannot start being processed before the one that blocks it leaves. After execution, the job leaves the system. The arrival times, the processing times and the blocking structures of the jobs form a stationary and ergodic sequence. The random precedence constraints capture the essential operational characteristic of parallel processing and allow a unified treatment of concurrent processing systems from such diverse areas as parallel computation, database concurrency control, queuing networks, flexible manufacturing systems. The above basic model includes the G/G/1 and G/G/ ∞  queuing systems as special extreme cases. Although there is an infinite number of processors, the precedence constraints induce a queuing phenomenon, which, depending on the loading conditions, can lead to stability or instability of the system. In this paper, the condition for stability of the system is first precisely specified. The asymptotic behavior, at large times, of the quantities associated with the performance of the system is then studied, and the degree of parallelism, expressed as the asymptotic average number of processors that work concurrently, is computed. Finally, various design and simulation aspects concerning parallel processing systems are considered, and the case of finite number of processors is discussed. The results proved for the basic model are then extended to cover more complex and realistic parallel processing systems, where each job has a random internal structure of subtasks to be executed according to some internal precedence constriants.	blocking (computing);central processing unit;computation;computer multitasking;concurrency (computer science);concurrency control;concurrent computing;degree of parallelism;ergodic sequence;ergodicity;instability;job stream;parallel computing;parallel processing (dsp implementation);queueing theory;randomness;simulation;stationary process	Nicholas Bambos;Jean C. Walrand	1991	J. ACM	10.1145/103516.103520	ergodic theory;parallel processing;mathematical optimization;combinatorics;parallel computing;real-time computing;multiprocessing;systems modeling;concurrency;computer science;concurrency control;distributed computing;queue management system;stability theory;programming language;queueing theory;algorithm	Theory	-11.55878335574469	61.41344385263546	79914
4cc598e53c638d673caa5d4365fc9b9207c73f67	grid of segment trees for packet classification	tree data structures data structures grid computing;complexity theory;memory management;packet classification;predefined rules;grid of tries;application software;classification tree analysis switches data structures quality of service costs application software computer science ip networks monitoring multimedia communication;tree data structures;2 dimensional;gst;monitoring;data structures;backtracking operation;traditional algorithmic;multimedia communication;classification algorithms;got;ip networks;classification tree analysis;computer science;quality of service;grid of segment trees;switches;grid computing;data structure;gst packet classification predefined rules grid of tries got traditional algorithmic backtracking operation data structure grid of segment trees	Packet classification problem has received much attention and continued to be an important topic in recent years. In packet classification problem, each incoming packet should be classified into flows according to a set of pre-defined rules. Grid-of-tries (GoT) is one of the traditional algorithmic schemes for solving 2-dimensional packet classification problem. The advantage of GoT is that it uses the switch pointers to avoid backtracking operation during the search process. However, the primary data structure of GoT is base on binary tries. The traversal of binary tries decreases the performance of GoT due to the heights of binary tries are usually high. In this paper, we propose a scheme called GST (Grid of Segment Trees). GST modifies the original GoT by replacing the binary tries with segment trees. The heights of segment trees are much shorter than those of binary tries. As a result, the proposed GST can inherit the advantages of GoT and segment trees to achieve better performance. Experiments conducted on three different kinds of rule tables show that our proposed scheme performs better than traditional schemes, such as hierarchical tries and grid-of-tries.	algorithm;backtracking;data structure;experiment;network packet;rule 184;segment tree;simpson's rule;tree traversal;trie	Yeim-Kuan Chang;Yung-Chieh Lin;Chen-Yu Lin	2010	2010 24th IEEE International Conference on Advanced Information Networking and Applications	10.1109/AINA.2010.38	two-dimensional space;application software;quality of service;data structure;telecommunications;network switch;computer science;theoretical computer science;operating system;data mining;database;tree;programming language;computer security;grid computing;computer network;memory management	Metrics	-6.676132791632454	67.8105881439073	79943
912a33ea01867541c36cc2e35df8ef54eeb78ade	new voter design enabling hot redundancy for asynchronous network nodes	ports computers switches routing field programmable gate arrays registers hardware payloads;fault injection experiments voter design hot redundancy asynchronous network nodes asynchronous network stream voting flow controlled networks automatic incoming data streams synchronisation failure mode handling streaming applications comparator redundant channels routing switch broadcast mechanism stand alone operation;telecommunication network routing broadcast channels computer network reliability ip networks network on chip redundancy switching networks synchronisation telecommunication congestion control	In this paper, a novel voter design is presented which allows the voting of asynchronous network streams in flow-controlled networks. The voter synchronises incoming data streams automatically and is able to handle failure modes that typically occur in streaming applications. The voter degrades to a comparator if one of the redundant channels has failed and reintegrates the channels once they are functional again. While the voter is mainly intended to be connected to a routing switch of the network, it also comprises a broadcast mechanism that enables a stand-alone operation. The design has been successfully implemented in hardware and evaluated by means of fault injection experiments.	broadcast domain;central processing unit;comparator;experiment;failure cause;fault injection;multilayer switch;network architecture;routing	Felix Siegle;Tanya Vladimirova;Jørgen Ilstad;Omar Emam	2014	2014 NASA/ESA Conference on Adaptive Hardware and Systems (AHS)	10.1109/AHS.2014.6880154	embedded system;routing;real-time computing;overlay network;non-broadcast multiple-access network;telecommunications;computer science;distributed computing;computer network	EDA	-5.330650180628799	69.20328200956571	80014
4fd7da612907b213fd8826d55ff04f33221d159e	seedertrading: trading swarm capacity for improving content distribution	groupware;download performance;simulation;collaboration;content distribution;multiswarm collaboration;estimation;downlink;throughput downlink synchronization estimation collaboration steady state simulation;synchronization;trading swarm capacity;peer to peer computing;peer to peer computing groupware;seedertrading;multiswarm collaboration seedertrading trading swarm capacity content distribution surplus seeding capacity download performance;surplus seeding capacity;uniform distribution;throughput;steady state	A surplus seeding capacity is often observed in large swarms with many seeders while small swarms with few seeders suffer from low download performance. In this paper, we propose a multi-swarm collaboration approach, called textit{Seeder Trading} to improve overall content distribution performance by exploiting non-uniform distribution of seeders over swarms. In a nutshell, we enable the over-seeded swarms to share their surplus seeding capacity with the under-seeded swarms. To realize the Seeder Trading, we resolve several issues including estimation of swarm capacity, selection of swarms to be matched, and seeder trading across the selected swarms. Our extensive measurement shows that 12.9% of under-seeded swarms can achieve their maximum download throughput by utilizing the surplus seeding capacity. Simulation results show that the under-seeded swarms can improve the download performance by over 20% while retaining the content distribution performance of over-seeded swarms. We also show that the trading seeding capacity across swarms can be done within 60 seconds.	bittorrent;digital distribution;download;overhead (computing);simulation;swarm robotics;throughput	HyunYong Lee;Masahiro Yoshida;Akihiro Nakao	2011	2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum	10.1109/IPDPS.2011.313	real-time computing;simulation;engineering;distributed computing	Arch	-15.316653300427639	73.85186536116734	80024
610cb23c157fe5df32f51304209848a5d4fac77e	dynamic web pages: performance impact on web servers	empirical study;measurement techniques;computacion informatica;web pages;performance evaluation;benchmark;regression model;regression statistics;ciencias basicas y experimentales;web server performance;world wide web;web server;grupo a;experimental measurement;multivariate linear regression	The World Wide Web has experienced phenomenal growth over the past few years, placing heavy load on Web servers. Today’s Web servers also process an increasing number of requests for dynamic pages, making server load even more critical. The performance of Web servers delivering static pages is well studied and well understood. However, there has been little analytic or empirical study of the performance of Web servers delivering dynamic pages. This paper focuses on experimentally measuring and analyzing the performance of the three dynamic Web page generation technologies: CGI, FastCGI and Servlets. In this paper, we present experimental results for Web server performance under CGI, Fast CGI and Servlets. Then, we develop a multivariate linear regression model and predict Web server performance under some typical dynamic requests. We find that CGI and FastCGI perform effectively the same under most low‐level benchmarks, while Servlets perform noticeably worse. Our regression model shows the same deficienc...	dynamic web page;web server	Bhupesh Kothari;Mark Claypool	2001	Internet Research	10.1108/10662240110365670	web service;static web page;web development;data web;web-based simulation;computer science;web api;web log analysis software;database;multimedia;world wide web;web server;application server;regression analysis;server	Metrics	-18.06315283654691	71.79464780094241	80052
9853b15aaad1beda2e925131b825dac51cee5d04	characterization of collaborative resolution in recursive dns resolvers		Recursive resolvers in the Domain Name System play a critical role in not only DNS’ primary function of mapping hostnames to IP addresses but also in the load balancing and performance of many Internet systems. Prior art has observed the existence of complex recursive resolver structures where multiple recursive resolvers collaborate in a “pool”. Yet, we know little about the structure and behavior of pools. In this paper, we present a characterization and classification of resolver pools. We observe that pools are frequently disperse in IP space, and some are even disperse geographically. Many pools include dual-stack resolvers and we identify methods for associating the IPv4 and IPv6 addresses. Further, the pools exhibit a wide range of behaviors from uniformly balancing load among the resolvers within the pool to proportional distributions per resolver.	recursion (computer science)	Rami Al-Dalky;Kyle Schomp	2018		10.1007/978-3-319-76481-8_11	computer network;ipv6 address;recursion;the internet;computer science;ipv4;load balancing (computing);resolver;domain name system	HPC	-11.387476253650165	74.15043165709794	80232
c2f8dab603e5629009a57bc81b1f8d9b5d67617f	approximate packet pre-filtering to accelerate pattern matching.	pattern matching	Intrusion detection system is a promising technique to improve Internet security. A daunting challenge in the design of this system is the requirement of simultaneous matching of hundreds to thousands of attack patterns at full wire speed. This paper presents a novel scheme to accelerate pattern matching by adding a prefilter to the exact pattern matching engines. This prefilter serves as a fast path for the majority incoming packets, which dramatically reduces the workload of exact pattern matching engines. Our prefilter checks each packet based on its header and content. To reduce matching complexity, the prefilter uses a much smaller set of representatives than the set of patterns. Our prefilter is false negative free, with a possible false positive rate, which can be reduced by increasing the representative length. Experiment results show that our prefilter has improved system throughput in the order of 100 times.	attack patterns;fast path;firewall (computing);high-throughput computing;internet security;intrusion detection system;network packet;pf (firewall);packet switching;pattern matching;string searching algorithm;throughput	Benfano Soewito;Ning Weng	2008			discrete mathematics;computer science;theoretical computer science;pattern matching;mathematics;distributed computing	Networks	-7.211005954694344	66.65832197158129	80263
1266f7599637e82ae6053f0a0b99d7ff1f3bb94b	scheduling grid tasks in face of uncertain communication demands	grid scheduling;optimisation;grid resource;uncertainty grid networks resource management task scheduling;availability;uncertainty;grid applications;fuzzy number;uncertainty proposals schedules estimation optimization linear programming availability;scheduling grid task;resource manager;resource management;fuzzy number scheduling grid task uncertain communication demand grid scheduling quality of service grid resource ipdt fuzzy scheduler grid application fuzzy optimization;fuzzy set theory;uncertain communication demand;estimation;scheduling fuzzy set theory grid computing optimisation quality of service;scheduling;grid networks;ipdt fuzzy scheduler;schedules;linear programming;linear program;optimization;grid application;task scheduling;quality of service;grid computing;proposals;fuzzy optimization	Grid scheduling is essential to Quality of Service provisioning as well as to efficient management of grid resources. Grid scheduling usually considers the state of the grid resources as well application demands. However, such demands are generally unknown for highly demanding applications, since these often generate data which will be transferred during their execution. Without appropriate assessment of these demands, scheduling decisions can lead to poor performance. Thus, it is of paramount importance to consider uncertainties in the formulation of a grid scheduling problem. This paper introduces the IPDT-FUZZY scheduler, a scheduler which considers the demands of grid applications with such uncertainties. The scheduler uses fuzzy optimization, and both computational and communication demands are expressed as fuzzy numbers. Its performance was evaluated, and it was shown to be attractive when communication requirements are uncertain. Its efficacy is compared, via simulation, to that of a deterministic counterpart scheduler and the results reinforce its adequacy for dealing with the lack of accuracy in the estimation of communication demands.	computation;e-science;experiment;fuzzy concept;fuzzy number;job shop scheduling;makespan;mathematical optimization;overhead (computing);provisioning;quality of service;real-time locating system;requirement;run time (program lifecycle phase);scheduling (computing);simulation;speedup	Daniel M. Batista;Nelson Luis Saldanha da Fonseca	2011	IEEE Transactions on Network and Service Management	10.1109/TNSM.2011.050311.100060	fixed-priority pre-emptive scheduling;availability;mathematical optimization;estimation;real-time computing;quality of service;uncertainty;schedule;computer science;linear programming;fuzzy number;resource management;distributed computing;fuzzy set;scheduling;grid computing	HPC	-18.55068458152871	62.672981166691116	80341
1eda630e09c0540006861bec8fc7d2fb34afc674	power-aware tcams for routing table lookup	ternary content addressable memory;routing protocols;routing;bismuth;tcam;indexes;power aware computing;load balancing algorithm power aware tcam ternary content addressable memories table lookup router design power aware architecture;table lookup content addressable storage power aware computing routing protocols;heuristic algorithms;ip networks;load balance;ip lookup;ip networks routing power demand indexes partitioning algorithms heuristic algorithms bismuth;tcam ip lookup routing table;power consumption;content addressable storage;table lookup;routing table;power demand;high power;partitioning algorithms	Ternary content addressable memories (TCAMs) give a simple and fast solution to IP lookups. However, the high power consumption in TCAMs limits the router design to fewer ports. In this paper, we propose an algorithm to partition prefixes in the routing table exactly and a power-aware architecture with two level TCAMs, index_TCAM and sub_TCAM. For the bursty access pattern, we propose a load-balancing algorithm to distribute the lookup traffic between buckets of sub_TCAM. For real routing tables and the given number (K) of buckets in sub_TCAM, the power consumption of our architecture is 9 percent +91 percent *(1/K) that of native TCAM.	algorithm;load balancing (computing);lookup table;router (computing);routing table;telecommunications access method;throughput	Weidong Wu;Dezhi Ji;Yu Lan;Tong Wu	2010	2010 IEEE/ACM Int'l Conference on Green Computing and Communications & Int'l Conference on Cyber, Physical and Social Computing	10.1109/GreenCom-CPSCom.2010.119	parallel computing;computer science;theoretical computer science;computer network	HPC	-5.805521104840301	66.92876641300943	80346
540c3528e5fa21821991184a02bc2b7b56e0d18d	multidimensional periodic scheduling model and complexity	digital signal processing;scheduling problem;high throughput	We discuss the multidimensional periodic scheduling problem, which originates from the design of high-throughput real-time digital signal processing systems. We introduce the concept of multidimensional periodic operations in order to cope with problems originating from loop hierarchies and explicit timing requirements. We present a model of the multidimensionalperiodic scheduling problem and show that this problem and two related sub-problems are NP-hard. Furthermore, we identify several special cases induced by practical situations. Some of these special cases are proven to be well-solvable. Finally, we present a sketch of a solution approach.	decision problem;digital signal processing;high-throughput computing;np-hardness;open-shop scheduling;real-time clock;requirement;scheduling (computing);throughput	Wim F. J. Verhaegh;Paul E. R. Lippens;Emile H. L. Aarts;Jef L. van Meerbergen;Albert van der Werf	1996		10.1007/BFb0024706	fair-share scheduling;high-throughput screening;fixed-priority pre-emptive scheduling;job shop scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;digital signal processing;two-level scheduling;maximum throughput scheduling;distributed computing;round-robin scheduling	Embedded	-9.850750469229338	62.04986241479706	80676
35fe6e35749f8bb79ce820dd1c0a404333d8d4fe	a unified resource scheduling approach on cluster computing systems	cluster computing		computer cluster	Jemal H. Abawajy;Sivarama P. Dandamudi	2003			real-time computing;round-robin scheduling;scheduling (computing);fair-share scheduling;scheduling (production processes);computer cluster;dynamic priority scheduling;two-level scheduling;computer science;rate-monotonic scheduling;distributed computing	HPC	-16.571467322747218	61.402662189032995	80930
707674d28bcfc955096b5ab12999909d365b942c	weight bound limits in supertasking approach for guaranteed timeline constraints	task analysis scheduling;multiprocessor scheduling;scheduling algorithm processor scheduling equations schedules scheduling optimal scheduling real time systems;multiprocessor scheduling pfair scheduling supertasking schedulability real time system;processor scheduling;supertasking;supertasking approach;schedulability loss;schedulability loss weight bound limits supertasking approach guaranteed timeline constraints pfair scheduled multiprocessor systems pfair task internal scheduling algorithm component tasks;pfair scheduling;weight bound limits;scheduling algorithm;guaranteed timeline constraints;optimal scheduling;scheduling;task analysis;pfair task;pfair scheduled multiprocessor systems;schedulability;schedules;real time system;component tasks;internal scheduling algorithm;real time systems;time constraint	We investigated the problem of supertasking in Pfair-scheduled multi-processor systems. In this approach, a set of tasks (component tasks) is grouped together to form a supertask, which is then scheduled as an ordinary Pfair task. Whenever a supertask is scheduled, its processor time is allocated to its component tasks according to an internal scheduling algorithm. Supertasking approach does not provide guarantees that its component tasks will respect the timeline constraints. In this paper, we propose a new condition for constructing a supertask from its component tasks in such a way that all timing constraints of its component tasks are guaranteed without compromising on schedulability loss. This condition is expressed as weight bound relation b/w supertask and its component tasks.	algorithm;multiprocessing;scheduling (computing);supertask;timeline	Muhammad Farooq;Fabrice Muller;Michel Auguin	2008	2008 International Conference on Parallel Processing - Workshops	10.1109/ICPP-W.2008.24	parallel computing;real-time computing;real-time operating system;computer science;operating system;distributed computing;scheduling	Embedded	-10.111260636789192	60.731483967976075	80988
c038c14661a7c7eaebf6256cf82e8e07b6d102ca	distributed job scheduling using snapshots	job scheduling	A methodology is developed for the solution of dynamic graph problems through the idea of snapshots. A snapshot of a dynamic graph is a collection of consistent local snapshots, where a local snapshot defines the neighborhood of a process. The methodology is illustrated by solving the distributed job scheduling problem. The solution combines a given snapshot algorithm with existing solutions to the dining philosophers and -coloring problems. The time and message complexities of the resulting algorithm depend minimally on global parameters.	job scheduler;job shop scheduling;scheduling (computing);snapshot (computer storage)	Manhoi Choy;Ambuj K. Singh	1993		10.1007/3-540-57271-6_33	fair-share scheduling;fixed-priority pre-emptive scheduling;job shop scheduling;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;rate-monotonic scheduling;job scheduler;two-level scheduling;deadline-monotonic scheduling;job queue;lottery scheduling	HPC	-11.62569586275693	61.601655497434706	81400
55c329ad3c4a2123236864991b39f92d3f016482	power-efficient virtual machine placement and migration in data centers	delay minimization;power efficiency;openflow power efficient virtual machine placement power efficient virtual machine migration power efficient solution fat tree data center network power consumption job delay hypervisor;virtual machines computer centres scheduling;computer centres;virtual machines;scheduling;virtual machine monitors servers bandwidth virtual machining network topology topology power demand;delay minimization power efficiency virtual machine migration;virtual machine migration	In this paper, we propose a power-efficient solution for virtual machine placement and migration in a fat tree data center network. This solution reduces power consumption as well as job delay by aggregating virtual machines to a few hyper visors and migrating communicating parties to close locations. In this work, we consider OpenFlow as the implementation protocol. In an OpenFlow environment, a centralized controller oversees job loads, virtual machine requirements and hardware availability. Given observation of such global knowledge, the OpenFlow controller can schedule jobs and distribute virtual machines accordingly. As jobs change and flows shift, the OpenFlow controller dynamically adjusts virtual machine assignments by aggregating virtual machines to close locations in order to save energy. With this placement and migration proposal, more jobs can operate concurrently with close sources and destinations of flows, thus both job and flow delay can be reduced.	centralized computing;data center;fat tree;job stream;openflow;requirement;virtual machine	Shuo Fang;Renuga Kanagavelu;Bu-Sung Lee;Chuan Heng Foh;Khin Mi Mi Aung	2013	2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing	10.1109/GreenCom-iThings-CPSCom.2013.246	embedded system;real-time computing;temporal isolation among virtual machines;electrical efficiency;computer science;virtual machine;operating system;virtual circuit;scheduling;computer network;virtual finite-state machine	HPC	-17.987752872707176	65.00619992532918	81557
a35e0323624303025b6cbcee29075e09b63f7654	autonomous learning for efficient resource utilization of dynamic vm migration	virtual machine;resource utilization;virtualization;standard deviation;benchmark problem;linux cluster;virtual machines;os migration;autonomous learning	Dynamic migration of virtual machines on a cluster of physical machines is designed to maximize resource utilization by balancing loads across the cluster. When the utilization of a physical machine is beyond a fixed threshold, the machine is deemed overloaded. A virtual machine is then selected within the overloaded physical machine for migration to a lightly loaded physical machine. Key to such threshold-based VM migration is to determine when to move which VM to what physical machine, since wrong or inadequate decisions can cause unnecessary migrations that would adversely affect the overall performance. We present in this paper a learning framework that autonomously finds and adjusts thresholds at runtime for different computing requirements. Central to our approach is the previous history of migrations and their effects before and after each migration in terms of standard deviation of utilization. We set up an experimental environment that consists of extensive real world benchmarking problems and a cluster of 16 physical machines each of which has on average eight virtual machines. We demonstrate through experimental results that our approach autonomously finds thresholds close to the optimal ones for different computing scenarios and that such varying thresholds yield an optimal number of VM migrations for maximizing resource utilization.	function overloading;requirement;run time (program lifecycle phase);virtual machine;z/vm	Hyung Won Choi;Hukeun Kwak;Andrew Sohn;Kyusik Chung	2008		10.1145/1375527.1375556	parallel computing;real-time computing;simulation;computer science;virtual machine;operating system	HPC	-17.707534100863764	60.91281170757977	82169
a81cbd984e6b9225f0582f6d43dc788ac6edaa43	level-based batch scheduling strategies for computational grid	computational grid;dag;level based scheduler;utilisation;np hard problems;turnaround time;batch scheduling	Grid computing is a high performance computing environment that allows sharing of geographically distributed resources across multiple administrative domains serving the ever growing demand for computational power. Scheduling m jobs to n resources to optimise the QoS for the given objective parameters has been proven to be NP-complete. This work presents two centralised level based batch scheduling strategies for a computational grid with the objective of minimising the turnaround time. The scheduler evaluates various computational nodes to schedule the batch of jobs consisting of a number of sub-jobs/modules having precedence and dependence constraints along with inter module communication requirements. Minimum Completion Time MCT and Minimum Execution Time MET heuristics have been used to decide the most suitable node for the given sub-job in terms of the turnaround time offered. A comparative analysis of the strategies with a model with similar objective has been performed to evaluate their place in the middleware.	grid computing;job scheduler;scheduling (computing)	Mohammad Shahid;Zahid Raza	2014	IJGUC	10.1504/IJGUC.2014.060223	real-time computing;computer science;job scheduler;operating system;np-hard;distributed computing;turnaround time	HPC	-17.62651783331939	62.826884334340036	82475
ff0de6740e365f2c4e95723049f8dc096c3629f5	proximity aware overlays in peer-to-peer networks	data sharing;topology;cluster algorithm;multicast communication;clustering algorithm;peer to peer network;time measurement;routing;distributed computing;hierarchical control;peer to peer overlay structure proximity aware overlays peer to peer network computing network communication network data sharing content distribution application level multicast internet application massive data mining application geographic framework;satisfiability;system performance;network topology;large scale;fault tolerant system;internet;data mining application;content distribution;peer to peer computing internet multicast communication;fault tolerant systems;community networks;fault tolerant systems distributed computing peer to peer networks clustering algorithm system performance;overlay network;ip networks;internet application;peer to peer computing;peer to peer networks;data transfer;application layer multicast;application level multicast;peer to peer computing routing topology internet network topology ip networks time measurement	In the internet today, computing and communication networks are very chaotic and complex. They do not have any centralized organization or hierarchical control. Thus there has been much interest in peer-to-peer networks because they provide a good substrate for creating large scale data sharing, content distribution and application level multicast. Many internet applications need to perform large scale data transfer from multiple sources example: massive data mining applications in geographic frameworks. An application layer multicast using peer to peer overlay structure is a good alternative. In this paper an overlay network structure is created with N nodes such that nodes satisfy certain proximity conditions. Overlay networks that are proximity aware have better performance than other overlay networks.	centralized computing;chaos theory;cluster analysis;data mining;digital distribution;file spanning;multicast;overlay network;peer-to-peer;product binning;spanning tree;telecommunications network	Tina Francis	2011	2011 International Conference for Internet Technology and Secured Transactions		overlay network;computer science;distributed computing;world wide web;computer network	HPC	-13.59633750325365	73.2751920565216	82538
494934f8793f96f9b6e69eb14979dc8bcdd35e7d	dynamic scheduling techniques for heterogeneous computing systems	processing element;heterogeneous systems;generic model;heterogeneous computing;scheduling algorithm;community networks;ke y words;communication cost;load balance;parallel architecture;communication channels;dynamic scheduling	There has been a recent increase of interest in heterogeneous computing systems, due partly to the fact that a single parallel architecture may not be adequate for e xploiting all of a program’ s available parallelism.In some cases, heterogeneous systems ha ve been sho wn to produce higher per formance for lower cost than a single lar ge machine.However, there has been only limited w ork on developing techniques and frame works for partitioning and scheduling applications across the components of a heterogeneous system. In this paper , we propose a general model for describing and evaluating heterogeneous systems that considers the de gr e of uniformity in the processing elements and the communication channels as a measure of the heterogeneity in the system. We also propose a class of dynamic scheduling algorithms for a heterogeneous computing system interconnected with an arbitrary communication netw ork. Thesealgorithms execute a novel optimization technique to dynamically compute schedules based on the potentially non-uniform computation and communication costs on the processors of a heterogeneous system. A unique aspect of these algorithms is that the y asily adapt to dif ferent task granularities, to dynamically v arying processor and system loads, and to systems with v arying degrees of heterogeneity . Our simulations are designed to f acilitate the e valuation of diferent scheduling algorithms under v arying degrees of heterogeneity . The results sho w improved performance for our algorithms compared to the performance resulting from e xisting scheduling techniques. Ke y Words: heterogeneous systems, dynamic scheduling, scheduling costs, communication cost, load balancing. Name email phone f ax Babak Hamidzadeh hamidzad@cs.ust.hk 852-358-7011 852-358-1477 David J. Lilja lilja@ee.umn.edu 612-625-5007 612-625-4583 Yacine Atif zohra@cs.ust.hk 852-358-7028 852-358-1477	algorithm;analysis of algorithms;branch and bound;central processing unit;centralized computing;circuit complexity;computation;email;experiment;heterogeneous computing;load balancing (computing);mathematical optimization;online and offline;ork;parallel computing;sparc;scheduling (computing);simulation;system of linear equations;value (ethics);workstation	Babak Hamidzadeh;Yacine Atif;David. J. Lilja	1995	Concurrency - Practice and Experience	10.1002/cpe.4330070705	fair-share scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;load balancing;operating system;database;distributed computing;scheduling;symmetric multiprocessor system;channel	HPC	-13.284078074979858	60.583986452946924	82539
07133f0d472708e1ff7e232d8ff5d20407eb2a9e	scheduling multiprocessor tasks on uniform processors			multiprocessing;scheduling (computing)	Jacek Blazewicz;Maciej Drozdowski;Günter Schmidt;Dominique de Werra	1993			parallel computing;symmetric multiprocessor system;multiprocessor scheduling;computer science;distributed memory;multiprocessing;scheduling (computing);fair-share scheduling;two-level scheduling;dynamic priority scheduling	OS	-11.808734497209748	61.59131959196921	82687
7573ac61d3b5493bc97c4221983ee11e4fba9930	resource allocation and revenue optimization for cloud service providers	priority queues;cloud service provider;personalization;versioning;advertising	a r t i c l e i n f o Online storage and streaming services are surpassing physical media as the predominate means of disseminating and sharing digital contents such as music, documents, photos, and videos. In addition, many software vendors are switching from on-premises installations to web-based rendering for their offerings. Differentiated pricing, based on tiered service responsiveness and advertisement displays, has been widely adopted by cloud service providers to optimize resource utilization and improve profitability under heterogeneous user demands. We analyze the impact of resource allocation and advertising decisions on provider profit and social welfare when separating premium subscription from more basic offerings. By considering queuing delays and advertising revenues , we suggest conditions under which the service provider should invest in service quality to grow the subscription base, which in turn helps attract more advertisers. We also assess the impact of advertising technology that lessens the users' disutility toward advertisements and increases the likelihood of ads click-through. Finally, we point out when offering free services could be more profitable than charging a subscription fee. The latest wave of technology advancement has made cloud-based distribution the primary channel for digital content (e.g., documents, mails, videos, images, music, and gaming). Compared with on-premises installations, cloud-based distribution enables content, application , and service providers to maintain better customer relationships (e.g., via analyzing usage patterns), faster updates/patches, and more efficient delivery of marketing offerings. Online service delivery has shown to be a viable and profitable business model. For example, a file-sharing site brought in $175 million of profits through premium membership fees and sponsored advertisements while accounting for a significant percentage of file sharing traffic. 1 Worldwide, the market for cloud-based content distribution is projected to reach $4bn by 2016. 2 An important issue when managing the cloud delivery platform is to balance the revenue streams from subscription and advertising. When managing user subscriptions, quality discrimination by offering differentiated features and service levels is a common approach that allows users to self-select the pricing tier per their willingness to pay. For example, one major web mail service is free, provided that the email contents are displayed with sidebar ads; the Plus version of the same service charges an annual subscription but is ads-free. While over-exposure to ads may be a turn-off to some users, content and service providers have come to rely on sponsored advertisements as a steady source of …	cloud computing;digital distribution;digital recording;email;end-user license agreement;file sharing;itil;mathematical optimization;multitier architecture;on-premises software;online service provider;primary channel;quality of service;responsiveness;streaming media;utility;web application;webmail	Jhih-Hua Jhang-Li;I. Robert Chiang	2015	Decision Support Systems	10.1016/j.dss.2015.04.008	service provider;service level requirement;service level objective;mobile qos;online charging system;differentiated service;computer science;software versioning;service delivery framework;marketing;service design;service guarantee;personalization;database;advertising;tiered service;world wide web;priority queue;commerce	Metrics	-19.074441055838516	73.93457701854757	82703
a97fb1b454a6d674d195e8b23b06161c86bdf79a	a pattern partitioning algorithm for memory-efficient parallel string matching in deep packet inspection	deep packet inspection;string matching;computer network security;network monitoring;pattern matching;finite state machine	This paper proposes a pattern partitioning algorithm that maps multiple target patterns onto homogeneous memory-based string matchers. The proposed algorithm adopts the greedy search based on lexicographical sorting. By mapping as many target patterns as possible onto each string matcher, the memory requirements are greatly reduced. key words: computer network security, deep packet inspection, finite state machine, pattern matching, and network monitoring	deep packet inspection;finite-state machine;greedy algorithm;lexicography;map;network packet;network security policy;pattern matching;requirement;sorting algorithm;string searching algorithm	Hyunjin Kim;Hyejeong Hong;Dongmyong Baek;Sungho Kang	2010	IEICE Transactions		deep packet inspection;commentz-walter algorithm;computer science;artificial intelligence;network security;pattern matching;boyer–moore string search algorithm;finite-state machine;network monitoring;algorithm;computer network;string searching algorithm	ML	-6.981034363605297	66.88459809607396	82811
1a0d3036a39fe9d1c61d6dbb3e5379054dcbfce5	a utility accrual scheduling algorithm for real-time activities with mutual exclusion resource constraints	resource constraint;overload management;processor scheduling;resource allocation;real time;processor scheduling resource management real time systems utility programs complexity theory operating systems;resource manager;simulation;resource management;operating systems computers processor scheduling resource allocation real time systems utility programs computational complexity;indexing terms;timeliness;resource management real time scheduling time utility functions utility accrual scheduling resource dependency mutual exclusion overload management;computer applications;mutual exclusion;scheduling algorithm;man computer interface;shape;operating system;computational complexity;scheduling;real time scheduling;time utility functions;polynomial time;utility programs;utility accrual scheduling;real time posix operating system utility accrual scheduling algorithm mutual exclusion resource constraint uni processor real time scheduling algorithm generic utility scheduling algorithm time utility function time constraint specification np hard problem;simulation study;algorithms;time utility function;overload;management;functions;operating systems computers;resource dependency;utilization;real time systems;time constraint	This paper presents a uni-processor real-time scheduling algorithm called the generic utility scheduling algorithm (which we refer to simply as GUS). GUS solves a previously open real-time scheduling problem-scheduling application activities that have time constraints specified using arbitrarily shaped time/utility functions and have mutual exclusion resource constraints. A time/ utility function are a time constraint specification that describes an activity's utility to the system as a function of that activity's completion time. Given such time and resource constraints, we consider the scheduling objective of maximizing the total utility that is accrued by the completion of all activities. Since this problem is NP-hard, GUS heuristically computes schedules with a polynomial-time cost of O(n/sup 3/) at each scheduling event, where n is the number of activities in the ready queue. We evaluate the performance of GUS through simulation and by an actual implementation on a real-time POSIX operating system. Our simulation studies and implementation measurements reveal that GUS performs close to, if not better than, the existing algorithms for the cases that they apply. Furthermore, we analytically establish several properties of GUS.	algorithm;cma-es;distributed computing;dynamic simulation;end-to-end principle;gravis ultrasound;heuristic;mutual exclusion;np-hardness;operating system;posix;process state;real-time clock;real-time transcription;scheduling (computing);simulation;time complexity;time-utility function;utility	Peng Li;Haisang Wu;Binoy Ravindran;E. Douglas Jensen	2006	IEEE Transactions on Computers	10.1109/TC.2006.47	fair-share scheduling;parallel computing;real-time computing;computer science;resource management;operating system;distributed computing;scheduling;algorithm	Embedded	-11.160969943124288	60.5523373083387	82851
9ac1da37785dba41f1b322bdc97905fa01a405c0	modeling and performance analysis of qos-aware load balancing of web-server clusters	web server cluster;high level petri net;web quality of service;stochastic high level petri net;performance analysis;load balancing;load balance;quality of service;process scheduling;modeling and analysis	This paper introduces mechanisms to correlate contents and priorities of incoming HTTP requests used for server process scheduling with the load balancing policies for Web-server clusters. This approach enables both load balancing and Web quality of service (QoS). Another contribution is a modeling and analysis technique based on stochastic highlevel Petri net methods for QoS-aware load balancing. We propose an approximate analysis technique to reduce the complexity of the model. 2002 Elsevier Science B.V. All rights reserved.	approximation algorithm;load balancing (computing);petri net;profiling (computer programming);quality of service;scheduling (computing);server (computing);web server	Zhiguang Shan;Chuang Lin;Dan C. Marinescu;Yang Yang	2002	Computer Networks	10.1016/S1389-1286(02)00253-0	round-robin dns;network load balancing services;real-time computing;computer science;load balancing;database;distributed computing;computer security	HPC	-12.065460455348358	66.86887656013039	82996
1f9e2b81630b192a7781a195711ff3d2552ddaf5	a scalable video server using intelligent network attached storage	sistema lineal;tratamiento datos;transmision paquete;distributed system;single system image;eficacia sistema;scalable video;systeme intelligent;architecture systeme;systeme reparti;simulation systeme;sintesis control;video a peticion;concepcion sistema;implementation;concepcion optimal;sistema inteligente;reseau ordinateur;simulacion numerica;video a la demande;conception optimale;serveur informatique;performance systeme;data processing;traitement donnee;stockage donnee;system performance;linear system;serveur video;experimental result;computer network;serveur reseau;ejecucion;simulation experiment;data storage;network servers;sistema repartido;system design;scheduling;synthese commande;intelligent network;simulation numerique;video on demand;video server;intelligent system;red ordenador;resultado experimental;optimal design;servidor informatico;almacenamiento datos;packet transmission;video servers;arquitectura sistema;ordonamiento;systeme lineaire;resultat experimental;system architecture;transmission paquet;system simulation;simulacion sistema;conception systeme;control synthesis;ordonnancement;admission control;numerical simulation;computer server	"""This paper proposes a new architecture, called intelligent network at- tached storage, for building a distributed video server. In this architecture, the data intensive and high overhead processing tasks such as data packaging and transmitting are handled locally at the storage nodes instead of at special deliv- ery nodes. Thus an unnecessary data trip from the storage nodes to the delivery nodes is avoided, and a large amount of resource consumption is saved. More- over, these """"intelligent"""" storage nodes work cooperatively to give a single sys- tem image to the clients. Based on the architecture, we design our admission control and stream scheduling strategies, and conduct some simulation experi- ments to optimize the system design. The simulation results exhibit a near lin- ear scalability of system performance with our design. Some implementation issues are also discussed in this paper."""		Guang Tan;Hai Jin;Liping Pang	2002		10.1007/3-540-45812-3_10	embedded system;intelligent network;simulation;data processing;telecommunications;computer science;optimal design;operating system;computer data storage;linear system;implementation;scheduling;server;systems design	Robotics	-12.83947770296087	70.21160441956835	83292
2d49abe1bc405690a8504c0502e2ec0143b2aa1e	web file transmission by object packaging - performance comparison with http 1.0 and http 1.1 persistent connection	file servers;performance evaluation;high speed networks;performance comparison;client server systems;response time web file transmission object packaging web servers world wide web http 1 0 http 1 1 persistent connection;packaging delay web server network servers bandwidth computer networks central processing unit access protocols time measurement computer science;data communication;transport protocols;hypermedia;data communication web sites internet file servers hypermedia transport protocols client server systems;internet;web sites;local computation;world wide web	Recently, the largest concern for corporate owners of web servers is how to minimize the response time. In order to minimize the response time, a new efficient file transmission technique for World-Wide-Web, called web file transmission by Object Packaging, is proposed. The prototype design and preliminary performance evaluation of Object Packaging have been presented in the 27th Conference on Local Computer Networks. In this paper, the performance of Object Packaging is compared to HTTP 1.0 and HTTP 1.1 Persistent Connection in terms of the server and client response time and CPU workload by experiment method. It is found that Object Packaging reduces the response time and CPU workload at the server by up to 92.0 and 91.1% from HTTP 1.0 and 64.5 and 82.4% from HTTP 1.1 Persistent Connection, respectively. From the results of the experiments, it is found that Object Packaging will be an efficient technique to minimize the response time in transferring web files. The results of the experiments also suggest the significance of disk I/O overhead for web servers in high speed networks.	central processing unit;computer networks (journal);experiment;http persistent connection;hypertext transfer protocol;input/output;overhead (computing);performance evaluation;prototype;response time (technology);server (computing);web server;world wide web	Hiroshi Fujinoki;Murugesan Sanjay;Chintan Shah	2003		10.1109/LCN.2003.1243114	web service;ajax;file server;static web page;web development;real-time computing;the internet;data web;computer science;web api;operating system;web navigation;web log analysis software;web page;database;web 2.0;world wide web;transport layer;web server;application server;client–server model;server;computer network	OS	-17.982030796490214	70.64908735668138	83531
00f9f3ce5efe2a608ee2214db15e698730697300	efficient olap query processing in distributed data warehouses	tratamiento datos;data transmission;base donnee;analisis estadistico;protocole transmission;distributed processing;flot donnee;database;base dato;data processing;telecommunication network;traitement donnee;stockage donnee;olap;flujo datos;synchronisation;data storage;protocolo transmision;flujo red;internet;statistical analysis;synchronization;red telecomunicacion;transmission donnee;analyse statistique;reseau telecommunication;almacenamiento datos;sincronizacion;network flow;data flow;traitement reparti;flot reseau;transmision datos;tratamiento repartido;transmission protocol	The success of Internet applications has led to an explosive growth in the demand for bandwidth from ISPs. Managing an IP network includes complex data analysis (see, e.g., [1]) that can often be expressed as OLAP queries. For example, using flow-level traffic statistics data one can answer questions like: On an hourly basis, what fraction of the total number of flows is due to Web traffic? Current day OLAP tools assume the availability of the detailed data in a centralized warehouse. However, the inherently distributed nature of of the data collection (e.g., flow-level traffic statistics are gathered at network routers) and the huge amount of data extracted at each collection point (of the order of several gigabytes per day for large IP networks) makes such an approach highly impractical. The natural solution to this problem is to maintain a distributed data warehouse, consisting of multiple local data warehouses (sites) adjacent to the collection points, together with a coordinator. In order for such a solution to make sense, we need a technology for distributed processing of complex OLAP queries. We have developed the Skalla system for this task. Skalla translates OLAP queries specified using relational algebra augmented with the GMDJ operator [2] into distributed query evaluation plans. Salient features of the Skalla approach are:	centralized computing;distributed computing;gigabyte;internet protocol suite;online analytical processing;relational algebra;router (computing);web traffic	Michael O. Akinde;Michael H. Böhlen;Theodore Johnson;Laks V. S. Lakshmanan;Divesh Srivastava	2002		10.1007/3-540-45876-X_23	synchronization;data processing;computer science;operating system;data mining;database;world wide web	DB	-12.270900674323075	69.80835528606866	84091
0646af683c0551a108fe25a4b18419b5d3239af4	a reliable ordered delivery protocol for interconnected local area networks	distributed system;high availability;protocols;total order;local area networks multicast protocols network topology maintenance intersymbol interference throughput delay broadcasting ethernet networks lan interconnection;network partitioning;maintenance;multiple ring protocol;intersymbol interference;distributed processing;replicated data totem multiple ring protocol interconnected local area networks ordered delivery protocol network partitioning processor failure and recovery fault tolerant distributed systems;processor failure and recovery;lan interconnection;fault tolerant distributed systems;network topology;fault tolerant computing;interconnected local area networks;multicast protocols;totem;replicated data;computer application;broadcasting;ethernet networks;replicated databases;local area networks;local area network;replicated databases protocols lan interconnection fault tolerant computing distributed processing;throughput;ordered delivery protocol	We present the Totem multiple-ring protocol, a novel reliable ordered multicast protocol for multiple interconnected local-area networks. The protocol exhibits excellent performance and maintains a consistent network-wide total order of messages despite network partitioning and remerging, or processor failure and recovery with stable storage intact. The Totem protocol is designed for fault-tolerant distributed systems , which replicate data to guard against failures and must ensure that replicated data remain consistent despite failures. The network-wide total order of messages provided by Totem simpliies the maintenance of consistency of replicated data and, thus, eases the development of fault-tolerant distributed systems.	distributed computing;fault tolerance;multicast;network partition;self-replicating machine;stable storage	Deborah A. Agarwal;Louise E. Moser;P. M. Melliar-Smith;Ravi K. Budhia	1995		10.1109/ICNP.1995.524853	local area network;real-time computing;two-phase commit protocol;computer science;distributed computing;computer network	Networks	-7.7077319729500005	72.0523987278081	84132
108b685009278c868184ce0ef2d89a97b0b5ad5f	formal analysis of sporadic bursts in real-time systems	adaptive test;reliability;real time systems;scheduling;computational modeling	In this paper we propose a new method for the analysis of response times in uni-processor real-time systems where task activation patterns may contain sporadic bursts. We use a burst model to calculate how often response times may exceed the worst-case response time bound obtained while ignoring bursts. This work is of particular interest to deal with dual-cyclic frames in the analysis of CAN buses. Our approach can handle arbitrary activation patterns and the static priority preemptive as well as non-preemptive scheduling policies. Experiments show the applicability and the benefits of the proposed method.	best, worst and average case;real-time clock;real-time computing;response time (technology);scheduling (computing)	Sophie Quinton;Mircea Negrean;Rolf Ernst	2013	2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)		embedded system;real-time computing;simulation;computer science;operating system;computerized adaptive testing;statistics	Embedded	-9.66482553389837	60.947496385947716	84215
317a05544a1e46ce01e121440c368f2f151a10b2	load balancing on networks with dynamically changing topology	workload;dynamic change;distributed system;time dependent;systeme reparti;distributed networks;distributed processing;synchronous;synchrone;difusion;network topology;sistema repartido;dependance du temps;time dependence;sincronico;link failure;charge travail;load balance;carga trabajo;diffusion;topologie circuit;traitement reparti;dependencia del tiempo;diffusion model;tratamiento repartido	In this paper, we present a time dependent diffusion model for load balancing on synchronous networks with dynamically changing topology. This situation can arise for example from link failures. Our model is general and include Cybenko's diffusion models for fixed topology networks. We will show that under some assumptions, the time dependent load balancing algorithm converges and balances the total work load among the processors in the distributed network.	load balancing (computing)	Jacques M. Bahi;Jaafar Gaber	2001		10.1007/3-540-44681-8_27	real-time computing;telecommunications;computer science;distributed computing;diffusion	ML	-12.57294231851947	64.51760929609556	84220
c896ec9aee988041dfe63c8983b0a07e3a155bfe	an efficient resource allocation (era) mechanism in iaas cloud	resource management;resource management schedules cloud computing clustering algorithms algorithm design and analysis heuristic algorithms quality of service;heuristic algorithms;schedules;clustering algorithms;tree searching cloud computing pattern clustering resource allocation;improved branch and bound based assignment algorithm efficient resource allocation jcc k means;quality of service;user satisfaction era mechanism iaas cloud cloud computing internet access efficient resource allocation resource providers dynamicity heterogeneous user request job centric cosine similarity based k means jcc k means resources cluster branch and bound based assignment algorithm cloud resources java eclipse ide resource discovery makespan;algorithm design and analysis;cloud computing	Cloud computing allows consumers to use the applications as remote with internet access as pay per use. Resource Allocation is one of the most challenging tasks in cloud since it depends on dynamicity of resource providers and heterogeneous user request. To efficiently allocate the user request in a resource, Efficient Resource Allocation (ERA) is proposed. Hence, in the proposed efficient resource allocation mechanism, Job Centric Cosine Similarity based K-Means ( JCC K-Means) is used to cluster the resources dynamically based on user request and improved branch and bound based assignment algorithm is used for efficient allocation of cloud resources to user request. The proposed work is simulated and compared with K-means and Random Allocation. The simulation is carried out in Java using Eclipse IDE The simulation results shows that the proposed work achieves better result in terms of efficient resource discovery, makespan and user satisfaction.	algorithm;branch and bound;cloud computing;cosine similarity;eclipse;internet access;java;journal of computational chemistry;k-means clustering;makespan;simulation	Rajalakshmi Shenbaga Moorthy	2015	2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2015.7275644	algorithm design;quality of service;cloud computing;schedule;resource allocation;computer science;resource management;database;distributed computing;resource allocation;cluster analysis;world wide web	HPC	-18.613844478058898	63.38422254866999	84399
77a75e688c96382856062a6852a624716126f4a8	a fully-pipelined hash table achieving low-latency and high throughput key-value retrieving system		Key-value store (KVS) systems are widely used in various network applications for retrieving a block of data called value according to an indicator called key. Hash table is often used as implementations of key-value stores for its high retrieving efficiency. However, the conventional implementations of hash tables are based on software, which introduce high latency and loss of requests for high speed Ethernet accesses. We present a hash table with optimized fully pipelined design for high throughput and low latency key-value accesses. This hash table inserts entries at the rate of 100 million requests per second (MRPS) when the load factor is less than 60% and retrieves or deletes entries at a constant rate of 100 MRPS. The integration with Ethernet and off-chip memories achieves 10Gbps line rate processing of requests and proves that our hash table is over-provisioned. The KVS system can handle the throughput beyond 10 Gbps, serving a maximum packet rate of 46 MRPS, which is 1.5 times faster than the best published result. The retrieve latency can be reduced down to 230ns, which is 2.5 times faster than the best published result.	attribute–value pair;data rate units;hash table;key-value database;network packet;throughput;web server	Li Ding;Wenbo Yin	2017	2017 IEEE 12th International Conference on ASIC (ASICON)	10.1109/ASICON.2017.8252480	real-time computing;hash table;latency (engineering);throughput;field-programmable gate array;latency (engineering);computer science;software;ethernet;network packet	Networks	-5.876448554918892	65.31312562598114	84572
98e7d807c39a33ba5ac4f30680701f47392daccf	optimal placement of replicas in trees with read, write, and storage costs	multiprocessor interconnection networks;multicast communication;computer society;information systems;web pages;cost function;tree nodes;optimal residence set;helium;file allocation;data replication;tree data structures;upper bound;tree graphs;trees;p medians;cost function multiprocessor interconnection networks tree graphs intelligent networks computer society upper bound helium web sites information systems web pages;multicasting;optimal placement of replicas;tree networks;web sites;minimum spanning tree;facility location multicast communication tree data structures file organisation;intelligent networks;tree network;optimal residence set optimal placement of replicas trees storage costs tree network tree nodes minimum spanning tree o n sup 3 p sup 2 time algorithm;o n 3 p 2 time algorithm;storage costs;facility location;reading and writing;file organisation	ÐWe consider the problem of placing copies of objects in a tree network in order to minimize the cost of servicing read and write requests to objects when the tree nodes have limited storage and the number of copies permitted is limited. The set of nodes that have a copy of the object is the residence set of the object. A node wishing to read the object will read the object from the closest node in the residence set. A node wishing to update the object will update the copy of the object at all the nodes in the residence set. Updates are propagated over a certain minimum spanning tree. The cost associated with a residence set equals the cost of servicing all the read and write requests and the storage costs for those copies. We describe a On3p2-time algorithm for finding an optimal residence set of size p for an object in a tree with n nodes, taking into consideration the read, write, and storage costs. Furthermore, we describe a On3p2 max-time algorithm for finding a minimum cost normal p-residence set for an object in a tree, this time also taking into account the load imposed by the nodes of the tree on the nodes in a residence set and their capacity constraints, where max is an upper bound on the capacity of each node of the tree. Index TermsÐData replication, multicasting, facility location, p-medians, file allocation, tree networks.	approximation algorithm;file spanning;high availability;minimum spanning tree;multicast;read-write memory;tree network	Konstantinos Kalpakis;Koustuv Dasgupta;Ouri Wolfson	2001	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.932716	intelligent network;parallel computing;real-time computing;multicast;exponential tree;computer science;theoretical computer science;minimum spanning tree;facility location problem;web page;database;distributed computing;tree;upper and lower bounds;helium;tree;information system;replication;computer network	Theory	-15.26683172940754	66.72117649212639	84973
4d982510b9b024c7ca69a0b7a8b5d90627224e1f	replication based fault tolerant job scheduling strategy for economy driven grid	economy driven grid;task replication;fault tolerance;grid resource management;grid job scheduling;grid computing	In this paper, the problem of fault tolerance in grid computing is addressed and a novel adaptive task replication based fault tolerant job scheduling strategy for economy driven grid is proposed. The proposed strategy maintains fault history of the resources termed as resource fault index. Fault index entry for the resource is updated based on successful completion or failure of an assigned task by the grid resource. Grid Resource Broker then replicates the task (submitting the same task to different backup resources) with different intensity, based on vulnerability of resource towards faults suggested by resource fault index. Consequently, in case of possible fault at a resource the results of replicated task(s) on other backup resource(s) can be used. Hence, user job(s) can be completed within specified deadline and assigned budget, even on the event of faults at the grid resource(s). Through extensive simulations, performance of the proposed strategy is evaluated and compared with the Time Optimization and Checkpointing based Strategy in an economy driven grid environment. The experimental results demonstrate that in the presence of faults, proposed fault tolerant strategy improves the number of tasks completed with varied deadline and fixed budget as well as number of tasks completed with varied budget and fixed deadline. Additionally, the proposed strategy used a smaller percentage of deadline time as compare to both Time Optimization and Checkpointing based Strategy. Although the proposed strategy has a percentage of budget spent greater than that of Time Optimization Strategy and Checkpointing based Strategy, it is accepted as a proposed strategy in time optimization where the main objective is to maximize tasks completed within a given deadline. It can be concluded from the experiments that the proposed strategy shows improvement in satisfying the user QoS requirements. It can effectively schedule tasks and tolerate faults gracefully even in the presence of failures, but the costs are slightly higher in terms of budget consumption. Hence, the proposed fault tolerant strategy helps in sustaining user’s faith in the grid, by enabling the grid to deliver reliable and consistent performance in the presence of faults.	algorithm;application checkpointing;backup;experiment;fault tolerance;grid computing;job scheduler;job stream;mathematical optimization;optimizing compiler;quality of service;replication (computing);requirement;run time (program lifecycle phase);scheduling (computing);simulation	Babar Nazir;Kalim Qureshi;Paul D. Manuel	2012	The Journal of Supercomputing	10.1007/s11227-012-0756-z	fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing;grid computing	HPC	-17.483567602082893	60.99518219236864	85185
57b7279ebeeba526298ff8267354a07b24741c90	scheduling and optimization of the delivery of multimedia streams using query scripts	multimedia streaming;optimal method;simulation;satisfiability;scheduling algorithm;distributed environment;multimedia data;query script;optimization;delivery scheduling;multimedia database;multimedia server;multimedia streams;multimedia database system	New techniques are necessary to satisfy the high bandwidth requirement and temporal relationships of multimedia data streams in a network environment. Clients can experience gaps between the multimedia data streams during presentations as the multimedia server services multiple clients. This variable delay occurs between the end of one multimedia stream and the beginning of the next multimedia stream because client requests are queued awaiting service. This leads to interruptions and discontinuities of the client's presentation. Special techniques are necessary to manage the temporal relationships between multimedia streams in distributed environments. In this paper we propose two scheduling algorithms for delivering multimedia streams by using the query script, which is a multimedia database interface for clients. A client can specify all the multimedia objects that make up the presentation and their temporal relationships in a query script. Once submitted, the information in the query script is used by the multimedia database system to schedule and optimize the delivery. Using simulations we analyzed the performance of the proposed delivery scheduling algorithms and the predelivery optimization method. The simulation results show that delivery scheduling algorithms satisfy the specified temporal relationships between multimedia streams while maintaining better use of system resources.	algorithm;baseline (configuration management);client (computing);computation;database;mathematical optimization;overhead (computing);requirement;schedule (computer science);scheduling (computing);server (computing);simulation;throughput	Scott T. Campbell;Soon Myoung Chung	2002	Multimedia Tools and Applications	10.1023/A:1015816232330	real-time computing;computer science;database;scheduling;world wide web;ip multimedia subsystem;distributed computing environment;satisfiability	DB	-15.290838539102156	70.9348096505067	85475
3dce1305bfaaf006641c5048cb062231ea37d412	bag of tasks rescheduling within real grid environments: different approaches	processor scheduling;resource allocation;resource management;heterogeneous computing resources bag of tasks rescheduling real grid environments quality of service resource reservation resource scheduling qos provision enhancement grid scenario fragmentation resource utilization resource allocation job reallocation np hard problem;np hard problem;time factors;resource management quality of service scheduling time factors processor scheduling np hard problem heuristic algorithms;computational complexity;scheduling;heuristic algorithms;task analysis computational complexity grid computing processor scheduling resource allocation;task analysis;quality of service;grid computing	Providing Quality of Service (QoS) in Grid environments is still a challenging task because advance reservation of resources is not always possible. By contrast, scheduling the use of resources in advance is a way of enhancing the provision of QoS, without physically reserving them. However, in a Grid scenario fragmentation may appear as a logic result of the allocation process, leading to poor resource utilization. To try to avoid that problem a rescheduling technique has been developed and applied periodically depending on the existing fragmentation. Nevertheless, reallocating jobs in an optimal way is an NP-Hard problem. Consequently, simple and scalable ways of distributing and allocating those jobs into the resources are presented and evaluated in a real Grid environment involving heterogeneous computing resources distributed across different national organizations, highlighting the benefits of using them to increase the resource usage.	algorithm;fork (software development);fragmentation (computing);heterogeneous computing;job stream;meta-scheduling;np-hardness;performance evaluation;quality of service;scalability;scheduling (computing);sorting	Luis Tomás;María Blanca Caminero;Carmen Carrión	2013	2013 21st Euromicro International Conference on Parallel, Distributed, and Network-Based Processing	10.1109/PDP.2013.38	parallel computing;real-time computing;quality of service;resource allocation;computer science;resource management;operating system;np-hard;task analysis;distributed computing;computational complexity theory;scheduling;grid computing	HPC	-18.07365518389612	62.50738354123935	85491
efa91dfa0ef10804c7209082b3aefc90bf1335b9	content-aware dispatching algorithms for cluster-based web servers	clusters;performance evaluation;dispatching algorithms;simulation experiment;settore ing inf 05 sistemi di elaborazione delle informazioni;load sharing;world wide web;database search	Cluster-based Web servers are leading architectures for highly accessed Web sites. The most common Web cluster architecture consists of replicated server nodes and a Web switch that routes client requests among the nodes. In this paper, we consider content-aware Web switches that can use application level information to assign client requests. We evaluate the performance of some representative state-of-the-art dispatching algorithms for Web switches operating at layer 7 of the OSI protocol stack. Specifically, we consider dispatching algorithms that use only client information as well as the combination of client and server information for load sharing, reference locality or service partitioning. We demonstrate through a wide set of simulation experiments that dispatching policies aiming to improve locality in server caches give best results for traditional Web publishing sites providing static information and some simple database searches. On the other hand, when we consider more recent Web sites providing dynamic and secure services, dispatching policies that aim to share the load are the most effective.	algorithm;cap computer;computer cluster;experiment;locality of reference;network switch;osi model;protocol stack;representation oligonucleotide microarray analysis;server (computing);server farm;simulation;surface web;web server	Emiliano Casalicchio;Valeria Cardellini;Michele Colajanni	2002	Cluster Computing	10.1023/A:1012796706047	web service;parallel computing;database search engine;data web;computer science;operating system;database;world wide web;web server;application server;client–server model;computer network	Web+IR	-18.04233334039294	70.76119417955614	85910
76518d9bb7c0066266e9058cd18ce9e0099b59af	a proxy-based approach for dynamic content acceleration on the www	cache storage;information resources;file servers;t technology general;acceleration world wide web bandwidth web pages uniform resource locators scalability added delay performance analysis runtime costs;internet;dynamic content;internet information resources cache storage file servers;web site performance dynamic content caching approaches performance scalability problems dynamic content generation applications back end caching approaches query result caching fragment level caching fine grained caching firewall delays bandwidth requirements dynamic proxy caching technique order of magnitude reductions world wide web proxy based caching approaches	Various dynamic content caching approaches have been proposed to address the performance and scalability problems faced by many Web sites that utilize dynamic content generation applications. Proxy-based caching approaches store content at various locations outside the site infrastructure and can improve Web site performance by reducing content generation delays, firewall processing delays, and bandwidth requirements. However, existing proxybased caching approaches either (a) cache at the page level, which does not guarantee that correct pages are served and provides very limited reusability, or (b) cache at the fragment level, which requires the use of pre-defined page layouts. To address these issues, several back end caching approaches have been proposed, including query result caching and fragment level caching. While back end approaches guarantee the correctness of results and offer the advantages of fine-grained caching, they neither address firewall delays nor reduce bandwidth requirements. In this paper, we present an approach and an implementation of a dynamic proxy caching technique which combines the benefits of both proxy-based and back end caching approaches, yet does not suffer from their above-mentioned limitations. Our analysis of the performance of our approach indicates that it is capable of providing significant reductions in bandwidth. Experimental results from an implementation of this approach indicate that our technique is capable of providing order-of-magnitude reductions in bandwidth.	cache (computing);correctness (computer science);dynamic web page;emoticon;firewall (computing);proxy server;requirement;scalability;www;web application	Anindya Datta;Kaushik Dutta;Helen M. Thomas;Debra E. VanderMeer;Krithi Ramamritham;Suresha	2002		10.1109/WECWIS.2002.1021254	real-time computing;false sharing;computer science;inline caching;database;smart cache;world wide web	DB	-18.79116211493356	70.48015713284379	86150
b49b9f14e38caa5468a1e7fa876ce23e2824c432	a deadline and cost constrained optimization algorithm for scheduling applications in grids based on proportional share systems	constrained optimization;resource scheduling;optimisation;costing;resource management;proportional share systems;biological system modeling;deadline cost constrained optimization algorithm;scheduling applications;scheduling algorithm;nimrod g methods;cost optimization;optimization resource management biological system modeling schedules scheduling economics scheduling algorithm;geographically distributed resources;scheduling;timing optimization;resource sharing;schedules;computational economy framework;optimization;economics;proportional share deadline cost constrained optimization algorithm scheduling applications proportional share systems geographically distributed resources nimrod g methods computational economy framework cost constrained optimization algorithm;cost constrained optimization algorithm;proportional share;optimal algorithm;grid computing;large scale problem;geographic distribution;scheduling costing grid computing optimisation;supply and demand	Since computation of grids enable the sharing, selection, query and aggregation of geographically distributed resources for solving large-scale problems, developing mechanisms for grid resource scheduling is a complex undertaking problem. We had investigated several famous schedule methods proposed by Nimrod-G, a famous computational economy framework for regulating the supply and demand for resources. In this paper, we propose a novel scheduling algorithm, called deadline and cost constrained optimization algorithm, which extends Buyyapsilas cost optimization and time optimization algorithm, keeping the cost and time optimization at same time. Our optimization algorithm, which is based on proportional share (PS), allows users to bid higher in order to gain more resource shares. Therefore, this algorithm adjusts a user bid periodically on these systems in order to finish the application on time. Empirical results show that the algorithm had better performance than with conventional algorithms.	algorithm;computation;constrained optimization;information retrieval;mathematical optimization;scheduling (computing);selection (user interface)	Dazhen Wang;Kwang Mong Sim;Benyun Shi	2008	2008 International Symposium on Electronic Commerce and Security	10.1109/ISECS.2008.116	mathematical optimization;constrained optimization;real-time computing;computer science;resource management;operating system;scheduling	EDA	-18.03481714466424	64.25616796834066	86665
5eb9e6a3a5bd6cb81b3f873307b8e9cbd3d229a4	randomized online file allocation on uniform ring networks	online algorithm;multicast communication;randomised algorithms deterministic algorithms file organisation;randomized algorithm randomized online file allocation uniform ring networks adaptive online adversary deterministic algorithm;steiner trees;randomized online file allocation;ring network;adaptive online adversary;resource management;data management;randomised algorithms;file allocation;distance measurement;deterministic algorithms;deterministic algorithm;adaptive systems;uniform ring networks;distributed databases;randomized algorithm;joining processes;lower bound;ring network file allocation data management online algorithm;distributed computing computer science concurrent computing internet file servers unicast multicast communication multicast algorithms joining processes;file organisation	We study the online file allocation problem on ring networks. In this paper, we present a 7-competitive randomized algorithm against an adaptive online adversary on uniform ring networks. The algorithm is deterministic if the file size is 1. Moreover, we obtain lower bounds of 4.25 and 3.833 for a deterministic algorithm and a randomized algorithm against an adaptive online adversary, respectively, on ring networks.	adversary (cryptography);deterministic algorithm;randomized algorithm	Akira Matsubayashi;Yasuyuki Kawamura	2008	2008 International Symposium on Parallel and Distributed Computing	10.1109/ISPDC.2008.27	ring network;online algorithm;steiner tree problem;data management;computer science;deterministic algorithm;resource management;theoretical computer science;distributed computing;upper and lower bounds;randomized algorithm;algorithm;adversary model;computer network	Theory	-9.109085506428597	68.8020562320903	86826
6acb1e93b518eec02cd918756c5297e356d306e1	theoretical study of cache systems	cache optimization;principles of cache construction;zipf-like distribution;renewal of web documents;long-term prefetching;system of equations;internet traffic;steady state	The aim of this paper is a theoretical study of a cache system in order to optimize proxy cache systems and to modernize construction principles including prefetching schemes. Two types of correlations, Zipf-like distribution and normalizing conditions, play a role of the fundamental laws. A corresponding system of equations allows to describe the basic effects like ratio between construction parts, steadystate performance, optimal size, long-term prefetching, etc. A modification of the fundamental laws leads to the description of new effects of documents’ renewal in the global network. An internet traffic caching system based on Zipf-like distribution (ZBS) is invented. The additional module to the cache construction gives an effective prefetching by lifetime.	cpu cache;cache (computing);computer data storage;global network;hit (internet);kernel (operating system);page replacement algorithm;steady state;web cache;zipf's law	Dmitry G. Dolgikh;Andrei M. Sukhov	2002	CoRR		cache invalidation;cache coloring;computer network;internet traffic;cache;computer science;smart cache;cache-oblivious algorithm;distributed computing;cache algorithms;cache pollution	Metrics	-14.687428411462546	73.92927423614903	86909
844d601df904d76907b246585ff5030908467c20	meeting deadlines of scientific workflows in public clouds with tasks replication	directed graphs;scientific workflows deadline;deadline constrained workflow;data transfer scheduling cloud computing virtual machining schedules computational modeling delays;task replication;financial management;public clouds direct acyclic graph cloud computing deadline constrained workflow cloud infrastructures elasticity scientific workflows deadline task replication;virtual machining;scientific workflows;computational modeling;workflow management software cloud computing directed graphs financial management;scheduling;distributed programming;soft deadline;schedules;workflow management software;cloud infrastructures elasticity;direct acyclic graph;distributed systems;soft deadline cloud computing scientific workflows task replication;public clouds;data transfer;delays;cloud computing	The elasticity of Cloud infrastructures makes them a suitable platform for execution of deadline-constrained workflow applications, because resources available to the application can be dynamically increased to enable application speedup. Existing research in execution of scientific workflows in Clouds either try to minimize the workflow execution time ignoring deadlines and budgets or focus on the minimization of cost while trying to meet the application deadline. However, they implement limited contingency strategies to correct delays caused by underestimation of tasks execution time or fluctuations in the delivered performance of leased public Cloud resources. To mitigate effects of performance variation of resources on soft deadlines of workflow applications, we propose an algorithm that uses idle time of provisioned resources and budget surplus to replicate tasks. Simulation experiments with four well-known scientific workflows show that the proposed algorithm increases the likelihood of deadlines being met and reduces the total execution time of applications as the budget available for replication increases.	algorithm;cloud computing;contingency plan;elasticity (cloud computing);experiment;provisioning;run time (program lifecycle phase);scalability;scheduling (computing);self-replicating machine;simulation;speedup	Rodrigo N. Calheiros;Rajkumar Buyya	2014	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2013.238	financial management;real-time computing;directed graph;cloud computing;schedule;computer science;operating system;database;distributed computing;computational model;scheduling	HPC	-17.80430435455788	61.5990189561656	87025
91aa51d570334aac4a243f8500b9822d788cae5e	priority inversion at the network adapter when scheduling messages with earliest deadline techniques	distributed system;real time;real time systems job shop scheduling processor scheduling protocols scheduling algorithm local area networks electrical equipment industry industrial control robust control costs;message scheduling scheduling messages earliest deadline techniques network adapter priority inversion real time distributed systems predictability earliest deadline message scheduling processor utilization;real time systems	In this paper we present a novel approach in the study of the predictability of real-time message transmission and its relationship with the design of network adapters for real-time distributed systems. The aim is to limit the occurrence of large priority inversions among messages, so as to achieve a better degree of predictability. We show that when the proper network adapters are used in conjunction with earliest deadline message scheduling the loss in processor utilization is minimized and predictable.	distributed computing;network interface controller;priority inversion;real-time clock;real-time web;scheduling (computing)	Antonio Meschi;Marco Di Natale;Marco Spuri	1996		10.1109/EMWRTS.1996.557931	priority inversion;fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing;least slack time scheduling;round-robin scheduling	Networks	-10.713071646290304	61.07162907113577	87426
f43ca69c5114d81b3b15bc991a2929eda0c1e5b3	optimal timer-based caching policies for general arrival processes	cache systems;heavy tails;optimization;90b18;90c25;68m20	In this paper, we analyze the hit performance of cache systems that receive file requests with general arrival distributions and different popularities. We consider timer-based policies, with differentiated timers over which we optimize. The optimal policy is shown to be related to the monotonicity of the hazard rate function of the interarrival distribution. In particular, for decreasing hazard rates, timer policies outperform the static policy of caching the most popular contents. We provide explicit solutions for the optimal policy in the case of Pareto-distributed inter-request times and a Zipf distribution of file popularities, including a compact fluid characterization in the limit of a large number of files. We compare it through simulation with classical policies, such as Least Recently Used and discuss its performance.	cache (computing);timer	Andrés Ferragut;Ismael Rodríguez;Fernando Paganini	2018	Queueing Syst.	10.1007/s11134-017-9540-3	real-time computing;cache;zipf's law;timer;hazard ratio;cache algorithms;monotonic function;computer science;distributed computing	Metrics	-13.054542455192173	68.00328631380123	87438
7ce6fcd4a2b946c928c0e42d3808b577efc5d3c8	some algorithms for analysis and synthesis of real-time multiprocessor computing systems	preemptive scheduling;release time;exact maximum flow algorithm;processor performance;relative priority;real-time multiprocessor computing system;single-processor algorithm;admissible schedule;approximate algorithm;deadline interval	The problem of preemptive scheduling in a real-time multiprocessor computing system with release time/deadline intervals is investigated. Approximate algorithms based on the generalization of a single-processor algorithm of relative priority are developed and compared to the exact maximum flow algorithm. An algorithm has been developed for the case where requests for the tasks occur periodically with given periods. An algorithm for determining the values of the processor performance for which there exists an admissible schedule for a given assembly of tasks with release time/deadline intervals has been developed.	algorithm;maximum flow problem;multiprocessing;real-time clock;scheduling (computing)	M. G. Furugyan	2014	Programming and Computer Software	10.1134/S0361768814010034	parallel computing;real-time computing;earliest deadline first scheduling;computer science;distributed computing;multiprocessor scheduling	Embedded	-10.55285216211597	61.125946418938014	87673
64b70107b6c557b13161b40ca51c21dbd7aa0f10	markov model based disk power management for data intensive workloads	power saving;mathematics;performance evaluation;markov;mulit speed;probability density function;disc storage;prediction algorithms;energy management power system modeling predictive models energy consumption spinning costs batteries grid computing mathematical model mathematics;data mining;disk power management;data intensive computer application;accuracy;power aware computing;data intensive workloads;markov model;prediction markov mulit speed power;disk subsystem;power aware computing disc storage hard discs markov processes performance evaluation;indexing;energy consumption;storage capacity;batteries;power management;prediction accuracy;mathematical model;power saving method;energy savings;predictive models;markov processes;experimental evaluation;data intensive computing;disk idleness prediction mechanism;power system modeling;grid computing;prediction;power;hard discs;multispeed disk management scheme;energy saving;multispeed disk management scheme markov model disk power management data intensive workloads data intensive computer application disk subsystem disk idleness prediction mechanism energy savings power saving method;energy management;spinning	In order to meet the increasing demands of present and upcoming data-intensive computer applications, there has been a major shift in the disk subsystem, which now consists of more disks with higher storage capacities and higher rotational speeds. These have made the disk subsystem a major consumer of power, making disk power management an important issue. People have considered the option of spinning down the disk during periods of idleness or serving the requests at lower rotational speeds when performance is not an issue. Accurately predicting future disk idle periods is crucial to such schemes. This paper presents a novel disk-idleness prediction mechanism based on Markov models and explains how this mechanism can be used in conjunction with a three-speed disk. Our experimental evaluation using a diverse set of workloads indicates that (i) prediction accuracies achieved by the proposed scheme are very good (87.5% on average); (ii) it generates significant energy savings over the traditional power-saving method of spinning down the disk when idle (35.5% onaverage); (iii) it performs better than a previously proposed multi-speed disk management scheme (19% on average); and (iv) the performance penalty is negligible (less than 1% on average). Overall, our implementation and experimental evaluation using both synthetic disk traces and traces extracted from real applications demonstrate the feasibility of a Markov-model-based approach to saving disk power.	computer;data-intensive computing;disk storage;hard disk drive;logical disk manager;markov chain;markov model;power management;synthetic intelligence;tracing (software)	Rajat Garg;Seung Woo Son;Mahmut T. Kandemir;Padma Raghavan;Ramya Prabhakar	2009	2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid	10.1109/CCGRID.2009.67	hard disk drive performance characteristics;real-time computing;simulation;prediction;computer hardware;computer science;operating system;statistics	Arch	-16.561061701104894	66.29170175204068	87683
03d54ba9d26a5007cca24d433fb650ebf9930a35	improving energy efficiency of virtual machines with timer tick variations			timer	Bijoy A. Jose;Abhishek Agrawal	2015	J. Low Power Electronics	10.1166/jolpe.2015.1386	real-time computing;engineering;efficient energy use;timer;virtual machine	HPC	-5.255267306536847	61.464387543509524	87691
749f9ba25d49bc0884b9c21f36fe72acad610843	dynamic control of the join-queue lengths in saturated fork-join stations	settore inf 01 informatica	The analysis of fork-join queueing systems has played an important role for the performance evaluation of distributed systems where parallel computations associated with the same job are carried out and a job is considered served only when all the parallel tasks it consists of are served and then joined. The fork-join nodes that we consider consist of (Kge 2) parallel servers each of which is equipped with two FCFS queues, namely the service-queue and the join-queue. The former stores the tasks waiting for being served while the latter stores the served tasks waiting for being joined. When the queueing station is saturated, i.e., the service-queues are never empty, we observe that the join-queue sizes tend to grow infinitely even if the expected service times at the servers are the same. In fact, this is due to the variance of the service time distribution. To tackle this problem, we propose a simple service-rate control mechanism, and show that under the exponential assumption on the service times, we can analytically study a set of relevant performance indices. We show that by selectively reducing the speed of some servers, significant energy saving can be achieved.		Andrea Marin;Sabina Rossi	2016		10.1007/978-3-319-43425-4_8	real-time computing;telecommunications;computer science;mathematics	Robotics	-13.454247978725624	64.99351024177815	87758
47419c7d160fd05f9be712b876c292cb6241228d	dynamic memory balancing for virtual machines	sistema operativo;virtual machine;resource utilization;core storage;virtual memory;modelo prevision;gestion memoire;lru histogram;tranchage;memory management;measurement;estrategia optima;virtualisacion proceso;multiplication operator;resource allocation;storage management;resource manager;resource management;radiobusqueda;memoria central;a la volee;machine virtuelle;memoire centrale;high precision;multiplaje;multiplexing;qualite service;forecast model;optimal strategy;gestion recursos;paging;gestion memoria;histogram;slicing;multiplexage;process virtualization;histogramme;operating system;performancevirtual machine;precision elevee;memoire virtuelle;precision elevada;chapeado;on the fly;gestion ressources;design;systeme exploitation;systems and applications;virtualisation processus;prediction model;asignacion recurso;al vuelo;memory allocation;virtual environment;quality of service;allocation ressource;experimentation;histograma;maquina virtual;management;radiomessagerie;strategie optimale;memoria virtual;service quality;memory balancing;calidad servicio;modele prevision	Virtualization essentially enables multiple operating systems and applications to run on one physical computer by multiplexing hardware resources. A key motivation for applying virtualization is to improve hardware resource utilization while maintaining reasonable quality of service. However, such a goal cannot be achieved without efficient resource management. Though most physical resources, such as processor cores and I/O devices, are shared among virtual machines using time slicing and can be scheduled flexibly based on priority, allocating an appropriate amount of main memory to virtual machines is more challenging. Different applications have different memory requirements. Even a single application shows varied working set sizes during its execution. An optimal memory management strategy under a virtualized environment thus needs to dynamically adjust memory allocation for each virtual machine, which further requires a prediction model that forecasts its host physical memory needs on the fly. This paper introduces MEmory Balancer (MEB) which dynamically monitors the memory usage of each virtual machine, accurately predicts its memory needs, and periodically reallocates host memory. MEB uses two effective memory predictors which, respectively, estimate the amount of memory available for reclaiming without a notable performance drop, and additional memory required for reducing the virtual machine paging penalty. Our experimental results show that our prediction schemes yield high accuracy and low overhead. Furthermore, the overall system throughput can be significantly improved with MEB.	computer data storage;input/output;memory management;multiplexing;on the fly;operating system;overhead (computing);paging;preemption (computing);quality of service;requirement;throughput;virtual machine;working set	Weiming Zhao;Zhenlin Wang;Yingwei Luo	2009	Operating Systems Review	10.1145/1618525.1618530	uniform memory access;distributed shared memory;shared memory;demand paging;embedded system;interleaved memory;real-time computing;simulation;distributed memory;computer science;physical address;virtual machine;virtual memory;resource management;operating system;memory protection;static memory allocation;overlay;extended memory;flat memory model;registered memory;data diffusion machine;memory management	OS	-12.326008436812625	64.91232372302687	88331
3be4311d99813ecaa4c4246553f3c7b98939a909	p2p architecture for scientific collaboration	groupware;resource allocation peer to peer computing groupware;resource allocation;p2p;preferential attachment;small world;social network;collaboration social network services collaborative work resilience peer to peer computing proposals humans open systems network topology conferences;degree distribution p2p architecture file exchange scientific collaboration networks social networks resource allocation system resilience assortative mixing preferential attachment;community structure;collaborative networks;p2p networks;peer to peer computing	P2P networks are often associated with file exchange applications among private users. However, their features make them suitable for other uses. In this paper we present a P2P architecture for scientific collaboration networks, which takes advantage of the properties inherent in these social networks - small-world, clustering, community structure, assortative mixing, preferential attachment and small and stable groups - in order to obtain better performance, efficient use of resources and system resilience.	assortative mixing;attachments;cluster analysis;peer-to-peer;social network	José Mitre;Leandro Navarro-Moldes	2004	13th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises	10.1109/ENABL.2004.48	resource allocation;computer science;knowledge management;peer-to-peer;distributed computing;management;world wide web;community structure;social network	HPC	-13.820781901602375	72.78927555181643	88485
31fbfb42bec8543f2fd8fbf9ea61a878d7a5e54e	prediction-based dynamic resource allocation for video transcoding in cloud computing	video streaming;image segmentation;streaming media transcoding servers resource management prediction algorithms heuristic algorithms high definition video;resource allocation;resource management;prediction algorithms;video coding;video transcoding;servers;virtual machines;streaming media;load prediction video transcoding cloud computing resource allocation;heuristic algorithms;virtual machines cloud computing image segmentation real time systems resource allocation transcoding video coding video on demand video streaming;video on demand;high definition video;load patterns prediction based dynamic resource allocation cloud computing video transcoding service infrastructure as a service cloud virtual machine deallocation vm deallocation video transcoding servers horizontal fashion two step load prediction method proactive resource allocation high prediction accuracy real time constraints multiple on demand video streams video segmentation group of pictures level discrete event simulation;load prediction;transcoding;cloud computing;real time systems	This paper presents prediction-based dynamic resource allocation algorithms to scale video transcoding service on a given Infrastructure as a Service cloud. The proposed algorithms provide mechanisms for allocation and deallocation of virtual machines (VMs) to a cluster of video transcoding servers in a horizontal fashion. We use a two-step load prediction method, which allows proactive resource allocation with high prediction accuracy under real-time constraints. For cost-efficiency, our work supports transcoding of multiple on-demand video streams concurrently on a single VM, resulting in a reduced number of required VMs. We use video segmentation at group of pictures level, which splits video streams into smaller segments that can be transcoded independently of one another. The approach is demonstrated in a discrete-event simulation and an experimental evaluation involving two different load patterns.	algorithm;cloud computing;group of pictures;memory management;real-time clock;simulation;streaming media;virtual machine	Fareed Jokhio;Adnan Ashraf;Sébastien Lafond;Ivan Porres;Johan Lilius	2013	2013 21st Euromicro International Conference on Parallel, Distributed, and Network-Based Processing	10.1109/PDP.2013.44	real-time computing;transcoding;computer science;resource management;operating system;multimedia;computer network	HPC	-16.19953256579625	72.15175017618289	88543
038410b7ee94b4ebeddb9ef799a5515eccee500b	hp: hybrid paxos for wans	distributed system;protocols;quorum system;delay history wide area networks access protocols network servers computer science fault tolerance protection resilience fault tolerant systems;classic paxos;history;fault tolerant;computer crashes;fault tolerant state machine;fast paxos;state machine;protection;servers;network servers;resilience;wan;fault tolerant systems;internet measurement;lead;hybrid paxos;fault tolerance;access protocols;fast paxos hybrid paxos wan fault tolerant state machine wide area networks network delays classic paxos;wide area networks fault tolerance;computer science;europe;wide area networks;network delays	Implementing a fault-tolerant state machine boils down to reaching consensus on a sequence of commands. In wide area networks (WANs), where network delays are typically large and unpredictable, choosing the best consensus protocol is difficult. During normal operation, Classic Paxos (CP) requires three message delays, whereas Fast Paxos (FP) requires only two. However, when collisions occur, due to interfering commands issued concurrently, FP re- quires four extra message delays. In addition, FP uses larger quorums than CP. Therefore, CP can outperform FP in many situations. We present Hybrid Paxos (HP), a consensus protocol that combines the features of FP and CP. HP implements generalized consensus, where collisions are caused only by interfering commands. In the absence of collisions HP requires two message delays, and only one extra message delay otherwise. Our evaluation shows that when collisions are rare, the latency of HP reaches the theoretical minimum. When collisions are frequent, HP behaves like CP.	consensus (computer science);fault tolerance;finite-state machine;maximum throughput scheduling;paxos (computer science)	Dan Dobre;Matthias Majuntke;Marco Serafini;Neeraj Suri	2010	2010 European Dependable Computing Conference	10.1109/EDCC.2010.23	reliability engineering;fault tolerance;real-time computing;computer science;engineering;operating system;distributed computing;finite-state machine;computer security;psychological resilience	Visualization	-6.622528594846428	70.62674648737675	88786
1f3728798964e4572fc6a914d90c8bd39b7f1a6f	dual-phase just-in-time workflow scheduling in p2p grid systems	p2p grid system;protocols;conference_paper;workflow management software grid computing heuristic programming just in time peer to peer computing scheduling;heuristic programming;task scheduling heuristic;p2p;just in time workflow scheduling dual phase model;p2p grid systems;dual phase model;peer to peer computing protocols dynamic scheduling equations delay mathematical model;scheduling;dual phase just in time workflow scheduling method;just in time workflow scheduling dual phase model p2p grid system;geographic distributed computers;decentralized algorithms;mathematical model;workflow management software;decentralized algorithms dual phase just in time workflow scheduling method p2p grid systems geographic distributed computers task scheduling heuristic dynamic shortest makespan first scheduling dsmf;just in time;just in time workflow scheduling;dynamic shortest makespan first scheduling;task scheduling;peer to peer computing;grid computing;dual phase;dsmf;grid system;geographic distribution;dynamic scheduling	This paper presents a fully decentralized just-in-time workflow scheduling method in a P2P Grid system. The proposed solution allows each peer node to autonomously dispatch inter-dependent tasks of workflows to run on geographically distributed computers. To reduce the workflow completion time and enhance the overall execution efficiency, not only does each node perform as a scheduler to distribute its tasks to execution nodes (or resource nodes), but the resource nodes will also set the execution priorities for the received tasks. By taking into account the unpredictability of tasks’ finish time, we devise an efficient task scheduling heuristic, namely dynamic shortest makespan first (DSMF), which could be applied at both scheduling phases for determining the priority of the workflow tasks. We compare the performance of the proposed algorithm against seven other heuristics by simulation. Our algorithm achieves 20%~60% reduction on the average completion time and 37.5%~90% improvement on the average workflow execution efficiency over other decentralized algorithms.	algorithm;computer;dynamic dispatch;heuristic (computer science);makespan;scheduling (computing);simulation	Sheng Di;Cho-Li Wang	2010	2010 39th International Conference on Parallel Processing	10.1109/ICPP.2010.31	communications protocol;parallel computing;real-time computing;dynamic priority scheduling;computer science;operating system;peer-to-peer;mathematical model;distributed computing;scheduling;workflow management system;grid computing	HPC	-16.64100326731167	61.7223190142415	88951
e738b4a4785b509a4fe7b8597025f8c2fa7fbafa	supporting the security awareness of ga-based grid schedulers by artificial neural networks	grid scheduling;computational grid;neural nets;processor scheduling;resource allocation;computer model;genetics;artificial neural networks;computational modeling;security of data genetic algorithms grid computing neural nets resource allocation scheduling;genetic algorithm computational grid scheduling artificial neural network data classification security;scheduling;schedules;genetic algorithm;genetic algorithms;security;genetic scheduling algorithms security awareness ga based grid schedulers artificial neural networks task scheduling resource allocation computational grids resolution methods task abortion awareness scheduling criteria security demand parameters;data classification;grid computing;security of data;artificial neural network;security schedules artificial neural networks genetic algorithms processor scheduling genetics computational modeling	Task scheduling and resource allocation remain still challenging problems in Computational Grids (CGs). Traditional computational models and resolution methods cannot effectively tackle the complex nature of Grid, where the resources and users belong to many administrative domains with their own access policies and users' privileges, and security and task abortion awareness are addressed as important scheduling criteria. In this paper we propose a neural network approach for supporting the security awareness of the genetic-based grid schedulers. Making a prior analysis of trust levels of the resources and security demand parameters of tasks, the neural network monitors the scheduling and task execution processes. The network learns patterns in input (tasks and machines initial characteristics) and outputs (information about resource failures and the resulting tasks and machines characteristics) data, and finally sub-optimal schedules are generated, which are then used to modify the initialization procedures of genetic scheduling algorithms. We extended the Hyper Sim-G Grid simulator framework by Neural Network module to evaluate the proposed model under the heterogeneity, the large-scale and dynamics conditions. The relative performance of GA-based and Neural Network GA-based schedulers is measured by the make span and flow time metrics. The obtained results showed the efficacy of the Neural Network approach to enhance the secure GA-based schedulers.	algorithm;artificial neural network;computation;computational complexity theory;computational model;experiment;fuzzy control system;genetic algorithm;grid computing;heuristic (computer science);job shop scheduling;makespan;metaheuristic;mobile data terminal;neuro-fuzzy;scheduling (computing);security awareness;software release life cycle	Marcin Bogdanski;Joanna Kolodziej;Fatos Xhafa	2011	2011 International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2011.47	real-time computing;computer science;theoretical computer science;distributed computing	HPC	-16.87853227066256	62.91100334773596	89050
90297dec0085d0c6d5dc05081d43d11210aa1539	acb-r: an adaptive clustering-based data replication algorithm on a p2p data-store	distributed system;metodo adaptativo;largeur bande;replication;systeme reparti;availability;disponibilidad;par a par;p2p;adaptive dynamics;methode adaptative;data replication;replicacion;network topology;sistema repartido;poste a poste;adaptive method;anchura banda;retard;bandwidth;retraso;peer to peer;topologie circuit;disponibilite;bandwidth sharing;geographic distribution	Replication on geographically distributed, unreliable, P2P interconnecting nodes can offer high data availability and low network latency for replica access. The challenge is how to take good control of the number of replicas and their distribution over well-chosen nodes to get a good replica access performance. We observe that, there exists such a logical node cluster overlay over any P2P data-store's underlying network topology that the replica transmission delay of inter-cluster is much greater than that of intra-cluster because of geographical distance or bandwidth sharing between nodes in different clusters. Based on nodes-clustering, we propose a decentralized algorithm ACB-R to direct the data replication, which can adapt dynamically to the changing replica access patterns or network topologies. The experiment shows that ACB-R can benefit much of the access requests at the price of negligible intra-cluster replica transmission and consequently achieves a good average replica access performance.	algorithm;replication (computing)	Junhu Zhang;Dongqing Yang;Shiwei Tang	2005		10.1007/11596370_11	availability;replication;telecommunications;computer science;peer-to-peer;database;distributed computing;network topology;bandwidth;replication;statistics;computer network	Theory	-11.801844499967695	70.17238956826252	89110
0b8dd836c7bbadc92696f52f79e4f0d8e908298d	a new method for optimization of allocation and scheduling in real time applications	minimisation;resource allocation real time applications performance improvements parallel processing real time environments rt constraints parallel system mapping problem minimization problem cost function optimal mapping searching space scheduling modalities feasible allocation simulated annealing algorithm adjacency criterion;cost function;search space;resource allocation;simulated annealing algorithm;real time;parallel programming;simulated annealing;performance improvement;parallel systems;scheduling;optimization methods concurrent computing processor scheduling actuators parallel processing cost function simulated annealing real time systems minimization methods computational modeling;search problems;search problems real time systems parallel algorithms parallel programming resource allocation scheduling minimisation simulated annealing;real time application;parallel processing;real time systems;parallel algorithms	Performance improvements achievable through parallel processing are useful in real time (RT) environments. The paper describes a method to map (i.e. allocate and schedule) a program with some RT constraints into a parallel system. We formulate the mapping problem as a minimization problem, defining a new cost function whose minimization leads to the optimal mapping of the program into the parallel system. The searching space over which the minimization must be carried out is defined; this space encloses all the feasible allocation and scheduling modalities for the program in the parallel system. The minimization is carried out through a simulated annealing algorithm, so we define an adjacency criterion on the searching space. Some examples illustrating the capabilities of the proposed method are presented.	mathematical optimization;scheduling (computing)	Moreno Coli;Paolo Palazzari	1995		10.1109/EMWRTS.1995.514320	parallel processing;mathematical optimization;real-time computing;simulated annealing;computer science;distributed computing	Embedded	-13.106386655653758	60.80575570927389	89137
4d027c5783a2b65e43932ff154dd5357414567f1	utilization based secured dynamic scheduling algorithm for real-time applications on grid (u-sdsa)	scheduling algorithms;heuristic algorithms;quality of service;security;dynamic scheduling;real time systems	Security is the major issue in most of the real-time applications, besides there being a stringent requirementfor such applications to provide high QoS. As security algorithmsdemand large computation time, the prevalent real-time packetscheduling algorithms tend to focus on meeting the deadlinewithout having much concern for security requirements. In thispaper, we propose a utilization based secured dynamic schedulingalgorithm (u-SDSA) for real-time applications on grid whichtries to meet both (security and scheduling) the above-mentioned requirements. Using grid of nodes or computing elements asthe distributed framework for processing real-time packets, wetry to ensure maximum guarantee ratio, maximum averagesecurity level, and optimal overall performance. To ensure optimaloverall performance of the grid, our mechanism distributes theincoming packets for processing amongst different nodes basedon utilization of the nodes. If the minimum security level of anincoming packet cannot be ensured, then it is forwarded to oneof the adjacent nodes having the least utilization, provided theutilization of this node is less than the utilization threshold value(U_thresh). Using extensive simulation, we show that the proposedu-SDSA algorithm performs better than the existing algorithms.	algorithm;computation;game theory;load (computing);network packet;nonlinear system;real-time clock;real-time transcription;requirement;scheduling (computing);simulation;time complexity	Surendra Singh;Sachin Tripathi;Suvadip Batabyal	2017	2017 IEEE 31st International Conference on Advanced Information Networking and Applications (AINA)	10.1109/AINA.2017.21	real-time computing;quality of service;dynamic priority scheduling;computer science;information security;operating system;distributed computing;scheduling;computer security;computer network	Embedded	-17.39051234034651	63.70598433312792	89390
990c5d4131d4d37db47ef2c49e146b91ef6c6784	answering multiple-item queries in data broadcast systems	query processing;data management;adaptive algorithm;scheduling algorithm;data broadcast system;data scheduling;data access;data broadcast;mobile computing	A lot of research has been done on answering single-item queries, only a few have looked at answering multiple-item queries in data broadcast systems. The few that did, have proposed approaches that are less responsive to changes in the query queue. It is not immediately clear how single-item scheduling algorithms will perform when used in answering pull-based multiple-item queries. This paper investigates the performance of existing single-item scheduling algorithms in answering multiple-item queries in pull-based data broadcast systems. We observed that Longest Wait First, a near-optimal single-item data scheduling algorithm, has been used in environments where users' data access pattern is skewed. This paper also investigates the performance of Longest Wait First under various user access patterns. We propose $\mathcal{Q}$LWF: an online data broadcast scheduling algorithm for answering multiple-item queries in pull-based data broadcast systems. For the purpose of comparison with $\mathcal{Q}$LWF, we adapted existing pull single-item algorithm, push single-item algorithm, and push multiple-item algorithm to answer multiple-item queries in pull environments. Results from extensive sets of experiments show that $\mathcal{Q}$LWF has a superior performance compared with the adapted algorithms.	broadcasting (networking)	Adesola Omotayo;Ken Barker;Moustafa A. Hammad;Lisa Higham;Jalal Kawash	2009		10.1007/978-3-642-02843-4_13	data access;atomic broadcast;data management;computer science;theoretical computer science;database;distributed computing;mobile computing;scheduling	DB	-14.962430977736574	69.11828949299424	89544
71ca1a76f8180fb658f554a1aa1e97dd5a2aa2bd	a prediction-based two-stage replica replacement algorithm	distributed data;replica value prediction;collaborative work;design engineering;economic forecasting;storage management;prediction of cost data grid replica replacement;distributed computing;data engineering;replica replacement;prediction of cost;internet;costs delay bandwidth grid computing algorithm design and analysis economic forecasting distributed computing collaborative work data engineering design engineering;storage capacity;distributed sites;data access;storage management grid computing internet;bandwidth;grid computing;algorithm design and analysis;data grid;replica value prediction prediction based two stage replica replacement algorithm distributed data data grid internet distributed sites storage capacity;prediction based two stage replica replacement algorithm	To access large and widely distributed data on data grid quickly and efficiently is an important goal of the implementation of data grid. Due to high latency of the Internet, large amounts of data need to be replicated in multiple copies at several distributed sites. However, the storage capacity is limited. So a good replacement algorithm is important to the efficiency of the access to the replicas. In this paper, we propose a prediction-based two-stage replica replacement algorithm. This algorithm achieves a good balance between value and cost by predicting replica value to make sure which replica will be replaced, and predicting the replacement cost to make it as low as possible. Simulation results show that compared with traditional replacement algorithms our prediction-based two-stage replica replacement algorithm shows better performance and efficiency of the data access on data grids.	data access;internet;job stream;page replacement algorithm;real-time web;simulation;single event upset	Tian Tian;Junzhou Luo	2007	2007 11th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2007.4281503	data access;algorithm design;the internet;computer science;theoretical computer science;economic forecasting;data grid;data mining;database;bandwidth;grid computing	HPC	-17.012511318978934	66.7144706021296	89627
24bad18654c0c1fabb2eaad79fc2fb9562e30f94	data placement and task scheduling optimization for data intensive scientific workflow in multiple data centers environment		Running data-intensive scientific workflow across multiple data centers faces massive data transfer problem which leads to low efficiency in actual workflow application for scientists. By considering data size and data dependency, we propose a k-means algorithm based initial data placement strategy that places the most related initial data sets into the same data center at workflow preparation stage. During the execution of scientific workflow, by analyzing interdependent relationship between data sets and tasks, we adopt multilevel task replication strategy to reduce volume of intermediate data transfer. The simulation results show that the proposed strategies can effectively reduce data transfer among data centers and improve performance of running data intensive scientific workflows.	algorithm;big data;cloud computing;cluster analysis;computation;data center;data dependency;data-intensive computing;interdependence;job shop scheduling;k-means clustering;makespan;replication (computing);schedule (project management);scheduling (computing);simulation	Mingjun Wang;Jinghui Zhang;Fang Dong;Junzhou Luo	2014	2014 Second International Conference on Advanced Cloud and Big Data	10.1109/CBD.2014.19	real-time computing;data quality;computer science;database;distributed computing;workflow management system;workflow technology	HPC	-17.132160154641436	60.46100974723326	89955
35ada5b7d89ca47b0ed14421bb025c77847c9c24	an adaptive routing mechanism for p2p resource discovery	p2p resource discovery;notice of violation;protocols;routing;peer to peer systems;unstructured p2p networks;network topology;innovative searching protocol;peer neighbor selection algorithm;telecommunication network routing;query interactions adaptive routing p2p resource discovery large scale decentralize p2p systems peer to peer systems distributed resource discovery unstructured p2p networks search algorithms flooding scheme innovative searching protocol network topology peer neighbor selection algorithm;flooding scheme;notice of violation routing peer to peer computing grid computing uniform resource locators usability large scale systems protocols network topology;adaptive routing;query interactions;telecommunication network routing peer to peer computing;peer to peer computing;distributed resource discovery;uniform resource locators;usability;grid computing;large scale decentralize p2p systems;search algorithms;large scale systems	The key to the usability of large-scale decentralize peer-to-peer (P2P) systems, and one of the most challenge design aspects, is efficient mechanism for distributed resource discovery. Unstructured P2P networks are very attractive because they do not suffer the limitations of centralized systems an the drawbacks of highly structured approaches. However the search algorithms are usually based on simple flooding scheme generating large loads on the network participants. In this paper to address this major limitation, we present the design an evaluation of an innovative searching protocol in unstructured P2P networks. The approach aims at dynamically adapting the network topology to peers' interests, on the basis of a peer neighbor selection algorithm. Each peer builds and maintains profiles of other peers, describing their interests and resources. Given a query, it is consequently routed according to the predicted match with other peers' profiles. Experimental evaluation shows that the approach is able to exploit query interactions among users, in order to dynamically group peer nodes in clusters containing peers with shared interests and organized into a small world topology.	routing	Luca Gatani;Giuseppe Lo Re;Salvatore Gaglio	2005		10.1109/CCGRID.2005.1558556	communications protocol;routing;usability;adaptive routing;computer science;database;distributed computing;world wide web;network topology;grid computing;computer network;search algorithm	ECom	-12.60528787507532	73.44109036732587	90063
b42bad0a9af1f3d3e55d290b3fe02ef1fbf0efa8	prefetching tiled internet data using a neighbor selection markov chain	transmision paquete;data transmission;chaine markov;cadena markov;data prefetch;transition probability;prechargement donnee;cache memory;antememoria;antememoire;electronic book;internet;transmission donnee;packet transmission;transmission paquet;space mapping;transmision datos;large data;markov chain	A large data file in the internet such as a map is served in small pieces, called tiles. To improve the service speed for such data, we can prefetch future tiles while the current one is being displayed. Traditional prefetching techniques examine the transition probabilities among the tiles to predict the next tile to be requested. However, when the tile space is very huge, and a large portion of it is accessed with even distribution, it is very costly to monitor all those tiles. In this paper, we propose a technique that captures the regularity in the tile request pattern by using an NSMC (Neighbor Selection Markov Chain) and predicts future tile requests based on it. The required regularity to use our technique is that the next tile to be requested is dependent on previous k movements (or requests) in the tile space. Map shows such regularity in a sense. Electronic books show a strong such regularity. We show how to build an NSMC and measure its prediction capability through experimentations.	link prefetching;markov chain	Yoo-Sung Kim;Ki-Chang Kim;Soo Duk Kim	2001		10.1007/3-540-48206-7_9	embedded system;markov chain;real-time computing;computer science;artificial intelligence;operating system;database;distributed computing;world wide web;computer security;algorithm;statistics	Metrics	-17.74300116458516	72.13919992622746	90169
b624b2b8ed6c2d935a391cd7af9fc52c41d2a488	traffic characteristics of striped disks in video servers with visual search functions	visual search;video server;queuing networks;video;multiple access	A striping scheme is proposed in which a video program is partitioned into small segments that are stored by distributing them across multiple disks in a video server. In a striped-disk system, the read workload will always be evenly distributed among the component disks as long as the terminals accessing the server perform only normal playback of the video materials. However, if normal playback is combined with visual search capabilities such asrnjumps and skip searches, then the workload on disks could become momentarily unbalanced or skewed, which could cause interruptions in playback at terminals. In this work, we developed a queueing network model for representing multiple accesses to video materials striped across multiple disks of a video server. An approximate analysis was performed on the model to clarify the traffic characteristics of disks when visual searches are executed. One useful finding for the design of video servers is that, spreading video data over a larger number of disks through striping alleviates momentary workload skewing, which enables a server to support more multiple accesses per disk.		Hideki Sakamoto;Hideharu Suzuki;Kazutoshi Nishimura	1998	J. Electronic Imaging	10.1117/1.482655	video;visual search;computer science;video processing;internet privacy;world wide web;computer network	Vision	-15.652732844464389	71.58484397633218	90248
3dffd4e102b776e35d53f6675eaa7762185fdac3	scheduling analysis of tdma-constrained tasks: illustration with software radio protocols	analytical models;tdma;time division multiple access;protocols;software radio protocol;schedulability test tdma constrained task scheduling software radio protocol radio stations dependent tasks channel access protocol periodic task model dependent general multiframe shared resource synchronization transaction model;software radio protocol scheduling analysis gmf tdma;processor scheduling;scheduling analysis;time division multiple access software radio telecommunication scheduling;computational modeling;vectors;scheduling;time division multiple access analytical models protocols processor scheduling scheduling vectors computational modeling;gmf	"""In this paper a new task model is proposed for scheduling analysis of dependent tasks in radio stations that embed a TDMA communication protocol. TDMA is a channel access protocol that allows several stations to communicate in a same network, by dividing time into several time slots. Tasks handling the TDMA radio protocol are scheduled in a manner to be compliant with the TDMA configuration: task parameters such as execution times, deadlines and release times are constrained by TDMA slots. The periodic task model, commonly used in scheduling analysis, is inefficient for the accurate specification of such systems, resulting in pessimistic scheduling analysis results. To encompass this issue, this paper proposes a new task model called Dependent General Multiframe (DGMF). This model extends the existing GMF model with precedence dependency and shared resource synchronization. We show how to perform scheduling analysis with DGMF by transforming it into a transaction model and using a schedulability test we proposed. In this paper we experiment on """"software radio protocols"""" from Thales Communications & Security, which are representative of the system we want to analyze. Experimental results show an improvement of system schedulability using the proposed analysis technique, compared to existing ones (GMF and periodic tasks). The new task model thus provides a technique to model and analyze TDMA systems with less pessimistic results."""	communications protocol;directed graph;graphical modeling framework;radio broadcasting;scsi rdma protocol;scheduling (computing)	Shuai Li;Stéphane Rubini;Frank Singhoff;Michel Bourdellès	2014	2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)	10.1109/HPCC.2014.90	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;distributed computing;time division multiple access;computer network	Embedded	-7.342506559354237	61.86442256267066	90403
fd3538865a0c2192b40c997fcb88b88c06d0e56a	high-speed and low-power network search engine using adaptive block-selection scheme	search engine;rate of change;search engines;chip;power consumption adaptive block selection scheme multiblock tcam chip ternary content addressable memory network search engine internet traffic flexibility table management scalability;telecommunication traffic;low power;internet traffic;internet;computer network management;power consumption;content addressable storage;table lookup;high speed;search engines throughput energy consumption internet art computer aided manufacturing cadcam telecommunication traffic traffic control hardware;computer network management content addressable storage search engines internet telecommunication traffic computer network reliability table lookup;computer network reliability	A new approach for using block-selection scheme to increase the search throughput of multi-block TCAM-based network search engines is proposed. While the existing methods try to counter and forcibly balance the inherent bias of the Internet traffic, our method takes advantage of it. Our method improves flexibility of table management and gains scalability towards high rates of change in traffic bias. It offers higher throughput than the current art and a very low average power consumption. One of the embodiments of the proposed model, using four TCAM chips, can deliver over six times the throughput of a conventional configuration of the same TCAM chips.	application-specific integrated circuit;clock rate;internet;lookup table;low-power broadcasting;network search engine;pro tools;scalability;speedup;storage efficiency;telecommunications access method;throughput;web search engine	Mohammad J. Akhbarizadeh;Mehrdad Nourani;Rina Panigrahy;Samar Sharma	2005	13th Symposium on High Performance Interconnects (HOTI'05)	10.1109/CONECT.2005.20	embedded system;real-time computing;computer science;operating system;search engine;computer network	Networks	-5.657291012867871	66.67982986958029	90527
21cf42ed95f53908b5ef82b54083140ae3c253fa	a note on system-on-chip test scheduling formulation	tecnologia electronica telecomunicaciones;system on chip test automation;test automation;embedded core testing;operations research;body of knowledge;precedence constraints;system on chip;embedded core based test scheduling;precedence constraint;scheduling problem;test scheduling;tecnologias;grupo a;job scheduling;power constrained scheduling	While many different formulations of the embedded core test scheduling problem (ECTSP) have been proposed in test literature recently, a single unified presentation of ECTSP in terms of conventional scheduling patterns has been lacking. There exists a large body of literature on multi-processor scheduling which can be directly applied to ECTSP; in this paper the author presents an introduction to scheduling notation and demonstrates the mapping between many important test scheduling problems like power-constrained, precedence constrained, and defect-oriented scheduling to conventional multi-processor job scheduling problems. Two examples are presented to illustrate this mapping. This unified presentation should make the existing body of knowledge in Operations Research scheduling research easily accessible to test engineers and test automation tool developers.	embedded system;job scheduler;multiprocessing;operations research;scheduling (computing);software bug;system on a chip;test automation;test engineer;windows nt processor scheduling	Sandeep Koranne	2004	J. Electronic Testing	10.1023/B:JETT.0000029463.01808.5e	system on a chip;fair-share scheduling;nurse scheduling problem;embedded system;job shop scheduling;parallel computing;real-time computing;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;job scheduler;genetic algorithm scheduling;body of knowledge;two-level scheduling;distributed computing;scheduling;instruction scheduling;multiprocessor scheduling	EDA	-7.264209373493018	62.29126047107129	90597
4216191d4d5551a43228c60afaa79c62f1b07850	self-stabilizing structured ring topology p2p systems	p2p system;protocols;network protocol self stability structured ring topology p2p systems modeless peer to peer network construction protocol peer to peer network maintenance protocol ring network protocol distributed asynchronous message passing protocol bootstrapping system network topology;message passing;technical report;peer to peer computing;telecommunication network topology;message passing telecommunication network topology peer to peer computing protocols;protocols network topology computer science time measurement costs convergence fault tolerant systems information retrieval merging monitoring	We propose a self-stabilizing and modeless peer-to-peer (P2P) network construction and maintenance protocol, called the Ring Network (RN) protocol. The RN protocol, when started on a network of peers that are in an arbitrary state, will cause the network to converge to a structured P2P system with a directed ring topology, where peers are ordered according to their identifiers. Furthermore, the RN protocol maintains this structure in the face of peer joins and departures. The RN protocol is a distributed and asynchronous message-passing protocol, which fits well the autonomous behavior of peers in a P2P system. The RN protocol requires only the existence of a bootstrapping system which is weakly connected. Peers do not need to be informed of any global network state, nor do they need to assist in repairing the network topology when they leave. We provide a proof of the self-stabilizing nature of the protocol, and experimentally measure the average cost (in time and number of messages) to achieve convergence.	autonomous robot;bootstrapping (compilers);connectivity (graph theory);converge;experiment;fits;global network;identifier;message passing;mode (computer interface);network topology;peer-to-peer;ring network;self-stabilization	Ayman Shaker;Douglas S. Reeves	2005	Fifth IEEE International Conference on Peer-to-Peer Computing (P2P'05)	10.1109/P2P.2005.34	internet protocol;reverse address resolution protocol;otway–rees protocol;communications protocol;general inter-orb protocol;ring network;message passing;network architecture;network management station;resource reservation protocol;internet protocol control protocol;computer science;technical report;link control protocol;theoretical computer science;tunneling protocol;network simulation;distributed computing;network management application;internet protocol suite;port control protocol;nat port mapping protocol;programming language;world wide web;network topology;computer network;logical topology;internetwork protocol	Networks	-7.520636612734653	72.58619964707663	91226
9168134cd9643918c4a94ee7a923946cf2e166fe	e-arl: an economic incentive scheme for adaptive revenue-load-based dynamic replication of data in mobile-p2p networks	economic incentive;replication;economic scheme;context aware;mobile device;performance evaluation;low energy;availability;network performance;p2p;data replication;network connectivity;success rate;mobile p2p;load balance;p2p networks;quality of service;peer to peer	In mobile ad hoc peer-to-peer (M-P2P) networks, frequent network partitioning occurs due to peer movement or owing to peers switching ‘off’ their mobile devices. This leads to typically low data availability in M-P2P networks, thereby necessitating data replication. This work proposes E-ARL, which is a novel Economic scheme for Adaptive Revenue-Load-based dynamic replication of data in dedicated M-P2P networks with the aim of improving data availability. Thus, E-ARL considers a mobile cooperative environment, where the MPs are working towards the same goal, and the network performance is facilitated by the economic scheme. E-ARL essentially allocates replicas based on its economic scheme. Each data item has a price in virtual currency. E-ARL requires a query issuing peer to pay the price of its queried data item to the query-serving peer and a commission to relay peers in the successful query path. The main contributions of E-ARL follow. First, it uses an economic scheme for efficiently managing M-P2P resources in a context-aware manner by facilitating effective replica hosting and message relaying by peers. Second, it collaboratively performs bid-based replica allocation to facilitate better quality of service. Third, it incorporates both revenue-balancing and load-balancing to improve peer participation and performance. Fourth, it conserves the energy of low-energy MPs to facilitate network connectivity. Our performance evaluation shows that E-ARL is indeed effective in improving peer participation in M-P2P networks, thereby improving query response times, query success rates, query hop-counts and replica allocation traffic.	data item;game theory;hoc (programming language);load balancing (computing);mps (format);mobile device;network partition;network performance;peer-to-peer;performance evaluation;prototype;quality of service;relay;replication (computing);virtual currency	Anirban Mondal;Sanjay Kumar Madria;Masaru Kitsuregawa	2010	Distributed and Parallel Databases	10.1007/s10619-010-7063-6	availability;replication;quality of service;computer science;load balancing;operating system;peer-to-peer;mobile device;database;distributed computing;network performance;computer security;replication;computer network	DB	-13.414995802357922	73.49183147734689	91230
d02018c6a44aa8f24209450eb41d72266777e224	load balancing method based on load vector	distributed system;eficacia sistema;systeme reparti;homogeneous heterogeneous systems;load vector;sistema informatico;distributed processing;heterogenous system;simulation;performance systeme;simulacion;computer system;system performance;algorithme;algorithm;sistema repartido;load balancing;systeme informatique;load balance;traitement reparti;tratamiento repartido;algoritmo	In the distributed processing applications, the dynamic load balancing is considered to be important. In most of the past studies concerning the dynamic load balancing, where the load is distributed based on the information during the job execution by the system, the load of a computer is defined as the number of jobs in execution on the computer. In other words, the computer resources are given little consideration. Even if the computer resources are considered, the model is defined as a homogeneous system composed of computers of the same performance, which seems to deviate from reality.	computer;distributed computing;job stream;load balancing (computing);system of linear equations	Sotetsu Ri;Yusheng Ji;Shoichiro Asano;Jun Matsukata	1994	Systems and Computers in Japan	10.1002/scj.4690250202	embedded system;network load balancing services;real-time computing;computer science;load balancing;distributed computing;computer performance	HPC	-13.106055557885329	63.40203980188878	91273
708c68d086dcb8a8ed4dbd6a153267fefc3aafad	on evaluating the influence of user’s music listening habits on cache replacement policies		Some of current Information-centric cellular networks strongly rely on clustering techniques to group users with similar preferences or behavior and assign them to a common base station. As a result, the most useful contents are kept near to users, thereby alleviating backhaul bottlenecks. Despite the performance gains, such strategies frequently adopt the same replacement policy, irrespectively the users’ profile. This paper presents a simulation-based study that evaluates the performance of cache replacement policies through clusters formed by users according to their music listening habits. It shows the benefits of using caching strategies according to users’ pattern of behavior on downloading songs. To accomplish such goals, we carried out a data mining based analysis of traces obtained from a music streaming service to identify user groups that share similar listening habits. The resulting clusters supported the experimental study carried out to evaluate the performance of three usual replacement policies.	backhaul (telecommunications);cache (computing);cluster analysis;data mining;download;experiment;hit (internet);online music store;simulation;streaming media;tracing (software);user profile	Stefani S. Pires;Adriana V. Ribeiro;Antonio M. de Sousa;Allan E. S. Freitas;Leobino Nascimento Sampaio	2018	2018 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2018.8538757	computer network;cluster analysis;distributed computing;cache;active listening;backhaul (telecommunications);computer science;data modeling;server;upload;cellular network	Metrics	-16.893319857026817	72.85456279954055	91334
4aad4c8f117bf946183840de408ae2a257abaae9	on the complexity of scheduling with communication delay and contention	grafo aciclico;protocole transmission;probleme np complet;np completeness;flot donnee;precedence constrained scheduling;graphe acyclique;mensajeria;flujo datos;messagerie;acyclic graph;message contention;protocolo transmision;interprocessor communication delays;scheduling;directed graph;message handling;graphe oriente;interprocessor communication;communication delay;ordonamiento;grafo orientado;problema np completo;temps retard;delay time;data flow;tiempo retardo;ordonnancement;np complete problem;transmission protocol	We show the NP-Completeness of two processor scheduling with tasks of execution time 1 or 2 units and unit interprocessor communication latency. We develop a model of scheduling in the presence of communication contention, and show the NP-Completeness of two processor scheduling with unit execution time tasks in our model.	inter-process communication;np-completeness;run time (program lifecycle phase);scheduling (computing);windows nt processor scheduling	Michael G. Norman;Susanna Pelagatti;Peter Thanisch	1995	Parallel Processing Letters	10.1142/S012962649500031X	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;np-complete;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;foreground-background;two-level scheduling;deadline-monotonic scheduling;distributed computing;least slack time scheduling;round-robin scheduling;algorithm	Arch	-11.28184014522893	61.80752164971133	91592
2280526394304a86e03d2f6be6792064a432a2c2	optimisation du cache sibling à l'aide d'une architecture pair à pair	estensibilidad;distributed system;red sin hilo;optimisation;gestion memoire;streaming;scalable video;systeme reparti;informatique mobile;multimedia;optimizacion;reseau sans fil;echange document;par a par;transmision continua;storage management;wireless network;cache memory;document exchange;intergiciel publication souscription;antememoria;peer to peer p2p;gestion memoria;antememoire;transmission en continu;sistema repartido;senal video;signal video;poste a poste;intergicial editor suscriptor;intercambio documento;jxta;video signal;video cache strategy;optimization;extensibilite;scalability;mobile computing;peer to peer;publish subscribe middleware	Nowadays, the data search concept on a peer to peer (P2P) network is more and more widely used. A new approach of this technique is the use of peer to peer technology for streaming video multimedia applications.The throughputs on future-generation wireless networks will be able to dispatch several multimedia streams simultaneously and their capabilities to handle download and upload throughputs will provide real interactivity in future multimedia applications. We have developed a cache sibling architecture called PACS whose issue is to increase the data exchange between caches. In this article, we intend to deal with document exchanges between caches thanks to a P2P platform.	mathematical optimization	Jean-Baptiste Ernst-Desmulier;Damien Charlet;Pascal Chatonnay;Julien Bourgeois;François Spies	2005	Technique et Science Informatiques	10.3166/tsi.24.887-907	scalability;cpu cache;telecommunications;computer science;operating system;wireless network;database;distributed computing;mobile computing;world wide web;computer security;computer network	Logic	-12.716561694516253	70.58477488598699	91600
03dfa1e58d12819cc55f5bf52e476ae4914bad0f	a comparison of replication strategies for reliable decentralised storage	comparative analysis;dhash;fault tolerant;distributed hash table;data replication;indexing terms;data storage;chord;simulation technique;communication cost;reliable storage;peer to peer	Distributed hash tables (DHTs) can be used as the basis of a resilient lookup service in unstable environments: local routing tables are updated to reflected changes in the network; efficient routing can be maintained in the face of participant node failures. This fault-tolerance is an important aspect of modern, decentralised data storage solutions. In architectures that employ DHTs, the choice of algorithm for data replication and maintenance can have a significant impact upon performance and reliability. This paper presents a comparative analysis of replication algorithms for architectures based upon a specific design of DHT. It presents also a novel maintenance algorithm for dynamic replica placement, and considers the reliability of the resulting designs at the system level. The performance of the algorithms is examined using simulation techniques; significant differences are identified in terms of communication costs and latency.	algorithm;computer data storage;control theory;distributed hash table;fault tolerance;lookup table;qualitative comparative analysis;replication (computing);routing table;simulation	Matthew John Leslie;Jim Davies;Todd Huffman	2006	JNW	10.4304/jnw.1.6.36-44	qualitative comparative analysis;embedded system;fault tolerance;real-time computing;index term;computer science;chord;operating system;key-based routing;computer data storage;database;distributed computing;chord;world wide web;replication;computer network	Networks	-11.469798290450417	72.46709228121762	91925
e27c28bb2b2d9b9ab2eb19173a139ac57e81bd66	an energy saving mechanism based on vacation queuing theory in data center networks		To satisfy the growing need for computing resources, data centers consume a huge amount of power which raises serious concerns regarding the scale of the energy consumption and wastage. One of the important reasons for such energy wastage relates to the redundancies. Redundancies are defined as the backup routing paths and unneeded active ports implemented for the sake of load balancing and fault tolerance. The energy loss may also be caused by the random nature of incoming packets forcing nodes to stay powered on all the times to await for incoming tasks. This paper proposes a re-architecturing of network devices to address energy wastage issue by consolidating the traffic arriving from different interfaces into fewer ports and turning off the idle ones. This paper also proposes to attribute sleeping and active periods to the processing ports to prevent them from remaining active waiting for random arrivals. Finally, we use the vacation queuing theory to model the packets arriving process and calculate the expectation of vacation periods and the energy saved. Then, we strengthen our work with a simulation part that validates the analytical derivations and shows that the proposed mechanism can reduce more than 25% of the energy consumption.	data center;queueing theory	Emna Baccour;Ala Gouissem;Sebti Foufou;Ridha Hamila;Zahir Tari;Albert Y. Zomaya	2017		10.1007/978-3-319-90775-8_16	networking hardware;fault tolerance;real-time computing;energy consumption;data center;load balancing (computing);network packet;backup;business;idle	OS	-9.266388878362374	70.30695672256289	91927
0ece6b25ddce863fd7c7ea1644511a33c41414c5	analysis of practical backoff protocols for contention resolution with multiple servers	optical network;multiple access channel;dynamic routing;standard model;client server;contention resolution	Backoff protocols are probably the most widely used protocols for contention resolution in multiple access channels. In this paper, we analyze the stochastic behavior of backoff protocols for contention resolution among a set of clients and servers, each server being a multiple access channel that deals with contention like an Ethernet channel. We use the standard model in which each client generates requests for a given server according to a Bernoulli distribution with a specified mean. The client-server request rate of a system is the maximum over all client-server pairs (i, j) of the sum of all request rates associated with either client i or server j. (Having ‘a sub-unit client-server request, rate is a necessary condition for stability for single-server systems.) Our main result is that any superlinear polynomial backoff protocol is stable for any multiple-server system with a sub-unit clientserver request rate. We confirm the practical relevance of our result by demonstrating experimentally that the average waiting time of requests is very small when such a system is run with reasonably few clients and reasonably small request rates such as those that occur in actual ethernets. Our result is the first proof of stability for any backoff protocol for contention resolution with multiple servers. (The multipleserver problem does not reduce to the single-server problem, because each client can only send a single message at any step.) Our result is also the first proof that any weakly acknowledgment based protocol is stable for contention resolution with multiple servers and such high request rates. Two special cases of our result are of interest. Hastad, Leighton and Rogoff have shown that for a single-server system with a ‘A version of this paper is currently available by email. tE-mail: leslie@rdcs.warwick.ac.uk. Address: Dept. of Computer Science, Univ. of Warwick, Coventry, CV4 7AL, UK. Part of this work was performed at Sandia National Laboratories and was supported by the U.S. Department of Energy under contract DEAC04-76DP00789. Part of this work was supported by the ESPRIT Basic Research Action Programm e of the EC under contract No. 20244 (project ALCOM-IT). *E-mail: phihnacOcs.sandia.gov. Address: Sandia National Laboratories, Albuquerque, NM 87185-1110. This work was performed at Sandia National Laboratories and was supported by the U.S. Department of Energy under contract DEACO476DP00789. Philip D. MacKenzie3 sub-unit client-server request rate any modified superlinear polynomial backoff protocol is stable. These modified backoff protocols are similar to standard backoff protocols but require more random bits to implement. The special case of our result in which there is only one server extends the result of Hastad, Leighton and Rogoff to standard (practical) backoff protocols. Finally, our result applies to dynamic routing in optical networks. Specifically, a special case of our result demonstrates that superlinear polynomial backoff protocols are stable for dynamic routing in optical networks.	acknowledgment index;backoff;bernoulli polynomials;client–server model;computer science;email;experiment;mail (macos);polynomial;relevance;routing;server (computing)	Leslie Ann Goldberg;Philip D. MacKenzie	1996		10.1006/jcss.1998.1590	standard model;real-time computing;adaptive routing;computer science;distributed computing;exponential backoff;client–server model;computer network	Theory	-13.524032927000363	65.94224199479615	92009
520d7d47e695e7bf66b3b8372cc7ea62d8f07280	an empirical study of the robustness of energy-aware schedulers for high performance computing systems under uncertainty		This article presents an empirical evaluation of energy-aware schedulers under uncertainties in both the execution time of tasks and the energy consumption of the computing infrastructure. We address an important problem with direct application in current clusters and distributed computing systems, by analyzing how the list scheduling techniques proposed in a previous work behave when considering errors in the execution time estimation of tasks and realistic deviations in the power consumption. The experimental evaluation is performed over realistic workloads and scenarios, and validated by in-situ measurements using a power distribution unit. Results demonstrate that errors in real-world scenarios have a significant impact on the accuracy of the scheduling algorithms. Different online and offline scheduling approaches were evaluated, and online approach showed improvements of up to 32% in computing performance and up to 18% in energy consumption over the offline approach using the same scheduling algorithm.		Santiago Iturriaga;Sebastián García;Sergio Nesmachnow	2014		10.1007/978-3-662-45483-1_11	real-time computing;distributed computing	HPC	-16.473746984956655	60.914289915615825	92012
1cbcf69b031185486fd85c317063c746a74d4269	tag indexed dht for scalable search infrastructure in social networkapplications	information retrieval;distributed processing;keyword search;indexing;social sciences computing;computational complexity;indexation;peer to peer;file organisation	"""Social applications associate a set of user defined keywords named tags when publishing social objects in order to locate them later. We propose T-DHT, a hybrid unstructured-structured DHT based approach, to cope with the high demanding requirements of social applications, in a fully scalable, distributed and balanced way. T-DHT behaves as a structured DHT when publishing """"tag, social-object"""" associations, and as an unstructured filter driven network when searching for the social-objects by means of any tag combination. The publishing process stores tag information across node links in order to drive adequately the later search operations in at most O(Log(N)). The search process takes at most O(logN) node hops for any tag combination and uses the previously stored node link tag information. Although T-DHT has been devised to build a scalable social application infrastructure, it can also be applied to solve general peer-to-peer keyword search problems"""	distributed hash table;peer-to-peer;requirement;scalability;search algorithm;social objects	Alberto Mozo;Joaquín Salvachúa	2006	Sixth IEEE International Conference on Peer-to-Peer Computing (P2P'06)	10.1109/P2P.2006.43	search engine indexing;computer science;operating system;database;distributed computing;computational complexity theory;world wide web;information retrieval	DB	-12.428843560828396	72.55576422034581	92125
2f58862dd02b9029c4d43d42093ff5922e5358a8	a mechanism for improving web server performance using fuzzy concept	fuzzy concept;file servers;performance isolation web server performance fuzzy concept load balancing fuzzy control workload estimation;resource allocation;fuzzy control;differentiated service;web server load management fuzzy control switches delay high performance computing quality of service information technology fuzzy systems industrial electronics;workload estimation;internet;resource allocation file servers fuzzy control internet;load balancing;web server performance;load balance;performance isolation	This paper presents a mechanism to improve Web server performance with fuzzy-based techniques. A load balancing mechanism based on the fuzzy control technique is developed in such a way that ambiguous situations caused by workload estimation of cluster- based Web servers, client request rates, and dynamic request rates can be represented in an effective way. Extensive experiments show that the fuzzy-based performance isolation technique improves the performance of Web servers in terms of the 95- percentile response times.	experiment;fuzzy concept;fuzzy control system;load balancing (computing);server (computing);web server	Bumjoo Park;Kiejin Park;Dongmin Shin;Sungsoo Kim	2007	7th IEEE International Conference on Computer and Information Technology (CIT 2007)	10.1109/CIT.2007.61	round-robin dns;real-time computing;computer science;load balancing;operating system;database;distributed computing;computer security;fuzzy control system;server;computer network;server farm	DB	-17.96807589548784	69.19466771767253	92173
da3d348d6bdc3358f1d643387e5363154750bf08	holistic analysis of asynchronous real-time transactions with earliest deadline scheduling	multiprocessor systems;earliest deadline first;real time;schedulability analysis;general purpose processor;scheduling algorithm;scheduling algorithms;distributed real time system;heterogeneous multiprocessors;precedence constraint;task allocation;real time systems	In distributed real-time systems, an application is often modeled as a set of real-time transactions, where each transaction is a chain of precedence-constrained tasks. Each task is statically allocated to a processor, and tasks allocated on the same processor are handled by a single-processor scheduling algorithm. Precedence constraints among tasks of the same transaction are modeled by properly assigning scheduling parameters as offsets, jitters and intermediate deadlines. In this paper we address the problem of schedulability analysis of distributed real-time transactions under the earliest deadline first scheduling algorithm. We propose a novel methodology that reduces the pessimism introduced by previous methods by explicitly taking into account the offsets of the tasks. Moreover, we extend the analysis to account for blocking time due to shared resources. In particular, we propose two kinds of schedulability tests, CDO-TO and MDO-TO, and show, with an extensive set of simulations, that they provides improved schedulability conditions with respect to classical algorithms. Finally, we apply the methodology to an important class of systems: heterogeneous multiprocessor systems, with a general purpose processor and one or more coprocessors (DSPs). © 2006 Published by Elsevier Inc.	acceptance testing;blocking (computing);coprocessor;earliest deadline first scheduling;experiment;feasible region;heuristic (computer science);holism;multidisciplinary design optimization;multiprocessing;np-hardness;offset (computer science);pseudocode;real-time clock;real-time computing;scheduling (computing);scheduling analysis real-time systems;search algorithm;simulated annealing;simulation;vergence;windows nt processor scheduling	Rodolfo Pellizzoni;Giuseppe Lipari	2007	J. Comput. Syst. Sci.	10.1016/j.jcss.2006.04.002	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;distributed computing;least slack time scheduling;scheduling	Embedded	-9.405196514777828	60.48717493622178	92203
6fc9e6cbe09ced5347eafc7482b8e7cffdd39219	operating system support for a video-on-demand file service	performance guarantee;disk scheduling;continuous media;interactive video;real time;operating system;design and implementation;video on demand;rate monotonic scheduling;weighted round robin;non real time;admission control	This paper describes the design and implementation of a continuous media file server intended for use in emerging video-on-demand applications. The main fo- cus and contribution of the paper is in scheduling and admission control algo- rithms for accessing the server's processor and storage resources. The schedul- ing algorithms support multiple classes of tasks with diverse performance requirements and allow for the co-existence of guaranteed real-time requests with sporadic, and unsolicited requests. The scheduler maintains performance guarantees for real-time streams in the presence of unpredictably varying non- real-time traffic while ensuring system stability even during overloads. A proto- type video file server was implemented on an Intel 486 platform. Performance results show that a large number of streams can be supported, while maintaining efficient utilization of system resources.	operating system	K. K. Ramakrishnan;Lev Vaitzblit;Cary G. Gray;Uresh Vahalia;Dennis Ting;Percy Tzelnic;Steve Glaser;Wayne Duso	1993		10.1007/3-540-58404-8_20	fair-share scheduling;real-time computing;computer science;rate-monotonic scheduling;operating system;distributed computing;round-robin scheduling;i/o scheduling;weighted round robin	OS	-12.202602835436503	62.8543394396058	92274
113a26ef1389705286ceb1acb801d5b404e3ed14	high-throughput sketch update on a low-power stream processor	simd;bit rate 10 gbit s;sketch;imagine stream processor;kernel;simd stream processor;low power stream processor;data stream;radiation detectors;process network;pipeline architecture;parallel programming;data stream processing;frequency 500 mhz;vliw;computer architecture;low power;minimum sized ip packet;parallel architectures;high throughput sketch update;streaming media;data structures;sketch data structure;indexation;stream architecture;mathematical model;ip networks;register file;high throughput;network processors;data structure;pipeline processing;indexed stream register file;parallel algorithms	Sketch algorithms are widely used for many networking applications, such as identifying frequent items, top-k flows, and traffic anomalies. This paper explores the implementation of the Count-Min sketch update using Indexed SRF accesses on a SIMD stream processor (Imagine). Both the sketch data structure and the packet stream are modeled as streams, and in-lane accesses to the stream register file (SRF) support concurrent updates without explicit synchronization. The 500-MHz stream processor is capable of supporting sketch update at 10 Gbps throughput for minimum-sized IP packets. This is nearly the same performance as the 1.4-GHz Intel IXP2800 (13 Gbps), using significantly less power (2.89W vs. 21W).	algorithm;count–min sketch;data rate units;data structure;low-power broadcasting;network packet;register file;simd;stream processing;throughput;traffic analysis	Yu-Kuen Lai;Gregory T. Byrd	2006	2006 Symposium on Architecture For Networking And Communications Systems	10.1145/1185347.1185364	high-throughput screening;parallel computing;kernel;real-time computing;data structure;simd;computer science;very long instruction word;operating system;mathematical model;parallel algorithm;particle detector;register file;network processor	Arch	-6.823712484124267	65.96511163192366	92406
51352be9e3e7e0da856faec023e58765941940bd	fuzzy logic load-balancing strategy based on software-defined networking		Traditional load balancing hardware is expensive and lacks scalability and flexibility. We propose a load balancing strategy based on fuzzy logic (LBSFL), which exploits the control and forwarding separation architecture characteristics of software-defined networking (SDN). First, the fuzzy membership function that affects the performance parameters of the server load is analyzed. Based on this, the load state of the virtual server is evaluated through fuzzy logic. Then the centralized control capability of SDN’s controllers for the whole network is utilized to monitor virtual server information in real time and to schedule virtual server tasks. Individual servers can be hibernated or restarted, to save power or to increase performance as necessary. Finally, the dynamic balance between the overall load, performance and energy consumption is realized. Simulation experiments showed that the proposed strategy improves overall performance of the network, especially when dealing with communication-intensive tasks and using a high-latency network.	fuzzy logic;load balancing (computing);software-defined networking	Guoyan Li;Tianying Gao;Zhigang Zhang;Yadong Chen	2017		10.1007/978-3-319-90802-1_42	fuzzy logic;architecture;software-defined networking;computer science;scalability;exploit;load balancing (computing);distributed computing;server;membership function	HPC	-18.173533056893568	68.29938985193218	92494
46c7d0bbf7731950aadf4a2f19bff7f9d80f0a02	saving 200kw and $200 k/year by power-aware job/machine scheduling	power engineering computing electric charge job shop scheduling parallel machines power consumption;empirical study;electric charge;job shop scheduling;power efficiency;10 tflops;power engineering computing;supercomputers processor scheduling energy consumption power engineering computing high performance computing hardware degradation computer science power engineering and energy space charge;waiting time;kyoto university supercomputer system;job machine scheduling;parallel machines;fiscal year;machine scheduling;power consumption;electric charge power aware operations job machine scheduling kyoto university supercomputer system 10 tflops;service quality;power aware operations	This paper reports our 3.75-year empirical study on power-aware operations of Kyoto University's supercomputer system. The supercomputer system of 10 TFlops had required about 540 kW on average in its first fiscal year 2004. After that and one-year try-and-error of power efficient operation, we implemented a simple but effective scheduler of jobs and machine powering to improve the per- load power efficiency by up to 39 % and to save 200 kW and $200,000 electric charge in the fiscal year 2006. The power-aware scheduler tries to minimize the number of active nodes in the system of eleven nodes keeping sufficient computational power for given loads. Thus the power- aware scheduler has not degraded, but has significantly improved, the service quality in terms of the average job- waiting time.	flops;performance per watt;scheduling (computing);supercomputer	Junichi Hikita;Akio Hirano;Hiroshi Nakashima	2008	2008 IEEE International Symposium on Parallel and Distributed Processing	10.1109/IPDPS.2008.4536218	job shop scheduling;parallel computing;real-time computing;simulation;electrical efficiency;electric charge;computer science;operating system;distributed computing;empirical research;service quality	Arch	-15.608621819269548	62.75216211842539	92580
50740829fc7dfaf4d500f82525c9d9d3a59c9592	on real-time and non real-time distributed computing	real time;distributed computing;scheduling algorithm;non real time;real time computing	Abs t r ac t . In this paper, taking an algorithmic viewpoint, we explore the differences existing between the class of non real-time computing problems (R~) versus the class of real-time computing problems (~). We show how a problem in class RN can be transformed into its counterpart in class ~. Claims of real-time behavior made for solutions to problems in class ~ are examined. Ah example of a distributed computing	distributed computing;real-time clock;real-time computing;real-time transcription	Gérard Le Lann	1995		10.1007/BFb0022137	distributed algorithm;distributed computing	Embedded	-10.822236987977506	61.53429132063646	92585
b4b7a53ab5d4485bfd4fce2afe74d9d99e6900ec	an sla-enabled grid datawarehouse	qos oriented scheduling;peer to peer computing quality of service data warehouses databases parallel processing predictive models scheduling delay distributed computing scalability;service level agreements grid data warehouse database servers quality of service distributed architecture context performance predict model qos oriented scheduling;quality of service data warehouses distributed databases grid computing;service level agreements;database servers;best effort;distributed architecture context;replicated data;distributed databases;grid data warehouse;performance prediction;service level agreement;data warehouses;quality of service;data warehouse;grid computing;performance predict model	Database servers typically offer a best-effort model of service to submitted commands, that is, they try to process every command as fast as possible. Hence, they are not prepared to provide differentiation for quality of service. In this paper we consider the distributed grid-DWPA architecture context, which fragments and replicates data into several sites to provide an efficient grid data warehouse solution. Instead of offering best-effort service to every query, we propose the use of a performance predict model that is used in conjunction with QoS oriented scheduling to enable the establishment of service level agreements (SLA).	best-effort delivery;high availability;quality of service;replay attack;requirement;scalability;scheduling (computing);service-level agreement	Rogério Luís de Carvalho Costa;Pedro Nuno San-Bento Furtado	2007	11th International Database Engineering and Applications Symposium (IDEAS 2007)	10.1109/IDEAS.2007.14	best-effort delivery;database server;quality of service;computer science;data warehouse;data mining;database;world wide web;grid computing	DB	-18.718631026911968	67.46861935647875	92692
a0c9c44ff7542193e779fc2b4ed5a2039dbb3d02	a flexible layered control policy for resource allocation in a sensor grid	sensor grid;optimization;layered control	The paper proposes a flexible layered control policy for sensor resource allocation in a sensor grid. In order to allocate sensor resources in the system to maximize the sensor grid utility, different controllers are deployed at three levels: a job-level controller, an application group controller, and a sensor grid system controller. At the lowest levels, job-level controllers perform fast, frequent, local adaptation for optimizing a single sensor grid application at a time, while, at the highest levels, sensor grid system controllers perform less frequent control actions to optimize all applications. Sensor grid system control considers all sensor grid applications in response to large system changes at coarse time granularity. Sensor grid system control exploits the interlayer coupling of the resource layer and the application layer to achieve a system-wide optimization based on the sensor grid users' preferences. Job-level control adapts a single application to small changes at fine granularity. The layered control system uses a set of utility functions to evaluate the performance of sensor grid applications and groups. The control system chooses control actions that would result in a higher level of utility. In the simulation, a performance evaluation of the algorithm is carried out.		Chunlin Li;Layuan Li	2012	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2012.04.002	real-time computing;computer science;distributed computing;key distribution in wireless sensor networks	HPC	-17.147651721854743	65.14699469465695	92723
5386b8eaefda8273530e8c9ad58dbb3651f07632	skip ring topology in fast failure detection service	distributed system;fault tolerant;probabilistic communication;failure detection;simulation experiment;local community;fault tolerance;skip list;distributed systems;data structure	This paper addresses the problem of communication among loosely coupled groups of nodes in distributed systems. We describe a novel proposal of logical communication topology based on skip list data structure. We enhance this structure to make it more resilient to failures. Its good self-stabilization characteristics are shown through extensive simulation experiments. We present this new concept in the context of our failure detection service, where we use it at a local communication level.	ring network	Jacek Kobusinski;Filip Gorski;Stanislaw Stempin	2007		10.1007/978-3-540-68111-3_4	fault tolerance;real-time computing;data structure;computer science;distributed computing;programming language;computer network	Metrics	-8.096472765732543	72.03163285324874	92802
304a563c274985b5967dca3712dc300718d032ac	general ternary bit strings on commodity longest-prefix-match infrastructures		Ternary Content-Addressable Memory (tcam) is a powerful tool to represent network services with line-rate lookup time. There are various software-based approaches to represent multi-field packet classifiers. Unfortunately, all of them either require exponential memory or apply additional constraints on field representations (e.g, prefixes or exact values) to have line-rate lookup time. In this work, we propose alternatives to tcam and introduce a novel approach to represent packet classifiers based on ternary bit strings (without constraining field representation) on commodity longest-prefix-match (lpm) infrastructures. These representations are built on a novel property, prefix reorderability, that defines how to transform an ordered set of ternary bit strings to prefixes with lpm priorities in linear memory. Our results are supported by evaluations on large-scale packet classifiers with real parameters from ClassBench; moreover, we have developed a prototype in P4 to support these types of transformations.	algorithm;content-addressable memory;longest prefix match;lookup table;network packet;prototype;telecommunications access method;time complexity	Pavel Chuprikov;Kirill Kogan;Sergey I. Nikolenko	2017	2017 IEEE 25th International Conference on Network Protocols (ICNP)	10.1109/ICNP.2017.8117542	telecommunications network;content-addressable memory;ternary operation;software;longest prefix match;theoretical computer science;computer science;sorting;network packet;prefix	Visualization	-6.32784676813523	67.33598745320175	92826
1bb5fbc959f143233c2e4d7cd845f103f6cfa24e	optimal task scheduling algorithm for cyclic synchronous tasks in general multiprocessor networks	algoritmo paralelo;arquitectura red;parallel algorithm;tâche synchrone cyclique;gestion labor;multiprocessor;parallel computing system;multiprocessor systems;routing;distributed computing;routage;allocation;architecture reseau;delai transmission;algorithme parallele;transmission time;scheduling space;asignacion optima;scheduling algorithm;gestion tâche;computing period;task allocation and scheduling;scheduling;allocation optimale;parallel computer;calculo repartido;network architecture;network structure;task scheduling;distributed systems;multiprocesador;algoritmo optimo;algorithme optimal;plazo transmision;optimal allocation;optimal algorithm;article;calcul reparti;models;ordonnancement;cyclic synchronous tasks;reglamento;exhaustive search;task allocation;multiprocesseur;enrutamiento	We develop an optimal task allocation and scheduling algorithm which minimizes the computing period for multiprocessor systems with general network structures considering task execution time and communication contentions and routing delays explicitly. We presented new ideas of scheduling: (i) individual start allowing overlapping two different iterations, (ii) the scheduling space and the scheduling graph representing feasible schedules, and (iii) the check-and-diffusion algorithm utilizing property of the start-time difference vs. the computing period. With concrete examples of scheduling spaces, segments, and schedules for various multiprocessor network architectures, we showed that individual start reduces the computing period, and our algorithm can find the optimal computing period without exhaustive search. © 2004 Elsevier Inc. All rights reserved.	algorithm;brute-force search;central processing unit;compiler;computer;deterministic routing;embedded system;fossil;fastest;iteration;multiprocessing;numerical analysis;operating system;parallel computing;run time (program lifecycle phase);scheduling (computing);simulation;synchronization (computer science)	Hee-Jun Park;Byung Kook Kim	2005	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2004.04.007	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;distributed computing;round-robin scheduling;scheduling;multiprocessor scheduling;i/o scheduling;computer network	HPC	-12.55607438615345	62.18842202197581	92974
bedfa2b608711e80cb55fd5c930b9297220d12d7	voronoi-diagram based heuristics for the location of mobile and unreliable service providers	service provider;service location;heuristics;parallel processing;voronoi diagram	"""A Computational Geometry Problem, the """"Mobile and Unreliable Service Provider"""", is introduced. Several heuristics to solve this problem are presented, which take advantage of the computations performed when calculating a discrete approximation to the Voronoi diagram. These heuristics, due to their low communication overhead, are appropriate for parallel environments."""	heuristic (computer science);voronoi diagram	Joseph S. Szakas;Christian Trefftz	2006			mathematical optimization;real-time computing;computer science;distributed computing	HCI	-8.998074916033595	69.0118398913154	93076
7746a31e28c6715d2a2ba286ee68ae264d6af943	distributed clouds for collaborative applications	google;virtualization;collaborative application;collaboration;servers collaboration videos synchronization real time systems cloud computing google;servers;synchronization;virtualization cloud computing collaborative application;videos;cloud computing;real time systems	With the advent of social networking and the appearance of Web 2.0, collaborative applications which allow users to share data online, often in real-time, have gained increasing prominence. Whether for sharing images, sharing videos, or even sharing live gaming sessions, such applications must deal with session sizes from tens to tens of thousands of people. However, existing products have not been able to provide a scalable cloud-based system that synchronizes disparate web content among many users. Such a goal is desired in order to provide the benefits of cloud deployments to collaborative applications. Many such applications cannot predict the number of connections which they may need to handle. As such, applications must either provision a higher number of servers in anticipation of more traffic, or be faced with a degradation of the user experience when a large number of clients connect to the application. Cloud-based deployments can alleviate these issues by allowing the application's server base to scale automatically with user demand. A cloud deployment can also distribute servers throughout different geographic locations in order to offer improved latency and response times to its clients. This paper will present an architecture for a distributed, collaborative, and server-based application. The application is deployed inside a distributed cloud environment, which consists of multiple clouds in various geographic locations.	autonomic computing;cloud computing;distributed computing;elegant degradation;image scaling;online chat;overhead (computing);real-time locating system;real-time transcription;real-time web;scalability;server (computing);software deployment;system 7;user experience;web 2.0;web application;web content	Bogdan Solomon;Dan Ionescu;Cristian Gadea;Stejarel Veres;Marin Litoiu;Joanna W. Ng	2012	2012 International Conference on Collaboration Technologies and Systems (CTS)	10.1109/CTS.2012.6261053	synchronization;virtualization;cloud computing;computer science;operating system;cloud testing;distributed computing;internet privacy;world wide web;computer security;server;collaboration	Networks	-18.261779988262013	73.7906211236998	93144
2d692211c220f4b16eabb7639108fba88d00cf2f	regular expression matching on graphics hardware for intrusion detection	data parallel;paper;intrusion detection;nvidia geforce 9800 gx2;cuda;expressive power;spam filtering;graphics hardware;pattern matching;nvidia;graphic processing unit;computer science;string matching;security;network intrusion detection system;regular expression;intrusion detection system	The expressive power of regular expressions has been often exploited in network intrusion detection systems, virus scanners, and spam filtering applications. However, the flexible pattern matching functionality of regular expressions in these systems comes with significant overheads in terms of both memory and CPU cycles, since every byte of the inspected input needs to be processed and compared against a large set of regular expressions. In this paper we present the design, implementation and evaluation of a regular expression matching engine running on graphics processing units (GPUs). The significant spare computational power and data parallelism capabilities of modern GPUs permits the efficient matching of multiple inputs at the same time against a large set of regular expressions. Our evaluation shows that regular expression matching on graphics hardware can result to a 48 times speedup over traditional CPU implementations and up to 16 Gbit/s in processing throughput. We demonstrate the feasibility of GPU regular expression matching by implementing it in the popular Snort intrusion detection system, which results to a 60% increase in the packet processing throughput.	algorithm;antivirus software;byte;central processing unit;commodity computing;computer graphics;data parallelism;email filtering;gigabit;graphics hardware;graphics processing unit;intrusion detection system;load balancing (computing);motherboard;network packet;pci express;parallel computing;pattern matching;prototype;regular expression;snort;speedup;throughput;video card	Giorgos Vasiliadis;Michalis Polychronakis;Spyros Antonatos;Evangelos P. Markatos;Sotiris Ioannidis	2009		10.1007/978-3-642-04342-0_14	intrusion detection system;redos;parallel computing;real-time computing;hardware acceleration;computer science;information security;theoretical computer science;computer security	Arch	-7.4342692907814385	66.33608470707765	93246
8cf76969fd08817de631774b22774108b1aaf855	reliable communication on emulated channels resilient to transient faults	embedding;topology;virtual topology;protocols;distributed protocol;fault tolerant;telecommunication network reliability;protocol design;emulation;fault tolerance reliable communication emulated channel transient fault protocol virtual topology real topology self stabilizing emulation execution slowdown adaptive message delivery delay;transient analysis;virtual topology distributed protocol embedding fault tolerance self stabilization transient fault;protocols emulation information science fault tolerance distributed computing network topology communications technology delay fault tolerant systems large scale systems;self stabilization;fault tolerant computing;reliable communication;synchronization;fault tolerance;transient fault;message passing;telecommunication network topology;telecommunication channels;relays;telecommunication network topology fault tolerant computing message passing protocols telecommunication channels telecommunication network reliability	Topology embedding enables us to execute a protocol designed for a specific (virtual) topology on another(real) topology by embedding the virtual topology on the real topology. In this paper, we propose a self-stabilizing emulation technique that provides reliable communication on a virtual topology in the presence of transient faults. The proposed protocol improves the execution slowdown of previous protocols and provides adaptive message delivery delay on the emulated channels, which is a new type of adaptability against transient faults.		Doina Bein;Toshimitsu Masuzawa;Yukiko Yamauchi	2009		10.1109/PDCAT.2009.53	fault tolerance;real-time computing;computer science;distributed computing;computer network;logical topology	Crypto	-7.003430551432943	71.95847609415453	93261
2588a2aa47dc9f410fbcc3bdc92f6fe4d089ea73	assignment-based partitioning in a condition monitoring system	multi party computation;byzantine agreement;broadcast;quantum signatures;data streams;condition monitoring;complex system;load balance;distributed systems;public key infrastructure	"""A condition monitoring system tracks real-world variables and alerts users when a predefined condition becomes true, e.g., when enemy planes take off, or when suspicious terrorist activities and communication are detected. Figure l(a) illustrates such a system. Each Data Monitor (DM) tracks the state of a real world variable, such as the temperature of a nuclear reactor. Periodically or whenever the variable changes, the DM sends out an update, i.e., a temperature reading. The Condition Evaluator (CE) receives the updates and uses them to evaluate a predefined user condition c, e.g., """"reactor temperature is over 3000 degrees."""" If the condition c is satisfied, an alert is sent to the Alert Presenters (AP), which are responsible for alerting the users. One problem with centralized monitoring systems (those with a single Condition Evaluator) is that the CE can easily get overloaded. A partitioned monitoring system (Figure l(b)), where N independent Condition Evaluators share the workload, alleviates the problem. With balanced partitioning, such a system can achieve an up to N-fold increase in capability. An obvious way of partitioning work in a system monitoring multiple conditions is to assign a subset of the conditions to each CE. However, we are interested in partitioning a single condition because even the work of monitoring one condition may exceed the capability of a single server, when there are high volume of updates and a large amount of work is needed to process each one (e.g., the update can be a satellite image that needs to be analyzed). Moreover, a partitioned system increases the reliability of the monitored condition, because even if one of the CEs goes down, the user should still be able to receive some alerts. We propose assignment-based partitioning as a way to partition the monitoring work among the CEs. In particular, each update is delivered to a subset of the N CEs, while assigned to a single CE among them. When a new update arrives at a particular CE, a quick assignment test is performed first. If an update has not been assigned to this CE, it can be processed very quickly (e.g., its data can be saved in order that a future condition evaluation may refer to this historical data). In this way, each CE is only responsible"""	centralized computing;function overloading;information assurance vulnerability alert;interpreter (computing);reactor (software);server (computing);system monitoring	Yongqiang Huang;Hector Garcia-Molina	2002		10.1145/571825.571849	complex systems;real-time computing;computer science;load balancing;public key infrastructure;operating system;distributed computing;data stream mining;computer security;algorithm	DB	-15.047699112754255	62.81614871067008	93375
95fc2908ee3198501ddd2948925ff9b5a88790dc	a physics-inspired performance evaluation of a structured peer-to-peer overlay network	graph theory;distributed system;computer engineering;performance evaluation;technology;computer and information science;teknikvetenskap;perturbation techniques;satisfiability;computer networks;distributed computer systems;natural sciences;structured overlay networks;complex system;data structures;performance analysis;overlay network;complex systems;datorteknik;data collapse;dht performance;large scale distributed systems;peer to peer overlays;computer simulation;peer to peer overlay networks;large scale systems	In the majority of structured peer-to-peer overlay network s a graph with a desirable topology is constructed. In most cases, the graph is maintained by a periodic activity performed by each node in the graph to preserve the desirable structure in face of the continuous change of the set of nodes. The interaction of the autonomous periodic activities of the nodes renders the performance analysis of such systems complex and simulation of scales of interest can be prohibitive. Physicists, however, are accustomed to deali ng with scale by characterizing a system using intensive variables, i.e. variables that are size independent. The approa ch has proved its usefulness when applied to satisfiability the ory. This work is the first attempt to apply it in the area of distributed systems. The contribution of this paper is twofold. First, we describe a methodology to be used for analyzing the performance of large scale distributed systems . Second, we show how we applied the methodology to find an intensive variable that describe the characteristic beh avior of the Chord overlay network, namely, the ratio of the magnitude of perturbation of the network (joins/failures) to the magnitude of periodic stabilization of the network.	algorithm;autonomous robot;continuation;distributed computing;distributed hash table;experiment;identifier;lookup table;overlay network;peer-to-peer;performance evaluation;rendering (computer graphics);simulation	Sameh El-Ansary;Erik Aurell;Seif Haridi	2005			simulation;computer science;theoretical computer science;distributed computing	Metrics	-11.630330962919857	72.0728283706805	93476
0cdc74540cff7c450e4656c4ef5ee94988d25fe4	performance study of synchronization schemes on parallel cbr video servers	scheduling algorithm;synchronization;video server;cbr;parallel video server	In this paper, we present the performance result and analysis of parallel CBR video servers with conflict-free scheduling algorithms and server synchronization at time slot and time cycle levels. The experimental outcome shows that by relaxing serverlevel synchronization to a time cycle, the conflict-free slot scheduling produces higher stream throughput than the cycle scheduling.	algorithm;case-based reasoning;scheduling (computing);server (computing);throughput	Chow-Sing Lin;Wei Shu;Min-You Wu	1999		10.1145/319878.319916	synchronization;real-time computing;telecommunications;computer science;operating system;scheduling;computer network	Arch	-14.872093333414309	70.52817766594112	93487
aa395d1f17aac2f67d594aa1a090f08e71e38a79	an exact stochastic analysis of priority-driven periodic real-time systems and its approximations	probability;markov processes stochastic analysis periodic real time systems response time distribution deadline miss probability fixed priority system dynamic priority system execution time distributions embedded system scheduling;approximation method;processor scheduling;earliest deadline first;index terms real time and embedded systems;fixed priority;indexing terms;markov processes index terms real time and embedded systems scheduling stochastic analysis;embedded systems;scheduling;markov process;stochastic analysis;markov processes scheduling probability;markov processes;embedded systems markov processes processor scheduling probability;rate monotonic;real time systems;real time and embedded systems	This paper describes a stochastic analysis framework which computes the response time distribution and the deadline miss probability of individual tasks, even for systems with a maximum utilization greater than one. The framework is uniformly applied to fixed-priority and dynamic-priority systems and can handle, tasks with arbitrary relative deadlines and execution time distributions.	approximation algorithm;best practice;best, worst and average case;central processing unit;computational complexity theory;deterministic algorithm;job stream;memory management;multiprocessing;polynomial;real-time clock;real-time computing;response time (technology);run time (program lifecycle phase);simulation;uniprocessor system	Kanghee Kim;José Luis Díaz;Lucia Lo Bello;José María López;Chang-Gun Lee;Sang Lyul Min	2005	IEEE Transactions on Computers	10.1109/TC.2005.174	stochastic process;real-time computing;computer science;theoretical computer science;distributed computing;markov process;statistics	Embedded	-9.57291505534484	61.35916293657708	93522
fa0964e7373783b2f1c02c9fde59c92628495ccc	managing redundant content in bandwidth constrained wireless networks	wireless networks;metadata;redundant content management bandwidth constrained wireless networks redundant content transfer suppression image features android smartphones ns3 simulations;smart phones;content management radio networks smart phones;challenged networks;servers;challenged networks image similarity redundant content reduction;redundancy;metadata servers bandwidth wireless networks redundancy smart phones;bandwidth;redundant content reduction;image similarity	Images/videos are often uploaded in situations like disasters. This can tax the network in terms of increased load and thereby upload latency, and this can be critical for response activities. In such scenarios, prior work has shown that there is significant redundancy in the content e.g., similar photos taken by users transferred. By intelligently suppressing/deferring transfers of redundant content, the load can be significantly reduced, thereby facilitating the timely delivery of unique, possibly critical information. A key challenge here however, is detecting “what content is similar,” given that the content is generated by uncoordinated user devices. Toward addressing this challenge, we propose a framework, wherein a service to which the content is to be uploaded first solicits metadata e.g., image features from any device uploading content. By intelligently comparing this metadata with that associated with previously uploaded content, the service effectively identifies and thus enables the suppression of redundant content. Our evaluations on a testbed of 20 Android smartphones and via ns3 simulations show that we can identify similar content with a 70% true positive rate and a 1% false positive rate. The resulting reduction in redundant content transfers translates to a latency reduction of 44 % for unique content.	android;sensitivity and specificity;sensor;simulation;smartphone;testbed;upload;zero suppression	Tuan A. Dao;Amit K. Roy-Chowdhury;Harsha V. Madhyastha;Srikanth V. Krishnamurthy;Thomas F. La Porta	2017	IEEE/ACM Transactions on Networking	10.1109/TNET.2016.2616901	telecommunications;computer science;operating system;wireless network;internet privacy;redundancy;metadata;world wide web;bandwidth;server;computer network	Mobile	-18.877770159704912	73.68518135428975	93562
1b7e6e3ad7fd2c257ce5d4e4cf46bc1be77cce40	an adaptive hybrid cdn/p2p solution for content delivery networks	amazon aws cloud services adaptive hybrid cdn p2p solution content delivery networks streaming services video on demand netflix youtube akamai optimal quality of service geographically distributed layer content awareness planetlab network;multimedia computing;peer to peer computing servers streaming media reliability quality of service content distribution networks delay;video on demand;social networking online;video delivery content delivery networks peer to peer;peer to peer computing;content based retrieval;video on demand cloud computing content based retrieval multimedia computing peer to peer computing social networking online;cloud computing	Streaming services have grown rapidly in the last few years and providers of video on-demand, such as Netflix or YouTube, are increasing the number of users even more quickly. The majority of these companies implement their services using huge Content Delivery Networks that are as much powerful as expensive, e.g. Amazon and Akamai. In this paper we propose a hybrid CDN/P2P solution that aims at reducing the infrastructural costs exploiting local caching and P2P while guaranteeing an optimal quality of service. The proposed architecture uses a classic CDN complemented by a geographically distributed layer where P2P can be activated exploiting network, content awareness and locality. The performance of the proposed solution is evaluated by means of a prototype implementation that has been deployed using the PlanetLab network and the Amazon AWS cloud services. Our findings show that the proposed approach provides adaptive, flexible, scalable and content centric service to the end users while significantly reducing the infrastructural costs.	amazon web services;cloud computing;content delivery network;locality of reference;planetlab;prototype;quality of service;scalability	Francesco Bronzino;Rossano Gaeta;Marco Grangetto;Giovanni Pau	2012	2012 Visual Communications and Image Processing	10.1109/VCIP.2012.6410737	cloud computing;computer science;internet privacy;world wide web;computer network	Mobile	-17.30463924850812	74.29548577435497	93815
aa53a9944d713cde05cd35e4505a66593e6b62ec	a fast ip routing lookup architecture for multi-gigabit switching routers based on reconfigurable systems	field programmable gate array;resource limitation;longest prefix matching;reconfigurable system;ip address lookup;field programmable gate array fpga;reconfigurable architecture;hashing;longest prefix matching lpm;ip routing;failure rate;reconfigurable hardware	With today’s networks complexity, routers in backbone links must be able to handle millions of packets per second on each of their ports. Determining the corresponding output interface for each incoming packet based on its destination address requires a longest matching prefix search on the IP address. Therefore, IP address lookup is one of the most challenging problems for backbone routers. In this paper, an IP routing lookup architecture is proposed which is based on a reconfigurable hardware platform. Experimental results show that the rate of 193 million lookups per second is achieved using our architecture while prefixes can be updated with a rate of 3 million updates per second. Furthermore, it was shown that using our reconfigurable architecture results in rare update failure rate due to resource limitations. 2008 Elsevier B.V. All rights reserved.	artificial neural network;failure rate;field-programmable gate array;gigabit;internet backbone;lookup table;network packet;packet switching;reconfigurable computing;requirement;router (computing);routing table;scalability;throughput	Hamid Fadishei;Mehdi Saeedi;Morteza Saheb Zamani	2008	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2008.01.001	embedded system;loose source routing;parallel computing;real-time computing;hash function;reconfigurable computing;computer science;optical ip switching;ip forwarding;failure rate;distributed computing;longest prefix match;field-programmable gate array;computer network	Networks	-5.902829296251966	66.60109900965426	93894
2acb57eb375bbb163edde87e9d818c5be734fe57	message based redundancy approach using totem protocol for telecom applications and protocol stacks	high availability;protocols;protocol stacks high availability redundancy checkpointing fault tolerance;fault tolerant;redundancy fault tolerance protocols;protocol stacks;totem protocol;checkpointing;redundancy;software level redundancy;fault tolerance;protocols redundancy hardware application software availability costs middleware communication industry telecommunication computing telecommunication standards;fault tolerance message based redundancy approach totem protocol telecom applications protocol stacks software level redundancy;telecom applications;message based redundancy approach	High availability in telecom system is achieved by having redundant setups of both hardware and software. Software level redundancy requires process context to be replicated across the redundant setup, so that other processes can take off from where the failed process left off. Several common ways of achieving the context replication is mentioned in various literatures and also presented in this paper mentioning their trade-offs. However, these approaches do not fare well when there are frequent context updates, which is typically the case of telecom and protocol stacks. This paper proposes an alternate approach for achieving context replication indirectly, specially suited for telecom stacks, by replicating the incoming and outgoing messages at a stack level across the redundant setup. As only the messages arriving at the stack are replicated, the overhead incurred by exchanging information whenever a context change takes place, is avoided resulting in superior performance.	application checkpointing;high availability;overhead (computing)	Balaji Rajappa;Yusuf Motiwala	2007	2007 2nd International Conference on Communication Systems Software and Middleware	10.1109/COMSWA.2007.382418	triple modular redundancy;embedded system;fault tolerance;active redundancy;real-time computing;computer science;operating system;distributed computing;redundancy;computer security;computer network	SE	-6.796442620376833	70.03660955037454	94252
beebf71ab0e33bd8524b4abcb2a45c1c88c9b1e6	mapping cooperating grid applications by affinity for resource characteristics	computational grid;grid applications;한국시뮬레이션학회;the korea society for simulation;input output;ki hyung kim;high performance computer;mapping cooperating grid applications by affinity for resource characteristics;2004 jeju international simulation multiconference parti;sang ryoul han	The Computational Grid, distributed and heterogeneous collections of computers in the Internet, has been considered a promising platform for the deployment of various high-performance computing applications. One of the crucial issues in the Grid is how to discover, select and map possible Grid resources in the Internet for meeting given applications. The general problem of statically mapping tasks to nodes has been shown to be NP-complete. In this paper, we propose a mapping algorithm for cooperating Grid applications by the affinity for the resources, named as MACA. The proposed algorithm utilizes the general affinity of Grid applications for certain resource characteristics such as CPU speeds, network bandwidth, and input/output handling capability. To show the effectiveness of the proposed mapping algorithm, we compare the performance of the algorithm with some previous mapping algorithms by simulation. The simulation results show that the algorithm could effectively utilize the affinity of Grid applications and shows good performance.	processor affinity	Ki-Hyung Kim;Sang-Ryoul Han	2004		10.1007/978-3-540-30583-5_34	input/output;simulation;computer science;theoretical computer science;distributed computing;grid computing	HPC	-15.686154764940204	62.353627707324286	94823
00cb083879ac128f84b4783ec1aa4eb51195ef4b	improving data availability through dynamic model-driven replication in large peer-to-peer communities	data sharing;personal communication networks;availability;dynamic model;large scale system;peer to peer system;peer to peer computing aggregates bandwidth costs availability computer science delay microcomputers personal communication networks power system reliability;network connectivity;aggregates;replicated data;bandwidth;power system reliability;user behavior;computer science;peer to peer computing;peer to peer;microcomputers;dynamic networks	Efficient data sharing in global peer-to-peer systems is complicated by erratic node failure, unreliable network connectivity and limited bandwidth. Replicating data on multiple nodes can improve availability and response time. Yet determining when and where to replicate data in order to meet performance goals in large-scale systems with many users and files, dynamic network characteristics, and changing user behavior is difficult. We propose an approach in which peers create replicas automatically in a decentralized fashion, as required to meet availability goals. The aim of our framework is to maintain a threshold level of availability at all times. We identify a set of factors that hinder data availability and propose a model that decides when more replication is necessary. We evaluate the accuracy and performance of the proposed model using simulations. Our preliminary results show that the model is effective in predicting the required number of replicas in the system.	model-driven integration;peer-to-peer;response time (technology);self-replicating machine;simulation	Kavitha Ranganathan;Adriana Iamnitchi;Ian T. Foster	2002	2nd IEEE/ACM International Symposium on Cluster Computing and the Grid (CCGRID'02)	10.1109/CCGRID.2002.1017164	availability;real-time computing;computer science;operating system;database;microcomputer;distributed computing;world wide web;bandwidth	Arch	-18.242305364823476	69.23780375039485	95074
a6954b663199c8c4ba816c475b76229019cabb19	enhanced fast spread replication strategy for data grid	tiempo respuesta;tolerancia falta;evaluation performance;replication;performance evaluation;fault tolerant;replication strategy;availability;disponibilidad;evaluacion prestacion;simulation;distributed computing;response time;simulacion;data replication;replicacion;frequency of requests;number of requests;fast spread;temps reponse;fault tolerance;calculo repartido;least frequently used;last request time;size;disponibilite;calcul reparti;tolerance faute;least recently used;data grid	Data replication is used in Data Grid to enhance data availability and fault tolerance. However, replication should be used wisely because the storage size of each node reside on the Data Grid is limited. Thus, the node must accommodate only the important replicas. In this paper, a dynamic replication strategy that takes into account the number and frequency of requests, the size of the replica, and the last time the replica was requested is proposed. This strategy is an enhanced version of Fast Spread replication strategy. The simulation results show that the new proposed strategy attained better performance than Fast Spread with Least Recently Used (LRU) and Fast Spread with Least Frequently Used (LFU) in terms of total response time and total bandwidth consumption. & 2010 Elsevier Ltd. All rights reserved.	encrypting file system;fast fourier transform;fault tolerance;least frequently used;replication (computing);response time (technology);simulation	Mohammad Bsoul;Ahmad Al-Khasawneh;Emad Eddien Abdallah;Yousef Kilani	2011	J. Network and Computer Applications	10.1016/j.jnca.2010.12.006	fault tolerance;real-time computing;simulation;telecommunications;computer science;operating system;distributed computing;computer security	HPC	-12.736412846892629	69.20041176566762	95187
ed52ff4b3fa6886ce890deb69afd059854a75c0c	an on-demand data broadcasting scheduling algorithm based on dynamic index strategy	dynamic index strategy;on demand data broadcasting;deadline;scheduling algorithm;request drop ratio	On-demand data broadcasting scheduling is an effective wireless data dissemination technique. Existing scheduling algorithms usually have two problems: (1) with the explosive growth of mobile users and real-time individual requirements, broadcasting systems present a shortage of scalability, dynamics and timeliness (request drop ratio); (2) with the growth of intelligent and entertained application, energy consumption of mobile client cannot be persistent (tuning time). This paper proposes an effective scheduling algorithm LxRxW. It takes into account the number of lost requests during next item broadcasting time, the number of requests and the waiting time. LxRxW can reduce the request drop ratio. At the same time, the algorithm employs a dynamic index strategy to put forward a dynamic adjusting method on the index cycle length (DAIL) to determine the proper index cycle. Extensive experimental results show that the LxRxW algorithm has better performance than other state-of-the-art scheduling algorithms and can significantly reduce the drop ratio of user requests by 40%–50%. The request drop ratio and accessing time of LxRxW with index increase by 1%–2% than LxRxW algorithm without index, but the tuning time decreases by 70%. The index strategy shows that when the index cycle length is less than 20 units, it can significantly reduce the average tuning time but when the index cycle length continues increasing, the average tuning time will increase contrarily. DAIL can dynamically determine the length of index cycle. Moreover, it can reach optimal integrated performance of the request drop ratio, the average accessing time and the average tuning time. Copyright © 2013 John Wiley & Sons, Ltd.	algorithm;data item;datacasting;experiment;john d. wiley;persistence (computer science);real-time clock;real-time transcription;regular expression;requirement;scalability;scheduling (computing);software engineering	Wenbin Hu;Cunlian Fan;Jiajia Luo;Chao Peng;Bo Du	2015	Wireless Communications and Mobile Computing	10.1002/wcm.2395	real-time computing;computer science;operating system;distributed computing;scheduling;computer network	DB	-15.762152496139127	69.58333882491453	95238
1c7644d4e52232de586c67e37423799f4a31d57a	online load balancing for distributed control plane in software-defined data center network		Distributed control plane is a common approach to improve the scalability of software-defined data center networks. However, learning how to balance the load among the controllers remains a difficult problem, since the flows in the network fluctuate frequently. In this paper, we propose an online controller load balancing (OCLB) scheme to address this issue. We first formulate the load balancing problem as an optimization problem to minimize the average controller response time. Then we decompose it into a sequence of switch migrations, with each migration aiming to reduce the average response time as much as possible based on the realtime request distribution. An OCLB algorithm is designed based on the derived optimality and termination conditions of switch migration, and is proved to be near optimal with a bounded competitive ratio. Evaluations demonstrate that our scheme can achieve near-optimal load balancing among the control plane in an online manner.	algorithm;competitive analysis (online algorithm);control plane;distributed control system;load balancing (computing);mathematical optimization;network switch;optimization problem;response time (technology);scalability;software-defined data center	Shaojun Zhang;Julong Lan;Penghao Sun;Yiming Jiang	2018	IEEE Access	10.1109/ACCESS.2018.2820148	control theory;competitive analysis;scalability;distributed computing;response time;computer science;load balancing (computing);load management;software-defined data center;optimization problem	Metrics	-18.74571910445076	65.29658730330674	95247
592ac7dcd9a9c13f1ac01cd83b2a640118f56ec3	analysis of data scheduling algorithms in supporting real-time multi-item requests in on-demand broadcast environments	data analysis algorithm design and analysis scheduling algorithm broadcasting time factors real time systems performance analysis bandwidth information analysis information management;information retrieval;real time;real time multiitem requests;data mining;wireless data dissemination;on demand broadcast environments;dynamic data access patterns;time critical on demand data broadcast;scheduling algorithm;servers;dynamic data;time factors;time critical on demand data broadcast data scheduling real time multiitem requests on demand broadcast environments wireless data dissemination system scalability dynamic data access patterns;scheduling;information dissemination;data scheduling;pattern recognition;bandwidth;system scalability;scheduling data handling information retrieval pattern recognition real time systems;data broadcast;data handling;wireless data;algorithm design and analysis;real time systems	On-demand broadcast is an effective wireless data dissemination technique to enhance system scalability and capability to handle dynamic data access patterns. Previous studies on time-critical on-demand data broadcast were under the assumption that each client requests only one data item at a time. With rapid growth of time-critical information dissemination services in emerging applications, there is an increasing need for systems to support efficient processing of real-time multi-item requests. Little work, however, has been done. In this work, we study the behavior of six representative single-item request based scheduling algorithms in time-critical multi-item request environments. The results show that the performance of all algorithms deteriorates when dealing with multi-item requests. We observe that data popularity, which is an effective factor to save bandwidth and improve performance in scheduling single-item requests, becomes a hindrance to performance in multi-item request environments. Most multi-item requests scheduled by these algorithms suffer from a starvation problem, which is the root of performance deterioration.	algorithm;broadcasting (networking);data access;data item;dynamic data;online and offline;real-time clock;scalability;scheduling (computing);window of opportunity	Jun Chen;Kai Liu;Victor Chung Sing Lee	2009	2009 IEEE International Symposium on Parallel & Distributed Processing	10.1109/IPDPS.2009.5161187	real-time computing;computer science;operating system;database;distributed computing;scheduling;computer network	Arch	-15.074169976740835	69.13448125736754	95503
2c82c9ef38404b0b355379dcac5daf61cf36228e	unified index for mobile object data and authorizations	moving object;controle acces;access control list;informatique mobile;moving object database;base donnee temporelle;securite informatique;corps mobile;index structure;tiempo acceso;mobile object;spatial database;computer security;mobile environment;access control policy;data privacy;seguridad informatica;base donnee spatiale;indexation;cuerpo movil;base donnee orientee objet;temps acces;spatial data structures;temporal databases;base dato especial;object oriented databases;access control;moving body;mobile computing;security policy;confidentialite donnee;access time;mobile user;structure donnee spatiale	Often, enforcing security incurs overhead, and as a result may degrade the performance of a system. In this paper, we attempt to address this problem in the context of enforcing access control policies in a mobile data object environment. There are a number of applications that call for fine-grained specification of security policies in guaranteeing the confidentiality of data or privacy of individuals in a mobile environment. In particular, the security policies state the rules for providing controlled access to the mobile user profiles, to their current location and movement trajectories, to mobile resources, and stationary resources based on the mobile user location. Either a subject or an object in an authorization specification can be a moving object. The access requests in such an environment can typically be based on past, present and future status of the moving objects. To effectively serve such access requests, one must efficiently organize the mobile objects as well as authorizations. Although implementation of authorizations as access control list, capability list or access matrix is suitable for traditional data, it is not suitable to search mobile object authorizations as they are based on spatial and temporal attributes of subjects and objects, rather than subject and object identifiers. When a subject issues an access request, the system must first retrieve the relevant objects from the moving object database, and then verify whether there exists an authorization that allows the subject to access these objects. Since both the moving objects and authorizations are spatiotemporal in nature, for efficient processing of access requests, it is essential that they both be organized using some index structures. As a result, processing an access request requires searching two indexes one, the moving object index, and the other, the authorization index. To improve the response time of access requests, in this paper, we propose a unified index structure, called TPR-tree to index both moving objects and authorizations that govern access to them. As a result of the unified index, access requests can be processed in one pass, thereby improving the response time. Note that current access control systems do not use any index for authorizations; our work is a step in this direction. We show how the TPR-tree can be constructed and maintained, and provide algorithms to process access requests.	access control matrix;access control list;algorithm;authorization;c-list (computer security);confidentiality;control system;identifier;overhead (computing);response time (technology);stationary process;user profile	Vijayalakshmi Atluri;Qi Guo	2005		10.1007/11555827_6	computer access control;information privacy;access time;computer science;security policy;access control;data mining;database;temporal database;mobile computing;computer security;spatial database	DB	-15.465529413613254	68.26460668991221	95519
9a9b5ab0527e426b64fbcbd7688cb4535bad6ea4	parametric real-time scheduling in distributes environments	distributed environment;real time scheduling		real-time transcription;scheduling (computing)	Sameh M. Elsharkawy;Ashok K. Agrawala	2002			fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing;scheduling;round-robin scheduling;distributed computing environment	Embedded	-11.368568532523668	62.15712137903675	95641
e0f073e3f7c94592d9e507072b9721a90b3214ca	an adaptive job allocation strategy for heterogeneous multiple clusters	cluster computing self scheduling multiple clusters loop scheduling load balancing heterogeneous;resource utilization;cluster computing;cluster computing adaptive job allocation strategy heterogeneous multiple clusters scheduling system multiclusters environment self scheduling scheme resource utility loop scheduling load balancing;multiclusters environment;resource utility;adaptive job allocation strategy;processor scheduling;resource allocation;resource management;heterogeneous multiple clusters;loop scheduling;heterogeneous;multiple clusters;self scheduling scheme;scheduling system;load management;load balancing;self scheduling;bandwidth;load balance;resource allocation processor scheduling;program processors;benchmark testing;processor scheduling dynamic scheduling load management resource management computer science information technology chaos proposals dispatching fault tolerance;dynamic scheduling	In this paper we proposal a new scheduling system based on multi-clusters environments. The work we present is Adaptive Job Allocation Strategy (AJAS) in which the scheduler dispatches jobs that with self-scheduling scheme into appropriate resources across multi-clusters. The strategy focuses on how to increase resource utility, jobs via self-scheduling and dispatching jobs to nodes with similar performance capacities, thus equalizing execution times among all the nodes the jobs require. Experimental results show that the proposed approach performs better than previous schemes.	benchmark (computing);central processing unit;job stream;linpack benchmarks;load balancing (computing);scheduling (computing)	Chao-Tung Yang;Keng-Yi Chou	2009	2009 Ninth IEEE International Conference on Computer and Information Technology	10.1109/CIT.2009.138	parallel computing;real-time computing;computer science;load balancing;resource management;job scheduler;distributed computing;computer security	HPC	-16.704303256961467	61.051303964298576	95776
403c509f81cc7bad81143cfe14f64e3eb2929a7d	design of distributed video cache system on the internet	cache storage;video caching server distributed video cache system design internet time variance behavior web proxy system video on demand;cache storage internet video on demand;internet;video on demand;internet prefetching streaming media ip networks web server network servers video sharing video on demand bandwidth algorithm design and analysis;web proxy	This paper identifies that time variance behavior (TVB) exists in today's Web proxy systems where the user request profile varies with time. As future video on demand (VoD) systems will very likely be implemented on the Internet, it is expected that TVB will have a significant impact on the performance of the video caching servers such as CDN. In this paper, a TVB-aware prefetch algorithm is proposed. Simulations on a distributed video system show that TVB-aware prefetch algorithm performs much better than conventional prefetch algorithm even when the user request patterns are not fully known.	internet	K. Y. Leung;Eric Wing Ming Wong;Alan Kai-Hau Yeung	2003		10.1109/ICDCSW.2003.1203673	the internet;cache;computer science;internet privacy;law;world wide web;computer network	Networks	-17.67307283383244	71.88839085863987	96140
0958fbec4de56343c7985df064ecc5ccc129b381	efficient striping techniques for variable bit rate continuous media file servers	continuous media file servers;disk arrays;continuous media;striping techniques;variable bit rate;media streaming;analytical model;disk array	The performance of striped disk arrays is governed by two parameters: the stripe unit size and the degree of striping. In this paper, we describe techniques for determining the stripe unit size and degree of striping for disk arrays storing variable bit rate continuous media data. We present an analytical model that uses the server configuration and the workload characteristics to predict the load on the most heavily loaded disk in redundant and non-redundant arrays. We then use the model to determine the optimal stripe unit size for different workloads. We also use the model to study the effect of various system parameters on the optimal stripe unit size. To determine the degree of striping, we first demonstrate that striping a continuous media stream across all disks in the array causes the number of clients supported to increase sub-linearly with increase in the number of disks. To maximize the number of clients supported in large arrays, we propose a technique that partitions a disk array and stripes each media stream across a single partition. Since load imbalance can occur in such partitioned arrays, we present an analytical model to compute the imbalance across partitions in the array. We then use the model to determine a partition size that minimizes the load imbalance, and hence, maximizes the number of clients supported by the array.	data striping;disk array;magnetic stripe card;server (computing);stripes	Prashant J. Shenoy;Harrick M. Vin	1999	Perform. Eval.	10.1016/S0166-5316(99)00044-9	real-time computing;data striping;disk array;computer hardware;computer science;operating system;distributed computing	Metrics	-15.27561299494722	70.92058761953615	96190
8b71362f28d9ab8f4085ad3feebfa3c2ef1dd436	mobile real-time read-only transaction processing in broadcast disks	estensibilidad;systeme temps reel;broadcast on schedule;gestion memoire;tratamiento transaccion;mise a jour;informatique mobile;reseau sans fil;telecommunication sans fil;memoire morte;broadcast on demand;storage management;real time;wireless network;dissemination;data management;radiodifusion;mobile computer;updates dissemination;real time data;mobile real time read only transaction;processing time;actualizacion;gestion memoria;read only memory rom;telecomunicacion sin hilo;diffusion donnee;difusion dato;version management;memoria muerta;temps traitement;real time system;sistema tiempo real;extensibilite;scalability;data broadcast;broadcasting;transaction processing;read only transaction;mobile computing;tiempo proceso;radiodiffusion;gestion version;real time computing;updating;data dissemination;traitement transaction;diseminacion;wireless telecommunication;time constraint	HONG-YA WANG, GUO-QIN NING, GUO-HUI LI AND KAM-YIU LAM School of Computer Science and Technology Donghua University Shanghai 200016, P.R.C. Department of Information Technology Central China Normal University Hubei 430079, P.R.C. College of Computer Science and Technology Huazhong University of Science and Technology Hubei 430074, P.R.C. Department of Computer Science City University of Hong Kong Kowloon, Hong Kong	broadcasting (networking);computer science;correctness (computer science);experiment;floppy disk;numerical analysis;read-only memory;real-time transcription;requirements analysis;simulation;transaction processing;yet another	Hongya Wang;Guo-Qin Ning;Guohui Li;Kam-yiu Lam	2006	J. Inf. Sci. Eng.		real-time computing;atomic broadcast;telecommunications;computer science;operating system;database;mobile computing;computer security;dissemination;computer network	Logic	-13.135221094553415	68.8206175057623	96370
a5b2995359f27ca6f2382bc9c47c7f4f2325b26f	delay optimal server assignment to symmetric parallel queues with random connectivities	stochastic process;cost function;resource allocation;queue length;wireless network;resource manager;resource management;maximum weight matching;servers;vectors;stochastic processes;queueing system;stochastic order;servers stochastic processes delay throughput vectors resource management cost function;throughput	In this paper, we investigate the problem of assignment of K identical servers to a set of N parallel queues in a time slotted queueing system. The connectivity of each queue to each server is randomly changing with time; each server can serve at most one queue and each queue can be served by at most one server per time slot. Such queueing systems were widely applied in modeling the scheduling (or resource allocation) problem in wireless networks. It has been previously proven that Maximum Weighted Matching (MWM) is a throughput optimal server assignment policy for such queueing systems [1], [2]. In this paper, we prove that for a symmetric system with i.i.d. Bernoulli packet arrivals and connectivities, MWM minimizes, in stochastic ordering sense, a broad range of cost functions of the queue lengths including total queue occupancy (or equivalently average queueing delay).	euler–bernoulli beam theory;motif window manager;network packet;queueing theory;queuing delay;randomness;scheduling (computing);server (computing);throughput	Hassan Halabian;Ioannis Lambadaris;Chung-Horng Lung	2011	IEEE Conference on Decision and Control and European Control Conference	10.1109/CDC.2011.6160652	mean value analysis;stochastic process;throughput;real-time computing;m/m/∞ queue;multilevel queue;bulk queue;resource allocation;computer science;resource management;wireless network;layered queueing network;mathematics;distributed computing;queue management system;m/g/1 queue;fork–join queue;queueing theory;server;statistics;computer network	Metrics	-13.006143404822543	66.75855990995869	96500
e22f07f5bf4eb9086df5cbad8b39b7b33958116d	an optimal checkpointing model with online oci adjustment for stream processing applications		Checkpoint-based fault tolerant method has been widely used to enhance the reliability of Distributed Stream Processing Engines (DSPEs), but a checkpointing process usually introduces considerable overhead. It is a critical issue to choose the Optimal Checkpoint Interval (OCI) that maximizes the processing efficiency. Traditional OCI models consider the recovery time only related to the execution time from the last checkpoint to the moment of the failure. They are not suitable for stream processing jobs because the recovery time is related to the reprocessing workload, which depends on the realtime input data before a failure. A new model is needed to choose the OCI for stream processing applications. Moreover, the input data rate of an stream processing job fluctuates over time. The OCI of an application should also be adjusted dynamically according to the input workload. To solve these problems, we present a novel DSPS Optimal Checkpoint Interval (DOCI) model in this paper. We prove that it maximizes the processing efficiency for a given time period. We propose an approach to dynamically adjust the OCI for an application to accommodate the realtime workload fluctuations. We conduct simulation experiments to verify the effectiveness of DOCI model and the efficiency of the online OCI adjustment algorithm. Experimental results with a real-world dataset show DOCI achieves an improvement on system efficiency by up to 40%, comparing with existing fault-tolerant approaches.	algorithm;application checkpointing;data rate units;experiment;fault tolerance;job stream;mathematical optimization;oracle call interface;overhead (computing);run time (program lifecycle phase);simulation;stream processing;transaction processing system	Yuan Zhuang;Xiaohui Wei;Hongliang Li;Yongfang Wang;Xubin He	2018	2018 27th International Conference on Computer Communication and Networks (ICCCN)	10.1109/ICCCN.2018.8487327	workload;task analysis;stream processing;fault tolerance;computer science;distributed computing	DB	-15.582240641097414	60.71573067487397	96620
004ac691f4078ac732eb41dd804056bb6086238d	ant colony optimization inspired resource discovery in p2p grid systems	estensibilidad;p2p system;modelizacion;parallelisme;distributed system;invertebrata;swarm intelligence;haute performance;architecture systeme;systeme reparti;range query;resource discovery;systeme grande taille;ant colony optimization;intelligence en essaim;arthropoda;insecto social;availability;geometrie algorithmique;disponibilidad;par a par;reponse transitoire;gestion trafic;localization;resource management;interrogation base donnee;computational geometry;distributed computing;interrogacion base datos;p2p;complex adaptive systems;large scale system;localizacion;supercomputer;traffic management;satisfiability;grid;supercomputador;modelisation;busquedas dentro de un rango;gestion recursos;large scale;parallelism;transient response;respuesta transitoria;sistema repartido;localisation;requete a intervalle;paralelismo;poste a poste;rejilla;aculeata;insecta;gestion trafico;alto rendimiento;grille;gestion ressources;calculo repartido;arquitectura sistema;geometria computacional;extensibilite;hymenoptera;scalability;insecte social;social insect;formicoidea;system architecture;peer to peer;modeling;inteligencia de enjambre;high performance;disponibilite;calcul reparti;database query;grid system;superordinateur;sistema gran escala	It is a challenge for the traditional centralized or hierarchical Grid architecture to manage the large-scale and dynamic resources, while providing scalability. The Peer-to-Peer (P2P) model offers a prospect of dynamicity, scalability, and availability of a large pool of resources. By integrating the P2P philosophy and techniques into a Grid architecture, P2P Grid system is emerging as a promising platform for executing large-scale, resource intensive applications. There are two typical resource discovery approaches for a large-scale P2P system. The first one is an unstructured approach which propagates the query messages to all nodes to locate the required resources. The method does not scale well because each individual query generates a large amount of traffic and the network quickly becomes overwhelmed by the messages. The second one is a structured approach which places resources at specified locations to make subsequent queries easier to satisfy. However, the method does not support multi-attribute range queries and may not work well in the network which has an extremely transient population. This paper proposes and designs a large-scale P2P Grid system which employs an Ant Colony Optimization (ACO) algorithm to locate the required resources. The ACO method avoids a large-scale flat flooding and supports multi-attribute range query. Multiple ants can be employed to improve the parallelism of the method. A simulator is developed to evaluate the proposed resource discovery mechanism. Comprehensive simulation results validate the effectiveness of the proposed method compared with the traditional unstructured and structured approaches.	algorithm;ant colony optimization algorithms;centralized computing;grid computing;mathematical optimization;parallel computing;peer-to-peer;range query (data structures);range query (database);scalability;simulation	Yuhui Deng;Frank Wang;Adrian Ciura	2008	The Journal of Supercomputing	10.1007/s11227-008-0214-0	complex adaptive system;range query;availability;active traffic management;supercomputer;ant colony optimization algorithms;scalability;simulation;systems modeling;internationalization and localization;computational geometry;swarm intelligence;computer science;artificial intelligence;resource management;peer-to-peer;distributed computing;grid;transient response;satisfiability	HPC	-10.897427718775932	69.69012413314378	97173
b3e4dc4743655984eeba01e58624d7d852771d08	minimum latency server selection for heterogeneous cloud services	linear programming cloud computing computer centres;user cluster cloud computing server selection minimum fatency network distance;servers;youtube;servers bandwidth cloud computing youtube ip networks equations mathematical model;mathematical model;bandwidth;ip networks;linear programming formulation minimum latency server selection heterogeneous cloud services cloud computing cloud service providers data centers geographical locations computational overhead bandwidth requirements online video service bandwidth constraint;cloud computing	Server selection is an important problem of cloud computing in which cloud service providers direct user demands to servers in one of the multiple data centers located in different geographical locations. The existing solutions usually assume homogeneity of cloud services (i.e., all users request the same type of service) and handle user demands in an individual basis which incurs high computational overhead. In this study, we propose a new and effective server selection scheme in which diversities of cloud services are taken into account. We focus on a specific cloud service, i.e., online video service, and assume that different videos have different bandwidth requirements. We group users into clusters and handle user demands on a cluster basis for faster and more efficient process. Given user demands and bandwidth capacities of servers in the data centers, our problem is to assign the user demands to the servers under the bandwidth constraint, such that the overall latency (measured by the network distance) between the user clusters and the selected servers is minimized. We design a server selection system and formulate this problem as a linear programming formulation which can be solved by existing techniques. The system periodically executes our scheme and computes an optimal solution for server selection. User demands are assigned to the servers according to the optimal solution and the minimum overall latency can be achieved. The simulation results show that our scheme is significantly better than the random algorithm and the YouTube server selection strategy.	cloud computing;data center;linear programming formulation;overhead (computing);randomized algorithm;requirement;selection algorithm;server (computing);simulation;type of service;video clip	He Chang;Yiu-Wing Leung;Xiaowen Chu	2014	2014 IEEE Global Communications Conference	10.1109/GLOCOM.2014.7037147	cloud computing;computer science;operating system;mathematical model;distributed computing;world wide web;bandwidth;server;computer network;server farm	Metrics	-18.729597446348812	65.87736523059564	97405
45ce241a34c5aee14fc2a536f1c391cd7f366806	an interconnect architecture for networking systems on chips	network on a chip system on a chip network synthesis telecommunication traffic ip networks web and internet services reduced instruction set computing costs scalability protocols;interconnections;cost interconnect architecture network processor systems on chips next generation internet routers octagon on chip communication architecture scalability performance;network processor;chip;interconnections telecommunication network routing internet;internet;telecommunication network routing;system on chip;networked systems;next generation internet	To meet the demands of ever-increasing Internet traffic, the next generation of Internet backbone routers must deliver ultrahigh performance over an optical infrastructure. At the current Internet traffic growth rate, network service providers will likely deploy OC-768 routers in the foreseeable future. At the same time, as Internet and application service providers attempt to provide more diverse and differentiated services, routers will have to take on new tasks. In addition to routing and packet forwarding, routers will likely perform packet classification, distinguishing packets and grouping them according to their requirements; buffer management, determining buffer allocation and admission control for packets; and packet scheduling, determining how to sequence packets to meet service level agreements (SLA). Traditionally, routers have used general-purpose reduced-instruction-set computer (RISC) processors or application-specific ICs (ASICs). Although general-purpose, processor-based router architectures provide the flexibility to upgrade to new router tasks, they will not satisfy the growing speed requirements for new, complex, packet-processing tasks. On the other hand, ASIC-based router implementations can provide the speed but not the required programming flexibility. These shortcomings of traditional RISC and ASIC designs mean that designers must develop new high-speed network processors that permit flexible programmability and work at OC-768 speed. At OC-768 (40 Gbps), IP packet arrival rate could reach approximately 114 x 10 packets per second (assuming 44 bytes per packet). To ensure that the worst-case time to process a packet does not exceed the packet arrival rate and thus violate SLAs, packet-processing time should be at most 9 ns per packet. To accommodate this requirement, a network processor must perform approximately 500 instructions on each arriving packet to enable packet forwarding and classification on packet flows. Hence, an OC-768 network processor must process 57 billion instructions per second, a performance level a multiprocessor system-ona-chip (SOC) architecture can provide. Octagon is a novel on-chip communication architecture that can meet the performance requirements of network processor SOCs. Octagon’s cost, performance, and scalability advantages make it suitable for the aggressive on-chip communication demands of not only networking SOCs, but also SOCs in several other domains. Faraydon Karim Anh Nguyen	application-specific integrated circuit;best, worst and average case;byte;central processing unit;data rate units;differentiated services;general-purpose markup language;internet backbone;multiprocessing;network packet;network processor;next-generation network;optical carrier transmission rates;original net animation;queueing theory;requirement;router (computing);routing;scalability;scheduling (computing);service-level agreement;system on a chip;throughput	Faraydon Karim;Anh Tuan Le Nguyen;Sujit Dey	2002	IEEE Micro	10.1109/MM.2002.1044298	chip;system on a chip;tier 1 network;embedded system;real-time computing;the internet;overlay network;network architecture;telecommunications;dynamic circuit network;computer science;network on a chip;internet connection sharing;network processor;computer network	Networks	-4.5706273260968455	65.68526270505595	97432
160e2e3cd670f26d2a125f629b67cd0e2677a415	adaptive data access in broadcast-based wireless environments	database indexing;databases;wireless access;tiempo espera;metodo adaptativo;base donnee;informatique mobile;wireless access methods;wireless communication systems;database;base dato;power conservation;client server systems;tiempo acceso;calcul mobile;methode adaptative;tree data structures;temps attente;broadcasting frequency energy consumption wireless communication mobile communication information retrieval optimization methods indexing databases communication cables;indexing;index terms mobile computing;broadcast channels;waiting time;mobile computing client waiting time reduction broadcast based wireless communication systems client power consumption adaptive data access method hashing techniques index tree based access methods wireless access methods;wireless access methods index terms mobile computing databases;indexation;adaptive method;diffusion donnee;indizacion;difusion dato;performance model;data access;distributed databases;radio communication;temps acces;radiocommunication;client server systems mobile computing tree data structures database indexing broadcast channels distributed databases power consumption;data broadcast;power consumption;consommation energie electrique;mobile computing;access method;methode acces donnee;radiocomunicacion;access time	Power conservation and client waiting time reduction are two important aspects of data access efficiency in broadcast-based wireless communication systems. The intention of data access methods is to optimize client power consumption with the least possible overhead on client waiting time. We propose an adaptive data access method which builds on the strengths of indexing and hashing techniques. We show that this method exhibits better average performance over the well-known index tree-based access methods. A new performance model is also proposed. This model uses more realistic assessment criteria, based on the combination of access and tuning times, for evaluating wireless access methods. This new model provides a dynamic framework to express the degree of importance of access and tuning times in an application. Under this new model, the adaptive method performance also outperforms the other access methods in the majority of cases.	access time;best, worst and average case;data access;overhead (computing);performance evaluation;range query (data structures);requirement;whole earth 'lectronic link;x-tree	Xu Yang;Athman Bouguettaya	2005	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2005.37	data access;database index;search engine indexing;access time;computer science;data mining;database;distributed computing;wireless distribution system;tree;mobile computing;access method;world wide web;distributed database;computer network;network access device	DB	-14.619991636462933	68.73732822710821	97675
0b71480c240f12cc9a13a31cf1bee30b674fb03a	improved response-time bounds in fixed priority scheduling with arbitrary deadlines	real-time systems;response-time upper bound;workload function	We consider fixed priority sporadic tasks with arbitrary deadlines to be executed upon a uni-processor platform. Efficient schedulability tests for this task model are required for both online task admission in dynamic systems and interactive design of complex embedded real-time systems. The paper derives novel continuous upper bounds on the worst-case response times which runs in linear complexity. These bounds are not comparable to the tightest existing continuous upper bound of Bini et al. (in: Proceedings of the IEEE international conference on real-time systems symposium (RTSS’15), San Antonio, 2015) and strictly tighter under some parameters configurations. Moreover, the proposed approach allows to combine various existing methods to produce the tightest known continuous response time bounds. These results are extended to be applicable to a wide range of processor and network scheduling problems, including: release jitters, blocking times and cache related preemption delay (CRPD). Response time upper bounds are also given for tasks that are scheduled pre-emptively, co-operatively with intervals where pre-emption is deferred, and non-preemptively. Lastly, the quality of the method is analyzed and various recommendations are provided by means of numerical experiments.	best, worst and average case;blocking (computing);dynamical system;embedded system;experiment;fixed-priority pre-emptive scheduling;interactive design;numerical analysis;preemption (computing);proceedings of the ieee;real-time clock;real-time computing;real-time transcription;response time (technology);responsiveness;scheduling (computing)	Werner Grass;Thi Huyen Chau Nguyen	2017	Real-Time Systems	10.1007/s11241-017-9282-7	scheduling (computing);distributed computing;real-time computing;dynamical system;cache;computer science;response time;preemption;upper and lower bounds	Embedded	-10.196706964299244	61.253782935883194	97787
f3f7982549342dd83d9a87cc9b96c0acf545465d	design of message-oriented middleware with publish/subscribe model on telemetry and command computer	computers;quality of service middleware;subscriptions computers computational modeling algorithm design and analysis quality of service redundancy computer architecture;violent matching message oriented middleware publish subscribe model telemetry command computer pub sub model information sharing many to many communication flexible resources reorganization concise message model real time message matching algorithm message routing protocol qos guarantee virtualization strategy multimachine redundancy predicate counting algorithm;computer architecture;routing pub sub message oriented middleware telemetry and command matching algorithm qos;computational modeling;redundancy;subscriptions;quality of service;algorithm design and analysis	Pub/Sub model with the characteristics of loose coupling, fully information sharing, many-to-many communication and flexible resources reorganization is suitable for Message-Oriented Middleware's information exchanging on Telemetry and Command(TT&C) computers. According to the disadvantage of traditional model of message-Oriented Middleware(point-to-point, message queue, shared memory), An architecture of pub/sub model on TT&C computer was put forward. The components of the architecture was analyzed. Priority the key technologies: Complete and concise message model, High efficient and real-time message matching algorithm, Message routing protocol with QoS guarantee, Virtualization strategy with double/multi machine redundancy was proposed. Experiments of matching algorithm show that the efficiency of matching algorithm proposed is higher than traditional predicate counting algorithm and violent matching.		C H Wang;Zongtao Wang;Hongwei Xing	2014		10.1109/ICSAI.2014.7009331	algorithm design;real-time computing;quality of service;computer science;operating system;database;distributed computing;redundancy;message broker;programming language;computational model	Theory	-11.685551841771403	74.1301456354546	97860
b1100439a260de809ca0ee79b62e0efdf976a610	decentralized decision making for task reallocation in a hard real-time system	systeme temps reel;simulation decentralised decision making task reallocation hard real time system deadlines distributed system performance analysis;distributed system;fiabilidad;reliability;systeme reparti;resource allocation;decision making real time systems algorithm design and analysis performance analysis computational modeling analytical models scheduling algorithm power system reliability process control control systems;distributed processing;simulation;simulacion;prise decision;algorithme;algorithm;control proceso;sistema repartido;hard real time system;deadlines;scheduling distributed processing real time systems;scheduling;task reallocation;fiabilite;analyse performance;performance analysis;process control;real time system;sistema tiempo real;asignacion recurso;allocation ressource;toma decision;decentralised decision making;commande processus;real time systems;algoritmo;analisis eficacia	A decentralized task reallocation algorithm for hard real-time systems is developed and analyzed. The algorithm, which is fast and reliable, specifically considers deadlines of tasks, attempts to utilize all the nodes of a distributed system to achieve its objective, handles tasks in priority order, and separates policy and mechanism. An extensive performance analysis of the algorithm by means of simulation shows that it is quite effective in performing reallocations and that it is significantly better than a centralized approach. >	real-time operating system;real-time transcription	John A. Stankovic	1989	IEEE Trans. Computers	10.1109/12.21121	real-time computing;simulation;resource allocation;computer science;operating system;process control;reliability;scheduling;algorithm	Embedded	-13.113895109750809	63.714900986738535	98172
1d11a25baa3506ba6082a2c7ef47e7efe2216285	operator-scheduling using dynamic chain for continuous-query processing	dynamic chain algorithm operator scheduling continuous query processing wireless sensor network data stream tuple starvation;scheduler sensor networks continuous query;operator scheduling;time varying;memory management;query processing;data stream;continuous query;wireless network;sensor network;wireless sensor network;scheduling algorithm;sensor networks;wireless sensor networks query processing scheduling;scheduling;heuristic algorithms;database systems;scheduler;continuous query processing;software algorithms;computer science;tuple starvation;dynamic chain algorithm;natural phenomena;wireless sensor networks;round robin scheduling algorithm delay job shop scheduling heuristic algorithms database systems computer science software engineering information science computerized monitoring	Sensor networks are a sort of wireless networks; monitoring and collecting data about the natural phenomena. These sensor data behave very differently from traditional database sources: they are continuous arrival in multiple, rapid, time varying, possibly unpredictable, unbounded streams, and keeping no record of historical information. Continuous-query processing for these data streams must be run using an efficient scheduler; the development of the original chain algorithm for scheduler has focused only on minimizing the maximum run-time memory usage, ignoring the important aspect of output latency. During bursts in input streams, chain suffers from tuple starvation, thereby incurring a high latency for these tuples. In this paper the proposed dynamic chain algorithm which is used in the scheduler is very powerful in reducing memory requirements for the system and has a very good performance in the latency issue, which is the drawback of the other scheduling algorithms.	adaptive grammar;algorithm;burst transmission;database;experiment;fifo (computing and electronics);requirement;scheduling (computing)	M. Sami Soliman;Guanzheng Tan	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.461	real-time computing;wireless sensor network;computer science;theoretical computer science;operating system;database;distributed computing	DB	-14.77752960652095	67.67299372894492	98188
b281f6a451c1f1049958ad054babe9e0265f403a	an incremental splitting scheme for efficient tag identification	radiofrequency identification protocols;protocols;query tree protocol;rfid collision;query tree protocol incremental splitting scheme efficient tag identification rfid automatic identification service industries manufacturing companies material flow system reader interrogation zone tag anticollision algorithm;approximation algorithms;efficient tag identification;rfid automatic identification;manufacturing companies;rfid tag;manufacturing industries;computer industry;data mining;binary trees;service industry;rfid tags;service industries;reader interrogation zone;heuristic algorithms;computer aided manufacturing;material flow;incremental splitting scheme;material flow system;computer science;radiofrequency identification protocols delay rfid tags computer aided manufacturing heuristic algorithms approximation algorithms computer science computer industry manufacturing industries;iss;tag anticollision algorithm;algorithm design and analysis;radiofrequency identification;rfid collision iss	In recent year, RFID automatic identification has become very popular in many service industries, manufacturing companies and material flow systems. One of the challenges in designing modern RFID systems is that when more than one tag exists in an RFID environment, it may occurs collisions so that the whole system becomes inefficient and increases the time for identifying RFID Tags. In order to simultaneously recognize multiple tags within a reader interrogation zone, tag anti-collision algorithm should be applied. In this paper, we present an Incremental Splitting Scheme (ISS), which is an enhanced technique based on the query tree protocol, for tag identification. The main idea of the proposed technique is that the ISS can dynamically adjust length of inquiry message to avoid unnecessary interrogation. To evaluate performance of the proposed technique, we have implemented the ISS along with other query tree based protocols. The experimental results show that the ISS outperforms other tree based approaches in terms of efficiency and identification overheads.	algorithm;automatic identification and data capture;material flow;radio-frequency identification;scheme;whole earth 'lectronic link	Ching-Hsien Hsu;I-Chung Hsu	2009	2009 International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2009.338	radio-frequency identification;tertiary sector of the economy;computer science;data mining;distributed computing;world wide web;approximation algorithm;algorithm;computer-aided manufacturing	Visualization	-7.53729138762447	68.8723755919724	98914
f38de1e757b9e7e4a955829ecd2ce3b04f0a2ffb	coding-based cooperative caching in on-demand data broadcast environments		Data broadcasting has been commonly deployed in many emerging mobile applications such as intelligent transportation systems and location-based services, because it is a scalable approach to disseminating information from a mobile support station (MSS) to a large population of mobile hosts (MHs). To provide timely data access and better data availability, MHs can store data items broadcast by the MSS in their local caches and share cached data items cooperatively among neighboring peers via peer-to-peer (P2P) communication. However, if MHs are not neighbors, they cannot cooperate even if they have each other’s requested data items in their own caches. Network coding is a technique, by which multiple MHs can decode out different requested data items from an encoded packet broadcast by the MSS in one broadcast time unit. In this work, we propose a network coding based solution to enable MHs which are not neighbors to cooperate indirectly. We formulate the Maximum Channel Efficiency Encoding (MCEE) problem by introducing network coding and cooperative caching techniques in on-demand data broadcast environments. We prove that MCEE is NP-hard by constructing a polynomial-time reduction from the Minimum Clique Cover (MCC) problem. Further, we propose two schemes (NCM and NCB) for on-demand data broadcasting using network coding. In each scheme, we propose two algorithms running at the MSS and MHs for making encoding decisions and decoding requested data items, respectively. We build the simulation model for performance evaluation and the simulation results demonstrate that the proposed schemes not only increase the bandwidth efficiency of the limited downlink communication channel, but also enhance the system performance by reducing the data access latency.	algorithm;broadcasting (networking);cache (computing);channel (communications);clique cover;cooperative mimo;data access;data item;datacasting;encode;linear network coding;location-based service;mobile app;modified huffman coding;np-hardness;network packet;peer-to-peer;performance evaluation;polynomial-time reduction;scalability;simulation;spectral efficiency;synergy;telecommunications link;throughput;time complexity	Houling Ji;Victor Chung Sing Lee;Chi-Yin Chow;Kai Liu;Guoqing Wu	2017	Inf. Sci.	10.1016/j.ins.2017.01.012	real-time computing;computer science;distributed computing;computer network	DB	-14.64776660672119	69.16945028558317	99092
a53776b082903f385f2945c383596f908dcd362f	dynamic cluster reconfiguration for energy conservation in computation intensive service	energy conservation;optimisation;cluster computing;probability;processor scheduling;servers energy consumption energy conservation computational modeling heuristic algorithms clustering algorithms quality of service;statistical analysis;large deviation principle;dynamic cluster reconfiguration;energy consumption;workstation clusters;quality of service;job scheduling;cluster computing energy conservation computation intensive service quality of service energy consumption constrained optimization problem overload probability estimation model deviation principle online measurement based algorithm power on off workload statistics dynamic cluster reconfiguration algorithm active server nonstationary workload workload distribution server scheduling decision algorithm job scheduling;cluster computing dynamic cluster reconfiguration energy conservation large deviation principle job scheduling;workstation clusters energy conservation energy consumption optimisation probability processor scheduling quality of service statistical analysis	This paper considers the problem of dynamic cluster reconfiguration for computation intensive services. In order to provide a quality-of-service in terms of overload probability, we formulate the problem of energy consumption as a constrained optimization problem, i.e., minimizing the number of active servers to reduce the energy consumption while keeping the overload probability below a desired threshold. An overload probability estimation model is derived by applying large deviation principle, and an online measurement based algorithm is developed to decide the number of servers to power on/off, which makes decision based on current workload without any prior knowledge of the workload statistics. Moreover, the proposed dynamic cluster reconfiguration algorithm iteratively adjusts the number of the active servers, instead of directly determining the number of active servers that is hard to guarantee optimality for the nonstationary workloads. Since the distribution of the workloads among the servers has an impact on potential active servers to turn off, a server scheduling strategy is proposed to collaborate with the proposed decision algorithm to achieve better energy conservation. In order to provide an integrated solution, we present an event model-based implementation to demonstrate the practical application of the proposed approach. Finally, we evaluate the performance of the scheme by using real workloads. The experimental results show the adaptability of the proposed approach to the variations in the workload and robustness of quality-of-service for nonstationary workloads.	algorithm;computation;computer cluster;constrained optimization;constraint (mathematics);event (computing);mathematical model;mathematical optimization;optimization problem;quality of service;scheduling (computing);server (computing)	Jian Yang;Ke Zeng;Han Hu;Hongsheng Xi	2012	IEEE Transactions on Computers	10.1109/TC.2011.173	parallel computing;real-time computing;quality of service;energy conservation;computer cluster;computer science;job scheduler;operating system;probability;distributed computing;statistics	Embedded	-17.905101883600558	61.43496039484311	99126
17f89a968065710153431d24a2804143d4dab035	enabling incremental updates to lc-trie for efficient management of ip forwarding tables	lc trie algorithm;internet protocol;degradation;level compression;protocolo internet;ip forwarding tables management;fast ip address lookup;routing;ip address lookup;information technology;data structures scalability throughput degradation heuristic algorithms information technology;protocole internet;routage;incremental deletion;tree data structures transport protocols table lookup;tree data structures;path compression;incremental route updates;transport protocols;dynamic environment;incremental insertion;data structures;heuristic algorithms;level compressed binary trie;dynamic environment incremental updates ip forwarding tables management level compression path compression ip router incremental insertion incremental deletion fast ip address lookup data structure lc trie algorithm;ip router;scalability;table lookup;incremental updates;data structure;throughput;enrutamiento	Level-compressed trie (LC-trie) is an efficient data structure for fast IP address lookup. However, the data structure needs to be rebuilt every time the table is updated. Consequently, the LC-trie algorithm is not suitable for application in a dynamic environment where frequent updates to the forwarding table are necessary. It is shown that with appropriate modifications to the data structure, incremental updates can be done efficiently.	algorithm;data structure;lookup table;trie	Derek Chi-Wai Pao;Yiu-Keung Li	2003	IEEE Communications Letters	10.1109/LCOMM.2003.812174	internet protocol;virtual routing and forwarding;routing;throughput;scalability;degradation;data structure;computer science;theoretical computer science;database;tree;transport layer;computer network	DB	-5.845698851115434	67.4277056845099	99297
bc61f430aab5a0bfe72ee8f015f770914bcb269f	partitioning-based workflow scheduling in clouds	resource assignment optimization science engineering precedence constrained tasks directed acyclic graph dag cloud computing deadline optimization budget optimization cost optimization partitioning based workflow scheduling algorithm pbws algorithm;processor scheduling;partitioning;scientific workflows;upper bound;scheduling;workflows;scheduling schedules cloud computing partitioning algorithms processor scheduling algorithm design and analysis upper bound;schedules;scheduling cloud computing directed graphs optimisation;scientific workflows cloud computing scheduling partitioning workflows;algorithm design and analysis;cloud computing;partitioning algorithms	Many applications in science and engineering become increasingly complex and large scale. These applications often consist of a large number of precedence-constrained tasks forming workflows represented by directed acyclic graph (DAG). In recent years, cloud computing has greatly leveraged the elastic and cost-efficient deployment of these applications. However, their effective deployment is largely dependent on the scheduling algorithm adopted. Most existing workflow scheduling algorithms are designed to optimize deadline or budget/cost, i.e., one being the objective and the other being constraint. In this paper, we present the Partitioning-Based Workflow Scheduling (PBWS) algorithm, which liberates the user from explicitly setting the upper bound of deadline and cost. Instead, PBWS adopts a slack parameter that controls the tradeoff point between deadline and cost. In particular, PBWS partitions a workflow into a number of small task graphs (or simply partitions) for which the granularity of such partitions is determined by the slack parameter. Each of these partitions is then matched with the best performing cloud resource in terms of both the overall execution time (makespan) and cost. The size of partitions may change by rearranging tasks between different partitions for the optimization of resource assignment. Our experimental results show that our PBWSalgorithm outperforms two existing algorithms in terms of cost by a large margin with little overhead on makespan.	algorithm;amazon web services;cloud computing;cloud storage;cost efficiency;directed acyclic graph;lxc;linux;makespan;mathematical optimization;overhead (computing);run time (program lifecycle phase);scheduling (computing);slack variable;software deployment;the australian	Khaled Almi'ani;Young Choon Lee	2016	2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA)	10.1109/AINA.2016.83	fair-share scheduling;algorithm design;workflow;parallel computing;real-time computing;earliest deadline first scheduling;cloud computing;dynamic priority scheduling;schedule;computer science;rate-monotonic scheduling;operating system;two-level scheduling;distributed computing;least slack time scheduling;upper and lower bounds;scheduling	EDA	-18.516740761388412	62.69320970107457	99432
bde1078bcb5553dafcacf0c6c1c741462fff3edf	a modified least-laxity-first scheduling algorithm for real-time tasks	degradation;task priority;simulation modified least laxity first scheduling algorithm real time tasks task priority uniprocessor systems context switches system overhead system performance performance enhancement;processor scheduling;resource allocation;real time;simulation;software performance evaluation;contracts;scheduling algorithm switches degradation processor scheduling system performance contracts real time systems;system performance;software performance evaluation scheduling real time systems resource allocation;scheduling algorithm;scheduling;system overhead;uniprocessor systems;performance enhancement;switches;modified least laxity first;context switches;real time tasks;real time systems;least laxity first	The Least-Laxity-First(LLF) scheduling algorithm assigns higher priority to a task with the least laxity, and has been proved to be optimal for a uniprocessor systems. The algorithm, however, is impractical to implement because laxity tie results in the frequent context switches among the tasks. The Modified Least-Laxity-First (MLLF) scheduling algorithm proposed in this paper solves the problem of the LLF scheduling algorithm by reducing the number of context switches significantly. By reducing the system overhead due to unnecessary context switches, the MLLF scheduling algorithm avoids the degradation of system performance and conserves more system resources for unanticipated aperiodic tasks. In this paper, we propose the MLLF scheduling algorithm and prove its optimality. We show the performance enhancement of the proposed MLLF scheduling algorithm by using simulation results.	algorithm;context switch;crew scheduling;data structure;elegant degradation;network switch;overhead (computing);preemption (computing);real-time clock;real-time transcription;scheduling (computing);simulation;uniprocessor system	Sung-Heun Oh;Seung-Min Yang	1998		10.1109/RTCSA.1998.726348	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;two-level scheduling;deadline-monotonic scheduling;distributed computing;computer performance;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling;proportionally fair	Embedded	-11.027749266443575	60.48371722015598	100315
677695f7d10247381be95460eda6ec93b2b34954	performance measurement and queueing analysis of medium-high blocking probability of two and three parallel connection servers	blocking probability;performance measure;analytical models;file servers;probability;time measurement;parallel connection servers;queueing theory;parallel connection server;web servers;time factors servers analytical models mathematical model queueing analysis time measurement measurement uncertainty;measurement uncertainty;system response time estimation;medium high blocking probability;servers;time factors;web server performance measurement queueing analysis medium high blocking probability parallel connection server system response time estimation asp multiplication loop;internet;queueing model;queueing theory file servers internet probability;parallel connection servers queueing networkt web servers service rate;queueing networkt;mathematical model;asp multiplication loop;web server;performance measurement;queueing analysis;service rate	In this paper we propose a performance measurement and queueing analysis for medium-high blocking probability where the service rate is less than equal to the arrival rate of parallel connection servers, and for which we can estimate the system response time. First, we calculate the system response time of the parallel connection servers. Second, we simulate the queueing model of the parallel connection servers and derive the system response time. Third, we measure the system response time by using different numbers of ASP multiplication loops to represent the different service rates of the parallel connection servers. Fourth, we compare the simulation and measurement results with the medium-high blocking probability of the parallel connection from the different service rates of the servers. Fifth, we compare the system response time of both multi-parallel connection servers and a single server.	blocking (computing);erlang (unit);queueing theory;response time (technology);series and parallel circuits;server (computing);simulation	Charlie Chung-Ping Chen;Ying-Wen Bai;Yin-Sheng Lee	2008	2008 33rd IEEE Conference on Local Computer Networks (LCN)	10.1109/LCN.2008.4664240	real-time computing;computer science;operating system;distributed computing;web server;statistics	Metrics	-11.86559028628638	67.05755074419366	100384
0144f00fcf8941684c6d0e512060efdb08f1fb28	multi-stream regular expression matching on fpga	field programmable gate array;random access memory;computer network security;multi stream;clocks;data stream;fpga;switches field programmable gate arrays context random access memory table lookup clocks impedance matching;maximum matching;network intrusion detection;deep packet inspection;single cycle switching multistream regular expression matching fpga deep packet inspection network intrusion detection single stream matching;design and implementation;impedance matching;context switching;place and route;distributed ram;field programmable gate arrays computer network security;field programmable gate arrays;switches;table lookup;fpga multi stream regular expression context switching distributed ram;regular expression;context	Regular expression matching (REM) is widely used by network community for deep packet inspection and network intrusion detection. Most of the existing REM solutions on FPGA address only single-stream matching. In many real-life scenarios, however, multiple data streams are often interleaved on a high-bandwidth input to be matched by a set of regular expressions. Each data stream, for example, can consist of the payloads of a packet flow in the network. This paper presents the design and implementation of a multi-stream regular expression matching engine on FPGA. Our approach includes: (1) a flexible distributed RAM-based context storage design, (2) an efficient context switching mechanism with single-cycle switching overhead. We implemented a multi-stream REM engine on FPGA for matching against up to 96 concurrent input streams. Using our design, a state-of-the-art FPGA device can match ~1,000 regular expressions, each of length up to 100 characters, against up to 64 concurrent input streams. Place-and-route results show that our design achieves 270 MHz while matching 4 input characters per cycle, resulting in a maximum matching throughput of 8.6 Gbps.	context switch;data rate units;deep packet inspection;field-programmable gate array;intrusion detection system;matching (graph theory);multiplexing;network packet;overhead (computing);place and route;random-access memory;real life;reconfigurability;regular expression;run time (program lifecycle phase);throughput;traffic flow (computer networking)	Yun Qu;Yi-Hua Edward Yang;Viktor K. Prasanna	2011	2011 International Conference on Reconfigurable Computing and FPGAs	10.1109/ReConFig.2011.63	embedded system;parallel computing;real-time computing;computer science;network security;operating system;field-programmable gate array	EDA	-6.968517229843505	66.13879238914711	100589
272c3f9baa2bf42c9329ef1c865a267072f19936	applying an efficient searching algorithm for intrusion detection on ubicom network processor		Intrusion Detection Systems (IDSs) have become widely recognized as powerful tools for identifying, deterring and deflecting malicious attacks over the network. Essential to almost every intrusion detection system is the ability to search through packets and identify content that matches known attacks. In this paper, common searching algorithms (string matching, Native, Boyer Moore and pattern matching algorithms) are examined on Ubicom Network Processor which is intended to be used as Network Intrusion Detection System (NIDS). Afterword, the suitable algorithm for Ubicom network processor is chosen which combine string matching and Native algorithms because these algorithms don’t have any type of preprocessing as Ubicom network processor doesn’t contain Micro Engine (ME) and doesn’t support multithreading which are used to speed the operation of preprocessing.	boyer–moore string search algorithm;embedded system;intrusion detection system;malware;multithreading (computer architecture);network processor;pattern matching;preprocessor;snort;string searching algorithm;thread (computing)	Qutaiba Ibrahim;Sahar Lazim	2011	Int. Arab J. e-Technol.		parallel computing;computer science;theoretical computer science;distributed computing	Security	-7.446665917650598	67.01877042882053	100700
788bc75797f21dd5317853f6f77c414ad4e97e96	dynamic search initialisation strategies for multi-objective optimisation in peer-to-peer networks	p2p system;distributed system;multiobjective optimisation;optimisation;search problems particle swarm optimisation peer to peer computing;new technology;multi objective optimisation;degradation;computational grid;concurrent computing;fault tolerant;peer to peer network;peer to peer computing distributed computing concurrent computing particle swarm optimization grid computing optimization methods design optimization performance loss degradation hybrid power systems;conference output;faculty of science environment engineering and technology;distributed computing;p2p;distributed computing environments;parallel and distributed computing;data mining;design optimization;particle swarm optimisation dynamic search initialisation strategies multiobjective optimisation peer to peer networks distributed computing environments population based optimisation algorithm;distance measurement;large scale;hybrid power systems;parallel systems;heuristic algorithms;particle swarm optimization;high performance computer;dynamic search initialisation strategies;population based optimisation algorithm;010303;optimization;distributed computing environment;approximation methods;search problems;distributed computing not elsewhere classified;p2p networks;peer to peer computing;peer to peer;peer to peer networks;grid computing;performance loss;particle swarm optimisation;080599;model simulation;optimization methods	Peer-to-peer based distributed computing environments can be expected to be dynamic to greater of lesser degree. While node losses will not usually lead to catastrophic failure of a population-based optimisation algorithm, such as particle swarm optimisation, performance will be degraded unless the lost computational power is replaced. When resources are replaced, one must consider how to utilise newly available nodes as well as the loss of existing nodes. In order to take advantage of newly available nodes, new particles must be generated to populate them. This paper proposes two methods of generating new particles during algorithm execution and compares the performance of each approach, then investigates a hybridised approach incorporating both mechanisms.	algorithm;authorization;baseline (configuration management);computation;distributed computing;distribution (mathematics);experiment;ieee congress on evolutionary computation;ieee xplore;mathematical optimization;mike lesser;pareto efficiency;particle swarm optimization;peer-to-peer;population;simulation;volatility	Ian Scriven;Andrew Lewis;Sanaz Mostaghim	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983122	mathematical optimization;fault tolerance;multidisciplinary design optimization;simulation;degradation;concurrent computing;computer science;theoretical computer science;peer-to-peer;distributed computing;particle swarm optimization;grid computing;distributed computing environment	HPC	-12.760055945645064	72.67673782796007	100983
956f442d30098de2057d44e900191f5a41210431	task allocation and optimization of distributed embedded systems with simulated annealing and geometric programming	time triggered;distributed embedded system;geometric program;task model;protocol design;simulated annealing;periodic tasks;coarse grained;task allocation	We consider the task model of periodic tasks running on a network of processor nodes connected by a bus based on the time-triggered protocol, an industry-standard bus protocol designed for safety-critical automotive and avionics distributed embedded systems, and present an integrated optimization framework that jointly considers one or more of the following attributes: task-toprocessor allocation, task priority assignment, task period assignment and bus access configuration. We adopt a hierarchical optimization framework, where each possible task allocation and priority assignment is treated as one top-level coarse-grained state, which may contain many lower-level fine-grained states defined by different task period assignments and bus access configurations. Simulated annealing is used to explore the top-level states, which calls a geometric programming solver as a subroutine to explore the lower-level states contained within a given top-level state. Performance evaluation shows that our framework has good performance in terms of solution quality and scalability.	approximation algorithm;avionics;batman: arkham city;blocking (computing);convex subgraph;design space exploration;embedded system;geometric programming;heuristic;iterative method;mathematical optimization;maxima and minima;np-hardness;non-blocking algorithm;optimization problem;performance evaluation;rate of convergence;scalability;simulated annealing;solver;subroutine;the computer journal;trusted third party	Xiuqiang He;Zonghua Gu;Yongxin Zhu	2010	Comput. J.	10.1093/comjnl/bxp084	parallel computing;real-time computing;simulated annealing;computer science;operating system;distributed computing	Embedded	-7.059494059491381	61.35178472211273	101110
65fb99d99c1a710555935ad4d5503ff21e65231e	intégration des évènements non périodiques dans les systèmes temps réel : application à la gestion des évènements dans la spécification temps réel pour java. (non periodic task integration in real-time systemes : application to the real-time specification for java)		In computer science, real-time systems are composed of tasks. To each task is associated a timing constraint called a deadline. We distinguish two kinds of tasks : the hard ones and the soft ones. Hard tasks have hard deadlines, which must be respected to ensure the correctness of the system. So hard tasks are in essence periodic, or sporadic. Their behavior has been extensively studied. Soft tasks have soft deadlines that the system has to try to respect. When a task arrival model is unknown, i.e. when task is aperiodic, burst arrivals situation can happens, which makes the tasks timing behavior unpredictable. So aperiodic tasks can only have soft deadlines. The studied problem in this thesis is then the joint scheduling of hard periodic tasks with soft aperiodic events, where the response times of soft tasks have to be as low as possible while the guarantee to meet their deadlines has to be given to hard tasks. A lot of solutions have been proposed these past two decades. We distinguish solutions based on resource reservation, like task servers, and solutions which take benefit from system idle times, like the slack stealer techniques. The first version of the Real-Time Specification for Java (RTSJ) was proposed in early 2000. This specification addresses a lot of problems related to the memory management or the scheduling of periodic tasks. But if it proposes a model to write aperiodic events, advanced mechanisms for the integration of such events to handle the above-mentioned problem are not discussed. We propose modifications to the main advanced mixed scheduling mechanisms like the Polling Server (PS), the Deferrable Server (DS) or the Dynamic Approximate Slack Stealer (DASS) in order to make their implementation possible with the RTSJ. Indeed, these algorithms are deeply connected to the system scheduler, and have to be adapted in order to be implemented in a user-land level. We propose extensions to current RTSJ APIs in order to integrate the modified algorithms and to allow the addition of other algorithms in a unified framework. We also propose some modifications to the RTSJ APIs in order to solve some problems we encountered during the integration of modified algorithms, especially in the field of the feasibility analysis algorithms integration in the specification. Finally, we propose the Minimal Approximate Slack Stealer algorithm (MASS), which is independent of the scheduler implementation and has a lower overhead than DASS.		Damien Masson	2008				Embedded	-9.79849557799065	60.73215826234693	101466
45f03e5125513c35a90b2faf740a4ed264911935	efficient binary search for ip address lookup	internet protocol;longest prefix matching;arbre recherche binaire;algoritmo busqueda;protocolo internet;descendant;routing;algorithme recherche;reseau ordinateur;simulation;search algorithm;protocole internet;routage;simulacion;tree data structures;trees mathematics;indexing terms;computer network;performance metric;memory access;transport protocols;software architecture;internet;telecommunication network routing;arbol investigacion binaria;binary search tree;internet router;red informatica;address lookup;binary search;binary tries internet routers software based ip address lookup binary search binary tree longest prefix matching;balance degree;internet routing binary trees switches associative memory hardware application specific integrated circuits costs time measurement scalability;binary trie;tree searching;table lookup;tree data structures internet software architecture table lookup tree searching trees mathematics transport protocols telecommunication network routing;ancestor;binary tree;enrutamiento	As an essential function in Internet routers, address lookup determines overall router performance. The most important performance metric in software-based address lookup is the number of memory accesses since it is directly related to lookup time. This letter proposes an algorithm to perform efficient binary search for IP address lookup. The depth of the proposed binary tree is very close to the minimum bound, and hence it results in much smaller number of worst case memory accesses compared to previous schemes. The proposed algorithm requires comparably small size of memory, and it can be used for software-based address lookup in practical Internet routers.	best, worst and average case;binary search algorithm;binary tree;lookup table;router (computing)	Changhoon Yim;Bomi Lee;Hyesook Lim	2005	IEEE Communications Letters	10.1109/LCOMM.2005.1461694	internet protocol;software architecture;routing;parallel computing;binary search tree;the internet;index term;binary tree;descendant;computer science;physical address;theoretical computer science;distributed computing;tree;longest prefix match;transport layer;computer network;binary search algorithm;search algorithm	Metrics	-5.702214097771678	66.93195939648082	101588
21a7e1b6e38a55b5dea1ca73e01bdce4c99f704c	availability is not enough: minimizing joint response time in peer-assisted cloud storage systems	replica placement bandwidth aware ba cloud storage peer assist;availability;resource management;joints;time factors;bandwidth;markov processes;availability time factors cloud computing joints resource management bandwidth markov processes;cloud computing	Cloud storage systems have been rapidly emerging recently since they bring fast and convenient storage services to users. We note that providing those service in a private-cloud way is costly, i.e., energy, bandwidth, and storage hardware are expensive for maintaining a cloud storage platform. To cope with the aforementioned issues, our idea is to exploit unused space and bandwidth at user-site machines to build a peer-assisted cloud storage platform. That is, in a peer-assisted cloud storage system, each peer helps back up data of other peers, and all peers form a virtual storage system. However, due to the uneven data popularity and the heterogeneous user upload capacity in peer-to-peer networks, bandwidth-oblivious replica placement might cause extremely long response time for certain data objects. Thus, this paper proposes a new metric called joint response time, which not only considers the waiting time when the requested data are unavailable but also the queuing delay and service time when data become available. We then design a 2-D Markov model to estimate this metric and propose a bandwidth-aware ( BA) replica placement algorithm to reduce the joint response time. Our trace-driven evaluation results validate that the proposed BA algorithm can efficiently utilize the upload capacity of each peer to provide peers a shorter joint response time.	backup;business architecture;cloud storage;computer data storage;fairness measure;load (computing);load balancing (computing);markov chain;markov model;peer-to-peer;queuing delay;response time (technology);responsiveness;rich internet application;scalability;selection algorithm;simulation;upload	Ming-Hung Chen;Yu-Chih Tung;Shih-Hao Hung;Kate Ching-Ju Lin;Cheng-Fu Chou	2016	IEEE Systems Journal	10.1109/JSYST.2014.2388223	availability;real-time computing;cloud computing;telecommunications;computer science;resource management;operating system;distributed computing;markov process;world wide web;computer security;bandwidth;statistics;computer network	OS	-18.338044339236006	66.5020535706408	101608
80b4d412ed167eb6c5ebccc19fec0464b0af6f4e	reliable memory efficient name forwarding in named data networking		Named Data Networking (NDN) is a promising future Internet architecture which retrieves the content using their names. Content names composed of strings separated by '/' are stored in the NDN Forwarding Information Base (FIB) to forward the incoming packets further. To retrieve content through their names poses two main challenges for the NDN FIB: high memory consumption and high lookup time. Therefore, an efficient and scalable data structure is required to store names in FIB. Encoding components in all the names with a unique integer can reduce the memory consumption as well as lookup time. In this paper, we propose a scalable and memory-efficient radix trie based name component encoding scheme, named RaCE, to implement NDN FIB. Our experiment results show that the RaCE scheme is reducing memory consumption by 89.95% and 26.07% compared to the original size of data and NCE [4] scheme for the 29 million dataset, respectively.	data structure;future internet;high memory;line code;lookup table;radix tree;scalability;trie	Divya Saxena;Vaskar Raychoudhury;Christian Becker;Neeraj Suri	2016	2016 IEEE Intl Conference on Computational Science and Engineering (CSE) and IEEE Intl Conference on Embedded and Ubiquitous Computing (EUC) and 15th Intl Symposium on Distributed Computing and Applications for Business Engineering (DCABES)	10.1109/CSE-EUC-DCABES.2016.160	computer network;memory management;trie;scalability;encoding (memory);high memory;data structure;computer science;network packet;forwarding information base	HPC	-6.6213626710527995	66.961454567183	101890
fed03b6431c8feaf8ec9450ce69cbdae629ec41d	scheduling a computational dag on a parallel system with communication delays and replication of node execution	directed graphs;computers;directed acyclic graph;data exchanges;optimisation;np complete node execution replication computational directed acyclic graph scheduling parallel system communication delays subtasks precedence constraints data exchanges optimization criterion;concurrent computing;search space;processor scheduling;processor scheduling concurrent computing delay systems optimal scheduling tree graphs scheduling algorithm computational modeling polynomials parallel processing computers;task model;data exchange;satisfiability;polynomials;tree graphs;scheduling algorithm;computational modeling;precedence constraints;optimization criterion;parallel systems;computational complexity;optimal scheduling;scheduling computational complexity delays directed graphs optimisation parallel algorithms;scheduling;computational directed acyclic graph scheduling;node execution replication;precedence constraint;communication delay;np complete;delay systems;parallel system;subtasks;parallel processing;communication delays;delays;exhaustive search;parallel algorithms	The authors consider the problem of optimally scheduling the subtasks of a computational task modeled by a dag (directed acyclic graph) on parallel systems with identical processors. Execution of the subtasks (nodes) must satisfy precedence constraints that are met via data exchanges among processors which introduce communication delays. The optimization criterion used is the minimization of the processing time and the authors assume that there is no restriction on the number of processors needed and that a node may be replicated. They prove that the optimal scheduling problem can be solved in polynomial amount of time when the computational graph is a two-level dag. For a general dag they develop an algorithm that significantly reduces the search space over exhaustive search and can work very fast in many cases (the problem is NP-complete). >		Pauline Markenscoff;Yong Yuan Li	1993		10.1109/IPPS.1993.262865	parallel computing;real-time computing;computer science;distributed computing;topological sorting	HPC	-13.304939374781439	60.727609670683634	102421
e971951098a67099b53bdcbacf68aecce5d99565	a gspn model for the analysis of dns-based redirection in distributed web systems	web system;distributed system;telecommunication computing computational modeling analytical models computer simulation;network servers;internet traffic;internet;stochastic processes;dispatching algorithms approximate generalized stochastic petri nets dns based redirection distributed web systems internet multiple servers proxy servers authoritative domain name server request dispatcher role url host name ip address replica servers time to live period schedulers parallel systems distributed systems;scheduling;petri nets;time to live;domain name server;stochastic processes petri nets internet network servers scheduling;geographic distribution;generalized stochastic petri net	The rapid growth of the Internet, in both user numbers and Web content, has fueled extensive efforts to improve the user's overall Internet experience. A growing number of providers deliver content from multiple servers or proxies to reduce response time by moving content closer to end users. An increasingly popular mechanism to direct client requests towards one of the replica servers is DNS-based redirection. In this mechanism, the authoritative domain name server (ADNS) of the Web site takes the request dispatcher role by mapping the URL host name into the IP address of one of the replica servers (both locally and geographically distributed). However, the ADNS controls only a very small fraction of the requests reaching the Web site because the address mapping is not requested for each client access. Indeed, to reduce Internet traffic due to DNS requests, address resolution is cached at various name servers for a time-to-live (TTL) period, opening a new set of problems not addressed in classical centralized schedulers of parallel and/or distributed systems. We present an approximate generalized stochastic Petri nets (GSPN) model for the analysis of the workload offered to replica servers in a DNS based redirection architecture. Different dispatching algorithms, as well as different strategies to manage TTL assignment at the ADNS, are considered to show the potential of the GSPN based analysis.	adns;approximation algorithm;centralized computing;distributed computing;internet;proxy server;response time (technology);server (computing);stochastic petri net;time to live;transistor–transistor logic;web content;world wide web	Rossano Gaeta;Marco Gribaudo;Daniele Manini;Matteo Sereno	2004	The IEEE Computer Society's 12th Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, 2004. (MASCOTS 2004). Proceedings.	10.1109/MASCOT.2004.1348180	root name server;round-robin dns;stochastic process;real-time computing;the internet;internet traffic;time to live;computer science;operating system;distributed computing;name server;scheduling;petri net;domain name system;server;computer network	Metrics	-18.211507979335284	70.00615113327993	102573
3015af482bb9423da9f89af1fab0a6d8372d4d2e	online cost minimization for operating geo-distributed cloud cdns	algorithm design and analysis servers heuristic algorithms bandwidth delays quality of service minimization;conference_paper;offline cost minimization optimization online cost minimization geo distributed cloud cdn content delivery network cost aware replica placement dynamic content replication request dispatching;minimisation cloud computing	"""Cloud-based content delivery networks (Cloud CDN) cache and deliver contents from geo-distributed cloud data centers to end users across the globe, exploiting """"infinite"""" on-demand cloud resources to address volatile user demands. It is critically important to efficiently manage cloud resources in different locations over time, for minimization of the operational cost of the CDN provider, while delivering short response delay to user requests. Although many have studied cost-aware replica placement and request redirection in CDN systems, most are restricted to an offline or one-time setting, or resort to greedy heuristics for online operation. This work proposes an efficient online algorithm for dynamic content replication and request dispatching in cloud CDNs operating over a long time span, targeting overall cost minimization with performance guarantees. Our online algorithm consists of two main modules: (1) a regularization method from the online learning literature to convert the offline cost-minimization optimization problem into a sequence of regularized problems, each to be efficiently solvable in one time slot; (2) a randomized approach to convert the optimal fractional solutions from the regularized problems to integer solutions of the original problem, achieving a good competitive ratio. The effectiveness of our online algorithm is validated through solid theoretical analysis and trace-driven simulations."""	cloud computing;competitive analysis (online algorithm);content delivery network;data center;decision problem;digital distribution;dynamic web page;greedy algorithm;heuristic (computer science);linear programming relaxation;mathematical optimization;online algorithm;online and offline;online machine learning;optimization problem;polynomial;randomized algorithm;randomized rounding;simulation;time complexity	Xiaoxi Zhang;Chuan Wu;Zongpeng Li;Francis C. M. Lau	2015	2015 IEEE 23rd International Symposium on Quality of Service (IWQoS)	10.1109/IWQoS.2015.7404698	real-time computing;simulation;computer science;operating system;distributed computing;computer network	Metrics	-18.776021635821024	65.7564751653171	102854
5c3b127b89aa038e8a9c6432d984c89312ff1ad1	work-in-progress: response time bounds for typed dag parallel tasks on heterogeneous multi-cores		Heterogenerous multi-cores utilize the strength of different architectures for executing particular types of workload, and usually offer higher performance and energy efficiency. In this paper, we study the worst-case response time (WCRT) analysis of typed scheduling of parallel DAG tasks on heterogeneous multi-cores, where the workload of each vertex in the DAG is only allowed to execute on a particular type of cores. The only known WCRT bound for this problem is grossly pessimistic and suffers the non-self-sustainability problem. In this paper, we propose two new WCRT bounds. The first new bound has the same time complexity as the existing bound, but is more precise and solves its non-self-sustainability problem. The second new bound explores more detailed task graph structure information to greatly improve the precision, but is computationally more expensive. We prove that the problem of computing the second bound is strongly NP-hard if the number of types in the system is a variable, and develop an efficient algorithm which has polynomial time complexity if the number of types is a constant. Experiments with randomly generated workload show that our proposed new methods are significantly more precise than the existing bound while having good scalability.		Meiling Han;Nan Guan;Jinghao Sun;Qingqiang He;Qingxu Deng;Weichen Liu	2018	2018 IEEE Real-Time Systems Symposium (RTSS)	10.1109/RTSS.2018.00028	parallel computing;time complexity;workload;work in process;distributed computing;efficient energy use;scalability;scheduling (computing);multi-core processor;response time;computer science	Embedded	-13.61647765246034	61.44425172247228	103125
6362bac65ff4cf85102974fc67eeda425d81a7ae	conflict detection and resolution in two-dimensional prefix router tables	conflict detection;filter conflict;packet classification;efficient algorithm;information filtering information filters testing internet two dimensional displays bandwidth protocols matched filters computer science information science;2 dimensional;packet classification filter conflict two dimensional prefix filters;internet;telecommunication network routing;computational complexity;two dimensional prefix filters;space complexity;2d filter sets conflict detection two dimensional prefix router tables first matching rule in table tie breaker np hard space complexity bit vector algorithm internet;information filters internet telecommunication network routing computational complexity;information filters	We show that determining the minimum number of resolve filters that need to be added to a set of two-dimensional (2-D) prefix filters so that the filter set can implement a given policy using the first-matching-rule-in-table tie breaker is NP-hard. Additionally, we develop a fast O(nlogn + s) time, n where is the number of filters and s is the number of conflicts, plane-sweep algorithm to detect and report all pairs of conflicting 2-D prefix filters. The space complexity of our algorithm is O(n). On our test set of 15 2-D filter sets, our algorithm runs between 4 and 17 times as fast as the 2-D trie algorithm of A. Hari et al. (2000) and uses between 1/4th and 1/8th the memory used by the algorithm of Hari et al. On the same test set, our algorithm is between 4 and 27 times as fast as the bit-vector algorithm of Baboescu and Varghese (2002) and uses between 1/205 and 1/6 as much memory. We introduce the notion of an essential resolve filter and develop an efficient algorithm to determine the essential resolve filters of a prefix filter set.	bit array;dspace;filter bank;image resolution;router (computing);routing table;sweep line algorithm;test set;trie	Haibin Lu;Sartaj Sahni	2005	IEEE/ACM Transactions on Networking	10.1109/TNET.2005.860108	adaptive filter;two-dimensional space;the internet;computer science;theoretical computer science;distributed computing;dspace;computational complexity theory;algorithm;computer network	Visualization	-6.834957259404639	68.57389884257408	103145
0d433f280cbde90f98ae202a46edd2bc05b77420	redundancy-d: the power of d choices for redundancy	replication;redundancy;task assignment;dispatching	Redundancy is an important strategy for reducing response time in multi-server distributed queueing systems. This strategy has been used in a variety of settings, but only recently have researchers begun analytical studies. The idea behind redundancy is that customers can greatly reduce response time by waiting in multiple queues at the same time, thereby experiencing the minimum time across queues. Redundancy has been shown to produce significant response time improvements in applications ranging from organ transplant waitlists to Google’s BigTable service. However, despite the growing body of theoretical and empirical work on the benefits of redundancy, there is little work addressing the questions of how many copies one needs to make to achieve a response time benefit, and the magnitude of the potential gains. In this paper we propose a theoretical model and dispatching policy to evaluate these questions. Our system consists of k servers, each with its own queue. We introduce the Redundancy-d policy, u...	download;institute for operations research and the management sciences;robot	Kristen Gardner;Mor Harchol-Balter;Alan Scheller-Wolf;Mark Velednitsky;Samuel Zbarsky	2017	Operations Research	10.1287/opre.2016.1582	redundancy (engineering);operations management;magnitude (mathematics);real-time computing;queueing theory;response time;ranging;computer science;queue;server	Logic	-15.071402792318652	65.81459782166475	103199
e75171ac9f47f3f9059a4a88444718e94d30fe0a	information access and qos issues in a mobile computing environment	distributed system;hierarchical system;largeur bande;computadora personal;systeme reparti;ordinateur personnel;mise a jour;personal computer;telecommunication sans fil;systeme hierarchise;hierarchical networks;mobile computer;080502 mobile technologies;information access;qualite service;sistema jerarquizado;mobile environment;sistema repartido;portable equipment;telecomunicacion sin hilo;analyse performance;anchura banda;performance analysis;acces information;bandwidth;acceso informacion;puesta al dia;quality of service issue;service quality;appareil portatif;updating;aparato portatil;calidad servicio;analisis eficacia;wireless telecommunication	Efficient access to coherent information files is an important issue in mobile computing. In this paper we consider performance analysis of information access in a mobile computing environment. We employ a distributed directory scheme that permits uninterrupted use under disconnected and low bandwidth connections and minimizes invalidation and false sharing. This scheme allows for two invalidation schemes that avoid false sharing, and a mechanism for efficient maintenance of file details. We analyse the performance of the directory scheme in terms of time taken and energy consumed in executing operations such as read/write, connection, disconnection, and hoarding in mobile environments. The directory scheme is employed for facilitating efficient transfer of partially updated files in hierarchical networks. We also investigate quality of serviceissues related to file accesses in the mobile computing environment discussed in the paper. However, the scheme can be extended to any mobile computing environment.  1999 Academic Press	access time;coherence (physics);coherent information;directory (computing);false sharing;file sharing;information access;locality of reference;lock (computer science);mobile computing;quality of service;read-write memory;scalability;simulation;software portability;tree network	Mithlesh Kumar;S. Venkatesh;K.-Y. Lim;H. Santoso	1999	J. Network and Computer Applications	10.1006/jnca.1999.0085	embedded system;mobile search;telecommunications;mobile database;computer science;artificial intelligence;operating system;hierarchical control system;mobile computing;computer security;service quality;bandwidth;computer network	HPC	-12.796385593108692	69.1657452977329	103206
ec6f4750ea3db2b7b7caa0268d4bc44fcef27245	evaluation of the feedback guided dynamic loop scheduling (fgdls) algorithms	parallel loop scheduling;tecnologia electronica telecomunicaciones;feedback guided dynamic loop scheduling;algorithms;tecnologias;grupo a		algorithm;loop scheduling	Sabin Tabirca;Tatiana Tabirca;Laurence Tianruo Yang;Len Freeman	2004	IEICE Transactions		embedded system;real-time computing;computer science;distributed computing;algorithm	Visualization	-11.628551107820048	62.37965739496351	103239
8c58ef8264622497641b8c5bc56b76d22891f75a	worst-case temperature analysis for real-time systems	worst case temperature analysis;thermal analysis;semiconductor technology;power density;realtime calculus;embedded realtime systems;thermal analysis real time systems compositional analysis worst case peak temperature;earliest deadline first;real time;rate monotonie scheduling algorithm;embedded real time systems;task execution time;task arrival jitter worst case temperature analysis semiconductor technology chip temperature embedded realtime systems earliest deadline first scheduling algorithm rate monotonie scheduling algorithm deadline monotonic scheduling algorithm network calculus realtime calculus task execution time task invocation period;task arrival jitter;real time embedded system;worst case peak temperature;chip;upper bound;embedded systems;earliest deadline first scheduling algorithm;scheduling algorithm;network calculus;real time systems jitter upper bound thermal management thermal analysis timing calculus;scheduling;calculus;chip temperature;deadline monotonic scheduling algorithm;jitter;compositional analysis;deadline monotonic;thermal management;rate monotonic;microprocessor chips;task invocation period;real time systems;scheduling calculus embedded systems microprocessor chips;timing	With the evolution of today's semiconductor technology, chip temperature increases rapidly mainly due to the growth in power density. For modern embedded real-time systems, it is crucial to estimate maximal temperatures in order to take mapping or other design decisions to avoid burnout, and still be able to guarantee meeting real-time constraints. This paper provides answers to the question: When work-conserving scheduling algorithms, such as earliest-deadline-first (EDF), rate-monotonie (RM), deadline-monotonic (DM), are applied, what is the worst-case peak temperature of a real-time embedded system under all possible scenarios of task executions? We propose an analytic framework, which considers a general event model based on network and real-time calculus. This analysis framework has the capability to handle a broad range of uncertainties in terms of task execution times, task invocation periods, and jitter in task arrivals. Simulations show that our framework is a cornerstone to design real-time systems that have guarantees on both schedulability and maximal temperatures.	algorithm;baseline (configuration management);best, worst and average case;computer simulation;critical system;earliest deadline first scheduling;embedded system;emoticon;event (computing);maximal set;noise temperature;non-monotonic logic;real-time clock;real-time computing;real-time transcription;scheduling (computing);semiconductor;thermal management of high-power leds	Devendra Rai;Hoeseok Yang;Iuliana Bacivarov;Jian-Jia Chen;Lothar Thiele	2011	2011 Design, Automation & Test in Europe	10.1109/DATE.2011.5763104	embedded system;parallel computing;real-time computing;telecommunications;computer science;operating system;distributed computing;scheduling	Embedded	-7.541202201468897	60.539959283813815	103285
a4ac63c70ea60ac995962c370bce7f6c205239a2	reducing maintenance overhead in dht based peer-to-peer algorithms	p2p system;distributed processing computational complexity file organisation telecommunication network routing telecommunication traffic;distributed processing;p2p;peer to peer computing routing data structures impedance computer science broadcasting telecommunication traffic secure storage information management fault tolerance;dynamic environment;telecommunication traffic;telecommunication network routing;computational complexity;network traffic;distributed hash table dht based peer to peer algorithms broadcasting based routing performance routing information maintenance overhead reduction network traffic p2p system complexity dynamic environment;peer to peer;file organisation	DHT basedPeer-to-Peer (P2P) algorithmsare very promising for their efficientroutingperformance. However, mostcommer cial P2PsystemsdonotadaptDHT algorithmsandstill usecentral facilities or broadcastingbasedrouting mechanisms. One reasonimpedingthe DHT algorithm popularity is the routing informationmaintenance overhead in DHT algorithms,it generatesconsider able network traffic and increases P2P system complexity, especiallyin a highly dynamic environment.In this paper, we discussits effectson DHT routing performance and proposeour solutionto reducethis overhead.	algorithm;distributed hash table;network traffic control;overhead (computing);peer-to-peer;routing	Zhiyong Xu;Rui Min;Yiming Hu	2003		10.1109/PTP.2003.1231533	policy-based routing;routing table;routing domain;routing;enhanced interior gateway routing protocol;static routing;real-time computing;hierarchical routing;dsrflow;zone routing protocol;equal-cost multi-path routing;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;peer-to-peer;database;distributed computing;routing protocol;link-state routing protocol;computational complexity theory;computer network	Metrics	-11.793458857601284	74.01405967469124	103363
c63d2a79b379be696a0cecd3833a1f0634ff4827	a modified bce algorithm for fault-tolerance scheduling of periodic tasks in hard real-time systems	cat algorithm;fault probability;fault tolerant;processor scheduling;software fault tolerance;scheduling algorithm;hard real time system;fault tolerant systems;periodic tasks;eit algorithm scheduling fault tolerant periodic tasks real time systems cat algorithm;processor utilization;scheduling;fault tolerance;real time control system;fault tolerance scheduling;software fault tolerance real time systems scheduling;scheduling algorithm fault tolerant systems real time systems job shop scheduling timing tomography asia control systems processor scheduling computational modeling;processor utilization fault tolerance scheduling hard real time systems fault probability;eit algorithm;algorithm design and analysis;hard real time systems;uniform distribution;real time systems;time constraint	Fault tolerance is an important aspect of real-time control systems, due to unavoidable timing constraints. In this paper, the timing problem of a set of concurrent periodic tasks is considered where each task has primary and alternate versions. In the literature, probability of fault in the alternate version of a task is assumed to be zero. Here, a fault probability with uniform distribution has been used. In addition, to cover the situations in which both versions are scheduled with some time overlapping, a criterion is defined for prioritizing primary version against the alternate version. A new scheduling algorithm is proposed based on the defined criterion. Simulation results show that an increase in the number of executed primary tasks which improves the efficiency of processor utilization, hence prove the efficiency of the proposed algorithm.	algorithm;control system;fault tolerance;real-time clock;real-time operating system;scheduling (computing);simulation	Meysam Asadi;Mohammad Bagher Menhaj;Ehsan Yavari	2009	2009 Third Asia International Conference on Modelling & Simulation	10.1109/AMS.2009.63	parallel computing;real-time computing;computer science;distributed computing	Embedded	-11.276178169401533	60.68462986585271	103381
84283c9d86940b037788477e78d06ca1868bde53	a scalable on-demand video delivery paradigm	video object;multicast communication;tariffs video on demand video servers visual communication scheduling multicast communication;scalable video;visual communication;tariffs;scheduling;video on demand;video on demand network servers telecommunication traffic watches costs processor scheduling motion pictures multimedia communication broadcasting;video servers;pricing scheme video on demand scalable video delivery scheduled video delivery multicasting groups video objects proxy servers	Most existing on-demand video services, such as VoD, batching and patching, are not scalable. Although the near VoD service is scalable, it can provide only dozens of videos. A scalable video delivery paradigm, named scheduled video delivery (SVD), is described. In the SVD paradigm, users submit requests with specification of start time. The SVD system combines requests to form multicasting groups and schedules these groups to meet the deadline. SVD is not only scaled to the number of users but also to the number of video objects. Furthermore, SVD can serve more clients with mirroring proxies.	programming paradigm;scalability	Sujun Ma;Min-You Wu;Wei Shu	2002		10.1109/ICME.2002.1035707	real-time computing;computer science;operating system;video tracking;multimedia;scheduling;visual communication;computer network	Vision	-16.14259382086806	72.43639954466681	103666
633043469dda64f17b21ec28de3822611d307223	on the design of a performance-aware load balancing mechanism for p2p grid systems	distributed computing;p2p;job migration;system performance;information gathering;grid;system integration;load balancing;load balance;grid computing;grid system	P2P grid computing systems integrate geographical computing resources across multiple administrative domains. In P2P grid systems, one of the most important challenges is how to efficiently exploit the load balancing of distributed computing resources. This paper proposes a performance-aware load balancing mechanism in order to exploit distributed computing resources in P2P grid computing systems. The performance-aware load balancing mechanism supports the capabilities of resource information gathering, job migration and load balancing. The resource information gathering uses the P2P technique to collect distributed resource information; the job migration mechanism adopts the P2P technique to improve the utilization of idle computing resources; and the decentralized load balancing policy could dynamically adjust the load according to the system performance. We quantify the performance of our performance-aware load balancing mechanism. Experimental results show that our proposed mechanism could efficiently distribute load in P2P Grid systems.	load balancing (computing)	You-Fu Yu;Po-Jung Huang;Kuan-Chou Lai;Chao-Tung Yang;Kuan-Ching Li	2009		10.1007/978-3-642-01671-4_25	round-robin dns;network load balancing services;parallel computing;real-time computing;computer science;load balancing;distributed computing;computer performance;computer security;grid computing	HPC	-17.357934693499917	60.613887235824514	103724
1402005ec32f2883b61df1b0f5ff6ae47c15d676	user-centric performance analysis of market-based cluster batch schedulers	time measurement;perforation;processor scheduling;performance analysis resource management processor scheduling cost accounting feedback aggregates scheduling algorithm time measurement clustering algorithms computer science;resource management;utility function;cluster of workstations;performance metric;cost accounting;system evaluation;scheduling algorithm;feedback;aggregates;performance analysis;clustering algorithms;computer science	This paper presents a performance analysis of market-based batch schedulers for clusters of workstations. In contrast to previous work, we use user-centric performance metrics as the basis for system evaluation. Each user is modeled as having a utility function for each job which measures value delivered to the user as function of execution time. Summing over all utility functions in the workload, we use aggregate utility as a measure of overall value delivered to users. With aggregate utility as the performance metric, simulations are used to quantify the performance of both market-based and traditional batch scheduling algorithms under a variety of synthetic work-loads. Results show that an auction-based batch scheduling algorithm improves performance by a factor of up to 2-5x for sequential workloads and up to 14x for highly parallel workloads compared to traditional scheduling algorithms.	aggregate data;aggregate function;algorithm;batch processing;category utility;computational resource;fifo (computing and electronics);job queue;job scheduler;job stream;preemption (computing);priority queue;profiling (computer programming);resource management (computing);run time (program lifecycle phase);scheduling (computing);shortest job next;simulation;supercomputer;synthetic intelligence;utility;value (ethics);workstation	Brent N. Chun;David E. Culler	2002	2nd IEEE/ACM International Symposium on Cluster Computing and the Grid (CCGRID'02)	10.1109/CCGRID.2002.1017109	real-time computing;simulation;computer science;resource management;job scheduler;operating system;feedback;distributed computing;cluster analysis;scheduling;time;cost accounting	HPC	-18.420587057577666	60.86891613540519	103999
da5409d93a7e843a97c4c1f6c142ebc614294041	efficient index caching schemes for data broadcasting in mobile computing environments	database indexing;cache storage;cutting plane;information dissemination mobile computing database indexing distributed databases cache storage data communication broadcasting;mobile computer;data communication;broadcasting mobile computing energy consumption delay broadcast technology scalability scheduling stock markets distributed computing conferences;mobile clients index caching schemes data broadcasting mobile computing disseminating data power consumption reduction index tree distributed access pattern;indexation;information dissemination;distributed databases;data broadcast;broadcasting;power consumption;mobile computing	Data broadcasting is an efficient technique for disseminating data in mobile computing environments. To reduce the power consumption of the mobile clients, index is used to expedite the access of the disseminated data. In our opinion, caching the indices on the mobile clients can further reduce the tuning time of the mobile clients. In this paper, we propose two policies to reduce the tuning time of the mobile clients. The lower level index first policy tends to cache the leave index nodes of the index tree while the cut plane first policy caches the cut-plane of the index tree. According to our experiments, both policies have significantly reduced the tuning time and the access time of the mobile clients. Furthermore, the cut plane first policy prevails in the case where the cache size of the clients is small, or when the clients have a uniformly distributed access pattern over the broadcast data items.	access time;cache (computing);coalition for patent fairness;datacasting;experiment;group policy;mobile computing	Jen-Jou Hung;Yungho Leu	2003		10.1109/DEXA.2003.1232013	database index;mobile search;mobile database;computer science;operating system;mobile technology;database;distributed computing;mobile computing;world wide web;broadcasting;computer network;cutting-plane method	Web+IR	-15.328167091487439	69.035636170709	104000
d89d745a0390a6fcf850443b63db1532cbe4ae0f	classifying e-commerce workloads under dynamic caching	resource allocation electronic commerce cache storage internet data mining transaction processing;cache storage;e commerce activity profiles e commerce workload classification dynamic caching database server performance online analytical processing online transaction processing;electronic commerce;capacity planning;resource allocation;e commerce;data mining;internet;web server transaction databases network servers image databases computer science educational institutions information technology scalability capacity planning resource management;transaction processing	In an e-commerce system, the database server performance is crucial. Dynamic caching is often used to reduce the load on the database server, which reduces the need for scalability within the server itself. A good understanding of the workload characteristics of the database server in an e-commerce environment is important to the design, tuning, and capacity planning. Using dynamic caching can dramatically alter the characteristics of requests that the database server receives, changing the dominant operations, even the workload type. The two major database workload classifications are online analytical processing and online transaction processing. Allocations for resources such as main memory can be very different, depending on the workload type. We investigate the e-commerce activity profiles resulting from dynamic caching. We find that dynamic caching does tend to alter the behavior towards transaction processing.	benchmark (computing);browsing;cache (computing);computer data storage;data mining;database server;e-commerce;e-commerce payment system;online analytical processing;online transaction processing;performance tuning;ping (networking utility);scalability;server (computing);tpc-w	Fujian Liu;Dwight J. Makaroff;Said Elnaffar	2005	2005 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2005.1571577	e-commerce;log shipping;real-time computing;the internet;transaction processing;distributed transaction;resource allocation;computer science;database;online transaction processing;world wide web;transaction processing system;server farm	DB	-18.363916193167583	69.22702201805498	104125
4abbcfb5709ed13d113324fed297ed334b6eb079	polynomial throughput bounds for equal conflict petri nets with multi-guarded transitions	throughput bounds;early evaluation;performance evaluation;multiguarded transitions;multiplexing equipment;polynomial throughput bounds;satisfiability;system performance;multiplexing;petri nets early evaluation throughput bounds;firing;firing throughput fires petri nets multiplexing steady state program processors;linear programming;early evaluation polynomial throughput bounds conflict petri nets multiguarded transitions multiplexer linear programming problem;linear program;multiplexer;petri nets;petri net;fires;conflict petri nets;program processors;throughput;linear programming problem;steady state;petri nets linear programming multiplexing equipment performance evaluation	Early evaluation is a strategy that aims at enhancing the system performance by executing operations as soon as enough information is available. A common unit that allows early evaluation is the multiplexer: its output can be produced as soon as data is available in the selected channel, without waiting for data in the other channels. Petri nets can model early evaluation of operations by associating several guards with each transition. A multi-guarded transition can fire as soon as the guard selected for the next firing is satisfied. This paper proposes a linear programming problem to compute throughput bounds for equal conflict Petri nets with multi-guarded transitions.		Jorge Júlvez	2008	2008 Fifth International Conference on Quantitative Evaluation of Systems	10.1109/QEST.2008.28	real-time computing;computer science;linear programming;theoretical computer science;distributed computing;petri net	SE	-11.688179688212204	60.45813353448602	104420
e756bdfad75d2f67bcbbc9682f5916e1123fee70	guaranteed task deadlines for fault-tolerant workloads with conditional branches	fault tolerant;real time	This work examines scheduling for a real-time multiprocessor (MAFT) in which both hard deadlines and fault-tolerance are necessary system components. A workload for this system consists of a set of concurrent dependent tasks, each with some execution frequency; tasks are also fully ordered by priority. Fault tolerance mechanisms include hardware-supported voting on computation results as well as on task starts, task completions, and branch conditions. The distributed agreement mechanism used on system-level decisions adds a variable threading delay to the run time of each copy of a task. These delays make current schedule verification techniques inapplicable. In the most general execution profile, each processor in the system runs a subset of the tasks, with different tasks possibly having different frequencies. In this work, however, we restrict attention to a special class of workloads, termed uni-schedule, in which each processor executes the entire task set, using the multiple processors to implement full redundancy. In addition, all tasks are assumed to have the same periodicity. Given these restrictions, we produce stable schedules consistent with the initial workload specifications. Algorithms are first given for uni-schedule workloads with no run-time branches, and then for uni-schedule workloads with branches.	algorithm;central processing unit;computation;fault tolerance;multiprocessing;quasiperiodicity;real-time clock;run time (program lifecycle phase);scheduling (computing);thread (computing)	Michelle C. McElvany;P. David Stotts	1991	Real-Time Systems	10.1007/BF00364959	fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing	Embedded	-10.247685566005709	60.61084681897336	104548
148566662093b37e3482fbffc063b30a1108d9d3	copacc: a cooperative proxy-client caching system for on-demand media streaming	p2p system;distributed system;streaming;systeme reparti;multimedia;systeme cooperatif;multimedia streaming;par a par;transmision continua;serveur informatique;proxy caching;p2p;cache memory;antememoria;antememoire;transmission en continu;sistema repartido;cooperative systems;poste a poste;media streaming;servidor informatico;peer to peer;computer server	Proxy caching is a key technique to reduce transmission cost for on-demand multimedia streaming. The effectiveness of current caching schemes, however, is limited by the insufficient storage space and weak cooperations among proxies and their clients, particularly considering the high bandwidth demands from media objects. In this paper, we propose COPACC, a cooperative proxy-and-client caching system that addresses the above deficiencies. This innovative approach combines the advantages of both proxy caching and peer-to-peer client communications. It leverages the client-side caching to amplify the aggregated cache space and rely on dedicated proxies to effectively coordinate the communications. We propose a comprehensive suite of protocols to facilitate the interactions among different network entities in COPACC. It also realizes a smart and cost-effective cache indexing, searching, and verifying scheme. Furthermore, we develop an efficient cache allocation algorithm for distributing video segments among the proxies and clients. The algorithm not only minimizes the aggregated transmission cost of the whole system, but also accommodates heterogeneous computation and storage constraints of proxies and clients. We have extensively evaluated the performance of COPACC under various network and end-system configurations. The results demonstrate that it achieves remarkably lower transmission cost as compared to pure proxy-based caching with limited storage space. On the other hand, it is much more robust than a pure peer-to-peer communication system in the presence of node failures. Meanwhile, its computation and control overheads are both kept in low levels.	algorithm;cache (computing);client-side;computation;entity;interaction;peer-to-peer;proxy server;verification and validation	Alan T. S. Ip;Jiangchuan Liu;John C. S. Lui	2005		10.1007/11422778_120	real-time computing;cpu cache;telecommunications;computer science;operating system;peer-to-peer;database;distributed computing;world wide web;server	OS	-13.047069299483297	70.95012038975162	104930
91e347cb807ef4ba2fd31e2da251b749fb9f5dd6	messages scheduling for data redistribution between heterogeneous clusters	cluster computing;approximate algorithm;network interface card;heterogeneous cluster;general solution;distributed environment;optimal scheduling;distribution pattern	In this paper, we tackle the problem of redistributing data between clusters connected by a backbone. On distributed environments, communications often take more time [12] and thus lead to worse results than on local clusters. There is therefore a strong need to optimize the time needed by communications.Indeed, when an application composed of several codes running on distant clusters is executing, data are required to be redistributed between the clusters. We propose a general solution to the problem when the platform is fully heterogeneous platforms (each node of each cluster can communicate at different speed) or when some nodes have several network interface cards. We provide an algorithm for scheduling the messages that gives a solution at most twice as long as the optimal one. Simulation results show that it is giving almost optimal schedules on large redistribution patterns, and very good results in the general case.	approximation algorithm;bottleneck (engineering);code;computer cluster;distributed shared memory;internet backbone;network interface controller;performance;scheduling (computing);simulation	Emmanuel Jeannot;Frédéric Wagner	2005			fair-share scheduling;parallel computing;real-time computing;computer cluster;computer science;operating system;distributed computing;network interface controller;distributed computing environment	HPC	-14.175054249017789	60.737733956670326	105129
f56abc87d37f11ece898054e06b379c39072e182	an approach to grid resource selection and fault management based on eca rules	resource selection;first come first serve;computational grid;performance evaluation;fault tolerant;active database;real time;resource manager;eca rules;satisfiability;performance metric;large scale;general methods;fault tolerance;grid service;parallel computer;quality of service qos;event condition action;quality of service;system architecture;grid computing;database management system;quick response;fault management	In grid computing, resource management and fault tolerance services are important issues. Because the numbers of the application tasks and amounts of required resources are enormous and quick responses to the requirements of users are necessary in the real grid environment, realtime resource co-allocation may be large-scale. This paper proposes an Active Grid Information Server (AGIS) that is a resource manager for optimal resource selection and fault tolerant service using a database management system that supports event–condition–action (ECA) rules. Our resource manager automatically selects the set of optimal resources among idle resources that achieves optimal performance while turnaround time is chosen as metric for performance evaluation. Typically, the probability of a failure is higher in grid computing than in traditional parallel computing and the failure of resources affects job execution fatally. Therefore, a fault tolerance service is essential in computational grids. Grid services are often expected to meet some minimum levels of Quality of Service (QoS) for a desirable operation. To address this issue, we also propose a fault tolerance service that satisfies QoS requirements. The fault tolerance requires timely notification of changes, raising the need for mechanisms for monitoring and processing such changes. Event–condition–action (ECA) rules are a natural candidate to fulfill this need. We develop conservative tests for determining the termination and confluence of sets of ECA rules. We argue that the employment of ECA rules, both for resource selection and fault tolerance, leads to efficiency and to additional techniques. Furthermore, the proposed AGIS system architecture offers a number of advantages owing to the performance and scalability that can be achieved using active databases. Our preliminary performance results indicate that the ECA rule-based approach for resource matching is efficient in speed and accuracy and can keep up with high job-arrival rates — an important criterion for online resource matching systems. We describe Grid-JQA, an architecture supporting such rules in grid environments, and our current implementation of this architecture. Three heuristic approaches have been designed and compared via simulations to match tasks which take into account the QoS requested by the tasks, and at the same time, to minimize the tasks makespan as much as possible. Also, an optimum method based on the performance metric has been designed to compare the performance of the heuristics developed. Our proposed solution has at least a 45% improvement over the general method which uses a first come, first served (FCFS) strategy. The implementation and simulation results indicate that our approaches are promising in that the resource manager finds the optimal set of resources to guarantee efficient job execution, the fault manager guarantees that the submitted jobs are completed, and job execution is improved owing to job duplication even if some failures occur. c © 2007 Elsevier B.V. All rights reserved.	active database;confluence;control table;dup (system call);emoticon;event condition action;experiment;fault tolerance;grid computing;heuristic (computer science);idle;job scheduler;job stream;logic programming;makespan;max;parallel computing;performance evaluation;quality of service;requirement;resource management (computing);scalability;scheduling (computing);selection algorithm;simulation;systems architecture;time complexity	Leili Mohammad Khanli;Morteza Analoui	2008	Future Generation Comp. Syst.	10.1016/j.future.2007.05.002	fault tolerance;parallel computing;real-time computing;computer science;artificial intelligence;resource management;operating system;database;distributed computing;computer security;systems architecture	HPC	-17.71721363079152	61.387792286057135	105165
61ad551a2fc8e7d88f23b5818ad880be36c1a08f	fault-tolerant quorum consensus scheme for replication control in mobile distributed database systems	distributed data;performance evaluation;fault tolerant;database management;mobile database;distributed database system;replicated data;minority group;mobile user	Recent advances in computing and networking technologies have made an extensive use of inexpensive portable computers and enabled sharing of on-line information via wireless communication channels. This new computing paradigm, called mobile computing, allows users to perform online transaction processing independent of their physical locations [Alonso and Korth, 1993; Imielinski and Badrinath, 1992; Pitoura and Bhargava, 1994]. Generally, such a mobile computing architecture includes two distinct sets of entities: mobile hosts (MHs) in the wireless network and fixed hosts (FHs) in the wired network(Figure 1). The MHs can dynamically move within a radio coverage area called a cell or between two cells while retaining their network connection. The average cell size is about two miles in diameter, and an MH is crossing through these cells tens of times a day. The FHs are steadily connected to the wired network and some of them, called mobile support stations Fault-Tolerant Quorum Consensus Scheme for Replication Control in Mobile Distributed Database Systems: FTQC	academy;computer science;consensus (computer science);distributed computing;distributed database;dual independent map encoding;fault tolerance;mobile computing;multi-user;network partition;partition type;performance evaluation;prototype;relational database management system;serializability	Siwoo Byun;Songchun Moon	1998	J. Database Manag.	10.4018/jdm.1998070102	fault tolerance;real-time computing;mobile database;computer science;database;distributed computing;distributed database	DB	-15.9908370200512	68.7461133610214	105239
eecf0ed42b530dec978eea48e8afd6a0b0cf527f	sla-based scheduling of applications for geographically secluded clouds	time factors virtual machining algorithm design and analysis heuristic algorithms scheduling algorithms resource management delays;qos cloud computing scheduling algorithms;virtual machining;resource management;qos sla based application scheduling geographically secluded clouds resource control geographically distributed clouds resource allocation techniques optimized scheduling algorithms task prioritizaton resource utilization job scheduling algorithms distributed datacenter network dc network user workload assignment virtual machines vm response time reduction end user location quality of service improvement;time factors;virtual machines cloud computing computer centres contracts quality of service resource allocation scheduling;scheduling algorithms;heuristic algorithms;algorithm design and analysis;delays	With recent advances in technology, resource control is a significant challenge for geographically distributed clouds. Users geographically close to the server get better services due to low latency. A few existing scheduling algorithms can provide better strategies through efficient job scheduling and resource allocation techniques. However, these algorithms are not efficient enough for distanced clouds. In order to gain maximum profits with optimized scheduling algorithms, it is necessary to utilize resources efficiently and also prioritize the tasks that are near to the servers. This paper proposes job scheduling algorithms in a distributed datacenter (DC) network, where the algorithms assign user's workloads to Virtual Machines (VMs) hosted to DC close to the users to reduce response time. The aspect of the proposed algorithms is the use of delay to evaluate if a VM provide a low or a high delay, it is required that the location of the end user generating the tasks should be known. Our results show that prioritizing tasks for the nearest servers not only improve the quality of service (QoS) but also demonstrates better utilization of the resources.	algorithm;best practice;cloud computing;data center;distributed computing;distributed shared memory;experiment;job scheduler;quality of service;response time (technology);round-robin scheduling;scheduling (computing);server (computing);service-level agreement;service-oriented architecture;tag cloud	Md Israfil Biswas;Gerard P. Parr;Sally I. McClean;Philip J. Morrow;Bryan W. Scotney	2014	2014 International Conference and Workshop on the Network of the Future (NOF)	10.1109/NOF.2014.7119800	fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;resource allocation;computer science;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing;lottery scheduling;round-robin scheduling;computer network	HPC	-18.766947508063634	62.61722761080274	105247
1d74f5c8ff30de49f5de0c253e04e1351f269ef3	resource co-allocation using advance reservations with flexible time-windows	blocking probability;time window;advance reservations;co allocation;flexible time windows;advance reservation	Co-allocations require the availability of more than one resource for utilization in a time interval. We show that co-allocations increase the blocking probability and analyze the use of flexible windows to lower blocking probability in spite of co-allocations.	blocking (computing);erlang (unit);microsoft windows	Neena R. Kaushik;Silvia M. Figueira;Stephen A. Chiappari	2007	SIGMETRICS Performance Evaluation Review	10.1145/1328690.1328710	real-time computing;operations research	HPC	-10.6148495016299	63.65842366254248	105387
b9e3e9108bc237f207e459cae6e3bca17af75fea	transparent caching for nomadic ws clients	cache storage;mobile device;wireless network;proxy caching;client server systems;meta data internet mobile computing client server systems cache storage access protocols;web service;network load reduction transparent caching nomadic ws clients mobile devices pervasive computing web service clients wireless network constrained bandwidth soap request response pair caching connectivity loss embedded soap caching crisp soap traffic;web services simple object access protocol bandwidth wireless networks telecommunication traffic middleware fluctuations computer science mobile computing computer architecture;internet;access protocols;meta data;mobile computing	"""As mobile devices become more pervasive they will emerge as a standard platform for hosting Web service clients. Unlike their """"static"""" counterparts, mobile devices are typically connected via a wireless network forcing them to deal with constrained bandwidth and the sudden loss of connectivity. This paper focuses on the use of caching SOAP request-response pairs in order to compensate for fluctuating bandwidth and loss of connectivity. We introduce the concept of embedded SOAP caching, highlighting the need for meta-data as a means to support it. A novel SOAP cache (CRISP) that can be embedded into the application or used as an independent proxy-cache is presented and evaluated under various loads and settings. The evaluation of CRISP shows that caching of SOAP traffic is not only an effective means to compensate for loss of connectivity but also enables reducing network loads which is particularly interesting when dealing with bandwidth constraint wireless connections."""	cache (computing);cross industry standard process for data mining;design structure matrix;embedded system;mathematical optimization;mobile device;pervasive informatics;proxy server;request–response;soap;web cache;web service	Kamal Elbashir;Ralph Deters	2005	IEEE International Conference on Web Services (ICWS'05)	10.1109/ICWS.2005.123	web service;the internet;computer science;operating system;wireless network;mobile device;distributed computing;mobile computing;metadata;law;world wide web;computer network	Mobile	-17.710276470964622	74.42330368542055	105660
08c5d301faea5e29166547e97887ec06cfd94923	the master-slave paradigm with heterogeneous processors	optimal solution;optimisation;approximate algorithm;asymptotic optimality;multiprocessing systems computational complexity optimisation processor scheduling;processor scheduling;complexity;computational complexity;polynomial algorithm;matching;master slave context polynomials approximation algorithms centralized control process control communication system control hardware random number generation inductors;heterogeneous processors;master slave tasking paradigm heterogeneous processors polynomial algorithm task execution slave processors np complete guaranteed approximation algorithm asymptotically optimal algorithms;multiprocessing systems;communication;master slave tasking	In this paper, we revisit the master-slave tasking paradigm in the context of heterogeneous processors. We assume that communications take place in exclusive mode. We present a polynomial algorithm that gives the optimal solution when a single communication is needed before the execution of the tasks on the slave processors. When communications are required both before and after the task processing, we show that the problem is at least as difficult as a problem whose complexity is open. In this case, we present a guaranteed approximation algorithm. Finally, we present asymptotically optimal algorithms when communications are required before the processing of each task, or both before and after the processing of each task.	approximation algorithm;asymptotically optimal algorithm;central processing unit;heterogeneous computing;master/slave (technology);polynomial;programming paradigm	Olivier Beaumont;Arnaud Legrand;Yves Robert	2001	Proceedings 42nd IEEE Symposium on Foundations of Computer Science	10.1109/TPDS.2003.1233712	matching;parallel computing;complexity;real-time computing;computer science;distributed computing;computational complexity theory;algorithm	Theory	-12.496367329422181	60.61555786730161	105765
d12e6c8181b68e5583df6a3951950ea03ed72df1	towards conscientious peers: combining agents and peers for efficient and scalable video segment retrieval for vod services	multiagent system;video on demand;peer to peer	In the last years, Video-on-Demand (VoD) systems, such as Youtube, have become a very popular way to watch videos. Researches in Multiagent Systems (MAS) and Peer-to-Peer (P2P) for VoD have focused on using agents to assist peers to share video segments efficiently, by replicating them or creating the best path between peers to transfer such segments. A key challenge faced by these systems is to efficiently search and to retrieve which peers own certain segments in order to provide the streaming service. In this paper we propose an innovative architecture that combines MAS and P2P network for multimedia information retrieval in the VoD environment. This architecture, composed of a P2P and a MAS layer, supports streaming and random seeking while providing scalability and efficiency. The P2P layer is responsible for discovering the peers that own the video segments and share these segments among them. Nevertheless, if such search is time consuming, it is forwarded to the MAS layer. The MAS layer is responsible for monitoring groups of peers as well as for discovering agents that manage a group of peers sharing certain video segments that could not be found efficiently by peers. This is made for improving the sharing performance of its monitored peers. Experimental results, using several metrics, showed the viability of adopting our approach if compared with the most used approaches.	scalability	Vladimir Rocha;Anarosa A. F. Brandão	2015	Eng. Appl. of AI	10.1016/j.engappai.2015.07.001	computer science;multimedia;internet privacy;world wide web	AI	-16.648589585722828	74.37474776904757	105799
4587b9e63d74d2fa0eb0591a99ad50a9db8695ca	exploiting location information for infostation-based hoarding	wireless network;mobile computer;information access;mobile environment;mobile information system	With the increasing popularity of mobile computing devices, the need to access information in mobile environments has grown rapidly. Since the information has to be accessed over wireless networks, mobile information systems often have to deal with problems like low bandwidth, high delay, and frequent disconnections. Information hoarding is a method that tries to overcome these problems by transferring information, which the user will probably need, in advance. The hoarding mechanism that we describe in this paper exploits the location dependence of the information access, which is often found in mobile information systems. Our simulation results show that it is beneficial to do so and that we achieve higher hit ratios than with a caching mechanism.	cache (computing);german research centre for artificial intelligence;information access;information system;mobile computing;nexus 10;simulation;situated	Uwe Kubach;Kurt Rothermel	2001		10.1145/381677.381680	mobile search;mobile database;computer science;operating system;wireless network;mobile technology;distributed computing;internet privacy;mobile computing;world wide web	Mobile	-15.577571375692369	68.5852633395022	106022
c78350db715125355b91d6aff9b851e7a98114b7	energy efficient scheduling and management for large-scale services computing systems	energy efficiency;services computing;processor scheduling;servers quality of service service computing energy consumption optimization processor scheduling computational modeling;service management;request scheduling;qos;servers;computational modeling;energy consumption;optimization;quality of service;qos services computing request scheduling service management energy efficiency;service computing	With the increasing popularity of services published online, energy consumption of services computing systems is growing dramatically. Besides Quality of Service (QoS), energy efficiency has become an important issue and drawn significant attention. However, energy efficient request scheduling and service management for large-scale services computing systems face challenges because of the high dynamics and unpredictability of request arrivals. In this paper, we jointly consider the conflicting metrics of performance, queue congestion and energy consumption. We propose a distributed online scheduling and management algorithm which does not require any priori statistical knowledge of request arrivals. Mathematical analysis is conducted which demonstrates that our algorithm can achieve arbitrary tradeoff between performance and energy efficiency. Numerical and real trace data based experiments are carried out to validate the effectiveness of our algorithm in optimizing energy efficiency while stabilizing the system.	algorithm;dynamic dispatch;dynamic voltage scaling;experiment;lpc;linear congruential generator;lyapunov fractal;lyapunov optimization;mathematical optimization;network congestion;numerical analysis;numerical integration;online algorithm;optimization problem;quality of service;randomized algorithm;scheduling (computing);server (computing);services computing;simulation	Ying Chen;Chuang Lin;Jiwei Huang;Xudong Xiang;Xuemin Shen	2017	IEEE Transactions on Services Computing	10.1109/TSC.2015.2444845	fair-share scheduling;real-time computing;quality of service;dynamic priority scheduling;computer science;operating system;distributed computing;services computing;computer network	HPC	-18.82551492217893	64.93966683768863	106053
ca54b45512eb9aaf279c594e1c5a542b2b0d85cb	adaptive video-on-demand broadcasting in ubiquitous computing environment	available bandwidth;scheduling;waiting time;video on demand;video on demand vod;ubiquitous computing;broadcasting;ubiquitous computing environment	Video-on-demand (VOD) is a service that allows users to view any video program from a server at the time of their choice, such kind of services are expected to be popular in future ubiquitous computing environment. Lots of broadcasting protocols for VOD services have been proposed, but they usually focus only on the tradeoff between bandwidth and delay, thus they are usually not efficient for the local storage. Since the ubiquitous network is heterogeneous and users will have different resource and communication capability, we need to address the storage issue in VOD systems. In this paper, we present several new effective broadcasting schemes, which can intelligently adjust the solution according to available bandwidth and local storage to achieve an ideal waiting time.	artificial intelligence;bandwidth (signal processing);bonaventura di bello;decibel;differentiated services;sdb (debugger);server (computing);system host board;thread-local storage;ubiquitous computing;versant object database	Chao Peng;Yasuo Tan;Naixue N. Xiong;Laurence Tianruo Yang;Jong Hyuk Park;Soon-Seok Kim	2009	Personal and Ubiquitous Computing	10.1007/s00779-009-0227-6	real-time computing;human–computer interaction;computer science;operating system;scheduling;world wide web;ubiquitous computing;broadcasting;computer network	HPC	-16.643344814310183	72.73186669509184	106237
eff6644551ef9bd643660826868808d007c3d1f7	interactive streaming of structured data	structured data streaming;fixed size arrays;online video editing;video signal processing;real time;data type;video signal processing mobile computing;linked lists;indexes;search trees;generic mechanism;resource adaptive playback structured data streaming chunkstream system generic mechanism fixed size arrays online video editing linked lists search trees;mobile computing;streaming media video sharing protocols data structures mobile computing internet pervasive computing smart phones clouds mashups;data structure;high speed;resource adaptive playback;chunkstream system;context;structured data	We present ChunkStream, a system for efficient streaming and interactive editing of online video. Rather than using a specialized protocol and stream format, ChunkStream makes use of a generic mechanism employing chunks. Chunks are fixed-size arrays that contain a mixture of scalar data and references to other chunks. Chunks allow programmers to expose large, but fine-grained, data structures over the network. ChunkStream represents video clips using simple data types like linked lists and search trees, allowing a client to retrieve and work with only the portions of the clips that it needs. ChunkStream supports resource-adaptive playback and “live” streaming of real-time video as well as fast, frame-accurate seeking; bandwidth-efficient high-speed playback; and compilation of editing decisions from a set of clips. Benchmarks indicate that ChunkStream uses less bandwidth than HTTP Live Streaming while providing better support for editing primitives.	compiler;data structure;http live streaming;linked list;programmer;real-time locating system;streaming media;video clip	Justin Mazzola Paluska;Hubert Pham	2010	2010 IEEE International Conference on Pervasive Computing and Communications (PerCom)	10.1109/PERCOM.2010.5466996	database index;embedded system;linked list;real-time computing;data structure;data type;data model;computer science;operating system;multimedia;mobile computing;world wide web	Visualization	-16.79886030215524	72.55555513260428	106247
231c6b13db4dec1dc9c35f33bc27b5fec9fe07e4	a middle ground between cams and dags for high-speed packet classification	directed graphs;directed acyclic graph;vpn;cam;packet classification;dag;boolean functions;high performance computing;bdd;binary decision diagrams cam content addressable memory dag directed acyclic graph high speed packet classification routers qos access control vpn classification rule set condition action pair graph like data structure rule evaluation units np hard problem bdd;telecommunication computing;intrusion detection;classification rule set;packet switching;telecommunication computing binary decision diagrams content addressable storage directed graphs packet switching telecommunication network routing knowledge based systems parallel architectures computational complexity;qos;np hard problem;cams boolean functions binary decision diagrams hardware data structures classification tree analysis high performance computing access control virtual private networks intrusion detection;binary decision diagrams;parallel architectures;telecommunication network routing;rule evaluation units;computational complexity;cams;data structures;high speed packet classification;content addressable memory;access control;classification tree analysis;content addressable storage;high performance;data structure;high speed;routers;knowledge based systems;condition action pair;graph like data structure;hardware;virtual private networks	Packet classification is a computationally intensive task that routers need to perform at high speed to implement features such as QoS, access control, and VPNs. A classification rule-set consists of a prioritized set of rules, wher e each rule is a condition-action pair. Current approaches to classification can be categorized as belonging in one of two extreme categories: (1.) an incoming packet is fed to custom hardware which concurrently checks all rules for applicability and returns the action of the highest priorit y applicable rule; (2.) a graph-like data-structure is store d in memory and traversed based on the bits in the incoming packet’s header. Both these approaches suffer from severe limitations: the former uses a large amount of hardware; the latter requires huge amounts of memory to achieve high performance. Our thesis is that the right approach to packet classification lies in the middle. Specifically, we describe an architecture with a small number of hardware-based rule evaluation units operating in parallel. We show that dividing the rule-set across these units so as to make them fit in the hardware available is NP-hard; our primary contribution is a heuristic for doing this division.	access control;categorization;data structure;heuristic;network packet;quality of service;router (computing);rule 90;virtual private network	Amit Prakash;Adnan Aziz	2002		10.1109/CONECT.2002.1039262	real-time computing;data structure;computer science;theoretical computer science;operating system;distributed computing;directed acyclic graph;computer network	Arch	-6.7857599537555835	67.41333160273065	106425
1d46a2a07474deadea194f50979acffa10d98127	evaluating the impact of different document types on the performance of web cache replacement schemes	workload;information resources;web documents;page description languages;html document types web cache replacement schemes performance study dynamic aging greedy dual size trace driven simulation;spine;multimedia;performance evaluation;red www;cost function;reseau web;type document;image multiple;cache memory;imagen multiple;aging;multiple image;antememoria;web cache;html;antememoire;performance study;internet;streaming media;algorithm theory;web cache replacement schemes;performance analysis;charge travail;dynamic aging;greedy dual size;performance evaluation information resources internet discrete event simulation algorithm theory;world wide web;least frequently used;document types;computer science;digital audio players;carga trabajo;web caching;trace driven simulation;langage html;least recently used;cost model;html language;lenguaje html;streaming media html aging cost function computer science page description languages digital audio players spine performance analysis;discrete event simulation	In this paper, we present a comprehensive performance study of Least Recently Used and Least Frequently Used with Dynamic Aging as traditional replacement schemes as well as for the newly proposed schemes Greedy Dual Size and Greedy Dual *. The goal of our study constitutes the understanding how these replacement schemes deal with different web document types. Using trace-driven simulation, we present curves plotting the hit rate and byte hit rate broken down for image, HTML, multi media, and application documents. The presented results show for the first workload that under the packet cost model Greedy Dual * outperforms the other schemes both in terms of hit rate and byte hit rate for image, HTML, and multi media documents. However, the advantages of Greedy Dual * diminish when the workload contains more distinct multi media documents and a larger number of requests to multi media documents.	analysis of algorithms;byte;greedy algorithm;html;least frequently used;network packet;simulation;web cache;web page	Christoph Lindemann;Oliver P. Waldhorst	2002		10.1109/DSN.2002.1029017	html;computer science;operating system;database;distributed computing;multimedia;programming language;world wide web;computer security;computer network	Metrics	-17.364344809996368	71.58628007901109	106483
9ede743fe568590db4a98e6b6689d46dd76998ae	adaptive scheduling of task graphs with dynamic resilience	computers;multiprocessor scheduling;dynamic algorithm;processor scheduling;task duplication dynamic algorithm dynamic resilience multiprocessor scheduling task graphs;heuristic algorithms;clustering algorithms;task graphs;dynamic resilience;program processors;task duplication;program processors heuristic algorithms processor scheduling dynamic scheduling computers clustering algorithms;dynamic scheduling	This paper studies a scheduling problem of task graphs on a nondedicated networked computing platform. The networked platform is characterized by a set of fully connected processors such as a multiprocessor system that can be shared by multiple tasks. Therefore, the computation and communication capacities of the computing platform dynamically fluctuate. To deal with this fluctuations for high performance task graph computing, we propose an online dynamic resilience scheduling algorithm called Adaptive Scheduling Algorithm (ASA) that bears certain distinct features compared to existing algorithms. First, the proposed algorithm deliberately assigns tasks to idle processors in multiple rounds to prevent any unfavorable decisions and also to avoid inefficient assignments of certain key tasks to slow processors. Second, the algorithm adopts task duplication as an attempt to minimize serious increase of schedule length due to unexpected processor slowdown. Finally, a look-ahead message transmission policy is applied to save communication time and further improve the overall performance. Performance evaluation results are presented to demonstrate the effectiveness and competitiveness of our approaches when compared with the existing algorithms.	algorithm;central processing unit;competitive analysis (online algorithm);computation;heuristic (computer science);multiprocessing;performance evaluation;profiling (computer programming);schedule (project management);scheduling (computing);simulation	Menglan Hu;Jun Luo;Yang Wang;Bharadwaj Veeravalli	2017	IEEE Transactions on Computers	10.1109/TC.2016.2574349	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic problem;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;two-level scheduling;distributed computing;least slack time scheduling;cluster analysis;lottery scheduling;round-robin scheduling;multiprocessor scheduling	HPC	-14.678025717738818	60.792039038161185	106744
aec004d8a60121d90a7aaa0783cf12c65a7227bf	scheduling bounded predictable (bp) and soft aperiodic tasks		The aim of this paper is to provide scheduling algorithms for the joint scheduling of BP and soft aperiodic tasks. In this paper, we present four scheduling algorithms for servicing soft aperiodic tasks in real-time systems, where a set of BP tasks is scheduled using the BP scheduling algorithm. A goal of these scheduling algorithms is to guarantee the hard deadlines of BP tasks while providing good response times for soft aperiodic tasks. The result of the scheduling algorithms will allow the real-time system designers to reason with confidence about timing constraints of highly dynamic behavior environments.	algorithm;real-time clock;real-time computing;real-time operating system;real-time transcription;scheduling (computing)	Ilhyun Lee;Haesun K. Lee;Narayan C. Debnath	2003			parallel computing;computer science;distributed computing;real-time computing;scheduling (computing);aperiodic graph;bounded function	Embedded	-9.669925460751989	60.75632858657457	106850
c67b4ea13ad97630c1ac3db6e0cf17f4d7145680	adaptive workflow scheduling for diverse objectives in cloud environments		Cloud computing environments facilitate applications by providing virtualised resources through the network and serve the clients by the pay-as-you-go mechanism. It is based on the rapid development of the network. Normally, economic cost is the most important factor of providing cloud services. However, under some special conditions, the objectives may change. In this scenario, it is impractical to reset the scheduling mechanism only for an occasional incident. So an adaptive scheduling mechanism is needed to address the issues of scheduling under different conditions. To the best of our knowledge, no works have well solved this problem. In this paper, we convert the problem to a multi-objective scheduling problem with varying objective weights and propose a two-phase algorithm, which is called adaptive priority-based workflow scheduling (DRAWS) algorithm. The algorithm will self regulate the priorities of tasks to adapt to different objectives. In the experimental part, simulation environments are set up and three classic workflows are used to evaluate the performance. Four comparing algorithms of resource sensitive scheduling algorithm, Best Fit-millions of instructions per second, Best Fit-random-access memory and Best Fit-Bandwidth are used to evaluate the performance of DRAWS. It is demonstrated that each phase of our algorithm would optimise the scheduling. Furthermore, we obtain the conclusion that DRAWS algorithm shows superior than the comparing algorithms. Copyright © 2015 John Wiley u0026 Sons, Ltd.	scheduling (computing)	Haoran Ji;Weidong Bao;Xiaomin Zhu	2017	Trans. Emerging Telecommunications Technologies	10.1002/ett.2941	real-time computing;computer science;database;distributed computing	HCI	-18.40877609546511	62.81652526019149	107060
7a74724a34e5f77712975e0c104260117cfbf1a3	task scheduling on the cloud with hard constraints	throughput mathematical model time factors performance gain scheduling heuristic algorithms cloud computing;time factors;scheduling;heuristic algorithms;performance gain;mathematical model;scheduling cloud computing grid computing pattern clustering;cloud resource type task scheduling hard constraint scheduling bag of tasks application bot application grid environment cluster environment budgetary constraint user defined budget heuristic algorithm;cloud computing;throughput	Scheduling Bag-of-Tasks (BoT) applications on the cloud can be more challenging than grid and cluster environments. This is because a user may have a budgetary constraint or a deadline for executing the BoT application in order to keep the overall execution costs low. The research in this paper is motivated to investigate task scheduling on the cloud, given two hard constraints based on a user-defined budget and a deadline. A heuristic algorithm is proposed and implemented to satisfy the hard constraints for executing the BoT application in a cost effective manner. The proposed algorithm is evaluated using four scenarios that are based on the trade-off between performance and the cost of using different cloud resource types. The experimental evaluation confirms the feasibility of the algorithm in satisfying the constraints. The key observation is that multiple resource types can be a better alternative to using a single type of resource.	algorithm;constraint (mathematics);experiment;heuristic (computer science);provisioning;query plan;scheduling (computing);virtual machine	Long Thai;Blesson Varghese;Adam Barker	2015	2015 IEEE World Congress on Services	10.1109/SERVICES.2015.22	fair-share scheduling;throughput;real-time computing;earliest deadline first scheduling;simulation;cloud computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;mathematical model;distributed computing;scheduling	Embedded	-18.871430796903795	62.75329353709317	107353
3e6aaddf6e7bca95209df4114b729fdb8af030fb	scheduling and caching strategies for broadcasting correlated data	caching strategy;scheduling strategy;simulation study;information system;data broadcast;correlated data;data correlation	Recently, there has been increasing interest in information systems that deliver data using broadcast in both wired and wireless environments. The strategy in which a server repeatedly broadcasts data to clients can result in a larger throughput, and various methods have been studied to reduce the average response time to data requests in such systems. In this paper, we propose a strategy for scheduling the broadcast program which takes into account the correlation among data. This strategy puts data items with strong correlation side by side in the broadcast program in order to reduce the average response time. We also propose a caching strategy which extends a conventional caching strategy so that it can take advantage of correlation among broadcast data for greater efficiency. Finally, we use simulation studies to evaluate the performance of our proposed strategies. K e y w o r d s : data broadcast, data correlation, scheduling strategy, caching strategy	broadcasting (networking);cache (computing);information system;response time (technology);scheduling (computing);server (computing);simulation;throughput	Etsuko Yajima;Takahiro Hara;Masahiko Tsukamoto;Shojiro Nishio	2001		10.1145/372202.372444	fair-share scheduling;real-time computing;database;distributed computing;information system	Mobile	-14.91301936511556	68.98413493506588	107360
a6dcb99b9aa576d86ce9b8ae85d9bc50b535bee6	anomalies in scheduling control applications and design complexity		Today, many control applications in cyber-physical systems are implemented on shared platforms. Such resource sharing may lead to complex timing behaviors and, in turn, instability of control applications. This paper highlights a number of anomalies demonstrating complex timing behaviors caused as a result of resource sharing. Such anomalous scenarios, then, lead to a dramatic increase in design complexity, if not properly considered. Here, we demonstrate that these anomalies are, in fact, very improbable. Therefore, design methodologies for these systems should mainly be devised and tuned towards the majority of cases, as opposed to anomalies, but should also be able to handle such anomalous scenarios.	anton (computer);call of duty: black ops;control theory;cyber-physical system;instability;scheduling (computing);software design	Amir Aminifar;Enrico Bini	2017	Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017		shared resource;algorithm design;electronic engineering;von neumann stability analysis;latency;real-time computing;simulation;jitter;design methods;telecommunications;computer science;operating system;distributed computing	EDA	-7.676693586706178	62.21228066255937	107780
2f6b142c095dac8eb631a2badc24cc4d5adaf5b3	energy and performance-aware task scheduling in a mobile cloud computing environment	mobile cloud computing mcc;task scheduling mobile cloud computing mcc energy minimization hard deadline constraint;hard deadline constraint;mobile handsets wireless communication energy consumption cloud computing processor scheduling time factors scheduling;energy minimization;task scheduling;scheduling cloud computing mobile computing performance evaluation power aware computing;linear time rescheduling algorithm energy reduction performance enhancement task scheduling problem mobile cloud computing environment mcc minimal delay scheduling solution	Mobile cloud computing (MCC) offers significant opportunities in performance enhancement and energy saving in mobile, battery-powered devices. An application running on a mobile device can be represented by a task graph. This work investigates the problem of scheduling tasks (which belong to the same or possibly different applications) in an MCC environment. More precisely, the scheduling problem involves the following steps: (i) determining the tasks to be offloaded on to the cloud, (ii) mapping the remaining tasks onto (potentially heterogeneous) cores in the mobile device, and (iii) scheduling all tasks on the cores (for in-house tasks) or the wireless communication channels (for offloaded tasks) such that the task-precedence requirements and the application completion time constraint are satisfied while the total energy dissipation in the mobile device is minimized. A novel algorithm is presented, which starts from a minimal-delay scheduling solution and subsequently performs energy reduction by migrating tasks among the local cores or between the local cores and the cloud. A linear-time rescheduling algorithm is proposed for the task migration. Simulation results show that the proposed algorithm can achieve a maximum energy reduction by a factor of 3.1 compared with the baseline algorithm.	algorithm;baseline (configuration management);computation;ibm notes;information science;mobile cloud computing;mobile device;reduction (complexity);requirement;schedule (project management);scheduling (computing);simulation;time complexity	Xue Lin;Yanzhi Wang;Qing Xie;Massoud Pedram	2014	2014 IEEE 7th International Conference on Cloud Computing	10.1109/CLOUD.2014.35	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;distributed computing;round-robin scheduling;energy minimization	Embedded	-18.429440698575295	62.681333939131015	108021
b195bedfb68e2b46df1d785c738636931abce379	a hybrid pagoda broadcasting protocol: fixed-delay pagoda broadcasting protocol with partial preloading	partial preloading;broadcasting multimedia communication bandwidth access protocols broadcast technology us department of transportation buffer storage harmonic analysis computer science scalability;set top box hybrid pagoda broadcasting protocol fixed delay pagoda broadcasting protocol partial preloading video on demand;protocols;protocols video on demand broadcasting;buffer storage;waiting time;video on demand;multimedia communication;fixed delay pagoda broadcasting protocol;broadcast technology;access protocols;us department of transportation;bandwidth;hybrid pagoda broadcasting protocol;scalability;computer science;broadcasting;set top box;harmonic analysis	Broadcasting protocols offer an efficient and scalable method to provide video-on-demand. We present a new broadcasting protocol that assumes that some portions of the video are already preloaded in the set-top-box (STB), and at the same time, requires the user to wait for a fixed-delay before viewing. As a result, there is a trade-off between the size of the consumed local storage, user waiting time, and bandwidth consumption. This trade-off makes this protocol very flexible, in that we can control the consumption of one resource by adjusting the use of the other two. Also, the performance of the proposed protocol is not very far from the theoretical minimum. We also present a heuristic version of the protocol, in which the performance is improved a little.	communications protocol;heuristic;scalability;thread-local storage	Hong Kee Sul;Hyunchul Kim;Kilnam Chon	2003		10.1109/ICME.2003.1221039	broadcasting;communications protocol;universal composability;real-time computing;scalability;stateless protocol;resource reservation protocol;computer science;harmonic analysis;distributed computing;broadcasting;bandwidth;statistics;computer network	Networks	-15.955763731679395	73.15772992376657	108128
c04d351ddc36a3fbd5b83a44380f0380af1fca8f	novel differential schema for high performance big data telehealth systems using pre-cache	big data differential technology pre caching network traffic;differential technology;sensors servers mobile communication embedded systems mobile computing accuracy real time systems;sensors;embedded systems;accuracy;pre caching;servers;big data;network traffic;mobile communication;mobile computing;real time systems	With the rapid development of the mobile computing and wireless network technology, the mobile telehealth system has been used more and more widely. An important issue of the telehealth system is that too many network traffics are generated while transferring data from the sensors to servers. To solve this problem, we propose a differential algorithm for reducing the network traffics of the telehealth system. The accuracy of sensors is often too high under some conditions and normally the captured data by sensors are little changed. Our algorithm provides an optimal tradeoff solution addressing both network traffics and data accuracy. The experimental results represent that the proposed approach can reduce network traffic effectively based on the acceptable data accuracy with choosing appropriate parameter.	algorithm;big data;deterministic finite automaton;mobile computing;network packet;programming paradigm;sensor;television	Hui Zhao;Keke Gai;Jie Li;Xin He	2015	2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems	10.1109/HPCC-CSS-ICESS.2015.156	embedded system;real-time computing;big data;mobile telephony;computer science;sensor;operating system;distributed computing;accuracy and precision;mobile computing;computer security;server;computer network	Embedded	-7.816819078962406	65.61119838173552	108368
396c28e14c8197f2302ff50ee25385efe1dd9bd1	online packet-routing in grids with bounded buffers	packet routing;bounded buffers;grid networks;online algorithms;admission control	We present deterministic and randomized algorithms for the problem of online packet routing in grids in the competitive network throughput model (Aiello et al. in SODA, pp 771–780 2003). In this model the network has nodes with bounded buffers and bounded link capacities. The goal in this model is to maximize the throughput, i.e., the number of delivered packets. Our deterministic algorithm is the first online algorithm with an $$O\left( \log ^{O(1)}(n)\right) $$ O log O ( 1 ) ( n ) competitive ratio for uni-directional grids (where n denotes the size of the network). The deterministic online algorithm is centralized and handles packets with deadlines. This algorithm is applicable to various ranges of values of buffer sizes and communication link capacities. In particular, it holds for buffer size and communication link capacity in the range $$[3 \ldots \log n]$$ [ 3 … log n ] . Our randomized algorithm achieves an expected competitive ratio of $$O(\log n)$$ O ( log n ) for the uni-directional line. This algorithm is applicable to a wide range of buffer sizes and communication link capacities. In particular, it holds also for unit size buffers and unit capacity links. This algorithm improves the best previous $$O(\log ^2 n)$$ O ( log 2 n ) -competitive ratio of Azar and Zachut (ESA, pp 484–495, 2005).	centralized computing;competitive analysis (online algorithm);deterministic algorithm;esa;network packet;online algorithm;randomized algorithm;router (computing);routing;throughput	Guy Even;Moti Medina	2016	Algorithmica	10.1007/s00453-016-0177-0	online algorithm;mathematical optimization;computer science;theoretical computer science;distributed computing	Theory	-4.830288058206479	71.83896309489079	108743
cd6490994239cfd9f6b1e2f62f801981adbd005e	batching and dynamic allocation techniques for increasing the stream capacity of an on-demand media server	multiprocessor interconnection networks;server model dynamic allocation techniques batching techniques stream capacity on demand media server interactive distributed multimedia system system utilization load balancing interconnection network scheduler retrieval capacity storage system server capacity media request assignment scheduling nodes;system utilization;storage system;batch processing computers multimedia computing multimedia communication interactive systems resource allocation multiprocessor interconnection networks network servers;resource allocation;information retrieval;distributed multimedia system;stream capacity;server model;media request assignment;multimedia systems;interconnection network;server capacity;scheduling nodes;multimedia computing;computer aided software engineering;network servers;dynamic allocation techniques;streaming media;scheduling;multimedia communication;scheduler;batch processing computers;load balancing;model development;bandwidth;space technology;interactive distributed multimedia system;on demand media server;streaming media information retrieval network servers bandwidth multimedia systems costs scheduling space technology computer aided software engineering multiprocessor interconnection networks;batching techniques;interactive systems;retrieval capacity	A server for an interactive distributed multimedia system may require thousands of gigabytes of storage space and high I/O bandwidth. In order to maximize system utilization, and thus minimize cost, the load must be balanced among the server's disks, interconnection network and scheduler. Many algorithms for maximizing retrieval capacity from the storage system have been proposed. The paper presents techniques for improving server capacity by assigning media requests to the nodes of a server so as to balance the load on the interconnection network and the scheduling nodes. Five policies for request assignment are developed. The performance of these policies on an implementation of a server model developed earlier is presented.		Chutimet Srinilta;Divyesh Jadav;Alok N. Choudhary	1997		10.1109/RIDE.1997.583717	real-time computing;computer science;distributed computing;client–server model;computer network;server farm	DB	-15.663662167251731	71.1532750211498	108888
26feb7ab3a588fe3f9788cdbfd36a80c223347d8	high performance ip routing table lookup using cpu caching	internet protocol;cache storage;cpu memory hierarchy;routing protocols;ip addresses;parallel algorithms table lookup telecommunication network routing transport protocols cache storage;virtual addresses;packet trace;ip packets;network address;pentium ii machine;16 kbyte;alpha processor;wire;wire speed ip routers;1 kbyte;transport protocols;internet;telecommunication network routing;500 mhz high performance ip routing table lookup ip addresses wire speed ip routers internet protocol ip packets network address routing table lookup algorithm cluster based parallel ip router cpu caching hardware cluster based parallel ip router project virtual addresses simulation model performance effects cpu memory hierarchy packet trace alpha processor software based routing table lookup architectural parameters storage costs pentium ii machine linux 16 kbyte 1 kbyte;performance effects;cluster based parallel ip router project;clustering algorithms;ip routing;software based routing table lookup;linux;table lookup hardware clustering algorithms computer science routing protocols costs linux wire internet algorithm design and analysis;computer science;memory hierarchy;architectural parameters;routing table lookup algorithm;500 mhz;high performance ip routing table lookup;table lookup;high performance;simulation model;storage costs;algorithm design and analysis;cpu caching hardware;cluster based parallel ip router;hardware;parallel algorithms	Wire-speed IP (Internet Protocol) routers require very fast routing table lookup for incoming IP packets. The routing table lookup operation is time consuming because the part of an IP address used in the lookup, i.e., the network address portion, is variable in length. This paper describes the routing table lookup algorithm used in a cluster-based parallel IP router project called Suez. The innovative aspect of this algorithm is its ability to use CPU caching hardware to perform routing table caching and lookup directly. By running a detailed simulationmodel that incorporates the performance e ects of the CPU memory hierarchy against a packet trace collected from a major network router, we show that the overall performance of the proposed algorithm can reach 87.87 million lookups per second for a 500-MHz Alpha processor with a 16-KByte L1 cache and a 1-MByte L2 cache. This result is one to two orders of magnitude faster than previously reported results on software-based routing table lookup implementations. This paper also reports the performance impacts of various architectural parameters in the proposed scheme and its storage costs.	address space;algorithm;backtracking;cidr;cpu cache;central processing unit;dec alpha;data system;decision table;digital data;high-availability cluster;ibm notes;memory hierarchy;network address;network packet;personal computer;prototype;router (computing);routing table;simulation;tracing (software);workstation	Tzi-cker Chiueh;Prashant Pradhan	1999		10.1109/INFCOM.1999.752162	internet protocol;policy-based routing;routing table;route;algorithm design;virtual routing and forwarding;enhanced interior gateway routing protocol;loose source routing;static routing;parallel computing;real-time computing;the internet;computer science;operating system;ip forwarding;dec alpha;simulation modeling;parallel algorithm;forwarding plane;routing protocol;cluster analysis;triangular routing;transport layer;linux kernel;computer network	Metrics	-5.697125348640278	66.6186660900272	109170
7027933a218616e9563f478be3787a99c95dd7b9	similarity search in sensor networks using semantic-based caching	semantics;similarity search	Sensor networks build temporary wireless connections in environments where the stationary infrastructures are either destroyed or too expensive to construct. Most of the previous research in sensor networks focuses on routing protocols that adapt to the dynamic network topologies, and not much work has been done on data accessing. One important data accessing application is similarity search, which provides the foundation of content-based retrieval. Many traditional similarity search algorithms are based on centralized or flooding mechanisms, which are not effective in wireless sensor network environments due to the multiple limitations such as bandwidth and power. In this paper we tackle the problem of similarity search by using semantic-based caching to reflect the data content distribution in the network. The basic idea is analyzing the cached results of earlier queries and trying to resolve the later queries within a small collection of content-related mobile nodes. Based on a Hilbert space-filling curve, the data points in a multi-dimensional semantic space are described as a linear representation. These data points are further cached to facilitate query processing. Through extensive simulations, we show that our method can perform similarity search with improved performance in terms of search cost and response time.	cache (computing);similarity search	Bo Yang;Mareboyana Manohar	2012	J. Network and Computer Applications	10.1016/j.jnca.2011.05.008	semantic search;computer science;data mining;database;nearest neighbor search;world wide web	Mobile	-10.562499711125545	73.21706034242152	109276
46b403c6fddafeafdfd8c5ce0e62c9d41f779592	query workload-aware overlay construction using histograms	p2p system;dynamic change;data sharing;small worlds;range query;peer to peer systems;edit distance;peer to peer system;satisfiability;small world;clustering;overlay network;peer to peer;query routing;range queries	Peer-to-peer(p2p) systems over an efficient means of data sharing among a dynamically changing set of a large number of a tonomous nodes.Each node in a p2p system is connected with a small number of other nodes thus creating an overlay network of nodes. A query posed at a node is routed through the overlay network towards nodes hosting data items that satisfy it. In this paper, we consider building overlays that exploit the query workload so that nodes are clustered based on their results to a given query workload. The motivation is to create overlays where nodes that match a large number of similar queries are a fewlinks apart. Query frequency is also taken into account so that popular queries have a greater effect on the formation of the overlay than unpopular ones. We focus on range selection queries and se histograms to estimate the query results of each node. Then, nodes are clustered based on the similarity of their histograms. To this end,we introd ce a workload-aware edit distance metric between histograms that takes into account the query workload. Our experimental results show that workload-aware overlays increase the percentage of query results returned for a given number of nodes visited as compared to both random (i.e., unclustered)overlays and non workload-aware clustered overlays (i.e., overlays that cluster nodes based solely on the nodes' content).	algorithm;cidr;cp/m;computer science;content addressable network;edit distance;francis;information discovery;information retrieval;java platform, standard edition;lookup table;mathematical software;octal;overlay network;podc;peer-to-peer;peter stoica;precedence effect;replication (computing);routing;schmidt decomposition;selectivity (electronic);symphony;vldb;watts humphrey;yang	Georgia Koloniari;Yannis Petrakis;Evaggelia Pitoura;Thodoris Tsotsos	2005		10.1145/1099554.1099717	range query;query optimization;web query classification;computer science;machine learning;database;distributed computing;world wide web	DB	-11.566324942872496	72.57508551502985	109689
aff2b4dfd6bcec5d44846afdaaff2fc51e519f11	qos negotiation in real-time systems and its application to automated flight control	real time systems degradation admission control power system modeling predictive models quality of service middleware resource management power system management distributed computing;aircraft control;degradation;quality of service negotiation;real time;distributed processing;resource management;embedded real time systems;distributed computing;distributed processing real time systems aircraft control;indexing terms;schedulability analysis;timeliness;computer networks;flight control systems;automated flight control;adaptive qos;real time guarantees;power system management;scheduling;qos negotiation;traditional schedulability analysis real time systems automated flight control quality of service negotiation admission control schemes application perceived system utility real time middleware service shared computing resources automated flight control system f 16 fighter aircraft real time guarantees;graceful degradation;real time middleware service;load sharing;traditional schedulability analysis;middleware;predictive models;reprints;f 16 fighter aircraft;quality of service;power system modeling;admission control schemes;shared computing resources;distributed data processing;application perceived system utility;real time application;flight control;admission control;real time systems;automated flight control system;automation	"""We propose a model for quality-of-service (QoS) negotiation in building real-time services to meet both predictability and graceful degradation requirements. QoS negotiation is shown to (i) outperform conventional """"binary"""" admission control schemes (either guaranteeing the required QoS or rejecting the service request), and (ii) achieve higher application-perceived system utility. We incorporated the proposed QoS-negotiation model into an example real-time middleware service, called RTPOOL, which manages a distributed pool of shared computing resources (processors) to guarantee timeliness QoS for real-time applications. The efficacy and power of QoS negotiation are demonstrated for an automated flight control system implemented on a network of PCs running RT-POOL. This system is used to fly an F-16 fighter aircraft modeled using the Aerial Combat (ACM) F-16 Flight Simulator. Experimental results indicate that QoS negotiation, while maintaining real-time guarantees, enables graceful QoS degradation under conditions in which traditional schedulability analysis and admission control schemes fail."""	quality of service;real-time transcription	Tarek F. Abdelzaher;Ella M. Atkins;Kang G. Shin	1997		10.1109/RTTAS.1997.601361	embedded system;fault tolerance;adaptive quality of service multi-hop routing;real-time computing;mobile qos;simulation;degradation;index term;quality of service;computer science;resource management;operating system;automation;middleware;predictive modelling;scheduling	Embedded	-15.712635412976907	65.34614529100926	109814
1e7ae11d3c4292039ba7a94cc4e7c17889658027	scheduling non-preemptive tasks with strict periods in multi-core real-time systems		Abstract Non-preemptive tasks with strict periods are usually adopted in practical multi-core real-time systems when continual sampling and processing of data are required. Systems designers need to provide a proper scheduling strategy such that the tasks’ deadlines will be met even under the worst-case conditions. In this paper, we study the scheduling problem of non-preemptive tasks with strict periods in multi-core real-time systems. We first derive a necessary and sufficient condition to determine whether a new task is schedulable upon a multi-core platform without changing the allocations of the existing tasks. Then, with a game theory analogy, we design a recursive method to calculate the maximum permissible execution time for a given task, and propose a new schedulability condition used when the start time and processor assignments of the existing tasks can be modified. Finally, based on the conditions derived previously, we present a task assignment algorithm, which not only provides valid allocations for all tasks, but also obtains the minimum number of processors required by the system. Simulation experiments with randomly generated task sets have been conducted to show the high efficiency and reliability of the proposed approach.	multi-core processor;real-time computing;real-time transcription;scheduling (computing)	Jinchao Chen;Chenglie Du;Fei Xie;Bin Lin	2018	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2018.09.002	game theory;real-time computing;job shop scheduling;recursion;sampling (statistics);nonpreemptive multitasking;scheduling (computing);analogy;multi-core processor;computer science	Embedded	-9.422536389794992	60.60179976012072	109865
2beae0a51ff6586b34be9208e4751dcadfff0ff8	p2p video streaming replication scheme for p2p vod services	servers bandwidth peer to peer computing bit rate simulation video on demand;video streaming peer to peer computing video on demand video servers;data replication peer to peer video streaming video on demand vod;partial video data storage p2p video streaming replication scheme video on demand service lightweight device storage size video data fetching video server bandwidth load p2p vod service	In P2P Video-on-Demand (VoD) services, the storage size of lightweight devices is limited so that they can only store the partial video data rather than a complete file. Therefore, peers cannot find the required video data from neighbor peers, and then fetch the video data from the video server thus increasing the bandwidth load of video server. In this paper, we propose a P2P VoD replication scheme to reduce the bandwidth load of video server. Peers can adaptively replicate video data under the storage space limitation. The experimental results show that our schemes can reduce 30% bandwidth load of the video server.	peer-to-peer;self-replicating machine;server (computing);streaming media;video server	Chi-Wen Lo;Yi-Yu Su	2014	2014 International Conference on Information and Communication Technology Convergence (ICTC)	10.1109/ICTC.2014.6983164	internet privacy;world wide web;computer network	DB	-16.158283418140915	73.39341472709891	110037
30ddb3586282f2873e8bdd56600f3eb816dc1c68	broker selection strategies in interoperable grid systems	computers;distributed system;scheduling layer broker selection interoperable grid system resource demand high performance computing system distributed system resource management job dispatch dynamic performance information;high performance computing processor scheduling resource management performance evaluation parallel processing computer architecture distributed computing grid computing international collaboration dynamic scheduling;resource allocation;scheduling grid computing open systems resource allocation;resource management;biological system modeling;job dispatch;scheduling layer;accuracy;computational modeling;scheduling;broker selection;high performance computer;scalability;dynamic performance information;open systems;simulation tool;resource demand;grid computing;interoperable grid system;high performance computing system;grid system;dynamic scheduling	The increasing demand for resources of the high performance computing systems has led to new forms of collaboration of distributed systems such as interoperable grid systems that contain and manage their own resources. While with a single grid domain one of the most important tasks is the selection of the most appropriate set of resources to dispatch a job, in an interoperable grid environment this problem shifts to selecting the most appropriate domain containing the requiring resources for the job. In this paper, we present and evaluate broker selection strategies for interoperable grid systems. They use aggregated resource information as well as dynamic performance information of the underlying scheduling layers. From our evaluations performed with simulation tools, we conclude that aggregation techniques do not penalize performance significantly, and that delegating part of the scheduling responsibilities to the underlying scheduling layers is a good way to balance the load among the different grid systems.	distributed computing;dynamic dispatch;grid systems corporation;interoperability;scheduling (computing);simulation;supercomputer	Ivan Rodero;Francesc Guim;Julita Corbalán;Liana L. Fong;Seyed Masoud Sadjadi	2009	2009 International Conference on Parallel Processing	10.1109/ICPP.2009.63	real-time computing;scalability;dynamic priority scheduling;resource allocation;computer science;resource management;operating system;database;distributed computing;accuracy and precision;open system;computational model;scheduling;grid computing	HPC	-17.455017088447814	60.580840998848196	110283
70bdc51a1967afb053fa5c0e95252345b81dc6ed	cpu scheduling with a round robin algorithm based on an effective time slice			algorithm;central processing unit;preemption (computing);scheduling (computing)	Mohammad M. Tajwar;Md. Nuruddin Pathan;Latifa Hussaini;Adamu Abubakar	2017	JIPS	10.3745/JIPS.01.0018	parallel computing;real-time computing;deficit round robin;computer science;scheduling (computing);round-robin scheduling;weighted round robin;preemption	EDA	-11.455489091867088	62.1621822907357	110390
e2e046c17dcb0dd1eecf235dbd9f8d9d04f66c28	optimal scheduling of task graphs on parallel systems	computational complexity;graph theory;parallel algorithms;processor scheduling;search problems;a* search algorithm;np-hard problem;optimal task graph a* scheduling algorithm;parallel system;program parallelisation;pruning technique;a*;parallel computing;optimal schedules;scheduling;task graphs	Scheduling tasks onto the processors of a parallel system is a crucial part of program parallelisation. Due to the NP-hard nature of the task scheduling problem, scheduling algorithms are based on heuristics that try to produce good rather than optimal schedules. Nevertheless, in certain situations it is desirable to have optimal schedules, for example for time critical systems or to evaluate scheduling heuristics. This paper investigates the task scheduling problem using A* search algorithm. The A* scheduling algorithm implemented can produce optimal schedules in reasonable time for small to medium sized task graphs. In comparison to a previous approach, the here presented A* scheduling algorithm has a significantly reduced search space due to a much improved cost function f(s) and additional pruning techniques. Last but not least, the experimental results show that the proposed A* scheduling algorithm significantly outperforms the previous approach.	scheduling (computing)	Oliver Sinnen;Alexander Vladimirovich Kozlov;Ahmed Zaki Semar Shahul	2007			fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;open-shop scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;least slack time scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling;proportionally fair	HPC	-13.910640284789405	61.41750134521518	110424
42ad2f7a57d048f23239e6108d7288aab280a66f	sequential and parallel approaches to incorporate reliability in the synthesis of computer networks	assignment problem;computer network	This paper presents a scenario-orientedoptimization model and solution algorithm to solve thejoint routing/capacity assignment problem for computernetworks. The advantage of this model is that failures are directly dealt with at the design stage.The model helps to find a suitable trade-off betweencapacity assignment and performance in the event offailures. As accounting for major failures can be very time consuming, we introduce parallelism as atool to solve this type of problem. Two parallelversions of the algorithm were implemented. Bothparallel versions were found to be extremely efficientin reducing computational time, the one presentingtwo levels of parallelization was found more suitablefor larger networks.	algorithm;assignment problem;parallel computing;routing;time complexity	Steven Chamberland;Brunilde Sansò	1997	Journal of Network and Systems Management	10.1023/A:1018718827282	computer science;generalized assignment problem;theoretical computer science;distributed computing;assignment problem;algorithm;computer network	PL	-13.931563831082023	62.189982686000754	110519
1e5e0fd0433cb0320fc8d80265d74d1bf397388d	utility maximization for resolving throughput/reliability trade-offs in an unreliable network with multipath routing	aggregate utility;limited resource;user requirement;different user;unreliable network;corresponding trade-offs;user-level utility function;level requirement;reliability trade-offs;multipath routing;utility maximization;distributed system;throughput;user requirements;resource allocation;pricing;congestion pricing;routing	This paper proposes a framework for balancing competing user (i.e., application) level requirements by resolving the corresponding trade-offs in a distributed system with limited resources. Assuming that each user's preferences are characterized by user-level utility function, the goal of balancing competing requirements for each user as well as across different users is to maximize the aggregate utility. The paper discusses this framework on an example of balancing user requirements for throughput and reliability in an unreliable network, where reliability is achieved through redundancy, e.g., using multipath routing.	aggregate data;distributed computing;entropy maximization;multipath routing;requirement;throughput;user requirements document;user space;utility	Vladimir Marbukh	2007		10.1145/1345263.1345308	congestion pricing;pricing;throughput;resource allocation;computer science;operations management;user requirements document;multipath routing;computer network	OS	-9.657834551282544	74.36211225218979	110535
a21a7a3b70544026c9386caefa44255fe5428257	integrated production and distribution scheduling		Contents List of Figures vi List of Algorithms vii 1 Introduction 1 1.	algorithm;list of algorithms;scheduling (computing);vii	Christian Viergutz	2011			fair-share scheduling;scheduling	Theory	-11.593222999623602	62.56023602681756	110544
4efd5dbdaf217dcef8ed3647d42e15939fcd4e88	introduction of novel rule based algorithms for scheduling in grid computing systems	dispatching rules;grid scheduling;rule based algorithm;resource selection;computational grid;rule based scheduling algorithm;scheduling algorithm computational grid rule based algorithm queuing strategy;job queuing strategy rule based scheduling algorithm grid computing system scheduling resource selection;queuing strategy;processor scheduling;resource allocation;information technology;rule based;scheduling algorithm processor scheduling grid computing dispatching dynamic scheduling heuristic algorithms computational modeling information technology asia computer simulation;grid computing system scheduling;scheduling algorithm;computational modeling;job queuing strategy;scheduling;heuristic algorithms;scheduling grid computing resource allocation;grid computing;computer simulation;dispatching;dynamic scheduling;asia	The rule based scheduling algorithms are a new trend in grid scheduling algorithms; the combination of rule based algorithms for resource selection with various dispatching rules for queuing of jobs can improve or deteriorate their performance. Thus, choosing a proper queuing strategy for each algorithm is a prominent issue in scheduling. In this paper, we introduce two new dispatching rules for resource selection and three new dispatching rules for queuing of jobs; we evaluate the performance of various combinations of these new rule based scheduling algorithms and queuing strategies. Also, we use some major combination of rule based scheduling algorithms with some important queuing strategies to verify the good results of these new algorithms. We introduce a set of criteria used to evaluate the grid scheduling algorithms.	algorithm;grid computing;job stream;scheduling (computing)	Aysan Rasooli Oskooei;Mohammad Mirza-Aghatabar;Siavash Khorsandi	2008	2008 Second Asia International Conference on Modelling &#x00026; Simulation (AMS)	10.1109/AMS.2008.83	fair-share scheduling;generalized processor sharing;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;fair queuing;distributed computing;lottery scheduling;round-robin scheduling	HPC	-16.479300418183655	62.12682257370798	110576
30f7f7dc7dace6fd57f1a9388ae51ec46f241f27	an improved scheduling technique for time-triggered embedded systems	protocols;time triggered;scheduling technique;information science;system modeling;processor scheduling;resource management;embedded system processor scheduling delay embedded computing information science computer architecture hardware application specific integrated circuits resource management scheduling algorithm;embedded system;synchronisation;computer architecture;embedded systems;scheduling algorithm;application specific integrated circuits;protocol implementation;communication protocol scheduling technique time triggered embedded systems system model time triggered protocol clock synchronization;system model;time triggered embedded systems;communication protocol;clock synchronization;protocols embedded systems processor scheduling synchronisation timing;time triggered protocol;embedded computing;hardware;timing	In this paper we present an improved scheduling technique for the synthesis of time-triggered embedded systems. Our system model captures both the flow of data and that of control. We have considered communication of data and conditions for a time-triggered protocol implementation that supports clock synchronization and mode changes. We have improved the quality of the schedules by introducing a new priority function that takes into consideration the communication protocol. Communication has been optimized through packaging messages into slots with a properly selected order and lengths. Several experiments and a real-life example demonstrate the efficiency of our approach.	clock synchronization;communications protocol;dataflow;embedded system;experiment;real life;schedule (computer science);scheduling (computing)	Paul Pop;Petru Eles;Zebo Peng	1999		10.1109/EURMIC.1999.794485	embedded system;real-time computing;computer science;distributed computing	Embedded	-7.407774580994759	61.69597940059004	110710
74beccb11f6067c719b10e79a827b6f6afa66fa6	an efficient list scheduling algorithm for time placement problem	partial reconfiguration;run time reconfiguration;satisfiability;run time reconfigurable;list scheduling;time placement;task graphs	The partially reconfigurable FPGAs allows an overlap between the execution and the reconfiguration of tasks. The partial approach can be used to fit a large application into the FPGA device by partitioning the application over time. The executions being partitioned over time and the configurations of tasks are done so that the imposed constraints are satisfied. The main aim of this work consists in answering the question when will a task be mapped in the FPGA? A time placement algorithm based on the list scheduling technique is developed to solve efficiently the above question. We have just used the list scheduling algorithm because of its fast run time. Compared to the run time of other algorithms used in this filed like the spectral and ILP algorithms, the list scheduling algorithm remains a good temporal placement candidate, especially, for a several nodes graph. Also, a part of this paper is devoted for the study and the implementation of DCT task graph. This graph is the most computationally intensive part of the Color Layout Descriptor algorithm of a low-level visual descriptor of MPEG 7. The studied case shows that the use of the partial approach is very efficient in terms of latency of the whole application than the full one.	algorithm;list scheduling;scheduling (computing)	Abdellatif Mtibaa;Bouraoui Ouni;Mohamed Abid	2007	Computers & Electrical Engineering	10.1016/j.compeleceng.2007.02.005	parallel computing;real-time computing;computer science;self-organizing list;distributed computing;satisfiability	DB	-13.074699753729767	61.989169627514435	110721
1faa57656fea16b2a1e507bfe24140633d8c81b0	circus: opportunistic block reordering for scalable content servers	arm movement;analytical model	Whole-file transfer is a basic primitive for Internet content dissemination. Content servers are increasingly limited by disk arm movement given the rapid growth in disk density, disk transfer rates, server network bandwidth, and content size. Individual file transfers are sequential, but the block access sequence on a content server is effectively random when many slow clients access large files concurrently. Although larger blocks can help improve disk throughput, buffering requirements increase linearly with block size. This paper explores a novel block reordering technique that can reduce server disk traffic significantly when large content files are shared. The idea is to transfer blocks to each client in any order that is convenient for the server. The server sends blocks to each client opportunistically in order to maximize the advantage from the disk reads it issues to serve other clients accessing the same file. We first illustrate the motivation and potential impact of opportunistic block reordering using a simple analytical model. Then we describe a file transfer system using a simple block reordering algorithm, called Circus. Experimental results with the Circus prototype show that it can improve server throughput by a factor of two or more in workloads with strong file access locality.	algorithm;block size (cryptography);dhrystone;download;file server;file transfer;locality of reference;prototype;requirement;scheduling (computing);server (computing);throughput	Stergios V. Anastasiadis;Rajiv Wickremesinghe;Jeffrey S. Chase	2004			file server;real-time computing;computer science;operating system;database;distributed computing;world wide web;server	OS	-16.10196687032255	72.29819372107164	110961
6a511843e93618e50c1f57e41c7c105c125ff108	an adaptive priority-based heuristic approach for scheduling dag applications with uncertainties		In the context of large-scale distributed computing environments, among various DAG scheduling heuristics aiming at coping with severe uncertainties during task execution, those ones that try to maximize the parallelism of ready tasks seems to be promising. However, most of such heuristics consider only the DAG structure when making scheduling decision. When the information about task execution time (even though might be inaccurate) is given, it might be interesting to investigate whether this information should be taken into account during scheduling, and if yes, how to. This paper presents an adaptive priority-based heuristic, which properly considers the task execution time estimate and the DAG structure attributes in the task prioritization. The evaluation result shows the proposed approach obtains better scheduling performance than existing solutions.	apb;batch processing;directed acyclic graph;distributed computing;heuristic (computer science);just-in-time compilation;parallel computing;programming paradigm;run time (program lifecycle phase);scheduling (computing);simulation;virtual reality	Wei Zheng;Xinbo Zhang;Lu Tang;Dongzhan Zhang;Jinjun Chen	2017	2017 IEEE International Symposium on Parallel and Distributed Processing with Applications and 2017 IEEE International Conference on Ubiquitous Computing and Communications (ISPA/IUCC)	10.1109/ISPA/IUCC.2017.00020	real-time computing;task analysis;human–computer interaction;resource management;scheduling (computing);heuristic;prioritization;heuristics;computer science	Embedded	-18.009443510026326	61.98181530126387	111158
603a2d14da70787ee8fdb94f8fcbd75e86bd645d	cache management for mobile databases: design and evaluation	databases;cache storage;databases mobile communication mobile computing cache storage bandwidth network servers batteries;database queries;wireless channels;mobile caching mechanism;query processing;point to point;database servers;storage management;mobile computing environment;mobile databases;mobile computer;simulation model cache management mobile databases mobile clients database servers mobile computing environment wireless channels frequently accessed database items local storage database queries query processing mobile caching mechanism mobile environment point to point communication paradigm caching granularity coherence strategy replacement policy;mobile database;mobile environment;network servers;caching granularity;coherence strategy;batteries;mobile communication;distributed databases;bandwidth;mobile clients;point to point communication paradigm;mobile computing;local storage;simulation model;cache management;frequently accessed database items;database query;replacement policy	Caching frequently accessed data on the client side is an effective technique for improving performance in a mobile environment. Average data access latency is reduced as several data access requests can be satisfied from the local cache, thereby obviating the need for data transmission over the scarce wireless links. However, frequent disconnections and mobility of the clients make cache consistency a challenging problem. Effective cache invalidation strategies are required to ensure the consistency between the cached data at the clients and the original data stored at the server.	cache coherence;cache invalidation;client-side;data access;server (computing)	Boris Y. L. Chan;Antonio Si;Hong Va Leong	1998		10.1109/ICDE.1998.655757	mobile search;mobile database;computer science;database;distributed computing;smart cache;mobile computing;world wide web	Mobile	-15.364835118109621	68.6480276312986	111323
42a86fc22d165cc647e7898ef2ada37dc680a02d	deca: a hierarchical framework for decentralized aggregation in dhts	estensibilidad;graph theory;distributed system;hierarchical system;teoria grafo;systeme reparti;systeme grande taille;gossiping all to all;gestion red;par a par;systeme hierarchise;gossip;large scale system;cayley graph;theorie graphe;aggregation;sistema jerarquizado;sistema repartido;poste a poste;todos a todos;algorithme reparti;gestion reseau;autoorganizacion;grafo cayley;self organization;algoritmo repartido;extensibilite;network management;scalability;peer to peer;distributed algorithm;structured p2p networks;dht;autoorganisation;hierarchical model;echange total;cayley graphs;sistema gran escala;graphe cayley	As Structured Peer-to-Peer (P2P) Networks become popular, there is an emerging need to monitor continuously the huge number of participants in a robust and scalable manner. To this end, aggregation has emerged as a basis for the self-management of these networks. However, the structured P2P networks lack today of efficient mechanisms for the decentralized computation of these aggregates. In this paper, we propose a hierarchical theoretic model based on Cayley Graphs, which overcomes the requisite to accommodate growth without impacting the efficiency of distributed applications. Also, the paper presents an aggregation protocol that fuses the fault-resilience of gossip algorithms with the scalability of trees. In particular, simulation results show that this algorithm is capable to cope with the distributed and unreliable nature of P2P networks.	algorithm;computation;distributed computing;fault tolerance;magma;programming paradigm;requirement;scalability;self-management (computer science);simulation;social peer-to-peer processes;theory	Marc Sánchez Artigas;Pedro García López;Antonio F. Gómez-Skarmeta	2006		10.1007/11907466_23	distributed algorithm;computer science;artificial intelligence;graph theory;cayley graph;distributed computing;algorithm	ML	-10.734329194408256	70.29742171729478	111327
14ccd280efcc904d774281a67efb04d16a33a2c1	miss behavior for caching with lease	stability;markov processes;random access;throughput	Caching with lease is to evict the data record from cache after its associated lease term expires. This policy differs from the traditional caching algorithms, e.g., LRU, by introducing a dimension of time to the data record stored in the cache. This model has recently attracted increasing interest not only from a theoretical perspective, but also in real system implementation. For the related theoretical studies, lease of each data record, also known as cache characteristic time and Time-To-Live (TTL), provides a convenient approximation that can simplify the complexity in analyzing popular caching algorithms such as LRU. This approach ignores the finite capacity of the cache size and assumes the lease term to be a known parameter that matches with the measurements. Recently, with new development in system engineering, caching with lease has been shown to be an efficient way to improve the performance of RDMA based key-value stores. This engineering practice imposes new challenges for designing caching algorithms based on lease. It calls for further theoretical investigation on the lease term in presence of a finite cache capacity. To this end, we derive the miss probabilities for caching with lease compared to LRU, when the frequency of requesting a data record is equal to the generalized Zipf's law. Based on the miss probability depending on the lease term, we also discuss adaptive algorithms that can optimally determine the lease term.	adaptive algorithm;approximation;attribute–value pair;cpu cache;cache (computing);remote direct memory access;row (database);systems engineering;time to live;transistor–transistor logic;zipf's law	Jian Tan;Xiang Lin;Yandong Wang	2015	SIGMETRICS Performance Evaluation Review	10.1145/2825236.2825260	throughput;parallel computing;real-time computing;stability;computer science;operating system;database;markov process;random access;statistics;computer network	Metrics	-13.564417704918904	68.30404486338037	111404
5807a9eca5f0c86a998d24f8c2bb5ac0871e67e3	an adaptive batched patch caching scheme for multimedia streaming	distributed system;metodo adaptativo;eje troncal;largeur bande;streaming;systeme reparti;multimedia;multimedia streaming;transmision continua;serveur informatique;proxy caching;cache memory;methode adaptative;reseau federateur;antememoria;serveur reseau;large scale;antememoire;transmission en continu;network servers;sistema repartido;streaming media;scheduling;adaptive method;anchura banda;video server;bandwidth;servidor informatico;backbone;ordonnancement;reglamento;computer server	Large-scale steaming media applications usually consume a significant amount of server and network resources due to the high bandwidth requirements and the long-lived nature of the streaming media objects. In this paper, we address the problem of efficiently streaming media object to the clients over a distributed infrastructure consisting of video server and proxy caches. We build on the earlier work and propose an adaptive batched patch caching scheme, which tightly combine the transmission scheduling with proxy caching. This scheme adaptively caches the next segment data at proxy from the ongoing entire stream, which depends on the current batching interval that has non-zero requests. We demonstrate the benefits of our scheme compare to the classical streaming strategies. Our evaluations show that this scheme can reduce significantly the consumption of aggregate bandwidth on backbone link within much wider range of request arrival rate.	aggregate data;cache (computing);internet backbone;media object server;numerical analysis;proxy server;queueing theory;requirement;scheduling (computing);server (computing);software propagation;streaming media;video server;web cache	ShaoHua Qin;Weihong He;Zimu Li;Jianping Hu	2004		10.1007/978-3-540-30189-9_6	embedded system;real-time computing;cpu cache;computer science;operating system;database;distributed computing;scheduling;bandwidth;server	OS	-15.390187991610269	71.81140915428685	111473
821632cecf15e61e84adb5662e19591cd707c8d9	pump scheduling optimization using asynchronous parallel			scheduling (computing)	Christian von Lücken;Benjamín Barán;Aldo Sotelo	2004	CLEI Electron. J.		computer science;fair-share scheduling;asynchronous communication;scheduling (computing);distributed computing	HPC	-11.527463760019083	62.55402629363622	111859
c065c30281c77bb48a5022da36329078b699f584	scheduling complete trees on two uniform processors with integer speed ratios and communication delays	uniform processors;scheduling;communication delay;communication delays;complete in trees	In this paper, we present an algorithm that builds optimal schedules for complete in-trees on two uniform processors, with arbitrary integer speed ratios, in the presence of communication delays.	scheduling (computing)	Jacek Blazewicz;Frédéric Guinand;Bernard Penz;Denis Trystram	2000	Parallel Processing Letters	10.1142/S0129626400000263	real-time computing;computer science;theoretical computer science;operating system;distributed computing;scheduling	Theory	-10.644919026186246	61.573623115579025	111872
ae51cf420ea0a8e8de4125bf76499e93b2c78d42	"""correction to """"a modified priority based probe algorithm for distributed deadlock detection and resolution"""""""	system recovery distributed processing error correction;distributed processing;deadlock detection;pseudocode;system recovery;distributed deadlock detection;error correction;probes system recovery information science;modified priority based probe algorithm;pseudocode modified priority based probe algorithm distributed deadlock detection	A line inadvertently omitted from a section of the pseudocode in the above paper (see ibid., vol.15, no.1, p.10-17, 1989) is provided. The correct reading of the section is given in full. >	algorithm;deadlock	Alok N. Choudhary;Walter H. Kohler;John A. Stankovic;Donald F. Towsley	1989	IEEE Trans. Software Eng.	10.1109/32.58776	pseudocode;real-time computing;error detection and correction;computer science;theoretical computer science;distributed computing;programming language;deadlock prevention algorithms	SE	-6.662533107375113	70.76598828123439	111906
64554228350d9e5a6048d635f8343e3de6b10a4c	scalable high-throughput sram-based architecture for ip-lookup using fpga	internet protocol;ternary content addressable memory;random access memory;routing;ip networks random access memory routing pipelines field programmable gate arrays throughput pipeline processing;tree traversal;sram based linear pipeline architecture;virtex 4;fpga;dupi;chip;memory utilization;mlps;backbone routers;internet traffic;power dissipation;pipelines;scalable high throughput sram based architecture;ip networks;pin limitations;ip lookup;pipelining;sram chips content addressable storage field programmable gate arrays ip networks;field programmable gate arrays;high throughput;content addressable storage;high speed;on chip memory;pipeline processing;throughput;internet traffic scalable high throughput sram based architecture ip lookup fpga internet protocol tree traversal pipelining memory utilization on chip memory pin limitations backbone routers ternary content addressable memory sram based linear pipeline architecture dupi virtex 4 mlps power dissipation;sram chips	Most high-speed Internet Protocol (IP) lookup implementations use tree traversal and pipelining. However, this approach results in inefficient memory utilization. Due to available on-chip memory and pin limitations of FPGAs, state-of-the-art designs on FPGAs cannot support large routing tables arising in backbone routers. Therefore, ternary content addressable memory (TCAM) is widely used. We propose a novel SRAM-based linear pipeline architecture, named DuPI. Using a single Virtex-4, DuPI can support a routing table of up to 228 K prefixes, which is 3times the state-of-the-art. Our architecture can also be easily partitioned, so as to use external SRAM to handle even larger routing tables (up to 2 M prefixes), while maintaining a 324 MLPS throughput. The use of SRAM (instead of TCAM) leads to orders of magnitude of reduction in power dissipation. Employing caching to exploit Internet traffic locality, we can achieve a throughput of 1.3 GLPS (billion lookups per second). Our design also maintains packet input order, and supports in-place non-blocking route updates.	blocking (computing);cpu power dissipation;cache (computing);content-addressable memory;field-programmable gate array;high-throughput computing;in-place algorithm;internet backbone;locality of reference;lookup table;network packet;non-blocking algorithm;pipeline (computing);routing table;static random-access memory;telecommunications access method;throughput;tree traversal	Hoang Le;Weirong Jiang;Viktor K. Prasanna	2008	2008 International Conference on Field Programmable Logic and Applications	10.1109/FPL.2008.4629921	embedded system;parallel computing;real-time computing;computer science;field-programmable gate array	DB	-5.7534645985795345	66.60853639355754	112224
67c23ee554c2dd48311ebb3e1fd25ac5444e799d	metrics, fundamental trade-offs and control policies for delay-sensitive applications in volatile environments	electrical engineering and computer science;thesis	With the explosion of consumer demand, media streaming will soon be the dominant type of Internet traffic. Since such applications are intrinsically delay-sensitive, the conventional network control policies and coding algorithms may not be appropriate tools for data dissemination over networks. The major issue with design and analysis of delay-sensitive applications is the notion of delay, which significantly varies across different applications and time scales. #R##N#We present a framework for studying the problem of media streaming in an unreliable environment. The focus of this work is on end-user experience for such applications. First, we take an analytical approach to study fundamental rate-delay-reliability trade-offs in the context of media streaming for a single receiver system. We consider the probability of interruption in media playback (buffer underflow) as well as the number of initially buffered packets (initial waiting time) as the Quality of user Experience (QoE) metrics. We characterize the optimal trade-off between these metrics as a function of system parameters such as the packet arrival rate and the file size, for different channel models. For a memoryless channel, we model the receiver's queue dynamics as an M/D/1 queue. Then, we show that for arrival rates slightly larger than the play rate, the minimum initial buffering required to achieve certain level of interruption probability remains bounded as the file size grows. For the case where the arrival rate and the play rate match, the minimum initial buffer size should scale as the square root of the file size. We also study media streaming over channels with memory, modeled using Markovian arrival processes. We characterize the optimal trade-off curves for the infinite file size case, in such Markovian environments. #R##N#Second, we generalize the results to the case of multiple servers or peers streaming to a single receiver. Random linear network coding allows us to simplify the packet selection strategies and alleviate issues such as duplicate packet reception. We show that the multi-server streaming problem over a memoryless channel can be transformed into a single-server streaming problem, for which we have characterized QoE trade-offs. #R##N#Third, we study the design of media streaming applications in the presence of multiple heterogeneous wireless access methods with different access costs. Our objective is to analytically characterize the trade-off between usage cost and QoE metrics. We model each access network as a server that provides packets to the user according to a Poisson process with a certain rate and cost. User must make a decision on how many packets to buffer before playback, and which networks to access during the playback. We design, analyze and compare several control policies. In particular, we show that a simple Markov policy with a threshold structure performs the best. We formulate the problem of finding the optimal control policy as a Markov Decision Process (MDP) with a probabilistic constraint. We present the Hamilton-Jacobi-Bellman (HJB) equation for this problem by expanding the state space, and exploit it as a verification method for optimality of the proposed control policy. #R##N#We use the tools and techniques developed for media streaming applications in the context of power supply networks. We study the value of storage in securing reliability of a system with uncertain supply and demand, and supply friction. We assume storage, when available, can be used to compensate, fully or partially, for the surge in demand or loss of supply. We formulate the problem of optimal utilization of storage with the objective of maximizing system reliability as minimization of the expected discounted cost of blackouts over an infinite horizon. We show that when the stage cost is linear in the size of the blackout, the optimal policy is myopic in the sense that all shocks are compensated by storage up to the available level of storage. However, when the stage cost is strictly convex, it may be optimal to curtail some of the demand and allow a small current blackout in the interest of maintaining a higher level of reserve to avoid a large blackout in the future. Finally, we examine the value of storage capacity in improving system's reliability, as well as the effects of the associated optimal policies under different stage costs on the probability distribution of blackouts. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)		Ali ParandehGheibi	2012			real-time computing;simulation;computer science;operations management	PL	-12.704681418308677	68.01415655265859	112467
dc475fd727fa7f388ddc4e34fb3b211bfd72d642	assessing the impact of imperfect diagnosis on service reliability: a parsimonious model approach	analytical models;reliability engineering;program diagnostics;optimisation;reliability;closed form solution;state space methods;service reliability optimization imperfect diagnosis impact service reliability parsimonious model approach diagnosis performance diagnosis settings markov model closed form solutions diagnosis imperfections tcp based services sctp based services model based sensitivity analysis diagnosis performance metrics diagnosis heuristics properties;fault diagnosis measurement equations sensitivity analysis analytical models reliability engineering closed form solution availability state space methods birth disorders;measurement;sctp based services;imperfect diagnosis impact;availability;policy evaluation diagnosis model imperfect diagnosis fault management end node;reliability modeling;diagnosis performance;parsimonious model approach;imperfect diagnosis;closed form solutions;reliability theory;transient analysis;diagnosis settings;performance metric;birth disorders;model based sensitivity analysis;markov model;end node;policy evaluation;sensitivity analysis;diagnosis model;diagnosis performance metrics;tcp based services;mathematical model;simulation study;service reliability;diagnosis heuristics properties;reliability theory markov processes optimisation program diagnostics;markov processes;diagnosis imperfections;service reliability optimization;fault management;fault diagnosis	Modelling imperfect diagnosis performance in service reliability models can help identify best recovery strategies and diagnosis settings. In this work, a parsimonious Markov model of imperfect diagnosis is proposed. Capturing complex diagnosis behavior in the model is non-trivial. In our approach, representative diagnosis performance metrics have been defined and their closed-form solutions obtained for the Markov model. These equations enable model parameterization from traces of implemented diagnosis components. The diagnosis model has been integrated in a reliability model assessing the impact of diagnosis imperfections on reliability for time-constrained SCTP/TCP-based services. This enables: (a) a model-based sensitivity analysis of the service reliability to the diagnosis performance metrics, and (b) investigation of whether the chosen metrics provide a sufficiently detailed characterization of the diagnosis functions for the studied reliability problem. In a simulation study we finally analyze trade-off properties of diagnosis heuristics from literature, map them to the analytic Markov model, and investigate its suitability for service reliability optimization.	emoticon;heuristic (computer science);markov chain;markov model;mathematical optimization;occam's razor;simulation;tracing (software)	Jesper Grønbæk;Hans-Peter Schwefel;Jens Kristian Kjaergard;Thomas Skjødeberg Toftegaard	2010	2010 European Dependable Computing Conference	10.1109/EDCC.2010.28	reliability engineering;availability;closed-form expression;simulation;reliability theory;computer science;engineering;fault management;mathematical model;reliability;markov process;markov model;sensitivity analysis;measurement;statistics	HPC	-7.870682358493059	73.86663130453468	112496
0c20f4a30033704802bbd7dc5dde7f4c213fdeb6	a parallel algorithm for mapping a special class of task graphs onto linear array multiprocessors	task graph partitioning;parallel algorithm;time complexity;linear array;multiprocessors;parallel and distributed computing;computational complexity;polynomial time;load balancing;load balance;task graphs;parallel algorithms	"""1 I n t r o d u c t i o n Parallel and distributed computing has become a popular discipline for research anddevelopment due to recent progress in micro-electronics and software technologies. The thrust in research has in general been focused on improving the performance of parallel applications on multiprocessors either by minimizing turn-around time or by maximizing throughput. One area of particular interest is how to map a given problem onto a multiprocessor of a specific topology and architecture so that a desired, if not optimal, peffbrmance can be obtained. This necessitates constructing a partition of the problem into subproblems that achieves the following two goals: 1) the partition is load-balanced and 2) the inter-process (inter-subproblems) communication is minimized. Obviously, achieving one goal does not necessarily mean that the other goal will be automatically achieved. In fact, these two goals are often contradictory. It is this contradictory nature of the problem that makes it challenging. In fact, the general problem of optimally mappinga problem onto a multiprocessor topology is known to b e NP-complete [5]. In general, the structural feature of a multiprocessor can be represented by a graph isomorphic to its topological structure. This architecture graph Is denoted by Gareh = (P, L), where P = {Pt, P2, ..., P~} is the set of processors and L = {li[li = (pj,p~) 6 P x P; where processors pj and pk are connected by a network channel} is the set of network links. Similarly, the structural feature of a parallel application can be represented by a task graph G,~k = (N, MD) where Y = {tl , t2, . . . , t~) is a set of Permission to copy without fee all or part o f this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. O 1994 ACM 089791-647..6/94/0003 $3,50"""" tasks comprising of the application and M D = {mi [ mi = (tj, t~) 6 N x N where tasks tj and tk need to exchange messages directly} is the set of data dependencies. The behavioral properties of a multiprocessor or a parallel application can be described by associating certain weights with respective graphs. For instance, a weight, w(pi), associated with a node Pi in Garch indicates the processing speed of processor pi (e.g., instructions per second), whereas a weight, w(li), on an edge Ii of Garch indicates the communication bandwidth of that network channel (i.e., bits per second). By the same token, the amount of processing requirement, w(ti) (in number of instructions), is associated with each node ti of Gt~sk and the amount of messages, w(rni) (in bits), is associated with each edge mi of Gta,k. Because of the extreme difficulty in approaching the above problem in entirety, this paper considers a special case o f the problem, in.which a linear type task graph Gea,k_tin,ar = (N, MD), where N = {tl, t2, ..., tn} and M D = {mi [ mi = (ti,ti+l) E N x N; 1 < i < n}, is mapped onto a linear array or ring-structured multiprocessor. As explained in a later section, this problem has its applications in the area of real-time computing, distributed simulation as well as shared memory architecture. For more examples one may refer to [3]. Some papers closely related to our work have been published in recent years. Here we briefly discuss about some most relevant past works only. In his 1988 paper Bokhari [3] solved the problem of partitioning a linear task graph for linear array architecture and host-satellite architecture. The algorithm runs in O(n3rn) time, where n is the number of nodes in the linear task graph and m is the number of processors in the linear array multiprocessor. Bokhari's bottleneck minimization problem takes polynomial time when the task graph is a tree and target architecture is single host multiple (identical) Satellite system. Whereas we have shown that bandwidth minimization problem is NP-complete for tree task graph (see appendix). To the best of our knowledge, this is the first NP-completeness proof for tree task graph. Nicol and O'ttallaron made some improvement over Bokhari's algorithm in their 1991 paper [8]. I-Iansen and and Lih solved the partitioning problem for linear task graph and linear array architecture in O(rn2n) time [6]. Though the time complexity achieved is no better than Nicol and O'Hallaron's algorithm, their approach is different, more lucid and easy to program. The paper is organized as follows. In section 2, the problem under consideration is formulated and a naive O(n + p2) and an improved O(n + plogp) sequential algorithm (p _< n) are developed and their complexity analyzed respectively. A cost-optimal parallel version of the naive algorithm is developed and analyzed in Section 3. In Section 4 we present two applications of the problem. Finally, concluding remarks are given in Section 5."""	central processing unit;charge-coupled device;cost efficiency;data dependency;data rate units;distributed computing;graph bandwidth;load balancing (computing);lucid;molecular dynamics;multiprocessing;np-completeness;nicol prism;parallel algorithm;partition problem;polynomial;real-time clock;real-time computing;sequential algorithm;shared memory;simulation;substructural type system;throughput;thrust;time complexity	Sibabrata Ray;Hong Jiang;Jitender S. Deogun	1994		10.1145/326619.326815	time complexity;parallel computing;computer science;load balancing;theoretical computer science;distributed computing;parallel algorithm;cost efficiency	Theory	-12.90065749150178	61.37261400731507	112613
2fab90b0da9aaaf3825fb8ef70efff9abe7bf57f	an empirical analysis of a large-scale mobile cloud storage service	mobile cloud storage;tcp performance;user behavior	Cloud storage services are serving a rapidly increasing number of mobile users. However, little is known about the differences between mobile and traditional cloud storage services at scale. In order to understand mobile user access behavior, we analyzed a dataset of 350 million HTTP request logs from a large-scale mobile cloud storage service. This paper presents our results and discusses the implications for system design and network performance. Our key observation is that the examined mobile cloud storage service is dominated by uploads, and the vast majority of users rarely retrieve their uploads during the one-week observation period. In other words, mobile users lean towards the usage of cloud storage for backup. This suggests that delta encoding and chunk-level deduplication found in traditional cloud storage services can be reasonably omitted in mobile scenarios. We also observed that the long idle time between chunk transmissions by Android clients should be shortened since they cause significant performance degradation due to the restart of TCP slow-start. Other observations related to session characteristics, load distribution, user behavior and engagement, and network performance.	android;backup;data deduplication;delta encoding;elegant degradation;load balancing (computing);mobile cloud computing;mobile cloud storage;network performance;systems design;tcp congestion control;upload	Zhenyu Li;Xiaohui Wang;Ningjing Huang;Mohamed Ali Kâafar;Zhenhua Li;Jianer Zhou;Gaogang Xie;Peter Steenkiste	2016		10.1145/2987443.2987465	mobile search;telecommunications;mobile database;engineering;operating system;internet privacy;mobile computing;world wide web;computer security;computer network	Metrics	-18.077899611880497	73.47984852191206	112652
e28cdeacba7ff818db0db3174938fc5ca646df71	multi-objective energy-efficient workflow scheduling using list-based heuristics	multi objective optimisation;energy efficient scheduling;workflow scheduling	Workflow applications are a popular paradigm used by scientists for modelling applications to be run on heterogeneous high-performance parallel and distributed computing systems. Today, the increase in the number and heterogeneity of multi-core parallel systems facilitates the access to high-performance computing to almost every scientist, yet entailing additional challenges to be addressed. One of the critical problems today is the power required for operating these systems for both environmental and financial reasons. To decrease the energy consumption in heterogeneous systems, different methods such as energy-efficient scheduling are receiving increasing attention. Current schedulers are, however, based on simplistic energy models not matching the reality, use techniques like DVFS not available on all types of systems, or do not approach the problem as a multi-objective optimisation considering both performance and energy as simultaneous objectives. In this paper, we present a new Pareto-based multi-objective workflow scheduling algorithm as an extension to an existing state-of-the-art heuristic capable of computing a set of tradeoff optimal solutions in terms of makespan and energy efficiency. Our approach is based on empirical models which capture the real behaviour of energy consumption in heterogeneous parallel systems. We compare our new approach with a classical mono-objective scheduling heuristic and state-of-the-art multi-objective optimisation algorithm and demonstrate that it computes better or similar results in different scenarios. We analyse the different tradeoff solutions computed by our algorithm under different experimental configurations and we observe that in some cases it finds solutions which reduce the energy consumption by up to 34.5% with a slight increase of 2% in the makespan.	heuristic (computer science);scheduling (computing)	Juan José Durillo;Vlad Nae;Radu Prodan	2014	Future Generation Comp. Syst.	10.1016/j.future.2013.07.005	fair-share scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;theoretical computer science;operating system;distributed computing;round-robin scheduling	Arch	-16.94994532804359	61.577027037929945	112726
6391744056341fa6fc7161a1e0ce8720d814acf8	algorithms for replica placement and update in tree network				Wu Jigang;Long Chen;Xu Wang;Guiyuan Jiang;Siew Kei Lam;Thambipillai Srikanthan	2018	Comput. J.	10.1093/comjnl/bxx074	theoretical computer science;distributed computing;tree network;replica;computer science	ECom	-8.733895011912734	68.9179162302102	112748
64ddccf2d04d692d749e2a6728159f5396a6bbd5	periodic real-time scheduling: from deadline-based model to latency-based model	non preemptive;preemptive scheduling;real time control;real time;periodic system;controller area network;deadline;periodicity;complex system;scheduling;real time scheduling;precedence constraint;reactive system;latency;real time application;distributed architecture;real time systems	This paper presents a connection between two real-time models: a deadline-based model and a latency-based model. The importance of the latency-based model is proved through a result showing that two deadlines, instead of a latency constraint, over-constrain the realtime applications. Moreover, we give a deadline-marking algorithm based on the relation between deadlines and latency constraints. This algorithm provides non-preemptive feasible schedules for systems with precedence constraints and deadlines, or more complex systems with deadlines and latencies. This is the first step toward non-preemptive schedulability for distributed architectures (without over-constraining the system) like, for example, the automotive applications using protocols such as Controller Area Network (CAN).	access time;algorithm;can bus;coexist (image);complex systems;distributed computing;item unique identification;quasiperiodicity;real-time clock;real-time computing;scheduling (computing);scheduling analysis real-time systems	Liliana Cucu-Grosjean;Nicolas Pernet;Yves Sorel	2008	Annals OR	10.1007/s10479-007-0279-9	complex systems;latency;parallel computing;real-time computing;real-time control system;can bus;reactive system;computer science;distributed computing;preemption;nonpreemptive multitasking;scheduling	Embedded	-9.916964520955965	61.199418320402884	112847
41b4952923c18a8679ddde0af83edd0052006a0c	comparing disk scheduling algorithms for vbr data streams	buffer requirements;multimedia;disk scheduling;continuous media;vbr;data stream;response time;necessary and sufficient condition;video server;variable bit rate;multimedia server	We compare a number of disk scheduling algorithms that can be used in a multimedia server for sustaining multiple variable-bit-rate (VBR) data streams. A data stream is sustained by repeatedly fetching a block of data from disk and storing it in a corresponding buffer. For each of the disk scheduling algorithms we give necessary and sufficient conditions for avoiding underflow and overflow of the buffers. In addition, the algorithms are compared with respect to buffer requirements as well as average response times. q 1998 Elsevier Science B.V.	algorithm;arithmetic underflow;i/o scheduling;requirement;scheduling (computing);server (computing);volume boot record	Jan H. M. Korst;Verus Pronk;Pascal Coumans;Giel van Doren;Emile H. L. Aarts	1998	Computer Communications	10.1016/S0140-3664(98)00201-1	real-time computing;computer science;distributed computing;variable bitrate;computer network	DB	-15.289638462103493	70.76717184302012	113563
8d1184303f33454b707030dec40d59b2e0de56f8	scheduling periodically occurring tasks on multiple processors			scheduling (computing)	Eugene L. Lawler;Charles U. Martel	1981	Inf. Process. Lett.	10.1016/0020-0190(81)90066-1	fair-share scheduling	DB	-11.408463467574963	62.413888450509006	113652
2594bd60f4670f2abafec41836650684af79a04e	a data transmission algorithm for distributed computing system based on maximum flow	skew;data;minimize bandwidth usage;transmission time;monitoring system;distributed computing system;data transmission time;computation	Data skew can lead to load imbalance and longer computation time in the distributed computing system. To avoid data skew and reduce the data computation time, it is necessary to transmit the data to appropriate machines, this may however take too much network resources. How to balance the computational resources and the network resources is a problem. In this paper, we introduce a computation model called distributed two-phase model, in which the process of a task can be divided into two independent phases: data transmission and data computation. Suppose an upper bound of relative computation time is given, we show how to schedule data transmission with minimum resources, such as data transmission time and occupied bandwidth, to meet the demand. In this paper, we present a novel algorithm to minimize data transmission time and network bandwidth usage in the data transmission phase, with the conditions that an upper bound of relative computation time of data computation phase is given. Moreover, the number of nodes that participate in data computation phase is also reduced, in this way, the computational resources are saved. The simulation results show that the occupied bandwidth can be reduced effectively (about 70 %) in the situation of large-scale data sets and large number of nodes. Our algorithm is also shown to be available in replication situation.	bandwidth (signal processing);computational resource;distributed computing;flow network;genetic algorithm;high- and low-level;maximum flow problem;model of computation;scheduling (computing);simulation;time complexity;two-phase commit protocol	Xiaolu Zhang;Jiafu Jiang;Xiaotong Zhang;Xuan Wang	2015	Cluster Computing	10.1007/s10586-015-0467-3	model of computation;skew;transmission time;parallel computing;real-time computing;computer science;theoretical computer science;operating system;computation;distributed computing;data	HPC	-15.004358558451356	62.681983972066625	113915
9395bb336c6227da0605c1cef934850b60dc73e4	multiple-server movie-retrieval strategies for distributed multimedia applications: a play-while-retrieve approach	service system;network servers motion pictures performance analysis fault tolerance computer architecture scalability closed form solution large scale systems service oriented architecture open source software;retrieval strategy;play while retrieve approach;buffer management;video retrieval;client server systems;video on demand access time play while retrieve retrieval strategy;installment retrieval strategies;large scale networks;large scale networks multiple server movie retrieval strategies distributed multimedia applications play while retrieve approach video on demand service multiple servers installment retrieval strategies;simulation experiment;play while retrieve;large scale;distributed multimedia applications;waiting time;video retrieval client server systems video on demand;video on demand;performance analysis;multiple servers;multiple server movie retrieval strategies;performance bounds;access time;video on demand service	In this paper, we present a generalized approach to retrieve a long-duration movie requested using a network-based video-on-demand service infrastructure employing multiple servers. We design and analyze a play-while-retrieve (PWR) playback strategy for this multiserver environment such that the access time (waiting time for the clients) is minimized. For this strategy, we use both the single-installment and multi-installment retrieval strategies to analyze the performance of the service system. For the above-mentioned retrieval strategies, we explicitly derive closed-form expressions for a minimum access time. For the case of multi-installment retrieval strategy, we conduct asymptotic performance analysis that quantifies the ultimate performance bounds of our strategy. We demonstrate analytically the impact of a large-scale network, as well as the impact of indefinitely increasing the number of installments, on the performance of such a multiserver service system. We then address the problem of buffer management at the client site, which is a closely related issue that has a significant influence on the performance of the strategy, and also serves as a key issue in making the service system attractive for clients. We derive relationships that quantify the minimum amount of buffer expected at the client site to have a smooth presentation with this multiserver service structure. Finally, we perform simulation experiments to verify all our theoretical findings. In the experiments, we compare the performance of PWR strategy with that of play-after-retrieve strategy, and discuss certain important points that are crucial for implementing a real-life working multiserver service system	access time;experiment;real life;server (computing);simulation	Long Chen;Bharadwaj Veeravalli	2006	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2005.851341	real-time computing;access time;computer science;distributed computing;world wide web;service system	Metrics	-16.90542162038554	71.96083300037434	113973
0ae21d75e2b88762d28e47c179b5b00e544cadb3	probabilistic strategies based on staged lsh for speedup of audio fingerprint searching with ten million scale database		We are developing and improving algorithms to identify audio fingerprints (AFP) in a network router. Staged Locality Sensitive Hashing (LSH) is one of them and nearly as fast as 1Gbps of prevalent network routers. In this paper, we propose two extensions from Staged LSH, both of which take advantage of probabilistic strategies. One is Neighbor Staged LSH, which is to tune up about how to choose buckets for the hash method for searching. The other is Hierarchy Staged LSH, whose strategy is to focus on the popularity of songs. Adopting both achieved at most 182.8 times as fast as the simple Staged LSH and it was equivalent to 1 Gbps. The accuracy rate was 100 % if the BER of AFP is less than 15 %.	acoustic fingerprint;adaptive replacement cache;algorithm;data rate units;experiment;internet;locality of reference;locality-sensitive hashing;random-access memory;router (computing);speedup;x.690;yang;lsh	Masahiro Fukuda;Yasushi Inoguchi	2017		10.1145/3120895.3120921	locality-sensitive hashing;internal medicine;cardiology;speedup;probabilistic logic;hash function;medicine;pattern recognition;artificial intelligence	ML	-6.435236823020337	66.66542642658528	114045
6641585c63a65d7ba61d769181a01f872a8d1772	adaptive scheduling for on-demand time-critical information dissemination over data broadcast channel		Modern information dissemination services can dynamically produce real-time data that is valid and useful depending on users’ on-demand data requests. Information servers must adopt a scheduling approach to maintain timely data access and system performance. Most previous studies on scheduling such data discuss on-demand data broadcasting and real-time task processing with various performance metrics. This paper exploits the attributes of request urgency, service productivity, and access fairness, and proposes an adaptive scheduling scheme for delivering on-demand, time-critical data objects over a data broadcast channel. In terms of request satisfaction and mean access time, performance results show that the proposed scheduling approach is amenable under dynamic on-demand time-critical requests, simultaneously achieving a low mean access time and request deadline miss rate.	access time;algorithm;broadcasting (networking);data access;datacasting;earliest deadline first scheduling;fairness measure;markov random field;online and offline;real-time clock;real-time data;scheduling (computing);simulation;synergy;window of opportunity	Chih-Lin Hu	2011	J. Inf. Sci. Eng.		distributed computing;computer network;access time;computer science;server;scheduling (computing);atomic broadcast;data access;broadcast radiation;communication channel;broadcasting	HPC	-14.934360982914834	69.38880341398192	114108
86df6c3104ba0202072d05bd113d97ccaa1d08d4	p3fsm: portable predictive pattern matching finite state machine	packet inspection;software portability;pattern matching automata intrusion detection doped fiber amplifiers samarium hardware engines encoding inspection software systems;deterministic automata;memory management;signature based network intrusion detection;software programmability;portable predictive pattern matching finite state machine;digital signatures;computer networks;network intrusion detection;deep packet inspection;indexes;finite state machines;deterministic finite automata portable predictive pattern matching finite state machine signature based network intrusion detection reconfigurable pattern matching packet inspection software based system software programmability software portability predictive state code encoding;engines;pattern matching;deterministic finite automata;telecommunication security;optimization;software specification;reconfigurable pattern matching;security of data;doped fiber amplifiers;telecommunication security computer networks deterministic automata digital signatures finite state machines pattern matching security of data;software based system;finite state machine;predictive state code encoding;throughput	Signature-based network intrusion detection requires fast and reconfigurable pattern matching for deep packet inspection. In our previous work we address this problem with a hardware based pattern matching engine that utilizes a novel state encoding scheme to allow memory efficient use of Deterministic Finite Automata. In this work we expand on these concepts to create a completely software based system, P3FSM, which combines the properties of hardware based systems with the portability and programmability of software. Specifically we introduce two methods, Character Aware and SDFA, for encoding predictive state codes which can forecast the next states of our FSM. The result is software based pattern matching which is fast, reconfigurable, memory-efficient and portable.	cluster analysis;deep packet inspection;deterministic finite automaton;finite-state machine;intrusion detection system;line code;network packet;pattern matching;reconfigurable computing;requirement;scalability;software portability;throughput	Lucas Vespa;Mini Mathew;Ning Weng	2009	2009 20th IEEE International Conference on Application-specific Systems, Architectures and Processors	10.1109/ASAP.2009.16	embedded system;deep packet inspection;computer architecture;parallel computing;real-time computing;computer science;theoretical computer science;operating system;distributed computing;finite-state machine;programming language;algorithm	EDA	-7.788915557041264	66.55285277307999	114138
6f4932b954819a8f46bd24a41963c3dda652eb65	scheduled video delivery for scalable on-demand service	video object;multimedia on demand;multimedia;continuous media;waiting time;content delivery;scalability;on demand service	Continuous media, such as digital movies, video clips, and music, are becoming an increasingly common way to present information, entertain and educate people. However, limited system and network resources have delayed the widespread usage of continuous media. In this paper, we propose a scalable and inexpensive video delivery paradigm, named Scheduled Video Delivery (SVD). In the SVD paradigm, users submit requests with specification of start time. The provider schedules these requests to meet the QoS specification and to maximize utilization of the resources. SVD scheduling has a different objective from many existing scheduling schemes. It does not aim at minimizing the waiting time. Instead, it focuses on meeting deadlines and at the same time combining requests to form multicasting groups. SVD scales not only to the number of users but also to the number of video objects.	digital media;multicast;programming paradigm;quality of service;scalability;scheduling (computing);singular value decomposition;video clip	Min-You Wu;Sujun Ma;Wei Shu	2002		10.1145/507670.507694	real-time computing;scalability;simulation;computer science;operating system;multimedia;computer network	HPC	-16.201189260978225	72.39241062429423	114580
21693f205150f35082e7634a6360e9907900efe4	scheduling for overload in real-time systems	systeme temps reel;evaluation performance;sobrecarga;performance evaluation;overload tolerance;processor scheduling;evaluacion prestacion;supercomputer education research centre;scheduling algorithm;fault tolerant computing;processor utilization real time systems overload scheduling uniprocessor robust overload performance overload tolerance overload tolerant systems uniprocessor scheduling performance evaluation;processor utilization;scheduling;surcharge;performance evaluation processor scheduling real time systems fault tolerant computing;real time systems scheduling algorithm processor scheduling robustness time measurement delay timing degradation algorithm design and analysis computer science;procesador;processeur;overload;processor;ordonnancement;uniprocessor scheduling;real time systems	No on-line scheduling algorithm operating in an uniprocessor environment can guarantee to obtain a useful processor utilization greater than 0.25 under conditions of overload. This result holds in the general case, where the deadlines of the input tasks can be arbitrarily “tight.” We address here the issue of improving overload performance in environments where there is a limit on the tightness of task deadlines. In particular, we present a new scheduling algorithm, ROBUST, that efficiently takes advantage of these limits to provide improved overload performance and is asymptotically optimal. We also introduce the concept of overload tolerance, wherein a system’s overload performance never falls below its design capacity, and describe how ROBUST may be used to construct overload tolerant systems.	asymptotically optimal algorithm;online and offline;real-time operating system;real-time transcription;robustness (computer science);scheduling (computing);uniprocessor system	Sanjoy K. Baruah;Jayant R. Haritsa	1997	IEEE Trans. Computers	10.1109/12.620484	embedded system;parallel computing;real-time computing;computer science;operating system;distributed computing;scheduling	Embedded	-10.810728802374248	60.84745370881239	114592
30ee0ce6b1eb612466660e2cd7fab1553012b973	error recovery in time-triggered communication systems using servers	protocols;error recovery time triggered communication traffic scheduling scheduling servers control area network;server capacity parameter error recovery mechanism time triggered communication system safety critical system temporal redundancy message set schedulability online traffic scheduling controller area network flexible time triggered can protocol server type parameter server period parameter;controller area networks;scheduling controller area networks protocols;scheduling;servers protocols bandwidth transient analysis bit error rate schedules reliability	In communication systems, transient faults will eventually occur. Thus, some mechanism is necessary to handle them and achieve appropriate levels of reliability, particularly in safety-critical systems. One possibility is to rely on temporal redundancy, i.e., using message retransmissions. General requirements for such a mechanism would include a parsimonious use of extra bandwidth while guaranteeing the schedulability of the message set. In this paper we propose using on-line traffic scheduling together with scheduling servers to recover message errors in time-triggered systems on Controller Area Network (CAN), taking advantage of the Flexible Time-Triggered CAN protocol. This novel mechanism is shown to offer a desired error recovery latency using much less extra bandwidth than typical approaches used in time-triggered systems. In this paper we present this novel error recovery mechanism, including a thorough characterization as well as configuration guidelines, namely concerning how to choose the server parameters (type, period and capacity). The correctness of the proposed approach and its superior performance are validated with simulation using several communication benchmarks available in the literature.	benchmark (computing);can bus;correctness (computer science);occam's razor;online and offline;requirement;scheduling (computing);server (computing);simulation	Luís Marques;Verónica Vasconcelos;Paulo Pedreiras;Luis Fernando de Almeida	2013	2013 8th IEEE International Symposium on Industrial Embedded Systems (SIES)	10.1109/SIES.2013.6601493	fair-share scheduling;embedded system;communications protocol;real-time computing;computer science;operating system;distributed computing;scheduling;computer network	Embedded	-6.703573337153425	70.13680311283574	115458
bf48e3bc45d63e9ca3e03dc03b287288a5269610	scheduling real-time systems with periodic tasks using a model-checking approach	complexity theory;processor scheduling;scheduling computational complexity decidability formal verification graph theory real time systems;computational modeling;optimal scheduling;cognition;schedules;computational complexity real time systems scheduling periodic tasks model checking approach scheduling theory scheduling schemes graphs quantitative temporal reasoning decidability necessary condition sufficient condition quasistatic offline schedulers;schedules real time systems complexity theory optimal scheduling cognition computational modeling processor scheduling;real time systems	Scheduling theory presents analytical solutions for different scheduling schemes, most of which based on necessary or sufficient conditions only. Available methods based on graphs use quantitative temporal reasoning to answer about decidability and to find feasible schedules. In this paper we present an alternative technique based on model-checking approach that uses only qualitative temporal reasoning with periodic tasks only. That technique gives a necessary and sufficient condition for decidability and assists the design of feasible static or quasistatic offline schedulers. Prospective results are illustrated by an example where a feasible solution can be reached dealing with aceptable computational complexity.	computational complexity theory;model checking;online and offline;prospective search;real-time clock;real-time computing;scheduling (computing)	Arianna Z. Olivera Salmon;Pedro M. Gonzalez del Foyo;Jose R. Silva	2014	2014 12th IEEE International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2014.6945486	fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;theoretical computer science;two-level scheduling;distributed computing;gain scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling	Embedded	-9.88824017492648	61.77021280785663	115935
8a44d450d8008c3f576bdb1dcf7f40a5e9a34c86	a multiobjective resources scheduling approach based on genetic algorithms in grid environment	resource scheduling;optimal solution;multiobjective genetic algorithms;sorting;processor scheduling;resource allocation;niched sharing multiobjective resources scheduling grid environment multiobjective optimization multiobjective genetic algorithms multidimensional qos metrics pareto sorting;multiobjective resources scheduling;multi dimensional;genetic algorithms processor scheduling quality of service costs bandwidth computer science genetic engineering grid computing delay sorting;niched sharing;grid environment;multiobjective optimization;genetic algorithm;genetic algorithms;sorting genetic algorithms grid computing processor scheduling quality of service resource allocation;pareto sorting;quality of service;grid computing;multidimensional qos metrics;multiobjective genetic algorithm	Resources scheduling plays an important role in grid. This paper converts resources scheduling problem in grid into a multiobjective optimization problem, and presents a resources scheduling approach based on multiobjective genetic algorithms. This approach deals with dependent relationships of jobs, and regards multi-dimensional QoS metrics, completion time and execution cost of jobs, as multiobjective. Based on Pareto sorting and niched sharing method, our approach determines optimal solutions. Experimental results show that our approach gets less completion time of jobs and total execution cost of jobs than min-min algorithm and max-min algorithm	genetic algorithm;job stream;mathematical optimization;maxima and minima;multi-objective optimization;optimization problem;pareto efficiency;scheduling (computing);sorting	Guangchang Ye;Ruonan Rao;Minglu Li	2006	2006 Fifth International Conference on Grid and Cooperative Computing Workshops	10.1109/GCCW.2006.9	mathematical optimization;genetic algorithm;computer science;theoretical computer science;distributed computing	HPC	-18.51126118094997	63.66290670349066	116116
057f35468f8566a87fe5e16773fcff92ae03bbd8	observations on the dynamic evolution of peer-to-peer networks	performance measure;largeur bande;reseau pair;protocole transmission;peer to peer network;routing;resource management;routage;peer to peer system;peer to peer p2p;gestion recursos;protocolo transmision;anchura banda;initial condition;gestion ressources;bandwidth;peer to peer;lower bound;enrutamiento;transmission protocol	A fundamental theoretical challenge in peer-to-peer syste m is proving statements about the evolution of the system whil e nodes are continuously joining and leaving. Because the sys t m will operate for an infinite time, performance measures base d on runtime are uninformative; instead, we must study the rat at which nodes consume resources to maintain the system state. This “maintenance bandwidth” depends on the rate at which nodes tend to enter and leave the system. In this paper, we for malize this dependence. Having done so, we analyze the Chord peer-to-peer protocol. We show that Chord’s maintenance ba ndwidth to handle concurrent node arrivals and departures is n ear optimal, exceeding the lower bound by only a logarithmic fac tor. We also outline and analyze an algorithm that converges to a correct routing state from an arbitrary initial condition .	algorithm;information retrieval;initial condition;models of dna evolution;outline (list);peer-to-peer;routing;tor messenger	David Liben-Nowell;Hari Balakrishnan;David R. Karger	2002		10.1007/3-540-45748-8_2	routing;simulation;telecommunications;computer science;resource management;distributed computing;upper and lower bounds;computer security;initial value problem;bandwidth;computer network	Metrics	-7.639778340652371	72.8149773388337	116226
b7e598d2589cbf6d2fe3850e86a25c03bfe1bb97	an efficient replication scheme to increase file availability in mobile peer to peer systems		The search efficiency improvement especially concerning search for rare files is a fundamental challenge in mobile peer-to-peer (MP2P) systems. In this paper, we propose a simple and efficient replication technique to increase file availability in MP2P systems which enhances the search efficiency. The aim of our proposal is to maintain a threshold level of availability at all times in order to find a file within a small number of overlay hops even for rare file. We base on a global availability estimation to choose suitable file to replicate and suitable replica degree. Simulations show that our proposal significantly improves search efficiency in terms of search success, search delay and overhead.	peer-to-peer	Moufida Rahmani;Mahfoud Benchaïba	2017		10.1109/ISNCC.2017.8072021	file system fragmentation;overlay;global namespace;peer-to-peer;replication (computing);bittorrent tracker;self-certifying file system;small number;distributed computing;computer science	Metrics	-12.67541306275851	73.51293435123254	116583
388e4dec51feeaa86a6a523546bfdb4c2d750381	core persistence in peer-to-peer systems: relating size to lifetime	distributed system;eje troncal;virtual network;churn;cluster computing;haute performance;systeme reparti;persistence;persistencia;par a par;dynamic distributed system;dynamic system;probabilistic approach;peer to peer system;reseau federateur;persistance;large scale;core;sistema repartido;internet;poste a poste;enfoque probabilista;approche probabiliste;alto rendimiento;overlay network;backbone;quality of service;survivability;peer to peer;high performance;probabilistic guarantee;peer to peer overlay networks;red virtual;reseau virtuel	Distributed systems are now both very large and highly dynamic. Peer to peer overlay networks have been proved efficient to cope with this new deal that traditional approaches can no longer accommodate. While the challenge of organizing peers in an overlay network has generated a lot of interest leading to a large number of solutions, maintaining critical data in such a network remains an open issue. In this paper, we are interested in defining the portion of nodes and frequency one has to probe, given the churn observed in the system, in order to achieve a given probability of maintaining the persistence of some critical data. More specifically, we provide a clear result relating the size and the frequency of the probing set along with its proof as well as an analysis of the way of leveraging such an information in a large scale dynamic distributed system.	distributed computing;dynamical system;organizing (structure);overlay network;peer-to-peer;persistence (computer science)	Vincent Gramoli;Anne-Marie Kermarrec;Achour Mostéfaoui;Michel Raynal;Bruno Sericola	2006		10.1007/11915072_52	persistence;core;the internet;simulation;overlay network;quality of service;telecommunications;computer cluster;computer science;dynamical system;distributed computing;computer security	Networks	-11.175152526150807	70.3202761520056	116625
1924f901af3c46b86c4a4f00249be77ebf2faba4	a necessary test for fixed-priority real-time multiprocessor systems based on lazy-adversary simulation		Many embedded systems have real-time requirements which are sometimes hard and must be guaranteed at design time, although most embedded systems have soft deadlines in the sense that they can be missed without any catastrophe being caused by that. Scheduling simulations can be used as a necessary but not sufficient schedulability test that is useful for both hard and soft real-time systems. They help to assess the pessimism of formal analysis applied to hard real-time systems and they can be used as test-case generators during the design of soft real-time systems. In this paper, we present a new adversary simulator for multiprocessors with global task queue and fixed-priority scheduling. We consider sporadic tasks with constrained deadlines (D ≤ T). An adversary simulator uses the non-determinism in the arrivals of sporadic tasks to stress the system scheduler with valid arrival patterns. The simulator proposed in this paper applies a lazy approach that delays the arrival of high-priority tasks in order to form gangs that will preclude the execution of a victim task. We show that the new lazy-adversary simulator presented in this paper outperforms the previously existing necessary schedulability tests.	adversary (cryptography);algorithm;catastrophe theory;embedded system;fixed-priority pre-emptive scheduling;lazy evaluation;multiprocessing;real-time clock;real-time computing;requirement;response time (technology);scheduling (computing);simulation	Rômulo Silva de Oliveira;Andreu Carminati;Renan Augusto Starke	2014	2014 4th International Conference On Simulation And Modeling Methodologies, Technologies And Applications (SIMULTECH)		embedded system;embedded operating system;real-time computing;computer science;distributed computing	Embedded	-9.682960719245022	60.50705191032547	116760
1033b2ba440940e0a963a2588b0a7c6c78ebe0a8	energy-efficient dynamic scheduling of deadline-constrained mapreduce workflows		Big data workflows comprised of moldable parallel MapReduce programs running on a large number of processors have become a main consumer of energy at data centers. The degree of parallelism of each moldable job in such workflows has a significant impact on the energy efficiency of parallel computing systems, which remains largely unexplored. In this paper, we validate with experimental results the moldable parallel computing model where the dynamic energy consumption of a moldable job increases with the number of parallel tasks. Based on our validation, we construct rigorous cost models and formulate a dynamic scheduling problem of deadline-constrained MapReduce workflows to minimize energy consumption in Hadoop systems. We propose a semi-dynamic online scheduling algorithm based on adaptive task partitioning to reduce dynamic energy consumption while meeting performance requirements from a global perspective, and also design the corresponding system modules for algorithm implementation in Hadoop architecture. The performance superiority of the proposed algorithm in terms of dynamic energy saving and deadline violation is illustrated by extensive simulation results in Hadoop/YARN in comparison with existing algorithms, and the core module of adaptive task partitioning is further validated through real-life workflow implementation and experimental results using the Oozie workflow engine in Hadoop/YARN systems.	algorithm;apache hadoop;big data;central processing unit;data center;degree of parallelism;mapreduce;parallel computing;real life;requirement;scheduling (computing);semiconductor industry;simulation;task allocation and partitioning of social insects;workflow engine	Tong Shu;Chase Qishi Wu	2017	2017 IEEE 13th International Conference on e-Science (e-Science)	10.1109/eScience.2017.18	computer science;architecture;scheduling (computing);big data;degree of parallelism;workflow engine;algorithm design;dynamic priority scheduling;energy consumption;distributed computing	HPC	-18.02798106079571	61.643974307822695	116839
6460b99227e8f25e53dbeebde94dd329e589245a	on-line hierarchical job scheduling on grids with admissible allocation	grid scheduling;online scheduling;resource manager;resource management;scheduling algorithm;efficient implementation;competitive analysis;grid computing;job scheduling;job allocation	In this paper, we address non-preemptive online scheduling of parallel jobs on a Grid. Our Grid consists of a large number of identical processors that are divided into several machines. We consider a Grid scheduling model with two stages. At the first stage, jobs are allocated to a suitable machine, while at the second stage, local scheduling is independently applied to each machine. We discuss strategies based on various combinations of allocation strategies and local scheduling algorithms. Finally, we propose and analyze a scheme named adaptive admissible allocation. This includes a competitive analysis for different parameters and constraints. We show that the algorithm is beneficial under certain conditions and allows for an efficient implementation in real systems. Furthermore, a dynamic and adaptive approach is presented which can cope with different workloads and Grid properties.	algorithm;central processing unit;competitive analysis (online algorithm);job scheduler;job stream;scheduling (computing)	Andrei Tchernykh;Uwe Schwiegelshohn;Ramin Yahyapour;Nikolai Kuzjurin	2010	J. Scheduling	10.1007/s10951-010-0169-x	fair-share scheduling;competitive analysis;fixed-priority pre-emptive scheduling;job shop scheduling;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;resource management;job scheduler;genetic algorithm scheduling;operating system;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling;multiprocessor scheduling;proportionally fair;grid computing	HPC	-14.153601492095166	60.512009245218024	116915
6679d5a91331e832a2eb56c968182bf214341632	on storage allocation for maximum service rate in distributed storage systems	storage allocation cloud computing probability;resource management decision support systems analytical models data models probabilistic logic redundancy sections;service rate maximum service rate distributed storage systems performance measures access model data recovery service rate analysis quasiuniform storage allocation fixed size access model probabilistic access model exponential waiting time distribution storage nodes minimal spreading allocation system service rate storage budget replication method	Storage allocation affects important performance measures of distributed storage systems. Most previous studies on the storage allocation consider its effect separately either on the success of the data recovery or on the service rate (time) where it is assumed that no access failure happens in the system. In this paper, we go one step further and incorporate the access model and the success of data recovery into the service rate analysis. In particular, we focus on quasi-uniform storage allocation and provide a service rate analysis for both fixed-size and probabilistic access models at the nodes. Using this analysis, we then show that for the case of exponential waiting time distribution at individuals storage nodes, minimal spreading allocation results in the highest system service rate for both access models. This means that for a given storage budget, replication provides a better service rate than a coded storage solution.	access network;clustered file system;data recovery;memory management;time complexity	Moslem Noori;Emina Soljanin;Masoud Ardakani	2016	2016 IEEE International Symposium on Information Theory (ISIT)	10.1109/ISIT.2016.7541297	real-time computing;computer science;database	Metrics	-14.717145191543487	70.30707469611362	116926
93386e621b3cf047c8172fe3826d7afa8997e173	some considerations in using vscan disk scheduling with optimal page arrangements	disk scheduling		i/o scheduling;schedule (project management)	C.-C. Wang;Bob P. Weems	1988			real-time computing;parallel computing;distributed computing;i/o scheduling;computer science	Theory	-11.622752254122377	62.40916449904908	117021
ecff4108a480715575207f9197851e5cdeaba5e6	learning decision rules for scheduling problems: a classifier hybrid approach	decision rule;classifier hybrid approach;scheduling problem	"""The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. To our families, for their love and gratitude! Preface Grid computing has emerged as one of the most promising computing paradigms of the new millennium! This paradigm can be seen as a main facet of Sun's lemma """" The internet is the computer """" : Grid computing systems are about sharing computational resources, software and data at a large scale. Grid computing , although recent, is attracting each time more large masses of researchers, projects, applications and investment from academia and industry. We are witnessing thus an explosion in Grid research projects (Google web search returns about 2,810,000 entries for """" Grid project """" !) To make the Grid computing fully beneficial to researchers, practitioners, academia and industry, there are still plenty of issues to deal with and currently researchers are very actively investigating. One such issue is the performance requirement on the resulting Grid system or the Virtual Grid-enabled Supercomputer. Achieving high performance Grid computing requires techniques to efficiently and adaptively allocate jobs and applications to available resources in a large scale, highly heterogenous and dynamic environment. This volume presents meta-heuristics approaches for Grid scheduling problems. Due to the complex nature of the problem, meta-heuristics are primary techniques for the design and implementation of efficient Grid schedulers. The volume brings new ideas, analysis, implementations and evaluation of meta-heuristic techniques for Grid scheduling, which make this volume novel in several aspects. First, Grid scheduling is tackled as a family of problems, it takes different forms depending on system requirement, application requirements, user requirements, etc. The chapters of this volume have identified several important formulations of the problem, which we believe will serve as a reference for the researchers in the Grid computing community. Second, the selected chapters for this volume comprise a variety of successful meta-heuristic approaches including: (a) Local Search based meta-VIII Preface as with other approaches. All these approaches aim to explore the capabilities of the meta-heuristics in dealing with many facets of the Grid scheduling. This is actually the best way to deal with the complexity of the problem, in particular with its multi-objective nature. Third, the contributed chapters in the book include formal definitions …"""	computational resource;cyber-security regulation;formal system;google search;grid computing;heuristic (computer science);hyper-heuristic;job stream;programming paradigm;requirement;scheduling (computing);supercomputer;system requirements;user requirements document;web search engine	Mike R. Hilliard;Gunar E. Liepins;Gita Rangarajan;Mark R. Palmer	1989			job shop scheduling;flow shop scheduling;dynamic priority scheduling;computer science;artificial intelligence;machine learning;two-level scheduling;data mining;decision rule	HPC	-16.929799515723147	64.1421844338067	117522
d985c93917cd0a145451ec2c02c9e25d988ac368	gnort: high performance network intrusion detection using graphics processors	simd;network security;parallel programming;gpu;intrusion detection;high performance networks;pattern matching;graphics processors;intrusion detection systems;parallel programs;network intrusion detection system;intrusion detection system;open source	The constant increase in link speeds and number of threats poses challenges to network intrusion detection systems (NIDS), which must cope with higher traffic throughput and perform even more complex per-packet processing. In this paper, we present an intrusion detection system based on the Snort open-source NIDS that exploits the underutilized computational power of modern graphics cards to offload the costly pattern matching operations from the CPU, and thus increase the overall processing throughput. Our prototype system, called Gnort, achieved a maximum traffic processing throughput of 2.3 Gbit/s using synthetic network traces, while when monitoring real traffic using a commodity Ethernet interface, it outperformed unmodified Snort by a factor of two. The results suggest that modern graphics cards can be used effectively to speed up intrusion detection systems, as well as other systems that involve pattern matching operations.	algorithm;backplane;central processing unit;computation;dhrystone;direct memory access;gigabit;graphics;graphics processing unit;intrusion detection system;maximum throughput scheduling;mmap;motherboard;network interface controller;network packet;open-source software;pci express;pattern matching;prototype;simd;snort;throughput;tracing (software);user space;video card	Giorgos Vasiliadis;Spyros Antonatos;Michalis Polychronakis;Evangelos P. Markatos;Sotiris Ioannidis	2008		10.1007/978-3-540-87403-4_7	intrusion detection system;embedded system;host-based intrusion detection system;real-time computing;computer science;network security;operating system;computer security	Security	-7.370852554810449	66.31905208107753	117790
25f316c74a633ee1330432efba3b0a8c4c11d599	towards optimized packet classification algorithms for multi-core network processors	decision tree;packet classification;expcuts;multi core network processors;storage management;network processor;hsm;optimized packet classification algorithms;storage management microprocessor chips parallel processing;worst case search time;hicuts;time consuming linear search;hierarchical space aggregation;explicit cuttings;parallel processing;memory usage optimized packet classification algorithms multi core network processors explicit cuttings hierarchical space aggregation time consuming linear search expcuts hicuts hsm;memory usage;core network;microprocessor chips;classification algorithms switches application specific integrated circuits random access memory space technology spine application software central processing unit information technology automation	In this paper, a novel packet classification scheme optimized for multi-core network processors is proposed. The algorithm, Explicit Cuttings (ExpCuts), adopts a hierarchical space aggregation technique to significantly reduce the memory usage. Consequently, without burst of memory usages, the time-consuming linear search in the conventional decision-tree based packet classification algorithms is eliminated, and an explicit worst-case search time is achieved. To evaluate the performance of ExpCuts, we implement the algorithm, as well as HiCuts and HSM, on the Intel IXP2850 network processor. Experimental results show that ExpCuts outperforms the existing best- known algorithms in terms of memory usage and classification speed.	algorithm;best, worst and average case;cellular automaton;central processing unit;decision tree;linear search;multi-core processor;network packet;network processor	Yaxuan Qi;Bo Xu;Fei He;Xin Zhou;Jianming Yu;Jun Li	2007	2007 International Conference on Parallel Processing (ICPP 2007)	10.1109/ICPP.2007.82	parallel processing;parallel computing;real-time computing;core network;computer science;theoretical computer science;operating system;decision tree;network processor;computer network;hardware security module	HPC	-6.6131649521734674	66.87118739419141	117927
8a4be3313ede9e52b23f1f264693bcb1c4145196	towards green routers: depth-bounded multi-pipeline architecture for power-efficient ip lookup	memory management;clocks;routing;power efficiency;bit rate 400 gbit s depth bounded multipipeline architecture power efficient ip lookup power consumption next generation routers sram based pipeline solutions memory size chip level parallelism clock gating techniques backbone routing table memory size 4 25 mbyte;clock gating;energy consumption pipelines routing engines clocks throughput spine equations logic random access memory;chip;simulation experiment;telecommunication network routing;telecommunication network routing ip networks;pipelines;next generation;ip networks;ip lookup;power consumption;power demand;high power;high speed;pipeline processing	"""Power consumption has become a major concern in designing IP lookup engines for next generation routers. Although TCAMs dominate today's high-end routers, they are not scalable in terms of clock rate and power consumption. SRAM-based pipeline solutions are considered promising alternatives for high-speed IP lookup engines. However, existing SRAM-based pipeline architectures suffer from high power consumption in the worst cases, due to the large memory size and the long pipeline depth. This paper proposes a power-efficient SRAM-based pipelined IP lookup engine for future """"green"""" routers. Both chip-level parallelism and clock gating techniques are employed to reduce the power consumption. With the aid of small TCAMs, a two-phase scheme is proposed to partition a routing trie into a number of height-bounded subtries, which are then mapped onto multiple pipelines. Each IP lookup is completed through a bounded number of accesses on small size memories. Simulation experiments using real-life traces show that our solution can store a backbone routing table with over 200 K prefixes in 4.25 MB memory, sustains a throughput of 400 Gbps, and achieves up to 7-fold and 3-fold reductions in power consumption over the state-of-the-art TCAM-based and SRAM-based solutions, respectively."""	best, worst and average case;clock gating;clock rate;data rate units;experiment;internet backbone;lookup table;next-generation network;optical carrier transmission rates;parallel computing;performance per watt;pipeline (computing);programming paradigm;real life;router (computing);routing table;scalability;simulation;static random-access memory;telecommunications access method;throughput;tracing (software);trie;two-phase commit protocol;two-phase locking	Weirong Jiang;Viktor K. Prasanna	2008	2008 IEEE International Performance, Computing and Communications Conference	10.1109/PCCC.2008.4745147	chip;routing;parallel computing;real-time computing;electrical efficiency;telecommunications;computer science;pipeline transport;clock gating;computer network;memory management	HPC	-5.543540494418834	66.68451073190508	118000
06f43740ceb57afadb2d042d2d78f03cfbdfc868	markov tree prediction on web cache prefetching	web pages;web accessibility;simulation experiment;markov model;internet traffic;web caching;web proxy;least recently used;replacement policy	As Web accesses increase exponentially in the past decade, it is fundamentally important for Web servers to be able to minimize the latency and respond to users’ requests very quickly. One commonly used strategy is to “predict” what pages the user is likely to access in the near future so that the server can prefetch these pages and store them in a cache on the local machine, a Web proxy or a Web server. In this paper, we present an approach to effectively make page predictions and cache prefetching using Markov tree. Our method builds a Markov tree from a training data set that contains Web page access patterns of users, and make predictions for new page requests by searching the Markov tree. These predicted pages are prefetched from the server and stored in a cache, which is managed using the Least Recently Used replacement policy. Algorithms are proposed to handle different cases of cache prefetching. Simulation experiments were conducted with a real world data of a Web access log from the Internet Traffic Achieve and the results show the effectiveness of our algorithms.	algorithm;cpu cache;cache (computing);cache prefetching;experiment;internet access;link prefetching;markov chain;markov model;profiling (computer programming);proxy server;response time (technology);server (computing);simulation;test case;test set;web cache;web page;web server;world wide web	Wenying Feng;Shushuang Man;Gongzhu Hu	2009		10.1007/978-3-642-01203-7_9	static web page;data web;web analytics;internet traffic;computer science;web accessibility;web page;database;internet privacy;markov model;cache algorithms;world wide web;web server	Metrics	-17.738872187862434	71.41392970917613	118361
5f3a6799b92a8cbc4c402c691746893388d38e72	a dynamic and complexity aware cloud scheduling algorithm for video transcoding	complexity theory;resource management;monitoring;streaming media;heuristic algorithms;load balance operation cloud video transcoding dynamic slot allocation complexity aware scheduler;load balance complexity aware cloud scheduling algorithm video transcoding cloud video processing heterogeneous network scalable video coding task scheduling algorithm hadoop mapreduce platform homogeneous node processing capability dynamic adjustment slot and complexity aware scheduler dascas algorithm video segment distributed computer cluster;video coding cloud computing telecommunication scheduling;transcoding;cloud computing;transcoding streaming media resource management complexity theory cloud computing monitoring heuristic algorithms	Cloud video processing and streaming services has to be delivered under heterogeneous network and device environments. Scalable video coding and transcoding are required to serve heterogeneous users. As the task scheduling algorithm pre-configures a Hadoop MapReduce platform with the assumption of homogeneous node processing capability and task complexity, it cannot well accommodate the practical heterogeneous resources and tasks. In this research, we proposed a Dynamic Adjustment Slot and Complexity Aware Scheduler (DASCAS) algorithm to assign tasks under heterogeneous resources and tasks environments. Complexities of decomposed video segments are evaluated for setting task priority. The scheduling algorithm utilizes a speculative mechanism to detect potential late tasks to re-assign to other nodes for fast processing. It also monitors processing status of the distributed computer cluster and dynamically adjust the number of slots for load balance operations. Experiments show that the proposed method can reduce the transcoding time to 14%~24% smaller and improve the resource utilization rates to 2%~12% higher.	algorithm;apache hadoop;computer cluster;data compression;experiment;load balancing (computing);mapreduce;scalable video coding;scheduling (computing);speculative execution;video processing	Ching-Cheng Huang;Jiann-Jone Chen;Yao-Hong Tsai	2016	2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)	10.1109/ICMEW.2016.7574743	real-time computing;transcoding;cloud computing;computer science;resource management;operating system;distributed computing;computer network	HPC	-17.04544653277001	62.51790091240032	118532
ffd87332dce1005d4860c01839cea7ef24b425f3	an improved greedydual cache document replacement algorithm	simulation;utility function;greedydual;performance metric;delay internet web server frequency measurement network servers file systems information science telecommunication traffic fault tolerant systems;algorithm;cache replacement;simulation web caching greedydual cache replacement algorithm;web caching	Web caching is an important technique for reducing web traffic, user access latency, and server load and cache replacement plays an important role in the functionality of web caching. In this paper we propose an improved GreedyDual (GD) cache document replacement algorithm, which considers update frequency as a factor in its utility function. We use both trace data and statistical data to simulate our proposed algorithm. The experimental results show that our improved GD algorithm can outperform the existing GD algorithm over the performance metrics considered.	page replacement algorithm;server (computing);simulation;utility;web cache;web traffic	Keqiu Li;Hong Shen	2004	IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)	10.1109/WI.2004.27	cache-oblivious algorithm;real-time computing;cache;computer science;database;adaptive replacement cache;smart cache;cache algorithms;world wide web	DB	-17.804449968206537	70.11890311365318	118562
dfc535eae913423062345bd95df1cbc89b5b30b4	a general scalable and elastic content-based publish/subscribe service	routing;content distribution general scalability elastic content based publish subscribe service pub sub model big data era internet scale cloud computing environment multihop routing techniques coarse grained partitioning techniques hybrid space partitioning technique helper based content distribution technique performance aware provisioning technique churn workloads cloudstack based testbed event matching;servers;content distribution;humidity;publish subscribe;clustering algorithms;subscriptions;scalability;subscriptions servers routing clustering algorithms throughput scalability humidity;event matching;network routing big data message passing middleware;space partitioning;cloud computing;throughput	The big data era is characterized by the emergence of live content with increasing complexities of data dimensionality and data sizes, which poses a new challenge to emergency applications: how to timely disseminate large-scale live content to users who are interested in. The publish/subscribe (pub/sub) model is widely used to disseminate data because of its possibility of expanding the system to Internet-scale size. However, existing pub/sub systems are inadequate to meet the requirement of disseminating live content in the big data era, since their multi-hop routing techniques and coarse-grained partitioning techniques lead to a low matching throughput, and their upload capacities do not scale well. In this paper, we propose a general scalable and elastic pub/sub service based on the cloud computing environment, called GSEC. For generality, we propose a two-layer pub/sub framework to support the dissemination with diverse data sizes and data dimensionality. For scalability, a hybrid space partitioningtechnique is proposed to achieve high matching throughput, which divides subscriptions into multiple clusters in a hierarchical manner. Moreover, a helper-based content distribution technique is proposed to achieve high upload bandwidth, where servers act as both providers and coordinators to fully explore the upload capacity of the system. For elasticity, we propose a performance-aware provisioningtechnique to adjust the scale of servers to adapt to the churn workloads. To evaluate the performance of GSEC, about 1,000 servers are deployed and hundreds of thousands of live content items are tested in our CloudStack-based testbed. Extensive experiments confirm that GSEC can linearly increase the capacities of event matching and content distribution with the growth of servers, adaptively adjust these capacities in tens of seconds according to the churn workloads, and significantly outperforms the state-of-the-art approaches under various parameter settings.	big data;cloud computing;digital distribution;elasticity (cloud computing);emergence;experiment;publish–subscribe pattern;routing;scalability;testbed;throughput;upload	Yijie Wang;Xingkong Ma	2015	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2014.2346759	routing;throughput;parallel computing;real-time computing;scalability;cloud computing;computer science;space partitioning;operating system;humidity;database;distributed computing;publish–subscribe pattern;cluster analysis;world wide web;computer security;server;computer network	DB	-13.36120019737829	72.68682867619191	118601
375c822c2e8b7eb232fbdc9f48483fa08d5b72cb	effect of job size characteristics on job scheduling performance	workload;parallelisme;distributed system;evaluation performance;systeme reparti;performance evaluation;multiprocessor;evaluacion prestacion;effet dimensionnel;parallelism;sistema repartido;paralelismo;scheduling;size effect;charge travail;parallel computer;ordonamiento;efecto dimensional;multiprocesador;carga trabajo;job scheduling;ordonnancement;multiprocesseur	A workload characteristic on a parallel computer depends on an administration policy or a user community for the computer system. An administrator of a parallel computer system needs to select an appropriate scheduling algorithm that schedules multiple jobs on the computer system e ciently. The goal of the work presented in this paper is to investigate mechanisms how job size characteristics a ect job scheduling performance. For this goal, this paper evaluates the performance of job scheduling algorithms under various workload models, each of which has a certain characteristic related to the number of processors requested by a job, and analyzes the mechanism for job size characteristics that a ect job scheduling performance signi cantly in the evaluation. The results showed that: (1) most scheduling algorithms classi ed into the rstt scheduling showed best performance and were not a ected by job size characteristics, (2) certain job size characteristics a ected performance of priority scheduling signi cantly. The analysis of the results showed that the LJF algorithm, which dispatched the largest job rst, would perfectly pack jobs to idle processors at high load, where all jobs requested power-of-two processors.	algorithm;central processing unit;computer;job queue;job scheduler;job shop scheduling;job stream;monic polynomial;parallel computing;performance evaluation;power of two;scheduling (computing);virtual community	Kento Aida	2000		10.1007/3-540-39997-6_1	fair-share scheduling;job shop scheduling;parallel computing;real-time computing;earliest deadline first scheduling;multiprocessing;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;job scheduler;operating system;job stream;job queue;least slack time scheduling;lottery scheduling;scheduling;multiprocessor scheduling	HPC	-13.173265579220187	62.93014738113154	119187
10970cc2dfaf81d28b32130aca776ae9a606abf0	optimization of resources in parallel systems using a multiobjective artificial bee colony algorithm		Most of the approaches to achieve exascale computing heavily rely on designing power efficient hardware, but experts usually forget that the usage of efficient middlewares, like resource managers or job schedulers, can also play an important role in optimizing power and performance of supercomputing infrastructures. For the optimization of both, power and performance, we propose the implementation of a multiobjective version of artificial bee colony algorithm (MOABC). We have compared our algorithm with other deterministic (first-fit and MOHEFT) and stochastic (NSGA-II) resource selection approaches. The results of our simulations show that, in real computing environments, MOABC is more likely to obtain better optimizations of response times and power consumption.	artificial bee colony algorithm;mathematical optimization;program optimization;simulation;supercomputer	César Gómez-Martín;Miguel A. Vega-Rodríguez	2018	The Journal of Supercomputing	10.1007/s11227-018-2407-5	parallel computing;distributed computing;artificial bee colony algorithm;computer science;multi-objective optimization;exascale computing;supercomputer	HPC	-17.726753034959653	60.98717829028249	119408
e7af67064d4118f437a5c5bce0f738db985403f1	maintaining mobile transactional consistency in hybrid broadcast environments	tiempo respuesta;tratamiento transaccion;informatique mobile;mobile transactional consistency;compuesto push pull;consistance transactionnelle mobile;radiodifusion;mobile computer;response time;calculo automatico;68wxx;compose push pull;computing;algorithme;calcul automatique;temps reponse;algorithm;push pull compound;informatique theorique;simulation study;broadcasting;transaction processing;mobile computing;radiodiffusion;data dissemination;traitement transaction;computer theory;algoritmo;informatica teorica	Recently there have been attempts in several research areas at efficiently utilizing the resources of mobile computers. Considering the properties in mobile computing environments, push-based data dissemination systems have lately attracted considerable attention. However, skewed access patterns among mobile clients makes response time worse, and they prefer to send data requests to the server explicitly through an uplink channel. A broadcast supporting an uplink channel is called a hybrid broadcast. In this paper, we devise new transaction processing algorithms for hybrid broadcasts. It is assumed that data objects that the server maintains are divided into Push_Data for periodic broadcasting and Pull_Data for on-demand service. That is, clients have to explicitly request data objects in Pull_Data. Maintaining transactional consistency in this environment without much additional cost is our main concern. Finally, we evaluate performance behavior through simulation study.	algorithm;client (computing);computer;datacasting;mobile computing;optimization problem;response time (technology);server (computing);simulation;telecommunications link;throughput;transaction processing	SungSuk Kim;Sun Ok Yang;SangKeun Lee	2003	Acta Informatica	10.1007/s00236-003-0142-7	embedded system;computing;real-time computing;transaction processing;computer science;distributed computing;mobile computing;response time;broadcasting	DB	-14.390318261589995	68.97122734753741	119636
a720d5feb480dbe7ce16a7c81adbe7630d972d48	on-demand overlay networking of collaborative applications	collaborative applications;groupware;collaborative nodes;routing tables;soft state mechanisms;probability;collaborative work;fault tolerant;distributed hash table;collaborative application;distributed hash table on demand overlay networking collaborative applications generic identifier network collaborative nodes organizational local namespaces organizational information dissemination external security attacks probability heuristic algorithms routing tables soft state mechanisms fault tolerance;maintenance cost;external security attacks;security of data computer networks fault tolerant computing file organisation groupware information dissemination;organizational information dissemination;computer networks;computer fault tolerance;organizational local namespaces;generic identifier network;fault tolerant computing;collaboration peer to peer computing uniform resource locators application software computer science fault tolerance web services scalability laboratories merging;heuristic algorithms;on demand overlay networking;fault tolerance;information dissemination;overlay network;high performance;security of data;heuristic algorithm;file systems;file organisation;data security	We propose a new overlay network, called Generic Identifier Network (GIN), for collaborative nodes to share objects with transactions across affiliated organizations by merging the organizational local namespaces upon mutual agreement. Using local namespaces instead of a global namespace can avoid excessive dissemination of organizational information, reduce maintenance costs, and improve robustness against external security attacks. GIN can forward a query with an O(1) latency stretch with high probability and achieve high performance. In the absence of a complete distance map, its heuristic algorithms for self configuration are scalable and efficient. Routing tables are maintained using soft-state mechanisms for fault tolerance and adapting to performance updates of network distances. Thus, GIN has significant new advantages for building an efficient and scalable distributed hash table for modern collaborative applications across organizations	algorithm;distance transform;distributed hash table;fault tolerance;global namespace;heuristic;identifier;overlay network;routing table;scalability;soft state;with high probability	Cheng-Jia Lai;Richard R. Muntz	2005	2005 International Conference on Collaborative Computing: Networking, Applications and Worksharing	10.1109/COLCOM.2005.1651211	fault tolerance;computer science;operating system;database;distributed computing;world wide web;computer security;computer network	HPC	-11.037631584575507	73.98766467068734	119808
1e99fd949ecdbb9ff390053ca1d8f08a63400550	scheduling despite inexact job-size information	queueing;performance guarantee;smart;response time;scheduling;job size estimates;srpt;upper and lower bounds;shortest remaining processing time;m g 1;conditioned response	"""Motivated by the optimality of Shortest Remaining Processing Time (SRPT) for mean response time, in recent years many computer systems have used the heuristic of """"favoring small jobs"""" in order to dramatically reduce user response times. However, rarely do computer systems have knowledge of exact remaining sizes. In this paper, we introduce the class of ε-SMART policies, which formalizes the heuristic of """"favoring small jobs"""" in a way that includes a wide range of policies that schedule using inexact job-size information. Examples of ε-SMART policies include (i) policies that use exact size information, e.g., SRPT and PSJF, (ii) policies that use job-size estimates, and (iii) policies that use a finite number of size-based priority levels.  For many ε-SMART policies, e.g., SRPT with inexact job-size information, there are no analytic results available in the literature. In this work, we prove four main results: we derive upper and lower bounds on the mean response time, the mean slowdown, the response-time tail, and the conditional response time of ε-SMART policies. In each case, the results explicitly characterize the tradeoff between the accuracy of the job-size information used to prioritize and the performance of the resulting policy. Thus, the results provide designers insight into how accurate job-size information must be in order to achieve desired performance guarantees."""	computer;heuristic;response time (technology);scheduling (computing);shortest remaining time	Adam Wierman;Misja Nuyens	2008		10.1145/1375457.1375461	classical conditioning;mathematical optimization;real-time computing;computer science;operating system;smart criteria;upper and lower bounds;queueing theory;scheduling;response time	Metrics	-8.592478668797686	61.5742240441081	119942
3b3d94937b521de6784874eff092b18b57d3fba9	distributed load balancing for the resilient publish/subscribe overlay in sedax	overlay networks;resource management;data redundancy distributed load balancing resilient publish subscribe overlay sedax secure data centric application extension publish subscribe information centric networking architecture delaunay triangulated overlay network distributed resource management system resilient data forwarding;peer to peer computing load management resilience servers overlay networks computer architecture resource management;computer architecture;servers;resilience;security of data internet mesh generation message passing resource allocation;load management;peer to peer computing;performance evaluation sedax smart grid communication publish subscribe information centric networking load balancing optimization	SEcure data-centric application eXtension (SeDAX) is a publish/subscribe information-centric networking architecture, where publishers send messages to the appropriate message broker over a Delaunay-triangulated overlay network. Resilient data forwarding and data redundancy enable a high level of reliability. Overlay nodes and topics are addressed via geo-coordinates. A topic is stored on primary and secondary nodes, those nodes closest and second-closest to the topic’s coordinate, respectively. The overlay automatically reroutes a topic’s messages to its secondary node should its primary node fail. In the original proposal, SeDAX determines the coordinate of a topic by hashing its name. This kind of topic allocation is static, which can lead to unintended load imbalances. We propose a topic delegation mechanism to make the assignment of topics to nodes dynamic. Our proposed mechanism is the only existing method to improve the flexibility and resource management of the SeDAX architecture so far. We define three resilience levels that allow information on the SeDAX overlay to survive 0, 1, or 2 node failures, imposing different loads on SeDAX nodes. For this elaborated SeDAX approach, we suggest a distributed resource management system that detects traffic imbalances among SeDAX nodes and re-assigns topics to other coordinates for load balancing purposes. We evaluate the load imbalance for the different resilience levels, for different topic characteristics, and in particular for topics with storage requirements growing over time. The proposed algorithm leads to well balanced load on SeDAX nodes while keeping load redistribution at a reasonable level.	algorithm;data redundancy;delaunay triangulation;geographic coordinate system;high-level programming language;job scheduler;load balancing (computing);message broker;operand forwarding;overlay network;publish–subscribe pattern;requirement	Michael Hoefling;Cynthia G. Mills;Michael Menth	2017	IEEE Transactions on Network and Service Management	10.1109/TNSM.2016.2647678	overlay network;computer science;resource management;operating system;distributed computing;world wide web;server;computer network	HPC	-12.019691014435786	72.99978744029568	120032
8430ad65d26a915151152be88f846a0567b4187d	a high efficient task scheduling algorithm based on heterogeneous multi-core processor	directed graphs;optimisation;multi core processor;complexity theory;performance evaluation;clustering algorithm;processor scheduling;task scheduling algorithm;heterogeneous multicore processor;program processors algorithm design and analysis scheduling scheduling algorithm clustering algorithms complexity theory;dag graph;scheduling algorithm;processor scheduling directed graphs multiprocessing systems optimisation performance evaluation;scheduling;clustering algorithms;multiprocessing systems;task graphs;task scheduling;high performance;high efficiency;hcddsl;program processors;algorithm design and analysis;task duplication;heuristic algorithm;heuristic algorithm task scheduling algorithm heterogeneous multicore processor hcddsl dag graph clustering algorithm task duplication	Task scheduling is an important part of high performance multi-core building. The shortcomings of existing task scheduling algorithms is analyzed, and a new efficient heuristic task scheduling algorithm, namely,HCDDSL is proposed in this paper. Firstly, the new algorithm optimizes DAG graph by using clustering, then the nodes are descended by the values of Succ_sum,the task schedule has been processed in the case of insert interval and task duplication are considered. The weight of task in the DAG is considered in the process of schedule. By this means, the result of task schedule is optimized effectively,and the makespan of all tasks is reduced also.The proposed task scheduling algorithm has been analyzed through simulation, the results show that compare to old scheduling algorithm,this new algorithm can shorten the scheduling length of the task graph greatly.	algorithm;cluster analysis;directed acyclic graph;heuristic;makespan;multi-core processor;scheduling (computing);simulation	Hui Cheng	2010	2010 2nd International Workshop on Database Technology and Applications	10.1109/DBTA.2010.5659041	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;machine learning;two-level scheduling;distributed computing;cluster analysis;round-robin scheduling;scheduling;interval scheduling	HPC	-14.717743337776374	61.25031139370258	120037
36c0754e85995f15a7404c36271693340fb985e2	hybrid task scheduling: integrating static and dynamic heuristics	directed graphs;dynamic scheduler hybrid task scheduling distributed system compile time static scheduling run time cost estimation;distributed system;parallel processing processor scheduling directed graphs resource allocation;processor scheduling;resource allocation;low complexity;dynamic scheduling processor scheduling runtime scheduling algorithm costs distributed computing computer architecture computational efficiency grid computing clustering algorithms;list scheduling;task scheduling;parallel applications;parallel processing;dynamic scheduling	Researchers are constantly looking for ways to improve the execution time of parallel applications on distributed systems. Although compile-time static scheduling heuristics employ complex mechanisms, the quality of their schedules are handicapped by estimated run-time costs. On the other hand, while dynamic schedulers use actual run-time costs, they have to be of low complexity in order to reduce the scheduling overhead. This paper investigates the viability of integrating these two approaches into a hybrid scheduling framework. The relationship between static schedulers, dynamic heuristics and scheduling events are examined. The results show that a hybrid scheduler can indeed improve the schedules produced by good traditional static list schedul-	central processing unit;compile time;compiler;computer architecture;degree confluence project;distributed computing;heterogeneous earliest finish time;heuristic (computer science);hybrid kernel;overhead (computing);run time (program lifecycle phase);schedule (project management);scheduling (computing)	Cristina Boeres;Alexandre Lima;Vinod E. F. Rebello	2003		10.1109/CAHPC.2003.1250339	fair-share scheduling;nurse scheduling problem;generalized processor sharing;fixed-priority pre-emptive scheduling;parallel processing;parallel computing;real-time computing;earliest deadline first scheduling;directed graph;gang scheduling;flow shop scheduling;dynamic priority scheduling;resource allocation;computer science;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;scheduling;least slack time scheduling;instruction scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling	HPC	-14.77775074265739	61.34446493628101	120143
da9751a2bbdf9984f4bc17076e453852b57d17a3	integrating real-time inter-task communication channels into hardware-software codesign	communication channel;hardware software codesign;real time;real time processing;real time embedded system;system on chip;periodic tasks;system design;inter task communication;experimental evaluation;coarse grained;communication channels;time constraint	Codesign in system on chip (SoC) systems is a joint development of hardware and software tasks to obtain a complete system design. Especially, a key problem in the hardware-software codesign for real-time embedded systems is related to the time-bounded communication channel that guarantees the deadlines of tasks, as well as the timely delivery of messages exchanged between tasks. This paper presents a technique to integrate a real-time inter-task communication channel into hardware-software codesign. The real-time inter-task communication channel presented in this paper is addressed from two perspectives: a unified inter-task communication interface and a combined task and message scheduling scheme. From the perspective of an inter-task communication interface, we consider three possible inter-task communication associations, software-to-software, software-to-hardware, and hardware-to-hardware task communication associations. Tasks and messages exploited in real-time inter-task communications are allowed to have periodic and aperiodic properties. In the unified inter-task communication interface, coarse-grained real-time processing is allowed at a level of task unit and fine-grained real-time processing is allowed at a piece of message frame unit. Consequently, periodic tasks and messages need to be timely processed and delivered to meet their deadlines, and aperiodic tasks and messages need to be quickly processed for fast response without missing periodic task and message deadlines. We present a novel scheduling policy from the perspective of the combined task and message scheduling scheme. In the scheduling policy, the first objective is to meet the timing constraints of periodic tasks as well as periodic messages simultaneously for given application-specific real-time requirements. The second objective is to improve the response time of aperiodic messages. We evaluated the performance of the proposed technique after implementing it on a commercial SoC platform. The experimental evaluation showed it yielded efficient performance in terms of the minimal deadline miss ratio of periodic tasks and messages, and a fast average response time for aperiodic messages.		Sungwoo Tak;Taehoon Kim;E. K. Park	2010	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2010.04.002	embedded system;parallel computing;real-time computing;computer science;operating system;distributed computing;channel	EDA	-7.6964845954261	60.73371149958981	120295
325f07d8a0c011d1401f49af2522f5d95a9d7baf	distributed and multiprocessor scheduling	cpu scheduling;multiprocessor scheduling;queue length;operating system;parallel systems;adaptive learning;load balance;distributed systems;resource allocation problems	In parallel and distributed systems, CPU scheduling is part of a broader class of resource allocation problems, and is probably the most carefully studied. The scheduling problem for multiprocessor systems can be generally stated as “How can we execute a set of tasks T on a set of processors P subject to some set of optimizing criteria C?” The most common goal of scheduling is to minimize the expected run time of a task set. Examples of other scheduling criteria include minimizing the cost, minimizing communication delay, and giving priority to certain users’ processes or needs for specialized hardware devices. The scheduling policy for a multiprocessor system usually involves several of these criteria.	central processing unit;distributed computing;multiprocessing;multiprocessor scheduling;run time (program lifecycle phase);scheduling (computing)	Steve J. Chapin	1996		10.1145/234313.234410	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;load balancing;operating system;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;scheduling;gain scheduling;lottery scheduling;round-robin scheduling;scheduling;adaptive learning;multiprocessor scheduling;i/o scheduling	Embedded	-12.34580485932526	60.95178381373549	120528
8de2968ac4b94f26fd5a56e6bf3d4aea995b365f	reliability design for large scale storage systems	analytical models;reliability engineering;reliability;storage system;data integrity;storage management;niobium;inter dependent system parameters;reliability modeling;maintenance engineering;large scale storage system data reliability reliability model;large scale storage systems;large scale;dependable systems;artificial neural networks;storage management data integrity;data reliability;bandwidth;reliability design;large scale storage system;object based repairing analytic model reliability design large scale storage systems data reliability inter dependent system parameters replica placement policies;replica placement policies;large scale systems switches reliability engineering design engineering systems engineering and theory computer science telecommunications internet search engines scientific computing;analytical model;object based repairing analytic model;reliability model	Data reliability are drawn much concern in large-scale storage systems built from thousands of storage devices, which highly depends on many inter-dependent system parameters, such as the replica placement policies, number of stored objects and so on. Previous work has discussed the impacts of these system parameters on reliability roughly and separately, and seldom provided their optimal values, nor mentioned their optimal combination. In this paper, we present a new object-based-repairing analytic model. Based on analyzing this model in three popular replica placement policies, we figure out the individual optimal values of these parameters at the beginning, and then work out their optimal combination. Compared with the existing models, our model is easier to solve while reaching more integrative and practical conclusions. These conclusions can directly and effectively instruct the designers to build more reliable storage systems.	glossary of computer graphics;object-based language;replication (computing)	Kai Du;Huaimin Wang;Shuqiang Yang;Yingwen Chen;Yan Wen	2008	2008 11th IEEE High Assurance Systems Engineering Symposium	10.1109/HASE.2008.48	maintenance engineering;reliability engineering;niobium;computer science;engineering;data integrity;data mining;reliability;database;bandwidth	Embedded	-10.129234349686056	71.67284208327322	120561
8efc3f1bd48dffc0c10cb5baae0117bbfce7f351	broadband packet switch processor	mode transfert asynchrone;architecture systeme;wide band;resource management;telecomunicacion via satelite;packet switching;conmutacion por paquete;telecommunication par satellite;large bande;gestion recursos;scheduling;gestion ressources;arquitectura sistema;ordonamiento;banda ancha;procesador;processeur;system architecture;satellite telecommunication;commutation paquet;processor;ordonnancement;asynchronous transfer mode;modo transferencia asincrono	This paper presents an overview of the architecture for a broadband, high-speed packet switch processor used in the TRW Gen*Star system. The first application of the Gen*Star design is the Astrolink program. TRW is currently in production of the 4th generation of digital communications processors. Features and benefits of several key capabilities of the processor design for space applications are presented in this paper. The high-speed packet switch processor uses standard asynchronous transfer mode (ATM) cell structure, which conveys all the Quality of Service (QoS) characteristics of ATM to the Gen*Star network. A non-blocking crossbar switch with overspeed and input arbitration optimizes switch performance and alleviates output port contention. The downlink has output priority queues with programmable downlink scheduling and adaptive coding that provides maximum flexibility for traffic control and QoS. The resource control function is a distributed architecture using a two-layer approach that maximizes performance vs. weight and power.	network packet;packet switching	Steve Mishima;Lisa Moy-Yee;Gefferie Yee-Madera;Esmaell Yousefi	2002	Space Communications		embedded system;real-time computing;telecommunications;computer science;engineering;resource management;asynchronous transfer mode;scheduling;packet switching;computer network;systems architecture	Networks	-5.691848764052085	72.86772956607255	120573
08d82186935bb6fc3e1f7c24a61221804a322ed3	a fast and compact method for unveiling significant patterns in high speed networks	heavy hitters;telecommunication traffic computer architecture file organisation internet statistical analysis;per ip statistics tracking;per flow statistics tracking;heavy changers;internet traces high speed networks network traffic pattern identification network anomaly detection per ip statistics tracking per flow statistics tracking computational overhead memory overhead generalized sequential hashing computer architectures heavy hitters heavy changers;high speed networks;efficient algorithm;high speed networks monitoring telecommunication traffic bandwidth usa councils computer networks cost function event detection traffic control predictive models;network traffic pattern identification;memory overhead;computer architectures;computer architecture;generalized sequential hashing;telecommunication traffic;internet;statistical analysis;theoretical analysis;network traffic;computational overhead;internet traces;network anomaly detection;file organisation	Identification of significant patterns in network traffic, such as IPs or flows that contribute large volume (heavy hitters) or introduce large changes (heavy changers), has many applications in accounting and network anomaly detection. As network speed and the number of flows grow rapidly, tracking per-IP or per-flow statistics becomes infeasible due to both the computational overhead and memory requirements. In this paper, we propose a novel sequential hashing scheme that requires only O(H log N) both in memory and computational overhead that are close to being optimal, where N is the the number of all possible keys (e.g., flows, IPs) and H is the maximum number of heavy keys. Moreover, the generalized sequential hashing scheme makes it possible to trade off among memory, update cost, and detection cost in a large range that can be utilized by different computer architectures for optimizing the overall performance. In addition, we also propose statistically efficient algorithms for estimating the values of heavy hitters and heavy changers. Using both theoretical analysis and experimental studies of Internet traces, we demonstrate that our approach can achieve the same accuracy as the existing methods do but using much less memory and computational overhead.	algorithm;anomaly detection;computation;computer architecture;hash function;internet;network traffic control;overhead (computing);requirement;simulation;tracing (software)	Tian Bu;Jin Cao;Aiyou Chen;Patrick P. C. Lee	2007	IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications	10.1109/INFCOM.2007.220	real-time computing;the internet;simulation;telecommunications;computer science;operating system;overhead;computer network	Metrics	-8.14825669577115	68.28222885729896	120748
30f4967ab1191c579e22f379daf091080a945412	a sram-based architecture for trie-based ip lookup using fpga	unbalanced memory allocation;internet protocol;packet input order sram based bidirectional optimized linear pipeline architecture trie based ip lookup rate internet protocol fpga unbalanced memory allocation ip routers biolp tree based search engines field programmable gate array perfectly balanced memory distribution pipeline stages caching process internet traffic locality;cache storage;field programmable gate array;search engine;internet traffic locality;random access memory;longest prefix matching;clocks;routing;search engines;ip address lookup;sram based bidirectional optimized linear pipeline architecture;biolp;tree based search engines;fpga;trees mathematics;field programmable gate array fpga;pipeline stages;trees mathematics cache storage field programmable gate arrays ip networks pipeline processing search engines sram chips table lookup telecommunication network routing telecommunication traffic;field programmable gate array fpga ip address lookup longest prefix matching reconfigurable hardware;packet input order;telecommunication traffic;internet traffic;internet;telecommunication network routing;trie based ip lookup rate;energy consumption;pipelines;caching process;field programmable gate arrays pipeline processing throughput search engines clocks internet random access memory energy consumption hardware routing;field pro grammable gate array;ip networks;ip lookup;memory allocation;field programmable gate arrays;high throughput;table lookup;reconfigurable hardware;ip routers;pipeline processing;perfectly balanced memory distribution;throughput;hardware;sram chips	Internet Protocol (IP) lookup in routers can be implemented by some form of tree traversal. Pipelining can dramatically improve the search throughput. However, it results in unbalanced memory allocation over the pipeline stages. This has been identified as a major challenge for pipelined solutions. In this paper, an IP lookup rate of 325 MLPS (millions lookups per second) is achieved using a novel SRAM-based bidirectional optimized linear pipeline architecture on Field Programmable Gate Array, named BiOLP, for tree-based search engines in IP routers. BiOLP can also achieve a perfectly balanced memory distribution over the pipeline stages. Moreover, by employing caching to exploit the Internet traffic locality, BiOLP can achieve a high throughput of up to 1.3 GLPS (billion lookups per second). It also maintains packet input order, and supports route updates without blocking subsequent incoming packets.	blocking (computing);field-programmable gate array;locality of reference;lookup table;network packet;pipeline (computing);static random-access memory;throughput;tree traversal;trie;unbalanced circuit;web search engine	Hoang Le;Weirong Jiang;Viktor K. Prasanna	2008	2008 16th International Symposium on Field-Programmable Custom Computing Machines	10.1109/FCCM.2008.9	embedded system;parallel computing;real-time computing;computer science;operating system;search engine;field-programmable gate array;computer network	Networks	-5.9207901008498105	66.6644414257943	120972
1cac7ff39678266fad1ffe323e2409b6fb6cc431	on adding bloom filters to longest prefix matching algorithms	routing protocols;generators;longest prefix matching;memory management;bloom filter;bloom filters binary search parallel multiple hashing algorithm performance evaluation level algorithm parallel multiple hashing algorithm pmh algorithm dynamic random access memory dram static random access memory sram hardware architectures fast parallel matching ternary content addressable memory technology tcam technology internet routers wire speed packet forwarding internet protocol ip address lookup prefix matching algorithms;routing;ip address lookup;ip networks indexes generators system on a chip memory management routing;system on a chip;indexes;internet;binary search on levels;data structures;sram chips data structures dram chips internet routing protocols;router;ip networks;leaf pushing;multihashing;binary search on levels ip networks indexes generators system on a chip memory management routing leaf pushing internet router ip address lookup longest prefix matching bloom filter multihashing;dram chips;sram chips	High-speed IP address lookup is essential to achieve wire-speed packet forwarding in Internet routers. Ternary content addressable memory (TCAM) technology has been adopted to solve the IP address lookup problem because of its ability to perform fast parallel matching. However, the applicability of TCAMs presents difficulties due to cost and power dissipation issues. Various algorithms and hardware architectures have been proposed to perform the IP address lookup using ordinary memories such as SRAMs or DRAMs without using TCAMs. Among the algorithms, we focus on two efficient algorithms providing high-speed IP address lookup: parallel multiple-hashing (PMH) algorithm and binary search on level algorithm. This paper shows how effectively an on-chip Bloom filter can improve those algorithms. A performance evaluation using actual backbone routing data with 15,000-220,000 prefixes shows that by adding a Bloom filter, the complicated hardware for parallel access is removed without search performance penalty in parallel-multiple hashing algorithm. Search speed has been improved by 30-40 percent by adding a Bloom filter in binary search on level algorithm.	binary search algorithm;bloom filter;computer memory;content-addressable memory;data structure;hash function;hash table;internet backbone;kilobyte;longest prefix match;lookup table;megabyte;network packet;performance evaluation;routing;single-access key;static random-access memory;telecommunications access method;trie	Hyesook Lim;Kyuhee Lim;Nara Lee;Kyong-Hye Park	2014	IEEE Transactions on Computers	10.1109/TC.2012.193	system on a chip;database index;embedded system;routing;parallel computing;the internet;data structure;computer science;theoretical computer science;bloom filter;routing protocol;programming language;longest prefix match;computer network;memory management	Metrics	-5.774065488481686	66.78154213757776	121188
e081c615324b322849cddaa6d939305f603a79c7	building effective mutual exclusion services for grids	distributed system;cluster algorithm;evaluation performance;service composition;haute performance;systeme reparti;grid 5000;performance evaluation;composition;pruning tree;evaluacion prestacion;distributed mutual exclusion algorithm;token protocol;distributed computing;service web;supercomputer;web service;poda;protocole jeton;service;exclusion mutual;mutual exclusion;grid;supercomputador;sistema repartido;heterogeneidad;rejilla;algorithme reparti;retard;alto rendimiento;grille;calculo repartido;algoritmo repartido;distributed mutual exclusion;mutual exclusion service;exclusion mutuelle;retraso;distributed algorithm;elagage;high performance;calcul reparti;protocolo testigo;superordinateur;heterogeneity;servicio web;heterogeneite	Taking into account the intrinsic heterogeneity of communication latency of grid environments, we propose in this article a composition approach that enables to build mutual exclusion services for grids. By using our approach, different intra and inter cluster token-based mutual exclusion algorithms can be combined easily. Performance evaluation tests were conducted on the French national grid testbed called Grid’5000, whose results show that our approach is effective and that the choice of the most suitable inter cluster algorithm depends on the behavior of the application.	algorithm;degree of parallelism;emulator;experiment;logical topology;mutual exclusion;parallel computing;performance evaluation;ring network;scalability;suzuki-kasami algorithm;tadao kasami;testbed;topological graph theory	Julien Sopena;Luciana Arantes;Fabrice Legond-Aubry;Pierre Sens	2008	The Journal of Supercomputing	10.1007/s11227-008-0235-8	web service;composition;distributed algorithm;supercomputer;service;mutual exclusion;computer science;heterogeneity;distributed computing;suzuki-kasami algorithm;grid;world wide web;computer security	HPC	-10.476602672676712	69.89319135988643	121525
17bbd2b72fef1eeff0c29e95c3c8d6928a543792	the cyclone server architecture: streamlining delivery of popular content	popularity;fec;erasure code;tcp;cache memory;satisfiability;webserver;concurrency;forward error correction;design and implementation;tornado codes;technical report;sliding window;digital fountain	We propose a new technique for efficiently delivering popular content from information repositories with bounded file caches. Our strategy relies on the use of fast erasure codes (a.k.a. forward error correcting codes) to generate encodings of popular files, of which only a small sliding window is cached at any time instant, even to satisfy an unbounded number of asynchronous requests for the file. Our approach capitalizes on concurrency to maximize sharing of state across different request threads while minimizing cache memory utilization. Additional reduction in resource requirements arises from providing for a lightweight version of the network stack. In this paper, we describe the design and implementation of our approach as a Linux kernel subsystem.	cpu cache;concurrency (computer science);correctness (computer science);cyclone;digital distribution;erasure code;error detection and correction;experiment;forward error correction;linux;maximal set;network packet;protocol stack;reed–solomon error correction;requirement;scalability;server (computing);vii;web server	Stanislav Rost;John W. Byers;Azer Bestavros	2002	Computer Communications	10.1016/S0140-3664(01)00412-1	erasure code;sliding window protocol;parallel computing;real-time computing;concurrency;cpu cache;telecommunications;computer science;technical report;operating system;transmission control protocol;tornado code;distributed computing;forward error correction;zeta-tcp;tcp acceleration;computer security;web server;computer network;satisfiability	OS	-16.399196891564305	72.34603946531264	122149
007e039142caf130567dc1eedc9f31f1de3c0951	t-man: gossip-based fast overlay topology construction	application development;red superpuesta;gossip based protocols;empirical analysis;distributed hash table;self organizing middleware;par a par;reseau ordinateur;overlay networks;reseau de recouvrement;logicial personalizado;peer to peer system;computer network;partage des ressources;intergiciel;decentralized system;large scale;poste a poste;gossip protocol;theoretical analysis;resource sharing;particion recursos;autogeneration mutuelle;sistema descentralizado;overlay network;autoorganizacion;red informatica;self organization;middleware;bootstrapping;systeme decentralise;analisis semantico;analyse semantique;peer to peer;autoorganisation;semantic analysis	Large-scale overlay networks have become crucial ingredients of fully-decentralized applications and peer-to-peer systems. Depending on the task at hand, overlay networks are organized into different topologies, such as rings, trees, semantic and geographic proximity networks. We argue that the central role overlay networks play in decentralized application development requires a more systematic study and effort towards understanding the possibilities and limits of overlay network construction in its generality. Our contribution in this paper is a gossip protocol called T-MAN that can build a wide range of overlay networks from scratch, relying only on minimal assumptions. The protocol is fast, robust, and very simple. It is also highly configurable as the desired topology itself is a parameter in the form of a ranking method that orders nodes according to preference for a base node to select them as neighbors. The paper presents extensive empirical analysis of the protocol along with theoretical analysis of certain aspects of its behavior. We also describe a practical application of T-MAN for building CHORD distributed hash table overlays efficiently from scratch. ! 2009 Elsevier B.V. All rights reserved.	distributed computing;distributed hash table;gossip protocol;overlay network;peer-to-peer;robustness (computer science)	Márk Jelasity;Alberto Montresor;Özalp Babaoglu	2009	Computer Networks	10.1016/j.comnet.2009.03.013	gossip protocol;overlay network;computer science;operating system;key-based routing;distributed computing;world wide web;computer network	Security	-10.710052719852309	70.35214518795893	122185
cbc913b7b8b1e45d628f1d98f11db626c19110ff	exact and heuristic mapreduce scheduling algorithms for cloud federation		Abstract Geo-distributed big-data processing has recently received much attention since it ensures large-scale and geographically distributed data processing, using Hadoop or Spark, in an efficient, fault-tolerant and reliable manner. The objective of this work is to propose a new geo-distributed MapReduce-based framework and algorithm for federated cloud platforms. A distributed heuristic algorithm, called FDMR (Federated Distributed MapReduce), that takes advantage of data locality, inter-cloud data transfer and high availability of capacities offered by the federation is proposed. The aim of FDMR is to reduce job cost while respecting deadline constraint. The goal of this paper is also to propose an exact MapReduce scheduling model to serve as a baseline for benchmarking and to compare and discuss the heuristic algorithm results. The performance evaluation proves that the proposed algorithm FDMR can improve resource utilization of the cloud federation and consequently reduce cost and job response time while satisfying the deadline constraint.	algorithm;heuristic;mapreduce;scheduling (computing)	Thouraya Gouasmi;Wajdi Louati;Ahmed Hadj Kacem	2018	Computers & Electrical Engineering	10.1016/j.compeleceng.2018.01.021	real-time computing;high availability;computer science;response time;heuristic (computer science);benchmarking;scheduling (computing);heuristic;job costing;cloud computing	DB	-18.96808865424121	62.615359109380734	122218
aaae38f23265a9c4b5ffab89f8a0bf0c3ff8ff93	design and performance evaluation of smart job first multilevel feedback queue (sjfmlfq) scheduling algorithm with dynamic smart time quantum		Multilevel feedback queue scheduling (MLFQ) algorithm is based on the concept of several queues in which a process moves. In earlier scenarios there are three queues defined for scheduling. The two higher level queues are running on Round Robin scheduling and last level queue is running on FCFS (First Come First Serve). A fix time quantum is defined for RR scheduling and scheduling of process depends upon the arrival time in ready queue. Previously a lot of work has been done in MLFQ. In our propose algorithm Smart Job First Multilevel feedback queue (SJFMLFQ) with smart time quantum (STQ), the processes are arranged in ascending order of their CPU execution time and calculate a Smart Priority Factor SPF on which processes are scheduled in queue. The process which has lowest SPF value will schedule first and the process which has highest SF value will schedule last in queue. Then a smart time quantum (STQ) is calculated for each queue. As a result, we found decreasing in turnaround time, average waiting time and increasing throughput as compared to the previous approaches and hence increase in the overall performance.	algorithm;multilevel feedback queue;performance evaluation;quantum;scheduling (computing)	Amit Kumar Gupta;Narendra Singh Yadav;Dinesh Goyal	2017	IJMDEM	10.4018/IJMDEM.2017040106	multilevel feedback queue;real-time computing;earliest deadline first scheduling;multilevel queue;dynamic priority scheduling;bulk queue;computer science;distributed computing;queue management system;fork–join queue;run queue;job queue;priority queue	HPC	-11.862832733194756	61.17856376873692	122228
417e4dca0254050c9d3e9d2f7d6a4513f8e78b84	cpi: a novel three-phase algorithm for qos-aware replica placement problem	cluster algorithm;large scale;theoretical analysis;computational complexity	QoS-aware replica placement decides how many replicas are needed and where to deploy them to meet every request from individual clients. In this paper, a novel three-phase algorithm, namely CPI, is proposed. By dividing candidate nodes into proper medium-scale partitions, CPI is capable to handle with large-scale QoS-aware replica placement problem. Pharos-based clustering algorithm obtains ideal grouping, and partition integrating method is developed to obtain final replica policy. Theoretical analysis and experiments show that CPI has lower computation complexity and good scalability. The replicating cost and updating cost remains acceptable under different simulating conditions.	algorithm;cluster analysis;computation;experiment;quality of service;scalability;simulation;testbed;xslt/muenchian grouping	Wei Fu;Yingjie Zhao;Nong Xiao;Xicheng Lu	2008		10.1007/978-3-540-88140-7_21	parallel computing;computer science;artificial intelligence;theoretical computer science;database;computational complexity theory;algorithm	Robotics	-17.396568185696868	64.42795330777754	122694
eb87e225c32943363ad759fd0d80edf22b30a477	a scalable video-on-demand system using multi-batch buffering techniques	estensibilidad;evaluation performance;multicast communication;degradation;scalable video;performance evaluation;video a peticion;bandwidth allocation;evaluacion prestacion;degradacion;video a la demande;simulation;multidestinatario;procede discontinu;buffer storage;client server systems;simulacion;centralized system;buffer system;performance evaluation video on demand video servers client server systems bandwidth allocation multicast communication buffer storage;serveur video;sistema amortiguador;etat actuel;slip and merge;large scale;demand systems;network servers performance analysis video on demand urban areas scalability unicast large scale systems costs degradation us department of transportation;state of the art;diffusion donnee;video on demand;video server;networking;batch process;difusion dato;systeme centralise;video servers;procedimiento discontinuo;estado actual;digital video;extensibilite;scalability;reseautique;data broadcast;systeme tampon;sistema centralizado;multidestinataire;set top box;multicast;clients scalable video on demand system multi batch buffering vod video servers metropolitan areas per user cost performance degradation centralized buffer interaction requests scalable buffering multicasting slip and merge set top boxes simulation performance evaluation	A Video-on-Demand (VOD) system delivers videos on demand over an installed network. Due to the large size of digitized videos, expensive video servers with high I/O capability are needed in order to provide VoD services in metropolitan areas. In addition, there is a great need for efficient networking distribution/interaction schemes so that the video servers can serve as many clients as possible. In particular, because of scalability problems, the classical unicast VoD system is not suitable for large-scale deployments. In this paper, a highly scalable VoD system with a low per-user cost is described and evaluated. We first analyze the performance degradation problems using recently proposed VoD systems, namely batched and centralized-buffer VoD systems that occur during the handling of interactions. Then a new system called theMulti-Batch Buffer (MBB) system, which attempts to solve these problems, is proposed. The proposed system handles a majority of interaction requests by scalable buffering techniques employed in the buffer of the local servers and the set-top boxes (STBs). We have performed extensive simulation for the analysis and performance evaluation of our proposed VoD system. The simulation results will demonstrate that our VoD system is very scalable and outperforms related state-of-the-art VoD systems.	buffer overflow;centralized computing;elegant degradation;input/output;interaction;minimum bounding box;performance evaluation;scalability;set-top box;simulation;unicast	Cyrus C. Y. Choi;Mounir Hamdi	2003	TBC	10.1109/TBC.2003.813435	embedded system;real-time computing;multicast;scalability;degradation;telecommunications;computer science;bicarbonate buffering system;computer network;batch processing;bandwidth allocation	HPC	-13.914167138723666	70.98420688378432	122702
3523903cefcf1f06798e6ea398870fc6bfe23924	performance evaluation of the random replacement policy for networks of caches	content distribution network;performance evaluation;information centric networking;asymptotic analysis;cache replacement;content distribution networks;cache replacement policies;network architecture;tree network;power law;replacement policy	Caching is a key component for Content Distribution Networks and new Information-Centric Network architectures. In this paper, we address performance issues of caching networks running the RND replacement policy. We first prove that when the popularity distribution follows a general power-law with decay exponent α > 1, the miss probability is asymptotic to O( C1-α) for large cache size C. We further evaluate network of caches under RND policy for homogeneous tree networks and extend the analysis to tandem cache networks where caches employ either LRU or RND policies.	cache (computing);content delivery network;performance evaluation;randomness	Massimo Gallo;Bruno Kauffmann;Luca Muscariello;Alain Simonian;Christian Tanguy	2012		10.1145/2254756.2254810	power law;parallel computing;real-time computing;asymptotic analysis;network architecture;computer science;distributed computing;smart cache;computer network	Metrics	-11.456670072732852	70.84697675575771	122949
0e92ae19167395d0ca655b714509f9412fd34e19	snap-stabilizing prefix tree for peer-to-peer systems	tolerancia falta;parallelisme;distributed system;metodo caso peor;unfolding;replication;systeme reparti;computational grid;range query;resource discovery;fault tolerant;deploiement;autonomous system;peer to peer systems;par a par;stabilization;resource management;interrogation base donnee;distributed computing;despliegue;interrogacion base datos;dynamic system;distributed data structure;final height;peer to peer system;replicacion;sistema autonomo;grid;busquedas dentro de un rango;gestion recursos;large scale;self stabilization;parallelism;fault tolerant system;sistema repartido;requete a intervalle;paralelismo;poste a poste;estabilizacion;indexing;rejilla;robustesse;indexation;fault tolerance;estructura datos;systeme autonome;indizacion;methode cas pire;sistema tolerando faltas;grille;gestion ressources;calculo repartido;robustness;systeme tolerant les pannes;structure donnee;stabilisation;snap stabilization;peer to peer;worst case method;grid computing;data structure;calcul reparti;database query;tolerance faute;robustez	Resource Discovery is a crucial issue in the deployment of computational grids over large scale peer-to-peer platforms. Because they efficiently allow range queries, Tries (a.k.a., Prefix Trees) appear to be among promising ways in the design of distributed data structures indexing resources. Self-stabilization is an efficient approach in the design of reliable solutions for dynamic systems. A snap-stabilizing algorithm guarantees that it always behaves according to its specification. In other words, a snap-stabilizing algorithm is also a self-stabilizing algorithm which stabilizes in 0 steps. In this paper, we provide the first snap-stabilizing protocol for trie construction. We design particular tries called Proper Greatest Common Prefix (PGCP) Tree. The proposed algorithm arranges the n label values stored in the tree, in average, in O(h+h′) rounds, where h and h′ are the initial and final heights of the tree, respectively. In the worst case, the algorithm requires an O(n) extra space on each node, O(n) rounds and O(n) actions. However, simulations show that, using relevant data sets, this worst case is far from being reached and confirm the average complexities, making this algorithm efficient in practice.	algorithm;best, worst and average case;data structure;distributed computing;dynamical system;experiment;fault tolerance;jxta;message passing;peer-to-peer;prototype;range query (data structures);requirement;scalability;self-stabilization;simulation;software deployment;tree (data structure);trie	Eddy Caron;Frédéric Desprez;Franck Petit;Cédric Tedeschi	2010	Parallel Processing Letters	10.1142/S012962641000003X	fault tolerance;parallel computing;real-time computing;data structure;computer science;resource management;operating system;distributed computing;algorithm	DB	-10.878967283755843	69.51042558131734	123102
2dcb0ed27b6a35b1dfe97b45604302a1f3705c01	storage device performance prediction with cart models	storage device modeling;classification and regression tree;storage system;performance evaluation;storage management;trees mathematics;relative error;machine learning;performance prediction;digital storage;test traces storage device performance prediction classification and regression trees models self managed storage machine learning tool storage device modeling input workloads per request response times black box models;learning artificial intelligence;learning artificial intelligence storage management digital storage trees mathematics performance evaluation;predictive models delay machine learning aggregates storage automation testing analytical models encoding telecommunication computing gold;device modeling	This work explores the application of a machine learning tool, CART modeling, to storage devices. We have developed approaches to predict a device's performance as a function of input workloads, requiring no knowledge of the device internals. Two uses of CART models are considered: one that predicts per-request response times (and then derives aggregate values) and one that predicts aggregate values directly from workload characteristics. After training on the device in question, both provide reasonably-accurate black box models across a range of test traces from real environments. An expanded version of this paper is available as a technical report [1].	aggregate data;black box;c++ technical report 1;decision tree learning;machine learning;performance prediction;rom cartridge;tracing (software)	Mengzhi Wang;Kinman Au;Anastasia Ailamaki;Anthony Brockwell;Christos Faloutsos;Gregory R. Ganger	2004	The IEEE Computer Society's 12th Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, 2004. (MASCOTS 2004). Proceedings.	10.1145/1005686.1005743	approximation error;simulation;computer science;artificial intelligence;operating system;machine learning	Arch	-17.153707719512397	66.50400495400582	123308
c5742d2fb2db05fffcff9b00a4958b0426322113	the file allocation problem under dynamic usage		Abstract   The file allocation problem considers a file and a fully connected network having  n  nodes. The problem assumes that the overall file usage over a unit time period is known and it asks for the optimal set of network sites at which to locate copies of the file. This paper considers the same problem but it assumes that the behavior of the user access patterns changes over  v  planning periods in a manner, known in advance. A model is presented which shows that there are (2  n   − 1)  v   possible file allocations. To assist the searching of this large solution space four theorems are presented which are subsequently utilized to analyze the problem and to solve an example case.		Michael Hatzopoulos;John G. Kollias	1980	Inf. Syst.	10.1016/0306-4379(80)90011-3	real-time computing;device file;computer science;class implementation file;operating system;data mining;database;open	DB	-13.918219986020755	65.62387536834397	123390
b1862eb3b3a607d9dcea64721a51a2a365119d9a	decentralized orchestration of compositeweb services	web services message passing;message routing;composite web service;network traffic reduction;service invocation trigger;decentralized orchestration;workflows composite web services decentralized orchestration;network traffic;workflows;web services telecommunication traffic application software simple object access protocol artificial intelligence laboratories routing distributed computing programming access protocols;web services;message passing;network traffic reduction decentralized orchestration composite web service message routing service invocation trigger;composite web services	Traditional, centralized orchestration of composite Web services often leads to inefficient routing of messages. To solve this problem, we present a novel scheme to execute composite Web services in a fully decentralized way. We introduce service invocation triggers, a lightweight infrastructure that routes messages directly from the producing service to the consuming one, enabling fully decentralized orchestration. An evaluation confirms that decentralized orchestration can significantly reduce the network traffic when compared with centralized orchestration	aggregate data;centralized computing;database trigger;mobile device;multicast;network packet;network traffic control;orchestration (computing);proxy server;routing;web service	Walter Binder;Ion Constantinescu;Boi Faltings	2006	2006 IEEE International Conference on Web Services (ICWS'06)	10.1109/ICWS.2006.48	web service;workflow;message passing;business process execution language;computer science;distributed computing;programming language;law;world wide web;computer network	HPC	-18.94527249488601	70.81046858280102	123794
c014694ca3230ba09a59972c54f9a676285883a2	an efficient task scheduling algorithm for heterogeneous multi-cloud environment	minimax techniques cloud computing;max min cloud computing resource allocation task scheduling virtualization min min;multicloud scheduling algorithms task scheduling algorithm heterogeneous multicloud environment cloud computing business community research community client demands data centers unlimited resources flexible resources cheaper resources scheduling workloads min min max min;scheduling coordinate measuring machines benchmark testing scheduling algorithms data models	Cloud Computing has been adopted as one of the growing technologies in the business and research community. However, due to significant client demands, there is a need to overflow some workloads to other data centers as no data center has unlimited resources. The workload sharing provides even more flexible and cheaper resources to complete the applications submitted to the data centers. However, scheduling workloads in multi-cloud environment is challenging as the data centers have resources which are heterogeneous in nature. In this paper, we propose a task scheduling algorithm in a heterogeneous multi-cloud environment. The algorithm is based on two popular algorithms namely, Min-Min and Max-Min. We perform extensive experiments on some benchmark and synthetic data sets and compare the results with two existing multi-cloud scheduling algorithms. The results show that the proposed algorithm outperforms both the algorithms in terms of makespan and average cloud utilization.	algorithm;scheduling (computing)	Sanjaya Kumar Panda;Prasanta K. Jana	2014		10.1109/ICACCI.2014.6968253	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing;round-robin scheduling	Robotics	-19.0649159388576	62.97338387575616	123982
71775a3bd41ccb953967e02697859b76630eea5d	non-stationary traffic analysis and its implications on multicore platform design	analytical models;fractals;multicore systems;network on chip;queueing theory;resource management;mapping multiple application;time dependent traffic behavior nonstationary traffic analysis multicore platform design network on chip mapping multiple application performance analysis communication infrastructure resource management queuing based approach statistical physics inspired approach space dependent traffic behavior;time dependent traffic behavior;communication infrastructure;computational modeling;stochastic processes;system on chip;non stationary traffic;queuing based approach;multicore processing;performance analysis;statistical physics inspired approach;traffic analysis;space dependent traffic behavior;queueing theory multiprocessing systems network on chip;networks on chip;fractals multicore processing analytical models stochastic processes optimization equations computational modeling;optimization;self similar behavior;multiprocessing systems;multicore platform design;nonstationary traffic analysis;systems on chip;systems on chip multicore systems networks on chip non stationary traffic self similar behavior	Networks-on-chip (NoCs) have been proposed as a viable solution to solving the communication problem in multicore systems. In this new setup, mapping multiple applications on available computational resources leads to interaction and contention at various network resources. Consequently, taking into account the traffic characteristics becomes of crucial importance for performance analysis and optimization of the communication infrastructure, as well as proper resource management. Although queuing-based approaches have been traditionally used for performance analysis purposes, they cannot properly account for many of the traffic characteristics (e.g., non-stationarity, self-similarity) that are crucial for multicore platform design. To overcome these limitations, we propose a statistical physics inspired approach to capture the traffic dynamics in multicore systems. As shown later in this paper, this is of fundamental significance for re-thinking the very basis of multicore systems design; it also opens up new research directions into NoC optimization which require accurate models of time-dependent and space-dependent traffic behavior.	algorithm;approximation;bernoulli polynomials;buffer overflow;computational resource;emoticon;expanded memory;finite difference method;fitness function;mathematical optimization;multi-core processor;network architecture;network on a chip;network packet;network traffic control;profiling (computer programming);real-time clock;real-time computing;rewrite (programming);robust control;scheduling (computing);self-similarity;stationary process;systems design;traffic analysis;triune continuum paradigm	Paul Bogdan;Radu Marculescu	2011	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2011.2111270	system on a chip;multi-core processor;embedded system;real-time computing;fractal;computer science;resource management;theoretical computer science;operating system;distributed computing;queueing theory;computational model;statistics;computer network	EDA	-7.093807939491412	63.25189925545084	124119
f90cd42a3b5ffde8b6eaa11400795074d59f9327	a swarm robotics approach to task allocation under soft deadlines and negligible switching costs		Developing swarm robotics systems for real-time applications is a challenging mission. Task deadlines are among the kind of constraints which characterize a large set of real applications. This paper focuses on devising and analyzing a task allocation strategy that allows swarm robotics systems to execute tasks characterized by soft deadlines and to minimize the costs associated with missing the task deadlines.	constraint (mathematics);real-time clock;robot;swarm robotics	Yara Khaluf;Mauro Birattari;Heiko Hamann	2014		10.1007/978-3-319-08864-8_26	real-time computing;simulation;computer science	Robotics	-8.313352136471906	60.65395125019405	124330
5cd464a7ead73bd26cee7351e524c0011b059679	a capacity planning model of unreliable multimedia service systems	reliability;capacity planning;queue length;multimedia service systems;failure rate;packet delay;open queueing network;multimedia services	To analyze the performance of multimedia service systems, which have unreliable resources, and to estimate the capacity requirement of the systems, we have developed a capacity planning model using an open queueing network. By acquisition of utilization, queue length of the resources and packet delay, and reliability of the systems, we have derived the service capacity of the systems along with the arrival rates of clients and the failure rates of the resources. We have validated the proposed capacity planning model by comparison of analytic results with simulation output. 2001 Elsevier Science Inc. All rights reserved.	disk array;fault tolerance;network packet;queueing theory;scheduling (computing);simulation	Kiejin Park;Sungsoo Kim	2002	Journal of Systems and Software	10.1016/S0164-1212(01)00141-8	reliability engineering;real-time computing;computer science;failure rate;reliability;computer network	Metrics	-8.35299327915265	74.42582124460029	124622
5709eebfc339045c0fd58f9d827a7d5af8b897c6	exploiting location-aware mechanism for distributed web crawling over dhts	content addressable network;network coordinate system;distributed web crawling;dht;location aware	Inspired by the concept of internet computing, DHT-based distributed Web crawling model is proposed to solve the bottlenecks of the traditional Web crawling systems. Based on this system model, we propose optimizations to reduce the download time of the Web crawling tasks in order to increase the efficiency of the system. The improvement on the download time is achieved by shortening the crawler-crawlee network distance. By utilizing the mapping mechanism of Content Addressable Network (CAN) over Network Coordinate System (NC), the issue can be mapped onto a problem of minimizing the distances between peers and resources on the DHT overlay. This paper focuses on reducing such distances, seeking to provide an improved location-aware infrastructure for distributed Web crawling. A new DHT-based distributed Web crawling model is proposed first. Then, under this model, a new method based on CAN’s splitting schemes is proposed which shows a significant decrease in crawler-crawlee distance against existing schemes. In addition, the issue of load balancing is also solved by combining the new method with old ones.	distributed web crawling;web crawler	Xiao Xu;Weizhe Zhang;Hongli Zhang;Binxing Fang	2010	JCP	10.4304/jcp.5.11.1646-1654	content addressable network;computer science;distributed web crawling;database;distributed computing;world wide web	Web+IR	-12.814605048664301	73.75849754356837	124737
0165904f64173a8584c9a6408cc60ca189d0be1a	flexible quality-of-control management in embedded systems using fuzzy feedback scheduling	workload;control application;resource constraint;calculateur embarque;control difusa;quality of control;incertidumbre;availability;uncertainty;disponibilidad;control inteligente;real time;echantillonnage;fuzzy control;fuzzy logic control;logique floue;resource management;logica difusa;logical programming;intelligent control;embedded system;systeme asservi;sampling;fuzzy logic;gestion recursos;programmation logique;scheduling;temps reel;integrated control;boarded computer;charge travail;controle qualite;gestion ressources;servomecanismo;tiempo real;commande intelligente;resource availability;incertitude;feedback system;muestreo;carga trabajo;quality control;programacion logica;disponibilite;calculador embarque;ordonnancement;reglamento;control calidad;commande floue	Today's embedded systems representatively feature computing resource constraints as well as workload uncertainty. This gives rise to the increasing demand of integrating control and scheduling in control applications that are built upon embedded systems. To address the impact of uncertain computing resource availability on quality of control (QoC), an intelligent control theoretic approach to feedback scheduling is proposed based on fuzzy logic control technology. The case with one single control task that competes for CPU resources with other non-control tasks is considered. The sampling period of the control task is dynamically adjusted. The goal is to provide runtime adaptation and flexible QoC management in the presence of CPU resource constraint and workload uncertainty. Preliminary simulation results argue that the fuzzy feedback scheduler is effective in managing QoC in real-time embedded control applications.	embedded system;scheduling (computing)	Feng Xia;Liping Liu;Youxian Sun	2005		10.1007/11548706_66	fuzzy logic;sampling;availability;quality control;real-time computing;uncertainty;computer science;artificial intelligence;resource management;feedback;scheduling;intelligent control	Embedded	-11.737935270058966	65.06619041033218	124740
0415104803b2f4723d5f23ef7d43d1292249a2c5	a scalable multi-fpga platform for complex networking applications	field programmable gate array;protocols;field programmable gate arrays protocols computer architecture internet ip networks routing program processors;routing;complex network;real time processing;scalable multidevice system;line speed processing rates;computer architecture;fpga implementation;network infrastructure;internet;application level network processing;complex real time processing;scalable multifpga platform;ip networks;network packets;field programmable gate arrays;complex networking application;program processors;scalable multidevice system scalable multifpga platform complex networking application complex real time processing network packets network infrastructure line speed processing rates application level network processing	Ballooning traffic volumes and increasing link-speeds require ever high compute power to perform complex real-time processing of network packets. FPGAs have already been successfully employed in the past to accelerate network infrastructure-operations at these line-speed processing rates. However, much of the prior work concentrated on single-FPGA platforms. To this end, we have studied how to extend an architecture for 10G application-level network processing into a scalable multi-device system. We present a ring-based approach, of which a quad-FPGA implementation will be evaluated on the BEEcube BEE3 computing platform.	complex network;encryption;extensibility;field-programmable gate array;https;network processor;plug-in (computing);real-time transcription;scalability	Sascha Mühlbach;Andreas Koch	2011	2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines	10.1109/FCCM.2011.26	embedded system;parallel computing;real-time computing;computer science;operating system;field-programmable gate array	Arch	-7.476583871998225	66.06941390129106	124776
a6fa881317a26798955a86fb7ea175ff530bbe57	an approach to indirect protocol conversion	protocole transmission;concepcion sistema;calculating time;etude experimentale;conversion indirecte;performance;reseau ordinateur;telecommunication network;transmission message;message transmission;computer network;algorithme;algorithm;temps calcul;protocolo transmision;system design;red telecomunicacion;reseau telecommunication;red ordenador;indirect conversion;conversion protocole;rendimiento;tiempo calculo;estudio experimental;reachability analysis;conception systeme;transmision mensaje;protocol conversion;algoritmo;converter state;transmission protocol	With the proliferation of different computer networks, protocol conversion is needed to achieve interoperability between computer networks that implement different protocols, so that users on different networks can communicate with one another. In its most efficient form, protocol conversion is performed on the fly, i.e. the messages produced in one protocol are converted and passed immediately to the other protocol; this is called direct conversion, and no buffer is needed to store the messages. For many practical protocols, however, it is possible that the messages produced in one protocol need to be re-ordered and converted before they are passed to the other protocol; this is called indirect conversion, and the messages produced in one protocol must be first stored in a non-FIFO buffer and then converted in proper order for the other protocol. This paper presents a formal technique to synthesize a converter by inserting the PUT and GET operations into two given protocols to manipulate the buffer for indirect conversion. The PUT operation inserts messages in one protocol into a non-FIFO buffer, and then the GET operation retrieves the messages in proper order from the buffer and converts them for the other protocol. Since the PUT and GET operations are asynchronous, they may create some problems for the buffer: (1) buffer overflow, i.e., the number of messages stored in the buffer exceeds its capacity; and (2) improper termination, i.e., the protocol terminates with some messages leftover in the buffer. Therefore, the synthesized converter needs to be validated. Several techniques are proposed to reduce the computing time and space spent in validating the converter. Finally, an algorithm for indirect conversion is presented and applied to a practical example for conversion between ISO OSI and IBM SNA protocols.		J. C. Shu;Ming T. Liu	1991	Computer Networks and ISDN Systems	10.1016/0169-7552(91)90100-Q	hostlink protocol;universal composability;real-time computing;two-phase commit protocol;performance;telecommunications;internet protocol control protocol;computer science;computer security;telecommunications network;computer network;systems design	Networks	-4.595232579825408	73.44068507172193	124931
68f39863b91a921894518dd2af4891498b32d8d8	a new proxy scheme for large-scale p2p vod system	large scale systems streaming media network servers bandwidth scalability peer to peer computing web and internet services costs centralized control cache storage;video streaming;server based proxies;trace driven simulations p2p video on demand system large scale stream media delivery internet content delivery network server based proxies centralized control chunk based proxy scheme gridcast client based p2p model;chunk based proxy scheme;client based p2p model;p2p;client server systems;large scale stream media delivery;trace driven simulations;p2p video on demand system;media;large scale;servers;network servers;internet;streaming media;gridcast;video on demand;video streaming client server systems grid computing internet network servers peer to peer computing video on demand;media streaming;bandwidth;cost effectiveness;self organization;centralized control;content delivery network;scalability;p2p networks;peer to peer computing;peer to peer;load modeling;grid computing;trace driven simulation;proxy server	Large-scale stream media delivery over Internet is one hot and hard problem. Three main solutions have been developed for this purpose. Content delivery network (CDN) can provide high quality streaming service with high cost. Server-based proxies are cost-effective but not scalable due to the limited proxy capacity and its centralized control. Peer-to-peer (P2P) network is scalable but does not guarantee high quality streaming service due to its self-restrained characteristic. This paper proposes a new chunk-based scalable and reliable proxy scheme for P2P network. Clients are self-organized in unstructured P2P VoD system GridCast and requests for media contents that are not found in P2P overlay from proxy servers. This scheme can address the limitations of server-based proxy model and client-based P2P model. The proposed scheme is evaluated by trace-driven simulations from logs collected in GridCast. The results show that the approach proposed significantly improves the quality of media streaming and the system scalability.	cache (computing);centralized computing;client–server model;content delivery network;display resolution;http 404;internet;one-hot;peer-to-peer;principle of good enough;proxy server;scalability;self-organization;server (computing);simulation;streaming media;systems architecture;web cache	Wenbin Jiang;Chong Huang;Hai Jin;Xiaofei Liao	2008	2008 IEEE/IFIP International Conference on Embedded and Ubiquitous Computing	10.1109/EUC.2008.148	scalability;the internet;self-organization;cost-effectiveness analysis;media;computer science;operating system;peer-to-peer;internet privacy;world wide web;bandwidth;grid computing;server;computer network	HPC	-16.62611693191449	73.55067300373605	125090
007ac3f2c9b2cd9fbf0ef668128a8dd2f12bcbbb	memory efficient and high performance key-value store on fpga using cuckoo hashing	random access memory;memory management;mrps memory efficient key value store high performance key value store cuckoo hashing kvs data explosion fpga based parallel architecture memory utilization constant worst case access time pipeline scheme insert operation search operation delete operation million requests per second;clocks;pipelines arrays throughput field programmable gate arrays memory management clocks random access memory;arrays;pipelines;parallel architectures cryptography field programmable gate arrays;field programmable gate arrays;throughput	Key-value stores (KVS) become critical in many applications because of the data explosion recently. There is a strong demand to improve the throughput and reduce the latency for KVS. FPGA-based parallel architecture can bring excellent performance and power efficiency. Cuckoo hashing has proven to be an efficient approach to implement KVS with good memory utilization and constant worst case access time. In this paper, an FPGA-based KVS implementation is proposed based on Cuckoo hashing, with a decoupled storage to achieve 81.7% memory utilization, and a pipeline scheme to achieve high performance. The latency of insert, search and delete operations is only 40 ns. And the throughput for search and delete can be 200 million requests per second (MRPS) which is 5× faster than [1]. Even when the load factor becomes 0.9, the throughput for insert can still achieve 147 MRPS.	access time;attribute–value pair;best, worst and average case;cuckoo hashing;dynamic random-access memory;field-programmable gate array;hash table;key-value database;parallel computing;performance per watt;throughput;web server	Wei Liang;Wenbo Yin;Ping Kang;Lingli Wang	2016	2016 26th International Conference on Field Programmable Logic and Applications (FPL)	10.1109/FPL.2016.7577355	embedded system;throughput;parallel computing;real-time computing;computer hardware;computer science;operating system;pipeline transport;field-programmable gate array;memory management	HPC	-5.8341274524144735	65.24507782908606	125432
db66d8116a7e17b50dff2187c5353ae4f1f8ac6c	a multi-channel end system multicasting scheme on p2p cluster overlay	multicast communication;and forward;p2p cluster overlay;channel switching end system multicast cluster overlay p2p;p2p;cluster overlay;peer to peer overlays multichannel end system multicasting scheme p2p cluster overlay internet;media;computer architecture;internet;multichannel end system multicasting scheme;distributed databases;telecommunication channels internet multicast communication peer to peer computing;switches computer architecture internet distributed databases peer to peer computing media service oriented architecture;peer to peer computing;telecommunication channels;service oriented architecture;switches;peer to peer;peer to peer overlays;clustered data;channel switching;end system multicast	In the last decade, more and more media data are produced and shared over Internet. To send data on Internet, casting techniques are commonly used. Attempting to provide scalable applications, many approaches of end system multicast (ESM) have been recently designed over peer-to-peer (P2P) overlays. Cluster overlay is one of scalable P2P overlays in which peers are organized into groups and are not aware of the whole system. In this paper, we address a multi-channel end system multicasting scheme based on cluster overlay. Each multicast group is called a channel. Peers can switch from one channel to another. Super peers in cluster overlay manage peers and channels transferring in its cluster. Data duplicating and forwarding are carried out by peers. Heads of the cluster overlay help peers to find nearby peers who have joined in the channel in-demand to speed up channel switching.	end system multicast;fibre channel;flow network;internet;intranet;peer-to-peer;scalability;speedup;swift (programming language)	Yinghua Ma;Richard Chbeir;Kokou Yétongnon;Guiyang Su	2007	2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System	10.1109/SITIS.2007.21	the internet;media;network switch;computer science;service-oriented architecture;peer-to-peer;database;distributed computing;world wide web;distributed database;computer network	HPC	-15.395167476168385	74.19567027415107	125440
1c2a5cec269f43e0d5441667c20e5dfdf8298beb	a framework for mapping with resource co-allocation in heterogeneous computing systems	dag scheduling;directed acyclic graph;graph theory;theoretical framework;multiprocessing programs;performance evaluation;computational grid environments;heterogeneous computing;processor scheduling;resource allocation;heuristic programming;simulation;concurrently executable tasks;software performance evaluation;two phase algorithm;satisfiability;runtime;application mapping;heterogeneous computing systems;computer applications;simulation experiment;indium tin oxide;multiprocessing programs resource allocation open systems heuristic programming software performance evaluation processor scheduling graph theory;performance improvement;maximal independent set;precedence constraints;heuristic algorithms;resource sharing;schedule length minimization;precedence constraint;lab on a chip;compatibility graph;list scheduling;grid computing runtime lab on a chip computer applications indium tin oxide;mapping;resource co allocation;open systems;grid computing;maximal independent sets;run time adaptation;simultaneous resource allocation;heuristic algorithm;resource sharing constraints;computational grid environments resource co allocation heterogeneous computing systems simultaneous resource allocation application mapping precedence constraints resource sharing constraints directed acyclic graph compatibility graph maximal independent sets concurrently executable tasks schedule length minimization heuristic algorithms two phase algorithm run time adaptation simulation performance evaluation list scheduling	In heterogeneous computing systems, an application often requires multiple resources of different types to be allocated simultaneously. This is the resource co-allocation problem. We develop a framework for mapping a collection of applications with resource co-allocation requirements. In our framework, application tasks have two types of constraints to be satisfied: precedence constraints and resource-sharing constraints. We use a graph theoretic framework to capture these constraints. A directed acyclic graph is used to represent precedence constraints of tasks within an application and a compatibility graph is used to represent resource-sharing constraints among tasks of applications. Both these graphs are used to find maximal independent sets of tasks that can be executed concurrently. The objective of the mapping is to minimize the overall schedule length for a given set of applications. We develop heuristic algorithms to solve the mapping problem with resource co-allocation constraints. We also provide a two-phase algorithm that can be used for run-time adaptation. We conducted simulation experiments to evaluate the performance of our heuristic algorithms. Simulation results for our algorithms show a performance improvement of 10% to 30% over a baseline algorithm of list scheduling which considers only the precedence constraints and allocates tasks from the resulting order. This paper demonstrates the importance of considering the co-allocation requirements when mapping applications in heterogeneous computing environments including grid environments.	heterogeneous computing	Ammar H. Alhusaini;Viktor K. Prasanna;Cauligi S. Raghavendra	2000		10.1109/HCW.2000.843751	parallel computing;real-time computing;computer science;distributed computing	HPC	-13.748905341611033	61.94101551109824	125862
fd5019a2465ae318f8b43c3e0ddab1095cbb37b3	implementation and evaluation of hybrid broadcasting system for webcasts		Due to the recent popularisation of grid environments, streaming delivery using broadcast and telecommunication method systems is attracting great attention. In streaming delivery in hybrid broadcasting environments, clients concurrently receive such streaming data as music or movies from both broadcasting and telecommunication systems. Although these systems compensate for their respective the demerits, the waiting time is lengthened if the system does not deliver the data efficiently. To reduce this waiting time, many researches have proposed scheduling methods. However, since most scheduling methods use a computer simulation, they do not clearly show their effectiveness. In this paper, we design and implement a hybrid broadcasting system to solve the problems of conventional methods. In our proposed system, we evaluate how efficiently they reduce waiting times using scheduling methods.		Takeshi Ozaki;Yusuke Gotoh	2018	IJWGS	10.1504/IJWGS.2018.092584	grid;webcast;scheduling (computing);distributed computing;computer science;streaming data;broadcasting	HCI	-16.776290371707972	72.63475783849951	125994
c82bf9c2a1cf0322c5391546376e4631e1be3c3a	a semantic broadcast scheme for a mobile environment based on dynamic chunking	databases;file servers;file servers mobile computing client server systems database management systems;information systems;performance evaluation;dynamic chunking;database management systems;pricing;data affinity index semantic broadcast scheme mobile environment dynamic chunking data broadcast database server mobile clients semantic based broadcast approach;client server systems;database server;mobile environment;scheduling;indexation;semantic description;broadcasting databases mobile computing scheduling performance evaluation bandwidth delay information systems pricing sun;sun;data affinity index;bandwidth;mobile clients;semantic broadcast scheme;data broadcast;broadcasting;mobile computing;experience base;simulation model;semantic based broadcast approach	"""Data broadcast is an effective approach to disseminate information from a database server to numerous mobile clients in a mobile environment. Since a broadcast session contains only a subset of the database items, a client might not be able to obtain all its items from the broadcast and is forced to request additional ones from the server on demand. We describe a semantic-based broadcast approach which attaches a semantic description to each broadcast unit, called a chunk, which is a cluster of data items. This allows a client to determine if a query can be answered entirely using a broadcast as well as defining the precise nature of the remaining items in the form of a """"supplementary"""" query. Chunks could be of different sizes and are hierarchically organized. We propose a heuristic to schedule the broadcast order of the chunks to improve the tuning time, access time, and a new metric called a data affinity index. The performances are evaluated via experiments based on a simulation model."""	shallow parsing	Ken C. K. Lee;Hong Va Leong;Antonio Si	2000		10.1109/ICDCS.2000.840966	broadcast domain;pricing;file server;atomic broadcast;database server;computer science;operating system;simulation modeling;database;distributed computing;mobile computing;scheduling;world wide web;broadcasting;information system;bandwidth;computer network;terminating reliable broadcast	Mobile	-16.730449014356676	68.65065358094746	126268
08c388b7edc95f4aa819f8c82897207e53047ed8	a scalable server architecture for mobile presence services in social network applications	search satisfaction level scalable server architecture mobile presence service mobile device social network application mobile user presence message distribution scalability problem presencecloud quorum based server to server architecture directed search algorithm one hop caching strategy search cost;message distribution;social network services;cache storage;one hop caching strategy;distributed presence servers;mobile device;telecommunication services cache storage cloud computing message passing mobile computing network servers search problems social networking online;scalability problem;directed search algorithm;search satisfaction level;mobile presence service;mobile user presence;cloud computing social networks mobile presence services distributed presence servers;computer architecture;servers;mobile presence services;network servers;internet;social networks;social networking online;mobile communication;search cost;message passing;scalable server architecture;telecommunication services;social network application;presencecloud;search problems;mobile communication servers mobile computing search problems social network services computer architecture internet;mobile computing;quorum based server to server architecture;cloud computing	Social network applications are becoming increasingly popular on mobile devices. A mobile presence service is an essential component of a social network application because it maintains each mobile user's presence information, such as the current status (online/offline), GPS location and network address, and also updates the user's online friends with the information continually. If presence updates occur frequently, the enormous number of messages distributed by presence servers may lead to a scalability problem in a large-scale mobile presence service. To address the problem, we propose an efficient and scalable server architecture, called PresenceCloud, which enables mobile presence services to support large-scale social network applications. When a mobile user joins a network, PresenceCloud searches for the presence of his/her friends and notifies them of his/her arrival. PresenceCloud organizes presence servers into a quorum-based server-to-server architecture for efficient presence searching. It also leverages a directed search algorithm and a one-hop caching strategy to achieve small constant search latency. We analyze the performance of PresenceCloud in terms of the search cost and search satisfaction level. The search cost is defined as the total number of messages generated by the presence server when a user arrives; and search satisfaction level is defined as the time it takes to search for the arriving user's friend list. The results of simulations demonstrate that PresenceCloud achieves performance gains in the search cost without compromising search satisfaction.	contact list;inter-server;mathematical model;mobile device;network address;online and offline;presence information;queueing theory;scalability;search algorithm;search problem;server (computing);simulation;social network	Chi-Jen Wu;Jan-Ming Ho;Ming-Syan Chen	2013	IEEE Transactions on Mobile Computing	10.1109/TMC.2011.263	message passing;mobile search;the internet;mobile telephony;cloud computing;computer science;telecommunications service;operating system;search cost;mobile device;distributed computing;mobile computing;world wide web;server;computer network;social network	Mobile	-18.78934315350737	70.82881367388794	126566
7ad869e904c105a144369ea25a607cd9ec7d6849	adaptive scheduling based on quality of service in heterogeneous environments	minimisation;grid technology;resource allocation;heterogeneous environments;heterogeneous environment;biological system modeling;quality of service scheduling scheduling algorithm biological system modeling computational modeling optimization;quality of service min min scheduling algorithm adaptive scheduling heterogeneous environments grid technology cloud technology task scheduling heterogeneous distributed system resource usage cost minimisation;cloud technology;quality of service min min scheduling algorithm;scheduling algorithm;computational modeling;heterogeneous distributed system;scheduling;task analysis;task analysis grid computing minimisation quality of service resource allocation scheduling;adaptive scheduling;optimization;task scheduling;quality of service;grid computing;resource usage cost minimisation	With the emergence of grid and cloud technologies, the problem of scheduling tasks in heterogeneous distributed systems has been arousing attention. In this paper, we present two scheduling techniques for optimizing overall execution time and minimizing resource usage cost. To evaluate the effectiveness of the proposed techniques, we have implemented both techniques along with the QoS Min-Min scheduling algorithm. The experimental results show that the proposed techniques provide noticeable improvements.	algorithm;distributed computing;emergence;job shop scheduling;makespan;mathematical optimization;quality of service;robot operating system;run time (program lifecycle phase);scheduling (computing);scheme	Ching-Hsien Hsu;Tai-Lung Chen	2010	2010 4th International Conference on Multimedia and Ubiquitous Engineering	10.1109/MUE.2010.5575084	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;distributed computing;scheduling;round-robin scheduling;scheduling;grid computing	HPC	-17.976629183184027	62.57388112737013	126976
a15aa1b5d8532fb687fa8d879a08909698cddf16	edf scheduling for tasks with uncertain execution times in networked control system	fuzzy theory;networked control systems;schedulability variable;uncertainty;edf algorithm;real time;uncertain execution times;satisfiability;fuzzy set theory;edf scheduling algorithm;uncertain characteristic;distribution function;scheduling algorithm;networked control systems scheduling algorithm optimal scheduling processor scheduling uncertainty real time systems computer networks control systems distribution functions packaging;optimal scheduling;scheduling;heuristic algorithms;uncertain characteristic networked control system edf algorithm fuzzy theory;distributed parameter systems;schedulability variable edf scheduling algorithm uncertain execution times networked control system classical scheduling algorithms fuzzy theory;distribution functions;networked control system;classical scheduling algorithms;scheduling distributed parameter systems fuzzy set theory;real time systems	The execution times of the real-time tasks are uncertain in the networked control system. So the classical scheduling algorithms are not suitable for deciding the priorities of tasks. On the basis of the classical EDF, this paper proposes the static extension EDF scheduling algorithm according to the uncertainty of the execution times. This algorithm can get the distribution function of the schedulability variable according to the distribution functions of tasks with the fuzzy theory. Then the value of schedulability variable which is satisfied the scheduling of the system can be determined by the possibility and necessity of the schedulability variable. The suitable execution time of each task can be calculated to decide the priority of each task. So the order of data can be decided. This algorithm is very simple and overcomes the disadvantage of not deciding priority by fuzzy time in classical scheduling algorithm. Also, it keeps the advantage of high occupancy rate of the resources. It is proved that this algorithm can schedule well under uncertainty.	algorithm;control system;earliest deadline first scheduling;fuzzy logic;real-time clock;real-time computing;run time (program lifecycle phase);schedule (computer science);scheduling (computing)	Tingna Shi;Zhengwei Chen;Changliang Xia;Hongwei Fang;Sujuan Wang	2008	2008 Fourth International Conference on Natural Computation	10.1109/ICNC.2008.142	fair-share scheduling;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;foreground-background;deadline-monotonic scheduling;distributed computing	Embedded	-11.841478024899732	61.05103494580915	126989
e83903787053599d9ae6683b2c852297e96711f7	towards a communication-aware task scheduling strategy for heterogeneous systems	evaluation performance;largeur bande;reseau communication;performance evaluation;heterogeneous systems;criterio resultado;gestion labor;gollete estrangulamiento;resource allocation;evaluacion prestacion;telecommunication network;performance requirement;critere performance;interconnection network;goulot etranglement;gestion tâche;red telecomunicacion;scheduling;anchura banda;reseau telecommunication;bandwidth;ordonamiento;asignacion recurso;task scheduling;allocation ressource;red de comunicacion;bottleneck;communication network;red interconexion;ordonnancement;reseau interconnexion	Many research activities have focused on the problem of task scheduling in heterogeneous systems from the computational point of view. However, a scheduling strategy should also take into account the communication requirements of the applications and the communication bandwidth offered by the network. Towards this end, in this paper we first propose a model of communication cost between network nodes. This model can be used to properly characterize the existing network resources. Second, we propose a criterion to measure the suitability of each allocation of network resources to each parallel application, according to the communication requirements. Third, we propose a scheduling technique based exclusively on this criterion that provides a near-optimal mapping of processes to processors according to the communication requirements. Evaluation results show that the use of this scheduling technique fully exploits the available network bandwidth, greatly improving network performance. Therefore, the proposed scheduling technique can be used in the design of communication-aware scheduling strategies for those situations where the communication requirements are the system performance bottleneck.	scheduling (computing)	Juan M. Orduña;Federico Silla;José Duato	2001	Computers and Artificial Intelligence		fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;earliest deadline first scheduling;simulation;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;two-level scheduling;deadline-monotonic scheduling;maximum throughput scheduling;network simulation;distributed computing;scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;telecommunications network	AI	-12.813562007217572	64.15211713997792	127123
9d9eb13c182a02a45c992404bcdd855498151db9	mixed-criticality scheduling to minimize makespan		In the mixed-criticality job model, each job is characterized by two execution time parameters, representing a smaller (less conservative) estimate and a larger (more conservative) estimate on its actual, unknown, execution time. Each job is further classified as being either less critical or more critical. The desired execution semantics are that all jobs should execute correctly provided all jobs complete upon being allowed to execute for up to the smaller of their execution time estimates, whereas if some jobs need to execute beyond their smaller execution time estimates (but not beyond their larger execution time estimates), then only the jobs classified as being more critical are required to execute correctly. The scheduling of collections of such mixed-criticality jobs upon identical multiprocessor platforms in order to minimize the makespan is considered here. 1998 ACM Subject Classification D.4.1 Scheduling, D.4.7 Real-time systems and embedded systems	criticality matrix;embedded system;job stream;makespan;mixed criticality;multiprocessing;programming language;real-time computing;real-time transcription;run time (program lifecycle phase);scheduling (computing);self-organized criticality	Sanjoy K. Baruah;Arvind Easwaran;Zhishan Guo	2016		10.4230/LIPIcs.FSTTCS.2016.7	johnson's rule;job shop scheduling;approximation algorithm;real-time computing;mixed criticality;scheduling (computing);multiprocessing;computer science;distributed computing;foreground-background	Embedded	-9.989665571190274	60.47183554132844	127292
46445964e8ee5655508a3c593fb38b3a81b02457	a hardware nic scheduler to guarantee qos on high performance servers	dispositif logique programmable;distributed system;algoritmo paralelo;programmable logic devices;field programmable gate array;arquitectura red;banking;streaming;haute performance;systeme reparti;mise a jour;gigue;red local;parallel algorithm;programmable logic device;transmision continua;data stream;secteur bancaire;credit;logical programming;red puerta programable;architecture reseau;reseau porte programmable;qualite service;algorithme parallele;actualizacion;local network;transmission en continu;sistema repartido;credito;programmation logique;grande vitesse;scheduling;retard;fluctuacion;alto rendimiento;network architecture;gran velocidad;jitter;flow control;retraso;reseau local;programacion logica;high performance;high speed;service quality;ordonnancement;updating;reglamento;calidad servicio	In this paper we present the architecture and implementation of a hardware NIC scheduler to guarantee QoS on servers for high speed LAN/SAN. Our proposal employs a programmable logic device based on an FPGA in order to store and update connection states, and to decide what data stream is to be sent next. The network architecture is connection-oriented and reliable, based on credit flow control. The architecture scales from 4 to 32 streams using a Xilinx Virtex 2000E. It supports links with speeds in the order of Gbps while, maintaining the delay and jitter constrains for the QoS streams.	clock rate;connection-oriented communication;data rate units;field-programmable gate array;gigabit;handel;high-level programming language;logic gate;network architecture;network interface controller;programmable logic device;quality of service;requirement;scalability;scheduling (computing);server (computing);specification language;supercomputer;throughput;virtex (fpga);volume boot record	José M. Claver;Manel Canseco;P. Agustí;German Leon	2006		10.1007/11946441_13	embedded system;parallel computing;real-time computing;telecommunications;computer science;programmable logic device	HPC	-5.722797230599035	73.02790285825157	127297
c1c7f46adc97576457e2f4289a8061dce40cc7f2	entry and exit probabilities based cache replacement policy for location dependent data in mobile environments	performance evaluation;mobile computer;system performance;mobile environment;data cache;cache replacement;location dependent information services;data access;dependent data;experimental evaluation;information service;mobile computing;location model;entry and exit;replacement policy	Data caching in mobile clients is an important technique to enhance data availability and to improve data access time. Due to cache size limitations, cache replacement policies are used to find a suitable subset of items for eviction from the cache. In this paper, we study the issues of cache replacement for location-dependent data under a geometric location model and we have proposed a new cache replacement policy RAAR (Re-entry probability, Area of valid scope, Age, Rate of Access) by taking into account the spatial and temporal parameters. The experimental evaluations using synthetic datasets show that our replacement policy is effective in improving the system performance in terms of the cache hit ratio of mobile clients.	access time;cache (computing);data access;hit (internet);synthetic intelligence	F. Magdalene Jane MaryMagdaleneJane;N. Ilayaraja;M. AshwinRaghav;R. Nadarajan;Maytham Safar	2009		10.1145/1821748.1821788	bus sniffing;data access;real-time computing;cache coloring;cache;computer science;cache invalidation;operating system;database;smart cache;mobile computing;cache algorithms;cache pollution	Metrics	-15.424833200337815	68.68251550019166	127339
fef0a2e23706add240ffb8b282cc7399803de77c	hardware-assisted design for fast packet forwarding in parallel routers	cache storage;parallel router;on chip cache memory;and forward;multistage interconnection networks;cache memory;cache oriented multistage structure;packet switching;line card;chip;communication system routing;internet;parallel architectures;telecommunication network routing;system on chip;hardware assisted design;sram;switching element;telecommunication network routing cache storage internet multistage interconnection networks packet switching parallel architectures sram chips system on chip table lookup;forwarding engine;table lookup;random access memory routing table lookup iron forward contracts internet algorithm design and analysis cache memory search engines partitioning algorithms;packet forwarding;forwarding engine hardware assisted design cache oriented multistage structure packet forwarding on chip cache memory switching element parallel router line card table lookup sram;cache memories;sram chips	A hardware-assisted design, dubbed cache-oriented multistage structure (COMS), is proposed for fast packet forwarding. COMS incorporates small on-chip cache memory in its constituent switching elements (SE’s) for a parallel router to interconnect its line cards (LC’s) and forwarding engines (FE’s, where table lookups are performed). Each lookup result in COMS is cached in a series of SE’s between the FE (which performs the lookup) and the LC (where the lookup request originates). The cached lookup results fulfill subsequent lookup requests for identical addresses immediately without resorting to FE’s for (time-consuming) lookups, thus reducing the mean lookup time tremendously. COMS calls for partitioning the set of prefixes in a routing table into subsets (of roughly equal sizes) so that each subset involves only a small fraction of the table for one FE. This leads to a substantial savings of SRAM required in each FE to hold its forwarding table, and the total savings of SRAM in a parallel router far exceeds the amount of SRAM employed in all SE’s of COMS combined. A COMS-based router of size 16 exhibits over 10 times faster mean packet forwarding than its compatible router without caching nor table partitioning. The worst case lookup time in COMS depends on the matching algorithm employed in FE’s and can often be shorter than that in a compatible router. With its ability to forward packets swiftly, COMS is ideally suitable for the new generation of parallel routers.	algorithm;best, worst and average case;byte;cpu cache;cache (computing);lookup table;multistage amplifier;network packet;parallel computing;router (computing);routing table;simulation;static random-access memory;switched fabric;tracing (software)	Nian-Feng Tzeng	2003		10.1109/ICPP.2003.1240561	chip;system on a chip;parallel computing;real-time computing;the internet;line card;static random-access memory;cpu cache;telecommunications;computer science;operating system;packet forwarding;packet switching;computer network	Metrics	-5.65815629106771	66.42988537939264	127556
adc464903cb373baeab11e205e492562d18120f1	load balancing in distributed parallel systems for telecommunications	tratamiento paralelo;distributed system;reseau communication;systeme reparti;traitement parallele;routing;real time control;equilibrio de carga;equilibrage charge;routage;algorithme;algorithm;sistema repartido;telecomunicacion;community networks;parallel systems;scheduling;telecommunication;load balancing;ordonamiento;load balance;red de comunicacion;simulation model;communication network;parallel processing;ordonnancement;algoritmo	Communication networks pose difficult problems for the soft limit real-time control of calls and services. For such highly parallel distributed systems the system observation limits are rigorously treated. As a consequence a parallel processing node model and the load parameters and balancing potential are analysed by the use of a suitable simulation model. Based upon the simulation results, new load balancing algorithms are developed for the respective problem class.	algorithm;distributed computing;information exchange;limit cycle;load balancing (computing);parallel computing;real-time clock;response time (technology);simulation;telecommunications network	Vjekoslav Sinkovic;Ignac Lovrek;Gábor Németh	1999	Computing	10.1007/s006070050031	embedded system;parallel processing;network load balancing services;real-time computing;computer science;load balancing;distributed computing	HPC	-12.586535037754798	64.41213977785719	127795
582d8f718f22cebca8f9ef21dc29c0fbd2371bc6	a novel mobile agent search algorithm	wireless links;search algorithm;mobile computer;mobile environment;network traffic;intelligent agent;binomial distribution;mobile agent	Intelligent agent has been shown to be a good approach to addressing the issues of limited capacity and unreliable wireless links in mobile computing. However, before the approach can be commercially viable, a set of management capabilities that support the controls of intelligent agents in a mobile environment need to be in place. Since controls can only be applied after the target agent is located, an effective agent search algorithm is an indispensable part of the management functions. In this paper, we propose a new algorithm, the Highest Probability First Algorithm, for locating the target agent. The approach makes use of the execution time information to reduce cost and network traffic. The execution time of the agent on a server is assumed to be binomial distributed and therefore is more realistic.	mobile agent;search algorithm	Wen-Shyen E. Chen;Chun-Wu Roger Leng;Yao-Nan Lien	2000	Inf. Sci.	10.1016/S0020-0255(99)00122-X	real-time computing;simulation;mobile database;computer science;binomial distribution;artificial intelligence;autonomous agent;mobile agent;distributed computing;mobile computing;intelligent agent;search algorithm	AI	-9.287950901867594	69.3074359532463	128136
a190de57099653edbbf91f67ff5cca8f836f98ad	a virtual preemption paradigm for using priority rules to solve job shop scheduling problems	history;constraint optimization;job shop scheduling;processor scheduling;resource management;manufacturing industries;simulation experiment;semiconductor device manufacture;production systems;computer science;job shop scheduling problem;job shop scheduling computer science manufacturing industries production systems history semiconductor device manufacture resource management constraint optimization throughput processor scheduling;throughput	To solve job shop scheduling problems, the priority rule is one of the most popular approach. It has the appeal because of simplicity, efficiency and effectiveness. However, the paradigm conventionally used to apply priority rules has a certain flaw. In this paper, we first point out this flaw and then propose a paradigm to remove it. A rule is also developed to exploit the potential of the new paradigm. The performance of the proposed approach is verified by several simulation experiments. The experimental results are quite satisfactory.	experiment;flaw hypothesis methodology;job shop scheduling;preemption (computing);programming paradigm;scheduling (computing);simulation	Tsung-Che Chiang;Li-Chen Fu	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570684	fair-share scheduling;fixed-priority pre-emptive scheduling;job shop scheduling;throughput;real-time computing;earliest deadline first scheduling;simulation;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;resource management;two-level scheduling;deadline-monotonic scheduling;scheduling;production system;least slack time scheduling;lottery scheduling;manufacturing;round-robin scheduling	Robotics	-11.439886480823667	60.918438877347924	128418
343c03be2c50afee2393c882a834383421058d78	a control theory approach to improve the real-time capability of multi-threaded microprocessors	microprocessors;multi threading;control theory;yarn;simultaneous multi threaded;clocks;ipc rate;closed loop systems;real time;control theory in high end microprocessors;multithreaded microprocessors;adaptive control;closed feedback loop;closed feedback controller control theory multithreaded microprocessors closed feedback loop mathematical model;real time microprocessors;feedback;feedback loop;mathematical model;multi threading closed loop systems feedback;point of view;communication system control;control theory microprocessors yarn clocks adaptive control communication system control robotics and automation throughput mathematical model delay;ipc rate control theory in high end microprocessors real time microprocessors;robotics and automation;throughput;closed feedback controller	Our aim is to investigate if it is possible to control the throughput (IPC rate) of a thread running on a simultaneous multi-threaded microprocessor by a closed feedback loop. We showed in previous experimental studies that the proposed approach works. In this paper we discuss the control theory approach from a theoretical point of view. We develop a mathematical model of a general purpose multi-threaded microprocessor enhanced with a closed feedback controller and use control theory methods to investigate properties like stability and settling time.	central processing unit;control theory;direct read after write;earliest deadline first scheduling;feedback;fixed-priority pre-emptive scheduling;instructions per cycle;mathematical model;microprocessor;p (complexity);pid;real-time cmix;real-time transcription;scheduling (computing);settling time;thread (computing);throughput	Uwe Brinkschulte;Mathias Pacher	2008	2008 11th IEEE International Symposium on Object and Component-Oriented Real-Time Distributed Computing (ISORC)	10.1109/ISORC.2008.8	embedded system;throughput;real-time computing;controller;multithreading;adaptive control;computer science;operating system;automatic control;feedback loop;mathematical model;feedback;distributed computing;feed forward	Embedded	-6.543381520925595	61.74893000450071	128480
bb87c839436d75304212426ba678ef1fc93a4962	scheduling divisible loads with processor release times and finite size buffer capacity constraints in bus networks	divisible loads;finite buffers;simulation experiment;processing time minimization;processor release times;communication delay;analytic solution;buffer capacity;communication delays	In this paper we address the problem of processing a computationally intensive divisible load with high memory requirements on a bus network. Each network node is assumed to have a limited memory capacity (buffer space), while at the same time being available for processing after a specific time (release time). The combined influence of the release times, as well as the limited buffer capacity available, is considered in the problem formulation, with the objective to minimize the overall processing time of the divisible load. In the existing literature, these two issues have been considered independently, although in practice, they are commonly found to coexist. The Multi-Installment Balancing Strategy (MIBS) presented in this paper, manages to address both of these constraints by building on-top of the analytical solutions derived by a buffer capacity-unaware approach. MIBS monitors the available resources and adapts the processing and communication phases according to their availability. Towards this goal both single and/or multi-installment scheduling is utilized. The description of the algorithms accompany simulation experiments that highlight the behavior of MIBS. It should be stressed that the use of MIBS allows the processing of loads that exceed by far the total memory capacity of the available machines, while at the same time exhibiting processing times that match the ones predicted by strategies that ignore the memory constraints.	algorithm;bus network;care-of address;central processing unit;coexist (image);experiment;high memory;load balancing (computing);overhead (computing);requirement;scheduling (computing);simulation	Bharadwaj Veeravalli;Gerassimos D. Barlas	2003	Cluster Computing	10.1023/A:1020971118034	closed-form expression;parallel computing;real-time computing;computer science;operating system;distributed computing	HPC	-14.145066637407941	62.010321098293716	128629
2f4d79d051876fc337d66d4fdc3ca8a23aa5f00d	a low cost and inner-round pipelined design of ecb-aes-256 crypto engine for solid state disk	ecb aes 256 crypto engine;look up table;random access memory;inner round pipelined techniques;encryption;encryption engines table lookup random access memory registers pipelines;loop rolling pipelined techniques;subbytes operation;ecb aes 256 crypto engine ssd inner round;flash memories cryptography;aes encryption module;engines;invsubbytes operation;registers;cryptography;ssd;data encryption standard;pipelines;inner round;data access;inner round pipelined techniques ecb aes 256 crypto engine solid state disks advanced encryption standard aes encryption module aes decryption module look up table subbytes operation invsubbytes operation loop rolling pipelined techniques;power consumption;advanced encryption standard;high throughput;solid state disks;table lookup;high speed;aes decryption module;flash memories;reading and writing	Solid-State Disks (SSD) are widely used in government and security departments owing to its faster speed of data access, more durability, more shock and drop, no noise, lower power consumption, lighter weight compared with Magnetic disk. As a result, the demand of security for storing data has been generated. The Advanced Encryption Standard (AES) is today's key data encryption standard for protecting data, but the implementation of high-speed AES encryption engine needs to consume a large number of hardware resources. This paper presents a low-cost and inner-round pipelined ECB-256-AES encryption engine. Through sharing the resources between the AES encryption module and the AES decryption module and using the look-up table for the SubBytes and InvSubBytes operations, the logic resources have been largely reduced; by using loop rolling and inner-round pipelined techniques, a high throughput of encryption and decryption operations is achieved. A 1.986Gbits/s throughput and 232.748MHz clock frequency are achieved using 614 slices of the Xilinx xc6slx45-3fgg484. The simulation results show that the AES crypto design is able to meet the read and write speed of SATA 1.0 interface.	clock rate;data access;durability (database systems);encryption;europe card bus;floppy disk;lookup table;magnetic storage;pipeline (computing);serial ata;simulation;solid-state drive;throughput;whirlpool (cryptography)	Fei Wu;Liang Wang;Jiguang Wan	2010	2010 IEEE Fifth International Conference on Networking, Architecture, and Storage	10.1109/NAS.2010.40	advanced encryption standard;data access;embedded system;parallel computing;encryption software;disk encryption theory;40-bit encryption;disk encryption;computer hardware;computer science;cryptography;operating system;filevault;on-the-fly encryption;disk encryption hardware;aes implementations;computer security;encryption;56-bit encryption	EDA	-5.790610932371184	65.00870587717613	128675
b014b2773002932c08495a5266e4705118e110e5	balancing traffic load for devolved controllers in data center networks	measurement;switches linear programming monitoring measurement algorithm design and analysis manganese;会议论文;np completeness traffic load balancing data center networks centralized controller resource management cloud services scalability concern unbalanced work load reconfiguration complexities large scale data centers load balancing problem for devolved controllers lbdc;manganese;monitoring;linear programming;switches;algorithm design and analysis;resource allocation cloud computing computational complexity computer centres	Using a centralized controller for resource management and coordination is a common practice in cloud services. For scalability concern, in recent literature a novel approach, namely devolved controllers, was proposed. Such approach splits the network into regions, while each controller only monitors a portion of the traffic. This technique alleviates scalability issue, but brings other critical problems, such as unbalanced work load among controllers and reconfiguration complexities. In this paper, we investigate the usage of devolved controllers for large-scale data centers, and design a new scheme to overcome shortcomings, and to improve system performance. We first define Load Balancing problem for Devolved Controllers (LBDC), and prove its NP-completeness. For LBDC, we design an f-approximation, where f is the largest number of potential controllers for a switch in the network. We also propose both centralized and distributed approaches to solve LBDC time effectively. The numerical results validate our designs, which become a solution to manage and coordinate large-scale data centers.	approximation;centralized computing;cloud computing;controller (computing);data center;distributed algorithm;dynamic circuit network;image scaling;load balancing (computing);np-completeness;numerical analysis;performance evaluation;responsiveness;scalability;throughput;unbalanced circuit	Wanchao Liang;Xiaofeng Gao;Fan Wu;Guihai Clien;Wei Wei	2014	2014 IEEE Global Communications Conference	10.1109/GLOCOM.2014.7037144	real-time computing;simulation;computer science;linear programming;manganese;operating system;distributed computing;measurement;computer network	Embedded	-18.771859776700314	65.08150962429082	128715
f33fe04fa65fb5900a45a4ea889f42ae77431baa	task assignment using a problem-space genetic algorithm	genetic algorithm;task assignment	Abstract#R##N##R##N#The task assignment problem is one of assigning tasks of a parallel program among the processors of a distributed computing system in order to reduce the job turnaround time and to increase the throughput of the system. Since the task assignment problem is known to be NP-complete except in a few special situations, satisfactory suboptimal solutions obtainable in a reasonable amount of computation time are generally sought. In the paper we introduce a technique based on the problem-space genetic algorithm (PSGA) for the static task assignment problem in both homogeneous and heterogeneous distributed computing systems to reduce the task turnaround time and to increase the throughput of the system by properly balancing the load and reducing the interprocessor communication time among processors. The PSGA based approach combines the power of genetic algorithms, a global search method, with a simple and fast problem-specific heuristic to search a large solution space efficiently and effectively to find the best possible solution in an acceptable CPU time. Experimental results on test examples from the literature show considerable improvements in both the assignment cost and the CPU times over the previous work. The proposed scheme is also applied to a digital signal processing (DSP) system consisting of 119 tasks to illustrate its balancing properties and computational advantage on a large system. The proposed scheme offers 12–30% improvement in the assignment cost as compared to the previous best known results for the DSP example.	genetic algorithm	Imtiaz Ahmad;Muhammad K. Dhodhi	1995	Concurrency - Practice and Experience	10.1002/cpe.4330070506	parallel computing;real-time computing;linear bottleneck assignment problem;genetic algorithm;computer science;generalized assignment problem;operating system;distributed computing;weapon target assignment problem	PL	-14.033252614774364	61.76731281147091	128721
0e12d7a004ea77a19391053fe10d333ab39dbbc8	brief announcement: analysis of a randomized contention-resolution protocol for distributed access	distributed protocol;local distributed protocols;probabilistic analysis;randomized protocols;contention resolution;load balancing;load balance	1. PROBLEM STATEMENT AND PROTOCOL We study the following abstract distributed access problem which naturally arises in many settings. Consider a network of n processors and each has one data item (for a total of n items). Each processor wants to access all (or some number, say k < n) of the data items located in the other processors. In one step, a processor can request only one data item from one other processor. If more than one processor requests the same data item in the same step only one will be able to access it and ties are broken randomly. We assume that success or failure to access an item will be known in the same step. We would like to design a simple and natural distributed algorithm where there is no coordination of requests among nodes and every node acts independently in a distributed (and selfish) manner. Our first goal is to minimize the time taken for all the processors to access all (or a specified number of) the items. Also, suppose that an item moves to a (new) processor when it is successfully accessed. That is, when processor A gets an item from processor B, A’s storage space increases by 1 and B’s storage space decreases by 1. If the items move, then our second goal is to minimize the storage space of all the processors during the entire course of the algorithm. If the nodes can somehow coordinate among themselves (e.g., in a round-robin fashion) all nodes can access all the items in n− 1 steps storing only one item at any time and this obviously is optimal with respect to both time and space. Broadcasting each item to all processors is possible. However, fast broadcasting involves	central processing unit;data item;distributed algorithm;randomized algorithm;randomness;round-robin dns;round-robin scheduling	Gopal Pandurangan;GaHyun Park	2005		10.1145/1073814.1073865	general inter-orb protocol;real-time computing;computer science;load balancing;distributed computing;computer network	Theory	-13.833511882477177	65.46967094046393	128734
e05bb730041a2635291a69ab70b79bcc7ce34c6b	link travel time prediction for decentralized route guidance architectures	automated highways driver information systems digital simulation iterative methods;traffic simulation;optimisation;time dependent;systeme intelligent;route guidance;fixed point theorem;travel time;optimizacion;road traffic;sistema inteligente;automated highways;temps minimal;traffic estimation;indexing terms;dynamic routing;dynamic linking;theoreme point fixe;teorema punto fijo;fixed point;decentralized system;iterative methods;trafic routier;transit time;troy link travel time prediction decentralized route guidance architectures anticipated congestion fixed point property traffic simulations dynamic route determinations dynamic link times back dating process stable routing;intelligent system;service oriented architecture vehicle dynamics vehicles broadcasting navigation traffic control predictive models routing telecommunication traffic information analysis;sistema descentralizado;temps parcours;minimum time;trafico carretera;optimization;systeme decentralise;information system;optimal prediction;tiempo recorrido;tiempo minimo;fixed point property;driver information systems;systeme information;digital simulation;sistema informacion	Wunderlich, Kaufman, and Smith 2 routing after a finite and usually small number of iterations. An empirical case study based on the roadway network in Troy, Michigan is included. * This research was supported in part by the University of Michigan ITS Research Center of Excellen Wunderlich, Kaufman, and Smith	centralized computing;device driver;fastest;fixed point (mathematics);iteration;link time;onset (audio);real-time computing;real-time transcription;routing;wunderlich (vacuum tube)	Karl E. Wunderlich;David E. Kaufman;Robert L. Smith	2000	IEEE Trans. Intelligent Transportation Systems	10.1109/6979.869017	simulation;index term;adaptive routing;decentralised system;control theory;mathematics;fixed point;transport engineering;iterative method;fixed-point theorem;information system;fixed-point property	Robotics	-4.782790968741281	69.65336225205795	128971
1c045bc6cf49f33695d54bcac9cd2ce39dfd4e91	statistical rate monotonic scheduling	priority assignment decisions;job admission controller;classical rms results;task isolation statistical rate monotonic scheduling classical rms results periodic tasks highly variable execution times statistical qos requirements task resource requirements guaranteed qos srms job admission controller multiple tasks feasibility test scheduling algorithm statistical qos constraints job admission controller srms scheduler preemptive fixed priority scheduler admit reject priority assignment decisions;real time computing and communication;task resource requirements;processor scheduling;resource allocation;guaranteed qos;multiple tasks;scheduling algorithms and analysis;resource management;testing;statistical qos requirements;multiprogramming;scheduling algorithm;programming theory;internet;statistical analysis;highly variable execution times;periodic tasks;probabilistic analysis;statistical rate monotonic scheduling;statistical qos constraints;scheduling;testing scheduling algorithm statistics processor scheduling internet computer science reactive power statistical analysis resource management real time systems;feasibility test;srms job admission controller;srms scheduler;statistics;rate monotonic scheduling;technical report;preemptive fixed priority scheduler;computer science;fixed priority scheduling;task isolation;admit reject;quality of service qos management;operating systems;admission control;real time systems;programming theory scheduling multiprogramming statistical analysis resource allocation;reactive power	Statistical Rate Monotonic Scheduling (SRMS) is a generalization of the classical RMS results of Liu and Layland [LL73] for periodic tasks with highly variable execution times and statistical QoS requirements. The main tenet of SRMS is that the variability in task resource requirements could be smoothed through aggregation to yield guaranteed QoS. This aggregation is done over time for a given task and across multiple tasks for a given period of time. Similar to RMS, SRMS has two components: a feasibility test and a scheduling algorithm. SRMS feasibility test ensures that it is possible for a given periodic task set to share a given resource without violating any of the statistical QoS constraints imposed on each task in the set. The SRMS scheduling algorithm consists of two parts: a job admission controller and a scheduler. The SRMS scheduler is a simple, preemptive, xed-priority scheduler. The SRMS job admission controller manages the QoS delivered to the various tasks through admit/reject and priority assignment decisions. In particular, it ensures the important property of task isolation, whereby tasks do not infringe on each other. We have evaluated SRMS against a number of alternative scheduling algorithms suggested in the literature, as well as re nements thereof. Consistently throughout our experiments, SRMS provided the best performance. In addition, to evaluate the optimality of SRMS, we have compared it to an ine cient, yet optimal scheduler for task sets with harmonic periods.	algorithm;application programming interface;experiment;fairness measure;job stream;mathematical optimization;naruto shippuden: clash of ninja revolution 3;online and offline;preemption (computing);quality of service;rate-monotonic scheduling;real-time transcription;rejection sampling;requirement;scheduling (computing);smoothing;spatial variability;statistical model	Alia Atlas;Azer Bestavros	1998		10.1109/REAL.1998.739737	fixed-priority pre-emptive scheduling;parallel computing;real-time computing;computer science;resource management;operating system;distributed computing;scheduling	Embedded	-10.440462860512744	62.82100426213679	129049
6a4899be127986118a7d6c5b48f9a2c10c9fcb60	responsive, deterministic ieee 802.5 token ring scheduling	real time;real time scheduling;guaranteed service;time domain;synchronous communication;dynamic adaptation;real time systems	This paper presents a novel approach for scheduling the IEEE 802.5 token ring. This approach not only guarantees deadlines for synchronous class messages, but also dramatically reduces asynchronous class response times. Further, highly responsive guaranteed service is introduced for alert class asynchronous messages. Conventional use of the IEEE 802.5 token ring standard guarantees synchronous communication services using Time Domain Multiplexing (TDM) techniques while relegating asynchronous class message services to background status. The result is poor responsiveness. Further, the TDM schedules tend to be fragile and difficult to modify and extend. This paper presents an algorithmic-based scheduling approach that supportsa priori schedulability determination for arbitrary synchronous message sets without the costly development, testing, and tuning of TDM schedules. This capability allows the IEEE 802.5 standard to support dynamic, adaptive, and reconfigurable run-time environments where the inflexibility of TDM would be prohibitive. Advanced real-time scheduling theory is applied to the IEEE 802.5 token ring standard and dramatically enhances asynchronous class messages' responsiveness while still maintaining guaranteed service for the synchronous class. The result is a highly responsive real-time ring that can form the backbone of predictable, stable, and extendible real-time systems.	extensibility;internet backbone;multiplexing;real-time clock;real-time computing;responsiveness;scheduling (computing);toad data modeler;token ring	Jay K. Strosnider;Thomas E. Marchok	1989	Real-Time Systems	10.1007/BF00571420	real-time computing;time domain;computer science;operating system;asynchronous communication;distributed computing;computer network	Embedded	-9.149766895134126	64.03690140478935	129053
28f2e2a16ec76b48784d296336df53b6f7e6c580	npf-a simple, traffic-adaptive packet classifier using on-line reorganization of rule trees	packet inspection;malicious packet detection;protocols;ids througput;computer network security;packet classification;rule trees;internal data structure;differentiated service;intrusion detection;test bed;network administrator;data mining;memory access;telecommunication traffic;telecommunication traffic computer network security pattern classification;npf traffic adaptive packet classifier rule trees packet classification intrusion detection system network administrator malicious packet detection packet inspection security threats memory access ids througput internal data structure memory bandwidth online reorganization;data structures;security threats;classification algorithms;pattern classification;npf traffic adaptive packet classifier;online reorganization;ip networks;classification tree analysis intrusion detection telecommunication traffic high speed networks computer security inspection throughput computer networks computer displays databases;data structure;memory bandwidth;intrusion detection system	Packet classification is one of the crucial components of application such as firewalls, intrusion detection, and differentiated services. For example, an intrusion detection system (IDS) classifies packets either as benign or malicious and alerts the network administrator when hostile traffic is detected. Since existing IDS spend the majority of CPU time in packet classification, an IDS fails to detect malicious packets under high load. Many ideas have been proposed to make the packet inspection faster so that an IDS spends less time in packet classification. However, because of the increasing number of security threats and vulnerabilities, the number of rules often exceeds thousands, requiring more than hundreds of megabytes of memory. As a result, an IDS spends longer time to classify packets since each packet incurs many memory accesses, and thus the throughput of an IDS is limited by memory bandwidth. The problem can be mitigated by exploiting locality in traffic patterns. In this paper, we propose npf, a fast and traffic-adaptive packet classifier which dynamically reorganizes the internal data structure based on the traffic pattern. Unlike existing approaches requiring a separate, off-line reorganization phase, npf performs reorganization on-line with little overhead, resulting in higher throughput without compromising accuracy. Experimental results on our test bed show that npf outperforms a traditional packet classifier by spending an order of magnitude less time per packet in order to classify the packet.	best, worst and average case;central processing unit;computation;data structure;differentiated services;firewall (computing);heap (data structure);intrusion detection system;link/cut tree;locality of reference;megabyte;memory bandwidth;npf;network packet;online and offline;overhead (computing);packet analyzer;sensor;testbed;throughput;tree rotation	Shariful Hasan Shaikot;Min Sik Kim	2009	2009 IEEE 34th Conference on Local Computer Networks	10.1109/LCN.2009.5355038	intrusion detection system;packet analyzer;fast packet switching;packet generator;data structure;telecommunications;computer science;processing delay;operating system;distributed computing;packet switch;computer security;computer network	Networks	-7.141304136897541	67.12572482092361	129095
97fb00617d21df1903df1d6b422514e32efbdfb3	evaluation of process scheduling mechanism for a web server based on its behavior while executing	web server execution behavior process scheduling mechanism operating systems processor resources fixed scheduling policy computer system timesharing systems processor allocation process execution behavior processing time process scheduling policies web server response time predicted behavior mean response times scheduling parameter;process scheduling mechanism;information resources;control systems;file servers;web server execution behavior;processor allocation;mean response times;information science;web server response time;processor scheduling;resource allocation;real time;resource allocation information resources file servers processor scheduling real time systems;process scheduling policies;computer system;scheduling parameter;processing time;operating system;predicted behavior;process control;fixed scheduling policy;web server;process execution behavior;processor resources;switches;process scheduling;timesharing systems;operating systems;real time systems;web server processor scheduling operating systems real time systems delay control systems process control costs switches information science	Traditional operating systems control the sharing of the processor resources among processes using a jixed scheduling policy based on the Utilization of a computer system such as real-time or timesharing systems. Since the control over the processor allocation is based on a fixed policy, not based on processes’ execution behavior, this can hinder an effective use of a processor or can extend the processing time of a process unnecessarily. Thus, we proposed a couple of process scheduling policies which respond to processes’ execution behavior. One of these policies is the policy f o r improving a Web server’s response time. This policy controls multiple processes of a Web server by adjusting the execution of these processes according to their predicted behavior. And we evaluated the performance of a Web server using this policy in simple cases. In this paper, we evaluate the performance of a Web server when it is busy which is likely to be a realistic case. This could be the case in which it is most desirable to improve the response time of a Web server. Our experimental results show that the mean response times are improved greatly (up to 33.8% in the best case). They also show that the scheduling pornmeter is effectively predicted and updated by our mechanism based on the Web server’s execution behavior.	best, worst and average case;computer;operating system;real-time computing;real-time transcription;response time (technology);scheduling (computing);server (computing);time-sharing;web server;world wide web	Sukanya Suranauwarat;Hideo Taniguchi;Kazuo Ushijima	1999		10.1109/APSEC.1999.809587	file server;real-time computing;information science;network switch;resource allocation;computer science;operating system;foreground-background;process control;distributed computing;scheduling;web server	Metrics	-13.897760766675365	62.86911229359016	129131
2d6b85a5bde4996274155a7cb99eff0d3c57b589	real-time scheduling in cloud-based virtualized software systems	virtual machine;virtualization;cloud;software engineering;hard deadlines;real time scheduling;programvaruteknik	The number of applications that use virtualized cloud-based systems is growing, and one would like to use this kind of systems also for real-time applications with hard deadlines. There is scheduling on two levels in real-time applications executing in a virtualized environment: traditional real-time scheduling of the tasks in the real-time application, and scheduling of different Virtual Machines (VMs) on the hypervisor level. Traditional real-time scheduling is well understood, and most of the existing results calculate schedules based on periods, deadlines and worst-case execution times of the real-time tasks. In order to apply the existing theory also to cloud-based virtualized environments we must obtain periods and worst-case execution times for the VMs containing real-time applications. In this paper, we describe a technique for calculating a period and a worst-case execution time for a VM containing a real-time application with hard deadlines. This new result makes it possible to apply existing real-time scheduling theory when scheduling VMs on the hypervisor level, thus making it possible to guarantee that the real-time tasks in a VM meet their deadlines.	best, worst and average case;cloud computing;hypervisor;real-time clock;real-time computing;real-time locating system;real-time operating system;real-time transcription;run time (program lifecycle phase);scheduling (computing);software system;virtual machine;worst-case execution time	Lars Lundberg;Sogand Shirinbab	2013		10.1145/2513534.2513544	fair-share scheduling;fixed-priority pre-emptive scheduling;embedded system;real-time computing;earliest deadline first scheduling;virtualization;cloud computing;dynamic priority scheduling;computer science;virtual machine;rate-monotonic scheduling;operating system;two-level scheduling;distributed computing	Embedded	-10.231752144653017	60.49035505198911	129189
b05ffa4972862663411336943583be688e327b09	storage-efficient tree structure with level-ordered unary degree sequence for packet classification	packet classification;tree data structure storage efficient tree structure level ordered unary degree sequence internet routers advanced network services virtual private networks quality of service decision tree based packet classification algorithms;decision trees classification algorithms throughput memory management arrays time complexity;level ordered unary degree sequence;virtual private networks decision trees quality of service telecommunication network routing tree data structures;decision tree algorithm;succinct representation;level ordered unary degree sequence packet classification decision tree algorithm succinct representation	Packet classification is an essential function in Internet routers that provides advanced network services such as virtual private networks (VPNs) and quality of service (QoS). Decision tree-based packet classification algorithms such as HiCuts and HyperCuts allow the tradeoff between storage and throughput in the experimental result with the real life rulesets. However, the memory consumption of these algorithms remains high when high throughput is required. In this paper, we propose the tree data structure whose storage is small maintaining high throughput. It is based on the two ideas: The first is to use Level Ordered Unary Degree Sequence (LOUDS) which is a succinct representation of a tree structure. A general tree of n nodes is usually represented in pointer form, requiring 64n bits in 64-bit architecture, whereas LOUDS requires 2n+o(n) bits. Because LOUDS can access any child node from its parent one in constant time, the tree traversal is fast. The second is reducing the information contained in the tree node. This also reduces storage requirements without affecting search speed. The proposed data structure requires up to approximately one ninth less memory than pointer-formed tree, and the time complexity of a packet classification is equivalent to the pointer-formed tree.	64-bit computing;algorithm;data structure;decision tree;degree (graph theory);experiment;network packet;pointer (computer programming);quality of service;real life;requirement;throughput;time complexity;tree (data structure);tree structure;tree traversal;unary operation;virtual private network	Yuta Kitamura;Akira Iwata;Masami Mohri;Yoshiaki Shiraishi	2015	2015 Third International Symposium on Computing and Networking (CANDAR)	10.1109/CANDAR.2015.86	left-child right-sibling binary tree;segment tree;vantage-point tree;binary tree;computer science;trie;theoretical computer science;order statistic tree;incremental decision tree;k-ary tree;interval tree;distributed computing;fractal tree index;search tree;tree;k-d-b-tree;tree traversal;algorithm	Networks	-6.417403651244047	67.77677123835356	129691
b40e597dcb9a3782a1e21b199c4664e3bb9f1028	designing a distributed design exploration framework in the inter-cloud environment	design exploration;simulation;inter cloud;optimization	We propose an extreme-scale distributed design exploration framework in the inter-cloud infrastructure consisting of supercomputers and cloud computing systems. In design explorations, we need to search optimal configurations of input parameters that maximize or minimize objective function(s). In our framework, simulations are performed in parallel employing multiple supercomputers of the Japanese nation-wide high-performance computing infrastructure, and virtual or real machines in academic cloud systems are employed for parameter surveys and optimizations with machine learning. To enable nation-wide scale collaborations of supercomputers and cloud systems, we employ scalable distributed databases and objective storages to store input design parameters and resulting output information generated by simulations.	cloud computing;distributed computing;distributed database;genetic algorithm;ibm websphere extreme scale;interactive evolutionary computation;loss function;machine learning;mathematical optimization;scalability;simulation;supercomputer	Masaharu Muneotmo;Tomoya Abe	2015	2015 IEEE 8th International Conference on Cloud Computing	10.1109/CLOUD.2015.155	simulation;computer science;theoretical computer science;operating system;distributed computing	HPC	-18.00672529723777	60.48387493502153	129715
90bbda48aafe596eb80acfbc43113721825abd1a	hoarding and prefetching for mobile databases	mobile data access;cache storage;prefetching scheme;mobile device;database management systems;mobile radio cache storage database management systems mobile computing;mobile database;data availability hoarding scheme prefetching scheme mobile database mobile data access mobile system cache management mobile device;mobile radio;data access;prefetching databases broadcasting bandwidth association rules availability history downlink delay data mining;hoarding scheme;mobile systems;mobile computing;cache management;mobile system;data availability	One of the main goals of mobile data access is to reach the ubiquity inherent to the mobile systems: to access information regardless of time and place. Due to mobile systems restrictions such as, for instance, limited memory and narrow bandwidth, it is only natural that researchers expend efforts to soothe such issues. This work approaches the issues regarding the cache management in mobile databases, with emphasis in techniques to reduce cache faults while the mobile device is either connected, or with a narrow bandwidth, or disconnected at all. Thus, it is expected improve data availability while a disconnection. In order to improve data availability on the DBMS hosted on mobile device side, this work proposes to select a priori a subset of the data available on the server side DBMS and copy them to the mobile device side DBMS. To the a priori data selection, this work proposes to mine the SQL history of the mobile device user	cpu cache;data access;database;mobile device;sql;server (computing);server-side	Mariano Cravo Teixeira Neto;Ana Carolina Salgado	2006	5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS International Workshop on Component-Based Software Engineering,Software Architecture and Reuse (ICIS-COMSAR'06)	10.1109/ICIS-COMSAR.2006.44	data access;mobile search;mobile database;computer science;mobile device;database;internet privacy;mobile computing;world wide web	DB	-15.576590414978277	68.43960275382055	129824
4d5a1e8554c4e7d1cccf93f1d74bc22f40fc7322	optimization of static task and bus access schedules for time-triggered distributed embedded systems with model-checking	verification;optimal solution;time division multiple access;time triggered;distributed embedded system;scheduling algorithms verification performance model checking optimization;spin static task schedule bus access schedule time triggered embedded system model checking time triggered protocol cpu safety critical embedded system distributed embedded system;helium;processor scheduling;performance;system buses embedded systems program verification safety critical software scheduling;program verification;runtime;embedded system;spin;system buses;embedded systems;scheduling algorithm;model checking;bus access schedule;permission;optimal scheduling;scheduling;heuristic algorithms;safety critical software;access protocols;safety critical embedded system;algorithms;optimization;task scheduling;time triggered embedded system;cpu;heuristic algorithm;time triggered protocol;static task schedule;operating systems;embedded system processor scheduling access protocols heuristic algorithms scheduling algorithm permission operating systems time division multiple access runtime helium	Time-Triggered Protocol for the bus and static task scheduling for the CPU are widely used in safety-critical distributed embedded systems. Researchers have presented efficient heuristic algorithms to jointly optimize static task and bus access schedules. In this paper, we use the model checker SPIN to provide a flexible and configurable technique for obtaining provably optimal solutions, and evaluate its performance tradeoffs compared to heuristic algorithms.	algorithm;central processing unit;embedded system;heuristic;mathematical optimization;model checking;spin;scheduling (computing);state space	Zonghua Gu;Xiuqiang He;Mingxuan Yuan	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278556	embedded system;parallel computing;real-time computing;computer science;operating system;scheduling	EDA	-7.059283412683292	61.34846190535269	129879
631172515da173fcadd3d0f8be0c96ad6cdfc77f	strifa: stride finite automata for high-speed regular expression matching in network intrusion detection systems	strifa acceleration scheme stride finite automata high speed regular expression matching network intrusion detection systems nids data stream attack database string matching attack identification line rate packet processing traffic stream malicious information;nondeterministic finite automaton nfa deep packet inspection dpi deterministic finite automaton dfa network intrusion detection systems nidses;string matching finite automata security of data;doped fiber amplifiers automata memory management pattern matching acceleration educational institutions engines;finite automata;string matching;security of data	Deep packet inspection has become a key component in network intrusion detection systems (NIDSes), where every packet in the incoming data stream needs to be compared with patterns in an attack database, byte-by-byte, using either string matching or regular expression matching. Regular expression matching, despite its flexibility and efficiency in attack identification, brings significantly high computation and storage complexities to NIDSes, making line-rate packet processing a challenging task. In this paper, we present stride finite automata (StriFA), a novel finite automata family, to accelerate both string matching and regular expression matching. Different from conventional finite automata, which scan the entire traffic stream to locate malicious information, a StriFA only needs to scan a partial traffic stream to find suspicious information. The presented StriFA technique has been implemented in software and evaluated based on different traces. The simulation results show that the StriFA acceleration scheme offers an increased speed over traditional nondeterministic finite automaton/deterministic finite automaton, while at the same time reducing the memory requirement.	automata theory;bitstream;byte;complex network;computation;deep packet inspection;deterministic finite automaton;finite-state machine;intrusion detection system;network packet;nondeterministic finite automaton;regular expression;simulation;string searching algorithm;tracing (software)	Xiaofei Wang;Yang Xu;Junchen Jiang;Olga Ormond;Bin Liu;Xiaojun Wang	2013	IEEE Systems Journal	10.1109/JSYST.2013.2244791	nondeterministic finite automaton with ε-moves;real-time computing;computer science;theoretical computer science;operating system;deterministic finite automaton;distributed computing;finite-state machine;dfa minimization;timed automaton;computer security;computer network;string searching algorithm	Security	-7.159165815678363	66.6221322114065	130018
09ca10527318acd34a23cbcdad744881aafff90d	model-driven simulation of world-wide-web cache policies	information systems;real time;informing science;system performance;network servers;internet;organizing;web sites;world wide web delay bandwidth network servers information systems educational institutions web sites internet web server organizing;bandwidth;world wide web;technical report;web server;cache management	The World Wide Web (WWW) has experienced a dramatic increase in popularity since 1993. Many reports indicate that its growth will continue at an exponential rate. This growth has created a tremendous increase in network loads and user response times. The complexity and diversity of many WWW documents (e.g., texts, images, video, audio, etc.) and the diversity of user requested WWW information require sophisticated WWW cache management strategies. Several popular WWW cache algorithms perform rather poorly and lack mathematical or empirical foundations. As a result, WWW system administrators and browser users are forced to arbitrarily define certain important cache parameters. Typically, such systems perform suboptimally averaging hit rates below 55%. Our objective in this study is to develop a cache management strategy that is based on sound theory and principles from the information sciences and that can be utilized on-line, in real-time. Our approach is to study current cache algorithms and utilize actual empirical data to develop efficient and effective self-adaptive cache management strategies to handle anticipated Web growth.	algorithm;information science;model-driven integration;online and offline;real-time clock;simulation;system administrator;time complexity;www;web cache;world wide web	Ying Shi;Edward F. Watson;Ye-Sho Chen	1997		10.1145/268437.268738	web service;web development;web modeling;the internet;simulation;cache;computer science;technical report;web navigation;web page;database;computer performance;multimedia;cache algorithms;world wide web;information system;bandwidth;web server	DB	-17.91476765583419	71.91244362131692	130165
9c1860469f35789fe30500832a44ec68c309a564	implementation and evaluation of scheduling algorithm based on pso hc for elastic cluster criteria		This paper analyses basic concept of elastic cluster as a hybrid solution of high-performance computing tasks for computing grid and cloud. The analysis is focused on the context of managing resources and tasks in the elastic cluster. In this work design, model and implementation of scheduling algorithm is described. The scheduling algorithm is based on particle swarm optimization (PSO) and hill climbing (HC) optimization and it is appropriate combination of good features the both methods. The algorithm is implemented on HPC cluster into the resource manager Torque. There is included methodology of measurement and evaluation of the algorithm. The paper presents methods of verifying behaviour of algorithm for different tasks requirements, which are typical for grid or elastic cluster. We compare suitability of the proposed algorithm with known solutions. On the base of analysed results is confirmed that proposed algorithm better satisfies specific criteria of elastic cluster.	algorithm;amazon elastic compute cloud (ec2);experiment;fifo (computing and electronics);grid computing;hill climbing;job design;job shop scheduling;makespan;mathematical optimization;maximal set;particle swarm optimization;phase-shift oscillator;requirement;scheduling (computing);simulation;supercomputer;torque;verification and validation	Jarmila Skrinarova	2014	Central European Journal of Computer Science	10.2478/s13537-014-0216-3	mathematical optimization;real-time computing;computer science;distributed computing	HPC	-17.653348114541856	63.13114631097989	130276
5d8a6326ca16692dc7a1889d78551626e7bc7f96	effective low-latency k-nearest neighbor search via wireless data broadcast	time average;batterie;optimisation;power saving;base donnee;secondary cell;informatique mobile;optimum;optimizacion;query processing;acumulador electroquimico;approximation plus proche voisin;traitement requete;arrival time;interrogation base donnee;database;interrogacion base datos;base dato;promedio temporal;value analysis;analyse valeur;battery;low latency;bateria;energy consumption;tiempo llegada;accumulateur electrochimique;indexation;optimo;diffusion donnee;retard;difusion dato;analisis valor;consommation energie;k nearest neighbor;optimization;tratamiento pregunta;data broadcast;power consumption;consommation energie electrique;temps arrivee;wireless data;mobile computing;retraso;database query;nearest neighbor approximation;consumo energia;moyenne temporelle	To facilitate power saving via wireless data broadcast, index information is typically broadcast along with the data. By first accessing the broadcast index, the mobile client is able to predict the arrival time of the desired data. However, it suffers from the drawback that the client has to wait and tune for an index segment, in order to conserve battery power consumption. Moreover, the average time elapsed between the request for the data and its receipt may increase as a result of these additional messages. In this paper, we present a broadcast-based spatial query processing method designed to support K-NN(K-Nearest Neighbor) queries via wireless data broadcast. With the proposed schemes, the client can perform NN query processing without having to tune into an index segment. Experiments are conducted to evaluate the performance of the proposed methods. The resulting latency and energy consumption are close to the optimum values, as the analysis and simulation results indicate.	broadcasting (networking);k-nearest neighbors algorithm;nearest neighbor search	Kwangjin Park;MoonBae Song;Ki-Sik Kong;Sang-Won Kang;Chong-Sun Hwang;Kwang-Sik Chung;Soon Young Jung	2006		10.1007/11733836_67	broadcast domain;broadcast radiation;atomic broadcast;simulation;telecommunications;computer science;artificial intelligence;mobile computing;k-nearest neighbors algorithm;battery;low latency	Mobile	-14.374509339167606	68.88376190757957	130677
1a1f3a915393e05bbb6b72a383b1debb9ebb8823	adaptive acknowledgment scheme for efficient error control in atm clustering system	error recovery;error correction codes;distributed database;performance evaluation;perforation;packet loss;conference;packet switching;transport layer;atm networks;packet loss rate;error correction codes asynchronous transfer mode workstation clusters performance evaluation distributed databases packet switching transport protocols;transport protocols;col;cluster system;error control;distributed databases;programmable control adaptive control error correction asynchronous transfer mode protocols workstations switches cost accounting electronic switching systems computer networks;workstation clusters;high throughput;sscop adaptive acknowledgment workstation clusters atm clustering system error control atm network distributed database server reliable data delivery error recovery protocol transport layer high throughput data transfers packet loss detection error free phase performance evaluation parameter values throughput packet loss rates;data transfer;asynchronous transfer mode	An ATM clustering system is a kind of workstation clusters over an ATM network. Such a system can be used as a distributed database server which requires reliable data delivery. This paper proposes an error recovery scheme at the transport layer for reliable data transfers with high throughput in the ATM clustering system. For such data transfers, acknowledgments are sent periodically as well as at the detection of packet losses. To be efficient the periods of acknowledgments for the scheme are adaptively varied depending on,whether current transfer is either in error-free phase or in an error recovery phase. The design and performance evaluation of the error recovery scheme is presented with a set of parameter values to achieve the best performance. The results show that the proposed scheme operates correctly and efficiently for the ATM clustering system. The throughput performance of the proposed scheme is superior to the SSCOP (service specific connection oriented protocol) regardless of packet loss rates.	atm turbo;acknowledgment index;error detection and correction	Jong-Kwon Lee;Yong Jae Kim;Jae Woong Chung;Tag Gon Kim	1998		10.1109/ICCCN.1998.739907	real-time computing;computer science;distributed computing;distributed database;transport layer;computer network	Networks	-16.915262042194307	69.500969660274	130805
deaea0670a5bda764c25de513443474c4ee2bd29	a scheduling approach with respect to overlap of computing and data transferring in grid computing	data exchange;distributed scheduling;theoretical analysis;data access;grid computing;data transfer	In this paper, we present a two-level distributed schedule model, and propose a scheduling approach with respect to overlap of computing and data transferring. On the basis of network status, node load, and the relation between task execution and task data access, data transferring and computing can occur concurrently in the following three cases: a) A task is being executed on a part of its dataset when the other of its dataset is being replicated; b) A dataset of a scheduled task is being replicated to a node, at which another task is running; c) Data exchange happens when dependant subtasks are running at different nodes. Corresponding theoretical analysis and experimental results demonstrate that the scheduling approach improves execution performance and resource utilization.	algorithm;computation;computational resource;computational science;data access;emoticon;grid computing;mind;parallel computing;scheduling (computing)	Changqin Huang;Yao Zheng;Deren Chen	2003		10.1007/978-3-540-24680-0_14	data exchange;fair-share scheduling;data access;grid file;computer science;theoretical computer science;two-level scheduling;data grid;database;distributed computing;utility computing;round-robin scheduling;grid computing	HPC	-15.137226695027726	60.93936941731417	130812
6469f6ae368b27b700c0ba81d3451f237eeae928	a novel buffer cache scheme for distributed multimedia streaming		In this paper, we present a novel buffer management algorithm for multimedia streaming workload. We carefully examine the workload traces obtained from several streaming servers in service. The analysis results show that most users exhibit non-sequential access pattern using VCR-like operations such as jump backward and jump forward. Moreover, short jump accesses are shown to be common. We exploit the workload characteristics of the VCR-like operation and develop a buffer caching algorithm called Virtual Interval Cachingscheme. Experimental results show that the proposed buffer management scheme yields better performance than the legacy schemes.	algorithm;page cache;sequential access;tracing (software);videocassette recorder	Kyoungwoon Cho;Yeonseung Ryu;Youjip Won;Kern Koh	2003			wireless multimedia extensions;computer science;disk buffer;computer network;distributed computing	DB	-16.144236225150348	71.80641811177284	130898
b0895b9f90a3080b4b2e1f66e4326d8793563625	catfish-pso based scheduling of scientific workflows in iaas cloud		Cloud computing is a technology wherein a network of remote servers is used to process large amount of data in real-time. The servers and data sources may be located in geographically distant regions. Scheduling of workflows is one of the major challenging issues in cloud computing. Workflows are used to express a wide variety of applications including scientific computing and multi-tier web applications. The Workflow scheduling problem is known to be NP-complete. No known traditional scheduling algorithm is able to provide an optimal solution in polynomial time for NP-complete problems. So, researchers rely on heuristics and meta-heuristics to achieve the most efficient solution. In this paper, a workflow scheduling algorithm is proposed to schedule large scientific workflows that are to be executed on IaaS clouds. The workflow scheduling algorithm generates a schedule with the task-to-resource mapping. The metaheuristic Catfish particle swarm optimization (C-PSO) technique is used to select the best schedule with the least makespan and execution cost. The performance of C-PSO is then compared with traditional PSO. The algorithm is simulated on the WorkFlowSim Simulator, an extension of CloudSim simulator. The solution is tested for different types of scientific workflows like Montage, Epigenome, CyberShake and Inspiral. It is observed from the experimental results that C-PSO gives better performance than traditional PSO in terms of execution cost and makespan.	algorithm;cloud computing;cloudsim;computational science;karp's 21 np-complete problems;makespan;mathematical optimization;metaheuristic;montagejs;multitier architecture;particle swarm optimization;polynomial;real-time clock;scheduling (computing);server (computing);tag cloud;time complexity;web application	S. Jaya Nirmala;S. Mary Saira Bhanu	2016	Computing	10.1007/s00607-016-0494-9	fair-share scheduling;real-time computing;dynamic priority scheduling;computer science;database;distributed computing	HPC	-18.799765500876642	63.452220660612596	130941
32acfcc495cbf814d7da73e84af97bef70e60d1e	on the design of hybrid peer-to-peer systems	time scale;peer to peer network;peer to peer system;random walk;mathematical model;scalability;peer to peer	In this paper, we consider hybrid peer-to-peer systems where users form an unstructured peer-to-peer network with the purpose of assisting a server in the distribution of data. We present a mathematical model that we use to analyze the scalability of hybrid peer-to-peer systems under two query propagation mechanisms: the random walk and the expanding ring. In particular, we characterize how the query load at the server, the load at peers as well as the query response time scale as the number of users in the peer-to-peer network increases. We show that, under a properly designed random walk propagation mechanism, hybrid peer-to-peer systems can support an unbounded number of users while requiring only bounded resources both at the server and at individual peers. This important result shows that hybrid peer-to-peer systems have excellent scalability properties. To the best of our knowledge, this is the first time that a theoretical study characterizing the scalability of such hybrid peer-to-peer systems has been presented. We illustrate our results through numerical studies.	experiment;linear programming relaxation;mathematical model;numerical analysis;parallels desktop for mac;peer-to-peer;response time (technology);scalability;server (computing);software propagation	Stratis Ioannidis;Peter Marbach	2008		10.1145/1375457.1375476	scalability;computer science;theoretical computer science;mathematical model;distributed computing;world wide web;random walk;statistics;computer network	Metrics	-13.201872899854312	74.17544568302345	131034
982abb902366d3c3f4503333d7bc8e3b51ef8bee	reduced transmission in multi-server coded caching		Coded caching has been widely used in the wireless network for shifting the some transmissions during the peak traffic times to the off-peak traffic times. Multi-server coded caching, which can share responsibility for the total amount of transmission in the wireless network during the peak traffic times by means of the collaboration among these servers, can be seen everywhere in our life. The three servers setting (two data servers and one parity check server) is used in practice, e.g. redundant array of independent disks-4. In this scenario, there are total N files which are equally stored in two data servers respectively and K users each of which has the memory size of M files. Each server connects to users by an independently channel. During the off-peak traffic times, two data servers place some parts of each files in each user’s cache. In that time, servers do not know users’ requests in future. During the peak traffic times each user just requests one file from N files. Luo et al. in 2016 proposed the first coded caching scheme for this setting. In this paper, we proposed some method that further reduces the amount of transmission in each channel when KM N is odd. This method also improves the transmission rate for systems with general multiply servers.	cache (computing);parity bit;server (computing)	Minquan Cheng;Qiaoling Zhang;Jing Jiang;Ruizhong Wei	2018		10.1007/978-3-030-02738-4_7	discrete mathematics;mathematics;bipartite graph;parity bit;server;distributed computing;transmission (mechanics)	Metrics	-14.681534400153799	71.8372139144666	131310
19f8f5f82fc1942bf808569de3128a5c0b968fd8	exact scheduling analysis of accumulatively monotonic multiframe tasks subjected to release jitter and arbitrary deadlines	protocols;processor scheduling;bismuth;arbitrary deadlines;release jitter;exact scheduling analysis;arbitrary deadline scenario;interference;schedulability analysis;upper bound;fixed priority scheduling scheme;processor scheduling jitter;time factors;am multiframe tasks;fixed priority scheduling;worst case response time;jitter;time factors equations interference jitter bismuth protocols upper bound;accumulatively monotonic multiframe tasks;arbitrary deadline scenario exact scheduling analysis accumulatively monotonic multiframe tasks release jitter arbitrary deadlines am multiframe tasks fixed priority scheduling scheme	An exact scheduling test for AM multiframe tasks executing on a uniprocessor according to the fixed priority scheduling scheme is presented in this paper. The test is given as a generalization of the exact worst case response time of AM multiframe tasks in two directions. First is an improvement of the exact analysis to be applicable to systems that are subjected to release jitter. Whilst the second is to cope with the arbitrary deadline scenario. A combined analysis of both scenarios is also introduced in this paper.	best, worst and average case;fixed-priority pre-emptive scheduling;response time (technology);scheduling (computing);scheme;uniprocessor system;while	Areej Zuhily;Alan Burns	2008	2008 IEEE International Conference on Emerging Technologies and Factory Automation	10.1109/ETFA.2008.4638459	communications protocol;parallel computing;real-time computing;jitter;telecommunications;computer science;bismuth;distributed computing;interference;upper and lower bounds	Embedded	-10.154299892033118	60.73896410266841	131527
c06b75a7fba386aff455333d842cd142fc066e26	platon: peer-to-peer load adjusting tree overlay networks	universiteitsbibliotheek	Peer-to-Peer systems supporting multi attribute and range queries use a number of techniques to partition the multi dimensional data space among participating peers. Load-balancing of data accross peer partitions is necessary in order to avoid the presence of network hotspots which may cause performance degradation or failures within the distributed environment. In this paper, we introduce a novel framework, PLATON, that preserves load balancing accross peer partitions when the multi-dimensional data space is dynamic, without requiring up-to-date global load information, e.g. information about the most loaded or least loaded peers in the network. A theoretical analysis on the upper bounds (ie. worst case) of the proposed algorithm is presented; its performance is evaluated in large-scale simulated networks and validated within in the PlanetLab emulation platform.	overlay network;peer-to-peer	Leonidas Lymberopoulos;Chariklis Pittaras;Mary Grammatikou;Symeon Papavassiliou;Basil S. Maglaris	2012	Peer-to-Peer Networking and Applications	10.1007/s12083-011-0114-6	real-time computing;computer science;theoretical computer science;operating system;database;distributed computing;world wide web;computer security;computer network	Theory	-11.638705161246465	73.06284720840542	131695
fd3410b1e2216af2357e9893d27c493bfc1657de	a network processor-based fault-tolerance architecture for critical network equipments	tolerancia falta;distributed system;red sin hilo;arquitectura red;critical;network design;fiabilidad;reliability;systeme reparti;informatique mobile;fault tolerant;reseau sans fil;redundancia;availability;disponibilidad;gestion red;wireless network;network processor;network fault tolerance;endommagement;architecture reseau;deterioracion;computer architecture;fault tolerant system;sistema repartido;redundancy;architecture ordinateur;network connectivity;fiabilite;fault tolerance;defaillance;gestion reseau;sistema tolerando faltas;systeme tolerant les pannes;network architecture;arquitectura ordenador;network management;failures;damaging;mobile computing;disponibilite;fallo;tolerance faute;redondance;network	Businesses and individuals often suffer from significant amount of damage as a result of network failures, and that is why network fault tolerant mechanism is important for network design and management. The most common failure is happen to the network equipments. Moreover, network equipments located at the entrance of a network play an important role in the availability and reliability of the internal network. Therefore, we design and implement a fault-tolerant system especially for the network equipments located at the entrance of a network. On the situation that no redundant device exists, the fault-tolerant system could bypass the forwarding path to survive the network connections. We adopt the Intel IXDP1200 Network Processor as development platform to implement the proposed system.	fault tolerance;network processor	Nen-Fu Huang;Ying-Tsuen Chen;Yi-Chung Chen;Chia-Nan Kao;Joe Chiou	2004		10.1007/978-3-540-25978-7_76	embedded system;element management system;fault tolerance;network admission control;network traffic control;intelligent computer network;network architecture;network management station;telecommunications;computer science;network information system;network simulation;mobile computing;computer security;network delay;computer network;network access device	HPC	-5.284556400217076	73.80943467303165	131982
65518d011befffdaa1293ace969ec38eff4cf7d6	on the benefits of relaxing the periodicity assumption for networked control systems over can	message scheduling networked control systems;control algorithm;networked control systems;sensors;point to point;benefits relaxing periodicity assumption;dynamic allocation bandwidth;controller area networks;controller;control loops closed;actuators;controller area network;data mining;control system;networked control systems control systems communication system control bandwidth actuators real time systems resource management sensor systems channel allocation wireless sensor networks;distributed environment;can;sensors actuators controller area networks;control system design;bandwidth;communication bandwidth;message scheduling;networked control system;controller area networks benefits relaxing periodicity assumption networked control systems can sensors controller actuators communication bandwidth dynamic allocation bandwidth control loops closed;real time systems	A vast majority of control systems require the use of networks for the communication between the different agents: sensors, controllers, and actuators. The existing paradigm regards the messages, between sensors and controllers and between controllers and actuators, as periodic. Although this strategy facilitates the analysis and implementation, it leads to a conservative usage of the communication bandwidth. Based on previous work by the authors, an aperiodic strategy is proposed in this paper for the dynamic allocation of bandwidth according to the current state of the plants and the available resources. The case of control loops closed over Controller Area Networks (CANs) is discussed in detail and illustrated on a train car.	can bus;control system;dropout (neural networks);instability;memory management;network packet;parameter (computer programming);programming paradigm;quasiperiodicity;sensor	Adolfo Anta Martinez;Paulo Tabuada	2009	2009 30th IEEE Real-Time Systems Symposium	10.1109/RTSS.2009.39	real-time computing;controller;can bus;point-to-point;computer science;networked control system;sensor;control system;bandwidth;distributed computing environment;actuator	Embedded	-8.387156313656844	63.389923339343575	132293
cb2e2a49b252eb528ca1cc00925b4a59d5477356	task-execution scheduling schemes for network measurement and monitoring	simulation ordinateur;time average;distributed system;tiempo espera;resource utilization;occupation time;largeur bande;coloracion grafo;periodic scheduling;network measurement;haute performance;systeme reparti;measurement accuracy;gestion labor;resolucion conflicto;finishing;gestion trafic;reglamento ps;simultaneidad informatica;active measurement;graph coloring;promedio temporal;qos provisioning;high performance networks;traffic management;periodicite;finissage;temps attente;qualite service;multigraph;periodicity;concurrency;periodicidad;sistema repartido;gestion tâche;coloration graphe;temps occupation;monitoring;resolution conflit;periodic tasks;multigrafo;scheduling;waiting time;precision mesure;contention resolution;anchura banda;retard;acabado;tiempo ocupacion;gestion trafico;alto rendimiento;clique number;bandwidth;task assignment;simulacion computadora;monitorage;precision medida;task scheduling;multigraphe;quality of service;network services;ordonnancement ps;monitoreo;retraso;conflict resolution;simultaneite informatique;high performance;computer simulation;clique;service quality;graph colouring;moyenne temporelle;calidad servicio	Measurement is a required process in high performance networks for efficient quality-of-service (QoS) provisioning and service verification. Active measurement is an attractive approach because the measurement traffic injected into the network can be controlled and the measurement tasks can be distributed throughout the network. However, the execution of measurement tasks in common parts of a network may face contention for resources, such as computational power, memory, and link bandwidth. This contention could jeopardize measurement accuracy and affect network services. This contention for limited resources defines a conflict between measurement tasks. Furthermore, we consider two sets of measurement tasks, those used to monitor network state periodically, called periodic tasks, and those for casual measurements issued as needed, called on-demand measurement tasks. In this paper, we propose a novel scheduling scheme to resolve contention for resources of both periodic and on-demand measurement tasks from graph coloring perspective, called ascending-order of the sum of clique number and degree of tasks. The scheme selects tasks according to the ascending order of the sum of clique number and conflict task degree in a conflict graph and allows concurrent execution of multiple measurement tasks for high resource utilization. The scheme decreases the average waiting time of all tasks in periodic measurement tasks scheduling. For on-demand measurement tasks, the proposed scheme minimizes the waiting time of inserted on-demand tasks while keeping time space utilization high. In other words, the total time spent on finishing all the tasks is shortened. We evaluate our proposed schemes under different measurement task assignment scenarios through computer simulations, and compare the performance of this scheme with others that also allow concurrent task execution. The simulation results show that the proposed scheme produces effective contention resolution and low execution delays.	algorithm;clique (graph theory);computation;computer simulation;graph coloring;ibm notes;provisioning;quality of service;run time (program lifecycle phase);scheduling (computing);serializability;sorting	Zhen Qin;Roberto Rojas-Cessa;Nirwan Ansari	2010	Computer Communications	10.1016/j.comcom.2009.11.005	computer simulation;clique;active traffic management;in situ resource utilization;real-time computing;simulation;quality of service;concurrency;telecommunications;computer science;operating system;multigraph;conflict resolution;graph coloring;distributed computing;accuracy and precision;scheduling;service quality;bandwidth	HPC	-11.222559685727868	68.79757339188791	132314
86d34786bd36d78e5d475f84bccfd6ef2de040af	a cost-effective critical path approach for service priority selections in grid computing economy	critical path method cpm;economie;distributed system;optimal solution;economia;intemet resources pricing;selection problem;problema seleccion;haute performance;systeme reparti;incentive compatibility;internet resources pricing;time complexity;trajectoire optimale;cube;resource allocation;pricing;cubo;heuristic method;distributed computing;priorite;service web;adjustment;differentiated service;metodo heuristico;diferenciacion servicio;web service;fijacion precios;camino optimo;reglage;qualite service;critical path method;chemin optimal;service utilisateur;grid;sistema repartido;tariffication;optimal path;chemin critique;computational complexity;optimal trajectory;rejilla;tarification;critical path;time cost tradeoff;trayectoria optima;borne inferieure;alto rendimiento;grille;service differentiation;calculo repartido;cost effectiveness;metodo camino critico;rapport signal bruit;economy;asignacion recurso;relacion senal ruido;methode heuristique;servicio usuario;information system;reglaje;signal to noise ratio;allocation ressource;user service;priority;prioridad;grid computing;high performance;article;calcul reparti;fixation prix;systeme information;differenciation service;service quality;lower bound;heuristic algorithm;recorrido critico;methode chemin critique;network pricing;servicio web;tarificacion;cota inferior;calidad servicio;sistema informacion;probleme selection	The increasing demand for grid computing resources calls for an incentive-compatible pricing mechanism for differentiated service qualities. This paper examines the optimal service priority selection problem for a grid computing services user, who is submitting a multi-subtask job for the priced services in a grid computing network. We conceptualize the problem into a prioritized critical path method (CPM) network, identify it as a time cost tradeoff problem, and differentiate it from the traditional problem by considering a delay cost associated to the total throughput time. We define the optimal solution for the prioritized CPM network as the globally cost-effective critical path (GCCP), the optimal critical path for the solution that minimizes the total cost. As the exponential time complexity of GCCP makes the problem practically unsolvable, we propose a locally cost-effective critical path (LCCP) based approach to the prioritized CPM problem with a heuristic solution. The locally optimized priority constituting the configuration for LCCP can provide a lower bound for the throughput time of GCCP with the same time complexity as that for a traditional CPM problem. To further improve the quality of the solution, we conceive a priority adjustment algorithm named Noncritical Path Relaxation (NPR) algorithm, to refine the priority selections of the nodes on the non-critical paths. A discussion of the effects of the users' priority selections on the grid network pricing is provided to elicit future research on the computing resource pricing problem on the service-side.	critical path method;grid computing	Mei Lin;Zhangxi Lin	2006	Decision Support Systems	10.1016/j.dss.2006.02.010	simulation;computer science;artificial intelligence;operations management;critical path method;operations research	HPC	-10.874463175783616	68.03475395919276	132460
69257e4839580f9cfdb35dbaf5e6bba352d57773	flash data dissemination in unstructured peer-to-peer networks	protocols;peer to peer network;unstructured peer to peer networks;radiation detectors;frequency estimation;unstructured p2p networks;catalogue exchange scheme flash data dissemination unstructured peer to peer networks dynamically created medium sized data unstructured p2p networks gossip based protocol catalogue gossip;dynamically created medium sized data;unstructured p2p networks flash dissemination gossip protocol;catalogue gossip;flash data dissemination;estimation;fault tolerant systems;gossip protocol;fault tolerance;catalogue exchange scheme;peer to peer computing protocols radiation detectors frequency estimation estimation fault tolerance fault tolerant systems;p2p networks;gossip based protocol;flash dissemination;peer to peer computing;data dissemination	The problem of flash data dissemination refers to spreading dynamically-created medium-sized data to all members of a large group of users. In this paper, we explore a solution to the problem of flash data dissemination in unstructured P2P networks and propose a gossip-based protocol, termed catalogue-gossip. Our protocol alleviates the shortcomings of prior gossip-based dissemination approaches through the introduction of an efficient catalogue exchange scheme that helps reduce unnecessary interactions among nodes in the unstructured network. We provide deterministic guarantees for the termination of the protocol and suggest optimizations concerning the order with which pieces of flash data are assembled at receiving peers. Experimental results show that catalogue-gossip is significantly more efficient than existing solutions when it comes to delivery of flash data.	bloom filter;experiment;gossip protocol;interaction;peer-to-peer	Antonis Papadimitriou;Alex Delis	2008	2008 37th International Conference on Parallel Processing	10.1109/ICPP.2008.66	communications protocol;gossip protocol;estimation;fault tolerance;computer science;distributed computing;internet privacy;particle detector;dissemination;statistics;computer network	DB	-8.965947506766245	71.93250353979957	132463
638407e2f7573064d697c89d498b092a0f232e19	hcube: routing and similarity search in data centers	data centre;flat routing;big data;hamming similarity;similarity search	The current Big Data scenario is mainly characterized by the huge amount of data available on the Internet. Some deployed mechanisms for handling such raw data rely on Data Centres (DCs) based on massive storage, memory and processing capacity, in which solutions like BigTable, MapReduce and Dynamo process information in order to provide its retrieval. The HCube presents a DC alternative for data storage/retrieval based on the similarity search, in which similar content is concentrated on servers physically close within the HCube, simplifying the recovery of similar data. A similarity search is performed using a primitive getðk; simÞ, in which k represents the reference content and sim a similarity threshold. The HCube network is organized in a three dimensional structure, in which the Gray Space Filling Curve (SFC) in conjunction with the Random Hyperplane Hashing (RHH) function and the XORbased flat routing mechanism offer an efficient and powerful mechanism for the similarity search. In this context, this work presents the HCube networking solution, detailing the benefits of using the Gray SFC and the XOR-based flat routing mechanism for the similarity search. & 2014 Elsevier Ltd. All rights reserved.	big data;computer data storage;data center;exclusive or;google bigtable;internet;mapreduce;routing table;server (computing);similarity search;space-filling curve	Rodolfo da Silva Villaça;Rafael Pasquini;Luciano Bernardes de Paula;Maurício F. Magalhães	2016	J. Network and Computer Applications	10.1016/j.jnca.2014.08.012	data center;big data;telecommunications;computer science;artificial intelligence;theoretical computer science;operating system;data mining;database;computer security;computer network	OS	-14.736930401116622	74.40228415850532	132539
764a839370a51203f084b517b061a370d4aea95c	cisne: a new integral approach for scheduling parallel applications on non-dedicated clusters	workload;distributed system;integrated approach;systeme temps partage;haute performance;systeme reparti;gestion labor;gang scheduling;distributed computing;time sharing;linux cluster;coreglamento;dynamical system;systeme dynamique;sistema repartido;gestion tâche;tiempo dividido;scheduling;charge travail;coordonnancement;alto rendimiento;calculo repartido;temps partage;profitability;sistema tiempo parcelado;time sharing system;sistema dinamico;task scheduling;point of view;carga trabajo;high performance;job scheduling;calcul reparti;parallel applications;ordonnancement;reglamento	Our main interest is oriented towards keeping both local and parallel jobs together in a non-dedicated cluster. In order to obtain some profits from the parallel applications, it is important to consider time and space sharing as a mean to enhance the scheduling decisions. In this work, we introduce an integral scheduling system for non-dedicated clusters, termed CISNE. It includes both a previously developed dynamic coscheduling system and a space-sharing job scheduler to make better scheduling decisions than can be made separately. CISNE allows multiple parallel applications to be executed concurrently in a non dedicated Linux cluster with a good performance, as much from the point of view of the local user as that of the parallel application user. This is possible without disturbing the local user and obtaining profits for the parallel user. The good performance of CISNE has been evaluated in a Linux cluster.	scheduling (computing)	Mauricio Hanzich;Francesc Giné;Porfidio Hernández;Francesc Solsona;Emilio Luque	2005		10.1007/11549468_27	real-time computing;gang scheduling;computer cluster;computer science;job scheduler;operating system;dynamical system;distributed computing;scheduling;time-sharing;profitability index	HPC	-13.229216423348252	63.78010650692078	132667
d1728f4937e6cc68c02be0833fa41ec1b0748e41	a process scheduling analysis model based on grid environment	system performance;resource sharing;load balancing;load balance;information system;process scheduling;grid computing	The functions of information systems based on grid architecture are resources sharing, collaborative processing, etc. Resources are used by processes. System performance is calculated from resource usages. To have good performance in the system based on grid environment, process scheduling is more important to have load-balancing in all grid nodes. In this paper, we propose a process scheduling analysis model (PSAM) based on grid environment. When the load of the node is high, PSAM can transfer jobs to the most suitable node which selected by supervisor grid node. By this model, we can make all grid nodes be load-balancing. Via implementing this model, we can improve the grid environment performance efficiently.	scheduling (computing)	Huey-Ming Lee;Tsang-Yean Lee;Ching-Hao Cheng;Chia-Hsien Chung	2009		10.1007/978-3-642-03095-6_2	parallel computing;real-time computing;computer science;load balancing;operating system;distributed computing;computer performance;computer security;grid computing	HPC	-17.028738328511864	60.72062849455467	133134
48ac271fc31990620766172c4128dbef813597ed	later validation/earlier write: concurrency control for resource-constrained systems with real-time properties	authorisation;concurrency control real time systems schedules distributed databases database systems delay;database management systems;transaction processing authorisation concurrency control database management systems program verification scheduling;program verification;transaction;eprints newcastle university;dr graham morgan;scheduling;open access;database systems;concurrency control;serializability;distributed databases;schedules;optimistic concurrency control;real time properties optimistic concurrency control resource constraint devices energy efficiency reducing latency battery life transaction scheduling databases latency reduction;real time database system;optimistic concurrency control transaction serializability real time database system;transaction processing;real time systems	We describe an algorithm for optimistic concurrency control suitable for governing transactions operating on databases residing on resource constraint devices. We are concerned with real-time applications that utilize such devices in a computationally demanding manner (e.g., gaming). Therefore, increasing energy efficiency and reducing latency are primary goals for our algorithm to afford higher overall performance and longevity of battery life. We attempt to improve energy efficiency by reducing persistent store access and satisfy real-time requirements via transaction scheduling that affords greater determinism.	algorithm;concurrency (computer science);database;optimistic concurrency control;persistence (computer science);real-time clock;real-time computing;real-time transcription;requirement;scheduling (computing)	Kamal Solaiman;Graham Morgan	2011	2011 IEEE 30th Symposium on Reliable Distributed Systems Workshops	10.1109/SRDSW.2011.11	optimistic concurrency control;real-time computing;transaction processing;schedule;computer science;operating system;concurrency control;database;distributed computing;authorization;serializability;scheduling;distributed database	Embedded	-14.742365710500971	67.21420840760271	133227
8f587def92b347ce1cbd40d10b294c67e644b2d1	upgrading the service capacity of video-on-demand servers with memory buffer	semiconductor memory;service capacity;video on demand	In this paper, we propose a new approach to exploit semiconductor memory to upgrade the service capacity of video-on-demand systems. The basic idea behind this so-called Gneralized Relay Mechanism is that if we can relay the data of frequently accessed programmes from one access request to another, then we can improve the service capacity of the system without requiring higher disk bandwidth. The design of the Generalized Relay Mechanism is aimed at optimizing allocation and trade-off of the memory resource and the disk bandwidth resource. A simulation-based study shows that the Generalized Relay Mechanism is a very competitive alternative in comparision with simply incorporating more hard disks. If compared with an intuitive approach of utilizing memory buffer that always fills up the memory with most frequently accessed programmes, the Generalized Relay Mechanism enjoys an advantage in terms of cost.		Fu-Ching Wang;Chun-Hung Wen;Chih-Yuan Cheng;Meng-Huang Lee;Tzu-How Lin;Szu-Chi Wang;Yen-Jen Oyang	1997	Future Generation Comp. Syst.	10.1016/S0167-739X(97)00020-4	interleaved memory;semiconductor memory;parallel computing;real-time computing;simulation;computer science;operating system;distributed computing;computer security;computer network	Arch	-16.023860898109373	72.05954020492594	133529
16ea002d9ad9d84140f3afdd8b1a19993ac25f88	collaborative web caching based on proxy affinities	trust;reliability;workload characterization;web pages;availability;analytical modeling;feasibility analysis;web accessibility;personal computer usage data;serverless distributed file system architecture;world wide web;exponential growth;security;distributed collaboration;web caching;trace driven simulation	With the exponential growth of hosts and traffic workloads on the Internet, collaborative web caching has been recognized as an efficient solution to alleviate web page server bottlenecks and reduce traffic. However, cache discovery, i.e., locating where a page is cached, is a challenging problem, especially in the fast growing World Wide Web environment, where the number of participating proxies can be very large. In this paper, we propose a new scheme which employs proxy affinities to maintain a dynamic distributed collaborative caching infrastructure. Web pages are partitioned into clusters according to proxy reference patterns. All proxies which frequently access some page(s) in the same web page cluster form an “information group”. When web pages belonging to a web page cluster are deleted from or added into a proxy's cache, only proxies in the associated information group are notified. This scheme can be shown to greatly reduce the number of messages and other overhead on individual proxies while maintaining a high cache hit rate. Finally, we employ trace driven simulation to evaluate our web caching scheme using three web access trace logs to verify that our caching structure can provide significant benefits on real workloads.	(formerly pro/engineer);acm symposium on user interface software and technology;algorithm;cpu cache;cache (computing);clock skew;computer cluster;desktop computer;graph bandwidth;internet access;network packet;overhead (computing);proxy pattern;proxy server;scalability;server (computing);simulation;time complexity;www;web cache;web page;world wide web	Jiong Yang;Wei Wang;Richard R. Muntz	2000		10.1145/339331.339360	web service;feasibility study;availability;exponential growth;web analytics;cache;computer science;information security;operating system;web accessibility;web page;reliability;database;distributed computing;same-origin policy;trustworthy computing;world wide web;web server;computer network	Metrics	-18.734155907054745	71.58293565386003	133796
f28e1f9195f6ced012901e239714b64262c170e2	scheduling with bus access optimization for distributed embedded systems	systeme temps reel;distributed system;schedule tables bus access optimization distributed embedded systems programmable processors application specific hardware components worst case delay temporally deterministic schedule communication protocol communication infrastructures process scheduling bus access scheme;communication process;bus access scheme;protocols;optimisation;time triggered;architecture systeme;systeme reparti;vlsi embedded systems scheduling protocols delays hardware software codesign timing;communication scheduling;calculateur embarque;hardware software codesign;protocole transmission;optimizacion;programmable processors;canal bus;distributed embedded system;perforation;processor scheduling;sistema informatico;canal colector;computer system;communication infrastructures;indexing terms;distributed embedded systems;approche deterministe;embedded system;application specific hardware components;schedule tables;proceso comunicacion;deterministic approach;computer architecture;embedded systems;processus communication;protocolo transmision;engineering and technology;teknik och teknologier;sistema repartido;system synthesis;optimal scheduling;control system synthesis;scheduling;synthese systeme;worst case delay;graph representation;enfoque determinista;boarded computer;sintesis sistema;access protocols;vlsi;bus channel;communication protocol;arquitectura sistema;ordonamiento;real time system;optimization;systeme informatique;sistema tiempo real;computer hardware;communication system control;system architecture;bus access optimization;process scheduling;optimal algorithm;embedded system hardware optimal scheduling processor scheduling delay access protocols computer architecture timing control system synthesis communication system control;materiel informatique;material informatica;calculador embarque;ordonnancement;temporally deterministic schedule;communication synthesis;time triggered protocol;delays;hardware;real time systems;timing;transmission protocol	(16/12/2018)  Scheduling with Bus Access Optimization for Distributed Embedded Systems In this paper, we concentrate on aspects related to the synthesis of distributed embedded systems consisting of programmable processors and application-specific hardware components. The approach is based on an abstract graph representation that captures, at process level, both dataflow and the flow of control. Our goal is to derive a worst case delay by which the system completes execution, such that this delay is as small as possible; to generate a logically and temporally deterministic schedule; and to optimize parameters of the communication protocol such that this delay is guaranteed. We have further investigated the impact of particular communication infrastructures and protocols on the overall performance and, specially, how the requirements of such an infrastructure have to be considered for process and communication scheduling. Not only do particularities of the underlying architecture have to be considered during scheduling but also the parameters of the communication protocol should be adapted to fit the particular embedded application. The optimization algorithm, which implies both process scheduling and optimization of the parameters related to the communication protocol, generates an efficient bus access scheme as well as the schedule tables for activation of processes and communications.	algorithm;best, worst and average case;central processing unit;communications protocol;control flow;dataflow;embedded system;graph (abstract data type);mathematical optimization;requirement;scheduling (computing)	Petru Eles;Alex Doboli;Paul Pop;Zebo Peng	2000	IEEE Trans. VLSI Syst.	10.1109/92.894152	fair-share scheduling;embedded system;communications protocol;electronic engineering;parallel computing;real-time computing;real-time operating system;computer science;operating system;scheduling;computer network;systems architecture	EDA	-7.149249915581893	61.77722771974922	134110
9d7e0a80aa0f0a6ff6291db90b4a56461f3e5d9b	multicriteria scheduling heuristics for gridrpc systems	dynamic scheduling heuristics;time sharing;multicriteria scheduling;simulation study;experimental evaluation;task graphs;grid computing;dynamic scheduling	In this paper, we address the problem of dynamically scheduling independent tasks and/or application task graphs on a GridRPC environment. Resources are assumed to compute submitted jobs within the time-share model. We present a non-intrusive predictive module, the historical trace manager (HTM), which is able to give the completion date of each task in the system. Four heuristics relying on its estimations are proposed and compared to the well-known minimum completion time (MCT) algorithm. We first analyze the accuracy of the HTM. Then we show with an extensive simulation study, and with numerous scenarios of execution performed on a real-world platform, that our heuristics outperform MCT on several metrics among which are the makespan and the response time.	algorithm;authorization;computation;experiment;graph (discrete mathematics);gridrpc;html;heuristic (computer science);makespan;microsoft solutions framework;mobile data terminal;performance;quality of service;response time (technology);schedule (computer science);scheduling (computing);server (computing);simulation;tree accumulation;whole earth 'lectronic link	Yves Caniou;Emmanuel Jeannot	2006	IJHPCA	10.1177/1094342006061890	fair-share scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;operating system;distributed computing;time-sharing;grid computing	Metrics	-16.375944430990383	63.273404218029604	134281
60682d5e2930e058ced60a8d506fe56c78fea98b	an adaptive mechanism for web browser cache management	cache storage;document handling;adaptive dynamics;internet;adaptive systems;document handling internet cache storage adaptive systems;document dynamics adaptive mechanism web browser cache management proxy server client caching techniques document selection adaptive model document life histories cache performance semi intelligent caching strategies adaptive cache management damped exponential smoothing responsive model;cache management;prefetching computer network management delay history web sites network servers smoothing methods coherence file servers	R esearchers have applied various caching techniques to decrease the network loads and response times caused by the phenomenal growth of the World Wide Web. These strategies include the use of callback, prefetching, and validation.1 However, callback mechanisms, which were developed for dedicated distributed systems, are not appropriate for Web objects, which may be cached in many proxies. Prefetching is also unsuitable, as current cache hit rates are typically only about 50 percent.2 It is, therefore, difficult to know which objects to prefetch or when to prefetch them, and thus impossible to ensure that preemptive document checking will improve cache performance. By contrast, validation has been implemented in most proxy servers and browsers. With this technique, cached files are time stamped with an expiry date, which allows the cached version’s currency to be checked when future requests are made. However, many browsers ignore the document expiry, potentially setting up a coherence problem, where stale documents are served as current.3 The validation method entails three decisions that influence effective cache management:	algorithm;cpu cache;cache (computing);cache coherence;callback (computer programming);distributed computing;download;link prefetching;network performance;prefetch input queue;proxy server;server (computing);simulation;web cache;world wide web	Mike Reddy;Graham P. Fletcher	1998	IEEE Internet Computing	10.1109/4236.656085	real-time computing;cache coloring;the internet;page cache;cache;computer science;artificial intelligence;adaptive system;cache invalidation;operating system;database;smart cache;cache algorithms;law;cache pollution;world wide web	Networks	-17.94877601374948	70.18700532296185	134870
a45a8d8499f413cff0193417b9012d0da6d41684	using shot-change information to prevent an overload of platform resources	computer hardware;algorithms;video;motion estimation;cost effectiveness;displays	Future consumer terminals (TV sets, set-top boxes, displays) will increasingly be based on programmable platforms instead of only dedicated hardware. When the available resources are insufficient to deal with the worst-case requirements then resource overloads might lead to system instability and reduced output quality. For robust and cost-effective media processing on programmable platforms, dynamic resource management is required together with resource-quality scalable video algorithms. rnrnA way to prevent resource overloads is to stop processing when the assigned resources have been used. This may lead to drops and changes in quality. We propose to use shot-change information prior to the actual processing to predict difficult situations and react on them in a proper way. For a scalable motion estimator we show that, after a shot-change, generating motion vectors that indicate zero or close to zero motion prevents overloads, saves resources and can lead to a higher quality.		Rob H. Wubben;Christian Hentschel	2003			image quality;scalability;simulation;cost-effectiveness analysis;video;telecommunications;resource allocation;computer science;resource management;motion estimation;television;computer security;algorithm	OS	-8.488646598793297	73.89746749495325	135087
0e9f9e5da3bd4e4d2017fd068dbe1c0e967be4da	flexray static segment scheduling on two independent channels with gateway	wireless channels automobile industry electronic messaging internetworking protocols telecommunication scheduling;heuristic algorithm flexray static segment scheduling flexray bus automotive industry message transmission time triggered scheduling problem independent communication channel gateway node intercommunication;logic gates schedules payloads job shop scheduling synchronization benchmark testing receivers	The FlexRay bus is a modern standard used in the automotive industry. It offers deterministic message transmission in the static segment following a time-triggered schedule. The scheduling problem for case of use two independent communication channels that can intercommunicate through the gateway node is investigated in the paper. Furthermore, a heuristic algorithm is proposed and evaluated.	algorithm;flexray;heuristic (computer science);schedule (computer science);scheduling (computing)	Jan Dvorák;Zdenek Hanzálek	2015	2015 IEEE World Conference on Factory Communication Systems (WFCS)	10.1109/WFCS.2015.7160554	fair-share scheduling;embedded system;real-time computing;flow shop scheduling;dynamic priority scheduling;engineering;rate-monotonic scheduling;two-level scheduling;computer network	Embedded	-7.874148607610361	63.15246992175184	135306
ac8c8263e0b0ca7578799d9eb61ce38d5f931c9e	a popularity-based data allocation scheme for a vod server	storage allocation;stress;magnetic disc storage;transfer operation;file servers;system response time;motion pictures;application software;information retrieval;magnetic disc storage interactive television interactive video multimedia systems file servers storage allocation;interactive video;information retrieval delay video on demand motion pictures computer science admission control multimedia systems application software stress read only memory;video popularity;multimedia systems;popularity based data allocation scheme;system response time popularity based data allocation scheme video on demand server video popularity data units hot cylinders seek operation rotation transfer operation data unit retrieval vod server;transfer operator;vod server;video on demand;hot cylinders;data unit retrieval;video on demand server;data units;spatial locality;computer science;interactive television;rotation;seek operation;read only memory;disk array;admission control	In the real world, the popularity of each video is different. We propose a new popularity-based data allocation scheme to allocate data units within a cluster such that the corresponding data units of these popular videos are stored in those cylinders at one end of each cluster. Due to a higher spatial locality within these hot cylinders, some data units requested by the users are stored in the same cylinder such that one seek operation, one rotation, and one transfer operation are required to retrieve these data units. Therefore, the time required to retrieve data for these requests can be reduced, thus reducing the system response time as well. Based on our results, the system response time could be reduced by half or even more.	versant object database	Carl K. Chang;Chiao-Chuan Shih;Pattanasak Mongkolwat;Thinh T. Nguyen	1996		10.1109/CMPSAC.1996.542427	file server;application software;real-time computing;disk array;rotation;computer science;operating system;database;interactive television;stress;world wide web;read-only memory	DB	-15.602258117551902	71.4190685937014	135674
5cd275bf3a06bdb2b33335073f06ff211f3b5487	acceleration of deep packet inspection using a multi-byte processing prefilter	computer network security;deep packet inspection	Fast string matching is essential for deep packet inspection (DPI). Traditional string matchers cannot keep up with the continuous increases in data rates due to their natural speed limits. We add a multibyte processing prefilter to the traditional string matcher to detect target patterns on a multiple character basis. The proposed winnowing prefilter significantly reduces the number of identity blocks, thereby reducing the memory requirements. key words: computer network security, deep packet inspection, and string matching	byte;deep packet inspection;network packet;network security policy;overhead (computing);requirement;snort;wide character	Hyejeong Hong;Sungho Kang	2013	IEICE Transactions		embedded system;deep packet inspection;real-time computing;deep content inspection;computer science;theoretical computer science;network security;computer network	Networks	-7.0964830135110155	66.5842845468544	135692
2f53ed86595947247bd9ae5403ba0903677be5a0	key factors in web latency savings in an experimental prefetching system	articulo;web prediction and prefetching;performance evaluation and measurement;web latency reduction	Although Internet service providers and communications companies are continuously offering higher and higher bandwidths, users still complain about the high latency they perceive when downloading pages from the web. Therefore, latency can be considered as the main web performance metric from the user’s point of view. Many studies have demonstrated that web prefetching can be an interesting technique to reduce such latency at the expense of slightly increasing the network traffic. In this context, this paper presents an empirical study to investigate the maximum benefits that web users can expect from prefetching techniques in the current web. Unlike previous theoretical studies, this work considers a realistic prefetching architecture using real traces. In this way, the influence of real implementation constraints are considered and analyzed. The results obtained show that web prefetching could improve page latency up to 52% in the studied traces.	algorithm;baseline (configuration management);cpu cache;download;internet;network traffic control;tracing (software);web performance	Bernardo de la Ossa;Julio Sahuquillo;Ana Pont;José A. Gil	2011	Journal of Intelligent Information Systems	10.1007/s10844-011-0188-x	embedded system;real-time computing;computer science;database;world wide web	Metrics	-18.04980692746021	72.55217516115869	136524
d30ce5f6151026cdba541fecf5e0d73409ea08b5	a discrete dp-wrap scheduling algorithm for multiprocessor systems	ddp discrete dp wrap scheduling algorithm multiprocessor real time systems hierarchical scheduling mechanism global scheduling algorithm discrete time model uniprocessor edf;multiprocessor systems;resource management;fairness notion;optimal scheduling program processors scheduling algorithms scheduling resource management real time systems;real time systems embedded systems processor scheduling;embedded systems;scheduling algorithms;optimal scheduling;scheduling;discrete time model multiprocessor systems optimal scheduling real time systems fairness notion embedded systems;program processors;discrete time model;real time systems	A discrete scheduling algorithm basing on DP-Wrap(DDP) for multiprocessor real-time systems is proposed in this paper. As fairness is a popular concept used in most of the published optimal algorithms(e.g., Pfair, Bfair), many of the scheduling produced by these algorithms leads to much run-time overhead such as preemptions and migrations. Meanwhile, many of the scheduling algorithms(e.g., LLREF, DP-Wrap) adopt a continuous time model, which mismatches the property of real-world digital computer system. Inspired by the DP-fair theory framework, a hierarchical scheduling mechanism is adopted in DDP. At the bottom level, the scheduling is carried out by a global scheduling algorithm basing on discrete time model, while at the top level, tasks are locally scheduled by uniprocessor EDF, which significantly reduces the run-time overhead in that execution pieces of a job can be packed together with a best effort. Analysis and experiment imply that DDP is expectable to outperform the algorithms adopting fairness notion in terms of preemptions and migrations.	algorithm;best-effort delivery;computer;context switch;correctness (computer science);data-directed programming;earliest deadline first scheduling;ftc fair information practice;fairness measure;linear programming;multiprocessing;network switch;overhead (computing);preemption (computing);real-time clock;real-time computing;scheduling (computing);system migration;uniprocessor system;whole earth 'lectronic link;xslt/muenchian grouping	Jingwei Yang;Xiaojian Luo;Xiang Long	2015	2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)	10.1109/SmartCity.2015.194	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;scheduling;gain scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling;i/o scheduling;proportionally fair	Embedded	-10.42008786889464	60.83888119207984	136651
3155a22313ef81b5e121e1fd1df2292b0e30a6f3	phone2cloud: exploiting computation offloading for energy saving on smartphones in mobile cloud computing	energy efficiency;execution time;computation offloading;mobile cloud computing;期刊论文;smartphone	With prosperity of applications on smartphones, energy saving for smartphones has drawn increasing attention. In this paper we devise Phone2Cloud, a computation offloading-based system for energy saving on smartphones in the context of mobile cloud computing. Phone2Cloud offloads computation of an application running on smartphones to the cloud. The objective is to improve energy efficiency of smartphones and at the same time, enhance the application’s performance through reducing its execution time. In this way, the user’s experience can be improved. We implement the prototype of Phone2Cloud on Android and Hadoop environment. Two sets of experiments, including application experiments and scenario experiments, are conducted to evaluate the system. The experimental results show that Phone2Cloud can effectively save energy for smartphones and reduce the application’s execution time. F. Xia · F. Ding · J. Li · X. Kong ( ) School of Software, Dalian University of Technology, Dalian 116620, China e-mail: xjkong@ieee.org F. Xia e-mail: f.xia@ieee.org L. T. Yang Department of Computer Science, St. Francis Xavier University, Nova Scotia, Canada e-mail: ltyang@stfx.ca J. Ma Faculty of Computer and Information Sciences, Hosei University, Tokyo, Japan e-mail: jianhua@hosei.ac.jp	android;apache hadoop;central processing unit;computation offloading;email;experiment;francis;information and computer science;mobile cloud computing;programming paradigm;prototype;run time (program lifecycle phase);semiconductor industry;smartphone;yang	Feng Xia;Fangwei Ding;Jie Li;Xiangjie Kong;Laurence Tianruo Yang;Jianhua Ma	2014	Information Systems Frontiers	10.1007/s10796-013-9458-1	embedded system;real-time computing;simulation;computer science;efficient energy use	Mobile	-16.283268060108398	64.27904622179784	136800
923d19faac7170df39c4beadbcf5a9eafd31ce3a	a study on web caching based on reference characteristics of web objects	web caching;web object heterogeneity;reference characteristics	There are various web caching replacement algorithms related to reference characteristics of web objects were researched. They could be used in regard to user characteristics of caching environment. An aggravation of web object heterogeneity more frequently generates a replacement of a web object, but cannot reflect enough all kinds of characteristics of web object in these traditional replacement techniques. Especially size heterogeneity of an object has an influence on performance of a web caching seriously. Therefore, a study on web caching algorithm with size heterogeneity of an object is required. In this study, we will consider some approaches related to web caching with the reference characteristics of a web object and analyze how it improves performance of the response speed. The paper also covers the methods of usercharacteristics analysis and the methods of its application in web caching systems. We also review an algorithm with reduced heterogeneity of a web object. The algorithm is designed with a divided scope that considered size reference characteristic and reduced size heterogeneity on web object. The performance of the algorithm is analyzed with an experiment. With the experiments results, the algorithm is compared with previous replacement algorithms, and its performance is confirmed with 10%-20% elevation of object-hit ratio and an improvement of response speed.	algorithm;cache (computing);experiment;hit (internet);web cache	Yun Ji Na;Sarvar R. Abdullaev;Il Seok Ko	2008	JCIT			Web+IR	-17.448013637712474	68.29854669760675	136960
7d0ac55ea149ca2d989dd97f7e0e194f79d07ddd	adaptive class-based scheduling of continuous queries	time factors schedules round robin monitoring manuals adaptive systems quality of service;query processing;scheduling data handling quality of service query processing;scheduling;data handling;quality of service;two level scheduling adaptive class based scheduling continuous query data stream management systems dsms cq quality of service requirements adaptive broadcast disk scheduler abd scheduler	The emergence of Data Stream Management Systems (DSMS) facilitates implementing many types of monitoring applications via continuous queries (CQs). However, these applications usually have different quality-of-service requirements for different CQs. In this work, we are proposing the Adaptive Broadcast Disks (ABD) scheduler, a new scheduling policy which employs two-level scheduling that can handle different ranks of CQ classes. The ABD scheduler optimizes the weighted average response time of the CQ classes while still preserving the relative importance of each class. We demonstrate that ABD outperforms state-of-the-art schedulers and adapts to changes in the workload without manual intervention.	conjunctive query;emergence;floppy disk;management system;quality of service;requirement;response time (technology);scheduling (computing);two-level scheduling	Lory Al Moakar;Alexandros Labrinidis;Panos K. Chrysanthis	2012	2012 IEEE 28th International Conference on Data Engineering Workshops	10.1109/ICDEW.2012.38	fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;quality of service;computer science;operating system;group method of data handling;data mining;database;distributed computing;scheduling	DB	-17.063803471230784	62.75226462283159	137437
02effa3949e539ee1aa672047ea4907aa7e4e999	vtube: efficient streaming of virtual appliances over last-mile networks	datacenters;inter datacenter links;network reliability;cloud services	Cloud-sourced virtual appliances (VAs) have been touted as powerful solutions for many software maintenance, mobility, backward compatibility, and security challenges. In this paper, we ask whether it is possible to create a VA cloud service that supports fluid, interactive user experience even over mobile networks. More specifically, we wish to support a YouTube-like streaming service for executable content, such as games, interactive books, research artifacts, etc. Users should be able to post, browse through, and interact with executable content swiftly and without long interruptions. Intuitively, this seems impossible; the bandwidths, latencies, and costs of last-mile networks would be prohibitive given the sheer sizes of virtual machines! Yet, we show that a set of carefully crafted, novel prefetching and streaming techniques can bring this goal surprisingly close to reality. We show that vTube, a VA streaming system that incorporates our techniques, supports fluid interaction even in challenging network conditions, such as 4G LTE.	backward compatibility;book;browsing;cpu cache;cloud computing;compaq lte;executable;last mile;software maintenance;streaming media;user experience;virtual appliance;virtual machine	Yoshihisa Abe;Roxana Geambasu;Kaustubh R. Joshi;H. Andrés Lagar-Cavilla;Mahadev Satyanarayanan	2013		10.1145/2523616.2523636	embedded system;data center;real-time computing;simulation;cloud computing;telecommunications;computer science;operating system;reliability;world wide web;computer network	Networks	-19.05525421444955	74.2681348974967	137605
0fbf94ebc025fe265da28710ee42c122465436fe	streaming, low-latency communication in on-line trading systems	electronic trading;protocols;streaming;decoding;myricom 10 gigabit ethernet technologies;packet payload streaming low latency communication on line trading systems prototype performance on line opra data feed decoder commodity hardware custom designed hardware solutions prototype system latest intel nehalem processors myricom 10 gigabit ethernet technologies innovative algorithmic design dotstar compilation tool commodity components opra feed processing rate;feeds;opra feed processing rate;multiprocessing systems data handling electronic trading microprocessor chips;prototype system;trading system;low latency communication;on line opra data feed decoder;low latency;commodity hardware;custom designed hardware solutions;system integration;gigabit ethernet;innovative algorithmic design;ip networks;commodity components;on line trading systems;multiprocessing systems;data handling;prototype performance;dotstar compilation tool;ethernet networks;program processors;algorithm design;microprocessor chips;latest intel nehalem processors;hardware;prototypes feeds hardware algorithm design and analysis delay decoding technological innovation ethernet networks bandwidth payloads;packet payload	This paper presents and evaluates the performance of a prototype of an on-line OPRA data feed decoder. Our work demonstrates that, by using best-in-class commodity hardware, algorithmic innovations and careful design, it is possible to obtain the performance of custom-designed hardware solutions. Our prototype system integrates the latest Intel Nehalem processors and Myricom 10 Gigabit Ethernet technologies with an innovative algorithmic design based on the DotStar compilation tool. The resulting system can provide low latency, high bandwidth and the flexibility of commodity components in a single framework, with an end-to-end latency of less then four microseconds and an OPRA feed processing rate of almost 3 million messages per second per core, with a packet payload of only 256 bytes.	algorithmic trading;byte;central processing unit;commodity computing;compiler;dbl-browser;data feed;end-to-end encryption;end-to-end principle;gigabit;library (computing);nehalem (microarchitecture);network interface controller;network packet;online and offline;operating system;oriented point relation algebra;parsing;protocol stack;prototype;seamless3d;streaming media;x86	Hari Subramoni;Fabrizio Petrini;Virat Agarwal;Davide Pasetto	2010	2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)	10.1109/IPDPSW.2010.5470717	embedded system;parallel computing;real-time computing;computer science	Arch	-6.687856173195549	65.53969430586312	137677
971b496be0dd44a139d11bfe340667fbc2311f0a	autonomic multi-server distribution in flash crowds alleviation network	content distribution network;internet load distribution;content distribution networks;load distribution;flash crowds	The Flash crowds are rapid increase in access to contents of web sites, which makes the web sites inaccessible, leaving the clients with unsatisfied requests. The major shortcoming of flash crowds researches is that they do not assist vital resizing feature of a cloud of the surrogates; the surrogates involved in the alleviation process do not change from the start to the end of flash crowds. Our system, FCAN (Flash Crowds Alleviation Network) is a system to provide resources to web sites to overcome flash crowds. A main feature of FCAN is its dynamically resizing feature, which can adapt to request load of flash crowds by enlarging or shrinking a cloud of surrogate servers used by the web sites. In this paper, we present a new feature of FCAN to support multiple servers which experience different flash crowds simultaneously, and show experiment results with real web log data provided by Live Eclipse 2006.	adobe flash;autonomic computing;blog;database;distributed shared memory;eclipse;flash crowds alleviation network;internet;lazy evaluation;network congestion;release consistency;server (computing);simulation;slashdot effect;surrogates	Merdan Atajanov;Toshihiko Shimokawa;Norihiko Yoshida	2007		10.1007/978-3-540-77090-9_28	simulation;computer science;weight distribution;operating system;internet privacy;world wide web;computer security	DB	-18.129260642539816	71.22657367986078	137773
cc06bfdf3c1b2954512743572ab39dce19177c29	energy aware list-based scheduling for parallel applications in cloud		As the growth of energy consumption has been explosive in current data centres and cloud systems, it has drawn greater attention in academia, industry and government. Task scheduling as a core in systems, it has become an important method to reduce energy dissipation. This paper proposes an energy aware list-based scheduling algorithm called EALS for parallel applications in the context of service level agreement (SLA) on cloud data centres. First, the EALS algorithm comprehensively considers the high power processors to minimise the number of high power processors used. Then, the algorithm try to migrate some tasks from a high power processor to a low power processor for energy saving. Finally, the EALS algorithm takes a more efficient way to assign the time slots among tasks based on the dynamic voltage scaling (DVS) technique. To demonstrate the effectiveness of the EALS algorithm, randomly generated graphs and several real-world applications are tested in our experiments. The experimental results show that the EALS algorithm can save up to 43.96% energy consumption for various parallel applications as well as balance the scheduling performance.	algorithm;apache hadoop;central processing unit;cloud computing;dynamic voltage scaling;experiment;ibm power microprocessors;image scaling;procedural generation;scheduling (computing);service-level agreement	Yongxing Liu;Keqin Li;Zhuo Tang;Keqin Li	2018	IJES	10.1504/IJES.2018.10015746	computer science;parallel computing;scheduling (computing);cloud computing	HPC	-18.704283743517706	61.903230850329585	137896
a118d25d3b87f3df37da557138753e8ee873b502	special issue on energy efficient methods and systems in the emerging cloud era		The energy consumption of information and communication technologies is today significant even when compared with other industries. The collective electricity consumption of communication networks, data centers and personal computers is growing at a rate of 6.6% per year and is predicted that 14% of the worldwide electrical energy in 2020 will be consumed by the ICT sector. While in the past performance was considered as the primary metric in the design of communication and computing systems, energy consumption and power dissipation are nowadays the two main optimization metrics. Designing power and energy efficient computing and communication system requires modeling, analysis, simulation capabilities, design techniques, optimization methods, algorithms and CAD tools operating at all levels of the design flow. This special issue attempts to create a platform to foster new ideas and technical insights for designing energy and power efficient communication and computing systems in the emerging cloud computing era. From the twenty received manuscripts, the guest editors selected only two manuscripts for this special issue. Six manuscripts are currently under revision and, if accepted, will be published in future issues of the journal. The first paper, Power and performance management for parallel computations in clouds and data centers, by Keqin Li, addressed scheduling independent and precedence constrained parallel tasks on multiple homogeneous processors in a data center with dynamically variable voltage and speed as combinatorial optimization problems. The author considers the problem of minimizing schedule length with energy consumption constraint and the problem of minimizing energy consumption with schedule length constraint on multiple processors. The proposed approach results in significant performance improvement as compared with previous algorithms. The second paper, Heterogeneity and thermal aware adaptive heuristics for energy efficient consolidation of virtual machines in Infrastructure clouds, by Mohan Raj Velayudhan Kumara and Shriram Raghunathan, observes that decisions like workload type, server configuration, load, utilization etc., contribute to power consumption and influence datacenter’s thermal profile and impact the energy required to control temperature within operational thresholds. Based on this, the authors present an adaptive virtual machine placement and consolidation approach to improve energy efficiency of a cloud datacenter. The proposed approach accounts for server heterogeneity, server processor low-power SLEEP state, state transition latency and integrated thermal controls to maintain datacenter within operational temperature. The guest editors would like to thank the authors for their valuable contributions to this special issue and all of the reviewers, who provided constructive suggestions and thorough reviews during the paper selection process. The encouragements and support from the managing editor, Prof. Michael Segal, and the editorial staff of the Journal of Computer and System Sciences throughout the preparation of this issue are also greatly appreciated.	algorithm;cpu power dissipation;central processing unit;cloud computing;combinatorial optimization;computation;computer-aided design;data center;heuristic (computer science);journal of computer and system sciences;low-power broadcasting;mathematical optimization;personal computer;scheduling (computing);semiconductor consolidation;server (computing);simulation;state transition table;telecommunications network;thermal profiling;virtual machine	Maurizio Palesi;Mario Collotta;Masoud Daneshtalab;Pradip Bose	2016	J. Comput. Syst. Sci.	10.1016/j.jcss.2015.11.006	theoretical computer science;discrete mathematics;cloud computing;mathematics;efficient energy use;information and computer science	HPC	-15.562525283676106	63.04207456472425	138053
259c7527791bad1f97afe1c4421cfd4bd06a2642	on unit task linear-nonlinear two-cluster scheduling problem	total order;multiprocessor;complexity;parallel and distributed processing;parallel and distributed computing;clustering;optimal scheduling;scheduling;exact algorithm;scheduling problem;task graphs	In parallel and distributed processing, tasks are ordinarily clustered and assigned to different processors or machines before they are scheduled. The assignment of tasks to processors is called clustering. The ordering of tasks for execution is called cluster scheduling. The set of tasks is typically modelled as a directed acyclic task graph (DAG). As a result of the clustering process, the set of tasks in each cluster either forms a total ordering, called linear, or it doesn't, called nonlinear, with respect to the DAG. It has been shown that two-cluster scheduling with one cluster being linear and the other nonlinear is strongly NP-hard. In this paper, we develop an exact algorithm to compute an optimal schedule for the above problem in O(e + α(n)n) time when tasks are restricted to unit tasks, where n is the number of nodes, e is the number of edges, and α(n) is similar to inverse Ack-erman function. We also show that when both clusters are nonlinear, even when tasks are restricted to unit-tasks and task graphs are restricted to those having no path of length more than three, the problem remains NP-complete in the strong sense.	central processing unit;cluster analysis;computer cluster;directed acyclic graph;distributed computing;exact algorithm;np-completeness;np-hardness;nonlinear system;scheduling (computing)	Zhichun Xiao;Wing Ning Li;Jing-Fu Jenq	2005		10.1145/1066677.1066839	fair-share scheduling;fixed-priority pre-emptive scheduling;job shop scheduling;parallel computing;complexity;real-time computing;multiprocessing;dynamic priority scheduling;computer science;operating system;distributed computing;cluster analysis;scheduling;multiprocessor scheduling;total order	HPC	-12.873629296702992	61.34660022119162	138712
df1e41f843ca2b3db91a3e9746836c0179a778ab	a grid scheduling algorithm for bag-of-tasks applications using multiple queues with duplication	grid scheduling;resource utilization;grid scheduling algorithm;computational grid;multiple queues duplication;scheduling algorithm processor scheduling grid computing resource management distributed computing security computer networks computational modeling information technology australia;bag of tasks application;resource allocation;mqd algorithm;duplication scheme grid scheduling algorithm bag of tasks application multiple queues duplication mqd algorithm;scheduling algorithm;bag of tasks;scheduling;it adoption;scheduling grid computing resource allocation;grid computing;evaluation studies;large scale problem;duplication scheme	Over the past decade the computational grid has emerged as an attractive platform to tackle various large-scale problems, especially in science and engineering. One primary issue associated with the efficient and effective utilization of heterogeneous resources in a grid is scheduling. Grid scheduling involves a number of challenging issues mainly due to the dynamic nature of the grid. In this paper, we propose a novel scheduling algorithm, called the multiple queues with duplication (MQD) algorithm for bag-of-tasks applications in grid environments. The proposed algorithm makes scheduling decisions implicitly taking the recent workload pattern of resources into account. In addition, it adopts a duplication scheme in order to achieve better resource utilization and to lead to better schedules. In our evaluation study a number of intensive experiments with various simulation settings have been conducted. Based on the experimental results, MQD confidently demonstrated its practicability and competitiveness with four previously proposed algorithms	algorithm;data deduplication;experiment;grid computing;schedule (computer science);scheduling (computing);simulation	Young Choon Lee;Albert Y. Zomaya	2006	5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS International Workshop on Component-Based Software Engineering,Software Architecture and Reuse (ICIS-COMSAR'06)	10.1109/ICIS-COMSAR.2006.7	fair-share scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;distributed computing;scheduling	HPC	-16.703178145674887	61.56540381358427	139040
9798351d74314083bc478175a6b182af532ecf28	energy-aware optimal cache consistency level for mobile devices	energy conservation;mobile device;cache consistency;wireless network;optimization	Power consumption in a mobile device is an important performance metric. It is strongly required for the mobile device to access wireless links efficiently because wireless communication expends a significant amount of energy per second. By using cache schemes, we can reduce communication costs and enhance performance by storing and reusing recently used data. However, the cached data on the mobile device should be updated in sync with the original data on the server as they are being modified. With a d consistency policy, we can provide the energy-efficient cache consistency level by setting d in accordance with various environmental parameters. This paper proposes a method to determine the optimal d that minimizes the overhead energy expenditure for mobile devices in wireless web environments. We derive the optimal d from a mathematical model and conduct a simulation for validation. We also implement a test application for the proposed optimal d method on a test-bed and assess its performance. 2012 Elsevier Inc. All rights reserved.	cpu cache;cache coherence;mathematical model;mobile device;overhead (computing);server (computing);simulation;testbed;turing test	Sung-Hwa Lim;Se Won Lee;Mye M. Sohn;Byoung-Hoon Lee	2013	Inf. Sci.	10.1016/j.ins.2012.09.035	embedded system;real-time computing;energy conservation;computer science;wireless network;mobile device;distributed computing	Mobile	-14.820000328251641	68.60965520709784	139069
fe6f8cdd9fa918737dd1a72eb34ac7a4fffce25c	ip address lookup by using gpu	longest prefix matching;ip address lookup;longest prefix matching ip address lookup cuda;graphics processing units data structures ip networks hardware instruction sets registers;cuda;registers;data structures;graphics processing units;ip networks;dual data structures gpu parallel ip address lookup architecture graphics processing unit compute unified device architecture cuda host function device function data structure construction data structure update computational resources lookup time trie based data structure multibit stride trie depth reduction texture cache efficiency improvement ipv4 routing tables gt200 gpu;instruction sets;hardware;telecommunication network routing cache storage data structures graphics processing units ip networks parallel architectures	We present a novel parallel IP address lookup architecture based on graphics processing unit (GPU) via compute unified device architecture (CUDA). Our architecture consists of two functions: (1) host function and (2) device function. The host function is executed by a CPU to construct and update the data structure of IP address lookup executed by the device function in a GPU. Both host and device functions are executed simultaneously to fully utilize computational resources. To shorten the lookup time, a trie-based data structure optimized for CUDA is developed. The trie-based data structure uses multi-bit stride to shorten the trie depth and also improves the efficiency of texture cache in GPUs. The experimental results show that a low-end G92 GPU can achieve a throughput of more than 1.3 billion packets per second for IPv4 routing tables with more than 350K prefixes while a high-end GT200 GPU can further double the performance. By employing dual data structures, the implementation can support several hundred thousand updates per second.	cuda;central processing unit;computation;computational resource;data structure;experiment;geforce 200 series;geforce 500 series;geforce 8 series;glossary of computer graphics;graphics processing unit;lookup table;network packet;pci express;routing table;single instruction, multiple threads;throughput;trie	Hung-Mao Chu;Tsung-Hsien Li;Pi-Chung Wang	2013	2013 IEEE 14th International Conference on High Performance Switching and Routing (HPSR)	10.1109/TETC.2015.2460453	computer architecture;parallel computing;data structure;computer science;theoretical computer science;operating system;instruction set;processor register;longest prefix match	HPC	-5.90837341545226	66.53939185919353	139071
79ddff9749b128064afbeb821831651d5a79f92c	towards a self-adaptive super-node p2p overlay based on information exchange	topology;topology matching;query processing;self adaptive super node peer to peer overlay;niobium;search algorithm;p2p;information exchange time self adaptive super node peer to peer overlay information exchange frequency search algorithm query similarity peer to peer topology design;telecommunication network topology peer to peer computing query processing search problems;network topology;query similarity;distance measurement;information exchange frequency;information exchange;information exchange time;success rate;p2p overlay;search problems;network topology peer to peer computing scalability robustness bandwidth delay effects frequency search methods information science design engineering;peer to peer computing;telecommunication network topology;integrated circuits;topology design;peer to peer topology design;topology matching p2p overlay super node information exchange;super node	P2P topology design is a hot topic because it is very important for solving the problems such as deficiency in scalability and effectivity of unstructured P2P overlays. A good topology can greatly improve the performance of search algorithm. The paper proposes a self-adaptive Super-node Overlay Based on Information Exchange called SOBIE. The super-node selection in the SOBIE is different from the general super-node selections which only consider physical capabilities such as bandwidth, CPU processing ability, storage space, and etc.. The SOBIE selects the super-nodes by considering the aggregation of the delay, distance, especially the information exchange frequency, exchange time and query similarity. The SOBIE also detects the free-riders and forces them to quit the system. Through experimental simulations, we prove that the SOBIE has better performance than random or standard super-node P2P topologies in terms of file query success rate, the average query hops, and the total number of query messages.	angular defect;central processing unit;information exchange;peer-to-peer;scalability;search algorithm;simulation;supernode (circuit)	Jiaqi Liu;Zhigang Chen;Deng Li;Hui Liu	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.316	niobium;information exchange;computer science;peer-to-peer;distributed computing;world wide web;network topology;computer network;search algorithm	HPC	-11.971783743024908	74.09411226653584	139125
315f947ffa4c0e39b66131a17ee18800fa3889b5	poster abstract: using linked list in exact schedulability tests for fixed priority scheduling	time factors processor scheduling schedules computer science time complexity electronic mail context;scheduling computational complexity polynomials real time systems;implicit deadline task systems linked list exact schedulability test fixed priority scheduling fixed priority preemptive real time systems periodic sporadic tasks restrictive system model rate monotonic scheduling rm scheduling response time analysis pseudopolynomial time complexity	Summary form only given. In the context of fixed priority preemptive real-time systems, for n periodic/sporadic tasks that comply with a restrictive system model and that have implicit deadlines the Rate-Monotonic (RM) scheduling is optimal. When these tasks are released simultaneously the time required by the first job of each task defines its response time. It thus needs only to make response time analysis or conduct exact schedulability test within a time length no more than the maximum task period (Tn) for RM scheduling, and these tests are thus known to be pseudo-polynomial in time complexity. Although the response time computation for RM schedules of implicit-deadline task-systems has been proved to be an NPhard problem, the scale of many commercial systems is such that pseudo-polynomial exact tests can be used, and to achieve more efficient exact tests such as for online response time analysis (RTA) is one of important considerations of both research motivation and practice stage. The innovative aspect of our solution is that we use a linked list for representing the schedule in the exact response-time schedulability test, referred to as the LList-based test. A busy period in the schedule is represented by a linked list node, recording the starting time and the end time of a busy period, and the pointer to the next node. The simulation is performed task per task in the priority order (from 1 to n), and, when the starting time or the end time of a busy period is the same as that of other busy periods, then the two nodes are merged into one node to represent a longer busy period. For improving the efficiency, memory allocation and recycle for each node are also performed in the user space. The time complexity of the LList-based test is O(N) where N is the total number of jobs within the time length Tn, while the total number of nodes in the linked list is no more than N - n + 1 in the worst case. Our experiments show that the LList-based exact test is a better candidate in exact response-time tests when task periods span no more than three orders of magnitude, since it outperforms the current best exact tests in this scenario, and the needed memory space is also affordable.	best, worst and average case;busy beaver;computation;dspace;experiment;fixed-priority pre-emptive scheduling;linked list;memory management;node (computer science);pointer (computer programming);polynomial;real-time clock;real-time computing;response time (technology);scheduling (computing);simulation;time complexity;user space	Jiaming Lv;Yu Jiang;Xingliang Zou;Albert Mo Kim Cheng	2016	2016 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)	10.1109/RTAS.2016.7461357	priority inversion;fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing;least slack time scheduling;round-robin scheduling	Embedded	-10.27314964548305	61.1356452693022	139816
e62f2e7a25901b7948c5fb47fe1ff740582a26b2	the triangular pyramid scheduling model and algorithm for pdes in grid	directed acyclic graph;resource utilization;feature matching;large scale;scheduling algorithm;parallel discrete event simulation;pdes parallel discrete event simulation;dag directed acyclic graph;grid computing	Grid is a perfect environment for the large scale Parallel Discrete Event Simulation (PDES), because its distribution and collaboration features match the PDES applications well. The PDES tasks or applications are modeled as a Directed Acyclic Graph (DAG), in which the simulation resources consist of three critical factors, simulation hosting machine (SHM), simulation service (SS) and simulation data (SD) in Grid environment. By solving the model we attempt to obtain an optimized triangular matching of the simulation resources on Grid, so that it can support the PDES activities better. We name the algorithm of solving the model Triangular Pyramid Scheduling (TPS). The PDES DAG is divided into three basic graph structures: Sequential structure, Fork structure, and Join structure. The TPS algorithm is developed based on these graph structures. The simulation results show that TPS algorithm can reduce the makespan and congestion, improve the simulation efficiency, and increase the resource utilization efficiency, compared to the existing algorithms.	algorithm;pyramid (geometry);scheduling (computing)	Zhihui Du;Man Wang;Yinong Chen;Yin Ye;Xudong Chai	2009	Simulation Modelling Practice and Theory	10.1016/j.simpat.2009.08.002	mathematical optimization;in situ resource utilization;computer science;theoretical computer science;operating system;distributed computing;scheduling;directed acyclic graph;grid computing	EDA	-15.95550735926055	61.23236814237315	140009
53dab982e5a73c519a9e4714b0f42f979c90c9c5	comparison of auction methods for job scheduling with absolute priorities		The model of geographically distributed computing system with absolute priorities of jobs is described in the paper. Authors designed the decentralized scheduling algorithm using the auction methods. Two auction methods were researched and compared: the first-price sealed-bid auction and the English auction. The paper includes results of experimental comparison of researched auction methods.		Anton Baranov;Pavel Telegin;Artem Tikhomirov	2017		10.1007/978-3-319-62932-2_37	job scheduler;management science;scheduling (computing);english auction;rate-monotonic scheduling;computer science;distributed computing	Theory	-17.43056672916233	63.99743561934595	140172
e9ba262cd71a899e9fc50d4cf9357d29871621de	extending pastry by an alphanumerical overlay	load balancing strategies;total order;hash collisions;range query;distributed hash table;routing;resource allocation;probability density function;alphanumerical overlay;load imbalance;maintenance engineering;data mining;skewed distribution;resource allocation peer to peer computing;distance measurement;hash functions;peer to peer computing routing load management intrusion detection books bandwidth distributed computing grid computing costs computational modeling;load management;load balancing;load balance;pastry peer to peer alphanumerical overlay range queries load balancing;hash function;p2p networks;peer to peer computing;distributed hash tables;peer to peer;peer to peer networks;p2p network pastry;peer to peer networks alphanumerical overlay load balancing strategies distributed hash tables hash functions hash collisions load imbalance p2p network pastry;pastry;range queries;key distribution	Many load balancing strategies have been proposed for distributed hash tables, like Pastry. These strategies assume that hash functions spread even skewed key distributions almost evenly over the ID space. They neglect the problem that many applications produce data with common keys (multi-sets) that entail hash collisions and therewith load imbalance concerning query and storage load. A second drawback of using hash functions in DHTs is the lack of range queries needed in many scenarios. This paper presents a solution for how to use the routing structure of the P2P network Pastry to create a new alphanumerical overlay with very little additional costs. This overlay is capable of storing data in a totally ordered manner instead of using hashed keys. Therewith, it enables range queries and sophisticated load balancing. We discuss the impact on Pastry that arises when nodes are relocated during load balancing. This possibly causes a skewed distribution of nodes in the circular id space. We demonstrate the feasibility of our idea including advantages and problems through an evaluation of simulations.	best, worst and average case;cluster analysis;collision (computer science);distributed hash table;hash function;internet topology;lazy evaluation;load balancing (computing);locality of reference;numerical analysis;population;randomized algorithm;range query (data structures);routing;routing table;simulation	Dominic Battré;André Höing;Martin Raack;Ulf Rerrer-Brusch;Odej Kao	2009	2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid	10.1109/CCGRID.2009.65	pastry;maintenance engineering;range query;content addressable network;hash function;computer science;load balancing;database;distributed computing;computer network	Networks	-11.466381179632071	73.12325504420816	140273
a7b06b8ae00ea5a9cf68081b47c739cc37a368c1	exploring blind online scheduling for mobile cloud multimedia services	scheduling cloud computing mobile computing multimedia systems recommender systems;multimedia systems;multimedia communication servers mobile communication quality of service scheduling optimal scheduling scheduling algorithms;scheduling;mobile computing;recommender systems;cloud computing;content recommendation system blind online scheduling mobile cloud multimedia services multimedia applications pervasive computing environment cloud based scheduling algorithms request rate service time bosa impartial free time multimedia servers first come first served rule	Mobile cloud is a new emerging technology which can be used to enable users to enjoy abundant multimedia applications in a pervasive computing environment. Therefore, the scheduling of massive multimedia flows with heterogeneous QoS guarantees becomes an important issue for the mobile cloud. Generally, the predominant popular cloud-based scheduling algorithms assume that the request rate and service time, are available for the system operator. However, this assumption can hardly be maintained in many practical scenarios, especially for the largescale mobile cloud. In this article, we consider the scheduling problem for a practical mobile cloud in which the above parameters are unavailable and unknown. Taking into account the performance of the users and the impartial free time among the servers, the highlight of this article lies in proposing a blind online scheduling algorithm (BOSA). Specifically, we assign available multimedia servers based on the last timeslot information of the users' requests, and route all the multimedia flows according to the first-come- first-served rule. Moreover, we design detailed steps to apply the BOSA to a content recommendation system, and show that the proposed BOSA can achieve asymptotic optimality.	asymptotically optimal algorithm;contextual advertising;mobile cloud computing;recommender system;scheduling (computing);sysop;ubiquitous computing	Liang Zhou;Zhen Yang;Joel Jos&#x00E9; P. C. Rodrigues;Mohsen Guizani	2013	IEEE Wireless Communications	10.1109/MWC.2013.6549283	fair-share scheduling;real-time computing;cloud computing;dynamic priority scheduling;computer science;operating system;two-level scheduling;distributed computing;round-robin scheduling;mobile computing;scheduling;world wide web;computer network	Metrics	-18.60191980447511	66.27026553449066	140333
275e7662e8f4e708660aa3fdf75994307b7fca4e	a balanced resource allocation and overload control infrastructure for the service grid environment	grid applications;resource allocation;distributed computing;overload control;web service;service based grid applications;hot spot;grid service;load balancing;middleware;load balance;adaptive resource allocation	For the service based Grid applications, the applications may be integrated by using the Grid services across Internet, thus we should balance the load for the applications to enhance the resource's utility and increase the throughput. To overcome the problem, one effective way is to make use of load balancing. Kinds of load balancing middleware have already been applied successfully in distributed computing. However, they don't take the services types into consideration and for different services requested by clients the workload would be different out of sight. Furthermore, traditional load balancing middleware uses the fixed and static replica management and uses the load migration to relieve overload. Therefore, we put forward an autonomic replica management infrastructure to support fast response, hot-spot control and balanced resource allocation among services. Corresponding simulation tests are implemented and results indicated that this model and its supplementary mechanisms are suitable to service based Grid applications.		Yi Ming Ren;Di Zheng;Quanyuan Wu	2007		10.1007/978-3-540-72584-8_62	network load balancing services;real-time computing;computer science;load balancing;distributed computing;grid computing;computer network	HPC	-18.257158273004475	69.33393628796274	140632
bf5cf71d58adab43848008f01c95fd94d3e8d88d	enabling high throughput and virtualization for traffic classification on fpga	field programmable gate array;hardware virtualization;post place and route;virtualization;engines hardware field programmable gate arrays pipelines accuracy throughput virtualization;decision tree;fpga;online traffic classification;virtualization traffic classification fpga throughput;accuracy;post place and route fpga field programmable gate array internet traffic classification online traffic classification massive parallelism decision tree rule set table modular processing elements 2 dimensional pipelined architecture hardware virtualization dynamic update mechanism;internet;engines;pipelines;computer network management;virtualisation computer network management decision trees field programmable gate arrays internet parallel processing;traffic classification;dynamic update mechanism;modular processing elements;rule set table;field programmable gate arrays;internet traffic classification;decision trees;massive parallelism;parallel processing;virtualisation;2 dimensional pipelined architecture;throughput;hardware	As an important network management task, Internet traffic classification requires high throughput. Virtualization is a technique sharing the same piece of hardware for multiple users. We present a high-throughput and virtualized architecture for online traffic classification. To explore massive parallelism, we provide a conversion from a decision-tree into a compact rule set table, we employ modular processing elements and map the table to a 2-dimensional pipelined architecture. To support hardware virtualization, we develop a novel dynamic update mechanism, it requires small resource overhead and has little impact on the overall throughput. To evaluate the performance of this architecture, we implement an online traffic classification engine on a state-of-the-art FPGA. Post place-and-route results show that, our classification engine achieves 5-fold throughput compared with existing dynamically up datable online traffic classification engines on FPGA.	algorithm;decision tree;field-programmable gate array;hardware virtualization;high-throughput computing;lambda calculus;multi-user;overhead (computing);parallel computing;place and route;throughput;traffic classification	Yun Qu;Viktor K. Prasanna	2015	2015 IEEE 23rd Annual International Symposium on Field-Programmable Custom Computing Machines	10.1109/FCCM.2015.20	embedded system;parallel processing;parallel computing;real-time computing;computer science;operating system;decision tree;field-programmable gate array	Arch	-6.776181648590708	65.81488645640252	140658
a00700c30f725cfb3e02cb0ae4acf6e67822598c	data broadcasting for dependent information using multiple channels in wireless broadcast environments	multiple channels;np completeness;data broadcasting;latency;dags	Data broadcasting is an effective approach to disseminating information to mobile clients and has attracted much research attention in recent years. In many applications, the access pattern among the data can be represented by a weighted DAG. In this paper, we consider the problem of efficiently generating the broadcast schedules on multiple channels when the data set has a DAG access pattern. We show that it is NP-hard to find an optimal broadcast schedule which not only minimizes the latency but also satisfies the ancestor property that retains the data dependency. We further derive a condition for the input DAGs under which one can generate an optimal broadcast schedule in linear time and propose an algorithm to generate the schedule. Due to the NP-completeness, we provide three heuristics for general DAGs based on the level of a vertex in the input DAGs and each heuristic uses a different policy to place vertices into the broadcast channels. There are two categories for the policies. The first category mainly considers the probability for a process to stop at a considered vertex. The second category takes the vertices which are affected most when assigning a vertex into consideration. We analyze and discuss these heuristics. A short experimental simulation is given for supporting and validating the discussion. In particular, the experimental results indicate that roughly considering the whole posterior vertices of each vertex is not precise and may not lead to good results and considering the vertices affected most when assigning a vertex will help reducing the latency.	datacasting	Chuan-Ming Liu;Ta-Chih Su;Jenq-Haur Wang;Yen-Lin Chen	2014	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2014.05.002	mathematical optimization;combinatorics;latency;parallel computing;real-time computing;np-complete;computer science;theoretical computer science;operating system;distributed computing;algorithm;computer network	HCI	-10.924696917154343	67.21979152016289	140985
11074eb85124a276cf622428f4e1f64cfa4a2a56	asymptotic convergence of scheduling policies with respect to slowdown	convergence;processor sharing;conservation;scheduling;large jobs;srpt;shortest remaining processing time	We explore the performance of an M/GI/1 queue under various s cheduling policies from the perspective of a new metric: the slowdownexperienced by largest jobs. We consider scheduling policies that bias against large jobs, towards l arge jobs, and those that are fair, e.g., Processor-Sharing. We prove that as job size increase s to infinity, all work conserving policies converge almost surely with respect to this metric to no more than1=(1 ), where denotes load. We also find that the expected slowdown under an y work conserving policy can be made arbitrarily close to that under Processor -Sha ing, for all job sizes that are sufficiently large.	categorization;centrality;converge;job stream;load (computing);scheduling (computing)	Mor Harchol-Balter;Karl Sigman;Adam Wierman	2002	Perform. Eval.	10.1016/S0166-5316(02)00132-3	real-time computing;convergence;conservation;computer science;operating system;distributed computing;scheduling;computer network	Metrics	-14.880739298745455	64.25265242199664	141046
af22f06be0e2391c996a5fe8c63e60d0b20ce546	ant colony-based load balancing and fault recovery for cloud computing environment		Scheduling a task and recovering resources in cloud computing is an important optimisation problem. Workload balancing of preemptive and non-preemptive task on the VM is a significant phase in task scheduling. The load of overloaded VM and under-loaded VM has to be balanced to achieve optimal machine utilisation. The recovery process is an essential phase when the failure in VM occurs. The resources that have been stored in the failed VM have to be recovered. The recovery process is done to reclaim the task that have been failed in the VM. In this paper, an algorithm named ant colony-based load balancing and fault recovery (ACB-LBR) is proposed that achieve well-balanced load across VM, activates recovery process at the time of VM failure and reduces power consumption among VMs. This algorithm uses for aging behaviour of Ant colony for balancing the tasks in overloaded VM that leads to high throughput. The ACB-LBR algorithm recovers the lost resource at failure time and manages less power consumption. The...	ant colony;cloud computing;load balancing (computing)	Balamurugan Balusamy;Kotteswari Karthikeyan;Arun Kumar Sangaiah	2017	IJAIP	10.1504/IJAIP.2017.10003577	parallel computing;distributed computing	HPC	-15.176020218454706	60.8418305267862	141231
f96114cb1239213f1866ce9f64f836d5d2381dee	a weighted segment-based caching algorithm for video streaming objects over heterogeneous networking environments	video streaming;mobile device;streaming video;proxy caching;cache relation tree;cache replacement;transcoding proxy;cache algorithm;heterogeneous network	Traditional caching technology is not applicable to cache video streaming objects over heterogeneous networking environments. The popularity of mobile devices in the heterogeneous networking environments make the access of Internet content become a common phenomenon. To support different mobile devices in the heterogeneity networking environments, a transcoding proxy is used to transcode different versions of the streaming videos according to clients' requests. In this paper, we propose a weighted caching replace strategy for video streaming objects over heterogeneous networking environments. A new caching algorithm with static weight transcoding graph and dynamic caching relation tree is introduced. The proposed algorithm is compared with LRU, LFU, CP and PF cache algorithms in three parts: hit ratio, byte hit ratio, and average transmission delay. Experimental results show that the proposed algorithm outperforms than traditional LRU, LFU, CP and PF cache algorithms.	algorithm;delay-tolerant networking;streaming media	Tz-Heng Hsu;Yueh-Heng Li	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.08.134	real-time computing;heterogeneous network;cache;computer science;mobile device;smart cache;cache algorithms;world wide web;computer network	ML	-16.91238635281352	73.82982536428443	141277
9b51c908c39ac39cac2d2523081f2178d3b0cbe3	messages scheduling for parallel data redistribution between clusters	optimal solution;approximate algorithm;approximation algorithm;grid computing message scheduling parallel data redistribution k preemptive bipartite scheduling np hard problem 8 3 approximation algorithm mpi tcp;performance index;tcp;low complexity;transport protocols computational complexity grid computing message passing scheduling;transport protocols;code coupling;parallel data redistribution;np hard problem;code coupling message scheduling data redistribution grid computing approximation algorithm;computational complexity;scheduling;message passing;message scheduling;mpi;data redistribution;8 3 approximation algorithm;grid computing;lower bound;k preemptive bipartite scheduling;spine grid computing clustering algorithms scheduling algorithm processor scheduling computer networks parallel machines concurrent computing wavelength division multiplexing time division multiple access	We study the problem of redistributing data between clusters interconnected by a backbone. We suppose that at most k communications can be performed at the same time (the value of k depending on the characteristics of the platform). Given a set of messages, we aim at minimizing the total communication time assuming that communications can be preempted and that preemption comes with an extra cost. Our problem, called k-preemptive bipartite scheduling (KPBS) is proven to be NP-hard. We study its lower bound. We propose two 8/3-approximation algorithms with low complexity and fast heuristics. Simulation results show that both algorithms perform very well compared to the optimal solution and to the heuristics. Experimental results, based on an MPI implementation of these algorithms, show that both algorithms outperform a brute-force TCP-based solution, where no scheduling of the messages is performed	algorithm;heuristic (computer science);internet backbone;message passing interface;optimization problem;preemption (computing);scheduling (computing);simulation	Johanne Cohen;Emmanuel Jeannot;Nicolas Padoy;Frédéric Wagner	2006	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2006.141	process performance index;parallel computing;message passing;computer science;message passing interface;theoretical computer science;operating system;transmission control protocol;np-hard;distributed computing;upper and lower bounds;computational complexity theory;scheduling;transport layer;approximation algorithm;algorithm;grid computing	HPC	-13.634302419588517	60.87489396978447	141290
5e7073eeef377d629b55e1c80c170091390bb030	job scheduling for acceleration systems in cloud computing		With the increase of various of applications, CPU is no longer adequate for the computation tasks. Accordingly, some providers deploy accelerators in their cloud. Since not all the servers in the cloud can carry accelerators, how to schedule jobs onto accelerators and improve the system performance is an important issue. Due to the distributed computing frameworks in cloud computing systems, the jobs usually arrive in batches, and hence we try to minimize the make-span of a batch of jobs in this paper. To this end, we first formulate this problem as a mathematic programming model, and prove the NP-hardness of this problem. To solve this problem efficiently, we propose a 4- approximation algorithm. Through extensive simulations, we find that our algorithm can reduce the make-span of a batch of jobs by about 32%, and enhance the system throughput by up to 29% compared with our comparison baseline.	approximation algorithm;baseline (configuration management);central processing unit;cloud computing;computation;distributed computing;job scheduler;job shop scheduling;job stream;np-hardness;programming model;schedule (project management);scheduling (computing);simulation;throughput	Yangming Zhao;Xin Liu;Chunming Qiao	2018	2018 IEEE International Conference on Communications (ICC)	10.1109/ICC.2018.8422110	task analysis;real-time computing;throughput;computation;programming paradigm;job scheduler;approximation algorithm;cloud computing;computer science;server	HPC	-18.91966760722333	62.43043475887324	141670
a79bd569d45630d8b5409d57305c42e8a2597400	a comparative analysis of centralized and distributed dynamic load balancing algorithms for cluster based video-on-demand systems	static load balancing algorithm;dynamic load balancing;comparative analysis;system dynamics;dynamic load balancing algorithm;video on demand;distribution dynamics;load balance;multimedia services;video on demand vod system	The advancements in the field of Computers and other related technologies are becoming a boon to multimedia industry. One of the multimedia service that is gaining attraction from millions of customers across the world is Video-on-Demand (VoD) systems. Hence, effective strategies for distribution of load among the servers are essential. This paper focuses on solving the load imbalance problem by using a dynamic load balancing strategy. In particular, it uses distributed dynamic load balancing strategy because of its efficiency upto 93% when compared to the centralized dynamic load balancing strategy which has 90% of efficiency. Thus, a comparative analysis of centralized and distributed strategies for dynamic load balancing in VoD systems is carried out.	algorithm;centralized computing;load balancing (computing);qualitative comparative analysis	A. Vinay;K. G. Abhijit;M. Saifulla;D. Jayashree;T. N. Anitha	2011		10.1145/1980022.1980099	round-robin dns;network load balancing services;real-time computing;load balancing;computer science;load balancing;distributed computing;computer network	HPC	-17.335307663270243	66.29126094599995	141674
325d0658c7b2d0d27adabb2fe2974cc9602c524f	an availability-aware task scheduling strategy for heterogeneous systems	task analysis scheduling;high availability;availability scheduling algorithm processor scheduling single machine scheduling scheduling computational modeling time factors resource management;single machine scheduling;heterogeneous systems;node computing capabilit;design and development;availability;processor scheduling;resource allocation;resource management;multiclass application;availability constraints;scheduling algorithm;multiclass applications;computational modeling;time factors;scheduling;task analysis;heterogeneous system;scheduling problem;multiclass application availability aware task scheduling strategy heterogeneous system node computing capabilit;task scheduling;resource allocation availability constraints heterogeneous systems multiclass applications scheduling;availability aware task scheduling strategy	High availability is a key requirement in the design and development of heterogeneous systems where processors operate at different speeds and are not continuously available for computation. Most existing scheduling algorithms designed for heterogeneous systems do not factor in availability requirements imposed by multiclass applications. To remedy this shortcoming, we investigate in this paper the scheduling problem for multiclass applications running in heterogeneous systems with availability constraints. In an effort to explore this issue, we model each node in a heterogeneous system using the node's computing capability and availability. Multiple classes of tasks are characterized by their execution times and availability requirements. To incorporate availability and heterogeneity into scheduling, we define new metrics to quantify system availability and heterogeneity for multiclass tasks. We then propose a scheduling algorithm to improve the availability of heterogeneous systems while maintaining good performance in the response time of tasks. Experimental results show that our algorithm achieves a good trade-off between availability and responsiveness.	algorithm;angular defect;branch and bound;central processing unit;computation;dynamic programming;heterogeneous computing;heuristic;high availability;integer factorization;requirement;response time (technology);responsiveness;scheduling (computing)	Xiao Qin;Tao Xie	2008	IEEE Transactions on Computers	10.1109/TC.2007.70738	fair-share scheduling;parallel computing;real-time computing;computer science;resource management;operating system;distributed computing;scheduling	Embedded	-17.91203205878843	62.35461672316502	141698
ec741eb362386168fa3763adf982163291951bce	a fluid limit for cache algorithms with general request processes	communications society;cache storage;fluid limit;request rates cache algorithms general request processes formal limit scaled stochastic models least recently used algorithm stochastic point processes inhomogeneous poisson processes asymptotic characteristics average miss probability asymptotic analysis;approximation algorithms;general request processes;least recently used algorithm;point process;asymptotic analysis;data mining;inhomogeneous poisson process;stochastic processes cache storage;nonhomogeneous media;stochastic processes algorithm design and analysis performance analysis h infinity control tail performance gain communications society laboratories scalability web sites;stochastic processes;ieee;scaled stochastic models;inhomogeneous poisson processes;web sites;performance analysis;cache algorithms;stochastic point processes;performance gain;average miss probability;scalability;stochastic model;numerical experiment;h infinity control;formal limit;asymptotic characteristics;cache management;titanium;algorithm design and analysis;least recently used;tail;request rates	We introduce a formal limit, which we refer to as a fluid limit, of scaled stochastic models for a cache managed with the Least-Recently-Used algorithm when requests are issued according to general stochastic point processes, which may be non-stationary. We define our fluid limit as a superposition of dependent replications of the original system with smaller item sizes as the number of replications approaches infinity. We derive the average probability that a requested item is not in a cache (average miss probability) in the fluid limit. The usefulness of the fluid limit is demonstrated in two ways. First, our numerical experiments show that, when items are requested according to inhomogeneous Poisson processes, the average miss probability in the fluid limit closely approximates that in the original system as long as there are sufficient number of items. Second, we show that the asymptotic characteristics of the average miss probability as the cache size approaches infinity are often preserved in the fluid limit. This preservation is attractive since the asymptotic analysis in the fluid limit appears to be simpler than that in the original system. In addition, we show that the average miss probability in the fluid limit is asymptotically insensitive to particular dependencies in the requests when the request rates have a light tail, a property not known for the original system.	algorithm;experiment;numerical analysis;quantum superposition;stationary process;stochastic process	Takayuki Osogami	2009	IEEE INFOCOM 2009	10.1109/INFCOM.2009.5062242	mathematical optimization;cache-oblivious algorithm;cache coloring;asymptotic analysis;page cache;cache;computer science;theoretical computer science;cache invalidation;cache algorithms;cache pollution;statistics	Metrics	-9.03372859352241	71.03349168210174	141716
33b603eb92360be90b5e78d44cdc90b8bc6c0ea9	deadline and cost based workflow scheduling in hybrid cloud	performance evaluation;cloud computing schedules scheduling algorithms scheduling organizations hardware;min min approach cost based workflow scheduling deadline based workflow scheduling hybrid cloud cloud computing on demand resources storage requirements private cloud workflow applications pay per use basis charge task scheduling complex process resource allocation level based scheduling algorithm level wise task execution subdeadline concept performance analysis;processor scheduling;resource allocation;storage management;storage management cloud computing performance evaluation processor scheduling resource allocation;hybrid cloud cloud computing workflow scheduling dag private cloud public cloud;cloud computing	Cloud computing provides on demand resources for compute and storage requirements. Private cloud is a good option for cost saving for executing workflow applications but when the resources in private cloud are not enough to meet storage and compute requirements of an application then public clouds are the option left. While public clouds charge users on pay-per-use basis, private clouds are owned by users and can be utilized with no charge. When a public cloud and a private cloud is merged, we get a hybrid cloud. In hybrid cloud, task scheduling is a complex process as jobs can be allocated resources either from private cloud or from public cloud. Deadline based scheduling is the main focus in many of the workflow applications. Proposed algorithm does cost optimization by deciding which resources should be taken on lease from public cloud to complete the workflow execution within deadline. In the proposed work, we have developed a level based scheduling algorithm which executes tasks level wise and it uses the concept of sub-deadline which is helpful in finding best resources on public cloud for cost saving and also completes workflow execution within deadlines. Performance analysis and comparison of the proposed algorithm with min-min approach is also presented.	algorithm;cloud computing;job (computing);job shop scheduling;makespan;mathematical optimization;maxima and minima;mike lesser;multistage interconnection networks;requirement;scheduling (computing)	Nitish Chopra;Sarbjeet Singh	2013	2013 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2013.6637285	fair-share scheduling;real-time computing;earliest deadline first scheduling;cloud computing;dynamic priority scheduling;resource allocation;computer science;cloud testing;database;distributed computing;workflow management system	HPC	-18.815444085874237	62.497730846039964	141767
874fbfa93dc056d40d6355bcf1393e180b3b75f4	tracking millions of flows in high speed networks for application identification	router assisted traffic differentiation;cache storage;small sized cache;field programmable gate array;application identification;power saving;tracking system;performance evaluation;high speed networks;fpga;space time;qos;chip;telecommunication traffic;internet;elephants;internet router;cost effectiveness;small sized cache high speed networks application identification internet routers qos router assisted traffic differentiation layer 4 traffic adaptive least frequently evicted replacement policy alfe replacement policy fpga;layer 4 traffic;alfe replacement policy;internet routers;internet application;field programmable gate arrays;quality of service;dram chips;adaptive least frequently evicted replacement policy;telecommunication traffic cache storage dram chips field programmable gate arrays internet quality of service;global change;replacement policy	Today's Internet applications exhibit increased diversity, while the Internet routers are still oblivious to this trend. To improve the end-to-end application QoS, one solution is to embed the application information explicitly in packet headers, but it will bring global changes. Another local solution is router-assisted traffic differentiation. To achieve this, the functionalities including packet identification and flow tracking inside the router are required. While most existing studies focus on the former, fewer efforts are put on the later. Given a large flow table is involved, how to track millions of concurrent flows in a cost-effective manner on a router's line card raises a great space-time challenge. To address this, we design an on-chip/off-chip flow tracking system to accommodate millions of flows and achieve the throughput at tens of Gigabits. By exploiting temporal locality and heavy-tailedness of Layer-4 traffic, we design the Adaptive Least Frequently Evicted (ALFE) replacement policy to catch elephant flows, therefore maintain a high cache hit rate. To alleviate performance penalty due to the cache misses, we organize the flow table in a fixed-allocated manner to fully utilize modern DRAM's burst feature. We have implemented a research prototype using FPGA for performance evaluation. The experiment results show that our system can reach 80% hit rate with a small-sized cache of 16K entries, while achieving 70Mpps throughput. This enables backbone line rate processing. Further, more than 40% power saving can be achieved by our system, which is fast and accurate with only 3% FPGA resource usage.	cache (computing);dynamic random-access memory;end-to-end principle;field-programmable gate array;gigabit;internet backbone;locality of reference;network packet;performance evaluation;prototype;quality of service;router (computing);throughput;tracking system	Tian Pan;Xiaoyu Guo;Chenhui Zhang;Junchen Jiang;Hao Wu;Bin Liu	2012	2012 Proceedings IEEE INFOCOM	10.1109/INFCOM.2012.6195535	embedded system;real-time computing;quality of service;telecommunications;computer science;operating system;field-programmable gate array;computer network	Networks	-6.986476161033129	65.35449036793442	142086
a68b06765a39667929ea999bf385ccc37bf20204	high performance internet traffic generators	parallelisme;distributed system;evaluation performance;haute performance;systeme reparti;performance evaluation;software platform;evaluacion prestacion;gestion trafic;supercomputer;traffic management;supercomputador;parallelism;sistema repartido;internet traffic;distributed and parallel architectures;internet;paralelismo;generation test;algorithme reparti;gestion trafico;alto rendimiento;test generation;algoritmo repartido;parallel architecture;high performance internet traffic generation;distributed algorithm;high performance;generacion prueba;superordinateur	In the networking field, traffic generator platforms are of a paramount importance. This paper deals with the description of a distributed software platform for synthetic traffic generation over IPv4/v6 networks, called D-ITG (Distributed Internet Traffic Generator). We point our attention on the original architectural choices and evaluate the performance achieved by the platform. D-ITG supports several protocols and many traffic patterns. We tested our generation platform over different scenarios and compared it to many of the currently available, and most widely adopted, traffic generators. We found that D-ITG offers enhanced functionalities and improved performance.	data rate units;distributed computing;emoticon;entity;experiment;linux;microsoft windows;network packet;scalability;software architecture;synthetic intelligence;throughput;uncompressed video;usability;vii	Stefano Avallone;Donato Emma;Antonio Pescapè;Giorgio Ventre	2006	The Journal of Supercomputing	10.1007/s11227-006-0798-1	traffic generation model;embedded system;distributed algorithm;active traffic management;supercomputer;parallel computing;the internet;simulation;internet traffic;telecommunications;computer science;operating system;distributed computing;internet traffic engineering	Networks	-6.048436512648412	74.25403936206354	142168
d088c117d2cdbe11e83b7e03f901f25660650f28	scalable key/value search in datacenters	software;intel data plane development kit;kvs;dpdk;open standard binary message format;ethernet;fpga;sockets;field programmable gate array logic;throughput kvs nosql ethernet sdn gdn dpdk fpga latency power;software logic gates sockets field programmable gate arrays throughput servers ip networks;local area networks computer centres field programmable gate arrays;computer centres;network data;servers;logic gates;linux server;microprocessor based servers;network data scalable key value search data centers kvs systems microprocessor based servers gateware field programmable gate array logic fpga open standard binary message format ethernet linux server udp ip sockets intel data plane development kit dpdk;sdn;kvs systems;ip networks;latency;gateware;field programmable gate arrays;udp ip sockets;gdn;power;local area networks;nosql;scalable key value search;throughput;data centers	Key/Value Store (KVS) is a fundamental service used widely in modern data centers to associate keys with data values. KVS systems, such as Redis, Memcached, and Dynamo DB have traditionally been implemented with software and run on clusters of microprocessor-based servers. In this work an alternate approach is taken that performs KVS with gate ware in Field Programmable Gate Array (FPGA) logic. We leverage an efficient, open-standard, binary message format to transfer keys and values over Ethernet. Results of three different implementations of this KVS were compared -- software running on a Linux server with network data sent over UDP/IP sockets, kernel bypass using Intel's Data Plane Development Kit (DPDK), and with pure FPGA logic implemented in gate ware. We characterize the three implementations in terms of throughput, latency, and power.	dpdk / dpdk.org;data center;field-programmable gate array;forwarding plane;linux;memcached;microprocessor;redis;server (computing);throughput;warez	John W. Lockwood	2015	2015 IEEE 23rd Annual International Symposium on Field-Programmable Custom Computing Machines	10.1109/FCCM.2015.67	embedded system;parallel computing;computer science;operating system;field-programmable gate array	Arch	-6.844627813374346	65.15460771449685	142211
d42165191e7613facc2a49d107dd607313e82c02	threshold-based dynamic replication in large-scale video-on-demand systems	data compression;interactive television;multimedia systems;performance evaluation;resource allocation;synchronisation;video coding;video discs;visual databases;vod system reconfiguration;bandwidth;costs;data access patterns;data delivery;data management;disk synchronization;fault tolerance;high speed networking;large-scale video-on-demand systems;movie;movie data striping;multimedia;parallel disks;performance evaluation;storage capacity;storage resources;threshold-based dynamic replication;video compression;video database;video server	Advances in high speed networking technologies and video compression techniques have made video-on-demand (VOD) services feasible. A large-scale VOD system imposes a large demand on bandwidth and storage resources, and therefore, parallel disks are typically used for providing VOD service. Although striping of movie data across a large number of disks can balance the utilization among these disks, such a striping technique can exhibit additional complexity, for instance, in data management, such as synchronization among disks during data delivery, as well as in supporting fault tolerant behavior. Therefore, it is more practical to limit the extent of data striping, for example, by arranging the disks in groups (or nodes) and then allowing intra-group (or intra-node) data striping only. With multiple striping groups, however, we may need to assign a movie to multiple nodes so as to satisfy the total demand of requests for that movie. Such an approach gives rise to several design issues, including: what is the right number of copies of each movie we need so as to satisfy the demand and at the same time not waste storage capacity; how to assign these movies to different nodes in the system; and what are efficient approaches to altering the number of copies of each movie (and their placement) when the need for that arises. We study an approach to dynamically reconfiguring the VOD system so as to alter the number of copies of each movie maintained on the server as the access demand for these movies fluctuates. We propose various approaches to addressing the above stated issues, which result in a VOD design that is adaptive to the changes in data access patterns. Performance evaluation is carried out to quantify the costs and the performance gains of these techniques		Peter W. K. Lie;John C. S. Lui;Leana Golubchik	1998		10.1109/RIDE.1998.658278	embedded system;real-time computing;computer science;world wide web	OS	-15.411255699952854	70.87670585590979	142276
4b846bdc41d55163e8a4a77e8999690a8b151503	an expiration age-based document placement scheme for cooperative web caching	network servers cooperative caching cache memory delay protocols telecommunication traffic web server bandwidth aggregates analytical models;cache storage;distributed caching;document handling;cooperative caching;proxy caching;document placement;internet;document handling internet cache storage;aggregate disk usage expiration age based document placement scheme cooperative web caching cache sharing document requests document placement schemes cache hit ratio aggregate disk space cache expiration age analytic modeling trace based simulation;cooperative web caching;web caching;analytical model	The sharing of caches among proxies is an important technique to reduce Web traffic, alleviate network bottlenecks, and improve response time of document requests. Most existing work on cooperative caching has been focused on serving misses collaboratively. Very few have studied the effect of cooperation on document placement schemes and its potential enhancements on cache hit ratio and latency reduction. We propose a new document placement scheme which takes into account the contentions at individual caches in order to limit the replication of documents within a cache group and increase document hit ratio. The main idea of this new scheme is to view the aggregate disk space of the cache group as a global resource of the group and uses the concept of cache expiration age to measure the contention of individual caches. The decision of whether to cache a document at a proxy is made collectively among the caches that already have a copy of this document. We refer to this new document placement scheme as the Expiration Age-based scheme (EA scheme). The EA scheme effectively reduces the replication of documents across the cache group, while ensuring that a copy of the document always resides in a cache where it is likely to stay for the longest time. We report our study on the potentials and limits of the EA scheme using both analytic modeling and trace-based simulation. The analytical model compares and contrasts the existing (ad hoc) placement scheme of cooperative proxy caches with our new EA scheme and indicates that the EA scheme improves the effectiveness of aggregate disk usage, thereby increasing the average time duration for which documents stay in the cache. The trace-based simulations show that the EA scheme yields higher hit rates and better response times compared to the existing document placement schemes used in most of the caching proxies.	aggregate data;cpu cache;cache (computing);cooperative multitasking;disk space;hit (internet);hoc (programming language);proxy server;response time (technology);trace-based simulation;web traffic	Lakshmish Ramaswamy;Ling Liu	2004	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2004.1277819	real-time computing;the internet;page cache;cache stampede;false sharing;cache;computer science;cache invalidation;database;smart cache;cache algorithms;cache pollution;world wide web	Web+IR	-15.57951024491343	68.89828957765984	142292
7fa51469854d78924d2f3b1f703314e9c579c5d4	adaptive multimedia cloud computing center applied on h.264/svc streaming		In recent years, the multimedia streaming technology becomes increasingly mature, and as network bandwidth and computing power of personal hand-held devices are developed; therefore, it leads the requirements for multimedia quality increased. In order to provide the quality multimedia content to numerous users, how to divide the loading of content servers to improve the streaming quality is an important challenge. As the concept of multimedia cloud network is formed, how to allocate multimedia streaming service to the nodes in the media cloud network is discussed in this paper. This study designs H.264/SVC streaming service at the media cloud computing center, with the video most suitable for client-side quality provided based on H.264/SVC features (temporal scalability, spatial scalability, and quality scalability) and network bandwidth. In addition, the loading balance and communication mechanisms between nodes are discussed, where the best node is selected by the evaluating node, client-side bandwidth and computing power, for determining the appropriate video streaming path that is used to provide quality multimedia streaming service. According to the experimental results, the bandwidth prediction error rate for general multimedia network streaming service can be maintained at about 6 %, while the utilization rate of various nodes of the multimedia cloud computing center is maintained in a balanced state during the period of executing multi-streaming service.	bit error rate;client-side;cloud computing;load balancing (computing);mobile device;requirement;scalability;streaming media	Wei-Ting Cho;Chin-Feng Lai	2013		10.1007/978-3-319-05506-0_2	real-time computing;computer science;operating system;multimedia;computer network	HPC	-17.34095778680098	74.08370454830441	142569
0599e5e7f7fd79a3f4914a964704ae9086ac93f7	a new server selection strategy for reliable server pooling in widely distributed environments	file servers;resource allocation;load balancing server selection reliable server pooling widely distributed environment server redundancy session failover ietf rserpool wg load distribution;distributed processing;load management web server redundancy network servers availability performance analysis delay web and internet services educational institutions information science;least used selection;session failover;system performance;resource allocation distributed processing file servers;server selection;widely distributed environment;distributed environment;load balancing;ietf rserpool wg;latency reliable server pooling load balancing least used selection;load distribution;server redundancy;reliable server pooling;load balance;network delay;latency	In order to provide a generic, application- independent and resource-efficient framework for server redundancy and session failover, the IETF RSerPool WG is currently standardizing the reliable server pooling (RSerPool) framework. Server redundancy has to take load distribution and load balancing into consideration since these issues are crucial for the system performance. There has already been some research on the server selection strategies of RSerPool for different application scenarios. In particular, it has been shown that the adaptive least used selection usually provides the best performance. This strategy requires up-to-date load information of the services, which has to be propagated among distributed pool management components. But network delay (which is realistic for systems being widely distributed to achieve availability in case of regional servers failures) as well as caching of information may both lead to obsolete load information. Therefore, the purpose of this paper is to analyse and evaluate the performance of a new server selection rule to cope with update latencies. Especially, we will also analyse the impact of different workload parameters on the performance of the new server selection strategy.	cache (computing);elegant degradation;failover;geographic coordinate system;group policy;load balancing (computing);planetlab;prototype;real life;selection rule;server (computing);simulation	Xing Zhou;Thomas Dreibholz;Erwin P. Rathgeb	2008	Second International Conference on the Digital Society	10.1109/ICDS.2008.12	real-time computing;computer science;load balancing;operating system;distributed computing;computer performance;world wide web;computer security;computer network	HPC	-18.198708019616877	69.67126867191062	142818
69e7683f2eb152a0f2d73d3fdc39fdc96f07d035	reducing resource usage based on user hints and policies	frames per second;policies;cpu management;multimedia application;network traffic;network management;user hints	Multimedia applications often have performance requirements that make these applications computing resource intense; e.g., the number of video frames displayed to the user must be about 25 frames per second. A user hint is an indication of the interest that a user has in an application. Examples of user hints include a screen saver being invoked or covering a window with another window. In the case that the user is running video, the occurrence of these hints imply that the user is no longer viewing the video. However, the resource usage of the application has not changed. This paper describes an architecture that make use of user hints to reduce the resource consumption of an application. The emphasis is on network traffic and CPU usage. Experimental results are presented.	central processing unit;network packet;requirement;screensaver	William Kulju;Hanan Lutfiyya	2006	Journal of Network and Systems Management	10.1007/s10922-006-9025-x	user interface design;network management;real-time computing;user modeling;computer science;multimedia;frame rate;world wide web;computer network	Mobile	-18.054820025314086	72.45509285986417	143309
914caf7aa7fa51dac3b58fa3d1d11583624cfd4e	toward optimal network topology design for fast and secure distributed computation		A typical distributed computation problem deals with a network of multiple agents and the constraint that each agent is able to communicate only with its neighboring agents. Two important issues of such a network are the convergence rate of the corresponding distributed algorithm and the security level of the network against external attacks. In this paper, we take algebraic connectivity as an index of convergence rate, which works for consensus and gossip algorithms, and consider certain type of external attacks by using the expected portion of the infected agents to measure the security level. Extremal examples and analysis show that fast convergence rate and high security level require opposite connectivity of the network. Thus, there has to be a trade-off between the two issues in the design of network topology. This paper aims to provide an approach to design a network topology which balances between convergence rate and security. A class of tree graphs, called extended star graphs, are considered. The optimal extended star graph is provided under appropriate assumptions.	computation;distributed computing;network topology	Ji Liu;Tamer Basar	2014		10.1007/978-3-319-12601-2_13	theoretical computer science;distributed computing;computer network;logical topology	Networks	-8.55982547065123	73.15881339400326	143388
5a14f1e746778fa36a06a890993c4e7a30f38bee	exploring peer heterogeneity: towards understanding and application	analytical models;fault tolerant;availability;computer model;peer to peer computing markov processes;performance improvement;computational modeling;markov model;peer to peer computing availability markov processes load modeling analytical models bandwidth computational modeling;markov process;cycle sharing systems peer to peer networks p2p networks peer heterogeneity resource dynamics individual specific parameters heterogeneous markov model online storage fault tolerance;bandwidth;markov processes;p2p networks;peer to peer computing;peer to peer;load modeling;analytical model	The heterogeneous nature of Peer-to-Peer (P2P) networks can be exploited to optimize a wide range of applications. But this requires an accurate characterization of peer heterogeneity, which is difficult due to huge population and disparate properties of individuals. To overcome this barrier, we conduct a thorough inspection of peer heterogeneity in terms of individual churn and resource capacity. We make a first attempt to (i) experimentally reduce heterogeneous churn and resource dynamics to simple distributions with individual-specific parameters, and to (ii) provide an empirical support for the heterogeneous Markov model of churn. We further demonstrate how our characterization can be leveraged to optimize practical systems, through two case studies: fast backup in online storage and fault-tolerance in cycle-sharing systems. Both applications gain remarkable performance improvement by incorporating our model of peer heterogeneity.	backup;bandwidth (signal processing);experiment;fault tolerance;location (geography);markov chain;markov model;peer-to-peer;simulation;systems design	Zhi Yang;Yuanjian Xing;Feng Xiao;Zhi Qu;Xiaoming Li;Yafei Dai	2011	2011 IEEE International Conference on Peer-to-Peer Computing	10.1109/P2P.2011.6038657	computer simulation;real-time computing;simulation;computer science;distributed computing;markov process;statistics;computer network	DB	-11.165629690799657	71.84249253275979	143479
727e7404c37d713d7583fd51f2f3ba76d95d8f94	research on scheduling algorithm for workflow-based grid resource	resource scheduling;grid applications;scheduling algorithm grid computing costs dynamic scheduling computer architecture processor scheduling search engines service oriented architecture pervasive computing computer science;workflow based grid resource;web service;dynamic feedback mechanism scheduling algorithm workflow based grid resource grid computing workflow technology web service technology grid resources scheduling time estimation;dynamic feedback mechanism;scheduling algorithm;web service technology;scheduling;web services;grid service;workflow technology;grid computing;web services grid computing scheduling;time estimation;grid resources scheduling	In the research area of grid computing and workflow technology, workflow products based on Web-service technology can work as grid services in grid architecture. A new algorithm of scheduling grid resource with workflow engine is discussed in this paper. The QoS, executing time of process, cost and workload of grid resources are the key factors in grid resources scheduling. Dynamic feed back mechanism and executing time estimation are applied in this algorithm, which can keep the grid resources in a good balance and advance the whole performance of the grid application with workflow service.	algorithm;enter the matrix;feedback;grid computing;mobile data terminal;quality of service;scheduling (computing);web service;workflow engine	Cong Chen;Yang Yu;Jinfan Lei;Youming Lin;Wenpeng Li	2008	2008 The 3rd International Conference on Grid and Pervasive Computing - Workshops	10.1109/GPC.WORKSHOPS.2008.51	web service;real-time computing;semantic grid;computer science;operating system;data grid;database;distributed computing;scheduling;workflow management system;drmaa;workflow engine;grid computing;workflow technology	HPC	-18.895774918048346	67.02839361550417	143575
802ddfefe24e37018d79621c19ed410652d65971	evaluating the average-case performance penalty of bandwidth-like interfaces	composability;real time;compositionality	"""Many solutions for composability and compositionality rely on specifying the interface for a component using bandwidth. Some previous works specify period (P) and budget (Q) as an interface for a component. Q/P provides us with a bandwidth (the share of a processor that this component may request); P specifies the time-granularity of the allocation of this processing capacity. Other works add another parameter deadline which can help to provide tighter bounds on how this processing capacity is distributed. Yet other works use the parameters α and Δ where α is the bandwidth and Δ specifies how smoothly this bandwidth is distributed. It is known [4] that such bandwidth-like interfaces carry a cost: there are tasksets that could be guaranteed to be schedulable if tasks were scheduled directly on the processor, but with bandwidth-like interfaces, it is impossible to guarantee the taskset to be schedulable. And it is also known that this penalty can be infinite, i.e., the use of bandwidth-like interfaces may require the use of a processor that has a speed that is k times faster, and one can show this for any k. This brings the question: """"What is the average-case performance penalty of bandwidth-like interfaces?"""" This paper addresses this question. We answer the question by randomly generating tasksets and then for each of these tasksets, compute a lower bound on how much faster a processor needs to be when a bandwidth-like scheme is used. We do not consider any specific bandwidth-like scheme; instead, we derive an expression that states a lower bound on how much faster a processor needs to be when a bandwidth-like scheme is used. For the distributions considered in this paper, we find that (i) the experimental results depend on the experimental setup, (ii) this lower bound on the penalty was never larger than 4.0, (iii) for one experimental setup, for each taskset, it was greater than 2.4, (iv) the histogram of this penalty appears to be unimodal, and (v) for implicit-deadline sporadic tasks, this lower bound on the penalty was exactly 1."""	bandwidth (signal processing);best, worst and average case;composability;emoticon;randomness;smoothing	Björn Andersson	2016	SIGBED Review	10.1145/2983185.2983191	embedded system;real-time computing;computer science;theoretical computer science;operating system;distributed computing;principle of compositionality	Embedded	-9.940292843837705	62.92978204025213	143607
141a886e2ee831918d6975efae9a6c740b0a7f92	effect of network latency on load sharing in distributed systems	transfer pair;fila espera m m 1;file attente;distributed system;evaluation performance;sobrecarga;systeme reparti;cuantila;performance evaluation;quantiles;distribucion carga;fonction repartition;pervasive computing;evaluacion prestacion;distributed computing;load imbalance;queue;general techniques;probabilistic approach;carga repartida;system performance;informatica difusa;funcion distribucion;distribution function;sistema repartido;distributed computing system;multiple job transfer;informatique diffuse;enfoque probabilista;approche probabiliste;surcharge;numerical computation;m m 1 queue;retard;distribution charge;load sharing;calculo repartido;charge repartie;load distribution;file attente m m 1;latency;quantile;probability distribution function;overload;retraso;fila espera;queues;calcul reparti;distributed load;load sharing window	Distributed computing systems consist of computers interconnected by communications links. In such systems, Load sharing is an important technique used to improve system performance in which jobs are transferred from overloaded nodes to underloaded ones. However, due to the ubiquitous and inescapable presence of network latencies, various pitfalls arise which can adversely affect the beneficial effects of job transfer. In this paper, we present an investigation into the effect of network latency on load sharing. The notions of Transfer Pair, and Load-Sharing Window are rigorously defined. A general expression for the probability distribution function of the Load-Sharing Window is derived. A class of rules, called quantile rules, is introduced and their role in avoiding unproductive job redistribution in spite of network latency, as well as to make multiple job transfers, is explained. The general technique is applied to the specific case of a distributed computing system consisting of M/M/1 queues. For this case, an expression for the mean of the Load-Sharing Window is derived. Numerical computations are presented, and their significance discussed. © 2005 Elsevier Inc. All rights reserved.	algorithm;approximation;computation;computer;distributed computing;gigabit;graphics;job stream;load balancing (computing);numerical linear algebra;small multiple;smoothing;with high probability	M. Sriram Iyengar;Mukesh Singhal	2006	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2005.09.005	embedded system;parallel computing;real-time computing;quantile;computer science;operating system;distributed computing;computer performance;queue;ubiquitous computing;statistics	HPC	-13.081530515320457	63.56087670737855	143644
26cf03234d99d915d83000d26fc8e9eafeae6f25	load balancing for clusters of vod servers	video object;dynamic load balancing;video streaming;dynamic migration;qos;load balancing;load balance;vod;simulation model;admission control;clustering servers	In a VOD system with clustering servers, how to support more clients and reduce the average response time of requests is a critical topic. In the paper, we focus on dynamic load balancing among the servers to reach these goals. The load balancing among the servers can be achieved if a load balancing mechanism is triggered to perform file migration and request migration when a load unbalance is detected. Besides we also integrate an admission control mechanism within the system to guarantee video streams displayed continuously at a given rate, and even use an initialization algorithm to allocate video objects to the servers in advance according to their popularity and the capabilities of the servers. Through the simulation model, we found that our algorithms have better load balancing, higher accepted rate and faster response time of requests.	load balancing (computing);versant object database	Yin-Fu Huang;Chih-Chiang Fang	2002	Inf. Sci.	10.1016/j.ins.2003.10.005	round-robin dns;network load balancing services;real-time computing;computer science;load balancing;distributed computing;computer network	HPC	-16.558474077427196	71.34647885721981	143744
8709209a616e2a0e19225bb927610c36635058af	deadline constrained adaptive multilevel scheduling system in cloud environment	resource utilization;load balancing;priority scheduler;job scheduling;cloud computing	In cloud, everything can be provided as a service wherein a large number of users submit their jobs and wait for their services. Thus, scheduling plays major role for providing the resources efficiently to the submitted jobs. The brainwave of the proposed work is to improve user satisfaction, to balance the load efficiently and to bolster the resource utilization. Hence, this paper proposes an Adaptive Multilevel Scheduling System (AMSS) which will process the jobs in a multileveled fashion. The first level contains Preprocessing Jobs with Multi-Criteria (PJMC) which will preprocess the jobs to elevate the user satisfaction and to mitigate the jobs violation. In the second level, a Deadline Based Dynamic Priority Scheduler (DBDPS) is proposed which will dynamically prioritize the jobs for evading starvation. At the third level, Contest Mapping Jobs with Virtual Machine (CMJVM) is proposed that will map the job to suitable Virtual Machine (VM). In the last level, VM Scheduler is introduced in the two-tier VM architecture that will efficiently schedule the jobs and increase the resource utilization. These contributions will mitigate job violations, avoid starvation, increase throughput and maximize resource utilization. Experimental results show that the performance of AMSS is better than other algorithms.	scheduling (computing)	Dinesh Komarasamy;Muthuswamy Vijayalakshmi	2015	TIIS	10.3837/tiis.2015.04.002	in situ resource utilization;real-time computing;cloud computing;computer science;load balancing;job scheduler;operating system;distributed computing	HPC	-17.73575666947091	62.62570621824235	143871
6796a8bec78ba4af23e38db8665a514bce510220	an analytical model and an optimal scheduling heuristic for collective resource management	present data;brief discussion;analytical model;future research plan;theoretical calculation;real-world example;optimal task scheduling heuristic;collective resource management;expected average;optimal scheduling heuristic;queueing theory;simulation;computer science;resource manager;virtual machines;games;resource allocation;sun;resource management;scheduling;queuing theory	In the this paper, we study the problem of collective resource management. We first introduce the problem through real-world examples. Then we generalize the problem and build an analytical model using queuing theory. Based on this model, we evaluate the expected average waiting time of tasks. We present data from simulations, and compare the expected average waiting time from theoretical calculations to that from our experiments. We propose an optimal task scheduling heuristic. We conclude with a brief discussion of our future research plans.	experiment;heuristic;queueing theory;scheduling (computing);simulation	Qingnan Sun	2000			real-time computing;simulation;computer science;resource management;distributed computing;queueing theory	AI	-16.121673265536437	60.53342549561821	143907
d951ae8592be69fd398aeb1daf3bc6171550ca14	transforming distributed acyclic systems into equivalent uniprocessors under preemptive and non-preemptive scheduling	directed graphs;directed acyclic graph;equivalent circuit;distributed system;circuit theory;equivalent uniprocessors;impedance;text;control theory;preemptive scheduling;uniprocessor schedulability analysis;processor scheduling directed graphs;processor scheduling;nonpreemptive scheduling;schedulability analysis;distributed acyclic systems;pipeline delay composition;pipelines;resource sharing;equivalent circuits;performance analysis;computer science;worst case bound distributed acyclic systems equivalent uniprocessors nonpreemptive scheduling real time systems distributed system uniprocessor schedulability analysis pipeline delay composition directed acyclic graph;distributed systems;worst case bound;real time systems	Many scientific disciplines provide composition primitives whereby overall properties of systems are composed from those of their components. Examples include rules for block diagram reduction in control theory and laws for computing equivalent circuit impedance in circuit theory. No general composition rules exist for real-time systems whereby a distributed system is transformed to an equivalent single stage analyzable using traditional uniprocessor schedulability analysis techniques. Towards such a theory, in this paper, we extend our previous result on pipeline delay composition for preemptive and non-preemptive scheduling to the general case of distributed acyclic systems. Acyclic systems are defined as those where the superposition of all task flows gives rise to a Directed Acyclic Graph (DAG). The new extended analysis provides a worst-case bound on the end-to-end delay of a job under both preemptive as well as non-preemptive scheduling, in the distributed system. A simple transformation is then shown of the distributed task system into an equivalent uniprocessor task-set analyzable using traditional uniprocessor schedulability analysis. Hence, using the transformation described in this paper, the wealth of theory available for uniprocessor schedulability analysis can be easily applied to a larger class of distributed systems.	best, worst and average case;characteristic impedance;control theory;diagram;directed acyclic graph;distributed computing;end-to-end principle;equivalent circuit;network analysis (electrical circuits);preemption (computing);real-time clock;real-time computing;scheduling (computing);scheduling analysis real-time systems;uniprocessor system	Praveen Jayachandran;Tarek F. Abdelzaher	2008	2008 Euromicro Conference on Real-Time Systems	10.1109/ECRTS.2008.31	equivalent circuit;parallel computing;real-time computing;computer science;distributed computing	Embedded	-8.961037224082824	62.07474672413678	143946
9375d78da3d1f782aeaac4d1cd872738d597b3d6	traffic-aware virtual machine migration scheduling problem in geographically distributed data centers	electronic mail;virtual machining;system performance;heuristic algorithms;stability analysis;dynamic scheduling;cloud computing	In this work, we tackle the problem of VM migration scheduling in geodistributed DCs while considering fixed lifetime for VMs. We propose both exact and heuristic solutions that aim to find the best migration and placement decisions in a dynamic cloud environment. We consider networking VMs and we try to minimize the backbone traffic. The conducted experiments show the impact of the VM's lifetime on the migration decisions and prove the effectiveness of our heuristic solution in terms of maintaining of system stability.	experiment;heuristic;internet backbone;scheduling (computing);virtual machine;z/vm	Hana Teyeb;Ali Balma;Samir Tata;Nejib Ben Hadj-Alouane	2016	2016 IEEE 9th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2016.0110	von neumann stability analysis;real-time computing;simulation;cloud computing;dynamic priority scheduling;computer science;operating system;distributed computing;computer performance	HPC	-18.968875888392535	64.52053138526456	144013
bedfc0cf24cbb8c52bc2e69a6b24a993fcbbfcc4	improved online algorithms for multiplexing weighted packets in bounded buffers	online algorithm;buffer management;differentiated service;competitive analysis;quality of service;lower bound;competitive ratio	Motivated by providing differentiated services in the Internet, we consider online buffer management algorithms for quality-of-service network switches. We study a  multi-buffer model  . Packets have values and deadlines; they arrive at a switch over time. The switch consists of multiple buffers whose sizes are bounded. In each time step, only one pending packet can be sent. Our objective is to maximize the total value of the packets sent by their deadlines. We employ competitive analysis to measure an online algorithm's performance. In this paper, we first show that the lower bound of competitive ratio of a broad family of online algorithms is 2. Then we propose a ($3 + \sqrt{3} \approx 4.723$)-competitive deterministic algorithm, which is improved from the previously best-known result 9.82 (Azar and Levy. SWAT 2006).	multiplexing;online algorithm	Fei Li	2009		10.1007/978-3-642-02158-9_23	competitive analysis;mathematical optimization;real-time computing;computer science;distributed computing	Theory	-4.862959835711181	71.82357053986536	144017
4d189c43bd3dd6b30809eafea0866f50e903a08d	the design of a dynamic efficient load balancing algorithm on distributed networks	workload;symmetric configuration;distributed system;block design;carga dinamica;reseau communication;haute performance;systeme reparti;distributed networks;equilibrio de carga;configuration symetrique;gestion trafic;communication complexity;equilibrage charge;distributed computing;complexite communication;traffic management;charge dynamique;dynamic load;carga repartida;plan bloc;plan bloque;configuracion simetrica;sistema repartido;balanced incomplete block design;algorithme reparti;charge travail;matrice adjacence;palabra;load balancing;gestion trafico;alto rendimiento;calculo repartido;charge repartie;algoritmo repartido;word;load balance;matriz adyacencia;adjacency matrix;carga trabajo;distributed algorithm;red de comunicacion;high performance;communication network;calcul reparti;algorithm design;mot;distributed load	In order to maintain load balancing in a distributed network, each node should obtain workload information from all the nodes in the network. To accomplish this, this processing requires O(v2) communication complexity, where v is the number of nodes. First, we present a new synchronous dynamic distributed load balancing algorithm on a (v,k+1,1)-configured network applying a symmetric balanced incomplete block design, where v=k2+k+1. Our algorithm designs a special adjacency matrix and then transforms it to (v,k+1,1)-configured network for an efficient communication. It requires only $O(v \sqrt v)$ communication complexity and each node receives workload information from all the nodes without redundancy since each link has the same amount of traffic for transferring workload information. Later, this algorithm is reconstructed on distributed networks, where v is an arbitrary number of nodes and is analyzed in terms of efficiency of load balancing.	algorithm;load balancing (computing)	Yeojin Lee;Okbin Lee;Wan-Kyoo Choi;Chunkyun Youn;Ilyong Chung	2006		10.1007/11847366_9	distributed algorithm;block design;real-time computing;computer science;load balancing;distributed computing;algorithm	Theory	-10.197372857586185	68.80694664316722	144137
f85ada76c863a4f23e8a3356888f4c095e0ba848	a high throughput asic design for ipv6 routing lookup system	dram high throughput asic design ipv6 routing lookup system cache centric binary content addressable memory fifo replacement algorithm ternary content addressable memory on chip bcam offchip tcam;routing application specific integrated circuits random access memory computer architecture cache memory ip networks generators;network routing;application specific integrated circuits;table lookup;table lookup application specific integrated circuits dram chips network routing;dram chips	This paper presents a cache-centric, hash-based architecture within a application specific integrated circuit (ASIC) implementation for IPv6 routing lookup system. In ASIC, the binary content addressable memory (BCAM) as cache memory has a hit ratio of up to 80% with a FIFO replacement algorithm. A hash function is used to reduce lookup time for the routing table and ternary content addressable memory (TCAM) effectively resolves the collision problem. The results of postlayout simulations show that the ASIC operates in 3.6ns so that the routing lookup system approaches 260 Mega lookups per second (Mlps), which is sufficient for 100 Gbps networks. The routing table only needs 10.24KB on-chip BCAM, 20.04KB offchip TCAM and 29.29MB DRAM for 3.6M routing entries in the proposed system.	application-specific integrated circuit;cpu cache;collision problem;content-addressable memory;data rate units;dynamic random-access memory;fifo (computing and electronics);hash function;high-throughput computing;hit (internet);kilobyte;lookup table;megabyte;page replacement algorithm;routing table;simulation;telecommunications access method;throughput	Yi-Mao Hsiao;Yuan-Sun Chu;Chao-Yang Chang;Chung-Hsun Huang;Hsi-Hsun Yeh	2013	2013 IEEE International Symposium on Circuits and Systems (ISCAS2013)	10.1109/ISCAS.2013.6571891	routing table;routing;parallel computing;real-time computing;computer hardware;computer science;application-specific integrated circuit	Arch	-5.686194528475589	66.60898516678776	144160
c5839de113f91306d067b691d28508c679d3b3ab	a scheduling method on selective contents delivery with node relay-based webcast considering data size		Due to the recent popularization of digital broadcasting systems, selective contents broadcasting depending on users' preferences have attracted great attention. Although the server can deliver programs reflecting users' preferences, clients have to wait until their selected contents start playing. Conventional methods reduce the waiting time by producing an effective broadcast schedule. Although the server can deliver programs that meet users' preferences, clients have to wait until their selected contents are delivered. In this paper, we propose a method to reduce the waiting time on selective contents delivery with node relay-based webcast that relay data among nodes. Our proposed method reduces the waiting time by scheduling contents considering available bandwidth of each node.	internet relay chat;scheduling (computing);server (computing)	Yusuke Gotoh;Tomoki Yoshihisa;Hideo Taniguchi;Masanori Kanazawa	2010	AISS		computer science;computer network	DB	-16.76963616662329	72.7848532548603	144216
9983a39bbd814d4a50be7705bf02a610a86e5bde	efficient non-blocking top-k query processing in distributed networks	distributed system;base donnee;systeme reparti;query processing;distributed networks;traitement requete;interrogation base donnee;database;interrogacion base datos;base dato;satisfiability;hierarchical classification;sistema repartido;intermitencia;network traffic;scheduling;retard;classification hierarchique;intermittency;tratamiento pregunta;intermittence;retraso;top k query processing;clasificacion jerarquizada;database query;ordonnancement;reglamento	Incremental access can be essential for top-k queries, as users often want to sift through top answers until satisfied. In this paper, we propose the progressive rank (PR, for short) algorithm, a new non-blocking top-k query algorithm that deals with data items from remote sources via unpredictable, slow, or bursty network traffic. By accessing remote sources asynchronously and scheduling background processing reactively, PR hides intermittent delays in data arrival and produces the first few results quickly. Experiments results show that PR is an effective solution for producing fast query responses in the presence of slow and bursty remote sources, and can be scaled well.		Bo Deng;Yan Jia;Shuqiang Yang	2006		10.1007/11733836_65	computer science;theoretical computer science;data mining;database;scheduling;intermittent energy source;satisfiability	DB	-13.529823382537286	69.71243136620122	144495
2c2f5afc64862b19f93f8c380a910a2238926f30	design exploration framework under impreciseness based on register-constrained inclusion scheduling	inclusion scheduling;multiple design attributes;informacion incompleta;specification;imprecise information;synthese haut niveau;imperfect information;sintesis alto nivel;imprecise design exploration;incomplete information;high level synthesis;scheduling algorithm;especificacion;filter;scheduling;information incomplete;register constraint;informacion imperfecta;filtre;scheduling allocation;functional unit;filtro;ordonnancement;reglamento;information imparfaite	In this paper, we propose a design exploration framework which consider impreciseness in design specification. In high-level synthesis, imprecise information is often encountered. Two kinds of impreciseness are considered here: imprecise characteristics of functional units and imprecise design constraints. The proposed design exploration framework is based on efficient scheduling algorithm which considers impreciseness, Register-Constrained Inclusion Scheduling. We demonstrate the effectiveness of our framework by exploring a design solution for a well-known benchmark, Voltera filter. The selected solution meets the acceptability criteria while minimizing the total number of registers.	scheduling (computing)	Chantana Phongpensri;Wanlop Surakumpolthorn;Edwin Hsing-Mean Sha	2004		10.1007/978-3-540-30502-6_6	real-time computing;computer science;artificial intelligence;operating system;database;scheduling;algorithm	EDA	-8.120318317309517	62.19574637609612	144754
6ed55ec813d68ee814d87bdc0eb7a327ae11718e	on load balancing equilibria in multiqueue systems with multiclass traffic	analytical models;optimal allocation load balancing equilibria multiqueue system multiclass traffic fcfs server;probability;routing;pricing;queueing theory;resource manager;resource management;individual object;servers resource management routing pricing load modeling analytical models load management;servers;telecommunication network routing;queueing system;load management;telecommunication network routing probability queueing theory;load balance;load modeling;analytical model	We consider a queueing system with two non identical FCFS servers together serving two classes of customers. All customers have i.i.d service requirements. One of the queues may charge an admission price, say c. Arrivals are randomly routed to one of the servers and the routing probabilities are determined centrally to optimise a global objective, or from a local mechanism minimising a local—class or individual—objective. Our interest is to analyse the use of c to achieve a target distribution of loads among the servers. We first analyse the structure of the optimal allocation and then consider (1) a system with a dispatcher for each class, (2) a non atomic system, and (3) a system where one of the classes has a dispatcher.	centralisation;load balancing (computing);mathematical optimization;queueing theory;randomness;requirement;routing	Tejas Bodas;D. Manjunath	2011	International Conference on NETwork Games, Control and Optimization (NetGCooP 2011)		real-time computing;distributed computing;business;computer network	Metrics	-13.139162235124065	66.21272790527523	144926
5314d7f857fa6b3e78ae1f54d6033991ffd90bfe	configuring hard real-time distributed systems		My work is concerned with configuring automatically distributed hard real-time systems. A large facet of this work is the development of analysis which can take a given configuration of a distributed hard real-time system and determining whether the timing constraints are met. To do this I have developed extensive scheduling theory, assuming a static priority pre-emptive scheduling algorithm. I have been largely successful in developing this theory, and can now determine worst-case response times (i.e. the time between a task being released and the task terminating after executing for a bounded of computation time) for a number of different task types. One of the most powerful and expressive pieces of theory allows a set of task transactions to be described: each transaction consists of a set of tasks which are released at fixed offsets in time relative to each other. The transactions can be used to implement distributed hard real time systems, and allow complex timing patterns to be described.	distributed computing;real-time operating system;real-time transcription	Ken Tindell	1992		10.1007/978-3-642-88049-0_122	scheduling (computing);facet (geometry);computation;bounded function;normalization property;computer science;distributed computing;database transaction	Logic	-9.918287229169984	61.11233965182365	145051
2f9fcf6747ee1a6c88ee7a24f720c3ac1eafe7e5	an efficient access reduction scheme of big data based on total probability theory	big data;total probability theory;divide-and-conquer;access reduction;multi-attribute	Big data is being widely used in various fields and the accuracy and calculation cost regarding the search results of big data are being researched constantly. In this paper, a big data access reduction scheme based on total probability theory is proposed to improve the accuracy and minimize calculation cost of big data search. The proposed scheme uses the reduction approach of divide-and-conquer; that is, it distinguishes all the attributes of data so as to minimize the data. Also, to improve the efficiency of data access, the proposed scheme assigns the attribute information in accordance with the properties of big data access to minimize the required amount of information to classify the information in the big data group into tuple based on the probability values, in order to apply the least randomness within the big data group. In particular, the proposed scheme aims to improve data access compared to the existing methods by connecting the probability values among the data to access the divided data more easily. The performance evaluation results show that compared to the existing method, the proposed scheme improved accuracy by 7.1%, decreased data storage space by 3.8%, and shortened the process time by 11.1%.	accessibility;big data;computer data storage;cylinder-head-sector;data access;entity–relationship model;geforce 7 series;interconnection;kempe chain;performance evaluation;randomness	Yoon-Su Jeong;Seung-Soo Shin	2017	Wireless Personal Communications	10.1007/s11277-016-3920-6	computer science;theoretical computer science;data mining;database	DB	-13.884384612736897	71.55182727173649	145086
b40465701c6b32edf144688e110703bf18fc7fc5	an adaptive hybrid technique for video multicast	multicast communication;television broadcasting multicast communication video on demand;unfairness adaptive hybrid technique video multicast periodic broadcast scheduled multicast server bandwidth hybrid techniques service latency throughput defection rate;television broadcasting;video on demand;delay throughput streaming media broadcasting processor scheduling software libraries computer science bandwidth motion pictures video on demand	Periodic broadcast and scheduled multicast have been shown to be very effective in reducing the demand on server bandwidth. While periodic broadcast is ideally suited for very popular videos, scheduled multicast is better for less demanded objects. Work has also been done to show that a hybrid of these techniques offers the best performance. Existing hybrid techniques, however, assume that the workload does not change with time. This assumption is not true for many applications, such as movie on demand, digital video libraries, or electronic commerce. In this paper, we show evidence that existing scheduled multicast techniques are not suited for hybrid designs. To address this issue, we propose a new scheme, and use it to design an adaptive hybrid strategy which adjusts itself to cope with a changing workload. We provide simulation results to show that the proposed technique is signi cantly better than the best static approach in terms of service latency, throughput, defection rate, and unfairness.	digital video;e-commerce;library (computing);multicast;server (computing);simulation;terms of service;throughput	Kien A. Hua;Jung Hwan Oh;Khanh Vu	1998		10.1109/ICCCN.1998.998781	real-time computing;multicast;ip multicast;inter-domain;reliable multicast;telecommunications;protocol independent multicast;computer science;pragmatic general multicast;distributed computing;distance vector multicast routing protocol;source-specific multicast;multimedia broadcast multicast service;broadcasting;xcast;computer network;multicast address	Metrics	-16.18425574084343	71.19056370191635	145480
aeb049d0a1869827523689a7b8ccddff43aaec0c	on the performance of wide-area thin-client computing	benchmarking;performance measure;distributed system;eficacia sistema;internet access;systeme reparti;computer communication networks;red larga distancia;reseau ordinateur;slow motion;evaluacion comparativa;performance systeme;movimiento lento;reseau longue distance;slow motion benchmarking;performance of systems;mouvement lent;system performance;computer network;sistema repartido;internet;internet2;thin client;red informatica;measurement technique;wide area network;application service provider;wide area networks	While many application service providers have proposed using thin-client computing to deliver computational services over the Internet, little work has been done to evaluate the effectiveness of thin-client computing in a wide-area network. To assess the potential of thin-client computing in the context of future commodity high-bandwidth Internet access, we have used a novel, noninvasive slow-motion benchmarking technique to evaluate the performance of several popular thin-client computing platforms in delivering computational services cross-country over Internet2. Our results show that using thin-client computing in a wide-area network environment can deliver acceptable performance over Internet2, even when client and server are located thousands of miles apart on opposite ends of the country. However, performance varies widely among thin-client platforms and not all platforms are suitable for this environment. While many thin-client systems are touted as being bandwidth efficient, we show that network latency is often the key factor in limiting wide-area thin-client performance. Furthermore, we show that the same techniques used to improve bandwidth efficiency often result in worse overall performance in wide-area networks. We characterize and analyze the different design choices in the various thin-client platforms and explain which of these choices should be selected for supporting wide-area computing services.	data compression;hardware description language;high- and low-level;internet access;interrupt latency;pixel;push technology;qualitative comparative analysis;server (computing);spectral efficiency;thin client	Albert M. Lai;Jason Nieh	2006	ACM Trans. Comput. Syst.	10.1145/1132026.1132029	embedded system;the internet;simulation;internet access;application service provider;telecommunications;computer science;operating system;computer performance;utility computing;computer network;benchmarking	Metrics	-6.476879670552324	74.45351235661306	145510
dbe6565f5a6c6dbde6520b5754f7ed897432988b	avoiding request-request type message-dependent deadlocks in networks-on-chips	network on chip noc;message dependent deadlock;virtual channel;streaming protocols	Article history: Available online 1 June 2013	algorithm;deadlock;np-completeness;network on a chip;routing	Xiaohang Wang;Peng Liu;Mei Yang;Yingtao Jiang	2013	Parallel Computing	10.1016/j.parco.2013.05.002	parallel computing;real-time computing;computer science;distributed computing	HPC	-11.368870693434939	62.93887583983406	145626
aa822ebef9127e377597292a319eb842e27686d4	fault tolerant queries in computer networks	tolerancia falta;nudo estructura;protocols;nodes;telecommunications control computer networks protocols fault tolerant computing decentralised control feedback;protocole interrogation;fault tolerant;telecommunications control;reseau ordinateur;query protocol;computer networks;computer network;algorithme;algorithm;fault tolerant computing;feedback;decentralised control;fault tolerance intelligent networks computer networks network topology protocols distributed control feedback costs printers postal services;commande decentralisee;protocols fault tolerant queries computer networks decentralized control distributed query mechanism node remote resource flooding feedback links message complexity;fault tolerance;red ordenador;decentralized control;control decentralizado;noeud structure;tolerance faute;algoritmo	In computer networks with decentralized control, it is necessary to provide a distributed query mechanism, whereby a node can dynamically discover the location of a remote resource. The authors propose a query mechanism based on flooding with feedback, which uses no more than two messages over any link. They examine the fault tolerant aspects of this distributed query mechanism, operating in a network where links and nodes may fail and show that, under certain conditions, the resource is indeed found. They then construct enhancements to this mechanism, where the conditions under which the resource is found are substantially relaxed, at the cost of some increase in message complexity. >	fault-tolerant computer system	Alan E. Baratz;Inder S. Gopal;Adrian Segall	1994	IEEE Trans. Communications	10.1109/26.275305	fault tolerance;real-time computing;computer science;distributed computing;computer network	Arch	-4.643573385384371	73.99086654720591	145830
337b292023c4b21a08fdbfd7f26b78a6883a01ef	virtual time synchronization over unreliable network transport	fault tolerance;message passing;context modeling;transport protocols;algorithm design and analysis;parsec;discrete event simulation;computational modeling;synchronisation;time management;semiconductor manufacturing;computer simulation;best effort	In parallel and distributed simulations, it is sometimes desirable that the application's time-stamped events and/or the simulator's time-management control messages be exchanged over a combination of reliable and unreliable network channels. A challenge in developing infrastructure for such simulations is to correctly compute simulation time advances despite the loss of some simulation events and/or control messages. Presented here are algorithms for synchronization in distributed simulations performed directly over best-effort network transport. The algorithms are presented in a sequence of progressive refinement, starting with all reliable transport and finishing with combinations of reliable and unreliable transports for both time-stamped events and time management messages. Performance results from a preliminary implementation of these algorithms are also presented. To our knowledge, this is the first work to solve asynchronous time synchronization performed directly over unreliable network transport.	algorithm;best-effort delivery;progressive refinement;refinement (computing);simulation	Kalyan S. Perumalla;Richard M. Fujimoto	2001			computer simulation;best-effort delivery;algorithm design;synchronization;fault tolerance;parallel computing;message passing;parsec;real-time computing;simulation;time management;computer science;discrete event simulation;operating system;distributed computing;context model;semiconductor device fabrication;computational model;transport layer;computer network	HPC	-9.054421371880693	65.21093674754145	145856
be9e47bc4c60a3613221888665cd0928051b4890	rate-distortion optimized streaming of fine-grained scalable video sequences	optimal solution;rate distortion;perceived quality;scalable video;video streaming;optimization technique;real time;streaming video;fine grained scalable streaming;model transformation;video quality;simplex method;optimization problem;peer to peer streaming;fgs;nonlinear problem;linear program;distributed streaming;rate distortion optimization;peer to peer;integer linear program;heuristic algorithm;rate distortion optimized streaming;rate distortion models	We present optimal schemes for allocating bits of fine-grained scalable video sequences among multiple senders streaming to a single receiver. This allocation problem is critical in optimizing the perceived quality in peer-to-peer and distributed multi-server streaming environments. Senders in such environments are heterogeneous in their outgoing bandwidth and they hold different portions of the video stream. We first formulate and optimally solve the problem for individual frames, then we generalize to the multiple frame case. Specifically, we formulate the allocation problem as an optimization problem, which is nonlinear in general. We use rate-distortion models in the formulation to achieve the minimum distortion in the rendered video, constrained by the outgoing bandwidth of senders, availability of video data at senders, and incoming bandwidth of receiver. We show how the adopted rate-distortion models transform the nonlinear problem to an integer linear programming (ILP) problem. We then design a simple rounding scheme that transforms the ILP problem to a linear programming (LP) one, which can be solved efficiently using common optimization techniques such as the Simplex method. We prove that our rounding scheme always produces a feasible solution, and the solution is within a negligible margin from the optimal solution. We also propose a new algorithm (FGSAssign) for the single-frame allocation problem that runs in O(nlog n) steps, where n is the number of senders. We prove that FGSAssign is optimal. Furthermore, we propose a heuristic algorithm (mFGSAssign) that produces near-optimal solutions for the multiple-frame case, and runs an order of magnitude faster than the optimal one. Because of its short running time, mFGSAssign can be used in real time. Our experimental study validates our analytical analysis and shows the effectiveness of our allocation algorithms in improving the video quality.	block size (cryptography);central processing unit;experiment;frame language;heterogeneous computing;heuristic (computer science);high-level programming language;integer programming;linear programming;mathematical optimization;memory management;nonlinear system;optimization problem;peer-to-peer;rounding;scalability;server (computing);simplex algorithm;streaming media;time complexity;total distortion;truncation;whole genome sequencing	Mohamed Hefeeda;Cheng-Hsin Hsu	2008	TOMCCAP	10.1145/1324287.1324289	heuristic;optimization problem;mathematical optimization;real-time computing;computer science;linear programming;video quality;theoretical computer science;rate–distortion optimization;simplex algorithm	Theory	-17.88541404103434	66.69305015389438	145883
29347e0f0e0ec322fce1ba183627f60baf642ca1	popularity-based partial caching for vod systems using a proxy server	cache storage;continuous media;multimedia streaming;proxy caching;multimedia systems;telecommunication traffic;network servers;streaming media;bandwidth;ip networks;streaming media delay web server telecommunication traffic cache storage network servers bandwidth computer science multimedia systems ip networks;web server;computer science;trace driven simulation;proxy server	In this paper, we propose a PPC (Populari@-based Partial Caching) scheme for continuous media objects on the proxy servers. In this scheme, either the initial portion or the entire blocks of objects are cached and the size of the initial portion of each stream varies with the popularity of that stream. Under the proposed scheme, the initial latency otherwise happens to access the requested objects from the remote server can be reduced signijlcantly and moreover, the limited cache storage space can be utilized ef~cient~. Considering the characteristics of continuous media objects, we also apply the popularity of each stream by taking the amount of the data of eac~~ stream played back by clients into consideration. As a result of trace-driven simulations with 9 days of log jiles for VOD server, which were obtained from the website http://imbc.hananet. net, we show that, PPC, our proposed caching scheme, outperforms other well-known caching schemes in hit ratios and replacement overhead.	cache (computing);david jiles;overhead (computing);proxy server;server (computing);simulation;versant object database	Seong-Ho Park;Eun-Ji Lim;Ki-Dong Chung	2001	Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001	10.1109/IPDPS.2001.925088	real-time computing;computer science;operating system;world wide web;bandwidth;web server;computer network	Arch	-16.18305147445315	71.90192941827925	146123
4b24a15c1ac4a71938f777a4f062396889c3e7ca	research on data interoperability based on clustering analysis in data grid	clustering analysis;data sharing;pattern clustering;data interoperability clustering analysis data replication strategy data grid;history;rsca;correlative relation;application software;prefetching;time sharing;data replication strategy;data replication;data engineering;correlative files sets;data analysis;data interoperability;statistical analysis data handling grid computing pattern clustering;cluster analysis;statistical analysis;data analysis data engineering history delay bandwidth application software information analysis grid computing prefetching load management;correlative files sets rsca correlative relation;load management;bandwidth;data handling;grid computing;information analysis;data grid	In data grid, it is an important research filed to complete interoperability of data. In the mean time, share of data also becomes the crucial problem. Data replication, as a solved solution of data share, goes into more and more vital. A strategy called Replication Strategy Based on Clustering Analysis (RSCA) is proposed, which confirms the correlation among the data files accessed according to the access history of users. And then, through clustering analysis operation obtains the correlative files sets related to the access habits of users. At the same time, it produces the data files replica on the basis of those sets, which achieves the aim of prefetching and buffering data. The experimental results show that RSCA is effective and available. Contrast to other dynamic replication strategies, it has reduced not only the average response time of client nodes, but also those of the bandwidth consumption.	blueprint;cpu cache;cluster analysis;computer cluster;data buffer;data mining;grid computing;han unification;interoperability;john d. wiley;mathematical optimization;replication (computing);response time (technology);simulation	Gui Liu;HaiLiang Wei;Xin Wang;Wei Peng	2009	2009 International Conference on Interoperability for Enterprise Software and Applications China	10.1109/I-ESA.2009.19	computer science;data mining;database;world wide web	DB	-17.183380358132972	68.74627743945705	146227
49a3f3c0e9fa9a6dace5472be0176cf31a433da2	snap-stabilizing pif algorithm in arbitrary networks	intelligent networks protocols feedback distributed computing broadcasting fault tolerance algorithm design and analysis tree graphs computer science fault detection;distributed algorithms;distributed algorithms protocols fault tolerant computing;protocols;self stabilization;fault tolerant computing;fault tolerance;deterministic protocol snap stabilizing propagation of information with feedback protocol snap stabilizing pif algorithm arbitrary networks arbitrary initial system configuration specification distributed protocol;wave algorithms;spanning tree;snap stabilization;reset protocols;propagation of information with feedback	We present the first snap-stabilizing propagation of information with feedback (PIF) protocol in arbitrary networks. A snap-stabilizing protocol, starting from any arbitrary initial system configuration, always behaves according to its specification. Our protocol is distributed, deterministic, and does not use a pre-constructed spanning tree.	algorithm;path integral formulation	Alain Cournier;Ajoy Kumar Datta;Franck Petit;Vincent Villain	2002		10.1109/ICDCS.2002.1022257	self-stabilization;communications protocol;distributed algorithm;fault tolerance;real-time computing;spanning tree;computer science;theoretical computer science;distributed computing	ML	-6.967798651830574	72.10850012110221	146285
5c1209f65d8ad43f8df0e820386431cd4c8684b4	an approximation-based load-balancing algorithm with admission control for cluster web servers with dynamic workloads	workload;load control;modelizacion;distributed system;acces contenu;commerce electronique;controle acces;carga dinamica;web based applications;entreprise;control theory;haute performance;systeme reparti;cluster based web server;comercio electronico;red www;distributed agents;temps service;e commerce;calculator cluster;equilibrio de carga;correction erreur;approximation algorithm;empresa;reseau web;serveur informatique;equilibrage charge;database;service web;base dato;tiempo servicio;supercomputer;service time;web service;charge dynamique;dynamic load balancing algorithm;dynamic load;commande charge;commande proportionnelle integrale;supercomputador;modelisation;grappe calculateur;sistema repartido;content access;internet;error correction;control carga;firm;retard;error handling;algoritmo aproximacion;charge travail;base de donnees;load balancing;acceso contenido;alto rendimiento;servidor informatico;world wide web;load balance;integral proportional control;access control;correccion error;pi controller;feedback controller design;algorithme approximation;carga trabajo;retraso;modeling;high performance;electronic trade;traitement erreur;racimo calculadora;proportional integral;analytical model;superordinateur;servicio web;admission control;analytical model of web server;computer server;control pi	The growth of web-based applications in business and e-commerce is building up demands for high performance web servers for better throughputs and lower user-perceived latency. These demands are leading to a widespread substitution of powerful single servers by robust newcomers, cluster web servers, in many enterprise companies. In this respect the load-balancing algorithms play an important role in boosting the performance of cluster servers. The previous load-balancing algorithms which were designed for the handling of static contents in web services suffer from significant performance degradation under dynamic and database-driven workloads. Regarding this, we propose an approximation-based load-balancing algorithm with admission control for cluster-based web servers in this study. Since it is difficult to accurately determine the loads of web servers through feedbacks from distributed agents in web servers, we propose an analytical model of a web server to estimate the web servers’ loads. To achieve this, the algorithm classifies requests based on their service times and track numbers of outstanding requests for each class of each web server node and also based on their resource demands to dynamically estimate the loads of each node. For the error handling of the model a proportional integral (PI) controller from control theory is used. Then the estimated available capacity of each web server is used for load balancing and admission control decisions. The implementation results with a standard benchmark confirm the effectiveness of the proposed scheme, which improves both the mean response time and the throughput of the cluster compared to rival load-balancing algorithms, and also avoids situations in which the cluster is overloaded, even when the request rates are beyond the cluster capacity.	algorithm;approximation;benchmark (computing);cap computer;central processing unit;computer cluster;control system;control theory;e-commerce;elegant degradation;exception handling;feedback;load balancing (computing);prototype;response time (technology);scalability;server (computing);throughput;web application;web server;web service;weighted round robin	Saeed Sharifian;Seyed A. Motamedi;Mohammad Kazem Akbari	2009	The Journal of Supercomputing	10.1007/s11227-009-0303-8	round-robin dns;embedded system;supercomputer;real-time computing;simulation;computer science;load balancing;operating system;computer security;approximation algorithm;client–server model;server;server farm	Metrics	-17.295446385580796	70.73625100039159	146513
714a7379259c9d5255d789485e9f9d9f09332a8a	optimal replica distribution in edge-node-assisted cloud-p2p platforms for real-time streaming		In recent years, there have been a number of large-scale deployments of P2P real-time streaming platforms in cloud storage systems due to their fast and convenient storage services for platform designers. Note that providing real-time streaming services for a platform is costly because of heavy bandwidth consumption from the platform to end-users. To cope with the above issue, our idea is to exploit the upload bandwidth of volunteers, namely, edge or fog nodes, to form an edge-node-assisted real-time streaming P2P platform. Specifically, according to designed strategies, the cloud distributes chunk replicas to edge nodes that can respond to end-user requests, and the public cloud supplements end-user demands only when the edge nodes cannot accommodate them. One of the important issues while introducing edge nodes into the system is how to utilize their resources efficiently. However, mainly due to the heterogeneous upload capacity of edge nodes and uneven request rates for different streaming chunks, the replica utilization at the edge nodes is diverse for different replica distribution strategies. Likewise bandwidth consumption in the public cloud varies correspondingly. Thus, this paper describes a mathematical model of the proposed replica distribution and designs an optimal algorithm for distributing chunk replicas. The results validate the effectiveness of the proposal.	algorithm;bandwidth (signal processing);cloud computing;cloud storage;mathematical model;peer-to-peer;real-time clock;real-time locating system;real-time transcription;upload	Wei Zhao;Jiajia Liu;Takahiro Hara	2018	IEEE Transactions on Vehicular Technology	10.1109/TVT.2018.2839725	replica;computer network;cloud storage;computer science;exploit;cloud computing;upload;bandwidth (signal processing);server	Embedded	-16.983627319963258	73.28964594535478	146743
ed9406d69b54c2163fdde9ad3768d0d6227e469c	a heuristic algorithm for agent-based grid resource discovery	heuristic;heuristic algorithms resource management scheduling algorithm large scale systems protocols computer architecture high performance computing educational institutions computer science scalability;first come first serve;resource discovery;agent based;resource allocation;scheduling multi agent systems grid computing resource allocation;resource manager;resource management;agent graph heuristic algorithm agent based grid resource discovery agent based resource management model first come first served strategy resource advertisement multiagent cooperation resource discovery;agent;multi agent systems;scheduling;graph;resource discovery agent graph resource management heuristic;task scheduling;grid computing;heuristic algorithm	"""This paper introduces an agent-based resource management model, agent structure and its function. On the basis of local resources adopting the strategy """"first come first served"""" to the task, we put forward a resource management heuristic algorithm using a technique of resource advertisement and discovery. Agents are organized into a graph and the heuristic algorithm is based on multi-agent cooperation, to ensure this methodology achieves the goal of task scheduling."""	agent-based model;algorithm;heuristic (computer science);multi-agent system;scheduling (computing)	Shunli Ding;Jingbo Yuan;Jiubin Ju;Liang Hu	2005	2005 IEEE International Conference on e-Technology, e-Commerce and e-Service	10.1109/EEE.2005.9	resource allocation;computer science;knowledge management;distributed computing;management science	Robotics	-16.74423286765588	63.669563785016265	146911
27184322958fb7b4a01a91c27286961d687d2372	mumq: a lightweight and scalable mqtt broker		A message broker is an imperative component in IoT systems, and it works as a gateway between IoT devices and application platforms. With the growth of IoT devices today, these systems can easily overwhelm message brokers unless the software can fully utilize hardware resources such as multi-core facility. This paper presents muMQ, a high-performance MQTT broker running on Commercial-Off-The-Shelf hardware. It tackles the challenge to improve the performance of message brokering on a single machine by efficiently utilizing multi-core CPUs. First, muMQ exploits an event-driven I/O mechanism for multi-core scalability. Each CPU core equally handles dispatched TCP connections and locally processes MQTT logic. Second, muMQ adopts a user-level TCP/IP stack, mTCP with DPDK, to avoid the overhead of the in-kernel TCP/IP stack, including system call overhead and resource contention. We evaluate the effectiveness of our approach through experiments. The results show that muMQ can handle 512K or greater long-lived subscribers with no message loss; muMQ achieves a publish messaging rate at 930K messages per second, which is 5.38 times faster than an existing MQTT broker. We also confirm mTCP accelerates the performance by 1.8 times compared with muMQ using the in-kernel TCP/IP stack.	bitbucket;central processing unit;dpdk / dpdk.org;event-driven programming;experiment;imperative programming;input/output;internet protocol suite;kernel (operating system);mqtt;message broker;multi-core processor;multiplexing;overhead (computing);resource contention;scalability;system call;thread (computing);throughput;user space	Wiriyang Pipatsakulroj;Vasaka Visoottiviseth;Ryousei Takano	2017	2017 IEEE International Symposium on Local and Metropolitan Area Networks (LANMAN)	10.1109/LANMAN.2017.7972165	computer network;system call;scalability;distributed computing;mqtt;internet protocol suite;computer science;multi-core processor;default gateway;message broker;exploit	Arch	-7.214709575597227	64.90350828965143	146974
7c80fe65bcbda840e7e2b2a45a7a51b6dcea5ae0	an improvement on load-balancing on linux virtual server for internet-based laboratory	load balance internet based laboratory lvs genetic algorithm optimized bp neural network algorithm modelica;neural networks;servers;time factors;scheduling;heuristic algorithms;electrical engineering virtual lab load balancing linux virtual server internet based laboratory cluster stability genetic optimized bp neural network algorithm load balancing cluster;clustering algorithms;servers neural networks load modeling time factors scheduling clustering algorithms heuristic algorithms;load modeling;virtualisation backpropagation computer aided instruction electrical engineering education genetic algorithms internet laboratory techniques linux network servers neural nets resource allocation	In order to make the performance of Electrical Engineering Virtual Lab meet growing customer demand, this paper makes an improvement on the architecture of load-balancing cluster on Linux Virtual Server, and proposes a genetic optimized BP neural network algorithm to improve the currency performance and stability of the cluster.	algorithm;artificial neural network;electrical engineering;linux virtual server;load balancing (computing);scheduling (computing)	Jun Chen;Qing-Guo Wang;Shanan Zhu	2016	2016 12th IEEE International Conference on Control and Automation (ICCA)	10.1109/ICCA.2016.7505358	real-time computing;computer science;operating system;distributed computing;cluster analysis;scheduling;artificial neural network;server	Robotics	-17.57569595275374	66.78859246024402	147633
e696d624ebcf7e6bc6552fd7e529edde5394d23a	smbr: a novel nat traversal mechanism for structured peer-to-peer communications	punching;macquarie university institutional repository;selective message buddy relaying nat traversal mechanism structured peer to peer communications smbr;protocols;researchonline;digital repository;macquarie university;p2p;transport protocols;transport protocols peer to peer computing;servers;nat traversal;transforms;structrued p2p nat traversal p2p dht;self organization;ip networks;peer to peer computing;relays;servers peer to peer computing ip networks relays protocols punching transforms;peer to peer;dht;structrued p2p	In recent years, structured P2P communications is being widely used for its features of self-organization as well as good scalability and flexibility. To make sure that every node can participate in such a network whether it is behind a NAT or not, we must solve the NAT traversal problem. However, existing NAT traversal methods all need the support of a centralized server which will destroy the distributive characteristic of structured P2P. In this paper, we propose a distributed NAT traversal mechanism called SMBR (Selective-Message Buddy Relaying) for structured P2P. SMBR has two main advantages. The first one is that it does not need the support of a server and thus can maintain the characteristics of structured P2P. Secondly, SMBR uses different mechanisms for the control messages and data according to their size. For control messages, it uses the method of buddy's relay while for data direct connections can be built with the help of the buddy. Using this mechanism, SMBR can achieve a balance between the traversal time and the buddies' load.	centralized computing;distributed hash table;experiment;nat traversal;network address translation;peer-to-peer;randomness;relay;scalability;self-organization;server (computing);tree traversal	Pinggai Yang;Jun Li;Jun Zhang;Hai Jiang;Yi Sun;Eryk Dutkiewicz	2010	The IEEE symposium on Computers and Communications	10.1109/ISCC.2010.5546719	communications protocol;digital library;self-organization;computer science;operating system;peer-to-peer;distributed computing;world wide web;transport layer;server;nat traversal;computer network	OS	-12.675502278229162	73.77680714836337	147693
9eed7f49dbda52db38b677fa4755deeef3187810	on the feasibility of 40 gbps network data capture and retention with general purpose hardware		New Ethernet standards, such as 40 GbE or 100 GbE, are already being deployed commercially along with their corresponding Network Interface Cards (NICs) for the servers. However, network measurement solutions are lagging behind: while there are several tools available for monitoring 10 or 20 Gbps networks, higher speeds pose a harder challenge that requires more new ideas, different from those applied previously, and so there are less applications available. In this paper, we show a system capable of capturing, timestamping and storing 40 Gbps network traffic using a tailored network driver together with Non-Volatile Memory express (NVMe) technology and the Storage Performance Development Kit (SPDK) framework. Also, we expose core ideas that can be extended for the capture at higher rates: a multicore architecture capable of synchronization with minimal overhead that reduces disordering of the received frames, methods to filter the traffic discarding unwanted frames without being computationally expensive, and the use of an intermediate buffer that allows simultaneous access from several applications to the same data and efficient disk writes. Finally, we show a testbed for a reliable benchmarking of our solution using custom DPDK traffic generators and replayers, which have been made freely available for the network measurement community.	analysis of algorithms;byte;call of duty: black ops;central processing unit;dpdk / dpdk.org;data rate units;file server;library (computing);multi-core processor;naruto shippuden: clash of ninja revolution 3;network interface;network interface controller;network packet;non-volatile memory;overhead (computing);parallel computing;rss;recursion;scalability;server (computing);synthetic intelligence;testbed;thread (computing);tracing (software);tweaking;volatile memory	Guillermo Julián-Moreno;Rafael Leira;Jorge E. López de Vergara;Francisco J. Gomez-Arribas;Ivan Gonzalez	2018		10.1145/3167132.3167238	embedded system;nvm express;network monitoring;timestamping;testbed;multi-core processor;ethernet;network interface;computer science;server	Networks	-7.151235396463286	64.93531775955604	147811
45d8dd8ff8e60b0212871cde0c422559161f859d	efficient state estimators for load control policies in scalable web server clusters	storage allocation;dns control;state estimators;centralized schedule;client requests state estimators load control policies scalable web server clusters information replication server cluster popular web sites domain name server centralized schedule address caching mechanisms non uniformity client domains load balancing issue scheduling algorithms distributed systems web server clusters theoretical dns policies system state information realistic situations state information dns policies load balancing dns control;resource allocation;information replication;load balancing issue;state information;realistic situations;popular web sites;state estimation;web server clusters;state estimation internet resource allocation scheduling network servers storage allocation;theoretical dns policies;server cluster;scalable web server clusters;dns policies;scheduling algorithm;network servers;scheduling algorithms;internet;client domains;settore ing inf 05 sistemi di elaborazione delle informazioni;address caching mechanisms;scheduling;load management;load balancing;state estimation load flow control web server world wide web electronic switching systems read only memory uniform resource locators service oriented architecture load management clustering algorithms;clustering algorithms;electronic switching systems;load flow control;world wide web;system state information;load balance;web server;information need;distributed systems;service oriented architecture;uniform resource locators;domain name server;read only memory;client requests;load control policies;non uniformity	Replication of information across a server cluster provides a promising way to support popular Web sites. However, a Web server cluster requires some mechanism for directing requests to the best server. One common approach is to use the Domain Name Server (DNS) as a centralized scheduler. However, address caching mechanisms and the non-uniformity of the load from different client domains complicate the load balancing issue and make existing scheduling algorithms for traditional distributed sys tems not applicable to Web server clusters. In this paper, we consider the theoretical DNS policies that require some system state information. We extend them to realistic situations where state information needs to be estimated with low computation and communication overhead. We show that, by incorporating these estimators into the DNS policies, load balancing improves substantially, even if the DNS control is limited to a small portion of client requests.	algorithm;centralized computing;circuit complexity;computation;computer cluster;control theory;function overloading;heuristic (computer science);information needs;load balancing (computing);overhead (computing);round-robin scheduling;scheduling (computing);server (computing);server farm;simulation;transistor–transistor logic;web server;world wide web	Valeria Cardellini;Michele Colajanni;Philip S. Yu	1998		10.1109/CMPSAC.1998.716694	network load balancing;round-robin dns;computer science;operating system;database;distributed computing;scheduling;world wide web;client–server model;server farm	OS	-18.33905583295669	69.90079186620845	147956
47c06511c3419f628edeabe65e2337fb6844747b	optimal path construction for fragmented file carving		Fragmented File carving is an important technique in Digital Forensics to recover files from their fragments in the absence of the file system allocation information. In this paper, the fragmented file carving problem is formulated as a graph theoretic problem. Using this model, we describe two algorithms, “Optimal Carve” and “Probabilistic-based Carve”, to perform file reconstruction and recovery. Optimal Carve is a deterministic technique to recover the best file construction path. We show that this technique is more efficient and accurate than existing brute force techniques. The Probabilistic-based Carve technique involves a trade-off between the final score of the constructed path of the file and the file recovery time to allow a faster recovery process for highly fragmented files.	algorithm;brute-force search;data recovery;theory	Hwei-Ming Ying;Vrizlynn L. L. Thing	2010			parallel computing;computer science;database;distributed computing;file system fragmentation	DB	-7.091202190245577	74.04964147421292	148018
afa61bcd58031dfe42414759855c4220f6bb0bfa	a hyper-heuristic approach for resource provisioning-based scheduling in grid environment	resource scheduling;heuristic methods;grid computing	Grid computing being immensely based on the concept of resource sharing has always been closely associated with a lot many challenges. Growth of Resource provisioning-based scheduling in large-scale distributed environments like Grid computing brings in new requirement challenges that are not being considered in traditional distributed computing environments. Resources being the backbone of the system, their efficient management plays quite an important role in its execution environment. Many constraints such as heterogeneity and dynamic nature of resources need to be taken care as steps toward managing Grid resources efficiently. The most important challenge in Grids being the job–resource mapping as per the users’ requirement in the most secure way. The mapping of the jobs to appropriate resources for execution of the applications in Grid computing is found to be an NP-complete problem. Novel algorithm is required to schedule the jobs on the resources to provide reduced execution time, increased security and reliability. The main aim of this paper is to present an efficient strategy for secure scheduling of jobs on appropriate resources. A novel particle swarm optimization-based hyper-heuristic resource scheduling algorithm has been designed and used to schedule jobs effectively on available resources without violating any of the security norms. Performance of the proposed algorithm has also been evaluated through the GridSim toolkit. We have compared our resource scheduling algorithm with existing common heuristic-based scheduling algorithms experimentally. The results thus obtained have shown a better performance by our algorithm than the existing algorithms, in terms of giving more reduced cost and makespan of user’s application being submitted to the Grids.	algorithm;distributed computing;experiment;grid computing;heuristic;hyper-heuristic;internet backbone;job stream;load balancing (computing);makespan;mathematical optimization;particle swarm optimization;provisioning;reduced cost;response time (technology);run time (program lifecycle phase);scheduling (computing);simulation	Rajni Aron;Inderveer Chana;Ajith Abraham	2014	The Journal of Supercomputing	10.1007/s11227-014-1373-9	fair-share scheduling;real-time computing;flow shop scheduling;dynamic priority scheduling;resource allocation;computer science;rate-monotonic scheduling;genetic algorithm scheduling;distributed computing;grid computing	HPC	-18.987212398942326	63.58984032911491	148360
d5317855daf6c91957275784cfc5715f34b61140	an enhanced workflow scheduling algorithm in cloud computing		Cloud Computing has gained high attention by provisioning resources and software as a service. Throughout the years, the number of users of clouds is increasing and thus will increase the number of tasks and load in the cloud. Therefore, scheduling tasks efficiently and dynamically is a critical problem to be solved. There are many scheduling algorithms that are used in cloud computing but most of them are concentrating on minimizing time and cost and some of them concentrate on increasing fault tolerance. However, very few scheduling algorithms that considers time, cost, and fault tolerance at the same time. Moreover, Considering pricing models in developing scheduling algorithms to provide cost-effective fault tolerant techniques is still in its infancy. Therefore, analysing the impact of the different pricing models on scheduling algorithm will lead to choosing the right pricing model that will not affect the cost. This paper proposes developing a scheduling algorithm that combines these features to provide an efficient mapping of tasks and improve Quality of Service (QoS).	algorithm;cloud computing;fault tolerance;job shop scheduling;makespan;provisioning;quality of service;scheduling (computing);software as a service	Nora Almezeini;Alaaeldin Hafez	2016		10.5220/0005908300670073	fair-share scheduling;distributed computing;workflow management system	HPC	-18.703213939577427	63.09150884493842	148391
517b473791bb51edebf216544e6d554e5a2a1ba9	scheduling algorithms (4. ed.)	scheduling algorithm		algorithm;schedule (project management);scheduling (computing)	Peter Brucker	2004			fair-share scheduling;fixed-priority pre-emptive scheduling;job shop scheduling;flow shop scheduling;rate-monotonic scheduling;deadline-monotonic scheduling	ML	-11.478256248669265	62.03963405721087	148451
4787757548722351608a7f74341a22e213d7b9c9	a hierarchical network storage architecture for video-on-demand services	storage management cable television multimedia communication interactive video probability;cable television;multimedia technologies;bandwidth network servers spine costs computer architecture computer networks information science cable tv multimedia systems probability distribution;residential customers;central service center;storage system;probability;interactive video;storage management;hierarchical networks;service providers;program reallocation algorithms;video on demand services;hierarchical network storage architecture;program viewing probability distribution function;program reallocation algorithms hierarchical network storage architecture video on demand services cable tv networks multimedia technologies content providers service providers network providers residential customers mass storage system storage management local service center local central service center central service center program viewing probability distribution function minimum cost function;cable tv networks;local service center;local central service center;video on demand;multimedia communication;content providers;proceedings paper;mass storage system;network providers;minimum cost function;network services	Recent advances in Cable TV networks and multimedia technologies open the possibilities for networWservicdcontent providers to ofer residential customers with video-on-demand services. However, the mass storage system in supporting such services demanh proper organization and management. In this paper we present a three-level hierarchical network storage architecture for the video-on-demand storage system. At the first-level (Local Service Center, LSC) a limited number of programs with high viewing probabilities are stored; while at the second-level (Local Central Service Center, LCSC) a few programs with second high viewing probabilities are stored. The third-level (Central Service Center, CSC) contains all programs provided in the system. Based on this architecture and the program viewing probability distribution function, we use a minimum-cost function to find out the numbers of programs stored in the two service centers (LSC and LCSC) and numbers of links among these three service centers. We also describe two program reallocation algorithms which swap programs between service centers according to the change in user request patterns.	algorithm;analysis of algorithms;computer data storage;elegant degradation;internet backbone;interrupt;linear function;loss function;mass storage;network topology;optimal design;paging;semi-continuity;streaming media;tree network;versant object database	Ying-Dar Lin;Horng-Zhu Lai;Yuan-Cheng Lai	1996		10.1109/LCN.1996.558164	service provider;simulation;differentiated service;computer science;operating system;probability;multimedia;television;statistics;computer network	Metrics	-15.231493841020356	72.3302857948218	148685
1afa1596c0092f5490ff5ca9edddc2fe252ec8d1	an efficient hybridization algorithm based task scheduling in cloud environment		The present paper describes a hybrid self-adaptive learning global search algorithm and firefly algorithm (HSLGSAFA)-based model for task scheduling in cloud computing. The proposed hybrid model combines gravitational search algorithm (GSA), which has been successfully scheduling the task in the application, with the use of SL strategy and the FA. The basic scheme of our approach is to utilize the benefits of both SLGSA algorithm and firefly algorithm and not including their disadvantages. In HSLGSAFA, each dimension of a solution represents a task and a solution as a whole signifies all tasks’ priorities. The vital issue is how to allocate users’ tasks to exploit the income of Infrastructure as a Service (IaaS) provider while promising Quality-of-Service (QoS). The generated solution is proficient to assure user-level QoS and improve IaaS providers’ credibility and economic benefit. The HSLGSAFA method also used to design the hybridization process and suitable fitness function of the corresponding task. ...	algorithm;scheduling (computing)	P. Neelima;A. Rama Mohan Reddy	2018	Journal of Circuits, Systems, and Computers	10.1142/S0218126618500184	quality of service;firefly algorithm;computer science;real-time computing;cloud computing;scheduling (computing);exploit;algorithm;search algorithm;distributed computing;fitness function	EDA	-18.74221383440414	63.807165088099374	148752
79e6dcb717a46c99abfd12c9a1350cefd284309a	a study of schemes for caching dynamically generated web pages	web pages;personal communication networks;assembly;html;navigation;web pages assembly personal communication networks html web server computer science delay markup languages navigation uniform resource locators;markup languages;web server;computer science;uniform resource locators	This paper discusses two schemes, CS-ESI and CSESI- F, for caching dynamically generated web pages. The schemes reduce the requests' response time by avoiding transmitting unnecessary data to users. In the schemes, web pages are partitioned into fragments of differing cacheability profiles and caching expiration time. The fragments are cached on users' PCs. A proxy runs on a user's PC to manage the cached fragments and to assemble the fragments into pages when needed.	cs-blast;cache (computing);computer simulation;dial-up internet access;dynamic web page;proxy server;response time (technology);transmitter	Xinfeng Ye;Qiang Liu	2006	The Sixth IEEE International Conference on Computer and Information Technology (CIT'06)	10.1109/CIT.2006.27	web service;navigation;static web page;web development;web modeling;html;computer science;operating system;dynamic web page;web page;database;assembly;multimedia;markup language;client-side scripting;world wide web;website parse template;rewrite engine;web server;computer network	DB	-18.87341057179302	71.68566485391408	149012
30e053c0de5887ed9b11d974b81638ef9b26ac81	a near-optimal memoryless online algorithm for fifo buffering two packet classes	online algorithm;buffer management;competitive analysis;packet scheduling	We consider scheduling packets with values in a capacity-bounded buffer in an online setting. In this model, there is a buffer with limited capacity B. At any time, the buffer cannot accommodate more than B packets. Packets arrive over time. Each packet has a non-negative value. Packets leave the buffer only because they are either sent or dropped. Those packets that have left the buffer will not be reconsidered for delivery any more. In each time step, at most one packet in the buffer can be sent. The order in which the packets are sent should comply with the order of their arrival time. The objective is to maximize the total value of the packets sent in an online manner. In this paper, we study a variant of this FIFO buffering model in which a packet's value is either 1 or @a>1. We present a deterministic memoryless 1.304-competitive algorithm. This algorithm has the same competitive ratio as the one presented in Lotker and Patt-Shamir [Z. Lotker, B. Patt-Shamir, Nearly optimal FIFO buffer management for DiffServ, in: Proceedings of the 21st Annual ACM Symposium on Principles of Distributed Computing, PODC, 2002, pp. 134-142; Z. Lotker, B. Patt-Shamir, Nearly optimal FIFO buffer management for DiffServ, Computer Networks 17 (1) (2003) 77-89]. However, our algorithm is simpler and does not employ any marking bits. The idea used in our algorithm is novel and different from all previous approaches that have been applied for the general model and its variants. We do not proactively preempt one packet when a new packet arrives. Instead, we may preempt more than one 1-value packet at the time when the buffer contains sufficiently many @a-value packets.	fifo (computing and electronics);network packet;online algorithm	Fei Li	2013	Theor. Comput. Sci.	10.1016/j.tcs.2011.11.039	competitive analysis;online algorithm;real-time computing;packet generator;computer science;distributed computing;packet loss;packet switch;circular buffer;computer network;out-of-order delivery	Theory	-4.844385219392473	71.84584140009926	149090
a6fe3187c51bf51f1e74020a9a8b926dc8fb38f7	thermal-aware task scheduling to minimize energy usage of blade server based datacenters	discretenonoptimal model;analogoptimal model;uniform task;blades costs thermal management processor scheduling computational modeling power system reliability cooling computational fluid dynamics scheduling algorithm energy consumption;task scheduling algorithms;thermal aware task scheduling;temperature distribution network servers scheduling;network servers;cfd simulation;energy consumption;scheduling;blade server based datacenter thermal management;uniform outlet profile;minimal computing energy;energy usage minimization;analogoptimal model thermal aware task scheduling energy usage minimization blade server based datacenter thermal management task scheduling algorithms uniform outlet profile minimal computing energy uniform task discretenonoptimal model discreteoptimal model analognonoptimal model;energy cost;analognonoptimal model;task scheduling;high performance;temperature distribution;thermal environment;discreteoptimal model	Blade severs are being increasingly deployed in modern datacenters due to their high performance/cost ratio and compact size. In this study, we document our work on blade server based datacenter thermal management. Our goal is to minimize the total energy costs (usage) of datacenter operation while providing a reasonable thermal environment for their reliable operation. Due to special characteristics of blade servers, we argue that previously proposed power-oriented schemes are ineffective for blade server-based datacenters and that task-oriented scheduling is a more practicable approach since the contribution to the total energy cost from cooling and computing systems varies according to the utilization rates. CFD simulations are used to evaluate scheduling results of three different task scheduling algorithms: uniform outlet profile (UOP), minimal computing energy (MCE), and uniform task (UT), under four different blade-server energy consumption models: discretenonoptimal (DNO), discreteoptimal (DO), analognonoptimal (ANO), and analogoptimal (AO). Simulation results show that the MCE algorithm, in most cases, results in a minimal total energy cost - a conclusion that differs from the findings of previous research. UOP performs better than UT at low datacenter utilization rates, whereas UT outperforms UOP at high utilization rates	algorithm;ambient occlusion;computer cooling;data center;linuxmce;nonlinear system;schedule (project management);scheduling (computing);server (computing);simulation;thermal management of high-power leds;tinymce;user operation prohibition	Qinghui Tang;Sandeep K. S. Gupta;Daniel C. Stanzione;Phil Cayton	2006	2006 2nd IEEE International Symposium on Dependable, Autonomic and Secure Computing	10.1109/DASC.2006.47	embedded system;real-time computing;simulation;computer science;operating system;scheduling	Arch	-18.99102108028078	61.70928282132405	149106
a91def80cda2c0bb54b682ff0759fae7f395e5f5	design and implementation of a video on-demand system	systeme temps reel;multimedia on demand;largeur bande;red numerica integracion servicios;haute performance;architecture systeme;delivery system;multimedia;video a peticion;concepcion sistema;implementation;data stream;real time;reseau ordinateur;video a la demande;satisfiability;qualite service;computer network;ejecucion;large scale;design and implementation;integrated services digital network;system design;video on demand;anchura banda;video server;red ordenador;alto rendimiento;quality of service qos;advanced technology;bandwidth;cost effectiveness;arquitectura sistema;real time system;load balance;sistema tiempo real;reseau numerique integration services;quality of service;system architecture;technologie avancee;high performance;conception systeme;service quality;tecnologia avanzada;calidad servicio;integrated services	Recent technological advances made multimedia on-demand servers feasible. Two challenging tasks in such systems are satisfying the real-time requirement for continuous delivery of objects at specified bandwidths and efficiently servicing multiple clients simultaneously. Our project is aimed at prototype development of such a large scale server. This paper jointly addresses the issues of load balancing, responsiveness, streaming capacity and cost effectiveness of high-performance storage servers and delivery systems for data streaming applications such as video-on-demand or news-on-demand. We propose a relatively simple, flexible and robust video-server architecture.  1998 Elsevier Science B.V. All rights reserved.	academy;active networking;continuous delivery;internet protocol suite;load balancing (computing);network packet;packet switching;prototype;real-time clock;responsiveness;router (computing);server (computing);startup weekend;video server	Miklós Berzsenyi;István Vajk;Hui Zhang	1998	Computer Networks	10.1016/S0169-7552(98)00166-4	embedded system;simulation;real-time operating system;cost-effectiveness analysis;quality of service;telecommunications;computer science;load balancing;integrated services digital network;integrated services;implementation;service quality;bandwidth;server;computer network;systems architecture;satisfiability;systems design	HPC	-12.617211420614504	70.10879517751833	149279
1be3cc0b6c1f68c99c8288a93535b82a1e1193db	the power of d choices for redundancy	redundancy;task assignment;power of d;dispatching	An increasingly prevalent technique for improving response time in queueing systems is the use of redundancy. In a system with redundant requests, each job that arrives to the system is copied and dispatched to multiple servers. As soon as the first copy completes service, the job is considered complete, and all remaining copies are deleted. A great deal of empirical work has demonstrated that redundancy can significantly reduce response time in systems ranging from Google's BigTable service to kidney transplant waitlists. We propose a theoretical model of redundancy, the Redundancy-d system, in which each job sends redundant copies to d servers chosen uniformly at random. We derive the first exact expressions for mean response time in Redundancy-d systems with any finite number of servers. We also find asymptotically exact expressions for the distribution of response time as the number of servers approaches infinity.	google bigtable;redundancy (engineering);response time (technology);theory	Kristen Gardner;Samuel Zbarsky;Mor Harchol-Balter;Alan Scheller-Wolf	2016		10.1145/2896377.2901497	triple modular redundancy;dual modular redundancy;real-time computing;redundancy;computer science;theoretical computer science;operating system;distributed computing;redundancy	Metrics	-15.06606916176649	65.80766080727759	149357
5451ef710d4021420ac3cde723c49ef4da55f1d3	message scheduling and timing analysis for flexray dynamic segment by considering slot-multiplexing	protocols;time factors vehicle dynamics delays protocols safety dynamic scheduling;time factors;safety;time division multiple access electronic messaging multiplexing protocols telecommunication scheduling;message scheduling analysis tdma approach bus bandwidth utilization flexray dynamic segment schedulability signal transmission electronic control unit automotive system message scheduling flexibility event triggered communication protocol time triggered communication protocol slot multiplexing message timing analysis;vehicle dynamics;delays;dynamic scheduling	FlexRay is a communication protocol that combines event- and time-triggered communication to increase the schedulability and flexibility of message scheduling in current car systems. Because safety and reliability are particularly crucial for automotive systems, the worst-case response times of signals transmitted by electronic control units must be under their deadlines. To increase the bandwidth utilization, the slotmultiplexing (SM) mechanism that is allowable in protocol specification was adopted to schedule messages offline in the dynamic segment of the FlexRay protocol, and this mechanism was also considered in the timing analysis. The proposed method was feasible to calculate worst-case response time of message under any bus load when considered slot-multiplexing. Then the approach was applied to a Society of Automotive Engineers benchmark to ensure that all messages were schedulable. The simulation results revealed that by using slot-multiplexing, only 17 identifiers were used, which was less than 23 identifiers that were needed when the slot-multiplexing was not considered. It also improved the schedulability of dynamic segment with up to 27% improvement in bus bandwidth utilization.	algorithm;benchmark (computing);best, worst and average case;communications protocol;flexray;identifier;online and offline;response time (technology);scheduling (computing);selective area epitaxy;simulation;static timing analysis;wavelength-division multiplexing	Zhan-Yao Gu;Yarsun Hsu;Chi-Ming Lee	2015	2015 IEEE International Conference on Vehicular Electronics and Safety (ICVES)	10.1109/ICVES.2015.7396893	embedded system;real-time computing;dynamic priority scheduling;computer science;computer network	Embedded	-7.913037858040932	63.14844674352274	149709
d8a38c54b055f4b37ea8f29fd80e3c258cc01731	file placement on distributed computer systems	databases;query processing;airports;distributed computing;computer networks;computer architecture;distributed computing system;financial advantage program;concurrency control;distributed computing distributed control computer architecture computer networks airports databases financial advantage program delay query processing concurrency control;distributed control	Advances in large-scale integrated logic and communication technology coupled with the applications explosion have led to distributed architectures. A distributed computer system is basically an interconnection of processing elements, each having certain capabilities, communicating with other elements through a network, and working on a set of related or unrelated jobs. DCS architecture is implemented in global systems such as Arpanet, local computer networks such as C,,*, and office information systems. One important DCS characteristic is localized information processing by a subset of the processing elements. A piece of information may be processed repeatedly within a local subsystem before it changes locality. For example, a seat assignment file in an airline reservation system is very heavily used first at the airport where passengers are preparing to board. Then, as the plane flies to another airport, the use locality changes. To maximize the efficiency of the system, the file should be distributed so that it is accessible at the locality of first use and should be allowed to migrate as the need changes. The distribution of DCS information is the distribution design problem. In general, information is partitioned into fragments (files) and placed in appropriate locations. In some systems, the files are uniquely defined, and no partitioning is necessary. But often databases must be partitioned horizontally, when the instances of an object are divided into fragments, or vertically when the attributes are divided into possibly overlapping fragments. After the fragments are partitioned, the FAP, or (optimal) file allocation problem, distributes files and fragments on a DCS to satisfy system objectives, such as availability, reliability, and delay constraints, and if the constraints and needs change dynamically, the files are allowed to migrate. The optimal file migration problem adjusts the file migration sequence to assure efficient adaptation to changing needs. Solutions to the distribution design problems depend on the operations performed on the information. In the simplest form, an operation is a file access from a specified origin. In a database distributed on a DCS, an operation or query may originate in a program located anywhere in the system. It may access multiple files assembled at a single node before it is processed, or the query and the intermediate results created in each step may be sent sequentially through the files. A combination of the two strategies is also possible. In addition, query processing is related to file placement, concurrency control, and communication network design, as shown in Figure 1, since files are partitioned and placed according to the network characteristics and query characteristics in the system. It is very difficult to solve these problems as whole units for real databases, so the designer usually decomposes them into independent problems. The FAP was originally isolated and investigated by Chu2 who studied it with respect to multiple files on a multiprocessor system. Current work lies in the integration of the query processing, file partitioning, concurrency control, and network design problems with the file placement problem. This article examines recent developments in these areas.	computer file;concurrency (computer science);concurrency control;database;distributed computing;face animation parameter;hardware description language;information processing;information system;interconnection;internationalization and localization;job stream;locality of reference;multiprocessing;network planning and design;telecommunications network	Benjamin W. Wah	1984	Computer	10.1109/MC.1984.1658928	distributed algorithm;concurrent computing;distributed data store;computer science;theoretical computer science;concurrency control;database;distributed computing;distributed system security architecture;distributed design patterns;non-lock concurrency control;serializability;replication;autonomic computing;distributed concurrency control	DB	-14.514783634180915	65.61997405283742	150151
5bb67328e288ffb86e083bc91c43aa1bf3c8371b	application scheduling and processor allocation in multiprogrammed parallel processing systems	workload;tratamiento paralelo;traitement parallele;multiprocessor;resource allocation;large scale;scheduling;charge travail;ordonamiento;asignacion recurso;multiprocesador;allocation ressource;carga trabajo;parallel processing;ordonnancement;multiprocesseur	When large-scale multiprocessors for parallel processing are subjected to heavy diverse workloads of applications, it will be necessary to schedule them in a multiprogrammed fashion in order to use the system resources effectively and keep response times low. Information about the characteristics of individual applications can be used to achieve effective scheduling. We identify some useful parameters for characterizing applications. Prior work on multiprocessor scheduling and examination of several simplified special cases reveal some guiding principles for scheduling. The synthesis of full scheduling algorithms based on the principles is explored. We address directly the case of scheduling a batch of applications with deterministically known characteristics, but we also consider extensions to handle uncertainty in service times, priorities, and an arrival stream of applications.	algorithm;effective dimension;multiprocessing;multiprocessor scheduling;parallel computing;parallel processing (dsp implementation);scheduling (computing)	Kenneth C. Sevcik	1994	Perform. Eval.	10.1016/0166-5316(94)90036-1	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel processing;parallel computing;real-time computing;earliest deadline first scheduling;multiprocessing;flow shop scheduling;dynamic priority scheduling;resource allocation;computer science;rate-monotonic scheduling;operating system;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;scheduling;lottery scheduling;round-robin scheduling;scheduling;multiprocessor scheduling	Metrics	-12.123147357675675	60.98995151786023	150769
6cf0ef7211ff05bf794059e829e26541204b8735	dacia: a mobile component framework for buildinh adaptive distributed applications	distributed application;reconfiguration;tratamiento datos;distributed system;metodo adaptativo;largeur bande;arquitectura red;reconfiguracion;reseau communication;systeme reparti;jini multicasting;red www;data compression;data stream;flot donnee;resource management;data processing;traitement donnee;methode adaptative;flujo datos;architecture reseau;graph connectivity;sistema repartido;run time reconfigurable;network connectivity;component framework;conexion;distributed heterogeneous systems;adaptive method;anchura banda;raccordement;conectividad grafo;communication cost;bandwidth;world wide web;arquitectura modular;network architecture;reseau www;compresion dato;data flow;connected component;connectivite graphe;red de comunicacion;modular architecture;connection;communication network;compression donnee;architecture modulaire;tunneling	Future distributed applications will need to support computing devices with a wide range of capabilities, varying network connectivity, increasing mobility of users, and a wide variation in load placed by clients on services. This paper presents DACIA, a framework for building adaptive distributed applications. In DACIA, distributed applications are viewed as consisting of connected components that typically implement data streaming, processing, and filtering functions. DACIA provides mechanisms for run-time reconfiguration of applications to allow them to adapt to the changing operating environments. Components can be moved to different hosts during execution, while maintaining communication connectivity with other components. New components can also be introduced along data paths, for example, to provide compression on low-bandwidth connections. Keeping communication overheads low is a significant challenge in designing component-based services. DACIA is designed so that communication costs among co-located components are similar to those of procedure calls. Performance results, as well as examples of adaptive services that can be built using DACIA are presented.	component-based software engineering;connected component (graph theory);distributed computing	Radu Litiu;Atul Prakash	2001	Operating Systems Review	10.1145/377069.377079	data compression;data flow diagram;real-time computing;network architecture;connected component;data processing;telecommunications;connection;computer science;connectivity;control reconfiguration;resource management;operating system;distributed computing;quantum tunnelling;bandwidth;telecommunications network	HPC	-11.783456289611859	69.18751568552061	151149
11dd049f6a0a4f5fbd42aa45ca1a6ad8b0615a1f	group: dual-overlay state management for p2p nve	state management networked virtual environments peer to peer systems distributed hash tables voronoi diagram interest management data distribution;distributed hash table;interest management;peer to peer systems;computational geometry;p2p;group membership management;peer to peer system;data distribution;peer to peer computing avatars computational geometry;computer architecture;group membership management dual overlay state management peer to peer networked virtual environment fully distributed peer to peer architecture avatar management object state management voronoi based overlay;servers;logic gates;peer to peer networked virtual environment;avatars;avatars computer architecture network servers virtual environment scalability computer network management conference management environmental management engineering management computer science;object state management;ip networks;group membership;scalability;peer to peer computing;distributed hash tables;peer to peer;networked virtual environment;avatar management;state management;dual overlay state management;fully distributed peer to peer architecture;voronoi diagram;networked virtual environments;distributed management;voronoi based overlay	Peer-to-peer (P2P) architectures have recently become a popular design choice to build scalable Networked Virtual Environments (NVEs). While P2P architectures offer better scalability than server-based architectures, efficient distribution and management of avatar and object states remains a highly challenging issue. In this paper, we propose GROUP, a fully-distributed P2P architecture for NVEs that addresses this issue by combining a structured P2P overlay, used for object state management, with a Voronoi-based overlay, used for avatar state and group membership management. The resulting dual overlay architecture enables efficient and fully distributed management of state updates for P2P-based NVEs.	algorithm;avatar (computing);avatar: the last airbender;cluster analysis;function overloading;peer-to-peer;scalability;server (computing);simulation;state management;virtual reality	Eliya Buyukkaya;Maha Abdallah;Romain Cavagna;Shun-Yun Hu	2008	2008 14th IEEE International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2008.122	scalability;voronoi diagram;logic gate;computational geometry;computer science;chord;peer-to-peer;database;distributed computing;world wide web;server;computer network	HPC	-14.484832346488734	73.06260167755664	151579
19a2693c2f8e8ce56eefb16e6df8440b42d3ad62	measurement of response time performance in small time-sharing systems			responsiveness;time-sharing	John P. Penny;C. R. Sheedy	1980	Australian Computer Journal		computer science;time-sharing;real-time computing;response time	OS	-11.577136790737027	62.71243932064935	152126
59566125e6f8d7c48b8b0b44f4ad969cac95d6dd	optimizing distributed real-time embedded system handling dependence and several strict periodicity constraints		This paper focuses on real-time nonpreemptive multiprocessor scheduling with precedence and strict periodicity constraints. Since this problem is NP-hard, there exist several approaches to resolve it. In addition, because of periodicity constraints our problem stands for a decision problem which consists in determining if, a solution exists or not. Therefore, the first criterion on which the proposed heuristic is evaluated is its schedulability. Then, the second criterion on which the proposed heuristic is evaluated is its execution time. Hence, we performed a schedulability analysis which leads to a necessary and sufficient schedulability condition for determining whether a task satisfies its precedence and periodicity constraints on a processor where others tasks have already been scheduled. We also present two multiperiodic applications.	aaa (video game industry);algorithm;central processing unit;decision problem;descendant tree (group theory);embedded system;existential quantification;feedback;heuristic (computer science);load balancing (computing);multiprocessing;multiprocessor scheduling;np-hardness;optimizing compiler;quasiperiodicity;real-time clock;run time (program lifecycle phase);scheduling (computing);scheduling analysis real-time systems	Omar Kermia	2011	Adv. Operations Research	10.1155/2011/561794	mathematical optimization;real-time computing;mathematics;distributed computing	Embedded	-10.424588385921448	61.321723506005604	152203
72900e95ef5a8b2c2638563922d71b2bbd3e0437	capacity planning and scheduling in grid computing environments	grid scheduling;queueing;scientific application;optimisation;capacity planning;heterogeneous systems;grid applications;grid computing environment;resource allocation;performance;advance reservations;satisfiability;large scale;distributed environment;scheduling;batch process;resource broker;cost effectiveness;profitability;brokering;advance reservation;quality of service;grid computing	Grid computing infrastructures embody a cost-effective computing paradigm that virtualises heterogeneous system resources to meet the dynamic needs of critical business and scientific applications. These applications range from batch processes and long-running tasks to realtime and even transactional applications. Grid computing environments are inherently dynamic and unpredictable environments sharing services amongst many different users. Grid schedulers aim to make the most efficient use of Grid resources (high utilisation) while providing the best possible performance to the Grid applications (reducing makespan) and satisfying the associated performance and Quality of Service (QoS) constraints. Additionally, in commercial Grid settings where economic considerations are an increasingly important part of Grid scheduling, it is necessary to minimise the cost of application execution on the behalf of the Grid users while ensuring that the applications meet their QoS constraints. Furthermore, efficient resource allocation may allow a resource broker to maximise their profit by minimising the quantity of resource procurement. Scheduling in such a large-scale, dynamic and distributed environment is a complex undertaking. In this paper, we propose an approach to Grid scheduling which abstracts over the details of individual applications, focusing instead on the global cost optimisation problem while taking into account the entire workload, dynamically adjusting to the varying service demands. Our model places particular emphasis on the stochastic and unpredictable nature of the Grid, leading to a more accurate reflection of the state of the Grid and hence more efficient and accurate scheduling decisions. c © 2007 Elsevier B.V. All rights reserved.	algorithm;approximation;automated planning and scheduling;e-science;end-to-end principle;grid computing;integer programming;makespan;mathematical optimization;nonlinear system;performance prediction;procurement;programming model;programming paradigm;quality of service;queueing theory;real-time computing;routing;scheduling (computing);seasonality;stochastic process	Ali Afzal;A. Stephen McGough;John Darlington	2008	Future Generation Comp. Syst.	10.1016/j.future.2007.07.004	real-time computing;cost-effectiveness analysis;quality of service;performance;resource allocation;computer science;operating system;data grid;distributed computing;queueing theory;scheduling;grid computing;profitability index;distributed computing environment;batch processing;satisfiability	HPC	-18.310659333290722	64.46073831112116	152251
bc0925aeab7d87f183b8efd232eb7c066ab6e569	treating uncertainty in distributed scheduling	bayesian theory;distributed system;fuzzy set;utility function;distributed scheduling;distributed real time system	In distributed systems the scheduler of an overloaded node may choose to transfer the execution of one or more tasks to other less busy nodes, in order to minimize their expected service times, or to increase the number of tasks that meet their deadlines, among other criteria. One solution makes use of Bayesian theory to infer the load state of the system and, based on this information, the scheduler of a busy node chooses an “appropriate” node to transfer a task too. The meaning of “appropriate” will be a function of the objectives established in the adopted location policy. In the Bayesian decision method, objectives are represented by a utility function. However, the development of a utility function can be a tricky and somewhat subjective task. In this paper, we describe a new approach that easily maps transfer objectives into useful mathematical expressions, representing location policy objectives by fuzzy sets. The proposed approach was successfully employed to add objectives to a Bayesian decision-based algorithm improving the number of tasks that are executed over time in a distributed real-time system.	scheduling (computing)	André M. Barroso;Julius C. B. Leite;Orlando Loques	2002	Journal of Systems and Software	10.1016/S0164-1212(01)00117-0	real-time computing;bayesian probability;computer science;operating system;distributed computing;fuzzy set	Robotics	-13.931067809432335	63.592574798566766	152335
d5b12c1d6a212c8e4489419340969603c6b2f4d9	an effective framework of light-weight handling for three-level fine-grained recoverable temporal violations in scientific workflows	quality of service middleware natural sciences computing optimisation probability;optimisation;ant colony optimisation;probability;processor scheduling;scientific workflow;light weight exception handling strategy;swinburne;workflow qos;scientific workflows temporal violations exception handling workflow scheduling workflow qos;workflow local rescheduling;workflow local rescheduling light weight handling fine grained recoverable temporal violation scientific workflow qos probability based temporal consistency light weight exception handling strategy tda time deficit allocation acowr ant colony optimisation;scientific workflows;qos;consistency model;tda;redundancy;fine grained recoverable temporal violation;acowr;workflow scheduling;cost effectiveness;artificial intelligence;middleware;exception handling;optimization;time deficit allocation;temporal violations;light weight handling;quality of service;probability based temporal consistency;natural sciences computing;quality of service redundancy optimization artificial intelligence gaussian distribution processor scheduling;gaussian distribution	Temporal violations may often take place and deteriorate the overall QoS of scientific workflows. To handle temporal violations in an automatic and cost-effective fashion, we need to resolve the following issues: 1) how to define fine-grained recoverable temporal violations, 2) which light-weight effective exception handling strategies to be facilitated. This paper proposes an effective exception handling framework. Based on a probability based temporal consistency model, the probability range for recoverable temporal violations is divided into three levels of fine-grained temporal violations. Afterwards, three corresponding light-weight exception handling strategies including TDA (Time Deficit Allocation), ACOWR (Ant Colony Optimisation based two-stage Workflow local Rescheduling) and TDA+ACOWR (the combined strategy of TDA and ACOWR) are presented. The experimental results demonstrate the excellent performance of our framework in reducing both local and global temporal violations.	ant colony optimization algorithms;consistency model;exception handling;mathematical optimization;quality of service;schedule (computer science);topological data analysis	Xiao Qiao Liu;Zhiwei Ni;Zhangjun Wu;Dong Yuan;Jinjun Chen;Yun Yang	2010	2010 IEEE 16th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2010.8	parallel computing;real-time computing;quality of service;computer science;operating system;database;distributed computing;statistics	SE	-17.124783852353147	62.180761158304385	152710
22684639f6d60c31bb4c040a9e6efea8ea294a8b	paging with multiple caches	servers stochastic processes algorithm design and analysis load modeling content distribution networks electronic mail routing;stochastic process caches content delivery networks back end servers front end servers single cache paging multiple cache paging;stochastic processes cache storage paged storage	"""Modern content delivery networks consist of one or more """"back-end"""" servers which store the entire content catalog, assisted by multiple """"front-end"""" servers with limited storage and service capacities located near the end-users. Appropriate replication of content on the front-end servers is key to maximize the fraction of requests served by the front-end servers. Motivated by this, a multiple cache variant of the classical single cache paging problem is studied, which is referred to as the Multiple Cache Paging (MCP) problem. In each time-slot, a batch of content requests arrive that have to be served by a bank of caches, and each cache can serve exactly one request. If a content is not found in the bank, it is fetched from the back-end server, and one currently stored content is ejected, and counted as `fault'. As in the classical paging problem, the goal is to minimize the total number of faults. The competitive ratio of any online algorithm for the MCP problem is shown to be unbounded for arbitrary input, thus concluding that the MCP problem is fundamentally different from the classical paging problem. Consequently, stochastic arrivals setting is considered, where requests arrive according to a known/unknown stochastic process. It is shown that near optimal performance can be achieved with simple policies that require no co-ordination across the caches."""	competitive analysis (online algorithm);content delivery network;http 404;online algorithm;page replacement algorithm;paging;replication (computing);server (computing);stochastic process	Rahul Vaze;Sharayu Moharir	2016	2016 14th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt)	10.1109/WIOPT.2016.7492953	parallel computing;real-time computing;page cache;cache;computer science;distributed computing;cache algorithms	Theory	-14.034108480066097	65.96232809733175	152856
9cf8a6a0f81d42b5fdc43388729760531f6212a0	transparent distributed web caching with minimum expected response time	layer 5 switch;network servers transport protocols cache storage distributed memory systems internet quality of service;cache storage;distributed caching;distributed memory systems;cooperative caching;web and internet services;information technology;traffic control;web service;transparent web caching;transport protocols;minimum expected response time;simulation experiment;telecommunication traffic;network servers;internet;network latency transparent web caching distributed web caching minimum expected response time quality of service distributed caching cache servers layer 5 switch http requests server workload;http requests;delay web server network servers switches web services telecommunication traffic traffic control cooperative caching web and internet services information technology;web services;distributed web caching;web server;quality of service;switches;network latency;cache servers;web caching;server workload	Web caching is a standard approach to improving the performance and quality of Web services. The effectiveness of a single cache in this environment, however, is relatively low. Caches hit rates of 40% or lower are typical in the Web. Distributed caching seeks to improve the effectiveness of Web caching by supporting the sharing of data across multiple cache servers. In this paper we describe the Minimum expected Response Time (MRT) distributed Web caching scheme. MRT uses a Layer 5 switch to transparently redirect cacheable HTTP requests to the cache server with the minimum expected response time. The response time estimate is produced based on information about cache server content, cache server workload, Web server workload and network latency. We present simulation experiments to show that MRT outperforms existing distributed Web caching schemes in terms of average HTTP request response times.	cpu cache;distributed cache;experiment;response time (technology);server (computing);simulation;web cache;web server;web service;world wide web	Qing Zou;Patrick Martin;Hossam S. Hassanein	2003		10.1109/PCCC.2003.1203721	web service;cache stampede;false sharing;cache;computer science;cache invalidation;database;smart cache;cache algorithms;information technology;world wide web;computer network	Web+IR	-17.954940561671762	70.25180639670988	152870
73d8341a63cb0709d748c63e11c5bca043596f00	a time optimization algorithm for scheduling bag-of-task applications in auction-based proportional share systems	auction based resource allocation system time optimization algorithm bag of task application auction based proportional share system grid network peer to peer network distributed resources;resource allocation;scheduling task analysis resource allocation;large scale;bag of tasks;scheduling;task analysis;scheduling algorithm application software resource management peer to peer computing processor scheduling grid computing computer applications large scale systems computer networks distributed computing;timing optimization;resource sharing;p2p networks;peer to peer	Grid and peer-to-peer (P2P) network technologies enable aggregation of distributed resources for solving large-scale and computationally-intensive applications. These technologies are well-suited for bag-of-tasks (BoT) applications, because each application consists of many parallel and independent tasks. With multiple users competing for the same resources, the key challenge is to finish a user application within a specified deadline. In this paper, we propose a time optimization algorithm that schedules a user application on auction-based resource allocation systems. These allocation systems, which are based on proportional share, allow users to bid higher in order to gain more resource shares. Therefore, this algorithm adjusts a user bid periodically on these systems in order to finish the application on time.	algorithm;application domain;euro-vo;global serializability;mathematical optimization;multi-user;peer-to-peer;preemption (computing);scheduling (computing);virtual organization (grid computing)	Anthony Sulistio;Rajkumar Buyya	2005	17th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD'05)	10.1109/CAHPC.2005.9	fair-share scheduling;shared resource;auction algorithm;real-time computing;resource allocation;computer science;operating system;task analysis;database;distributed computing;resource allocation;scheduling	HPC	-17.584782097747624	64.55598431648342	153075
cd2112f3d4a8a30db562deba443d78cc3a8841f1	a parallel bee colony algorithm for resource allocation application in cloud computing environment	parallel computing;sorting;resource allocation;multi objective;resource management;servers;energy consumption;bee colony algorithm;optimization;sociology;cloud computing	Cloud computing has been widely used in every social field. The problem of energy consumption in a cloud computing environment has brought cost pressure to service providers and affected the natural environment. However, the reasonable and efficient scheduling of resources could save a lot of energy for cluster. Meanwhile, it's necessary for us to take into account of the emergent needs of every consumer. So the resource scheduling is often regarded as a multi-objective problem with the optimization of energy consumption and time cost. We redefine the problem in this paper and set up a multi-objective optimization model, and the parallel computing is improved on the basis of bee colony algorithm. Furthermore, multi-objective problem optimization based on fast non-dominated sorting method is used in parallel environment. Experimental results show that the proposed algorithm can save energy, reduce the execution time of tasks and have very good stability in parallel environment.	algorithm;cloud computing;crowding;definition;distribution (mathematics);emergence;genetic algorithm scheduling;information privacy;mathematical model;mathematical optimization;multi-objective optimization;np-hardness;parallel algorithm;parallel computing;pareto efficiency;run time (program lifecycle phase);scheduling (computing);sorting	Tingxi Wen;Zhongnan Zhang;Meihong Wang	2015	2015 IEEE International Conference on Data Science and Data Intensive Systems	10.1109/DSDIS.2015.36	simulation;computer science;operations management;distributed computing	HPC	-18.828825991761025	63.47901807880175	153094
efeaaab50eab3dd04147b13ca31c41b5e2a90055	migrating big video data to cloud: a peer-assisted approach for vod	cloud computing video;content distribution;peer-assistance	Since user demand for a Video-on-demand (VoD) service varies with time in one-day period, provisioning self-owned servers for the peak load it must sustain afew hours per day leads to bandwidth under-utilization at other times. Content clouds, e.g. Amazon CloudFront and Azure CDN, let VoD providers pay by bytes for bandwidth resources, potentially leading to cost savings even if the unit rate to rent a machine from a cloud provider is higher than the rate to own one. In addition, recent studies have presented fog computing as a new paradigm to extend the cloud-based platform for a cost-effective and highly scalable service. In this paper, based on long-term traces from two large-scale VoD systems and temporal development model of content clouds, we tackle challenges, design and potential benefits in migrating both Clients/Server-based and peer-assisted VoD services into the hybrid cloud and edge peers in fog computing environment. Our measurements show that the popularity of the most popular videos decays so quickly, for example, by 11% after one hour that it poses large challenges on updating videos in the cloud. However, the trace-driven evaluations show that our proposed migration strategies (active, reactive and smart strategies), although simply based on the current information, can make the hybrid cloud-assisted VoD deployment save up to 30% bandwidth expense compared with the Clients/Server mode. Moreover, they can also handle the flash crowd traffic with little cost. Leveraging the edge peers in fog computing, we propose a cloud-friendly peer replication strategy, which further reduces the migration cost by a factor of 4. Our simulation also shows that the cloud price and server bandwidth chosen play the most important roles in saving cost, while the cloud storage size and cloud content update strategy play the key roles in the user experience improvement.		Fei Chen;Haitao Li;Jiangchuan Liu;Bo Li;Ke Xu;Yuemin Hu	2018	Peer-to-Peer Networking and Applications	10.1007/s12083-017-0575-3	software deployment;computer network;user experience design;scalability;cloud computing;byte;computer science;server;provisioning	Metrics	-18.338501022249364	73.89901398937272	153113
4fdcde6e7e54e1f1e3652cff4b60c6354cf03027	a cost efficient scheduling strategy to guarantee probabilistic workflow deadlines	workflow management software parallel processing probability scheduling search problems;schedules time factors processor scheduling dynamic scheduling optimal scheduling simulated annealing;execution cost reduction scheduling strategy probabilistic workflow deadlines business process modeling heterogeneous distributed system large scale distributed system response time search space parallel service invocation sequential service invocation workflow execution	Today, workflows are widely used to model business processes. A recent trend is to use them to model applications in heterogeneous, large-scale distributed systems. In such systems, many, possibly mobile, providers offer independent and interchangeable services that can be used to satisfy the different activities of a workflow. Due to varying server loads, failures, and changing network characteristics, the response time of these services is highly volatile. Thus, it is hard to ensure the timely and reliable execution of workflows depending on such services. A common approach is to invoke several services in parallel to increase the probability of success. This, however, can easily lead to overprovisioning and high cost when needlessly invoked services have to be compensated. In this paper, we investigate the search space between parallel and sequential invocation of services. We propose to invoke independent services staggered over time to ensure timely workflow execution at minimal cost. Evaluations show that our approach reduces the execution cost by up to 85% while it guarantees to fulfill activity deadlines with 99.9 % probability.	business process;cost efficiency;distributed computing;pin grid array;response time (technology);scheduling (computing);server (computing);volatile memory	Thomas Bach;Muhammad Adnan Tariq;Boris Koldehofe;Kurt Rothermel	2015	2015 International Conference and Workshops on Networked Systems (NetSys)	10.1109/NetSys.2015.7089072	real-time computing;dynamic priority scheduling;computer science;database;distributed computing;workflow management system;workflow engine;workflow technology	DB	-18.764464292009734	61.02172455246421	153128
195f6186ec186b6fac02db2a83a354d29f34c303	performance investigation of an on-line auction system	electronic commerce;perforation;stochastic process algebra;load balancing;agent systems;active networks	The standard design of on-line auction systems places most of the computational load on the server and its adjacent links, resulting in a bottleneck in the system. In this paper, we investigate the impact, in terms of the performance of the server and its adjacent links, of introducing active nodes into the network. The performance study of the system is done using the stochastic process algebra formalism PEPA.	cpu cache;computation;formal grammar;formal system;online and offline;pepa;process calculus;server (computing);stochastic process;throughput	Jane Hillston;Leïla Kloul	2001	Concurrency and Computation: Practice and Experience	10.1002/cpe.546	e-commerce;active networking;parallel computing;simulation;computer science;load balancing;operating system;database;distributed computing;computer security	Metrics	-11.717341635813575	66.95298249707878	153248
fa335aa2e7ce949f80e9777c9dcbcca749f5b6a2	topnet: a network-aware top(1)	network monitoring;user interface;real time;traffic flow;design and implementation;network traffic;traffic monitoring	System administrators regularly use the top utility for understanding the resource consumption of the processes running on UNIX computers. Top provides an accurate and real-time display of the computing and memory capacity of the system among the running processes, but it provides no information about the network traffic sent and received by the processes running on the system. Although we’ve seen a proliferation of network monitoring tools that help system administrators understand the traffic flowing through their networks, most of these tools have been designed for network deployment and can not easily, if at all, provide real-time attribution of network resources to individual processes running on end hosts. In this paper, we describe the design and implementation of Topnet, an extension of the top UNIX utility that provides a process-centric approach to traffic monitoring. Topnet presents users with an intuitive real-time attribution of network resources to individual processes. Our evaluation suggests that Topnet through (i) the familiar user interface of top and (ii) a reasonable performance overhead, provides an accurate way to attribute network traffic to individual processes, enabling users to have a more comprehensive process-aware understanding of network resource consumption in their systems.	computer;network traffic control;overhead (computing);real-time clock;software deployment;system administrator;unix;user interface	Antonis Theocharides;Demetres Antoniades;Michalis Polychronakis;Elias Athanasopoulos;Evangelos P. Markatos	2008			network traffic control;real-time computing;simulation;computer science;traffic flow;distributed computing;user interface;network monitoring	OS	-18.348358492025152	72.60028229318716	153272
a39dab3d28256a9f0827e84465e349dacc73488f	a dynamic sliding load balancing strategy in distributed syatems	load balance	A sliding strategy for load balancing is introduced. The strategy groups a certain number of adjacent nodes to perform a load balancing process. Upon the completion of a given period, the groups are to be rotated by shifting each group one position to the right, thus produces different groups. This strategy (sort of clustering) not only reduces the load balancing overheads, but also it could be utilized as a backbone by any load balancing strategy. The proposed load balancing strategy always converges, and tends to be in a steady state in a negligible processing time. In this paper, the load status and the locations of the nodes regarding the system’s topology are irrelevant to load balancing process. The new algorithm can be always applied to any distributed system, even if it is heavily loaded, since the cost of scheduling is very low due to the highly reduced number of messages. This is achieved by reducing dramatically the overheads incurred from attached information tables, message passing, job thrashing, and response time.	algorithm;cluster analysis;computation;distributed computing;internet backbone;load balancing (computing);message passing;numerical analysis;overhead (computing);relevance;response time (technology);scalability;scheduling (computing);steady state;thrashing (computer science);xslt/muenchian grouping	Ahmad Dalal'ah	2006	Int. Arab J. Inf. Technol.		artificial intelligence;machine learning;computer science;control engineering;load balancing (computing)	HPC	-8.955005181127063	70.05157996767097	153278
cd1e0d9ea9603a0d3f092544b82414322fe9e015	a context-aware cache structure for mobile computing environments	context aware;caching;prefetching;mobile computer;system performance;movement pattern;context aware information service;location awareness;information service;mobile computing;cache management;mobile terminal;mobile user	This paper proposes a cache management method that maintains a mobile terminal’s cache content by prefetching data items with maximum benefit and evicting cache data entries with minimum benefit. The data item benefit is evaluated based on the user’s query context which is defined as a set of constraints (predicates) that define both the movement pattern and the information context requested by the mobile user. A context-aware cache is formed and maintained using a set of neighboring locations (called the prime list) that are restricted by the validity of the data fetched from the server. Simulation results show that the proposed strategy, using different levels of granularity, can greatly improve system performance in terms of the cache hit ratio. Published by Elsevier Inc.	affinity analysis;cpu cache;cache (computing);cell (microprocessor);data item;emoticon;hit (internet);ibm notes;mobile computing;mobile phone;phong shading;programming paradigm;server (computing);shortest path problem;simulation;user profile	Stylianos Drakatos;Niki Pissinou;Kia Makki;Christos Douligeris	2007	Journal of Systems and Software	10.1016/j.jss.2006.10.027	real-time computing;mobile search;cache coloring;page cache;cache;mobile database;computer science;write-once;cache invalidation;operating system;database;smart cache;mobile computing;cache algorithms;cache pollution;world wide web	DB	-15.243960962371835	68.65913346641558	153540
35b01d316c07de0265b603ae22a500828fbe65dc	acs: an effective admission control scheme with deadlock resolutions for workflow scheduling in clouds	storage resource constraint;deadlock resolution;workflow scheduling;admission control;68m20	The Cloud with its abundant on-demand processor, storage, and bandwidth capacities and the elastic billing models has been emerging as a promising platform to scientific workflow computations. However, in reality, due to ineffective use of or practical constraints on the provisioned resources, the best-effort model to allocate as many as possible resources from Clouds is not always cost effective or feasible for cloud users to compute their workflow applications. To address this problem, in this paper, we study the effective use of a virtual cluster with a shared finite storage system to improve the performance of the workflow scheduling. Since the concurrent executions of multiple concurrent instances of the workflow are subject to the storage capacity constraints, deadlock resolution is our major concern in the performance optimization. To this end, we propose an effective admission control scheme (ACS) that integrates a set of deadlock resolution algorithms to admit workflow instances to the system based on the available storage capacities. With ACS, we can reduce the competitiveness on the finite storage and minimize the adverse impact of deadlock as well. We show the benefits of ACS via intensive simulation studies on the performance changes of a set of selected benchmark workflows. Our results demonstrate that the proposed ACS is a cost-effective way to fully utilize the provisioned storage resources for workflow scheduling in cloud virtual clusters.	algorithm;benchmark (computing);best-effort delivery;cloud computing;computation;computer data storage;data transfer object;deadlock;electronic billing;mathematical optimization;performance tuning;scheduling (computing);simulation	Yang Wang;Menglan Hu;Kenneth B. Kent	2014	Computing	10.1007/s00607-014-0409-6	real-time computing;computer science;database;distributed computing;workflow management system;deadlock prevention algorithms	HPC	-18.822759290074153	62.437602635696344	153559
df5a4934ddd836ec9c34d0e6214a2ad89063f014	efficient load balancing in large-scale systems	server driven manner load balancing large scale systems n identical parallel server pools poisson process exponential distribution;servers;stochastic processes large scale systems resource allocation	We consider a system of N identical parallel server pools and a single dispatcher where tasks arrive as a Poisson process. Arriving tasks cannot be queued, and must immediately be assigned to one of the server pools to start execution. The execution times are assumed to be exponentially distributed, and do not depend on the number of tasks contending for service. However, the experienced performance (e.g. in terms of received throughput or packet-level delay) does degrade with an increasing number of concurrent tasks at the same server pool. In order to optimize the performance, the dispatcher therefore aims to evenly distribute the tasks across the various server pools, using either a power-of-d or a threshold-based load balancing scheme. In the power-of-d scheme, an arriving task is assigned to the server pool with the minimum number of active tasks among d(N) randomly selected server pools (1 ≤ d(N) ≤ N). In the threshold-based scheme, an incoming task is dispatched to an arbitrary server pool with fewer than L active tasks, if there is any, to an arbitrary server pool with fewer than H > L tasks otherwise, or to a randomly selected server pool if all server pools have H or more tasks. This scheme can be implemented in a server-driven manner, with O(1) communication overhead per task, as opposed to O(d(N)) in the power-of-d scheme. We derive the fluid-level dynamics for the power-of-d scheme with d(N) → ∞ as N → ∞ and the threshold-based scheme, along with the associated fixed points. As it turns out, the fluid limit for the power-of-d scheme does not depend on the exact growth rate of d(N). We also characterize the diffusion-level behavior of the power-of-d scheme with d(N) ≫ √N log(N), and show that it coincides with that of the threshold-based scheme with suitably selected parameters L and H. In particular, the threshold-based scheme can achieve similar performance as the power-of-d scheme with d(N) ≫ √N log(N), and thus diffusion-level optimality, with only O(1) rather than O(N) communication overhead per task.	client–server model;fixed point (mathematics);load balancing (computing);network packet;overhead (computing);randomness;server (computing);throughput	Debankur Mukherjee;Sem C. Borst;Johan van Leeuwaarden;Philip A. Whiting	2016	2016 Annual Conference on Information Science and Systems (CISS)	10.1109/CISS.2016.7460533	real-time computing;computer science;theoretical computer science;distributed computing;server	Metrics	-13.850208983537039	65.15424725926428	153614
2a6c07c0f1507cd96ea9bf6834edabc2a7502ed0	packet classification using adaptive rules cutting (arc)	routing protocols;random access memory;packet classification;routing;web and internet services;degree of freedom;information technology;arc;routing protocols packet switching;packet switching;multi dimensional;optimum rule cutting advanced packet classification algorithm adaptive rules cutting arc rule reduction;quality of service routing hardware random access memory classification algorithms web and internet services information technology space technology hypercubes tv;rule reduction;classification algorithms;hypercubes;advanced packet classification algorithm;space technology;tv;quality of service;adaptive rules cutting;optimum rule cutting;hardware	This paper introduces an advanced packet classification algorithm called adaptive rules cutting (ARC). In the same way as the HiCuts and HyperCuts Algorithm, ARC is based on cutting the multi-dimensional space into smaller segments for rule reduction. Unlike HiCuts where dividing the region takes more than 1 level, and unlike HyperCuts in which each node represents a k-dimensional hypercube, ARC allows the flexibility of considering all dimensions. This extra degree of freedom and a new set of heuristics allow adaptation for optimum rule cutting for a given amount of storage. Rule cutting simulations and performance studies show that ARC can provide a reduction of up to 98% of the given rules in the first instance.	algorithm;heuristic (computer science);network packet;simpson's rule;simulation	Motasem Abdelghani;Sakir Sezer;Emi Garcia-Palacios;Jun Mu	2005	Advanced Industrial Conference on Telecommunications/Service Assurance with Partial and Intermittent Resources Conference/E-Learning on Telecommunications Workshop (AICT/SAPIR/ELETE'05)	10.1109/AICT.2005.67	routing;arc;quality of service;computer science;theoretical computer science;machine learning;data mining;distributed computing;space technology;routing protocol;degrees of freedom;information technology;packet switching;hypercube;computer network	HPC	-6.587326299560972	67.91005171094432	153669
a64fb5038e0becb599fd072265a3e988cb47fe7a	compact route computation: improving parallel bgp route processing for scalable routers	parallel bgp route processing;routing protocols;routing protocols partitioning algorithms delay distributed control internet process control convergence;internet size;convergence;scalable routers;border gateway protocol;scale route processing capacity;forces;distributed control plane;control element;scalable routers compact route computation parallel bgp route processing internet router border gateway protocol internet size router workload routing convergence performance cluster router forces distributed control plane control element scale route processing capacity parallel computation;compact routing;parallel computation;internet;internet router;process control;routing protocols internet parallel processing;compact route computation;routing convergence performance;router workload;cluster router;distributed control;parallel processing;partitioning algorithms	Nowadays Internet routers are overwhelmed by a large quantity of BGP (Border Gateway Protocol) updates triggered by route changes. The fast growth of the Internet size further aggravates router workloads and exacerbates routing convergence performance. Scalable routers, such as cluster routers and For CES, are proposed to exploit distributed control plane (DCP) with multiple control elements (CEs) to scale route processing capacity. Previous studies show that most route updates are duplicated in the Internet. Traditional parallel computation schemes only consider calculating route in parallel but most routes are computed in vain since they will not be finally selected. This paper proposes a simple and novel idea of compact route computation (CRC) to reduce BGP route processing load and improve routing convergence performance. Our scheme partitions Adj-RIBs-in among multiple CEs in the granularity of prefixes, which makes non-consecutive updates for a prefix queued adjacently in distributed control plane. Route computations triggered by a prefix's consecutive updates are compacted into one. We evaluate our scheme by simulations with real BGP update data, and results show that our scheme is very effective to reduce route computation workloads. For example, for a scalable router with 4 CEs and the updates received from 24 neighbors, our scheme reduces 60% route computation load. It can distinctly reduce route computation load with more CEs.	border gateway protocol;computation;control plane;cyclic redundancy check;distributed control system;internet;parallel computing;router (computing);routing;scalability;simulation	Xue Zhi Jiang;Mingwei Xu;Qi Li	2011	2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum	10.1109/IPDPS.2011.302	parallel computing;route poisoning;computer science;distributed computing;default-free zone;null route;computer network	OS	-8.752314377518896	70.04898312069892	154184
8982f624d6d1f7c321c55f038813ec40de3e4903	on a local protocol for concurrent file transfers	file transfer;average completion time;local protocol;makespan;scheduling	We study a very natural local protocol for a file transfer problem. Consider a scenario where several files, which may have varied sizes and get created over a period of time, are to be transferred between pairs of hosts in a distributed environment. Our protocol assumes that while executing the file transfers, an individual host does not use any global knowledge; and simply subdivides its I/O resources equally among all the active file transfers at that host at any point in time. This protocol is motivated by its simplicity of use and its applications to scheduling map-reduce workloads.  Here we study the problem of deciding the start times of individual file transfers to optimize QoS metrics like average completion time or MakeSpan. To begin with, we show that these problems are NP-hard. We next argue that the ability of scheduling multiple concurrent file transfers at a host makes our protocol stronger than previously studied protocols that schedule a sequence of matchings, in which no two active file transfers share a host at any time. We then generalize the approach of Queyranne and Sviridenko (J. Scheduling, 2002) and Gandhi et al. (ACM T. Algorithms, 2008) that relates the MakeSpan and completion time objectives and present constant factor approximation algorithms.	approximation algorithm;file transfer;input/output;job shop scheduling;mapreduce;matching (graph theory);np-hardness;optimization problem;preemption (computing);schedule (computer science);scheduling (computing);theoretical computer science	Mohammad Taghi Hajiaghayi;Rohit Khandekar;Guy Kortsarz;Vahid Liaghat	2011	Theory of Computing Systems	10.1007/s00224-013-9500-1	job shop scheduling;real-time computing;computer science;database;distributed computing;scheduling	Theory	-13.606774631696322	65.52876404278871	154375
10c593f7c7f1aaa71b9186894d0525bb886ac294	efficient approximation algorithm for data retrieval with conflicts in wireless networks	indexing;wireless data broadcast;data retrieval	Given a set of data items broadcasting at multiple parallel channels, where each channel has the same broadcast pattern over a time period, and a set of client's requested data items, the data retrieval problem requires to find a sequence of channel access to retrieve the requested data items among the channels such that the total access latency is minimized, where both channel access (to retrieve a data item) and channel switch are assumed to take a single time slot. As an important problem of information retrieval in wireless networks, this problem arises in many applications such as e-commerce and ubiquitous data sharing, and is known two conflicts: requested data items are broadcast at same time slots or adjacent time slots in different channels. Although existing studies focus on this problem with one conflict, there is little work on this problem with two conflicts. So this paper proposes efficient algorithms from two views: single antenna and multiple antennae. Our algorithm adopts a novel approach that wireless data broadcast system is converted to DAG, and applies set cover to solve this problem. Through Experiments, this result presents currently the most efficient algorithm for this problem with two conflicts.	approximation algorithm;broadcasting (networking);data item;data retrieval;directed acyclic graph;e-commerce;information retrieval;set cover problem	Ping He;Hong Shen;Hui Tian	2013		10.1145/2536853.2536879	search engine indexing;computer science;theoretical computer science;data mining;distributed computing;data retrieval;computer network	DB	-14.631024911379294	69.17542902865739	154719
d90b1a9aebdfced8895b9eb26af9cee9d84b3465	efficient processing of wireless read-only transactions in data broadcast	read only transactions;dynamic workload changes;dynamic change;predeclaration based query optimization;protocols;base stations;predeclaration;data integrity;data engineering satellite broadcasting query processing bandwidth protocols telephone sets performance analysis delay artificial satellites base stations;query processing;dynamic workload changes wireless read only transaction processing data broadcast multiple data item consistency read only transactions wireless data broadcast data broadcast environment strictly sequential data access predeclaration based query optimization transaction processing methods local caching;telephone sets;multiple data item consistency;query optimization;data engineering;strictly sequential data access;satellite broadcasting;local caching;wireless read only transaction processing;mobile communication data integrity broadcasting transaction processing;transaction processing methods;mobile communication;performance analysis;artificial satellites;bandwidth;wireless data broadcast;data broadcast;broadcasting;transaction processing;read only transaction;wireless data;data consistency;data broadcast environment	In this paper, we address the issue of ensuring consistency of multiple data items requested in a certain order by read-only transactions in wireless data broadcast. To handle the inherent property in a data broadcast environment that data can only be accessed strictly sequential by users, we explore a predeclaration-based query optimization and devise two practical transaction processing methods in the context of local caching. We also evaluate the performance of the proposed methods by an analytical study. Evaluation results show that the predeclaration technique we introduce reduces response time significantly and adapts to dynamic changes in workload.	broadcasting (networking);javaserver pages;mathematical optimization;order by;overhead (computing);query optimization;read-only memory;response time (technology);serializability;transaction processing	SangKeun Lee;Masaru Kitsuregawa;Chong-Sun Hwang	2002		10.1109/RIDE.2002.995104	real-time computing;atomic broadcast;computer science;database;distributed computing	DB	-15.126738256964616	68.45385444021544	155188
72aadda62f72320567eb8338b1390754480a61e0	a novel replication strategy for efficient xml data broadcast in wireless mobile networks		Recently, the use of XML for data broadcasting in mobile wireless networks has gained many attentions. In these networks, a stream of XML data is broadcasted via a wireless channel, and mobile clients access the broadcast stream using energy-restricted portable devices. Several indexing methods have been proposed to selectively access XML data over a broadcast stream. Although existing indexing methods improve the performance of XML query processing in terms of access time and tuning time but they do not use a replication strategy to replicate the indexes in the broadcast XML stream. In this paper, we propose a novel replication strategy for XML data broadcast called Triangle-based Replication (TR) strategy which replicates the partial and relevant parts of indexes into suitable positions in the broadcast XML stream. Experimental results show that our proposed XML replication strategy has better performance compared to existing XML replication strategies.		Ali Borjian Boroujeni;Meghdad Mirabi	2016	J. Inf. Sci. Eng.		computer network;distributed computing;xml;wireless;computer science;broadcast radiation;broadcasting	DB	-14.907906587483247	68.89349044078466	155265
3e065d36edded332fa0a4fb82c8fa2b435864df4	work-efficient load balancing	convergence;heuristic algorithms load management load modeling partitioning algorithms convergence computational modeling network topology;scheduling graph theory resource allocation;convergence load balancing diffusion algorithms dimension exchange algorithms dynamic networks work efficiency;network topology;computational modeling;heuristic algorithms;network topologies work efficient load balancing parallel applications distributed applications undirected connected graph node weight distribution scheduling static networks dynamic networks;load management;load balancing;work efficiency;load modeling;dimension exchange algorithms;diffusion algorithms;dynamic networks;partitioning algorithms	Load balancing is the key to many parallel and distributed applications. We consider the following load balancing problem: given any undirected connected graph and an initial weight distribution on the nodes, determine a schedule to move weights across edges so as to have (almost) equal weights on the nodes. Weights are moved across edges in rounds, and, in a round, weights are moved between the adjacent nodes exactly once. We study this problem in both static and dynamic networks. Previously studied diffusion and dimension exchange algorithms are slow in practice in the sense that they require many rounds of weight exchanges. In this paper, we present a class of algorithms that are work-efficient, i.e., they reduce the number of rounds (i.e., iterations) of weight exchanges needed to balance the load. In our algorithms, a node exchanges load with its neighbors sequentially (one neighbor at a time) and the load at that node is updated before subsequent exchanges with other neighbors. Simulation results on six network topologies show that our algorithms balance the load quite work-efficiently compared to previous algorithms.	algorithm;connectivity (graph theory);distributed computing;graph (discrete mathematics);graph theory;iteration;load balancing (computing);network topology;simulation;telephone exchange;universal quantification	Gokarna Sharma;Suresh Rai;Costas Busch;Jerry L. Trahan;Ramachandran Vaidyanathan	2014	2014 43rd International Conference on Parallel Processing Workshops	10.1109/ICPPW.2014.17	mathematical optimization;convergence;computer science;load balancing;theoretical computer science;distributed computing;computational model;network topology;computer network	Theory	-9.47201421402701	73.69978039611863	155359
be350bbb30e7490f671958638677f169d81e7a83	non-clairvoyant weighted flow time scheduling on different multi-processor models	multiprocessor scheduling;weighted flow time;non clairvoyant scheduling;competitive analysis;online algorithms	We study non-clairvoyant scheduling to minimize weighted flow time on two different multi-processor models. In the first model, processors are all identical and jobs can possibly be speeded up by running on several processors in parallel. Under the non-clairvoyant model, the online scheduler has no information about the actual job size and degree of speed-up due to parallelism, yet it has to determine dynamically when and how many processors to run the jobs. The literature contains several O(1)-competitive algorithms for this problem under the unit-weight multi-processor setting (Edmonds, Theor. Comput. Sci. 235(1), 109–141, 2000; Edmonds and Pruhs, in Proceedings of ACM-SIAM Symposium on Discrete Algorithms (SODA), 685–692, 2009) as well as the weighted single-processor setting (Bansal and Dhamdhere, ACM Trans. Algorithms 3(4), 2007). This paper shows the first O(1)-competitive algorithm for weighted flow time in the multi-processor setting. In the second model, we consider processors with different functionalities and only processors of the same functionality can work on the same job in parallel. Here a job is modeled as a sequence of non-clairvoyant demands of different functionalities. This model is derived naturally from the classical job shop scheduling; but as far as we know, there is no previous work on scheduling to minimize flow time. In this paper we take a first step to study non-clairvoyant scheduling on this multi-processor model. Motivated by the literature on 2-machine job shop scheduling, we focus on the special case when processors are divided into two types of functionalities, and we show a non-clairvoyant algorithm that is O(1)-competitive for weighted flow time.	central processing unit;edmonds' algorithm;job shop scheduling;job stream;multiprocessing;parallel computing;scheduling (computing);symposium on discrete algorithms	Jianqiao Zhu;Ho-Leung Chan;Tak Wah Lam	2013	Theory of Computing Systems	10.1007/s00224-013-9475-y	fair-share scheduling;competitive analysis;job shop scheduling;online algorithm;parallel computing;real-time computing;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;mathematics;distributed computing;least slack time scheduling;round-robin scheduling;multiprocessor scheduling	Theory	-11.682586608725314	61.10633739937758	155434
4e4537e93eb02e63f0e9f4d4d0201400797a73d3	a novel reconfigurable wrapper for testing of embedded core-based socs and its associated scheduling algorithm	dynamic change;reconfigurable wrapper;test access mechanism;efficient algorithm;chip;scheduling algorithm;system on chip;embedded core based test scheduling;system on chip test;parallel scheduling of malleable tasks;scheduling problem;vlsi test;test scheduling;task scheduling	In this paper a mathematical formulation and an efficient solution, of the embedded core-based system-on-chip (SOC) test scheduling problem (ECTSP) is presented. The ECTSP can be stated as followss given a chip with NC cores each having a test Tis where Ti takes time {\cal F}_T(T_i,w_j) to execute on a test access mechanism (TAM) of width wj, and a constraint W on the number of top-level test pinss calculate the TAM assignment vector π and the schedule Σ for each test Ti, such that the completion time of the full chip test is minimized. All existing approaches have solved the ECTSP by solving the TAM partition and scheduling problem sequentially. In this paper we present an unified approach to solve the ECTSP. We present the first report of a design of reconfigurable core wrapper which allows for a dynamic change in the width of the test access mechanism (TAM) executing a core test. An automatic procedure for the creation of DfT hardware required for reconfiguration using a graph theoretic representation of core wrappers is also presented. For the case of reconfigurable wrappers, efficient algorithms to compute the schedule are presented based upon some recent results in the field of malleable task scheduling. Cases in which the degree of reconfigurability are constrained are considereds the case when only a single core can have reconfigurable wrapper, a schedule with zero TAM idle time can be found in time O(NC(NC + W)lgW), and the case when only 2 different wrapper configurations are allowed can be solved in time O(NC3). Comparison with existing results on benchmark SOCs show that our algorithms outperform state-of-art ILP formulations not only in schedule makespan, but also significantly reduce computation time.		Sandeep Koranne	2002	J. Electronic Testing	10.1023/A:1016593423844	chip;system on a chip;fair-share scheduling;embedded system;job shop scheduling;parallel computing;real-time computing;telecommunications;dynamic priority scheduling;computer science;scheduling	EDA	-8.9393464335479	60.80027670595586	155721
90ef94c7db27d4eff216def1a7c36a739af4d3fa	multiprocessor task scheduling with resource requirements	multiprocessor systems;polynomial time algorithm;linear program;task scheduling	One of the most important problems arising in multiprocessor systems is scheduling of tasks on a set of parallel processors. Recently, new models of task processing have been formulated in which certain tasks can require more than one processor at a time. This model is especially justified in some applications of multi-microprocessor systems. In this paper, we extend the above model to cover the case of scheduling in the presence of additional scarce resources. First a subcase of the problem is considered in which preemptable tasks need simultaneously one or two processors and one additional resource in the amount of one unit. For this case a low order polynomial-time algorithm is presented. Then the general case is solved via a linear programming approach.	algorithm;central processing unit;linear programming;microprocessor;multiprocessing;parallel computing;requirement;scheduling (computing);time complexity	Jacek Blazewicz;Klaus H. Ecker	1994	Real-Time Systems	10.1007/BF01245298	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;linear programming;distributed computing;least slack time scheduling;multiprocessor scheduling;symmetric multiprocessor system	Embedded	-12.017033909476636	60.791807209139314	155945
1c4e265536b2cefb8998fd7289001e8c6b1811c1	an adaptively hierarchical framework for remote paging on grids	servers random access memory performance evaluation memory management probability distribution performance analysis gaussian distribution;paged storage;random access memory;memory management;performance evaluation;remote paging;adaptively hierarchical framework;real time;memory client;p2p;grid remote paging data transfer network latency data transfer memory client peer to peer;client server systems;grid;servers;network servers;theoretical analysis;probability distribution;performance analysis;least recently used remote paging grids network latency adaptively hierarchical framework;communication cost;paged storage client server systems electronic data interchange grid computing network servers;grids;dynamic adaptation;peer to peer;network latency;grid computing;gaussian distribution;least recently used;electronic data interchange;data transfer	The performance of remote paging on grids is strongly dominated by the network latency of data transfer. However, the memory clients in the previously proposed remote paging systems do not always put/get pages to/from the memory servers with the least network latency. Consequently, the communication cost of remote paging has not been reduced effectively. To address this problem, we propose an adaptively hierarchical framework for remote paging on grids in this paper. The memory servers in this framework are organized as a hierarchical list in an ascendant order based on their network latencies. Only the head server in the hierarchical list can accept pages from the memory client while the others can receive pages only from the upper-level server. When a memory server uses up allowed memory space, it will move a number of the least recently used pages to the lower-level server, and will release the memory space occupied by these pages for storing new arriving pages. Moreover, the order of memory servers in the hierarchical list is dynamically adapted according to their real-time network latencies. We have compared the hierarchical framework with the peer-to-peer one which is popularly adopted by the previously proposed remote paging systems through theoretical analysis and performance evaluation. The results show that the proposed framework indeed is more effective than the P2P one for improving the performance of remote paging.	dspace;paging;peer-to-peer;performance evaluation;random-access memory;real-time clock;real-time computing;server (computing)	Tyng-Yeu Liang;Hung-Fu Li	2010	2010 13th IEEE International Conference on Computational Science and Engineering	10.1109/CSE.2010.46	normal distribution;probability distribution;demand paging;latency;real-time computing;thrashing;page replacement algorithm;computer science;operating system;electronic data interchange;peer-to-peer;database;distributed computing;flat memory model;grid;cache algorithms;grid computing;server;computer network;paging;memory management	HPC	-15.953950322882534	68.06403707379296	156171
69f1145c4748e4bc11ceb72d7302ea9dc342b4a2	a fuzzy critical path method based scheduling approach for collaboration process	resource scheduling;fuzzy timing high level petri net;temporal uncertainty;groupware;high level petri net;collaborative design process;probability;concurrent computing;collaborative work;performance evaluation;critical path analysis;uncertainty;processor scheduling;resource allocation;resource management;collaboration;resource conflict solving policy;critical path method cscw workflow fthpn;time management;fuzzy set theory;critical path method;fuzzy critical path method based scheduling;scheduling algorithm;stochastic processes;computer supported collaborative work;scheduling;critical path;fthpn;cscw fuzzy critical path method based scheduling collaborative design process temporal uncertainty workflow technology probability theory fuzzy timing high level petri net resource conflict solving policy resource scheduling time management computer supported collaborative work;probability theory;workflow management software;workflow;cscw;workflow technology;petri nets;collaborative design;collaboration collaborative work processor scheduling uncertainty resource management scheduling algorithm petri nets concurrent computing concurrent engineering stochastic processes;concurrent engineering;workflow management software critical path analysis fuzzy set theory groupware petri nets probability resource allocation scheduling	The temporal uncertainty of activities and limited resources are important factors for successful operation and performance evaluation on collaborative design. In the paper a method of modelling well-define collaboration process based on workflow technology, probability theory and fuzzy-timing high-level Petri nets is presented. Then while an approach for identifying the fuzzy critical path is given, a policy of solving resource conflict and resource scheduling with limited resources is introduced. These approaches offer theoretic basis and available means of time management, resource scheduling and conflict solving in collaborative work processes. Finally, the validity of those proposed methods is proven by an example	critical path method;high- and low-level;performance evaluation;petri net;scheduling (computing);ti-nspire series;theory	Feng Tian;Renhou Li	2006	2006 10th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2006.253148	real-time computing;concurrent computing;resource allocation;computer science;knowledge management;resource management;critical path method;distributed computing;management	EDA	-8.376244635062662	60.71079227518942	156206
24366ec003453019850c338b40140fba08ebe796	scheduling policies to support distributed 3d multimedia applications	broadband networks;real time;cluster of workstations;multimedia application;large deviations;parameter space;effective bandwidths;traffic engineering;atm;local area network	We consider the problem of scheduling the rendering component of 3D multimedia applications on a cluster of workstations connected via a local area network. Our goal is to meet a periodic real-time constraint.In abstract terms, the problem we address is how best to schedule tasks with unpredictable service times on distinct processing nodes so as to meet a real-time deadline, given that all communication among nodes entails some (possibly large) overhead. We consider two distinct classes of schemes, static, in which task reallocations are scheduled to occur at specific times, and dynamic, in which reallocations are triggered by some processor going idle. For both classes we further examine both global reassignments, in which all nodes are rescheduled at a rescheduling moment, and local reassignments, in which only a subset of the nodes engage in rescheduling at any one time.We show that global dynamic policies work best over a range of parameterizations appropriate to such systems. We introduce a new policy, Dynamic with Shadowing, that places a small number of tasks in the schedules of multiple workstations to reduce the amount of communication required to complete the schedule. This policy is shown to dominate the other alternatives considered over most of the parameter space.	computer cluster;overhead (computing);real-time clock;real-time locating system;scheduling (computing);workstation	Thu D. Nguyen;John Zahorjan	1998		10.1145/277851.277930	local area network;embedded system;traffic engineering;large deviations theory;real-time computing;computer science;operating system;distributed computing;atmosphere;parameter space;statistics;computer network;broadband networks	Metrics	-14.125977904572386	64.1355280285355	156266
df224187b92939b56bcf59c3feb88a543a403ba6	a 2-approximation algorithm for scheduling parallel and time-sensitive applications to maximize total accrued utility value	approximation algorithm;time sensitive applications knapsack based scheduling algorithm gang edf algorithm gang earliest deadline first algorithm backfilling algorithm fcfs algorithm first come first come serve algorithm stib c algorithm continuous spatial temporal interference based algorithm stib scheduling algorithm discrete time domain utility value maximization problem total accrued utility value;interference scheduling algorithms schedules scheduling time domain analysis optimal scheduling;interference;time domain analysis;scheduling algorithms;approximation algorithm parallel time sensitive scheduling;optimal scheduling;scheduling;parallel;schedules;time sensitive;processor scheduling approximation theory knapsack problems optimisation	For a time-sensitive application, the usefulness of its end results (also called the application's accrued utility value in the paper) depends on the time when the application is completed and its results are delivered. In this paper, we address the accrued utility value maximization problem for narrow parallel and time-sensitive applications. We first consider the problem in the context of a discrete time domain and present the Spatial-Temporal Interference Based (STIB) scheduling algorithm. We formally prove that the STIB algorithm is a 2-approximation algorithm. Second, we extend our work to a continuous time domain and present a heuristic scheduling algorithm, i.e., the Continuous Spatial-Temporal Interference Based (STIB-C) algorithm to maximize the system's total accrued utility value when the system operates in a continuous time domain. The extensive empirical evaluations reveal that: (1) in a discrete time domain, the systems' total accrued utility values obtained through the STIB algorithm are consistent with the theoretic bound, i.e., they never go below 50 percent of the optimal value. In fact, on average, the STIB algorithm can achieve over 92.5 percent of the optimal value; (2) compared to other scheduling policies listed in the literature, the developed STIB and STIB-C algorithms have clear advantages in terms of the system's total accrued utility value and the profitable application ratio. In particular, in terms of the system's total accrued utility value, both the STIB and the STIB-C algorithms achieve as much as six times for both the First Come First Come Serve(FCFS) with backfilling algorithm and the Gang Earliest Deadline First (EDF) algorithm, and 4.5 times for the 0-1 Knapsack based scheduling algorithm. In terms of the profitable application ratio, both the STIB and the STIB-C algorithms obtain as much as four times for both the FCFS with backfilling algorithm and the Gang EDF algorithm, and two times for the 0-1 Knapsack based scheduling algorithm.	algorithm;earliest deadline first scheduling;entropy maximization;experiment;global serializability;heuristic;mathematical optimization;optimization problem;run time (program lifecycle phase);scheduling (computing);simulation;statistical interference;theory;time complexity;utility;valid time	Shuhui Li;Miao Song;Peng-Jun Wan;Shangping Ren	2016	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2015.2474360	fair-share scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;two-level scheduling;distributed computing;least slack time scheduling;scheduling;approximation algorithm;proportionally fair	Metrics	-10.109116343378165	63.27708458219172	156295
7ad4551825b2e744a9f8c9ebea7250be5bd9b746	effective data placement for wireless broadcast	mobile computer;data clustering;data broadcasting;data broadcast;wireless data;mobile computing;article;data placement;multi point query	This paper investigates how to place data objects on air for wireless broadcast such that mobile clients can access the data in short latency. We first define and analyze the problem of wireless data placement, and also propose a measure, named Query Distance (QD), which represents the coherence degree of data set accessed by a query. We show that the problem is NP-complete, and then propose an effective data placement method that constructs the broadcast schedule by appending each query's data set in greedy way. We show through performance experiments that the proposed method reduces the access time of mobile query.	access time;experiment;f1 score;greedy algorithm;heuristic;np-completeness;quantum dot;schedule (computer science);scheduling (computing)	Yon Dohn Chung;Myoung-Ho Kim	2001	Distributed and Parallel Databases	10.1023/A:1018992406195	query optimization;computer science;operating system;database;distributed computing;cluster analysis;mobile computing;computer network	DB	-14.685678644482001	69.03580722584469	156303
d2174f0eac16816951b11e20ad8185567ef4e94f	configuration of overloaded servers with dynamic routing	input flow;dynamic routing;similar effect;independent poisson input flow;k server;overloaded server	We consider overload of servers in a network with dynamic routing of messages. The system consists of k servers and independent Poisson input flows. Messages from each flow are directed to m servers, and each message is directed to a server that is the least loaded at the moment of its arrival. In such a system, configuration of overloaded servers depends on the intensity of input flows. A similar effect was considered in [1] for a system with another geometry. DOI: 10.1134/S0032946011030070	routing;server (computing)	Nikita D. Vvedenskaya	2011	Probl. Inf. Transm.	10.1134/S0032946011030070	server	Theory	-12.668754183442633	66.09523622447725	157020
a093b841fc312a96b4493e0cec05d03a26303351	a data allocation scheme using data mining for wireless cellular network	remote access;mining for collaborative technologies;data;association rules mobile and wireless computing data mining for collaborative technologies mobile database distributed databases;site selection;query optimization;data replication;association rules;collaborative system;data mining;mobile database;data distribution;distributed query processing;association rule;base station;mobile and wireless computing;wireless cellular network;data mining land mobile radio cellular systems query processing collaboration network servers base stations costs delay prefetching call admission control;distributed databases;call admission control;data mining for collaborative technologies	"""A centralized collaborative system between nodes, servers and Base Stations (BSs) is developed, and a new data allocation scheme based on group and query prediction mobility scheme with Data Mining techniques is proposed. With this approach we minimize the cost of remote access by reducing the number of network messages and improve the response time of the queries. A series of algorithms is developed so that the system can provide the """"prefetch"""" operation for the group of users according to their mobility. The data have to follow the users’ moves. Our new approach contains Call Admission Control (CAC) with a prediction scheme for Group and Query Mobility (GQM) based on two phases: the Merge Itemsets Algorithm (MIA) and the one step dynamic Replication Algorithm (RAL1) respectively. The RAL1, providing two data replication policies, can guarantee the acceleration of the query execution. The proposed system can be used for site selection or reduction of the number of sites in query optimization, and also the design of any new architecture for distributed query processing. Simulation results are provided."""	algorithm;centralized computing;common access card;data mining;gqm;mathematical optimization;multitier architecture;query optimization;remote desktop software;replication (computing);response time (technology);simulation	John Tsiligaridis;Raj Acharya	2006	International Symposium on Collaborative Technologies and Systems (CTS'06)	10.1109/CTS.2006.5	sargable;query optimization;association rule learning;computer science;data mining;database;world wide web;distributed database	DB	-15.771388901471463	68.7490557000046	157085
15ffd3b8008ee4b94237180c02fab0c608e02678	exploiting local popularity to prune routing indices in peer-to-peer systems	peer to peer network;query processing;query processing peer to peer computing;peer to peer system;dynamic environment;indexation;least recently used replacement strategy unstructured peer to peer systems routing indices local popularity method global popularity method least frequently used replacement strategy;least frequently used;peer to peer computing;routing peer to peer computing broadcasting computer science learning floods performance analysis protocols storage automation conferences;least recently used	Routing in unstructured peer-to-peer systems relies either on broadcasting (also called flooding) or on routing indices. An approach using routing indices is only scalable if the routing indices are of manageable size. In this paper, we present a strategy to prune routing indices based on popularity of resources. Routing indices maintain routing information for queries to the most popular resources, leaving queries to other resources to be routed randomly. The popularity of resources at each node of a network is learnt by each routing index, by means of a replacement strategy. We compare the performance of the local popularity method against that of the global popularity method in pruning routing indices in both static and dynamic environments. We compare the effectiveness and the efficiency of two standard replacement strategies: least frequently used (LFU) and least recently used (LRU). Our results confirm the efficiency and effectiveness of pruning routing indices based on the local popularity of resources in unstructured peer-to-peer networks.	least frequently used;peer-to-peer;randomness;reinforcement learning;routing table;scalability	Stéphane Bressan;Achmad Nizar Hidayanto;Zainal A. Hasibuan	2005	16th International Workshop on Database and Expert Systems Applications (DEXA'05)	10.1109/DEXA.2005.89	policy-based routing;routing table;routing domain;least frequently used;routing;static routing;hierarchical routing;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;operating system;database;distributed computing;routing protocol;link-state routing protocol;triangular routing;cache algorithms;dead peer detection;world wide web;geographic routing	DB	-12.574402601165396	73.63853757056522	157133
57a4259121bf6fe22bd1a99fcb410c95798d5e03	a client-assisted interval caching strategy for video-on-demand systems	largeur bande;entrada salida;streaming;video streaming;gollete estrangulamiento;transmision continua;client assisted;video a la demande;serveur informatique;cache memory;servicing cost;antememoria;input output;antememoire;goulot etranglement;transmission en continu;cout moyen;senal video;signal video;average cost;video on demand;coste medio;anchura banda;video server;video signal;bandwidth;interval caching;servidor informatico;cost effectiveness;video stream;bottleneck;video a la carta;i o bandwidth;entree sortie;computer server	In a Video-on-Demand (VoD) system, in order to guarantee smooth playback of a video stream, sufficient resources (such as disk I/O (Input/Output) bandwidth, network bandwidth) have to be reserved in advance. Thus, given limited resources, the number of simultaneous streams can be supported by a video server is restricted. Due to the mechanical nature, the I/O subsystem is generally the performance bottleneck of a VoD system, and there have been a number of caching algorithms to overcome the disk bandwidth limitation. In this paper, we propose a novel caching strategy, referred to as client-assisted interval caching (CIC) scheme, to balance the requirements of I/O bandwidth and cache capacity in a cost-effective way. The CIC scheme tends to use the cache memory available in clients to serve the first few blocks of streams so as to dramatically reduce the demand on the I/O bandwidth of the server. Our objective is to maximize the number of requests that can be supported by the system and minimize the overall system cost. Simulations are carried out to study the performance of our proposed strategy under various conditions. The experimental results show the superior of CIC scheme to the tradition Interval Caching (IC) scheme, with respect to request accepted ratio and average servicing cost per stream. 2006 Elsevier B.V. All rights reserved.	algorithm;analysis of algorithms;cpu cache;cache (computing);competitive analysis (online algorithm);computer simulation;digital video;input/output;interval arithmetic;requirement;server (computing);streaming media;video server;videocassette recorder	Lin Wujuan;Law Sie Yong;Yong Khai Leong	2006	Computer Communications	10.1016/j.comcom.2006.06.014	input/output;embedded system;real-time computing;simulation;cost-effectiveness analysis;cpu cache;telecommunications;computer science;operating system;computer security;bandwidth;server;computer network	DB	-14.60373901681944	70.84947937037617	157373
467f537d596bd2e4de503f3d4b5493e8191ba694	a new approach for limited preemptive scheduling in systems with preemption overhead	limited preemption scheduling;cache related preemption delay limited preemption scheduling real time systems schedulability analysis;schedulability analysis;cache related preemption delay;servers;scheduling algorithms;loose harmonic task sets limited preemptive scheduling algorithm systems preemption reduction periodic task sets maximum time interval rs lp fixed priority scheduling maximum blocking tolerance preemption overhead aware schedulability tests;conferenceobject;scheduling;real time systems scheduling algorithms scheduling servers mathematical model aerospace electronics;aerospace electronics;mathematical model;real time systems	This paper considers the problem of reducing the number of preemptions in a system with periodic tasks and preemption overhead. The proposed solution is based on the key observation that for periodic task sets, the task with the smallest period plays an important role in determining the maximum interval of time during which a lower priority task can be executed without being preempted. We use this property to build a new limited preemptive scheduling algorithm, named RS-LP, based on fixed-priority scheduling. In RS-LP, the length of each task's non-preemptive region is varying during the system execution so as to keep the preemptions aligned with the releases of the highest priority task. This simple mechanism allows us to reduce the overall number of preemptions. The proposed algorithm, decides whether or not to preempt the currently executing task based on the maximum blocking tolerance of the higher priority tasks. In any case, the preemptions are authorized only at release instants of the task with the smallest period, thereby limiting the maximum number of preemptions to the number of releases of the highest priority task. Moreover, in this paper, we provide two different preemption overhead aware schedulability tests for periodic and loose-harmonic task sets (i.e., where each period is an integer multiple of the smallest period), together with a lower bound on the maximum number of preemptions. To conclude, extensive experiments comparing RS-LP with the state of the art limited preemptive scheduling algorithms are finally presented.	algorithm;authorization;blocking (computing);experiment;fault tolerance;fixed-priority pre-emptive scheduling;international symposium on fundamentals of computation theory;item unique identification;np-hardness;overhead (computing);performance;preemption (computing);scheduling (computing);serial digital video out;slack variable	Mitra Nasri;Geoffrey Nelissen;Gerhard Fohler	2016	2016 28th Euromicro Conference on Real-Time Systems (ECRTS)	10.1109/ECRTS.2016.15	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;deadline-monotonic scheduling;distributed computing;round-robin scheduling;scheduling	Embedded	-10.523305270967725	60.86872111127488	157597
cce69e76a55529d0344c184a841edeac60256be9	notes on real-time distributed database systems stability	distributed databases;fault tolerant computing;real-time systems;control algorithms;degradation indexes;dependability;fault-tolerant distributed database;load-balancing;real-time distributed database systems stability;routing	"""The very simple algorithms we deal with in this paper are but e ~ a m ~ l e s of how algorithms can and must be accounted for in evaluating the overall system dependability. at the end of this paper. Issues On the Of routing and load balancing A detailed description can be found in the references on the stability of a fault-tolerant distributed database system are emmined. Degradation indezes are defined for the system dependability and some open question are risen. 1.1 Preliminary concepts 1. Introduction This paper deals with concepts related to algorithms as an important issue in the evaluation of the Dependability of Information and Control Systems. Such systems can be seen as very complex """"machines"""" whose components belong to three different technological species: 1. hardware; 2. algorithms; 3. software (both system and application). Mentioning algorithms as components in the evaluation of systems dependability, I want to separate algorithms themselves even if in the broad meaning of problem resolution procedures-from their materialization by means of programs which can be buggy, in which case they would fall into species 3 [SCH 861. To be more precise, I mainly refer to control algorithms, i.e. to those algorithms which can be found in the heart of Operating Systems, Database Management Systems, industrial process control systems, etc.. These algorithms, even if """"correct"""" with respect to functional specifications, can influence the availability of the system to the end user """"phys-iologically""""-in the sense that their very function is to deny a user the access to a particular resource owing to instantaneous workload conditions (e.g. concurrency control). However algorithms can influence the overall system dependability """"pathologically"""" since they can show a faulty behaviour under particular dynamic workload conditions and system constraints (e.g. load balancing, routing, etc. under tight response time constraints). First of all, let us review some concepts which are closely related to """"good behaved"""" algorithms: Correctness: it is the fundamental property of whatever algorithm. An algorithm is correct if for whatever legal input it produces an output in accordance with the functional specifications of the problem [BOY 81, GHE 871. Efficiency: it is the property which deals with the practical implementability and with the overhead the algorithm introduce in the system. Generally it is measured in terms of number of computation steps (time complexity) or of memory occupation (space complexity) as asymptotycal functions of the dimension of the problem [HAR 871. …"""	.sch;algorithm;computation;concurrency (computer science);concurrency control;control system;correctness (computer science);dspace;dependability;distributed database;elegant degradation;fault tolerance;functional specification;load balancing (computing);management system;overhead (computing);real-time transcription;response time (technology);routing;time complexity	Fabio A. Schreiber	1990			distributed algorithm;real-time computing;computer science;load balancing;database;distributed computing;distributed database;distributed concurrency control	DB	-9.551278475080805	62.84163281098795	157600
e9eed000e876a9a855296d698d3a9f1486cb2ee2	task scheduling on bus-based networks of workstations	task scheduling;reasonable computational complexity;pre-allocating network communication resource;potential communication conflict;dynamic critical path;task graph;irregular task graph;heuristic algorithm;bus-based network;various task graph	In this paper, we propose a heuristic algorithm based on dynamic critical path (DCP) to solve the problem of task scheduling on networks of workstations (NOW). The algorithm takes into account both the characteristics of DCP and NOW by intelligently pre-allocating network communication resources so as to avoid potential communication conflict. It has a reasonable computational complexity of O(v2(1 + p)), where v is the number of nodes in the task graph and p is the number of processors in the NOW. It is suitable for regular as well as irregular task graphs. The algorithm when tested under various task graphs shows performance much superior to previously known techniques.	schedule (project management);scheduling (computing);workstation	Wei-Ming Lin;Qiuyan Gu	1999	Scalable Computing: Practice and Experience		parallel computing;real-time computing;computer science;operating system;distributed computing	HPC	-13.50816604962563	61.69031197555148	157960
397b98f74e66cef462e1339b381ee84941a7d492	computing estimates of waiting times in ring local area networks with priority classes	local area network			Mostafa A. Bassiouni;Akash Gupta	1987	Comput. Syst. Sci. Eng.			Theory	-8.14316945999482	69.76107045522211	158050
4e899a2d94cdc6c672b932b97c5ca3d9ea577b2c	effective load balancing for cloud-based multimedia system	resource allocation;resource allocation cloud computing load balancing;multimedia systems;load balance;quality of service;cmlb load balancing cloud based multimedia system multimedia application stringent multimedia qos provision multimedia service task;resource allocation cloud computing multimedia systems quality of service;cloud computing;load management multimedia communication servers educational institutions cloud computing time factors	Cloud computing, as a new concept, provides a good solution for handling multimedia applications effectively and efficiently. It can facilitate the execution of complicated multimedia tasks, as well as supports specific and stringent multimedia QoS provisioning. However, for this new idea, a key challenge is how to make each multimedia service task to obtain the required resources in the shortest time. In this paper, we propose an effective load balancing approach for cloud-based multimedia system, called CMLB. Its main advantage is fully considering the load of all servers and the network conditions, and thus achieving reasonable resource allocation and scheduling. The evaluation results demonstrate the effectiveness of our approach.	algorithm;cloud computing;computational complexity theory;load balancing (computing);provisioning;quality of service;scheduling (computing);throughput	Wen Hui;Chuang Lin;Hai-ying Zhao;Yang Yang	2011	Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology	10.1109/EMEIT.2011.6022888	real-time computing;quality of service;cloud computing;resource allocation;computer science;load balancing;cloud testing;distributed computing;computer network	HPC	-18.762943668870516	65.62846275089257	158306
5cefb6d5bcfc43491cce010cb8d8f4fa3e34b32f	qos matching offset oriented resource clustering scheduling algorithm in grid environment	grid scheduling;task scheduling grid qos qos matching offset clustering;resource utilization;pattern clustering;collaborative work;design engineering;resource management;qos matching offset;qos;grid;resource clustering scheduling algorithm;scheduling grid computing pattern clustering quality of service;scheduling algorithm;clustering;scheduling;grid environment;scheduling algorithm quality of service clustering algorithms algorithm design and analysis resource management security grid computing collaborative work computer science design engineering;clustering algorithms;load balance;computer science;task scheduling;quality of service;security;grid computing;algorithm design and analysis;grid environment qos matching resource clustering scheduling algorithm;qos matching	With more and more research carried on in the QoS of Grid, QoS-based Grid task scheduling algorithm has become a hot research aspect. In this paper, various existing QoS-based Grid scheduling algorithms are analyzed firstly. And by introducing the conception of QoS matching offset between tasks and resources in Grid scheduling, resources and tasks can be clustering upon their offset in order that the resources in scheduling are able to be allocated on demand. Meanwhile, we take into consideration some parameters in the scheduling like QoS benefit value obtained by the task and some restricted condition: deadline of the task. The simulation results show that the algorithm's performance is better than most of the proposed algorithms in the aspects of effective resource utility, resource load balance, task acceptance rate and average QoS benefit value.	algorithm;angular defect;cluster analysis;computer cluster;directed acyclic graph;load balancing (computing);quality of service;scheduling (computing);simulation	Fang Dong;Junzhou Luo	2007	2007 11th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2007.4281506	fair-share scheduling;real-time computing;earliest deadline first scheduling;quality of service;dynamic priority scheduling;computer science;rate-monotonic scheduling;resource management;operating system;two-level scheduling;database;distributed computing;cluster analysis;scheduling	HPC	-17.980031330131588	62.80350075529831	158373
12aa71450f938054e86a1c738e16f1e18dac6824	evaluation of p2p streaming systems for webcast	electronic mail;bandwidth peer to peer computing schedules servers optimal scheduling computational modeling electronic mail;computer model;p2p;computer network performance evaluation;servers;computational modeling;internet;peer to peer computing computer network performance evaluation entertainment internet media streaming;optimal scheduling;waiting time;schedules;media streaming;interruption time p2p streaming system evaluation webcast peer to peer streaming technology movies network load distribution waiting time reduction computer simulation;bandwidth;peer to peer computing;peer to peer;computer simulation;entertainment	Due to the recent spread of streaming delivery of movies, streaming using Peer-to-Peer (P2P) streaming technology has attracted much attention. In P2P streaming systems, to distribute the network load, peers from which the user receives data is selected at random. For this, clients have to wait until their desired data is delivered. Therefore, there are many researches to reduce the waiting time. However, because of the complexity of the implementation, they usually evaluate these methods using computer simulations. In actual environment, indeed, interruption time is not always reduced by increasing clients to deliver data. To evaluate the effectiveness of P2P streaming systems, it is important to implement an actual P2P streaming system. In this paper, we evaluate a P2P streaming system. By using our implemented P2P streaming system, we investigate situations that its system is effective. As a result of our evaluation, we confirmed that interruption time is reduced effectively.	computer simulation;fast forward;interrupt;load balancing (computing);overhead (computing);peer-to-peer;scheduling (computing);streaming media	Yusuke Gotoh;Kentaro Suzuki;Tomoki Yoshihisa;Hideo Taniguchi;Masanori Kanazawa	2011	2011 Sixth International Conference on Digital Information Management	10.1109/ICDIM.2011.6093352	computer simulation;real time streaming protocol;entertainment;real-time computing;the internet;simulation;schedule;computer science;peer-to-peer;database;multimedia;computational model;law;bandwidth;server	HPC	-16.967100332343	72.24713722417061	158553
b73430d53ae75c97bb8d8e8b811c3d2e36158402	an unstructured termination detection algorithm using gossip in cloud computing environments	termination detection;gossip;unstructured algorithm;cloud computing	Determining termination in dynamic environments is hard due to node joining and leaving. In previous studies on termination detection, some structures, such as spanning tree or computational tree, are used. In this work, we present an unstructured termination detection algorithm, which uses a gossip based scheme to cope with scalability and fault-tolerance issues. This approach allows the algorithm not to maintain specific structures even when nodes join and leave during runtime. These dynamic behaviors are prevalent in cloud computing environments and little attention has been paid by existing approaches. To measure the complexity of our proposed algorithm, a new metric, self-centered message complexity is used. Our evaluation over scalable settings shows that an unstructured approach has a significant merit to solve scalability and fault-tolerance problems with lower message complexity over existing algorithms.	algorithm;cloud computing	JongBeom Lim;Kwang-Sik Chung;Joon-Min Gil;Taeweon Suh;Heon-Chang Yu	2013		10.1007/978-3-642-36424-2_1	gossip;real-time computing;cloud computing;computer science;theoretical computer science;operating system;distributed computing	HPC	-9.540827196651529	71.13169036326636	158654
0ad8d9cf294b33b5deeaa3cb820d0cbbc135fdb8	performance implications of chipset caches in web servers	cache storage;front end;file servers;performance evaluation;storage management;performance;prefetching;simulation framework;server chipset;future internet;process design;standards development;network servers;internet;web server network servers prefetching delay throughput read write memory standards development councils internet process design;internet usage;internet servers;chipset caches;memory requests;memory systems;councils;web server;read write memory;server chipset internet chipset caches internet servers web server prefetching performance memory requests;high performance;user satisfaction;performance evaluation storage management cache storage file servers internet;throughput	"""As Internet usage continues to expand rapidly, careful attention needs to be paid to the design of Internet servers for achieving high performance and end-user satisfaction. In this paper, with the aim of improving memory system performance of Internet servers, we propose and evaluate various design alternatives for """"chipset caches"""", a shared cache layer embedded within a server chipset. Using our trace-based cache simulation framework (CASPER) and SPECweb99 as a representative workload for web servers, we present the performance implications of chipset caches in a front-end dual-processor web server. We start by analyzing the improvement gained by caching the data from processor-initiated requests alone. We study the sensitivity to basic cache parameters (such as cache size and associativity) and also study the impact of prefetching into the chipset cache. We then present the performance implications of routing memory requests initiated by I/O devices through the chipset cache. Finally, we also study the implications of making the chipset cache inclusive. Based on detailed simulation data and its implications on system level performance, this paper shows that chipset caches have significant potential for future Internet servers."""	chipset;web server	Ravishankar K. Iyer	2003		10.1109/ISPASS.2003.1190244	process design;embedded system;file server;throughput;parallel computing;real-time computing;the internet;performance;cache;computer science;front and back ends;operating system;uncore;cache algorithms;cache pollution;web server	HPC	-10.107764340510895	66.88753619238638	158841
bf61d330c140c5be3b0570ce2b1995dc729f6ea4	performance analysis of cloud dvr for energy efficiency clustering strategy		Cloud digital video recorder (cDVR) is a new service that Comcast provides to its subscribers. The primary current legal interpretation approving cloud DVR relies on a single copy in the Cablevision decision. This makes the cDVR data center running cost very high. An asynchronous service system with categorizing users by cDVR usage is employed to reduce the energy consumption. In this system, cDVRs with similar usage schedule are constructed in one cluster. The cloud recording service on this cluster goes to sleep if there has been a period with no cDVR requests. When there are one or more cDVR request arrivals, those requests are buffered in queues while the cDVR service wakes up. In this paper, a 2-class Markov Geo/G/1/K vacation model is presented to analyze the performance of this system. Different scheduling policies are compared in the simulations and experiments.	computer cluster;digital video recorder;profiling (computer programming)	Zhen Zhao	2013		10.1007/978-3-319-05506-0_7	computer science;scheduling (computing);real-time computing;cluster analysis;data center;cloud computing;asynchronous communication;markov process;service system;markov chain	HPC	-16.636557773181174	67.13310866536057	158890
4982ac3a3830cecdc600e1e0ca3ae00d5af26ff5	high performance embedded route lookup coprocessor for network processors	distributed system;cam;fabricacion asistida por computador;haute performance;systeme reparti;mise a jour;informatique mobile;storage access;itineraire;itinerario;network processor;high performance networks;coprocessor;actualizacion;memory access;fabrication assistee;sistema repartido;route;energy consumption;coprocesador;computer aided manufacturing;coprocesseur;acces memoire;consommation energie;alto rendimiento;acceso memoria;information system;came;power consumption;leva;consommation energie electrique;mobile computing;high performance;systeme information;updating;consumo energia;sistema informacion	Embedded Route Lookup Coprocessors (RLCs) are attractive for their potential in building high-performance Network Processors. But compared with conventional lookup schemes, it always imposes more severe restrictions on table size and power consumption, which poses challenge in the state of art. In this paper, we propose a novel lookup mechanism, Compounded CAM with Optimized Bitmap Compression (CCAM-OBC), which employs different lookup methods for prefixes of different length ranges, so as to combine the benefits of CAMs and bitmap compressed tries. With this scheme, table size, power consumption and update complexity are all well optimized while very high lookup throughput is achieved, which makes it a perfect solution to embedded RLC. For a real-life 130K-prefix route table, the implemented prototype performs more than 100 Million Packets Per Second (MPPS) with only 24KB TCAM, 48KB BCAM and 251KB SRAM. Furthermore, each update needs only 2 memory accesses averagely.	algorithm;bitmap;coprocessor;embedded system;internet branding;lookup table;network processor;prototype;rlc circuit;real life;routing table;static random-access memory;telecommunications access method;throughput;trie	Kai Zheng;Zhen Liu;Bin Liu	2005		10.1007/11534310_22	route;embedded system;parallel computing;cam;telecommunications;computer science;operating system;mobile computing;information system;coprocessor;network processor	Mobile	-6.1395947206504955	64.33714337663908	158939
e6a4e0cfd1a6a09d62922a6646b4ebe9d8df1b64	meeting subscriber-defined qos constraints in publish/subscribe systems	content based;qos;publish subscribe	Current distributed publish/subscribe systems consider all participants to have similar QoS requirements and contribute equally to the system’s resources. However, in many real-world applications, the message delay tolerance of individual participants may differ widely. Disseminating messages according to individual delay requirements not only allows for the satisfaction of user-specific needs, but also significantly improves the utilization of the resources that participants contribute to a publish/subscribe system. In this article, we propose a peer-to-peer-based approach to satisfy the individual delay requirements of subscribers in the presence of bandwidth constraints. Our approach allows subscribers to dynamically adjust the granularity of their subscriptions according to their bandwidth constraints and delay requirements. Subscribers maintain the overlay in a decentralized manner, exclusively establishing connections that satisfy their individual delay requirements, and that provide messages exactly meeting their subscription granularity. The evaluations show that for many practical workloads, the proposed publish/subscribe system can scale up to a large number of subscribers and performs robustly in a very dynamic setting. Copyright 2011 John Wiley & Sons, Ltd.	algorithm;internet access;john d. wiley;overlay network;peer-to-peer;publish–subscribe pattern;quality of service;requirement;zipf's law	Muhammad Adnan Tariq;Boris Koldehofe;Gerald G. Koch;Imran Khan;Kurt Rothermel	2011	Concurrency and Computation: Practice and Experience	10.1002/cpe.1751	real-time computing;quality of service;computer science;database;distributed computing;publish–subscribe pattern;world wide web	SE	-15.003685664837818	72.97271696543382	159023
9117f2732494c3c54e01b5bb04e613e7dd1e02d5	hashed patricia trie: efficient longest prefix matching in peer-to-peer systems	longest prefix matching;distributed hash table;peer to peer system;hash table;data structure	The design of efficient search structures for peer-to-peer systems has attracted a lot of attention in recent years. In this paper we address the problem of longest prefix matching and present an efficient data structure called hashed Patricia trie. Our hashed Patricia trie supports Prefixsearch(x) and Insert(x) in O(log |x|) hash table accesses and Delete(x) in O(1) hash table accesses when |x| is the number of bits used to encode x. That is the costs only depend on |x| and not the size of the data structure. The hash table accesses may be realized by any distributed hash table (DHT).	longest prefix match;peer-to-peer;trie	Sebastian Kniesburges;Christian Scheideler	2011		10.1007/978-3-642-19094-0_18	hash table;double hashing;content addressable network;hash function;linear hashing;perfect hash function;extendible hashing;dynamic perfect hashing;merkle tree;rainbow table;data structure;primary clustering;sha-2;computer science;chord;theoretical computer science;hash chain;hash buster;database;distributed computing;hash list;rolling hash;hash array mapped trie;programming language;longest prefix match;cryptographic hash function;hash tree;hat-trie	Theory	-8.41664467632168	68.11871033223107	159148
3432f213f6674becbc0a9aa25c323e3d8943a907	online stable matching as a means of allocating distributed resources	distributed system;online algorithm;on line processing;reseau communication;systeme reparti;first come first serve;algoritmo adaptativo;resource allocation;stable matching;aproximacion;partage ressource;fifo system;approximation;tratamiento en linea;adaptive algorithm;systeme fifo;sistema repartido;algorithme adaptatif;heterogeneous distributed system;resource sharing;particion recursos;adaptive windowing;asignacion recurso;traitement en ligne;adaptive online stable matching aosm;allocation ressource;distributed resources;red de comunicacion;user satisfaction;communication network	In heterogeneous distributed systems, achieving optimali ty in both effective use of computational resources (e.g. throughput) and user satisfaction (e.g. re sponse time) is an important unresolved problem. If the users of the system participate dynamically as co nsumers as well as donors of computational resources, the task of optimizing the exchange of these comp utational resources leads to a combinatorial problem. As a solution, we propose a novel algorithm, Adaptive Online Stable Matching (AOSM). We present experimental data which compare the performance of AOSM with the performance of two alternative algorithms, First-come First-served (FCFS) a nd Fixed-k online.	atm turbo;algorithm;computation;computational resource;dos;distributed computing;fairness measure;quality of service;stable marriage problem;steady state;telecommunications network;throughput;world-system	Hyunyoung Lee	1999	Journal of Systems Architecture	10.1016/S1383-7621(98)00072-1	fifo;shared resource;online algorithm;real-time computing;simulation;stable marriage problem;resource allocation;computer science;approximation;distributed computing;telecommunications network	HPC	-12.86726436376815	64.31322678979022	159432
f8264001eac70865ec4739864add0d73895346d3	compressed bloom filters	cache storage;protocols;performance evaluation;arithmetic coding;data compression;bloom filter;limiting factor;distributed computing;computer networks;computer network;protocols randomized data structure performance web cache information proxies compressed bloom filters space efficient data structure membership queries error probability false positive probability computation per lookup processing time decompression arithmetic coding memory use computer networks information theory distributed computing distributed information systems;protocols data compression data structures performance evaluation internet cache storage error statistics arithmetic codes;distributed information systems;arithmetic codes;internet;distributed information system;data structures;error statistics;algorithms;false positive;data structures information filtering information filters broadcasting protocols digital filters costs arithmetic computer networks information theory;web caching;data structure;information theory	A Bloom filter is a simple space-efficient randomized data structure for representing a set in order to support membership queries. Although Bloom filters allow false positives, for many applications the space savings outweigh this drawback when the probability of an error is sufficiently low. We introduce compressed Bloom filters, which improve performance when the Bloom filter is passed as a message, and its transmission size is a limiting factor. For example, Bloom filters have been suggested as a means for sharing Web cache information. In this setting, proxies do not share the exact contents of their caches, but instead periodically broadcast Bloom filters representing their caches. By using compressed Bloom filters, proxies can reduce the number of bits broadcast, the false positive probability, and/or the amount of computation per lookup. The cost is the processing time for compression and decompression, which can use simple arithmetic coding, and more memory use at the proxies, which utilize the larger uncompressed form of the Bloom filter.	arithmetic coding;bloom filter;computation;data compression;data structure;lookup table;proxy server;randomized algorithm;web cache	Michael Mitzenmacher	2002	IEEE/ACM Trans. Netw.	10.1109/TNET.2002.803864	data compression;arithmetic coding;communications protocol;the internet;limiting factor;data structure;type i and type ii errors;computer science;theoretical computer science;bloom filter;database;distributed computing;statistics;computer network	Theory	-6.729858705204056	68.34580371774337	159695
58568f1d97434b0c53e4dcaad033d0f5a71be0f7	an auction mechanism for allocating the bandwidth of networks to their users	estensibilidad;optimal solution;evaluation performance;optimisation;dutch;solution optimale;networks;social welfare;performance evaluation;parametro s;optimizacion;parametre s;holandes;complexite calcul;asymmetry;resource allocation;pricing;efficiency;evaluacion prestacion;vickrey clarke groves;resource management;prior information;problema np duro;bandwidth markets;asymetrie;fijacion precios;optimization problem;np hard problem;gestion recursos;complejidad computacion;informacion a priori;probleme np difficile;computational complexity;solucion optima;subasta;bidding;s parameter;gestion ressources;asimetria;neerlandais;optimization;extensibilite;enchere;scalability;asignacion recurso;allocation ressource;market efficiency;information a priori;fixation prix;auctions	We present a mechanism for auctioning bandwidth on a network-wide basis to end users or ISPs that will utilize it for the same time period. This mechanism consists of a set of simultaneous multi-unit descending-price (i.e. Dutch) auctions, one per link of the network. The per unit prices of bandwidth at the various links are asymmetric, thus reflecting the asymmetry of demand for these links. A user can be instantly allocated bandwidth over a certain path, by simultaneously bidding for the quantity desired at all relevant auctions. This winner determination rule is complemented by a payment rule of the VCG (Vickrey–Clarke–Groves) type, which provides users with the incentive to bid truthfully, thus simplifying bidding. Also, the mechanism enables the auctioneer to use his prior information on market demand anticipated and its spreading among the various links in order to set effectively the auction’s parameters. We argue that our mechanism attains nearly efficient allocation of the network’s bandwidth (i.e. the resulting social welfare is close to the respective maximum for the quantity decided to be sold by the auctioneer), while it is simple, scalable and applicable to real networks, even for auctioning the capacity of links owned by multiple providers and then splitting the revenue among them. Alternatively, the mechanism offers the provider the opportunity to optimize his revenue, rather than the social welfare. Since our mechanism’s computational complexity is low it can serve as a fast, practical, and near-optimal solution to a generally NP-hard optimization problem. 2007 Elsevier B.V. All rights reserved.	bandwidth (signal processing);computational complexity theory;edmund m. clarke;mathematical optimization;np-hardness;optimization problem;scalability	Manos Dramitinos;George D. Stamoulis;Costas A. Courcoubetis	2007	Computer Networks	10.1016/j.comnet.2007.08.007	pricing;optimization problem;scalability;bidding;telecommunications;resource allocation;computer science;efficient-market hypothesis;resource management;np-hard;social welfare;efficiency;scattering parameters;computational complexity theory;computer security;asymmetry	ECom	-10.75108315917371	68.09626192835796	159711
55564969f049f48ac702a3309f3837c8922aeab4	transmission reduction between mobile phone applications and restful apis	wireless links;query language;smart phone;mobile computer;rest;mobile phone;mobile web;mobile mashup applications;mobile computing;mobile application	Recently, the popularity of mobile smart phones has fostered the development of a variety of mobile Mashup applications. A mobile Mashup application retrieves and glues together resources on the Web to create a new service. Compared with mobile Web browsers, mobile Mashup applications provide users with fancy GUIs and specialized services. Thus, mobile Mashup applications have become a significant role on mobile phones. Due to low-bandwidth wireless links and limited battery capacity, a large number of transmissions of mobile applications is prohibitive. However, because mobile clients mainly use mobile Web browsers to access the Web, prior work only focused on reducing the data sent to mobile Web browsers. In this paper, we present a proxy system as well as several techniques to reduce the volume of transmissions sent from and received by mobile Mashup applications based on the observations on characteristics of RESTful APIs. We propose an API query language (AQL), which enables mobile applications to batch multiple RESTful API method calls into one single query, thereby reducing the number of HTTP requests and responses. In addition, we employ an image multi-get module and Gzip compression module for image and text transmission reduction, respectively. The experimental results show that the proposed system and techniques effectively reduces the number of HTTP requests and responses and sizes of packets.	android;application programming interface;data compression;download;hypertext transfer protocol;mashup (web application hybrid);mobile app;mobile phone;netbsd gzip / freebsd gzip;picasa;query language;representational state transfer;smartphone;world wide web	Chin-Liang Tsai;Hsiao-Wen Chen;Jiun-Long Huang;Chih-Lin Hu	2011		10.1145/1982185.1982280	web service;radio access network;embedded system;mobile identification number;mobile search;mobile web;wireless application protocol;gsm services;mobile processor;mobile database;computer science;operating system;mobile technology;database;rest;mobile deep linking;internet privacy;mobile station;mobile computing;world wide web;mobile communications over ip;computer security;query language;mashup;mobile payment	Mobile	-18.90988803474459	74.2114182788203	159967
cdcfc165fc66aefa5393fdbdac6151bda8177993	classification of web caching systems.	web caching	The Internet has been experiencing a phenomenal growth in the past decade. The World Wide Web has also been growing at the same rate. Web traffic comprises two thirds of all the activity on the Internet. The growth is in terms of increasing numbers of servers, and increasing numbers of users that want to access the huge amounts of information distributed at vast geographical sites. Therefore, it was necessary to implement cache systems (e.g., distributed or hierarchical) to reduce network bandwidth demand, reduce latency, and move data near clients to improve performance. This paper provid es all the design principles and issues considered when designing web-caching systems, and provides several case studies of cache systems employed on the Internet.	bottleneck (software);cpu cache;cache (computing);data access;data compression;directory (computing);image scaling;internet;lookup table;multicast;network performance;server (computing);web cache;web traffic;world wide web	Maytham Safar	2002			data web	Metrics	-17.05805040051196	73.35592619748233	160059
27f646e20a8279d073f6ac36e5661e2698f411a2	analysis and evaluation of grid scheduling algorithms using real workload traces	grid scheduling;distributed system;software tool;cluster;computational grid;performance evaluation;simulation;workload modeling;performance comparison;performance metric;large scale;scheduling algorithm;task synchronization;statistical analysis;load balancing;robustness;load balance;distributed systems;grid computing;parallel processing	Computational grid has the potential for solving large-scale scientific problems using distributed resources. Grid scheduling is a vital component of a Computational Grid infrastructure. In this paper, we evaluate our proposed Grid scheduling algorithms (the Multilevel Hybrid Scheduling Algorithm and the Multilevel Dual Queue Scheduling Algorithm) using real workload traces, taken from leading computational centers. An extensive performance comparison is presented using real workload traces to evaluate the efficiency of scheduling algorithms. To facilitate the research, a software tool has been developed which produces a comprehensive simulation of a number of Grid scheduling algorithms. The tool's output is in the form of scheduling performance metrics.  The experimental results, based on performance metrics, demonstrate that the performances of our Grid scheduling algorithms give good results. Our proposed scheduling algorithms also support true scalability, that is, they maintain an efficient approach when increasing the number of CPUs or nodes. This paper also includes a statistical analysis of workload traces to present the nature and behavior of jobs.		Syed Nasir Mehmood Shah;Ahmad Kamil Mahmood;Alan Oxley	2010		10.1145/1936254.1936298	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel processing;parallel computing;real-time computing;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;load balancing;genetic algorithm scheduling;two-level scheduling;distributed computing;least slack time scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling	HPC	-16.59664465272373	60.82816915521531	160246
32f3f7fc4b1addb455d9d170e11af61bc8593e2b	an efficient method for assigning harmonic periods to hard real-time tasks with period ranges	rate monotonic scheduling algorithm;period assignment;processor scheduling;period range;data structure size real time systems quality of service system schedulability schedulability analysis rate monotonic scheduling algorithm rm scheduling algorithm harmonic period assignment problem necessary and sufficient conditions pseudopolynomial computational complexity heuristic algorithm low utilization harmonic task sets task set utilization;schedulability analysis;harmonic period assignment problem;data structure size;harmonic analysis real time systems computational complexity heuristic algorithms discrete cosine transforms safety time factors;time factors;rm scheduling algorithm;task set utilization;computational complexity;discrete cosine transforms;heuristic algorithms;safety;necessary and sufficient conditions;hard deadline real time systems period range period assignment harmonic tasks;system schedulability;quality of service;real time systems computational complexity processor scheduling;heuristic algorithm;low utilization harmonic task sets;pseudopolynomial computational complexity;real time systems;hard deadline;harmonic tasks;harmonic analysis	During the design phase of many real-time systems, designers often have a range of acceptable period values for which some levels of safety or quality of service are guaranteed. The choice of period values influences system schedulability and computational complexity of schedulability analysis, especially for the rate monotonic (RM) scheduling algorithm. It has been shown that RM guarantees 100% utilization if the periods are harmonic, i.e., Each period is an integer multiple of shorter periods. In this paper, we address harmonic period assignment problem where each task has a given period range. We extend the results of our previous work and present an O(n^2log(n)) algorithm (where n is the number of tasks) to verify necessary and sufficient conditions for the existence of a harmonic period assignment in cases where the previous solution has pseudo-polynomial computational complexity. We provide utilization bounds of the potential assignments as well as a heuristic algorithm to construct low utilization harmonic task sets. The efficiency of our period assignment algorithms has been evaluated in terms of acceptance ratio, task set utilization, data structure size, and the number of operations required for harmonic period assignment.	algorithm;assignment problem;backward induction;computational complexity theory;data structure;heuristic (computer science);polynomial;quality of service;real-time clock;real-time computing;real-time transcription;scheduling (computing);scheduling analysis real-time systems;time complexity	Mitra Nasri;Gerhard Fohler	2015	2015 27th Euromicro Conference on Real-Time Systems	10.1109/ECRTS.2015.21	heuristic;mathematical optimization;real-time computing;quality of service;computer science;harmonic analysis;distributed computing;computational complexity theory	Embedded	-10.088698527220155	62.22232154928943	160732
6d3acc00828f4f0e2e3a1325c001b50eb2647e80	an asynchronous recovery scheme based on optimistic message logging for mobile computing systems	distributed system;wireless networks;frequency synchronization;checkpointing only schemes;fault tolerant;unreliable mobile hosts;mobile computing checkpointing bandwidth computer networks distributed computing space stations frequency synchronization computer science fault tolerant systems wireless networks;distributed computing;mobile host;mobile computing system;mobile computer;fragile network connection;optimistic message logging;logging;checkpointing;computer networks;mobility tracking asynchronous recovery scheme optimistic message logging mobile computing fault tolerance checkpointing only schemes unreliable mobile hosts fragile network connection logging dependency tracking;mobile environment;fault tolerant computing;system recovery;network connectivity;fault tolerant systems;asynchronous recovery scheme;fault tolerance;message passing system recovery mobile computing wireless lan fault tolerant computing;mobility tracking;space stations;message passing;bandwidth;wireless lan;computer science;distributed systems;mobile systems;mobile computing;message logging;asynchronous recovery;dependency tracking	To provide the fault-tolerance for the mobile computing sys tems, many checkpointing-based recovery schemes have been proposed. However, considering the na tur of the mobile environment in which some mobile hosts (MHs) are often disconnected from the netw ork and the probability of concurrent failures on MHs is high, any kind of coordination during the c he kpointing and even during the recovery may not be recommended. In this paper, we propose an async hronous recovery scheme based on the optimistic message logging. Logging-based schemes hav e m ny advantages such as asynchronous recovery, handling of concurrent failures, and independen t checkpointing. However, for the efficient implementation, the followings must be considered: First, me ssage logging itself can be a burden on the MHs; and second, the information for the dependency trackin g can be a problem, if it has to be added to the message between the MH and the mobile support station ( MSS). In the proposed scheme, to cope with such problems, the tasks of logging and dependency trac king are fully performed by the MSSs. MHs are only carrying the minimum information, so that, the m obility of the MHs can properly traced by the MSSs. As a result, with a little overhead, optimistic m essage logging and asynchronous recovery can be implemented in the mobile environment.	application checkpointing;asynchronous i/o;fault tolerance;mobile computing;modified huffman coding;numerical aperture;ork;overhead (computing);trac	Taesoon Park;Heon Young Yeom	2000		10.1109/ICDCS.2000.840956	fault tolerance;real-time computing;computer science;operating system;distributed computing;mobile computing;computer network	DB	-7.575257373318665	71.6684488245097	161210
2b74791c93c53bc2e9d94092e8d42b933db0462b	on the inherent cost of atomic broadcast and multicast in wide area networks	fault tolerant;fault tolerant system;low latency;atomic broadcast;wide area network	In this paper, we study the atomic broadcast and multicast problems, two fundamental abstractions for building fault-tolerant systems. As opposed to atomic broadcast, atomic multicast allows messages to be addressed to a subset of the processes in the system, each message possibly being multicast to a different subset. Our study focuses on wide area networks where groups of processes, i.e., processes physically close to each other, are inter-connected through high latency communication links. In this context, we capture the cost of algorithms, denoted latency degree, as the minimum number of inter-group message delays between the broadcasting (multicasting) of a message and its delivery. We present an atomic multicast algorithm with a latency degree of two and show that it is optimal. We then present the first fault-tolerant atomic broadcast algorithm with a latency degree of one. To achieve such a low latency, the algorithm is proactive, i.e., it may take actions even though no messages are broadcast. Nevertheless, it is quiescent: provided that the number of broadcast messages is finite, the algorithm eventually ceases its operation.	algorithm;atomic broadcast;fault tolerance;multicast;proactive parallel suite	Nicolas Schiper;Fernando Pedone	2008		10.1007/978-3-540-77444-0_12	broadcast radiation;fault tolerance;real-time computing;multicast;atomic broadcast;computer science;distributed computing;source-specific multicast;multimedia broadcast multicast service;computer network	Theory	-7.584506698397032	72.0354786101474	161476
adeb0058afe2ff3a27f5615d680b0bd6c2b36b33	netmap: memory mapped access to network devices	similar performance;device driver overhead;network device;maps packet buffer;per-packet system call;wire-speed packet processing;memory mapped access;simpler device driver operation;data copying;clock speed;standard os path;clock cycle;operating system;packet forwarding	Recent papers have shown that wire-speed packet processing is feasible in software even at 10~Gbit/s, but the result has been achieved taking direct control of the network controllers to cut down OS and device driver overheads.  In this paper we show how to achieve similar performance in safer conditions on standard operating systems. As in some other proposals, our framework, called netmap, maps packet buffers into the process' memory space; but unlike other proposals, any operation that may affect the state of the hardware is filtered by the OS. This protects the system from crashes induced by misbehaving programs, and simplifies the use of the API.  Our tests show that netmap takes as little as 90 clock cycles to move one packet between the wire and the application, almost one order of magnitude less than using the standard OS path. A single core at 1.33~GHz can send or receive packets at wire speed on 10~Gbit/s links (14.8~Mpps), with very good scalability in the number of cores and clock speed.  At least three factors contribute to this performance: i) no overhead for encapsulation and metadata management; ii) no per-packet system calls and data copying (ioctl()s are still required, but involve no copying and their cost is amortized over a batch of packets); iii) much simpler device driver operation, because buffers have a plain and simple format that requires	amortized analysis;application programming interface;clock rate;clock signal;dspace;device driver;encapsulation (networking);ioctl;map;network packet;operating system;overhead (computing);scalability;system call	Luigi Rizzo;Matteo Landi	2011		10.1145/2018436.2018500	embedded system;real-time computing;computer science;operating system;distributed computing;packet forwarding;computer security;computer network	OS	-5.64966042920852	68.83043041672364	161586
a290ab3546d13bbfbd223847ffc8b20761e35bda	a2dlt: divisible load balancing model for scheduling communication-intensive grid applications	grid applications;divisible load theory;load balancing;load balance;power modeling;grid system;data grid	Scheduling an application in data grid is significantly complex and very challenging because of its heterogeneous in nature of the grid system. Divisible Load Theory (DLT) is a powerful model for modelling data-intensive grid problem where both communication and computation loads are partitionable. This paper presents a new divisible load balancing model known as adaptive ADLT (A2DLT) for scheduling the communication intensive grid applications. This model reduces the maximum completion time (makespan) as compared to the ADLT and Constraint DLT (CDLT) models. Experimental results showed that the model can balance the load efficiently, especially when the communication-intensive applications are considered.		Mohamed Othman;Monir Abdullah;Hamidah Ibrahim;Subramaniam Shamala	2008		10.1007/978-3-540-69384-0_30	parallel computing;real-time computing;computer science;load balancing;distributed computing	HPC	-16.47851223222174	61.13772255666541	161990
bf36cc979406b6310031b79031ecba4bca2f7042	adaptive scheduling techniques for multimedia computing in hard real-time systems	processor scheduling;bandwidth allocation;mpeg video;satisfiability;dynamic control;multimedia computing;simulation experiment;video coding;hard real time system;multimedia communication;adaptive scheduling;server based mechanism adaptive scheduling multimedia computing hard real time systems bandwidth allocation mpeg applications;video coding adaptive scheduling multimedia computing bandwidth allocation multimedia communication real time systems processor scheduling;adaptive scheduling multimedia computing real time systems;hard real time;real time systems;time constraint	In this paper, we propose adaptive scheduling and bandwidth allocation techniques to efficiently integrate multimedia tasks for MPEG applications in hard real-time systems. The paper describes a server-based mechanism for assigning the CPU resource to hard real-time tasks and multimedia tasks, respectively. Especially for MPEG video applications, we show how to dynamically control the fraction of the CPU bandwidth allocated to each multimedia task according to the priority. The primary purpose of these techniques is to minimize the mean tardiness of multimedia tasks while satisfying the timing constraints of hard real-time tasks. The performance of the proposed scheduling techniques is compared with that of similar mechanisms through simulation experiments.	real-time operating system;real-time transcription;scheduling (computing)	Jinhwan Kim;Namyun Kim;Bonggyou Lee	2003		10.1109/DISRTA.2003.1242996	embedded system;real-time computing;computer science;distributed computing	Embedded	-10.741758395949907	63.00957581052946	162083
768baaab3247a8b6969f4f3b81ebfcb1627907a3	low complexity content replication through clustering in content-delivery networks	content replication;content clustering;content-delivery networks;coordinated caching	Contemporary Content Delivery Networks (CDN) handle a vast number of content items. At such a scale, the replication schemes require a significant amount of time to calculate and realize cache updates, and hence they are impractical in highly-dynamic environments. This paper introduces cluster-based replication, whereby content items are organized in clusters according to a set of features, given by the cache/network management entity. Each cluster is treated as a single item with certain attributes,  e.g. , size, popularity,  etc.  and it is then altogether replicated in network caches so as to minimize overall network traffic. Clustering items reduces replication complexity; hence it enables faster and more frequent caches updates, and it facilitates more accurate tracking of content popularity. However, clustering introduces some performance loss because replication of clusters is more coarse-grained compared to replication of individual items. This tradeoff can be addressed through proper selection of the number and composition of clusters. Due to the fact that the exact optimal number of clusters cannot be derived analytically, an efficient approximation method is proposed. Extensive numerical evaluations of time-varying content popularity scenarios allow to argue that the proposed approach reduces core network traffic, while being robust to errors in popularity estimation.	cluster analysis;content delivery network	Lazaros Gkatzikis;Vasilis Sourlas;Carlo Fischione;Iordanis Koutsopoulos	2017	Computer Networks	10.1016/j.comnet.2017.04.043	computer science;computer network;distributed computing;hardware architecture;cluster analysis;real-time computing;cache;network management;core network;popularity	Theory	-14.11552900636013	73.22885829898743	162706
b361e5a52343d30d7fbd1de60b6d6f424ba8bdd0	routing on longest-matching prefixes	communication system;access control list;reseau transmission donnee;protocole transmission;routing;network operating systems;reseau ordinateur;teleinformatica;access control lists longest matching prefixes routing dynamic prefix tries data structure insertion deletion retrieval dynamic database binary keys compact digital tries input key operating system kernels small code size minimal storage computational efficiency communication systems networking functions address resolution maintenance verification;routing databases information retrieval binary sequences data structures operating systems kernel access protocols upper bound computational efficiency;tree data structures;access protocol;computer networks;computer network;algorithme;algorithm;teleinformatique;protocolo transmision;data transmission network;telecommunication network routing;operating system;estructura datos;red transmision datos;red ordenador;access protocols;code size;structure donnee;encaminamiento;operating system kernels telecommunication network routing computer networks access protocols tree data structures network operating systems;operating system kernels;protocole acces;computational efficiency;high performance;remote data processing;data structure;acceso protocolo;acheminement;algoritmo;transmission protocol	This article describes the dyynamic p r e f i x tries'-a novel data structure with algorithms for insertion, deletion, and retrieval to build and maintain a dynamic database of binary keys of arbitrary length. These tries extend the concepts of compact digital (Patricia) tries to support the storage of prefixes and to guarantee retrieval times at most linear in the length of the input key irrespective of the trie size, even when searching for longest-matching prefixes. The new design permits very efficient, simple and nonrecursive implementations of small code size and minimal storage requirements. Insert and delete operations have strictly local effects, and their particular sequence is irrelevant for the structure of the resulting trie, thus maintaining at all times the desired storage and computational efficiency. The algorithms have been successfully employed in experimental communication systems and products for a variety of networking functions such as address resolution, maintenance and verification of access control lists, and high-performance routing tables in operating system kernels.	access control list;algorithm;computation;data structure;kernel (operating system);operating system;relevance;requirement;routing table;trie	Willibald A. Doeringer;Günter Karjoth;Mehdi Nassehi	1996	IEEE/ACM Trans. Netw.	10.1109/90.503764	routing;data structure;telecommunications;computer science;theoretical computer science;operating system;database;distributed computing;tree;communications system;computer network	Theory	-6.106777551220719	68.1472705666645	162712
c6a371fd1234f5b23c047ee2746e2a66485dc254	scalable web service discovery on p2p overlay network	semantic web service;load balancing web service discovery p2p overlay network peer to peer network skip graph servicelndex system semantic web services description language tree data structure;p2p overlay network;protocols;owl;web service discovery;peer to peer network;servicelndex system;resource allocation;p2p;tree data structures;web service;system performance;systems engineering and theory;web services peer to peer computing aggregates load management scalability protocols owl programming switching systems systems engineering and theory;tree data structure;aggregates;indexation;web services;load management;load balancing;semantic web;overlay network;scientific communication;semantic web services description language;skip graph;load balance;switching systems;scalability;service discovery;peer to peer computing;peer to peer;programming;web services peer to peer computing resource allocation semantic web tree data structures	Decentralized approaches for Web services discovery, such as peer-to-peer, become more and more attention - getting in the scientific community. In this paper, we propose a peer-to-peer framework, which adopts an enhanced skip graph named Servicelndex as the overlay network for service discovery. To guarantee discovery efficiency, Servicelndex schemed WSDL-S (Web services semantics) as semantic Web services description language and extracted its semantic attributes as indexing keys in skip graph. Also a multi-layer P2P overlay network was constructed to aggregate similar keys and keep load balancing on peer nodes. The evaluation showed that the Servicelndex system performs considerable service discovery efficiency.	aggregate data;experiment;layer (electronics);load balancing (computing);locality of reference;newsml;overlay network;peer-to-peer;quantum fluctuation;semantic web service;semantic search;service discovery;skip graph;web services description language;web services discovery;web services semantics;xml	Gang Zhou;Jianjun Yu;Rui Chen;Hui Zhang	2007	IEEE International Conference on Services Computing (SCC 2007)	10.1109/SCC.2007.95	web service;computer science;semantic web stack;database;service discovery;world wide web;universal description discovery and integration;computer network	DB	-12.651845683703012	74.01312139844453	163331
daacb3c336b631580d8c92530383ce247d491cd4	design, implementation and performance evaluation of software openflow flow counters in a bare metal commodity switch	software;protocols;metals;radiation detectors;telecommunication switching application specific integrated circuits protocols software defined networking software performance evaluation switching circuits;proceedings paper;bit rate 10 gbit s software openflow flow counter design performance evaluation software openflow flow counter implementation bare metal commodity switch line rate operations large flow based sdn network hardware counters switching asic;switches;switches radiation detectors software hardware metals central processing unit protocols;central processing unit;hardware	In this paper, we designed, implemented, and evaluated the performance of software OpenFlow flow counters in a bare metal commodity switch. Normally, flow counters are implemented in hardware for line-rate operations and their number needs to be very large to support a large flow-based SDN network. Although these hardware counters operate very fast, they greatly increase the cost of an OpenFlow switch. In addition, due to the limited chip size of the switching ASIC used in an OpenFlow switch, the number of hardware counters cannot scale to a large number. To overcome these drawbacks, we designed and implemented software flow counters in a 48 port × 10 Gbps (port bandwidth) bare metal commodity switch and evaluated their performance and limitations. This paper also reports important findings obtained from this practical work.	application-specific integrated circuit;bare machine;central processing unit;data rate units;dynamic random-access memory;linux;network packet;network switch;open-source software;openflow;operating system;performance evaluation;prototype;software-defined networking;throughput	Shie-Yuan Wang;Szu-Yu Liu;Chih-Liang Chou	2016	2016 IEEE Symposium on Computers and Communication (ISCC)	10.1109/ISCC.2016.7543811	embedded system;communications protocol;parallel computing;real-time computing;network switch;computer science;operating system;central processing unit;particle detector;computer security;computer network	Security	-5.973814636628653	65.84620087168108	163564
9f43507c6258fdf421bcf1a3a910ba0c3181ebcf	the parallel optimization of network bandwidth allocation based on generalized particle model	teletrafic;algoritmo paralelo;resource utilization;multiobjective programming;evaluation performance;programmation multiobjectif;optimisation;congestion trafic;parallel algorithm;performance evaluation;optimizacion;congestion trafico;resource allocation;implementation;bandwidth allocation;evaluacion prestacion;reseau ordinateur;simulation;resource management;projection method;multi objective optimization;simulacion;lagrange multiplier;computer networks;algorithme parallele;computer network;optimization problem;mouvement particule;gestion recursos;multiple objectives;teletrafico;methode projection;traffic congestion;particle motion;computational complexity;methode lagrange;force field;movimiento particula;algorithme reparti;metodo proyeccion;metodo lagrange;multiplicateur lagrange;teletraffic;multiplicador lagrange;red informatica;gestion ressources;lagrangian method;algoritmo repartido;optimization;kinematics and dynamics;asignacion recurso;allocation ressource;implementacion;distributed parallel algorithm;particle modeling;generalized particle model;distributed algorithm;hardware implementation;allocation bande passante;supply and demand;numerical simulation;duality model;programacion multiobjetivo	This paper presents a new duality approach to optimize the resource assignment and bandwidth allocation in networks, which is based on the generalized particle model (GPM). By the GPM, the network's optimization problem is transformed into the kinematics and dynamics of numerous particles in two reciprocal dual force-fields. Like the Kelly's duality model and Low's duality model related to Lagrangian multipliers methods (LMM), the GPM-based duality model also contains two distributed algorithms for resource supplies and resource demands, respectively, and can be carried out in parallel. Both the LMM-based and GPM-based duality models may not only embody the market mechanism between the supplies and demands very well, but also may describe the influence of congestion degree of networks on the resource allocation. But the GPM-based duality model is different from other duality models in terms of the basic principle, mathematical formalization, and properties. Features of the GPM-based duality model and the corresponding duality algorithm include a powerful processing ability in a complex environment that involves the priority, personality, autonomy, and interaction of different entities in networks. Furthermore, the GPM-based duality model can realize the optimization of multiple objectives, including the aggregate utility, the personal utility, the minimal personal utility, the resource utilization, and the users' satisfactory degree. The proposed approach also has the advantages in terms of the higher parallelism, lower computation complexity, and the ease for hardware implementation. The properties of the GPM-based duality model, including the correctness, convergency and stability, are discussed in detail. The numerous simulations on the network bandwidth allocation have shown the effectiveness and suitability of the proposed approach.		Dianxun Shuai;Xiang Feng	2006	Computer Networks	10.1016/j.comnet.2005.05.033	optimization problem;distributed algorithm;mathematical optimization;in situ resource utilization;simulation;telecommunications;resource allocation;computer science;resource management;multi-objective optimization;force field;supply and demand;parallel algorithm;projection method;lagrange multiplier;computational complexity theory;implementation;magnetosphere particle motion;computer network;bandwidth allocation	Theory	-15.663922528558427	64.68264039388123	163598
071564b3b65a03bfd73773fbbef62dcb3bf8d895	distributed hash sketches: scalable, efficient, and accurate cardinality estimation for distributed multisets	busqueda informacion;distributed data;estensibilidad;distributed system;distributed estimation;agregacion;nudo estructura;data sharing;evaluation performance;optimisation;nodes;tunable circuit;systeme reparti;mise a jour;storage access;performance evaluation;optimizacion;peer to peer network;distributed hash table;building block;distribucion carga;information retrieval;par a par;evaluacion prestacion;performance;reseau ordinateur;circuit accordable;pregunta documental;transmission message;probabilistic approach;distributed information retrieval;satisfiability;aggregation;message transmission;estimator;computer network;partage des ressources;equite;actualizacion;estimador;equidad;accuracy;distributed information systems;equity;sistema repartido;precision;internet;poste a poste;distributed information system;recherche information;enfoque probabilista;approche probabiliste;distributed data summary structures;logiciel libre;resource sharing;acces memoire;particion recursos;distributed cardinality estimation;query;agregation;distribution charge;acceso memoria;red informatica;algorithms;software libre;load distribution;design;noeud structure;circuito acordable;optimization;load balance;extensibilite;scalability;experimental evaluation;information system;experimentation;peer to peer;hash sketches;systeme information;updating;requete;open source software;transmision mensaje;open source;sistema informacion;peer to peer networks and systems;estimateur	Counting items in a distributed system, and estimating the cardinality of multisets in particular, is important for a large variety of applications and a fundamental building block for emerging Internet-scale information systems. Examples of such applications range from optimizing query access plans in peer-to-peer data sharing, to computing the significance (rank/score) of data items in distributed information retrieval. The general formal problem addressed in this article is computing the network-wide distinct number of items with some property (e.g., distinct files with file name containing “spiderman”) where each node in the network holds an arbitrary subset, possibly overlapping the subsets of other nodes. The key requirements that a viable approach must satisfy are: (1) scalability towards very large network size, (2) efficiency regarding messaging overhead, (3) load balance of storage and access, (4) accuracy of the cardinality estimation, and (5) simplicity and easy integration in applications. This article contributes the DHS (Distributed Hash Sketches) method for this problem setting: a distributed, scalable, efficient, and accurate multiset cardinality estimator. DHS is based on hash sketches for probabilistic counting, but distributes the bits of each counter across network nodes in a judicious manner based on principles of Distributed Hash Tables, paying careful attention to fast access and aggregation as well as update costs. The article discusses various design choices, exhibiting tunable trade-offs between estimation accuracy, hop-count efficiency, and load distribution fairness. We further contribute a full-fledged, publicly available, open-source implementation of all our methods, and a comprehensive experimental evaluation for various settings.	distributed computing;distributed hash table;fairness measure;information retrieval;information system;information theory;load balancing (computing);open-source software;overhead (computing);peer-to-peer;requirement;scalability	Nikos Ntarmos;Peter Triantafillou;Gerhard Weikum	2009	ACM Trans. Comput. Syst.	10.1145/1482619.1482621	computer science;theoretical computer science;operating system;database;distributed computing;accuracy and precision;statistics;computer network	DB	-11.088768234183943	70.35761114348595	163881
5b7767172d606974355099e8944d9eb9f6278c4c	a complex network-based approach for job scheduling in grid environments	processing element;stochastic method;optimization technique;complex network;simulated annealing;system performance;degree distribution;scale free;genetic algorithm;grid computing;job scheduling	Many optimization techniques have been adopted for efficient job scheduling in grid computing, such as: genetic algorithms, simulated annealing and stochastic methods. Such techniques present common problems related to the use of inaccurate and out-of-date information, which degrade the global system performance. Besides that, they also do not properly model a grid environment. In order to adequately model a real grid environments and approach the scheduling using updated information, this paper uses complex network models and the simulated annealing optimization technique. The complex network concepts are used to better model the grid and extract environment characteristics, such as the degree distribution, the geodesic path, latency. The complex network vertices represent grid process elements, which are generalized as computers. The random and scale free models were implemented in a simulator. These models, associated with Dijkstra algorithm, helps the simulated annealing technique to find out efficient allocation solutions, which minimize the application response time.	complex network;computer;degree distribution;dijkstra's algorithm;genetic algorithm;grid computing;interconnection;internet;job scheduler;job shop scheduling;mathematical optimization;response time (technology);scheduling (computing);simulated annealing;simulation;vertex (geometry);vertex (graph theory)	Renato Porfirio Ishii;Rodrigo Fernandes de Mello;Laurence Tianruo Yang	2007		10.1007/978-3-540-75444-2_24	mathematical optimization;genetic algorithm;degree distribution;simulated annealing;computer science;theoretical computer science;job scheduler;operating system;scale-free network;distributed computing;computer performance;adaptive simulated annealing;complex network;grid computing	HPC	-14.616173210588439	62.38195956287837	163938
dcbd08fd3f330cde94752a177d426707d937d609	a policy-driven scheduler for a time-sharing system	level of service;real time;data processing;time sharing;operating system;scheduling;scheduler;resource allocation and swapping	The services received by a process from a time-sharing operating system can be characterized by a resource count ∑ <italic>w</italic><subscrpt><italic>i</italic></subscrpt><italic>R</italic><subscrpt><italic>ij</italic></subscrpt> where <italic>R</italic><subscrpt><italic>ij</italic></subscrpt> is the number of units of service received by process <italic>j</italic> from resource <italic>i</italic> and <italic>w</italic><subscrpt><italic>i</italic></subscrpt> is the cost per unit of the service. Each class of users can be characterized by a policy function which specifies the amount of service a user who belongs to this class should receive as a function of time. Priority changes dynamically as a function of the difference between the service promised to the user by the policy function and the service he actually receives. A scheduling and swapping algorithm which keeps the resource count of each process above its policy function will provide the specified level of service. Overhead can be reduced by avoiding swaps of processes which have received at least this level of service. The algorithm has been implemented in a general purpose operating system, and it has provided significantly better service to interactive and to batch jobs than the previous scheduler.	algorithm;bellman equation;job stream;operating system;paging;scheduling (computing);time-sharing	Arthur J. Bernstein;J. C. Sharp	1971	Commun. ACM	10.1145/362515.362520	real-time computing;data processing;computer science;operating system;distributed computing;level of service;scheduling;time-sharing	Networks	-14.026350238580168	64.71207638725122	164103
bb2baa4dce7494210730dfc57c37fdd41beab95c	bus bandwidth management in a high resolution video workstation	high resolution;management system;resource manager;bandwidth management;time constraint	Time-Critical Computing encompasses that set of applications to which correctness of operation is a function of time. Applications that manipulate digital audio and video frequently have timeliness requirements associated with their correct function. These applications must perform operations such as the acquisition, processing, and delivery of audio or video data within a specified set of time constraints (as defined by the user, the application, or the media itself) or the value of the computation is significantly diminished. Furthermore, a system's effectiveness may be reduced if it permits computations to consume resources when they can no longer provide value to the user (e.g., after their deadlines are missed). A technique known as Time-Driven Resource Management (TDRM) has been developed to manage system resources, and this paper describes the application of this technique to the management of i/o bus bandwidth within an experimental integrated video workstation.	bandwidth management;workstation	Gerard A. Wall;James G. Hanko;J. Duane Northcutt	1992		10.1007/3-540-57183-3_24	embedded system;bandwidth management;real-time computing;image resolution;computer science;resource management;management system;dynamic bandwidth allocation;computer network	DB	-10.654733175084418	64.74396219092111	164285
5ddd23cad36eefaabce6fda14c59c4bd228a50ad	adaptive resource management and scheduling for cloud computing		With the advent of new computing technologies, such as cloud computing and contemporary parallel processing systems, the building blocks of computing systems have become multi-dimensional. Traditional scheduling algorithms based on a single-resource optimization like processor fail to provide near optimal solutions. The efficient use of new computing systems depends on the efficient use of all resource dimensions. Thus, the scheduling algorithms have to fully use all resources. In this paper, we propose a queuing mechanism based on a multi-resource scheduling technique. For that, we model multi-resource scheduling as a multi-capacity bin-packing scheduling algorithm at the queue level to reorder the queue in order to improve the packing and as a result improve scheduling metrics. The experimental results demonstrate performance improvements in terms of waittime and slowdown metrics.	algorithm;bin packing problem;cloud computing;mathematical optimization;parallel computing;schedule (project management);scheduling (computing);set packing	John C. Mitchell;Moni Naor	2014		10.1007/978-3-319-13464-2	fair-share scheduling;cloud computing;dynamic priority scheduling;resource allocation;cloud testing;distributed computing;utility computing	HPC	-17.68188151130803	62.21426624765098	164376
1e5802934a3073aba2d0ff2e29069bd66a32d48f	routing based load balancing for unstructured p2p networks	dynamic load balancing;development strategy;load transfer;resource allocation;load transfer routing based load balancing peer to peer networks dynamic load balancing self organizing networks overloaded nodes balanced structured p2p networks routing based algorithm heterogeneous networks dynamic unstructured p2p networks dynamic node arrivals;dynamic unstructured p2p networks;telecommunication network routing peer to peer computing resource allocation;overloaded nodes;balanced structured p2p networks;telecommunication network routing;routing based algorithm;dynamic node arrivals;routing load management peer to peer computing network topology computer science self organizing networks algorithm design and analysis network servers distributed control availability;self organization;load balance;p2p networks;peer to peer computing;peer to peer;peer to peer networks;heterogeneous networks;routing based load balancing;self organizing networks	Load balancing is an important problem for the efficient operation of peer-to-peer(P2P) networks. A key issue for dynamic load balancing in self-organizing networks is to identify overloaded nodes and reassign their loads to others. Recently, most of researchers have concentrated on developing strategies to the design of balanced structured P2P networks. However, none of these strategies is suitable for unstructured P2P networks. This paper proposes a novel routing based algorithm for load balancing in heterogeneous, dynamic unstructured P2P networks. Our algorithm does not need the global information and hence is resilient to dynamic node arrivals, departures, and failures. Experimental results indicate that our algorithm outperforms existing load balancing algorithms in terms of load transfer.	algorithm;load balancing (computing);organizing (structure);peer-to-peer;routing;self-organization	Ming Xu;Jihong Guan	2007	Future Generation Communication and Networking (FGCN 2007)	10.1109/FGCN.2007.197	network load balancing services;real-time computing;computer science;distributed computing;computer network	HPC	-12.167479029952059	73.31436615564684	164386
93197459c47e04b29896faec812a3eca540b0a4a	building a flexible web caching system	cache storage;web caching architecture;caching communication telecommunication traffic internet web caching architecture distributed web caching system cooperative web caching system cooperative web architectures http proxy servers web object validation;software architecture;telecommunication traffic;internet;add;service oriented architecture web server cooperative caching protocols internet network servers costs collaborative work network topology quality of service;conference report;software architecture internet cache storage;cooperative web architecture;web object validation;distributed web caching systems;http proxy servers;web caching;proxy server	Web caching is a technology that has demonstrated to improve traffic on the Internet. To find out how to implement a Web caching architecture that assures improvements is not an easy task. The problem is more difficult when we are interested in deploying a distributed and cooperative Web caching system. We have found that some cooperative Web caching architectures could be unviable when changes on the network environment appear. This situation suggests that a cooperative Web caching system could get worst access to Web objects. However in this paper we present an architecture that combines the best of several Web caching configurations that we have previously analyzed. Our architecture gives basic ideas for implementing a cooperative Web caching system using groups of HTTP proxy servers which can improve access to remote Web objects regardless of the changes that might occur on the network environment (changes that could produce modifications in Web object validation policies and/or types of caching communication).	authorization;cache (computing);computer science;cryptographic hash function;hypertext transfer protocol;ieee xplore;internet;multicast;performance;proxy server;simulation;web cache;world wide web	Víctor Jesús Sosa Sosa;Juan Gabriel González Serna;Leandro Navarro-Moldes	2003		10.1109/ENC.2003.1232875	web service;software architecture;web development;web modeling;the internet;web analytics;false sharing;computer science;software engineering;ws-policy;web navigation;database;internet privacy;world wide web;web server;mashup	Web+IR	-18.74309871257565	70.76544157445872	164539
4f416716d851a8048eca8b22f9d942bd753b759b	a multifit algorithm for uniform multiprocessor scheduling	uniform multiprocessor scheduling;multifit algorithm	Independent tasks are nonpreemptively scheduled on m2 processors which are assumed to have different speeds. By generalizing ideas of bin packing techniques scheduling algorithms are constructed which have better worst case bounds than the well-known LPT algorithm.	algorithm;multiprocessing;multiprocessor scheduling;scheduling (computing)	Manfred Kunde	1983		10.1007/BFb0009643	fair-share scheduling;fixed-priority pre-emptive scheduling;bin packing problem;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;mathematics;distributed computing;round-robin scheduling;scheduling;multiprocessor scheduling	Embedded	-11.321589095315463	61.19471084390112	164928
b98535f1aa5ab1541f72735e61404508694bb59d	graph models for scheduling systems with machine saturation property	makespan;polynomial algorithm;graph model;task scheduling;intersection graphs;multiprocessor task scheduling;polynomial algorithms	Let T = {T1, T2, . . . , Tn} be a set of n independent tasks and P = {P1, P2, . . . , Pm} a set of m processors. During each time instant, each processor can be used by a single task at most. A schedule is for each task an allocation of one or more time intervals to one or more processors. A schedule is said to be optimal if it minimizes the maximum completion time. We say a schedule S has the machine saturation property (MS property) if, at any time instant of task execution, all the machines are simultaneously busy. In this paper, we analyze the conditions under which a parallel scheduling system allows a schedule with the MS property. While for some simple models the analytical conditions can be easily stated, a graph model approach is required when conflicts of processor usage are present. For this reason, we define the class of saturated graphs that correspond to scheduling systems with the MS property. We present efficient graph recognition algorithms to verify the MS property directly on some classes of saturated graphs.	algorithm;central processing unit;graph (discrete mathematics);graph coloring;makespan;multiprocessing;polynomial;schedule (computer science);scheduling (computing)	Paolo Dell'Olmo;Monica Gentili	2006	Math. Meth. of OR	10.1007/s00186-005-0016-6	job shop scheduling;mathematical optimization;real-time computing;computer science;theoretical computer science;mathematics;distributed computing	Theory	-10.245843114771503	61.11696312064009	165017
e2b4c32d134f116ae666c6f087f20e91e37801d5	a survey on grid task scheduling	swarm intelligence;heuristic algorithms;research topics;grid task scheduling;directed acyclic graphs;grid computing;metatasks	Grid is a new distributed heterogeneous computing platform, which attracts many researchers. The allocation of tasks to distributed resources is crucial to grid application. So, Grid Task Scheduling (GTS) becomes the key issue of grid computing, and its algorithm has a direct effect on the performance of the whole grid system. In this paper, we summarise the most popular GTS algorithms, including traditional GTS, heuristic intelligent GTS and DAG-based GTS, separately. Furthermore, the comparative analysis is made among them. Finally, some main research directs of GTS are pointed out.	algorithm;directed acyclic graph;global telecommunications system;grid computing;heterogeneous computing;heuristic;qualitative comparative analysis;scheduling (computing)	Tinghuai Ma;Qiaoqiao Yan;Wenjie Liu;Cui Mengmeng	2011	IJCAT	10.1504/IJCAT.2011.042707	parallel computing;real-time computing;swarm intelligence;computer science;distributed computing;directed acyclic graph;grid computing	HPC	-16.321136574290502	62.4101755240543	165090
b6b9c89d66631d63d5ea0b57b78ae98687437f8e	evaluation of p2p resource discovery architectures using real-life multi-attribute resource and query characteristics	p2p system;peer to peer computing advertising computer architecture collaboration load management indexing;range query;resource discovery;query processing;resource allocation;simulation;collaboration;p2p;indexing resources p2p resource discovery architecture evaluation real life multiattribute resource characteristics query characteristics collaborative peer to peer applications p2p applications group aggregation planetlab advertising resource cost querying resource cost index size load balancing issues simulation based analysis unstructured dominated query based structured p2p solutions superpeer dominated query based structured p2p solutions single attribute dominated query based structured p2p solutions query answering;multi attribute queries;computer architecture;software architecture;indexing;indexation;simulation multi attribute queries peer to peer resource discovery;load management;software architecture peer to peer computing query processing resource allocation;load balance;peer to peer computing;peer to peer;advertising	Emerging collaborative Peer-to-Peer (P2P) applications rely on resource discovery solutions to aggregate groups of heterogeneous, multi-attribute, and dynamic resources that are distributed. In the absence of data and understanding of real-life resource and query characteristics, design and evaluation of existing solutions have relied on many simplifying assumptions. We first present a summary of resource and query characteristics from PlanetLab. These characteristics are then used to evaluate fundamental design choices for multi-attribute resource discovery based on the cost of advertising/querying resources, index size, and load balancing. Simulation-based analysis indicates that the cost of advertising dynamic attributes is significant and in-creases with the number of attributes. Compared to uniform queries, real-world queries are relatively easier to resolve using unstructured, superpeer, and single-attribute dominated query based structured P2P solutions. However, they cause significant load balancing issues in all the designs where a few nodes are mainly involved in answering majority of queries and/or indexing resources. Moreover, cost of resource discovery in structured P2P systems is effectively O(N) as most range queries are less specific. Thus, many existing design choices are applicable only under specific conditions and their performances tend to degrade under realistic workloads.	aggregate data;load balancing (computing);overhead (computing);peer-to-peer;performance;planetlab;range query (data structures);real life;simulation	H. M. N. Dilum Bandara;Anura P. Jayasumana	2012	2012 IEEE Consumer Communications and Networking Conference (CCNC)	10.1109/CCNC.2012.6181143	range query;software architecture;search engine indexing;resource allocation;computer science;load balancing;peer-to-peer;data mining;database;world wide web;collaboration	DB	-13.209421654351646	73.18636190001446	165107
cb30c8f13ed3b856e65dbdb3e5f09e83185e7ba1	enhancing cache invalidation in mobile environments	wireless channels;manet;mobile device;cache consistency;caching;cost reduction;network performance;mobile computer;cache invalidation;performance metric;mobile environment;power consumption;mobile computing;network congestion	The diversity of services delivered over wireless channels has increased people desire in ubiquitously accessing these services from their mobile devices. However, an ubiquitous mobile computing environment faces several challenges such as scarce bandwidth, limited energy resources, and frequent disconnection of the server and mobile devices. Caching frequently accessed data is an effective technique to improve the network performance since it reduces the network congestion, the query delay, and the power consumption. When caching is used, maintaining cache consistency becomes a major challenge since data items that are updated on the server should be also updated in the cache of the mobile devices. In this paper we propose a new cache invalidation scheme called Selective Adaptive Sorted (SAS) cache invalidation strategy. The proposed scheme overcomes the false invalidation problem that exists in most of the invalidation strategies found in the literature. The performance of the proposed strategy is evaluated. Results showed that a significant cost reduction can be obtained with SAS when measuring performance metrics such as delay, bandwidth, and energy.	cache (computing);cache coherence;cache invalidation;mobile computing;mobile device;network congestion;network performance;sas;server (computing)	Haïdar Safa;Hassan Artail;Mirna Nahhas	2008		10.1145/1506270.1506272	real-time computing;mobile ad hoc network;cache;computer science;cache invalidation;operating system;mobile device;distributed computing;smart cache;network performance;network congestion;mobile computing;cache algorithms;cache pollution;computer network	Mobile	-15.315469360247095	68.7636168751545	165453
1ba4649b7ab046a847c320cda0d2d98b685e8f42	a game theoretic approach to web caching	distributed system;systeme reparti;game theory;theoretical framework;funcion utilidad;red www;fonction utilite;reseau web;utility function;teoria juego;cache memory;theorie jeu;antememoria;antememoire;sistema repartido;internet;juego no cooperativo;world wide web;non cooperative game;web caching;jeu non cooperatif	In this paper, the Game Theoretic framework is applied to Web caching. The interaction of multiple clients with a caching subsystem is viewed as a noncooperative game. Some clients may continuously request resources, occupy a large segment of the cache disk space and thus, enjoy high hit rates. Owing to this situation, the remaining clients may suffer the removal of their “important” resources from the cache, and, subsequently, experience numerous cache misses. A utility function is introduced and calculated by clients in a decentralized fashion to avoid such monopolizing scenarios and guarantee similar performance levels for all users.	cpu cache;cache (computing);disk space;fairness measure;game theory;noise-equivalent power;simulation;utility;web cache	Stathes Hadjiefthymiades;Yiannis Georgiadis;Lazaros F. Merakos	2004		10.1007/978-3-540-24693-0_115	non-cooperative game;game theory;the internet;simulation;cpu cache;cache;computer science;artificial intelligence;operating system;database;distributed computing;world wide web;computer security;algorithm	Web+IR	-12.581193168395755	70.04676947650249	165557
333267ef2e84d45db01515f54af7e865c09a1574	random early detection web servers for dynamic load balancing	web server load management quality of service round robin network servers state feedback service oriented architecture frequency web and internet services computer science;oscillations;dynamic load balancing;resource allocation;oscillators;dns server;dns based;buffer storage;load oscillation random early detection web server dynamic load balancing quality of service domain name server dns server load buffer range;red;computer architecture;internet;resource allocation buffer storage internet quality of service;red dns based load buffer range;load buffer range;load management;load balance;web server;load oscillation;quality of service;service oriented architecture;domain name server;article;random early detection	Modern Web-server systems use multiple servers to handle an increased user demand. Such systems need effective methods to spread the load among web servers evenly in order to keep web server utilization high while providing sufficient quality of service for end users. In conventional DNS-based load balancing architecture, a Doman Name Server (DNS) dispatches requests to web servers based on their load status. Because web servers need to inform the DNS server about their load status from time to time, a so-called load buffer range is often employed to reduce the update frequency. Without care, however, using a load buffer range may result in load oscillation among web servers. To address this problem, we propose a Random Early Detection (RED) method with the intuition that the probability for a web server to become overloaded in near future is directly proportional to its current load. Simulation confirms that our method helps reducing the oscillation of the web server load significantly.	load balancing (computing);quality of service;random early detection;server (computing);simulation;web server	Chih-Chiang Yang;Chien Chen;Jing-Ying Chen	2009	2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks	10.1109/I-SPAN.2009.44	round-robin dns;network load balancing services;computer science;load balancing;distributed computing;world wide web;client–server model;server;computer network;server farm	Metrics	-18.708919926537178	69.37689533661226	165876
232bbe981db68a0773aa972ac0347c72dc7dd231	integrated real-time scheduling and communication with probabilistic timing assurances in unreliable distributed systems	distributed system;system reliability;real time systems timing time factors scheduling algorithm ad hoc networks telecommunication network reliability uncertainty usa councils runtime interference;probability;distributed computing;system reliability real time systems distributed computing fault tolerance;unreliable distributed systems;data communication;fault tolerant system;task time constraints integrated real time scheduling probabilistic timing assurances unreliable distributed systems distributed real time systems run time uncertainty communication delays arbitrary node failures message losses communication algorithm reliable data delivery node to node real time communication;distributed real time system;node to node real time communication;scheduling;real time scheduling;fault tolerance;integrated real time scheduling;reliable data delivery;communication delay;real time communication;run time uncertainty;arbitrary node failures;time utility function;communication algorithm;probabilistic timing assurances;distributed real time systems;scheduling data communication probability real time systems;task time constraints;communication delays;message losses;real time systems;local time;time constraint	We consider distributed real-time systems that operate under run-time uncertainties including those on execution times and communication delays, and subject to arbitrary node failures and message losses. We present an integrated real-time scheduling and communication algorithm called real-time scheduling with reliable data delivery (RTSRD) that provides probabilistic end-to-end assurances on distributed task timeliness behaviors in such systems. RTSRD considers distributed tasks with end-to-end timing requirements that are expressed using time/utility functions and the optimality criterion of maximizing the total accrued utility. The algorithm decomposes end-to-end time constraints into local time constraints, and uses local slack time for node-local real-time scheduling and node-to-node real-time communication. We analytically establish RTSRD's properties including probabilistic satisfaction of task time constraints. We also compare RTSRD with a prior algorithm called RTG- L for the same problem. Our comparisons show that RTSRD outperforms RTG-L in terms of timeliness assurances (stronger) and algorithm overhead (lower).	algorithm;distributed computing;end-to-end encryption;end-to-end principle;optimality criterion;overhead (computing);real-time clock;real-time computing;real-time operating system;real-time transcription;requirement;scheduling (computing);slack variable	Fei Huang;Kai Han;Binoy Ravindran;E. Douglas Jensen	2008	13th IEEE International Conference on Engineering of Complex Computer Systems (iceccs 2008)	10.1109/ICECCS.2008.15	fair-share scheduling;embedded system;fault tolerance;real-time computing;computer science;distributed computing;least slack time scheduling	Embedded	-9.92961869037341	65.70335387543695	165934
34a76e871061c515b498e4ebe6ae099728ae0591	the optimal control approach to generalized multiprocessor scheduling	multiprocessor scheduling;parallel algorithm;continuous variable;operations research;optimal control;optimal scheduling;precedence constraint;task scheduling	In this paper we present several new results in the theory of homogeneous multiprocessor scheduling. We start with some assumptions about the behavior of tasks, with associated precedence constraints, as processor power is applied. We assume that as more processors are applied to a task, the time taken to compute it decreases, yielding some speedup. Because of communication, synchronization, and task scheduling overhead, this speedup increases less than linearly with the number of processors applied. We also assume that the number of processors which can be assigned to a task is a continuous variable, with a view to exploiting continuous mathematics. The optimal scheduling problem is to determine the number of processors assigned to each task, and task sequencing, to minimize the finishing time. These assumptions allow us to recast the optimal scheduling problem in a form which can be addressed by optimal control theory. Various theorems can be proven which characterize the optimal scheduling solution. Most importantly, for the special case where the speedup function of each task isp α , wherep is the amount of processing power applied to the task, we can directly solve our equations for the optimal solution. In this case, for task graphs formed from parallel and series connections, the solution can be derived by inspection. The solution can also be shown to be shortest path from the initial to the final state, as measured by anl 1/α distance metric, subject to obstacle constraints imposed by the precedence constraints.	central processing unit;constraint (mathematics);control theory;multiprocessing;multiprocessor scheduling;numerical analysis;optimal control;optimal stopping;overhead (computing);scheduling (computing);shortest path problem;speedup	G. N. Srinivasa Prasanna;Bruce R. Musicus	1996	Algorithmica	10.1007/BF01942605	fair-share scheduling;fixed-priority pre-emptive scheduling;mathematical optimization;parallel computing;real-time computing;earliest deadline first scheduling;optimal control;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;mathematics;distributed computing;parallel algorithm;least slack time scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling	Theory	-12.885132286560834	61.385155421597354	165972
91610872e7f57bd627b73de7fb0cfeb6c4a0f50c	pde models for population and residual work applied to peer-to-peer networks	stability feedback frequency domain analysis partial differential equations peer to peer computing random processes;frequency domain analysis;stability;feedback;partial differential equations;p2p networks pde models peer to peer networks partial differential equations peer population workloads peer residual workloads file sharing control theoretic methods download progress equilibrium local stability analysis small gain argument feedback loop random noise equilibrium variability analysis frequency domain transient studies completion times;random processes;peer to peer computing;mathematical model queueing analysis sociology statistics stability analysis differential equations peer to peer computing	This paper studies partial differential equations that have recently been proposed as fluid models for queueing networks, where both populations and residual workloads must be accounted for. After reviewing these models in general, we focus on an application to peer-to-peer networks, where the dynamics must keep track of the download progress of a population of peers as content propagates among them through file sharing. Applying control-theoretic methods to this PDE yields a series of analytical results, in particular: local stability analysis of the equilibrium is proved through a small-gain argument on an appropriate feedback loop; variability around this equilibrium in the presence of random noise is analyzed through the frequency domain; and transient studies are performed to compute completion times.	download;feedback;file sharing;heart rate variability;noise (electronics);peer-to-peer;population;referring expression generation;spatial variability;theory;time complexity	Fernando Paganini;Andrés Ferragut	2012	2012 46th Annual Conference on Information Sciences and Systems (CISS)	10.1109/CISS.2012.6310760	stochastic process;simulation;stability;computer science;theoretical computer science;feedback;mathematics;distributed computing;frequency domain;partial differential equation;statistics	Metrics	-9.003814749531253	71.49290145706246	166647
d45fb1a290029f422769005f903f4c557f4beda4	reliability driven, non-preemptive real time scheduling on heterogeneous systems.	heterogeneous systems;real time scheduling			Nitin Auluck;Dharma P. Agrawal	2002			fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;round-robin scheduling	Embedded	-10.410915313807958	61.19702904542466	166752
ef68378e84fbf0fa39ceac17e7ad17fbf9ad719e	an effective reliability-driven technique of allocating tasks on heterogeneous cluster systems	heterogeneous cluster systems;weibull distribution;scheduling algorithm;duplication;reliability analysis	In large-scale heterogeneous cluster computing systems, processor and network failures are inevitable and can have an adverse effect on applications executing on such systems. One way of taking failures into account is to employ a reliable scheduling algorithm. However, most existing scheduling algorithms for precedence constrained tasks in heterogeneous systems only consider scheduling length, and not efficiently satisfy the reliability requirements of task. In recognition of this problem, we build an application reliability analysis model based on Weibull distribution, which can dynamically measure the reliability of task executing on heterogeneous cluster with arbitrary networks architectures. Then, we propose a reliability-driven earliest finish time with duplication scheduling algorithm (REFTD) which incorporates task reliability overhead into scheduling. Furthermore, to improve system reliability, it duplicates task as if task hazard rate is more than threshold $$\theta $$ θ . The comparison study, based on both randomly generated graphs and the graphs of some real applications, shows that our scheduling algorithm can shorten schedule length and improve system reliability significantly.	algorithm;clustered file system;computation;computer cluster;heterogeneous computing;heuristic (computer science);overhead (computing);parallel computing;procedural generation;requirement;round-robin scheduling;scheduling (computing);simulation	Xiaoyong Tang;Keqin Li;Guiping Liao	2014	Cluster Computing	10.1007/s10586-014-0372-1	fair-share scheduling;fixed-priority pre-emptive scheduling;weibull distribution;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;distributed computing;scheduling;gene duplication	HPC	-14.963794019354552	60.848576322952866	166776
a527c8d31a8f7c1d730fe5f8bfd94abe4a432fb5	bottom-up trie structure for p2p live streaming	diffusion p2p live streaming bottom up trie tree based swarming;bottom up;video streaming;video signal processing;p2p;internet;video streaming internet peer to peer computing video signal processing;isp bottom up trie structure video contents audio contents peer to peer live video streaming p2p lvs software multibit trie structure bu trie p2p live contents child nodes leaf nodes parent node root node diffusion phase swarming phase local peers physical locations source node end users video stream chunks most popular chunk first mpcf chunk exchange performance evaluation internet service providers;swarming;tree based;peer to peer computing;trie;diffusion;live streaming;peer to peer computing streaming media throughput ip networks delay algorithm design and analysis bandwidth	By simultaneously providing live video and audio contents to millions of users around the world, peer-to-peer live video streaming (P2P LVS) has become one of the most popular Internet applications in recent years. However, current P2P LVS software has problems such as non-smooth playback and long start-up delay for end users. To address these issues, we design a P2P-based multi-bit Trie structure, called Bottom-Up Trie (BU-Trie), for distributing P2P live contents. Different from other approaches, BU-Trie is a Trie formed and built inversely from leaf nodes (or child nodes) back to the root node (or parent node). This architecture consists of two phases: a diffusion phase and a swarming phase. The main design goal of the diffusion phase is to group the local peers together by discovering physical locations of peers, and design the paths for fast distributing live streams from the source node to end users. The objective of the swarming phase is to find an optimal way for exchanging the video stream chunks within a local group. We propose an algorithm called Most Popular Chunk First (MPCF) and apply it for the swarming phase for efficient chunk exchange. Performance evaluation of the proposed BU-Trie shows that, when compared to other approaches, the sequential throughput of video chunks is increased. The inter-domain traffic, the traffic between different Internet service providers (ISPs), is reduced as well. Such a reduction would benefit carriers economically.	algorithm;bottom-up parsing;inter-domain;internet;linux virtual server;peer-to-peer;performance evaluation;streaming media;throughput;top-down and bottom-up design;tree (data structure);trie	Boyuan Zhang;Changcheng Huang;James Yan	2012	2012 IEEE International Conference on Communications (ICC)	10.1109/ICC.2012.6364344	the internet;telecommunications;computer science;trie;peer-to-peer;top-down and bottom-up design;diffusion;internet privacy;swarming;world wide web;computer network	Metrics	-15.503216994366957	74.4451282821507	166795
4bff17d9beaa4e1730bdc53d8f1faa032c7dddf4	an adaptive task scheduling system for grid computing	grid scheduling;application software;processor scheduling;adaptive grid;prediction information dynamic scheduling grid computing high throughput application task replica;computer networks;accuracy;scheduling algorithm;adaptive systems;heuristic algorithms;prediction information;task replica;adaptive scheduling;high throughput application;task assignment;task scheduling;coarse grained;high throughput;adaptive systems adaptive scheduling processor scheduling grid computing scheduling algorithm dynamic scheduling application software accuracy computer networks heuristic algorithms;grid computing;job scheduling;dynamic scheduling	In order to efficiently utilize available grid resources and promptly complete tasks assigned to the grid, providing a suitable job scheduling strategy for the grid computing is necessary. Lots of grid scheduling algorithms have already been developed, and some of them are used to schedule independent coarse-grained tasks. Those algorithms don't adapt very well to the grid tasks that are submitted continuously and randomly. Besides, they mostly need a prediction system to provide the prediction information about the processor utilization and the task workloads. This paper proposes an adaptive grid scheduling system for high-throughput applications. Firstly, a grid scheduling model is adopted to represent the performance of processors, the task workloads, and the schedules. Then we develop a scheduling algorithm that doesn't need any prediction information and can adapt to the grid environment. Finally, the scheduling system combines the proposed algorithm with the best of scheduling algorithms that need the prediction information. According to the accuracy of the prediction system in the grid, the system selects the proper strategy to schedule tasks. A prototype of this model is developed and tested with several experiments. The experimental results of the simulation show that the proposed scheduling system is able to perform scheduling well in the grid environment.	adaptive mesh refinement;algorithm;central processing unit;computation;experiment;grid computing;high-throughput computing;job scheduler;kerrison predictor;maxima and minima;prototype;randomness;schedule (computer science);scheduling (computing);simulation;throughput	Liang-Teh Lee;Chin-Hsiian Liang;Hung-Yuan Chang	2006	The Sixth IEEE International Conference on Computer and Information Technology (CIT'06)	10.1109/CIT.2006.36	fair-share scheduling;high-throughput screening;fixed-priority pre-emptive scheduling;application software;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;adaptive system;job scheduler;operating system;two-level scheduling;deadline-monotonic scheduling;distributed computing;accuracy and precision;scheduling;lottery scheduling;round-robin scheduling;scheduling;multiprocessor scheduling;grid computing	HPC	-16.364416908347476	61.57143421191422	167091
ede44602184e414834d50ccac65ef8814b40d8da	event-triggered real-time scheduling of stabilizing control tasks	event triggered real time scheduling event triggered scheduler asymptotic stability control unrelated software tasks feedback controller real time scheduler embedded processors scheduling stabilizing control tasks;event triggered scheduler;scheduling stabilizing control tasks;calculateur embarque;control unrelated software tasks;gestion labor;stabilite asymptotique;real time;asymptotic stability;sistema reactivo;feedback controller;real time scheduler;communication system control processor scheduling microprocessors scheduling algorithm adaptive control stability computer networks embedded computing physics computing feedback;stabilidad entrada estado;embedded systems;feedback;gestion tâche;retroaccion;stabilite entree etat;event triggered real time scheduling;retroaction;scheduling;task analysis;real time scheduling;temps reel;embedded processors;boarded computer;input to state stability;feedback regulation;reactive system;real time scheduling event triggered input to state stability;systeme reactif;tiempo real;control engineering computing;estabilidad asintotica;task scheduling;event triggered;embedded processor;calculador embarque;task analysis asymptotic stability control engineering computing embedded systems feedback scheduling;ordonnancement;reglamento	In this note, we revisit the problem of scheduling stabilizing control tasks on embedded processors. We start from the paradigm that a real-time scheduler could be regarded as a feedback controller that decides which task is executed at any given instant. This controller has for objective guaranteeing that (control unrelated) software tasks meet their deadlines and that stabilizing control tasks asymptotically stabilize the plant. We investigate a simple event-triggered scheduler based on this feedback paradigm and show how it leads to guaranteed performance thus relaxing the more traditional periodic execution requirements.	central processing unit;control theory;embedded system;programming paradigm;real-time clock;real-time transcription;requirement;scheduling (computing)	Paulo Tabuada	2007	IEEE Transactions on Automatic Control	10.1109/TAC.2007.904277	embedded system;real-time computing;reactive system;computer science;task analysis;control theory;feedback;distributed computing;scheduling	Embedded	-9.723455394652003	61.69555661173552	167319
f032a8cca9f17df1695ca929288cfc472ca22f26	the content placement problem in d2d networks under coupling distributed caching and distributed storage			distributed cache	Basma Nissar;Ahmed El Ouadrhiri;Mohamed El-Kamili	2018		10.1007/978-3-030-02849-7_19		Theory	-18.66877014144828	73.09525989383528	167452
0754397a147776d8e606eeac536089cdcd03a7c9	improving the real-time behaviour of a multithreaded java microcontroller by control theory and model based latency prediction	microcontrollers;multi threading;control theory;pid controller;closed loop systems;processor scheduling;real time;java microcontrollers control theory predictive models delay yarn throughput feedback loop three term control educational institutions;stability;feedback loop;three term control;stability multi threading real time systems java microcontrollers three term control processor scheduling closed loop systems;stabilization multithreaded java microcontroller control theory model based latency prediction ipc rate multithreaded java processor closed feedback loop pid controller model based latency predictor processor simulator komodo microcontroller guaranteed percentage scheduling multithreading three term control processor scheduling closed loop systems;java;real time systems	Our aim is to investigate if it is possible to control and to stabilize the throughput (IPC rate) of a thread running on a multithreaded Java processor by a closed feedback loop and a model based latency predictor. We implemented a PID controller and a model based latency predictor in the processor simulator of the Komodo microcontroller developed at the universities of Karlsruhe and Augsburg to simulate both as additional hardware modules. GP (guaranteed percentage) scheduling is used to control the thread. Evaluations show that the aimed IPC rate of a thread is achieved by the controller and stabilized by the latency predictor thus improving the real-time capabilities of the Java processor.	branch predictor;clock signal;control theory;feedback;instructions per cycle;java processor;kerrison predictor;komodo edit;lock (computer science);microcontroller;multithreading (computer architecture);pid;preemption (computing);real-time clock;real-time transcription;scheduling (computing);simulation;testbed;thread (computing);throughput	Uwe Brinkschulte;Mathias Pacher	2005	10th IEEE International Workshop on Object-Oriented Real-Time Dependable Systems	10.1109/WORDS.2005.38	embedded system;parallel computing;real-time computing;computer science	Embedded	-6.551778119380782	61.747507191133316	167889
8ba036b9ada46a93ee235bda2a8884c90a7b837a	a modeling methodology and pre-run-time scheduling for embedded real-time software	optimisation;formal specification;formal model;system modeling;real time;embedded real time software prerun time scheduling formal modeling methodology time petri nets application specific scheduler synthesis np hard problem state space exploration system modeling partial order reduction method depth first search based method;formal verification embedded systems computational complexity petri nets optimisation tree searching formal specification scheduling;embedded systems;time petri net;formal verification;computational complexity;embedded software processor scheduling real time systems state space methods timing petri nets space exploration modeling scheduling algorithm embedded computing;scheduling;state space;partial order reduction;depth first search;petri nets;modeling methodology;tree searching;real time systems	One of the most intricate problems in the synthesis of real-time systems is the scheduling. We present a formal modeling methodology based on time Petri nets (TPN) and a framework for application-specific scheduler synthesis. Finding a feasible scheduling is not an easy task because this problem, in its general form, is NP-hard. The method proposed finds a scheduling, whether one exists, using state space exploration. The problem with this approach is the space size, which can be very large for medium to large systems. We show how to minimize this problem using behavior restrictions at system modeling, and a partial-order reduction method. Additionally, the algorithm proposed for finding a feasible schedule uses a depth-first search based method. Therefore, states are only generated if strictly necessary. It is verified through real-world experimental results that a schedule is found examining a reduced number of states.		Raimundo S. Barreto;Paulo Romero Martins Maciel;Sérgio Cavalcante	2003		10.1109/CAHPC.2003.1250323	fair-share scheduling;partial order reduction;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;systems modeling;breadth-first search;dynamic priority scheduling;formal verification;computer science;state space;rate-monotonic scheduling;theoretical computer science;genetic algorithm scheduling;two-level scheduling;formal specification;distributed computing;programming language;computational complexity theory;scheduling;petri net	Embedded	-7.481417979607066	60.9671957220772	167985
715b307424034b0c606f45fcb20a2ad2ec50482e	collaborative proxy system for distributed web content transcoding	caching;prefetching;hierarchical networks;settore ing inf 05 sistemi di elaborazione delle informazioni;load distribution;pattern analysis;web server	Content transformation (or transc oding) proxies ha ve been recen tly proposed to tailor Web con tentto device characteristics of Web clients. In this paper, we address the problem of distributing the computational load caused by object transcoding throughout a collaborative proxy system organized in a hierarchical net w ork.We evaluate through simulation the impact of load distribution and caching policies on users' response time. We nd that the simple global policy that captures the proxy load information along the request path can provide reasonably good load sharing, and that, to e ectiv ely share the load, it is necessary to provide the edge proxies a mechanism to push up some transcoding load. On the caching policy, we examine policies that allow di erent versions of an object to be cached. Our study shows that the demand based caching policy which has the transcoding proxy cac he the transcoded version performs better than the coverage based caching policy that caches the more detailed version and the anticip atorycaching policy that caches both of these v ersions.	cache (computing);internet;load balancing (computing);naruto shippuden: clash of ninja revolution 3;ork;response time (technology);simulation;web content	Philip S. Yu;Valeria Cardellini;Yun-Wu Huang	2000		10.1145/354756.354861	real-time computing;computer science;weight distribution;database;world wide web;web server	Web+IR	-18.017618622373654	70.61408591868232	168257
8528433c5103c7e08823f7ad6f0b87a3ac20b6e6	topic 3: scheduling and load balancing - (introduction)	null	Despite significant effort parallel and distributed systems available today are still not fully utilized and exploited. Scheduling and load balancing techniques remain crucial for implementing efficient parallel and distributed applications and for making best use of existing parallel and distributed systems. The need for such techniques intensifies with the foreseen advent of exa-scale computer systems with many core and accelerator architectures. Similarly, cloud computing became a viable paradigm for some applications. Scheduling includes planning and optimization of the resource allocation as well as coping with the dynamics of the systems. These topics have been subject for research for many decades but remain one of the core topics in parallel and distributed computing. © 2013 Springer-Verlag.	load balancing (computing);scheduling (computing)	Zhihui Du;Ramin Yahyapour;Yuxiong He;Nectarios Koziris;Bilha Mendelson;Veronika Rehn-Sonigo;Achim Streit;Andrei Tchernykh	2013		10.1007/978-3-642-40047-6_9	dynamic priority scheduling;parallel computing;scheduling (computing);real-time computing;fair-share scheduling;computer science;load balancing (computing);distributed computing	Theory	-16.84175912704443	61.48533976736928	168277
36cc20c02558551313845735b90643264abe1a80	a streaming high-throughput linear sorter system with contention buffering		Popular sorting algorithms do not translate well into hardware implementations. Instead, hardware-based solutions like sorting networks, systolic sorters, and linear sorters exploit parallelism to increase sorting efficiency. Linear sorters, built from identical nodes with simple control, have less area and latency than sorting networks, but they are limited in their throughput. We present a system composed of multiple linear sorters acting in parallel to increase overall throughput. Interleaving is used to increase bandwidth and allow sorting of multiple values per clock cycle, and the amount of interleaving and depth of the linear sorters can be adapted to suit specific applications. Contention for available linear sorters in the system is solved through the use of buffers that accumulate conflicting requests, dispatching them in bulk to reduce latency penalties. Implementation of this system into a field programmable gate array (FPGA) results in a speedup of 68 compared to a MicroBlaze processor running quicksort.		Jorge L. Ortiz;David L. Andrews	2011	Int. J. Reconfig. Comp.	10.1155/2011/963539	parallel computing;real-time computing;computer science;distributed computing	Arch	-5.06951253967879	64.11761198476586	168306
37715696f5cd9e4397c622f04938b7f6d00b9587	a dynamic and adaptive cache retrieval scheme for mobile computing	cache storage;wireless technologies;file servers;distributed server architecture;dynamic cache retrieval scheme;system simulator;query processing;mobile computing system;mobile computer;system performance;mobile users;mobile computing systems;coordinator buffer;mobile radio;mobile computing costs information systems wireless communication mobile communication postal services information retrieval banking delay fault tolerant systems;communication overhead reduction;data access;distributed databases;adaptive cache retrieval scheme;query processing mobile radio cache storage file servers distributed databases;mobile systems;wireless technology;system simulator adaptive cache retrieval scheme dynamic cache retrieval scheme mobile computing systems wireless technologies mobile users system performance distributed server architecture communication overhead reduction service handoff coordinator buffer transactions;system simulation;transactions;cache memories;service handoff;mobile user	Recent advances in wireless technologies have made the mobile computing a reality. In order to provide services of good quality to mobile users and improve the system performance, the mobile computing system is usually of a distributed server architecture. As users move to a new service area, the new server is expected to take over the execution of running programs for mobile users so as to reduce the communication overhead of the mobile system. This procedure is referred to as service handoff. Note that when service handoff occurs, the cache of the new server does not contain any data entry that was accessed by prior transactions and the new server will thus lose its advantages for cache access. To remedy this, we examine in this paper several cache retrieval schemes to improve the efficiency of cache retrieval. In particular, we analyze the impact of using a coordinator buffer to improve the overall performance of cache retrieval. Moreover, in light of the properties of transactions (i.e, temporal locality of data access among transactions), we devise a Dynamic and Adaptive cache Retrieval scheme (DAR) that can adopt proper cache methods based on some specific criteria devised to deal with the service handoff situation in a mobile computing environment. The performance of these cache retrieval schemes is analyzed and a system simulator is developed to validate our results.	data access;data recovery;locality of reference;mobile computing;overhead (computing);server (computing)	Wen-Chih Peng;Ming-Syan Chen	1998		10.1109/COOPIS.1998.706203	bus sniffing;data access;file server;cache-oblivious algorithm;real-time computing;cache coloring;page cache;cache;computer science;write-once;cache invalidation;operating system;database;distributed computing;computer performance;smart cache;mobile computing;cache algorithms;cache pollution;distributed database;computer network	Web+IR	-15.638250362356807	68.57314057964422	168337
578b9619e854d49f439018a3f0748fd755f5f7c4	a fast ip routing lookup scheme for gigabit switching routers	storage allocation;longest prefix matching;routing random access memory packet switching hardware telecommunication traffic optical fiber cables internet databases computer science electronic mail;electronic switching systems telecommunication network routing transport protocols table lookup pipeline processing sram chips;response time;pipeline processing systems;packet switching;memory access;transport protocols;computer architecture;telecommunication traffic;network protocols;internet;telecommunication network routing;congestion control;10 ns fast ip routing lookup gigabit switching routers ip packet longest prefix matching address lookup sram pipelined hardware forwarding table memory accesses 450 to 470 kbyte;data communication systems;electronic switching systems;ip routing;random access storage;table lookup;routers;pipeline processing;sram chips	One of the key design issues for the new generation IP routers is the route lookup mechanism. For each incoming IP packet, the IP routing requires to perform a longest prefix matching on the address lookup in order to determine the packet’s next hop. This paper presents a fast route lookup mechanism that only needs tiny SRAM and can be implemented in a pipelined skill in hardware. Based on the proposed scheme, the forwarding table is tiny enough to fit in SRAM with very low cost. For example, a large routing table with 40,000 routing entries can be compacted to a forwarding table of 450-470 Kbytes. In the worst case, the number of memory accesses for a lookup is three. When implemented in a pipeline skill in hardware, the proposed mechanism can achieve one routing lookup every memory access. With current 10ns SRAM, this mechanism furnishes approximately 100 million routing lookups per second. This is much faster than any current commercially available routing lookup schemes.	algorithm;best, worst and average case;gigabit;longest prefix match;lookup table;memory bank;network packet;routing table;static random-access memory	Nen-Fu Huang;Shi-Ming Zhao;Jen-Yi Pan;Chi-An Su	1999		10.1109/INFCOM.1999.752163	policy-based routing;routing table;routing domain;route;communications protocol;virtual routing and forwarding;routing;enhanced interior gateway routing protocol;loose source routing;static routing;source routing;parallel computing;real-time computing;the internet;equal-cost multi-path routing;computer science;dynamic source routing;destination-sequenced distance vector routing;ip forwarding;routing protocol;link-state routing protocol;triangular routing;network congestion;longest prefix match;response time;transport layer;packet switching;computer network	Networks	-5.642978863193127	66.6169683769481	168458
4a9ffcf9e43c70ad82d35ce590fd0aae668963b9	optimal task assignment in mobile cloud computing by queue based ant-bee algorithm	mobile cloud computing;offloading;queue model;ant colony optimization;artificial bee colony optimization;drop rate;load balance	Mobile cloud computing (MCC) broadens the mobile devices capability by offloading tasks to the ‘cloud’. Hence, offloading numerous tasks simultaneously increases the ‘cloudlets’ load and augments the average completion duration of the offloaded tasks. To withstand this issue, we propose a hybrid Queue Ant Colony-Artificial Bee Colony Optimization (Ant-Bee) algorithm for optimal assignment of tasks in MCC environment. The proposed algorithm works on a two-way MCC model with offloading technique, that considers of both the ‘cloudlets’ and the public ‘cloud’. The ‘cloud’ and the ‘cloudlets’ are designed on the basis of queue model for the estimation of clients waiting time in the limitation of resources. The major concern of the proposed algorithm is to offload the tasks by identifying the accurate place preferably in a ‘cloud/cloudlet’. The ‘cloud/cloudlet’ is encompassed by a queue model with the end goal to minimize the drop rate by permitting the tasks to wait in the queue. It also aims for the optimal assignment of tasks to manage the ‘cloudlets’ load and to minimize the entire tasks average completion time. The performance of the proposed algorithm is analyzed with few Queue based conventional algorithms such as, “Round Robin”, “Weighted Round Robin” and “Random”. From the simulation result, it is analyzed that our proposed algorithm outperforms in the power consumption of the mobile devices, the average completion time of tasks, and drop rate. Also, to ensure the efficiency of our proposed hybrid QAnt-Bee algorithm, it is contrasted with the “HACAS” application scheduling algorithm, which fails to consider queue in the ‘cloudlets’.		Vinu Sundararaj	2018	Wireless Personal Communications	10.1007/s11277-018-6014-9	computer network;computer science;ant colony optimization algorithms;mobile cloud computing;scheduling (computing);cloudlet;cloud computing;load balancing (computing);algorithm;weighted round robin;queue	Mobile	-19.048615307356645	63.0819467294251	168524
081a1df1064449718ff8555e8854e6414ce8247c	dynamic thermal and timeliness guarantees for distributed real-time embedded systems	analytical models;timeliness control loops;coordinated control solution;system reliability;control algorithm;distributed real time embedded;real time;temperature control;real time embedded system;runtime;thermal stability;real time systems embedded system control systems runtime thermal management embedded computing processor scheduling temperature computer applications distributed computing;stability;embedded systems;coordinated control solution realtime embedded systems temperature control timeliness control loops distributed systems system reliability;stability analysis;process control;utilization control;distributed systems;thermal management;feedback control thermal management timeliness guarantees utilization control;feedback control;microcomputers;temperature control embedded systems microcomputers stability;realtime embedded systems;real time systems;timeliness guarantees	Distributed real-time embedded systems have stringent requirements for key performance properties, such as end-to-end timeliness and reliability, in order to operate properly. In recent years, with the continuously decreasing feature size and increasing demand for computation capabilities, today's real-time embedded systems face an increasing probability of overheating and even thermal failures. As a result, their temperature must be explicitly controlled for improved reliability. While a variety of control algorithms have been proposed for either real-time guarantees or thermal management in an isolated manner, this paper proposes a coordinated control solution that can provide simultaneous thermal and timeliness guarantees for distributed real-time embedded systems running in unpredictable environments. Our control solution features a novel coordination design, which allows the thermal and timeliness control loops to run on their respective desired small timescales for prompt control actions and yet achieve theoretically guaranteed control accuracy and system stability. In addition, while most existing work relies solely on simulations, we present empirical results on a physical testbed to demonstrate the efficacy of our control solution.	algorithm;computation;control flow;control system;control theory;embedded system;end-to-end principle;real-time clock;real-time computing;real-time locating system;real-time operating system;requirement;robust control;simulation;testbed;thermal management of high-power leds	Xing Fu;Xiaorui Wang;Eric Puster	2009	2009 15th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications	10.1109/RTCSA.2009.49	thermal stability;embedded system;von neumann stability analysis;real-time computing;thermal management of electronic devices and systems;stability;computer science;operating system;process control;temperature control;feedback;microcomputer;distributed computing	Embedded	-8.318177870844943	61.766038793801435	168863
52ea03f2b26192c3ba9a17f03f41f95a5d21051f	simple cart based real-time traffic classification engine on fpgas		Traffic classification is a process which assorts computer network traffic into predefined traffic classes by utilizing packet header information or network packet statistics. Real-time traffic classification is mainly used in network management tasks comprising traffic shaping and flow prioritization as well as in network security applications for intrusion detection. Machine Learning (ML) based traffic classification that exploits statistical characteristics of traffic, has come into prominence recently, due to its ability to cope with encrypted traffic and newly emerging network applications utilizing non-standard ports to circumvent firewalls. To meet high data rates and achieve online classification with ML-based techniques, Field Programmable Gate Arrays (FPGAs) providing abundant parallelism and high operating frequency is the most appropriate platform. In this paper, we propose to use Simple Classification and Regression Trees (Simple CART) machine learning algorithm for traffic classification. However, the variations in node sizes of Simple CART decision tree caused by discretization pre-process incur memory and resource inefficiency problems when the tree is directly mapped onto the hardware. To resolve these problems, we propose to represent Simple CART decision tree by two stage hybrid data structure (Extended-Simple CART) that comprises multiple range trees in Stage 1 and a Simple CART decision tree enriched with bitmaps at its nodes in Stage 2. Our design is implemented on parallel and pipelined architectures using Field Programmable Gate Arrays (FPGAs) to acquire high throughput. Extended-Simple CART architecture can sustain 557 Gbps or 1741 million classification per second (MCPS) (for the minimum packet size of 40 Bytes) on a state-of-the-art FPGA and achieve an accuracy of 96.8% while classifying an internet traffic trace including eight application classes.	algorithm;bitmap;byte;clock rate;cluster analysis;data rate units;data structure;decision tree learning;discretization;encryption;field-programmable gate array;firewall (computing);intrusion detection system;machine learning;microsoft cordless phone system;network packet;network security;network traffic control;parallel computing;preprocessor;rom cartridge;real-time clock;real-time web;statistical classification;throughput;traffic classification;traffic shaping	Tuncay Soylu;Oguzhan Erdem;Aydin Carus;Edip S. Guner	2017	2017 International Conference on ReConFigurable Computing and FPGAs (ReConFig)	10.1109/RECONFIG.2017.8279820	traffic shaping;internet traffic;computer science;real-time computing;traffic classification;network management;architecture;network security;intrusion detection system;network packet	Metrics	-6.860219631372861	66.0879442244694	168867
a4f67fd246baa05f5987c6fa78a8ae4df8f2769c	neural network hot spot prediction algorithm for shared web caching system	log files;hot spot;load balance;web caching;proxy server;neural network	There are innumerable objects found on the Web. Both the popular objects that are requested frequently by the users and unpopular objects that are rarely requested exist. Hot spots are produced whenever huge numbers of objects are requested by the users. Often this situation produces excessive load on the cache server and original server, resulting in the system becoming a swamped state. Many problems arise, such as server refusals or slow operations. In this paper, a neural network prediction algorithm is suggested in order to solve the problems caused by the hot spot. The hot spot would be requested in the near future is prefetched to the proxy servers after the prediction of the hot spot; then the fast response for the users’ requests and a higher efficiency for the proxy server can be achieved. The hot spots are obtained by analyzing the access logs file. A simulator is developed to validate the performance of the suggested algorithm, through which the hit rate improvement and the request among the shared proxy servers are load-balanced.	algorithm;artificial neural network;consistent hashing;hash function;hot spare;load balancing (computing);network congestion;prefetch input queue;proxy server;server (computing);web cache;world wide web	Jong Ho Park;Sung Chil Jung;Changlei Zhang;Kil To Chong	2005		10.1007/978-3-540-31849-1_76	reverse proxy;real-time computing;computer science;load balancing;operating system;machine learning;data mining;database;distributed computing;world wide web;hot spot;artificial neural network	Web+IR	-17.67493307935767	71.22355654319682	169054
c13b26271cf14425ce7f8182926c14a81aa53307	scheduling continuous queries in data stream management systems	continuous query;data stream management system	Recently, several policies have been proposed for scheduling multiple Continuous Queries (CQs) in a Data Stream Management System (DSMS). The decision on which policy to use plays an important role in shaping the percieved online performance provided by the DSMS. In this tutorial, we provide an overview of different policies employed by current CQ schedulers and the performance goals optimized by these policies. Further, we discuss the salient properties of CQs conisdered by current policies as well as the efficent implementation of such policies into CQ schedulers. Finally, we present future research directions and open problems in CQ scheduling.	adaptive partition scheduler;conjunctive query;management system;noise shaping;scheduling (computing)	Mohamed A. Sharaf;Alexandros Labrinidis;Panos K. Chrysanthis	2008	PVLDB	10.14778/1454159.1454222	real-time computing;computer science;data mining;database;distributed computing	DB	-16.625833440710323	63.09873833562908	169701
61dc64a519110f0afe1643392d95b94f3080543d	energy-aware scheduling algorithm for time-constrained workflow tasks in dvfs-enabled cloud environment		Abstract Energy consumption in cloud data centers is increasing as the use of such services increases. It is necessary to propose new methods of decreasing energy consumption. Green cloud computing helps to reduce energy consumption and significantly decreases both operating costs and greenhouse gas emissions. Scheduling the enormous number of user-submitted workflow tasks is an important aspect of cloud computing. Resources in cloud data centers should compute these tasks using energy efficient techniques. This paper proposed a new energy-aware scheduling algorithm for time-constrained workflow tasks using the DVFS method in which the host reduces the operating frequency using different voltage levels. The goal of this research is to reduce energy consumption and SLA violations and improve resource utilization. The simulation results show that the proposed method performs more efficiently when evaluating metrics such as energy utilization, average execution time, average resource utilization and average SLA violation.	algorithm;dynamic voltage scaling;scheduling (computing)	Monire Safari;Reihaneh Khorsand	2018	Simulation Modelling Practice and Theory	10.1016/j.simpat.2018.07.006	real-time computing;computer science;energy consumption;workflow;scheduling (computing);efficient energy use;cloud computing;greenhouse gas	EDA	-18.977581642960114	62.582415931308844	169963
d77c2e4f772050340826206d3c285c4e76478991	a scalable solution for interactive near video-on-demand systems	resource management;vod interactive requests multicast near video on demand nvod realistic workload stream merging video streaming;servers streaming media delays aggregates merging resource management;servers;streaming media;aggregates;merging;extensive simulation interactive near video on demand systems scalable solution high rate transfer multimedia data vod systems resource sharing techniques interactive operations resource sharing client side cache management interactive requests realistic workload;video on demand multimedia communication;delays	The required real-time and high-rate transfer of multimedia data limits the numbers of requests that can be concurrently serviced by video-on-demand (VOD) systems. Resource-sharing techniques can be used to address this scalability challenge, but they greatly complicate the efficient support for interactive operations. We develop an overall solution for interactive near VOD systems that employ resource sharing. The proposed solution supports user interactions with short response times and low rejection probabilities. The solution includes a novel stream provisioning policy, which dynamically determines the best number of I-Streams (unicast streams for supporting interactive requests) and the maximum I-Stream length that can be allocated by the server. Furthermore, we use a sophisticated client-side cache management policy to maximize the percentage of interactive requests serviced from the client's own cache. We study the system using realistic workload through extensive simulation.	aggregate data;blocking (computing);cpu cache;client-side;erlang (unit);fairness measure;interaction;meta content framework;provisioning;real-time clock;rejection sampling;scalability;scheduling (computing);server (computing);simulation;stream (computing);stream processing;unicast	Kamal K. Nayfeh;Nabil J. Sarhan	2016	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2015.2478708	real-time computing;computer science;resource management;world wide web;server;computer network	DB	-15.741275411772383	71.36339765403712	169998
c8130412637dc2050581b4fdbfe55df6c6e70a16	power consumption scheduling for peak load reduction in smart grid homes	power schedule;execution time;time complexity;search space;task model;power transmission;smart grid;peak load reduction;power consumption;home controller	This paper presents a design and evaluates the performance of a power consumption scheduler in smart grid homes, aiming at reducing the peak load in individual homes as well as in the system-wide power transmission network. Following the task model consist of actuation time, operation length, deadline, and a consumption profile, the scheduler copies or maps the profile according to the task type, which can be either preemptive or nonpreemptive. The proposed scheme expands the search space recursively to traverse all the feasible allocations for a task set. A pilot implementation of this scheduling method reduces the peak load by up to 23.1% for the given task set. The execution time greatly depends on the search space of a preemptive task, as its time complexity is estimated to be <i>O</i> (<i>M</i><sup><i>N</i></sup><sub><i>np</i></sub> · (<i>M</i><sup><i>M/2</i></sup>)<sup><i>N</i></sup><sub><i>p</i></sub>), where <i>M, N</i><sub><i>np</i></sub>, and <i>N</i><sub><i>p</i></sub> are the number of time slots, preemptive tasks, and nonpreemptive tasks, respectively. However, it can not only be reduced almost to 2% but also made stable with a basic constraint processing mechanism which prunes a search branch when the partial peak value already exceeds the current best.	algorithmic trading;embedded system;heuristic;home automation;load profile;map;multi-agent system;network model;power management;preemption (computing);recursion;run time (program lifecycle phase);scheduling (computing);traverse;telecommunications network;time complexity;web service	Junghoon Lee;Gyung-Leen Park;Sang Wook Kim;Hye-Jin Kim;Chang Oan Sung	2011		10.1145/1982185.1982310	time complexity;fixed-priority pre-emptive scheduling;embedded system;parallel computing;real-time computing;power transmission;computer science;smart grid	HPC	-5.639586889708855	60.843401056143605	170150
8501db7105db9e736583057387fe3b1bfd728832	current results on edzl scheduling for multiprocessor real-time systems	optimal uniprocessor scheduler;edzl;multiprocessor systems;processor scheduling;earliest deadline first;upper bound;rm;zero laxity scheduling;multiprocessor real time system;zero laxity scheduling multiprocessor real time system optimal uniprocessor scheduler earliest deadline first;processor scheduling multiprocessing systems;edf;real time systems processor scheduling optimal scheduling multiprocessing systems scheduling algorithm computer science dynamic scheduling chaos upper bound multicore processing;multiprocessing systems;task scheduling;on line algorithm;rate monotonic;lower bound;real time systems	Many optimal uniprocessor schedulers, such as earliest deadline first (EDF) and rate monotonic (RM), do not have a good schedulability bound on multiprocessor systems. In this paper, we study an on-line algorithm earliest deadline first until Zero laxity (EDZL) for multiprocessor systems. A set of tasks scheduled by EDZL is scheduled using EDF until a job experiences a zero laxity. To avoid the job from missing its deadline, the priority of the job is immediately promoted to the highest priority. We derive the schedulability bound of 3/2+\umax-1/2\ for two-processor systems, where umax is the maximum utilization of an individual task in the given task set. We also discuss the best known upper bound and lower bound on EDZL schedulability conditions.	clock rate;computer form factor;context switch;converge;earliest deadline first scheduling;experience;link-local address;multiprocessing;online algorithm;online and offline;real-time transcription;scheduling (computing);uniprocessor system	Hsin-Wen Wei;Yi-Hsiung Chao;Shun-Shii Lin;Kwei-Jay Lin;Wei-Kuan Shih	2007	13th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA 2007)	10.1109/RTCSA.2007.34	parallel computing;real-time computing;computer science;distributed computing;upper and lower bounds	Embedded	-10.486957409720384	60.94342128472867	170161
6b63e975630bbaa69b1ed18a601ba8cb7c4d11e5	a cost-based admission control algorithm for digital library multimedia systems storing heterogeneous objects	digital library;continuous media;multimedia systems;admission control;time constraint	We present and analyze a cost-based admission control algorithm for handling mixed workloads in modern multimedia systems such as a digital library multimedia system that must provide access services to heterogeneous objects stored in the library. The cost-based scheme considered in the paper is based on the concept of ‘rewards’ and ‘penalties’ associated with requests of various media object types. Instead of admitting object requests until resources are exhausted as a condition for admission control, resources are reserved to requests of different media types dynamically based on the cost-based scheme so that the system is capable of maximizing the total reward received by the system in response to workload changes in the environment. We analyze the maximum queue sizes for admitting discrete media requests to meet the imposed response-time constraints and for improving the total reward received by the system by exploiting leftover resources from servicing continuous media requests. A solution for the total reward obtainable is derived and validated via simulation.	digital library;greedy algorithm;i/o scheduling;media object server;object type (object-oriented programming);queueing theory;response time (technology);run time (program lifecycle phase);scheduling (computing);server (computing);simulation	Ing-Ray Chen;Naresh K Verma	2003	Comput. J.	10.1093/comjnl/46.6.645	real-time computing;digital library;simulation;computer science;operating system;database;multimedia	DB	-15.340033586529433	70.82584785677258	170418
66720640d7f82747249f10fbefa58b1ebc9c4db8	a virtual-service-domain based bidding algorithm for resource discovery in computational grid	computational grid;resource discovery;grid computing delay scalability resource management databases project management clustering algorithms costs large scale systems educational programs;resource allocation;software performance evaluation;peer to peer computing grid computing resource allocation software performance evaluation;system scalability virtual service domain bidding algorithm computational grid grid computing performance evaluation resource request bidding letter peer to peer resource discovery;peer to peer computing;peer to peer;grid computing	Resource discovery is a basic service in grid computing : gives a description of resources desired and finds the available one to match the description. In computational grid, how to discover resources efficiently has become a crucial factor to evaluate the performance in the whole system. In this paper, we present a bid-based resource discovery algorithm, which converts a resource request into a bidding letter and sends it to a group of physical services owned by the same virtual service to call for bidding. All resources receiving bidding letter make offers to bid according to our algorithm. Job manager selects the best one to response client request. To evaluate the performance of our method, we compare our system with the centralized and peer-to-peer resource discovery approaches. The analysis results show that our system reduces average response time of jobs, leverages the cost of the resource discovery, and improves the system scalability.	algorithm;centralized computing;grid computing;peer-to-peer;response time (technology);scalability	Hongbo Zou;Hai Jin;Zongfen Han;Jing Tie;Xuanhua Shi	2005	The 2005 IEEE/WIC/ACM International Conference on Web Intelligence (WI'05)	10.1109/WI.2005.17	semantic grid;resource allocation;computer science;database;distributed computing;management;world wide web;grid computing	HPC	-18.864558599394538	67.25930623514571	170659
c8b937fed40d7d8dfcf7fb1ba11d560f1d51c256	an adaptive sector-based routing model over structured peer-to-peer networks	structured peer to peer network;sector based;two tier routing	It is common that members of a peer-to-peer network join and leave the system at any time. But in a structured peer-to-peer network, frequent joining and leaving may cause huge maintenance overhead. To deal with this churn problem, we proposed a two-tier architecture called adaptive sector-based routing model (ASBRM). In ASBRM the key space is divided into several sectors and each one has a super peer who plays the role of the relay proxy of the sector. When the number of peer members in a sector exceeds a predefined threshold, it will split into two sectors so that the traffic and computational overhead of the super peer can be kept within an acceptable range. For the convenience of explanation, we combine ASBRM with Chord and perform a series of simulations. Both analysis and simulation results show that ASBRM achieves lower communication cost of members’ joining and leaving while at the same time the message routing path length is also shortened. 2012 Published by Elsevier B.V.	computation;disk sector;instruction path length;internet of things;key space (cryptography);lookup table;maximal set;multitier architecture;overhead (computing);peer-to-peer;relay;routing;simulation	Jiunn-Jye Lee;Hann-Huei Chiou;Chia-Chang Hsu;Chin-Laung Lei	2013	Computer Networks	10.1016/j.comnet.2012.11.006	simulation;telecommunications;distributed computing;computer security;computer network	Networks	-13.997621117175518	71.66872100488226	170698
26ec80da7838ece7ecd31826de17156edb4ba54f	placement strategy of virtual machines based on workload characteristics	noniterative matching approach placement strategy workload characteristics virtual machines workload resource allocation resource utilization;resource allocation;virtual machines placement strategy workload characteristics;virtual machining;resource management;workload characteristics;accuracy;placement strategy;time factors;virtual machines resource allocation;virtual machines;virtual machining resource management quality of service time factors accuracy correlation;correlation;quality of service	Traditional Virtual Machines are over-provisioned to provide peak performance and waste a lot of system resources. In this paper, we propose and implement a placement strategy of Virtual Machines based on workload characteristic-s. In our approach, the virtual machines are placed into various groups after several iterations and matching based on the complementary of virtual machines' workloads. Requested resources are allocated to virtual machines placed in the same group according to the sum of individual resource requests. The experiment results show that the resource utilization of our approach was increased by 37.5% compared to traditional placement approaches, and it was increased by 12.5% compared with non-iterative matching approach. And we can conclude that our approach uses fewer physical machines and provides acceptable application performance.	algorithm;iteration;matching (graph theory);quality of service;virtual machine	Jian Wan;Fei Pan;Congfeng Jiang	2012	2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum	10.1109/IPDPSW.2012.264	real-time computing;simulation;quality of service;resource allocation;computer science;virtual machine;resource management;operating system;distributed computing;accuracy and precision;correlation	HPC	-18.822888229973426	62.58378538414734	170723
03e702c07f53f326454383a8b1a36c2eac0b6a98	guaranteed smooth switch scheduling with low complexity	switches processor scheduling scheduling algorithm round robin delay jitter computational complexity packet switching matrix decomposition fabrics;time complexity;low complexity;packet switching;guaranteed rate;scheduling algorithm;matrix decomposition scheduling packet switching computational complexity;matrix decomposition;computational complexity;scheduling;smoothed round robin smooth switch scheduling packet delay computational complexity birkhoff von neumann decomposition;space complexity;packet delay;smoothed round robin	A smooth scheduling with guaranteed rate service and bounded packet delay is a desired objective of any switch scheduling algorithm. We present a scheme that generates low jitter schedules with low computational complexity. The scheduler uses an integer decomposition of the rate-matrix, similar to the Birkhoff-von Neumann decomposition. It improves the delay and jitter performance of the smooth scheduler as described in Keslassy et al. with an increase in the number of permutation matrices that the switch fabric has to cycle through. This increase is shown to be a constant for all practical purposes. Two algorithms are presented that have time complexity O(n/sup 2/ + log n) and space complexity O(n/sup 2/) and O(n) respectively. An existing scheduling algorithm for single links, smoothed round robin, is employed for scheduling the permutation matrices. This algorithm has a computational complexity overhead of O(1) and ensures smooth scheduling.	algorithm;birkhoff interpolation;computational complexity theory;dspace;network packet;overhead (computing);round-robin scheduling;schedule (computer science);scheduling (computing);smoothing;time complexity	Satya Ranjan Mohanty;Laxmi N. Bhuyan	2005	GLOBECOM '05. IEEE Global Telecommunications Conference, 2005.	10.1109/GLOCOM.2005.1577699	fair-share scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;average-case complexity;dynamic priority scheduling;computer science;rate-monotonic scheduling;worst-case complexity;mathematics;distributed computing;round-robin scheduling;scheduling;i/o scheduling;weighted round robin	Embedded	-10.273677266332	62.234414001873915	170830
b33989597b6865b71a4d9c0d01691ce0ae996c43	a constant-approximate feasibility test for multiprocessor real-time scheduling	earliest deadline first;real time scheduling	We devise the first constant-approximate feasibility test for sporadic multiprocessor real-time scheduling. We give an algorithm that, given a task system and  i¾? > 0, correctly decides either that the task system can be scheduled using the earliest deadline first algorithm on  m speed-(2 i¾? 1/ m +  i¾? ) machines, or that the system is infeasible for  m speed-1 machines. The running time of the algorithm is polynomial in the size of the task system and 1/ i¾? . We also provide an improved bound trading off speed for additional machines.#R##N##R##N#Our analysis relies on a new concept for counting the workload of an interval, that might also turn useful for analyzing other types of task systems.	multiprocessing;real-time transcription;scheduling (computing)	Vincenzo Bonifaci;Alberto Marchetti-Spaccamela;Sebastian Stiller	2008		10.1007/978-3-540-87744-8_18	parallel computing;real-time computing;earliest deadline first scheduling;computer science;distributed computing	Embedded	-10.128133962427189	60.731671321860304	170858
f3bf31743361c271d8016af28d6c5125a36f20c6	scalable scheduling algorithm for distributed memory machines	directed graphs;directed acyclic graph;optimisation;distributed memory systems;idle processors;processor scheduling;distributed memory machine;software performance evaluation;optimal scheduling algorithm;contracts;complexity;satisfiability;scheduling algorithm;software performance evaluation processor scheduling parallel algorithms distributed memory systems optimisation computational complexity directed graphs;computational complexity;optimal scheduling;scalable scheduling algorithm;clustering algorithms;distributed memory machines;idle processors scalable scheduling algorithm distributed memory machines task scheduling optimal schedule np complete problem directed acyclic graphs complexity processor scheduling parallel time;directed acyclic graphs;optimal schedule;task scheduling;parallel time;computational efficiency;scheduling algorithm optimal scheduling processor scheduling clustering algorithms partitioning algorithms np complete problem contracts costs computational efficiency equations;np complete problem;partitioning algorithms;parallel algorithms	The problem of scheduling tasks onto distributed memory machines f o r obtaining an optimal schedule is an NP-complete problem. In this paper, we present a scalable scheduling algorithm which can schedule the tasks of a directed acyclic graphs (DAGs) with a complexity of O ( V 2 ) in the worst case, where V is the number of nodes of the DAG. This algorithm generates an optimal schedule for a class of DAGs which satisfy certain condition and i f the required number of processors are available. The algorithm initially generates a schedule for a small number of processors. In case, the available number of processors are higher than the number of processors required by the initial schedule, the algorithm scales the schedule appropriately in an efort t o obtain a lower parallel t ime by utilizing the extra or idle processors. The algorithm has been applied to some practical DAGs and the results are very promising.	algorithm;best, worst and average case;central processing unit;directed acyclic graph;distributed memory;np-completeness;norm (social);scalability;schedule (computer science);scheduling (computing)	Sekhar Darbha;Dharma P. Agrawal	1996		10.1109/SPDP.1996.570320	parallel computing;real-time computing;computer science;distributed computing;directed acyclic graph;algorithm	Theory	-13.300590123652977	60.64102783462082	170934
a8fda9fb009774a6beabc0a4736273d4b210c696	programmable packet scheduling at line rate	switch hardware;programmable scheduling	Switches today provide a small menu of scheduling algorithms. While we can tweak scheduling parameters, we cannot modify algorithmic logic, or add a completely new algorithm, after the switch has been designed. This paper presents a design for a {\em programmable} packet scheduler, which allows scheduling algorithms---potentially algorithms that are unknown today---to be programmed into a switch without requiring hardware redesign.  Our design uses the property that scheduling algorithms make two decisions: in what order to schedule packets and when to schedule them. Further, we observe that in many scheduling algorithms, definitive decisions on these two questions can be made when packets are enqueued. We use these observations to build a programmable scheduler using a single abstraction: the push-in first-out queue (PIFO), a priority queue that maintains the scheduling order or time.  We show that a PIFO-based scheduler lets us program a wide variety of scheduling algorithms. We present a hardware design for this scheduler for a 64-port 10 Gbit/s shared-memory (output-queued) switch. Our design costs an additional 4% in chip area. In return, it lets us program many sophisticated algorithms, such as a 5-level hierarchical scheduler with programmable decisions at each level.	algorithm;algorithmic logic;gigabit;network packet;network scheduler;network switch;priority queue;scheduling (computing);shared memory	Anirudh Sivaraman;Suvinay Subramanian;Mohammad Alizadeh;Sharad Chole;Shang-Tse Chuang;Anurag Agrawal;Hari Balakrishnan;Tom Edsall;Sachin Katti;Nick McKeown	2016		10.1145/2934872.2934899	fair-share scheduling;fixed-priority pre-emptive scheduling;embedded system;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;deadline-monotonic scheduling;lottery scheduling;round-robin scheduling;scheduling;computer network	Networks	-5.009129886813697	64.3545581544849	170984
2aee256306d2644a3038ffe0a2c39a248584d4b9	hierarchical control policy for dynamic resource management in grid virtual organization	distributed system;hierarchical system;unfolding;grain size;optimisation;commande hierarchisee;empresa virtual;control de calidad;haute performance;systeme reparti;funcion utilidad;optimizacion;entreprise virtuelle;deploiement;grid applications;cross layer optimization;resource allocation;pricing;fonction utilite;systeme hierarchise;resource management;distributed computing;despliegue;utility function;structure sandwich;hierarchical control;supercomputer;fijacion precios;grid;supercomputador;sandwich structure;gestion recursos;sistema jerarquizado;sistema repartido;control jerarquizado;tariffication;grosor grano;crid;rejilla;tarification;theorie utilite;virtual organization;teoria utilidad;virtual enterprise;controle qualite;alto rendimiento;grille;gestion ressources;calculo repartido;optimization;asignacion recurso;estructura sandwich;allocation ressource;quality control;dynamic resource management;high performance;calcul reparti;fixation prix;grid system;superordinateur;tarificacion;utility theory;grosseur grain	This paper proposes a hierarchical control system in grid virtual organization. The hierarchical system can be decomposed into multiple application groups, which can be further decomposed into multiple applications. At the top of the hierarchy, the global controller controls the gross allocation of resources to the groups. At the next level down, the group controller coordinates the local deployments of all applications that consume the local allocation of resources. At the lowest level, the local controllers adjust the local resource usages to optimize the utility of single application. The hierarchical control system considers all applications and coordinates all layers of grid architecture upon any changes. According to different time granularity, we adopt a different control scheme. The global control considers all applications and coordinates three layers of grid architecture in response to large system changes at coarse time granularity, while local control adapts a single application to small changes at fine granularity. This paper adopts utility-driven cross layer optimization for grid applications to find a system wide optimization and solves the cross-layer optimization by using pricing based decomposition. A set of hierarchical utility functions is used to measure the performance of the grid system that follows the system, group and application hierarchy. This paper uses total utility to measure the overall quality of grid system. The experiments are conducted to test the performance of the hierarchical control algorithms.	algorithm;experiment;grid computing;hierarchical control system;ibm notes;mathematical optimization;overhead (computing);simulation;virtual organization;virtual organization (grid computing)	Chunlin Li;Layuan Li	2008	The Journal of Supercomputing	10.1007/s11227-008-0231-z	pricing;quality control;supercomputer;simulation;resource allocation;computer science;resource management;distributed computing;hierarchical control system;grid;operations research;utility;grain size	HPC	-13.693806358092921	64.1160873763668	171068
3844e6e52312a3e53a9d62a36c27dbc28985b268	adaptive real-time scheduling of cyber-physical energy systems		This article addresses the application of real-time scheduling to the reduction of the peak load of power consumption generated by electric loads in Cyber-Physical Energy Systems (CPES). The goal is to reduce the peak load while achieving a desired Quality of Service of the physical system under control. The considered physical processes are characterized by integrator dynamics and modelled as sporadic real-time activities. Timing constraints are obtained from physical parameters and are used to manage the activation of electric loads by a real-time scheduling algorithm. As a main contribution, an algorithm derived from the multi-processor real-time scheduling domain is proposed to efficiently deal with a high number of physical processes (i.e., electric loads), making its scalability suitable for large CPES, such as smart energy grids. The cyber-physical nature of the proposed method arises from the tight interaction between the physical processes operated by the electric loads, and the applied scheduling.  To allow the use of the proposed approach in practical applications, modelling approximations and uncertainties on physical parameters are explicitly included in the model. An adaptive control strategy is proposed to guarantee the requirements on physical values under control in presence of modelling and measurement uncertainties. The compensation for such uncertainties is done by dynamically adapting the values of timing parameters used by the scheduler. Formal results have been derived to put into relationship the values of quantities describing the physical process with real-time parameters used to model and to schedule the activation of loads. The performance of the method is evaluated by means of physically accurate simulations of thermal systems, showing a remarkable reduction of the peak load and a robust enforcement of the desired physical requirements.	algorithm;approximation;control theory;load profile;multiprocessing;quality of service;real-time clock;real-time computing;real-time transcription;requirement;scalability;scheduling (computing);simulation	Daniele De Martini;Guido Benetti;Marco L. Della Vedova;Tullio Facchinetti	2017	TCPS	10.1145/3047412	cyber-physical system;integrator;scalability;earliest deadline first scheduling;engineering;real-time computing;adaptive control;scheduling (computing);enforcement;physical system;control engineering	Embedded	-7.146875955039461	60.7077024031626	171207
174c700a935423694db5363cc59836b59cfa354b	design procedure to minimize power consumption and delays in wsan	control application;time division multiple access;reliability;system configuration;sensors;job shop scheduling;system analysis and design;wireless network;actuators;wireless sensor networks delays jitter power consumption;computer architecture;real time systems sensors program processors actuators time division multiple access computer architecture job shop scheduling;jitter power consumption delays wsan reliability latency;industrial application;latency;power consumption;jitter;wsan;program processors;wireless sensor networks;energy saving;delays;real time systems	Current trends in the development of industrial applications enforce the use of wireless networks to communicate the system nodes mainly to increase flexibility and reliability of these applications and to reduce the implementation cost. However, in control applications, as consequence of the latency and jitter generated by the network, not always the results achieved by the experimental results and desired performance are coherent. This is due to the imprecise models for system analysis and design used and the non appropriated validation methods and platforms to support these models. Therefore this paper presents a method to achieve an optimal system configuration in order to fulfil the desired performance in control applications with a significant energy saving and minimum delay.	coherence (physics);control flow;data validation;heuristic (computer science);mathematical optimization;routing;system analysis;system configuration	Diego Martínez;Patricia Balbastre Betoret;Francisco Blanes;José-Enrique Simó-Ten;Alfons Crespo	2010	2010 IEEE 15th Conference on Emerging Technologies & Factory Automation (ETFA 2010)	10.1109/ETFA.2010.5641283	embedded system;job shop scheduling;electronic engineering;latency;real-time computing;wireless sensor network;jitter;telecommunications;computer science;engineering;sensor;operating system;wireless network;reliability;structured systems analysis and design method;time division multiple access;computer network;actuator	EDA	-7.474176483252841	62.23756013371533	171489
f1d329b7d28b9122abe3ef06c3a79a82a488ddb1	implementation of a hybrid tcp/ip offload engine prototype	internet protocol;field programmable gate array;calculateur embarque;programacion entera;protocole transmission;protocolo internet;protocole internet;network performance;red puerta programable;protocole tcp;reseau porte programmable;programmation en nombres entiers;transmission control protocol;computer architecture;protocolo transmision;architecture ordinateur;protocolo tcp;integer programming;boarded computer;arquitectura ordenador;embedded processor;calculador embarque;transmission protocol	Recently TCP/IP Offload Engine (TOE) technology, which processes TCP/IP on a network adapter instead of the host CPU, has become an important approach to reduce TCP/IP processing overhead in the host CPU. There have been two approaches to implementing TOE: software TOE, in which TCP/IP is processed by an embedded processor on a network adapter; and hardware TOE, in which all TCP/IP functions are implemented by hardware. This paper proposes a hybrid TOE that combines software and hardware functions in the TOE. In the hybrid TOE, functions that cannot have guaranteed performance on an embedded processor because of heavy load are implemented by hardware. Other functions that do not impose as much load are implemented by software on embedded processors. The hybrid TOE guarantees network performance near that of hardware TOE and it has the advantage of flexibility, because it is easy to add new functions or offload upper-level protocols of TCP/IP. In this paper, we developed a prototype board with an FPGA and an ARM processor to implement a hybrid TOE prototype. We implemented the hardware modules on the FPGA and the software modules on the ARM processor. We also developed a coprocessing mechanism between the hardware and software modules. Experimental results proved that the hybrid TOE prototype can greatly reduce the load on a host CPU and we analyzed the effects of the coprocessing mechanism. Finally, we analyzed important features that are required to implement a complete hybrid TOE and we predict its performance.	prototype;tcp offload engine	Hankook Jang;Sang-Hwa Chung;Soo-Cheol Oh	2005		10.1007/11572961_37	internet protocol;embedded system;large segment offload;real-time computing;integer programming;computer science;tcp offload engine;operating system;transmission control protocol;distributed computing;network performance;computer security;field-programmable gate array	OS	-5.7132550635460735	73.05781474411663	171632
8a91a3f5419dacc31d05e669407148e710e4f7cf	a task scheduling algorithm for the parallel expression evaluation in a reconfigurable fully digit on-line network	precedence constraint;task scheduling	In this paper, we present a task scheduling algorithm which accounts for digit-level pipelines of on-line arithmetic units when a limited number of heterogeneous on-line arithmetic units can be connected totally with each other and the network is reconfigurable during the execution. In on-line arithmetic, an arithmetic unit can be reused after the completion of its computing process while its result is available digit by digit during the computation. Thus, a new criterion, called the maximal delay is introduced to take into account additional precedence constraints based on the on-line delay.	algorithm;scheduling (computing)	Hong-Jin Yeh	1992		10.1007/3-540-55895-0_466	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;rate-monotonic scheduling;two-level scheduling;distributed computing;round-robin scheduling	HPC	-10.84220249638439	60.71216405790753	171650
0914e130b0e70572ba5e94cbbab163ffbf6fce32	deterministic scheduling of cbr and vbr media flows on parallel media servers	debit binaire variable;algoritmo paralelo;velocidad de bit variable;parallel algorithm;constant bit rate;continuous media;real time;multimedia servers;approche deterministe;parallel computation;algorithme parallele;serveur multimedia;deterministic approach;calculo paralelo;scheduling;real time scheduling;temps reel;enfoque determinista;variable bit rate;parallel computer;media streaming;tiempo real;ordonamiento;calcul parallele;ordonnancement	We study a new design strategy for the implementation of Parallel Media Servers with a predictable behavior. This strategy makes the timing properties and the quality of presentation of a set of media streams predictable. The proposed real-time scheduling approach exploits the performance of parallel environments and seems a promising method that brings the advantages of parallel computation in media servers. The proposed mechanism provides deterministic service for both Constant Bit Rate (CBR) and Variable Bit Rate (VBR) streams. A prototype implementation of the proposed parallel media server illustrates the concepts of server allocation and scheduling of continuous media streams.	case-based reasoning;scheduling (computing);volume boot record	Costas Mourlas	2002		10.1007/3-540-45706-2_114	parallel computing;real-time computing;computer science;operating system;distributed computing;parallel algorithm;variable bitrate;constant bitrate;deterministic system;scheduling	HPC	-11.725272614184561	63.49155688003377	171775
0d62920d6a39873923624644595da97b3c4a323d	high performance flow feature extraction with multi-core processors	machine learning algorithms;security policies;multi core processor;serial architecture;software tool;high performance flow feature extraction;network protocol;computer network security;packet processing;performance evaluation;serial architecture multicore processors high performance flow feature extraction network traffic network applications packet flows security policies network protocols open source parallel software tool performance evaluation packet processing hybrid architecture;next generation network;network applications;open source parallel software tool;parallelism flow feature extraction multi core processors;real time;process network;parallel programming;telecommunication traffic;network protocols;parallelism;parallel architectures;flow feature extraction;network traffic;feature extraction instruction sets multicore processing payloads throughput machine learning algorithms;feature extraction;packet flows;multicore processing;hybrid architecture;payloads;multicore processors;software tools;multiprocessing systems;security policy;high performance;telecommunication traffic computer network security feature extraction multiprocessing systems parallel architectures parallel processing parallel programming performance evaluation software tools;multi core processors;parallel processing;instruction sets;throughput;open source	Next generation networks anticipate an increasing amount of network traffic from a wide range of emerging network applications. The features of packet flows (such as the minimal packet inter-arrival time and the number of packets with non-zero options in TCP headers) are used frequently in determining the traffic type and applying security policies. However, the extraction of flow features is difficult due to the increasing line rates, a broad range of network protocols, and a variety of complex flow features. In this paper, we leverage the multi-core processors to speed up the feature extraction process. We design an open source parallel software tool, aiming for processing network packet flows in real-time. We implement the software in four different designs including serial, parallel, pipelined and hybrid architectures. We evaluate the performance of the parallel software tool through measurement experiments. Our experimental results show that each method increases the packet processing throughput by 5-7% in comparison with the previous method. And finally the implementation based on the hybrid architecture improves the packet processing performance by 19.3% than the implementation based on the serial architecture.	central processing unit;communications protocol;experiment;feature extraction;multi-core processor;network packet;network traffic control;next-generation network;open-source software;parallel computing;pipeline (computing);programming tool;real-time clock;serial port;throughput;time of arrival	Sanping Li;Yan Luo	2010	2010 IEEE Fifth International Conference on Networking, Architecture, and Storage	10.1109/NAS.2010.36	traffic generation model;multi-core processor;parallel processing;parallel computing;real-time computing;packet analyzer;packet generator;computer science;processing delay;operating system;distributed computing;packet switch;computer network	HPC	-7.420431532246519	66.24032026808689	171848
bd0c01e6fd4d8403f287b47a9e21aad3c66f9c36	joint scheduling of distributed complex periodic and hard aperiodic tasks in statically scheduled systems	guarantee ratios;aperiodic tasks;statically scheduled;processor scheduling;joint scheduling;load aperiodic tasks joint scheduling distributed real time systems guarantee ratios periodic tasks statically scheduled precedence constrained deadline scenarios;distributed processing;testing;processor scheduling scheduling algorithm real time systems dynamic scheduling testing computer science runtime computational modeling computer simulation process control;runtime;deadline scenarios;scheduling algorithm;computational modeling;distributed real time system;periodic tasks;precedence constrained;scheduling;process control;computer science;distributed real time systems;computer simulation;real time systems processor scheduling scheduling distributed processing;dynamic scheduling;real time systems	In this paper we present algorithms for the joint scheduling of periodic and aperiodic tasks in statically scheduled distributed real-time systems. Periodic tasks are precedence constrained, distributed, and communicating over the nodes of the systems. Both soft and hard aperiodic tasks are handled. After a static schedule has been created in a rst step, the algorithms determine the amount and distribution of unused resources and leeway in it. These are then used to incorporate aperiodic tasks into the schedule by shifting the periodic tasks' execution, without violating their feasibility. Run-time mechanisms are simple and require only little memory. Processors and communication nodes can be utilized fully. The algorithm performs an optimal online guarantee algorithm for hard aperiodic tasks of O(N). An extensive simulation study exhibits very high guarantee ratios for various load and deadline scenarios , which underlines the eeciency of our method.	algorithm;aperiodic graph;central processing unit;real-time clock;real-time computing;scheduling (computing);serializability;simulation	Gerhard Fohler	1995		10.1109/REAL.1995.495205	computer simulation;parallel computing;real-time computing;computer science;operating system;process control;distributed computing;scheduling	Embedded	-10.252847404023338	60.554038781845236	171864
8ca58402c8be5859907d8b6e9cb207092e74be2c	reconfigurable gang scheduling algorithm	workload;tiempo respuesta;dynamic change;distributed system;algoritmo paralelo;reponse temporelle;occupation time;besoin de l utilisateur;evaluation performance;systeme reparti;parallel algorithm;performance evaluation;execution time;reconfigurable architectures;gang scheduling;evaluacion prestacion;multiprogrammation;exigence usager;exigencia usuario;metric;response time;necesidad usuario;multiprogramming;coreglamento;algorithme parallele;performance metric;temps reponse;sistema repartido;temps occupation;time response;user need;multiprogramacion;user requirement;scheduling;performance analysis;tiempo ocupacion;charge travail;coordonnancement;user requirements;temps execution;metrico;parallel architecture;tiempo ejecucion;carga trabajo;respuesta temporal;architecture reconfigurable;ordonnancement;metrique;reglamento	 Using a single traditional gang scheduling algorithm cannot provide the best performance for all workloads and parallel architectures. A solution for this problem is the use of an algorithm that is capable of dynamically changing its form (configuration) into a more appropriate one, according to environment variations and user requirements. In this paper, we propose, implement and analyze the performance of a Reconfigurable Gang Scheduling Algorithm (RGSA) using simulation. The RGSA uses combinations of independent features that are often implemented in GSAs such as: packing and re-packing schemes (alternative scheduling etc.), multiprogramming levels etc. Ideally, the algorithm may assume infinite configurations and it reconfigures itself according to entry parameters such as: performance metrics (mean utilization, mean jobs response time etc.) and workload characteristics (mean jobs execution time, mean parallelism degree of jobs etc.). Also ideally, a reconfiguration causes the algorithm to output the best configuration for a particular situation considering the system’s state at a given moment and based on past information. The main contributions of this paper are: the definition, proposal, implementation and performance analysis of RGSA. Keywords Reconfigurable Algorithm, Gang Scheduling, Performance Analysis.	algorithm;computer multitasking;gang scheduling;job stream;parallel computing;profiling (computer programming);requirement;response time (technology);run time (program lifecycle phase);scheduling (computing);set packing;simulation;user requirements document	Luís Fabrício Wanderley Góes;Carlos Augusto Paiva da Silva Martins	2004		10.1007/11407522_5	fair-share scheduling;embedded system;parallel computing;real-time computing;gang scheduling;dynamic priority scheduling;computer science;user requirements document;operating system	HPC	-13.09148573439988	62.94136472132795	171876
5ec12f46999ad1578103044ca5ee96351a82f32a	live sharing with multimodal modes in mobile network	key frame;live sharing;multimodal;video;mobile network	Live video sharing is a newly generated and interesting service, with which users can broadcast and view the videos being recorded by mobile phones. However, mobile network usually blocks users to enjoy that service since video transmitting is still a nontrivial task with poor bandwidth. In order to make live sharing easier in mobile environment, a novel service with multimodal modes is proposed in this paper, which could save a lot of bandwidth for sharing and is more adaptive in mobile network. To save bandwidth and introduce differentiated user experience, real-time extracted key-frames, audio or hybrid information can be transmitted instead of original video stream. Both publishers and receivers can select suitable mode according to their preference or network condition. Thanks to the key frame mode of the proposed service, detailed tagging of video content and live cooperation with other SNS can be implemented. Experimental results and user study demonstrate that the proposed multimodal live sharing service is of high adaption of mobile network and introduces direct and interesting user experience.	multimodal interaction	Xiao Zeng;Kongqiao Wang;Da Huo	2012	J. Mobile Multimedia		cellular network;mobile search;video;computer science;multimodal interaction;multimedia;internet privacy;world wide web;computer network	HCI	-17.444586950240932	73.89293408016273	172222
6536f59b8a4eabdc18453c27cbf9ef5308be3b91	on the feasibility of dynamic superpeer ratio maintenance	protocols;node arrivals;p2p;p2p applications scalability;maintenance engineering;pso;pso dynamic superpeer ratio maintenance p2p applications scalability node arrivals node departures optimization problem distributed algorithm particle swarm optimization;optimization problem;particle swarm optimizer;peer to peer computing protocols maintenance engineering heuristic algorithms bandwidth scalability optimization;heuristic algorithms;particle swarm optimization;dynamic superpeer ratio maintenance;bandwidth;optimization;scalability;peer to peer computing;node departures;peer to peer computing particle swarm optimisation;distributed algorithm;particle swarm optimisation	"""The notion of """"superpeer"""" has been shown to be very effective to increase the scalability of P2P applications. For superpeer systems to work, it is critical to preserve the optimal ratio between the number of superpeers and normal peers participating in the overlay. This requires that peers change dynamically their role (i.e., from su-perpeer to normal peer and vice versa) in the presence of node arrivals and departures, a problem that is hard to solve if no peer has global knowledge of the network. In this article, we first investigate the feasibility of superpeer ratio maintenance when each peer can decide to be a superpeer independently of each other. We then show how this problem can be treated as an optimization problem, and we propose a distributed algorithm, based on particle swarm optimization (PSO), to solve it. Our simulation results prove the viability of a PSO-based approach for this problem."""	distributed algorithm;mathematical optimization;optimization problem;particle swarm optimization;scalability;simulation;system reference manual	Marc Sánchez Artigas;Pedro García López;Antonio F. Gómez-Skarmeta	2008	2008 Eighth International Conference on Peer-to-Peer Computing	10.1109/P2P.2008.15	maintenance engineering;optimization problem;communications protocol;distributed algorithm;mathematical optimization;scalability;computer science;theoretical computer science;peer-to-peer;distributed computing;particle swarm optimization;bandwidth	DB	-10.628260487879922	73.87595973433828	172450
f6aaf1adf9750d10480ed36d1b5c4b8f7fc869b0	an application of queuing theory to the design of a message-switching computer system	file attente;message switching;technology;queueing theory;queue;system design;information processing;technologie;fila de espera;commutation message;traitement information;perte message;conception systeme;procesamiento de informacion;tecnologia	Inexact or real-world queueing techniques are used to determine that the number of buffers provided in system design is indeed adequate to guard against message loss.	linc;queueing theory;systems design	Jack Gostl;Irwin Greenberg	1985	Commun. ACM	10.1145/3532.3535	real-time computing;information processing;telecommunications;computer science;distributed computing;message switching;programming language;queueing theory;queue;technology	Theory	-4.718226362161978	73.04324804475547	172543
0ff326a9b93a0585db8ecd77c87d165bd56ce12a	performance modeling of an apache web server with bursty arrival traffic	blocking probability;elektroteknik och elektronik;capacity planning;perforation;overload control;processor sharing;queueing model;markov modulated poisson process;kommunikationssystem;performance model;web server performance;world wide web;model fitting	-Performance modeling is an important topic in capacity planning and overload control for web servers. We present a queueing model of an Apache web server that uses bursty arrival traffic. The arrivals of HTTP requests is assumed to be a Markov Modulated Poisson Process and the service discipline of the server is processor sharing. The total number of requests that can be processed at one time is limited to K. We obtain web server performance metrics such as average response time, throughput and blocking probability by simulations. Compared to other models, our model is conceptually simple. The model has been validated through measurements and simulations in our lab. The performance metrics predicted by the model fit well to the experimental outcome. Keywords--Internet, World Wide Web, web server, performance model, MMPP.	blocking (computing);erlang (unit);event-driven programming;experiment;fits;hard disk drive;internet;markov chain;modulation;queueing theory;response time (technology);server (computing);simulation;thread (computing);throughput;web server;world wide web	Mikael Andersson;Jianhua Cao;Maria Kihl;Christian Nyberg	2003			real-time computing;simulation;computer science;world wide web	Metrics	-12.002452171631782	67.02632621856687	172577
4f4674b3b9ca3e88d8e90ff159695f1679ef75fb	a comparison of heuristics for scheduling multiprocessor tasks on three dedicated processors	multiprocessor tasks;scheduling;dedicated processors	We consider the problem of scheduling a set of independent multiprocessor tasks on three dedicated processors in order to minimize the makespan. We propose a new heuristic, called Divide Uniprocessor Tasks (DUT), and we provide simulation results comparing the effectiveness of DUT with previously known heuristics.	central processing unit;heuristic (computer science);multiprocessing;scheduling (computing)	Abdel Krim Amoura;Evripidis Bampis;Yannis Manoussakis;Zsolt Tuza	1999	Parallel Computing	10.1016/S0167-8191(98)00102-1	computer architecture;parallel computing;real-time computing;computer science;operating system;scheduling;multiprocessor scheduling;symmetric multiprocessor system	HPC	-12.198643645355178	61.4806063940023	172792
9ee640209c986df6b0839cf26ec90d9bcc1eb7cc	lower-bound complexity algorithm for task scheduling on heterogeneous grid	task scheduling;grid computing;heterogeneous grids;68m14	The problem of best schedule of dependent-tasks application into nodes of computational grid in low complexity is the most important issue to obtain high performance application execution. Scheduling can be performed at compile-time or at run-time depends on tasks and grid-nodes available information. Due to the NP-completeness of the problem, heuristics are used in compile-time solution of the problem. Two of these heuristics are list-scheduling and duplication-based. List-scheduling heuristics produce reasonable schedule in reasonable time complexity, while duplication-based heuristics produce better schedule in higher time complexity. Many algorithms based on list-scheduling and duplication-based heuristics have been addressed in the literature. This paper proposes a scheduling algorithm based on list-scheduling and duplication-based heuristics. The algorithm is called Best-Node based Critical-Parent. The algorithm keeps the lower-bound complexity of any classes of heuristics-based scheduling algorithms. Random generated applications, in addition to real-world applications have been examined. The experimental results based on computer simulation show that the proposed algorithm performed better than the most-recent and well-known existing algorithms.	algorithm;compile time;compiler;computer simulation;grid computing;heuristic (computer science);list scheduling;np-completeness;schedule (computer science);scheduling (computing);time complexity	Asmaa Atef;Tarek Hagras;Youssef B. Mahdy;Jan Janecek	2017	Computing	10.1007/s00607-017-0558-5	grid;scheduling (computing);time complexity;grid computing;dynamic priority scheduling;fair-share scheduling;real-time computing;algorithm;heuristics;computer science;distributed computing;upper and lower bounds	HPC	-13.95721653403019	61.57359244480868	172911
0ecadd2787a4c035e82c22c3bca7b092ee20a4e2	decomposition based algorithm for state prediction in large scale distributed systems	distributed system;prediction method;resource utilization;error reduction;neural networks;availability;resource allocation;distributed processing;prediction algorithms large scale systems resource management monitoring availability frequency artificial intelligence system testing real time systems load management;resource manager;resource management;real time monitoring;prediction algorithms;state monitoring;artificial intelligent;monitoring;load management;distributed systems state monitoring prediction method neural networks fourier decomposition;system testing;fourier analysis;artificial intelligence;load balance;large scale distributed systems;distributed systems;frequency;resource management system;artificial intelligence models decomposition based algorithm state prediction large scale distributed systems resource management fourier decomposition alice experiment system monitoring load balancing;large scale systems;fourier decomposition;neural network;real time systems;resource allocation artificial intelligence distributed processing fourier analysis large scale systems	Prediction represents an important component of resource management, providing information about the future state, utilization and availability of resources. We propose a new prediction algorithm inspired from the decomposition of a complex wave into simpler waves with fixed frequencies (similar to Fourier decomposition). The partial results obtained from this decomposition stage are combined using approaches inspired from artificial intelligence models. The experimental results for different system parameters, used in Alice experiment, highlight the great improvement, discussed in terms of error reduction, offered by this new prediction algorithm. The tests were made using real-time monitoring data provided by a system monitoring tool, in the case of one-step and multi-step ahead prediction. The prediction's results can be used by the resource management systems in order to improve the scheduling decisions, assuring the load balancing and optimizing the resource utilization.	algorithm;artificial intelligence;distributed computing;load balancing (computing);meta-scheduling;real-time clock;resource management (computing);sampling (signal processing);scheduling (computing);system monitoring;time series;vii	Mihai Istin;Andreea Visan;Florin Pop;Valentin Cristea	2010	2010 Ninth International Symposium on Parallel and Distributed Computing	10.1109/ISPDC.2010.13	availability;in situ resource utilization;real-time computing;simulation;prediction;resource allocation;computer science;load balancing;resource management;frequency;data mining;distributed computing;fourier analysis;system testing;fourier series	HPC	-16.756732175315936	62.15941152703896	172986
b56c4eed7770f43b4828ef95e7f4bb70e2bd169e	group mutual exclusion in token rings	group mutual exclusion	The group mutual exclusion (GME) problem was introduced by J oung [6]. The GME solution allowsn processes to share m mutually exclusive resources. We first present a group mutual exclusion algorit hm (Algorithm GME ) for anonymous token rings. The space requirement and the si ze of messages of this algorithm depend only on the number of share d resources (O(logm) bits). So, the proposed algorithm solves the problem sugges ted in [7], which is to obtain a solution using messages of bounde d size. All costs related to the time depend on n. We then present two variations of Algorithm GME . We design the second algorithm (AlgorithmGME) such that its cost depends mainly on the m instead ofn. The third algorithm (Algorithm nmGME ) is a general algorithm which takes advantage of the lowest value betweenandm.	algorithm;depth-first search;gme of deutscher wetterdienst;message passing;mutual exclusion;token ring	Sébastien Cantarell;Ajoy Kumar Datta;Franck Petit;Vincent Villain	2001		10.1093/comjnl/bxh077	computer science;theoretical computer science;mathematics;distributed computing;suzuki-kasami algorithm;algorithm	Theory	-13.501261440585528	65.74587052811475	172999
105cc4eb4036efd2c9b47988b66ebff5d8c35fd0	the design and evaluation of a self-organizing superpeer network	semantic similarity;protocols;pattern clustering;history;fault tolerant;semantic clustering;self adjusting systems;p2p;data mining;network topology;self organizing system;computer architecture;peer to peer computing protocols computer architecture history organizing data mining load management;sospnet architecture self organizing network peer to peer network superpeer network file sharing;organizing;load management;self organization;network architecture;load balance;file sharing;p2p networks;peer to peer computing;self adjusting systems pattern clustering peer to peer computing;self organizing systems;peer to peer;self organizing systems peer to peer superpeer architectures semantic clustering;superpeer architectures	Superpeer architectures exploit the heterogeneity of nodes in a peer-to-peer (P2P) network by assigning additional responsibilities to higher capacity nodes. In the design of a superpeer network for file sharing, several issues have to be addressed: how client peers are related to superpeers, how superpeers locate files, how the load is balanced among the superpeers, and how the system deals with node failures. In this paper, we introduce a self-organizing superpeer network architecture (SOSPNet) that solves these issues in a fully decentralized manner. SOSPNet maintains a superpeer network topology that reflects the semantic similarity of peers sharing content interests. Superpeers maintain semantic caches of pointers to files, which are requested by peers with similar interests. Client peers, on the other hand, dynamically select superpeers offering the best search performance. We show how this simple approach can be employed not only to optimize searching, but also to solve generally difficult problems encountered in P2P architectures such as load balancing and fault tolerance. We evaluate SOSPNet using a model of the semantic structure derived from eight-month traces of two large file-sharing communities. The obtained results indicate that SOSPNet achieves close-to-optimal file search performance, quickly adjusts to changes in the environment (node joins and leaves), survives even catastrophic node failures, and efficiently distributes the system load taking into account superpeer capacities.	fault tolerance;file sharing;load (computing);load balancing (computing);network architecture;network topology;organizing (structure);peer-to-peer;self-organization;semantic similarity;tracing (software)	Pawel Garbacki;Dick H. J. Epema;Maarten van Steen	2010	IEEE Transactions on Computers	10.1109/TC.2009.157	parallel computing;self-organization;computer science;operating system;database;distributed computing;world wide web;computer network	Networks	-11.66768680656493	73.25806845386191	173107
a7189cc14de9878bb212bdf8c304008e109a1ed0	laxity-based restricted-migration scheduling	static priority;multiprocessor scheduling;processor scheduling;real time;scheduling algorithm;processor scheduling multiprocessing systems;utilization bound laxity based restricted migration scheduling real time multiprocessor scheduling periodic tasksets static priority scheduling restricted migration approach global scheduling;multiprocessing systems;heuristic algorithms prediction algorithms scheduling algorithm schedules scheduling tin	We focus on the real-time multiprocessor scheduling of periodic tasksets. We propose a new static priority scheduling algorithm based on the restricted-migration approach. Restricted-migration approach is a global scheduling approach for which the number of migrations is bounded just by one migration per job at most. Our algorithm uses the laxity of already admitted jobs to decide the admission of newly arrived jobs. We prove that this algorithm is predictable. We give a feasible interval and we propose a utilization bound for this algorithm. We also compare our algorithm to other global algorithms in terms of schedulability by simulations.	algorithm;multiprocessing;multiprocessor scheduling;process migration;real-time clock;scheduling (computing);simulation;slack variable	Frédéric Fauberteau;Serge Midonnet;Laurent George	2011	ETFA2011	10.1109/ETFA.2011.6059012	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;foreground-background;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling;multiprocessor scheduling;proportionally fair	Embedded	-10.750803381280424	60.93343425530942	173156
76d4d91dcfe4c3bdf52bd9469914140d1a4a9e93	a distributed quality of service index framework	distributed system;web service selection;query processing;binary search trees;distributed networks;resource allocation;distributed processing;quality of service peer to peer computing web services indexes binary search trees load modeling ontologies;tree structured distributed network;tree data structures;web service;satisfiability;non functional requirement;dqos tree;indexes;structured distributed system;indexation;tree structure;qos index framework;load balance web service selection quality of service dqos tree;web services;nonfunctional requirement;overlay network;ontologies;distributed quality of service index framework;load balance;query load imbalance web service nonfunctional requirement distributed quality of service index framework qos index framework structured distributed system chord overlay network tree structured distributed network dqos tree query effectiveness;query effectiveness;web services distributed processing quality of service query processing resource allocation tree data structures;peer to peer computing;quality of service;chord overlay network;load modeling;query load imbalance	To efficiently support customers to find web service which satisfies the non-functional requirement, a distributed quality of service(QoS) index framework is proposed in this paper. The framework consists of two kinds of structured distributed system, one is chord overlay network which is assigned to classify the web services according to the similarity of web services descriptions, the other is a tree-structured distributed network named DQoS tree which manages the classified web services' QoS. Since there is a dominance relation among multi-dimension QoS, therefore, a guideline based on this relation to construct a QoS tree managed by a sub peer is designed. Through the dominance relation, it's easily find the qualified QoS among web services with less compare times, thus, the query effectiveness is guaranteed. Additionally, to avoid the load imbalance of query load in the DQoS tree, a load balance strategy is introduced which can balance work load efficiently. Experimental results validate the effectiveness and efficiency of the proposed approaches.	distributed computing;functional requirement;load balancing (computing);non-functional requirement;overlay network;quality of service;self-balancing binary search tree;tree structure;web service	XiLu Zhu;Bai Wang	2010	2010 IEEE Asia-Pacific Services Computing Conference	10.1109/APSCC.2010.80	web service;mobile qos;computer science;database;distributed computing;law;world wide web;computer network	DB	-19.11647331520571	67.57313076509075	173178
90858a68f4c1e5cb2c185e70586dd42e19548bc6	multi-processor schedulability analysis of preemptive real-time tasks with variable execution times	preemptive scheduling;real time;schedulability analysis;datavetenskap datalogi;scheduling problem;timed automata;computer science;real time systems	In this paper, we study schedulability analysis problems for multi-processor real-time systems. Assume a set of real time tasks whose execution times and deadlines are known. We use timed automata to describe the non-deterministic arrival times of tasks. The schedulability problem is to check whether the released task instances can be executed within their given deadlines on a multi-processor platform where each processor has a task queue to bu er task instances scheduled to run on the processor. On the positive side, we show that the problem is decidable for systems with non-preemptive schedulers or tasks with xed execution times. A surprising negative result is that for multi-processor systems with variable task execution times and a non-preemptive scheduler, the schedulability analysis problem is undecidable, which is still an open problem in the single-processor setting.	automata theory;central processing unit;computation;computer multitasking;multiprocessing;preemption (computing);real-time clock;real-time computing;scheduling (computing);scheduling analysis real-time systems;timed automaton;undecidable problem	Pavel Krcál;Martin Stigge;Wang Yi	2007		10.1007/978-3-540-75454-1_20	fixed-priority pre-emptive scheduling;job shop scheduling;parallel computing;real-time computing;computer science;distributed computing;preemption;worst-case execution time	Embedded	-9.99818043367263	60.915368847623604	173253
7c1d0f88ab8d13be74eb23c571992086dd6866f3	the optimization theory of file partition in network storage environment	optimisation;success file block storage process;probability;time measurement;availability redundancy optimization mathematical model equations batteries time measurement;availability;storage management;reliability modeling;storage node availability;network storage;reliability theory;storage area networks;optimal strategy;network storage facing massive files;redundancy;network storage environment;file partition;storage management optimisation probability reliability theory storage area networks;batteries;success file storage process;mathematical model;partition granularity;network storage facing massive files optimization theory file partition network storage environment network nodes storage nodes reliability model storage node availability probability model success file block storage process store after partition strategy success file storage process partition granularity optimal strategy;optimization;store after partition strategy;probability model;optimality theory;optimizing file partition;optimization theory;optimizing file partition network storage storage node availability file partition;storage nodes;network nodes;reliability model	The instability of the network and storage nodes may lead to the failure of the storage process in the network storage environment. In this paper, we establish the realibility model of the storage node availability, and the probability model of a success file block storage process, give the Store-After-Partition Strategy, compare the probabilities of a success file storage process at different partition granularities, and finally put forward the optimal strategy of file partition among network storage environment. This strategy is valuable for network storage facing massive files.	block (data storage);instability;mathematical optimization;network-attached storage	Wu Hai-Jia;Liu Peng;Chen Wei-Wei	2010	2010 Ninth International Conference on Grid and Cloud Computing	10.1109/GCC.2010.19	file server;availability;parallel computing;real-time computing;storage area network;converged storage;reliability theory;computer science;probability;mathematical model;emc invista;database;storage violation;redundancy;node;information repository;global namespace;time	HPC	-10.099479704978656	71.7277706363224	173406
31f2bfb075dd447ea0b79932ff13e3725a8550d7	clock synchronization integrated with traffic smoothing technique for distributed hard real-time systems	control systems;frequency synchronization;embedded control system;performance evaluation;clocks;real time;clocks smoothing methods real time systems frequency synchronization hardware control systems telecommunication traffic access protocols peer to peer computing registers;telecommunication traffic;smoothing methods;distributed real time system;hard real time system;registers;access protocols;clock synchronization;peer to peer computing;hard real time;hardware;real time systems	"""This paper introduces a novel lightweight clock synchronization protocol (LCSP) and BUB clock synchronization algorithm based on real-time micro-kernel. Unlike other clock synchronization approaches which rely on redundant exchanged messages, this approach takes advantages of the traffic smoothing technique at each end node to suppress or """"block"""" other traffics during the clock synchronization duration. The BUB algorithm efficiently decreases the number of synchronization messages exchanged during each synchronization round and can easily extend to large distributed real-time systems. Performance evaluation results prove that the LCSP protocol and the BUB algorithm can provide perfect synchronization precision and are appropriate for most distributed hard real-time and embedded control systems, when integrated with the traffic smoothing technique."""	algorithm;clock synchronization;clustered file system;communications protocol;computer cluster;control system;embedded system;fault tolerance;n-gram;performance evaluation;protocol stack;real-time clock;real-time computing;real-time transcription;server (computing);smoothing;time server	Hai Jin;Minghu Zhang;Pengliu Tan	2006	The Sixth IEEE International Conference on Computer and Information Technology (CIT'06)	10.1109/CIT.2006.61	clock synchronization;embedded system;real-time computing;computer science;control system;operating system;self-clocking signal;distributed computing;data synchronization;processor register;synchronization;frame synchronization;computer network	Embedded	-6.345079483571941	70.8097123965129	173550
ba1e1f83b7223e1d95ce3507ba6785833796a9fd	adaptive kalman filter for time synchronization over packet-switched networks: an heuristic approach	distributed application;kalman filtering;network time protocol adaptive kalman filter time synchronization packet switched networks distributed applications ntp synchronization protocol electromagnetic noise network traffic characteristics;protocols;high resolution;adaptive kalman filter;stochastic method;estimation method;adaptive synchronization computer networks time estimation kalman filtering;kalman filter;time synchronization;packet switched;packet switching;satisfiability;distributed applications;computer networks;computer network;synchronisation;ntp synchronization protocol;telecommunication traffic;adaptive;network traffic;synchronization;telecommunication traffic adaptive kalman filters packet switching protocols synchronisation;network time protocol;network traffic characteristics;adaptive computing;adaptive kalman filters;electromagnetic noise;packet switched networks;synchronization global positioning system protocols electromagnetic interference computer networks hardware costs clocks stochastic resonance computer errors;time estimation	The importance of Time synchronization for distributed applications is growing. The most currently used synchronization protocol is NTP [1]. NTP and GPS satisfy the majority of the world's time synchronization needs, although, GPS have limitations [2]. GPS cannot function inside buildings, or in places where there are physical obstructions and high amounts of electromagnetic noise. In addition, GPS is a costly solution. This work proposes a new approach to synchronize time among machines interconnected by computer networks, which minimizes the disturbance introduced by the network with no extra hardware cost. The methodology employs high-resolution clocks and stochastic methods to minimize the error introduced in time measurement carried out across the network. It also uses an adaptive approach to continuously tune the synchronization mechanism to the network traffic characteristics. An increase of time synchronization accuracy of two orders of magnitude, in comparison with traditional estimation methods was obtained as a result.	distributed computing;global positioning system;heuristic;image resolution;kalman filter;network traffic control;synchronization (computer science)	Leandro Fabrício Auler;Roberto d'Amore	2007	2007 2nd International Conference on Communication Systems Software and Middleware	10.1109/COMSWA.2007.382439	kalman filter;clock synchronization;synchronization;real-time computing;computer science;distributed computing;data synchronization;computer network	HPC	-7.569354841667985	70.77627399296078	173712
7b488c915f95301792a41fc99fee215862b4a0d5	the case for dynamic real-time task timing in modern real-time systems	application development;program diagnostics;software platform;real time;best effort;system performance;dynamic analysis dynamic real time task timing real time system worst case execution time static timing analysis;computational complexity program diagnostics real time systems;software architecture;worst case execution time;a priori knowledge;computational complexity;static timing analysis;tools and techniques;real time systems computer aided software engineering timing application software hardware bandwidth digital audio players games computer science system performance;dynamic analysis;real time systems	Summary form only given. Traditional real-time systems require a priori knowledge of process period and worst-case execution times in order to guarantee application and system performance. Traditional static worst-case execution time analysis has been developed to support this requirement. However, real-time systems have grown beyond static applications developed for unchanging and well-documented hardware and software architectures. They now include (perhaps predominately) a large variety of highly dynamic applications, written by a large number of developers inexperienced with traditional real-time design, and executed on widely varying hardware and software platforms in competition with greedy best-effort applications with unknown processing characteristics. In such an environment, static timing analysis or specification is useless. This sea change in application and system characteristics requires a corresponding change in the tools and techniques used to characterize the application requirements and to meet those requirements. In many instances, dynamic analysis is the only possibly solution.	best, worst and average case;best-effort delivery;experience;greedy algorithm;real-time clock;real-time computing;real-time locating system;requirement;run time (program lifecycle phase);software architecture;static timing analysis;worst-case execution time	Scott A. Brandt	2004	18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.	10.1109/IPDPS.2004.1303091	best-effort delivery;embedded system;software architecture;parallel computing;real-time computing;a priori and a posteriori;simulation;computer science;operating system;distributed computing;computer performance;dynamic program analysis;programming language;computational complexity theory;rapid application development;static timing analysis;worst-case execution time	Embedded	-8.568696650880286	60.74909736186941	173841
bba5acd03a208c9af914dd518470c6130960b8bb	cyclone: a high-performance cluster-based web server with socket cloning	socket cloning;cluster;pg_thesis;object replication;load balance;web server;high performance;article	With the ever-growing web traffic, cluster-based web server is becoming more and more important to the Internet's infrastructure. Making the best use of all the available resources in the cluster to achieve high performance is thus a significant research issue. In this paper, we introduce Cyclone, a cluster-based web server that can achieve nearly optimal throughput. Cyclone makes use of a novel network support mechanism called Socket Cloning (SC), together with the method of hot object replication, to obtain high performance. SC allows an opened socket to be moved efficiently between cluster nodes. With SC, the processing of HTTP requests can be migrated to the node that has a cached copy of the requested document, thus obviating the need for any cache transfer between cluster nodes. To achieve better load balancing, frequently accessed documents (hot objects) are replicated to other cluster nodes. Trace-driven benchmark tests using http_load show that Cyclone outperforms existing approaches and can achieve a throughput of 14575 requests/s (89.5 MBytes/s), which is 98% efficiency of the available network bandwidth, with eight web server nodes.	benchmark (computing);cyclone;hypertext transfer protocol;load balancing (computing);server (computing);throughput;web server;web traffic	Yiu-Fai Sit;Cho-Li Wang;Francis C. M. Lau	2004	Cluster Computing	10.1023/B:CLUS.0000003941.07598.47	parallel computing;real-time computing;computer science;load balancing;operating system;world wide web;web server;computer network;server farm;cluster	HPC	-18.025870402583998	70.84645237983997	173928
bbd46de29a9263531c2afc6879a2b4485adc91bd	consens: consistency-sensitive opportunistic data access in wireless networks	radio networks;wireless networks;distributed database;cache consistency;query processing;optimization technique;data access techniques consens consistency sensitive opportunistic data access wireless networks internet services optimization techniques query delay consistency sensitive data access query delay;radio networks query processing;wireless network;cache invalidation;opportunistic data access;servers;internet;strong consistency;servers delay wireless networks distributed databases internet;lazy request;data access;distributed databases;internet services;wireless networks cache consistency cache invalidation lazy request opportunistic data access	In order to fulfill the users' insatiable interests in accessing the Internet services and information wirelessly, one of key optimization techniques is caching frequently accessed the data items in a local cache. However, a strong consistency is implicitly assumed in most caching schemes but it may frequently occur a long query delay. In this paper, we propose a consistency-sensitive data access scheme to support applications' diverse consistency requirements, called ConSens, where a user can flexibly set its own consistency level. We also propose a lazy request and opportunistic data access techniques to effectively balance the data accessibility and query delay. Extensive performance studies indicate that the proposed techniques reduce the query delay and increase the number of opportunistic accesses significantly.	accessibility;cache (computing);data access;lazy evaluation;mathematical optimization;requirement;strong consistency;web service	Sunho Lim;Yumin Lee;Manki Min	2011	2011 - MILCOM 2011 Military Communications Conference	10.1109/MILCOM.2011.6127776	computer science;database;distributed computing;computer network	DB	-15.338221848013571	68.60440940364563	174055
0834c0ec89608ed1f7e91a48de457eefbc8043e0	identification of efficient peers in p2p computing system for real time applications		Currently the Peer-to-Peer computing paradigm rises as an economic solution for the large scale computation problems. However due to the dynamic nature of peers it is very difficult to use this type of systems for the computations of real time applications. Strict deadline of scientific and real time applications require predictable performance in such applications. We propose an algorithm to identify the group of reliable peers, from the available peers on the Internet, for the processing of real time application’s tasks. The algorithm is based on joint evaluation of peer properties like peer availability, credibility, computation time and the turnaround time of the peer with respect to the task distributor peer. Here we also define a method to calculate turnaround time (distance) on task distributor peers at application level.	algorithm;computation;internet;lookup table;network traffic control;overhead (computing);peer-to-peer;programming paradigm;real-time computing;time complexity	Jigyasu Dubey;Vrinda Tokekar	2012	CoRR		parallel computing;real-time computing;simulation;computer science;operating system;distributed computing	HPC	-18.096531498668007	65.99853553505842	174163
41f7f396ff255d227fc6d112c91ba169ece2d813	method-based caching in multi-tiered server applications	estensibilidad;tiempo respuesta;commerce electronique;reponse temporelle;comercio electronico;capacidad canal;red www;cache consistency;maintenance;gollete estrangulamiento;perforation;e commerce;logiciel a securite critique;application server;reseau web;capacite canal;response time;cache memory;sistema reactivo;antememoria;temps reponse;antememoire;goulot etranglement;internet;time response;channel capacity;object oriented;user behaviour;safety critical software;reactive system;mantenimiento;systeme reactif;world wide web;extensibilite;scalability;respuesta temporal;bottleneck;electronic trade	In recent years, application server technology has become very popular for building complex but mission-critical systems such as Web-based E-Commerce applications. However, the resulting solutions tend to suffer from serious performance and scalability bottlenecks, because of their distributed nature and their various software layers. This paper deals with the problem by presenting an approach about transparently caching results of a service interface’s readonly methods on the client side. Cache consistency is provided by a descriptive cache invalidation model which may be specified by an application programmer. As the cache layer is transparent to the server as well as to the client code, it can be integrated with relatively low effort even in systems that have already been implemented. Experimental results show that the approach is very effective in improving a server’s response times and its transactional throughput. Roughly speaking, the overhead for cache maintenance is small when compared to the cost for method invocations on the server side. The cache’s performance improvements are dominated by the fraction of read method invocations and the cache hit rate. Our experiments are based on a realistic E-commerce Web site scenario and site user behaviour is emulated in an authentic way. By inserting our cache, the maximum user request throughput of the web application could be more than doubled while its response time (such as perceived by a web client) was kept at a very low level. Moreover, the cache can be smoothly integrated with traditional caching strategies acting on other system tiers (e.g. caching of dynamic Web pages on a Web server). The presented approach as well as the related implementation are not restricted to application server scenarios but may be applied to any kind of interface-based software layers.	application server;bottleneck (software);cpu cache;cache (computing);cache invalidation;client-side;dynamic web page;e-commerce payment system;emulator;experiment;mission critical;overhead (computing);programmer;response time (technology);scalability;server (computing);server-side;smoothing;throughput;web application;web server	Daniel Pfeifer;Hannes Jakschitsch	2003		10.1007/978-3-540-39964-3_83	e-commerce;web service;cache coloring;scalability;the internet;page cache;cache stampede;cpu cache;cache;reactive system;computer science;artificial intelligence;cache invalidation;operating system;database;distributed computing;smart cache;programming language;object-oriented programming;cache algorithms;cache pollution;world wide web;response time;computer security;channel capacity;algorithm;application server	Web+IR	-17.383191149291786	70.97363012872486	174691
3300a452ee33ab1e5c1354db68110ff345a0467e	schedulability analysis for the dynamic segment of flexray: a generalization to slot multiplexing	automotive electronics;slot multiplexing;protocols;bismuth;automotive company;scheduling automobile industry automotive electronics multiplexing protocols;event triggered component;schedulability analysis;flexray;multiplexing;delay equation;engineering and technology;time factors;teknik och teknologier;flexray bus protocol;scheduling;mathematical model;time factor;flexray standard;timing analysis;real time communication;real time communication protocol;dynamic segment;flexray bus protocol schedulability analysis dynamic segment slot multiplexing automotive company real time communication protocol automotive network timing analysis event triggered component flexray standard bandwidth utilization;automobile industry;multiplexing delay equations bismuth mathematical model time factors;timing analysis flexray slot multiplexing;bandwidth utilization;automotive network	FlexRay, developed by a consortium of over hundred automotive companies, is a real-time communication protocol for automotive networks. In this paper, we propose a new approach for timing analysis of the event-triggered component of FlexRay, known as the dynamic segment. Our technique accounts for the fact that the FlexRay standard allows slot multiplexing, i.e., the same priority can be assigned to more than one message. Existing techniques have either ignored slot multiplexing in their analysis or made simplifying assumptions that severely limit achieving high bandwidth utilization. Moreover, we show that our technique returns less pessimistic results compared to previously known techniques even in the case where slot multiplexing is ignored.	communications protocol;flexray;multiplexing;real-time transcription;scheduling analysis real-time systems;static timing analysis	Bogdan Tanasa;Unmesh D. Bordoloi;Stefanie Kosuch;Petru Eles;Zebo Peng	2012	2012 IEEE 18th Real Time and Embedded Technology and Applications Symposium	10.1109/RTAS.2012.10	embedded system;communications protocol;real-time computing;computer science;operating system;bismuth;mathematical model;scheduling;static timing analysis;multiplexing;computer network	Embedded	-7.86975369980594	63.2488409824828	174800
1af7298cc8abad3506b68a61f7d4e6453f1f0bb5	swarovsky: optimizing resource loading for mobile web browsing	optimization mobile web resource loading;loading html browsers mobile computing web servers mobile communication mobile handsets	Imperfect Web resource loading prevents mobile Web browsing from providing satisfactory user experience. In this article, we design and implement the SWAROVsky system to address three main issues of current inefficient Web resource loading: (1) on-demand and thus slow loading of sub-resources of webpages; (2) duplicated loading of resources with different URLs but the same content; and (3)  redundant loading of the same resource due to improper cache configurations. SWAROVsky employs a dual-proxy architecture that comprises a remote cloud-side proxy and a local proxy on mobile devices. The remote proxy proactively loads webpages from their original Web servers and maintains a resource loading graph for every single webpage. Based on the graph, the remote proxy is capable of deciding which resources are “really” needed for the webpage and their loading orders, and thus can synchronize these needed resources with the local proxy of a client efficiently and timely. The local proxy also runs an intelligent and light-weight algorithm to identify resources with different URLs but the same content, and thus can avoid duplicated downloading of the same content via network. Our system can be used with existing Web browsers and Web servers, and does not break the normal semantics of a webpage. Evaluations with 50 websites show that on average our system can reduce the page load time by 43.1 percent and the network data transmission by 57.6 percent, while imposing marginal system overhead.	algorithm;browsing;download;loader (computing);marginal model;mobile device;optimizing compiler;overhead (computing);proxy pattern;user experience;web page;web resource	Xuanzhe Liu;Yun Ma;Xinyang Wang;Yunxin Liu;Tao Xie;Gang Huang	2017	IEEE Transactions on Mobile Computing	10.1109/TMC.2016.2645563	web page;web resource;mobile search;computer network;web server;cache;architecture;mobile web;computer science;mobile computing	Web+IR	-18.898587147313993	73.59029640408151	174839
a6f6154e98678ebd47021630887271d143d2584d	relaxing constraints in stateful network data plane design		Modern network devices have to meet stringent performance requirements while providing support for a growing number of use cases and applications. In such a context, a programmable network data plane has emerged as an important feature of modern forwarding elements, such as switches and network cards. Bosshart et al. [1] introduced RMT, a first example of a high-performance programmable data plane. RMT provides a reconfigurable switching ASIC that can parse and modify arbitrary packet headers in a pipeline of match-action tables (MAT). Interestingly, [1] shows that such programmability can be supported with performance comparable to state-of-the-art fixed-function chips: it can process packets at a line rate of 640 Gb/s. More recently, Sivaraman et al. [2] presented an abstraction for a switching ASIC, named Banzai, which supports the programming of stateful packet processing functions. The statefullness lays in the ability to create and modify state while processing a packet, enabling the definition of functions that depend on the history of previously received packets. Such functions enable complex applications such as stateful firewalls, active queue management, scheduling, monitoring, etc. Banzai extends RMT’s MATs by adding stateful actions, named “atoms”. Each atom, as the name suggests, performs state operations atomically. The atomicity is required to guarantee consistency, i.e., read and write operations to an atom’s memory area cannot be performed by different packets at the same time. In effect, Banzai requires the serial processing of all the packets. This model is convenient since a forwarding element’s data plane is already processing packets in a serial manner. However, to meet a given performance target, the serial processing model requires the definition of a strict time budget for the processing of each packet. For instance, in the case of RMT, the switching ASIC is dimensioned to process 640 Gb/s with minimum size Ethernet packets (64 bytes), which translates to a time budget of 1 ns per packet1. Likewise, the chip clock frequency is dimensioned according to the desired target throughput. In the previous case, a 1 Ghz clock is used to provide the 640 Gb/s. The final outcome is that each atom has to perform state read, modification and write operations in at most 1 ns, i.e., 1 clock cycle. Unfortunately, while providing line rate guarantees, Banzai fails to implement more complex functions that require atoms that cannot be executed in the available time budget.	active queue management;application-specific integrated circuit;atom;atomicity (database systems);byte;clock rate;clock signal;firewall (computing);fixed-function;forwarding plane;gigabyte;network interface controller;network packet;network switch;parsing;reconfigurable computing;requirement;scheduling (computing);stateful firewall;throughput;virtual economy	Carmelo Cascone;Roberto Bifulco;Salvatore Pontarelli	2017	CoRR		parallel computing;real-time computing;distributed computing	Networks	-5.0517415042534966	64.28820091726054	175039
688f941bcaf2640e5724b031a5966eaa32aa3951	maximizing availability of consistent data in unreliable networks	network partition;optimisation;availability;distributed processing;consistent data;wide area networks data handling distributed processing optimisation;max smt problem maximizing availability consistent data unreliable networks wide area network data availability combinatorial optimization;smt;data handling;majority voting;wide area networks;smt consistent data majority voting availability network partition;availability servers optimization wide area networks network topology probabilistic logic topology	We address the issue of maximization of the availability of replicated data that are distributed in a wide area network. We consider a system that uses majority voting, which is a common mechanism for providing consistency of replicated data in the presence of failures. The data availability provided by this mechanism critically depends on the vote assignment to the replicas. In this paper we formulate the problem of finding the optimal vote assignment into a specific form of a combinatorial optimization problem, namely the MAX-SMT problem. This formulation allows us to use a modern, fast MAX-SMT solver to solve the vote assignment problem. To evaluate the effectiveness of this approach, we build a failure repair model of underlying networks and estimate the data availability using that model. The results of the estimation show that data availability can be significantly improved using the optimal vote assignment in the presence of failures.	assignment problem;combinatorial optimization;expectation–maximization algorithm;failure cause;mathematical optimization;max;network partition;optimization problem;simulation;solver	Yuki Matsui;Hideharu Kojima;Tatsuhiro Tsuchiya	2012	2012 IEEE 18th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2012.26	majority rule;availability;real-time computing;computer science;group method of data handling;data mining;distributed computing	DB	-10.02692985609913	66.30261994117498	175152
2dc26d90105c4d8b0423cbe8523f2f17dd3b5801	resource scheduling algorithms for grid computing and its modeling and analysis using petri net	resource scheduling;time petri net;state explosion;petri net;grid computing;modeling and analysis	A resource scheduling algorithm called XMin-min is proposed in this paper. In the XMin-min algorithm, we consider not only the expected execution time of tasks, but also expected communication time when calculating expected completion time. In the paper, the execution cost of tasks and budget of application are selected as QoS and an algorithm XMin-min with QoS is also proposed. An extended high-level timed Petri net (EHLTPN) model suiting scheduling of resource in grid computing is presented in the paper. In the EHLTPN, the firing times assigned to transitions are functions of the tokens of input places. We construct a simple model for the resource scheduling in grid computing using EHLTPN. A definition of Reachable Scheduling Graph (RSG) of EHLTPN to analyze the timing property of the resource scheduling is given in this paper. Two algorithms can be use to settle the “state explosion” problem while constructing RSG of EHLTPN.	algorithm;grid computing;high- and low-level;iteration;maxima and minima;min-max heap;multistage interconnection networks;petri net;quality of service;run time (program lifecycle phase);scheduling (computing);transmitter	Yaojun Han;Changjun Jiang;You Fu;Xuemei Luo	2003		10.1007/978-3-540-24680-0_10	fair-share scheduling;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;theoretical computer science;distributed computing;petri net;grid computing	HPC	-10.259350472809581	62.86998781318869	175397
a9a357bb17d51af192e3b29dd1009e4659e51e32	schedulability analysis for distributed heterogeneous time/event triggered real-time systems	protocols;time triggered;distributed memory systems;distributed embedded system;processor scheduling;real time systems job shop scheduling protocols automotive applications vehicle dynamics timing embedded system automotive engineering time division multiple access processor scheduling;bus protocols schedulability analysis heterogeneous time triggered real time system heterogeneous event triggered real time system distributed embedded system bus access optimization;schedulability analysis;embedded systems;processor scheduling distributed memory systems embedded systems protocols;hybrid system;datavetenskap datalogi;timing analysis;computer science;real time systems	This paper deals with specific issues related to the design of distributed embedded systems implemented with mixed, event-triggered and time-triggered task sets, which communicate over bus protocols consisting of both static and dynamic phases. Such systems are emerging as a new standard for automotive applications. We have developed a holistic timing analysis and scheduling approach for this category of systems. Three alternative scheduling heuristics are presented and compared. We have also identified several new design problems characteristic to such hybrid systems. An example related to bus access optimization in the context of a mixed static/dynamic bus protocol is presented. Experimental results prove the efficiency of such an optimization approach.	embedded system;fits;heuristic (computer science);holism;hybrid system;mathematical optimization;optimization problem;program optimization;real-time operating system;real-time transcription;requirement;scheduling (computing);scheduling analysis real-time systems;static timing analysis	Traian Pop;Petru Eles;Zebo Peng	2003		10.1109/EMRTS.2003.1212751	fair-share scheduling;embedded system;communications protocol;parallel computing;real-time computing;computer science;operating system;static timing analysis;hybrid system	Embedded	-7.522894480573522	60.45890844268091	175681
b49880ec404b0823a11af13ba9976bd1cbfd2f4c	performance comparison of multi-agent grid job scheduler organizations	job scheduling		job scheduler	J. S. Iyilade;G. Adesola Aderounmu;Michael O. Adigun	2005			distributed computing;parallel computing;job scheduler;grid;real-time computing;scheduling (computing);job queue;computer science;rate-monotonic scheduling	ML	-16.62975696242651	61.42343142118107	175702
1900ce80401429578035d73e9193b539cc854aca	a read-write-validate approach to optimistic concurrency control for energy efficiency of resource-constrained systems	matthew brook;resource allocation;storage management;smart phones;kamal solaiman;eprints newcastle university;dr graham morgan;open access;concurrency control;transaction processing concurrency control resource allocation smart phones storage management;transaction processing;dr gary ushaw;ubiquitous databases optimistic concurrency control transactions;transaction scheduling read write validate approach energy efficiency resource constrained systems smartphone shared data access solid state storage memory resource battery drain solid state device data retrieval data storage optimistic concurrency control algorithm read write validate phase sequence virtual execution protocol database resource constrained device latency reduction persistent store access real time requirement satisfaction;protocols throughput time factors databases concurrency control real time systems energy efficiency	Modern smartphones feature multiple applications which access shared data on the solid state storage within the device. As applications become more complex, contention over this memory resource is becoming an issue. This leads to increased battery drain as the applications are forced to touch the solid state device repeatedly after failing to retrieve or store data due to contention from other applications. We describe an optimistic concurrency control algorithm, combining a novel Read-Write-Validate phase sequence with virtual execution. The protocol is suitable for governing transactions operating on databases residing on resource-constrained devices. Increasing energy efficiency and reducing latency are primary goals for our algorithm. We show that this is achieved by reducing persistent store access, and satisfy real-time requirements via transaction scheduling that affords greater determinism.	algorithm;concurrency (computer science);correctness (computer science);database;failure;optimistic concurrency control;persistence (computer science);read-modify-write;read-write memory;real-time clock;real-time computing;real-time transcription;requirement;scheduling (computing);simulation;smartphone;solid-state drive;solid-state electronics;throughput	Kamal Solaiman;Matthew Brook;Gary Ushaw;Graham Morgan	2013	2013 9th International Wireless Communications and Mobile Computing Conference (IWCMC)	10.1109/IWCMC.2013.6583765	embedded system;timestamp-based concurrency control;optimistic concurrency control;real-time computing;isolation;transaction processing;resource allocation;computer science;operating system;concurrency control;database;distributed computing;multiversion concurrency control;serializability;computer security;computer network;distributed concurrency control	Embedded	-14.757233706389584	67.26701148199398	175709
84a5cf7ec90f3f08bbe40f0004e7d2d2bc64a76f	popularity-biased random walks for peer-to-peer search under the square-root principle		The square-root principle is known to achieve low search time for peer-to-peer search techniques that do not utilize query routing indices (e.g., query flooding or random walk searches). Under this principle, each object is probed with probability proportional to the square root of its query popularity. Existing search methods realize the square-root principle by using either object replication or topology reconstruction, which may not be desirable for those applications with large, dynamic datasets and limited network bandwidth. We propose a new approach that uses popularity-biased random walks to achieve the square-root principle. With the guidance of the Metropolis algorithm, each step of the random walks is determined based on the content popularities of current neighbors. Compared to previous methods, our approach has comparable search performance at no cost of data movement or topology changes.	metropolis;metropolis–hastings algorithm;peer-to-peer;root-finding algorithm;routing;simulation	Ming Zhong;Kai Shen	2006			random walk;square root;popularity;peer-to-peer;computer science;distributed computing	Networks	-12.481452795155892	74.31707313961569	175756
eab760d3507ec80050fc5d38a65d3b013815d9c0	optimal partitioning of nodes to space-sharing parallel tasks	distributed application;grid scheduling;space shared platforms;distributed applications;polynomial algorithm;space sharing parallel tasks	This paper focuses on the execution of distributed applications on parallel platforms, such as MPPs or homogeneous clusters. These applications are usually formed by individual tasks, which are each mapped to the nodes available in the parallel platform. When these tasks can execute simultaneously, it may be necessary to space-share the nodes available within the application. In this case, partitioning the nodes among the space-sharing tasks is key in obtaining the best performance. This paper presents a polynomial algorithm to provide an optimal partitioning of nodes to parallel tasks, enabling them to execute simultaneously in minimum time.		Silvia M. Figueira	2006	Parallel Computing	10.1016/j.parco.2006.01.002	parallel computing;real-time computing;computer science;distributed computing	HPC	-14.090083207126316	60.72713975414699	175762
1113d2b60b26c3bbf04076fa3d5e913c1e13ee9d	rule hashing for efficient packet classification in network intrusion detection	hierarchical rule trees;protocols;memory management;cpu time;packet classification;rule based intrusion detection system;high speed networks;rule based;intrusion detection;trees mathematics;network intrusion detection;memory access;trees mathematics cryptography finite automata;open source intrusion detection system rule hashing packet classification rule based intrusion detection system cpu time graph finite automata security threats hierarchical rule trees snort;snort;indexes;engines;pattern matching;cryptography;intrusion detection pattern matching tree graphs databases automata high speed networks open source software protocols payloads engines;graph;security threats;finite automata;ip networks;open source intrusion detection system;rule hashing;intrusion detection system;open source	A rule-based intrusion detection system compares the incoming packets against rule set in order to detect intrusion. Unfortunately, it spends the majority of CPU time in packet classification to search for rules that match each packet. A common approach is to build a graph such as rule trees or finite automata for a given rule set, and traverse it using a packet as an input string. Because of the increasing number of security threats and vulnerabilities, the number of rules often exceeds thousands requiring more than hundreds of megabytes of memory. Exploring such a huge graph becomes a major bottleneck in high-speed networks since each packet incurs many memory accesses with little locality. In this paper, we propose rule hashing for fast packet classification in intrusion detection systems. The rule hashing, combined with hierarchical rule trees, saves memory and reduce the number of memory accesses by allowing the whole working set to be accommodated in a cache in most of the time, and thus improves response times in finding matching rules. We implement our algorithm in Snort, a popular open-source intrusion detection system. Experimental results show that our implementation is faster than original Snort to deal with the same real packet traces while consuming an order of magnitude less memory.	acf;algorithm;automata theory;bottleneck (engineering);cpu cache;central processing unit;dspace;finite-state machine;hash function;hash table;intrusion detection system;locality of reference;logic programming;megabyte;network packet;open-source software;pattern matching;rule 184;snort;traverse;tracing (software);working set	Atsushi Yoshioka;Shariful Hasan Shaikot;Min Sik Kim	2008	2008 Proceedings of 17th International Conference on Computer Communications and Networks	10.1109/ICCCN.2008.ECP.120	rule-based system;intrusion detection system;real-time computing;computer science;theoretical computer science;operating system;distributed computing;finite-state machine	Metrics	-7.1475743200598645	66.95639803900465	175788
2a859c1a1b16aa6991bc7e39075201ff2abe5719	resource discovery based on virgo p2p distributed dns framework	range query;resource discovery;time complexity;scientific workflow;p2p;tree structure;space complexity;overlay network	"""Resource discovery plays an important role on scientific workflows in large scalable network environment. This paper presents a resource discovery framework based on VIRGO P2P Distributed DNS. With the convention of resource name as the format---  functionscheme"""":""""  global-hier-part""""/""""local-name , this framework supports flexible queries using partial keywords and wildcards, and range queries by a SQL-like query statement. The global-hier-part is managed by registers the same as DNS servers except the extension of RRs. The DNS servers construct n-tuple overlay virtual hierarchical overlay network of VIRGO. With cached addresses of DNS servers, the overload of traffic in tree structure can be avoided. The time complexity, space complexity and message-cost of lookup with this framework is  O ( L ), where L is the number of sub domains in Domain Name."""		Lican Huang	2008		10.1007/978-3-540-69389-5_57	time complexity;range query;overlay network;computer science;peer-to-peer;data mining;database;tree structure;dspace;world wide web;algorithm;domain name system;computer network	ML	-13.033934344814694	72.22620840701077	175800
795fc8189190be002954cf49155d767a5c952b4b	network traffic load balancing in hierarchical peer-to-peer systems	multidimensional indexing;network load balancing;hierarchical data structure;telecommunication traffic peer to peer computing resource allocation;peer to peer computing routing load management binary trees distributed databases indexing maintenance engineering;network load balancing p2p systems multidimensional indexing distributed systems hierarchical data structure;hybrid structure network traffic load balancing hierarchical peer to peer systems multiple sites p2p indexing searching structure maintenance messages nonuniform distribution hierarchical structures unbalanced traffic load overlay structure g grid small world network social networks uniform traffic distribution;distributed systems;p2p systems	The management of huge amounts of data distributed across multiple sites has become a necessity more and more demanding. Peer-to-peer systems (P2P) can afford the requirements of managing, indexing, searching and analyzing data with scalability and self-organization. Until now, most efforts have focused primarily on improving the number of hops and structure maintenance messages. However, the non-uniform distribution of data and the hierarchical structures, together with heavy load, can cause unbalanced traffic load. In this paper we improve our previous work on the overlay structure G-Grid, merging it with a Small World network. The Small World networks make a compromise between order and randomness, they are derived from social networks and show an almost uniform traffic distribution. Experiments show how this new hybrid structure obtains the best performance in traffic distribution.	approximation;continuation;data center;experiment;load balancing (computing);network traffic control;peer-to-peer;randomness;requirement;scalability;self-organization;simulation;social network;unbalanced circuit	Gianluca Moro;Tommaso Pirini;Claudio Sartori	2015	2015 10th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC)	10.1109/3PGCIC.2015.95	computer science;database;distributed computing;computer network	DB	-12.255899895613126	73.14748696743993	176369
db20ee7fc03363f888edc53bbbfcd07868e2a34e	versatile time-cost algorithm (vtca) for scheduling non-preemptive tasks of time critical workflows in cloud computing systems	cloud computing scheduling;dependent task scheduling;makespan minimisation;time critical workflows;time cost scheduling	In cloud computing environments, resources and infrastructure are provided as a service over internet on demand. The users are interested in reducing the service cost provided by the cloud service providers. Scheduling tasks of workflows play a vital role in determining performance of cloud computing systems. Workflows have many tasks in it and are interdependent on each other. Time critical workflows comprise of a collection of tasks which should be completed as early as possible so that other workflows get its turn. The budget involved in executing the time critical tasks is very high. The execution cost increases whenever we try to reduce the execution time. In this paper, we propose a method called versatile time-cost algorithm (VTCA) to schedule time critical workflows with minimum cost. VTCA will schedule the tasks to complete in earliest possible time as well as optimise the cost involved in resource provisioning. The results of experiments conducted using CloudSim simulator show that our scheduling policy minimises the completion time of workflows than other existing algorithms like min-min and fair max-min by 5% to 30% and it also reduces the costs by 5% to 35%.	algorithm;cloud computing;cloudsim;experiment;interdependence;internet;maxima and minima;mike lesser;provisioning;run time (program lifecycle phase);schedule (project management);scheduling (computing);simulation	L. D. Dhinesh Babu;P. Venkata Krishna	2013	IJCNDS	10.1504/IJCNDS.2013.057718	real-time computing;computer science;operating system;distributed computing	HPC	-18.73968204661799	62.64689057537588	176829
d940f39651df06e2e14dd5d2ad96eaeb0f63edd6	a unified model for real-time data grids supporting hierarchical scheduling of jobs and data	unified model;real time data		real-time data;real-time transcription;schedule (computer science);unified model	Mustafa Müjdat Atanak;Safai Tandogan;Atakan Dogan	2010			real-time data;scheduling (computing);real-time computing;unified model;distributed computing;computer science	Embedded	-11.70702164947619	62.784672525601586	177122
3dfec58e2d62fb6af09808251fc2d83779961ca4	multiobjective differential evolution for workflow execution on grids	grid scheduling;differential evolution;multiobjective differential evolution;multiobjective optimization;quality of service	Most algorithms developed for scheduling applications on global Grids focus on a single Quality of Service (QoS) parameter such as execution time, cost or total data transmission time. However, if we consider more than one QoS parameter (eg. execution cost and time may be in conflict) then the problem becomes more challenging. To handle such scenarios, it is convenient to use heuristics rather than a deterministic algorithm. In this paper we have proposed a workflow execution planning approach using Multiobjective Differential Evolution (MODE). Our goal was to generate a set of trade-off schedules according to two user specified QoS requirements (time and cost). The alternative tradeoff solutions offer more flexibility to users when estimating their QoS requirements of workflow executions. We have compared our results with two baseline multiobjective evolutionary algorithms. Simulation results show that our modified MODE is able to find a comparatively better spread of compromise solutions.	baseline (configuration management);deterministic algorithm;differential evolution;evolutionary algorithm;heuristic (computer science);quality of service;requirement;run time (program lifecycle phase);scheduling (computing);simulation	A. K. M. Khaled Ahsan Talukder;Michael Kirley;Rajkumar Buyya	2007		10.1145/1376849.1376852	differential evolution;mathematical optimization;real-time computing;quality of service;computer science;multi-objective optimization;distributed computing	HPC	-18.52615541215402	63.08186592229108	177409
3c8ea2e46eafc1358f6ed80b83ef8ae4bf77ea47	energy-aware data transfer algorithms	energy efficiency;conference paper;servers;protocol tuning;big data;mathematical model;power demand;energy aware data transfers;power modeling;data transfer;pipeline processing;data models;throughput	The amount of data moved over the Internet per year has already exceeded the Exabyte scale and soon will hit the Zettabyte range. To support this massive amount of data movement across the globe, the networking infrastructure as well as the source and destination nodes consume immense amount of electric power, with an estimated cost measured in billions of dollars. Although considerable amount of research has been done on power management techniques for the networking infrastructure, there has not been much prior work focusing on energy-aware data transfer algorithms for minimizing the power consumed at the end-systems. We introduce novel data transfer algorithms which aim to achieve high data transfer throughput while keeping the energy consumption during the transfers at the minimal levels. Our experimental results show that our energy-aware data transfer algorithms can achieve up to 50% energy savings with the same or higher level of data transfer throughput.	algorithm;exabyte;power management;throughput;zettabyte	Ismail Alan;Engin Arslan;Tevfik Kosar	2015	SC15: International Conference for High Performance Computing, Networking, Storage and Analysis	10.1145/2807591.2807628	data modeling;throughput;real-time computing;simulation;big data;computer science;mathematical model;data mining;efficient energy use;server;computer network	HPC	-4.6022657605958335	62.61818044665197	177450
242bc7a77f01ec9ac282239808bbe98fb9422275	building topology-aware overlays using global soft-stat	control systems;round trip time measurement topology aware overlay network global soft state distributed hash table fault tolerant storage space network proximity information landmark clustering expanding ring search global proximity information;fault tolerant storage space;fault tolerant;time measurement;distributed hash table;routing;distributed processing network topology fault tolerant computing content addressable storage file organisation table lookup;topology aware overlay network;distributed processing;round trip time;routing network topology internet buildings fault tolerance time measurement communication system control control systems fault tolerant systems extraterrestrial measurements;network topology;fault tolerant computing;col;internet;global soft state;network proximity information;informational efficiency;fault tolerant systems;global proximity information;fault tolerance;publish subscribe;landmark clustering;overlay network;expanding ring search;p2p networks;communication system control;round trip time measurement;content addressable storage;table lookup;extraterrestrial measurements;peer to peer;buildings;file organisation	Distributed hash table (DHT) based overlay networks offer an administration-free and fault-tolerant storage space that maps “keys” to “values”. For these systems to function efficiently, their structures must fit that of the underlying network. Existing techniques for discovering network proximity information, such as landmark clustering and expanding-ring search are either inaccurate or expensive. The lack of global proximity information in overlay construction and maintenance can result in bad proximity approximation or excessive communication. To address these problems, we propose the following: (1) Combining landmark clustering and round-trip time (RTT) measurements to generate proximity information, achieving both efficiency and accuracy. (2) Controlled placement of global proximity information on the system itself as soft-state, such that nodes can independently access relevant information efficiently. (3) Publish/subscribe functionality that allows nodes to subscribe to the relevant soft-state and get notified as the state changes necessitate overlay restructuring.	approximation;cartesian closed category;centrality;cluster analysis;dejan ristanović;distributed computing;distributed hash table;fault tolerance;hash function;hilbert curve;icdcs;lookup table;map;mathematical optimization;overlay network;publish–subscribe pattern;recursion;routing;soft state;space-filling curve;system information (windows)	Zhichen Xu;Chunqiang Tang;Zheng Zhang	2003		10.1109/ICDCS.2003.1203500	fault tolerance;real-time computing;computer science;control system;database;distributed computing;computer security;computer network	DB	-11.036460819814561	73.87353265216298	177484
e2258ca09f017ffc3737d1e0739406ab7a66ca25	an energy efficient re-access scheme for data caching in data broadcast of a mobile computing environment	broadcast channel;energy efficient;mobile computer;re access;data cache;data broadcast;power consumption;data caching	Data caching is used to improve the response time and the power consumption of a mobile client in a mobile computing environment. To enhance the performance of data caching, one needs to improve the hit ratio and to reduce the cost in processing a cache miss. In a mobile computing environment, a cached data item of a mobile client needs to remain up-todate with respect to its corresponding data item in the server. A cached data item which is out of date is called a cached invalidated data item. Accessing a cached invalidated data item can be regarded as processing a cache miss. To access a cached invalidated data item, a mobile client needs to download the new content of the data item from the broadcast channel. This operation is called a re-access operation in this paper. Re-accessing a cached invalidated data item incurs large tuning time overhead. In this paper, we propose a re-access scheme that reduces this overhead by allowing a mobile client to access a cached invalidated data item from the broadcast channel without accessing indices. We analyze the performance of the proposed scheme and validate the analysis through experiments. The experiments showed that the proposed scheme significantly reduces the tuning time of a mobile client. Furthermore, the proposed scheme is robust in the sense that it allows changes on the broadcast structure in data broadcasting. 2007 Elsevier Inc. All rights reserved.	access time;broadcasting (networking);cpu cache;cache (computing);cache invalidation;data item;datacasting;download;experiment;hit (internet);mobile computing;national supercomputer centre in sweden;numerical analysis;overhead (computing);philips 68070;response time (technology);server (computing);simulation	Yungho Leu;Jen-Jou Hung	2007	Inf. Sci.	10.1016/j.ins.2007.06.033	real-time computing;computer science;database;efficient energy use;mobile computing;world wide web	Mobile	-15.066805868880994	68.69302608503023	177960
14251de2096cd03ba290287d9fc860ee013739ce	scalable ip lookup for programmable routers	internet protocol;field programmable gate array;routing protocols;random access memory;engineering design;performance evaluation;perforation;distributed networks;reconfigurable logic;costs search engines random access memory optical fiber communication ip networks web and internet services associative memory computer aided manufacturing cadcam hardware;internet routers scalable ip lookup programmable routers performance bottleneck reconfigurable logic device commodity random access memory ram fast internet protocol lookup fipl engine tree bitmap algorithm sram throughput latency update performance sample routing table mae west;telecommunication traffic;internet;internet router;content addressable memory;random access storage;delays routing protocols table lookup internet performance evaluation random access storage telecommunication traffic;ip lookup;table lookup;high performance;delays	Continuing growth in optical link speeds places increasing demands on the performance of Internet routers, while deployment of embedded and distributed network services imposes new demands for flexibility and programmability. IP adress lookup has become a significant performance bottleneck for the highest performance routers. New commercial products utilize dedicated Content Addressable Memory (CAM) devides to achieve high lookup speeds. This paper describes an efficient, scalable lookup engine design, able to achieve high-performance with the use of a small portion of a reconfigurable logic device and a commodity Random Access Memory (RAM) device. Based on Eatherton's Tree Bitmap algorithm [1] the Fast Internet Protocol Lookup (FIPL) engine can be scaled to achieve over 9 million lookups per second at the fairly modest clock speed of 100 MHz. FIPL's scalability, efficiency, and favorable update performance make it an ideal candidate for System-On-a-Chip (SOC) solutions for programmable router port processors. ... Read complete abstract on page 2.	algorithm;bitmap;central processing unit;clock rate;content-addressable memory;embedded system;internet;logic gate;lookup table;random access;random-access memory;reconfigurable computing;router (computing);scalability;software deployment;system on a chip	David E. Taylor;John W. Lockwood;Todd S. Sproull;Jonathan S. Turner;David B. Parlour	2002		10.1109/INFCOM.2002.1019301	internet protocol;parallel computing;real-time computing;the internet;telecommunications;computer science;operating system;content-addressable memory;routing protocol;engineering design process;field-programmable gate array;computer network	Networks	-5.6480338676291275	66.66998651114535	178169
4a07be3417d3754074d92e5e8c7628259c96f7d6	energy-aware data transfer tuning	conference paper;power aware computing;end to end data transfers energy aware data transfer tuning annual electricity power management energy efficiency power aware networking end system power management;servers power demand data transfer throughput mathematical model data models concurrent computing;power modeling power aware data transfers energy efficiency bigdata protocol tuning	The annual electricity consumed by data transfers in the U.S. is estimated to be 20 Terawatt hours, which translates to around 4 billion U.S. Dollars per year. There has been considerable amount of prior work looking at power management and energy efficiency in hardware and software systems, and more recently in power-aware networking. Despite the growing body of research in power management techniques for the networking infrastructure, there has been no prior work (to the best of our knowledge), focusing on saving energy at the end systems(sender and receiver nodes) during the data transfer. We argue that although network-only approaches are part of the solution, the end-system power management is a key in optimizing energy efficiency of the data transfers, which has been long ignored. In this paper, we analyze various factors that will affect the power consumption in end-to-end data transfers, such as the level of parallelism, concurrency and pipelining. Our results show that significant amount of energy savings can be achieved at the end-systems during data transfer with no or minimal performance penalty.	concurrency (computer science);end-to-end principle;network packet;overhead (computing);parallel computing;pipeline (computing);power management;software system;throughput	Ismail Alan;Engin Arslan;Tevfik Kosar	2014	2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing	10.1109/CCGrid.2014.117	embedded system;real-time computing;computer science;computer network	Arch	-4.617378956729402	62.54580943810572	178231
4baae75daf9a60f6e57a1489677951931ee48a19	evaluation of content-access qos for various dissemination strategies in peer to peer networks	bandwidth measurement;file organisation quality of service information dissemination forward error correction internet;performance evaluation;peer to peer network;intelligent networks peer to peer computing quality of service bandwidth network servers forward error correction streaming media computer networks routing memory;erasure code;qos guarantee;data storage;forward error correction;internet;information dissemination;media streaming;network architecture;p2p networks;quality of service;peer to peer;media streaming peer to peer networks content access qos dissemination strategies logical network architecture end user nodes interconnected physical network infrastructure quality of service bandwidth distribution evaluation statistical content access content replication gnutella network simple file replication block file replication erasure encoded block replication forward error correction fec;file organisation	Peer to peer (P2P) Network is a high level logical network architecture build over end-user nodes interconnected by a physical network infrastructure. The main interest of their distributed structure is to avoid any centralized point. However, this structure makes difficult the evaluation of the global properties of the network. In the present effort, we propose a method to evaluate quality of service (QoS) for the content access in P2P networks. This method, based on bandwidth distribution evaluation, allows determining statistical content-access QoS guarantees in function of both the level of content replication in the network and the strategies of file dissemination. An implementation of this model, based on real bandwidth measurements on the Gnutella network, is proposed. Three dissemination strategies are evaluated: simple file replication, block file replication, and erasure-encoded (often called forward error correction (FEC) code) block replication. The results shows that statistical QoS guarantees can be provided by controlling the various dissemination parameters, and illustrates the interest of the FEC-based strategy. A simple application in the context of media streaming is finally proposed.	peer-to-peer;quality of service	Laurent Lancérica;Laurent Dairaine;Jérôme Lacan	2003		10.1109/ICON.2003.1266213	erasure code;the internet;network architecture;quality of service;computer science;computer data storage;distributed computing;forward error correction;world wide web;computer network	Theory	-14.118399311389044	73.55598530102691	178249
034ffd5c8825e09083b9d2e4788fbef3a838f435	system design issues for future in-vehicle ethernet-based time- and safety-critical networks	vehicular ad hoc networks local area networks mobile computing scheduling traffic engineering computing;sensor phenomena and characterization;bandwidth delays sensor phenomena and characterization radar cameras switches;bandwidth;bandwidth utilization factors in vehicle ethernet based time critical networks in vehicle ethernet based safety critical networks timing behavior predictability switched ethernet based networks ethernet based advanced driver assistance systems ethernet based adas earliest deadline first scheduling edf scheduling;switches;cameras;delays;radar	Timing behavior predictability is a necessary real-time requirement for future switched Ethernet-based networks in the automotive and similar domains. Schedulability of such safety- and time-critical networks has to be guaranteed. The paper proposes a system architecture for future Ethernet-based advanced driver assistance systems (ADAS) and analyzes its timing requirements on transmission and forwarding deadlines. It studies the schedulability for strict priority combined with earliest deadline first (EDF) scheduling. For that, conditions on bandwidth utilization factors guaranteeing schedulability in the whole network are formally determined.	architecture design and assessment system;earliest deadline first scheduling;real-time transcription;requirement;scheduling (computing);scheduling analysis real-time systems;simulation;systems architecture;window of opportunity	Aboubacar Diarra;Armin Zimmermann	2015	2015 Annual IEEE Systems Conference (SysCon) Proceedings	10.1109/SYSCON.2015.7116730	embedded system;real-time computing;synchronous ethernet;ethernet flow control;engineering;jumbo frame;connection-oriented ethernet;carrier ethernet;ethernet over sdh;network interface controller;ethernet;computer network	Embedded	-6.396009125530674	69.89117618565022	178284
62c6d3040a27b412931d3c1fd65fd0bceb3be237	designing packet buffers using random round robin	random access memory;randomized rounding;packet buffers;complexity theory;memory management;time complexity;sram chips buffer storage dram chips memory architecture;buffer storage;traffic control;hierarchical buffer architectures;mathematical analysis;upper bound;random round robin;round robin;time complexity packet buffers random round robin sram dram hierarchical buffer architectures memory management;memory architecture;random access memory delay round robin memory management traffic control complexity theory;sram;dram;high speed;dram chips;sram chips	High-speed routers rely on well-designed packet buffers that support multiple queues, large capacity and short response times. Some researchers suggested combined SRAM/DRAM hierarchical buffer architectures to meet these challenges. However, these architectures suffer from either large SRAM requirement or high time-complexity in the memory management. Our analysis indicates that they perform exactly the same in the worst case. In this paper, we present a novel packet buffer architecture which reduces the SRAM size requirement by (k-1)/2k, where k denotes the number of DRAMs working in parallel. We use a fast batch load scheme and per-queue Random Round Robin memory management algorithm. Our mathematical analysis and simulation results indicate that the proposed architecture provides guaranteed performance in terms of low time complexity, short access delay and upper-bounded drop rate, when a little speedup is provided.	algorithm;best, worst and average case;data buffer;dynamic random-access memory;memory management;network packet;requirement;router (computing);simulation;speedup;static random-access memory;time complexity	Dong Lin;Mounir Hamdi;Jogesh K. Muppala	2010	2010 IEEE Global Telecommunications Conference GLOBECOM 2010	10.1109/GLOCOM.2010.5683309	time complexity;randomized rounding;parallel computing;real-time computing;static random-access memory;computer hardware;computer science;operating system;upper and lower bounds;dram;memory management	HPC	-4.58284826555582	66.69202786184634	178973
b9b833103424c094e01de63e67049f1c470b3327	access time minimization for distributed multimedia applications	retrieval schedule;closed form solution;video streaming;sequencing;distributed multimedia applications;video distribution;bandwidth;document retrieval;multi installments;access time;heterogeneous network	The problem of minimizing the access time of a requested multimedia (MM) document on a network based environment is addressed. A generalized version of this problem is formulated and retrieval strategies that minimize the access time of the user-requested MM document from a pool of MM servers are proposed. To this end, we design single-installment and multi-installment MM document retrieval strategies, through which the minimization of access time can be carried out. The main idea is to utilize more than one MM server in downloading the requested document. Each server assumes the responsibility of uploading a predetermined portion of the entire document in a particular order. Single- and multi-installment strategies differ in the number of disjoint document pieces each server sends to the client. We first introduce a directed flow graph (DFG) model to represent the retrieval process and generate a set of recursive equations using this DFG. Then, we derive closed-form solutions for the portions of the MM document downloaded from the various servers and the corresponding access time. We present rigorous analysis for these two strategies and show their performance under MPEG-I and MPEG-II video streams playback rates. Their behavior under different network bandwidths is also examined, revealing in-depth information about their expected performance. We also show that in the case of a multi-installment strategy, the access time can be completely controlled by fine tuning the number of installments. Since the number of installments is software tunable, the adaptive nature of the strategies to different channel bandwidths is also demonstrated. Important trade-off studies with respect to the number of servers involved in the retrieval process and the number of installments are presented. In the case of a heterogeneous network employing a single-installment strategy, we prove that the access time is independent of the server sequence used. Illustrative examples are provided for ease of understanding.	access time;approximation;document retrieval;download;internet;mpeg-1;mpeg-2;mathematical optimization;moving picture experts group;norm (social);quality of service;recursion;server (computing);streaming media;upload;volatility;way to go	Bharadwaj Veeravalli;Gerassimos D. Barlas	2000	Multimedia Tools and Applications	10.1023/A:1009623825393	document retrieval;closed-form expression;heterogeneous network;telecommunications;access time;computer science;operating system;machine learning;sequencing;database;distributed computing;world wide web;computer security;bandwidth;algorithm;computer network	Web+IR	-16.625477112621073	71.99143311680511	179041
c6f8cc5d4471bc5c9add42d1a285eeb4a772265a	resource availability evaluation in service grid environment	availability scheduling distribution functions predictive models grid computing time measurement resource management statistical distributions workstations telecommunication traffic;task analysis grid computing probability quality of service resource allocation scheduling;task scheduling resource availability evaluation service grid environment dynamic grid environment resource availability prediction resource selection qos guarantee probability theory availability metrics resource off line time local task execution time waiting queue length waiting time time complexity	Federated digital libraries are composed of autonomous, possibly heterogeneous information services distributed across the Internet. Interoperation between diverse information services is one of the main challenges faced by FDLs. In this paper we describe an agent based mediator architecture that bridges the gap between heterogeneity systems. All agents communicate with each other by exchanging RDF (Resource Description Framework) messages. We illustrate our approach with a prototype system involving a SDLIP and a Z39.50 server, and we analyze performance of our infrastructure.		Zhoujun Hu;Zhigang Hu;Zhenhua Liu	2007		10.1109/APSCC.2007.17	real-time computing;resource allocation;distributed computing;business;computer network	HPC	-18.771049928710582	67.40407983242304	179378
a3037be106a217dde580be17fd5952979e4525b8	fault tolerant active rings for structured peer-to-peer overlays	practical fault prone networks;fault tolerant active rings;fault tolerant;storage overheads;structured overlay network;messaging overheads;dynamic system;b method;dynamic systems;paxos commit algorithm;fault tolerance peer to peer computing network topology protocols routing fault diagnosis systems engineering and theory formal specifications computer networks sections;active topology maintenance algorithm;telecommunication network topology fault tolerant computing peer to peer computing;storage overheads fault tolerant active rings structured peer to peer overlays passive topology maintenance periodic background repair neighbor pointers fault free networks active topology maintenance algorithm practical fault prone networks ring continuity normal topology changes paxos commit algorithm b method event driven extensions dynamic systems messaging overheads;ring continuity;fault tolerant computing;passive topology maintenance;normal topology changes;neighbor pointers;peer to peer computing;telecommunication network topology;periodic background repair;fault free networks;event driven extensions;structured peer to peer overlays	Algorithms by which peers join and leave structured overlay networks can be classified as passive or active. Passive topology maintenance relies on periodic background repair of neighbor pointers. When a node passively leaves the overlay, subsequent lookups may fail silently. Active maintenance has been proven only for fault-free networks. We develop an active topology maintenance algorithm for practical, fault-prone networks. Unlike prior work, it a) maintains ring continuity during normal topology changes and b) guarantees consistency and progress in the presence of faults. The latter property is inherited by novel extension of the Paxos commit algorithm. The topology maintenance algorithm is formally developed using the B method and its event-driven extensions for dynamic systems. Messaging and storage overheads are quantified	active filter;algorithm;b-method;dynamical system;emoticon;event-driven programming;overlay network;peer-to-peer;scott continuity	John Risson;Ken Robinson;Tim Moors	2005	The IEEE Conference on Local Computer Networks 30th Anniversary (LCN'05)l	10.1109/LCN.2005.69	real-time computing;computer science;dynamical system;distributed computing;computer network	DB	-7.673944417703656	72.15199424832784	179634
6adbab110663aec3f5122524f2fa8b60c55a44ea	ordering messages in virtual can networks	time division multiple access;protocols;time triggered;can based software automotive industry safety critical by wire system virtual can network can protocol time triggered architecture time triggered communication protocol;automotive industry;computer architecture real time systems protocols time division multiple access delay communication systems matlab;communication systems;safety critical by wire system;cost reduction;controller area networks;computer architecture;time triggered communication protocol;time triggered architecture;can based software;can protocol;safety critical software;present day;communication protocol;matlab;automobile industry;virtual can network;safety critical software automobile industry controller area networks protocols;real time systems	The automotive industry is at the verve to deploy computer systems not only for safety-related and comfort functionality, but for safety-critical by-wire systems. While the CAN protocol is prevalent in present day automotive networks, safety-critical by-wire systems will employ time-triggered architectures. Virtual CAN networks on top of a time-triggered communication protocol are a solution to integrate existing CAN-based applications into such a time-triggered architecture. Thus, there is the possibility to eliminate physical CAN networks, which leads to cost reductions and reliability improvements. In order to ensure that existing CAN-based software works correctly in a time-triggered architecture, a virtual CAN network must provide the temporal behavior of a physical CAN network. For this reason, we develop a solution for establishing in a virtual CAN network the same temporal message order as in a physical CAN network. We present a CAN emulation service and provide validation results based on an implementation in the Time-Triggered Architecture.	communications protocol;computer;emulator;time-triggered architecture;verve	Roman Obermaisser	2005	2005 12th IEEE International Conference on Electronics, Circuits and Systems	10.1109/ICECS.2005.4633552	embedded system;real-time computing;simulation;engineering	Visualization	-6.736569696458397	69.86003727123544	179892
882d3af5fa87705f8b6f3a97bec7599f8b034959	regular expression matching with pipelined delayed input dfas for high-speed networks		Regular expression matching (RE matching) is a widely used operation in network security monitoring applications. With the speed of network links increasing to 100 Gbps and 400 Gbps, it is necessary to speed up packet processing and provide RE matching at such high speeds. Although many RE matching algorithms and architectures have been designed, none of them supports 100 Gbps throughput together with fast updates of an RE set. Therefore, this paper focuses on the design of a new hardware architecture that addresses both these requirements. The proposed architecture uses multiple highly memory-efficient Delayed Input DFAs (D2FAs), which are organized to a processing pipeline. As all D2FAs in the pipeline have only local communication, the proposed architecture is able to operate at high frequency even for a large number of parallel engines, which allows scaling throughput to hundreds of gigabits per second. The paper also analyses how to scale the number of engines and the capacity of buffers to achieve desired throughput. Using the parameters obtained while matching a sample RE set represented by a D2FA in a real network traffic, the architecture can be tuned for wire-speed throughput of 400 Gbps.	algorithm;clock rate;data rate units;fits;field-programmable gate array;gigabit;image scaling;network packet;network security;regular expression;requirement;throughput;virtex (fpga)	Denis Matousek;Juraj Kubis;Jirí Matousek;Jan Korenek	2018		10.1145/3230718.3230730	computer science;architecture;real-time computing;throughput;packet processing;speedup;network security;regular expression;gigabit;hardware architecture	Arch	-6.778116538821993	66.30789807474486	179903
5c45f523e2cd04abe441fc6ab3ea68b076e4ef03	cross-layer real-time support for jvm-based smartphone systems	real time;smart phones;real time systems java kernel delay humanoid robots androids;virtual machines java operating system kernels real time systems scheduling smart phones;operating system;virtual machines;scheduling;os kernel cross layer real time support jvm based smartphone system jvm layer operating system scheduler timeliness requirement response time java virtual machine;operating system kernels;cross layer;java;real time systems	The existence of the JVM layer hinders applications from notifying the operating system scheduler about their timeliness requirements and, therefore, the applications sometimes fail to respond on time. This research proposes a cross-layer real-time support by which applications notify operating systems about their timeliness requirements. Our prototype shows significant improvements in the response times and throughputs of prioritized applications.	operating system;prototype;real-time clock;real-time computing;real-time transcription;requirement;scheduling (computing);smartphone	Youngjoo Woo;Jungwook Cho;Donghyouk Lim;Euiseong Seo	2012	2012 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2012.6162031	embedded system;real-time computing;computer science;virtual machine;operating system;java;scheduling	Embedded	-10.53835979141294	64.26542529313845	180083
f0047fc976509b28f7da099f9f3c033fc7774e6f	enabling efficient peer to peer resource discovery in dynamic grids using variable size routing indexes	p2p system;range query;resource discovery;query processing;routing;peer to peer systems;resource allocation;bandwidth allocation;distributed computing;range query processing;peer to peer system;accuracy;indexes;dynamic grid;servers;telecommunication network routing;peer to peer resource discovery;telecommunication network routing bandwidth allocation grid computing peer to peer computing query processing resource allocation;indexation;resource sharing;cities and towns;peer to peer computing;routing peer to peer computing grid computing scalability resource management computer networks computational modeling pervasive computing query processing bandwidth;variable size routing index;peer to peer;grid computing;grid system;range query grid computing resource discovery distributed computing peer to peer systems;network bandwidth consumption;network bandwidth consumption peer to peer resource discovery dynamic grid variable size routing index peer to peer system grid system p2p system resource sharing range query processing	Existing Methods and techniques utilized by Peer-to-Peer (P2P) systems could address the scalability issue faced by Grid systems. Today's Grid systems have to deal with potentially a large number of resources which their status changes over time. Therefore, accurate, fast and scalable discovery of resources are key issues that Grid systems should deal with. Typical P2P systems enable sharing static resources, such as files, among users. However, resources in Grids are dynamic. In this paper, we propose a solution for efficient processing of range queries on available resources. We examine our proposed method using simulation data. The experimental results show that our proposed method improves the performance of existing methods in terms of precision of query processing, average hit rate and network bandwidth consumption.	algorithm;database;grid systems corporation;hybrid system;network packet;peer-to-peer;range query (data structures);routing;scalability;simulation;software propagation	Mohammad Hassan Khoobkar;Mehregan Mahdavi	2009	2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks	10.1109/I-SPAN.2009.119	computer science;distributed computing;world wide web;computer network	HPC	-12.492410118212465	73.37068507778211	180219
21ac5b98cc5c5f121f3db56d12bee9a1377b65eb	distributed oblivious load balancing using prioritized job replication	electronic mail;ec2 distributed oblivious load balancing prioritized job replication distributed server system complex optimization problem cloud system data center load balancing system amazon elastic compute cloud;resource allocation;radiation detectors;computer centres;servers;servers load modeling delay load management queueing analysis radiation detectors electronic mail;load management;resource allocation cloud computing computer centres;load modeling;queueing analysis;cloud computing	Load balancing in large distributed server systems is a complex optimization problem of critical importance in cloud systems and data centers. However, any full (i.e., optimal) solution incurs significant, often prohibitive, overhead due to the need to collect state-dependent information. We propose a novel scheme that incurs no communication overhead between the users and the servers upon job arrivals, thus removing any scheduling overhead from the job execution's critical path. Furthermore, our scheme is oblivious, that is, it does not use any state information. Our approach is based on creating, in addition to the regular job requests that are assigned to randomly chosen servers, also replicas that are sent to different servers; these replicas are served in low priority, such that they do not add any real burden on the servers. Through analysis and simulations we show that the expected system performance improves up to a factor of 2 (even under high load conditions), if job lengths are exponentially distributed, and over a factor of 5, when job lengths adhere to heavy-tailed distributions. We implemented a load balancing system based on our approach and deployed it on the Amazon Elastic Compute Cloud (EC2). Realistic load tests on that system indicate that the actual performance is as predicted.	amazon elastic compute cloud (ec2);amazon web services;cloud computing;critical path method;data center;job scheduler;job stream;load balancing (computing);load testing;mathematical optimization;network packet;no-communication theorem;optimization problem;overhead (computing);propagation time;randomness;response time (technology);scheduling (computing);server (computing);simulation;software propagation;timeout (computing);world-system	Amir Nahir;Ariel Orda;Danny Raz	2012	2012 8th international conference on network and service management (cnsm) and 2012 workshop on systems virtualiztion management (svm)		round-robin dns;network load balancing services;real-time computing;cloud computing;resource allocation;computer science;load balancing;operating system;cloud testing;distributed computing;particle detector;server;computer network	HPC	-18.590871385992305	60.574153954965226	180319
23686516a3fc951abc2a4fb7131d97205045843c	rethinking the design of openflow switch counters	openflow;sdn counter	OpenFlow, as the Software Defined Networking (SDN) primitive, provides a simple forwarding plane abstraction, which heavily relies on the fast memory inside the OpenFlow Switch (OFS). OFS components, e.g. flow table, meter table, counters, have to compete for the limited fast memory resource. As a result, only a few counting functions are defined as mandatory in the OFS specification, although a lot of SDN proposals depend on a detailed states collected by the optional counters in the specification. This fact motivates us to rethink the way to maintain counters in the OFS. We propose a new architecture called CACTI, which only consumes several registers in the fast path and moves the completed counters into the on chip RAM like cache in the slow path processor. Theoretical analysis and experiments on the prototype system demonstrated the efficiency of our architecture: CACTI is capable to achieve the throughput of 29.4-39.7M pps packets per second (pps). No RAM resource is needed any more in the fast path, instead, CACTI consumes only 0.24-0.54\% Look-Up Table and 0.35-0.43\% flip-flops compared with the entire FPGA-based OFS design in the fast path, and the unused CPU cache in the slow path.	cpu cache;central processing unit;experiment;flops;fast path;field-programmable gate array;forwarding plane;network switch;openflow;prototype;random-access memory;software-defined networking;throughput	Ji Yang;Chengchen Hu;Peng Zheng;Ruilong Wang;Peng Zhang;Xiaohong Guan	2016		10.1145/2934872.2959062	openflow;parallel computing;real-time computing;computer science;operating system;distributed computing;computer security;computer network	Networks	-5.198961068747347	64.60990968693113	180608
72f1988de95ba97dc207b9124c3aac91bacb43e4	placement problems for transparent data replication proxy services	optimal solution;cache storage;performance evaluation;distributed networks;client server systems;data replication;indexing terms;system performance;computer networks;client server systems cache storage computer networks;simulation experiment;caching placement problems transparent data replication proxy services system performance large distributed network hybrid transparent replication model data replica placement reads writes data transfer cost tree network agga wpop aggregate access weighted popularity replication proxy placement problem replica placement problem;data access;system performance costs information retrieval sensor systems aggregates explosives computer networks distributed computing authoring systems;tree network;data placement;data transfer;reading and writing	Transparent data replication has been considered a promising technique for improving system performance for a large distributed network. In this paper, a hybrid transparent replication model is presented. We address the problems of replication proxy placement in the network and data replica placement on the installed proxies given that a maximum of proxies are allowed. Both reads and writes are considered in these problems. The performance objective is to minimize the total data transfer cost. To address the placement problems, we first present the optimal solutions for a single object in a tree network without/with constraint on the number of replicas. Based on that, two schemes, namely, AGGregate Access(AGGA)and Weighted POPularity (WPOP), are proposed for the replication proxy placement problem. An optimal solution is described for the replica placement problem. The performance of the proposed placement schemes is evaluated with a set of carefully designed simulation experiments over a wide range of system parameters. The results give us several helpful intuitions in deploying transparent replication proxies in a practical system.	aggregate function;experiment;proxy server;replication (computing);simulation;tree network	Jianliang Xu;Bo Li;Dik Lun Lee	2002	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2002.802068	data access;index term;computer science;database;distributed computing;computer performance;world wide web;replication;computer network	Networks	-15.488251985080806	66.98233684106557	180905
c9e700582129c187ac9a395456c767503922b1f0	content-based clustered p2p search model depending on set distance	document handling;vector space model;query processing;distributed hash table;documents similarity content based clustered p2p search model query efficiency redundant messages set distance;p2p;costs floods computational modeling contracts computer science peer to peer computing aerospace industry scalability real time systems network topology;gnutella;query efficiency;vector space model peer to peer gnutella distributed hash tables set distance;linear time;query processing document handling peer to peer computing;search cost;redundant messages;documents similarity;set distance;peer to peer computing;search model;distributed hash tables;peer to peer;high dimension;content based clustered p2p search model;document similarity	The main issues that affect query efficiency and search cost in content-based unstructured P2P search system are the complexity of computing the similarity of the documents brought by high dimensions and the great deal of redundant messages coming with flooding. This paper defines the documents similarity by the way of set distance. This method restrains the complexity of computing the document similarity in linear time. Also, this paper clusters the peers based on content by their set distance to reduce the query time and redundant messages. Simulations show that the content-based search model constructed by set distance not only has higher recall, but also reduce the search cost and query time to the rate of 40% and 30% of Gnutella.	gnutella;simulation;time complexity	Jing Wang;Shoubao Yang	2006	2006 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology Workshops	10.1109/WI-IATW.2006.53	time complexity;computer science;chord;theoretical computer science;search cost;peer-to-peer;data mining;database;world wide web;vector space model	DB	-12.051552885161348	74.04261297495266	181242
ce202b595fb0e8ae0a346e81eed83b8ebba03ab4	a task scheduling algorithm for multi-core-cluster systems	multi core processor;dag;scheduling length;task scheduling;multi core cluster systems;task duplication	The quantity of cores on one chip increases rapidly with the development of multi-core technology, which has led to more complex structure of cluster system and greatly increasing number of tasks. In order to schedule tasks in multi-core-cluster systems efficiently, a task schedule model based on the directed acyclic graph(DAG) is built, and then a algorithm based on task duplication is proposed. The algorithm is composed of two steps of operations, in which the processes are assigned to processor nodes in the first step and the threads in processes are assigned to core nodes in the second step respectively. The time complexity of this algorithm is less than similar algorithms. For the algorithm, minimization scheduling length is the primary objective, and keeping load balancing between processing nodes is secondary objectives. It can be seen through comparison with correlative work that the algorithm has advantages in scheduling length; furthermore, while the ratio of total communication cost and total computation cost in the task schedule model becomes larger, the advantage of this algorithm is more obvious.	algorithm;clustered file system;computation;directed acyclic graph;load balancing (computing);multi-core processor;scheduling (computing);time complexity	Xiaozhong Geng;Gaochao Xu;Xiaodong Fu;Yuan Zhang	2012	JCP	10.4304/jcp.7.11.2797-2804	multi-core processor;fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;foreground-background;distributed computing	HPC	-14.793449739034362	60.97191705063802	181268
e0ec0dc44465ffd556d839988397c72ae83981f3	a soft real-time web news classification system with double control loops	workload;busqueda informacion;tiempo respuesta;time average;systeme temps reel;analisis contenido;reponse temporelle;gestion informacion;feed forward;text;control theory;sobrecarga;prensa;feedforward;red www;bucle multiple;information retrieval;real time;reseau web;multiple loop;bucle control;response time;promedio temporal;theorie commande;texte;boucle anticipation;classification;soft real time;text classification;temps reponse;press;content analysis;ciclo anticipacion;internet;time response;recherche information;surcharge;information management;temps reel;presse;classification system;charge travail;tiempo real;world wide web;control loop;real time system;sistema tiempo real;gestion information;analyse contenu;carga trabajo;overload;respuesta temporal;texto;feedback control;clasificacion;boucle commande;boucle multiple;moyenne temporelle	This paper proposes a framework for soft real-time text classification system, which use control theory as a scientific underpinning, rather than ad hoc solutions. In order to provide real-time guarantee, two control loops are adopted. The feed forward control loop estimates the suitable number of classifiers according to the current workload, while the feedback control loop provides fine-grained control to the number of classifiers that perform imprecise computation. The soft real-time classification system can accommodate to the change of workload and transitional overload. The theory analysis and experiments result further prove its effectiveness: the variation range of the average response time is kept within ± 3% of the desired value; the computational resource is dynamically reallocated and reclaimed.	real-time transcription;real-time web	Huayong Wang;Yu Chen;Yiqi Dai	2005		10.1007/11563952_8	content analysis;telecommunications;computer science;artificial intelligence;information management;feed forward	ML	-11.723782698997038	65.45644405615624	181573
34a4804ef54fae88c5a377876beed2812cdfa391	the structure and modeling results of the parallel spatial switching system	system of mass service;switched system;parallel spatial switching system;information systems;mass service;parallel switching;packet switched;packet switching;communication network parallel switching information systems system of mass service packet switching;indexing terms;switching systems communication switching packet switching information systems communication system control delay effects mathematical model logic programming communication networks control systems;random time;parallel spatial switching system mass service random time switching parallel system designing;community networks;parallel systems;switching parallel system designing;information system;communication network;parallel processing;random times	Problems of the switching parallel system designing provided spatial switching of packets from random time are discussed. Results of modeling of switching system as systems of mass service are presented.		Denis Kutuzov	2007	2007 Siberian Conference on Control and Communications	10.1109/SIBCON.2007.371303	parallel processing;real-time computing;optical burst switching;computer science;theoretical computer science;distributed computing;information system;computer network	HPC	-4.54546660519457	69.31969014953593	181638
17edec722f6fb22909b0f175a7e82a0157cab249	a hyperbolic bound for the rate monotonic algorithm	analytical models;exact test;exact response time analysis;protocols;mathematics;rate monotonic algorithm;exact response time analysis hyperbolic bound rate monotonic algorithm schedulability analysis large periodic task sets formal verification complexity concurrency control protocols;processor scheduling;hyperbolic bound;concurrency control protocols;testing;complexity;schedulability analysis;runtime;testing algorithm design and analysis scheduling algorithm runtime mathematics h infinity control concurrency control protocols analytical models delay;scheduling algorithm;formal verification;periodic tasks;computational complexity;formal verification concurrency control protocols computational complexity processor scheduling;concurrency control;large periodic task sets;h infinity control;algorithm design and analysis;rate monotonic	In this paper we propose a novel schedulability analysis for verihing the feasibility of large periodic task sets under the rate monotonic algorithm, when the exact test cannot be applied on line due to prohibitively long execution times. The proposed test has the same complexity as the original Liu and Layland bound but it is less pessimistic, so allowing to accept task sets that would be rejected using the original approach. The performance of the proposed approach is evaluated with respect to the classical Liu and Layland method, and theoretical bounds are derived as a function oyn (the number of tasks) and for the limit case of n tending to infinity. The analysis is also extended to include aperiodic servers and blocking times due to concurrency control protocols. Extensive simulations on synthetic tasks sets are presented to compare the effectiveness of the proposed test with respect to the Liu and Layland method and the exact response time analysis.	algorithm;aperiodic graph;blocking (computing);concurrency (computer science);concurrency control;ll parser;lucas–lehmer primality test;memory bound function;online and offline;polynomial;response time (technology);rough set;scheduling (computing);scheduling analysis real-time systems;simulation;synthetic intelligence;time complexity	Enrico Bini;Giorgio C. Buttazzo;Giuseppe M. Buttazzo	2001		10.1109/EMRTS.2001.934000	communications protocol;algorithm design;complexity;real-time computing;formal verification;computer science;theoretical computer science;concurrency control;distributed computing;exact test;software testing;computational complexity theory;scheduling	Embedded	-9.7889412504314	61.18990016255949	181701
82f94c37f589fc8aac1490acc9025b50d9f75c75	supporting soft real-time dag-based systems on multiprocessors with no utilization loss	directed graphs;directed acyclic graph;bounded deadline tardiness;multiprocessor systems;processor scheduling;real time;real time systems scheduling algorithm schedules partitioning algorithms joining processes timing;dag model soft real time dag based system globally scheduled real time multiprocessor system general processing graph model bounded deadline tardiness periodic based directed acyclic graph model sporadic based directed acyclic graph model rate based directed acyclic graph model;soft real time;general processing graph model;scheduling algorithm;dag model;processing graph method;soft real time dag based system;sporadic based directed acyclic graph model;schedules;joining processes;multiprocessing systems;real time systems directed graphs multiprocessing systems processor scheduling;graph model;periodic based directed acyclic graph model;real time application;rate based directed acyclic graph model;globally scheduled real time multiprocessor system;partitioning algorithms;real time systems;timing	In work on globally-scheduled real-time multiprocessor systems, analysis is lacking for supporting real-time applications developed using general processing graph models. In this paper, it is shown that bounded deadline tardiness can be ensured for such applications on a multiprocessor with no utilization loss. This result is general: it is applicable to periodic, sporadic, and rate-based directed-acyclic-graph (DAG) models and allows sophisticated notions of precedence to be supported (particularly, notions allowed by the processing graph method). This paper is the first to show that bounded tardiness can be ensured for globally-scheduled DAG-based applications without utilization loss.	algorithm;central processing unit;directed acyclic graph;earliest deadline first scheduling;fifo (computing and electronics);heisenbug;multiprocessing;process state;real-time clock;real-time operating system;real-time transcription;scheduling (computing);uniprocessor system;work-conserving scheduler	Cong Liu;James H. Anderson	2010	2010 31st IEEE Real-Time Systems Symposium	10.1109/RTSS.2010.38	parallel computing;real-time computing;directed graph;schedule;computer science;distributed computing;scheduling;directed acyclic graph	Embedded	-10.334522784923143	60.93440424719843	181850
564f600b0334e94095ccbb86c0f47202d4d47bde	scheduling uet-uct series-parallel graphs on two processors	time delay;series parallel graph;uct;task graphs	The scheduling of task graphs on two identical processors is considered. It is assumed that tasks have unit-execution-time, and arcs are associated with unit-communication-time delays. The problem is to assign the tasks to the two processors and schedule their execution in order to minimize the makespan. A quadratic algorithm is proposed to compute an optimal schedule for a class of series-parallel graphs, called SP1 graphs, which includes in particular in-forests and out-forests.	algorithm;central processing unit;makespan;scheduling (computing);series-parallel graph	Lucian Finta;Zhen Liu;Ioannis Milis;Evripidis Bampis	1996	Theor. Comput. Sci.	10.1016/0304-3975(96)00035-7	1-planar graph;pathwidth;open-shop scheduling;parallel computing;real-time computing;interval graph;graph product;longest path problem;computer science;hopcroft–karp algorithm;distributed computing;maximal independent set;modular decomposition;treewidth;partial k-tree;indifference graph	Theory	-10.893566218534135	61.64552805885576	182673
4d387d56eee38eeb1bc6dd507cc7ceba9502bce4	a peer-to-peer architecture for efficient live scalable media streaming on internet	scalable video coding;p2p;scheduling algorithm;indexation;media streaming;overlay network;live media streaming;peer to peer;heterogeneous network	This paper presents a manageable overlay network architecture SVCP2P for live scalable media streaming. Every peer in SVCP2P periodically exchanges data availability information with one of distributed central servers which act as the centralized index for storing peer list, program list and buffer information of peers. An efficient scheduling algorithm is proposed, which achieves real-time and continuous transmission of the scalable streaming. There are three characteristics of this architecture: 1) easy management; 2) efficient to heterogeneous network because of the scalable media streaming adapting to the heterogeneous demand; and 3) robust and resilient. We have examined the SVCP2P which has been implemented based on the IP Internet over LAN, and the results demonstrate the efficiency of SVCP2P.	algorithm;centralized computing;internet;network architecture;overlay network;peer-to-peer;real-time clock;scalability;scheduling (computing);streaming media	Xuguang Lan;Nanning Zheng;Jianru Xue;Xiaoguang Wu;Bin Gao	2007		10.1145/1291233.1291410	scalable video coding;real time streaming protocol;overlay network;heterogeneous network;computer science;peer-to-peer;internet privacy;scheduling;world wide web;computer network	OS	-16.036689506750314	73.51807889766008	182777
093ee87a642a4bef09b4ed3be909e465a1bb4da1	optimization of secure embedded systems with dynamic task sets	difficult problem;modern embedded system;embedded systems design;security constraint;novel secure embedded system;design framework;design process;dynamic task set;high quality;active task;runtime quality optimization;igbt;computer and information science;algorithm design and analysis;optimization;quality of service;embedded systems;encryption	In this paper, we approach embedded systems design from a new angle that considers not only quality of service but also security as part of the design process. Moreover, we also take into consideration the dynamic aspect of modern embedded systems in which the number and nature of active tasks are variable during run-time. In this context, providing both high quality of service and guaranteeing the required level of security becomes a difficult problem. Therefore, we propose a novel secure embedded systems design framework that efficiently solves the problem of runtime quality optimization with security constraints. Experiments demonstrate the efficiency of our proposed techniques.	display resolution;embedded system;mathematical optimization;quality of service;systems design	Ke Jiang;Petru Eles;Zebo Peng	2013	2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)		embedded system;electronic engineering;insulated-gate bipolar transistor;real-time computing;telecommunications;computer science;electrical engineering;theoretical computer science;operating system;distributed computing	EDA	-4.767561412179586	61.12021048708771	182809
94a5b150bf8b75cd6c97a7abf67108e9eb145244	load balancing in homogeneous broadcast distributed systems	identical processor;multi-resource system;load balancing;csma communication system;analytic model;balancing process;different load;balancing algorithm;homogeneous broadcast;communication system;load balance;distributed system	Three different load balancing algorithms for distributed systems that consist of a number of identical processors and a CSMA communication system are presented in this paper. Some of the properties of a multi-resource system and the balancing process are demonstrated by an analytic model. Simulation is used as a mean for studying the interdependency between the parameters of the distributed system and the behaviour of the balancing algorithm. The results of this study shed light on the characteristics of the load balancing process.	algorithm;central processing unit;distributed computing;glossary of computer graphics;interdependence;load balancing (computing);simulation	Miron Livny;Myron Melman	1982		10.1145/800047.801689	parallel computing;real-time computing;computer science;load balancing;distributed computing;communications system	Metrics	-13.32078048099671	63.81175010330092	182983
a5c138582584f56fe3156cf65f87552e7971ccb3	thermal-aware performance optimization in power constrained heterogenous data centers	computers;optimisation;air conditioning;power demand heating optimization servers computational modeling data models computers;heterogeneous computing;heterogeneous computing thermal aware performance states data center crac;heating;computer centres;power aware computing;data center;servers;computational modeling;power aware computing air conditioning computer centres optimisation;crac;thermal aware;optimization;performance states;performance state assignments thermal aware performance optimization power constrained heterogeneous data centers power consumption thermal constraints computer room air conditioning units crac compute nodes optimization techniques compute cores;power demand;data models	The power consumption of data centers has been increasing at a rapid rate over the past few years. Many of these data centers experience physical limitations on the power needed to run the data center. This paper attempts to maximize the performance of a data center that is subject to total power consumption and thermal constraints. We consider a power model for a data center that includes power consumed in both Computer Room Air Conditioning (CRAC) units and compute nodes. Our approach quantifies the performance of the data center as the total reward collected from completing tasks in a workload by their individual deadlines. We develop novel optimization techniques for assigning the performance states of compute cores at the data center level to increase the performance of the data center. The assignment problem in this paper is thermal aware as it considers the temperature evolution effects of performance state assignments, which in turn affects the power consumed by the CRAC units. Our simulation studies show that in some cases the assignment technique used in this paper achieves about 10% average improvement in the performance of a data center over an assignment problem that only considers putting a compute core in the performance state with the highest performance or turning the core off.	advanced configuration and power interface;assignment problem;data center;mathematical optimization;simulation	Abdulla Al-Qawasmeh;Sudeep Pasricha;Anthony A. Maciejewski;Howard Jay Siegel	2012	2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum	10.1109/IPDPSW.2012.19	embedded system;data modeling;data center;parallel computing;real-time computing;simulation;air conditioning;power usage effectiveness;computer science;operating system;distributed computing;computational model;symmetric multiprocessor system;server;computer network	HPC	-15.836524540247076	62.815391294236434	183274
432d880005c00a09124563e45f8cf05f26ab7ae3	netp1-03: partition filter set for power-efficient packet classification	ternary content addressable memory;matched filters partitioning algorithms energy consumption tcpip nonlinear filters access protocols data structures computer science algorithm design and analysis access control;power efficient packet classification;partition filter;time space complexity;digital filters content addressable storage;digital filters;partition algorithm;content addressable storage;hilbert curve partition filter power efficient packet classification ternary content addressable memory multi dimensional filters time space complexity partition algorithm;multi dimensional filters;hilbert curve	Ternary Content-Addressable Memory (TCAM) has been widely used for high-performance multi-dimensional packet classification. High power consumption limits the use of TCAM for large filter sets. TCAM power consumption is proportional to the number of TCAM entries enabled for search. Dividing TCAM into many blocks and enabling only a few blocks for search has been proposed to reduce the power consumption dramatically. However, it is quite challenging to design efficient algorithms to partition a set of multi-dimensional filters into many subsets (a subset is placed in one TCAM block). The efficiency of the algorithm is evaluated in three aspects: the maximum number of TCAM blocks that need to be enabled for a single search, the storage utilization of TCAM blocks, and the time and space complexity of the partition algorithm. In this paper, we developed a simple but efficient partition algorithm based on the Hilbert curve. The algorithm reduces TCAM power consumption by a factor of ten on average. The TCAM storage utilization is over 99%. The algorithm takes 0(n log n) time and 0(n) space.	algorithm;basic block;content-addressable memory;dspace;decade (log scale);hilbert curve;network packet;overlap–add method;storage efficiency;telecommunications access method	Haibin Lu;Mian Pan	2006	IEEE Globecom 2006	10.1109/GLOCOM.2006.229	partition problem;discrete mathematics;real-time computing;digital filter;computer science;theoretical computer science;mathematics	Networks	-5.9949618801768185	67.21877194309427	183688
fbdd1fd6502039db49060f6221b74b8b991353a2	end-to-end schedulability analysis for bi-directional real-time multistage pipeline	pipeline schedulability test technique;uniprocessor schedulability analysis theory;processor scheduling;end to end schedulability analysis;periodic arrival pattern;pipeline schedulability test technique end to end schedulability analysis bi directional real time multistage pipeline end to end delay bound uniprocessor schedulability analysis theory periodic arrival pattern;upper bound;end to end delay bound;scheduling;pipelines;bidirectional control;real time systems pipeline processing processor scheduling;generalized pipeline system;end to end schedulability analysis generalized pipeline system;delay pipelines bidirectional control upper bound scheduling real time systems load modeling;load modeling;bi directional real time multistage pipeline;pipeline processing;real time systems	In this paper we discuss the end-to-end schedulability analysis for the bi-directional multistage pipeline systems, in which the arriving tasks could traverse the pipeline nodes in either of the two opposite directions. By accounting for the task execution overlap among nodes, we could derive an end-to-end delay bound formula for each task, which transforms the schedulability analysis of the task in the pipeline system into the schedulability analysis of that task in a corresponding single node system essentially, then the uniprocessor schedulability analysis theory could be applied to test the schedulability of this task in the original pipeline system. This transformation makes no assumptions on task arrival patterns and thus could be applied to both periodic and a periodic arrival patterns. We compare this technique with previous pipeline schedulability test techniques and show by simulations that our technique could derive better end-to-end delay bound except when node count is small and the ratio of deadline to period is large.	dynamic priority scheduling;end-to-end principle;holism;multistage amplifier;quasiperiodicity;real-time clock;real-time transcription;scheduling (computing);scheduling analysis real-time systems;simulation;traverse;tree-meta;uniprocessor system	Shenglin Gui;Lei Luo	2011	2011 IEEE Ninth International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2011.27	embedded system;parallel computing;real-time computing;computer science;operating system;pipeline transport;upper and lower bounds;scheduling;worst-case execution time	Embedded	-8.797551935681785	62.26473623122264	183877
378dee89f6f1ea243b3918c03b53a721a82a9c55	making a cost-effective video server	storage allocation;television;file servers;video signal processing;interactive video;motion pictures streaming media multimedia systems file servers analytical models cost function bandwidth educational technology games programming profession;file allocation problem cost effective video server cost effective video server cost effective system video file allocation storage media analytical model;video server;cost effectiveness;interactive television;storage allocation television interactive television video signal processing file servers interactive video;analytical model	A cost-effective system must allocate video files to the right place at the right time. We present the characteristics of different storage media and provide an analytical model for obtaining the cost of storing video files. We then state the video file allocation problem and provide a solution.<<ETX>>	digital video;server (computing);video file format;video server	Yurdaer N. Doganata;Asser N. Tantawi	1994	IEEE MultiMedia	10.1109/93.338684	microsoft video 1;file server;real-time computing;cost-effectiveness analysis;uncompressed video;telecommunications;computer science;operating system;video tracking;multimedia;video processing;smacker video;interactive television;television;world wide web;non-linear editing system	DB	-15.46443620197099	71.50494377146332	184001
01d700847cf6bbc9cb3f710f50ef2765f44d56dd	scheduling algorithms for i/o blockings with a multi-frame task model	scheduling distributed processing genetic algorithms;rate monotonic analysis;distributed processing;i o blockings;task model;genetic algorithm scheduling algorithms i o blockings multiframe task model distributed environments real time scheduling rate monotonic analysis dynamic priority assignment saturation summation maximum interference function frame laxity monotonic scheduling;schedulability analysis;maximum interference function;scheduling algorithm interference dynamic scheduling genetic algorithms information science sufficient conditions educational institutions processor scheduling real time systems computer applications;scheduling algorithm;scheduling algorithms;scheduling;scheduling theory;real time scheduling;dynamic priority assignment;genetic algorithm;genetic algorithms;frame laxity monotonic scheduling;saturation summation;task scheduling;multiframe task model;hard real time;distributed environments	A task that suspends itself to wait for an I/O completion or to wait for an event from another node in distributed environments is called an I/O blocking task. In conventional hard real-time scheduling theories, there exist several approaches to schedule such I/O blocking tasks within the conventional framework of rate monotonic analysis (RMA). However, most of them are pessimistic. In this paper, we propose effective algorithms that can schedule a task set which includes I/O blocking tasks under dynamic priority assignment. We present a new critical instant theorem for multi-frame task set under dynamic priority assignment. The schedulability is analyzed under the new critical instant theorem. For the schedulability analysis , this paper presents saturation summation which is used to calculate maximum interference function (MIF). With the saturation summation, the schedulability of a task set including I/O blocking tasks can be analyzed more accurately. We propose an algorithm which is based on a frame laxity monotonic scheduling (FLMS). Genetic algorithm is also applied. From our experiments, we can conclude that the FLMS can significantly reduce the time of the calculation time, and GA can improve task schedulability ratio than the FLMS.	blocking (computing);euler–maclaurin formula;existential quantification;experiment;genetic algorithm;input/output;instant messaging;interference (communication);non-monotonic logic;real-time clock;real-time computing;revolution in military affairs;scheduling (computing);scheduling analysis real-time systems;software release life cycle	Shan Ding;Hiroyuki Tomiyama;Hiroaki Takada	2007	13th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA 2007)	10.1109/RTCSA.2007.65	parallel computing;real-time computing;computer science;operating system;distributed computing;scheduling	Embedded	-11.385281669684993	60.68439199840821	184016
0cf2690a3417c55f77708346cf423f862d2c2e83	towards high-performance flow-level packet processing on multi-core network processors	classification algorithm;network processor;packet order;high performance networks;classification;hashing;load balance;access control;memory hierarchy;high performance;core network	There is a growing interest in designing high-performance network devices to perform packet processing at flow level. Applications such as stateful access control, deep inspection and flow-based load balancing all require efficient flow-level packet processing. In this paper, we present a design of high-performance flow-level packet processing system based on multi-core network processors. Main contribution of this paper includes: a) A high performance flow classification algorithm optimized for network processors; b) An efficient flow state management scheme leveraging memory hierarchy to support large number of concurrent flows; c) Two hardware-optimized order-preserving strategies that preserve internal and external per-flow packet order. Experimental results show that: a) The proposed flow classification algorithm, AggreCuts, outperforms the well-known HiCuts algorithm in terms of classification rate and memory usage; b) The presented SigHash scheme can manage over 10M concurrent flow states on the Intel IXP2850 NP with extremely low collision rate; c) The performance of internal packet order-preserving scheme using SRAM queue-array is about 70% of that of external packet order-preserving scheme realized by ordered-thread execution.	access control;algorithm;central processing unit;emoticon;load balancing (computing);memory hierarchy;multi-commodity flow problem;multi-core processor;network packet;network processor;state management;stateful firewall;static random-access memory;whole earth 'lectronic link	Yaxuan Qi;Bo Xu;Fei He;Baohua Yang;Jianming Yu;Jun Li	2007		10.1145/1323548.1323552	link state packet;parallel computing;real-time computing;hash function;core network;packet analyzer;fast packet switching;packet generator;biological classification;computer science;packet segmentation;processing delay;access control;load balancing;operating system;end-to-end delay;distributed computing;transmission delay;packet switch;computer security;network processor;computer network	Networks	-6.658551144228017	66.5196495197601	184075
81edcfa072984936910ecaef33e820e65341c9dc	on scheduling real-time multi-item query with network coding in multi-rsu vehicular networks	servers;network coding;scheduling algorithms;vehicular ad hoc networks;bandwidth;vehicles;encoding	Road Side Units (RSUs) installed alongside the road in Vehicular Ad Hoc Networks (VANETs) act as buffer points and alleviate the frequent vehicle-to-vehicle connectivity problem. In VANETs, submitting multi-item query is a common phenomenon, for instance, a query with required traffic information of multiple routes. Unlike the single item query, a multi-item query only be satisfied successfully if all the required data items are served within the stipulated deadline. In serving multi-item query, the system also needs to address the query starvation problem which causes due to the presence of less popular data items in the same query with the high popular data items. In this paper, for serving multi-item queries efficiently, we have proposed an approach which integrates network coding with on-demand broadcasting in multi-RSU VANETs. The traditional on-demand broadcast only disseminates a single data item in a broadcast tick which restricts the maximum channel bandwidth utilization. On the contrary, our proposed approach uses network coding through which multiple data items can be broadcast in a single broadcast. Again, our proposed network coding based approach learns the cache information of vehicles intrinsically which cuts the overhead of network coding, namely avoids uploading cache information of vehicles to the RSU server explicitly. In addition, the proposed approach is equally good to integrate both with the item-level and query-level on-demand scheduling algorithms for maximizing the system performance. Finally, we have performed an extensive simulation experiment to demonstrate the superiority of our proposed approach against the traditional broadcasting system for a number of on-demand scheduling algorithms.	algorithm;cpu cache;data item;linear network coding;overhead (computing);real-time transcription;scheduling (computing);server (computing);simulation;upload;vehicle-to-vehicle;window of opportunity	Md. Ashiqur Rahman;G. G. Md. Nawaz Ali;Peter Han Joo Chong;Syeda Khairunnesa Samantha;Mohammed Muntasir;C. Chen	2016	2016 IEEE 22nd International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)	10.1109/RTCSA.2016.49	embedded system;query optimization;linear network coding;real-time computing;computer science;operating system;distributed computing;scheduling;bandwidth;server;encoding;computer network	DB	-14.961932890169763	69.56662276269826	184151
a2abd3c9ae13405b9a86e471afa8c2b628cccf8e	publish/subscribe and jxta based cloud service management with qos	cloud service;multi dimension;service management;qos;publish subscribe;jxta	How to manage cloud services efficiently is difficult for large scale of services with frequently changing Quality of Service (QoS) in cloud computing environment. A multiple-dimension publish/ subscribe (pub/sub) and JXTA based cloud service management mechanism, consists of registry overlay, service publisher and subscriber, is proposed to manage cloud services with active QoS refreshing and fast subscribe capability. The registry overlay with multiple managers cooperating on JXTA, can manage large scale services discovery. The service model with QoS describes a formal model for pub/sub based service management, and a fast subscribing algorithm with filter matrix and multi-dimension index is proposed. The filter matrix helps to reduce candidate services and the multi-dimension index is used to find satisfied services fast. Based on pub/sub and JXTA, the cloud management system is realized. The experiments show that the proposed cloud service management mechanism has good publication and subscribing performance, and is faster than traditional methods for large scale cloud services. KeywoRdS Cloud Service, JXTA, Multi Dimension, Publish/Subscribe, QoS, Service Management	algorithm;cloud computing;cloud management;experiment;jxta;publish–subscribe pattern;quality of service;the filter	Qian He;Yong Wang;Jia Li;Mengfei Cai	2016	IJGHPC	10.4018/IJGHPC.2016070102	mobile qos;quality of service;cloud computing;service management;computer science;operating system;database;publish–subscribe pattern;world wide web;computer network	HPC	-19.117347056144176	67.58431557746115	184307
83cd180fe27888749d6a6f68bfba3f5fb5e7d8f2	cost-effective partial migration of vod services to content clouds	migration strategy;costing;cost saving;video on demand cloud computing costing;content cloud;video on demand;popularity evolution;cloud computing bandwidth servers streaming media ash aggregates electronic mail;client server mode cost effective partial migration content clouds video on demand service self owned servers bandwidth underutilization amazon cloudfront azure cdn hybrid cloud assisted deployment;cost effectiveness;bandwidth cost savings;bandwidth cost savings content cloud vod migration strategy popularity evolution;vod;cloud computing	Since user demand for a Video-on-demand (VoD) service varies with time in one-day period, provisioning self-owned servers for the peak load it must sustain a few hours per day leads to bandwidth underutilization at other times. Content clouds, e.g. Amazon Cloud Front and Azure CDN, let VoD providers pay by bytes for bandwidth resources, potentially leading to cost savings even if the unit rate to rent a machine from a cloud provider is higher than the rate to own one. In this paper, based on long-term traces from two large-scale VoD systems and temporal development model of content clouds, we tackle challenges, design and potential benefits in migrating VoD services into the hybrid cloud-assisted deployment, where the user requests are partly served by the self-owned servers and partly served by the cloud. Our measurements show that the popularity of the most popular videos decays so quickly, for example, by 11% after one hour that it poses large challenges on updating videos in the cloud. However, the trace-driven evaluations show that our proposed migration strategies (active, reactive and smart strategies), although simply based on the current information, can make the hybrid cloud-assisted VoD deployment save up to 30% bandwidth expense compared with the Clients/Server mode. They can also handle unpredicted the flash crowd traffic with little cost. It also shows that the cloud price and server bandwidth chosen play the most important roles in saving cost, while the cloud storage size and cloud content update strategy play the key roles in the user experience improvement.	amazon elastic compute cloud (ec2);amazon web services;byte;cloud computing;cloud storage;content delivery network;heuristic evaluation;load profile;microsoft azure;pps.tv;peer-to-peer;performance evaluation;provisioning;server (computing);simulation;slashdot effect;software deployment;system migration;tracing (software);user experience	Haitao Li;Lili Zhong;Jiangchuan Liu;Bo Li;Ke Xu	2011	2011 IEEE 4th International Conference on Cloud Computing	10.1109/CLOUD.2011.41	cost-effectiveness analysis;cloud computing;computer science;operating system;internet privacy;world wide web;activity-based costing;computer network	Metrics	-18.369839164296362	73.86920419110355	184354
4945c3cf5fea699b66b8880466c11d0858ddab02	determining job-scheduling priorities through simulation	job scheduling		job scheduler;scheduling (computing);simulation	Angela Toussaint	1995			job scheduler;real-time computing;operations management;dynamic priority scheduling;rate-monotonic scheduling;computer science;flow shop scheduling	EDA	-11.68908916732399	62.23195983607102	184355
46aaab09845001a90b5c8ccdb874f6f9f3d068f7	performance-enhanced caching scheme for web clusters for dynamic content	cache;performance;qos;web cluster;web services;dynamic content	In order to improve the QoS of applications, clusters of web servers are increasingly used in web services. Caching helps improve performance in web servers, but is largely exploited only for static web content. With more web applications using backend databases today, caching of dynamic content has a crucial role in web performance. This paper presents a set of cache management schemes for handling dynamic data in web clusters by sharing cached contents. These schemes use either automatic or expiry-based cache validation, and work with any type of request distribution. The techniques improve response by utilizing the caches efficiently and reducing redundant database accesses by web servers while ensuring cache consistency. The authors present caching schemes for both horizontal and vertical cluster architectures. Simulations show an appreciable performance rise in response times of queries in clustered web servers.	cpu cache;cache (computing);cache coherence;computer simulation;database;dynamic data;dynamic web page;quality of service;web application;web content;web performance;web server;web service	A. Raghunathan;K. Murugesan	2011	IJBDCN	10.4018/jbdcn.2011070102	web service;real-time computing;quality of service;performance;cache;computer science;operating system;dynamic web page;database;world wide web;web server	Web+IR	-17.89190616544459	70.02022275208998	184456
112df7bd393f7d7cd6c01bc4ff36678a66d77b12	stateful inspection firewall session table processing	filtering;authorisation;inspection data structures application specific integrated circuits computer science computer architecture costs ethernet networks filtering security space technology;firewall session table processing;inspection;computer architecture;telecommunication network routing;application specific integrated circuits;data structures;gigabit ethernet;network devices;authorisation local area networks telecommunication network routing table lookup application specific integrated circuits;space technology;gigabit ethernet network firewall session table processing network devices routers data structures patricia algorithm asic;computer science;asic;table lookup;security;ethernet networks;data structure;routers;local area networks;gigabit ethernet network;patricia algorithm	Stateful Inspection is a key technology to network devices such as routers and firewalls. Existed session table architectures of Stateful Inspection devices store all session information in a single entry, which causes high time cost of session table timeout processing. In this paper we present a new architecture which divides a session entry into two parts, and designs different data structures for each other. The new architecture can improve the performance of session table greatly. A new PATRICIA algorithm is proposed to organize session table, which is proved to be an optimal 2-ary trie for fixed-length match. An ASIC is implemented for the architecture and corresponding algorithms. Both theoretical and experimental results show that the new architecture has better performance than existed architectures, and can work well in Gigabit Ethernet network.	algorithm;application-specific integrated circuit;data structure;firewall (computing);gigabit;lookup table;radix tree;router (computing);stateful firewall;trie	Xin Li;Zhenzhou Ji;Mingzeng Hu	2005	International Conference on Information Technology: Coding and Computing (ITCC'05) - Volume II	10.1109/ITCC.2005.261	parallel computing;real-time computing;computer science;computer network	HPC	-6.685074597043107	67.22547327887985	184523
e2cab1cfb04f8aac0035539b276caec08addcc3c	web caching: architectures and performance evaluation survey	service oriented architecture routing cooperative caching internet network servers performance analysis telecommunication traffic delay bandwidth scalability;cache storage;performance evaluation;storage management;storage management internet cache storage;internet;performance parameters web caching performance evaluation routing techniques;web caching	In this paper, we study the architectures and routing techniques used in cooperative web caching and the techniques to evaluate the performances of caching systems. In the first part, the paper studies those advantages and disadvantages of different architectures of caching systems. In the second part, we describe routing techniques combined with these architectures of caching systems. And in the rest of this paper, we discuss the performance parameters and tools with which people can evaluate the performance of different web caching mechanisms.	performance evaluation;web cache	Guanpi Lai;Ming-Kuan Liu;Fei-Yue Wang;Daniel Dajun Zeng	2001		10.1109/ICSMC.2001.971982	real-time computing;the internet;cache stampede;false sharing;computer science;smart cache;world wide web;computer network	Vision	-17.609524331272787	71.55907843526411	184552
e99c6425420fdb99bcccb22b7790083d15561e6f	topology re-formation algorithms for ubiquitous p2p networks based on response statistics	query processing;query issuer topology re formation algorithms ubiquitous p2p networks response statistics peer to peer networks ubiquitous environments flooding based p2p networks content matching;network topology statistics context aware services telecommunication traffic information retrieval ubiquitous computing floods peer to peer computing computational modeling home appliances;simulation experiment;ubiquitous computing peer to peer computing query processing statistics;network traffic;statistics;ubiquitous computing;p2p networks;peer to peer computing;peer to peer	Recently, peer-to-peer (P2P) networks are becoming popular as communication forms for ubiquitous environments. Flooding-based P2P networks such as Gnutella have a problem that they generate a huge amount of network traffic. Moreover, their recall ratio is generally low because their topologies are constructed regardless of preference of each peer. In this paper, we propose a topology re-formation algorithm for flooding-based P2P networks. In the proposed algorithm, each peer observes responses that passed through itself and re-forms the topology so that peers with a content matching the query can be located near the query issuer. By simulation experiments, we show that peers with similar preferences get collected in the P2P network, and the recall ratio improves greatly	algorithm;authentication;experiment;gnutella;hot swapping;network traffic control;paging;peer-to-peer;simulation	Hirokazu Nakano;Kaname Harumoto;Shojiro Nishio	2007	2007 International Symposium on Applications and the Internet Workshops	10.1109/SAINT-W.2007.101	computer experiment;computer science;internet privacy;world wide web;ubiquitous computing;statistics;computer network	Metrics	-13.589911023058564	74.17859313729586	184654
482c881daf714e9c4c6e8b2a8306efbafec3d3d5	scalable gpu-accelerated ipv6 lookup using hierarchical perfect hashing		IPv6 has been proposed to fulfil the increasing demand of IP addresses. As the data rate and volume of network traffic keep increasing and the Internet evolves, high-speed IPv6 lookup for large routing tables is essential. In this paper, we propose a novel IPv6 lookup approach based on hierarchical perfect hashing. The lookup complexity of the proposed algorithm is O(1) in the worst case. The performance is independent of the prefix distribution or the size of the routing table. Each lookup is performed by examining up to 3 perfect hash tables. Each hash table uses a range of bits of the input IP address as lookup key. We develop a simple scheme to choose appropriate key length for each hash table, which can efficiently reduce the total memory requirement. We implement our design on a state- of-the-art Compute Unified Device Architecture (CUDA) platform. Experimental results show that our GPU-accelerated lookup engine is scalable to sustain a high throughput of over 1.6 billion lookups per second (GLPS) for routing tables from 10K to 1M. This corresponds to 80% of the peak throughput of the target platform. Compared with a state-of-the-art GPU-based IPv6 lookup engine, our design demonstrates 2x improvement with respect to throughput for large tables.	algorithm;best, worst and average case;cuda;data rate units;graphics processing unit;hash table;internet;key size;lookup table;network traffic control;perfect hash function;routing table;scalability;throughput	Shijie Zhou;Viktor K. Prasanna	2014	2015 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2014.7417259	routing table;routing;throughput;parallel computing;lookup table;computer science;theoretical computer science;operating system;key-based routing;distributed computing;pearson hashing;computer network;memory management	Networks	-6.2108469025420305	66.57934424716322	184977
6efbcd2c0f747f98895625cc43ba32dbea5ab3f7	managing temporal allocation in integrated modular avionics	avionics;production management avionics;systeme d exploitation;architectures materielles;aerospace electronics resource management delays computer architecture ports computers robustness jitter;resource management;systemes embarques;production management;computer architecture;reseaux et telecommunications;aerospace electronics;robustness;ports computers;end to end delay constraints temporal allocation management integrated modular avionics ima system integration process timing requirements;jitter;delays	Recent civil airborne platforms are produced using Integrated Modular Avionics (IMA). IMA promotes both sharing of execution and communication resources by the avionics applications. Designs following IMA decrease the weight of avionics equipment and improve the whole system scalability. However, the price to pay for these benefits is an increase of the system's complexity, triggering a challenging system integration process. Central to this integration step are the timing requirements of avionics applications: the system integrator has to find a mapping of applications and communications on the available target architecture (processing modules, networks, etc.) such as end-to-end delay constraints are met. These challenges stress the need for a tool capable of evaluating different integration choices in the early design stages of IMA. In this paper, we present and formalize the problem of spatial and temporal integration of an IMA system. Then, we focus on the temporal allocation problem which is critical to ensure a proper timely behavior of the system. Two main properties are presented to ensure perfect data transmission for hard real-time flows. To quantify the quality of a set of valid temporal allocations, CPM utilization and communication robustness performance criteria are defined. We show on an example that both criteria are antagonist and that they can be leveraged to choose an allocation that either improves the system computing performance or the robustness of the network.	airborne ranger;end-to-end principle;integrated modular avionics;mathematical optimization;multi-objective optimization;optimization problem;real-time clock;real-time computing;requirement;robustness (computer science);scalability;system integration;systems integrator	Nesrine Badache;Katia Jaffrès-Runser;Jean-Luc Scharbarg;Christian Fraboul	2014	Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA)	10.1109/ETFA.2014.7005225	avionics;embedded system;real-time computing;simulation;jitter;telecommunications;computer science;engineering;electrical engineering;resource management;operating system;programming language;robustness;computer network	Embedded	-7.305675308221367	60.57457925545774	185592
24e27327111c2a092dbe91a8dd17c4ec7f9af4e0	a structured overlay for multi-dimensional range queries	range query;multi dimensional;uniform distribution	We introduce SONAR, a structured overlay to store and retrieve objects addressed by multi-dimensional names (keys). The overlay has the shape of a multi-dimensional torus, where each node is responsible for a contiguous part of the data space. A uniform distribution of keys on the data space is not necessary, because denser areas get assigned more nodes. To nevertheless support logarithmic routing, SONAR maintains, per dimension, fingers to other nodes, that span an exponentially increasing number of nodes. Most other overlays maintain such fingers in the key-space instead and therefore require a uniform data distribution. SONAR, in contrast, avoids hashing and is therefore able to perform range queries of arbitrary shape in a logarithmic number of routing steps—independent of the number of systemand query-dimensions. SONAR needs just one hop for updating an entry in its routing table: A longer finger is calculated by querying the node referred to by the next shorter finger for its shorter finger. This doubles the number of spanned nodes and leads to exponentially spaced fingers.	dataspaces;key space (cryptography);locality-sensitive hashing;overlay network;range query (data structures);routing table;sonar;topography;zipf's law	Thorsten Schütt;Florian Schintke;Alexander Reinefeld	2007		10.1007/978-3-540-74466-5_54	range query;telecommunications;theoretical computer science;database;distributed computing;uniform distribution	DB	-10.971058273271877	73.15955083111278	185737
c2f689e8228f66783c79d33c260e5543b768ebfd	a novel approach for implementing high-speed and long-distance networking protocols in a limited memory embedded kernel	streams;evaluation performance;kernel;calculateur embarque;network protocol;performance evaluation;protocole transmission;red larga distancia;evaluacion prestacion;propagacion larga distancia;reseau longue distance;long distance propagation;transport layer;buffer system;embedded system;sistema reactivo;sistema amortiguador;embedded systems;protocolo transmision;long distance;propagation longue distance;grande vitesse;commande ecoulement;boarded computer;reactive system;systeme reactif;gran velocidad;stream flow;systeme tampon;flow control;high speed;calculador embarque;wide area network;transmission protocol	STREAMS kernel mechanisms are being used to implement networking protocols in limited memory embedded systems. The current approaches for STREAMS-based networking protocols implementation suffer from some shortcomings when these approaches are used to implement high-speed and long distance WAN protocols that require large transport windows. Accumulation of duplicate copies of large transport layer windows in the subnet layer cause unnecessary hogging of kernel memory resources. This memory hogging leads to performance degradation since shortage of buffers forces the protocols to operate at smaller window sizes. The reason for this overhead is that the protocols cannot be implemented efficiently due to strict layering scheme of STREAMS. We have devised new kernel mechanisms to provide solution to this problem. We have defined new mapping mechanisms between protocol layers and have coupled these mechanisms with novel “event-based” flow control mechanisms. These mechanisms provided appropriate flow control handling in the kernel that led to significant reduction in memory buffers hogging. This makes embedded systems handle large windows efficiently.	communications protocol;embedded system	Vimal K. Khanna	2000	Journal of Systems Architecture	10.1016/S1383-7621(00)00028-X	embedded system;communications protocol;kernel;real-time computing;telecommunications;reactive system;computer science;bicarbonate buffering system;operating system;flow control;streamflow;streams;transport layer	Arch	-5.357674769486287	73.37327831850435	185889
abd36e2066f263504c6db0a37a07156ccf6cbdc8	an sram-based novel hardware architecture for longest prefix matching for ip route lookup	forwarding table;ip address lookup;longest prefix matching;routing table;sram-based ip lookup	A static random access memory (SRAM)-based novel hardware architecture for longest prefix match (LPM) search scheme has been proposed in this paper. The key concept of this architecture is to store the IP prefixes virtually in the forwarding table. This architecture reduces memory consumption by using a two-tier hierarchical SRAM-based memory structure for maintaining the next hop port information. Originally, next hop addresses are kept in the shared global memory called next hop global memory (NHGM) and its links are maintained in another memory, called next hop link memory (NHLM). This approximately reduces memory consumption by 50–62.5% compared to existing SRAM-based schemes. The proposed architecture consumes single memory write cycle to store an IP prefix and also takes single memory read cycle for LPM search. However, finding next hop information incurs two memory read cycles due to hierarchical next hop memory structure. The proposed scheme performs an LPM lookup operation in 1.05–1.31 ns in IPv4 and between 1.05 and 1.6 ns in IPv6. This results into LPM search throughput of 950 million lookups per second (MLPS) to 760 MLPS in IPv4 and between 620 and 950 MLPS in IPv6. The average search throughput achievable from this architecture is roughly 850 MLPS in IPv4 and 780 MLPS in IPv6. The numerical results show that this architecture significantly reduces memory requirement, power consumption, and transistor-count/bit requirement.	algorithm;classless inter-domain routing;gigabit;load balancing (computing);longest prefix match;lookup table;multitier architecture;numerical analysis;pipeline (computing);pointer (computer programming);random access;shortest path problem;static random-access memory;throughput;transistor count	Sanchita Saha Ray;Surajeet Ghosh;Bhaskar Sardar	2016	Photonic Network Communications	10.1007/s11107-016-0674-8	uniform memory access;distributed shared memory;shared memory;interleaved memory;parallel computing;real-time computing;computer science;distributed computing;conventional memory;extended memory;flat memory model;registered memory;computer network;memory management	Metrics	-5.596651240272143	66.63189312880726	186132
e47769faa687a17a575da1c4b6ff29d0eccd5dfc	real-time worst-case temperature analysis with temperature-dependent parameters	formal worst cast temperature analysis;temperature dependent leakage power;real time analysis;resource availability;real time systems	With the evolution of today’s semiconductor technology, chip temperature increases rapidly mainly due to the growth in power density. Therefore, for modern embedded real-time systems it is crucial to estimate maximal temperatures early in the design in order to avoid burnout and to guarantee that the system can meet its real-time constraints. This paper provides answers to a fundamental question: What is the worst-case peak temperature of a real-time embedded system under all feasible scenarios of task arrivals? A novel thermal-aware analytic framework is proposed that combines a general event/resource model based on network and real-time calculus with system thermal equations. This analysis framework has the capability to handle a broad range of uncertainties in terms of task execution times, task invocation periods, jitter in task arrivals, and resource availability. The considered model takes both dynamic and leakage power as well as thermal dependent conductivity into consideration. Thorough simulation experiments validate the theoretical results.	best, worst and average case;burst transmission;computation;computer cooling;control system;embedded system;emoticon;experiment;maximal set;nonlinear system;real-time clock;real-time computing;real-time transcription;scheduling (computing);semiconductor;server (computing);simulation;spectral leakage;traffic shaping	Hoeseok Yang;Iuliana Bacivarov;Devendra Rai;Jian-Jia Chen;Lothar Thiele	2013	Real-Time Systems	10.1007/s11241-013-9188-y	real-time computing;simulation;computer science;operating system	Embedded	-7.347480500753019	60.655670856196245	186510
4daf7a789515eaa4041d1333dc9b196564c6a8ec	dynamic load balancing in distributed systems in the presence of delays: a regeneration-theory approach	distributed system;dynamic load balancing;uncertainty;queuing theory;load management delay effects distributed computing queueing analysis local area networks ip networks random media uncertainty telecommunication traffic;renewal theory;distributed computing;delay effects;indexing terms;random media;telecommunication traffic;load management;ip networks;load balance;dynamic load balancing renewal theory queuing theory distributed computing;local area networks;queueing analysis	A regeneration-theory approach is undertaken to analytically characterize the average overall completion time in a distributed system. The approach considers the heterogeneity in the processing rates of the nodes as well as the randomness in the delays imposed by the communication medium. The optimal one-shot load balancing policy is developed and subsequently extended to develop an autonomous and distributed load-balancing policy that can dynamically reallocate incoming external loads at each node. This adaptive and dynamic load balancing policy is implemented and evaluated in a two-node distributed system. The performance of the proposed dynamic load-balancing policy is compared to that of static policies as well as existing dynamic load-balancing policies by considering the average completion time per task and the system processing rate in the presence of random arrivals of the external loads.	autonomous robot;distributed computing;load balancing (computing);randomness	Sagar Dhakal;Majeed M. Hayat;Jorge E. Pezoa;Cundong Yang;David A. Bader	2007	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2007.1009	local area network;renewal theory;real-time computing;index term;uncertainty;computer science;load balancing;distributed computing;queueing theory;statistics;computer network	HPC	-14.177852695773742	64.60428377444805	186586
8d235843ab65ad52be25d2e35ca2330c17802a3c	grid resource management using lottery scheduling	resource manager;resource management;grid;large scale;scheduling algorithm;lottery scheduling;gridsim	The GRID infrastructure provides an aggregation of a wide variety of distributed resources for solving large-scale data intensive problems in various fields. The aim of this paper is to propose a method for grid resource management based on lottery scheduling. The lottery scheduling algorithm is implemented as an extension of GridSim simulator that integrates an additional strategy for planning and resource management.	algorithm;data-intensive computing;lottery scheduling;scheduling (computing)	Plamenka Borovska;Adelina Aleksieva-Petrova;Veska Gancheva;Stefan Beshkov	2011		10.1145/2023607.2023651	fair-share scheduling;real-time computing;dynamic priority scheduling;resource allocation;computer science;rate-monotonic scheduling;resource management;operating system;two-level scheduling;database;distributed computing;lottery scheduling;grid;scheduling	HPC	-17.14366004299985	61.559340563725584	186937
14e51e6715ddaa937907231a6fac5a4b0669a2f6	engineering grid applications and middleware for high performance	grid scheduling;resource utilization;grid applications;qos in grids;resource manager;qos guarantee;resource management;matchmaking;system performance;middleware;advance reservation;service oriented architecture;grid computing;high performance;user satisfaction;np complete problem	Meeting QoS objectives of applications while maintaining high system utilization is a challenging task in multi-institutional Grids. In this paper, we effectively engineer Grid applications and resource management middleware for achieving user satisfaction and high resource utilizations. The paper presents a complete framework based on advance reservations (ARs) for resource management in Grids. The framework is capable of providing QoS guarantees to applications while maintaining high resource utilizations. The paper focuses on the scheduling component of the framework and presents a novel heuristic-based algorithm, Grid Scheduling with Deadlines (GSD), for an NP-Complete problem of scheduling ARs with laxities on a shared resource. GSD can be configured with the help of pluggable strategies to adapt to various workload conditions and needs of the system. The paper studies with the aid of an extensive set of experiments the effect of various workload and system parameters on system performance. It is not always possible to accurately predict the runtimes of the jobs. The paper discusses the impact of error in user-estimated runtimes on system performance and investigates strategies to avoid substandard performance resulting from such inaccuracies. Experimental results demonstrate the efficacy of our methodology.	algorithm;experiment;heuristic;middleware;quality of service;runtime system;scheduling (computing)	Umar Farooq;Shikharesh Majumdar;Eric W. Parsons	2007		10.1145/1216993.1217019	in situ resource utilization;real-time computing;np-complete;computer science;resource management;operating system;service-oriented architecture;middleware;database;distributed computing;grid computing	HPC	-18.2660898467569	62.4016861810153	186981
d1f4397a1c9a903d9395ad763ba9f1638578d93e	advanced real-time scheduling using the ieee 802	algorithmic based scheduling;reconfigurable run time environments real time scheduling ieee 802 5 token ring synchronous class messages alert class asynchronous messages time domain multiplexing algorithmic based scheduling a priori schedulability determination arbitrary synchronous message sets;spine;arbitrary synchronous message sets;application software;processor scheduling;ieee 802 5 token ring;reconfigurable run time environments;time domain multiplexing;token networks time division multiplexing real time systems processor scheduling timing delay spine statistics application software ice;scheduling;real time scheduling;a priori schedulability determination;synchronous class messages;statistics;alert class asynchronous messages;guaranteed service;time domain;token networks;token networks real time systems scheduling time division multiplexing;time division multiplexing;synchronous communication;dynamic adaptation;ice;hard real time;real time systems;timing	An approach for scheduling the IEEE 802.5 token ring for hard real-time applications is presented that not only guarantees deadlines for synchronous class messages, but also greatly reduces asynchronous class response times. Highly responsive guaranteed service is introduced for alert class asynchronous messages. Conventional use of the IEEE 802.5 token ring provides synchronous communication services using time-domain multiplexing (TDM) while relegating asynchronous class message services to background status. An algorithmic-based scheduling approach is presented that supports a priori schedulability determination for arbitrary synchronous message sets without the costly time-line development, testing, and tuning associated with TDM techniques. This capability allows the IEEE 802.5 to support dynamic, adaptive and reconfigurable run-time environments where the inflexibility of TDM would be prohibitive. Advanced real-time scheduling applied to the IEEE 802.5 token ring greatly enhances the responsiveness of asynchronous class messages while still maintaining guaranteed service for the synchronous class. >	real-time clock;token ring	Jay K. Strosnider;Thomas E. Marchok;John P. Lehoczky	1988		10.1109/REAL.1988.51099	embedded system;application software;real-time computing;token passing;spine;time domain;computer science;operating system;asynchronous communication;distributed computing;scheduling;time-division multiplexing	Embedded	-9.156654906626782	63.990314822638865	187098
4fe4c14c717c1d5e28be655f026beb5a8d6d2050	network-aware adaptation techniques for mobile file systems	file servers;wireless networks;time sharing computer systems;base stations;network operating systems;bandwidth allocation;wireless network;interference;system performance;mafs;computer networks;file system;mobile radio;graceful degradation;mobile communication;file systems bandwidth file servers delay interference wireless networks mobile communication time sharing computer systems computer networks base stations;mobile file system;network operating systems bandwidth allocation mobile computing mobile radio;bandwidth;read write contention;mobile computing;network aware adaptation techniques;read write contention network aware adaptation techniques mobile file system wireless network mafs;file systems	Wireless networks present unusual challenges for mobile file system clients, since they are characterised by unpredictable connectivity and widely-varying bandwidth. The traditional approach to adapting network communication to these conditions is to write back file updates asynchronously when bandwidth is low. Unfortunately, this can lead to underutilisation of bandwidth and inconsistencies between clients. We describe a new mobile file system, MAFS, that supports graceful degradation of file system performance as bandwidth is reduced, as well as rapid propagation of essential file updates. MAFS is able to achieve 10-20% improvements in execution time for real-life file system traces featuring read-write contention	algorithm;bandwidth (signal processing);cache (computing);elegant degradation;francis;fault tolerance;read-write memory;real life;run time (program lifecycle phase);software propagation;tracing (software)	Benjamin Atkin;Kenneth P. Birman	2006	Fifth IEEE International Symposium on Network Computing and Applications (NCA'06)	10.1109/NCA.2006.42	self-certifying file system;real-time computing;device file;computer science;stub file;operating system;wireless network;journaling file system;distributed computing;open;distributed file system;file system fragmentation;global namespace;mobile computing;computer network	Embedded	-18.565904577555	68.83553543435752	187122
aaa0498c55b4196691e12db12e7372abe405de6a	performance analysis of bio-inspired scheduling algorithms for cloud environments	bio inspired algorithms;job shop scheduling;swarm optimization scheduling bio inspired algorithms;cloud computing scheduling algorithms optimization job shop scheduling genetic algorithms;random biased sampling bioinspired scheduling algorithm cloud computing internet cloud technology cloud service task scheduling virtual machine ant colony optimization aco honey bee optimization hbo networking scheduling algorithm;swarm optimization;scheduling algorithms;virtual machines ant colony optimisation cloud computing random processes sampling methods;scheduling;genetic algorithms;optimization;cloud computing	Cloud computing environments mainly focus on the delivery of resources, platforms, and applications as services to users over the Internet. Cloud promises users access to as many resources as they need, making use of an elastic provisioning of resources. The cloud technology has gained popularity in recent years as the new paradigm in the IT industry. The number of users of Cloud services has been increasing steadily, so the need for efficient task scheduling is crucial for maintaining performance. In this particular case, a scheduler is responsible for assigning tasks to virtual machines efficiently, it is expected to adapt to changes along with defined demand. In this paper, we present a comparative performance study on bio-inspired scheduling algorithms: Ant Colony Optimization (ACO) and Honey Bee Optimization (HBO). A networking scheduling algorithm, Random Biased Sampling, is also evaluated. Those algorithms show the ability of self-managing and adapting to changes in the environment. The experimental results have shown that ACO performs better when computation power is set as the objective, and HBO shows better scheduling when the objective mainly relies on costs.	algorithm;ant colony optimization algorithms;british informatics olympiad;cloud computing;computation;experiment;gibbs sampling;internet;optimizing compiler;profiling (computer programming);programming paradigm;provisioning;requirement;scheduling (computing);self-management (computer science);simulation;virtual machine	Ali Al Buhussain;Robson Eduardo De Grande;Azzedine Boukerche	2016	2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)	10.1109/IPDPSW.2016.186	fair-share scheduling;nurse scheduling problem;job shop scheduling;real-time computing;simulation;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;two-level scheduling;distributed computing;scheduling;lottery scheduling;round-robin scheduling;scheduling	HPC	-18.61312096941531	63.554502401739846	187278
cb893e96a4084de830ce3ddf670098577785e421	providing performance guarantees in multipass network processors	performance guarantee;network processor;buffer management;buffer storage;multiprocessing systems buffer storage microprocessor chips;low latency;scheduling;process control;algorithm design and analysis throughput recycling program processors delay scheduling process control;simulation study;multiprocessing systems;buffer management algorithm performance guarantee multipass network processors heterogeneous processing time low latency traffic run to completion processing;recycling;program processors;algorithm design;algorithm design and analysis;microprocessor chips;throughput	Current network processors (NPs) increasingly deal with packets with heterogeneous processing times. As a consequence, packets that require many processing cycles can significantly delay low-latency traffic, because the common approach in today's NPs is to employ run-to-completion processing. These difficulties have led to the emergence of the Multipass NP architecture, where after a processing cycle ends, all processed packets are recycled into the buffer and re-compete for processing resources. In this work we provide a model that captures many of the characteristics of this architecture, and consider several scheduling and buffer management algorithms that are specially designed to optimize the performance of multipass network processors. In particular, we provide analytical guarantees for the throughput performance of our algorithms. We further conduct a comprehensive simulation study that validates our results.	algorithm;central processing unit;emergence;network processor;run to completion scheduling;scheduling (computing);simulation;throughput	Isaac Keslassy;Kirill Kogan;Gabriel Scalosub;Michael Segal	2011	2011 Proceedings IEEE INFOCOM	10.1109/INFCOM.2011.5935167	embedded system;algorithm design;parallel computing;real-time computing;computer science;operating system;process control;computer network	Arch	-6.310539134997462	63.36154990341169	187402
a688c484e572fc4c87a1527433a53d0e13042c57	uniprocessor feasibility of sporadic tasks remains conp-complete under bounded utilization	complexity theory real time systems boosting electronic mail resumes scheduling algorithms schedules;electronic mail;complexity theory;real time;bounded feasibility problem uniprocessor feasibility conp complete bounded utilization real time scheduling theory sporadic task system constrained deadline preemptive uniprocessor pseudo polynomial time solution polynomial time solution;complexity;resumes;computer science with specialization in real time systems;feasibility;boosting;scheduling algorithms;scheduling;processor scheduling computational complexity;sporadic;schedules;datavetenskap datalogi;computer science;periodic;complexity real time scheduling sporadic periodic feasibility;datavetenskap med inriktning mot realtidssystem;real time systems	A central problem in real-time scheduling theory is to decide whether a sporadic task system with constrained deadlines is feasible on a preemptive uniprocessor. It is known that this problem is strongly coNP-complete in the general case, but also that there exists a pseudo-polynomial time solution for instances with utilization bounded from above by any constant c, where 0 <; c <; 1. For a long time it has been unknown whether the bounded case also has a polynomial-time solution. We show that for any choice of the constant c, such that 0 <; c <; 1, the bounded feasibility problem is (weakly) coNP-complete, and thus that no polynomial-time solution exists for it, unless P = NP.	algorithm;co-np;p versus np problem;polynomial;pseudo-polynomial time;real-time clock;real-time locating system;scheduling (computing);time complexity;uniprocessor system	Pontus Ekberg;Wang Yi	2015	2015 IEEE Real-Time Systems Symposium	10.1109/RTSS.2015.16	feasibility study;parallel computing;real-time computing;computer science;operating system;distributed computing;scheduling	Embedded	-10.146221400992768	61.445583986920376	187484
dc32cc505d248c21496db430fe1246919879e231	an integer programming approach for assigning votes in a distributed system	distributed system;communication networks;network partitions;availability;distributed processing integer programming replicated databases fault tolerant computing;distributed processing;distributed computing;maintenance engineering;data engineering;computer networks;partition failures integer programmimg approach votes assignment distributed system replicated data network partitions node failures monte carlo simulation;fault tolerant computing;linear programming voting computer science maintenance engineering data engineering throughput computer networks distributed computing communication networks availability;integer programming;voting;replicated data;votes assignment;linear programming;integer programmimg approach;computer science;integer program;monte carlo simulation;replicated databases;node failures;partition failures;throughput	Voting is a general approach to maintain consistency of replicated data under node failures and network partitions. In voting, each node is assigned a particular number of votes, and any group with majori ty of votes can perform operations. Votes assigned t o the nodes have a significant impact on the performance of a voting system. I n this report, we propose an integer programming approach f o r determining the vote assignment f o r maximizing the throughput. W e use monte-carlo simulation to find the most likely groups formed due to partition failures and use these groups to formulate vote assignment as a n integer programming problem. W e have developed a tool called vote assignment tool ( V A T ) that implements this approach. VAT takes as input the configuration of the network, and after formulating the problem as integer programming exercise, solves it to output a vote assignment. W e have tried this approach f o r different networks and have found that in many cases this approach assigns votes equivalent t o or better than the best vote assignmen t given b y the various heuristics.	distributed computing;heuristic (computer science);integer programming;monte carlo method;simulation;throughput	D. Venkaiah;Pankaj Jalote	1995		10.1109/RELDIS.1995.526220	maintenance engineering;availability;throughput;real-time computing;integer programming;voting;computer science;linear programming;theoretical computer science;operating system;database;distributed computing;computer security;monte carlo method	DB	-9.996585386866785	66.17956295044888	187523
dd7deea4308fe14577e9cb791be28e3b65ddbb43	advanced reservation-based scheduling of task graphs on clusters	processing element;directed acyclic graph;graph theory;distributed system;grafo aciclico;resource utilization;programa paralelo;cluster graph;teoria grafo;haute performance;systeme reparti;information systems;gestion labor;distributed computing;telecommunication network;graphe acyclique;grafo monton;theorie graphe;acyclic graph;interconnection network;graphe amas;sistema repartido;gestion tâche;red telecomunicacion;scheduling;directed graph;graphe oriente;reseau telecommunication;alto rendimiento;calculo repartido;grafo orientado;advance reservation;task graphs;task scheduling;parallel programs;high performance;parallel program;calcul reparti;ordonnancement;conference proceeding;reglamento;programme parallele	A Task Graph (TG) is a model of a parallel program that consists of many subtasks that can be executed simultaneously on different processing elements. Subtasks exchange data via an interconnection network. The dependencies between subtasks are described by means of a Directed Acyclic Graph. Unfortunately, due to their characteristics, scheduling a TG requires dedicated or uninterruptible resources. Moreover, scheduling a TG by itself results in a low resource utilization because of the dependencies among the subtasks. Therefore, in order to solve the above problems, we propose a scheduling approach for TGs by using advance reservation in a cluster environment. In addition, to improve resource utilization, we also propose a scheduling solution by interweaving one or more TGs within the same reservation block and/or backfilling with independent jobs.	algorithm;directed acyclic graph;graph property;interconnection;job stream;schedule (project management);scheduling (computing)	Anthony Sulistio;Wolfram Schiffmann;Rajkumar Buyya	2006		10.1007/11945918_12	fair-share scheduling;parallel computing;real-time computing;computer science;artificial intelligence;graph theory;operating system;database;distributed computing;directed acyclic graph;algorithm	HPC	-12.929367482681105	62.659563229568505	187580
316c72c3cc45467e4fbc52c46da8cdb2cbc52de0	effective cost mechanism for cloudlet retransmission and prioritized vm scheduling mechanism over broker virtual machine communication framework		In current scenario cloud computing is most widely increasing platform for task execution. Lot of research is going on to cut down the cost and execution time. In this paper, we propose an efficient algorithm to have an effective and fast execution of task assigned by the user. We proposed an effective communication framework between broker and virtual machine for assigning the task and fetching the results in optimum time and cost using Broker Virtual Machine Communication Framework (BVCF). We implement it over cloudsim under VM scheduling policies by modification based on Virtual Machine Cost. Scheduling over Virtual Machine as well as over Cloudlets and Retransmission of Cloudlets are the basic building blocks of the proposed work on which the whole architecture is dependent. Execution of cloudlets is being analyzed over Round Robin and FCFS scheduling policy.	algorithm;cloud computing;cloudsim;cloudlet;retransmission (data networks);round-robin scheduling;run time (program lifecycle phase);scheduling (computing);virtual machine	Gaurav Raj;Sonika Setia	2012	CoRR	10.5121/ijccsa.2012.2305	parallel computing;real-time computing;computer science;operating system;distributed computing	HPC	-17.974187155652512	62.76228090845081	187947
1070f6749a08530961c10046d6a8f5e74d0f5f87	self-chord: a bio-inspired algorithm for structured p2p systems	p2p system;distributed algorithms;distributed system;mobile agent bio inspired algorithm structured peer to peer system information service distributed system computational grid cloud self chord model;swarm intelligence;computational grid;sorting;probability density function;mobile agents;p2p self organization;cloud;simulation framework;p2p;information services;data mining;indexes;distance measurement;self chord model;self organization;bio inspired;bio inspired algorithm;swarm intelligence bio inspired p2p self organization;peer to peer computing distributed algorithms grid computing information services mobile agents;structured peer to peer system;information service;peer to peer computing;mobile agent;grid computing;mobile agents peer to peer computing cloud computing distributed computing grid computing clustering algorithms insects sorting humans scalability	"""This paper presents “Self-Chord”, a bio-inspired P2P algorithm that can be profitably adopted to build the information service of distributed systems, in particular Computational Grids and Clouds. Self-Chord inherits the ability of Chord-like structured systems for the construction and maintenance of an overlay of peers, but features enhanced functionalities deriving from the activity of ant-inspired mobile agents, such as autonomy behavior, self-organization and capacity to adapt to a changing environment. Self-Chord features three main benefits with respect to classical P2P structured systems: (i) it is possible to give a semantic meaning to keys, which enables the execution of """"class"""" queries, often issued in Grids and Clouds; (ii) the keys are fairly distributed over the peers, thus improving the balancing of storage responsibilities; (iii) maintenance load is reduced because, as new peers join the ring, the mobile agents will spontaneously reorganize the keys in logarithmic time."""	algorithm;biological system;british informatics olympiad;computation;distributed computing;mobile agent;organizing (structure);scalability;self-organization;simulation;time complexity;tree (data structure)	Agostino Forestiero;Carlo Mastroianni;Michela Meo	2009	2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid	10.1109/CCGRID.2009.39	database index;probability density function;self-organization;cloud computing;swarm intelligence;computer science;sorting;theoretical computer science;peer-to-peer;mobile agent;database;distributed computing;world wide web;information system;grid computing	HPC	-12.462057554757198	72.26211130695195	188098
2ed2afa05685a5ebbba48924f8aeb348fee9d3f0	self-stabilization by local checking and global reset (extended abstract)	global reset;local checking;extended abstract;spanning tree;virtual circuit;network protocol	We describe a method for transforming asynchronous network protocols into protocols that can sustain any transient fault, i.e., become self-stabilizing. We combine the known notion of local checking with a new notion of internal reset, and prove that given any self-stabilizing internal reset protocol, any locally-checkable protocol can be made self-stabilizing. Our proof is constructive in the sense that we provide explicit code. The method applies to many practical network problems, including spanning tree construction, topology update, and virtual circuit setup.	algorithm;broadcast domain;communications protocol;computation;correctness (computer science);file spanning;list of algorithms;minimum spanning tree;resultant;ring counter;self-stabilization;shortest path problem;spanning tree protocol;spanning tree;timeout (computing);timer;universal quantification;virtual circuit	Baruch Awerbuch;Boaz Patt-Shamir;George Varghese;Shlomi Dolev	1994		10.1007/BFb0020443	parallel computing;real-time computing;computer science;distributed computing	Theory	-6.538153259799102	71.90037581388304	188101
46b1abdc4f802299616906ce2776cc5d37dd7fdc	a scheduling algorithm based on user satisfaction degree in cloud environment		Efficient task scheduling strategy in cloud environment plays a vital role. Because the size of computing tasks and the time of arrival to the cloud are uncertain, and users tend to have certain expectations in the respect of carrying out the tasks, how to allocate computing resources reasonably for task scheduling is an important problem while satisfying the users’ expectations. Combining the idea of greedy algorithm, this paper presents a task scheduling algorithm named UTS. UTS adopts user satisfaction degree model as the evaluation criteria for task scheduling. Comparing with RR, max-min and min-min scheduling policies by simulation using CloudSim, experimental results show that UTS is a more effective task scheduling algorithm.	algorithm;scheduling (computing)	Feng Ye;Yong Chen;Qian Huang	2018		10.1007/978-981-13-2203-7_38	real-time computing;scheduling (computing);cloudsim;cloud computing;time of arrival;computer science;greedy algorithm	EDA	-18.64909260941891	63.00194478476107	188199
7c958fbd74f101e5401140ad1f63a50497cff921	on adaptive resource allocation for complex real-time application	software metrics;dynamic change;embedded system platforms;complex real time applications;timing constraints;data dependent;real time environments;command and control systems resource allocation real time systems software performance evaluation timing software metrics computability;worst case application needs;resource allocation;computability;real time;limited resource availability;software performance evaluation;satisfiability;embedded system;performance metric;dynamic resource allocation;time critical applications;high performance real time applications;data dependence;resource management runtime real time systems availability timing time factors contracts radar tracking embedded system measurement;c31 systems adaptive resource allocation complex real time applications high performance real time applications data dependent limited resource availability embedded system platforms resource needs timing constraints over sizing worst case application needs satisfiability performance metrics time critical applications;over sizing;resource needs;resource availability;technical report;adaptive resource allocation;performance metrics;high performance;command and control systems;real time application;c31 systems;real time systems;timing;time constraint	Resource allocation for high-performance real-time applications is challenging due to the applications’ data-dependent nature, dynamic changes in their external environment, and limited resource availability in their target embedded system platforms. These challenges may be met by use of Adaptive Resource Allocation (ARA) mechanisms that can promptly adjust resource allocation to changes in an application’s resource needs, whenever there is a risk of failing to satisfy its timing constraints. By taking advantage of an application’s adaptation capabilities, ARA eliminates the need for ‘over-sizing’ real-time systems to meet worst-case application needs. This paper proposes a model for describing an application’s adaptation capabilities and the runtime variation of its resource needs. The paper also proposes a satisfiability-driven set of performance metrics for capturing the impact of ARA mechanisms on the performance of adaptable real-time applications. The relevance of the proposed set of metrics is demonstrated experimentally, using a synthetic application designed to represent time-critical applications in C3I systems. College of Computing Georgia Institute of Technology Atlanta, Georgia 30332–0280 Funded in part by DARPA through the Honeywell Technology Center under Contract No. B09332478 and Contract No. B09333218, and by NSF equipment grants CDA-9501637, CDA-9422033 and ECS-9411846. On Adaptive Resource Allocation for Complex Real-Time Applications Daniela Roşu, Karsten Schwan, Sudhakar Yalamanchili Georgia Institute of Technology 801 Atlantic Drive, Atlanta, GA 30332-0208 f daniela,schwan g@cc.gatech.edu sudhakar.yalamanchili@ee.gatech.edu Rakesh Jha Honeywell Technology Center 3660 Technology Drive Minneapolis, MN-55418 jha@src.honeywell.com	application release automation;best, worst and average case;data dependency;embedded system;experiment;failure;ibm notes;rakesh agrawal (computer scientist);real-time clock;real-time computing;real-time transcription;relevance;software release life cycle;synthetic intelligence;window of opportunity	Daniela Rosu;Karsten Schwan;Sudhakar Yalamanchili;Rakesh Jha	1997		10.1109/REAL.1997.641293	real-time computing;simulation;resource allocation;computer science;technical report;operating system;distributed computing;computability;software metric;satisfiability	Embedded	-8.498302685559178	60.9324931807265	188525
79cb7414e7a19cee2db64bfc0cea0dbd0342c770	optimal clip ordering for multi-clip queries	graph theory;distributed system;acoplamiento grafo;graphe biparti;teoria grafo;systeme reparti;multimedia;grafo bipartido;reseau ordinateur;theorie graphe;maximum matching;graph matching;multimedia systems;computer network;algorithme;algorithm;couplage graphe;sistema repartido;optimal scheduling;scheduling;analyse performance;performance analysis;red ordenador;optimality criteria;ordonamiento;systeme gestion base donnee;information system;performance of multimedia systems;bipartite graph;sistema gestion base datos;database management system;systeme information;ordonnancement;bipartite graph matching;admission control;algoritmo;sistema informacion;analisis eficacia	A multi-clip query requests multiple video clips be returned as the answer of the query. In many applications and situations, the order in which these clips are to be delivered does not matter that much to the user. This allows the system ample opportunities to optimize system throughput by using schedules that maximize the effect of piggybacking. In this paper, we study how to find such optimal schedules. In particular, we consider two optimization criteria: (i) one based on maximizing the number of piggybacked clips, and (ii) the other based on maximizing the impact on buffer space. We show that the optimal schedule under the first criterion is equivalent to a maximum matching in a suitably defined bipartite graph, and that under the second criterion, the optimal schedule is equivalent to a maximum matching in a suitably defined weighted bipartite graph. Our experimental results, which are based on realistic distributions, indicate that both kinds of optimal schedules can lead to a gain in throughput of over 300%. And yet the time taken to compute such an optimal schedule is negligible. Finally, we show how to deal with clips that are variable in length.	algorithm;matching (graph theory);mathematical optimization;piggybacking (security);requirement;schedule (computer science);sorting;surround sound;throughput;video clip	Raymond T. Ng;Paul Shum	1998	The VLDB Journal	10.1007/s007780050067	computer science;graph theory;theoretical computer science;distributed computing;algorithm;matching	DB	-13.923315772867149	70.22438464101322	188559
adba459438e5324c28272abd27ae785597ff9035	remote-control caching: proxy-based url rewriting to decrease mobile browsing bandwidth		Mobile browsers suffer from unnecessary cache misses. The same binary object is often named by multiple URLs which correspond to different cache keys. Furthermore, servers frequently mark objects as uncacheable, even though the objects' content is stable over time.  In this paper, we quantify the excess network traffic that mobile devices generate due to inefficient caching logic. We demonstrate that mobile page loads suffer from more redundant transfers than reported by prior studies which focused on desktop page loads. We then propose a new scheme, called Remote-Control Caching (RC2), in which web proxies (owned by mobile carriers or device manufacturers) track the aliasing relationships between the objects that a client has fetched, and the URLs that were used to fetch those objects. Leveraging knowledge of those aliases, a proxy dynamically rewrites the URLs inside of pages, allowing the client's local browser cache to satisfy a larger fraction of requests. Using a concrete implementation of RC2, we show that, for two loads of a page separated by 8 hours, RC2 reduces bandwidth consumption by a median of 52%. As a result, mobile browsers can save a median of 469 KB per warm-cache page load.	aliasing;bandwidth (signal processing);cpu cache;cache (computing);desktop computer;html;hypertext transfer protocol;mobile device;mobile phone;network packet;offset binary;proxy server;remote control;rewrite engine;rewriting;web cache	Ravi Netravali;James Mickens	2018		10.1145/3177102.3177118	rewrite engine;binary object;cache;computer network;mobile device;aliasing;remote control;server;bandwidth (signal processing);computer science	Mobile	-19.023563165568618	73.47348122317172	188565
8eeebf8dc52c21669bca2d48378a5e56f27c3475	openflow-based dynamic server cluster load balancing with measurement support		—In the current cloud computing environment, the size of the server cluster in the data center is growing in response to the increasing traffic. Due to the use of multiple replicas in the server cluster to provide the same services, effective load balancing as a key technology is very important. In this paper we implement and evaluate an alternative loadbalancing architecture using OpenFlow switches connected to a controller, which gains high flexibility without additional equipment, and has the potential to be more robust than traditional load balancing approach. The system could measure network and server status in real-time and dynamic set weights of server according to the server's processing capability. Our load balancer installs wildcard rules in the switches proactively to direct requests of large groups of clients without involving the controller which effectively saves the flow table space and reduces the delay of the network. Our implementation uses the OpenFlow controller Floodlight and network emulator Mininet to verify the validity of this algorithm. The preliminary evaluation results demonstrate that our dynamic load balancing scheme is superior to not only the random load balancing algorithm but also the round robin load balancing algorithm.	algorithm;cloud computing;computer cluster;data center;emulator;load balancing (computing);network switch;openflow;real-time clock;server (computing)	Qingwei Du;Huaidong Zhuang	2015	JCM	10.12720/jcm.10.8.572-578	computer network;openflow;distributed computing;computer cluster;network load balancing services;load balancing (computing);computer science;round-robin dns	OS	-18.150949116151423	68.20299121002573	188623
b40c8aa05528314f894939116bfbe983b32ea197	distributed network resource allocation with integer constraints	approximation algorithms;nickel;resource management;servers;heuristic algorithms;optimization;cloud computing	This paper considers the resource allocation problem defined over a hybrid data center and edge server network, where the allocations are subject to integer constraints, taking the granularity of network resources and service requests into account. We develop two efficient heuristic algorithms to solve this nonconvex program, both based the alternating direction method of multipliers (ADMM) and a distributed integral projection scheme. The first algorithm ignores the integer constraints and solves the relaxed convex program, while the second algorithm includes the integer constraints in the optimization process. We develop a distributed integral projection scheme, which approximately projects the resulting resource allocation strategies onto the feasible set. Numerical experiments validate the effectiveness of the proposed algorithms.	algorithm;augmented lagrangian method;content delivery network;convex optimization;data center;experiment;feasible region;heuristic;integer programming;mathematical optimization;server (computing)	Yujiao Cheng;Houfeng Huang;Gang Wu;Qing Ling	2016	2016 IEEE Global Conference on Signal and Information Processing (GlobalSIP)	10.1109/GlobalSIP.2016.7905909	mathematical optimization;computer science;theoretical computer science;distributed computing	HPC	-18.887177277633363	65.64753925757519	188831
1835b3ad8a5baff86804c553f0f3942835695364	an integrated architecture for the scalable delivery of semi-dynamic web content	denial of service attacks;file servers;multicast communication;unicast mechanisms;web pages;server load;scalable delivery;network load;tcp;multicast channels;browsers;denial of service attack;transport protocols;computer architecture;internet transport protocols multicast communication file servers;h t t p m protocol;http model integrated architecture scalable delivery semi dynamic web content web pages frequently changing hot pages web sites multicast mechanisms unicast mechanisms h t t p m protocol browsers url multicast channels dns mechanisms denial of service attacks simulation results server load network load clients delay tcp;internet;multicast protocols;http model;web sites;ip networks;clients delay;web server;dynamic web content;computer science;dns mechanisms;service oriented architecture;switches;uniform resource locators;simulation results;frequently changing hot pages;service oriented architecture costs unicast multicast protocols computer architecture switches uniform resource locators web server ip networks computer science;integrated architecture;semi dynamic web content;unicast;multicast mechanisms;url	The competitionon clientsattentionrequiressitesto updatetheir contentfrequently. As a result,a largepercentageof web pagesaresemi-dynamic,i.e., changequiteoften andstaystaticbetweenchanges.The costof maintainingconsistenc y for such pagesdiscouragescachingsolutions.We suggestherean integratedarchitecturefor thescalabledelivery of frequentlychanging hot pages. Our schemeenablessitesto dynamicallyselectwhetherto cyclically multicasta hot pageor to unicastit, and to switch betweenmulticastandunicastmechanismsin a transparent way. Our schemedefinesa new protocol,calledhttpm. In addition,it usescurrentlydeployedprotocols,anddynamicallydirectsbrowsersseekingfor a URL to multicastchannels,while usingexisting DNS mechanisms.Thus,we enablesitesto deliver contentto a growing amountof usersat lesscostandduring denialof serviceattacks,while reducingloadon corelinks. We reportsimulationresultsthatdemonstratethe advantagesof the Integratedarchitecture, andits significantimpactonserver andnetworkload,aswell asclientsdelay.	dynamic web page;scalability;semiconductor industry;thomas' cyclically symmetric attractor;web content	Danny Dolev;Osnat Mokryn;Yuval Shavitt;Innocenty Sukhov	2002		10.1109/ISCC.2002.1021679	computer science;distributed computing;world wide web;denial-of-service attack;computer network	Networks	-15.813408740876092	74.1292252198178	189046
20da36cfed071dbe72a7286d4bdb85312da747c0	ggreen: a greedy energy-aware scheduling algorithm on grid systems	energy aware scheduling;conferences scientific computing;scientific computing;greedy algorithm;power aware computing computer centres greedy algorithms green computing grid computing;greedy algorithm grid computing energy aware scheduling;grid computing;grid simulation environment greedy energy aware scheduling algorithm grid systems large scale distributed systems data center electricity energy aware scheduling problem greedy task scheduling algorithm global energy consumption reduction ggreen strategy observational approach heavy task assignment power resource;conferences	Current large scale distributed systems face growth in data center electricity. In this paper, we have discussed energy-aware scheduling problem on grid systems. In this way, we provide GGreen -- a greedy task scheduling algorithm in order to reduce the global energy consumption on grid systems. GGreen strategy has an observational approach that focus on assigning heavy tasks to lowest power resource. Additionally, GGreen algorithm has been implemented and evaluated by using a grid simulation environment over three distinct scenarios. Experimental results show gains as compared to other alternatives with the main benefit of reducing the energy consumption.	data center;distributed computing;greedy algorithm;grid systems corporation;scheduling (computing);simulation	Fábio Gonçalves Coutinho;Evandro Verdino;Jesus Ossian;Renato Santana	2014	2014 IEEE 17th International Conference on Computational Science and Engineering	10.1109/CSE.2014.81	fair-share scheduling;greedy algorithm;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;theoretical computer science;distributed computing;grid computing	Robotics	-18.386338089153956	61.827396049861825	189241
486fffa44fa8bc95194cbe44f545fffd322b0ef9	a cache architecture for counting bloom filters: theory and application	packet classification;bloom filter;network processor;tuple space;mathematical analysis;hardware architecture;memory access;memory architecture;hash function;memory hierarchy	Within packet processing systems, lengthy memory accesses greatly reduce performance. To overcome this limitation, network processors utilize many different techniques, for example, utilizing multilevel memory hierarchies, special hardware architectures, and hardware threading. In this paper, we introduce a multilevel memory architecture for counting Bloom filters. Based on the probabilities of incrementing of the counters in the counting Bloom filter, a multi-level cache architecture called the cached counting Bloom filter (CCBF) is presented, where each cache level stores the items with the same counters. To test the CCBF architecture, we implement a software packet classifier that utilizes basic tuple space search using a 3-level CCBF. The results of mathematical analysis and implementation of the CCBF for packet classification show that the proposed cache architecture decreases the number of memory accesses when compared to a standard Bloom filter. Based on the mathematical analysis of CCBF, the number of accesses is decreased by at least 53%. The implementation results of the software packet classifier are at most 7.8% (3.5% in average) less than corresponding mathematical analysis results. This difference is due to some parameters in the packet classification application such as number of tuples, distribution of rules through the tuples, and utilized hashing functions.	bloom filter;cpu cache;central processing unit;memory hierarchy;network packet;network processor;thread (computing);tuple space	Mahmood Ahmadi;Stephan Wong	2011	J. Electrical and Computer Engineering	10.1155/2011/475865	parallel computing;real-time computing;hash function;computer science;tuple space;theoretical computer science;bloom filter;hardware architecture;network processor;computer network	Arch	-6.132342961098345	66.68684861620885	189445
02aeb20538ec9cd4c616652a5dcdcd67e94a2b70	step: self-tuning energy-safe predictors	energy conservation;adaptive caching;power saving;prefetching;simulation;mobile computer;power management;data access;mobile systems;mobile computing;prediction	Data access prediction has been proposed as a mechanism to overcome latency lag, and more recently as a means of conserving energy in mobile systems. We present a fully adaptive predictor, that can optimize itself for any arbitrary workload, while simultaneously offering simple adjustment of goals between energy conservation and latency reduction. Our algorithm. STEP, achieves power savings on mobile computers by eliminating more data fetches, which would otherwise have caused excess energy to be consumed in accessing local storage devices or using the wireless interface to fetch remote data. We have demonstrated our algorithm to perform as well as some of the best access predictors, while incurring almost none of the associated increase in I/O workloads typical of their use. Our algorithm reduced average response times by approximately 50% compared to an LRU cache, while requiring less than half the I/O operations that traditional predictors would require to achieve the same performance, thereby incurring no energy penalty.	algorithm;computer;data access;input/output;kerrison predictor;mobile computing;offset binary;self-tuning;thread-local storage	James Larkby-Lahet;Ganesh Santhanakrishnan;Ahmed M Amer;Panos K. Chrysanthis	2005		10.1145/1071246.1071264	data access;real-time computing;simulation;energy conservation;prediction;computer science;operating system;distributed computing;mobile computing;computer network	Arch	-14.860747631173973	67.97930803567145	189497
6d45009a02f520298599ab742c9278dbd4a0238b	designing file replication schemes for peer-to-peer file sharing systems	p2p system;file replication scheme;peer to peer computing usa councils statistics communications society scalability optimization methods measurement cost function computational modeling statistical distributions;p2p;performance metric;statistical analysis;statistical analysis peer to peer computing;file sharing;peer to peer computing;p2p system file replication scheme peer to peer file sharing system;peer to peer;peer to peer file sharing system	Peer-to-peer (P2P) file sharing systems are becoming increasingly popular due to their flexibility and scalability. We propose a new model to design file replication schemes for P2P file sharing systems. The model introduces expected costs for serving user requests for the files which are computed from node up/down statistics. Based on the model we introduce and develop several methods to determine the sets of nodes to store copies of the files in order to optimize certain performance metrics (e.g., maximize the system hit rate, minimize the total expected cost). We verify the effectiveness of the file replication schemes via simulation. We also outline a framework to implement the file replication schemes for P2P file sharing systems in a distributed and adaptive manner. The framework scales to a large number of nodes and files and can handle user request pattern change via file migration.	aggregate data;distributed hash table;jargon file;makefile;peer-to-peer file sharing;scalability;server (computing);simulation	Jian Ni;Jie Lin;S. J. Harrington;Naveen Sharma	2008	2008 IEEE International Conference on Communications	10.1109/ICC.2008.1051	self-certifying file system;torrent file;computer science;ssh file transfer protocol;journaling file system;peer-to-peer;database;distributed computing;bittorrent tracker;open;distributed file system;file system fragmentation;global namespace;world wide web;file sharing;replication;computer network	DB	-13.320899997297191	72.85962438813618	189561
ad59d7adcdd230ddbc9918a391884cdeeb846fbb	dynamic level task scheduling algorithm based on risk estimation model in grid computing	dag;processor scheduling;risk estimation model;dynamic level task scheduling algorithm;dynamic level scheduling dls grid computing risk model dag;adverse effect;computational modeling;risk dls algorithm;estimation;risk estimation;task analysis grid computing scheduling;scheduling;heuristic algorithms;task analysis;dynamic level scheduling dls;mathematical model;heterogeneous distributed grid system;risk dls algorithm dynamic level task scheduling algorithm risk estimation model grid computing heterogeneous distributed grid system;task scheduling;risk model;grid computing;estimation heuristic algorithms dynamic scheduling mathematical model computational modeling processor scheduling equations;grid system;dynamic scheduling	In a heterogeneous distributed Grid system, machines and network failures are inevitable and can have an adverse effect on applications execution on the system, therefore the objective of task scheduling is not only to minimize the makespan of applications, but also to reduce risks for application execution failures. A new algorithm named by Risk-DLS algorithm will be proposed, which will combine a risk estimation model of resources with the DLS algorithm through an improved equation of dynamic level. The simulation shows that when choosing reasonable parameters, Risk-DLS algorithm is better than DLS algorithm in makespan, at the same time, it can also reduce the adverse effect due to uncertain environment of grid computing.	algorithm;grid computing;schedule (project management);scheduling (computing)	Kan Yi;Ruchuan Wang;Xun-Yi Ren;Yi-mu Ji	2008		10.1109/ChinaGrid.2008.8	parallel computing;real-time computing;computer science;distributed computing	HPC	-17.25342912648042	61.79528468442356	190059
5d0a9f886c4a4af96cffe6a7fa406a59681ddda6	fast packet classification using field-level trie	packet classification;packet filtering;resource allocation;packet switching;tree data structures;data structures quality of service chaos web and internet services information filtering information filters hardware routing telecommunication traffic load management;telecommunication traffic;internet;telecommunication network routing;load balance;field level trie classification packet classification next generation internet routers packet filtering policy routing traffic policing load balancing;tree data structures internet packet switching telecommunication network routing resource allocation telecommunication traffic;next generation internet	Packet classification plays an important role in nextgeneration Internet routers in providing various services such as packet filtering, policy routing, traffic policing, and load balancing. In this paper, we propose an original field-level trie classification (FLTC) scheme that accommodates classifier (rule database) with multiple fields specified in different forms (prefix and range). The FLTC achieves a high classification speed with reasonable storage. It is also highly scalable regarding the size and the number of fields of classifiers.	algorithm;emoticon;firewall (computing);load balancing (computing);network packet;routing;scalability;statistical classification;telecommunications access method;time complexity;trie;on-line system	Guansong Zhang;H. Jonathan Chao;Jinoo Joung	2003		10.1109/GLOCOM.2003.1258827	link state packet;routing;source routing;real-time computing;the internet;packet analyzer;fast packet switching;resource allocation;computer science;processing delay;load balancing;distributed computing;tree;packet switch;packet switching;internet traffic engineering;computer network	Networks	-6.860922638546495	67.41853442045222	190341
f4f415bbcc2b6eac25a71a9a08a4c3807131771e	implementation of round robin policy in dns for thresholding of distributed web server system	oscillations;adaptive thresholding;round robin dns;web server system;puzzled random early detection;round robin;load balance;quality of service;domain name server;system simulation;random early detection	Modern Web-server systems use multiple servers to handle an increased user demand. Such systems need effective methods to spread the load among web servers evenly in order to keep web server utilization high while providing sufficient quality of service for end users. In conventional Domain Name Server DNS-based load balancing architecture, a DNS dispatches requests to web servers based on their load status. Because web servers need to inform the DNS server about their load status from time to time, a so-called load buffer ranges is often employed to reduce the update frequency. Without care, however, using a load buffer range may result in load oscillation among web servers. To address this problem, we propose a Puzzled Random Early Detection (PRED) method with the intuition that the probability for a web server to become overloaded in near future is directly proportional to its current load. And also propose a web server system arranged in the multiple logical ring connection, in which Round Robin DNS is integrated with adaptive thresholding in web server system. Simulation confirms that our method helps reducing the oscillation of the web server load significantly.	load balancing (computing);quality of service;random early detection;round-robin dns;server (computing);simulation;thresholding (image processing);web server	G. M. Borkar;M. A. Pund;Prashant Jawade	2011		10.1145/1980022.1980067	dns zone transfer;round-robin dns;real-time computing;computer science;distributed computing;name server;world wide web;nsupdate;web server;client–server model;server;server farm	Metrics	-18.739504310906597	69.30156401619615	190362
c63e7b450acb22cbba93dfc59c3639d00a264980	a cloud-based content gathering network		Many popular Web services use CDNs to host their content closer to users and thus improve page load times. While this model’s success is beyond question, it has its limits: for users with poor last-mile latency even to a nearby CDN node, the many RTTs needed to fetch a Web page add up to large delays. Thus, in this work, we explore a complementary model of speeding up Web page delivery – a content gathering network (CGN), whereby users establish their own geo-distributed presence, and use these points of presence to proxy content for them. We show that deploying only 14 public cloud-based CGN nodes puts the closest node within a median RTT of merely 4.8 ms (7.2 ms) from servers hosting the top 10k (100k) most popular Web sites. The CGN node nearest to a server can thus obtain content from it rapidly, and then transmit it to the client over fewer (limited by available bandwidth) high-latency interactions using aggressive transport protocols. This simple approach reduces the median page load time across 100 popular Web sites by as much as 53%, and can be deployed immediately without depending on any changes to Web servers at an estimated cost of under $1 per month per user.	cloud computing;content delivery network;interaction;internet;last mile;load (computing);loader (computing);server (computing);web page;web server;web service;world wide web	Debopam Bhattacherjee;Muhammad Tirmazi;Ankit Singla	2017			computer network;cloud computing;computer science	Networks	-18.382811122518387	74.16069110105767	190865
cc52fa97365ca2071a69878ef3ead5ae237dea32	stability of adaptive distributed real-timesystems with dynamic resource management		Today’s embedded distributed real-time systems, are exposed to large variations in resource usage due to complex software applications, sophisticated hardware platforms, and the impact of their run-time environment. As efficiency becomes more important, the applications running on these systems are extended with on-line resource managers whose job is to adapt the system in the face of such variations. Distributed systems are often heterogeneous, meaning that the hardware platform consists of computing nodes with different performance, operating systems, and scheduling policies, linked through one or more networks using different protocols. In this thesis we explore whether resource managers used in such distributed embedded systems are stable, meaning that the system’s resource usage is controlled under all possible run-time scenarios. Stability implies a bounded worst-case behavior of the system and can be linked with classic real-time systems’ properties such as bounded response times for the software applications. In the case of distributed systems, the stability problem is particularly hard because software applications distributed over the different resources generate complex, cyclic dependencies between the resources, that need to be taken into account. In this thesis we develop a detailed mathematical model of an adaptive, distributed real-time system and we derive conditions that, if satisfied, guarantee its stability.	best, worst and average case;distributed computing;embedded system;mathematical model;online and offline;operating system;real-time clock;real-time computing;runtime system;scheduling (computing)	Sergiu Rafiliu	2013			distributed algorithm;real-time computing;simulation;computer science;distributed computing	Embedded	-8.938546430235174	61.437437184759105	191044
5244ea36deae427114cac7393f543ca5a79385ef	power-saving in storage systems for internet hosting services with data access prediction	sorting;disc storage;storage management;photography;arrays;indexes;power aware computing;servers;time factors;internet;storage management disc storage internet photography power aware computing;storage systems average response time flickr public photos access patterns data popularity pdc standby mode storage array disks video photo sharing services internet hosting services power saving method data access prediction;correlation;servers arrays sorting correlation time factors power demand indexes;power demand	We present a power-saving method for storage systems in Internet hosting services, particularly those providing video/photo sharing services. The key idea behind our method is to skew the workload towards a subset of disks in the storage array, thereby extending the periods in standby mode of the other disks. Our method is based on the idea behind PDC, but the main objective of this study is to investigate a method that is adaptable to both constant massive influx of data and changes in data popularity over time. Moreover, to reduce accesses to disks in standby mode, our method periodically rearranges data in the order of potential future accesses presumed to be associated with elapsed time after upload and the accesses in the past, instead of just sorting according to the latest number of accesses. This correlation is obtained by analyzing access patterns for 45,000 randomly selected public photos on Flickr. Performance is evaluated through both simulation and a prototype implementation. In the experiments, we observed that our method saved 24.0% of running time of the disks in active mode, with an overall average response time of 47.6 ms, in which 0.43% of the total accesses involved disks in standby mode.	clustered file system;computer data storage;data access;data center;disk array;distributed hash table;experiment;flickr;peripheral dma controller;prototype;randomness;response time (technology);scalability;simulation;sleep mode;sorting;time complexity;tracing (software);upload	Jumpei Okoshi;Koji Hasebe;Kazuhiko Kato	2013	2013 International Green Computing Conference Proceedings	10.1109/IGCC.2013.6604522	real-time computing;computer science;database;world wide web	DB	-16.431061939923556	67.13407993014881	191199
6803629c3df0561659bc86ba4c6d5edaaccd4118	a prediction-based dynamic replication strategy for data-intensive applications		Data-intensive applications produce huge amount of data sets which need to be analyzed among geographically distributed nodes in grid computing environment. Data replication is essential in this environment to reduce the data access latency and to improve the data availability across several grid sites. In this work, an Intelligent Replica Manager (IRM) is designed and incorporated in the middleware of the grid for scheduling data-intensive applications. IRM uses a Multi-criteria based replication algorithm which considers multiple parameters like storage capacity, bandwidth and communication cost of the neighboring sites before taking decisions for the selection and placement of replica. Additionally, future needs of the grid site are predicted in advance using modified apriori algorithm, which is an association rule based mining technique. This IRM based strategy reduces the data availability time, data access time and make span. The simulation results prove that the proposed strategy outperforms the existing strategies. © 2016 Elsevier Ltd. All rights reserved.	access time;apriori algorithm;association rule learning;cloud computing;data access;data-intensive computing;grid computing;information rights management;job stream;list of toolkits;middleware;replication (computing);scheduling (computing);simulation	Vijaya Nagarajan;Mulk Abdul Maluk Mohamed	2017	Computers & Electrical Engineering	10.1016/j.compeleceng.2016.11.036	computer science;operating system;data grid;data mining;database;world wide web;computer network	HPC	-18.594237572906465	61.07188306398387	191461
21299a3159c8e6a4dce663214bedbb55ae130337	transient model for jackson networks and its approximation	parallel and distributed system;file attente;distributed system;evaluation performance;phenomene transitoire;systeme reparti;performance evaluation;reponse transitoire;evaluacion prestacion;population size;taille population;queue;systeme ouvert;jackson network;transient response;respuesta transitoria;sistema repartido;fenomeno transitorio;regime permanent;regimen permanente;transients;open systems;sistema abierto;tamano poblacion;fila espera;steady state;transient behavior	Jackson networks have been very successful in so many areas in modeling parallel and distributed systems. However, the ability of Jackson networks to predict performance with system changes remains an open question, since Jackson networks do not apply to systems where there are population size constraints. Also, the product-form solution of Jackson networks assumes steady state systems exponential service centers with FCFS queueing discipline. In this paper, we present a transient model for Jackson networks. The model is applicable under any population size. This model can be used to study the transient behavior of Jackson networks and if the number of customers in the network is large enough, the model accurately approaches the product-form solution (steady state solution). Finally, an approximation to the transient model using the steady state solution is presented.	active queue management;apollonian network;approximation;central processing unit;computer engineering;computer science;distributed computing;jackson;network scheduler;population;semantic network;steady state;time complexity	Ahmed M. Mohamed;Lester Lipsky;Reda A. Ammar	2003		10.1007/978-3-540-27860-3_19	jackson network;population size;gordon–newell theorem;telecommunications;computer science;distributed computing;open system;programming language;steady state;transient response;queue	Metrics	-12.528706123162525	64.5025814024157	191708
59351617369454b97a6a82e6802dbd7ea4d9658f	out of order rendering on visualization clusters	tiled displays;workload balancing;distributed rendering;chromium;out of order;frame synchronization	A technique for workload balancing on distributed visualization clusters is suggested. The round-robin scheduling of partial object geometry “chunks” avoids render node starvation and balances the data backlog in the send buffers of the geometry nodes. Because frame synchronization requires that all send buffers drain, balancing these send buffer backlogs is seen to substantially improve frame rate performance for dynamic displays.	round-robin scheduling;scheduling (computing)	Karl Rasche;Robert Geist;James Westall	2003			real-time computing;computer hardware;workload;rendering (computer graphics);visualization;out-of-order execution;frame rate;scheduling (computing);frame synchronization;tiled rendering;computer science	HPC	-15.587319884722508	71.38278068650591	191763
afd2476ecadfb8ec1e38782665716fd28eb10cc8	a scheme for slot allocation of the flexray static segment based on response time analysis	static segment;network scheduling;flexray;automotive network	"""In the last decade, the FlexRay communication protocol has been promoted as a standard for dependable in-vehicular communications. In the FlexRay protocol, the communication timeline is organized as a sequence of four segments, whereas the Static Segment assigns a set of static slots for the transmission of synchronous messages. In this paper, we address the following problems: """"How to efficiently transmit periodic messages in the Static Segment without requiring their periods to be multiples of, or to be synchronized with the FlexRay Communication Cycle?"""" """"Is it possible to guarantee that periodic messages are transferred before their deadlines, without imposing such strict synchronization?"""" Unlike traditional approaches that use linear-programming based techniques, we evaluate the minimum number of allocated slots using traditional Response Time Analysis (RTA). The use of RTA techniques allows us to consider the timing requirements associated to each of the asynchronous message streams. Unlike other approaches, the RTA-based technique proposed in this paper: (a) is able to deal with message stream sets where periods are not multiple of the FlexRay cycle duration and (b) does not require the strict synchronization between tasks/signals at the application layer and slots at the FlexRay communication controller. The proposed slot allocation scheme may be of high practical interest when considering the interconnection of FlexRay/CAN in-vehicular communication systems, allowing the remapping of existing CAN message streams to FlexRay."""	flexray;response time (technology)	Rodrigo Lange;Francisco Vasques;Rômulo Silva de Oliveira;Paulo Portugal	2015	Computer Communications	10.1016/j.comcom.2015.02.016	embedded system;real-time computing;computer network	Metrics	-8.036318565516035	61.43181690159963	192188
ed2eb941aab1298c7e245e22c456350e2e49fd9f	mining correlated policy rules with concept lattice	mobility management mobile radio;policy storage models;conflict detection;conflict detection concept lattice correlated policy rules;lattices resource management computer science performance analysis analytical models admission control educational institutions computational modeling information analysis application software;lattices;dynamic policy correlated policy rules mining concept lattice conflict detection routine policy repository policy storage models;resource management;data mining;mobility management mobile radio data mining mobile computing;computational modeling;conflict detection routine;policy rules;concept lattice;heuristic algorithms;policy repository;mobile communication;performance analysis;dynamic policy;quality of service;mobile computing;algorithm design and analysis;correlated policy rules mining;correlated policy rules	Concept lattice was creatively used in mining correlated policy rules in this study. It takes much time for a conflict detection routine to search every policy in policy repository with conventional policy storage models to see if conflict occurs before a new dynamic policy is added to the policy repository. A novel storage model for dynamic policies was proposed to address this problem. Dynamic policies were organized into a concept lattice to be grouped effectively and stably. Then a correlated policy rules algorithm based on the concept lattice was proposed after the concept of correlated policy rules was defined. The algorithm greatly reduces the number of policies necessary for conflict detection, and increases efficiency of conflict detection. Performance analysis and simulation show that the proposed algorithm is effective.	algorithm;file synchronization;formal concept analysis;simulation;storage model	Suyun Jiao;Yanheng Liu;Xuejie Liu;Da Wei;Hai-yan Hu	2008	2008 International Symposium on Computer Science and Computational Technology	10.1109/ISCSCT.2008.271	computer science;knowledge management;data mining;management science	Arch	-17.137457862976966	68.63637951474568	192206
d037374a282a52aff641529c8041ebb5d502e713	an open-source flexible scheduling simulator for real-time applications	scheduling public domain software real time systems;automotvie real time scheduling scheduling simulator;engine control;engine control application;open source flexible scheduling simulator;application modeling;public domain software;computational modeling;scheduling algorithms;engines;instruction set simulator;complex task control flows;scheduling;multicore processing;automotvie;real time scheduling;control flow;dependency relations;real time applications;scheduling simulator;scheduling algorithms real time systems scheduling computational modeling engines multicore processing;computing system;task scheduling;worst case response time;real time application;instruction set simulator open source flexible scheduling simulator real time applications task scheduling computing system application modeling complex task control flows dependency relations engine control application;open source;real time systems	There are several scheduling simulators to verify the behavior of real-time applications under different task scheduling algorithms. Current simulators cannot model the application accurately, and consequently the result of the simulation differs considerably from the actual behavior on a real computing system. This paper presents a scheduling simulator with application modeling capabilities for real-time applications. The proposed approach supports modeling of complex task control flows and dependency relations between tasks. In order to evaluate the modeling capabilities, we modeled a real engine control application and simulated it. We measured the response times of the application model running on our scheduling simulator and compared them with the ones obtained by running the real engine application binaries on an instruction set simulator. The average percentage errors in mean and worst-case response time between both simulations were only 9.6% and 8.6% respectively.	algorithm;best, worst and average case;instruction set simulator;open-source software;real-time clock;real-time locating system;real-time transcription;response time (technology);scheduling (computing);simulation;symmetric multiprocessing	Yutaka Matsubara;Yasumasa Sano;Shinya Honda;Hiroaki Takada	2012	2012 IEEE 15th International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing	10.1109/ISORC.2012.11	fair-share scheduling;embedded system;parallel computing;real-time computing;computer architecture simulator;computer science;operating system;scheduling	Embedded	-9.025935132822147	60.499042119338085	192222
17d3a05287c161b9af591da13e4605629a7fc687	a fast algorithm for single processor scheduling	silicon;processor scheduling;scheduling algorithm processor scheduling computer science job design algorithm design and analysis polynomials;polynomials;scheduling algorithm;scheduling;fast algorithm;schedules;algorithms;job design;computer science;job listing service;algorithm design and analysis	Suppose we are given a single processor and a set S of n jobs. For each job X there is a release time rx and a deadline dx , with rx and dx nonnegative real numbers. A schedule is feasible if there is no time at which more than one job is being run and if every job in the schedule is begun no earlier than its release time and is completed by its deadline. The problem is to find a feasible schedule in which each job is run for the same amount of time p. The processing is nonpreemptive in that once a job is started it continues executing until it has run for precisely p units of time.	algorithm;job stream;rx microcontroller family;scheduling (computing);windows nt processor scheduling	Barbara B. Simons	1978	19th Annual Symposium on Foundations of Computer Science (sfcs 1978)	10.1109/SFCS.1978.4	fair-share scheduling;generalized processor sharing;fixed-priority pre-emptive scheduling;job shop scheduling;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing;scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling;multiprocessor scheduling;algorithm;i/o scheduling	Theory	-10.931631555847483	61.40287405045571	192385
60f51d96b8353c6ce0e28650aef383660dc6328e	profile based caching to enhance data availability in push/pull mobile environments	cache storage;mobility management mobile radio;xml profile based caching data availability mobile environment prefetching ubiquitous environment context awareness;mobility management mobile radio mobile computing cache storage xml;prefetching bandwidth personnel xml mobile computing fires accidents delay intelligent networks computer science;profiles techniques;mobile environment;xml;crisis management;mobile computing	Caching techniques have been successfully employed to overcome some of the problems posed by disconnection and/or limited bandwidth in mobile environments. Demand driven and prefetching techniques to maintain optimal caches have been found to have limited success in such environments. We develop profile based methods to maintain and enhance data availability at mobile client's caches. Profiling techniques determine data items to be prefetched and cached depending on a user group and context. We have developed a prototype system that demonstrates the applicability of the proposed scheme in a crisis management situation. Results of implementation of the above technique in experimental mobile environments show that profile based caching can significantly enhance data availability in mobile and ubiquitous environments.	cpu cache;cache (computing);profiling (computer programming);prototype	Ravindra Kambalakatta;Mohan Kumar;Sajal K. Das	2004	The First Annual International Conference on Mobile and Ubiquitous Systems: Networking and Services, 2004. MOBIQUITOUS 2004.	10.1109/MOBIQ.2004.1331712	embedded system;mobile search;xml;mobile web;computer science;operating system;mobile technology;database;mobile computing;world wide web;computer network	SE	-15.538944740555062	68.65039576972403	192431
5429852ff373aa57545c3900f98c46c3aadf52da	am-trie: an oc-192 parallel multidimensional packet classification algorithm	intel ixp2800 network processor am trie oc 192 parallel multidimensional packet classification algorithm internet services power slurping hardware asymmetrical multi bit trie parallel algorithm heuristic field division algorithm;multi threading;pediatrics;parallel algorithm;complexity theory;performance test;packet classification;web and internet services;prototypes;network processor;am trie;packet switching;transport protocols;heuristic field division algorithm;internet;heuristic algorithms;asymmetrical multi bit trie;classification algorithms;oc 192 parallel multidimensional packet classification algorithm;multidimensional systems classification algorithms costs web and internet services hardware field programmable gate arrays parallel algorithms scalability heuristic algorithms prototypes;intel ixp2800 network processor;internet services;scalability;multiprocessing systems;field programmable gate arrays;transport protocols internet multi threading multiprocessing systems packet switching parallel algorithms;high speed;power slurping hardware;algorithm design and analysis;multidimensional systems;hardware;parallel algorithms	"""Nowadays, many high-speed Internet services and applications require high-speed multidimensional packet classification, but current high-speed classification often use expensive and power-slurping hardware (such as TCAM and FPGA). In this paper, we presented a novel algorithm, called AM-Trie (asymmetrical multi-bit Trie). Our algorithm creatively use redundant expression to reduce the height of Trie; use compression to reduce the storage cost and eliminate the trace back to enhance the search speed further. Moreover, AM-Trie is a parallel algorithm and very fit for the """"multi-thread and multi-core"""" features of network processor; it has good scalability, the increase of policy number influences little to its performance. A heuristic field division algorithm is also presented, we proved in theoretical that there exists a minimum storage cost dividing solution when the height of the AM-Tire is given. Finally, a prototype is implemented based on Intel IXP2800 network processor. The performance testing result proves that AM-Trie is high-speed and scalable, the throughput of the TCP/IP 6-tuple classification achieves OC-192 (10 Gbps, 64 bytes per packet, i.e.20 Mpps) wire-speed in all situations"""	byte;data rate units;division algorithm;field-programmable gate array;heuristic;ip (complexity);internet protocol suite;multi-core processor;network packet;network processor;optical carrier transmission rates;parallel algorithm;prototype;random-access memory;scalability;software performance testing;telecommunications access method;throughput;time complexity;trie	Bo Zheng;Chuang Lin;Xuehai Peng	2006	First International Multi-Symposiums on Computer and Computational Sciences (IMSCCS'06)	10.1109/IMSCCS.2006.28	parallel computing;computer science;theoretical computer science;distributed computing	HPC	-6.464416703848818	67.13342081333403	192494
0666b13c5ab9368fabc4f1e5da36d7c1cc7dc699	online packet scheduling for cioq and buffered crossbar switches	online algorithms;competitive analysis;scheduling;buffer management;cioq switches;buffered crossbar switches	We consider the problem of online packet scheduling in Combined Input and Output Queued (CIOQ) and buffered crossbar switches. In the widely used CIOQ switches, packet buffers (queues) are placed at both input and output ports. An $$N \times N$$ N×N CIOQ switch has N input ports and N output ports, where each input port is equipped with N queues, each of which corresponds to an output port, and each output port is equipped with only one queue. In each time slot, arbitrarily many packets may arrive at each input port, and only one packet can be transmitted from each output port. Packets are transferred from the queues of input ports to the queues of output ports through the internal fabric. Buffered crossbar switches follow a similar design, but are equipped with additional buffers in their internal fabric. In either model, our goal is to maximize the number or, in case the packets have weights, the total weight of transmitted packets. Our main objective is to devise online algorithms that are both competitive and efficient. We improve the previously known results for both switch models, both for unweighted and weighted packets. For unweighted packets, Kesselman and Rosén (J. Algorithms 60(1):60–83, 2006) give an online algorithm that is 3-competitive for CIOQ switches. We give a faster, more practical algorithm achieving the same competitive ratio. In the buffered crossbar model, we also show 3-competitiveness, improving the previously known ratio of 4. For weighted packets, we give 5.83- and 14.83-competitive algorithms with an elegant analysis for CIOQ and buffered crossbar switches, respectively. This improves upon the previously known ratios of 6 and 16.24.	competitive analysis (online algorithm);crossbar switch;input/output;network packet;online algorithm;protocol buffers;scheduling (computing)	Kamal Al-Bawani;Matthias Englert;Matthias Westermann	2018	Algorithmica	10.1007/s00453-018-0421-x	competitive analysis;online algorithm;mathematical optimization;real-time computing;head-of-line blocking;computer science;operating system;distributed computing;scheduling;computer network	Theory	-4.732884102644655	71.88540924103032	192556
689b730d0cf0d0ec20402557f04b577c4c3e890b	scheduling real-time hil co-simulation of cyber-physical systems on multi-core architectures		When designing complex cyber-physical systems, engineers have to integrate numerical models from different modeling environments in order to simulate the whole system and estimate its global performances. Co-simulation refers to such joint simulation of heterogeneous models. If some parts of the system are physically available, it is possible to connect these parts to the co-simulation in a Hardware-in-the-Loop (HiL) approach. In this case, the simulation has to be performed in real-time where models execution consists in periodically reacting to the real (physically available) components and providing periodic output updates. This paper deals with the parallelization and scheduling of real-time Hardware-in-the-Loop co-simulation of numerical models on multi-core architectures. A method for defining real-time constraints that have to be met is proposed. Also, an ILP formulation as well as a heuristic are proposed to solve the problem of scheduling the co-simulation on a multicore architecture while satisfying the previously defined real-time constraints. The proposed approach is evaluated for different sizes of co-simulations and multi-core processors.		Salah Eddine Saidi;Nicolas Pernet;Yves Sorel	2018	2018 IEEE 24th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)	10.1109/RTCSA.2018.00031	real-time computing;periodic graph (geometry);scheduling (computing);architecture;cyber-physical system;co-simulation;heuristic;multi-core processor;distributed computing;computer science	Embedded	-8.073754755610285	60.80564492151754	192610
5a3585987ee0366bd528b7f69fd74d96812348ad	the method of constructing models of peer to peer protocols	protocols;mathematical model stochastic processes equations protocols peer to peer computing differential equations vectors;vectors;stochastic processes;mathematical model;differential equations;fasttrack protocols peer to peer protocols one step process bittorrent protocols;peer to peer computing	The models of peer to peer protocols are presented with the help of one-step processes. On the basis of this presentation and the method of randomization of one-step processes, it is described method for constructing models of peer to peer protocols. The models of FastTrack and Bittorrent protocols are studied by means of proposed method.	bittorrent;fasttrack;peer-to-peer;randomized algorithm	Anastasiya V. Demidova;Anna V. Korolkova;Dmitry S. Kulyabov;Leonid A. Sevastyanov	2014	2014 6th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)	10.1109/ICUMT.2014.7002162	stochastic process;communications protocol;computer science;theoretical computer science;mathematical model;distributed computing;differential equation;statistics;computer network	Metrics	-8.696394613942878	71.57516416390632	192838
04e593f3b19b21ea86acecb789c32a1587e0925a	grid_jqa: a qos guided scheduling algorithm for grid computing	resource selection;resource scheduling;application software;processor scheduling;resource allocation;scheduling algorithm grid computing resource management quality of service quality management problem solving software algorithms processor scheduling application software environmental management;active database;resource manager;resource management;environmental conditions;satisfiability;emerging technology;qos;scheduling algorithm;grid_jqa;virtual organization;resource sharing;resource allocation active databases grid computing java quality of service;resource scheduling grid_jqa qos guided scheduling algorithm grid computing resource sharing dynamic multi institutional virtual organizations resource matching problem resource brokering;resource broker;software algorithms;guided scheduling algorithm;active databases;quality of service;environmental management;grid computing;resource brokering;resource matching problem;problem solving;quality management;dynamic multi institutional virtual organizations;java	The Grid is an emerging technology for enabling resource sharing and coordinated problem solving in dynamic multi-institutional virtual organizations. The resource matching problem in the Grid involves assigning resources to tasks in order to satisfy task requirements and resource policies. This contribution presents algorithms, methods, and software for a Grid resource manager, responsible for resource brokering and scheduling in Grids. The broker selects computing resources based on actual job requirements and a number of criteria identifying the available resources, with the aim to minimize the turnaround time for the individual application. In pervious work, we proposed Grid-JQA [8] [9]. In this work we propose an aggregation formula for the QoS parameters. The formula is a unit less combination of the parameters together with weighting factors. It is shown that the formula needs to put into a threshold consideration. A discussion on the threshold and its level is also provided. The paper introduces an optimum but not practical solution for matching. The optimum method is considered for comparing other practical solutions. Main features of the resource manager include resource selection based on active database rules and environmental conditions and a basic adaptation facility. The paper is finalized by the results obtained from simulation and a comparison study.	active database;algorithm;esri grid;grid computing;problem solving;quality of service;requirement;scheduling (computing);simulation;virtual organization (grid computing)	Leili Mohammad Khanli;Morteza Analoui	2007	Sixth International Symposium on Parallel and Distributed Computing (ISPDC'07)	10.1109/ISPDC.2007.25	real-time computing;quality of service;semantic grid;resource allocation;computer science;resource management;operating system;database;distributed computing	HPC	-17.512650586570672	63.20205142055164	192866
6ba6e44ff2fdb57535fecd0d19c81fe9a2b2ba09	a novel approach for cooperative overlay-maintenance in multi-overlay environments	distributed system;protocols;multi overlay environment peer to peer overlay network multiple overlays cooperative overlay maintenance;routing;redundancy computer networks cooperative systems distributed processing peer to peer computing;distributed processing;p2p;maintenance engineering;multiple overlays;maintenance engineering subscriptions computational fluid dynamics protocols estimation routing peer to peer computing;system performance;computer networks;redundant maintenance overhead cooperative overlay maintenance multioverlay environment distributed system resource sharing overlay network cloud system virtualized resource p2p application;computational fluid dynamics;redundancy;cooperative systems;estimation;cooperative overlay maintenance;virtualized resource;resource sharing;overlay network;subscriptions;cloud system;redundant maintenance overhead;peer to peer computing;multioverlay environment;multi overlay environment;p2p application;peer to peer	Overlay networks are widely adopted in many distributed systems for efficient resource sharing. Recently, issues in overlay network have also been introduced into cloud systems, in order to organize thousands of virtualized resources. In parallel, the explosion of P2P applications introduces the multi-overlay environment in which a number of nodes simultaneously participate in multiple overlays. When multiple applications running over a large set of nodes, some of nodes may take repeated efforts to preserve multi-overlay networks. Therefore, maintaining these co-existing overlays brings the redundant maintenance overhead. This paper presents a cooperative strategy to analyze the overlay maintenance of multi-overlay environments and to elaborate multiple overlays for simplifying the overlay maintenance. The proposed strategy exploits the synergy of co-existing overlays to handle their common overlay-maintenance, so that the redundant maintenance overhead could be eliminated while keeping performance. To evaluate the system performance, this paper not only analyzes several overlays but also considers realistic multi-overlay environments by varying the intersection ratio of diverse overlays and the combination of multiple overlays. Experimental results show that the proposed cooperative strategy significantly decreases the redundant overlay-maintenance overhead, where the reduction ratio of maintaining multiple overlays is higher than 60 percent in some of cases.	cloud computing;computational fluid dynamics;distributed computing;overhead (computing);overlay network;synergy	Chin-Jung Hsu;Wu-Chun Chung;Kuan-Chou Lai;Kuan-Ching Li;Yeh-Ching Chung	2010	2010 IEEE Second International Conference on Cloud Computing Technology and Science	10.1109/CloudCom.2010.12	maintenance engineering;shared resource;communications protocol;routing;estimation;real-time computing;overlay network;computational fluid dynamics;computer science;peer-to-peer;distributed computing;redundancy;computer network	HPC	-12.015377038845177	73.2559103135792	192876
4f2813d019d5c99099b3f0d27adb687ed8d52f9c	static security optimization for real-time systems	control systems;security aware optimization problem static security optimization real time systems group based security service model real time scheduling algorithm earliest deadline first;real time scheduling algorithm;security model;rail transportation;data integrity;design and development;security aware optimization problem;earliest deadline first;security of data data integrity embedded systems scheduling;real time;embedded real time systems;static security optimization;group based security service model;security embedded real time systems optimization;optimization problem;service model;embedded systems;control system;scheduling algorithm;scheduling;security requirements;real time scheduling;real time systems radar tracking information security control systems computer science rail transportation application software medical control systems scheduling algorithm testing;optimization;informatics;security;real time application;security of data;real time systems	An increasing number of real-time applications like railway signaling control systems and medical electronics systems require high quality of security to assure confidentiality and integrity of information. Therefore, it is desirable and essential to fulfill security requirements in security-critical real-time systems. This paper addresses the issue of optimizing quality of security in real-time systems. To meet the needs of a wide variety of security requirements imposed by real-time systems, a group-based security service model is used in which the security services are partitioned into several groups depending on security types. While services within the same security group provide the identical type of security service, the services in the group can achieve different quality of security. Security services from a number of groups can be combined to deliver better quality of security. In this study, we seamlessly integrate the group-based security model with a traditional real-time scheduling algorithm, namely earliest deadline first (EDF). Moreover, we design and develop a security-aware EDF schedulability test. Given a set of real-time tasks with chosen security services, our scheduling scheme aims at optimizing the combined security value of the selected services while guaranteeing the schedulability of the real-time tasks. We study two approaches to solve the security-aware optimization problem. Experimental results show that the combined security values are substantially higher than those achieved by alternatives for real-time tasks without violating real-time constraints.	algorithm;authentication;computation;confidentiality;control system;data integrity;display resolution;earliest deadline first scheduling;fixed-priority pre-emptive scheduling;heuristic;integer programming;linear programming;mathematical optimization;optimization problem;optimizing compiler;overhead (computing);real-time clock;real-time computing;real-time locating system;real-time operating system;real-time transcription;requirement;scheduling (computing);scheduling analysis real-time systems;security bug;security service (telecommunication);test suite	Man Lin;Li Xu;Laurence Tianruo Yang;Xiao Qin;Nenggan Zheng;Zhaohui Wu;Meikang Qiu	2009	IEEE Transactions on Industrial Informatics	10.1109/TII.2009.2014055	software security assurance;computer security model;cloud computing security;embedded system;real-time computing;security engineering;covert channel;computer science;control system;operating system;security service;distributed computing;security testing;scheduling;computer security;computer network	Embedded	-4.936557573946196	61.326850166340975	192896
4e423596f6838e1095be025e65923d860d1c711d	scalar prefix search: a new route lookup algorithm for next generation internet	internet routing binary search trees communications society algorithm design and analysis costs search methods encoding tree data structures data structures;pediatrics;complexity theory;binary search trees;routing;route lookup;tree searching internet ip networks telecommunication network routing;search method;data mining;memory cost;internet;telecommunication network routing;binary search tree;internet router;avl tree scalar prefix search route lookup next generation internet internet router ipv4 ipv6 memory cost trie based algorithm ip address length tree structure binary search tree rb tree;tree structure;ip address length;ipv6;ip networks;peer to peer computing;tree searching;avl tree;scalar prefix search;trie based algorithm;ipv4;rb tree;next generation internet	"""Currently, the increasing rate of routing lookups in Internet routers, the large number of prefixes and also the transition from IPV4 to IPV6, have caused Internet designers to propose new lookup algorithms and try to reduce the memory cost and the prefix search and update procedures times. Recently, some new algorithms are proposed trying to store the prefixes in a balanced tree to reduce the worst case prefix search and update times. These algorithms improve the search and update times compared to previous range based trees. In this paper it is shown that there is no need to treat the prefixes as ranges. It is only required to compare them like scalar values using a predefined rule. The method """"Scalar Prefix Search"""" which is presented here, is built on this concept and combining it with the proposed store and search methods, interprets each prefix as a number without any encoding, the need to convert it to the prefix end points or to use the Trie based algorithms whose performance completely depends on IP address length. This method can be applied to many different tree structures. It is implemented using the Binary Search Tree and some other balanced trees such as RB-tree, AVL-tree and B-tree for both IPV4 and IPV6 prefixes. Comparison results show better lookup and update performance or superior storage requirements for Scalar Prefix Search in both average and worst cases, against current solutions like PIBT [1] and LPFST [2]. Keywords-Prefix; Scalar; Match; search; update; Lookup"""	avl tree;authorization;b-tree;best, worst and average case;binary tree;bitwise operation;graph traversal;ieee xplore;insertion sort;internet;lookup table;red–black tree;requirement;routing table;sp/k;scalar processor;search algorithm;self-balancing binary search tree;terminate (software);tree structure;trie	Mohammad Behdadfar;Hossein Saidi;Hamid Alaei;Babak Samari	2009	IEEE INFOCOM 2009	10.1109/INFCOM.2009.5062179	prefix code;binary search tree;computer science;trie;theoretical computer science;distributed computing;ternary search tree;longest prefix match;computer network	Networks	-5.994982684699478	67.58035416502625	193008
95d5e8c15b038e661ef63217d6763bc890265862	adaptive networks with self-organizing multi-hop links	distributed system;distributed processing;local adaptation;adaptive systems;self organising feature maps;adaptive systems spread spectrum communication joining processes integrated circuit interconnections adaptive optics optical interconnections optical fiber networks radio transceivers wireless networks counting circuits;self organization;distributed processing self organising feature maps adaptive systems;ad hoc distributed systems adaptive networks self organizing multi hop links multi hop paths local adaptation transmission weights autonomous organization	A method is proposed for adapting transmissions in a network so that multi-hop paths form to link nodes emitting compatible signal types. The method uses a simple, local adaptation of transmission weights at each node depending only on the signals passing through the node. This method is applicable for autonomous organization of functions in ad-hoc distributed systems mediated by communication.	autonomous robot;broadcast relay station;distributed computing;electronic circuit;evolutionary algorithm;fault tolerance;gnu nano;hoc (programming language);hop;organizing (structure);self-organization;transmitter	Peter Davis	1999		10.1109/EH.1999.785446	telecommunications;computer science;distributed computing;computer network	Mobile	-6.736994024865263	72.30581931871814	193061
acec0a12a1946279a35b79828cab4f4cb13761fd	vmbuddies: coordinating live migration of multi-tier applications in cloud environments	virtual machine;migration cost minimization vmbuddies coordination system live multitier application migration cloud environment virtualization technology virtual machines vm cloud data centers load management power saving routine server maintenance quality of service data exchange adaptive network bandwidth allocation algorithm;protocols;degradation;cloud computing computer centres virtual machines virtualisation;cloud;drntu engineering computer science and engineering;journal article;bandwidth channel allocation synchronization distributed databases protocols telecommunication traffic degradation;telecommunication traffic;virtualisation cloud computing computer centres virtual machines;synchronization;multi tier application;distributed databases;bandwidth;vmbuddies coordination system live multitier application migration cloud environment virtualization technology virtual machines vm cloud data centers load management power saving routine server maintenance quality of service data exchange adaptive network bandwidth allocation algorithm migration cost minimization;channel allocation;live migration	Enabled by virtualization technologies, various multi-tier applications (such as web applications) are hosted by virtual machines (VMs) in cloud data centers. Live migration of multi-tier applications across geographically distributed data centers is important for load management, power saving, routine server maintenance and quality-of-service. Different from a single-VM migration, VMs in a multi-tier application are closely correlated, which results in a correlated VM migrations problem. Current live migration algorithms for single-VM cause significant application performance degradation because intermediate data exchange between different VMs suffers relatively low bandwidth and high latency across distributed data centers. In this paper, we design and implement a coordination system called VMbuddies for correlated VM migrations in the cloud. Particularly, we propose an adaptive network bandwidth allocation algorithm to minimize the migration cost in terms of migration completion time, network traffic and migration downtime. Experiments using a public benchmark show that VMbuddies significantly reduces the performance degradation and migration cost of multi-tier applications.	algorithm;benchmark (computing);cloud computing;data center;downtime;elegant degradation;load management;multitier architecture;network packet;quality of service;server (computing);virtual machine;web application	Haikun Liu;Beixin Julie He	2015	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2014.2316152	communications protocol;synchronization;parallel computing;real-time computing;degradation;cloud computing;computer science;virtual machine;multitier architecture;operating system;database;distributed computing;distributed database;computer security;bandwidth;computer network	HPC	-18.36912216467179	69.06016732119211	193644
3466383431c1f5b76e65f6266528849b6c5d6471	evaluating the scalability of distributed systems	software metrics;distributed system;p scalability;concurrent computing;power metric;scaling path;scalability metric;distributed computing;software performance evaluation;parallel programming;scaling up;distributed systems scalability evaluation;time factors;system design;scalability enabling parameters;scalability;quality of service;scalability delay throughput costs distributed computing power generation economics time factors quality of service power measurement concurrent computing;maximum value;power generation economics;distributed operation;power measurement;throughput;scalability metric distributed systems scalability evaluation distributed operation p scalability power metric scaling path scalability enabling parameters maximum value	Many distributed systems must be scalable, meaning that they must be economically deployable in a wide range of sizes and con gurations. This paper presents a scalability metric based on coste ectiveness, where the e ectiveness is a function of the system's throughput and its quality of service. It is part of a framework which also includes a scaling strategy for introducing changes as a function of a scale factor, and an automated virtual design optimization at each scale factor. This is an adaptation of concepts for scalability measures in parallel computing. Scalability is measured by the range of scale factors that give a satisfactory value of the metric, and good scalability is a joint property of the initial design and the scaling strategy. The results give insight into the scaling capacity of the designs, and into how to improve the design. A rapid simple bound on the metric is also described. The metric is demonstrated in this work by applying it to some well-known idealized systems, and to real prototypes of communications software.	central processing unit;computation;distributed computing;evaluation function;image scaling;mathematical optimization;naruto shippuden: clash of ninja revolution 3;nonlinear gameplay;numerical analysis;open road tolling;parallel computing;quality of service;queueing theory;recursion;response time (technology);scalability;software prototyping;speedup;throughput;whole earth 'lectronic link	Prasad Jogalekar;C. Murray Woodside	1998		10.1109/HICSS.1998.649248	throughput;real-time computing;scalability;quality of service;concurrent computing;computer science;theoretical computer science;distributed computing;scalability testing;software metric;systems design	Networks	-16.28237952322104	64.86309339652902	193702
3c681e0767a7252ae1e6de24672534c7f3c126ea	an estimation-based task load balancing scheduling in spot clouds		Cloud computing is a computing paradigm in which users can rent computing resources from service providers according to their requirements. Cloud computing based on the spot market helps a user to obtain resources at a lower cost. However, these resources may be unreliable. In this paper, we propose an estimation-based distributed task workflow scheduling scheme that reduces the estimated generation compared to Genetic Algorithm (GA). Moreover, our scheme executes a user's job within selected instances and stretches the user's cost. The simulation results, based on a before-and-after estimation comparison, reveal that the task size is determined based on the performance of each instance and the task is distributed among the different instances. Therefore, our proposed estimation-based task load balancing scheduling technique achieves the task load balancing according to the performance of instances.	load balancing (computing);scheduling (computing);tag cloud	Daeyong Jung;HeeSeok Choi;Dae-Won Lee;Heon-Chang Yu;Eunyoung Lee	2014		10.1007/978-3-662-44917-2_55	parallel computing;real-time computing;computer science;distributed computing	HPC	-18.45945809351323	62.56540981196355	194162
44c030daaec5480c969f0e84fd4d9a6fc0c928a6	simulation of an integrated architecture for ip-over-atm frame processing	acceso multiple;optimisation;tecnologia electronica telecomunicaciones;acces multiple;systeme evenement discret;computacion informatica;integration memoire processeur;protocole transmission;cell size;optimizacion;direct memory access;ip over atm;reseau ordinateur;simulation;simulacion;computer systems;processor memory integration;computer networks;transmision asincronica;computer network;chip;sistema acontecimiento discreto;protocolo transmision;discrete event system;red atm;ciencias basicas y experimentales;virtual channel;red ordenador;segmentation and reassembly;asynchronous transmission;flexible structure;transmission asynchrone;estructura flexible;optimization;tecnologias;structure flexible;grupo a;multiple access;reseau atm;simulation model;virtual path;atm network;discrete event simulation;transmission protocol	The performance of an integrated architecture for full-duplex IP-over-ATM processing is evaluated through detailed simulation. The architecture combines processing, memory, and multiple direct-memory-access engines for single-chip implementation. The simulation models the segmentation and reassembly operations needed to translate IP frames to and from a fixed ATM cell size. A key operation is the insertion of a virtual path and virtual channel identifier (VPI/VCI) into the outgoing ATM cells. Software-based VPI/VCI insertion provides flexibility but requires the on-chip processor to perform this function. Hardware-based VPI/VCI insertion is an optimization that requires one of the direct-memory-access engines to perform this task. The two approaches are evaluated through simulated execution of representative control software with detailed modeling of all on-chip components. Results indicate that software-based VPI/VCI insertion supports full-duplex traffic at 475 Mbps on a 500-MHz processor and that hardware-based VPI/VCI insertion supports full-duplex traffic at 560 Mbps on a 500-MHz processor.	atm turbo;algorithm;content-control software;data rate units;direct memory access;duplex (telecommunications);identifier;mathematical optimization;segmentation and reassembly;simulation;virtual channel	Peter M. Ewert;Naraig Manjikian	2002	Simulation	10.1177/0037549702078004543	chip;embedded system;real-time computing;simulation;telecommunications;computer science;discrete event simulation;operating system;asynchronous communication;segmentation and reassembly;simulation modeling;direct memory access;computer network	Arch	-5.484137956771068	72.4837488832867	194200
9ac01488c7c51d2ff5d1a542e939afd40d5a42b3	bio-inspired replica density control in dynamic networks	distributed application;distributed system;population model;evaluation performance;replication;adaptability;adaptabilite;systeme reparti;performance evaluation;ecologia;evaluacion prestacion;ecologie;commande repartie;dinamica poblacion;ecology;replicacion;system performance;adaptabilidad;partage des ressources;sistema repartido;biomimetique;resource sharing;population ecology;particion recursos;population dynamics;control repartido;dynamique population;distributed control;dynamic networks;biomimetics	Resource replication is a crucial technique for improving system performance of distributed applications with shared resources. A larger number of replicas require shorter time to reach a replica of the requested resource, but consume more storage of hosts. Therefore, it is indispensable to adjust the number of replicas appropriately for its application.#R##N##R##N#This paper considers the problem for controlling the density of replicas adaptively in dynamic networks. The goal of the problem is to adjust the number of replicas to a constant fraction of the current network size. This paper proposes algorithm inspired by the single species population model, which is a well-known population ecology model. The simulation results show that the proposed algorithm realize self-adaptation of the replica density in dynamic networks.		Tomoko Suzuki;Taisuke Izumi;Fukuhito Ooshita;Hirotsugu Kakugawa;Toshimitsu Masuzawa	2006		10.1007/11613022_23	biomimetics;shared resource;population ecology;replication;adaptability;simulation;population model;computer science;artificial intelligence;population dynamics	Robotics	-11.169191695500738	69.50808912294981	194448
0a77604b02047bebe174691261190f16447d5734	compositionality of statically scheduled ip	timing closure;static scheduling;interconnected circuits;very large scale integration;interconnected systems;multiport circuits;n synchronous;synchronous;delay effects;equalization;very large scale integrated;latency insensitive design;digital integrated circuits;system on chip;synchronization;interconnected system;soc;globally asynchronous locally synchronous gals;synchronous dataflow;globally asynchronous locally synchronous;delay estimation;dynamic scheduling;asynchronous logic circuits	Timing Closure in presence of long global wire interconnects is one of the main current issues in System-onChip design. One proposed solution to the Timing Closure problem is Latency-Insensitive Design (LID) [5,7]. It was noticed in [7] that, in many cases, the dynamically scheduled synchronisations introduced by latency-insensitive protocols could be computed off-line as a static periodic schedule. We showed in [2,3] how this schedule could then be used to further optimize the protocol resources when they are found redundant. The purpose of the present paper is to study how the larger blocks, obtained as synchronous components interconnected by LID protocols optimized by static schedule informations, can be again made to operate with an environment that provides also I/O connections at its own (synchronous or GALS) rate. We also consider the case of multirate SoC, using results from SDF (Synchronous DataFlow) theory [12].	clock gating;clock rate;clock signal;closure problem;control flow;dataflow;electrical connection;globally asynchronous locally synchronous;input/output;interrupt latency;linear algebra;online and offline;point of view (computer hardware company);quasiperiodicity;schedule (computer science);stationary process;synchronous circuit;throughput;timing closure;web resource	Julien Boucaron;Jean-Vivien Millo	2008	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2008.02.007	system on a chip;parallel computing;real-time computing;computer science;distributed computing	Embedded	-6.5420374617913115	62.41495968755461	194462
d86d34e6acbadd13cdb7df945303330f618adcdf	exploiting user behaviour in prefetching www documents	teletrafic;indonesia;largeur bande;architecture systeme;indonesie;red www;concepcion sistema;information source;source information;implementation;tiempo acceso;stockage donnee;general techniques;ejecucion;data storage;teletrafico;asie;design and implementation;user behaviour;system design;anchura banda;teletraffic;bandwidth;almacenamiento datos;world wide web;temps acces;arquitectura sistema;reseau www;system architecture;proxy server;langage html;conception systeme;html language;fuente informacion;access time;asia;java	As the popularity of the World Wide Web increases, the amount of traffic results in major congestion problems for the retrieval of data over wide distances. To react to this, users and browser builders have implemented various prefetching and parallel retrieval mechanisms, which initiate retrieval of documents that may be required later. This additional traffic is even worsening the situation. Since we believe that this will remain the general approach for quite a while, we try to make use of the general technique but try to reduce the destructive effects by retrieving less content which remains finally unread. In our user-specific prefetch mechanism, the prefetching system gathers references by parsing the HTML pages the user browses, identifies the links to other pages, and puts the words describing the links into a keyword list. If such a word was already present in the list, its associated weight is incremented. Otherwise it is added to the table and a weighting factor allocated. We have designed and implemented a client based proxy-server with this mechanism. This paper shows the design and implementation of this prefetching proxy server, presents results and general considerations on this technique.	access time;anchor text;bandwidth (signal processing);cpu cache;html;internet;link prefetching;need to know;network congestion;parsing;proxy server;server (computing);speculative execution;thesaurus;user profile;www;while;world wide web	Abdulmotaleb El-Saddik;Carsten Griwodz;Ralf Steinmetz	1998		10.1007/BFb0055327	html;telecommunications;access time;computer science;artificial intelligence;operating system;computer data storage;database;distributed computing;programming language;implementation;java;world wide web;computer security;bandwidth;algorithm;systems architecture;systems design	Web+IR	-17.789570401474744	71.90689440937513	194545
30413917fa7b28feff69d4c8b9f5180bfb65fde7	dynamic duty cycle control for end-to-end delay guarantees in wireless sensor networks	energy conservation dynamic duty cycle control end to end delay guarantee wireless sensor networks static sleep scheduling energy efficiency dutycon single hop delay guarantee problem data flow dynamic feedback control problem system stability queuing delay adaptation scheme energy balancing approach;energy efficiency;energy conservation;network lifetime;warranties;control systems;control theory;wireless sensor networks sleep delay effects feedback control control systems communication system control costs dynamic scheduling runtime energy efficiency;energy efficient;queueing theory;queuing delay adaptation scheme;delay effects;dynamic feedback control problem;runtime;single hop delay guarantee problem;wireless sensor network;receivers;sleep;system stability;end to end delay guarantee;feedback;wireless sensor networks data flow analysis delays energy conservation feedback queueing theory warranties;dynamic duty cycle control;energy balance;duty cycle;static sleep scheduling;schedules;mathematical model;data flow analysis;communication delay;communication system control;data flow;end to end delay;dutycon;feedback control;wireless sensor networks;energy saving;delays;dynamic scheduling;energy balancing approach	It is well known that periodically putting nodes into sleep can effectively save energy in wireless sensor networks, at the cost of increased communication delays. However, most existing work mainly focuses on static sleep scheduling, which cannot guarantee the desired delay when the network conditions change dynamically. In many applications with user-specified end-to-end delay requirements, the duty cycle of every node should be tuned individually at runtime based on the network conditions to achieve the desired end-to-end delay guarantees and energy efficiency. In this paper, we propose DutyCon, a control theory-based dynamic duty cycle control approach. DutyCon decomposes the end-to-end delay guarantee problem into a set of single-hop delay guarantee problems along each data flow in the network. We then formulate the single-hop delay guarantee problem as a dynamic feedback control problem and design the controller rigorously, based on feedback control theory, for analytic assurance of control accuracy and system stability. DutyCon also features a queuing delay adaptation scheme that adapts the duty cycle of each node to unpredictable packet rates, as well as a novel energy balancing approach that extends the network lifetime by dynamically adjusting the delay requirement allocated to each hop. Our empirical results on a hardware testbed demonstrate that DutyCon can effectively achieve the desired tradeoff between end-to-end delay and energy conservation. Extensive simulation results also show that DutyCon outperforms two baseline sleep scheduling protocols by having more energy savings while meeting the end-to-end delay requirements.	baseline (configuration management);bonjour sleep proxy;control theory;dataflow;duty cycle;end-to-end principle;feedback;network packet;queuing delay;requirement;run time (program lifecycle phase);scheduling (computing);simulation;testbed	Xiaodong Wang;Xiaorui Wang;Guoliang Xing;Yanjun Yao	2010	2010 IEEE 18th International Workshop on Quality of Service (IWQoS)	10.1109/IWQoS.2010.5542743	real-time computing;wireless sensor network;computer science;control system;processing delay;elmore delay;end-to-end delay;feedback;distributed computing;efficient energy use;transmission delay;network delay;queuing delay;computer network	Embedded	-5.76831734909866	62.15959043140388	194684
c82822537de88dfd83210991369a13139ffe0d6b	the edl server for scheduling periodic and soft aperiodic tasks with resource constraints	aperiodic tasks;resource constraint;earliest deadline;scheduling algorithm;periodic tasks;scheduling;priority ceiling protocol;critical resources;critical section;real time systems;time constraint	In this paper, we are concerned with the problem of serving soft aperiodic tasks on a uniprocessor system where periodic tasks are scheduled on a dynamic-priority, preemptive basis and exclusively access to critical sections. Scheduling of tasks is handled by the Dynamic Priority Ceiling Protocol working with an Earliest Deadline scheduler. Our analysis determines the maximum processing time which may be stolen from periodic tasks without jeopardizing both their timing constraints and resource consistency. It provides the basis for an on-line scheduling algorithm, the EDL Server, to deal with the minimization of response times for soft aperiodic tasks.	algorithm;critical section;deadline scheduler;earliest deadline first scheduling;online and offline;priority ceiling protocol;scheduling (computing);uniprocessor system	Maryline Chetto	1999	Real-Time Systems	10.1023/A:1008093629946	fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;deadline-monotonic scheduling;distributed computing;scheduling;priority ceiling protocol	Embedded	-10.337152928898302	60.49284529383244	195004
f49321afef1636cb9c170bb82154878cec745f3e	worst-case response time analysis for osek/vdx compliant real-time distributed control systems	osek vdx compliant real time distributed control systems;preemptive scheduling;distributed control system;processor scheduling;delay real time systems distributed control control systems vehicles job shop scheduling timing processor scheduling electrical equipment industry industrial control;real time;fixed priority;development process;fixed priority preemptive scheduling model worst case response time analysis osek vdx compliant real time distributed control systems temporal behaviors prediction;fixed priority preemptive scheduling model;real time control system;worst case response time analysis;timing analysis;worst case response time;electronic control unit;temporal behaviors prediction;distributed control;hard real time;real time systems processor scheduling;real time systems	Temporal behaviors prediction is very critical for real-time control systems. This paper presents a method to analyse the worst-case response time of OSEK/VDX compliant hard real-time distributed control systems. OSEK/VDX is an industry standard for an open-ended architecture for distributed control units in vehicles. Traditional time analysis methods based on the fixed priority preemptive scheduling model do not account for the problems occur in practical systems. Based on the current time analysis technologies, we propose an accurate time analysis method considering the practical effects of resource access synchronization, mixed preemptive and non-preemptive scheduling, as well as the overheads of OSEK OS. Furthermore, we also propose a scheme to efficiently integrate time analysis tools into the current development process for electronic control units in vehicles	best, worst and average case;distributed control system;fixed-priority pre-emptive scheduling;nonlinear gameplay;osek;operating system;preemption (computing);real-time clock;real-time computing;real-time locating system;response time (technology);scheduling (computing);technical standard;vdx (library software)	Lei Wang;Zhaohui Wu;Mingde Zhao	2004	Proceedings of the 28th Annual International Computer Software and Applications Conference, 2004. COMPSAC 2004.	10.1109/CMPSAC.2004.1342819	embedded system;electronic control unit;real-time computing;real-time control system;computer science;operating system;distributed control system;preemption;static timing analysis;software development process	Embedded	-9.069004577232464	60.865937719077365	195365
6ab7c531badc81cbb4818b464010f0b4896d01e3	service task partition and distribution in star topology computer grid subject to data security constraints	level of service;computational grid;distributed computing;optimization problem;generating function;evolutionary optimization;grid computing;resource management system;grid system;data security	The paper considers grid computing systems in which the resource management systems (RMS) can divide service tasks into execution blocks (EBs) and send these blocks to different resources. In order to provide a desired level of service reliability the RMS can assign the same blocks to several independent resources for parallel execution.#R##N##R##N#The data security is a crucial issue in distributed computing that affects the execution policy. By the optimal service task partition into the EBs and their distribution among resources, one can achieve the greatest possible service reliability and/or expected performance subject to data security constraints. The paper suggests an algorithm for solving this optimization problem. The algorithm is based on the universal generating function technique and on the evolutionary optimization approach. Illustrative examples are presented.		Yanping Xiang;Gregory Levitin	2011	Rel. Eng. & Sys. Safety	10.1016/j.ress.2011.06.013	optimization problem;generating function;real-time computing;computer science;theoretical computer science;mathematics;distributed computing;utility computing;data security;level of service;grid computing	HPC	-17.10089478715772	63.511457525153354	195409
750fdd2da2cb956b1bc004c7a5128995cd2af035	genetic list scheduling algorithm for scheduling and allocation on a loosely coupled heterogeneous multiprocessor system	heuristic;genetic algorithms multiprocessing systems processor scheduling resource allocation;shared bus scheduling allocation heterogeneous multiprocessor system heuristic method list scheduling genetic algorithm;heterogeneous system design;heterogeneous systems;application software;multiprocessor systems;processor scheduling;resource allocation;heuristic method;heterogeneous multiprocessor system;allocation;satisfiability;genetics;computer architecture;scheduling algorithm;partially ordered set;biological cells;permission;shared bus;data dependence;scheduling;heuristic algorithms;list scheduling;genetic algorithm;genetic algorithms;scheduling algorithm processor scheduling genetic algorithms biological cells multiprocessing systems computer architecture application software hardware permission heuristic algorithms;multiprocessing systems;ge netic algorithm;hardware	Our problem consists of a partially ordered set of tasks communicating over a shared bus which are to be mapped to a heterogeneous multiprocessor system. The goal is to minimize the makespan, while satisfying constrains implied by data dependencies and exclusive resource usage. We present a new efficient heuristic approach based on list scheduling and genetic algorithms, which finds the optimum in few seconds on average even for large examples (up to 96 tasks) taken from [3]. The superiority of our algorithm compared to some other algorithms is demonstrated. Keywords— heterogeneous system design, heuristic, genetic algorithms, list scheduling	data dependency;genetic algorithm;heuristic;list scheduling;loose coupling;makespan;multiprocessing;scheduling (computing);systems design	Martin Grajcar	1999		10.1145/309847.309931	fair-share scheduling;parallel computing;real-time computing;genetic algorithm;heuristic;dynamic priority scheduling;computer science;genetic algorithm scheduling;operating system;distributed computing;scheduling;multiprocessor scheduling	Embedded	-13.177729307716188	61.649158423806114	195714
36daaa92ac438d189e09e788335d55d6365f18b0	enhancing the web's infrastructure: from caching to replication	cache storage;naming services;replication;user perceived latency;client server system;performance evaluation;fault tolerant;caching;performance;software performance evaluation;client server systems;high latency;replicate servers;application level naming;client server system world wide web caching replication bandwidth high latency application level naming performance main proxy cache replicate servers user perceived latency fault tolerant system internet;fault tolerant system;fault tolerant computing;single machine;internet;main proxy cache;bandwidth;world wide web;document retrieval;delay web server web sites bandwidth network servers performance analysis system software fault tolerant systems robustness usability;point of view;client server systems internet cache storage replicated databases performance evaluation naming services software performance evaluation fault tolerant computing;replicated databases;network congestion;data transfer	The World Wide Web and the phrase “traffic jam” have become as linked in the minds of many computer users as are the urban superhighway and “rush hour” to the early morning commuter. Insufficient bandwidth causing high latency are the order of the day. Caching is a standard solution for this type of problem, and it was applied to the Web early on for this reason. The more advanced approaches of replication and applicationlevel naming were introduced over the past two years to further attack the problem. However, these complex methods could easily exacerbate the situation if the implementation is not well designed and the results are not evaluated carefully.	cache (computing);fault tolerance;internet;jam;load balancing (computing);quality of service;replication (computing);urban computing;user (computing);www;web application;world wide web	Michael Baentsch;Lothar Baum;Georg Molter;Steffen Rothkugel;Peter Sturm	1997	IEEE Internet Computing	10.1109/4236.601083	document retrieval;fault tolerance;real-time computing;computer science;operating system;database;distributed computing;world wide web;computer security;computer network	Web+IR	-17.80183783785802	71.57284057157942	195721
b730a97ba1b92bcd00fc4d274f938a07579e730e	optimal load distribution in nondedicated heterogeneous cluster and grid computing environments	cluster computing;heterogeneous cluster;dedicated task;grid computing environment;response time;optimization problem;nondedicated environment;load distribution;load balance;generic task;grid computing	We consider optimal load distribution in a nondedicated cluster or grid computing system with heterogeneous servers processing both generic and dedicated applications. The goal of load balancing is to find an optimal load distribution strategy for generic tasks on heterogeneous servers preloaded by different amount of dedicated tasks such that the overall average response time of generic applications is minimized. The optimization problem is solved for three different queueing disciplines, namely, dedicated applications without priorities, prioritized dedicated applications without preemption, and prioritized dedicated applications with preemption. For each case, we derive equations that permit us to find optimal load distribution of generic tasks such that their average response time is minimized.	grid computing;load balancing (computing)	Keqin Li	2008	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2007.04.003	optimization problem;parallel computing;real-time computing;computer cluster;computer science;weight distribution;load balancing;operating system;distributed computing;response time;grid computing	HPC	-15.591964326985199	60.724506800285674	195732
02935651334cc9846121da4e0e47613c75047df3	performance comparison of adaptation approaches for mobile information system	information systems telecommunication traffic network servers traffic control mobile communication adaptation model usa councils internet performance analysis web pages;proxy based model;information systems;web pages;access behavior;process capability;software performance evaluation;performance comparison;traffic control;differentiated service;usa councils;differential services;free services performance comparison adaptation approaches mobile information system access behavior network traffic web site qos server based model proxy based model differential services scalability mobile traffic;server based model;qos;telecommunication traffic;network servers;adaptation model;mobile service;internet;free services;network traffic;quality of service mobile computing distributed databases software performance evaluation telecommunication traffic web sites;web sites;mobile communication;performance analysis;distributed databases;adaptation approaches;mobile information system;scalability;quality of service;mobile computing;mobile traffic;web site;mobile user	We analyze the access behavior and traffic characteristics of typical mobile services, study and compare the performance of different adaptation approaches. For a typical unified Web site, 10% of access requests are from mobile users, 90% from PC users. The heterogeneity in the communicating devices and networks QoS characteristics need to be handled through different forms of software-supported adaptation. The two main adaptation models are server-based model and proxy-based model. The processing load of server or proxy carrying out the adaptation may increase by about 10 times or more. In order to provide differential services and increase the scalability, the server-adaptation and proxy-adaptation should coexist. They are suitable for paid and free services respectively. Paid services account for about 80% of mobile traffic, and free services account for 20%. Server and proxy processing capability should be increased by more than 2 times. Thus traffic and processing load is divided rationally.	information system	Qingguo Shen;Li Wang	2003		10.1109/AINA.2003.1192874	quality of service;computer science;operating system;database;internet privacy;mobile computing;world wide web;computer security;computer network	Robotics	-18.945182647815244	69.98077803637426	195802
e770d86b8622569bcde8e74d4f36a8ea73598460	schedulability analysis of distributed hard real-time systems with multiple-event synchronization	distributed system;client server systems real time systems processor scheduling synchronisation timing message passing;timing requirements schedulability analysis distributed hard real time systems multiple event synchronization representation model task synchronization resource sharing activation event combinations event generation message passing systems client server architecture rate monotonic analysis upper bounds worst case response times;client server architecture;real time systems timing communication networks processor scheduling linear systems communication standards fddi telecommunication traffic character generation delay;processor scheduling;message passing system;rate monotonic analysis;client server systems;schedulability analysis;upper bound;synchronisation;distributed real time system;hard real time system;resource sharing;message passing;worst case response time;real time systems;timing	In this paper we present a schedulability analysis technique for distributed hard real-time systems in which responses to different events may synchronize with each other. This technique uses a representation model for distributed systems that allows us to describe not only the task synchronization due to resource sharing, but also the activation due to combinations of events or the generation of several events by a single task. The model is representative of a large number of systems and is suitable for the treatment of message-passing systems or the client-server architecture. The analysis technique is based on the existing RMA techniques for analyzing distributed real-time systems; it allows obtaining upper bounds for the worst-case response times of the system , thus allowing us to make guarantees about the fulfillment of the timing requirements that have been imposed.	best, worst and average case;client–server model;distributed computing;message passing;real-time clock;real-time computing;requirement;revolution in military affairs;scheduling analysis real-time systems;server (computing)	J. Javier Gutiérrez;J. Carlos Palencia;Michael González Harbour	2000		10.1109/EMRTS.2000.853988	shared resource;synchronization;parallel computing;message passing;real-time computing;computer science;operating system;distributed computing;upper and lower bounds;programming language;client–server model	Embedded	-9.320981662012517	61.545817733963624	196061
45546be0498a61dbcd530041870d0d3aad0d5696	bio-inspired p2p systems: the case of multidimensional overlay	resource discovery;bio inspired;peer to peer;self organizing	This article presents an ant-based approach that enhances the flexibility, robustness and load balancing characteristics of structured P2P systems. Most notably, the approach allows peer indexes and resource keys to be defined on different and independent spaces, so that it overcomes the main limitation of standard structured P2P systems, that is, the need to assign each key to a peer having a specified index. This helps to improve load balancing, especially when the popularity distribution of resource keys is nonuniform, and enables the efficient execution of complex and range queries, which are essential in important types of distributed systems, for example, in Grids and Clouds. Beyond describing the general approach, this article focuses on the specific case of Self-CAN, a self-organizing P2P system that, while relying on the multidimensional structured organization of peers provided by CAN, exploits the operations of ant-based mobile agents to sort the resource keys and distribute them to peers. This system is particularly useful for the management and discovery of the resources that can be conveniently characterized by the values of several independent attributes.	cloud computing;code;distributed computing;grid computing;hash function;load balancing (computing);mobile agent;organizing (structure);peer-to-peer;range query (data structures);self-organization;sorting	Raffaele Giordanelli;Carlo Mastroianni;Michela Meo	2012	TAAS	10.1145/2382570.2382571	simulation;computer science;operating system;distributed computing;world wide web;computer network	OS	-12.484851586991498	72.26384405149797	196291
fc3a65ff67e28dc83187489ebc30354720156f3f	smart unix svr4 support for multimedia applications	unix system v release 4;system loading;time sharing computer systems;dynamic feedback;multimedia applications;application software;processor scheduling;real time;resource management;software performance evaluation;multimedia application;multimedia systems;solaris unix operating system;multimedia computing;smart interface;feedback;operating system;scheduling;application program interfaces;solaris unix operating system smart unix svr4 multimedia applications adaptive real time requirements scheduling unix system v release 4 smart interface application specific time constraints dynamic feedback system loading;smart unix svr4;software performance evaluation unix multimedia computing real time systems scheduling application program interfaces;adaptive real time requirements;real time systems multimedia systems operating systems resource management timing processor scheduling time sharing computer systems application software laboratories feedback;unix;application specific time constraints;operating systems;real time systems;timing;time constraint	Multimedia applications ha ve dynamic and adapti ve realtime requirements. Current scheduling practice, as typified by UNIX System V Release 4, lacks the necessary information and interf aces to meet these requirements. T o address this problem, we ha ve created the SMAR T (Scheduler for Multimedia And Real-T ime) interface. It explicitly accounts for application-specific time constraints and provides dynamic feedback from the scheduler to applications to allow them to adapt to the system loading condition. This paper describes the design of the interf ace and its implementation in the Solaris UNIX operating system to provide an ef fective SVR4-conformant full featured en vironment for supporting multimedia applications.	automatic computing engine;operating system;requirement;smart;scheduling (computing);unix	Jason Nieh;Monica S. Lam	1997		10.1109/MMCS.1997.609751	unix architecture;embedded system;application software;real-time computing;computer science;resource management;operating system;feedback;unix;scheduling	OS	-10.562695346887242	64.28454334100124	196464
24cad686ba24262c92ad83376ce836927c791da1	deadline missing prediction through the use of milestones	distributed threads;en to end deadline;prediction mechanisms	Distributed Real-Time Thread is an important concept for distributed real-time systems. Distributed Threads are schedulable entities with an end-to-end deadline that transpose nodes, carrying their scheduling context. In each node, the thread will be locally scheduled according to a local deadline, which is defined by a deadline partitioning algorithm. Mechanisms for predicting the missing of deadlines are fundamental if corrective actions are incorporated for improving system quality of service. In this work, a mechanism for predicting missing deadlines is proposed and evaluated through simulation. In order to illustrate the main characteristics of the proposed mechanism, experiments will be presented taking into account different scenarios of normal load and overload. Simulations show that the deadline missing prediction mechanism proposed presents good results for improving the overall performance and availability of distributed systems.	algorithm;computation;computational resource;computer simulation;distributed computing;earliest deadline first scheduling;end-to-end principle;entity;experiment;heuristic (computer science);load (computing);operational semantics;quality of service;real-time clock;real-time computing;real-time transcription;response time (technology);scheduling (computing);time complexity	Patricia Della Mea Plentz;Carlos Montez;Rômulo Silva de Oliveira	2011	Computing and Informatics		parallel computing;real-time computing;earliest deadline first scheduling;simulation;computer science;distributed computing	Embedded	-15.105671154009558	61.158800565313875	196666
197c3c23df68548e639ecd1fe1c28b0f414ca0e9	ultra-low latency and high throughput key-value store systems over ethernet		Key-value store (KVS) systems are playing important roles as the caches of database to improve the data access efficiency. In this paper, we propose general architectures of KVS systems based on field programmable gate arrays (FPGAs) which can adapt to different application scenarios. Data hazards introduced by the pipeline are fully handled to improve the throughput. The batch operation is proposed to support the variable-length key-value pairs. The memory address management system reduces CPU load further by managing memory addresses on hardware. We implement and evaluate our KVS systems on VC709 evaluation board targeting throughput, latency and capacity respectively. The ultra-low latency KVS system can achieve 160 ns latency and about 155 million request per second (MRPS) to retrieve 96-bit values with 96-bit keys. The ultra-high throughput KVS system can achieve about 200 ns latency and 200 MRPS throughput to retrieve the same size key-value pairs. The ultra-capacity KVS system retrieves 64-byte values with 12-byte keys, serving a maximum request rate of more than 35 MRPS with latency less than 500 ns.	attribute–value pair;central processing unit;data access;field-programmable gate array;hash table;interrupt latency;key-value database;memory address;microprocessor development board;pipeline (computing);throughput	Li Ding;Wenbo Yin;Lingli Wang	2018	2018 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2018.8351742	field-programmable gate array;memory address;throughput;real-time computing;latency (engineering);memory management;electronic engineering;computer science;latency (engineering);data access;ethernet	Arch	-5.8531088329515155	65.0699496391513	197004
97e1c93c7b773d91bdaa8ef62b8fda050de73040	networks of multi-server queues with parallel processing		We consider a network of multi-server queues wherein each job can be processed in parallel by any subset of servers within a pre-defined set that depends on its class. Each server is allocated in FCFS order at each queue. Jobs arrive according to Poisson processes, have independent exponential service requirements and are routed independently at random. We prove that, when stable, the network has a product-form stationary distribution. From a practical perspective, we propose an algorithm on this basis to allocate the resources of a computer cluster.	parallel computing;server (computing)	Thomas Bonald;Céline Comte	2016	CoRR		parallel computing;real-time computing;computer science;distributed computing;fork–join queue;computer network	HPC	-13.659023437376657	65.05516204649474	197125
efe446de30cd2ea9592b70d208191312b9fd18cd	brief announcement: improved asynchronous group mutual exclusion in token-passing networks	group mutual exclusion;ring network;mutual exclusion;upper bound;message passing;token passing;distributed algorithm	Group mutual exclusion (GME) was first introduced by Joung in 1998 as a generalization of the n-process mutual exclusion problem, and subsequently modeled as the Congenial Talking Philosophers problem. GME allows processes requesting for the same resource to concurrently access the shared resource. However, a process requesting a resource that is different from the one currently being used will not be able to access the requested resource at the same time. At any time, only one resource may be in use.There have been two solutions to the GME problem for a ring network. The first solution proposed by Wu and Joung [2] had an unbounded message size problem, while the second solution proposed by Cantarell et. al. [1] attempted to provide an upper-bound for the message size. However, in doing so, the second solution generated an unbounded number of messages. Hence, in this work we present a GME algorithm for a token-passing network that solves both of the problems found in the two previous solutions by providing an upper bound both to the number of messages and to message size.	algorithm;gme of deutscher wetterdienst;mutual exclusion;ring network	David Lin;Teng-Sheng Moh;Melody Moh	2005		10.1145/1073814.1073866	distributed algorithm;ring network;message passing;real-time computing;token passing;mutual exclusion;computer science;theoretical computer science;distributed computing;upper and lower bounds;programming language	Theory	-13.56525068807094	65.64866262330669	197202
df41ce2573bac52300b45e354224337219a4e89b	a hardware-based caching system on fpga nic for blockchain		Engineers and researchers have recently paid attention to Blockchain. Blockchain is a fault-tolerant distributed ledger without administrators. Blockchain is originally derived from cryptocurrency, but it is possible to be applied to other industries. Transferring digital asset is called a transaction. Blockchain holds all transactions, so the total amount of Blockchain data will increase as time proceeds. On the other hand, the number of Internet of Things (IoT) products has been increasing. It is difficult for IoT products to hold all Blockchain data because of their storage capacity. Therefore, they access Blockchain data via servers that have Blockchain data. However, if a lot of IoT products access Blockchain network via servers, server overloads will occur. Thus, it is useful to reduce workloads and improve throughput. In this paper, we propose a caching technique using a Field Programmable Gate Array-based (FPGA) Network Interface Card (NIC) which possesses four 10Gigabit Ethernet (10GbE) interfaces. The proposed system can reduce server overloads, because the FPGA NIC instead of the server responds to requests from IoT products if cache hits. We implemented the proposed hardware cache to achieve high throughput on NetFPGA-10G board. We counted the number of requests that the server or the FPGA NIC processed as an evaluation. As a result, the throughput improved by on average 1.97 times when hitting the cache. key words: Blockchain, IoT, FPGA, cache	bitcoin;cache (computing);cryptocurrency;database transaction;digital asset;distributed database;fault tolerance;field-programmable gate array;internet of things;network interface controller;server (computing);throughput	Yuma Sakakibara;Shin Morishima;Kohei Nakamura;Hiroki Matsutani	2018	IEICE Transactions		field-programmable gate array;artificial intelligence;computer vision;parallel computing;computer science;cache;blockchain;internet of things	DB	-5.7744421358217775	65.08626634259181	197210
f241ecd80cf46f2539ef261ea8448888ea1d8796	energy conserving multiple data access in wireless data broadcast environments	energy conservation;tiempo espera;acceso multiple;methode globale locale;evaluation performance;air index;partition method;acces multiple;performance evaluation;telecommunication sans fil;evaluacion prestacion;simulation;simulacion;temps attente;wireless communication;miniaturisation;methode partition;telecomunicacion sin hilo;waiting time;conservation energie;diffusion donnee;difusion dato;data access;conservacion energetica;broadcast system;global local method;metodo particion;miniaturization;data broadcast;miniaturizacion;multiple access;wireless data;metodo global local;data retrieval;wireless telecommunication	This letter proposes a group-based distributed air index (called GDI) using two-leveled groups by partitioning the identifiers of data items to reduce the size of the index. GDI provides both global and local views of data items and multiple pointers to data items in a single access to an index. Simulation results show that GDI outperforms the existing index in terms of multiple data access, energy conservation and data waiting time.	broadcasting (networking);data access	SeokJin Im;MoonBae Song;Sang-Won Kang;Jongwan Kim;Chong-Sun Hwang;SangKeun Lee	2007	IEICE Transactions	10.1093/ietcom/e90-b.9.2629	data access;energy conservation;telecommunications;computer science;miniaturization;computer security;data retrieval;wireless	Mobile	-14.385914008668713	68.98752502948739	197340
3c89bb9cbdeca12d821411a5fbae7fd1662bae7b	message reordering for the reuse of can-based legacy applications in a time-triggered architecture	automotive engineering;protocols;time triggered;fault tolerant;telecommunication network reliability;application software;cost reduction;distributed computing;computer architecture;application software computer architecture protocols automotive engineering telecommunication network reliability bandwidth real time systems distributed computing computer network reliability costs;time triggered architecture;present day;bandwidth;failure rate;hard real time;computer network reliability;real time systems	While CAN is the most widely used communication protocol in present day distributed automotive computer systems, time-triggered architecture will provide the ability to handle the communication needs of future by-wire cars. In addition to hard real-time performance, time-triggered architectures help in managing the complexity of faulttolerance and corresponding formal dependability models, as required for the establishment of ultra-high reliability (failure rates in the order of 10-9 failures/hour). Virtual CAN networks on top of a time-triggered communication protocol are a solution to integrate existing CAN-based legacy applications into such a time-triggered architecture. Thus, there is the possibility to eliminate physical CAN networks, which leads to cost reductions and reliability improvements. In order to ensure that existing CAN-based software works correctly in a time-triggered architecture, a virtual CAN network must provide the temporal behavior of a physical CAN network. For this reason, we develop a solution for establishing in a virtual CAN network the same temporal message order as in a physical CAN network. We present a CAN protocol emulation algorithm and provide validation results based on an implementation in the Time- Triggered Architecture.	algorithm;communications protocol;dependability;emulator;legacy system;real-time computing;real-time transcription;time-triggered architecture	Roman Obermaisser	2006	12th IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS'06)	10.1109/RTAS.2006.28	reference architecture;embedded system;communications protocol;fault tolerance;application software;real-time computing;computer science;operating system;failure rate;distributed computing;bandwidth	Embedded	-6.7472655560516825	69.84702374872836	197439
e668595d6cdb5b23cf717def47158fdccec6dcaa	a framework of n-screen services based on pvr and named data networking in cloud computing	personal video recording pvr;multimedia contents;n screen;named data networking ndn;cloud computing	"""We develop architecture of a new N-Screen Service which enables application streaming based on N-Screen services using Personal Video Recorder (PVR) and Named Data Networking (NDN) in cloud computing environment. In particular, we propose a framework of N-Screen Services called """"ShopMark"""" based on PVR and NDN technology in cloud computing environment. This service will be provided to user with playback method for their previously recorded multimedia contents which was combined with Advertisement. The user will be able to playback/re-play their multimedia contents, interact with the advertisement and choose their interesting advertised product by scenes. The objective of proposing ShopMark service based on PVR and NDN are to (1) allow user to playback previously recorded multimedia contents anytime with diversity of devices for screen sharing, (2) user are able to easily track and select advertised products in multimedia contents by scenes (e.g. movies scenes, etc), (3) reduce the requested content delay, provide sufficient use of bandwidth and resources (4) overcome limitation of multimedia content and provide efficient approach for content distribution in network and (5) obtain more knowledge and understanding of application NDN. This service will provide an excellent example to show how NDN can offer advantages for the multimedia contents distribution over the internet and provide more space for the development of new other N-Screen services/applications which rely on multimedia contents distribution instead of communication."""	anytime algorithm;application streaming;cloud computing;digital distribution;digital video recorder;remote desktop software	Aymen Abdullah Alsaffar;Eui-nam Huh	2013		10.1145/2448556.2448656	embedded system;cloud computing;telecommunications;computer science;operating system;database;multimedia;internet privacy;world wide web;computer security;computer network	HPC	-17.408897834940124	74.27893821284127	197567
0f6fd0ccdadff33103bb4f6403d5a6dca21b4604	enabling live video streaming services realization in telecommunication networks using p2p technology	content distribution;live video streaming;ims;p2p systems	Peer-to-peer (P2P) systems enjoy wide adoption from internet users. Success of P2P architecture is due to its ability to scale and organize dynamically the traffic according to the user resources and requests. However, P2P adoption is constrained in non-real time applications, like content distribution and file sharing. The major reason behind this fact is the inability of P2P to deliver content within user-desired bit rates by making optimal use of network resources. In this paper we focus on the solution and implementation of technical problems toward a complete system implementation that delivers live multimedia streaming through P2P architecture by the use of IMS. The content indexing and discovery, the scalable management and the distributed optimization of the graph that connects participating peers, the distributed scheduling mechanisms for data exchange, a scalable monitoring architecture and a bandwidth control mechanism constitute the major components toward a complete scalable multimedia streaming system offering streaming stability and high performance. Copyright 2011 John Wiley & Sons, Ltd.	algorithm;bandwidth management;content discovery platform;digital distribution;download;file sharing;forwarding plane;john d. wiley;locality of reference;mathematical optimization;network architecture;peer-to-peer;quality of service;real-time clock;scalability;scheduling (computing);streaming media;upload	Nikolaos Efthymiopoulos;Spyridon L. Tompros;Athanasios Christakidis;Konstantinos Koutsopoulos;Spyros G. Denazis	2011	Int. J. Communication Systems	10.1002/dac.1250	real-time computing;telecommunications;computer science;operating system;multimedia;world wide web;ip multimedia subsystem;computer security;computer network	HPC	-15.913555613280012	73.9619289543207	197633
ee01f719c4091ae7a7103375af58832ef1de23a0	routega: a grid load balancing algorithm with genetic support	resource allocation genetic algorithms grid computing;heterogeneous computing;resource allocation;genetics;grid load balancing algorithm;genetic algorithm routega grid load balancing algorithm;load management application software concurrent computing genetic algorithms grid computing scheduling algorithm data mining machine learning algorithms distributed computing computer networks;genetic algorithm;genetic algorithms;load balance;grid computing;routega;parallel applications;knowledge base	Motivated by the first process allocation limitations of the original Route load balancing algorithm, this paper presents RouteGA (Route with Genetic Algorithm support) which considers historical information about parallel application executions in order to optimize the first scheduling. This information is extracted by using monitors and summarized in a knowledge base used to quantify process occupation at the launch moment. Such occupation is used to parameterize a genetic algorithm responsible for optimizing the process allocation on heterogeneous computing environments such as Grids. Results confirm RouteGA over- performs the original Route, which had previously overper-formed others from literature.	genetic algorithm;grid computing;heterogeneous computing;knowledge base;load balancing (computing);scheduling (computing)	Rodrigo Fernandes de Mello;Jose Augusto Andrade Filho;Luciano José Senger;Laurence Tianruo Yang	2007	21st International Conference on Advanced Information Networking and Applications (AINA '07)	10.1109/AINA.2007.125	distributed algorithm;knowledge base;parallel computing;genetic algorithm;cultural algorithm;computer science;artificial intelligence;theoretical computer science;distributed computing;parallel algorithm;grid computing;population-based incremental learning	HPC	-16.85626660990572	62.39502249426756	197735
13e0d7083b38931d2c04decfb7e533f4af8e5857	dragonfly: cloud assisted peer-to-peer architecture for multipoint media streaming applications	multipoint media streaming;edge cloud dragonfly architecture cloud assisted peer to peer architecture multipoint media streaming applications technology trends software applications cloud computing cloud deployment user interactions realtime continuous media streams multiuser streaming media p2p architecture media delivery system 2 tier edge cloud peer to peer dynamic overlays streaming session management planetlab user level p2p overlay;hybrid architecture multipoint media streaming cloud computing peer to peer systems p2p cloud multicast live streaming geometric routing;peer to peer systems;geometric routing;p2p cloud;media streaming;hybrid architecture;peer to peer computing;peer to peer computing cloud computing media streaming;streaming media peer to peer computing bandwidth media computer architecture maintenance engineering cloud computing;live streaming;multicast;cloud computing	Technology trends are not only transforming the hardware landscape of end-user devices but are also dramatically changing the types of software applications that are deployed on these devices. With the maturity of cloud computing during the past few years, users increasingly rely on networked applications that are deployed in the cloud. In particular, new applications will emerge where user interactions will be based on real-time continuous media streams instead of the traditional request-response types of interfaces. Furthermore, many of these applications will be multi-user streaming media based interactions instead of a single user interaction with an application. In this paper, we propose a geographic location-aware, hybrid, scalable cloud assisted peer-to-peer (P2P) architecture to support such applications that targets low administration cost, reduced bandwidth consumption, low latency, low initial investment cost and optimized resource usage. The main objective is to develop an efficient media delivery system that leverages locality. We propose a 3-layer novel architecture that uses at the core the cloud for application management, 2-tier edge cloud for supporting geo-dispersed user groups, and at the lowest level peer-to-peer dynamic overlays for locally clustered user groups. The proposed architecture manages multiple streaming sessions simultaneously and each streaming session is an independent entity. Our experiments on PlanetLab show that the dynamic construction and maintenance of delivering streams at both the user-level P2P overlay and edge cloud are indeed feasible and effective.	application lifecycle management;cns;capability maturity model;client–server model;cloud computing;experiment;fairness measure;geographic coordinate system;geographic routing;ibm notes;interaction;locality of reference;location awareness;multi-user;multicast;multipoint ground;peer-to-peer;planetlab;real-time transcription;request–response;scalability;streaming media;testbed;user space	Erdinc Korpeoglu;Cetin Sahin;Divyakant Agrawal;Amr El Abbadi;Takeo Hosomi;Yoshiki Seo	2013	2013 IEEE Sixth International Conference on Cloud Computing	10.1109/CLOUD.2013.60	multicast;cloud computing;computer science;operating system;cloud testing;distributed computing;world wide web;computer network	HPC	-17.779727787343564	73.57151566251036	197934
ab427b4741294a2cb380f91765c48ae207b5d86d	cluster based peers configuration using hcnp in peer-to-peer overlay networks	hierarchical clustering;topology;physical parameters;protocols;heterogeneous cluster;workstation clusters peer to peer computing protocols;p2p;peers physical resources;network topology;capability level;accuracy;hcnp;data structures;peer to peer computing protocols data structures topology network topology accuracy clustering algorithms;heterogeneous based newscast protocol;overlay network;clustering algorithms;cluster identifier;workstation clusters;nonhierarchical cluster based approach;peer to peer computing;newscast protocol;peer to peer overlay networks;cluster identifier newscast protocol capability level heterogeneity physical parameters;heterogeneous based newscast protocol cluster based peers configuration hcnp peer to peer overlay networks peers physical resources nonhierarchical cluster based approach;heterogeneity;cluster based peers configuration	The paper addresses the need of efficient collaboration of peers with different levels of heterogeneity in order to share resources in p2p overlay networks. Here the heterogeneity reflects differences in peers physical resources like free storage space, processor speed etc. A non-hierarchical cluster-based approach has been introduced to make the network comprising of heterogeneous nodes, more efficient and scalable. NP (newscast protocol) has been used to generate the nodes (peers) randomly in the network, where nodes also maintain the properties of its neighboring nodes in a cache associated to each node. NP has proved to be the most efficient protocol to maintain the current state of the network. In this paper a heterogeneous cluster-based NP (HCNP) has been introduced, which, not only preserves the properties of NP, but also configures clusters on the basis of changes in physical parameters of the node at any particular time instant.	clock rate;computer cluster;np (complexity);overlay network;peer-to-peer;randomness;scalability	Irum Kazmi;Saira Aslam;M. Y. Javed	2010	2010 2nd International Conference on Computational Intelligence, Communication Systems and Networks	10.1109/CICSyN.2010.30	communications protocol;overlay network;data structure;computer science;heterogeneity;machine learning;peer-to-peer;database;distributed computing;hierarchical clustering;accuracy and precision;cluster analysis;network topology;computer network	HPC	-13.12491504174211	72.71735258589135	198126
9756999b7bf0ba3f1005ae90190c8d1f2aed0957	multi-agent based network management task decomposition and scheduling	multi agent systems internet computer network management dynamic scheduling;multiagent system;agent based;agent scheduling;processor scheduling;satisfiability;technology management;large scale;multi agent systems;internet;task decomposition;engineering management;computer network management;intelligent agent;ip networks;network management;computer science;task scheduling;large scale network;environmental management;agent scheduling multiagent system network management task decomposition task scheduling internet large scale network dynamic scheduling;large scale systems;dynamic scheduling;computer network management environmental management large scale systems processor scheduling intelligent agent ip networks technology management computer science engineering management dynamic scheduling	The rapid development of Internet makes network management on large-scale network a critical issue. But with the management task of large-scale network becoming more complicated, neither centralized network management nor agent based network management can satisfy the increasing demands. This paper presents a network management framework to support dynamic scheduling decisions. In this framework, some algorithms are proposed to decompose the whole network management task into several groups of sub-tasks. During the course of decomposition, different priorities are assigned to sub-tasks. Then based on the priorities of these sub-tasks, the strategies of agent scheduling are established. Priority-ranked sub-tasks are grouped according to their inter-dependences. Sub-tasks with the same priority are put into the same group and they can be performed in parallel manner, while different groups of sub-tasks with different priorities must be implemented according to the order of their priorities. An experiment has been done with the algorithms, the results of which demonstrate the advantage of the algorithms.	agent-based model;algorithm;centralized computing;entity;inter-process communication;internet;multi-agent system;multitier architecture;scalability;scheduling (computing)	Bo Liu;Junzhou Luo;Wei Li	2005	19th International Conference on Advanced Information Networking and Applications (AINA'05) Volume 1 (AINA papers)	10.1109/AINA.2005.254	network management;real-time computing;the internet;simulation;dynamic priority scheduling;computer science;artificial intelligence;technology management;network simulation;distributed computing;intelligent agent;satisfiability	HPC	-16.531756714682274	63.84030719348817	198129
09939432d34bf447bf84a18426afd8e6915cd576	atm connection and traffic management schemes for multimedia internetworking	teletrafic;microprocessor;tecnologia electronica telecomunicaciones;base donnee repartie;red local;distributed database;computacion informatica;multimedia;real time;gestion trafic;base repartida dato;grupo de excelencia;telecommunication network;traffic management;transmision asincronica;local network;teletrafico;grande vitesse;ciencias basicas y experimentales;red telecomunicacion;conexion;almacenamiento;temps reel;raccordement;reseau telecommunication;stockage;teletraffic;gestion trafico;tiempo real;asynchronous transmission;transmission asynchrone;gran velocidad;microprocesseur;tecnologias;reseau local;connection;microprocesador;storage;high speed	The rapid advances being made in microprocessor technology have stimulated significant interest in distributed multimedia applications supported by high-speed networks. Examples of distributed multimedia applications include multimedia database retrieval, distributed multimedia documents, and video mail. Due to the large amount of multimedia traffic for audio/visual applications, these applications require high speed networks to retrieve data in real time, instead of huge local disk storage	atm turbo;internetworking	Atsushi Iwata;N. Mori;Chinatsu Ikeda;Hiroshi Suzuki;Maximilian Ott	1995	Commun. ACM	10.1145/204826.204846	local area network;embedded system;active traffic management;real-time computing;telecommunications;connection;computer science;asynchronous communication;law;distributed database;wireless multimedia extensions;telecommunications network	Networks	-12.607403525020768	70.15486970107187	198134
c0c7e8da5fdd74d7e21bf74d6916c16f73c59c91	data recovery after geographic correlated attacks	computational geometry geographic correlated attack distributed storage network hardware fault hardware failure data availability geographically correlated failure information location redundancy scheme data recovery;reliability engineering;computational modeling distributed databases redundancy reliability engineering encoding shape;redundancy computational geometry computer network reliability computer network security;computational modeling;redundancy;shape;distributed databases;encoding	In distributed storage networks, ensuring data availability in the presence of hardware faults is an important requirement. Typically, redundancy schemes such as replication and erasure coding are used to ensure this. In case of hardware failures, these networks may be disconnected into multiple components, each of which may require access to the data. In addition, the placement of redundant information must also be optimized as it is ever-changing and requires constant updating. We study the problem of selecting a set of nodes in networks of this kind so that data availability is maintained in the face of geographically correlated failures. We model failure events of arbitrary shapes as the union of disks or line segments in the plane and present approximation algorithms for the problem of selecting a minimum number of redundant information locations (such as replicas or coded file segments) so that data recovery is guaranteed at every node in the face of any failure event. Using tools from computational geometry, our algorithms are efficient and provide good guarantees.	approximation algorithm;clustered file system;computation;computational geometry;computer hardware;data recovery;erasure code;replication (computing)	Guy Grebla;Alon Efrat;Esther Ezra;Rom Pinchasi;Swaminathan Sankararaman	2015	2015 11th International Conference on the Design of Reliable Communication Networks (DRCN)	10.1109/DRCN.2015.7148986	reliability engineering;real-time computing;shape;computer science;theoretical computer science;distributed computing;redundancy;computational model;distributed database;encoding;computer network	DB	-10.059772509736593	72.38241890510278	198708
e1455372d1e67a6af2b05294728f6b1af380783a	caching under content freshness constraints		Several real-time delay-sensitive applications pose varying degrees of freshness demands on the requested content. The performance of cache replacement policies that are agnostic to these demands is likely to be sub-optimal. Motivated by this concern, in this paper, we study caching policies under a request arrival process which incorporates user freshness demands. We consider the performance metric to be the steady-state cache hit probability. We first provide a universal upper bound on the performance of any caching policy. We then analytically obtain the content-wise hit-rates for the Least Popular (LP) policy and provide sufficient conditions for the asymptotic optimality of cache performance under this policy. Next, we obtain an accurate approximation for the LRU hit-rates in the regime of large content population. To this end, we map the characteristic time of a content in the LRU policy to the classical Coupon Collector’s Problem and show that it sharply concentrates around its mean. Further, we develop modified versions of these policies which eject cache redundancies present in the form of stale contents. Finally, we propose a new policy which outperforms the above policies by explicitly using freshness specifications of user requests to prioritize among the cached contents. We corroborate our analytical insights with extensive simulations. Index Terms Sensor networks, freshness, hit-rate, Zipf’s law, characteristic time, Coupon Collector’s Problem, concentration bound, LRU.	approximation;asymptotically optimal algorithm;broadcast delay;cpu cache;cache (computing);real-time clock;replay attack;simulation;steady state;zipf's law	Pawan Poojary;Sharayu Moharir;Krishna P. Jagannathan	2017	CoRR		computer science;computer network;cache;distributed computing;coupon collector's problem;performance metric;population;upper and lower bounds	Metrics	-13.128261996580289	68.04242697407093	199399
ab4ec72b32d8de5213b48e4e77e3c41a9f6c7e4c	scampi: a scalable and programmable architecture for monitoring gigabit networks	estensibilidad;parallelisme;distributed system;architecture systeme;systeme reparti;network monitoring;surveillance;high speed networks;resource control;resource management;gestion recursos;software architecture;parallelism;vigilancia;sistema repartido;paralelismo;monitoring;present day;gestion ressources;arquitectura sistema;extensibilite;scalability;monitorage;system architecture;monitoreo;architecture logiciel;policy management	Effective network monitoring is vital for the growing number of control and management applications typically found in present-day networks. Increasing link speeds and the diversity of monitoring applications’ needs have exposed severe limitations of existing monitoring techniques. As a response, the EU IST SCAMPI project designs and implements a scalable and programmable architecture for monitoring multi-gigabit networks. The SCAMPI architecture has an expressive programming interface, uses intelligent hardware, provides user policy management and resource control, and achieves scalability through parallelism. This paper addresses the problems with current high-speed network monitoring and presents the system architecture and components of the SCAMPI platform.	application programming interface;backward compatibility;experiment;gigabit;packet analyzer;parallel computing;scalability;standard cmmi appraisal method for process improvement;systems architecture;winpcap	Jan Coppens;Steven Van den Berghe;Herbert Bos;Evangelos P. Markatos;Filip De Turck;Arne Øslebø;Sven Ubik	2003		10.1007/978-3-540-39404-4_36	embedded system;software architecture;real-time computing;scalability;telecommunications;computer science;resource management;operating system;network monitoring	HPC	-5.889340969154691	73.09318354233018	199581
8875745d67911ea943ec805dc09ab46a5a299b99	cloud task scheduling based on swarm intelligence and machine learning		Cloud computing is the expansion of parallel computing, distributed computing. The technology of cloud computing becomes more and more widely used, and one of the fundamental issues in this cloud environment is related to task scheduling. However, scheduling in Cloud environments represents a difficult issue since it is basically NP-complete. Thus, many variants based on approximation techniques, especially those inspired by Swarm Intelligence (SI) have been proposed. This paper proposes a machine learning algorithm to guide the cloud choose the scheduling technique by using multi criteria decision to optimize the performance. The main contribution of our work is to minimize the makespan of a given task set. The new strategy is simulated using the CloudSim toolkit package where the impact of the algorithm is checked with different numbers of VMs varying from 2 to 50, and different task sizes between 30 bytes and 2700 bytes. Experiment results show that the proposed algorithm minimizes the execution time and the makespan between 7% and 75%, and improves the performance of the load balancing scheduling.	abc;approximation;artificial neural network;byte;central processing unit;cloud computing;cloudsim;decision tree;distributed computing;experiment;k-nearest neighbors algorithm;load (computing);load balancing (computing);machine learning;makespan;mathematical optimization;multi-label classification;np-completeness;parallel computing;particle swarm optimization;quality of service;random-access memory;run time (program lifecycle phase);schedule (project management);scheduling (computing);swarm intelligence	Gaith Rjoub;Jamal Bentahar	2017	2017 IEEE 5th International Conference on Future Internet of Things and Cloud (FiCloud)	10.1109/FiCloud.2017.52	swarm intelligence;job shop scheduling;cloudsim;cloud computing;scheduling (computing);real-time computing;machine learning;load balancing (computing);load management;computer science;particle swarm optimization;artificial intelligence;distributed computing	HPC	-18.62717115598159	63.24681601314589	199719
e1b10cd6e935bd46c37c02633f6c3976d41adead	grid dependent tasks security scheduling model and dpso algorithm	dependent tasks scheduling;dpso;security model;grid computing	Due to   the security threat to task scheduling problems in the grid environment, by considering both the inherent security and behavior safety of grid resource nodes, security benefit functions and credibility assessment strategies of grid resource nodes are constructed respectively. At the same time, the corresponding membership function is established in order to establish the membership between task security requirements and resource security attributes. Based on these, a new grid dependent tasks security scheduling model is set up. In order to solve this model, the particle evolution equation is re-designed by combining the specific characteristics of the dependent task scheduling problem. Meanwhile, in order to prevent the algorithm falling into local optimum, a uniform speed of disturbance is adopted and a new discrete Particle Swarm Optimization algorithm is proposed. Simulation results show that this algorithm has better scheduling length and higher safety performance   than     the   genetic algorithm.	algorithm	Hai Zhu;Yuping Wang;Zhanxin Ma;Hecheng Li	2011	JNW	10.4304/jnw.6.6.850-857	computer security model;fair-share scheduling;real-time computing;simulation;dynamic priority scheduling;computer science;rate-monotonic scheduling;distributed computing;computer security;grid computing	EDA	-16.88081205059388	63.00318924652213	199734
b60f297c4613fb9f1711604027a91f60f94550bc	neural networks for the design of distributed, fault-tolerant, computing environments	database system;optimisation;fault tolerant;neural networks;neural nets;optimisation distributed processing fault tolerant computing neural nets;distributed processing;resource management;distributed computing;simulated annealing;binary optimisation models;design optimization;computer networks;fault tolerant computing;hopfield neural networks;fault tolerant systems;system design;neural networks fault tolerance computer networks distributed computing fault tolerant systems resource management simulated annealing design optimization shape control hopfield neural networks;fault tolerance;optimum allocation binary optimisation models system design distributed systems fault tolerant computing task allocation file assignment modeling partitioning algorithm;optimum allocation;file assignment modeling;partitioning algorithm;shape control;distributed systems;optimization model;task allocation;neural network	Binary optimization models for the design of distributed, fault-tolerant computing systems are considered, with a focus on the task allocation and file assignment modeling schema proposed by J. Bannister and K. Trivedi (Proc. Second Symp. on Reliability in Distributed Software and Database Systems, 1982). It is shown that R. Graham's (1969) partitioning algorithm, S, when applied to this schema can, in the case of finite resources, yield allocations that are arbitrarily poor with respect to the optimum allocation. This contrasts sharply with the case of ample resources, where S provides allocations that are provably close to the optimum. Two alternative allocation algorithms are suggested. Both are seen to deliver allocations preferable to those provided by S, but at some additional computational expense. >	neural networks	Robert Geist;Darrell Suggs	1992		10.1109/RELDIS.1992.235127	fault tolerance;real-time computing;computer science;theoretical computer science;distributed computing;artificial neural network	HPC	-15.443179405279201	66.06461543742756	199771
d90ae82e887eb16e0c531131f5dbe78b6d1981b5	improving the availability of scalable on-demand streams by dynamic buffering on p2p networks	streaming;video on demand;dynamic buffering;multiple description coding;p2p networks;peer to peer	In peer-to-peer (P2P) on-demand streaming networks, the alleviation of server load depends on reciprocal stream sharing among peers. In general, on-demand video services enable clients to watch videos from beginning to end. As long as clients are able to buffer the initial part of the video they are watching, on-demand service can provide access to the video to the next clients who request to watch it. Therefore, the key challenge is how to keep the initial part of a video in a peer's buffer for as long as possible, and thus maximize the availability of a video for stream relay. In addition, to address the issues of delivering data on lossy network and providing scalable quality of services for clients, the adoption of multiple description coding (MDC) has been proven as a feasible resolution by much research work. In this paper, we propose a novel caching scheme for P2P on-demand streaming, called Dynamic Buffering. The proposed Dynamic Buffering relies on the feature of MDC to gradually reduce the number of cached descriptions held in a client's buffers, once the buffer is full. Preserving as many initial parts of descriptions in the buffer as possible, instead of losing them all at one time, effectively extends peers’ service time. In addition, this study proposes a description distribution balancing scheme to further improve the use of resources. Simulation experiments show that Dynamic Buffering can make efficient use of cache space, reduce server bandwidth consumption, and increase the number of peers being served.	peer-to-peer;streams	Chow-Sing Lin	2010	TIIS	10.3837/tiis.2010.08.003	real-time computing;computer science;multiple description coding;world wide web;computer network	Metrics	-16.160715855617912	74.182429428721	199938
87d3013483871b9fb96b47b2502d9b2b6090d0d7	splitquest: controlled and exhaustive search in peer-to-peer networks	unnecessary query replication;query duplication;exhaustive search;low response time;query routing;query propagation;peer-to-peer network;replication group;query resolution;high level;high churn rate;low overhead	This paper presents SplitQuest, a controlled and exhaustive search protocol that relies on a hybrid network structure to avoid unnecessary query replication and to speed up query propagation in P2P networks. In SplitQuest, peers are organized in replication groups, in which each peer shares its contents with all members, and queries are propagated only once to a group. By avoiding query duplication, directing queries to disjoint groups, and exploiting peers’ heterogeneity, SplitQuest is able to achieve high levels of recalls and low response times, while incurring very low overhead. We simulate SplitQuest using synthetic and traces of real-world topologies and show that it outperforms the best known solution in number of messages, response time, number of hops, and success rate for query resolution, while being resilient to high churn rates. We also derive upper bounds on query routing for SplitQuest.	brute-force search;overhead (computing);peer-to-peer;replication (computing);response time (technology);routing;simulation;software propagation;synthetic intelligence;tracing (software)	Pericles Lopes;Ronaldo A. Ferreira	2010			sargable;query optimization;real-time computing;theoretical computer science;database;distributed computing;computer network	Web+IR	-11.524577104946049	73.098959697097	199963
