id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
64b0e4343c0f3153a2d835bde7642f0dca5f9ae3	retrieval of video story units by markov entropy rate	motion pictures;tv broadcasting;availability;hidden markov model;information retrieval;prototypes;video retrieval;markov entropy rate;layout;video story units retrieval;expressed visual concepts;indexes;visualization;entropy hidden markov models information retrieval layout indexing motion pictures visual databases prototypes tv broadcasting availability;computational modeling;hidden markov models;indexing;indexation;story structures;entropy rate;hidden markov model hmm;entropy;lsu;video retrieval entropy hidden markov models;semantic relations;markov entropy rate video retrieval logical story units lsu hidden markov model hmm;logical story units lsu;structural similarity;hidden markov models video story units retrieval markov entropy rate story structures expressed visual concepts;visual databases	In this paper we propose a method to retrieve video stories from a database. Given a sample story unit, i.e., a series of contiguous and semantically related shots, the most similar clips are retrieved and ranked. Similarity is evaluated on the story structures, and it depends on the number of expressed visual concepts and the pattern in which they appear inside the story. Hidden Markov models are used to represent story units, and Markov entropy rate is adopted as a compact index for evaluating structure similarity. The effectiveness of the proposed approach is demonstrated on a large video set from different kinds of programmes, and results are evaluated by a developed prototype system for story unit retrieval.	database;entropy rate;hidden markov model;markov chain;prototype	Sergio Benini;Pierangelo Migliorati;Riccardo Leonardi	2008	2008 International Workshop on Content-Based Multimedia Indexing	10.1109/CBMI.2008.4564925	layout;database index;availability;search engine indexing;entropy;speech recognition;visualization;computer science;structural similarity;machine learning;pattern recognition;prototype;computational model;world wide web;entropy rate;hidden markov model;statistics	Vision	-13.718588198530767	-55.97461643686063	52467
fa3041fbd9a3d37c61a2a19b7bf2a9812c824cc2	collaborative data mining for clinical trial analytics		This paper proposes a collaborative data mining technique to provide multi-level analysis from clinical trials data. Clinical trials for clinical research and drug development generate large amount of data. Due to dispersed nature of clinical trial data, it remains a challenge to harness this data for analytics. In this paper, we propose a novel method using master data management (MDM) for analyzing clinical trial data, scattered across multiple databases, through collaborative data mining. Our aim is to validate findings by collaboratively utilizing multiple data mining techniques such as classification, clustering, and association rule mining. We complement our results with the help of interactive visualizations. The paper also demonstrates use of data stratification for identifying disparities between various subgroups of clinical trial participants. Overall, our approach aims at extracting useful knowledge from clinical trial data in order to improve design of clinical trials by gaining confidence in the outcomes using multi-level analysis. We provide experimental results in drug abuse clinical trial data.	association rule learning;cluster analysis;data mining;database;interactive visualization;master data management;multilevel model;secondary source;stratified sampling	Vandana Pursnani Janeja;Jay Gholap;Prathamesh Walkikar;Yelena Yesha;Naphtali Rishe;Michael A. Grasso	2015	2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.3233/IDA-173440	text mining;interactive visualization;computer science;bioinformatics;data science;clinical trial;data mining;world wide web	DB	-7.159178316134915	-62.22534275010592	52507
74720c7d531daa9f3a8ccf52ad13f56bef24580e	virtual explorer	virtual explorer	Students navigate through the bloodstream, the lymph system, and infected tissue of a patient, performing the assigned tasks and functions of the immune system from various first-person points of view, and enhancing their integrated understanding of its complex processes. The virtual environment simulates the viewscreen of a nanobot that has been injected into a human body. It includes detailed, biologically accurate models of cells and proteins of the immune system and bloodstream, which are rendered in real-time during the simulation.	biological neuron model;nanorobotics;real-time computing;real-time transcription;simulation;virtual reality	Kevin Dean	1997		10.1145/259081.259200	computer vision;computer graphics (images);artificial intelligence;computer science	Visualization	-8.522832790759825	-56.38481597403221	52737
8b652ec427ec6093f05bd533a346ad3900013185	towards automatic classification of learning objects: reducing the number of used features		The automatic classification of LOs into different categories enables us to search for, access, and reuse them in an effective and efficient way. Following this idea, in this paper, we focus specifically on how to automatically recommend the classification attribute of the IEEE LOM when a user adds a new LO to a repository. To do it, we propose the use of the multi-label classification approach, since each LO might be simultaneously associated with multiple labels. An initial problem we have found is that the number of terms or pure text features that characterize LOs tends to be very high. So, we propose to apply a dimensionality reduction process. We have carried out an experiment using 515 LOs from the AGORA repository in order to try to reduce the number of features or attributes used, improving execution time without losing prediction accuracy.	agora;dimensionality reduction;multi-label classification;run time (program lifecycle phase)	Cristóbal Romero;Pedro G. Espejo;Eva Lucrecia Gibaja Galindo;Alfredo Zapata;Víctor Hugo Menéndez-Domínguez	2017			machine learning;artificial intelligence;computer science	Vision	-18.003987583759862	-61.63229255231123	52874
97ca681fba5f0996bbc5740a5cdcf168896e399b	semantic indexing of multimedia content using audio, text and visual cues	visual cues	"""ABSTRACT In this paper we describe methods for automatic labeling of high - level semantic concepts in documentary style videos The empha - sis  of  this  paper  is  on  audio  processing  and  on  fusing  informa - tion from multiple modalities The work described represents ini - tial work towards a trainable system that acquires a collection of generic """"intermediate"""" semantic concepts across modalities (such as audio, video, text) and combines information from these modal - ities for  automatic  labeling of  a """"high - level""""  concept Initial  re - sults  suggest  that  multi - modal  fusion  achieves  a  12 5%  relative improvement over the best unimodal model"""	sound card	Giridharan Iyengar;Harriet J. Nock;Chalapathy Neti	2002			sensory cue;multimedia;information retrieval;search engine indexing;computer science	HCI	-15.811564884712396	-59.52666610292562	53427
3ba7d346734c32624615e6d57a8ddf3068959a8c	email answering assistance by semi-supervised text classification	unlabeled data;customer service;support vector classifier;text classification;frequently asked questions;support vector machine;training algorithm	Many individuals, organizations, and companies have to answer large amounts of emails. Often, many of these emails contain variations of relatively few frequently asked questions. We address the problem of predicting which of several frequently used answers a user will choose to respond to an email. We map the problem to a semi-supervised text classification problem. In a case study with emails that have been sent to a corporate customer service department, we investigate the ability of the naive Bayesian and support vector classifier to identify the appropriate answers to emails. We study how effectively the transductive Support Vector Machine and the co-training algorithm utilize unlabeled data and investigate why co-training is only beneficial when very few labeled data are available. In addition, we describe a practical assistance system.	algorithm;co-training;document classification;email;semi-supervised learning;semiconductor industry;support vector machine	Tobias Scheffer	2004	Intell. Data Anal.		support vector machine;computer science;machine learning;pattern recognition;data mining;world wide web	ML	-18.78783571025746	-65.53258540139555	53507
715832bfb78c8819edbf5ba93f0907cbada327d7	dynamite extended: two new services to simplify protein dynamic analysis	spectrometrie rmn;proteine;visualizacion;protein dynamics;estructura;molecular dynamics;bioinformatique;dynamique moleculaire;visualization;visualisation;nmr spectrometry;proteina;bioinformatica;dinamica molecular;espectrometria rmn;protein;structure;bioinformatics	We describe two additional services now available as part of the previously described Dynamite protein dynamics web service. Dynatraj provides principle component analysis and visualization of modes of motion for a user's own ensemble of protein structures, e.g. from Molecular Dynamics, NMR or experimental ensembles. Dynapocket predicts probable configurations of a protein pocket from a single known structure. Both have been provided in response to requests from users for additional functionality from the Dynamite server. Like Dynamite, both are available free of charge to all users.	dynamite;imagery;molecular dynamics;principal component analysis;probability;server (computer);server (computing);staphylococcal protein a;web service	C. Paul Barrett;Martin E. M. Noble	2005	Bioinformatics	10.1093/bioinformatics/bti464	molecular dynamics;visualization;computer science;bioinformatics	Comp.	-5.495938097759244	-57.90175606550314	54385
2522fd2345112b91319a40638458e28d0ce9f86f	pattern browsing and query adjustment for the exploratory analysis and cooperative visualisation of microarray time-course data	qh natural history;time course;cooperative visualisation;exploratory analysis;combined multiple views;time series;multiple views;data analysis;microarray data analysis;bioinformatics	This paper presents work to support collaborative visualisation and data analysis in the microarray time-series explorer (MaTSE) software. We introduce a novel visualisation component called the ‘pattern browser’ which is used to support the annotation and adjustment of user queries. This includes an explanation of why this component is required and how it can be used with our online pattern repository by biologists collaborating in the analysis of a microarray time-course data set. To conclude we suggest which other types of collaborative visualisation would benefit from the introduction of a component with comparable functionality.	browsing;exploratory testing;microarray;time series	Paul Craig;Alan Cannon;Jessie B. Kennedy;Robert Kukla	2010		10.1007/978-3-642-16066-0_30	microarray analysis techniques;computer science;bioinformatics;data science;time series;data mining;database;data analysis	HCI	-5.580083302791843	-59.917961046508985	54980
111ccb406a68d3fa898d65e059d1c8dab71f26d6	expression analysis in the wild: from individual to groups	keywords active field;search engines expression analysis in the wild;group mood analysis;expression analysis;facial expression analysis;conference paper;image browsing;stepping stone;real world;human facial expressions;expression analysis in the wild	With the advances in the computer vision in the past few years, analysis of human facial expressions has gained attention. Facial expression analysis is now an active field of research for over two decades now. However, still there are a lot of questions unanswered. This project will explore and devise algorithms and techniques for facial expression analysis in practical environments. Methods will also be developed for inferring the emotion of a group of people. The central hypothesis of the project is that close to real-world data can be extracted from movies and facial expression analysis on movies is a stepping stone for moving to analysis in the real-world. For the analysis of groups of people various attributes effect the perception of mood. A system which can classify the mood of a group of people in videos will be developed and will be used to solve the problem of efficient image browsing and retrieval based on emotion.	algorithm;computer vision;image viewer;stepping level	Abhinav Dhall	2013		10.1145/2461466.2461529	computer vision;artificial intelligence;multimedia	Vision	-16.223161369070052	-52.898070262955564	55023
1d0e66943f15ef789ec0b0d0dc37617635d76eab	imagilar: a real-time image similarity search system on mobile platform	2614 theoretical computer science;1700 computer science	With the rapid development of mobile intelligent devices and wireless communications, users are gradually changing the way of consuming interesting content from the traditional personal computers to smart phones. Hence, we introduce a brand-new content-based image similarity search system which runs on mobile platform in real time. This paper outlines the system which has several novel components, including multi-feature composition, multi-feature indexing, and customized user interface with auxiliary Web data display.	real-time transcription;similarity search	Bicheng Luo;Zi Xuan Huang;HongYun Cai;Yang Yang	2013		10.1007/978-3-642-41154-0_47	mobile search;mobile web;human–computer interaction;computer science;distributed computing;multimedia;world wide web;computer security	Robotics	-16.05205765498251	-54.991120601305944	55151
e937af2179b672c20ce5b573c6d261e07b7c80ef	improvement of commercial boundary detection using audiovisual features	top down method;methode descendante;modelizacion;television;caption;audiovisual;multimedia;edge detection;sous titrage;top down;musica;extraction forme;subtitulo;audiovisual equipment;deteccion contorno;domain knowledge;modelisation;detection contour;musique;senal video;signal video;extraccion forma;audiovisuel;metodo descendente;video signal;equipement audiovisuel;boundary detection;discriminacion;modeling;equipo audiovisual;music;pattern extraction;discrimination	Detection of commercials in TV videos is difficult because the diversity of them puts up a high barrier to construct an appropriate model. In this work, we try to deal with this problem through a top-down approach. We take account of the domain knowledge of commercial production and extract features that describe the characteristics of commercials. According to the clues from speech-music discrimination, video scene detection, and caption detection, a multi-modal commercial detection scheme is proposed. Experimental results show good performance of the proposed scheme on detecting commercials in news and talk show programs.	experiment;modal logic;sensor;television;top-down and bottom-up design	Jun-Cheng Chen;Jen-Hao Yeh;Wei-Ta Chu;Jin-Hau Kuo;Ja-Ling Wu	2005		10.1007/11581772_68	computer vision;discrimination;speech recognition;edge detection;computer science;music;multimedia;television;law;domain knowledge	Vision	-11.88737829575443	-62.89950064607945	55201
bbc6407f763f9ea2684f921b7c680deba70c5d0f	the evogrid - a framework for distributed artificial chemistry cameo simulations supporting computational origins of life endeavors		The Evolution Grid, or EvoGrid is a computer simulatio n framework for distributed artificial chemistry (AC) supp orting computational origins of life (COoL) research. The Ev oGrid consists of a number of small experiments running on sho rt time scales pruned by aggressive tree-branching search es supported by random parametric re-seeding and temporal backtracking. The EvoGrid is designed to converge upon the observation of “cameo” simulations of key pre-biotic or simple biological structures or behaviors. These cameo simula tions can then inform and feed larger AC simulations operating over biologically relevant time scales. In addition, the framework is designed to plug into a heterogeneous set of engines ranging from high fidelity molecular dynamics (MD) to more ab stract AC techniques on the same set of data. The EvoGrid a lso provides shared web-based simulation management service s and uniform, open standards for execution, storage an d data analysis. We conclude by describing the first prototype implementation of the EvoGrid, early results, next ste p and open questions in this and other COoL endeavors.	artificial chemistry;backtracking;computation;computer simulation;converge;experiment;extended validation certificate;eyetoy;molecular dynamics;prototype;simula;web application;web-based simulation	Bruce Damer;Peter Newman;Richard Gordon;Tom Barbalet;David Deamer;Ryan Norkus	2010				HPC	-6.860836396629332	-57.888870877310396	55346
dd327e9beeb76597be5a2eeb1574f251d64cecfc	mobile video browsing and retrieval with the ovidius platform	mobile device;video browsing and search;video retrieval;video indexing;multimedia description schemes;video browsing;mpeg 7 standard;visual descriptors;mobile video	This paper describes a mobile video browsing and retrievalapproach, based on the so-called OVIDIUS (On-line VIDeo Indexing Universal System) platform. In contrast with traditional and commercial video retrieval platforms, where video content is treated in a more or less monolithic manner (i.e. with global descriptions associated with the whole document), the proposed approach makes it possible to browse and access video content in a finer, per-segment basis. The hierarchical metadata structure exploits the MPEG-7 approach for structural description of video content. The MPEG-7 description schemes have been here enriched with both semantic and content-based metadata. The developed approach shows all its pertinence within a multiterminal context and in particular for video access from mobile devices. The platform has been recently (February, 2010) validated within the framework of the Médi@TIC French national project.	browsing;digital video;mpeg-7;mobile device;multiseat configuration;relevance	Andrei Bursuc;Titus B. Zaharia;Françoise J. Prêteux	2010		10.1145/1873951.1874315	video compression picture types;microsoft video 1;computer vision;h.263;uncompressed video;computer science;operating system;video tracking;visual descriptors;mobile device;multimedia;video processing;smacker video;internet privacy;world wide web;multiview video coding;non-linear editing system	Vision	-15.044770263727395	-55.64336851257831	56363
cae14245b6ca276d1fedd3b597f52c44593be791	beyond audio and video retrieval: topic-oriented multimedia summarization	video retrieval	Given the deluge of multimedia content that is becoming available over the Internet, it is increasingly important to be able to effectively examine and organize these large stores of information in ways that go beyond browsing or collaborative filtering. In this paper, we review previous work on audio and video processing, and define the task of topic-oriented multimedia summarization (TOMS) using natural language generation (NLG): given a set of automatically extracted features from a video, a TOMS system will automatically generate a paragraph of natural language, which summarizes the important information in a video belonging to a certain topic, and for example provides explanations for why a video was matched and retrieved. Possible features include visual semantic concepts, objects, and actions, environmental sounds, and transcripts from automatic speech recognition (ASR). We see this as a first step towards systems that will be able to discriminate visually similar, but semantically different videos, compare two videos and provide textual output or summarize a large number of videos at once. In this paper, we introduce our approach of solving the TOMS problem. We extract various visual concept features, environmental sounds and ASR transcription features from a given video, and develop a template-based NLG system to produce a textual recounting based on the extracted features. We also propose possible experimental designs for continuously evaluating and improving TOMS systems, and present results of a pilot evaluation of our initial system.	automatic summarization;baseline (configuration management);collaborative filtering;crowdsourcing;design of experiments;experiment;information;iterative method;medline;medical transcription;multimedia framework;natural language generation;speech recognition;text-based (computing);transcription (software);usability testing;video processing	Florian Metze;Duo Ding;Ehsan Younessian;Alexander G. Hauptmann	2012	International Journal of Multimedia Information Retrieval	10.1007/s13735-012-0028-y	computer vision;computer science;data mining;database;multimedia;world wide web;information retrieval	NLP	-17.525747311244835	-56.26047170618099	56370
9015e9b41e864292b05e0a16cfd40580456f0b34	a personal video summarization system by integrating rfid and gps information for marathon activities	conferences consumer electronics;consumer electronics;video signal processing global positioning system radiofrequency identification;personal video summarization system meta data video clip searching program video pre processing program video summary system gps rfid;sports video summary personal video;conferences	This paper presents a video summary system that generates an interesting personal video efficiently in marathon activities. First, a video pre-processing program uploads captured videos into the cloud storage. Second, a video clip searching program identifies the personal video segments. Finally, all personal video segments are summarized with different special-effects in predefined scripts by the video post-processing program. Videos are segmented in seconds and managed by meta-data, and human assisted requirement is low for cutting and editing videos. This system severs over 200,000 people in two marathon activities, and the evaluation results show that our system achieves a high experience satisfaction.	cloud storage;global positioning system;marathon;preprocessor;radio-frequency identification;upload;video clip;video post-processing	Chih-Chung Kao;Chi-Wen Lo;Kun-Hsien Lu	2015	2015 IEEE 5th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)	10.1109/ICCE-Berlin.2015.7391276	simulation;video production;computer science;video capture;video tracking;multimedia;video processing;smacker video;world wide web;non-linear editing system	Mobile	-14.831909644197223	-54.02730889980213	56388
9f83afb18710ebbac7f39dfa15c66a37a820b2f3	image annotation via graph learning	busqueda informacion;anotacion;metodo correlacion;evaluation performance;performance evaluation;image processing;learning;recherche image;correlation method;information retrieval;evaluacion prestacion;image understanding;graph learning;procesamiento imagen;annotation;image annotation;traitement image;journal;similitude;word correlation;aprendizaje;web image search;image interpretation;apprentissage;interpretacion imagen;recherche information;similarity;web search;interpretation image;similitud;methode correlation;image retrieval;image similarity	Image annotation has been an active research topic in recent years due to its potential impact on both image understanding and web image search. In this paper, we propose a graph learning framework for image annotation. First, the image-based graph learning is performed to obtain the candidate annotations for each image. In order to capture the complex distribution of image data, we propose a Nearest Spanning Chain (NSC) method to construct the image-based graph, whose edge-weights are derived from the chain-wise statistical information instead of the traditional pairwise similarities. Second, the word-based graph learning is developed to refine the relationships between images and words to get final annotations for each image. To enrich the representation of the word-based graph, we design two types of word correlations based on web search results besides the word co-occurrence in the training set. The effectiveness of the proposed solution is demonstrated from the experiments on the Corel dataset and a web image dataset.		Mingjing Li;Qingshan Liu;Hanqing Lu;Songde Ma	2009	Pattern Recognition	10.1016/j.patcog.2008.04.012	computer vision;similarity;image processing;image retrieval;computer science;similitude;pattern recognition;mathematics;automatic image annotation;information retrieval	Vision	-13.774830440370716	-61.25449257588839	56444
00e45ef46a7fa76d934990b1482b6944851ee75b	dissimilarity representation of images for relevance feedback in content-based image retrieval	busqueda informacion;analisis contenido;contenu image;image content;base donnee;recherche image;image databank;information retrieval;interrogation base donnee;image database;database;pertinencia;interrogacion base datos;base dato;content analysis;recherche information;pertinence;banco imagen;banque image;retroaction pertinence;relevance;analyse contenu;content based image retrieval;contenido imagen;relevance feedback;content based retrieval;database query;recherche par contenu;image retrieval	Relevance feedback mechanisms are adopted to refine image-based queries by asking users to mark the set of retrieved images as being relevant or not. In this paper, a relevance feedback technique based on the “dissimilarity representation” of images is proposed. Each image is represented by a vector whose components are the similarity values between the image itself and a “representation set” made up of the images retrieved so far. A relevance score is then assigned to each image according to its distances from the sets of relevant and non-relevant images. Three techniques to compute such relevance scores are described. Reported results on three image databases show that the proposed relevance feedback mechanism allows attaining large improvements in retrieval precision after each retrieval iteration. It also outperforms other techniques proposed in the literature.	algorithm;computational complexity theory;content-based image retrieval;database;experiment;heuristic (computer science);iteration;microsoft windows 98;operating system;performance;relevance feedback;response time (technology);vector graphics	Giorgio Giacinto;Fabio Roli	2003		10.1007/3-540-45065-3_18	computer vision;relevance;content analysis;image retrieval;computer science;data mining;database;information retrieval	Web+IR	-12.573506681888027	-60.21897409999613	56458
4800d01364cf833c6e70a864fc44f86e6809e615	semantic pooling for complex event detection	multimedia event representation;semantic pooling;complex event detection	"""Complex event detection is very challenging in open source such as You-Tube videos, which usually comprise very diverse visual contents involving various object, scene and action concepts. Not all of them, however, are relevant to the event. In other words, a video may contain a lot of """"junk"""" information which is harmful for recognition. Hence, we propose a semantic pooling approach to tackle this issue. Unlike the conventional pooling over the entire video or specific spatial regions of a video, we employ a discriminative approach to acquire abstract semantic """"regions"""" for pooling. For this purpose, we first associate low-level visual words with semantic concepts via their co-occurrence relationship. We then pool the low-level features separately according to their semantic information. The proposed semantic pooling strategy also provides a new mechanism for incorporating semantic concepts for low-level feature based event recognition. We evaluate our approach on TRECVID MED [1] dataset and the results show that semantic pooling consistently improves the performance compared with conventional pooling strategies."""	debian-med;high- and low-level;open-source software	Qian Yu;Jingen Liu;Hui Cheng;Ajay Divakaran;Harpreet S. Sawhney	2013		10.1145/2502081.2502191	semantic similarity;semantic computing;computer science;pattern recognition;data mining;information retrieval	Vision	-15.24623892794975	-60.40410950215688	56533
9c5b17f01dcb82302d616b2a25b62439bb5506fd	a novel video annotation framework using near-duplicate segment detection	databases;web video analysis video annotation automatic annotation near duplicate segment detection;web video analysis video annotation framework near duplicate segment detection keyframe extraction keyword distribution;semantics;semantics motion segmentation visualization feature extraction databases youtube redundancy;visualization;motion segmentation;youtube;redundancy;video signal processing feature extraction internet;feature extraction;automatic annotation;near duplicate segment detection;proceedings paper;video annotation;web video analysis	The traditional video annotation approaches focus on annotating keyframes, shots, or the whole video with semantic keywords. However, the extractions of keyframes and shots lack of semantic meanings, and it is hard to use a few keywords to describe a video by using multiple topics. Therefore, we propose a novel video annotation framework using near-duplicate segment detection not only to preserve but also to purify the semantic meanings of target annotation units. A hierarchical near-duplicate segment detection method is proposed to efficiently localize near-duplicate segments in frame-level. Videos containing near-duplicate segments are clustered and keyword distributions of clusters are analyzed. Finally, the keywords ranked according to keyword distribution scores are annotated onto the obtained annotation units. Comprehensive experiments demonstrate the effectiveness of the proposed video annotation framework and near-duplicate segment detection method.	experiment;key frame;purify	Chien-Li Chou;Hua-Tsung Chen;Chun-Chieh Hsu;Suh-Yin Lee	2015	2015 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)	10.1109/ICMEW.2015.7169854	visualization;feature extraction;computer science;semantics;multimedia;redundancy;world wide web;information retrieval	Vision	-14.67403348747749	-56.04695212112309	57031
259b1341564bf9c9f98b4add9b1a129118ef4f32	a user’s commentary on fiswidgets		computing environment for neuroimaging data analysis that involves the construction of graphical interfaces for existing software packages and tools. Two independent groups are targeted as users of this software resource: developers of new software tools for neuroimaging data analysis and end users who use image processing software to analyze data for publication. This commentary provides a perspective on the strengths and weaknesses of the Fiswidgets software as perceived by users within my neuroimaging research laboratory. We have served as beta testers of the software for the past two years, and some of the Fiswidgets developers also provide computer system administration support for my laboratory. All fourteen members of the laboratory involved in neuroimaging studies use the software, which has been used to analyze the data for two published papers, and six papers currently in preparation or review. In general, we have found the claims made by Fissell et al. (2002) to be well supported. Particular strengths of the Fiswidgets environment are its ease of use, its flexibility and commitment to multiple analysis packages and tools, and its capacity to support automatic and iterative execution of a complex processing sequence. A significant factor in the adoption of any new neuroimaging software is the ease by which it can be used. One of the biggest advantages to the Fiswidgets environment is the rapid learning curve demonstrated by new users. A few hours of one-on-one training with another experienced user in the laboratory, coupled with access to a “how-to” manual generated for use within the laboratory, can provide a new user with enough knowledge to complete a set of basic processing steps for a single subject (e.g., image reconstruction, detrending, baseline normalization, etc.). This is made possible by the use of graphical interfaces to the underlying processing software; most users with only rudimentary Unix or command-scripting skills can operate very proficiently within a Windows-like environment. Additionally, it is possible to save and recall stored processing sequences via the	baseline (configuration management);cns disorder;computation (action);fourteen;graphical user interface;image processing;iteration;iterative reconstruction;linc;learning disorders;list of neuroimaging software;microsoft windows;paper;published comment;scientific publication;system administrator;unix;usability;weakness	Julie A. Fiez	2003	Neuroinformatics	10.1385/NI:1:1:127		SE	-9.395508543971225	-54.82683810248601	57226
555001f32681d36c56fd175c5ba85ba2c8656523	optical structure recognition application entry to clef-ip 2012		We present our entry to CLEF 2012 Chemical Structure Recognition task. Our submission includes runs for both bounding box extraction and molecule structure recognition tasks using Optical Structure Recognition Application. OSRA is an open source utility to convert images of chemical structures to connection tables into established computerized molecular formats. It has been under constant development since 2007.	minimum bounding box;open-source software	Igor V. Filippov;Dmitry Katsubo;Marc C. Nicklaus	2012			chemical structure;theoretical computer science;clef;minimum bounding box;computer science	Robotics	-7.0619926905770285	-63.236697231885174	57290
96d886121273073cba9258c8f60ec5bb1a4c3664	complex event processing for object tracking in wireless sensor networks	intrusion cep wireless sensor network semantic query;intrusion;sensor systems;query processing;semantic query processing wireless sensor networks object tracking complex event processing multilevel architecture pattern identification voluminous streams object detection intruder detection;real time;wireless sensor networks object detection query processing security of data;semantic query;engines wireless sensor networks radiofrequency identification real time systems servers sensor systems;emerging technology;wireless sensor network;intruder detection;servers;engines;cep;semantic query processing;object tracking;complex event processing;voluminous streams;multilevel architecture;security of data;wireless sensor networks;radiofrequency identification;object detection;pattern identification;real time systems	Complex Event Processing (CEP) is a relatively new, but got wider acceptability due to its systematic and multi level architecture driven concept approach. CEP is an emerging technology for processing and identifying patterns of interest from multiple streams of events. CEP is used in development of applications which have to deal with voluminous streams of incoming data with the task of finding meaningful events or patterns of events, and respond to the events of interest in real time. In this paper a CEP based application for object detection and tracking in a Wireless Sensor Network (WSN) environment is proposed. Also the detection of an intruder using semantic query processing is proposed.	complex event processing;database;intrusion detection system;multi-storey car park;object detection;semantic query;streaming media	R. Bhargavi;Vijay Vaidehi;P. T. V. Bhuvaneswari;P. Balamurali;M. Girish Chandra	2010	2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2010.70	real-time computing;wireless sensor network;computer science;complex event processing;database;distributed computing	Robotics	-8.85958873906081	-63.617555069568	57634
0d0df133b3af8504687ca1b42cb24b1c55450734	combining p-plan and the reproduce-me ontology to achieve semantic enrichment of scientific experiments using interactive notebooks		End-to-end reproducibility of scientific experiments requires scientists to share their experimental data along with the computational environment. Interactive notebooks have recently gained widespread popularity among scientists because they allow users to document their experiments along with the code, visualize the results inline and selectively execute the code. In a multi-user environment where users can run and modify the shared notebooks, it becomes essential to capture the provenance of notebooks along with the experiments which used them. In this paper, we propose a way to capture provenance of these interactive notebooks and convert them into semantic descriptions so that a user can query the difference between the results, steps, errors and the execution environment of the code. We use the REPRODUCE-ME ontology extended from PROV-O and P-Plan to describe the provenance of notebook execution. We evaluate our prototype in a multi-user environment provided by JupyterHub.	experiment;gene ontology term enrichment;multi-user;prototype;user interface	Sheeba Samuel;Birgitta König-Ries	2018		10.1007/978-3-319-98192-5_24	data mining;experimental data;information retrieval;ontology;computer science	Web+IR	-6.644059796843891	-58.83603336789767	57835
562e92078ea5b2579d7c34ec4726827965ef8c82	semantic analysis for video contents extraction - spotting by association in news nideo	content extraction;batching;digital library;video analysis;video segmentation;near video on demand;natural language;partially patient customers;video server throughput;quasi video on demand;semantic analysis	Spotting by Association method for video analysis is a novel method to detect video segments with typical semantics. Video data contains various kinds of information through continuous images, natural language, and sound. For videos to be stored and retrieved in a Digital Library, it is essential to segment the video data into meaningful pieces. To detect meaningful segments, we need to identify the segment in each modality (video, language, and sound) that corresponds to the same story. For this purpose, we propose a new method for making correspondences between image clues detected by image analysis and language clues detected by natural language analysis. As a result, relevant video segments with su cient information from every modality are obtained. We applied our method to closed-captioned CNN Headline News. Video segments with important events, such as a public speech, meeting, or visit, are detected fairly well.	digital library;experiment;image analysis;modality (human–computer interaction);natural language;video content analysis;visit	Yuichi Nakamura;Takeo Kanade	1997		10.1145/266180.266391	video compression picture types;microsoft video 1;digital library;h.263;uncompressed video;computer science;video quality;video capture;video tracking;multimedia;video processing;smacker video;internet privacy;natural language;world wide web;pevq;multiview video coding;non-linear editing system	Vision	-15.223766679618878	-54.561302549223775	57952
6565a40c4cb88caa889e7e8c99d3851aad21f074	proposal for an integrated video analysis framework	proposals data mining feature extraction layout indexing information retrieval performance analysis algorithm design and analysis telecommunications data analysis;off line applications integrated video analysis framework objects descriptive characteristics multimedia applications automatic tools user guidance performance segmentation feature extraction modules semantic criteria;image recognition;object recognition;image segmentation;video signal processing;video analysis;image recognition feature extraction image segmentation video signal processing object recognition;video segmentation;multimedia application;feature extraction;user interaction;semantic analysis	The analysis of video data targeting the identification of relevant objects and the extraction of associated descriptive characteristics will be the enabling factor for a number of multimedia applications. This process has intrinsic difficulties, and since semantic criteria are difficult to express, usually only a part of the desired analysis results can be automatically achieved. For many applications, the automatic tools can be complemented with user guidance to improve performance. This paper proposes an integrated framework for video analysis, addressing the video segmentation and feature extraction problems. The framework includes a set of modules that can be combined following specific application needs. It includes both automatic (more objective) and user interaction (more semantic) analysis modules. The paper also proposes a specific segmentation solution to one of the most relevant application scenarios considered off-line applications requiring precise segmentation.	feature extraction;online and offline;video content analysis	Paulo Lobato Correia;Fernando da Cruz Pereira	1998		10.1109/ICIP.1998.723436	computer vision;feature extraction;computer science;cognitive neuroscience of visual object recognition;segmentation-based object categorization;video tracking;data mining;image segmentation;scale-space segmentation;information retrieval	Vision	-13.028576680144134	-55.514989944982176	58299
86dc975f9cbd9a205f8e82fb1db3b61c6b738fa5	large-scale concept ontology for multimedia	broadcast news;broadcast news video large scale concept ontology multimedia large standardized taxonomy;lscom;video signal processing;vocabulary;large scale concept ontology for multimedia;semantics;standardized taxonomy;ontologies artificial intelligence;multimedia computing;large scale;video data sets;large scale systems ontologies digital multimedia broadcasting multimedia communication tagging vocabulary collaboration libraries taxonomy design optimization;multimedia communication;standardized taxonomy lscom large scale concept ontology for multimedia automated extraction semantics video data sets broadcast news;semantic space;vocabulary multimedia computing ontologies artificial intelligence video signal processing;automated extraction	As increasingly powerful techniques emerge for machine tagging multimedia content, it becomes ever more important to standardize the underlying vocabularies. Doing so provides interoperability and lets the multimedia community focus ongoing research on a well-defined set of semantics. This paper describes a collaborative effort of multimedia researchers, library scientists, and end users to develop a large standardized taxonomy for describing broadcast news video. The large-scale concept ontology for multimedia (LSCOM) is the first of its kind designed to simultaneously optimize utility to facilitate end-user access, cover a large semantic space, make automated extraction feasible, and increase observability in diverse broadcast news video data sets	interoperability;library science;taxonomy (general);vocabulary	Milind R. Naphade;John R. Smith;Jelena Tesic;Shih-Fu Chang;Winston H. Hsu;Lyndon S. Kennedy;Alexander G. Hauptmann;Jon Curtis	2006	IEEE MultiMedia	10.1109/MMUL.2006.63	computer science;semantics;multimedia;world wide web;information retrieval	DB	-16.410067804197492	-55.664668518242955	58660
686f0315954a3c76a097c33fb8819c188850c51a	two-phase schema matching in real world relational databases	databases;documentation based matcher;training schema;machine learning technique;neural networks;availability;interconnected systems;training;controller area networks;relational database;operations research;data mining;relational databases learning artificial intelligence pattern matching;schema matching;training data;internet;machine learning;voting;voting combiner;pattern matching;relational databases voting internet database systems informatics training data ontologies machine learning neural networks availability;database systems;ontologies;informatics;relational databases;learning artificial intelligence;indium;documentation;documentation based matcher two phase relational schema matching relational database voting combiner training schema machine learning technique;arsenic;cleaning;beryllium;two phase relational schema matching	"""We propose a new approach to the problem of schema matching in relational databases that merges the hybrid and composite approach of combining multiple individual matching techniques. In particular, we propose assigning individual matchers to two categories, """"strong"""" matchers that provide a priori higher quality matches, and """"weak"""" matchers that may be more sensitive to the inputs and are less reliable but can still help generate some matches. Matching is correspondingly done in two phases, with strong """"matches"""" being produced by strong matchers being combined using a simple voting combiner, and weak matchers providing additional evidence for attributes left unmatched (again using a voting combiner). We observe that, while many recent advances in schema matching (Madhavan et al., 2005) use composite schema matching and rely on the existence of training schemas to train combiners, in many real-world situations it is not feasible to employ learning techniques because of the unavailability of training data (i.e., schemas or instance data.) We hypothesize that """"weak"""" matchers can often hurt overall accuracy if used in a """"single-phase"""" composite matcher that does not employ learning techniques. We implement our two-stage approach in the ASED system and evaluate it using real life schemas. The experiments validate our hypothesis regarding the negative effect of """"weak"""" matchers and also show ASID performs comparably to state of the art systems while requiring no training schemas. We also demonstrate the benefits of a simple documentation-based matcher. Our experimental data included schemas ranging from 20 to 120 attributes. Note that schemas with 120 attributes are as large or larger than other published evaluations of relational schema matching."""	diplexer;dirty data;documentation;experiment;field (computer science);plasma cleaning;real life;relational database;two-phase locking;unavailability;xml	Nick Bozovic;Vasilis Vassalos	2008	2008 IEEE 24th International Conference on Data Engineering Workshop	10.1109/ICDEW.2008.4498334	relational database;computer science;machine learning;data mining;database;artificial neural network	DB	-12.386618999370071	-64.88789440025377	58808
2aad49544fd486c1f38e60b461594b10d627c01f	co-occurrence of medical conditions: exposing patterns through probabilistic topic modeling			topic model	Moumita Bhattacharya;Claudine Jurkovitz;Hagit Shatkay	2018		10.1145/3233547.3233723	co-occurrence;topic model;machine learning;latent dirichlet allocation;probabilistic logic;jensen–shannon divergence;artificial intelligence;computer science;gibbs sampling	ML	-16.635528214081713	-64.13431885661628	58909
2b60be507fb669e87c78a0ee838035b8c416a34e	development of dna relational database and data manipulation experiments	dna;base relacional dato;base donnee;relation algebra;reaccion quimica;computer model;interrogation base donnee;database;interrogacion base datos;base dato;relational database;calcul analogique;data model;genome;base donnee relationnelle;dna computation;modele donnee;genoma;reaction chimique;chemical reaction;database query;calculo adn;data models;analog calculus;calculo analogico;calcul adn	An enormous amount of data such as genomic data can be stored into DNA molecules as base sequences. DNA database is important for organizing and maintaining these data, because extracted data from DNA database can be directly manipulated by chemical reactions. In this paper, we develop a DNA relational database with a simple data model and realize a computational model (relational algebra) of data manipulation as a sequence of chemical experiments. By using the developed database, it is shown that we can execute query operations based on the contents of data (the values of attributes). Furthermore, we propose a conversion scheme of query input to a series of experiment operations.	bioinformatics;computational model;dicom;dna computing;dna database;data model;database model;experiment;lambda calculus;organizing (structure);processor affinity;relational algebra;relational database management system;relational model;run time (program lifecycle phase);sql	Masahito Yamamoto;Yutaka Kita;Satoshi Kashiwamura;Atsushi Kameda;Azuma Ohuchi	2006		10.1007/11925903_33	computer simulation;data modeling;query optimization;relational model;chemical reaction;semi-structured model;database tuning;data model;relational database;computer science;probabilistic database;database model;data mining;relation algebra;database;change data capture;view;database schema;physical data model;dna;alias;algorithm;database design;genome	DB	-6.7215551586551925	-54.463941735251076	59354
009940aba18efabaaab1efb06845fc9b4470e2fa	on the exploitation of hidden markov models to improve location-based temporal segmentation of egocentric videos		Wearable cameras allow to easily acquire long and unstructured egocentric videos. In this context, temporal video segmentation methods can be useful to improve indexing, retrieval and summarization of such content. While past research investigated methods for temporal segmentation of egocentric videos according to different criteria (e.g., motion, location or appearance), many of them do not explicitly enforce any form of temporal coherence. Moreover, evaluations have been generally performed using frame-based measures, which only account for the overall correctness of predicted frames, overlooking the structure of the produced segmentation. In this paper, we investigate how a Hidden Markov Model based on an ad-hoc transition matrix can be exploited to obtain a more accurate segmentation from frame-based predictions in the context of location-based segmentation of egocentric videos. We introduce a segment-based evaluation measure which strongly penalizes over-segmented and under-segmented results. Experiments show that the exploitation of a Hidden Markov Model for temporal smoothing greatly improves temporal segmentation results and outperforms current video segmentation methods designed for both third-person and first-person videos.	coherence (physics);correctness (computer science);digital camera;experiment;frame language;hidden markov model;hoc (programming language);location-based service;markov chain;performance;smoothing;stochastic matrix	Antonino Furnari;Sebastiano Battiato;Giovanni Maria Farinella	2017		10.1145/3080538.3080539	automatic summarization;hidden markov model;computer vision;search engine indexing;segmentation-based object categorization;stochastic matrix;smoothing;scale-space segmentation;artificial intelligence;pattern recognition;geography;segmentation	Vision	-17.280916529602916	-58.76052689550303	59439
07c455da6e66f1d3b7a763eda870bf6c0860d8ef	easyalbum: an interactive photo annotation system based on face clustering and re-ranking	management system;digital camera;annotation;system performance;h 5 2 user interfaces;face recognition;photo tagging;graphic user interface;mobile phone cameras;face tagging;cluster annotation;information search and retrieval;interaction technique	"""Digital photo management is becoming indispensable for the explosively growing family photo albums due to the rapid popularization of digital cameras and mobile phone cameras. In an effective photo management system photo annotation is the most challenging task. In this paper, we develop several innovative interaction techniques for semi-automatic photo annotation. Compared with traditional annotation systems, our approach provides the following new features: """"cluster annotation"""" puts similar faces or photos with similar scene together, and enables user label them in one operation; """"contextual re-ranking"""" boosts the labeling productivity by guessing the user intention; """"ad hoc annotation"""" allows user label photos while they are browsing or searching, and improves system performance progressively through learning propagation. Our results show that these technologies provide a more user friendly interface for the annotation of person name, location, and event, and thus substantially improve the annotation performance especially for a large photo album."""	cluster analysis;digital camera;hoc (programming language);interaction technique;mobile phone;semiconductor industry;software propagation;usability	Jingyu Cui;Fang Wen;Rong Xiao;Yuandong Tian;Xiaoou Tang	2007		10.1145/1240624.1240684	facial recognition system;computer vision;human–computer interaction;image retrieval;computer science;digital photo frame;graphical user interface;management system;computer performance;multimedia;management;world wide web;interaction technique	HCI	-16.627786152224704	-55.42905423245079	59524
64473f5f6b1262a48a38639919822ac12893227d	incorporating concept ontology for hierarchical video classification, annotation, and visualization	content based video retrieval system;anotacion;correlacion;automatic video concept detection;ontologie;multimedia;high dimensionality;modele agrege;visualizacion;supervised learning;support vector machines;low level feature extraction;concept ontology;transmission error;recherche image;base donnee tres grande;intuitive query specification concept ontology hierarchical video classification video annotation video visualization content based video retrieval system low level feature extraction semantic gap automatic video concept detection semantic classification high dimensional heterogeneous feature space multimodal boosting algorithm feature hierarchy interlevel error transmission problem multitask learning hyperbolic visualization;interlevel error transmission problem;extraction forme;interrogation base donnee;apprentissage conceptuel;interrogacion base datos;semantics;bridges;modelo agregado;video retrieval;annotation;intelligence artificielle;error transmision;indexing terms;feature space;semantica;semantique;ontologies artificial intelligence;ontologies visualization boosting bridges content based retrieval feature extraction support vector machines support vector machine classification costs large scale systems;video coding;large scale;visualization;hierarchical classification;boosting;aprendizaje conceptual;senal video;signal video;video classification and annotation concept ontology hierarchical boosting hyperbolic visualization multimodal boosting multitask learning semantic gap;extraccion forma;intuitive query specification;visualisation;multimodal boosting algorithm;hierarchical boosting;feature extraction;video retrieval content based retrieval feature extraction learning artificial intelligence ontologies artificial intelligence signal classification video coding;machine exemple support;high dimensional heterogeneous feature space;semantic gap;signal classification;multimodal boosting;pattern recognition;classification hierarchique;concept learning	Most existing content-based video retrieval (CBVR) systems are now amenable to support automatic low-level feature extraction, but they still have limited effectiveness from a user's perspective because of the semantic gap. Automatic video concept detection via semantic classification is one promising solution to bridge the semantic gap. To speed up SVM video classifier training in high-dimensional heterogeneous feature space, a novel multimodal boosting algorithm is proposed by incorporating feature hierarchy and boosting to reduce both the training cost and the size of training samples significantly. To avoid the inter-level error transmission problem, a novel hierarchical boosting scheme is proposed by incorporating concept ontology and multitask learning to boost hierarchical video classifier training through exploiting the strong correlations between the video concepts. To bridge the semantic gap between the available video concepts and the users' real needs, a novel hyperbolic visualization framework is seamlessly incorporated to enable intuitive query specification and evaluation by acquainting the users with a good global view of large-scale video collections. Our experiments in one specific domain of surgery education videos have also provided very convincing results.	algorithm;archive;boosting (machine learning);computational complexity theory;computer multitasking;emoticon;experiment;feature extraction;feature selection;feature vector;high- and low-level;machine learning;multimodal interaction;ontology (information science)	Jianping Fan;Hangzai Luo;Yuli Gao;Ramesh Jain	2007	IEEE Transactions on Multimedia	10.1109/TMM.2007.900143	computer vision;concept learning;visualization;image retrieval;computer science;machine learning;video tracking;ontology;pattern recognition;semantics;supervised learning;world wide web	Vision	-13.126690505441744	-60.75066803767966	59800
ba6c19771926564e89be4ace7c33dc3da580249e	utilisation du contexte pour l'indexation sémantique des images et vidéos. (using context for semantic indexing of images and videos)		The automated indexing of image and video is a difficult problem because of the“distance” between the arrays of numbers encoding these documents and the concepts (e.g. people, places, events or objects) with which we wish to annotate them. Methods exist for this but their results are far from satisfactory in terms of generality and accuracy. Existing methods typically use a single set of such examples and consider it as uniform. This is not optimal because the same concept may appear in various contexts and its appearance may be very different depending upon these contexts. In this thesis, we considered the use of context for indexing multimedia documents. The context has been widely used in the state of the art to treat various problems. In our work, we use relationships between concepts as a source of semantic context. For the case of videos, we exploit the temporal context that models relationships between the shots of the same video. We propose several approaches using both types of context and their combination, in different levels of an indexing system. We also present the problem of multiple concept detection. We assume that it is related to the context use problematic. We consider that detecting simultaneously a set of concepts is equivalent to detecting one or more concepts forming the group in a context where the others are present. To do that, we studied and compared two types of approaches. All our proposals are generic and can be applied to any system for the detection of any concept. We evaluated our contributions on TRECVID and VOC collections, which are of international standards and recognized by the community. We achieved good results comparable to those of the best indexing systems evaluated in recent years in the evaluation campaigns cited previously.	best practice;sensor	Abdelkader Hamadi	2014				Vision	-15.500361774678774	-57.07284917330164	60210
6bcc80298b2367bd04294e0c83ce5beba21b1c1c	fouille de séquences d'images médicales. application en chirurgie mini-invasive augmentée. (content-based video medical retrieval for computer-aided eye surgery)				Mohammed Zakarya Droueche	2012				Vision	-10.168038631265429	-59.889072482863604	60311
e33c8a4c6b46c19397a9a51ed2e0dad8f07055ad	regularizing query-based retrieval scores	busqueda informacion;design principle;cluster;regularisation;information retrieval system;query processing;pseudo relevance feedback;document expansion;information retrieval;elargissement requete;cluster based retrieval;pertinencia;regularization;retroaccion;general methods;retroaction;recherche information;cluster hypothesis;pertinence;feedback regulation;traitement de la requete;regularizacion;tratamiento pregunta;relevance;query expansion;expansion busqueda	We adapt the cluster hypothesis for score-based information retrieval by claiming that closely related documents should have similar scores. Given a retrieval from an arbitrary system, we describe an algorithm which directly optimizes this objective by adjusting retrieval scores so that topically related documents receive similar scores. We refer to this process as score regularization. Because score regularization operates on retrieval scores, regardless of their origin, we can apply the technique to arbitrary initial retrieval rankings. Document rankings derived from regularized scores, when compared to rankings derived from un-regularized scores, consistently and significantly result in improved performance given a variety of baseline retrieval algorithms. We also present several proofs demonstrating that regularization generalizes methods such as pseudo-relevance feedback, document expansion, and cluster-based retrieval. Because of these strong empirical and theoretical results, we argue for the adoption of score regularization as general design principle or post-processing step for information retrieval systems.	algorithm;baseline (configuration management);black box;cluster hypothesis;holism;information retrieval;matrix regularization;relevance feedback;video post-processing;vocabulary	Fernando Díaz	2007	Information Retrieval	10.1007/s10791-007-9034-8	regularization;query expansion;relevance;computer science;machine learning;data mining;vector space model;information retrieval;cluster	Web+IR	-17.733373467558046	-63.444229614919365	60758
6be756d05f7ba9fbb2e7b951b817f0262fde1386	video classification and retrieval with the informedia digital video library system	video tracking;video retrieval;digital video library;image retrieval	This paper is organized in three parts. The first part details some of the lower level shot classification work, the second part describes the ‘manual’ retrieval systems while the last section details the interactive retrieval system for the Carnegie Mellon University TREC Video Retrieval Track runs. The description of the data can be found elsewhere in the proceedings of the 2002 TREC conference video track overview.	digital video;text retrieval conference	Alexander G. Hauptmann;Rong Yan;Yanjun Qi;Rong Jin;Michael G. Christel;Mark Derthick;Ming-yu Chen;Robert V. Baron;Wei-Hao Lin;Tobun Dorbin Ng	2002			visual word;video;uncompressed video;image retrieval;computer science;video capture;video tracking;video processing;smacker video;multiview video coding;non-linear editing system	Web+IR	-15.493844324181115	-56.12470782606385	60866
7a8acf349548c8390190eaddc464133932d5836f	neuron and python	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;python;computational neuroscience;uk phd theses thesis;life sciences;uk research reports;medical journals;simulation environment;europe pmc;biomedical research;bioinformatics	The NEURON simulation program now allows Python to be used, alone or in combination with NEURON's traditional Hoc interpreter. Adding Python to NEURON has the immediate benefit of making available a very extensive suite of analysis tools written for engineering and science. It also catalyzes NEURON software development by offering users a modern programming tool that is recognized for its flexibility and power to create and maintain complex programs. At the same time, nothing is lost because all existing models written in Hoc, including graphical user interface tools, continue to work without change and are also available within the Python context. An example of the benefits of Python availability is the use of the xml module in implementing NEURON's Import3D and CellBuild tools to read MorphML and NeuroML model specifications.	genus python (organism);graphical user interface;hoc (programming language);neuroml;neuron;programming tool;simulation;software development;specification;user interface device component;xml;benefit	Michael L. Hines;Andrew P. Davison;Eilif Müller	2009	Frontiers in Neuroinformatics	10.3389/neuro.11.001.2009	neuroscience;medicine;python;computer science;bioinformatics;data science;programming language;computational neuroscience	SE	-6.895888398253612	-59.2821610250718	60944
2538077537cc66f5b3dddd6ff7e95c61a00f1558	ch5m3d: an html5 program for creating 3d molecular structures	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	BACKGROUND While a number of programs and web-based applications are available for the interactive display of 3-dimensional molecular structures, few of these provide the ability to edit these structures. For this reason, we have developed a library written in JavaScript to allow for the simple creation of web-based applications that should run on any browser capable of rendering HTML5 web pages. While our primary interest in developing this application was for educational use, it may also prove useful to researchers who want a light-weight application for viewing and editing small molecular structures.   RESULTS Molecular compounds are drawn on the HTML5 Canvas element, with the JavaScript code making use of standard techniques to allow display of three-dimensional structures on a two-dimensional canvas. Information about the structure (bond lengths, bond angles, and dihedral angles) can be obtained using a mouse or other pointing device. Both atoms and bonds can be added or deleted, and rotation about bonds is allowed. Routines are provided to read structures either from the web server or from the user's computer, and creation of galleries of structures can be accomplished with only a few lines of code. Documentation and examples are provided to demonstrate how users can access all of the molecular information for creation of web pages with more advanced features.   CONCLUSIONS A light-weight (≈ 75 kb) JavaScript library has been made available that allows for the simple creation of web pages containing interactive 3-dimensional molecular structures. Although this library is designed to create web pages, a web server is not required. Installation on a web server is straightforward and does not require any server-side modules or special permissions. The ch5m3d.js library has been released under the GNU GPL version 3 open-source license and is available from http://sourceforge.net/projects/ch5m3d/.	canvas element;computer mouse;cryptography;documentation;ephrin type-b receptor 1, human;gnu;html5;javascript library;kilobyte;molecular structure;open-source license;open-source software;page (document);pointing device;r programming language;server (computer);server (computing);server-side;source lines of code;sourceforge;web application;web page;web server	Clarke W. Earley	2013		10.1186/1758-2946-5-46	biology;web modeling;medical research;medicine;computer science;bioinformatics;data science	Comp.	-4.80467922231191	-58.71405055217373	61377
10bc0e14430af6da9bc79b3b9ec982d9e1c0c923	a similarity-based approach for audiovisual document classification using temporal relation analysis	signal image and speech processing;biometrics;pattern recognition;image processing and computer vision;document classification	We propose a novel approach for video classification that bases on the analysis of the temporal relationships between the basic events in audiovisual documents. Starting from basic segmentation results, we define a new representation method that is called Temporal Relation Matrix (TRM). Each document is then described by a set of TRMs, the analysis of which makes events of a higher level stand out. This representation has been first designed to analyze any audiovisual document in order to find events that may well characterize its content and its structure. The aim of this work is to use this representation to compute a similarity measure between two documents. Approaches for audiovisual documents classification are presented and discussed. Experimentations are done on a set of 242 video documents and the results show the efficiency of our proposals.	cluster analysis;data mining;document classification;experiment;federal enterprise architecture;hierarchical clustering;high- and low-level;iterative method;naive bayes classifier;relevance;similarity measure;supervised learning	Zein Al Abidin Ibrahim;Isabelle Ferrané;Philippe Joly	2011	EURASIP J. Image and Video Processing	10.1155/2011/537372	computer vision;speech recognition;computer science;archaeology;pattern recognition;information retrieval;biometrics	Vision	-13.454037872664081	-58.769580609849804	61384
3490683560ca18d19884949dccca0ad7c98d4749	content-based filtering for video sharing social networks		In this paper we compare the use of several features in the task of content filtering for video social networks, a very challenging task, not only because the unwanted content is related to very high-level semantic concepts (e.g., pornography, violence, etc.) but also because videos from social networks are extremely assorted, preventing the use of constrained a priori information. We propose a simple method, able to combine diverse evidence, coming from different features and various video elements (entire video, shots, frames, keyframes, etc.). We evaluate our method in three social network applications, related to the detection of unwanted content — pornographic videos, violent videos, and videos posted to artificially manipulate popularity scores. Using challenging test databases, we show that this simple scheme is able to obtain good results, provided that adequate features are chosen. Moreover, we establish a representation using codebooks of spatiotemporal local descriptors as critical to the success of the method in all three contexts. This is consequential, since the state-of-the-art still relies heavily on static features for the tasks addressed.	anti-spam techniques;closing (morphology);codebook;color;content-control software;cutscene;database;experiment;high- and low-level;information source;interaction information;key frame;modality (human–computer interaction);multimodal interaction;social network;supervised learning	Eduardo Valle;Sandra Eliza Fontes de Avila;Antonio da Luz;Fillipe Dias Moreira de Souza;Marcelo de Miranda Coelho;Arnaldo de Albuquerque Araújo	2011	CoRR		computer vision;computer science;multimedia;internet privacy	Vision	-18.299877354485897	-55.288650423418126	61604
a0486b1de93124babdc00e4de44f8db94f30450f	automatic video annotation using multimodal dirichlet process mixture model	image sampling;multinomial distribution;automatic video annotation;web pages;video signal processing;markov chain automatic video annotation multimodal dirichlet process mixture model video data gaussian multinomial distribution visual track speech transcripts videos audio track predictive model blocked gibbs sampling algorithm;videos audio track;gibbs sampling;predictive models gaussian distribution sampling methods distributed computing data engineering data mining speech processing web pages statistical learning cameras;speech processing;distributed computing;data engineering;data mining;gaussian multinomial distribution;speech transcripts;statistical learning;blocked gibbs sampling algorithm;keyword extraction;video signal processing gaussian distribution image sampling markov processes;video annotation;multimodal dirichlet process mixture model;visual track;predictive models;dirichlet process mixture model;prediction model;markov processes;video data;sampling methods;visual tracking;gaussian distribution;cameras;predictive model;markov chain	In this paper we infer a multimodal Dirichlet process mixture model from video data, the mixture components in this model follow a Gaussian-multinomial distribution. The multimodal Dirichlet process mixture model clusters freely available multimodal data in videos i.e., the combination of visual track and the corresponding keywords extracted from speech transcripts obtained from the audio track of videos, using the parameters of the model we build a predictive model that can output keyword annotations given video shots. In the multimodal Dirichlet process mixture model the keywords follow a multinomial distribution while the features used to represent the video shot follow a Gaussian distribution. We infer the multimodal Dirichlet process mixture model by collecting samples from the corresponding Markov chain using a blocked Gibbs sampling algorithm, and use the inferred parameters to predict video shot annotations that can be used to perform text based retrieval of shots. We compare the performance of our proposed model with other baseline models that use predicted annotations for retrieval.	algorithm;baseline (configuration management);gibbs sampling;markov chain;mixture model;multimodal interaction;multinomial logistic regression;predictive modelling;sampling (signal processing);text-based (computing)	Atulya Velivelli;Thomas S. Huang	2008	2008 IEEE International Conference on Networking, Sensing and Control	10.1109/ICNSC.2008.4525431	speech recognition;computer science;machine learning;pattern recognition;speech processing;predictive modelling;statistics	Vision	-16.28909280162603	-62.77937563903982	61712
1247af6f8936e7687d74e97f4ce0879695b4be73	hashing forests for morphological search and retrieval in neuroscientific image databases		In this paper, for the first time, we propose a data-driven search and retrieval (hashing) technique for large neuron image databases. The presented method is established upon hashing forests, where multiple unsupervised random trees are used to encode neurons by parsing the neuromorphological feature space into balanced subspaces. We introduce an inverse coding formulation for retrieval of relevant neurons to effectively mitigate the need for pairwise comparisons across the database. Experimental validations show the superiority of our proposed technique over the state-of-the art methods, in terms of precision-recall trade off for a particular code size. This demonstrates the potential of this approach for effective morphology preserving encoding and retrieval in large neuron databases.	hash function	Sepideh Mesbah;Sailesh Conjeti;Ajayrama Kumaraswamy;Philipp L. Rautenberg;Nassir Navab;Amin Katouzian	2015		10.1007/978-3-319-24571-3_17	encoding (memory);code word;artificial intelligence;locality-sensitive hashing;computer science;coding (social sciences);pattern recognition;database;hash function;parsing;feature vector;pairwise comparison	Vision	-16.066988107879652	-65.20256872723252	61894
f0492028afaa4969708c831009cfb296144994c7	large scale image retrieval for location estimation		The geo-graphical location at which an image or video was taken is a key piece of multimedia information. Such geo-information has become an indispensable component of systems enabling personalized and context-aware multimedia services. The research reported in this thesis investigates how to automatically derive geo-information from multimedia content. In particular, it focuses on the challenge of estimating the geo-coordinates of the location of an image solely on the basis of its visual content. The goal of the research is to develop a scalable visual content-based location estimation system for images and to investigate the possibilities to improve its accuracy and reliability to a substantial extent. The system should be applicable in both the geo-constrained scenario, in which the multimedia item is taken at one of a previously defined set of locations, and the geo-unconstrained scenario, in which the multimedia item could have been taken anywhere in the world. The thesis makes two different kinds of contributions. The first is high-level framework design. We develop a generic large-scale image retrieval-based framework for location estimation. The second is optimization of specific components of the system. We develop two approaches, geometric verification and geo-distinctive visual element matching, that address specific challenges faced by our retrieval-based framework. The resulting system makes location estimation more tractable in case of large image collections, and also more reliable. Our experimental results demonstrate that the system leads to an overall significant improvement of the location estimation performance and redefines the state-of-the art in both geo-constrained and geo-unconstrained location estimation. Based on the findings presented in this thesis, we make recommendations for future research directions, which we think are substantial and promising for large scale image retrieval and geo-location estimation.	image retrieval	Xinchao Li	2016			image retrieval;scalability;data mining;information retrieval;computer science	Vision	-16.31482355439199	-57.38358217628194	62133
9208ecbd7244040ba6ee59a067b527c8b095fe0a	gaussian lda for topic models with word embeddings		Continuous space word embeddings learned from large, unstructured corpora have been shown to be effective at capturing semantic regularities in language. In this paper we replace LDA’s parameterization of “topics” as categorical distributions over opaque word types with multivariate Gaussian distributions on the embedding space. This encourages the model to group words that are a priori known to be semantically related into topics. To perform inference, we introduce a fast collapsed Gibbs sampling algorithm based on Cholesky decompositions of covariance matrices of the posterior predictive distributions. We further derive a scalable algorithm that draws samples from stale posterior predictive distributions and corrects them with a Metropolis–Hastings step. Using vectors learned from a domain-general corpus (English Wikipedia), we report results on two document collections (20-newsgroups and NIPS). Qualitatively, Gaussian LDA infers different (but still very sensible) topics relative to standard LDA. Quantitatively, our technique outperforms existing models at dealing with OOV words in held-out documents.	cholesky decomposition;gibbs sampling;local-density approximation;metropolis;metropolis–hastings algorithm;nips;natural language processing;prototype;sampling (signal processing);scalability;text corpus;unsupervised learning;wikipedia;word embedding	Rajarshi Das;Manzil Zaheer;Chris Dyer	2015			natural language processing;speech recognition	ML	-17.067562162806233	-64.08605323424362	62262
7d7672a49fbec0866f52cbd0d932e024121be89f	automated preparation of dna sequences for publication	dna;printing;computers;software;investigation method;information systems;methode etude;computerized processing;tratamiento informatico;amino acid sequence;automatisation;automatizacion;personality character;primary structure;estructura primaria;time factors;proteins;metodo estudio;tecnica;base sequence;dna sequence;traitement informatique;technique;structure primaire;automation	A computer program which draws DNA sequences is described. A simple method is used which enables the user to highlight or annotate specific parts of a sequence. The sizes of the characters in the sequence to be drawn are specified by the user. In addition, vertical spacing between lines and horizontal spacing between characters can be specified. Sequences can be prepared and high quality output produced on a plotter in a short period of time, making the program advantageous to use over typing, computer printing, or preparation by a graphics department.	computer program;display resolution;graphics;personality character;plotter device component;printer (computing);printing;spacing	M. B. Shapiro;P. Senapathy	1986	Nucleic acids research	10.1093/nar/14.1.65	biology;dna sequencing;automation;protein primary structure;peptide sequence;genetics;dna;information system	Graphics	-4.603030839937842	-56.56205149364047	62460
5b5c1a27fce2cf7fb70af21137cbc5df5ff7f175	ontology based image retrieval framework using qualitative semantic image descriptions	image retrieval	This research proposes an ontology based image retrieval framework from a corpus of natural scene images by imparting human cognition in the retrieval process. The proposed architecture addresses the issues of keyword based image retrieval and content-based image retrieval through the use of qualitative spatial representations over semantic image annotations. Domain ontology has been developed to model qualitative semantic image descriptions and retrieval, thereafter can be accomplished either using a natural language description of an image containing semantic concepts and spatial relations, or in a query by example fashion. A psychophysical evaluation has also been carried out to evaluate the effectiveness of our approach and results of different experiments are quite promising in terms of retrieval accuracy and relevance of retrieved images.	image retrieval	Sohail Sarwar;Zia Ul-Qayyum;Saqib Majeed	2013		10.1016/j.procs.2013.09.105	natural language processing;computer vision;visual word;image retrieval;computer science;automatic image annotation;information retrieval	Vision	-14.756578673108056	-58.862912327866475	62913
2ebed7d32d6ac47fd7cae01b61db90c6efc8885d	multi-stream viewer: simultaneous viewing system for streaming videos with the time tag	videos watches streaming media servers youtube media;video streaming;title information multistream viewer simultaneous viewing system time tag internet peripheral devices web services video broadcast service streaming youtube ustream tag information	As the Internet, computer technology, and peripheral devices continue to grow, web services for users are increasing, including such streaming video broadcast services as YouTube and Ustream that allow users to watch the streaming in which they are interested. In the current streaming video broadcast services, users search for streaming videos by title and tag information. However, since many streaming videos have insufficient information, they are often difficult to find. In addition, since only one streaming video can be watched in one browser, simultaneously comparing two or more streaming videos is difficult. In this research, we propose Multi-Stream Viewer as a simultaneous viewing system for streaming videos with tag information added to the time axis to enable users to watch streaming videos. We also implement and evaluate our proposed system.	apache axis;computer;internet;peripheral;streaming media;web service	Kazuki Nakamura;Ryo Tanigawa;Hideki Shimada;Kenya Sato	2013	2013 IEEE 10th Consumer Communications and Networking Conference (CCNC)	10.1109/CCNC.2013.6488513	real time streaming protocol;computer science;multimedia;internet privacy;world wide web	Mobile	-15.46191335739471	-53.98607768546681	62933
7b1aa242f059bd1fdb74ce4be5fabd6d7ee87f51	sar analyzer: a tool for interactive sar data visualization and navigation	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	The analysis of structure-activity relationships (SAR) is a central task in medicinal chemistry. The association between chemical structures of biologically active molecules and multiple property and assay data provides the basis for selection, optimization, and evaluation of potential drug candidate molecules. In an endeavour to facilitate the navigation of complex data landscapes and enable intuitive access to SAR information, an interactive SAR analysis platform is being developed at Roche. Focusing on information-rich data visualizations, we aim at supporting the medicinal chemists in their decision-making process, rather than making quantitative or qualitative predictions. The “SAR Analyzer” integrates cutting-edge visualization techniques and enhances them with key capabilities such as real-time interaction with the data, an intuitive user interface, and functionality to easily extract and navigate multi-property data. Here we show how two complementary approaches are integrated in the SAR Analyzer. The “SAR Map” visualization provides a holistic view of the distribution of molecular structures and properties in a data set [1]. Molecules are displayed in a 2D map projection based on chemical features or similarity. Color shading indicates the distribution of selected molecular properties or biological activity. By contrast, the “SAR Tree” visualization [2] focuses on subsets of similar compounds. Starting at a user-selected reference compound, all molecules within a similarity radius are organized in a hierarchical tree structure that makes it possible to interactively browse different compound series and derive and test SAR hypotheses. Both concepts depart from classical SAR data analysis and support scientific reasoning by making SAR information accessible in an intuitive visual way. Linking both approaches allows the analysis of SAR data on different levels of detail and helps to address questions that are relevant in different stages of a medicinal chemistry research project.	browsing;data visualization;endeavour (supercomputer);holism;interactivity;map projection;mathematical optimization;medicinal chemistry;real-time clock;shading;tree structure;user interface	Lisa Sach-Peltason;Daniel Stoffler	2012		10.1186/1758-2946-4-S1-P31	biology;medical research;medicine;computer science;bioinformatics;data science;data mining	Visualization	-6.180916539817902	-60.867085117589745	63404
b32ba120e309fa7b90d8cc144e279dce4ebda296	application of ai techniques to a voice-actuated computer system for reconstructing and displaying magnetic resonance imaging data	software;microelectromechanical systems;interfaces;computed tomography;computer graphics;magnetic resonance image;visualization;magnetic resonance imaging;computing systems;artificial intelligence;imaging systems	To provide a means of rendering complex computer architectures languages and input/output modalities transparent to experienced and inexperienced users research is being conducted to develop a voice driven/voice response computer graphics imaging system. The system will be used for reconstructing and displaying computed tomography and magnetic resonance imaging scan data. In conjunction with this study an artificial intelligence (Al) control strategy was developed to interface the voice components and support software to the computer graphics functions implemented on the Sun Microsystems 4/280 color graphics workstation. Based on generated text and converted renditions of verbal utterances by the user the Al control strategy determines the user''s intent and develops and validates a plan. The program type and parameters within the plan are used as input to the graphics system for reconstructing and displaying medical image data corresponding to that perceived intent. If the plan is not valid the control strategy queries the user for additional information. The control strategy operates in a conversation mode and vocally provides system status reports. A detailed examination of the various AT techniques is presented with major emphasis being placed on their specific roles within the total control strategy structure. 1.© (1990) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Patrick L. Sherley;Alfonso Pujol;John S. Meadow	1990		10.1117/12.18901	computer vision;simulation;computer science;real-time computer graphics;3d computer graphics;computer graphics (images)	AI	-10.104839526347275	-53.412027067388514	63948
9b2a0f355531b2b5f878dd343eba78430b1c312a	spam filter analysis	text classification;spam filtering;bayesian filtering;genetic algorithm;article in monograph or in proceedings	Unsolicited bulk email (aka. spam) is a major problem on the Internet. To counter spam, several techniques, ranging from spam filters to mail protocol extensions like hashcash, have been proposed. In this paper we investigate the effectiveness of several spam filtering techniques and technologies. Our analysis was performed by simulating email traffic under different conditions. We show that genetic algorithm based spam filters perform best at server level and naı̈ve Bayesian filters are the most appropriate for filtering at user level.	bogofilter;email filtering;filter (signal processing);genetic algorithm;hashcash;hypertext transfer protocol;internet;particle filter;server (computing);simulation;spamming	Flavio D. Garcia;Jaap-Henk Hoepman	2004		10.1007/1-4020-8143-X_26	genetic algorithm;computer science;bag-of-words model;data mining;internet privacy;world wide web	Metrics	-19.114758145923588	-56.208565194485146	64230
b6c824fd558fa4784cb9f6a5d291898ee6860bd1	random mappings designed for commercial search engines		We give a practical random mapping that takes any set of documents represented as vectors in Euclidean space and then maps them to a sparse subset of the Hamming cube while retaining ordering of inter-vector inner products. Once represented in the sparse space, it is natural to index documents using commercial text-based search engines which are specialized to take advantage of this sparse and discrete structure for large-scale document retrieval. We give a theoretical analysis of the mapping scheme, characterizing exact asymptotic behavior and also giving non-asymptotic bounds which we verify through numerical simulations. We balance the theoretical treatment with several practical considerations; these allow substantial speed up of the method. We further illustrate the use of this method on search over two real data sets: a corpus of images represented by their color histograms, and a corpus of daily stock market index values.	cube mapping;discrete mathematics;document retrieval;hamming distance;map;numerical analysis;simulation;sparse matrix;text corpus;text-based (computing);web search engine	Roger Donaldson;Arijit Gupta;Yaniv Plan;Thomas Reimer	2015	CoRR		computer science;theoretical computer science;machine learning;world wide web;information retrieval;statistics	ML	-15.438662106395666	-65.00510008021668	64697
8b52f616385e75f9a7f84b9dab9fdbebc7d96ee2	target estimation method for a udio-visual recorders based on users' operation history	semantic similarity;audio visual systems;human computer interaction;estimation method;information retrieval;consumer electronics;history estimation semantics vectors home appliances singular value decomposition aerospace electronics;recorders audio visual systems consumer electronics home automation human computer interaction information retrieval natural language processing;remote controller buttons target estimation method audio visual recorders user operation history label following strategy av appliances semantic similarity;natural language processing;recorders;home automation	This paper proposes a target estimation method based on users' operation history in which the operation history is assumed to be based on the label-following strategy. The proposed method is applied for AV appliances, and the effectiveness of the method is assessed. A target function is estimated from the semantic similarity between the collection of words of the menu items and labels of remote controller buttons selected by the user. Experimental results show that the average rank of the estimated order of finding the target function from all the selection history data was 8.7.	remote control;semantic similarity;xml appliance	Tsuyoshi Inoue;Jun Ozawa	2012	2012 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2012.6161951	home automation;computer vision;semantic similarity;simulation;computer science;multimedia;world wide web	Robotics	-17.070847692814652	-54.54692826672485	65086
9d92d4341c5c046e00676262f1d0f5f11e5ec21e	object retrieval based on user-drawn sketches		Sketches drawn by users are one of the most intuitive forms of Human Computer Interaction. Users can easily express their intention by sketching simple hand-drawn lines. In this paper, we consider the problem of target object detection and retrieval from a query by a sketch which is not in the database. Our novel approach consists of three steps: (1) Preprocessing to extract the skeletal features from a sketched query using size normalization, labelling, and binarization, (2) Skeletal feature extraction of query and data images in the space of diffusion tensor fields, and (3) Similarity measure using tensorial information between sketched query and database to retrieve the most similar target object in	computer vision;feature extraction;human computer;human–computer interaction;image retrieval;intension;object detection;preprocessor;scalability;similarity measure;software repository;structural analysis	Sang Min Yoon;Arjan Kuijper	2010			computer vision;artificial intelligence;computer science	DB	-11.676930744048734	-56.718091434154005	65215
c35cb81f7f5da7e8ca233b0c3d016ba6ac233061	the complexity of comparing reaction systems	inorganic organic physical and analytical chemistry;general and miscellaneous mathematics computing and information science;informing science;information network;higher order;graph isomorphism;lanl;comparative evaluations;computerized simulation;chemical reactions;kinetics;chemical reaction;biological network	MOTIVATION As more genomic data becomes available there is increased attention on understanding the mechanisms encoded in the genome. New XML dialects like CellML and Systems Biology Markup Language (SBML) are being developed to describe biological networks of all types. In the absence of detailed kinetic information for these networks, stoichiometric data is an especially valuable source of information. Network databases are the next logical step beyond storing purely genomic information. Just as comparison of entries in genomic databases has been a vital algorithmic problem through the course of the sequencing project, comparison of networks in network databases will be a crucial problem as we seek to integrate higher-order network knowledge.   RESULTS We show that comparing the stoichiometric structure of two reactions systems is equivalent to the graph isomorphism problem. This is encouraging because graph isomorphism is, in practice, a tractable problem using heuristics. The analogous problem of searching for a subsystem of a reaction system is NP-complete. We also discuss heuristic issues in implementations for practical comparison of stoichiometric matrices.	biopolymer sequencing;cobham's thesis;database;databases;graph - visual representation;graph isomorphism problem;heuristics;information source;kinetics;np-completeness;sbml;systems biology;xml	Mark Ettinger	2002	Bioinformatics	10.1093/bioinformatics/18.3.465	chemical reaction;computer science;bioinformatics;theoretical computer science;mathematics;statistics	Comp.	-5.26170343081174	-62.7108364209276	65221
8e097b35ee164daadcfb5bbfa40dfe324cf0dc60	the outline of an 'intelligent' image retrieval engine.	image retrieval	The first image retrieval systems hold the advantage of being fully automatic, and thus scalable to large collections of images but are restricted to the representation of low-level aspects (e.g. colors, textures...) without considering the semantic content of images. This obviously compromises interaction, making it difficult for a user to query with precision. The growing need for ‘intelligent’ systems, i.e. being capable of bridging this semantic gap, leads to new architectures combining multiple characterizations of the image content. This paper presents SIR, a promising high-level framework featuring semantics, signal color and spatial characterizations. It features a fully-textual query module based on a language manipulating both boolean and quantification operators, therefore making it possible for a user to request elaborate image scenes such as a “covered(mostly grey) sky” or “people in front of a building”.	bridging (networking);color;entity;facet (geometry);high- and low-level;image retrieval;scalability;semantics (computer science)	Mohammed Belkhatir;Philippe Mulhem;Yves Chiaramella	2004			visual word;image retrieval;automatic image annotation;world wide web;information retrieval;human–computer information retrieval	Vision	-14.66097514601553	-58.60148807182499	65558
4021e1345d3f12ecd386bc75f2b048623a715058	image retrieval method using visual query suggestion and relevance feedback	human computer interaction;relevance feedback content based retrieval human computer interaction image retrieval;relevance feedback human computer interaction visual query suggestion content based image retrieval;information retrieval visual query suggestion relevance feedback human computer interaction hci image feature similarity query keyword cbir system content based image retrieval system query ambiguity problem query interface vqs human vision system;relevance feedback;content based retrieval;image retrieval	Query suggestion is an effective human-computer interaction (HCI) approach in information retrieval. According to human vision system, the image retrieval method using visual query suggestion (VQS) can provide a friendly query interface to solve the query ambiguity problem. In this paper, the content-based image retrieval (CBIR) system is realized first. Human-computer interaction used VQS to obtain users' intention. In this step, user submitted a query keyword to the system. VQS is utilized to provide a list of suggestions, each containing a keyword and a collection of representative images. If the user selects one of the image suggestions, this image will be viewed as the key image. Then CBIR system will retrieve the image sets to return the similar images based on the similarity of image features. In relevance feedback, user scored each returned image by the slider to optimize retrieval results. A friendly query interface is designed to carry out HCI in our system and the experimental result shows the proposed method can improve the average recall and precision efficiently.	content-based image retrieval;human–computer interaction;information retrieval;precision and recall;relevance feedback	Jing Zhang;Yuncong Yang;Li Zhuo;Mengmeng Diao	2012	2012 International Conference on Wireless Communications and Signal Processing (WCSP)	10.1109/WCSP.2012.6542907	computer vision;query optimization;query expansion;web query classification;visual word;ranking;image retrieval;computer science;concept search;multimedia;web search query;automatic image annotation;information retrieval;query language;human–computer information retrieval	Vision	-12.596350437503	-58.07908422498357	65826
2baef72a0dff00a5de9cd003e6dc2151ba561719	user-centred personalised video abstraction approach adopting sift features	video summarization;relevancy level;personalization;sift;saliency score;article	The rapid growth of digital video content in recent years has imposed the need for the development of technologies with the capability to produce condensed but semantically rich versions of original input video. Consequently, the topic of Video Summarisation is becoming increasingly popular in the multimedia community and numerous video abstraction approaches have been proposed. Creating personalised video summaries remains a challenge, though. Accordingly, in this paper we propose a methodology for generating user-tailored video abstracts. First, video frames are scored by a group of video experts (operators) according to audio, visual and textual content of the video. Later, SIFT visual features are adopted in our proposed approach to identify the video scenes’ semantic categories. Fusing this retrieved data with pre-built users’ profiles will provide a metric to update the previously averaged saliency scores assigned by video experts to each frame in accordance to users’ priorities. In the next stage, the initial averaged scores of the frames are updated based on the end-users’ generated profiles. Eventually, the highest scored video frames alongside the auditory and textual content are inserted into final digest Experimental results showed the effectiveness of this method in delivering superior outcomes comparing to our previously recommended algorithm and the three other automatic summarisation techniques.	algorithm;automatic summarization;cryptographic hash function;digital video;scale-invariant feature transform	Kaveh Darabi;George Ghinea	2015	Multimedia Tools and Applications	10.1007/s11042-015-3210-4	video compression picture types;subjective video quality;computer vision;computer science;video quality;machine learning;video tracking;scale-invariant feature transform;personalization;multimedia;world wide web;pevq;information retrieval	AI	-14.580996873636435	-53.48665130374323	66096
f212574b1373f0154c0eb9177fec8d0cb5a19449	digesting multilingual reader comments via latent discussion topics with commonality and specificity	latent discussion topics;commonality and specificity;multilingual news reader comments	Many news websites from different regions in the world allow readers to write comments in their own languages about an event. Digesting such enormous amount of comments in different languages is difficult. One elegant way to digest and organize these comments is to detect latent discussion topics with the consideration of language attributes. Some discussion topics are common topics shared between languages whereas some topics are specifically dominated by a particular language. To tackle this task of discovering discussion topics that exhibit commonality or specificity from news reader comments written in different languages, we propose a new model called TDCS based on graphical models, which can cope with the language gap and detect language-common and language-specific latent discussion topics simultaneously. Our TDCS model also exploits comment-oriented clues via a scalable Dirichlet Multinomial Regression method. To learn the model parameters, we develop an inference method which alternates between EM and Gibbs sampling. Experimental results show that our proposed TDCS model can provide an effective way to digest multilingual news reader comments.	cryptographic hash function;gibbs sampling;graphical model;multinomial logistic regression;sampling (signal processing);scalability;sensitivity and specificity;sensor;transcranial direct-current stimulation	Bei Shi;Wai Lam;Lidong Bing;Yinqing Xu	2016		10.1145/2983323.2983683	natural language processing;speech recognition;computer science;artificial intelligence;machine learning;data mining;database;world wide web;information retrieval	ML	-17.715510760139676	-64.47963837437827	66105
c88c29af1da9c0d9f7d9e8a21c39474f1c9f5ea0	approaches for content-based retrieval of surface defect images ; pintavirhekuvien sisältöpohjaisesta hausta		There are two properties which all industrial manufacturing processes try to optimize: speed and quality. Speed can also be called throughput and tells how much products can be created in a specified time. The higher speeds you have the better. Quality means the perceived goodness of the finished product. Broken or defective products simply don’t sell, so they must be eliminated. These are contradicting goals. The larger the manufacturing volumes, the less time there is to inspect a single product, or the more inspectors are required. A good example is paper manufacturing. A single paper machine can produce a sheet of paper several meters wide and several hundred kilometers long in just a few hours. It is impossible to inspect these kinds of volumes by hand. In this thesis the indexing and retrieval of defect images taken by an automated inspection machine is examined. Some of the images taken contain serious defects such as holes, while others are less grave. The goal is to try to develop automated methods to find the serious fault images from large databases using only the information in the images. This means that there are no annotations. This is called content-based image retrieval, or CBIR. This problem is examined in two different ways. First the PicSOM CBIR tool’s suitability for this task is evaluated. PicSOM is a platform for content-based image retrieval developed at the Laboratory of Computer and Information Science, Helsinki University of Technology. PicSOM has earlier been succesfully applied to various different CBIR tasks. The other part involves developing new algorithms for efficient indexing of large, high-dimensional databases. The Evolving Tree (ETree), a novel hierarchical, tree-shaped, self-organizing neural network is presented and analyzed. It is noticeably faster than classical methods, while still obtaining good results. The suitability and performance of both CBIR and ETree on this problem is evaluated using several different experiments. The results show that both approaches are applicable for this real world quality inspection problem with good results.	algorithm;artificial neural network;content-based image retrieval;database;electron hole;experiment;information and computer science;information science;organizing (structure);self-organization;software bug;throughput	Jussi Pakkanen	2006				Web+IR	-10.606834667257507	-64.73956336105115	66163
ea57ef97e7bd5bc58226eb53ea695293125ffa08	flexible 3d searching: the directed tweak technique	industrie agricole;industria farmaceutica;base donnee;estructura 3 dimensiones;aplicacion;industria agricola;information retrieval;database;base dato;spatial structure;industrie pharmaceutique;structure 3 dimensions;biological activity;relacion estructura propiedad;recherche information;structure moleculaire;agricultural industry;recuperacion informacion;pharmaceutical industry;application;estructura molecular;actividad biologica;relation structure propriete;activite biologique;property structure relationship;molecular structure	published in Advance ACS Abstracts, January 15, 1994. 0095-2338/94/ 1634-01 90$04.50/0 mations themselves are then discarded. The conformations are regenerated using the same technique after the hits are found. The problem with these approaches is that the number of conformations required to span conformational space is extremely large. In active analog studies using the systematic search technique, it is often found that millions of conformations are required to span conformational space? In 3D searching, the same will be true unless the query has very large tolerances. If in addition, only conformations which are energy minimized are generated, another problem is seen. Often, the bound conformation is not an energy minimal conformation. In fact, the receptor often activates the structure by placing it in a more energetic conformation.1° Thus, using only a handful of energy-minimal conformations for 3D searching will bypass many relevant conformations. A better approach is to investigate the flexibility of the molecule at search-time, using the query to direct the conformation changes needed to find a match to the query. We call this “query-directed conformational exploration”. Many techniques have been investigated. These techniques include systematic search (from SYBYL”), random search, distance geometry, genetic algorithm, and directed tweak. The results of these investigations are reported by Willett and Clark.’* This paper reports the details of the directed tweak technique, which is the method of choice from among those investigated. Directed tweak is a torsional space minimizer, in which the rotatable bonds of the structures are adjusted at search time to produce a conformation which matches the 3D query as closely as possible. This involves the use of analytical derivatives and, because of this, is a very fast technique. This method is applicable when the queries contain distance constraints only. The flexibility of the ring systems can also be investigated with this technique. The conformations of the structures that match the query must not be extremely high in energy. To this end, thedirected tweak technique also can address the van der Waals interactions between the atoms of the database structure, thus producing energy-accessible conformers which present the query geometry. HISTQRY The directed tweak method for 3D searching is based on the random tweak method used for protein loop searching reported by Levinthal et d . 1 3 and uses torsional space Q 1994 American Chemical Society THE DIRECTED TWEAK TECHNIQUE IN 3D SEARCHING Angles Required position Closure Structurally Conserved Region of Protein Figure 1. Random tweak technique for protein loop generation.	dvd region code;genetic algorithm;interaction;random search	Tad Hurst	1994	Journal of Chemical Information and Computer Sciences	10.1021/ci00017a025	molecule;computer science;artificial intelligence;biological activity;database;quantum mechanics	Comp.	-6.233965678916937	-54.425848998162564	66493
d7c2210df019dbfb710dfd3860dccc9b8639b745	dialogue scenes detection in mpeg movies: a multi-expert approach	individual sequence;video databases;evaluation performance;representacion conocimientos;sistema experto;performance evaluation;man machine dialogue;evaluacion prestacion;semantics;technique video;base donnee video;segmentation;tecnica video;semantica;semantique;decision problem;systeme multiexpert;video technique;dialogo hombre maquina;mpeg;systeme expert;knowledge representation;representation connaissances;segmentacion;dialogue homme machine;expert system	In this paper we propose a method for the detection of dialogue scenes within movies. This task is of particular interest given the special semantic role played by dialogue based scenes in the most part of movies. The proposed approach firstly operates the segmentation of the video footage in shots, then each shot is classified as dialogue or not-dialogue by a Multi-Expert System (MES) and, finally, the individuated sequences of dialogue shots are aggregated in dialogue scenes by means of a suitable algorithm. The MES integrates three experts which consider different and complementary aspects of the same decision problem, so that the combination of the single decisions provides a performance that is better than that of any single expert. While the general approach of multiple experts is not new, its application to this specific problem is interesting and novel and the obtained results are encouraging.	algorithm;combining rules;decision problem;expert system;manufacturing execution system;moving picture experts group;performance	Massimo De Santo;Gennaro Percannella;Carlo Sansone;Mario Vento	2001		10.1007/3-540-44819-5_16	computer vision;computer science;artificial intelligence;decision problem;semantics;multimedia;segmentation;expert system	Vision	-13.29719737062534	-56.15140366593643	67092
063bf45413fafccd0f05c49494b51aeaae2f7d93	sampling latent emotions and topics in a hierarchical bayesian network	belief networks;bayesian network;gibbs sampling;hidden markov model;text analysis;hidden markov models indexes predictive models training random variables joints;web sites belief networks sampling methods text analysis;blog article latent emotion sampling topic sampling hierarchical bayesian network text emotion analysis emotion feature gibbs sampling method emotion combination phenomenon latent random variable word emotion topic model parsing method hidden markov model conditional random field;indexation;web sites;random variable;conditional random field;prediction model;sampling methods	Text emotion analysis suffers from the lack of faithful emotion features, and the difficulty of mining multiple emotions that are mixed together. In this paper, we provide a Gibbs sampling method to solve these two problems. We explicitly characterize the emotion combination phenomenons, and predict the complex emotions of words together with the emotion intensities for each singular emotion through raw texts. Both emotions and emotion intensities are embedded as latent random variables in a hierarchical Bayesian network, while only the words and some preliminary expectations are represented as observed variables. The model which we call word emotion topic (WET) model, also depicts the distribution of word emotions among different topics, which helps to study the variation of word topics and word emotions. Experiment shows promising results of word emotion prediction, which outperforms traditional parsing methods such as Hidden Markov Model and Conditional Random Fields on raw text. The result also presents interesting emotion-topic variations through blog articles.	bayesian network;blog;conditional random field;diagram;embedded system;gibbs sampling;hidden markov model;markov chain;negative feedback;parsing;regular expression;sampling (signal processing)	Xin Kang;Fuji Ren	2011	2011 7th International Conference on Natural Language Processing and Knowledge Engineering	10.1109/NLPKE.2011.6138166	speech recognition;computer science;machine learning;pattern recognition	AI	-16.427941629759324	-63.12520811264744	67161
6861a4ea81079be6c002e59c56a80dbc42eae6aa	event recognition in sport programs using low-level motion indices	event recognition;indexing video sequences video compression data mining game theory transform coding event detection decision making spatial databases discrete event simulation;semantic indexing;game theory;video compression;video sequences;event detection;transform coding;data mining;video indexing;indexing;spatial databases;audio visual;video database;finite state machine;discrete event simulation	In this paper we present a semantic video indexing algorithm based on finite-state machines and low-level motion indices extracted from the MPEG compressed bit-stream. The problem of semantic video indexing is actually of great interest due to the wide diffusion of large video databases. In literature we can find many video indexing algorithms, based on various types of low-level features, but the problem of semantic indexing is less studied and surely it is a great challenging one. The proposed algorithm is an example of solution to the problem of finding a semantic relevant event (e.g., scoring of a goal in a soccer game) in case of specific categories of audio-visual programmes. The simulation results show that the proposed algorithm can effectively detect the presence of goals and other relevant events in sport programs.	algorithm;bitstream;database;finite-state machine;high- and low-level;moving picture experts group;simulation	A. Bonzanini;Riccardo Leonardi;Pierangelo Migliorati	2001	IEEE International Conference on Multimedia and Expo, 2001. ICME 2001.	10.1109/ICME.2001.1237894	data compression;game theory;computer vision;search engine indexing;transform coding;computer science;theoretical computer science;discrete event simulation;data mining;statistics	Vision	-13.446099019050926	-55.535435842194744	67214
2cf98ee58e57320a25b72a8da31aa3277cdf236e	partially labeled topic models for interpretable text mining	unsupervised learning;dirichlet process;web pages;generic model;supervised learning;text mining;partially supervised learning;supervised classification	Abstract Much of the world's electronic text is annotated with human-interpretable labels, such as tags on web pages and subject codes on academic publications. Effective text mining in this setting requires models that can flexibly account for the textual patterns that underlie the observed labels while still discovering unlabeled topics. Neither supervised classification, with its focus on label prediction, nor purely unsupervised learning, which does not model the labels explicitly, is appropriate. In this paper, we present two new partially supervised generative models of labeled text, Partially Labeled Dirichlet Allocation (PLDA) and the Partially Labeled Dirichlet Process (PLDP). These models make use of the unsupervised learning machinery of topic models to discover the hidden topics within each label, as well as unlabeled, corpus-wide latent topics. We explore applications with qualitative case studies of tagged web pages from del.icio.us and PhD dissertation abstracts, demonstrating improved model interpretability over traditional topic models. We use the many tags present in our del.icio.us dataset to quantitatively demonstrate the new models' higher correlation with human relatedness scores over several strong baselines.	baseline (configuration management);code;dissertations abstracts;supervised learning;tag (metadata);text mining;unsupervised learning;web page	Daniel Ramage;Christopher D. Manning;Susan T. Dumais	2011		10.1145/2020408.2020481	semi-supervised learning;unsupervised learning;text mining;computer science;machine learning;pattern recognition;web page;data mining;supervised learning	ML	-17.344323384868222	-64.39277387919353	67281
f7e9ccc1e43fba723373fa3ca070c620e2c8b4a3	integrating features from different sources for music information retrieval	cluster algorithm;pattern clustering;data set;clustering algorithm;acoustic data;information retrieval;pattern clustering information retrieval multimedia systems music;music information retrieval clustering algorithms semisupervised learning supervised learning computer science unsupervised learning motion pictures personnel algorithm design and analysis boosting;multimedia systems;data set music information retrieval acoustic data clustering algorithm bimodal learning;bimodal learning;music information retrieval;music	"""Efficient and intelligent music information retrieval is a very important topic of the 21st century. With the ultimate goal of building personal music information retrieval systems, this paper studies the problem of identifying """"similar"""" artists using both lyrics and acoustic data. In this paper, we present a clustering algorithm that integrates features from both sources to perform bimodal learning. The algorithm is tested on a data set consisting of 570 songs from 53 albums of 41 artists using artist similarity provided by All Music Guide. Experimental results show that the accuracy of artist similarity classifiers can be significantly improved and that artist similarity can be efficiently identified."""	acoustic cryptanalysis;algorithm;cluster analysis;experiment;ground truth;ibm notes;information retrieval;multimodal interaction;self-similarity	Tao Li;Mitsunori Ogihara;Shenghuo Zhu	2006	Sixth International Conference on Data Mining (ICDM'06)	10.1109/ICDM.2006.89	document clustering;computer science;machine learning;pattern recognition;music;cluster analysis;information retrieval;data set;human–computer information retrieval	ML	-16.958489028585486	-61.47531737857007	67582
4dbc91a2cff8c9575c93ac77435d24541bd606ea	using mpeg-7 and mpeg-21 for personalizing video	semantic similarity;video databases;portals;video coding multimedia databases video databases portals image retrieval middleware;video coding;multimedia databases;middleware;mpeg 7 standard auditory displays layout signal generators surveillance personnel indexing speech processing signal processing engines;new media;semantic summarization engines multimedia mpeg 7 standards mpeg 21 standards video personalization video summarization system heterogeneous usage environments three tier architecture standards compliant infrastructure news media sources browser portals;image retrieval	As multimedia content has proliferated over the past several years, users have begun to expect that content be easily accessed according to their own preferences. One of the most effective ways to do this is through using the MPEG-7 and MPEG-21 standards, which can help address the issues associated with designing a video personalization and summarization system in heterogeneous usage environments. This three-tier architecture provides a standards-compliant infrastructure that, in conjunction with our tools, can help select, adapt, and deliver personalized video summaries to users. In extending our summarization research, we plan to explore semantic similarities across multiple simultaneous news media sources and to abstract summaries for different viewpoints. Doing so will allow us to track a semantic topic as it evolves into the future. As a result, we should be able to summarize news repositories into a smaller collection of topic threads.	mpeg-21;mpeg-7;multitier architecture;personalization;standards-compliant	Belle L. Tseng;Ching-Yung Lin;John R. Smith	2004	IEEE MultiMedia	10.1109/MMUL.2004.1261105	semantic similarity;new media;image retrieval;computer science;operating system;automatic summarization;middleware;multimedia;world wide web;information retrieval	Web+IR	-16.216461681582075	-55.54788134738641	67739
18d46a0fc3c93f9301c3acd0f9a2a795c6c00ca3	impression estimation of video and application to video creation	the cold start problem;audio signal processing;data models visualization training data estimation error image color analysis computational modeling;training data video impression estimation video creation bgm background music computer mesurable audio features visual features otopittan static user model dynamic user model;video signal processing;the cold start problem impression estimation audio and video analysis personalization;personalization;audio and video analysis;video signal processing audio signal processing learning artificial intelligence;learning artificial intelligence;impression estimation	Adding BGM (background music) to a video is an important process in video creation because BGM determines the impression of the video. We model impression estimation of a video as mappping from computer-mesurable audio and visual features to impression degrees. As an application of impression estimation of a video, we propose OtoPittan, a system for recommending BGM for helping users to make impressive videos. OtoPittan regards the problem of selecting BGM from a music collection as a partial inverse problem of the impression estimation. That is, to an inputted video and desired impression, BGM which produces a good match to the desired impression when adding it to the inputted video is recommended. As implementation ways of impression estimation of a video, we use a static user model and a dynamic user model. The first model statically constructs a mapping function learnt from training data. The second model dynamically optimizes a mapping function through user interaction. Experimental results have shown that the static user model has high estimation accuracy and the dynamic user model can efficiently performs optimization without much user interaction.	bayesian network;mathematical optimization;personalization;recommender system	Kiyoshi Tokunaga;Takahiro Hayashi	2013	2013 IEEE International Symposium on Multimedia	10.1109/ISM.2013.25	computer vision;simulation;audio signal processing;computer science;artificial intelligence;video quality;video capture;video tracking;personalization;multimedia;video processing;world wide web	Vision	-16.91628887255285	-52.76928500578542	67839
084750a4cdc4580a517444113013eb6eaa60ef36	semantic analysis for automatic event recognition and segmentation of wedding ceremony videos	search and retrieval;event recognition;analisis contenido;home video;evaluation performance;image recognition;home videos;electronic mail;audiovisual;image segmentation;performance evaluation;image processing;video signal processing;hidden markov model semantic analysis event recognition event segmentation wedding ceremony videos;probabilidad condicional;hidden markov model;information retrieval;relacion orden;event segmentation;estudio comparativo;automatic segmentation;evaluacion prestacion;modele markov variable cachee;probabilite conditionnelle;procesamiento imagen;video signal processing hidden markov models image recognition image segmentation;ordering;speech;wedding ceremonies;video segmentation;event detection;probabilistic approach;traitement image;statistical model;multimedia systems;etude comparative;videos hidden markov models multimedia systems music information retrieval speech context modeling ieee news information retrieval councils electronic mail;accuracy;relation ordre;content analysis;automatic recognition;campo aleatorio;precision;hidden markov models;senal video;signal video;audiovisuel;enfoque probabilista;approche probabiliste;music information retrieval;image sequence;segmentation image;comparative study;modele statistique;conditional random field;traitement signal video;video signal;councils;wedding ceremony videos;modelo estadistico;secuencia imagen;analyse contenu;analisis semantico;analyse semantique;semantic content analysis;ieee news;wedding ceremonies event detection home videos semantic content analysis video segmentation;conditional probability;context modeling;video domestique;sequence image;reconocimiento automatico;champ aleatoire;semantic analysis;reconnaissance automatique;videos;random field	Wedding is one of the most important ceremonies in our lives. It symbolizes the birth and creation of a new family. In this paper, we present a system for automatically segmenting a wedding ceremony video into a sequence of recognizable wedding events, e.g., the couple's wedding kiss. Our goal is to develop an automatic tool that helps users to efficiently organize, search, and retrieve his/her treasured wedding memories. Furthermore, the obtained event descriptions could benefit and complement the current research in semantic video understanding. Based on the knowledge of wedding customs, a set of audiovisual features, relating to the wedding contexts of speech/music types, applause activities, picture-taking activities, and leading roles, are exploited to build statistical models for each wedding event. Thirteen wedding events are then recognized by a hidden Markov model, which takes into account both the fitness of observed features and the temporal rationality of event ordering to improve the segmentation accuracy. We conducted experiments on a collection of wedding videos and the promising results demonstrate the effectiveness of our approach. Comparisons with conditional random fields show that the proposed approach is more effective in this application domain.	application domain;bayesian network;conditional random field;experiment;feature model;finite-state machine;hidden markov model;information privacy;markov chain;rationality;statistical model;taxonomy (general);video content analysis	Wen-Huang Cheng;Yung-Yu Chuang;Yin-Tzu Lin;Chi-Chang Hsieh;Shao-Yen Fang;Bing-Yu Chen;Ja-Ling Wu	2008	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2008.2005608	computer vision;speech recognition;computer science;mathematics;accuracy and precision;multimedia;hidden markov model;statistics	Vision	-11.74167908332142	-60.180619152090415	68005
62d1a14784fe1721f97409370858fe4d0973fdf0	a relational vector-space model of information retrieval adapted to images	vector space model;information retrieval;image search;digital image	The increase of digital image acquisition devices, combined to the growth of the Web, requires the definition of Information Retrieval (IR) models and systems providing fast access to images searched by users among large amounts of data.	digital image;information retrieval;world wide web	Jean Martinet	2004	SIGIR Forum	10.1145/1067268.1067292	computer vision;visual word;image retrieval;computer science;digital image processing;data mining;automatic image annotation;vector space model;information retrieval;digital image;human–computer information retrieval	Web+IR	-13.749149497344872	-57.86878949598108	68106
bb58f99eeae4a270ac94a9dd41d59abb0c692120	performing text categorization on manifold	high dimensionality;text documents;text analysis;intrinsic global manifold structure;geodesic distance;empirical validation;text information;k nearest neighbor;geodesic distance text categorization text information k nearest neighbor classification accuracy text documents low dimensional manifold intrinsic global manifold structure;text categorization manifolds space technology organizing support vector machines euclidean distance cybernetics gallium nitride performance evaluation level measurement;classification accuracy;low dimensional manifold;text categorization	Text categorization has become the key technology in organizing and processing the large amount of text information. It normally involves an extremely high dimensional space, which makes most existing approaches generate highly biased estimates so as to reduce the classification accuracy. These approaches do not consider that the text documents may be intrinsically located on the low-dimensional manifold. This paper presents an approach that performs text categorization on texts manifold with respect to the intrinsic global manifold structure, such as by geodesic distance to measure the distance between two texts. This approach has been applied to improve the KNN for text categorization. This is empirically validated by the conducted experiments.	categorization;distance (graph theory);document classification;experiment;k-nearest neighbors algorithm;organizing (structure)	Guihua Wen;Gan Chen;Lijun Jiang	2006	2006 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2006.384735	text mining;geodesic;computer science;machine learning;pattern recognition;data mining;mathematics;k-nearest neighbors algorithm;manifold alignment	Robotics	-14.54876293723915	-62.622532848231565	68639
3216d0a2cf5a7b8b315be9cf14561038941432bc	segmentation of lecture videos based on spontaneous speech recognition	video signal processing distance learning image segmentation speech recognition;multimedia retrieval;image segmentation;video signal processing;distance learning;training;speech;lecture video topic segmentation multimedia retrieval speech recognition;linear text segmentation algorithm lecture videos segmentation spontaneous speech recognition digital academic lecture videos multimedia lecture video content;error analysis;accuracy;lecture video;vectors;speech recognition;spontaneous speech recognition;speech recognition video recording audio recording indexing natural languages algorithm design and analysis testing streaming media layout automatic speech recognition;text segmentation;topic segmentation;videos	In the past decade, the number of digital academic lecture videos has increased dramatically as recording technology has become more affordable. There are technical problems in the use of recorded lectures for learning: the problem of easy access to the multimedia lecture video content and the problem of finding the appropriate information. The first step to a solution is to segment the videos into smaller cohesive areas. In this paper, we present a study on segmenting recorded lecture videos based on their transcripts with standard linear text segmentation algorithm (LTSA). Our evaluation dataset is based on different languages and various speakers' recordings. Three different tests analyze the outcome of ten algorithms: 1) Whether LTSA is able to segment the transcript into the slide transitions. 2) The presentation slides are used as an additional resource for the segmenting procedure. 3) Analyzing the topic boundaries independently from the slide transitions.	accessibility;algorithm;digital video;local tangent space alignment;max-flow min-cut theorem;sensor;speech recognition;spontaneous order;text segmentation	Stephan Repp;Christoph Meinel	2008	2008 Tenth IEEE International Symposium on Multimedia	10.1109/ISM.2008.20	distance education;text segmentation;computer vision;speech recognition;computer science;speech;accuracy and precision;multimedia;image segmentation	Theory	-14.807573385683327	-55.94843705645113	69065
d7775bdf14dcbd7e0ab254e8d3638c8feccdc443	user-defined music sequence retrieval	copyright;satisfiability;intellectual property protection;digital rights management;digital media;mp3;integer linear program	A system for retrieving a sequence of music excerpts or songs based on users and producers requirements is proposed in this paper. Our system provides a flexible way to retrieve music pieces based on its contents as well as user-defined constraints. The proposed system allows online users to extract a sequence of songs whose first and last tracks are known and at the same time the in-between songs have minimum inter-track differences and satisfy predefined requirements. We model the problem as a constrained minimum cost flow problem which leads to a binary integer linear program (BILP) that can be solved in a reasonable amount of time.	flow network;linear programming;minimum-cost flow problem;requirement	Masoud Alghoniemy;Ahmed H. Tewfik	2000		10.1145/354384.375451	simulation;computer science;digital media;machine learning;digital rights management;multimedia;law;world wide web;intellectual property;satisfiability	ML	-14.879670999785544	-53.519038964648736	69084
fa728afef3a9dbd6e71081f7263b0ad51c01f1e3	approximation of cosmic functional size of scenario-based requirements in agile based on syntactic linguistic features—a replication study	agile;replication study;cosmic;functional size measurement	Context: Expert judgment is the most frequently used method of effort estimation in Agile software development. Unfortunately, Agile teams often underestimate development effort. Therefore, it seems beneficial to support such teams with the information regarding the functional size of requirements they are estimating. Hussain, Kosseim and Ormandjieva (HKO) proposed a method that can be used to automatically classify textual requirements with respect to their COSMIC functional size. Unfortunately, the method has not been sufficiently validated to confirm its usefulness. Objective: To provide external validation of the HKO method and investigate if it can be applied to classify scenario-based requirements (in the form of use cases) with respect to their COSMIC size. Method: Similarily to the original study, we used a set of natural language processing tools to extract syntactic linguistic features and the C4.5 decision tree-based classifiers to classify requirements. We validated the performance of the classifiers using the 10-fold cross-validation procedure on a dataset containing 93 use cases. We compared the performance of the HKO method with the performance of the classifiers trained using a single prediction feature-the number of steps in a use case. Results: Depending on the considered number of size classes and the algorithm used to compute boundaries of the classes, the accuracy of the HKO method ranged between .387 and .785 while the Cohen's kappa index was between .194 and .577. The accuracy of the use-case-steps-based classifiers performed slightly worse. Their accuracy ranged between .015 and .769 while Cohen's kappa was between .067 and .423. We observed that the performance of both types of classifiers dropped visibly when applied to four or more size classes. Conclusion: The classification performance of the HKO method was moderate. However, it was still better than the classification based on the number of steps. Unfortunately, we also observed that the accuracy of the HKO method is sensitive to the language used in descriptions of requirements.	agile software development;approximation;business object;c4.5 algorithm;cosmic;computers, freedom and privacy conference;cost estimation in software engineering;cross-validation (statistics);decision tree;natural language processing;requirement;statistical classification;syntactic predicate	Miroslaw Ochodek	2016	2016 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement (IWSM-MENSURA)	10.1109/IWSM-Mensura.2016.039	computer science;artificial intelligence;machine learning;data mining	SE	-11.454986567028469	-64.61258716357646	69531
8d1ca1edd84b6cbf1edf2b1851b8f978dad93d15	localized content-based image retrieval	multiple instance learning algorithm;contenu image;image content;raisonnement base sur cas;similarity measure accio localized content based image retrieval system multiple instance learning algorithm salient point based technique segmentation based technique image representation database image ranking;razonamiento fundado sobre caso;image segmentation;supervised learning;image databases;machine learning information search and retrieval relevance feedback;recherche image;image retrieval content based retrieval image segmentation image representation feedback image databases spatial databases surveillance partitioning algorithms feature extraction;image databank;surveillance;multiple instance learning;analisis forma;metric;intelligence artificielle;segmentation;accio localized content based image retrieval system;salient points;indexing terms;similitude;hypermedia;segmentation based technique;detection objet;software architecture;feedback;algorithms artificial intelligence database management systems databases factual documentation image enhancement image interpretation computer assisted information storage and retrieval pattern recognition automated radiology information systems;machine learning;database image ranking;busqueda por contenido;image representation;feature extraction;banco imagen;salient point based technique;spatial databases;comportement utilisateur;banque image;similarity;information retrieval systems;artificial intelligence;metrico;pattern analysis;learning artificial intelligence content based retrieval image representation image retrieval image segmentation information retrieval systems;inteligencia artificial;user behavior;similitud;apprentissage supervise;case based reasoning;learning artificial intelligence;content based image retrieval;contenido imagen;aprendizaje supervisado;similarity measure;relevance feedback;content based retrieval;information search and retrieval;hipermedia;recherche par contenu;segmentacion;metrique	We define localized content-based image retrieval as a CBIR task where the user is only interested in a portion of the image, and the rest of the image is irrelevant. In this paper we present a localized CBIR system, Accio, that uses labeled images in conjunction with a multiple-instance learning algorithm to first identify the desired object and weight the features accordingly, and then to rank images in the database using a similarity measure that is based upon only the relevant portions of the image. A challenge for localized CBIR is how to represent the image to capture the content. We present and compare two novel image representations, which extend traditional segmentation-based and salient point-based techniques respectively, to capture content in a localized CBIR setting.		Rouhollah Rahmani;Sally A. Goldman;Hui Zhang;Sharath R. Cholleti;Jason E. Fritts	2008	IEEE transactions on pattern analysis and machine intelligence	10.1109/TPAMI.2008.112	case-based reasoning;software architecture;computer vision;index term;similarity;metric;feature extraction;image retrieval;computer science;similitude;machine learning;pattern recognition;feedback;image segmentation;supervised learning;segmentation;automatic image annotation;information retrieval	Vision	-12.759314739268019	-59.90478002222512	69675
8474cbd89ea04c2e3da931f10ca5a3b2e13a7eb1	the semantic pathfinder for generic news video indexing	performance indicator;video signal processing;generic news video indexing;video retrieval;semantic pathfinder;universiteitsbibliotheek;video signal processing feature extraction indexing video retrieval;production process;video indexing;content analysis;indexing;feature extraction;generic news video indexing semantic pathfinder;indexation;indexing production detectors nist cameras intelligent systems search engines prototypes roads tv	This paper presents the semantic pathfinder architecture for generic indexing of video archives. The pathfinder automatically extracts semantic concepts from video based on the exploration of different paths through three consecutive analysis steps, closely linked to the video production process, namely: content analysis, style analysis, and context analysis. The virtue of the semantic pathfinder is its learned ability to find a best path of analysis steps on a per-concept basis. To show the generality of this indexing approach we develop detectors for a lexicon of 32 concepts and we evaluate the semantic pathfinder against the 2004 NIST TRECVID video retrieval benchmark, using a news archive of 64 hours. Top ranking performance indicates the merit of the semantic pathfinder	archive;benchmark (computing);lexicon;sensor;video production	Cees Snoek;Marcel Worring;Jan-Mark Geusebroek;Dennis C. Koelma;Frank J. Seinstra;Arnold W. M. Smeulders	2006	2006 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2006.262819	search engine indexing;content analysis;feature extraction;computer science;performance indicator;scheduling;multimedia;world wide web;information retrieval	Vision	-15.268094147584755	-56.927388319063716	69687
dfe9619dcec744b1f7b2a5b8035b3451b0695ec1	automatic recognition of object use based on wireless motion sensors	wireless motion sensor;object recognition;image motion analysis;history;features extraction;sensors;object use automatic recognition;wireless sensor nodes;accuracy;wireless sensor networks feature extraction image motion analysis object recognition;time factors;online detection;feature extraction;interactive multiuser game object use automatic recognition wireless motion sensor online detection user interaction distributed activity recognition system features extraction wireless sensor nodes;distributed activity recognition system;correlation;peer to peer computing;user interaction;correlation sensors feature extraction time factors history accuracy peer to peer computing;wireless sensor networks;interactive multiuser game	In this paper, we present a method for automatic, online detection of a user's interaction with objects. This represents an essential building block for improving the performance of distributed activity recognition systems. Our method is based on correlating features extracted from motion sensors worn by the user and attached to objects. We present a complete implementation of the idea, using miniaturized wireless sensor nodes equipped with motion sensors. We achieve a recognition accuracy of 97% for a target response time of 2 seconds. The implementation is lightweight, with low communication bandwidth and processing needs. We illustrate the potential of the concept by means of an interactive multi-user game.	activity recognition;multi-user;response time (technology);sensor	Stephan Bosch;Raluca Marin-Perianu;Paul J. M. Havinga;Arie Horst;Mihai Marin-Perianu;Andrei Vasilescu	2010	International Symposium on Wearable Computers (ISWC) 2010	10.1109/ISWC.2010.5665858	embedded system;computer vision;real-time computing;wireless sensor network;feature extraction;computer science;sensor;cognitive neuroscience of visual object recognition;accuracy and precision;multimedia;correlation	Mobile	-8.869960258608847	-63.82226065006782	69736
3d68f8a72eec9b3d3ec4bebb0991e13a839c3a11	hooke: an open software platform for force spectroscopy	outil logiciel;plataforma;software tool;software platform;platform;logiciel libre;software libre;herramienta software;plateforme;open source software	SUMMARY Hooke is an open source, extensible software intended for analysis of atomic force microscope (AFM)-based single molecule force spectroscopy (SMFS) data. We propose it as a platform on which published and new algorithms for SMFS analysis can be integrated in a standard, open fashion, as a general solution to the current lack of a standard software for SMFS data analysis. Specific features and support for file formats are coded as independent plugins. Any user can code new plugins, extending the software capabilities. Basic automated dataset filtering and semi-automatic analysis facilities are included.   AVAILABILITY Software and documentation are available at (http://code.google.com/p/hooke). Hooke is a free software under the GNU Lesser General Public License.	algorithm;atomic-force microscopy;documentation;gnu;microscope device component;mike lesser;open-source software;plug-in (computing);scanning probe microscopes (device);scientific publication;semiconductor industry;silo (dataset);tomography, emission-computed, single-photon;format	Massimo Sandal;Fabrizio Benedetti;Marco Brucale;Alberto Gomez-Casado;Bruno Samorì	2009	Bioinformatics	10.1093/bioinformatics/btp180	software distribution;embedded system;software visualization;computer science;operating system;open platform;platform;software system	SE	-4.905642761163668	-58.416715805637025	69859
17a0182ee8d12aa2491a1f4309afe84e6869b2a0	luhn revisited: significant words language models	pseudo relevance feedback;significant words language models;universiteitsbibliotheek;relevance feed back	Users tend to articulate their complex information needs in only a few keywords, making underspecified statements of request the main bottleneck for retrieval effectiveness. Taking advantage of feedback information is one of the best ways to enrich the query representation, but can also lead to loss of query focus and harm performance in particular when the initial query retrieves only little relevant information when overfitting to accidental features of the particular observed feedback documents. Inspired by the early work of Luhn [23], we propose significant words language models of feedback documents that capture all, and only, the significant shared terms from feedback documents. We adjust the weights of common terms that are already well explained by the document collection as well as the weight of rare terms that are only explained by specific feedback documents, which eventually results in having only the significant terms left in the feedback model.  Our main contributions are the following. First, we present significant words language models as the effective models capturing the essential terms and their probabilities. Second, we apply the resulting models to the relevance feedback task, and see a better performance over the state-of-the-art methods. Third, we see that the estimation method is remarkably robust making the models in- sensitive to noisy non-relevant terms in feedback documents. Our general observation is that the significant words language models more accurately capture relevance by excluding general terms and feedback document specific terms.	archive;document;error-tolerant design;experiment;information needs;information retrieval;intermediate representation;language model;luhn algorithm;mixture model;overfitting;personalization;primitive recursive function;query expansion;radio frequency;relevance feedback;unsupervised learning	Mostafa Dehghani;Hosein Azarbonyad;Jaap Kamps;Djoerd Hiemstra;Maarten Marx	2016		10.1145/2983323.2983814	natural language processing;computer science;artificial intelligence;machine learning;data mining;database;information retrieval	Web+IR	-18.09835265849951	-66.08292532738689	70137
3e903eecba5b9f4cb636b2f1e7f6549385caaa5b	collocation extraction beyond the independence assumption	new measure;two-part collocation extraction association;well-known measure;mutual information;aggregate markov models;expected probability;new association measure;independence assumption;pointwise mutual information;collocation gold standard	In this paper we start to explore two-part collocation extraction association measures that do not estimate expected probabilities on the basis of the independence assumption. We propose two new measures based upon the well-known measures of mutual information and pointwise mutual information. Expected probabilities are derived from automatically trained Aggregate Markov Models. On three collocation gold standards, we find the new association measures vary in their effectiveness.	aggregate function;blue (queue management algorithm);collocation extraction;curve fitting;heuristic;markov chain;markov model;pointwise mutual information;smart meter;unsupervised learning;virtual private cloud;whole earth 'lectronic link	Gerlof Bouma	2010			data mining;statistics;pointwise mutual information	NLP	-16.441541169715556	-64.22544528621297	70195
ba49dd0db4c9fe50886f93f2c873bd7904305f5d	random manhattan indexing	text analysis data reduction indexing;vector space model;retrieval models vector space model dimensionality reduction random projection manhattan distance;manhattan distance;conference paper;dimensionality reduction;natural language text random manhattan indexing l1 normed vsm dimensionality reduction technique rmi sparse cauchy random projections vector space model;vectors context mathematical model equations computational modeling indexing;retrieval models;random projection	Vector space models (VSMs) are mathematically well-defined frameworks that have been widely used in text processing. In these models, high-dimensional, often sparse vectors represent text units. In an application, the similarity of vectors -- and hence the text units that they represent -- is computed by a distance formula. The high dimensionality of vectors, however, is a barrier to the performance of methods that employ VSMs. Consequently, a dimensionality reduction technique is employed to alleviate this problem. This paper introduces a new method, called Random Manhattan Indexing (RMI), for the construction of L1 normed VSMs at reduced dimensionality. RMI combines the construction of a VSM and dimension reduction into an incremental, and thus scalable, procedure. In order to attain its goal, RMI employs the sparse Cauchy random projections.	curse of dimensionality;dimensionality reduction;feature vector;hamming distance;locality-sensitive hashing;nonlinear system;scalability;sparse matrix;viable system model	Behrang Q. Zadeh;Siegfried Handschuh	2014	2014 25th International Workshop on Database and Expert Systems Applications	10.1109/DEXA.2014.51	computer science;theoretical computer science;machine learning;pattern recognition;euclidean distance;vector space model;dimensionality reduction	NLP	-14.64786154973703	-63.03522020101063	70319
8eea6d5367fd989ede43d80cbefb3df96015a632	dpx: for the analysis of the protein core	graphical programming;fast algorithm;solvent accessibility	SUMMARY In order to obtain an accurate description of the protein interior, we describe a simple and fast algorithm that measures the depth of each atom in a protein (dpx), defined as its distance (A) from the closest solvent accessible atom. The program reads a PDB file containing the atomic solvent accessibility in the B-factor field, and writes a file in the same format, where the B-factor field now contains the dpx value. Output structure files can be thus directly displayed with molecular graphics programs like RASMOL, MOLMOL, Swiss-PDB View and colored according to dpx values.   AVAILABILITY The algorithm is implemented in a standalone program written in C and its source is freely available at ftp.icgeb.trieste.it/pub/DPX or on request from the authors.	4-dichlorobenzene;accessibility;algorithm;atom;digital picture exchange;graphics software;molecular graphics;protein data bank;rasmol;reading (activity);standalone program;staphylococcal protein a;switzerland	Alessandro Pintar;Oliviero Carugo;Sándor Pongor	2003	Bioinformatics	10.1093/bioinformatics/19.2.313	computer science;bioinformatics;theoretical computer science;visual programming language;world wide web	Comp.	-5.107098491435153	-58.06619781161744	70750
604aec385dd0b974ff2af4f5af59ab89bb7784bc	comparing algorithms for large-scale sequence analysis	distributed algorithms;biology computing;sequences;distributed computing;genetics;large scale;internet computing;internet;distributed computation;homology;high performance computer;large scale systems algorithm design and analysis genomics bioinformatics internet distributed computing visual databases genetics visualization biology computing;internet sequences genetics distributed algorithms biology computing;sequence analysis;sequence alignment;sequence alignment algorithms homology analysis large scale sequence analysis algorithms similarity search genomic databases blast algorithm distributed computing platforms parabon frontier internet computing platform idle computer cycles high performance computing smith waterman algorithm large sequence databases visualization tool;similarity search	The first step in homology analysis is usually the comparison of sequences by similarity search. The explosive growth of genomic databases makes it increasingly important to develop more rapid approaches to the comparison of large sequence databases while using the most sensitive methods available. This paper explores the consequences of this trade-off, comparing the results produced by BLAST and Smith-Waterman on genoinic- scale sequence searches. Stich comparisons are now possible thanks to the development of novel distributed computing platforms. This study uses the Parabon Frontier/sup TM/ Internet computing platform, which enables the effective use of the vast supply of idle computer cycles on the Internet for high-performance computing. We have ported both Smith-Waterman and BLAST to the Frontier platform, enabling the efficient use of these algorithms on large sequence databases. In addition, we present a novel visualization tool along with quantitative metrics for comparing the results of alternative sequence alignment algorithms. Our results compare the sensitivity of Smith-Waterman and BLAST for identifying homologies on proteome databases.	algorithm;sequence analysis	Hadon Nash;Douglas Blair;John J. Grefenstette	2001		10.1109/BIBE.2001.974416	biology;distributed algorithm;homology;the internet;computer science;bioinformatics;theoretical computer science;sequence analysis;sequence alignment;data mining;sequence;genetics	ML	-4.717462755579052	-53.37909284056635	71016
5db12987c190e65b14ef10423f0720598780768d	integrated video archive tools	video databases;digital library;digital libraries;browsing;video database;content based retrieval;applications	In traditional video archives, video data are stored on analogue video tapes while meta-data, such as textual descriptions of the contents of the video tapes, are stored and handled digitally by computers. In a fully digital video archive, both video data and meta-data are managed by computers and, thus, more powerful tools can be developed. In this paper, we discuss what kind of tools a digital video archive should ooer its users, and we describe an experimental video archive system which consists of tools for playing, browsing, searching and indexing video information. All tools in the system are based on a generic database platform called VideoSTAR (Video STorage And Retrieval) and they share video and meta-data via the common database. The tools are managed by a video archive tool manager which provides mechanisms for communication and cooperation between different tools. The system has been demonstrated to professional archivists and librarians who have given positive response, and as the next step we will have the system tested in a real video archive environment.	archive;computer;digital video;librarian;videocassette recorder	Rune Hjelsvold;Stein Langørgen;Roger Midtstraum;Olav Sandstå	1995		10.1145/217279.215282	digital library;computer science;multimedia;world wide web;information retrieval;non-linear editing system	Networks	-14.729363242556971	-54.830792186050076	71036
e589b61a3f651a0b1a58558a914f5676c7bf1d97	video summarization based on user-defined constraints and preferences	video summarization;video streaming;video segmentation;feature extraction	In this work we propose a versatile approach to an automatic video summarization problem. In contrast to rigid schemes it allow s a user to specify his preferences concerning desirable content of a summary by imposing constraints on the video segments features. Multiple signal-level and semantic-level features extracted from both the audio and the video streams are combined in this way in order to select relevant video fragment s for a summary. As these fragments are select ed globally for the whole video, some higher level semantic segments may be missed in the summary. To avoid this, a modified technique is proposed that generates a kind of a summary which we call a digest that preserves the semantic structure of the video.	algorithm;automatic summarization;coefficient;cryptographic hash function;interactivity;streaming media	Vyacheslav Parshin;Liming Chen	2004			video compression picture types;computer vision;automatic summarization;video tracking;multimedia;smacker video;motion compensation;video post-processing;world wide web	Vision	-14.622718467187646	-53.54432753515563	71090
ae1565ab95e384e4c204383f349135846d6424d7	learning to collectively link entities	learning;associative markov network;entity disambiguation	Recently Kulkarni et al. [20] proposed an approach for collective disambiguation of entity mentions occurring in natural language text. Their model achieves disambiguation by efficiently computing exact MAP inference in a binary labeled Markov Random Field. Here, we build on their disambiguation model and propose an approach to jointly learn the node and edge parameters of such a model. We use a max margin framework, which is efficiently implemented using projected subgradient, for collective learning. We leverage this in an online and interactive annotation system which incrementally trains the model as data gets curated progressively. We demonstrate the usefulness of our system by manually completing annotations for a subset of the Wikipedia collection. We have made this data publicly available. Evaluation shows that learning helps and our system performs better than several other systems including that of Kulkarni et al.	collective intelligence;entity;markov chain;markov random field;natural language;subderivative;subgradient method;wikipedia;word-sense disambiguation	Ashish Kulkarni;Kanika Agarwal;Pararth Shah;Sunny Raj Rathod;Ganesh Ramakrishnan	2016		10.1145/2888451.2888454	natural language processing;computer science;machine learning;data mining	NLP	-14.4346562521937	-65.61196832340892	71485
2e80fc7e276dc0021c610a3346b8aa080591b3d4	person-based search in videos	person matching;person retrieval;face matching;video editing;face clustering	"""This technical demo is build around a system we developed to automatically match persons within a video sequence. The persons are clustered by face similarity and shot information. The demo is a video editing tool with a """"person query"""" option to show only that part of the sequence that features one of the selected actors. The demo is targeted for narrative content: series and movies, and shows the ability of the underlying person matching algorithm to operate well in a general (unconstrained) case."""	algorithm;information retrieval	Bart Kroon;Sabri Boughorbel;Alan Hanjalic	2007		10.1145/1291233.1291263	computer vision;simulation;computer science;multimedia	Vision	-15.233997525105108	-55.174220989925644	71490
2c23e6ae4b263463ef260ccd76df2508465eb652	multi-transfer: transfer learning with multiple views and multiple sources	transfer learning	Transfer learning, which aims to help the learning task in a target domain by leveraging knowledge from auxiliary domains, has been demonstrated to be effective in different applications, e.g., text mining, sentiment analysis, etc. In addition, in many real-world applications, auxiliary data are described from multiple perspectives and usually carried by multiple sources. For example, to help classify videos on Youtube, which include three views/perspectives: image, voice and subtitles, one may borrow data from Flickr, Last.FM and Google News. Although any single instance in these domains can only cover a part of the views available on Youtube, actually the piece of information carried by them may compensate with each other. In this paper, we define this transfer learning problem as Transfer Learning with Multiple Views and Multiple Sources. As different sources may have different probability distributions and different views may be compensate or inconsistent with each other, merging all data in a simplistic manner will not give optimal result. Thus, we propose a novel algorithm to leverage knowledge from different views and sources collaboratively, by letting different views from different sources complement each other through a co-training style framework, while revise the distribution differences in different domains. We conduct empirical studies on several real-world datasets to show that the proposed approach can improve the classification accuracy by up to 8% against different state-of-the-art baselines.	algorithm;baseline (configuration management);co-training;computerized speech lab;dspace;embedded system;entity–relationship model;experiment;fm broadcasting;flickr;free viewpoint television;google news;hsinchun chen;multimodal interaction;os-tan;overhead (computing);sentiment analysis;single-instance storage;text mining;time complexity;web services distributed management;yang	Ben Tan;Evan Wei Xiang;Qiang Yang;Erheng Zhong	2013		10.1137/1.9781611972832.27	transfer of learning;computer science;data science;machine learning;data mining	ML	-18.236932791241028	-64.82122906923554	71588
c0dda81e5ba813d8fbbea791c19dd3750fcfd546	notice of violation of ieee publication principlesctmir: a novel correlated topic model for image retrieval	notice of violation;model combination;image databases;similarity measure probabilistic latent semantic analysis latent dirichlet allocation image retrieval;notice of violation image retrieval information retrieval large scale systems image databases context modeling content based retrieval data mining;information retrieval;latent dirichlet allocation model;correlation methods;data mining;real world database correlated topic model large scale image retrieval image representation latent dirichlet allocation model similarity measure;large scale image retrieval;latent dirichlet allocation;visual databases correlation methods image representation image retrieval;large scale;image representation;knowledge discovery and data mining;correlated topic model;experimental evaluation;context modeling;similarity measure;content based retrieval;probabilistic latent semantic analysis;large scale systems;real world database;visual databases;image retrieval	Representation of images by the Latent Dirichlet Allocation model combined with an appropriate similarity measure is suitable for performing large scale image retrieval in a real-world database. The LDA model, however, relies on the assumption that all topics are independent of each other something that is obviously not true in most cases. In this work we study a recently proposed model, the Correlated Topic Model (CTM) [1], in the context of large-scale image retrieval. This approach is able to explicitly model such correlations of topics. We experimentally evaluate the proposed retrieval approach on a real-world large-scale database consisting of more than 246,000 images and compare the performance to related approaches.	experiment;generative model;image retrieval;latent dirichlet allocation;similarity measure;topic model	Jian Wen Tao;Pei FenDing	2009	2009 Second International Workshop on Knowledge Discovery and Data Mining	10.1109/WKDD.2009.232	latent dirichlet allocation;image retrieval;computer science;machine learning;pattern recognition;data mining;context model;probabilistic latent semantic analysis;information retrieval;divergence-from-randomness model	Vision	-15.21313556826922	-62.1899324564617	71760
76a4300a52f155d31ff85415dec1e0c2cd3302cf	using thumbnail affinity for fragmentation point detection of jpeg files		File carving tools carry out file recovery whenever the file-system meta-data is not available, which makes them a valuable addition to the cyber crime investigator's toolkit. Existing file carvers either cannot handle fragmented files or require a probabilistic model derived using a number of training images. This training data may not always be feasible to aggregate or its sheer size could undermine practicality. Similar to existing techniques, our method exploits both the JPEG syntax and semantic-based analysis steps in order to distinguish the correct fragments required for recovering images. The thumbnail affinity-based semantic analysis constitutes the novel aspect of this approach. Comparative evaluation using three widely used benchmark test sets show that our carver compares with the state-of-the-art commercial tool that requires an a-priori model while beating a number of popular forensic tools. This outcome demonstrates the successful replacement of the probabilistic model with thumbnail affinity, rendering this technique the right complement for existing carvers in situations where thumbnail information is readily available.	affinity analysis;aggregate data;anti-computer forensics;benchmark (computing);cybercrime;cyclic redundancy check;data recovery;embedded system;entropy encoding;fragmentation (computing);heuristic (computer science);image file formats;internet police;jpeg;lookup table;semantic analysis (compilers);statistical model;test set;thumbnail;video file format	Brandon Birmingham;Reuben A. Farrugia;Mark Vella	2017	IEEE EUROCON 2017 -17th International Conference on Smart Technologies	10.1109/EUROCON.2017.8011068	rendering (computer graphics);file carving;thumbnail;probabilistic logic;file system fragmentation;transform coding;data mining;jpeg;computer science;fragmentation (computing)	SE	-9.862928073014215	-62.44055095749791	72385
78f6ba67bc1d4544f4e6df5e7a4aa8ec861c32e6	video hyperlinking: libraries and tools for threading and visualizing large video collection	partial near duplicates;large scale video browsing;video hyperlinking	While HTML documents could be effortlessly hyperlinked by markup tags, creation of the hyperlinks for multimedia objects is by no means easy due to the involvement of various visual processing units and intensive computational overhead. This paper introduces an open source, named VIREO-VH, which provides end-to-end support for creating hyperlinks to thread and visualize collections of videos. The software components include video pre-processing, bag-of-words based inverted file indexing for scalable near-duplicate keyframe search, localization of partial near-duplicate segments, and galaxy visualization of video collection. The open source has been internally used by VIREO research team since 2007, and was evolved over years based on experiences through developing various multimedia applications.	bag-of-words model;component-based software engineering;computation;end-to-end principle;html;hyperlink;inverted index;key frame;library (computing);markup language;open-source software;overhead (computing);preprocessor;scalability;thread (computing)	Lei Pang;Wei Zhang;Hung-Khoon Tan;Chong-Wah Ngo	2012		10.1145/2393347.2396520	computer science;video tracking;database;multimedia;world wide web	Web+IR	-15.634481322582078	-55.38532418189628	73444
1ba262424fb816e85c9bb787bcae0d9217d96b3b	modeling functional magnetic resonance imaging (fmri) experimental variables in the ontology of experimental variables and values (ooevv)	software;neuroimaging;magnetic resonance imaging;humans	Neuroimaging data is raw material for cognitive neuroscience experiments, leading to scientific knowledge about human neurological and psychological disease, language, perception, attention and ultimately, cognition. The structure of the variables used in the experimental design defines the structure of the data gathered in the experiments; this in turn structures the interpretative assertions that may be presented as experimental conclusions. Representing these assertions and the experimental data which support them in a computable way means that they could be used in logical reasoning environments, i.e. for automated meta-analyses, or linking hypotheses and results across different levels of neuroscientific experiments. Therefore, a crucial first step in being able to represent neuroimaging results in a clear, computable way is to develop representations for the scientific variables involved in neuroimaging experiments. These representations should be expressive, computable, valid, extensible, and easy-to-use. They should also leverage existing semantic standards to interoperate easily with other systems. We present an ontology design pattern called the Ontology of Experimental Variables and Values (OoEVV). This is designed to provide a lightweight framework to capture mathematical properties of data, with appropriate 'hooks' to permit linkage to other ontology-driven projects (such as the Ontology of Biomedical Investigations, OBI). We instantiate the OoEVV system with a small number of functional Magnetic Resonance Imaging datasets, to demonstrate the system's ability to describe the variables of a neuroimaging experiment. OoEVV is designed to be compatible with the XCEDE neuroimaging data standard for data collection terminology, and with the Cognitive Paradigm Ontology (CogPO) for specific reasoning elements of neuroimaging experimental designs.	cognition disorders;computable function;computational neuroscience;data collection;design of experiments;experiment;interoperability;linkage (software);magnetic resonance imaging;mathematics;meta analysis (statistical procedure);neuritis, autoimmune, experimental;neuroimaging;neuroscience discipline;nomenclature;ontology;programming paradigm;reasoning;software design pattern;web standards;fmri;genetic linkage;standards characteristics	Gully A. P. C. Burns;Jessica A. Turner	2013	NeuroImage	10.1016/j.neuroimage.2013.05.024	psychology;neuroscience;radiology;medicine;computer science;artificial intelligence;magnetic resonance imaging;data mining;mathematics;communication;neuroimaging	ML	-5.528262962473467	-64.28321191259667	73787
51a10e4a447aa6940448b878807665b23c88c413	modeling personalized email prioritization: classification-based and regression-based approaches	learning;performance;email prioritization;mathematical methods and computing;human factors;spam filtering;machine learning;simulation algorithms;productivity;experimentation;ordinal regression	Email overload, even after spam filtering, presents a serious productivity challenge for busy professionals and executives. One solution is automated prioritization of incoming emails to ensure the most important are read and processed quickly, while others are processed later as/if time permits in declining priority levels. This paper presents a study of machine learning approaches to email prioritization into discrete levels, comparing ordinal regression versus classifier cascades. Given the ordinal nature of discrete email priority levels, SVM ordinal regression would be expected to perform well, but surprisingly a cascade of SVM classifiers significantly outperforms ordinal regression for email prioritization. In contrast, SVM regression performs well -- better than classifiers -- on selected UCI data sets. This unexpected performance inversion is analyzed and results are presented, providing core functionality for email prioritization systems.	email filtering;machine learning;ordinal data;ordinal regression;personalization;priority queue	Shinjae Yoo;Yiming Yang;Jaime G. Carbonell	2011		10.1145/2063576.2063683	ordinal regression;productivity;performance;computer science;human factors and ergonomics;data science;machine learning;data mining;database;world wide web	ML	-19.110083596321722	-52.530522049643245	73841
303b21f0941984df4c34a305e6dfb809be50930f	high quality visualization of biochemical pathways in biopath	visualization;biochemical pathways;metabolic pathways;graph drawing;complex network;hierarchical clustering;metabolic pathway	Biochemical reactions form large and complex networks. Comprehensible visual representations of these networks help biochemists understand the relationships between the chemical components. Typically pathway diagrams are manually produced drawings. Because of the steady progress of knowledge and the complex relationships in these networks, automatic visualizations are necessary. Bio-Path is a system for the exploration and automatic visualization of biochemical pathways. It has been developed to obtain an electronic version of the well-known Boehringer Biochemical Pathways poster and offers new possibilities to find information and to navigate through pathways. BioPath has a specific database containing reactions and a hierarchical clustering of reactions and reaction networks. One feature is the automatic generation of pathways from the database and their high quality visualization. This paper states the requirements for the visualization of biochemical pathways, presents a layout algorithm and shows how BioPath can be used to explore biochemical reaction networks.	algorithm;biochemical phenomena;biochemical reaction;cluster analysis;complex network;diagram;display resolution;drawings (art);force-directed graph drawing;gene regulatory network;hierarchical clustering;imagery;requirement;whole earth 'lectronic link;statistical cluster	Falk Schreiber	2002	In silico biology		visualization;bioinformatics;complex network;graph drawing;hierarchical clustering;computer science	Visualization	-6.4773052134014195	-60.43948359950506	73868
5b89190c4f32c14f29fbd65ec4a52830c6a29612	automatic annotation of video streams	image recognition;video streaming;video signal processing;temporal logic;temporal logic model automatic annotation video stream soccer highlight;sports video;automatic annotation;streaming media multimedia communication production europe logic tv broadcasting cameras tin indexing content based retrieval;image recognition video signal processing broadcasting temporal logic sport object detection;broadcasting;sport;product quality;object detection	Broadcasters are demonstrating interest in systems that ease the process of annotating huge amount of live and archived video materials. Exploitation of such assets is considered a key method for the improvement of production quality and sport videos (one of the most marketable assets). In Europe, soccer is one of the most relevant sport types. This paper deals with detection and recognition of soccer highlights, using an approach based on temporal logic models.	archive;streaming media;temporal logic	Marco Bertini;Alberto Del Bimbo;Walter Nunziati	2004	IEEE 6th Workshop on Multimedia Signal Processing, 2004.	10.1109/MMSP.2004.1436393	computer vision;temporal logic;computer science;sport;video capture;video tracking;multimedia;video processing;internet privacy;broadcasting	Vision	-13.828640278731962	-55.32417282758123	73926
249757ad6f167d6340c5f809fea061180af3136e	a variational bayesian em algorithm for tree similarity	variational bayesian em algorithm;generators;learning algorithm;trees mathematics bayes methods expectation maximisation algorithm learning artificial intelligence tree data structures;labeled tree;tree similarity;generic model;hidden markov models probabilistic logic tuning data mining bayesian methods generators training data;bayes methods;bayesian methods;variational bayesian;tree matching;tree data structures;trees mathematics;data mining;probabilistic model;training data;maximum likelihood estimate;hidden markov models;learning algorithm variational bayesian em algorithm tree similarity tree structured data;tuning;expectation maximization;tree structure;probabilistic logic;learning artificial intelligence;tree structured data;probabilistic model tree matching;em algorithm;similarity measure;expectation maximisation algorithm	In recent times, a vast amount of tree-structured data has been generated. For mining, retrieving, and integrating such data, we need a fine-grained tree similarity measure that can be adapted to objective data. To achieve this goal, this paper (1) proposes a probabilistic generative model that generates pairs of similar trees, and (2) derives a learning algorithm for estimating the parameters of the model based on the variational Bayesian expectation maximization (VBEM) method. This method can handle rooted, ordered, and labeled trees. We show that the tree similarity model obtained via the BEM technique performs better than that obtained via maximum likelihood estimation by tuning the hyper parameters.	boundary element method;calculus of variations;expectation–maximization algorithm;generative model;similarity measure;variational principle	Atsuhiro Takasu;Daiji Fukagawa;Tatsuya Akutsu	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.264	mathematical optimization;expectation–maximization algorithm;computer science;machine learning;pattern recognition;mathematics;hidden markov model;statistics	ML	-16.884694942897532	-63.22985228907658	73935
8363432b096bb45f8d87f2f9304e0869ebf7bb3a	user-driven nearest neighbour exploration of image archives		Learning what a specific user is exactly looking for, during a session of image search and retrieval, is a problem that has been mainly approached with “classification” or “exploration” techniques. Classification techniques follow the assumption that the images in the archive are statically subdivided into classes. Exploration approaches, on the other hand, are more focused on following the varying needs of the user. It turns out that image retrieval techniques based on classification approaches, though often showing good performances, are not prone to adapt to different users’ goals. In this paper we propose a relevance feedback mechanism that drives the search into promising regions of the feature space according to the Nearest Neighbor paradigm. In particular, each image labelled as being relevant by the user, is used as a “seed” for an exploration of the space based on the Nearest Neighbors paradigm. Reported results show that this technique allows attaining higher recall and average precision performances than other state-of-the-art relevance feedback approaches.	adaptive behavior;archive;categorization;content-based image retrieval;experiment;feature vector;future internet;image retrieval;information retrieval;iteration;performance;programming paradigm;relevance feedback;social network;statistical classification	Luca Piras;Deiv Furcas;Giorgio Giacinto	2015			image retrieval;computer science;machine learning;pattern recognition;data mining	Web+IR	-17.83739325771413	-61.53560053922198	74054
5e5a6070d57ca3b9920f2700581b2bc7d9ced144	content-based description of images for retrieval in large databases: muvis	content;indexing;query;retrieval;color;features;shape;texture	The rapid increase in the size of digital image and video collections is urging for the development of efficient browsing and search tools that skip the subjective task of keyword indexing, paving the way for the ambitious and challenging idea of content based description of imagery. With this goal in mind the MUVIS1 system attempts to provide an integrated solution for the indexing and retrieval of images based on their content within large databases. In this paper we describe briefly the overall structure of the system and expose the promising results obtained so far, demonstrating the similarity retrieval capabilities of the system based on separate image features.	content-based image retrieval;database;digital image;web indexing	Mejdi Trimeche;Faouzi Alaya Cheikh;Moncef Gabbouj;Bogdan Cramariuc	2000	2000 10th European Signal Processing Conference		computer vision;visual word;computer science;multimedia;automatic image annotation;information retrieval	Vision	-14.232576020234799	-58.08360927327191	74345
66029f1be1a5cee9a4e3e24ed8fcb65d5d293720	accounting for the relative importance of objects in image retrieval	image retrieval	We introduce a method for image retrieval that leverages the implicit information about object importance conveyed by the list of keyword tags a person supplies for an image. We propose an unsupervised learning procedure based on Kernel Canonical Correlation Analysis that discovers the relationship between how humans tag images (e.g., the order in which words are mentioned) and the relative importance of objects and their layout in the scene. Using this discovered connection, we show how to boost accuracy for novel queries, such that the search results may more closely match the user’s mental image of the scene being sought. We evaluate our approach on two datasets, and show clear improvements over both an approach relying on image features alone, as well as a baseline that uses words and image features, but ignores the implied importance cues.	baseline (configuration management);image retrieval;importance sampling;natural language;unsupervised learning	Sung Ju Hwang;Kristen Grauman	2010		10.5244/C.24.58	computer vision;visual word;image retrieval;computer science;data mining;automatic image annotation;information retrieval	Vision	-16.380529541211803	-61.2811752226865	74684
66b051d13d752a27187b443f6288b12b99c6b5d6	an online advertisement platform based on image content bidding	advertisement platform;image content understanding;search engine;image retrieval content based retrieval search engines image matching message service tellurium internet web pages asia motion pictures;roi detection;keyword matching techniques;advertisement editorial tool;search engines;advertising data processing;image matching;servers;image color analysis;feature extraction;visual search;image content bidding;multimedia communication;image search;online advertising;user queries;lighting;editorials;advanced keyword matching;content based image retrieval;multimedia messaging service;content based image retrieval online advertisement platform image content bidding search engines advanced keyword matching user queries keyword matching techniques advertisement editorial tool image content understanding image matching multimedia messaging service;search engines advertising data processing image matching;online advertisement platform;roi detection advertisement platform image content bidding image search	A critical component of today's commercial search engines is an advertisement platform. The current state-of-the-art of such platforms is primarily based on advanced keyword matching to determine the relevance of advertisements for users' queries. However, such keyword matching techniques suffer from missing user intent when the query domain is visual as opposed to textual. To handle such a domain, we propose a new advertisement platform which allows search engine advertisers to bid on images instead of just plain text. The main components of this platform include an advertisement editorial tool, ROI detection, image content understanding, and image matching modules. This platform is suitable for application scenarios where images are the main input or consumed content, for example, in Multimedia Messaging Service (MMS) or content based image retrieval. We demonstrated the effectiveness of our proposed advertisement platform solution when used in a mobile visual search scenario involving querying for real world billboards.	content-based image retrieval;image registration;online advertising;region of interest;relevance;web search engine	Wei Jiang;Dechao Liu;Xing Xie;Matthew R. Scott;Jonathan Tien;Dong Xiang	2009	2009 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2009.5202724	online advertising;computer science;multimedia;world wide web;information retrieval;search engine	Vision	-15.420154722240573	-55.24568591210663	74961
969b70e0489d6a3fdd53292459cbb2a815d5f7c6	bioimage informatics: a new area of engineering biology	diagnostic imaging;computer graphics;bioinformatique;models biological;biology;biologia;biomedical engineering;bioinformatica;user computer interface;computational biology;computer simulation;biologie;bioinformatics	In recent years, the deluge of complicated molecular and cellular microscopic images creates compelling challenges for the image computing community. There has been an increasing focus on developing novel image processing, data mining, database and visualization techniques to extract, compare, search and manage the biological knowledge in these data-intensive problems. This emerging new area of bioinformatics can be called 'bioimage informatics'. This article reviews the advances of this field from several aspects, including applications, key techniques, available tools and resources. Application examples such as high-throughput/high-content phenotyping and atlas building for model organisms demonstrate the importance of bioimage informatics. The essential techniques to the success of these applications, such as bioimage feature identification, segmentation and tracking, registration, annotation, mining, image data management and visualization, are further summarized, along with a brief overview of the available bioimage databases, analysis tools and other resources.	annotation;atlases;bioimage informatics;bioinformatics;data mining;data-intensive computing;database;high-throughput computing;image processing;image registration;imagery;informatics (discipline);throughput;registration - actclass	Hanchuan Peng	2008	Bioinformatics	10.1093/bioinformatics/btn346	computer simulation;biology;computer science;bioinformatics;data science;data mining;computer graphics	Visualization	-5.950156809659162	-61.52576298818801	75016
040e69b7a1605577150a7533f57c1b76d2da165c	topic models for unsupervised cluster matching		We propose topic models for unsupervised cluster matching, which is the task of finding matching between clusters in different domains without correspondence information. For example, the proposed model finds correspondence between document clusters in English and German without alignment information, such as dictionaries and parallel sentences/documents. The proposed model assumes that documents in all languages have a common latent topic structure, and there are potentially infinite number of topic proportion vectors in a latent topic space that is shared by all languages. Each document is generated using one of the topic proportion vectors and language-specific word distributions. By inferring a topic proportion vector used for each document, we can allocate documents in different languages into common clusters, where each cluster is associated with a topic proportion vector. Documents assigned into the same cluster are considered to be matched. We develop an efficient inference procedure for the proposed model based on collapsed Gibbs sampling. The effectiveness of the proposed model is demonstrated with real data sets including multilingual corpora of Wikipedia and product reviews.	cluster analysis;computer cluster;dictionary;discrete mathematics;emoticon;experiment;general instrument ay-3-8910;gibbs sampling;markov chain monte carlo;monte carlo method;public-key cryptography;sampling (signal processing);semi-supervised learning;semiconductor industry;text corpus;topic model;unsupervised learning;vector graphics;wikipedia	Tomoharu Iwata;Tsutomu Hirao;Naonori Ueda	2018	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2017.2778720	machine learning;topic model;computer science;artificial intelligence;data modeling;cluster analysis;data set;sorting;inference;vocabulary;gibbs sampling	ML	-16.54124672728835	-64.03340705409825	75206
8c38fa7f7ea682733163b291e8ca7b775422ad26	random positive-only projections: ppmi-enabled incremental semantic space construction.		We introduce positive-only projection (PoP), a new algorithm for constructing semantic spaces and word embeddings. The PoP method employs random projections. Hence, it is highly scalable and computationally efficient. In contrast to previous methods that use random projection matrices R with the expected value of 0 (i.e., E(R) = 0), the proposed method uses R with E(R) > 0. We use Kendall’s τb correlation to compute vector similarities in the resulting non-Gaussian spaces. Most importantly, since E(R) > 0, weighting methods such as positive pointwise mutual information (PPMI) can be applied to PoP-constructed spaces after their construction for efficiently transferring PoP embeddings onto spaces that are discriminative for semantic similarity assessments. Our PoP-constructed models, combined with PPMI, achieve an average score of 0.75 in the MEN relatedness test, which is comparable to results obtained by state-of-the-art algorithms.	algorithm;algorithmic efficiency;artificial neural network;computation;computational resource;dimensionality reduction;entity–relationship model;experiment;natural language;pointwise mutual information;random projection;scalability;semantic similarity;word embedding	Behrang Q. Zadeh;Laura Kallmeyer	2016		10.18653/v1/S16-2024	combinatorics;discrete mathematics;topology;mathematics	ML	-15.763615310453828	-65.11242402901021	75397
fb08766a5ac0ac43ea50db7d58843b5bd8c7b796	using ontologies for preprocessing and mining spectra data on the grid	software tool;mass spectrometry;integrated management;data mining	The analysis of mass spectrometry proteomics data requires the composition of different software tools devoted to the loading, management, preprocessing, mining, and visualization of spectra data. This paper proposes the use of ontologies to guide the composition of preprocessing and data mining tools and describes the approach through MS-Analyzer, a software tool for the integrated management, preprocessing and mining of spectra data on the Grid. c © 2006 Elsevier B.V. All rights reserved.	data mining;ontology (information science);preprocessor;programming tool;proteomics	Mario Cannataro;Pietro Hiram Guzzi;Tommaso Mazza;Giuseppe Tradigo;Pierangelo Veltri	2007	Future Generation Comp. Syst.	10.1016/j.future.2006.04.011	mass spectrometry;computer science;bioinformatics;data science;data mining	HPC	-5.331323898618125	-59.07409674415493	75905
0dc966ff1a90c43fbf5c8193142ae46cdd74fc91	specdb: a database for storing and managing mass spectrometry proteomics data	mass spectrometer;human disease;data integrity;mass spectra;mass spectrometry;knowledge extraction;software systems	Data produced by mass spectrometer (MS) have been using in proteomics experiments to identify proteins or patterns in clinical samples that may be responsible of human diseases. Nevertheless, MS data are affected by errors and different preprocessing techniques have to be applied to manipulate and gathering information from data. Moreover, MS samples contain a huge amount of data requiring an efficient organization both to reduce access time to data, and to allow efficient knowledge extraction. We present the design and the implementation of a database for managing MS data, integrated in a software system for the loading, preprocessing, storing and managing of mass spectra data.	proteomics	Mario Cannataro;Pierangelo Veltri	2005		10.1007/11676935_29	mass spectrum;mass spectrometry;computer science;bioinformatics;data integrity;data mining;mass spectrometry data format;software system	DB	-4.9397200037493025	-61.817259996401184	76901
1f9b9f2dab626df96ba5decceb8296346e076fc6	ranking feature for classifier-based instance matching		Instance matching is the problem of finding the instances that describe the same object. It can be viewed as a classification problem, where a pair of two instances is predicted as match or non-match. A common limitation of existing classifier-based matching systems is the absence of instance pairs ranking. We propose using a ranking feature to enhance the classifier in instance matching. Experiments on real datasets confirm the significant improvement when applying our method.	statistical classification	Khai Nguyen;Ryutaro Ichise	2016			ranking svm;computer science;classifier (linguistics);margin classifier;artificial intelligence;pattern recognition;ranking	DB	-17.706054524985724	-65.85064437255588	77580
aafecf4743a70fe7a0827cf50c53ee3275c18035	smart video player	video summaries;video collage;video content analysis techniques content based smart video player video sharing web site video summaries video collage;video sharing web site;content based smart video player;video equipment;video content analysis techniques;video recording;video content analysis;video recording video equipment	In this demonstration, we present a content-based smart video player, which can help users browse and seek videos in an effective and efficient manner. Through this player, users can easily get recommendations from local hard disk or video sharing Web site, create video summaries, and generate video collage. With the video content analysis techniques, the smart video player brings users better viewing experience.	browsing;digital video;hard disk drive;video content analysis	Linjun Chang;Yichen Yang;Xian-Sheng Hua	2008	2008 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2008.4607760	video compression picture types;microsoft video 1;video;h.263;bink video;video production;uncompressed video;video capture;video tracking;multimedia;video processing;smacker video;internet privacy;world wide web;pevq;non-linear editing system	Visualization	-15.048596204362328	-54.252630299836326	78155
0e979422896f63a93ab463af9eeb0013f6c5abb0	learning local semantic distances with limited supervision	semantic aware;manifolds semantics measurement vectors data mining context symmetric matrices;instance based;measurement;manifolds;semantics;semantic aware semi supervised instance based similarity learning metric learning;semi supervised;data mining;metric learning;symmetric matrices;retrieval application local semantic distance learning distance function learning distance metric data mining web search user intentions single global distance function data locality local metric learning algorithm local semantic sensing lss manifold structure supervised intentional knowledge;vectors;similarity learning;search engines data mining information retrieval internet learning artificial intelligence;context	Recent advances in distance function learning have demonstrated that learning a good distance metric can greatly improve the performance in a wide variety of tasks in data mining and web search. A major problem in such scenarios is the limited labeled knowledge available for learning the user intentions. Furthermore, distances are inherently local, where a single global distance function may not capture the distance structure well. A challenge here is that local distance learning is even harder when the labeled information available is limited, because the distance function varies with data locality. To address these issues, we propose a local metric learning algorithm termed Local Semantic Sensing (LSS), which augments the small amount of labeled data with unlabeled data in order to learn the semantic information in the manifold structure, and then integrated with supervised intentional knowledge in a local way. We present results in a retrieval application, which show that the approach significantly outperforms other state-of-the-art methods in the literature.	algorithm;baseline (configuration management);data mining;experiment;intensional logic;locality of reference;principle of locality;semiconductor industry;unsupervised learning;web search engine	Shiyu Chang;Charu C. Aggarwal;Thomas S. Huang	2014	2014 IEEE International Conference on Data Mining	10.1109/ICDM.2014.114	semi-supervised learning;manifold;machine learning;pattern recognition;data mining;mathematics;semantics;measurement;symmetric matrix	ML	-16.02022038418892	-66.14596967411575	78731
6931dad6d6c5c7682966ceaf47f388ee2c61be98	automatic classification for the identification of relationships in a meta-data repository	database system;text;classification algorithm;metadata;intelligence artificielle;texte;data mining;text classification;detection objet;detector proximidad;automatic detection;fouille donnee;metadonnee;base donnee orientee objet;artificial intelligence;object oriented databases;object classification;metadatos;inteligencia artificial;classification automatique;automatic classification;texto;clasificacion automatica;busca dato;proximity detector;object detection;detecteur proximite	For a major company a prototype for automatic detection of similar objects in database systems has been developed. This task has been accomplished by transferring the database object classification problem into a text classification problem and applying standard classification algorithms. Although the data provided for the task did not look promising from a technical point of view, the results turned out to be very good.	algorithm;database;document classification;point of view (computer hardware company);prototype	Gerd Beuster;Ulrich Furbach;Margret Groß-Hardt;Bernd Thomas	2003		10.1007/978-3-540-39644-4_24	computer science;artificial intelligence;pattern recognition;data mining;database;metadata;one-class classification;information retrieval;library classification	DB	-12.954548076454873	-59.75946166731378	78776
45c44703caf22501ef8dbf1b670eade1c64faf01	fusion analysis of information retrieval models on biomedical collections	analytical models;multiple scoring systems;biomedical measurements;score function;biomedical literature collection;medical administrative data processing;performance evaluation;information retrieval;biological system modeling;semantics;information retrieval model;combinatorial fusion analysis cfa;rank score function;biomedical literature collection information retrieval combinatorial fusion analysis cfa rank score function rank score characteristic rsc graph multiple scoring systems multiple ranking systems information fusion;mathematical model;biological system modeling analytical models information retrieval mathematical model biomedical measurements correlation semantics;information fusion;correlation;sensor fusion;sensor fusion information retrieval medical administrative data processing;multiple ranking systems;high performance;analytical model;ranking behavior information retrieval models biomedical collections biomedical information retrieval area information fusion combinatorial fusion analysis scoring behavior;rank score characteristic rsc graph;scoring system	A variety of endeavors have been made to improve the performance of traditional information retrieval models in biomedical domain. However, majority of the studies have focused on improving the performance of individual information retrieval models, while few attempts have been made to the investigation of combining multiple information retrieval models and exploring their interactions in biomedical information retrieval area. In this study, a comprehensive performance evaluation of seven popular generic information retrieval models is conducted on a biomedical literature collection. In addition, an information fusion method called the Combinatorial Fusion Analysis is applied to perform extensive combinatorial experiments on these information retrieval models. Our experimental results have demonstrated that a combination of multiple information retrieval models can outperform a single model only if each of the individual models has different scoring and ranking behavior and relatively high performance.	experiment;information retrieval;interaction;performance evaluation	Yanjun Li;Ningtao Shi;D. Frank Hsu	2011	14th International Conference on Information Fusion		relevance;cognitive models of information retrieval;computer science;machine learning;data mining;adversarial information retrieval;information retrieval;human–computer information retrieval	Web+IR	-18.322862492027458	-61.07322762614871	79343
fbadf89b990acedf23e1df03d4869010d2dbc59e	human focused video description	humans legged locomotion feature extraction natural languages streaming media visualization face;video streaming;legged locomotion;video signal processing;high level feature extraction human focused video description natural language description human action human behaviour video stream image processing;natural languages;video signal processing feature extraction natural language processing;visualization;streaming media;feature extraction;natural language;image processing techniques;face;humans;natural language processing	This contribution addresses generation of natural language descriptions for human actions and behaviour observed in video streams. The work starts with implementation of conventional image processing techniques to extract high-level features from video. Because human is often the most important and also interesting feature, description focuses on humans and their activities. Although feature extraction processes are erroneous at various levels, we explore approaches to put them together to produce a coherent description. Evaluation is made by calculating the overlap similarity score between human authored and machine generated descriptions.	audio description;coherence (physics);feature extraction;high- and low-level;high-level programming language;image processing;interaction;natural language;natural language generation;streaming media;top-down and bottom-up design	Muhammad Usman Ghani Khan;Yoshihiko Gotoh	2011	2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)	10.1109/ICCVW.2011.6130425	computer vision;feature extraction;computer science;multimedia;natural language;information extraction	Vision	-14.748017075557145	-57.53350524588122	79448
5a304c45dceaa1a7ca78805e112c9653d360d8b2	camera selection using scsps	sports video;scsp;finite state machine;camera	An automated director is needed for sports video games to select between multiple camera views. An SCSP approach enables setting preferences for views that depend on the current situation. This approach is better than using a classical CSP, or a finite state machine.	finite-state machine;yamaha ymf292	Michael Janzen;Michael C. Horsch;Eric Neufeld	2008		10.1145/1496984.1497038	computer vision;simulation;computer science;multimedia	AI	-13.025014603828074	-53.14587116093319	80091
6d6c152d3f8c3e4d8f02a081bc0d2b069b6e17c3	personalized video summarization by highest quality frames	biomedical monitoring;video summarization;video signal processing;semantics;transform coding;personalization;conference paper;visualization;personalized video summaries personalized video summarization video frames video segments video scenes predefined skimming time;streaming media;abstracts;upgrading frames scores;visualization abstracts semantics streaming media biomedical monitoring context transform coding;upgrading frames scores video summarization personalization;context	In this work, a user-centered approach has been the basis for generation of the personalized video summaries. Primarily, the video experts score and annotate the video frames during the enrichment phase. Afterwards, the frames scores for different video segments will be updated based on the captured end-users (different with video experts) priorities towards existing video scenes. Eventually, based on the pre-defined skimming time, the highest scored video frames will be extracted to be included into the personalized video summaries. In order to evaluate the effectiveness of our proposed model, we have compared the video summaries generated by our system against the results from 4 other summarization tools using different modalities.		Kaveh Darabi;George Ghinea	2014	2014 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)	10.1109/ICMEW.2014.6890674	video compression picture types;transform coding;visualization;computer science;video quality;automatic summarization;video tracking;personalization;semantics;multimedia;video processing;smacker video;world wide web;pevq;information retrieval;multiview video coding	Vision	-14.566950800216542	-53.565002689554376	80587
f32c5a443775ea085ec3cd6056cc826f603de635	a descriptive tour of the semantic structures apply to video surveillance systems		Automatic systems that monitor human behavior for detecting security problems are a challenge today. In this work, we analysing the semantic structure required to representing the human behaviour in high-level semantic events. We identify the principal components of different ontologies and describe the goal of each semantic structure. This work describes Horus, because we believe that this framework is a good example of a methodology composed to different levels, the goal is to describe human behavior a video surveillance systems. We propose an idea to complete Horus based in semantic structures. The finish work is obtain an art state about semantic structures apply to video surveillance systems, and generating conclusions and future works from of theory.		Héctor F. Gómez Alvarado;Silvia Elena Malo Martínez;Claudia Paola Cartuche Flores	2016		10.1007/978-3-319-31232-3_34	computer vision;computer science;data mining;multimedia	NLP	-11.932929429889539	-52.22398820109308	80694
1dc1916d4330a210ed3a962ac831591b8332b30c	a retrieval mechanism for semi-structured photographic collections	base donnee;multimedia;information re trieval;information retrieval;dempster shafer theory of evidence;database;base dato;multimedia information retrieval;recherche documentaire;recherche information;indexation;dempster shafer theory;recuperacion documental;retrieval model;document retrieval;recuperacion informacion;theorie information;information theory;everyday life;teoria informacion	Abs t rac t . In this paper, a new approach for retrieval from semistructured photographic collections is described. We have developed a retrieval model based on the Dempster-Shafer theory of evidence combination. Basic concepts of the Dempster-Shafer theory are explained and the suitability of this theory for information retrieval is explored. A retrieval model for a semi-structured photographic collection is presented. Extensibitity of this retrieval model for multimedia information retrieval is discussed. Integration of database and information retrieval concepts is a major requirement for semi-structured multimedia information retrieval and is accomplished in this model. A novel indexing scheme for photographic materials is described. We use spatial features, which are objects and their location, as photographic features. We. have developed a multi-modal query interface for querying a photographic collection. A prototype system, Epic, has been implemented and is described in this paper.	autostereogram;database;exploit (computer security);feature (computer vision);feature extraction;image processing;information retrieval;modal logic;prototype;semi-structured data;semiconductor industry	Joemon M. Jose;David J. Harper	1997		10.1007/BFb0022038	document retrieval;computer vision;visual word;relevance;dempster–shafer theory;information theory;computer science;data mining;vector space model;data retrieval;information retrieval;statistics;human–computer information retrieval	Web+IR	-12.7629327083885	-58.67208957342575	81084
283469e94a81030662dc06331ac401f9a4974904	audio similarity retrieval engine	metric space;messif;similarity retrieval;audio;similarity measure;similarity search;mpeg 7	This paper briefly describes an audio similarity retrieval engine included in the MUFIN project. The engine uses low-level audio descriptors defined by MPEG-7 standard for calculation of similarity measure between audio recordings. The core of the engine is implemented in Java with the use of the MESSIF framework that provides support for metric-based indexing and searching. The presentation layer of the engine is provided by the MUFIN interface.	high- and low-level;java;mpeg-7;similarity measure	Pavel Jurkas;Milan Stefina;David Novak;Michal Batko	2010		10.1145/1862344.1862365	topology;metric space;theoretical computer science;mathematics;world wide web;information retrieval	Web+IR	-13.55487899352787	-57.420160362816894	81101
e66ee337aa47e2d6829476ee4379513b3d180fc4	visual haptic-based biomolecular docking	drugs;biology computing;e learning haptic interface biomolecular docking;electronic learning;drugs electronic learning assembly visualization haptic interfaces chemistry biophysics bioinformatics computer simulation biology computing;computer aided design;haptic device;cad;real time;computer aided instruction;interactive visualization;virtual reality;structural biology;force;three dimensional;biomembranes;biomolecular docking;rational drug design;data visualisation;distance measurement;visualization;proteins;visualization technique;virtual reality assembling biology computing cad computer aided instruction data visualisation drugs haptic interfaces molecular biophysics;helix helix interactions visual haptic biomolecular docking cyberworlds e learning research intensive disciplines computer simulation molecule assembling computer aided rational drug design real time interactive visualization molecule manipulation virtual environment pharmaceutical drugs haptic interfaces;assembling;molecular biophysics;e learning;virtual environment;haptic interfaces;molecular interactions;computer simulation;molecular docking;haptic interface	Cyberworlds could be a platform for both research and e-learning particularly in research intensive disciplines such as biology, physical chemistry, molecular medicine, biophysics, structural biology, bioinformatics, etc. The computer simulation of assembling molecules has been studied intensively in the field of computer-aided rational drug design. The assembly of molecules in a three-dimensional space or molecular docking is used for rational drug design where a ligand docks onto a receptor. The computer-aided design systems allow real-time interactive visualization and manipulation of molecules in virtual environment. These techniques help the user to understand molecular interactions, and to evaluate the design of pharmaceutical drugs. Besides the visualization techniques, there has been increasing interest in using haptic interfaces to facilitate the exploration and analysis of molecular docking. Haptic device could enable the users to manipulate the molecules and feel its interaction during the docking process in virtual experiment on computer. In this paper, we propose visual haptic-based biomolecular docking system that could be used for biomolecular docking to study helix-helix interactions and in e-learning.	bioinformatics;computer simulation;computer-aided design;docking (molecular);haptic technology;interaction;interactive visualization;real-time transcription;virtual reality;virtual world	Olga Sourina;Jaume Torres;Jing Wang	2008	2008 International Conference on Cyberworlds	10.1109/CW.2008.77	computer simulation;simulation;interactive visualization;human–computer interaction;computer science;bioinformatics;artificial intelligence;virtual reality;structural biology;haptic technology;molecular biophysics	Visualization	-8.349216818836	-56.7183403549379	81324
90b36d9d26513db248b0c4e0d16c51c69738a797	modeling continuous visual features for semantic image annotation and retrieval	busqueda informacion;modelizacion;anotacion;ajustamiento modelo;semantic annotation;image processing;learning;continuous plsa;recherche image;information retrieval;automatic image annotation;procesamiento imagen;annotation;probabilistic approach;image annotation;traitement image;journal;aprendizaje;ajustement modele;modelisation;etat actuel;apprentissage;expectation maximization;recherche information;enfoque probabilista;approche probabiliste;model matching;state of the art;semantic gap;visual features;algorithme em;latent aspect model;estado actual;algoritmo em;analisis semantico;analyse semantique;em algorithm;modeling;probabilistic latent semantic analysis;semantic analysis;image retrieval	Automatic image annotation has become an important and challenging problem due to the existence of semantic gap. In this paper, we firstly extend probabilistic latent semantic analysis (PLSA) to model continuous quantity. In addition, corresponding Expectation–Maximization (EM) algorithm is derived to determine the model parameters. Furthermore, in order to deal with the data of different modalities in terms of their characteristics, we present a semantic annotation model which employs continuous PLSA and standard PLSA to model visual features and textual words respectively. The model learns the correlation between these two modalities by an asymmetric learning approach and then it can predict semantic annotation precisely for unseen images. Finally, we compare our approach with several state-of-the-art approaches on the Corel5k and Corel30k datasets. The experiment results show that our approach performs more effectively and accurately. 2010 Elsevier B.V. All rights reserved.	automatic image annotation;corel linux;expectation–maximization algorithm;iterative method;probabilistic latent semantic analysis;text corpus	Zhixin Li;Zhiping Shi;Xi Liu;Zhongzhi Shi	2011	Pattern Recognition Letters	10.1016/j.patrec.2010.11.015	natural language processing;computer vision;semantic computing;expectation–maximization algorithm;image retrieval;computer science;pattern recognition;probabilistic latent semantic analysis;automatic image annotation	Web+IR	-13.365235169105624	-61.60312297492479	81481
1e5a61b40af717e42c136b30ff950c4643d50a81	training selection for tuning entity matching	data integrity	Entity matching is a crucial and difficult task for data integration. An effective solution strategy typically has to combine several techniques and to find suitable settings for critical configuration parameters such as similarity thresholds. Supervised (trainingbased) approaches promise to reduce the manual work for determining (learning) effective strategies for entity matching. However, they critically depend on training data selection which is a difficult problem that has so far mostly been addressed manually by human experts. In this paper we propose a trainingbased framework called STEM for entity matching and present different generic methods for automatically selecting training data to combine and configure several matching techniques. We evaluate the proposed methods for different match tasks and smalland medium-sized training sets.		Hanna Köpcke;Erhard Rahm	2008			data mining;data integration;computer science;data integrity;artificial intelligence;training set;machine learning;pattern recognition	AI	-17.306472354202054	-65.56938504724617	81529
88b575977bf5e8627bad945c00f36881ab220b91	visual indexing and retrieval	populated direction;important trend;information technology;content-based indexing;algorithmic solution;video protection;visual content;visual information indexing;visual indexing;visual information;dailymotion host	Some people may be laughing when looking at you reading in your spare time. Some may be admired of you. And some may want be like you who have reading hobby. What about your own feel? Have you felt right? Reading is a need and a hobby at once. This condition is the on that will make you feel that you must read. If you know are looking for the book enPDFd visual indexing and retrieval as the choice of reading, you can find here.	feature extraction;feature model;gist;harris affine region detector;interest point detection;scale-invariant feature transform;sensor;speeded up robust features	Mohammadamin Erfanmanesh;Elaheh Hosseini	2014	Webology		computer science;multimedia;world wide web;information retrieval	HCI	-15.462491854478898	-56.42168230228698	81701
8b220c304e09e0329bd43144f2ea8a3414dd0503	modelling of visual feature derivation in the vizir framework	visual information retrieval;multimedia systems feature extraction image retrieval iso standards;visualization abstracts media semantics transform coding;visual features;visual feature derivation modelling visual information retrieval vizir feature extraction semantic enrichment mpeg 7 structures	If visual information retrieval should make further progress, it will be necessary to identify new ways to derive visual properties from higher levels of understanding than the pixel level (e.g. from low-level features). The paper outlines the implementation of modelling of feature hierarchies in the visual information retrieval framework VizIR (free under GPL). The approach allows for the derivation of high-level features from low-level features by aggregation and localisation as well as semantic enrichment with additional knowledge. The technical implementation is based on the MPEG-7 structures for aggregation and specialisation.	feature data;gene ontology term enrichment;high- and low-level;information retrieval;mpeg-7;pixel;transformers	Horst M. Eidenberger	2004	2004 12th European Signal Processing Conference	10.5281/zenodo.38261	natural language processing;computer vision;visual word;computer science;information retrieval	Vision	-14.300810754873837	-58.033673778255974	81715
3d10e35d2243dfdd3122687a618cc826749f2f5c	multimod data manager: a tool for data fusion	computer aided medicine;application framework;software tool;data management;data fusion;biomedical engineering;medical image;lower limb;musculoskeletal apparatus;computer simulation	Nowadays biomedical engineers regularly have to combine data from multiple medical imaging modalities, biomedical measurements and computer simulations and this can demand the knowledge of many specialised software tools. Acquiring this knowledge to the depth necessary to perform the various tasks can require considerable time and thus divert the researcher from addressing the actual biomedical problems. The aim of the present study is to describe a new application called the Multimod Data Manager, distributed as a freeware, which provides the end user with a fully integrated environment for the fusion and manipulation of all biomedical data. The Multimod Data Manager is generated using a software application framework, called the Multimod Application Framework, which is specifically designed to support the rapid development of computer aided medicine applications. To understand the general logic of the Data Manager, we first introduce the framework from which it is derived. We then illustrate its use by an example--the development of a complete subject-specific musculo-skeletal model of the lower limb from the Visible Human medical imaging data to be used for predicting the stresses in the skeleton during gait. While the Data Manager is clearly still only at the prototype stage, we believe that it is already capable of being used to solve a large number of problems common to many biomedical engineering activities.	application framework;comparison of command shells;computer simulation;lower extremity;medical imaging;prototype;biomedical engineering field	Marco Viceconti;Fulvia Taddei;Laura Montanari;Debora Testi;Alberto Leardini;Gordon Clapworthy;Serge L. Van Sint Jan	2007	Computer methods and programs in biomedicine	10.1016/j.cmpb.2007.05.002	computer simulation;computer vision;simulation;data management;computer science;machine learning;data mining;sensor fusion	Visualization	-9.833243319819502	-54.69363493387914	82075
3a458fd0236f44a568079371f361c50af17cd95d	high performance system framework for parallel in-silico biological simulations	databases;computers;genomics;portals;software tool;comparative analysis;influenza virus;high performance computing;workstation clusters bioinformatics molecular biophysics parallel programming portals;parallel programming;influenza;genetics;web portal;molecular biology;molecular biophysics;high performance computer;parallel computer;web portal bioinformatics biological data high performance computing in silico experiments;software tools;parallel program high performance system framework parallel in silico biological simulations parallel implementation high performance computing high performance framework scientific experiments bioinformatics parallel computer simulations heterogeneous compact computer cluster genetic biological data advanced software tools in silico simulations molecular biology web portal secure access;parallel implementation;biological data;workstation clusters;parallel programs;in silico experiments;databases influenza portals genomics computers software tools;high performance;bioinformatics;in silico	The parallel implementation of methods and algorithms for analysis of biological data using high-performance computing is essential for accelerating the research and reduce the investment. The paper presents a high-performance framework for carrying out scientific experiments in the area of bioinformatics, on the basis of parallel computer simulations on a heterogeneous compact computer cluster. Several of the most popular and widely used methods and algorithms using for simulations intended for high performance platforms in order to increase the efficiency of the computations have been implemented. Important role is building up a database consisting of a reference genetic biological data, advanced software tools for in-silico simulations for the purposes of molecular biology, and web portal enabling secure access to the services. Web portal provides as services access and extraction of biological data and execution of various parallel program implementations based on algorithms for comparative analysis of biological data. The proposed framework is verified experimentally for the case study of investigation the influenza virus variability.	algorithm;bioinformatics;computation;computer cluster;computer simulation;database;experiment;heart rate variability;parallel computing;qualitative comparative analysis;supercomputer	Plamenka Borovska;Ognian Nakov;Veska Gancheva;Ivailo Georgiev	2011	2011 Developments in E-systems Engineering	10.1109/DeSE.2011.72	computational science;computer science;bioinformatics;theoretical computer science	HPC	-5.457981964668258	-53.1549542124838	82330
23250e56499e6fe11e4f4d88956b187a8de3a863	imis: a multi-platform software package for telediagnosis and 3d medical image processing	multi platform software package;ct;software tool;3d medical image transmission;image coding;image processing;computed tomography;image resolution;fmri;data compression;imis software package;telediagnosis;magnetic resonance images;software packages biomedical imaging magnetic resonance imaging positron emission tomography computed tomography software tools biomedical image processing graphical user interfaces performance loss image processing;functional mri;pet;3d medical image processing;biomedical nmr;modular programming strategy;biomedical imaging;graphical user interface;magnetic resonance image;positron emission tomography;3d lossless multiresolution image compression;isdn;graphical user interfaces;medical image;image compression;medical image processing;magnetic resonance imaging;fmri imis software package multi platform software package telediagnosis 3d medical image processing medical imaging departments 3d medical image transmission modular programming strategy graphical user interface tcl tk toolkit high performance image processing techniques 3d lossless multiresolution image compression narrow band isdn magnetic resonance images mri positron emission tomography pet computed tomography ct functional mri;mri;medical imaging departments;computerised tomography;software package;graphic user interface;biomedical image processing;image processing techniques;software tools;high performance;performance loss;isdn medical image processing image resolution data compression image coding graphical user interfaces software packages biomedical nmr positron emission tomography computerised tomography;software packages;tcl tk toolkit;high performance image processing techniques;narrow band isdn	In this paper, we present a project developed in our University in order to provide Medical Imaging Departments with eecient software tools for 3D medical image processing , storage and transmission. In this context, the IMIS software package has been developed, combining, in a modular programming strategy, an easily upgradable graph-ical user interface, using the Tcl/Tk toolkit, with high performance image processing techniques, such as 3D lossless multiresolution image compression, transmission, and advanced 3D medical image processing tools.	image compression;image processing;itcl;lossless compression;medical imaging;modular programming;tcl;user interface;ical	Jean-Philippe Thiran;Bruno Piscaglia;Patrick Piscaglia;Benoit M. Macq;Jean-Francois Goudemant;Roger Demeure	1996		10.1109/ICIP.1996.560773	computer vision;computer science;magnetic resonance imaging;graphical user interface;computer graphics (images)	Robotics	-10.233028415740822	-53.20602447122309	82486
e9588b99e035726c340c503f195ad5119550819f	content-based medical image retrieval using low-level visual features and modality identification	medical image retrieval;indexation;visual features;content based image retrieval;image retrieval	This paper presents the image retrieval results obtained by the BioIngenium Research Group, in the frame of the ImageCLEFmed 2007 edition. The applied approach consists of two main phases: a preprocessing phase, which builds an image category index and a retrieval phase, which ranks similar images. Both phases are based only on visual information. The experiments show a consistent frame with theory in content-based image retrieval: filtering images with a conceptual index outperforms only-ranking-based strategies; combining features is better than using individual features; and low-level features are not enough to model image semantics.	content-based image retrieval;experiment;high- and low-level;preprocessor;text corpus;two-phase locking;whole earth 'lectronic link	Juan C. Caicedo;Fabio A. González;Eduardo Romero	2007		10.1007/978-3-540-85760-0_78	image texture;computer vision;feature detection;visual word;image processing;image retrieval;computer science;pattern recognition;multimedia;automatic image annotation;information retrieval	Vision	-13.389889420423568	-58.60320268227046	82573
5549f6f79b3312abd8dc4ba0f7b8f46b3bd6760b	toward cross-language and cross-media image retrieval	busqueda informacion;texture;text;keyword;recherche image;information retrieval;interrogation base donnee;interrogacion base datos;tratamiento lenguaje;palabra clave;information access;texte;mot cle;language processing;recherche information;traitement langage;textura;text retrieval;visual features;acces information;acceso informacion;multilinguisme;texto;database query;multilingualism;multilinguismo;image retrieval	This report describes the approach used in our participation of ImageCLEF. Our focus is on image retrieval using text, i.e. Cross-Media IR. To do this, we first determine the strong relationships between keywords and types of visual features. Then the subset of images retrieved by text retrieval are used as examples to match other images according to the most important types of features of the query words.	document retrieval;image retrieval	Carmen Alvarez;Ahmed Id Oumohmed;Max Mignotte;Jian-Yun Nie	2004		10.1007/11519645_66	computer vision;visual word;speech recognition;image retrieval;computer science;pattern recognition;texture;information retrieval	Web+IR	-12.76343500376885	-60.73753659348532	82795
cbf2853e1bbcf9afc2605eccdb68f5e0b5c5a36d	a visual word weighting scheme based on emerging itemsets for video annotation	busqueda informacion;assignment;asignacion;68p20;68q55;keyword;procesamiento informacion;algorithm analysis;information retrieval;performance;weighting;assignation;semantics;clasificador;palabra clave;mot cle;ponderacion;semantica;semantique;classifier;saco;recherche information;informatique theorique;information processing;sac;classificateur;video annotation;analyse algorithme;ponderation;rendimiento;bag of visual words;traitement information;bag;bow;analisis algoritmo;emerging itemsets;computer theory;informatica teorica	a r t i c l e i n f o a b s t r a c t The method based on Bag-of-visual-Words (BoW) deriving from local keypoints has recently appeared promising for video annotation. Visual word weighting scheme has critical impact to the performance of BoW method. In this paper, we propose a new visual word weighting scheme which is referred as emerging patterns weighting (EP-weighting). The EP-weighting scheme can efficiently capture the co-occurrence relationships of visual words and improve the effectiveness of video annotation. The proposed scheme firstly finds emerging patterns (EPs) of visual keywords in training dataset. And then an adaptive weighting assignment is performed for each visual word according to EPs. The adjusted BoW features are used to train classifiers for video annotation. A systematic performance study on TRECVID corpus containing 20 semantic concepts shows that the proposed scheme is more effective than other popular existing weighting schemes.	bag-of-words model in computer vision;benchmark (computing);document retrieval;expectation propagation;language model;visual word	Guiguang Ding;Jianmin Wang;Kai Qin	2010	Inf. Process. Lett.	10.1016/j.ipl.2010.05.027	bag domain;speech recognition;classifier;information processing;performance;computer science;data mining;assignment;weighting;semantics;bag-of-words model in computer vision;programming language;information retrieval	AI	-13.414674502863095	-61.38066814738149	82948
00db743a4245fcb49439009bc870f6251f78cbee	hybrid affinity propagation		In this paper, we address a problem of managing tagged images with hybrid summarization. We formulate this problem as finding a few image exemplars to repres nt the image set semantically and visually, and solve it in a hybrid way by exploiting both visual and text ual information associated with images. We propose a novel approach, called homogeneous and heterogen ous message propagation (H MP). Similar to the affinity propagation (AP) approach, H MP reduce the conventional vector message propagation to scalar message propagation to make the algorithm more efficient. Be yond AP that can only handle homogeneous data, H MP generalizes it to exploit extra heterogeneous relations and the generalization is non-trivial as the reduction to scalar messages from vect or messages is more challenging. The main advantages of our approach lie in 1) that H MP exploits visual similarity and in addition the useful information from the associated tags, including the associat i ns relation between images and tags and the relations within tags, and 2) that the summary is both visual ly and semantically satisfactory. In addition, our approach can also present a textual summary to a tagged im age collection, which can be used to automatically generate a textual description. The experim ental results demonstrate the effectiveness and efficiency of the proposed approach.	affinity propagation;algorithm;processor affinity;software propagation	Jingdong Wang;Hao Xu;Xian-Sheng Hua;Shipeng Li	2013	CoRR		natural language processing;computer science;theoretical computer science;machine learning;pattern recognition;information retrieval	Vision	-17.54386794104325	-65.29923165006767	83329
9a9998098e2b28c55e0b1c9032c6092572096386	brief survey on image semantic analysis and understanding	computer model;image understanding;semantics;data and knowledge coherence image understanding semantic gap;computer vision;visualization;computational modeling;semantics visualization computational modeling pattern recognition educational institutions computer vision benchmark testing;semantic gap;pattern recognition;semantic coherency high level interpretation text image gap text formatting discriminative grammar descriptive grammar contextual features;data and knowledge coherence;benchmark testing;semantic analysis	Semantic issues are highly concerned with high-level interpretation in image understanding, which include text-image gap and its own affinity. Concentrating on text-formatting with entities in images, three sophisticated methodologies are roundly reviewed as generative, discriminative and descriptive grammar on the basis of contextual features. The following objective benchmark for visual words is also directly presented for semantic coherency. Finally, the summarized directions on semantics in image understanding are discussed intensively for further researches.	affinity analysis;benchmark (computing);cognition;computer vision;discriminative model;entity;generative model;high- and low-level	Zhao Xie;Jun Gao;Kewei Wu;Jun Zhang	2011	2011 International Conference of Soft Computing and Pattern Recognition (SoCPaR)	10.1109/SoCPaR.2011.6089136	natural language processing;benchmark;computer vision;semantic interpretation;semantic computing;visualization;computer science;machine learning;data mining;semantic compression;semantics;computational model;semantic gap	Vision	-15.78306933533765	-62.52294867074014	84563
dbf57978066e4d7d822688d69929b13e96e7c94d	identification of document types from various kinds of document images based on physical and layout features	document model	When we develop a general purpose document image understanding system, it is important, as the first step, to distinguish individual documents. We propose an approach which first classifies document images into some distinct types and then interprets them exactly by using an appropriate document model. In this paper, we define groups of documents and describe the classification method based on the verification mechanism by using physical and layout features of documents. Also, we show the experimental result in our method.	computer vision;statistical classification	Hiroyuki Masai;Toyohide Watanabe	1996			document clustering;computer science;document layout analysis;data mining;world wide web;information retrieval;design document listing	Web+IR	-13.80303136671504	-59.92233930362006	84793
9d04b3115f53a1f296317c9eb2c2aeab9bc6c100	ribosome builder: a software project to simulate the ribosome	computer program;gnu public license;time scale;graphical interface;dynamic model;application program interface;steered molecular dynamics;3d simulation;ribosomal translation;rna;level of detail;atomic structure;macromolecular simulation;ribosome modeling;molecular dynamic;tools and techniques;macromolecules computer simulation;ribosomes computer simulation;scripting language;open source	The Ribosome Builder is a software project that provides tools and techniques to create dynamic models of macromolecular systems from the rapidly growing numbers of atomic structural models. It includes a computer program that allows the user to assemble the multiple molecular components within a 3D space and to define the hypothetical interactions of these components with the initial goal of understanding protein translation at an atomic level of detail. The program employs a simplified molecular dynamics forcefield that can simulate the long time-scale events, such as docking of translation factors and mRNA translocation. An embedded scripting language and Application Programming Interface (API) enable the creation of Steered Molecular Dynamics (SMD) simulations through the programmable application of external forces and torques on atoms and bonds. A graphical interface is provided for displaying and interacting with models, recording movies of molecular dynamics movements, and creating annotated 3D simulations of complex macromolecular events. Initial applications of the project include simulation of tetraloop folding, docking of an mRNA on the 30S subunit and a schematic simulation of the translation elongation cycle. The program is an open source project released under the GNU public license.	application programming interface;boat dock;computer program;docking (molecular);docking -molecular interaction;embedded system;embedding;gnu;graphical user interface;interface device component;level of detail;molecular dynamics;movement;movies;open-source software;protein biosynthesis;ribosomes;schematic;scripting language;simulation;software project management;surface-mount technology;translational elongation	William Knight;Walter Hill;J. Stephen Lodmell	2005	Computational biology and chemistry	10.1016/j.compbiolchem.2005.01.001	molecular dynamics;rna;simulation;atom;human–computer interaction;application programming interface;computer science;bioinformatics;level of detail;graphical user interface;scripting language;genetics;quantum mechanics	Comp.	-5.5726410783412055	-58.031945604633414	84918
d010de0b95c3fbad7d2d236392b59d1b43c69c7e	viral transcript alignment		We present an end-to-end system for aligning transcript letters to their coordinates in a manuscript image. An intuitive GUI and an automatic line detection method enable the user to perform an exact alignment of parts of document pages. In order to bridge large regions in between annotation, and augment the manual effort, the system employs an optical-flow engine for directly matching at the pixel level the image of a line of a historical text with a synthetic image created from the transcript's matching line. Meanwhile, by accumulating aligned letters, and performing letter spotting, the system is able to bootstrap a rapid semi-automatic transcription of the remaining text. Thus, the amount of manual work is greatly diminished and the transcript alignment task becomes practical regardless of the corpus size.	bootstrapping (compilers);edge detection;end system;end-to-end principle;graphical user interface;interpolation;machine learning;mathematical optimization;open-source software;optical flow;optimization mechanism;pixel;semiconductor industry;synthetic intelligence;transcription (software)	Gil Sadeh;Lior Wolf;Tal Hassner;Nachum Dershowitz;Daniel Stokl Ben-Ezra	2015	2015 13th International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2015.7333854	speech recognition;computer science;bioinformatics;world wide web	Vision	-7.49861640361672	-64.32107189323112	84930
5ed45a6243ae2158fba9f7e76cb4aedeec38746f	why meaningful automatic tagging of images is very hard	internet content based retrieval image retrieval;cbir;web bot;data mining;visualization;captcha application;internet;automatic image tagging;games;pixel;tagging pixel image retrieval humans content based retrieval information retrieval birds statistics labeling statistical distributions;exif image tagging content based image retrieval cbir captcha;image tagging;humans;content based image retrieval;content based retrieval;exif;captcha application automatic image tagging cbir content based image retrieval web bot;labeling;captcha;tagging;image retrieval	The paper points out that while automatic image tagging is often studied in connection with content-image image retrieval (CBIR), it is actually a much harder problem. Given the difficulty of the latter, the prospects for automatic image tagging do not appear promising. A brief survey of the current state of the art confirms that conclusion. Then the paper discusses an effort to tag images based on nonpixel data and proceeds with the outline of a case where the difficulty of automatic tagging is taken advantage to construct image based CAPTCHA to distinguish human users from web-bots. That has led to certain interesting approaches to achieve reliable human tagging that is needed for the CAPTCHA application.	captcha;content-based image retrieval;tag (metadata)	Theodosios Pavlidis	2009	2009 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2009.5202771	games;computer vision;labeling theory;the internet;visualization;image retrieval;computer science;captcha;world wide web;information retrieval;pixel	Robotics	-14.650661566035415	-58.33862189405995	85400
26a4f0316af64acc5591ab96482cb59b3e4af445	vdbms: a testbed facility for research in video database benchmarking	search and retrieval;management system;high dimensionality;query processing;streaming video;buffer management;video processing;data type;database management;feature vector;data storage;indexation;access control models;visual features;image processing techniques;digital video;video database;video search	Real-world video-based applications require database technology that is capable of storing digital video in the form of video databases and providing content-based video search and retrieval. Methods for handling traditional data storage, query, search, retrieval, and presentation cannot be extended to provide this functionality. The VDBMS research initiative is motivated by the requirements of video-based applications to search and retrieve portions of video data based on content and by the need for testbed facilities to facilitate research in the area of video database management. In this paper we describe the VDBMS video database research platform, a system that supports comprehensive and efficient database management for digital video. Our fundamental concept is to provide a full range of functionality for video as a well-defined abstract database data type, with its own description, parameters, and applicable methods. Research problems that are addressed by VDBMS to support the handling of video data include MPEG7 standard multimedia content representation, algorithms for image-based shot detection, image processing techniques for extracting low-level visual features, a high-dimensional indexing technique to access the high-dimensional feature vectors extracted by image preprocessing, multimedia query processing and optimization, new query operators, real-time stream management, a search-based buffer management policy, and an access control model for selective, content-based access to streaming video. VDBMS also provides an environment for testing the correctness and scope of new video processing techniques, measuring the performance of algorithms in a standardized way, and comparing the performance of different implementations of an algorithm or component. We are currently developing video component wrappers with well-defined interfaces to facilitate the modification or replacement of video processing components. The ultimate goal of the VDBMS project is a flexible, extensible framework that can be used by the research community for developing, testing, and benchmarking video database technologies.	access control;algorithm;computer data storage;correctness (computer science);database;digital video;feature vector;high- and low-level;image processing;mpeg-7;mathematical optimization;preprocessor;real-time clock;requirement;semiconductor industry;shot transition detection;streaming media;testbed;video processing	Walid G. Aref;Ann Christine Catlin;Ahmed K. Elmagarmid;Jianping Fan;Moustafa A. Hammad;Ihab F. Ilyas;Mirette S. Marzouk;Sunil Prabhakar;Yi-Cheng Tu;Xingquan Zhu	2003	Multimedia Systems	10.1007/s00530-003-0129-9	feature vector;data type;computer science;operating system;video tracking;computer data storage;management system;database;video processing;world wide web;information retrieval	DB	-12.535977760277717	-56.243240446827436	85438
807fce8b4fe19ac5808df55ea8520b20e62d38dc	biochemical space: a framework for systemic annotation of biological models	biological models;systems biology;model annotation;cyanobacteria	In this tool paper, we target the problem of unique annotation of organism-specific computational models presented in a public model database. In particular, we present Biochemical Space, a novel annotation methodology accompanied with a set of software tools that allow to create, manage and maintain the Biochemical Space content. The main idea behind is to create a transparent well-annotated reaction network of chemical entities and elemental reactions onto which the mathematical models are projected. For a given organism, the Biochemical Space represents a unifying platform for understanding of the related biological processes. The contribution of the methodology is three-fold: (i) systemic projection of models to a wellstructured biological knowledge, (ii) simplification of annotation procedure, (iii) targetting several problems such as the presence of lumped model variables, combinatorial explosion in chemical modifications of entities, and hierarchical organisation of locations of individual entities. In these aspects the Biochemical Space goes beyond the features of current standards such as SBML. Application of the framework is demonstrated on a set of annotation data compiled for complex cyanobacteria processes.	compiler;computational model;database;elemental;entity;fits;mathematical model;ontology (information science);sbml;text simplification	Matej Klement;T. Ded;David Safránek;Jan Cervený;Stefan Müller;Ralf Steuer	2014	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2014.06.013	computer science;bioinformatics;data science;data mining;systems biology	ML	-4.763980154132092	-63.09916459997939	85530
0f45ef4d65c1387e107361c912ef3a1bd54b0c9d	generating natural language tags for video information management	video information management;video annotation;natural language generation	This exploratory work is concerned with generation of natural language descriptions that can be used for video retrieval applications. It is a step ahead of keyword-based tagging as it captures relations between keywords associated with videos. Firstly, we prepare hand annotations consisting of descriptions for video segments crafted from a TREC Video dataset. Analysis of this data presents insights into human’s interests on video contents. Secondly, we develop a framework for creating smooth and coherent description of video streams. It builds on conventional image processing techniques that extract high-level features from individual video frames. Natural language description is then produced based on high-level features. Although feature extraction processes are erroneous at various levels, we explore approaches to putting them together to produce a coherent, smooth and well-phrased description by incorporating spatial and temporal information. Evaluation is made by calculating ROUGE scores between human-annotated and machine-generated descriptions. Further, we introduce a task-based evaluation by human subjects which provides qualitative evaluation of generated descriptions.	coherence (physics);experiment;feature extraction;high- and low-level;ietf language tag;image processing;information management;interaction;natural language generation;semantics (computer science);streaming media;top-down and bottom-up design	Muhammad Usman Ghani Khan;Yoshihiko Gotoh	2017	Machine Vision and Applications	10.1007/s00138-017-0825-7	computer vision;computer science;video tracking;multimedia;information retrieval	Vision	-14.769725279799664	-57.53240876508863	86104
5c2f7a9c3f894e4c938035c4b820c92804b4a3dd	an interactive appearance-based document retrieval system for historical newspapers		In this paper we present a retrieval-based application aimed at assisting a user to semi-automatically segment an incoming flow of historical newspaper images by automatically detecting a particular type of pages based on their appearance. A visual descriptor is used to assess page similarity while a relevance feedback process allow refining the results iteratively. The application is tested on a large dataset of digitised historic newspapers.	active learning (machine learning);crowdsourcing;document retrieval;interactivity;relevance feedback;semiconductor industry;sensor;visual descriptor	Hongxing Gao;Marçal Rusiñol;Dimosthenis Karatzas;Apostolos Antonacopoulos;Josep Lladós	2013			computer vision;information retrieval;artificial intelligence;computer science;newspaper;document retrieval;relevance feedback	Vision	-14.433705557790168	-56.87840827675343	86568
8928d153dfcdcc7ac7db055e4b1a2d8c89b02e01	representation of structural relationships in the foundational model of anatomy	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;sig publications;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Previous attempts at the symbolic representation of anatomical relationships have been largely limited to partonomy.  We propose an ontology of anatomical relationships and illustrate the inheritance of structural attributes in the Digital Anatomist Foundational Model.  Our purpose is to generate a sharable resource that can support inference about the structural organization of the body.	foundational model of anatomy	José L. V. Mejino;Natalya Fridman Noy;Mark A. Musen;James F. Brinkley;Cornelius Rosse	2001			computer science;data science;data mining;information retrieval	DB	-4.926279555747729	-63.7702892311222	86779
65d6e48674d4a2b8b8e4be402ca24e6c06001ecb	visual saliency with side information	content management;semantic image classification visual content saliency side information machine learning algorithm join statistics diverse density contextual clustering algorithm multiple instance learning data content visualization;machine learning algorithms;pattern clustering;machine learning algorithm;pattern clustering methods;machine learning algorithms algorithm design and analysis layout organizing information analysis performance analysis statistical analysis clustering algorithms prototypes video sharing;multiple instance learning;prototypes;image classification;large images;statistical analysis content management data visualisation image classification learning artificial intelligence pattern clustering;visual content saliency;indexing terms;data mining;visual pa image classification;conference paper;data visualisation;visualization;photo collections;video datasets;visual content;semantic image classification;statistical analysis;machine learning;photo collection;image classification pattern clustering methods;image color analysis;seasonality;join statistics;pixel;visual analysis;news video;clustering algorithms;data content visualization;learning artificial intelligence;keywords contextual clustering;side information;novel algorithm;algorithm design and analysis;trecvid;diverse density contextual clustering algorithm	We propose novel algorithms for organizing large image and video datasets using both the visual content and the associated side-information, such as time, location, authorship, and so on. Earlier research have used side-information as pre-filter before visual analysis is performed, and we design a machine learning algorithm to model the join statistics of the content and the side information. Our algorithm, Diverse-Density Contextual Clustering (D2C2), starts by finding unique patterns for each sub-collection sharing the same side-info, e.g., scenes from winter. It then finds the common patterns that are shared among all subsets, e.g., persistent scenes across all seasons. These unique and common prototypes are found with Multiple Instance Learning and subsequent clustering steps. We evaluate D2C2 on two web photo collections from Flickr and one news video collection from TRECVID. Results show that not only the visual patterns found by D2C2 are intuitively salient across different seasons, locations and events, classifiers constructed from the unique and common patterns also outperform state-of-the-art bag-of-features classifiers.	algorithm;cluster analysis;flickr;machine learning;multiple instance learning;organizing (structure)	Wei Jiang;Lexing Xie;Shih-Fu Chang	2009	2009 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2009.4959946	algorithm design;computer vision;contextual image classification;visual analytics;visualization;index term;content management;computer science;machine learning;pattern recognition;data mining;prototype;cluster analysis;data visualization;pixel;seasonality;statistics	Vision	-17.859905928644594	-58.40348051132735	86850
b5d68dc535fa08c16b52e138ad5ae9d56fe5b99b	trecvid 2008 - goals, tasks, data, evaluation mechanisms and metrics	informatics	The TREC Video Retrieval Evaluation (TRECVID) 2008 is a TREC-style video analysis and retrieval evaluation, the goal of which remains to promote progress in content-based exploitation of digital video via open, metrics-based evaluation. Over the last 7 years this effort has yielded a better understanding of how systems can effectively accomplish such processing and how one can reliably benchmark their performance. TRECVID is funded by the Intelligence Advanced Research Projects Activity (IARPA), the US Department of Homeland Security (DHS), and the US National Institute of Standards and Technology (NIST). 77 teams (see Table 1) from various research organizations — 24 from Asia, 39 from Europe, 13 from North America, and 1 from Australia — participated in one or more of five tasks: high-level feature extraction, search (fully automatic, manually assisted, or interactive), pre-production video (rushes) summarization, copy detection, or surveillance event detection. The copy detection and surveillance event detection tasks are being run for the first time in TRECVID. In 2008, TRECVID is the second year in what may be a 3-year cycle using new data sources for feature extraction and search, data which is related to the broadcast TV news used in 2003-2006 but significantly different. Test data for the search and feature tasks was about 100 hours of (MPEG-1) TV news magazine, science news, news reports, documentaries, educational programming, and archival video almost entirely in Dutch from the Netherlands Institute for Sound and Vision. An equal amount of video was available for search/feature system development. The combined 200 hours were used in the copy detection task. The BBC Archive provided about 50 hours of “rushes” — pre-production video material with natural sound, errors, etc. — from several BBC dramatic	archive;benchmark (computing);broadcast television systems;digital video;feature extraction;high- and low-level;mpeg-1;test data;text retrieval conference;video content analysis	Paul Over;George Awad;R. Travis Rose;Jonathan G. Fiscus;Wessel Kraaij;Alan F. Smeaton	2008				Web+IR	-15.817832026511937	-56.475846780926354	87425
4238ce9152b02b5ae07e8e42074d1ab7462ac652	illustration2vec: a semantic vector representation of illustrations	illustration;search;cnns;visual similarity	Referring to existing illustrations helps novice drawers to realize their ideas. To find such helpful references from a large image collection, we first build a semantic vector representation of illustrations by training convolutional neural networks. As the proposed vector space correctly reflects the semantic meanings of illustrations, users can efficiently search for references with similar attributes. Besides the search with a single query, a semantic morphing algorithm that searches the intermediate illustrations that gradually connect two queries is proposed. Several experiments were conducted to demonstrate the effectiveness of our methods.	algorithm;artificial neural network;convolutional neural network;experiment;morphing	Masaki Saito;Yusuke Matsui	2015		10.1145/2820903.2820907	computer vision;illustration;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;mathematics;programming language;computer graphics (images)	Web+IR	-10.247103218286016	-61.367629522124396	88532
f984da3b2aeb03c978a45ca6fef9c191a84cd363	efficient word retrieval by means of som clustering and pca	document structure;analisis componente principal;analyse amas;document analysis;image processing;document imprime;estructura documental;index words;structure document;digital library;interrogation base donnee;procesamiento imagen;interrogacion base datos;caracter impreso;printed character;classification;traitement image;analyse documentaire;biblioteca electronica;cluster analysis;recherche documentaire;printed document;documento impreso;busqueda documental;principal component analysis;analyse composante principale;pattern recognition;autoorganizacion;analisis documental;self organization;self organized map;analisis cluster;electronic library;document retrieval;reconnaissance forme;reconocimiento patron;caractere imprime;database query;clasificacion;autoorganisation;bibliotheque electronique;principal component	We propose an approach for efficient word retrieval from printed documents belonging to Digital Libraries. The approach combines word image clustering (based on Self Organizing Maps, SOM) with Principal Component Analysis. The combination of these methods allows us to efficiently retrieve the matching words from large documents collections without the need for a direct comparison of the query word with each indexed word.	algorithm;cluster analysis;digital library;image retrieval;list of algorithms;principal component analysis;printing;proximity search (text);x-tree	Simone Marinai;Stefano Faini;Emanuele Marino;Giovanni Soda	2006		10.1007/11669487_30	document retrieval;visual word;digital library;speech recognition;image processing;computer science;machine learning;world wide web;principal component analysis	Web+IR	-11.98595312990273	-61.41476743921658	88535
52a7e257eb27287d01b82ea96fbcf2eb83956813	semantics modeling in diagnostic medical image databases using customized fuzzy membership functions	image features;diagnostic imaging;fuzzy membership function;linguistic variable;medical image databases;semantic network;image database;fuzzy set theory;lung;semantic model;medical image processing;membership function;common knowledge;visual databases image retrieval lung medical image processing fuzzy set theory content based retrieval;hrct lung images semantics modeling diagnostic medical image database customized fuzzy membership functions fuzzy methods semantic query system crisp hierarchical semantic networks content based image retrieval cbir perceptual understanding physician defined linguistic variables customized fuzzy mappings query methods;content based image retrieval;content based retrieval;biomedical imaging medical diagnostic imaging image databases image retrieval information retrieval content based retrieval fuzzy set theory fuzzy systems fuzzy sets engines;visual databases;image retrieval	It is widely recognized thatfirtry method play an important role in image database retrieval, especially in the context of semantic queries. Known approaches that use crisp hierarchical semantic networks have been shrdied and applied to content-based image retrieval (CBIR) to narrow the gap between semantia and image feahrres. Unforhrnately, most of the studies lack the flexibilic to adapt to an individual’s preferences andor to establish a general-purpose semantic network for sharing the perceplual understanding. In this paper, we propose a semantic query system for diagnostic image database retrieval that uses physician-defined linguistic variables. Users can obtain more desirable retrieval results by creating new, customizedsemantic t e m , and by modeling a suite of membershipfirnctions lo reflect their preferences. The system brings an increased versatiliv for image retrieval, and a great amount of possibilities for customizing the semantic terms using customized furry mappings. Our unique approach provider various query method that use the semantic terms within the domain of HRCT images of the lung and allows individual users to bring the contribution to the common howledge base.	content-based image retrieval;database;general-purpose modeling;high-resolution computed tomography;membership function (mathematics);semantic network;semantic query	Adrian S. Barb;Chi-Ren Shyu	2003		10.1109/FUZZ.2003.1206595	semantic data model;computer vision;semantic similarity;semantic computing;visual word;membership function;image retrieval;computer science;artificial intelligence;data mining;fuzzy set;semantic network;feature;information retrieval;common knowledge	Web+IR	-10.47068743616152	-58.55207632655203	88576
37849b0b5be6908fd0d3d2c050f4be53bfb2324a	audio content-based music retrieval	004;music retrieval content based query by example audio identification audio matching cover song identification	The rapidly growing corpus of digital audio material requires novel retrieval strategies for exploring large music collections. Traditional retrieval strategies rely on metadata that describe the actual audio content in words. In the case that such textual descriptions are not available, one requires content-based retrieval strategies which only utilize the raw audio material. In this contribution, we discuss content-based retrieval strategies that follow the query-by-example paradigm: given an audio query, the task is to retrieve all documents that are somehow similar or related to the query from a music collection. Such strategies can be loosely classified according to their specificity, which refers to the degree of similarity between the query and the database documents. Here, high specificity refers to a strict notion of similarity, whereas low specificity to a rather vague one. Furthermore, we introduce a second classification principle based on granularity, where one distinguishes between fragment-level and document-level retrieval. Using a classification scheme based on specificity and granularity, we identify various classes of retrieval scenarios, which comprise audio identification, audio matching, and version identification. For these three important classes, we give an overview of representative state-of-the-art approaches, which also illustrate the sometimes subtle but crucial differences between the retrieval scenarios. Finally, we give an outlook on a user-oriented retrieval system, which combines the various retrieval strategies in a unified framework. 1998 ACM Subject Classification H.5.5 Sound and Music Computing, J.5 Arts and Humanities– Music, H.5.1 Multimedia Information Systems, I.5 Pattern Recognition	comparison and contrast of classification schemes in linguistics and metadata;document;information system;microsoft outlook for mac;pattern recognition;programming paradigm;query by example;sensitivity and specificity;sound and music computing;text corpus;unified framework;vagueness	Peter Grosche;Meinard Müller;Joan Serrà	2012		10.4230/DFU.Vol3.11041.157	query expansion;visual word;computer science;multimedia;communication;information retrieval	Web+IR	-15.96685427702202	-57.67660726973731	88602
5db00525e733cdd53120392a58505ef5f174460b	a syntactic approach based on distortion-tolerant adjacency grammars and a spatial-directed parser to interpret sketched diagrams	grammar;modelizacion;sistema interactivo;langage visuel programmation;search space;frase;lenguaje visual;metodo combinatorio;visual communication;natural variation;index structure;incremental parsing;methode combinatoire;detection de symboles;systeme conversationnel;visual programming language;modelisation;diagram understanding;sentence;comunicacion visual;spatial directed parsing;analyse syntaxique;indexing;communication visuelle;interactive system;analisis sintaxico;grammaire;syntactic analysis;indexation;syntactic pattern recognition;sketched diagrams;adjacency grammars;indizacion;visual language;user testing;deteccion de simbolo;pattern recognition;analizador sintaxico;combinatorial method;parser;phrase;reconnaissance forme;reconocimiento patron;modeling;analyseur syntaxique;gramatica;symbol detection;symbol recognition	This paper presents a syntactic approach based on Adjacency Grammars (AG) for sketch diagram modeling and understanding. Diagrams are a combination of graphical symbols arranged according to a set of spatial rules defined by a visual language. AG describe visual shapes by productions defined in terms of terminal and non-terminal symbols (graphical primitives and subshapes), and a set functions describing the spatial arrangements between symbols. Our approach to sketch diagram understanding provides three main contributions. First, since AG are linear grammars, there is a need to define shapes and relations inherently bidimensional using a sequential formalism. Second, our parsing approach uses an indexing structure based on a spatial tessellation. This serves to reduce the search space when finding candidates to produce a valid reduction. This allows order-free parsing of 2D visual sentences while keeping combinatorial explosion in check. Third, working with sketches requires a distortion model to cope with the natural variations of hand drawn strokes. To this end we extended the basic grammar with a distortion measure modeled on the allowable variation on spatial constraints associated with grammar productions. Finally, the paper reports on an experimental framework an interactive system for sketch analysis. User tests performed on two real scenarios show that our approach is usable in interactive settings. & 2010 Elsevier Ltd. All rights reserved.	attribute grammar;depth-first search;diagram;distortion;entity;experiment;expressive power (computer science);graphical user interface;interactivity;linear grammar;online and offline;parse tree;parsing;randomness extractor;reduction (complexity);semantics (computer science);sketch;spatial database;spatial variability;statistical model;tessellation (computer graphics);time complexity;visual language	Joan Mas Romeu;Josep Lladós;Gemma Sánchez;Joaquim A. Jorge	2010	Pattern Recognition	10.1016/j.patcog.2010.07.003	natural language processing;computer vision;speech recognition;computer science;machine learning;parsing;pattern recognition;grammar;mathematics;visual programming language;algorithm;visual communication	AI	-11.169728028891425	-62.00057072327167	89298
97d3bc65073389ccebb363253faf7a74a5d1eb8f	integration of information and volume visualization for analysis of cell lineage and gene expression during embryogenesis	estensibilidad;0705k;large data visualization;organisms;microscopie fluorescence;complete genome;4230;microscopia fluorescencia;0130c;gene regulation;interactive visualization;imagerie;microscopy;information visualization;gene expression data;data type;embryos;0705r;gene expression;expression genique;visualization;imagery;fluorescent protein;fluorescence microscopy;genome;cell lineage;laser scanners;developpement embryonnaire;data visualization;8764;cell division;photons;volume visualization;image analysis;visualisation donnee;desarrollo embrionario;imagineria;extensibilite;scalability;genoma;embryonic development;analyse image;data integration;large data	Dramatic technological advances in the field of genomics have made it possible to sequence the complete genomes of many different organisms. With this overwhelming amount of data at hand, biologists are now confronted with the challenge of understanding the function of the many different elements of the genome. One of the best places to start gaining insight on the mechanisms by which the genome controls an organism is the study of embryogenesis. There are multiple and inter-related layers of information that must be established in order to understand how the genome controls the formation of an organism. One is cell lineage which describes how patterns of cell division give rise to different parts of an organism. Another is gene expression which describes when and where different genes are turned on. Both of these data types can now be acquired using fluorescent laser-scanning (confocal or 2-photon) microscopy of embryos tagged with fluorescent proteins to generate 3D movies of developing embryos. However, analyzing the wealth of resulting images requires tools capable of interactively visualizing several different types of information as well as being scalable to terabytes of data. This paper describes how the combination of existing large data volume visualization and the new Titan information visualization framework of the Visualization Toolkit (VTK) can be applied to the problem of studying the cell lineage of an organism. In particular, by linking the visualization of spatial and temporal gene expression data with novel ways of visualizing cell lineage data, users can study how the genome regulates different aspects of embryonic development.	algorithm;cell (microprocessor);gene expression profiling;informatics;information visualization;interactivity;lineage (evolution);list of toolkits;open-source software;scalability;scientific visualization;terabyte;titan;vtk	Andrej Cedilnik;Jeffrey Baumes;Luis Ibáñez;Sean G. Megason;Brian N. Wylie	2008		10.1117/12.768014	organism;fluorescence microscope;embryo;embryogenesis;scalability;image analysis;regulation of gene expression;gene expression;information visualization;visualization;interactive visualization;data type;bioinformatics;microscopy;data integration;photon;nanotechnology;cell division;data visualization;genome	Visualization	-4.597875690143537	-58.09764815339167	89315
04e37201a4d5f8dc19e90b0400c7f901166ca099	semantic modelling for behaviour characterisation and threat detection	endnotes;pubications	Threat detection in computer vision can be achieved by extraction of behavioural cues. To achieve recognition of such cues, we propose to work with Semantic Models of behaviours. Semantic Models correspond to the translation of Low-Level information (tracking information) into High-Level semantic description. The model is then similar to a naturally spoken description of the event. We have built semantic models for the behaviours and threats addressed in the PETS 2016 IPATCH dataset. Semantic models can trigger a threat alarm by themselves or give situation awareness. We describe in this paper how semantic models are built from Low-Level trajectory features and how they are recognised. The current results are promising.	computer vision;machine learning;semantic data model;sensor	Jose Luis Patino;James M. Ferryman	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)	10.1109/CVPRW.2016.162	computer vision;semantic integration;computer science;data mining	Vision	-9.246198574800584	-65.32149635375818	89363
e48a610cfa8748e9da1acc91499cb7f8243c0d32	canonical correlation inference for mapping abstract scenes to text		We describe a technique for structured prediction, based on canonical correlation analysis. Our learning algorithm finds two projections for the input and the output spaces that aim at projecting a given input and its correct output into points close to each other. We demonstrate our technique on a language-vision problem, namely the problem of giving a textual description to an “abstract scene.”	algorithm;structured prediction	Nikos Papasarantopoulos;Helen Jiang;Shay B. Cohen	2018			machine learning;computer science;artificial intelligence;canonical correlation;inference;structured prediction;pattern recognition	AI	-13.42347673384192	-64.21636910630167	89690
08c9ac26c605b08afcf8ac9e601c013a6e026cf7	semantic human activity detection in videos	context specific information;semantic human activity detection	Many solutions have been proposed for human action detection in the past. Even though, almost all the solutions address only the detection of basic human activities such as 'shaking hands', 'sitting down' etc and all of them are based on the structure of the activity pattern. No considerable attention has been paid to detect more semantic activities (more meaningful activities) like 'smoking', 'fighting', 'riding', etc. Therefore existing solutions are not capable of identifying such semantic activities accurately. There are three main reasons behind this inability. First one is most activities do not have any identifiable common action structure in it ('talking'). Secondly even when there is such an identifiable structure that activity pattern does not follow every single instance of activity performing ('smoking'). Third reason is some activities are too complex to identify using such basic action pattern analyses approaches ('hurdling'). Nevertheless ultimate expectation of human activity detection is identifying more complex/meaningful activities. Therefore, it is essential to address this problem properly for implementation of more useful applications in the future. In this paper, we urge the importance of using contextual information associated with semantic activities to overcome above mentioned three problems.	activity recognition;single-instance storage	Hirantha Weerarathna;Anuja Dharmaratne	2014		10.1145/2636240.2636874	engineering;artificial intelligence;data mining;communication	Vision	-11.93576294217009	-52.123730712715385	89734
59fb27051461fcf438ea4679e3348c2a4cb43fe8	attributing semantics to personal photographs	image features;information extraction;image;annotation;image annotation;photographs;clustering;natural language;semantic capture	A major bottleneck for the efficient management of personal photographic collections is the large gap between low-level image features and high-level semantic contents of images. This paper proposes and evaluates two methodologies for making appropriate (re)use of natural language photographic annotations for extracting references to people, location and objects and propagating any location references encountered to previously unannotated images. The evaluation identifies the strengths of each approach and shows extraction and propagation results with promising accuracy.	algorithmic efficiency;computation;global positioning system;high- and low-level;local bus;machine learning;natural language;precision and recall;randomness extractor;refinement (computing);software propagation	Rodrigo F. Carvalho;Sam Chapman;Fabio Ciravegna	2008	Multimedia Tools and Applications	10.1007/s11042-008-0249-5	natural language processing;computer vision;image retrieval;computer science;machine learning;image;cluster analysis;natural language;information extraction;feature;information retrieval	HCI	-15.54532299824611	-59.93806801785489	90601
ba44837e27834b39f69e099708f59e9a62b8fa21	search engine for handwritten documents	databases;image features;evaluation performance;search engine;buscador;base donnee;document analysis;performance evaluation;image processing;caracter manuscrito;evaluacion prestacion;manuscript character;speech processing;database;tratamiento palabra;procesamiento imagen;page segmentation;traitement parole;base dato;image indexing;segmentation;traitement image;word segmentation;analyse documentaire;reconocimiento voz;indexing;local features;indexation;image search;indizacion;word recognition;speech recognition;analisis documental;reconnaissance parole;moteur recherche;caractere manuscrit;local search;segmentacion	The design and functionality of a versatile search engine on handwritten documents is described. Documents are indexed using global image features, e.g., stroke width, slant, word gaps, as well local features that describe shapes of characters and words. Image indexing is done automatically using page analysis, page segmentation, line separation, word segmentation and recognition of characters and words. Several types of searches are permitted: (i) Word / Phrase Spotting; (ii) Text to Image Search; (iii) Plain Text Search; (iv) Word Recognition from Lexicon. The words in the document are characterized by various features and it forms the basis for the different searching techniques. The system was implemented in Microsoft Visual C++. The paper reports on the functional capabilities of the various search techniques and their performance.	c++;image retrieval;lexicon;named entity;similarity measure;text segmentation;web search engine	Sargur N. Srihari;Chen Huang;Harish Srinivasan	2005		10.1117/12.585883	natural language processing;text segmentation;computer vision;search engine indexing;speech recognition;image processing;word recognition;computer science;local search;speech processing;segmentation;feature;search engine	Vision	-12.122962204649287	-61.65453700069479	90791
942788c58670918a04bc00db62a9f4366b8ba870	deep learning at the shallow end: malware classification for non-domain experts		Current malware detection and classification approaches generally rely on time consuming and knowledge intensive processes to extract patterns (signatures) and behaviors frommalware, which are then used for identification. Moreover, these signatures are often limited to local, contiguous sequences within the data whilst ignoring their context in relation to each other and throughout the malware file as a whole. We present a Deep Learning based malware classification approach that requires no expert domain knowledge and is based on a purely data driven approach for complex pattern and feature identification. © 2018 The Author(s). Published by Elsevier Ltd on behalf of DFRWS. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).	antivirus software;deep learning;malware;norsk data;statistical classification;type signature;while	Quan Le;Oisín Boydell;Brian Mac Namee;Mark Scanlon	2018	Digital Investigation	10.1016/j.diin.2018.04.024	data mining;computer science;domain knowledge;malware;deep learning;data-driven;artificial intelligence	ML	-19.014511134494292	-59.7484442962165	90964
006268c93d5ed90f3f180209172b1c231727db7a	lecture video segmentation by automatically analyzing the synchronized slides	video segmentation;slides content analysis;ocr	In this paper we propose a solution which segments lecture video by analyzing its supplementary synchronized slides. The slides content derives automatically from OCR (Optical Character Recognition) process with an approximate accuracy of 90%. Then we partition the slides into different subtopics by examining their logical relevance. Since the slides are synchronized with the video stream, the subtopics of the slides indicate exactly the segments of the video. Our evaluation reveals that the average length of segments for each lecture is ranged from 5 to 15 minutes, and 45% segments achieved from test datasets are logically reasonable.	approximation algorithm;optical character recognition;relevance;streaming media	Xiaoyin Che;Haojin Yang;Christoph Meinel	2013		10.1145/2502081.2508115	computer science;multimedia;world wide web;computer graphics (images)	Vision	-15.559681002707949	-54.404204502450476	91019
9baccfadfe859592090b4e02ed42ac001ba45665	cyanofactory knowledge base & synthetic biology - a plea for human curated bio-databases		Nowadays, life science research is dominated by two conditions: interdisciplinarity and high-throughput. The former leads to highly diverse datasets from a data type point of view while high-throughput yields massive amounts of data. Both aspects are reflected by the byte-growth of public bio-databases and the sheer number of specialised databases or databases of databases (i.e. data warehouses). We provide an insight to the development of a biodata knowledge base (dubbed CyanoFactory KB) targeted to bio-engineers in the field of synthetic biology and exemplify the need for data type specific data curation and cross-linking. CyanoFactory KB is unique in incorporating experimental data from a broad range of scientific methods that are based on one strain of Synechocystis sp. PCC 6803. The knowledge base can be accessed upon request via cyanofactory.hs-	british informatics olympiad;byte;data curation;database;digital curation;exemplification;high-throughput computing;knowledge base;portable c compiler;synthetic biology;synthetic intelligence;throughput	Gabriel Kind;Eric Zuchantke;Röbbe Wünschiers	2015			biology;bioinformatics;data mining	DB	-4.688051075898634	-61.748365521224464	91044
1538f7b97be3c6e49a1300b3c54d9fea2fdde5e0	hop-map: efficient message passing with high order potentials	message passing	There is a growing interest in building probabilistic models with high order potentials (HOPs), or interactions, among discrete variables. Message passing inference in such models generally takes time exponential in the size of the interaction, but in some cases maximum a posteriori (MAP) inference can be carried out efficiently. We build upon such results, introducing two new classes, including composite HOPs that allow us to flexibly combine tractable HOPs using simple logical switching rules. We present efficient message update algorithms for the new HOPs, and we improve upon the efficiency of message updates for a general class of existing HOPs. Importantly, we present both new and existing HOPs in a common representation; performing inference with any combination of these HOPs requires no change of representations or new derivations.	algorithm;cobham's thesis;ground truth;interaction;message passing;time complexity;tom gruber;tor messenger;victor allis;word lists by frequency	Daniel Tarlow;Inmar E. Givoni;Richard S. Zemel	2010			computer science;theoretical computer science;distributed computing;algorithm	ML	-12.802152027573054	-65.68405621796661	91139
598d758cb58b6b91dbfcab87ab45196f47bba047	interactive video retrieval using combination of semantic index and instance search		We present our efficient implementation of interactive video search tool for Known Item Search(KIS) using the combination of Se- mantic Indexing(SIN) and Instance Search(INS). The interaction way allows users to index a video clip via their knowledge of visual con- tent. Our system offers users a set of concepts and SIN module returns candidate keyframes based on userss selection of concepts. Users choose keyframes which contains the interest items, and the INS module recom- mends frames with similar content to the target clip. Finally, the precise time stamps of the clip are given by the Temporal Refinement(TR).		Hongliang Bai;Lezi Wang;Yuan Dong;Kun Tao	2013		10.1007/978-3-642-35728-2_67	computer vision;computer science;machine learning;data mining;multimedia;world wide web;information retrieval	Web+IR	-16.39018995428035	-54.05839752627606	91194
7bb61a5262b8b5ca93e64bb662af264f62c86b5f	deep hybrid recommender systems via exploiting document context and statistics of items		Abstract The sparsity of user-to-item rating data is one of the major obstacles to achieving high rating prediction accuracy of model-based collaborative filtering (CF) recommender systems. To overcome the obstacle, researchers proposed hybrid methods for recommender systems that exploit auxiliary information together with rating data. In particular, document modeling-based hybrid methods were recently proposed that additionally utilize description documents of items such as reviews, abstracts, or synopses in order to improve the rating prediction accuracy. However, they still have two following limitations on further improvements: (1) They ignore contextual information such as word order or surrounding words of a word because their document modeling methods use bag-of-words model. (2) They do not explicitly consider Gaussian noise differently in modeling latent factors of items based on description documents together with ratings although Gaussian noise depend on statistics of items . In this paper, we propose a robust document context-aware hybrid method, which integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF) with the statistics of items to both capture contextual information and consider Gaussian noise differently. Our extensive evaluations on three real-world dataset show that our variant recommendation models based on our proposed method significantly outperform the state-of-the-art recommendation models.	recommender system	Dong Hyun Kim;Chanyoung Park;Jinoh Oh;Hwanjo Yu	2017	Inf. Sci.	10.1016/j.ins.2017.06.026	collaborative filtering;convolutional neural network;machine learning;recommender system;artificial intelligence;probabilistic logic;gaussian noise;statistics;deep learning;matrix decomposition;exploit;computer science	AI	-17.35409582851479	-65.48851731279761	91293
48615874915014d6eb4706f7df4860573854947c	visual haptic-based biomolecular docking and its applications in e-learning	computer aided design;haptic device;real time;interactive visualization;structural biology;virtual environments;three dimensional;biomolecular docking;molecular visualization;rational drug design;visualization technique;learning scenario;e learning;virtual environment;haptic interfaces;molecular interactions;molecular docking;haptic interface	Visual haptic-based biomolecular docking systems could be used for both research and e-learning in research intensive disciplines such as biology, physical chemistry, molecular medicine, biophysics, structural biology, bioinformatics, etc. The assembly of molecules in a three-dimensional space or molecular docking is used for rational drug design where a ligand docks onto a receptor. The computer-aided design systems allow a real-time interactive visualization and manipulation of molecules in virtual environment. These techniques help the user to understand molecular interactions. In recent years, besides the visualization techniques, there has been increasing interest in using haptic interfaces to facilitate the exploration and analysis of molecular docking. Haptic device enables the users to manipulate the molecules and feel its interaction during the docking process in virtual experiment on computer. In this paper, we describe a visual haptic-based biomolecular docking system that we developed for research in helix-helix docking and propose its application in e-learning. We also describe haptic-based collaborative e-learning scenarios.	bioinformatics;computer-aided design;docking (molecular);haptic technology;interaction;interactive visualization;real-time transcription;virtual reality	Olga Sourina;Jaume Torres;Jing Wang	2009	Trans. Edutainment	10.1007/978-3-642-03270-7_8	simulation;human–computer interaction;bioinformatics;engineering	Visualization	-8.341875069680034	-56.72292756237797	91718
973e818327ace7df58f36e4807908c9fff548ded	adding semantics to image-region annotations with the name-it-game	labeling game;image region annotation;large data sets;image annotation;universiteitsbibliotheek;interactive multimedia;ontology	In this paper we present the Name-It-Game, an interactive multimedia game fostering the swift creation of a large data set of region-based image annotations. Compared to existing annotation games, we consider an added semantic structure, by means of the WordNet ontology, the main innovation of the Name-It-Game. Using an ontology-powered game, instead of the more traditional annotation tools, potentially makes region-based image labeling more fun and accessible for every type of user. However, the current games often present the players with hard-to-guess objects. To prevent this from happening in the Name-It-Game, we successfully identify WordNet categories which filter out hard-to-guess objects. To verify the speed of the annotation process, we compare the online Name-It-Game with a desktop tool with similar features. Results show that the Name-It-Game outperforms this tool for semantic region-based image labeling. Lastly, we measure the accuracy of the produced segmentations and compare them with carefully created LabelMe segmentations. Judging from the quantitative and qualitative results, we believe the segmentations are competitive to those of LabelMe, especially when averaged over multiple games. By adding semantics to region-based image annotations, using the Name-It-Game, we have opened up an efficient means to provide precious labels in a playful manner.	algorithm;automated reasoning;computer user satisfaction;connected-component labeling;desktop computer;emoticon;experiment;labelme;pixel;prototype;swift (programming language);wordnet	Jeroen Steggink;Cees Snoek	2010	Multimedia Systems	10.1007/s00530-010-0220-y	computer vision;image retrieval;computer science;ontology;data mining;interactive media;world wide web;information retrieval	AI	-16.14965145033498	-60.26635570095545	91758
be055abe7ee5d113efc25e0e22b60a6f04134d2a	video collage: a novel presentation of video sequence	focusing;video collage;home videos;video presentation schemes;static video summary;video signal processing;user study;energy minimization problem;video sequences;multimedia systems;visualization;shape;video equipment;region of interest;image analysis;video sequences visualization shape automation asia multimedia systems video equipment focusing image analysis information analysis;energy minimization;home videos video collage video sequences static video summary energy minimization problem video presentation schemes;information analysis;asia;automation	This paper presents an automatic procedure for constructing a compact synthesized collage from a video sequence. The synthesized image called video collage, is a kind of static video summary - to select most representative images from video, to extract salient regions of interest (ROI) from these images and resize them according to their saliency, and to seamlessly arrange ROI on a given canvas with the temporal structure of video content preserved. We formulate the generation of video collage as an energy minimization problem in which each of above desirability is represented by an energy term. Unlike most existing video presentation schemes, video collage is more compact and visually appealing. We have applied video collage on several home videos and report superior performance in a user study compared with key existing approaches to video presentation.	digital video;energy minimization;region of interest;usability testing	Tang Wang;Tao Mei;Xian-Sheng Hua;Xueliang Liu;He-Qin Zhou	2007	2007 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2007.4284941	video compression picture types;microsoft video 1;computer vision;image analysis;visualization;shape;computer science;automation;video tracking;block-matching algorithm;multimedia;video processing;smacker video;data analysis;energy minimization;motion compensation;video post-processing;multiview video coding;computer graphics (images);region of interest	Vision	-14.638456776999016	-54.00229632183746	91788
26b7fd7fdb5c3dbcde6529a3a3b0f74fc7322f2c	3dem loupe: analysis of macromolecular dynamics using structures from electron microscopy	software;internet;protein conformation;microscopy electron;macromolecular substances	Electron microscopy (EM) provides access to structural information of macromolecular complexes in the 3-20 Å resolution range. Normal mode analysis has been extensively used with atomic resolution structures and successfully applied to EM structures. The major application of normal modes is the identification of possible conformational changes in proteins. The analysis can throw light on the mechanism following ligand binding, protein-protein interactions, channel opening and other functional macromolecular movements. In this article, we present a new web server, 3DEM Loupe, which allows normal mode analysis of any uploaded EM volume using a user-friendly interface and an intuitive workflow. Results can be fully explored in 3D through animations and movies generated by the server. The application is freely available at http://3demloupe.cnb.csic.es.	animation;electron microscopy;interface device component;ligands;movement;movies;normal mode;protein binding;server (computer);server (computing);usability;web server;protein protein interaction	Rubén Nogales-Cadenas;Slavica Jonic;Florence Tama;A. A. Arteni;Daniel Tabas-Madrid;Miguel Vázquez;Alberto D. Pascual-Montano;Carlos Oscar Sánchez Sorzano	2013		10.1093/nar/gkt385	protein structure;biophysics;the internet	Comp.	-5.6265067046503905	-58.15070130993686	91859
4f05358e75e44b147d92bc50080530e11f4a8a2d	measuring the influence of concept detection on video retrieval	feature detection;semantic concept detection;image processing;information retrieval;video retrieval;semantic concepts;signal processing;evaluation;digital video	There is an increasing emphasis on including semantic concept detection as part of video retrieval. This represents a modality for retrieval quite di erent from metadata-based and keyframe similaritybased approaches. One of the premises on which the success of this is based, is that good quality detection is available in order to guarantee retrieval quality. But how good does the feature detection actually need to be? Is it possible to achieve good retrieval quality, even with poor quality concept detection and if so then what is the tipping point below which detection accuracy proves not to be bene cial? In this paper we explore this question using a collection of rushes video where we arti cially vary the quality of detection of semantic features and we study the impact on the resulting retrieval. Our results show that the impact of improving or degrading performance of concept detectors is not directly re ected as retrieval performance and this raises interesting questions about how accurate concept detection really needs to be.	feature detection (computer vision);feature detection (web development);key frame;modality (human–computer interaction);ontology (information science);sensor	Pablo Toharia;Oscar David Robles;Alan F. Smeaton;Angel Rodríguez	2009		10.1007/978-3-642-03767-2_71	computer vision;visual word;image processing;computer science;evaluation;signal processing;concept search;feature detection;multimedia;information retrieval	Vision	-14.874169657632772	-58.68024822956129	91906
02cbb54d4ee60c503d4db3afc5e6b97b06357fa2	keyword and face image retrieval based on latent semantic indexing	reconnaissance visage;busqueda informacion;representacion conocimientos;keyword;procesamiento informacion;multimedia;image processing;facies;traitement image stereoscopique;recherche image;information retrieval;procesamiento imagen;semantics;palabra clave;latent semantic space latent semantic indexing face image retrieval image annotation information processing;mot cle;image annotation;semantica;semantique;traitement image;multimedia systems;face recognition;recherche information;latent semantic indexing;stereo image processing;information processing;representation connaissance;visual features;image retrieval indexing information processing information retrieval content based retrieval shape face recognition character recognition histograms;multimedia systems face recognition image retrieval;semantic space;analisis semantico;knowledge representation;traitement information;analyse semantique;semantic analysis;image retrieval	To annotate images in keywords and to map visual features to symbolic features are critical problems in sense of multimedia information processing. This work describes mechanisms for retrieving suitable keywords on face images and for retrieving face images based on latent semantic indexing in a face image annotation and a retrieval system. The visual features are represented in sizes/lengths of face parts, and symbolic features in keywords, respectively. A space is constructed by applying latent semantic indexing, which is called the latent semantic space. This space consists of face images and keywords. Also, this space reflects the sizes/lengths of the face pans. Retrieving face images and keywords in terms of sizes/lengths of face parts, and retrieving keywords, which are suitable to be assigned to the face images, are achieved. Retrieving keywords using the sizes/lengths is corresponding to assignment of keywords to one face image.	automatic image annotation;image retrieval;information processing;latent semantic analysis	Hideaki Ito;Hiroyasu Koshimizu	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1398323	computer vision;latent semantic indexing;facies;information processing;image processing;image retrieval;computer science;pattern recognition;semantics;information retrieval	Vision	-12.202843382011476	-59.538649447643124	92609
619a5fc3a558d2857ee2533975dd9d81e3c03764	recognizing objects and scenes in news videos	busqueda informacion;anotacion;alignement;naming;text;traduccion automatica;analisis estadistico;image processing;recherche image;availability;disponibilidad;information retrieval;procesamiento imagen;annotation;texte;probabilistic approach;traitement image;automatic generation;statistical ma chine translation;traduction automatique;senal video;statistical analysis;signal video;recherche information;enfoque probabilista;approche probabiliste;analyse statistique;denomination;alineamiento;denominacion;video signal;texto;disponibilite;alignment;automatic translation;image retrieval	We propose a new approach to recognize objects and scenes in news videos motivated by the availability of large video collections. This approach considers the recognition problem as the translation of visual elements to words. The correspondences between visual elements and words are learned using the methods adapted from statistical machine translation and used to predict words for particular image regions (region naming), for entire images (auto-annotation), or to associate the automatically generated speech transcript text with the correct video frames (video alignment). Experimental results are presented on TRECVID 2004 data set, which consists of about 150 hours of news videos associated with manual annotations and speech transcript text. The results show that the retrieval performance can be improved by associating visual and textual elements. Also, extensive analysis of features are provided and a method to combine features are proposed.	pattern recognition;statistical machine translation	Muhammet Bastan;Pinar Duygulu Sahin	2006		10.1007/11788034_39	computer vision;availability;speech recognition;image processing;image retrieval;computer science;pattern recognition;information retrieval	Vision	-12.120035209543616	-62.0368874739174	92621
1f8aa48979d2a1d4c374b0d5afb1a58c1a3cc98e	a context-based region labeling approach for semantic image segmentation	sensibilidad contexto;anotacion;mathematical morphology;representacion conocimientos;ontologie;context aware;morfologia matematica;image segmentation;multimedia;image processing;bassin versant;imagen fija;automatic image annotation;relation semantique;arbre maximal;recursive shortest spanning tree;logique floue;relacion semantica;procesamiento imagen;semantics;logica difusa;annotation;semantica;semantique;traitement image;interpretacion informacion;fuzzy logic;interpretation information;fixed image;arbol maximo;cuenca;segmentation image;representation connaissance;visual features;ontologia;image fixe;semantic relation;spanning tree;sensibilite contexte;knowledge representation;watershed;region growing;information interpretation;ontology;domain specificity;morphologie mathematique	In this paper we present a framework for simultaneous image segmentation and region labeling leading to automatic image annotation. The proposed framework operates at semantic level using possible semantic labels to make decisions on handling image regions instead of visual features used traditionally. In order to stress its independence of a specific image segmentation approach we applied our idea on two region growing algorithms, i.e. watershed and recursive shortest spanning tree. Additionally we exploit the notion of visual context by employing fuzzy algebra and ontological taxonomic knowledge representation, incorporating in this way global information and improving region interpretation. In this process, semantic region growing labeling results are being re-adjusted appropriately, utilizing contextual knowledge in the form of domain-specific semantic concepts and relations. The performance of the overall methodology is demonstrated on a real-life still image dataset from the popular domains of beach holidays and motorsports.	algorithm;automatic image annotation;connected-component labeling;file spanning;image segmentation;knowledge representation and reasoning;minimum spanning tree;norm (social);real life;recursion;region growing;watershed (image processing)	Thanos Athanasiadis;Phivos Mylonas;Yannis S. Avrithis	2006		10.1007/11930334_17	fuzzy logic;computer vision;semantic computing;mathematical morphology;watershed;spanning tree;image processing;computer science;artificial intelligence;machine learning;ontology;semantics;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation;automatic image annotation;algorithm	Vision	-11.395344342124979	-60.392392612773605	92657
b6248bd5aa880001c6dbb43ebff8b0353875153c	a visual model approach for parsing colonoscopy videos	busqueda informacion;analisis imagen;criblage;endoscopia;image processing;tumor maligno;average precision;information retrieval;screening;endoscopy;procesamiento imagen;aparato digestivo;data mining;traitement image;digestive system;appareil digestif;educational resource;analyse syntaxique;col;senal video;signal video;visual modeling;fouille donnee;analisis sintaxico;recherche information;visual inspection;syntactic analysis;depistage;visual features;descubrimiento;colorectal cancer;cernido;video signal;image analysis;tumeur maligne;medical screening;endoscopie;analisis sonido;analisis semantico;sound analysis;analyse semantique;audio analysis;analyse image;content based retrieval;busca dato;recherche par contenu;analyse son;compressed video;malignant tumor;semantic analysis	Colonoscopy is an important screening procedure for colorectal cancer. During this procedure, the endoscopist visually inspects the colon. Currently, there is no content-based analysis and retrieval system that automatically analyzes videos captured from colonoscopic procedures and provides a user-friendly and efficient access to important content. Such a system will be valuable as an educational resource for endoscopic research, a platform to assess procedural skills for endoscopists, and a platform for mining for unknown abnormality patterns that may lead to colorectal cancer. The first necessary step for the analysis is parsing for semantic units. In this paper, we propose a new visual model approach that employs visual features extracted directly from compressed videos together with audio analysis to discover important semantic units called scenes. Our experimental results show average precision and recall of 93% and 85%, respectively.	colon classification;information retrieval;parsing;precision and recall;usability;visual modeling	Yu Cao;Wallapak Tavanapong;Dalei Li;Jung Hwan Oh;Piet C. de Groen;Johnny S. Wong	2004		10.1007/978-3-540-27814-6_22	computer vision;digestion;image analysis;speech recognition;image processing;computer science;colorectal cancer;parsing;multimedia;audio analyzer;visual inspection	AI	-12.451471316847876	-60.579132165808154	92663
51572793fb2d985c8a12a1d041b8c59149092ef3	finding more relevance: propagating similarity on markov random field for object retrieval	markov random field;bag of visual words;image retrieval	To retrieve objects from large corpus with high accuracy is a challenging task. In this paper, we propose a Markov random field (MRF) based probabilistic retrieval framework. In this framework, the similarities between the query image and dataset images are modeled as the likelihood and the relationships among the images in the dataset are modeled as the prior. Then, the prior and the likelihood are combined to improve retrieval performance. Further, we present an approximate belief propagation algorithm as well as a subgraph extraction algorithm for efficient inference in MRF. Finally, we design a new image retrieval system under our framework. This system can be considered as an extended bag-of-visual-words retrieval system with the probabilistic based re-ranking module. We evaluate our method on three standard datasets: Oxford-5K, Oxford-105K and Paris-6K. The experimental results show that the proposed system significantly improves the retrieval accuracy on these datasets and exceeds the state-of-the-art results. & 2015 Elsevier B.V. All rights reserved.	approximation algorithm;bag-of-words model in computer vision;belief propagation;computational complexity theory;experiment;feature extraction;image retrieval;markov chain;markov random field;modal logic;real-time clock;relevance;software propagation;text corpus;tf–idf	Peng Lu;Xujun Peng;Xinshan Zhu;Ruifan Li	2015	Sig. Proc.: Image Comm.	10.1016/j.image.2015.01.007	computer vision;image retrieval;computer science;machine learning;pattern recognition;data mining;bag-of-words model in computer vision;divergence-from-randomness model	Vision	-15.37616948664658	-60.315731577119756	92978
11c5171e76f7b1e2038461b1c678676627b88d29	application of automated structure analysis to some organic compounds using pcs. 3. crystallographic programs	structure analysis;organic compound	The DIRECT-SEARCHER automatic system (DS*SYSTEM) ls2 is designed to carry out the calculations for the structure analysis of organic compounds running on mainframe and personal computers (PC). This system consists of heavy-atom methods (PSL + SEARCHER), direct methods (DIRECTER, MULTAN series), and other crystallographic programs. In the first’ and the second paper: the automation of heavyatom methods and direct methods for crystallographic phasing are described. In this paper details of the other improved crystallographic programs are described, respectively. DS*SYSTEM is suitable for use by organic chemists as well as professional crystallographers.	mainframe computer;personal computer	Sachiko Okada;Kouichirou Okada	1994	Journal of Chemical Information and Computer Sciences	10.1021/ci00020a035	crystallography;stereochemistry;chemistry;combinatorial chemistry;structural analysis	Robotics	-6.1591977683958135	-56.289028043533236	93497
2dd943da98edbf60a55dfdc1333321685556c713	trada: tree based ranking function adaptation	regression tree;selected works;model adaptation;ranking function;web search engine;machine learning;weight training;bepress;web search;learning to rank;web search ranking	"""Machine Learned Ranking approaches have shown successes in web search engines. With the increasing demands on developing effective ranking functions for different search domains, we have seen a big bottleneck, i.e., the problem of insufficient training data, which has significantly limited the fast development and deployment of machine learned ranking functions for different web search domains. In this paper, we propose a new approach called tree based ranking function adaptation (""""tree adaptation"""") to address this problem. Tree adaptation assumes that ranking functions are trained with regression-tree based modeling methods, such as Gradient Boosting Trees. It takes such a ranking function from one domain and tunes its tree-based structure with a small amount of training data from the target domain. The unique features include (1) it can automatically identify the part of model that needs adjustment for the new domain, (2) it can appropriately weight training examples considering both local and global distributions. Experiments are performed to show that tree adaptation can provide better-quality ranking functions for a new domain, compared to other modeling methods."""	decision tree learning;experiment;gradient boosting;learning to rank;norm (social);ranking (information retrieval);software deployment;tree (data structure);web search engine	Keke Chen;Rongqing Lu;Chak-Kuen Wong;Gordon Sun;Larry P. Heck;Belle L. Tseng	2008		10.1145/1458082.1458233	ranking;web search engine;computer science;strength training;machine learning;decision tree;pattern recognition;data mining;ranking svm;world wide web;learning to rank	ML	-18.709887861935023	-63.90968284592075	93588
428aa213faadd3f2efb9f3cac23307d4c291c208	a pipeline for extracting multi-modal markers for meaning in lectures		This article introduces initial concepts for a context sensitive computing pipeline to detect multimodal markers for meaning from video and audio data, to notify the audience of markers of importance and then to classify sequences of a recorded video into segments by content and importance in order to summarise the content as video and audio and in other modalities. In this paper, we first consider the linguistic background, then show the input data for the pipeline. Finally, we outline the concepts which are to be implemented in each step of this pipeline and discuss how the evaluation for this pipeline can be achieved.	incremental backup;machine learning;modal logic;multimodal interaction;prototype;realization (linguistics);usability	Johannes Ude;Frederick Michaud;Rebekah Wegener;Jörg Cassens	2018				HCI	-18.175747567258973	-59.56910922783488	93707
0da4714f5fd4aa61bab2abfbb6373d6dbae5af92	historical document analysis: a review of french projects and open issues	document handling;history;knowledge representation;french projects review;heritage documents;historical document analysis;cultural differences;layout;shape;indexing;text analysis	This subject is on the crossroad of different fields like signal or image processing, pattern recognition, artificial intelligence, man-machine interaction and knowledge engineering. Indeed, each of these different fields can contribute to build a reliable and efficient document interpretation system. This paper points out the necessities and importance of dedicated services oriented to historical documents. In a first step, a bird view approach is adopted describing document specificities and associated projects which deal with the enrichment and the exploitation of heritage documents. This synthesis lead to a set of particular Research Problems. The second part focuses on a set of open issues, which should be tackled by the document analysis community, for the management of the features and the knowledge representation of these ancient documents.	artificial intelligence;bird's-eye view;gene ontology term enrichment;historical document;human–computer interaction;image processing;knowledge engineering;knowledge representation and reasoning;pattern recognition;signal processing	Mickaël Coustaty;Romain Raveaux;Jean-Marc Ogier	2011	2011 19th European Signal Processing Conference		document engineering;computer science;data science;data mining;information retrieval;design document listing	AI	-13.734352336174513	-58.921054083644485	93849
d4f7169925446fadd0fa99e9c027fdb65a1a6a47	coarctate transition states: the discovery of a reaction principle	transition state;topology;base donnee;quimica organica;reaccion quimica;chimie organique;topologie;database;base dato;mecanisme reaction;classification;topologia;mecanismo reaccion;estado transitorio;computer aid;asistencia ordenador;reaction chimique;chemical reaction;clasificacion;assistance ordinateur;etat transition;reaction mechanism;organic chemistry			Rainer Herges	1994	Journal of Chemical Information and Computer Sciences	10.1021/ci00017a011	chemistry;chemical reaction;biological classification;organic chemistry;reaction mechanism;physical chemistry;transition state	Theory	-6.642832891970489	-54.41312257726184	94469
1f7343e01a05e8c30e2f232f84099ea67419e134	tonal mir: a music retrieval engine based on semantic web technologies	tonal music;multimedia computing science;music retrieval;design and development;semantic web technology;inference rule;music similarity;music information retrieval;semantic web;normal form;computer science;inference rules;mir	Within the Music Information Retrieval context, this paper describes an innovative approach to discovering music similarities. The Tonal MIR system has been designed and developed to provide a powerful and flexible music retrieval mechanism using semantic web technologies. The retrieval process is based on an algorithm consisting of two main phases: the preprocessing, that converts an audio file into an XML/RDF normalized form; the matching phase, based on inference rules, that compares the normalized music excerpt with the music items stored in a database, and produces as output a list of results ranked according to a similarity degree.	algorithm;information retrieval;preprocessor;semantic web;xml	Matteo Magistrali;Nadia Catenazzi;Lorenzo Sommaruga	2010		10.1145/1839707.1839734	speech recognition;computer science;pop music automation;world wide web;information retrieval	Web+IR	-13.147530297300763	-53.975693044113484	94595
7554fcffe9bf371196481a6745efab906897d78b	prodigen: visualizing the probability landscape of stochastic gene regulatory networks in state and time space	systems biology;network analysis;computational biology bioinformatics;feature detection and tracking;modelling simulation;algorithms;computer appl in life sciences;microarrays;bioinformatics	Visualizing the complex probability landscape of stochastic gene regulatory networks can further biologists’ understanding of phenotypic behavior associated with specific genes. We present PRODIGEN (PRObability DIstribution of GEne Networks), a web-based visual analysis tool for the systematic exploration of probability distributions over simulation time and state space in such networks. PRODIGEN was designed in collaboration with bioinformaticians who research stochastic gene networks. The analysis tool combines in a novel way existing, expanded, and new visual encodings to capture the time-varying characteristics of probability distributions: spaghetti plots over one dimensional projection, heatmaps of distributions over 2D projections, enhanced with overlaid time curves to display temporal changes, and novel individual glyphs of state information corresponding to particular peaks. We demonstrate the effectiveness of the tool through two case studies on the computed probabilistic landscape of a gene regulatory network and of a toggle-switch network. Domain expert feedback indicates that our visual approach can help biologists: 1) visualize probabilities of stable states, 2) explore the temporal probability distributions, and 3) discover small peaks in the probability landscape that have potential relation to specific diseases.	feature toggle;gene regulatory network;glyph;probability;projections and predictions;simulation;spaghetti code;state space;subject-matter expert;web application	Chihua Ma;Timothy Luciani;Anna Terebus;Jie Liang;G. Elisabeta Marai	2016		10.1186/s12859-016-1447-1	biology;dna microarray;network analysis;computer science;bioinformatics;data science;data mining;systems biology	ML	-6.568474496758613	-60.563367973296536	94929
8ac5530ac875c7d33a683e7e98670a6aefd4a51f	multimedia processing for advanced content services	short form;video analysis;personalization;multimodal user interface;content analysis;media processing;network connectivity;content repurposing;video search	The proliferation of network-connected media-enabled devices has given users access to large volumes of information and entertainment in video form. Taking advantage of these vast video resources involves the creation of effective mechanisms for searching, navigating, personalizing, and repurposing video to support alternative consumption modes. Automated content analysis algorithms that utilize media processing techniques are the key to the creation of such mechanisms. Media processing also serves to facilitate retrieval and navigation of content by enabling multimodal user interfaces.  In this talk I will discuss some of the media processing research at AT&T Labs aimed at extracting content-based metadata, identifying relevant segments to create short-form personalized content, and providing speech-enabled multimodal user interfaces. I will describe several prototype systems based on these capabilities for giving users easy access to video and multimedia information on a wide range of media-enabled devices.	accessibility;algorithm;information retrieval;multimodal interaction;personalization;prototype;user interface	Behzad Shahraray	2010		10.1145/1743384.1743388	content analysis;computer science;personalization;multimedia;internet privacy;world wide web	OS	-15.96306977529882	-55.110090098213696	95081
cf33162fb89c2a50bf8e2100a8d5fb8dcec13b4e	chemcalc: a building block for tomorrow's chemical infrastructure	json;html5;molecular formula;mass spectrometry;monoisotopic mass;web services;cloud computing	Web services, as an aspect of cloud computing, are becoming an important part of the general IT infrastructure, and scientific computing is no exception to this trend. We propose a simple approach to develop chemical Web services, through which servers could expose the essential data manipulation functionality that students and researchers need for chemical calculations. These services return their results as JSON (JavaScript Object Notation) objects, which facilitates their use for Web applications. The ChemCalc project http://www.chemcalc.org demonstrates this approach: we present three Web services related with mass spectrometry, namely isotopic distribution simulation, peptide fragmentation simulation, and molecular formula determination. We also developed a complete Web application based on these three Web services, taking advantage of modern HTML5 and JavaScript libraries (ChemDoodle and jQuery).	chemical formula;cloud computing;computational science;fragmentation (computing);html5;json;javascript;libraries;package testing;physical object;simulation;spectrometry;web application;web service;jquery	Luc Patiny;Alain Borel	2013	Journal of chemical information and modeling	10.1021/ci300563h	web service;ajax;web application security;web development;web application;web modeling;monoisotopic mass;chemistry;content security policy;web mapping;web-based simulation;mass spectrometry;web design;cloud computing;html5;web standards;computer science;bioinformatics;theoretical computer science;web api;ws-policy;service-oriented architecture;ws-addressing;database;services computing;ws-i basic profile;web 2.0;world wide web;json-ld	Web+IR	-5.020641903643344	-59.35822146280941	95372
95eaa4009ec9e630badb5b451a21ca4dc8a7ffe6	indexing large online multimedia repositories using semantic expansion and visual analysis	mediaeval;information resources;multimedia;video signal processing;semantics;complementary textual resources large online multimedia repository indexing semantic expansion visual analysis user tag prediction online videos visual features associated textual metadata;video signal processing indexing information resources meta data multimedia computing semantic web;large scale multimedia data;multimedia computing;mediaeval multimedia large scale multimedia data indexing tagging geotagging semantic expansion visual similarity bag of articles;visualization;internet;indexing;feature extraction;bag of articles;indexing internet videos electronic publishing tagging feature extraction prediction models visualization semantics;semantic expansion;semantic web;meta data;electronic publishing;visual similarity;geotagging;videos;tagging;prediction models	The proposed framework automatically predicts user tags for online videos from their visual features and associated textual metadata, which is semantically expanded using complementary textual resources.	video clip	Xavier Sevillano;Tomas Piatrik;Krishna Chandramouli;Qianni Zhang;Ebroul Izquierdo	2012	IEEE MultiMedia	10.1109/MMUL.2012.28	search engine indexing;the internet;visualization;feature extraction;computer science;semantic web;database;semantics;geotagging;predictive modelling;electronic publishing;metadata;world wide web;information retrieval	Vision	-15.006027447020433	-55.90547186749063	95588
fbe9a0f1887732fab42d344951fd2eec06006889	nativity based raga identification systems	music data mining;data mining;decision support systems hybrid intelligent systems us department of defense;audio file nativity based raga identification systems computational musicology computer science data mining pattern relationship historical patterns future trends engaging tonal context western music indian classical music;music;scale and note computational musicology ragas data mining indian classical music neural network	Computational Musicology is a new and emerging field which draws heavily from Computer Science, particularly Data mining (cataloging through data to identify patterns and establish relationships). The relationship among patterns provides information for the ragas. It can be converted into knowledge about historical patterns and future trends. Raga is an attractive combination of notes, engaging tonal context. Western Music has been under the gaze of this community for quite some time. However, Indian music has remained relatively untouched. Generating script for a musical composition and identifying raga in Indian Classical music is a tedious and time consuming task. Here, we depict a system which takes an audio file as an input identifies the language and instruments which will give nativity of music and converts it into sequence of notes, identifies the raga. The system is analyzed for 55 different rags and tested for 20 different ragas. The system performs with a result of 85%.	computation;computational musicology;computer science;data mining	K. Karunakar;B. Anand Kumar;G. V. Suresh;T. Immanuel	2012	2012 12th International Conference on Hybrid Intelligent Systems (HIS)	10.1109/HIS.2012.6421349	speech recognition;engineering;artificial intelligence;communication	DB	-17.680882672652363	-53.351534549013685	96458
bac68ed6bddf4a991d1c3b716301861395270e81	simicon: a web tool for protein-ligand model comparison through calculation of equivalent atomic contacts	ligando;software;proteine;computer graphics;ligands;calculation;calculo;model comparison;modelo;internet;proteins;protein conformation;ligand;modele;proteina;calcul;protein;models;databases protein	SUMMARY SimiCon is a web server designed for an automated identification of equivalent protein-ligand atomic contacts in different conformational models of a complex. The contacts are computed with internal coordinate mechanics (ICM) software with respect to molecular symmetry and the results are shown in the browser as text, tables and interactive 3D graphics. The web server can be executed remotely without a browser to allow users to automate multiple calculations.   AVAILABILITY SimiCon is freely available at http://abagyan.ucsd.edu/SimiCon	3d computer graphics;data table;execution;extracellular matrix;internal coordinate mechanics;iterated conditional modes;ligands;model selection;server (computer);server (computing);web server;world wide web;z-matrix (chemistry)	Manuel Rueda;Vsevolod Katritch;Eugene Raush;Ruben Abagyan	2010	Bioinformatics	10.1093/bioinformatics/btq504	simulation;computer science;bioinformatics;theoretical computer science;ligand	Web+IR	-5.592375201299394	-57.80047034646556	96575
6d0f0d4761258a47df388f32c3703a290d779920	interactive acquisition, analysis, and visualization of sonographic volume data		This article discusses the design features of an interactive system for acquiring, analyzing, and displaying volume sonographic patient data. Methods for reprojection of two-dimensional (2D) sonographic image data into a volume matrix are discussed. We describe an intuitive, easy-to-use graphical user interface that facilitates physician operation of a system incorporating an interactive volume renderer for optimization of viewing orientation and data presentation and incorporates stereoscopic viewing. Visualization methods are described that permit the operator interactively to extract tissues or organs of interest from the rest of the volume scanned. Selected examples of clinical images are given to demonstrate system capability. The system represents a cost-effective 3D ultrasound system integrating clinical scanners and graphics workstations. © 1997 John Wiley u0026 Sons, Inc. Int J Imaging Syst Technol, 8: 26–37, 1997		Thomas R. Nelson;Dolores H. Pretorius	1997	Int. J. Imaging Systems and Technology	10.1002/(SICI)1098-1098(1997)8:1%3C26::AID-IMA4%3E3.0.CO;2-V	computer vision;simulation;computer science;computer graphics (images)	Visualization	-9.898898717065316	-53.779352800647466	96804
e58086670dc322f0c1ab01f024a607612aaebcf0	web document analysis based on visual segmentation and page rendering	web documents;web sites document handling learning artificial intelligence pattern classification rendering computer graphics support vector machines;document handling;web pages;text analysis conferences;support vector machines;web blog database web document analysis page rendering visual segmentation web page segmentation dynamic layout textual information block segmentation block classification svm based machine learning approach textual features visual based features;internet document;machine learning;web sites;pattern classification;web page segmentation;block segmentation;learning artificial intelligence;rendering computer graphics;semantic block;web page segmentation internet document block segmentation semantic block	This paper proposes an approach for segmenting a Web page into its semantic parts. Such analysis may be useful for adapting blog or other pages on small devices. In this approach, we take advantage of both dynamic layout after rendering and textual information. Our method segments the page into blocks and then classifies the blocks. A classification in semantic parts is performed thanks to a SVM-based machine learning approach using a set of 30 textual and visual-based features. Evaluation is conducted on a Web blog database. Results are provided for both block classification and blog segmentation into articles.	blog;machine learning;support vector machine;web page	Cong Kinh Nguyen;Laurence Likforman-Sulem;Jean-Claude Moissinac;Claudie Faure;Jérémy Lardon	2012	2012 10th IAPR International Workshop on Document Analysis Systems	10.1109/DAS.2012.95	support vector machine;computer science;machine learning;web page;data mining;world wide web;information retrieval	Web+IR	-18.935341187024328	-58.34493257008157	96992
ec6b608742a217c59daee56084b7134e5e2fa54a	n-gram over context	latent variable models;nonparametric models;n gram topic model;graphical models;topic models;mapreduce	Our proposal, N -gram over Context (NOC), is a nonparametric topic model that aims to help our understanding of a given corpus, and be applied to many text mining applications. Like other topic models, NOC represents each document as a mixture of topics and generates each word from one topic. Unlike these models, NOC focuses on both a topic structure as an internal linguistic structure, and N gram as an external linguistic structure. To improve the quality of topic specific N -grams, NOC reveals a tree of topics that captures the semantic relationship between topics from a given corpus as context, and forms N -gram by offering power-law distributions for word frequencies on this topic tree. To gain both these linguistic structures efficiently, NOC learns them from a given corpus in a unified manner. By accessing this entire tree at the word level in the generative process of each document, NOC enables each document to maintain a thematic coherence and form N -grams over context. We develop a parallelizable inference algorithm, DNOC, to support large data sets. Experiments on review articles/papers/tweet show that NOC is useful as a generative model to discover both the topic structure and the corresponding N -grams, and well complements human experts and domain specific knowledge. D-NOC can process large data sets while preserving full generative model performance, by the help of an open-source distributed machine learning framework.	algorithm;cache coherence;generative model;machine learning;n-gram;network on a chip;open-source software;outline (list);scalability;stream (computing);streaming media;text corpus;text mining;topic model;word lists by frequency	Noriaki Kawamae	2016		10.1145/2872427.2882981	natural language processing;computer science;machine learning;pattern recognition;database;graphical model;topic model;world wide web	NLP	-17.41956716522082	-64.17556048117488	97772
e15edb388838e55a42c087591795cb0e4713f1a8	application of bi-gram driven chinese handwritten character segmentation for an address reading system	document structure;vocabulaire;text;confiance;keyword;document analysis;image processing;feature recognition;estructura documental;caracter manuscrito;base donnee tres grande;structure document;reading device;localization;manuscript character;edit distance;vocabulary;character segmentation;database;procesamiento imagen;base dato;palabra clave;localizacion;vocabulario;texte;segmentation;chino;mot cle;traitement image;appareil lecture;analyse documentaire;confidence;localisation;confianza;indexing;pattern matching;indexation;indizacion;base de donnees;segment droite;distancia;pattern recognition;analisis documental;segmento recta;line segment;appariement chaine;pretraitement;concordance forme;reconnaissance forme;very large databases;reconocimiento patron;string matching;connected component;chinois;texto;chinese;caractere manuscrit;segmentacion;aparato lectura;distance;pretreatment;pretratamiento	In this paper, we describe a bi-gram driven method for automatic reading of Chinese handwritten mails. In destination address block (DAB) location, text lines are first extracted by connected components analysis. Each candidate line is segmented and recognized by our holistic method, which incorporates mail layout features, recognition confidence and context cost. All these are also taken into consideration to identify the DABs from the candidate text lines. Based on them, street address line and organization name line are determined. At last step, edit distance based string matching is performed against given databases. We also discuss the pretreatment to deal with Chinese address databases consisted of a large amount of vocabularies in order to generate keywords for fast indexing during matching. Detailed experiment results on handwritten mail samples are given in the last section.		Yan Jiang;Xiaoqing Ding;Qiang Fu;Zheng Ren	2006		10.1007/11669487_20	feature recognition;speech recognition;connected component;edit distance;line segment;image processing;computer science;artificial intelligence;pattern matching;database;confidence;distance;segmentation;chinese;algorithm	NLP	-11.87610886072708	-61.96834935588301	97835
205115bca0d843972d0fa2f735d32cba59fe67ad	distributed medical imaging applications using java technology	computers;radiology;user friendliness java technology internet technologies medical image interpretation functions hospital java based distributed medical imaging applications remote medical image dataset windowing fly through visualisations java based medical imaging application radiology interpretation;colon;biomedical imaging;internet;three dimensional displays;java three dimensional displays biomedical imaging radiology colon internet computers;medical image processing java;java	Advances in Internet technologies have opened up new opportunities in relation to medical image interpretation. This task can be accomplished outside the hospital using distributed medical imaging applications. In this paper, a Java-based distributed medical imaging application is presented. This application is able to access to a remote medical image dataset via a network and provide the necessary interpretation functions, such as windowing and fly-through visualisations. Experimental results show that this Java-based medical imaging application has the ability to provide comprehensive functionality for radiology interpretation as well as a high level of user friendliness. Thus demonstrating Java is a suitable tool for developing distributed medical imaging applications.	high-level programming language;internet;java;medical imaging;radiology;usability;visualization (graphics)	Qiusha Min;Robert J. T. Sadleir	2015	2015 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)	10.1109/APSIPA.2015.7415343	computer science;theoretical computer science;multimedia;computer graphics (images)	EDA	-9.79247313901568	-54.28385589932639	98207
f69d63e25159084da319ff5105ba841e61bec2f3	introducing hippy: a visualization tool for understanding the alpha-helix pair interface.	contact maps;protein structure prediction;open source	Hippy is a novel protein visualization tool designed to meet the needs of those who are working with contact maps for protein structure prediction, and in particular for those desiring to gain insight into the configurations and properties of pairs of alpha helices. It is the only known program that allows the simultaneous display of the structure and the contact map. Users can customize Hippy to display the side chains, contacts, and the steric surface of the helices. The program is open source; the software was implemented in OpenGL with an aim for platform independence.		Robert Fraser;Janice I. Glasgow	2006			human–computer interaction;computer science;bioinformatics;world wide web	Visualization	-5.78692238595845	-58.26554909369337	99355
08889075d1477aaab7c173d43e5aedd7438d9dd2	semantic-oriented 3d shape retrieval using relevance feedback	search engine;computer graphic;web search engine;3d model;feature extraction;shape retrieval;relevance feedback	Shape-based retrieval of 3D models has become an important challenge in computer graphics. Object similarity, however, is a subjective matter, dependent on the human viewer, since objects have semantics and are not mere geometric entities. Relevance feedback aims at addressing the subjectivity of similarity. This paper presents a novel relevance feedback algorithm that is based on supervised as well as unsupervised feature extraction techniques. It also proposes a novel signature for 3D models, the sphere projection. A Web search engine that realizes the signature and the relevance feedback algorithm is presented. We show that the proposed approach produces good results and outperforms previous techniques.	3d modeling;algorithm;color;computer graphics;electronic signature;entity;feature extraction;information retrieval;item unique identification;iteration;mind;relevance feedback;texture mapping;web search engine	George Leifman;Ron Meir;Ayellet Tal	2005	The Visual Computer	10.1007/s00371-005-0341-z	computer vision;web search engine;feature extraction;computer science;machine learning;information retrieval;search engine	Vision	-13.607705470759125	-57.84412773302624	99369
0c958d2dbd807d12916db40b5acbcc204eceed94	variant view: visualizing sequence variants in their gene context	dna;databases;genetic variants;context awareness;genomics;genomics bioinformatics data visualisation diseases dna;sequential analysis;information visualization;browsers;data visualisation;information spaces variant view tool sequence variant visualization gene context dna sequence individual genome standard reference genome disease biological context variant impact assessment data abstractions task abstractions information dense visual encoding prevalent genome browsers;design study;bioinformatics bioinformatics genomics sequential analysis browsers databases context awareness design methodology genetic variants information visualization design study;diseases;algorithms animals base sequence chromosome mapping computer graphics dna dna mutational analysis humans information storage and retrieval molecular sequence data sequence alignment sequence analysis dna user computer interface;bioinformatics genomics sequential analysis browsers databases context awareness design methodology;bioinformatics;design methodology	Scientists use DNA sequence differences between an individual's genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.	imagery;maximal set	Joel A. Ferstay;Cydney B. Nielsen;Tamara Munzner	2013	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2013.214	genomics;information visualization;design methods;computer science;bioinformatics;sequential analysis;data mining;world wide web;dna;data visualization;statistics	Visualization	-6.030413796790724	-60.21149594851967	99371
b78344f49946e1422ddd01f2e101f87b15e78a55	label propagation using amendable clamping		Assigning several labels to digital data is becoming easier because we can perform it in a collaborative manner with Internet users. However, some suitable labels may be missed and may not be attached to the data leading to inaccuracies in classification. In this paper, we propose a novel graphbased multi-label classifier to support the multi-labeling task. The core process of our algorithm is to update label weights of labeled data from their top-k similar data in each label propagation step. We report that our algorithm is more stable for F-scores compared to the state-of-the-art ones even though the some correct labels are missed. ACM Classification	acm computing classification system;algorithm;care-of address;cluster hypothesis;digital data;emoticon;experiment;f1 score;internet;multi-label classification;multiclass classification;software propagation;wikipedia	Tatsurou Miyazaki;Yasunobu Sumikawa	2018			clamping;electronic engineering;mathematics	ML	-18.54353801220512	-64.82863151752505	100270
0eed3cfb67236636350d1634d9db2c8a1f5c2a09	dovis: an implementation for high-throughput virtual screening using autodock	software;integrated systems;score function;drug discovery;queuing system;ligands;queueing theory;pharmaceutical preparations;graphical user interface;binding sites;models chemical;linux cluster;software engineering;computer applications;computational biology bioinformatics;computer programs;molecules;chemical compounds;large scale;virtual screening;proteins;drug design;high performance computer;graphic user interface;protein binding;algorithms;reprints;user computer interface;combinatorial libraries;high throughput;computer appl in life sciences;computer simulation;molecular docking;parallel processing;sequence analysis protein;throughput;microarrays;bioinformatics;in silico	Molecular-docking-based virtual screening is an important tool in drug discovery that is used to significantly reduce the number of possible chemical compounds to be investigated. In addition to the selection of a sound docking strategy with appropriate scoring functions, another technical challenge is to in silico screen millions of compounds in a reasonable time. To meet this challenge, it is necessary to use high performance computing (HPC) platforms and techniques. However, the development of an integrated HPC system that makes efficient use of its elements is not trivial. We have developed an application termed DOVIS that uses AutoDock (version 3) as the docking engine and runs in parallel on a Linux cluster. DOVIS can efficiently dock large numbers (millions) of small molecules (ligands) to a receptor, screening 500 to 1,000 compounds per processor per day. Furthermore, in DOVIS, the docking session is fully integrated and automated in that the inputs are specified via a graphical user interface, the calculations are fully integrated with a Linux cluster queuing system for parallel processing, and the results can be visualized and queried. DOVIS removes most of the complexities and organizational problems associated with large-scale high-throughput virtual screening, and provides a convenient and efficient solution for AutoDock users to use this software in a Linux cluster platform.	active worlds;autodock;behavior;boat dock;chemicals;computer cluster;contain (action);docking (molecular);drug discovery;graphical user interface;high-throughput computing;ligands;linux;manuscripts;parallel computing;score;scoring functions for docking;small molecule;software design;supercomputer;throughput;user interface device component;virtual screening	Shuxing Zhang;Kamal Kumar;Xiaohui Jiang;Anders Wallqvist;Jaques Reifman	2007	BMC Bioinformatics	10.1186/1471-2105-9-126	computer simulation;parallel processing;human–computer interaction;computer science;bioinformatics;theoretical computer science;graphical user interface	HPC	-6.239535681828074	-57.59237222980204	100837
4629702f5912b93228cce205ee3b85617a112cc7	sound visualization and retrieval technique for assisting hearing memory of patrol worker	interfase usuario;informatique mobile;image segmentation;visualizacion;seuil;user interface;automatic segmentation;threshold;hombre;spectrum;visualization;senal video;signal video;visualisation;segmentation image;human;video signal;interface utilisateur;audition;audicion;umbral;mobile computing;audio acoustics;hearing;homme;acoustique audio	In this paper, we propose a system to support equipment check patrol. One of the most difficult tasks for patrol worker is discriminating the difference of equipment sound in the check spot. The main purpose of our system is to support human hearing by automatic segmentation, visualization and retrieval of equipment sound. Automatic segmentation function is realized using a new video shot segmentation method. The method uses fluctuating thresholds according to time transition of visual changes, and performs automatic segmentation of recorded sound according to the step of check work. The visualization and the retrieval functions are based on the spectrum subtraction method and analyzing technology of the temporal frequency map. This paper shows the evaluation result of the segmentation method using equipment check video. And it also shows the effectiveness of the proposed visualizing and retrieval method through an example of electric discharge sound.		Fujio Tsutsumi	2003		10.1007/978-3-540-45233-1_29	computer vision;speech recognition;visualization;computer science;artificial intelligence;operating system;mobile computing	Visualization	-11.408392739650493	-62.60351612324707	101103
fadfa2581f6413fcccd75ffb5a968c6aa8ab7f22	a combined image-query creation method for expressing user's intentions with shape and color features in multiple digital images	image query creation;content based image retrieval;query by an image;multimedia database;user s intentions	This paper presents a combined-image query creation method for expressing user's intentions by combining multiple digital images for image retrieval. This method uses image databases provided for query-creation and performs several set-operators to express user's imagination by combining user's imaginary images and real scenes. The user's intentions are expressed by the operation of subspace projection in the image feature space. This method makes it possible to create an imaginary image as the combined-image query for expressing user's intentions by combining several images and operators in the query creation process. The important feature of this method is to use shape and color features for expressing imaginations by extending our previously proposed method. This paper shows several experimental results to clarify the feasibility and effectiveness of our method.		Yasuhiro Hayashi;Yasushi Kiyoki;Xing Chen	2010		10.3233/978-1-60750-690-4-258	computer vision;query optimization;query expansion;computer science;multimedia;information retrieval	HCI	-12.230390460516578	-58.04575684117296	101143
7f3ec6e4ded6a4db2dcf9502c3f08f20d4f93c66	concept pre-digestion method for image relevance reinforcement learning	concept digestion method;image storage;image database pre digestion method image relevance reinforcement learning relevance feedback cbir system q learning;learning;image databases;information retrieval;bismuth;reinforcement learning;concept digestion method relevance feedback reinforcement learning q learning;q learning;image database;bayesian methods;user feedback;visual databases content based retrieval image retrieval learning artificial intelligence relevance feedback;learning radio frequency feedback image databases image retrieval image storage spatial databases bismuth information retrieval bayesian methods;image relevance reinforcement learning;feedback;radio frequency;spatial databases;pre digestion method;learning artificial intelligence;relevance feedback;content based retrieval;cbir system;visual databases;image retrieval	Relevance feedback (RF) is commonly used to improve the performance of CBIR system by allowing incorporation of user feedback iteratively. Recently, a method called image relevance reinforcement learning (IRRL) has been proposed for integrating several existing RF techniques as well as for exploiting RF sessions of multiple users. The precision obtained at the end of every iteration is used was a reward signal in the Q-learning based reinforcement learning (RL) approach. The objective of learning in IRRL is to estimate the optimal RF technique to be applied for a given query at a specific iteration. The main drawback of IRRL is its prohibitive learning time and storage requirement. We propose a way of addressing these difficulties by performing `pre-digestion' of concepts before applying IRRL. Experimental results on two databases of images demonstrated the viability of the proposed approach	content-based image retrieval;database;homology (biology);information retrieval;iteration;long short-term memory;multi-user;q-learning;radio frequency;reinforcement learning;relevance feedback	Sudhakara P. Reddy;Raju S. Bapi;Chakravarthy Bhagvati;Bulusu Lakshmana Deekshatulu	2007	2007 International Conference on Computing: Theory and Applications (ICCTA'07)	10.1109/ICCTA.2007.43	computer vision;bayesian probability;image retrieval;computer science;artificial intelligence;machine learning;bismuth;feedback;reinforcement learning;radio frequency;information retrieval;q-learning	Robotics	-14.741351002543567	-60.27910846022537	101229
bef250032e449e47adfd105525372aceb58a3452	performance evaluation of document layout analysis algorithms on the uw data set	databases;presentacion documento;systeme gestion electronique document;evaluation performance;base donnee;document image analysis;document analysis;performance evaluation;evaluacion prestacion;document layout;database;base dato;segmentation;presentation document;analyse documentaire;electronic document management system;data visualization;analisis documental;algorithms;sistema gestion electronica documento;segmentacion	A performance evaluation protocol for the layout analysis (page segmentation) is discussed in this paper. In the University of Washington English Document Image Database-III, there are 1600 English document images that come with manually edited ground truth of entity bounding boxes. These bounding boxes enclose text and non-text zones, text-lines, and words. We describe a performance metric for the comparison of the detected entities and the ground truth in terms of their bounding boxes. The Document Attribute Format Speciication (DAFS) is used as the standard data representation. The protocol is intended to serve as a model for using the UW-III database to evaluate the document analysis algorithms. A set of layout analysis algorithms which detect diierent entities have been tested based on the data set and the performance metric. The evaluation results are presented in this paper.	algorithm;data (computing);direct access file system;document layout analysis;entity;ground truth;performance evaluation	Jisheng Liang;Ihsin T. Phillips;Robert M. Haralick	1997		10.1117/12.270067	computer science;document layout analysis;data mining;database;world wide web	Web+IR	-11.912586887214237	-62.01984526049544	101307
d4220644ef94fa4c2e5138a619cfcd86508d2ea1	confidence-aware negative sampling method for noisy knowledge graph embedding		Knowledge graph embedding (KGE) can benefit a variety of downstream tasks, such as link prediction and relation extraction, and has therefore quickly gained much attention. However, most conventional embedding models assume that all triple facts share the same confidence without any noise, which is inappropriate. In fact, many noises and conflicts can be brought into a knowledge graph (KG) because of both the automatic construction process and data quality problems. Fortunately, the novel confidence-aware knowledge representation learning (CKRL) framework was proposed, to incorporate triple confidence into translation-based models for KGE. Though effective at detecting noises, with uniform negative sampling methods, and a harsh triple quality function, CKRL could easily cause zero loss problems and false detection issues. To address these problems, we introduce the concept of negative triple confidence and propose a confidence-aware negative sampling method to support the training of CKRL in noisy KGs. We evaluate our model on the knowledge graph completion task. Experimental results demonstrate that the idea of introducing negative triple confidence can greatly facilitate performance improvement in this task, which confirms the capability of our model in noisy knowledge representation learning (NKRL).		Yingchun Shan;Chenyang Bu;Xiaojian Liu;Shengwei Ji;Lei Li	2018	2018 IEEE International Conference on Big Knowledge (ICBK)	10.1109/ICBK.2018.00013	graph embedding;task analysis;knowledge representation and reasoning;machine learning;noise measurement;relationship extraction;sampling (statistics);embedding;computer science;artificial intelligence;data quality	AI	-16.39891484086055	-65.94041419422759	101556
6a9f231d5516bfd9bedce1db6e3586adb5fd6bf1	lire: open source image retrieval in java	content based image retrieval	Content based image retrieval has been around for some time. There are lots of different test data sets, lots of published methods and techniques, and manifold retrieval challenges, where content based image retrieval is of interest. LIRE is a Java library, that provides a simple way to index and retrieve millions of images based on the images' contents. LIRE is robust and well tested and is not only recommended by the websites of ImageCLEF and MediaEval, but is also employed in industry. This paper gives an overview on LIRE, its use, capabilities and reports on retrieval and runtime performance.	content-based image retrieval;java;open-source software;run time (program lifecycle phase);test data	Mathias Lux	2013		10.1145/2502081.2502226	visual word;image retrieval;computer science;multimedia;world wide web;information retrieval	Web+IR	-13.87142262393011	-57.30142059997836	101989
22bc1eaf33be8ab6a0da6603cbc89730b5b56354	iiit-h at ijcnlp-2017 task 3: a bidirectional-lstm approach for review opinion diversification		The Review Opinion Diversification (Revopid-2017) shared task (Singh et al., 2017b) focuses on selecting top-k reviews from a set of reviews for a particular product based on a specific criteria. In this paper, we describe our approaches and results for modeling the ranking of reviews based on their usefulness score, this being the first of the three subtasks under this shared task. Instead of posing this as a regression problem, we modeled this as a classification task where we want to identify whether a review is useful or not. We employed a bi-directional LSTM to represent each review and is used with a softmax layer to predict the usefulness score. We chose the review with highest usefulness score, then find its cosine similarity score with rest of the reviews. This is done in order to ensure diversity in the selection of top-k reviews. On the top-5 list prediction, we finished 3rd while in top-10 list one, we are placed 2nd in the shared task. We have discussed the model and the results in detail in the paper.	cosine similarity;diversification (finance);long short-term memory;matrix regularization;softmax function;word embedding	Pruthwik Mishra;Prathyusha Danda;Silpa Kanneganti;Soujanya Lanka	2017			computer science;natural language processing;artificial intelligence;diversification (marketing strategy)	NLP	-18.53452353527884	-62.9761176791166	102239
31229e9e8ae89333cdad35452487cb5664cf3d4e	hybrid visual and conceptual image representation within active relevance feedback context	information extraction;image database;lexical database;semantic interpretation;feature vector;image descriptors;image representation;semantic gap;visual features;keyword annotations;relevance feedback;image retrieval	"""Many of the available image databases have keyword annotations associated with the images. In spite of the availability of good quality low-level visual features that reflect well the physical content, image retrieval based on visual features alone is subject to semantic gap. Text annotations are related to image context or semantic interpretation of the visual content and are not necessarely directly linked to the visual appearance of the images. Keywords and visual features thus provide complementary information. Using both sources of information is an advantage in many applications and recent work in this area reflects this interest. In this paper, we address the challenge of semantic gap reduction using a hybrid visual and conceptual representation of the content within an active relevance feedback context. We introduce a new feature vector, based on the keyword annotations available for the images, which makes use of conceptual information extracted from an external lexical database, information represented by a set of """"core concepts"""". Our experiments show that the use of the proposed hybrid conceptual and visual feature vector dramatically improves the quality of the relevance feedback results."""	experiment;feature vector;gap reduction;high- and low-level;image retrieval;lexical database;relevance feedback;semantic interpretation	Marin Ferecatu;Nozha Boujemaa;Michel Crucianu	2005		10.1145/1101826.1101860	natural language processing;semantic interpretation;visual word;feature vector;image retrieval;computer science;pattern recognition;information extraction;information retrieval;semantic gap	Vision	-14.983855268757	-59.14685729508627	102451
7f381d01fa2f81568ddbae4bb3cb76defef7c73c	neural memories and search engines	search engine;common factor;vector space model;context memories;neural memories;weighted averaging;search engines;vector space models;associative memory;evolutionary process;68t35;68t30;dimensional reduction;latent semantic analysis;92b20;reverse engineering;memory model;matrix model	In this article, we show the existence of a formal convergence between thematrixmodels of biological memories and the vector space models designed to extract information from large collections of documents.Wefirst show that, formally, the term-by-document matrix (a mathematical representation of a set of codified documents) can be interpreted as an associative memory. In this framework, the dimensionality reduction of the termby-document matrices produced by the latent semantic analysis (LSA) has a common factor with the matrix biological memories. This factor consists in the generation of a statistical ‘conceptualisation’ of data using little dispersed weighted averages. Then, we present a class of matrix memory that built up thematic blocks using multiplicative contexts. The thematic memories define modular networks that can be acceded using contexts as passwords. This mathematical structure emphasises the contacts between LSA andmatrixmemorymodels and invites to interpret LSA, and similar procedures, as a reverse engineering applied on context-deprived cognitive products, or on biological objects (e.g. genomes) selected during large evolutionary processes.	content-addressable memory;dimensionality reduction;latent semantic analysis;mathematical structure;password;reverse engineering;the matrix;web search engine	Eduardo Mizraji	2008	Int. J. General Systems	10.1080/03081070802037738	computer science;artificial intelligence;theoretical computer science;machine learning;search engine	ML	-7.110986315755555	-64.80418746282555	102741
81cec7e705d698b4f0c32b75a95db2488e29bec5	ontology–based context–dependent personalization technology	implicit decision context;ontology based extraction;customer decisions;rs personalization technology;personal e mail assistant recommendation system ontology context feature filtering machine learning;personal cause consequence decision rules;personal cause consequence decision rules ontology based context dependent personalization technology recommendation systems explicit decision context implicit decision context rs personalization technology ontology based extraction semantically interpretable context customer decisions historical data sample machine learning customer centered feature set;recommender systems learning artificial intelligence ontologies artificial intelligence;ontologies artificial intelligence;recommendation system;explicit decision context;machine learning;feature filtering;semantically interpretable context;ontology based context dependent personalization technology;personal e mail assistant;customer centered feature set;learning artificial intelligence;ontology;recommender systems;recommendation systems;context;historical data sample	Personalization, a topmost concern of modern recommendation systems (RS), is intended to predict individual motivation of a customer for this or that choice. It depends on many factors forming explicit and implicit decision context. The paper proposes RS personalization technology that focuses on ontology–based extraction of semantically interpretable context of each particular customer’s decisions from his/her historical data sample with the subsequent machine learning–based extraction of customer–centered feature set and personal cause–consequence decision rules. The technology is fully implemented by Practical Reasoning, Inc. and validated via several case studies.	binary data;gene ontology term enrichment;information;machine learning;personalization;recommender system;reed–solomon error correction;software engine	Vladimir Gorodetsky;Vladimir Samoilov;Sergey Serebryakov	2010	2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2010.254	computer science;knowledge management;machine learning;data mining;information retrieval;recommender system	SE	-18.178781490990094	-53.3992697733343	102844
7eff359fc617f923d8771ce1517382e34c44aa3f	the human genome project: software challenges and future directions	dna;biology computing;genomics;sequences;biology computing genetics;sociotechnical systems;cloning;genetics;assembly;software challenges;fingerprint recognition;human genome;human genome project;humans genomics bioinformatics dna sequences laboratories assembly fingerprint recognition sociotechnical systems cloning;humans;gene sequences human genome project software challenges;gene sequences;program development;bioinformatics	Summary form only given. The sequencing of the human genome would not have been possible without software - and, because of the specific nature of this effort, very little of it was previously available. We provide an overview of the programs developed for the human genome project, some of which have not been published before. The sequencing was officially completed in 2003, but its results (in combination with other obtained genomes) enabled the analysis on a grand scale. That mandated even more complex programming work. We conclude with an outline of several research directions which, in this author's opinion, become increasingly important.		Nikola Stojanovic	2005	The 3rd ACS/IEEE International Conference onComputer Systems and Applications, 2005.	10.1109/AICCSA.2005.1387117	computational biology;genomics;human genome;bioinformatics;sociotechnical system;sequence;cloning;assembly;dna;fingerprint recognition	SE	-4.618709576673733	-60.280413579431745	103177
94471713ef64f1e49f881d0ac09a6470a4bd1de5	a test-bed for region-based image retrieval using multiple segmentation algorithms and the mpeg-7 experimentation model: the schema reference system	busqueda informacion;modele reference;analisis contenido;interfase usuario;centro gravitacional;analisis escena;analyse scene;image segmentation;centre gravite;image processing;recherche image;image databank;user interface;information retrieval;information visuelle;automatic segmentation;reference model;center of mass;critical mass;procesamiento imagen;image multiple;semantics;imagen multiple;test bed;semantica;semantique;traitement image;region based image retrieval;multiple image;systeme reference;content analysis;informacion visual;reference systems;indexing;recherche information;visual information;banco imagen;indexation;banque image;segmentation image;sistema referencia;experimental model;indizacion;interface utilisateur;analyse contenu;analisis semantico;analyse semantique;reference system;content based retrieval;recherche par contenu;semantic analysis;scene analysis;modelo referencia;network of excellence;image retrieval	The aim of the SCHEMA Network of Excellence is to bring together a critical mass of universities, research centers, industrial partners and end users, in order to design a reference system for contentbased semantic scene analysis, interpretation and understanding. In this paper, recent advances in the development of the SCHEMA reference system are reported, focusing on the application of region-based image retrieval using automatic segmentation. More specifically, the first and the second version of the reference system are presented and the motivation behind the different approaches followed during the development of these two versions is discussed. Experimental results for both systems, using a common collection of images, are shown. Additionally, a comparative evaluation of the two versions both in terms of retrieval accuracy and in terms of time-efficiency is performed, allowing the evaluation of the system as a whole as well as the evaluation of the usability of different components integrated with the reference system, such as the MPEG-7 eXperimentation Model. This illustrates the suitability of the SCHEMA reference system in serving as a test-bed for evaluating and comparing different algorithms and approaches pertaining to the content-based and semantic manipulation of visual information, ranging from segmentation algorithms to indexing features and methodologies.	algorithm;automatic summarization;content-based image retrieval;interactivity;mpeg-7;relevance feedback;testbed;usability	Vasileios Mezaris;Charalambos Doulaverakis;Raúl Medina Beltrán de Otálora;Stephan Herrmann;Yiannis Kompatsiaris;Michael G. Strintzis	2004		10.1007/978-3-540-27814-6_69	center of mass;computer vision;search engine indexing;reference model;content analysis;image processing;image retrieval;computer science;artificial intelligence;pattern recognition;semantics;critical mass;image segmentation;user interface;information retrieval;testbed	Web+IR	-13.12404869852179	-58.40063381215165	103284
b58faaf54f09d876873a126286a08ea45e6c4bb2	example-based caricature generation with exaggeration control	example based;caricature;visual appearance facial feature;exaggeration	Caricature is a popular artistic media widely used for effective communications. The fascination of caricature lies in its expressive depiction of a person’s prominent features, which is usually realized through the so-called exaggeration technique. This paper proposes a new example-based automatic caricature generation system supporting the exaggeration of both the shape of facial components and the spatial relationships among the components. Given the photograph of a face, the system automatically computes the feature vectors representing the shape of facial components as well as the spatial relationship among the components. Those features are exaggerated and then used to search the learning database for the corresponding caricature components and for arranging the retrieved components to create the caricature. Experimental results show that our system can generate the caricatures of the example style capturing the prominent features of the subjects.	experiment;fascination;feature vector	Wei Yang;Masahiro Toyoura;Jiayi Xu;Fumio Ohnuma;Xiaoyang Mao	2015	The Visual Computer	10.1007/s00371-015-1177-9	computer vision;computer graphics (images)	AI	-10.151931458527086	-61.27004835503724	103353
ca0bdb450ab2bc5d6a5f47f10e231d81a1f5374e	pbm: a software package to create, display and manipulate interactively models of small molecules and proteins on ibm-compatible pcs	microordenador;modelizacion;software;computer program;pascal language;molecular model;proteine;logiciel;computerized processing;tratamiento informatico;implementation;modelo molecular;microordinateur;microcomputer;algorithme;modelisation;algorithm;ejecucion;proteins;modele moleculaire;ibm pc compatible;software package;logicial;proteina;pascal;interaction model;programa computador;modeling;traitement informatique;programme ordinateur;algoritmo	The PBM package was developed to create, display and conveniently manipulate protein and small molecule structures on IBM-compatible microcomputers. It consists of four modules: CREATE, SPHERE, RIBBON and CONVERT. CREATE includes commands to create or alter ('mutate') the primary and subsequently the tertiary structure of a given peptide or protein by defining phi and psi angles of residues at will, options to add, delete or alter atoms in a structure, utilities to choose easily between the most common rotamers of amino acid residue sidechains and options to analyse in various ways a protein conformation. SPHERE provides for an interactive manipulation of structures containing up to 2700 atoms which can belong up to six different molecules. All manipulations can be made with the use of an ordinary mouse, by choosing from a variety of pull-down menus. Three types of models can be implemented to display molecules on the computer screen or the plotter: skeletal, solid space-filling and wireframe space-filling models. RIBBON creates ribbon models of proteins and allows for a limited variety of interactive manipulations. CONVERT is a file converter, which is capable of converting files of atom coordinates of literally any format to Brookhaven Data Bank format files. The package produces very good results for protein molecules of reasonable sizes, both in terms of graphics quality and speed of operations, on an 80486 IBM PC-compatible machine equipped with a 1 MByte VGA display card and a colour VGA monitor, which is a recommended configuration.		Anastassis Perrakis;C. Constantinides;A. Athanasiades;Stavros J. Hamodrakas	1995	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/11.2.141	simulation;pascal;systems modeling;computer science;bioinformatics;molecular model;microcomputer;ibm pc compatible;implementation;pascal;computer graphics (images)	Graphics	-5.2490677108621115	-57.00062407883582	103423
4543111e78a5dacc84773757257a32a872ce8d3a	substructure discovery using minimum description length and background knowledge	original data;appropriate substructure;structural regularity;subdue system;hierarchical description;minimum description length principle;structural data;structural concept;subdue substructure discovery system;minimum description length;artificial intelligent;structured data	The ability to identify interesting and repetitive substructures is an essential component to discovering knowledge in structural data. We describe a new version of our Subdue substructure discovery system based on the minimum description length principle. The Subdue system discovers substructures that compress the original data and represent structural concepts in the data. By replacing previously-discovered substructures in the data, multiple passes of Subdue produce a hierarchical description of the structural regularities in the data. Subdue uses a computationally-bounded inexact graph match that identi es similar, but not identical, instances of a substructure and nds an approximate measure of closeness of two substructures when under computational constraints. In addition to the minimumdescription length principle, other background knowledge can be used by Subdue to guide the search towards more appropriate substructures. Experiments in a variety of domains demonstrate Subdue's ability to nd substructures capable of compressing the original data and to discover structural concepts important to the domain.	approximation algorithm;centrality;database;discovery system;experiment;kelly criterion;minimum description length;optimal substructure;semiconductor;tom	Diane J. Cook;Lawrence B. Holder	1994	J. Artif. Intell. Res.	10.1613/jair.43	bioinformatics	AI	-6.24276058401273	-63.52906495118664	103668
837e4ec15bbd8c6f2064d200a04f736ebb25a9d2	human behaviour profiling for anomaly detection	surveillance;unsupervised anomaly detection;co clustering;computer vision;behaviour;topic models;video;spatio temporal feature points	Purpose – The purpose of this paper is to address the problem of profiling human behaviour patterns captured in surveillance videos for the application of online normal behaviour recognition and anomaly detection.Design/methodology/approach – A novel framework is developed for automatic behaviour profiling and online anomaly detection without any manual labeling of the training dataset.Findings – Experimental results demonstrate the effectiveness and robustness of the authors' approach using noisy and sparse datasets collected from one real surveillance scenario.Originality/value – To discover the topics, co‐clustering topic model not only captures the correlation between words, but also models the correlations between topics. The major difference between the conventional co‐clustering algorithms and the proposed CCMT is that CCMT shows a major improvement in terms of recall, i.e. interpretability.	anomaly detection;profiling (computer programming)	Xudong Zhu;Zhijing Liu	2011	Int. J. Intelligent Computing and Cybernetics	10.1108/17563781111160039	video;computer science;machine learning;pattern recognition;data mining;topic model;biclustering	AI	-18.548552411983255	-57.94205140293594	103690
409acb240fef18fc1e6630864763de9630dfbd8c	fast retrieval of similar configurations	content based retrieval information retrieval computer science image retrieval genetic algorithms simulated annealing query processing world wide web prototypes;optimal solution;local search algorithm;query processing;object locations;helium;search space;information retrieval;query processing configuration similarity content based image retrieval object locations semantic features spatio temporal constraints exhaustive processing exponential complexity multimedia information nonsystematic search heuristics genetic algorithms simulated annealing hill climbing synthetic datasets;prototypes;heuristic method;configuration similarity;indexing terms;simulated annealing;satisfiability;multimedia systems;multimedia systems simulated annealing genetic algorithms content based retrieval;temporal constraints;nonsystematic search heuristics;exhaustive processing;multimedia information;world wide web;genetic algorithm;genetic algorithms;hill climbing;computer science;content based image retrieval;exponential complexity;semantic features;spatio temporal constraints;real time application;content based retrieval;synthetic datasets;image retrieval	Configuration similarity is a special form of content-based image retrieval that considers relative object locations. It can be used as a standalone method, or to complement retrieval based on visual or semantic features. The corresponding queries ask for sets of objects that satisfy some spatio-temporal constraints, e.g., “find all triplets of objects ( 1, 2, 3), such that 1 is northeastof 2, which is inside 3.” Exhaustive processing (i.e., retrieval of the best solutions) of configuration similarity queries, in general, has exponential complexity and fast search for sub-optimal solutions is the only way to deal with the vast amounts of multimedia information in several real-time applications. In this paper we first discuss the utilization of nonsystematic search heuristics, based on genetic algorithms, simulated annealing and hill climbing approaches. An extensive experimentation with real and synthetic datasets reveals that hill climbing techniques are the best for the current problem; therefore, as a subsequent step we study the search space, and develop improved variations of hill climbing that take advantage of the special structure of the problem to enhance speed. The proposed heuristic methods significantly outperform systematic search when there is only limited time for query processing.	content-based image retrieval;database;genetic algorithm;heuristic (computer science);hill climbing;real-time web;simulated annealing;synthetic intelligence;time complexity	Dimitris Papadias;Marios Mantzourogiannis;Ishfaq Ahmad	2003	IEEE Trans. Multimedia	10.1109/TMM.2003.811629	genetic algorithm;image retrieval;computer science;theoretical computer science;machine learning;world wide web;information retrieval	DB	-11.246441160486869	-57.73231243517033	103825
13ac67f7d1a2ed8601db4b10c657f155de47ddcd	a new approach to retrieve video by example video clip	factor;video retrieval;similarity;example clip;similarity measure	The similarity measure between video clips is a key issue in video retrieval. In the developing of our video retrieval system, we propose a new video similarity model. In contrast to existing algorithms, it proposes many influencing factors, such as order factor, speed factor, disturbance factor, etc, based on the subjective visual judgement of human. So this algorithm embodies the degree of similarity completely and systematically. On the other hand, it has resolution adaptation because it can be applied to every level of video structure. In the retrieval system, it can be used to process video query by example clip. This paper introduces it in detail and presents experiment results at the end of the paper.	algorithm;query by example;similarity measure;video clip	Xiaoming Liu;Yueting Zhuang;Yunhe Pan	1999		10.1145/319878.319889	similarity;information retrieval	Vision	-12.056198725982393	-57.461954890505034	103976
fcaf2d387b4e1371d8057092327b86734719fce9	natural language processing for large-scale medical image analysis using deep learning	radiology;medical image analysis;big data;deep learning;natural language processing	Recent advances in deep learning enable us to analyze a large number of images efficiently; however, collecting such large dataset has been mostly hindered by the rate of manual human efforts. Nonetheless, medical images are usually saved with the accompanying radiology reports, and accommodating the natural language information for image analysis has great potential. For example, data collection can be automated to leverage the large volume of data available in the Picture Archiving and Communication Systems (PACS). Additionally, image annotation can be automated by incorporating the human annotation in the radiology reports. The size of medical dataset usually is much smaller than the natural image dataset which advanced deep learning technology is developed for. We can unleash the full capacity of deep learning for analyzing a large volume of medical images, by automating the data collection and annotation. Moreover, a sustainable system can be developed even when the data are continuously being updated, shared, and integrated. This chapter will review some fundamentals of natural language processing (NLP) and cover various NLP techniques to help automate medical image collection and annotation.	deep learning;image analysis;medical image computing;natural language processing	Hoo-Chang Shin;Le Lu;Ronald M. Summers	2017		10.1016/B978-0-12-810408-8.00023-7	image retrieval;computer science;data science;data mining;temporal annotation;information retrieval	ML	-10.678464931369051	-66.01288830161835	104079
aeb8b2fa2ac0286362f8c991a7590f305e642bae	nfu-enabled fasta: moving bioinformatics applications onto wide area networks	health research;uk clinical guidelines;biological patents;europe pubmed central;large dataset;research paradigm;citation search;large data sets;computational biology bioinformatics;internet technology;data storage;uk phd theses thesis;life sciences;functional unit;uk research reports;distributed collaboration;medical journals;computer appl in life sciences;wide area network;europe pmc;biomedical research;internet backplane protocol;bioinformatics	Advances in Internet technologies have allowed life science researchers to reach beyond the lab-centric research paradigm to create distributed collaborations. Of the existing technologies that support distributed collaborations, there are currently none that simultaneously support data storage and computation as a shared network resource, enabling computational burden to be wholly removed from participating clients. Software using computation-enable logistical networking components of the Internet Backplane Protocol provides a suitable means to accomplish these tasks. Here, we demonstrate software that enables this approach by distributing both the FASTA algorithm and appropriate data sets within the framework of a wide area network. For large datasets, computation-enabled logistical networks provide a significant reduction in FASTA algorithm running time over local and non-distributed logistical networking frameworks. We also find that genome-scale sizes of the stored data are easily adaptable to logistical networks. Network function unit-enabled Internet Backplane Protocol effectively distributes FASTA algorithm computation over large data sets stored within the scaleable network. In situations where computation is subject to parallel solution over very large data sets, this approach provides a means to allow distributed collaborators access to a shared storage resource capable of storing the large volumes of data equated with modern life science. In addition, it provides a computation framework that removes the burden of computation from the client and places it within the network.	algorithm;backplane device component;bioinformatics;biological science disciplines;clients;computation (action);computer data storage;fasta;internet;logistics;programming paradigm;time complexity	Erich J. Baker;Guan N. Lin;Huadong Liu;Ravi Kosuri	2007	Source Code for Biology and Medicine	10.1186/1751-0473-2-8	computer science;bioinformatics;data science;computer data storage;data mining;world wide web	Networks	-4.781410290619871	-60.77421526671603	104488
575a8f39f383c92cf6a258f9e73e3ff1da819b3d	efficient access methods for image databases	symbolic computation;symbolic databases;spatial reasoning;image databases;image databank;information retrieval;interrogation base donnee;image database;interrogacion base datos;2d c string;satisfiability;similarity retrieval;systeme base donnee;calculo simbolico;recherche information;banco imagen;database systems;banque image;2d string;prime number;hash function;spatial relationships;pictorial query;access method;calcul symbolique;database query	In the previous approaches to retrieve a symbolic picture from an image database which contains multiple symbolic pictures, only 9 spatial relationships that are represented in 2D strings or 9DLT matrices were considered. In this paper, we propose two efficient access methods for image databases, which can handle 169 spatial relationships. In the first proposed method, each record signature is represented by 26 bits and 26-bit strings of size N, where N > 0. In the second proposed method, each record signature is represented by 26 bits and 26 products of prime numbers. Given the same image databases, the same query picture and the same hash functions, the ratio of the false match in our strategy can be smaller than that of the previous approaches, where a false match is that a record signature matches a query signature but the corresponding record does not satisfy the query.		Ye-In Chang;Bi-Yen Yang	1997	Inf. Process. Lett.	10.1016/S0020-0190(97)00151-8	spatial relation;symbolic computation;hash function;computer science;theoretical computer science;data mining;database;mathematics;spatial intelligence;access method;prime number;algorithm;satisfiability	DB	-11.54455702229495	-58.609548454943074	104857
9f615d55cdb20df57a2f01f52eddd303524756b9	a knowledge acquisition method for improving data quality in services engagements	address standardization;software;automatic cleansing knowledge acquisition method data quality services engagements enterprise databases data cleansing algorithms ripple down rules conditional random field address standardization system;enterprise databases;context buildings dictionaries training standardization knowledge based systems software;knowledge acquisition method;automatic cleansing;information extraction;training;data cleansing rules artificial intelligence information extraction address standardization;ripple down rules;artificial intelligent;rewriting systems business data processing knowledge acquisition learning artificial intelligence;rewriting systems;business data processing;knowledge acquisition;dictionaries;it adoption;services engagements;conditional random field;artificial intelligence;data cleansing;data quality;data cleansing algorithms;learning artificial intelligence;context;standardization;data cleansing rules;knowledge based systems;buildings;conditional random field address standardization system	Poor Data Quality is a serious problem affecting enterprises. Enterprise databases are large and manual data cleansing is not feasible. For such large databases it is logical to attempt to cleanse the data in an automated way. This has led to the development of commercial tools for automatic cleansing. However, offering data cleansing as a service has been a challenge because of the need to customize the tool for different datasets. This is because current commercial systems lack the ability to incorporate the unique exceptions of different data sources. This makes the migration of underlying data cleansing algorithms from one dataset to another difficult. In this paper we specifically look at the address standardization task. We use Ripple Down Rules (RDR) framework to lower the manual effort required in rewriting the rules from one source to another. The RDR framework allows us to incrementally patch the existing rules or add exceptions without breaking other rules. We compare the RDR approach with a conditional random field (CRF) address standardization system and an existing commercially available data cleansing tool. We demonstrate that RDR is an effective knowledge acquisition method and that its adoption for data cleansing can allow data cleansing to be offered as a service.	algorithm;conditional random field;data quality;database;knowledge acquisition;restrictive design rules;rewriting;ripple	Mohan N. Dani;Tanveer A. Faruquie;Rishabh Garg;Govind Kothari;Mukesh K. Mohania;K. Hima Prasad;L. Venkata Subramaniam;Varsha N. Swamy	2010	2010 IEEE International Conference on Services Computing	10.1109/SCC.2010.91	computer science;data science;data mining;database	DB	-12.531888354523657	-65.0099777626853	105091
bbe7931dd27d200ba52f300ecbb6763f97440550	spatio-temporal querying of video content using sql for quantizable video databases	multimodal information retrieval;video databases;information retrieval;indexing terms;semantic model;structured query language;semantic modeling;graphic user interface;data reduction;video database;multimedia database;spatiotemporal queries	Multimedia database modeling and representation play an important role for efficient storage and retrieval of multimedia. Modeling of semantic video content that enables spatiotemporal queries is one of the challenging tasks. A video is called as “quantizable” if the instants of a video are enough for a person to imagine the missing scenes properly. A semantic query for quantizable videos can be defined in a more flexible way using spatio-temporal instants. In this paper, we provide a semantic modeling and retrieval system, termed as G-SMART. Firstly, the videos are quantized according to semantic events. Then semantic instants and events of the video that include objects, events, and locations are provided as a grammar-based string. This linear string representation enables both the spatial and temporal retrieval of the video using Structured Query Language (SQL). The redundancy in this linear representation is reduced by using data reduction properties such as removal of implied information. Various types of queries such as event-object-location, event-location, object-location, eventobject, current-next event, projection and semantic event are supported by G-SMART. A graphical user interface is designed to build queries and view the query results. GSMART enables multimodal presentation by displaying the query results in the form images and videos. We show our results on a tennis video database.	database;digital video;graphical user interface;multimodal interaction;quantization (signal processing);query language;smart;sql;semantic query;string (computer science)	Vani Jain;Ramazan Savas Aygün	2009	Journal of Multimedia	10.4304/jmm.4.4.215-227	semantic data model;sql;semantic computing;data reduction;index term;computer science;graphical user interface;database;world wide web;information retrieval	DB	-14.122723388083127	-54.426454494136024	105176
e6d8d347a42e91889dde54477550f76e67d79f2c	tolerance to inaccuracy in computer programs	computer program		computer program	E. B. James;Derek Partridge	1976	Comput. J.	10.1093/comjnl/19.3.207	computer science	Theory	-7.215703546988969	-55.757393538672005	106203
12e98c5cb66ead448b2c7ffb82f9474b93cb276a	compact descriptors for video analysis: the emerging mpeg standard		This paper provides an overview of the on-going compact descriptors for video analysis standard (CDVA) from the ISO/IEC moving pictures experts group (MPEG). MPEG-CDVA targets at defining a standardized bitstream syntax to enable interoperability in the context of video analysis applications. During the developments of MPEGCDVA, a series of techniques aiming to reduce the descriptor size and improve the video representation ability have been proposed. This article describes the new standard that is being developed and reports the performance of these key technical contributions.	backward compatibility;bitstream;deep learning;digital video;feature extraction;feature model;feature vector;graphics pipeline;interoperability;key frame;mathematical optimization;microsoft outlook for mac;modality (human–computer interaction);moving picture experts group;video content analysis;video tracking	Ling-yu Duan;Vijay Chandrasekhar;Shiqi Wang;Yihang Lou;Jie Lin;Yan Bai;Tiejun Huang;Alex ChiChung Kot;Wen Gao	2017	CoRR		theoretical computer science;multimedia;computer science;interoperability;bitstream;syntax	HCI	-12.789842139119164	-56.49644528147173	106324
7900d6f9f02f4b2ec8324f8a846ad2da4df4ca96	a statistical approach to the generation of a database for evaluating ocr software	statistical approach;base donnee;analisis estadistico;bootstrap;statistical processes;optical character recognition;database;base dato;military intelligence;time series;data bases;software engineering;reconnaissance caractere;statistical analysis;time series analysis;block bootstrap;analyse statistique;serie temporelle;reconocimento optico de caracteres;serie temporal;pattern recognition;reconnaissance forme;reconocimiento patron;character recognition;computer program verification;reconocimiento caracter;machine translation;reconnaissance optique caractere	In this paper we consider a statistical approach to augment a limited database of groundtruth documents for use in evaluation of optical character recognition software. A modified moving-blocks bootstrap procedure is used to construct surrogate documents for this purpose which prove to serve effectively and, in some regards, indistinguishably from groundtruth. The proposed method is validated through a rigorous statistical procedure.	comparison of optical character recognition software;n-gram;natural language processing;resultant	F. S. Brundick;Ann E. M. Brodeen;Malcolm S. Taylor	2002	International Journal on Document Analysis and Recognition	10.1007/s100320200067	speech recognition;computer science;artificial intelligence;time series;machine translation;statistics	Vision	-12.388717864658775	-61.32600495723409	106386
9e46f0fb5ca8ff2b6d7573e6b283ddd98ba07439	interactive analysis and synthesis of facial expressions based on personal facial expression space	image recognition;principal component analysis interactive analysis facial expressions synthesis personal facial expression space facial expression image sequences real time face image;interaction analysis;interactive analysis;facial expression image sequences;user interface;real time;personal facial expression space;emotion recognition;data mining;facial expression analysis;feedback;mpeg 4 standard;face recognition;emotion recognition face recognition image sequences real time systems principal component analysis feature extraction;feature extraction;principal component analysis;financial advantage program;facial animation space technology face recognition mpeg 4 standard financial advantage program information analysis image recognition feedback data mining humans;image sequence;facial animation;humans;space technology;facial expression;real time face image;facial expressions synthesis;information analysis;real time systems;image sequences	In this paper novel methods for interactive facial expression analysis and synthesis are presented based on personal facial expression space (PFES). We proposed PFES to recognize person-specific, primary facial expression image sequences by both temporal and spatial characteristics taken into consideration. On PFES, facial expression parameters which are compatible with MPEG-4 high level facial expression animation parameters can be extracted from a user's real-time face image and, they are processed to synthesize a face image in real-time. Users can interact by viewing synthesized images and, this feedback leads to interaction. Experimental results are shown to demonstrate the effectiveness of the proposed method. We also have developed user interfaces for analysis and synthesis processes.	experiment;high-level programming language;interaction;real-time locating system;user interface	Naiwala P. Chandrasiri;Takeshi Naemura;Hiroshi Harashima	2004	Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings.	10.1109/AFGR.2004.1301516	facial recognition system;computer vision;computer facial animation;feature extraction;computer science;machine learning;feedback;multimedia;space technology;data analysis;user interface;facial expression;principal component analysis	Vision	-12.92235347693954	-55.333313957677774	107095
a5d55aad646b9a97c2a2a9ae61837aa53e1f812a	continuous word embeddings for detecting local text reuses at the semantic level	word embedding;fisher vector;local text reuse	Text reuse is a common phenomenon in a variety of user-generated content. Along with the quick expansion of social media, reuses of local text are occurring much more frequently than ever before. The task of detecting these local reuses serves as an essential step for many applications. It has attracted extensive attention in recent years. However, semantic level similarities have not received consideration in most previous works. In this paper, we introduce a novel method to efficiently detect local reuses at the semantic level for large scale problems. We propose to use continuous vector representations of words to capture the semantic level similarities between short text segments. In order to handle tens of billions of documents, methods based on information geometry and hashing methods are introduced to aggregate and map text segments presented by word embeddings to binary hash codes. Experimental results demonstrate that the proposed methods achieve significantly better performance than state-of-the-art approaches in all six document collections belonging to four different categories. At some recall levels, the precisions of the proposed method are even 10 times higher than previous methods. Moreover, the efficiency of the proposed method is comparable to or better than that of some other hashing methods.	aggregate data;code;hash function;information geometry;memory segmentation;sensor;social media;user-generated content	Qi Zhang;Jihua Kang;Jin Qian;Xuanjing Huang	2014		10.1145/2600428.2609597	natural language processing;speech recognition;machine learning;pattern recognition;data mining;world wide web;information retrieval	Web+IR	-18.131093971434957	-65.3529284300797	107254
0a3c846e4ac896e3d6423b827ade6a122155a86c	analysis and semantic querying in large biomedical image datasets	analisis imagen;processor architecture;medical imagery;image processing;image resolution;complex disease;querying large image datasets;query processing;image databank;base donnee tres grande;interrogation base donnee;procesamiento imagen;interrogacion base datos;semantics;hombre;microscopy;biomedical imaging;spatial information semantic querying large biomedical image datasets biomedical image analysis querying large image datasets semantic information;semantica;semantique;traitement image;computer vision;artificial intelligent;semantic information;parallel architectures;feature extraction;medical image processing;query processing medical image processing;banco imagen;banque image;human;data intensive computing processor architectures parallel architectures information storage and retrieval artificial intelligence computer vision computer assisted prognosis;imagineria medica;imagerie medicale;artificial intelligence;image analysis;tiles;parallel architecture;data intensive computing;very large databases;analisis semantico;quality of service;analyse semantique;semantic querying;processor architectures;analyse image;information storage and retrieval;database query;computer assisted prognosis;large biomedical image datasets;spatial information;semantic analysis;homme;biomedical image analysis;spatial resolution;image analysis biomedical imaging image resolution spatial resolution algorithm design and analysis adaptive algorithm partitioning algorithms image sequence analysis image generation	Biomedical image analysis plays an important role in diagnosing, prognosing, and treating complex diseases. The authors describe a set of techniques for analyzing, processing, and querying large image datasets using semantic and spatial information.	image analysis	Vijay S. Kumar;Sivaramakrishnan Narayanan;Tahsin M. Kurç;Jun Kong;Metin Nafi Gürcan;Joel H. Saltz	2008	Computer	10.1109/MC.2008.108	computer vision;image analysis;image resolution;image processing;computer science;microscopy;data mining;semantics;information retrieval	Vision	-10.524284503951655	-59.994567374944005	107304
328a216dba032e150dba3a21fd650b8e34b962cd	a context space model for detecting anomalous behaviour in video surveillance	caviar dataset context space model automatic anomalous human behaviour detection video surveillance smart surveillance systems human factor issues contextual information context based system video clips;video surveillance;surveillance;behavioural sciences computing;security anomalous behaviour context model surveillance cctv;cctv;anomalous behaviour;context model;context context modeling humans computational modeling mathematical model video surveillance computer vision;human factors;video surveillance behavioural sciences computing human factors;security	An automatic anomalous human behaviour detection is one of the goals of smart surveillance systems' domain of research. The automatic detection addresses several human factor issues underlying the existing surveillance systems. To create such a detection system, contextual information needs to be considered. This is because context is required in order to understand human behaviour. Unfortunately, the use of contextual information is still limited in the automatic anomalous human behaviour detection approaches. This paper proposes a context space model which has two benefits: (a) It provides guidelines for the system designers to select information which can be used to describe context, (b) It enables a system to distinguish between different contexts. A comparative analysis is conducted between a context-based system which employs the proposed context space model and a system which is implemented based on one of the existing approaches. The comparison is applied on a scenario constructed using video clips from CAVIAR dataset. The results show that the context-based system outperforms the other system. This is because the context space model allows the system to consider knowledge learned from the relevant context only.	closed-circuit television;computer vision;emoticon;human computer;human factors and ergonomics;human–computer interaction;information needs;microsoft forefront;qualitative comparative analysis;requirement;sensor;video clip	Arnold Wiliem;Vamsi Krishna Madasu;Wageeh W. Boles;Prasad K. D. V. Yarlagadda	2012	2012 Ninth International Conference on Information Technology - New Generations	10.1109/ITNG.2012.11	computer vision;simulation;computer science;information security;human factors and ergonomics;data mining;context model;computer security	SE	-11.96465677951188	-52.61855006947099	107523
545a18a5237fb8dd570680ecb6c5a92209d8d2e1	on the problem of placing names on a map	cartography;map generation;text placement	Probably the most difficult task of producing a map is that of placing the text for the point, line and area features that one expects to see depicted on a geographic map. This paper describes the problem, its subtleties, and challenges, and outlines a computerized approach to solving it. With the newly developed methods, it is now possible to produce fully labeled maps and charts with a quality that approaches that achievable only by an expert cartographer and to do so in tiny fraction of the time required when done manually. r 2007 Elsevier Ltd. All rights reserved.	cartography;chart;map	Herbert Freeman	2007	J. Vis. Lang. Comput.	10.1016/j.jvlc.2007.08.006	locator map;automatic label placement;artificial intelligence;data mining	AI	-18.37607715363244	-60.140125136287736	108030
ec7286d8b9bbe29ca74cfce281fb0a6a055d5b86	the vision digital video library	search and retrieval;analisis contenido;video library;information retrieval system;online searching;information retrieval;implementation;automatic segmentation;real time;video processing;higher education;segmentation;computer networks;computer network;videoteca;video indexing;ejecucion;content analysis;recherche information;online systems;feature extraction;indexation;electronic libraries;search strategies;electronic library;recuperacion informacion;videotheque;information system;analyse contenu;video;vision;digital video library;systeme information;segmentacion;bibliotheque electronique;futures of society;library automation;sistema informacion	The goal of the VISION (Video Indexing for Searching Over Networks) project is to demonstrate the technology necessary for a comprehensive, online digital video library. We have developed automatic mechanisms to populate the library and provide content-based search and retrieval of video over computer networks. The salient feature of our approach is the integrated application of mature image or video processing, information retrieval, speech feature extraction and word-spotting technologies for efficient creation and exploration of the library materials. First, full-motion video is captured in real time with flexible qualities to meet the requirements of library patrons connected via a wide range of network bandwidths. Then, the videos are automatically segmented into a number of logically meaningful video clips by our novel two-step algorithm based on video and audio contents. A closed caption decoder has also been incorporated into the system to extract textual information to index the video clips by their contents. Finally, all information is stored in a full-text information retrieval system for content-based exploration of the library over networks of varying bandwidths.	digital video	Susan Gauch;Li Wei;John M. Gauch	1997	Inf. Process. Manage.	10.1016/S0306-4573(97)00010-1	video compression picture types;microsoft video 1;vision;video;content analysis;uncompressed video;feature extraction;computer science;video capture;video tracking;multimedia;video processing;smacker video;higher education;implementation;segmentation;video post-processing;world wide web;information retrieval;information system;non-linear editing system	HCI	-14.754727355539773	-55.39083418214771	108197
357d4b6b5daa1788d2c8e35633f1dcf45f697c7e	multimedia human brain database system for surgical candidacy determination in temporal lobe epilepsy with content-based image retrieval	databases;analisis contenido;database system;medical imagery;brain;architecture systeme;multimedia;image processing;image databank;information retrieval;segmentation;temporal lobe epilepsy;brain invertebrata;data mining;data analysis;data storage;content analysis;cerebro;epilepsie temporale;recherche information;cerveau;magnetic resonance imaging;banco imagen;chirurgie;banque image;single photon emission computed tomography;surgery;imagineria medica;imagerie medicale;arquitectura sistema;cirugia;recuperacion informacion;information system;analyse contenu;electroencephalography;system architecture;content based image retrieval;human brain;systeme information;segmentacion;epilepsia temporal;epilepsy;sistema informacion	This paper presents the development of a human brain multimedia database for surgical candidacy determination in temporal lobe epilepsy. The focus of the paper is on content-based image management, navigation and retrieval. Several medical image-processing methods including our newly developed segmentation method are utilized for information extraction/correlation and indexing. The input data includes T1-, T2-Weighted MRI and FLAIR MRI and ictal and interictal SPECT modalities with associated clinical data and EEG data analysis. The database can answer queries regarding issues such as the correlation between the attribute X of the entity Y and the outcome of a temporal lobe epilepsy surgery. The entity Y can be a brain anatomical structure such as the hippocampus. The attribute X can be either a functionality feature of the anatomical structure Y, calculated with SPECT modalities, such as signal average, or a volumetric/morphological feature of the entity Y such as volume or average curvature. The outcome of the surgery can be any surgery assessment such as memory quotient. A determination is made regarding surgical candidacy by analysis of both textual and image data. The current database system suggests a surgical determination for the cases with relatively small hippocampus and high signal intensity average on FLAIR images within the hippocampus. This indication pretty much fits with the surgeons’ expectations/observations. Moreover, as the database gets more populated with patient profiles and individual surgical outcomes, using data mining methods one may discover partially invisible correlations between the contents of different modalities of data and the outcome of the surgery.	acoustic lobing;content-based image retrieval;data mining;database;electroencephalography;fits;information extraction;medical imaging;population	Mohammad-Reza Siadat;Hamid Soltanian-Zadeh;Farshad Fotouhi;Kost V. Elisevich	2003		10.1117/12.476296	computer vision;geography;artificial intelligence;biological engineering	DB	-10.251206386733825	-59.94099187785222	108262
d4151613fabbb9d3caf1da2ac2c2c5bc1b1da187	integrating image-rich biological information with a web search tool: the inside wood model	libraries;wood biology computing botany computer aided instruction image retrieval internet scientific information systems teaching;biology computing;wood;image storage;internet access;image databases;taxonomic database;information retrieval;teaching tool;computer aided instruction;biological system modeling;wood anatomy;reference tool;web search biological system modeling image databases anatomy spatial databases image storage information retrieval image retrieval biological information theory libraries;image intensive searchable biological collections;luna insight;internet accessible wood anatomy tool;ncsu;image collection;internet;perl;spatial databases;taxonomy;biological information theory;insidewood model;web search;image intensive searchable biological collections internet accessible wood anatomy tool teaching tool research tool reference tool image rich biological information web search tool taxonomy anatomical information sets insidewood model;anatomical information sets;image rich biological information;web search tool;research tool;anatomy;botany;scientific information systems;teaching;coldfusion oracle;north carolina;wood anatomy luna insight perl botany coldfusion oracle image collection taxonomic database;image retrieval	North Carolina State University is collaborating with global partners to produce a comprehensive Internet-accessible wood anatomy reference, research, and teaching tool incorporating images, taxonomy, and anatomical information sets. With its multiple search capabilities, content types, and user options, InsideWood serves as a model for image-intensive, searchable biological collections. http://insidewood.lib.ncsu.edu/search/	taxonomy (general);web search engine	Shirley Rodgers;Elisabeth Wheeler;Troy Simpson;Jeff Bartlett	2005	Proceedings of the 5th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL '05)	10.1145/1065385.1065500	the internet;internet access;image retrieval;computer science;data science;wood;world wide web;information retrieval;taxonomy	HPC	-8.289765896220175	-61.3344571144583	108633
6cfc14c88d735544d8653a647870728c6fef8903	search for complexity generating chemical transformations by combining connectivity analysis and cascade transformation patterns	arbre graphe;topology;evaluation performance;performance evaluation;transformacion matematica;tree graph;analisis forma;biomimetica;evaluacion prestacion;analisis quimico;mathematical transformation;topologie;chemical analysis;analyse chimique;topologia;planificacion;biomimetique;transformation mathematique;data flow analysis;architecture basee modele;analyse flux donnee;planning;analisis de flujo de datos;pattern analysis;planification;sintesis quimica;arbol grafo;synthese chimique;model driven architecture;chemical synthesis;analyse forme;biomimetics;arquitectura basada modelo	Retrosynthetic analysis involved in a backward search for strategic disconnections is still the most powerful strategy, recently advanced by topology-based complexity estimation, for discovering the shortest sequences of transformations and chemical synthesis planning. Therein, we propose an alternative strategy that combines backward and forward search embodied within a mathematical model of generating chemical transformations. The backward reasoning involves a new concept of the strategic bond tree for alternative multibond disconnections of a target molecule. In the forward direction, each combination of the resulted structural fragments is examined for reconstruction of the target structure by means of biomimetic transformation patterns that describe one-pot multibond forming reactions. The algorithm has been implemented into the CSB system, and its performance is illustrated by examples of published complex molecule syntheses for comparison and analysis. This paper describes the strategy for discovering the shortest synthetic pathways based on the multibond forming cascade transformations for application in synthesis design and generating synthetically accessible product libraries.		Grazyna Nowak;Grzegorz Fic	2010	Journal of chemical information and modeling	10.1021/ci100146n	planning;biomimetics;chemical synthesis;chemistry;computer science;artificial intelligence;data-flow analysis;organic chemistry;tree;algorithm	AI	-6.763809264895295	-54.34149986614161	109263
d5217f09a219f4c54c864b964226291e5be2a382	clustering ocr-ed texts for browsing document image database	document image database browsing;document clustering;image databases;information science;ordinal clustering methods;recognition faults;information retrieval;optical character recognition;image database;ocr text clustering;optical character recognition software;document database;human factors;feature extraction;clustering method;merging;document image processing;complete link;clustering algorithms;recognition faults ocr text clustering document image database browsing document clustering user interaction cluster extraction method ordinal clustering methods complete link term loss;cluster extraction method;term loss;frequency;clustering methods;image databases clustering methods information science frequency merging clustering algorithms object detection information retrieval optical character recognition software;user interaction;interactive systems;extraction method;word processing;object detection;feature extraction document image processing visual databases optical character recognition word processing human factors interactive systems;visual databases	Document clustering is a powerful tool for browsing throughout a document database. Similar documents are gathered into several clusters and a representative document of each cluster is shown to users. To make users infer the content of the database from several representatives, the documents must be separated into tight clusters, in which documents are connected with high similarities. At the same time, clustering must be fast for user interaction. We propose an O(n/sup 2/) time, O(n) space cluster extraction method. It is faster than the ordinal clustering methods, and its clusters compare favorably with those produced by Complete Link for tightness. When we deal with OCR-ed documents, term loss caused by recognition faults can change similarities between documents. We also examined the effect of recognition faults to the performance of document clustering.		Koji Tsuda;Shuji Senda;Michihiko Minoh;Katsuo Ikeda	1995		10.1109/ICDAR.1995.598969	correlation clustering;document clustering;fuzzy clustering;feature extraction;information science;computer science;machine learning;frequency;pattern recognition;data mining;cluster analysis;optical character recognition;information retrieval	Vision	-16.886115552365954	-59.204421555427736	109319
67b45d7c6085fa871d35dcbf8e3ac0fc86f83c51	taxonomy in fish species complexes: a role for multimedia information	automated feature selection;multimedia representation;shape analysis;regression classifier;image classification;logistic regression;taxonomy marine animals multimedia databases image databases spatial databases history internet information retrieval image retrieval information representation;carpiodes;image quality;multimedia databases;taxonomy;fish species;regression analysis image classification multimedia databases;feature selection;regression analysis;multimedia database taxonomy fish species carpiodes regression classifier automated feature selection image quality classification accuracy;multimedia representation taxonomy feature selection logistric regression shape analysis;logistric regression;natural history;classification accuracy;multimedia database;species complex	"""Biologists could make valuable use of the wealth of specimen information in natural history museum databases. """"Taxonomy via the Internet"""" aims to build a centralized database where biologists can store, manipulate and retrieve biologically meaningful data from images of specimens and use the data to classify the specimens taxonomically. Multimedia information representation provides a new computational tool for extracting useful features from large databases of specimen images and has potential to expedite the pace of taxonomic research. In this paper, we use a taxonomic problem involving species of suckers in the genus Carpiodes to demonstrate the utility of this method. Logistic regression classifier with fully automated feature selection procedure is compared with the best landmark based classifier to illustrate how image quality affects classification accuracy. We discuss the need of creating a multimedia database using images of specimens from a fish collection"""	biological specimen;centralized computing;database;evolutionary taxonomy;feature selection;image quality;logistic regression;numerical taxonomy	Huimin Chen;Shuqing Huang;Henry L. Bart	2006	2006 IEEE Workshop on Multimedia Signal Processing	10.1109/MMSP.2006.285354	image quality;contextual image classification;computer science;machine learning;natural history;pattern recognition;data mining;shape analysis;logistic regression;feature selection;information retrieval;species complex;taxonomy;regression analysis	DB	-8.332405658523724	-61.34120979648256	109406
539cf2053e7308a8aa974b982803d487f64105bc	media streams: an iconic visual language for video annotation	search and retrieval;hierarchical structure;iconic annotations;cascading hierarchical structure;design criteria;reusable video archive;prototypes;streaming video;natural languages;iconic visual language;streams video data;cascading hierarchical structure media streams iconic visual language video annotation video content video annotation language reusable video archive iconic annotations streams video data director s workshop;query languages;video content;visual languages;streaming media;video on demand;data visualization;video annotation language;visual language;media streaming;video annotation;director s workshop;visual languages image sequences query languages user interfaces visual databases;tv;streaming media natural languages content based retrieval video on demand tv cameras data visualization laboratories prototypes image retrieval;content based retrieval;user interfaces;cameras;image sequences;media streams;visual databases;image retrieval	In order to enable the search and retrieval of video from large archives, we need a representation of video content. Although some aspects of video can be automatically parsed, a detailed representation requires that video be annotated. We discuss the design criteria for a video annotation language with special attention to the issue of creating a global, reusable video archive. Our prototype system, Media Streams, enables users to create multi-layered, iconic annotations of streams video data. Within Media Streams, the organization and categories of the Director’s Workshop allow users to browse and compound over 2200 iconic primitives by means of a cascading hierarchical structure which supports compounding icons across branches of the hierarchy. The problems of creating a representation of action for video are given special attention, as well as describing transitions in video.	approximation;archive;browsing;digital media;digital video;global information grid;parsing;prototype;streaming media;visual language	Marc Davis	1993		10.1109/VL.1993.269596	computer vision;computer science;video tracking;multimedia;world wide web	HCI	-14.484690875536714	-55.291073225461176	109640
313bd4cb802778fc333ba44ee43cf3c12b17687d	retrieving similar pictures from a pictorial database by an improved hashing table	information retrieval;hash table;indexation;hashing value;mapping;spatial relationships;iconic indexing;hasing value;spatial knowledge	In this paper, we introduce a more succinct and precise definition of spatial relationships in 2D space and a new approach for representing a picture by a set of hashing values. Using this approach, the problem of pictorial information retrieval becomes a problem of matching hashing value subsequences. This method combines the picture representation with the picture retrieval, and it avoids the ambiguity problems that exist in other methods. © 1997 Elsevier Science B.V.	database;hash function;image;information retrieval	Xiao Ming Zhou;Chuan-Heng Ang	1997	Pattern Recognition Letters	10.1016/S0167-8655(97)00055-X	spatial relation;feature hashing;hash table;extendible hashing;dynamic perfect hashing;computer science;theoretical computer science;universal hashing;data mining;locality preserving hashing;information retrieval;locality-sensitive hashing	Vision	-11.473050053846874	-58.638527572839706	109656
c3e5efa3b594b6d3b1838c4aebd98e393a68d3da	mining transposed motifs in music	frequent pattern mining;motifs;musical mining	The discovery of frequent musical patterns (motifs) is a relevant problem in musicology. This paper introduces an unsupervised algorithm to address this problem in symbolically-represented musical melodies. Our algorithm is able to identify transposed patterns including exact matchings, i.e., null transpositions. We have tested our algorithm on a corpus of songs and the results suggest that our approach is promising, specially when dealing with songs that include non-exact repetitions.	algorithm;asymptotically optimal algorithm;data mining;experiment;parallel computing;run time (program lifecycle phase);string (computer science);text corpus	Aída Jiménez;Miguel Molina-Solana;Fernando Berzal Galiano;Waldo Fajardo Contreras	2010	Journal of Intelligent Information Systems	10.1007/s10844-010-0122-7	speech recognition;machine learning	ML	-18.50215936770986	-62.40644175862191	109941
1f8de183322954e1fbeb4c74101aa80e70653321	knowledge propagation in collaborative tagging for image retrieval	knowledge propagation;content analysis;radial basis function;visual features;support vector machine;collaborative tagging;keyword classifier;image retrieval	An important issue in current collaborative framework for media tagging is that some images or videos may not be annotated properly or even not annotated at all. In view of this, this paper proposes a new knowledge propagation scheme to automatically propagate keywords from a subset of annotated images to the unannotated ones. The main idea is based on image content analysis and training of keyword classifiers. An evolutionary scheme is utilized to find the salient regions in the annotated images, and the importance of the other regions is estimated using one-class support vector machine (OCSVM). An ensemble of variable-length radial basis function (VLRBF)-based classifiers is trained based on the visual features of the annotated images. The trained classifiers are then used for knowledge propagation. Experimental results using 100 concept categories demonstrate the effectiveness of the proposed method.	folksonomy;image retrieval;software propagation	Kim-Hui Yap;Kui Wu;Ce Zhu	2010	Signal Processing Systems	10.1007/s11265-008-0288-1	support vector machine;radial basis function;content analysis;image retrieval;computer science;machine learning;pattern recognition;data mining;information retrieval	ML	-17.69899948190183	-59.70227602196302	110024
c75cea408d0fd38f0a48242024d6a72f63fcdf46	incorporating word correlation knowledge into topic modeling		This paper studies how to incorporate the external word correlation knowledge to improve the coherence of topic modeling. Existing topic models assume words are generated independently and lack the mechanism to utilize the rich similarity relationships among words to learn coherent topics. To solve this problem, we build a Markov Random Field (MRF) regularized Latent Dirichlet Allocation (LDA) model, which defines a MRF on the latent topic layer of LDA to encourage words labeled as similar to share the same topic label. Under our model, the topic assignment of each word is not independent, but rather affected by the topic labels of its correlated words. Similar words have better chance to be put into the same topic due to the regularization of MRF, hence the coherence of topics can be boosted. In addition, our model can accommodate the subtlety that whether two words are similar depends on which topic they appear in, which allows word with multiple senses to be put into different topics properly. We derive a variational inference method to infer the posterior probabilities and learn model parameters and present techniques to deal with the hardto-compute partition function in MRF. Experiments on two datasets demonstrate the effectiveness of our model.	coherence (physics);latent dirichlet allocation;markov chain;markov random field;partition function (mathematics);topic model;variational principle	Pengtao Xie;Diyi Yang;Eric P. Xing	2015			natural language processing;speech recognition;machine learning;pattern recognition	NLP	-16.615509950878394	-64.40683496927568	110028
ad0817d227d2e308780fe92f240a3f59aae5a8da	content-based image indexing and retrieval in an image database for technical domains	analisis imagen;non destructive testing;algoritmo busqueda;learning;algorithme recherche;search algorithm;interrogation base donnee;image database;interrogacion base datos;image indexing;intelligence artificielle;similitude;aprendizaje;apprentissage;spatial relation;indexing;indexation;estructura datos;similarity;indizacion;visual features;pattern recognition;artificial intelligence;image analysis;structure donnee;inteligencia artificial;reconnaissance forme;similitud;systeme gestion base donnee;information system;reconocimiento patron;sistema gestion base datos;analyse image;database management system;data structure;data acquisition;query by image content;database query;systeme information;structural similarity;sistema informacion	The availability of a variety of sophisticated data acquisition instruments has resulted in large repositories of imagery data in different applications like non-destructive testing, technical drawing, medicine, museums and so one. Effective extraction of visual features and contents is needed to provide meaningful index of and access to visual data. In the paper, we proposed an image database architecture, which can be used for most industrial problems. The image database is able to handle structural representations of images. Indexing is possible object based, spatial relation based, and by a combination of both. The query can be a textual query or an image content-based query. We describe how the image query is processed, how similarity based retrieval is performed over images, and how the image database is organized. Results are presented based on an application of ultra sonic images from non-destructive testing.		Petra Perner	1998		10.1007/BFb0016500	spatial relation;search engine indexing;query optimization;query expansion;visual word;image analysis;similarity;data structure;nondestructive testing;image processing;image retrieval;computer science;artificial intelligence;similitude;structural similarity;data mining;database;data acquisition;view;automatic image annotation;world wide web;information system;search algorithm	Vision	-12.149799245200814	-59.19953385114693	110432
d453fe8293644003afdbb937dfad7bbd16974aa3	winbioinftools: bioinformatics tools for windows cluster	databases;computers;coconut;genomics;sequences;ms windows;query processing;pairwise sequence alignment;winpsa;biological database search;coconut bioinformatics winbioinftools windows cluster;linux cluster;bioinformatics sequences linux biology computing genomics informatics operating systems databases performance analysis computer science;public domain software;global pairwise sequence alignment;single machine;sequences bioinformatics genomics linux operating systems computers public domain software query processing;biological cells;operating system;genome comparison;windows cluster;high performance computer;biological sequence analysis;linux unix;linux;pairwise genome comparison;sequence analysis;linux unix winbioinftools windows cluster open source bioinformatics tools ms windows windows hpc cluster operating system biological sequence analysis coconut pairwise genome comparison winblast biological database search winpsa global pairwise sequence alignment;biological database;winblast;windows hpc cluster;operating systems computers;winbioinftools;open source;open source bioinformatics tools;bioinformatics	Open source bioinformatics tools running under MS Windows are rare to find, and those running under Windows HPC cluster are almost non-existing, in spite of the fact that Windows is the most popular operating system. Therefore, we introduce WinBioinfTools, an open source toolkit containing a number of bioinformatics tools running under Windows High Performance Computing Server 2008. The current version contains three programs for biological sequence analysis: 1) CoCoNUT for pairwise genome comparison, 2) WinBLAST for biological database search, and 3) WinPSA for global pairwise sequence alignment. We show how the Linux/Unix components of these programs were ported to run under Windows. We also demonstrate by experiments the advantage of using a computer cluster compared to a single machine, highlighting the benefits of using the Windows HPC Cluster 2008. Furthermore, we compare the performance of WinBioinfTools on the Windows- and Linux Cluster.	bioinformatics;biological database;computer cluster;experiment;linux;microsoft windows;open-source software;operating system;sequence alignment;sequence analysis;unix	Hisham Mohamed;Mohamed Ibrahim Abouelhoda	2009	2009 IEEE International Conference on Cluster Computing and Workshops	10.1109/CLUSTR.2009.5289141	genomics;biological database;computer cluster;computer science;bioinformatics;software versioning;operating system;sequence analysis;sequence;public domain software;world wide web;binary code compatibility;dll hell;linux kernel	HPC	-4.575546191084582	-53.530773172758614	110642
3d23666c6d97d6ba3c86044d83c697821084bed6	variational sequential labelers for semi-supervised learning		We introduce a family of multitask variational methods for semi-supervised sequence labeling. Our model family consists of a latentvariable generative model and a discriminative labeler. The generative models use latent variables to define the conditional probability of a word given its context, drawing inspiration from word prediction objectives commonly used in learning word embeddings. The labeler helps inject discriminative information into the latent space. We explore several latent variable configurations, including ones with hierarchical structure, which enables the model to account for both label-specific and word-specific information. Our models consistently outperform standard sequential baselines on 8 sequence labeling datasets, and improve further with unlabeled data.	baseline (configuration management);calculus of variations;computer multitasking;discriminative model;generative model;label printer applicator;latent variable;part-of-speech tagging;semi-supervised learning;semiconductor industry;sequence labeling;sequential consistency;supervised learning;variational principle	Mingda Chen;Qingming Tang;Karen Livescu;Kevin Gimpel	2018			artificial intelligence;semi-supervised learning;natural language processing;machine learning;computer science	NLP	-14.367302799741543	-65.6479453059249	111319
961f073e0ca782e34d1778a7f9b9d9991577ae00	metadata extraction and correction for large-scale traffic surveillance videos	metadata quality large scale traffic surveillance videos metadata correction system metadata extraction method metadata spatial temporal relationship image similarity hadoop hbase;traffic surveillance video;vehicle retrieval;metadata extraction;metadata correction;video metadata;vehicle retrieval video metadata metadata extraction metadata correction traffic surveillance video;licenses vehicles cameras videos surveillance image color analysis data mining;video surveillance feature extraction meta data parallel processing traffic engineering computing	Metadata is widely used to facilitate user defined queries and high-level event recognition applications in traffic surveillance videos. Current metadata extraction approaches rely on some computer vision algorithms, which are not accurate enough in the real world traffic scenes, and do not deal with big surveillance data efficiently. In this paper, we design a novel metadata extraction and metadata correction system. Firstly, we define the structure of metadata to determine which attribute (e.g., vehicle enter time, license plate number, vehicle type) we need to extract. Based on this structure, we employ a three-phase method to extract metadata. Secondly, we propose a graph-based metadata correction approach for compensating the accuracy of metadata extraction method. It fuses the big metadata of whole camera network, automatically detects suspicious metadata and corrects them based on the metadata spatial-temporal relationship and the image similarity. As the centralized framework may not be able to cope with the huge amount of data generated by traffic surveillance system, our system is implemented in a distributed fashion using Hadoop and HBase. Finally, the experimental results on real world traffic surveillance videos demonstrate the efficiency of our system, and also demonstrate that the metadata quality is significantly improved after metadata correction.	algorithm;apache hbase;apache hadoop;centralized computing;computer vision;experiment;high- and low-level;internet of things;scalability	Xiaomeng Zhao;Huadong Ma;Haitao Zhang;Yi Tang;Guangping Fu	2014	2014 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2014.7004258	computer science;database;database catalog;world wide web;data element;meta data services;information retrieval;metadata repository	Robotics	-11.45876764089028	-55.60065750600959	111702
0402a0eb6abe85d15c83688580f1ed9822a30187	bilevel feature extraction-based text mining for fault diagnosis of railway systems	rail transportation;text mining;maintenance;semantics;maintenance engineering;data mining;fault monitoring;feature extraction maintenance engineering rail transportation syntactics fault diagnosis semantics text mining;syntactics;feature extraction;railway systems text mining feature selection fault diagnosis;railroad safety;railroads;diagnosis;fault diagnosis	A vast amount of text data is recorded in the forms of repair verbatim in railway maintenance sectors. Efficient text mining of such maintenance data plays an important role in detecting anomalies and improving fault diagnosis efficiency. However, unstructured verbatim, high-dimensional data, and imbalanced fault class distribution pose challenges for feature selections and fault diagnosis. We propose a bilevel feature extraction-based text mining that integrates features extracted at both syntax and semantic levels with the aim to improve the fault classification performance. We first perform an improved X2 statistics-based feature selection at the syntax level to overcome the learning difficulty caused by an imbalanced data set. Then, we perform a prior latent Dirichlet allocation-based feature selection at the semantic level to reduce the data set into a low-dimensional topic space. Finally, we fuse fault features derived from both syntax and semantic levels via serial fusion. The proposed method uses fault features at different levels and enhances the precision of fault diagnosis for all fault classes, particularly minority ones. Its performance has been validated by using a railway maintenance data set collected from 2008 to 2014 by a railway corporation. It outperforms traditional approaches.	black and burst;categorization;experiment;f1 score;feature extraction;feature selection;information gain in decision trees;latent dirichlet allocation;relevance;sensor;text corpus;text mining	Feng Wang;Tianhua Xu;Tao Tang;Mengchu Zhou;Haifeng Wang	2017	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2016.2521866	maintenance engineering;text mining;feature extraction;computer science;engineering;machine learning;pattern recognition;data mining;semantics	AI	-19.08321115615376	-63.41170115914097	111945
29193b3c80f5e8ca4b9e3b3edd6612250e55c560	automatic keyword extraction from historical document images	busqueda informacion;spacing;document structure;modelizacion;espacement;keyword;document analysis;analisis estadistico;image processing;estructura documental;espaciamiento;average precision;information retrieval;structure document;interrogation base donnee;procesamiento imagen;interrogacion base datos;palabra clave;segmentation;probabilistic approach;mot cle;traitement image;modelisation;word segmentation;analyse documentaire;statistical analysis;recherche information;enfoque probabilista;approche probabiliste;keyword extraction;analyse statistique;pattern recognition;analisis documental;reconnaissance forme;statistical language model;reconocimiento patron;modeling;database query;segmentacion	This paper presents an automatic keyword extraction method from historical document images. The proposed method is language independent because it is purely appearance based, where neither lexical information nor any other statistical language models are required. Moreover, since it does not need word segmentation, it can be applied to Eastern languages where they do not put clear spacing between words. The first half of the paper describes the algorithm to retrieve document image regions which have similar appearance to the given query image. The algorithm was evaluated in recall-precision manner, and showed its performance of over 80–90% average precision. The second half of the paper describes the keyword extraction method which works even if no query word is explicitly specified. Since the computational cost was reduced by the efficient pruning techniques, the system could extract keywords successfully from relatively large documents.	algorithm;algorithmic efficiency;cluster analysis;computation;document retrieval;experiment;historical document;information retrieval;keyword extraction;language model;precision and recall;preprocessor;text segmentation	Kengo Terasawa;Takeshi Nagasaki;Toshio Kawashima	2006		10.1007/11669487_37	natural language processing;text segmentation;speech recognition;systems modeling;image processing;computer science;document structure description;database;segmentation;information retrieval	NLP	-11.890220458521586	-62.02854661166232	112000
414ee4aea16e84d659ffe5b17c26c74f16352e67	structural protein interactions: from months to minutes	protein structure;information integration;computational complexity;load balance;structural classification of proteins;protein interaction;protein databank	Protein interactions are important to understand the function of proteins. PSIMAP is a protein interaction map derived from protein structures in the Protein Databank PDB and the Structural Classification of Proteins SCOP. In this paper we review how to reduce the computation of PSIMAP from months to minutes, first by designing a new effective algorithm and second by distributing the computation over a Linux PC farm using a simple scheduling mechanism. From this experience we derive some general conclusions: Besides computational complexity, most problems in bioinformatics require information integration and this integration is semantically complex. We sketch our relevant work to tackle computational and semantic complexity. Regarding the former, we classify problems and infrastructure and review how market-based load-balancing can be applied. Regarding the latter, we outline a Java-based rule-engine, which allows users to declaratively specify workflows separate from implementation details.	algorithm;bioinformatics;business rules engine;computation;computational complexity theory;computational geometry;computer cluster;declarative programming;executable;interaction;java;linux;load balancing (computing);logic programming;protein data bank;scheduling (computing);scop	Panos Dafas;Jacek Gomoluch;Alexander Kozlenkov;Michael Schroeder	2003		10.1016/S0927-5452(04)80084-4	protein structure;parallel computing;complexity;computer science;bioinformatics;load balancing;information integration;theoretical computer science;operating system;computational resource;mathematics;protein data bank (rcsb pdb);programming language;computational complexity theory;algorithm	Comp.	-5.479021317665918	-53.39029708062835	112087
e118684cf407fd3070b74ca9f2326be738cec8c6	a hpc infrastructure for processing and visualizing neuro-anatomical images obtained by confocal light sheet microscopy	confocal microscopy hpc data neuroscience visualisation human brain project;parallel processing data visualisation medical image processing neurophysiology optical microscopy;confocal light sheet microscopy hpc infrastructure high performance computing neuroanatomical image processing data visualization;lenses data visualization microscopy image resolution pipelines mice biomedical imaging	Scientific problems dealing with the processing of large amounts of data require efforts in the integration of proper services and applications to facilitate the research activity, interacting with high performance computing resources. Easier access to these resources have a profound impact on research in neuroscience, leading to advances in the management and processing of neuro-anatomical images. An ever increasing amount of data are constantly collected with a consequent demand of top-class computational resources to process them. In this paper, a HPC infrastructure for the management and the processing of neuro-anatomical images is presented, introducing the effort made to optimize and integrate specific applications in order to fully exploit the available resources.	computation;computational resource;experiment;human brain project;interaction;international neuroinformatics coordinating facility;storage resource broker;supercomputer	Alessandro Bria;Giulio Iannello;Paolo Soda;Hanchuan Peng;Giovanni Erbacci;Giuseppe Fiameni;Giacomo Mariani;Roberto Mucci;Marco Rorro;Francesco Pavone;Ludovico Silvestri;Paolo Frasconi;Roberto Cortini	2014	2014 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2014.6903741	computer vision;computer science;computer graphics (images)	HPC	-8.645209736050498	-54.105237831997165	112108
470b720b4fd9f292ec2060b0af24fc614aca37cf	combining multiple retrieval systems using combinatorial fusion analysis and rank-score characteristic function	cognitive diversity;cognitive diversity information retrieval ir multiple scoring systems mss combinatorial fusion analysis cfa rank score characteristic rsc function score combination rank combination;multiple scoring systems mss;rank combination;information retrieval;sensor fusion information retrieval;combinatorial fusion analysis cfa;system performance;score combination;cognitive diversity information retrieval system information fusion paradigm combinatorial fusion analysis trec dataset rank score characteristic function rsc function;characteristic function;rank score characteristic rsc function;information fusion;sensor fusion;diversity reception correlation educational institutions algorithm design and analysis search engines computers;information retrieval ir;scoring system	Combining the resulting lists of multiple information retrieval (IR) systems has been known to outperform, in many cases, the best of the individual systems. However, it remains a challenging question to know what combination method to use and in what conditions the combination system can perform better than its individual systems. In this paper, we use an information fusion paradigm: Combinatorial Fusion Analysis (CFA) to study these issues. We take the TREC dataset as our experiment data and use the rank-score characteristic (RSC) function to measure the cognitive diversity between different individual systems. Results from our experiment demonstrate that: 1) combined system can improve performance only if the individual systems have relative good performance and are diverse, 2) there is no guarantee that the combined system performs better when more individual systems are added, and 3) rank combination is better than score combination in majority of the cases when the diversity between two individual systems measured by the RSC function is large enough.	characteristic function (convex analysis);convolutional code;information retrieval;programming paradigm	Hongzhi Liu;Zhonghai Wu;D. Frank Hsu	2011	2011 14th IEEE International Conference on Computational Science and Engineering	10.1109/CSE.2011.71	characteristic function;computer science;machine learning;data mining;mathematics;sensor fusion;computer performance;information retrieval;statistics	Robotics	-18.313730775504574	-61.07867718906289	112165
42add4ae86235c040a278ca8d2a008cbe65f5288	a semi-automatic object extraction tool for querying in multimedia databases	color	Considering the complexity and huge volume of image and or video data e cient methods need to be developed for querying multimedia databases A well known technique used for querying multimedia data is query by feature e g color shape texture size of the objects residing in images and or video frames In this paper we propose a tool for extracting objects from images and or video frames called Object Extractor as well as the ways of coping with the object features within extracted objects The tool is semi automatic in the sense that the user speci es the colors on the object by clicking the mouse to make the tool capture object pixels In order to extract objects an improved version of the Flood Fill algorithm for polygon lling is provided The extraction algorithm uses ltered images to perform better Moreover the experimental results obtained for evaluating the performance of the tool in extracting objects are presented It is shown through these results that a few mouse clicks would su ce to extract objects e ectively	algorithm;color;database;flood fill;pixel;randomness extractor;semiconductor industry	Ediz Saykol;Ugur Güdükbay;Özgür Ulusoy	2001			polygon;pixel;multimedia;information retrieval;multimedia database;flood fill;database;extractor;computer science	DB	-11.827559179883668	-56.85359916140574	112210
f0c18fc65b815fee080af85ab5cf330c9ce07f9f	mining the human genome using virtual reality	visualizing network;genomic data;virtual reality application;target gene;human genome;virtual reality;new drug;gene expression data;gene family;new data;diverse biological data source;biological data;dna microarray	The analysis of genomic data and integration of diverse biological data sources has become increasingly difficult for researches in the life sciences. This problem is exacerbated by the speed with which new data is gathered through automated technology like DNA microarrays. We developed a virtual reality application for visualizing hierarchical relationships within a gene family and for visualizing networks of gene expression data. Integration of other information from multiple databases with these visualizations can aid pharmaceutical researchers in selecting target genes or proteins for new drugs. We found the application of virtual reality to the field of genomics to be successfull.	virtual reality	Bram Stolk;Faizal Abdoelrahman;Anton H. J. Koning;Paul Wielinga;Jean-Marc Neefs;Andrew Stubbs;An de Bondt;Peter Leemans;Peter J. van der Spek	2002			human genome;dna microarray;biological data;computer science;bioinformatics;data science;gene family;data mining;virtual reality	Visualization	-5.576639257440127	-61.117728608565486	112277
b1d94c3f2d67832e7c481963c1b30760a6076ff3	toward content-aware multimodal tagging of personal photo collections	intelligent interfaces;collaborative interaction;content analysis;photo collection;multimodal processing;automatic label extraction;tagging;photo annotation	A growing number of tools is becoming available, that make use ofexisting tags to help organize and retrieve photos, facilitating the management and use of photo sets. The tagging on which these techniques rely remains a time consuming, labor intensive task that discourages many users. To address this problem, we aim to leverage the multimodal content of naturally occurring photo discussions among friends and families to automatically extract tags from a combination of conversational speech, handwriting, and photo content analysis. While naturally occurring discussions are rich sources of informationabout photos, methods need to be developed to reliably extract a set of discriminative tags from this noisy, unconstrained group discourse. To this end, this paper contributes ananalysis of pilot data identifying robust multimodal features examining the interplay between photo content and other modalities such as speech and handwriting. Our analysis is motivated by a search for design implications leading to the effective incorporation of automated location and person identification(e.g. based on GPS and facial recognition technologies) into a system able to extract tags from natural multimodal conversations.	facial recognition system;global positioning system;multimodal interaction	Paulo Barthelmess;Edward C. Kaiser;David McGee	2007		10.1145/1322192.1322215	content analysis;computer science;multimedia;world wide web	HCI	-17.573411361193205	-57.22319820754126	112440
e305ac9b3e28c0f09f364964780a4be0a874c97a	towards semantically meaningful feature spaces for the characterization of video content	filtering;sex;motion pictures;video signal processing;sorting;local activities;browsing;home appliances;layout;television broadcasting;feature space;satellite broadcasting;layout motion pictures content based retrieval streaming media filtering sorting satellite broadcasting home appliances image retrieval local activities;video content;stochastic processes;pictorial content;image space;streaming media;image representation;video editing;profanity;transformation;stochastic model;television broadcasting video signal processing entertainment image representation stochastic processes;content characterization;violence;content based retrieval;entertainment;low dimensional feature space;semantically meaningful feature spaces;categorization semantically meaningful feature spaces video content browsing filtering sorting pictorial content content characterization violence sex profanity stochastic model video editing image space transformation low dimensional feature space;categorization;image retrieval	CHARACTERIZATION OF VIDEO CONTENT Nuno Vasconcelos Andrew Lippman MIT Media Laboratory fnuno,lipg@media.mit.edu ABSTRACT E cient procedures for browsing, ltering, sorting or retrieving pictorial content require accurate content characterization. Of particular interest are representations based on semantically meaningful feature spaces, capable of capturing properties such as violence, sex or profanity. In this work we report on a rst step towards this goal, the design of a stochastic model for video editing which provides a transformation from the image space to a low-dimensional feature space where categorization by degree of action can be easily accomplished.	categorization;feature vector;image;sorting;spaces	Nuno Vasconcelos;Andrew Lippman	1997		10.1109/ICIP.1997.647375	transformation;filter;layout;computer vision;entertainment;feature vector;image retrieval;computer science;sorting;stochastic modelling;sex;multimedia;categorization;computer graphics (images)	Vision	-13.693133318571274	-55.57697450077412	112764
37ec5a4b0075e451a574b64d132120ecffe0f3d7	explanation systems for influence maximization algorithms		The field of influence maximization (IM) has made rapid advances, resulting in many sophisticated algorithms for identifying “influential” members in social networks. However, in order to engender trust in IM algorithms, the rationale behind their choice of “influential” nodes needs to be explained to its users. This is a challenging open problem that needs to be solved before these algorithms can be deployed on a large scale. This paper attempts to tackle this open problem via four major contributions: (i) we propose a general paradigm for designing explanation systems for IM algorithms by exploiting the tradeoff between explanation accuracy and interpretability; our paradigm treats IM algorithms as black boxes, and is flexible enough to be used with any algorithm; (ii) we utilize this paradigm to build XplainIM, a suite of explanation systems; (iii) we illustrate the usability of XplainIM by explaining solutions of HEALER (a recent IM algorithm) among ∼200 human subjects on Amazon Mechanical Turk (AMT); and (iv) we provide extensive evaluation of our AMT results, which shows the effectiveness of XplainIM.	amazon mechanical turk;black box;design rationale;expectation–maximization algorithm;experiment;natural language generation;programming paradigm;social network;the turk;usability	Amulya Yadav;Aida Rahmattalabi;Ece Kamar;Phebe Vayanos;Milind Tambe;Venil Loyd Noronha	2017			machine learning;artificial intelligence;computer science;maximization	ML	-13.490195849126172	-65.04766450274197	112898
cc5fa87dd4d3407063e1e49c834986558b8d1f08	hadoop mapreduce framework to implement molecular docking of large-scale virtual screening	databases;google;drugs;chemistry computing;storage management;computational chemistry e science development hadoop mapreduce framework large scale virtual screening result collection massive data storage small molecule files storage small molecule files management result files docking hdfs mapreduce programming framework parallel molecular docking virtual screening molecular docking automation drug researcher data storage management system drug discovery cloud environment;storage management chemistry computing cloud computing distributed programming drugs public domain software;public domain software;proteins;distributed programming;web services;mapreduce;hadoop;molecular docking hadoop mapreduce large scale virtual screening;programming;molecular docking;drugs programming databases proteins web services google;large scale virtual screening;cloud computing	Traditional virtual screening in the grid needs chemists to upload small molecule files and collect the results manually, which cannot implement docking and collection of results automatically. This caused heavy workload to chemists. In this paper, we took advantage of Hadoop platform in the massive data storage. We stored and managed small molecule files and docking results files using HDFS. In addition, MapReduce programming framework is used for parallel molecular docking to preliminarily process results files, in order to achieve the automation of the virtual screening molecular docking. The research of this thesis will be helpful to drug researcher by offering a massive data storage management system for large-scale virtual screening, and will also provide a reference for drug discovery in the cloud environment to promote the development of computational chemistry e-science.	apache hadoop;cloud computing;computational chemistry;computer data storage;docking (molecular);e-science;hierarchical storage management;mapreduce;upload;virtual screening	Jing Zhao;Ruisheng Zhang;Zhili Zhao;Dianwei Chen;Lujie Hou	2012	2012 IEEE Asia-Pacific Services Computing Conference	10.1109/APSCC.2012.67	web service;programming;docking;cloud computing;computer science;bioinformatics;operating system;data mining;database;management;law;public domain software;world wide web	HPC	-5.487483442640872	-53.26684236638242	113222
16a3df230434eee55066ae6c3ee671f051b7f5b9	a tool for supporting integration across multiple flat-file datasets	query processing biology computing data integrity;biology computing;data integration tool;multiple flat file biological datasets;data integrity;bioinformatics research literature multiple flat file biological datasets microarray blast program queries processing multiple data entries data integration tool database like query operation biological queries;query processing;database systems utility programs scalability bioinformatics computer science data engineering biology indexing web services humans;blast program;queries processing;biological queries;declarative languages;indexation;bioinformatics research literature;microarray;database like query operation;functional requirement;high throughput;database management system;multiple data entries	Traditionally, biologists focused on a single research subject. New high-throughput experimental and analytical technologies, such as microarray and BLAST programs, have changed this. An important functionality required now is the ability to process queries about multiple data entries with little user intervention. This paper presents the design, implementation, and evaluation of a data integration tool that supports database-like query operations across flat-file biological datasets. Compared with the existing solutions, our system has several advantages, i.e., no database management system is required, users can still use declarative languages to communicate with the system, and no data parsing, loading, or indexing utility programs need to be written. We have used the system on three biological queries, each of which was inspired by an actual study from bioinformatics research literature. These case studies have demonstrated the functionality and scalability of our tool. Overall, our approach provides a light-weight and scalable solution for data integration over flat-file datasets	blast;bioinformatics;flat file database;high-throughput computing;microarray;parsing;scalability;scientific literature;throughput	Xuan Zhang;Gagan Agrawal	2006	Sixth IEEE Symposium on BioInformatics and BioEngineering (BIBE'06)	10.1109/BIBE.2006.253327	high-throughput screening;computer science;bioinformatics;microarray;data integrity;data mining;database;functional requirement;information retrieval	DB	-4.73035955238769	-61.83794035605784	113303
1f8654a8d6f6b626a7c40bdf5552b3eb4d64ff46	phase4: automatic evaluation of database search methods	scop;programming language;false positive counts;automatic evaluation;roc;object oriented;coverage versus error plot;graphic user interface;performance figure;false positive;equivalence numbers;database search	It has become standard to evaluate newly devised database search methods in terms of sensitivity and selectivity and to compare them with existing methods. This involves the construction of a suitable evaluation scenario, the execution of the methods, the assessment of their performances, and the presentation of the results. Each of these four phases and their smooth connection usually imposes formidable work. To relieve the evaluator of this burden, a system has been designed with which evaluations can be effected rapidly. It is implemented in the programming language Python whose object-oriented features are used to offer a great flexibility in changing the evaluation design. A graphical user interface is provided which offers the usual amenities such as radio- and checkbuttons or file browsing facilities.	cdisc sdtm evaluator terminology;evaluation;graphical user interface;interpreter (computing);performance;programming language;python;selectivity (electronic);user interface device component	Marc Rehmsmeier	2002	Briefings in bioinformatics	10.1093/bib/3.4.342	database search engine;type i and type ii errors;computer science;bioinformatics;theoretical computer science;data mining;graphical user interface;database;object-oriented programming;statistics;structural classification of proteins database	Web+IR	-6.044152209438508	-56.18623515908886	113401
e8c01eba1065ba569064dd90e9764df44afca1cf	construction of functional group reactivity database under various reaction conditions automatically extracted from reaction database in a synthesis design system	velocidad reaccion;reactivite chimique;chemical reactivity;criblage virtuel;reaccion quimica;systeme modulaire;tipo dato;reaction rate;vitesse reaction;sistema modular;data type;reactividad quimica;groupe fonctionnel;virtual screening;grupo funcional;chemical databasis;modular system;base donnee chimique;type donnee;functional group;reaction chimique;chemical reaction;base dato quimica;cribado virtual	"""To be able to estimate the reactivity of functional groups under certain reaction conditions, we have stored three types of data: (1) data of change or destruction of the functional groups by the conditions of the reaction conditions; (2) data showing no influence of the reaction conditions on the functional groups; and (3) data showing the relative reactivity of two functional groups in the presence of certain reaction conditions. These three types of data, considered together, form entities that are referenced as """"interaction data"""". These interaction data are used in a synthesis design system called SYNSUP. A new module in our system has been constructed that automatically generates interaction data from the reaction databases. From 15 265 reactions in the database, our program selected 2763 useful reactions with yields of > or =90% and one functional group change. From these useful reactions, data regarding 465 interferences, 815 cases of inert functional groups (under the reaction conditions), and 62 relative rate data could be extracted. In addition, with the use of multiple relative rate datasets, the reactivity of more than two functional groups could be deduced."""		Akio Tanaka;Hideho Okamoto;Malcolm Bersohn	2010	Journal of chemical information and modeling	10.1021/ci9004332	stereochemistry;reactivity;chemistry;chemical reaction;data type;virtual screening;organic chemistry;reaction rate;algorithm	Comp.	-5.550662344957342	-55.46307223818697	113545
6bdddbcaffea172555d16345eb0299617c693693	sparse nonparametric topic model for transfer learning	count data;dirichlet process;multi task learning;transfer learning;indian buffet process	Count data arises for example in bioinformatics or analysis of text documents represented as word count vectors. With several data sets available from related sources, exploiting their similarities by transfer learning can improve models compared to modeling sources independently. We introduce a Bayesian generative transfer learning model which represents similarity across document collections by sparse sharing of latent topics controlled by an Indian Buffet Process. Unlike Hierarchical Dirichlet Process based multi-task learning, our model decouples topic sharing probability from topic strength, making sharing of low-strength topics easier, and outperforms the HDP approach in experiments.	bioinformatics;computer multitasking;count data;experiment;multi-task learning;parametric model;sparse matrix;topic model;triune continuum paradigm	Ali Faisal;Jussi Gillberg;Jaakko Peltonen;Gayle Leen;Samuel Kaski	2012			multi-task learning;transfer of learning;computer science;data science;machine learning;count data;pattern recognition;statistics;hierarchical dirichlet process	ML	-16.57103577494307	-63.89056709029329	113771
7d25fca92fec421aa148f68b9efaee5584160531	towards an empirical evaluation of imperative and declarative process mining		Process modelling notations fall in two broad categories: declarative notations, which specify the rules governing a process; and imperative notations, which specify the flows admitted by a process. We outline an empirical approach to addressing the question of whether certain process logs are better suited for mining to imperative than declarative notations. We plan to attack this question by applying a flagship imperative and declarative miner to a standard collection of process logs, then evaluate the quality of the output models w.r.t. the standard model metrics of precision and generalisation. This approach requires perfect fitness of the output model, which substantially narrows the field of available miners; possible candidates include Inductive Miner and MINERful. With the metrics in hand, we propose to statistically evaluate the hypotheses that (1) one miner consistently outperforms the other on one of the metrics, and (2) there exist subsets of logs more suitable for imperative respectively declarative mining.	declarative programming;imperative programming	Christoffer Olling Back;Søren Debois;Tijs Slaats	2018		10.1007/978-3-030-01391-2_24	data mining;notation;computer science;process mining;generalization;process modeling	SE	-11.418755160513745	-64.58734908429577	113981
8040a38bf5412505624f54322248747d16a90c9f	temporal-based video event detection and retrieval	temporal association;video retrieval;event detection;video semantic analysis;video data archives	With the proliferation of multimedia data and ever-growing requests for multimedia applications, new challenges emerge for efficient and effective managing and accessing large audio-visual collections. Discovering events from video streams improves the access and reuse of large video collections. Events are real-world occurrences that unfold over space and time, and play important roles in classic areas of multimedia and new experiential applications such as eChronicles, life logs, and event-centric media managers (Westermann & Jain, 2007). However, with current technologies, there is little or no metadata ABSTRACT	streaming media	Min Chen	2012	IJOCI	10.4018/ijoci.2012100103	computer science;video tracking;multimedia;world wide web;information retrieval	Web+IR	-15.008926469899219	-54.935349393225835	114243
676a136f5978783f75b5edbb38e8bb588e8efbbe	matrix completion for resolving label ambiguity	yttrium face standards visualization training data videos data models;text analysis matrix algebra pattern classification;labeled yahoo news dataset news photo matrix completion based method label ambiguity ambiguously labeled instances standard supervised classifier labeling constraints lost dataset	In real applications, data is not always explicitly-labeled. For instance, label ambiguity exists when we associate two persons appearing in a news photo with two names provided in the caption. We propose a matrix completion-based method for predicting the actual labels from the ambiguously labeled instances, and a standard supervised classifier can learn from the disambiguated labels to classify new data. We further generalize the method to handle the labeling constraints between instances when such prior knowledge is available. Compared to existing methods, our approach achieves 2.9% improvement on the labeling accuracy of the Lost dataset and comparable performance on the Labeled Yahoo! News dataset.	machine learning	Ching-Hui Chen;Vishal M. Patel;Rama Chellappa	2015	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2015.7299038	computer science;machine learning;pattern recognition;data mining;information retrieval	Vision	-18.264500010524873	-64.87600171278687	114674
768eb4583ba487321ba153cd384a932bf4ae4d10	generating structure of latent variable models for nested data		Probabilistic latent variable models have been successfully used to capture intrinsic characteristics of various data. However, it is nontrivial to design appropriate models for given data because it requires both machine learning and domainspecific knowledge. In this paper, we focus on data with nested structure and propose a method to automatically generate a latent variable model for the given nested data, with the proposed method, the model structure is adjustable by its structural parameters. Our model can represent a wide class of hierarchical and sequential latent variable models including mixture models, latent Dirichlet allocation, hidden Markov models and their combinations in multiple layers of the hierarchy. Even when deeply-nested data are given, where designing a proper model is difficult even for experts, our method generate an appropriate model by extracting the essential information. We present an efficient variational inference method for our model based on dynamic programming on the given data structure. We experimentally show that our method generates correct models from artificial datasets and demonstrate that models generated by our method can extract hidden structures of blog and news article datasets.	algorithm;blog;complexity;data structure;dynamic programming;experiment;gibbs sampling;hidden markov model;latent dirichlet allocation;latent variable model;machine learning;markov chain;mixture model;sampling (signal processing);slice sampling;synthetic intelligence;variational principle	Masakazu Ishihata;Tomoharu Iwata	2014			latent class model;latent dirichlet allocation;computer science;multilevel model;machine learning;pattern recognition;data mining;probabilistic latent semantic analysis;statistics	ML	-16.52922749447348	-63.52082232999345	115158
b22f3d4fe04d407997ca1b775cc2e69daeefd369	ontology-based resources for bioinformatics analysis	bioinformatics resources;biomolecular ontologies	A number of specific web accessible databases are developed in order to shed light into biomolecular data, providing novel perspectives about particular scientific problems or presenting innovative data integration approaches. Ontologies constitute an important enhancement, since they allow a better representation of biological data, by providing a hierarchical structure to organise information, enabling more effective queries, statistical analysis and semantic web searching. Here we present our experience in exploiting ontologies to enrich biomolecular databases in diverse biomolecular contexts. The semantic layer improves data organisation, accessibility and analysis and represents an invaluable support to identify relations among biological components.	accessibility;bioinformatics;bioinformatics;database;high-throughput computing;java annotation;linkage (software);metabolomics;obo foundry;ontology (information science);proteomics;semantic web;systems biology;throughput;vocabulary;web search engine	Federica Viti;Ivan Merelli;Andrea Calabria;Paolo Cozzi;Ettore Mosca;Roberta Alfieri;Luciano Milanesi	2011	IJMSO	10.1504/IJMSO.2011.042488	computer science;bioinformatics;data mining;world wide web;information retrieval	Web+IR	-5.198231808057367	-62.269052355453965	115536
afde58d50e8590bd574b9560e05d4b384f50e90c	improving semantic scene categorization by exploiting audio-visual features	video signal processing;color;semantic content;semantics;emotion recognition;audio visual features semantic classifications audio visual cues film production semantic content human perception retrieval content video repository semantic scene categorization;video signal processing content based retrieval emotion recognition feature extraction pattern classification;visualization;hidden markov models;feature extraction;video repository;semantic scene categorization;audio visual features;layout humans motion pictures content based retrieval cameras face detection information analysis graphics production image retrieval;pattern classification;semantic classifications;audio visual;face;lighting;film production;retrieval content;human perception;content based retrieval;audio visual cues;films	We address the issue of categorizing scenes from feature films into semantic classifications based on the audio-visual cues. Specifically, we first exploit the grammar of film production to specify the semantic content of scenes. Then, each scene is classified into one of the following categories: conversation, action and suspense. Finally, to achieve more specific scene and consist with human perception, conversation scene is further categorizes into emotional conversation and common one, and action scene is further categorizes into gunfight, beating and chasing scene. This work is a step toward browsing and retrieval content of feature films in limited bandwidth, video repository, and rating of feature films of interest effectively and efficiently.	categorization	Songhao Zhu;Junchi Yan;Yuncai Liu	2009	2009 Fifth International Conference on Image and Graphics	10.1109/ICIG.2009.17	face;computer vision;visualization;scene statistics;feature extraction;computer science;machine learning;lighting;semantics;multimedia;perception;information retrieval	Vision	-13.725005265435033	-55.65178383720819	115672
f18fe123e9017f3a9ac7cd140560a30b5a9b82c2	improving text-based person search by spatial matching and adaptive threshold		As an important complement to person re-identification, text-based person search in large-scale database is concerned greatly for person search applications. Given language description of a person, existing frameworks search the images in the dataset that describe the same person, by computing the affinity score between the description and each image. In this paper, we first propose an efficient patch-word matching model, which can accurately capture the local matching details between image and text. In particular, it computes the affinity between an image and a word as the affinity of the best matching patch of the image toward the word. Compared with the state-of-the-art framework, it achieves competitive performance, but yields lowcomplexity structure. In addition, we put forward a significant limitation of affinity-based model, it is overly sensitive to the matching degree of a corresponding image-word pair. For this limitation, we feed a creative adaptive threshold mechanism into the model, it automatically learns an adaptive threshold for each word, and effectively “compress” the affinity score between a word and an image when the score exceeds the words threshold. Extensive experiments on the benchmark dataset demonstrate the effectiveness of the proposed framework, which outperforms other approaches for text-based person search. To provide a deeper insight into the proposed model, we visualize the matching details between spatial patches of images and words of texts on typical examples, and illustrate how adaptive threshold mechanism compresses the affinity score and benefits the final rank of different images toward a text description.	affinity analysis;benchmark (computing);database trigger;experiment;f1 score;processor affinity;text-based (computing)	Tianlang Chen;Chenliang Xu;Jiebo Luo	2018	2018 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2018.00208	task analysis;artificial intelligence;fold (higher-order function);computer science;feature extraction;visualization;pattern recognition	Vision	-15.822418329188666	-60.193596991055266	115790
41ce0e08bec17f155e1dba9a784c05dd3af4c813	geneshelf: a web-based visual interface for large gene expression time-series data repositories	gene expression profile;microarray data;large gene expression time series data repositories;biology computing;front end;gene expression profiling bioinformatics visualization augmented timeline animation zoomable grid;design and development;spinal cord;static data representations;web based visual interface;augmented timeline;gene expression data;indexing terms;gene expression genetics displays bioinformatics time series analysis databases injuries spinal cord mice rats;bar charts;genetics;chip;public databases;gene expression;visualization;internet;gene expression analysis;qualitative user study;image color analysis;data structures;injuries;animation;data visualization;animals computational biology computer graphics database management systems databases genetic gene regulatory networks internet mice oligonucleotide array sequence analysis rats spinal cord injuries user computer interface;time series data;static data representations geneshelf web based visual interface large gene expression time series data repositories bar charts public databases;geneshelf;high throughput;bioinformatics visualization;visual interfaces;user interfaces;zoomable grid;gene expression profiling;gene expression omnibus;user interfaces biology computing data structures genetics internet	A widespread use of high-throughput gene expression analysis techniques enabled the biomedical research community to share a huge body of gene expression datasets in many public databases on the web. However, current gene expression data repositories provide static representations of the data and support limited interactions. This hinders biologists from effectively exploring shared gene expression datasets. Responding to the growing need for better interfaces to improve the utility of the public datasets, we have designed and developed a new web-based visual interface entitled GeneShelf (http://bioinformatics.cnmcresearch.org/GeneShelf). It builds upon a zoomable grid display to represent two categorical dimensions. It also incorporates an augmented timeline with expandable time points that better shows multiple data values for the focused time point by embedding bar charts. We applied GeneShelf to one of the largest microarray datasets generated to study the progression and recovery process of injuries at the spinal cord of mice and rats. We present a case study and a preliminary qualitative user study with biologists to show the utility and usability of GeneShelf.	animation;application program interface;bioinformatics;biomedical research;categorization;chart;classification;color gradient;database;databases;dimensions;embedding;experiment;gene expression profiling;high-throughput computing;imagery;information visualization;interaction;interface device component;largest;microarray;positive feedback;problem solving (mental process);repository;spinal cord;throughput;time series;timeline fluoride releasing resin;usability testing;web application	Bo Hyoung Kim;Bongshin Lee;Susan Knoblach;Eric P. Hoffman;Jinwook Seo	2009	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2009.146	gene expression;computer science;bioinformatics;data mining;world wide web;data visualization;statistics	Visualization	-5.655592547089403	-60.03625455258925	117093
73b32dde073ac5660c11374afe9b6e71719fcb1b	automatic scene detection in news program by integrating visual feature and rules	broadcast news;recherche image;scene video;segmentation;information integration;produccion video;video production;visual features;production video;segmentacion;image retrieval	Organizing video sequences from shot level to scene level is a challenging task, however, without the scene information, it will be very hard to extract the content of the video. In this paper, a visual and rule information integrated strategy is proposed to detect the scene information of the News programs. First, we extract out the video caption and anchor person (AP) shots in the video. Second, the rules among the scene, video caption, AP shots will be used to detect the scenes. Third, the visual features will also be used to analysis the scene information in the region which can not be covered by the rules. And experimental results based on this strategy are provided and analyzed on broadcast News videos.		Xingquan Zhu;Lide Wu;Xiangyang Xue;Xiaoye Lu;Jianping Fan	2001		10.1007/3-540-45453-5_109	video compression picture types;computer vision;video production;image retrieval;computer science;information integration;video capture;video tracking;multimedia;video processing;segmentation;computer graphics (images)	ML	-13.865278955870929	-55.9396397340397	117094
401a407a1067414899fea7263b8f6ce72824ed15	evaluation and knowledge representation formalisms to improve video understanding	user evaluation;real time;video processing;knowledge representation	This article presents a methodology to build efficient real-time semantic video understanding systems addressing real world problems. In our case, semantic video under- standing consists in the recognition of predefined scenario models in a given application domain starting from a pixel analysis up to a symbolic description of what is happening in the scene viewed by cameras. This methodology proposes to use evaluation to acquire knowledge of programs and to represent this knowledge with appropriate formalisms. First, to obtain efficiency, a formalism enables to model video processing programs and their associated parameter adaptation rules. These rules are written by experts after performing a technical evaluation. Second, a scenario for- malism enables experts to model their needs and to easily refine their scenario models to adapt them to real-life situa- tions. This refinement is performed with an end-user evalu- ation. This second part ensures that systems match end-user expectations. Results are reported for scenario recognition performances on real video sequences taken from a bank agency monitoring application.	application domain;knowledge representation and reasoning;performance;pixel;real life;real-time locating system;refinement (computing);semantics (computer science);video processing	Benoît Georis;Magale Maziere;François Brémond	2006	Fourth IEEE International Conference on Computer Vision Systems (ICVS'06)	10.1109/ICVS.2006.23	knowledge representation and reasoning;computer vision;simulation;computer science;artificial intelligence;video tracking;data mining;multimedia;video processing	Vision	-12.161031344947881	-52.50789133972969	117589
68e4280770c447ad2fb95118e62ac56548a49d4a	content-based cover song identification in music digital libraries	test collection;music digital library	In this paper we report the status of our research on the problem of content-based cover song identification in music digital libraries. An approach which exploits both harmonic and rhythmic facets of music is presented and evaluated against a test collection. Directions for future work are proposed, and particular attention is given to the scalability challenge.	digital library;library (computing);scalability	Riccardo Miotto;Nicola Montecchio;Nicola Orio	2010		10.1007/978-3-642-15850-6_19	speech recognition;computer science;multimedia	Web+IR	-15.973533087591617	-57.51653868524187	117799
6875368e6ca0db19db3c71af5e8a6301be2b8f5b	a ring-based chemical structural query system: use of a novel ring-complexity heuristic	topology;base donnee;topologie;database;base dato;anneau;topologia;estructura quimica;almacenamiento;stockage;ring;chemical structure;structure chimique;storage;anillo		heuristic	Ramaswamy Nilakantan;Norman Bauman;Kevin S. Haraki;R. Venkataraghavan	1990	Journal of Chemical Information and Computer Sciences	10.1021/ci00065a015	chemistry;organic chemistry;database;mathematics;chemical structure;algorithm;ring	DB	-6.524954889963545	-54.325011699589275	118044
91b94dd2e1ad7eab57d5ee26b0c4e3a056046f41	the tocai description scheme for indexing and retrieval of multimedia documents	analytical index;effective retrieval;table of contents;indexing and retrieval;indexing;indexation;audio visual;description schemes;extraction method;multimedia documents	A framework, called Table of Content-Analytical Index (ToCAI), for the content description of multimedia material is presented. The idea for such a description scheme (DS) comes out from the structures used for indexing technical books (containing a Table of Content, typically placed at the beginning of the book, where the list of topics is organized hierarchically into chapters, sections, and an Analytical Index, typically placed at the end of the book, where keywords are listed alphabetically). The ToCAI description scheme provides similarly a hierarchical description of the time sequential structure of a multimedia document (ToC), suitable for browsing, and an “Analytical Index” (AI) of audio-visual key items for the document, suitable for effective retrieval. Besides two other sub-description schemes are proposed to specify the program category and the description of other metadata associated to the multimedia document in the general DS. The detailed structure of the DS is presented by means of a UML diagram. Moreover, some suitable automatic extraction methods for the identification of the values associated to the descriptors that compose the ToCAI are presented and discussed. Finally, a browsing application example is also proposed.	analytical engine;book;diagram;mpeg-7;moving picture experts group;uml state machine;unified modeling language	Nicola Adami;Alessandro Bugatti;Riccardo Leonardi;Pierangelo Migliorati;Lorenzo A. Rossi	1999	Multimedia Tools and Applications	10.1023/A:1011347200133	search engine indexing;table of contents;computer science;database;multimedia;world wide web;information retrieval	Web+IR	-14.396917479123683	-54.68679350099346	118240
1fda6c956494304cf5118a1a6580e9eed023f943	a collaborative personalized affective video retrieval system	filtering;collaboration motion pictures information retrieval filtering cultural differences internet multimedia databases content based retrieval computer vision multimedia systems;video retrieval filtering theory;motion pictures;collaboration;video retrieval;serveur institutionnel;hollywood movies;internet;archive institutionnelle;collaborative personalized affective video retrieval system;collaborative filtering;streaming media;open access;multimedia communication;emotional keyword query;archive ouverte unige;cybertheses;institutional repository;filtering theory;cultural differences;collaborative filtering collaborative personalized affective video retrieval system hollywood movies emotional keyword query	In this demonstration, a collaborative personalized affective video retrieval is introduced. A dataset of 155 video clips extracted from Hollywood movies were annotated by the emotion felt by participants. More than 1300 annotations from 40 participants were gathered in a database to be used for affective retrieval system. The retrieval system is able to retrieve videos based on emotional keyword query as well as arousal and valence query. The user's personal profile (gender, age, cultural background) was employed to improve the collaborative filtering in retrieval.	collaborative filtering;hollywood;personalization;video clip	Mohammad Soleymani;Jonathan H Davis;Thierry Pun	2009	2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops	10.1109/ACII.2009.5349526	filter;the internet;computer science;collaborative filtering;machine learning;multimedia;world wide web;cultural diversity;information retrieval;collaboration	Vision	-16.302327572999964	-53.18875195580272	118314
9a9877791945c6fa4c1743ec6d3fb32570ef8481	the m2vts multimodal face database (release 1.00)	institutional repositories;fedora;language resources;vital;multiple views;image sequence;vtls;ils	The primary goal of the M2VTS project is to address the issue of secured access to buildings or multi-media services by the use of automatic person verification based on multimodal strategies (secured access based on speech, face images and other information). This paper presents an overview of the multimodal face database recorded at UCL premises for the purpose of research applications inside the M2VTS project. This database offers synchronized video and speech data as well as image sequences allowing to access multiple views of a face. This material should permit the design and the testing of identification strategies based on speech andro labial analysis, frontal and/or profile face analysis as well as 3-D analysis thanks to the multiple views. The M2VTS Database is available to any non-commercial user on request to the European Language Resource Agency.	multimodal interaction	Stéphane Pigeon;Luc Vandendorpe	1997		10.1007/BFb0016021	computer vision;computer science;artificial intelligence;data mining;database;multimedia;world wide web;computer security	Vision	-15.823179996546253	-56.13067072763133	118410
4eb3e74f0b561fa19c3cd39cc4de5e9d64dd849b	web-based probabilistic retrieval of chinese calligraphic character images: an efficiency study	high dimensionality;indexing method;probabilistic model;shape similarity;indexation	This paper proposes an efficient probabilistic indexing scheme called Probabilistic Retrieval-Tree(PR-Tree) to facilitate a efficient probabilistic retrieval of Chinese calligraphic manuscript images based on triple features such as contour points, character styles and number of strokes. To the best of our understanding, this is first work on probabilistic retrieval over Chinese character. Different from conventional character retrieval and indexing methods [18] which only adopts shape similarity as a query metric, our proposed indexing algorithm allows user to choose the above three kinds of features as query elements. Moreover, a probabilistic model is introduced into the character retrieval process. Comprehensive experiments are conducted to testify the effectiveness and efficiency of our proposed retrieval and indexing methods respectively.	algorithm;experiment;probabilistic database;statistical model	Yanping Zhuang	2010		10.1007/978-3-642-17407-0_36	statistical model;computer science;pattern recognition;data mining;information retrieval;divergence-from-randomness model	Web+IR	-11.09160444807431	-59.14947398117883	118735
2ec4baa2ee41cecc2c652cdb98931b090851f7be	extending a multi-agent system for genomic annotation	multidisciplinaire;multiagent system;multi agent system;aplicacion medical;genome annotation;information technology;informe actividad;technologie information;information gathering;rapport activite;multidisciplinario;progress report;genome;human genome project;multidisciplinary;medical application;genoma;information system;sistema multiagente;tecnologia informacion;systeme information;systeme multiagent;application medicale;sistema informacion	The explosive growth in genomic (and soon, expression and proteomic) data, exemplified by the Human Genome Project, is a fertile domain for the application of multi-agent information gathering technolgies. Furthermore, hundreds of smaller-profile, yet still economically important organisms are being studied that require the efficient and inexpensive automated analysis tools that multiagent approaches can provide. In this paper we give a progress report on the use of the DECAF multi-agent toolkit to build reusable information gathering systems for bioinformatics. We will briefly summarize why bioinformatics is a classic application for information gathering, how DECAF supports it, and recent extensions underway to support new analysis paths for genomic information.	agent-based model;bioinformatics;computer online forensic evidence extractor;computer multitasking;dvd region code;distributed computing;gene expression profiling;gene regulatory network;graphical user interface;heterogeneous database system;high- and low-level;interoperability;multi-agent system;pathway analysis;primary source;proteomics;query language	Keith S. Decker;Salim Khan;Carl J. Schmidt;Dennis Michaud	2001		10.1007/3-540-44799-7_12	computer science;bioinformatics;artificial intelligence;multi-agent system;data mining;multidisciplinary approach;genome project;information technology;information system;genome	ML	-5.298167690783135	-61.19713445728951	119220
c75a912ade24024078b99c3d12f48f458ea48969	reconn: a cytoscape plug-in for exploring and visualizing reactome	interactive visualization;cytoscape;pathways;biological networks;multiscale;dynamic;reactome	Interface and visualization tools usually provide static representations of biological pathways, which can be a severe limitation: fixed pathway boundaries are used without consensus about the elements that should be included in a particular pathway; one cannot generate new pathways or produce selective views of existing pathways. Also, the tools are not capable of integrating multiple levels that conceptually can be distinguished in biological systems. We present ReConn, an interface and visualization tool for a flexible analysis of large data at multiple biological levels. ReConn (Reactome Connector) is an open source extension to Cytoscape which allows user friendly interaction with the Reactome database. ReConn can use both predefined Reactome pathways as well as generate new pathways. A pathway can be derived by starting from any given metabolite and existing pathways can be extended by adding related reactions. The tool can also retrieve alternative routes between elements of a biological network. Such an option is potentially applicable in the design and analysis of knockout experiments. ReConn displays information about multiple levels of the system in one view. With these dynamic features ReConn addresses all of the above mentioned limitations of the interface tools.		Willem P. A. Ligtenberg;Dragan Bosnacki;Peter A. J. Hilbers	2013	Journal of bioinformatics and computational biology	10.1142/S0219720013500042	biological network;interactive visualization;computer science;bioinformatics;theoretical computer science;data mining	Visualization	-5.781341877336339	-59.92019110322543	119412
ed5d87fb24d70a44986ef7d2a090dab57ced404d	a map-search framework based on attributed graph matching	semantics;pixel;image retrieval;cartography;databases;graph matching;data mining;graph theory;classification algorithms;semantic web;ubiquitous computing	Our proposed sketch-based search and retrieval system in map databases shows the promise that intuitive search can be possible even when searching in nonannotated conventional map data. We plan to perform further work in this area to allow for more intuitive and semantic queries, applications for mobile and ubiquitous computing, and integration to existing map searching applications.	attributed graph grammar;database;matching (graph theory);ubiquitous computing	Athanasios Mademlis;Michael G. Strintzis;Konstantinos Kostopoulos;Konstantinos Moustakas;Dimitrios Tzovaras	2010	IEEE MultiMedia	10.1109/MMUL.2010.5692180	computer vision;image retrieval;computer science;graph theory;semantic web;data mining;semantics;ubiquitous computing;information retrieval;pixel;matching	DB	-11.669995578348058	-56.491338234810385	119572
f646b148b0d1c48b92be497aed62f4acc7948def	chemical abstracts service chemical registry system. 11. substance-related statistics: update and additions	traitement automatise;statistique;base donnee;evolucion;database;base dato;chimie;indexing;tratamiento automatizado;indexation;chemistry;indizacion;quimica;statistics;estadistica;automated processing;evolution	Statistics are updated for types of substances, ring systems, and elemental composition that have been determined for the Chemical Abstracts Service Registry Structure File at different points in time. This paper reports the updated figures and in addition some new statistics and offers some comparisons to show various shifts in file characteristics.		Robert E. Stobaugh	1988	Journal of chemical information and computer sciences	10.1021/ci00060a003	computer science;data mining;evolution;database;algorithm;statistics	Theory	-5.458516071379132	-55.764503612586694	119684
f31f776e368592729a15c489df3ab3adf7859d9f	iseapeaks: an excel platform for genescan and immunoscope data retrieval, management and analysis	data retrieval	ISEApeaks retrieves and handles DNA sequencer raw data (peak area and nucleotidic length). This Macintosh package efficiently interfaces GeneScan and Immunoscope softwares to Excel by extracting data from scattered files, organizing data and gathering it into a unique peak database for all samples.	data retrieval;microsequencer;organizing (structure)	A. Collette;Adrien Six	2002	Bioinformatics	10.1093/bioinformatics/18.2.329	biology;computer science;data mining;database;world wide web;data retrieval	DB	-4.7884866515230495	-59.105299537796675	119876
779a10ec75e9f10c8646e26aa0741e6cb9ef30e4	tunnex: an easy-to-use wentzel-kramers-brillouin (wkb) implementation to compute tunneling half-lives	gui;kinetics;tunneling;tunneling control	Tunneling in experiments (TUNNEX) is a free open-source program with an easy-to-use graphical user interface to simplify the process of Wentzel-Kramers-Brillouin (WKB) computations. TUNNEX aims at experimental chemists with basic knowledge of computational chemistry, and it offers the computation of tunneling half-lives, visualization of data, and exporting of graphs. It also provides a helper tool for executing the zero-point vibrational energy correction along the path. The program also enables computing high-level single points along the intrinsic reaction path. TUNNEX is available at https://github.com/prs-group/TUNNEX. As the WKB approximation usually overestimates tunneling half-lives, it can be used to screen tunneling processes before proceeding with elaborate kinetic experiments or higher-level tunneling computations such as instanton theory and small curvature tunneling approaches. © 2018 Wiley Periodicals, Inc.		Henrik Quanz;Peter R. Schreiner	2019	Journal of computational chemistry	10.1002/jcc.25711		Comp.	-6.795897155064113	-58.03981454452671	120118
b50bdafe4e6240813caa90ef3ade9518f82e9b3f	a web service for enabling medical image retrieval integrated into a social medical image sharing platform		Content-based visual image access is in the process from a research domain towards real applications. So far, most image retrieval applications have been in one specialized domain such as lung CTs as diagnosis aid or for classification of general images based on anatomic region, modality, and view. This article describes the use of a content-based image retrieval system in connection with the medical image sharing platform MEDTING, so a data set with a very large variety. Similarity retrieval is possible for all cases of the social image sharing platform, so cases can be linked by either visual similarity or similarity in keywords. The visual retrieval search is based on the GIFT (GNU Image Finding Tool). The technology for updating the index with new images added by users employs RSS (Really Simple Syndication) feeds. The ARC (Advanced Resource Connector) middleware is used for the implementation of a web service for similarity retrieval, simplifying the integration of this service. Novelty of this article is the application/integration and image updating strategy. Retrieval methods themselves employ existing techniques that are all open source and can easily be reproduced.		Marko Niinimäki;Xin Zhou;Enrique de la Vega;Miguel Cabrer;Henning Müller	2010	Studies in health technology and informatics	10.3233/978-1-60750-588-4-1273	anatomic region;rss;novelty;data mining;automatic image annotation;image sharing;information retrieval;web service;image retrieval;middleware;computer science	Web+IR	-13.662646184611434	-57.283299926089335	120149
08bb016f8cf5f3a45937e2636d4a8e204c051472	image retrieval with feature selection and relevance feedback	cbir;content based image retrieval system;online feature selection procedures;high level semantic information;semantics;bayesian methods;user feedback;accuracy;semantic information;feature extraction;feature selection cbir relevance feedback;visual features;low level visual feature;user feedback information;image retrieval feature extraction semantics bayesian methods accuracy;feature selection;content based image retrieval;relevance feedback;relevance feedback feature extraction image retrieval;high level semantic information content based image retrieval system relevance feedback online feature selection procedures user feedback information low level visual feature;image retrieval	This paper proposes a new content based image retrieval (CBIR) system combined with relevance feedback and the online feature selection procedures. A measure of inconsistency from relevance feedback is explicitly used as a new semantic criterion to guide the feature selection. By integrating the user feedback information, the feature selection is able to bridge the gap between low-level visual features and high-level semantic information, leading to the improved image retrieval accuracy. Experimental results show that the proposed method obtains higher retrieval accuracy than a commonly used approach.	content-based image retrieval;feature selection;high- and low-level;relevance feedback	Yu Sun;Bir Bhanu	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5651984	computer vision;visual word;feature extraction;bayesian probability;image retrieval;computer science;machine learning;pattern recognition;semantics;accuracy and precision;feature selection;feature;information retrieval	Vision	-14.760207604059321	-59.48721877615305	120559
036ffabc10771b4edeb32b55da22e9d8f1590245	multi-conditional learning: generative/discriminative training for clustering and classification	probability;learning;selected works;random variables;exponential family;latent dirichlet allocation;symposia;mathematical models;natural language;conditional random field;classification error;artificial intelligence;bepress;discriminative training;markov processes;conditional probability;binary processors	This paper presents multi-conditional learning (MCL), a training criterion based on a product of multiple conditional likelihoods. When combining the traditional conditional probability of “label given input” with a generative probability of “input given label” the later acts as a surprisingly effective regularizer. When applied to models with latent variables, MCL combines the structure-discovery capabilities of generative topic models, such as latent Dirichlet allocation and the exponential family harmonium, with the accuracy and robustness of discriminative classifiers, such as logistic regression and conditional random fields. We present results on several standard text data sets showing significant reductions in classification error due to MCL regularization, and substantial gains in precision and recall due to the latent structure discovered under MCL.	conditional random field;discriminative model;latent dirichlet allocation;latent variable;logistic regression;macintosh common lisp;monte carlo localization;precision and recall;text corpus;time complexity	Andrew McCallum;Christopher Joseph Pal;Gregory Druck;Xuerui Wang	2006			latent dirichlet allocation;random variable;exponential family;conditional probability;computer science;machine learning;pattern recognition;probability;mathematical model;markov process;natural language;generative model;conditional random field;discriminative model;statistics	AI	-14.446575944540436	-65.62566292717786	121230
814f6391e548a3df507a60c2ea6c379477e73e8c	banglalekha-isolated: a comprehensive bangla handwritten character dataset		Bangla handwriting recognition is becoming a very important issue nowadays. It is potentially a very important task specially for Bangla speaking population of Bangladesh and West Bengal. By keeping that in our mind we are introducing a comprehensive Bangla handwritten character dataset named BanglaLekha-Isolated. This dataset contains Bangla handwritten numerals, basic characters and compound characters. This dataset was collected from multiple geographical location within Bangladesh and includes sample collected from a variety of aged groups. This dataset can also be used for other classification problems i.e: gender, age, district. This is the largest dataset on Bangla handwritten characters yet.	handwriting recognition;location (geography)	Mithun Biswas;Rafiqul Islam;Gautam Kumar Shom;Md Shopon;Nabeel Mohammed;Sifat Momen;Md Anowarul Abedin	2017	CoRR		numeral system;artificial intelligence;natural language processing;computer science;bengali;population;handwriting recognition	AI	-10.097092664545077	-63.360491771363634	121869
31144ecb73a6afe23c82b09f641a4a1af08a35d3	estimating multiple evoked emotions from videos		Video-sharing websites have begun to provide easy access to user-generated video content. How do we find what we want to view among the huge video database? When people search for a video, they may want to know whether the video evokes a certain emotional sensation. The evoked emotion is one of the important factors we consider when we select a video. One of the key concepts of evoked emotions from videos: the evoked emotions are different for each scene and for each viewer. Considering these differences, we obtained humanevoked emotions from 33 videos. We used these emotions to estimate the multiple emotions evoked by each scene of the videos. Using a computational model of emotion estimation based on mid-level visual features, we found that, in individual videos, the same scene evoked multiple emotions. Our results show that a video evoked different emotions from different people. A computational model might deliver probabilistic multiple-evoked emotions from video analyses.	accessibility;computation;computational model;digital video;motion estimation;user-generated content;web search engine	Wonhee Choe;Hyo-Sun Chun;Junhyug Noh;Seong-Deok Lee;Byoung-Tak Zhang	2013			sadness;amateur;digital media;psychology;mood;amusement;categorization;image retrieval;multimedia;international affective picture system	Vision	-16.20417788295472	-53.05410862256328	122175
c7c916ab0044ddc7ab43b839e5de4907489fb5db	advanced visual analytics approaches for the integrative study of genomic and transcriptomic data			visual analytics	Günter Jäger	2016			database;world wide web;information retrieval	Visualization	-5.636560385888767	-61.426884885884895	122196
117551a64fbb3b3aea5d5c4d1504b9040cf0a019	movie genre classification via scene categorization	video analysis;visual features;scene understanding;bag of visual words;genre classification	This paper presents a method for movie genre categorization of movie trailers, based on scene categorization. We view our approach as a step forward from using only low-level visual feature cues, towards the eventual goal of high-level seman- tic understanding of feature films. Our approach decom- poses each trailer into a collection of keyframes through shot boundary analysis. From these keyframes, we use state-of- the-art scene detectors and descriptors to extract features, which are then used for shot categorization via unsuper- vised learning. This allows us to represent trailers using a bag-of-visual-words (bovw) model with shot classes as vo- cabularies. We approach the genre classification task by mapping bovw temporally structured trailer features to four high-level movie genres: action, comedy, drama or horror films. We have conducted experiments on 1239 annotated trailers. Our experimental results demonstrate that exploit- ing scene structures improves film genre classification com- pared to using only low-level visual features.	bag-of-words model in computer vision;categorization;experiment;high- and low-level;key frame;scene graph;sensor	Howard Zhou;Tucker Hermans;Asmita V. Karandikar;James M. Rehg	2010		10.1145/1873951.1874068	computer vision;speech recognition;computer science;machine learning;multimedia;bag-of-words model in computer vision	Vision	-13.960048391958694	-56.39338349833349	122638
21245d3da384adec6914fd4eb416099ea2846a21	music information retrieval	music;information retrieval	Huge amount of audio resources, including music data, is becoming available in various forms, both analog and digital. Notes, CDs, and digital resources of the World Wide Web are constantly growing in amount, but the value of music information depends on how easy it can be found, retrieved, accessed, filtered and managed. MIR consists in quick and efficient searching for various types of audio data of interest to the user, and filtering them in order to receive only the data items which satisfy the user’s preferences (Fingerhut, 1997), (International Organization for Standardization, 2003), (Wieczorkowska & Ras, 2003). MIR applications include retrieval of music pieces from huge audio databases, and automatic production of music score on the basis of the presented input. The MIR topics are interrelated, since similar techniques can be applied for various purposes, e.g., source separation is applied in auditory scene analysis, music transcription, and even for restoring (de-noising) of all recordings. Generally, the research within MIR domain is focused on: harmonic structure analysis, note extraction, melody and rhythm tracking, timbre and instrument recognition, classification of type of the signal (speech, music, pitched vs. non-pitched), etc. The research basically uses digital audio recordings, where sound waveform is digitally stored as a sequence of discrete samples representing the sound intensity at given time instant, and MIDI files, storing information on parameters of electronically synthesized sounds (voice, note on, note off, pitch bend etc.). Sound analysis and data mining tools are used to extract information from music files, in order to provide the data that meet user’s needs (Wieczorkowska & Ras, 2001).	analog signal;digital data;information retrieval;world wide web	Alicja Wieczorkowska	2009			information retrieval;human–computer information retrieval	Web+IR	-13.338811183412298	-54.10217777939582	122661
7abd0d5aa3e323dd62352892a8cc16565802b612	dj-mvp: an automatic music video producer.	taste;projection mapping;mixed reality technology;flavor;multimodal perception	A music video (MV) is a videotaped performance of a recorded popular song, usually accompanied by dancing and visual images. In this paper, we outline the design of a generative music video system, which automatically generates an audio-video mashup for a given target audio track. The system performs segmentation for the given target song based on beat detection. Next, according to audio similarity analysis and color heuristic selection methods, we obtain generated video segments. Then, these video segments are truncated to match the length of audio segments and are concatenated as the final music video. An evaluation of our system has shown that users are receptive to this novel presentation of music videos and are interested in future developments.	algorithm;beat detection;concatenation;heuristic;mashup (web application hybrid);sound card	Jianyu Fan;William Li;Jim Bizzocchi;Justine Bizzocchi;Philippe Pasquier	2016		10.1145/3001773.3001782	speech recognition;computer science;video tracking;multimedia;video processing;communication	AI	-15.496966340462263	-54.15541781296852	122845
359b660b1dc86ef4fccb89b6dae6c4197174f6ea	semantic mapping of energy simulation data using bag of words and graph matching		Energy simulation is essential to urban planning and environment protection. It can be used to compare the effectiveness of different investment or construction strategies for decision makers. However, in the city level, the energy consumption simulation is difficult to implement because of the lack of datasets. In this paper, we propose an algorithm of automatic semantic mapping of energy simulation data from CityGML to data format of existing energy simulation software such as EnergyPlus. The proposed method makes use of bag of words algorithm to detect the semantic similarity between two objects in different data format and then the graph matching method is employed for overall mapping and information transformation. The experimental results indicate that the proposed method can effectively extract semantic information from CityGML for energy simulation.		Rong Li;Bing Tian;Li Yan;Yansheng Qu	2018	2018 26th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2018.8557096	simulation software;semantic similarity;semantic matching;data mining;semantic mapping;matching (graph theory);citygml;energy consumption;bag-of-words model;computer science	Robotics	-11.406506678339133	-55.894522541945385	123335
523cd7c490094f71f2d97a29bdde1f21166fa083	image classification and retrieval on the world wide web	image content;texture detection;neural networks;generic algorithm;digital library;textual indices;image database;image classification;computer vision;development tool;non structural;image search;world wide web;information system;parallel programs;multimedia database;color image;neural network;image retrieval	Image retrieval is emerging as an important research area with many applications in various fields such as image and multimedia databases and digital libraries. The World Wide Web is an enormous, distributed, hypermedia and non-structured information system. Tens of millions of images exist on the World Wide Web. Developing tools which would make it possible to seek specific images in this enormous image database is of an unquestionable utility and would give to the WWW all its potential. However, the search for images in the context of the WWW is an extremely difficult task and poses new challenges. Two characteristics are to be taken into account when dealing with images on the WWW: 1. the incredibly large size of all these images and the extraordinary diversity of types of images which one can find on the WWW; 2. in the field of image processing and computer vision, there is no general algorithm able to process all types of images. Two fundamental issues must be addressed when developing retrieval tools: effectiveness of search and effectivity of search. The effectiveness implies that one can find information in a reasonable time. With the power of the current workstations and the development of techniques such as parallel programming and multi-thread programming, the effectiveness is not a bottleneck. However the effectivity of the images retrieved compared to the request is a major problem and should be examined more closely. The majority of the retrieval tools existing on the WWW are not pertinent: many retrieved documents are not pertinent to the request (noise) and many documents pertinent to the request are not retrieved (silence). Taking into account all these facts, we believe that a preliminary and crucial step before developing an image retrieval tool on the WWW is, first, to classify these images in many classes such as photographs, graphics, cartoons, faces, textured images, color images, etc. and then perform a search in each class. Doing so, we take at least two advantages: 1. effectivity is improved (noise and silence are reduced) since search is done in a specific class and not in all the database; 2. we can apply appropriate algorithms on each class of images given that a general algorithm for all types of images does not exist. In this paper, we are interested in performing image search on the WWW using both the image content and textual key-words. The following features are yet available in our system:	algorithm;computer vision;database;digital library;graphics;hypermedia;image noise;image processing;image retrieval;information system;library (computing);parallel computing;relevance;www;workstation;world wide web	Noureddine Abbadeni;Djemel Ziou;Shengrui Wang	1999		10.1145/313238.313316	computer vision;web query classification;visual word;web mapping;image retrieval;computer science;data mining;automatic image annotation;information retrieval;human–computer information retrieval	Vision	-11.580595304788284	-57.4300297451882	124068
b279303c2546b899946203e03d553f3557df46bc	3wnews: who, where, and when in news video	browsing;time;location;indexation;news video;people;video browsing	We describe 3WNews as a novel system for browsing news video by the people (who) and locations (where) appearing in the footage as well as the time (when) of news events. The people names, locations, and time expressions are recognized from video transcript and their ambiguous references are resolved. As a key advantage, 3WNews distinguishes the people and locations that actually appear in the video from those merely mentioned in the transcript, and uses them as (better) indexes for browsing. It also supports browsing of news video by event time instead of broadcasting time.		Jun Yang;Alexander G. Hauptmann	2006		10.1145/1180639.1180746	multimedia;internet privacy;location;world wide web	Vision	-17.411858252617726	-56.074899539660706	124211
faf1500cca739838d7111f847e227670befc3d76	efficient method for content extraction applied in multimedia communication	content extraction;video signal processing feature extraction image motion analysis image segmentation multimedia communication;multimedia content extraction method;nonoverlapping homogenous regions;image motion analysis;static object detection multimedia content extraction method object segmentation content adaptation semantic video modeling video segmentation nonoverlapping homogenous regions region based methods motion based methods;image segmentation;video signal processing;vocabulary;region based methods;motion based methods;video segmentation;segmentation;operations research;data mining;multimedia communication streaming media data mining image segmentation internet electronic learning encoding intelligent networks object segmentation image edge detection;object segmentation;content analysis;motion segmentation;image edge detection;streaming media;feature extraction;multimedia communication;motion detection content analysis video modeling segmentation;video modeling;content adaptation;indium;motion detection;semantic video modeling;iodine;object detection;static object detection;nitrogen	In this paper we present the multimedia content extraction method based on region and object segmentation. The process of content extraction represents one step in solving the problem of content adaptation. Adaptation means the preparation and delivery of content that matches the resources of the connected terminal or network in an optimal way. The process of multimedia content extraction consists of two stages: semantic video modeling and video segmentation. The result of semantic video modeling is the representation of raw data in a more structured form, and it is essential in the following stage. Video segmentation means the partition of an image into a set of non overlapping homogenous regions whose union is the entire image. The presented segmentation methods are edge-based, region-based and motion-based, and are used for moving or static object detection.	computer terminal;content adaptation;edge detection;information extraction;object detection	Ionut Pirnog;Radu Mihnea Udrea;Constantin Paleologu	2008	Seventh International Conference on Networking (icn 2008)	10.1109/ICN.2008.45	computer vision;content analysis;feature extraction;computer science;segmentation-based object categorization;video tracking;nitrogen;iodine;multimedia;image segmentation;indium;scale-space segmentation;segmentation;computer graphics (images)	Vision	-14.012273275746157	-55.33194402087046	124266
7f1484110988699f38dd32c80634cd2b29114eb0	viewing genome data as objects for application development	dna;genes;application development;diagrams;data representation;genetics;protein structure;graph representation;hybridization;data flow;biology and medicine basic studies;data base management;mathematics computers information science management law miscellaneous	Genomics is becoming a data-intensive science, and an increasing number of laboratories are generating data which swamps storage in traditional paper-and-ink notebooks. Capturing the data flow requires large systems with multiple applications manipulating the same or similar data. Large systems often have conflicting requirements for data representation. Consistency across applications is a prime consideration, and appropriate data representation is an important issue in developing practical systems for molecular biologists. Graphs are a natural representation for describing genome data, while objects are good for modeling the behavior necessary for laboratory applications. We present a method for translating graph descriptions of genome data into objects using objects as views on graphs. Graph representations describe genome concepts while objects capture individual views for application development insuring consistency across genome applications.	conflict (psychology);data (computing);data-intensive computing;dataflow;description;graph (abstract data type);graph - visual representation;ink (substance);laboratory;physical object;requirement	Ellen R. Bergeman;Mark Graves;Charles B. Lawrence	1995	Proceedings. International Conference on Intelligent Systems for Molecular Biology		biology;data flow diagram;orbital hybridisation;protein structure;computer science;bioinformatics;diagram;theoretical computer science;machine learning;gene;mathematics;external data representation;graph;rapid application development;genetics;dna	HPC	-5.0723417139659475	-62.52109602586547	124365
fa610f6980ccea8a69f19ee0bcc172d8150bd0e9	how computers are changing biology	sophisticated computer model;test tube;biology research	Sophisticated computer models and simulations are replacing test tubes and beakers. This revolution in biology research is redefining medicine, agriculture, and more.	computer simulation;definition	Samuel Greengard	2014	Commun. ACM	10.1145/2591230	computer science	Networks	-8.114487404732893	-55.97609997469228	124368
50e683b9e85125b9d0252b13635cab595251c4cd	multiple-instance image database retrieval by spatial similarity based on interval neighbor group	multiple instance;content based image retrieval cbir;multiple instance learning;image database;spatial relation;retrieval by spatial similarity rss;content based image retrieval;interval neighbor group ing;similarity measure;image retrieval	In this paper, a multiple-instance image retrieval system incorporating a general spatial similarity measure is proposed. A multiple-instance learning is employed to summarize the commonality of spatial features among positive and negative example images. The general spatial similarity measure evaluates the degree of similarity between matching atomic spatial relations present in the maximum common object set of the query and a database image based on their nodal distance in an Interval Neighbor Group (ING). The shorter the distance, the higher degree of similarity, while a longer one, a lower degree of similarity. An ensemble similarity measure, derived from the spatial relations of all constituent objects in the query and a database image, will then integrate these atomic spatial similarity assessments and give an overall similarity value between two images. Therefore, images in a database can be quantitatively ranked according to the degree of ensemble spatial similarity with the query. In order to demonstrate the feasibility of the proposed approach, two sets of test for querying an image database are performed, namely, single-instance v.s. multiple-instance retrieval by employing the RSS-ING scheme proposed and the RSS-ING scheme v.s. 2D Be-string similarity method incorporating identical multiple-instance learning. The ING-based spatial similarity measure with fine granularity, combined with the utilization of a multiple-instance learning paradigm to forge a unified query key, produces desirable retrieval results that better match user's expectation.	forge;image retrieval;multiple-instance learning;programming paradigm;rss;semantic similarity;similarity measure;single-instance storage;string metric	John Y. Chiang;Shuenn-Ren Cheng;Yen-Ren Huang	2010		10.1145/1816041.1816064	spatial relation;semantic similarity;visual word;image retrieval;computer science;pattern recognition;data mining;information retrieval	Vision	-15.202360504786958	-64.38991450426991	124453
447ec6e614959a5e49815a23527a361ef2a6f046	fria: fast and robust instance alignment	hierarchical partitioning;instance alignment;entity matching;knowledge base	This paper proposes Fria, a fast and robust instance alignment framework across two independently built knowledge bases (KBs). Our objective is two-fold: (1) to design an effective instance similarity measure and (2) to build a fast and robust alignment framework. Specifically, Fria consists of two-phases. Fria first achieves high-precision alignment for seed matches which have strong evidence for aligning. To obtain high-recall alignment, Fria then divides non-matched instances according to the types identified from seeds, and gives additional chances to the same-typed instances to be matched. Experimental results show that Fria is fast and robust, by achieving comparable accuracy to state-of-the-arts and a 10-times speed up.	knowledge base;robustness (computer science);similarity measure	Sanghoon Lee;Jongwuk Lee;Seung-won Hwang	2013		10.1145/2487788.2487875	knowledge base;computer science;machine learning;pattern recognition;data mining	NLP	-17.463986873831573	-65.72626745244726	124560
fd073f68be28f5bb7219e571092828e74476d0a3	cdna sequence of human beta-ngf	dna;splicing;gene β ngf;factor crecimiento nervio;nerve growth factor;empalme;hombre;secuencia nucleotido;nucleotide sequence;sequence nucleotide;polymerase chain reaction;epissage;clonacion molecular;facteur croissance nerf;sequence homology nucleic acid;cdna sequence;clonage moleculaire;human;molecular cloning;humans;molecular sequence data;base sequence;nerve growth factors;exons;homme	Full textFull text is available as a scanned copy of the original print version. Get a printable copy (PDF file) of the complete article (145K), or click on a page image below to browse page by page. Links to PubMed are also available for Selected References.#R##N##R##N##R##N##R##N##R##N#4020#R##N##R##N##R##N##R##N##R##N##R##N#Selected References#R##N#These references are in PubMed. This may not be the complete list of references from this article. #R##N##R##N#Ullrich A, Gray A, Berman C, Dull TJ. Human beta-nerve growth factor gene sequence highly homologous to that of mouse. Nature. 1983 Jun 30;303(5920):821–825. [PubMed]#R##N#Selby MJ, Edwards R, Sharp F, Rutter WJ. Mouse nerve growth factor gene: structure and expression. Mol Cell Biol. 1987 Sep;7(9):3057–3064. [PMC free article] [PubMed]#R##N#Frohman MA, Dush MK, Martin GR. Rapid production of full-length cDNAs from rare transcripts: amplification using a single gene-specific oligonucleotide primer. Proc Natl Acad Sci U S A. 1988 Dec;85(23):8998–9002. [PMC free article] [PubMed]		G. Borsani;A. Pizzuti;Elena I Rugarli;A. Falini;Vincenzo Silani;A. Sidoli;G. Scarlato;Francisco E. Baralle	1990	Nucleic acids research	10.1093/nar/18.13.4020	molecular cloning;biology;molecular biology;exon;nucleic acid sequence;bioinformatics;polymerase chain reaction;genetics;rna splicing;dna	Robotics	-5.0650618811807515	-57.001309766106594	124572
3be5429fd362396005cc05eb2c26c2b56772175b	efficient pattern-based conceptual image retrieval	databases;manuals;snow;image matching;semantic image retrieval pattern based conceptual image retrieval text based image retrieval high priced manual annotation cost content based image retrieval query image cbir systems high visual feature dimensions pbcir visual patterns visual pattern matching;argon;vectors;image edge detection;image retrieval content based retrieval image matching;abstracts;snow vectors abstracts manuals argon image edge detection databases;content based retrieval;image retrieval	Actually, text-based image retrieval is a method to retrieve the user's interested images semantically, but there still exist some problems in it such as high-priced manual annotation cost. To avoid the problems in text-based image retrieval, a considerable number of studies have been made on Content-Based Image Retrieval called CBIR over the past few years. Most past studies for CBIR focused on how to search the images most relevant to the query image without considering the concepts hidden. However, CBIR systems encounter the problem of high computation cost due to high visual feature dimensions. To cope with the problems, in this paper, we propose a Pattern-Based Conceptual Image Retrieval method named P BCIR to convert visual features into visual patterns. By visual pattern matching, the relevant images and concepts can be derived to achieve the purpose of semantic image retrieval. The experimental results show that, the proposed method can capture the user's visual and conceptual intents more effectively and efficiently than that considering only visual features.	computation;content-based image retrieval;pattern matching;recommender system;text-based (computing);vector graphics	Ja-Hwung Su;Chun-Yi Kuo;Vincent S. Tseng	2012	2012 IEEE International Conference on Granular Computing	10.1109/GrC.2012.6468694	image texture;computer vision;snow;feature detection;visual word;image retrieval;computer science;data mining;argon;automatic image annotation;information retrieval;human–computer information retrieval	Vision	-15.019051274282367	-58.6676137261294	124695
429f033c108761b9bac7ffeb738a0b0849c0eca0	an efficient multimodal language processor for parallel input strings in multimodal input fusion	natural language interfaces;image annotations;multimedia reasoning;natural language interfaces multimedia systems;user interface;semantic integration;user interfaces multimedia reasoning natural language support semantic integration image annotations domain ontologies ontological representation formal semantics;formal semantics;multimedia systems;natural language support;natural language;natural languages ontologies natural language processing face detection multimedia systems multimedia computing image analysis indexing resource description framework layout;ontological representation;domain ontologies;domain ontology;user interfaces;natural language processing	Multimodal user interaction technology aims at building more natural and intuitive interfaces allowing a user to interact with a computer in a way similar to human-to-human communication, for example, through speech and gesture. As a critical component in multimodal user interaction, multimodal input fusion explores the ways to effectively interpret the combined semantic interpretation of user inputs through multiple modalities. This paper proposes a new efficient unification-based multimodal language processor which can handle parallel input strings for multimodal input fusion. With a structure sharing technology, it has the potential to achieve a low polynomial computational complexity while parsing multimodal inputs in versatile styles. The applicability of the proposed processor has been validated through an experiment with multimodal commands collected from traffic incident management scenarios. The description of the proposed multimodal language processor and preliminary experiment results are presented.	computational complexity theory;incident management;multimodal interaction;natural language processing;parsing;polynomial;semantic interpretation;unification (computer science)	Yong Sun;Yu Shi;Fang Chen;Vera Chung	2007	International Conference on Semantic Computing (ICSC 2007)	10.1109/ICSC.2007.61	natural language processing;language identification;natural language programming;universal networking language;natural language user interface;computer science;database;linguistics;programming language;user interface;computational semantics	NLP	-16.249375095264153	-59.295278388031896	125461
07fbceb17797562e4008c49fd1cf6f3d98825ca1	a novel semantic smoothing method based on higher order paths for text classification	text analysis bayes methods indexing pattern classification smoothing methods;higher order smoothing semantic smoothing method higher order paths text classification latent semantic indexing lsi implicit higher order structure bayesian framework higher order naïve bayes honb hos;higher order naive bayes;semantic smoothing;bayes methods;naive bayes;text analysis;higher order smoothing;smoothing methods semantics niobium text categorization support vector machines classification algorithms training;text classification;smoothing methods;indexing;conferenceobject;pattern classification;text classification naive bayes semantic smoothing higher order naive bayes higher order smoothing	"""It has been shown that Latent Semantic Indexing (LSI) takes advantage of implicit higher-order (or latent) structure in the association of terms and documents. Higher order relations in LSI capture """"latent semantics"""". Inspired by this, a novel Bayesian framework for classification named Higher Order Naïve Bayes (HONB), which can explicitly make use of these higher-order relations, has been introduced previously. We present a novel semantic smoothing method named Higher Order Smoothing (HOS) for the Naive Bayes algorithm. HOS is built on a similar graph based data representation of HONB which allows semantics in higher order paths to be exploited. Additionally, we take the concept one step further in HOS and exploited the relationships between instances of different classes in order to improve the parameter estimation when dealing with insufficient labeled data. As a result, we have not only been able to move beyond instance boundaries, but also class boundaries to exploit the latent information in higher-order paths. The results of our extensive experiments demonstrate the value of HOS on several benchmark datasets."""	additive smoothing;algorithm;baseline (configuration management);benchmark (computing);binary data;data (computing);document classification;estimation theory;experiment;naive bayes classifier;sparse matrix;support vector machine;tf–idf;whole earth 'lectronic link	Mitat Poyraz;Zeynep Hilal Kilimci;Murat Can Ganiz	2012	2012 IEEE 12th International Conference on Data Mining	10.1109/ICDM.2012.109	search engine indexing;text mining;naive bayes classifier;computer science;machine learning;pattern recognition;data mining;smoothing	DB	-17.218216182700232	-63.3827491196115	125960
064b31c2e6cbfff21b0a7910d88e9184ce0ff0db	what is happening: annotating images with verbs	semantic similarity;image annotation;visualness;visual similarity;re ranking;verb tag	Image annotation has been widely investigated to discover the semantics of an image. However, most of the existing algorithms focus on noun tags (e.g. concepts and objects). Since an image is a snapshot of the real world event, annotating images with verbs will enable richer understanding of an image. In this paper, we propose a data-driven approach to verb oriented image annotation. At first, we obtain verb candidates by generating search queries for a given image with initial noun tags and establishing a sentence corpus from those queries. We utilize visualness to filter tags which are not visually presentable (e.g. pain) and differentiate tags into two categories (i.e. scene based and object based) to impose linguistic rules in verb extraction. Then we further re-rank the candidate verbs with the tag context discovered from the images which are both semantically and visually similar to the given image in the MIRFlickr dataset. Our experimental results from user study demonstrate that our proposed approach is promising.	algorithm;automatic image annotation;object-based language;snapshot (computer storage);usability testing;web search query	Gang Tian;Genliang Guan;Zhiyong Wang;David Dagan Feng	2012		10.1145/2393347.2396387	natural language processing;semantic similarity;computer science;pattern recognition;data mining;automatic image annotation;information retrieval	AI	-15.952498797566593	-60.36063345286715	126013
b1150f59c1e55fc1582241f673e474422f23c42d	enhancing the detection of concepts for visual lifelogs using contexts instead of ontologies	lifelog;concept detection;image processing;concept semantics visual lifelogging concept detection non negative matrix factorization;concept semantics;training;semantics;visual lifelogging;media;training data;accuracy;visualization;non negative matrix factorization;semantic concept automatic detection absence pattern adjustment appearance pattern adjustment nonnegative matrix refactorization wearable cameras quantified self movement visual lifelogging low level features automatic mapping visual media;semantics visualization accuracy ontologies media training data training;ontologies;video recording image capture matrix decomposition	Automatic detection of semantic concepts in visual media is typically achieved by an automatic mapping from low-level features to higher level semantics and progress in automatic detection within narrow domains has now reached a satisfactory performance level. In visual lifelogging, part of the quantified-self movement, wearable cameras can automatically record most aspects of daily living. The resulting images have a diversity of everyday concepts which severely degrades the performance of concept detection. In this paper, we present an algorithm based on non-negative matrix refactorization which exploits inherent relationships between everyday concepts in domains where context is more prevalent, such as lifelogging. Results for initial concept detection are factorized and adjusted according to their patterns of appearance, and absence. In comparison to using an ontology to enhance concept detection, we use underlying contextual semantics to improve overall detection performance. Results are demonstrated in experiments to show the efficacy of our algorithm.	algorithm;digital camera;experiment;high- and low-level;lifelog;ontology (information science);wearable computer	Peng Wang;Alan F. Smeaton;Yuchao Zhang;Bo Deng	2014	2014 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)	10.1109/ICMEW.2014.6890570	computer vision;training set;media;visualization;image processing;computer science;ontology;machine learning;semantics;accuracy and precision;multimedia;lifelog;non-negative matrix factorization	Robotics	-15.784746277088745	-60.56140493586073	126060
1c2deee5cf067beb505181136690836c54e37ad4	mspi and ssti rflps at the human insulin receptor locus on chromosome 19	hormona proteina;deoxyribonuclease hpaii;protein hormone;insulina;chromosomes human pair 19;hormonal receptor;cromosoma f19;hombre;hormona pancreatica;deoxyribonucleases type ii site specific;genetic mapping;determinismo genetico;receptor hormonal;hormone pancreatique;gene frequency;hormone proteine;aguja molecular;polymorphism;sonde moleculaire;determinisme genetique;human;carte genetique;frequence genique;insuline;f19 chromosome;insulin;recepteur hormonal;pancreatic hormone;polymorphisme;humans;mapa genetico;polimorfismo;receptor insulin;inheritance;frecuencia genica;chromosome f19;polymorphism restriction fragment length;insulin receptor;homme;molecular probe	Full textFull text is available as a scanned copy of the original print version. Get a printable copy (PDF file) of the complete article (91K), or click on a page image below to browse page by page. Links to PubMed are also available for Selected References.#R##N##R##N##R##N##R##N##R##N#209#R##N##R##N##R##N##R##N##R##N##R##N#Selected References#R##N#These references are in PubMed. This may not be the complete list of references from this article. #R##N##R##N#Elbein SC, Corsetti L, Ullrich A, Permutt MA. Multiple restriction fragment length polymorphisms at the insulin receptor locus: a highly informative marker for linkage analysis. Proc Natl Acad Sci U S A. 1986 Jul;83(14):5223–5227. [PMC free article] [PubMed]#R##N#Elbein SC. Molecular and clinical characterization of an insertional polymorphism of the insulin-receptor gene. Diabetes. 1989 Jun;38(6):737–743. [PubMed]	chromosomes, human, pair 19;locus;restriction fragment length polymorphism;ssti endonuclease	S. C. Elbein;L. Sorensen	1990	Nucleic acids research	10.1093/nar/18.1.209	biology;endocrinology;polymorphism;gene mapping;bioinformatics;allele frequency;insulin receptor;genetics;proinsulin;molecular probe	Vision	-5.033560670733067	-56.982406897497235	126320
08a73d6132ca7b1e4c09970276175f32db39269f	web-based metaprogrammable frontend for molecular dynamics simulations		Molecular dynamics simulators are indispensable tools in the arsenal of chemical engineers and material scientists. However, they are often difficult to use and require programming skills as well as deep knowledge of both the given scientific domain and the simulation software itself. In this paper, we describe a metaprogramming approach where simulator experts can create a library of simulation components and templates of frequently used simulations. Domain experts, in turn, can build and customize their own simulations and the required input for the various supported simulators is automatically synthesized. The web-based environment also supports setting up a suite of simulation jobs, for example, to carry out automated parameter optimization, via a visual programming environment. The entire simulation setup – including the various parameters, the version of tools utilized and the results – is stored in a database to support searching and browsing of existing simulation outputs and facilitating the reproducibility of	archive;database;ibm notes;integrated development environment;mathematical optimization;metaprogramming;molecular dynamics;simulation software;user interface;visual programming language;web application;world wide web	Gergely Varga;Sara Toth;Christopher R. Iacovella;János Sallai;Péter Völgyesi;Ákos Lédeczi;Gabor Karsai;Peter T. Cummings	2013		10.5220/0004486401710178	molecular dynamics;simulation software;simulation;web application;visual programming language;theoretical computer science;template;computer science;metaprogramming	Comp.	-7.037441955464012	-57.58138310750957	126353
586c39f9fb8bd9ed79e66837f1711cb4f1f108e1	design and implementation of coirs (a concept-based image retrieval system)	object recognition;procesamiento informacion;information retrieval;query formulation;reconnaissance objet;base donnee visuelle;visual languages;indexing;design and implementation;recherche information;langage visuel;indexation;information processing;indizacion;spatial relationships;recuperacion informacion;information system;traitement information;content based image retrieval;systeme information;sistema informacion;visual databases;image retrieval	In this paper, we design and implement COIRS (COnceptbased Image Retrieval System). It is a content-based image retrieval system to search for images as well as indexing them based on concepts. The concepts are detected by a thesaurus called triple thesaurus. The triple thesaurus consists of a series of rules defining the concepts. COIRS adopts an image descriptor called triple to specify the spatial relationships between objects in an image. An image is indexed by a set of triples each of them is enrolled into an inverted file, pointing to the image. We also develop a query processor to retrieve relevant images by evaluating a user query. The query formulated in terms of triples is evaluated by matching its triples with those of the inverted file.	content-based image retrieval;inverted index;thesaurus;visual descriptor	Hyung Jeong Yang;Hoyoung Kim;Jae Dong Yang	1999		10.1007/3-540-48762-X_49	spatial relation;search engine indexing;information processing;image retrieval;computer science;cognitive neuroscience of visual object recognition;data mining;database;information retrieval;information system	Web+IR	-12.067323886021727	-58.971958333858936	126647
4a631192b69fe3650cb6b469f769f20f711479b3	developing smart video semantic sensors	front end;image recognition;video surveillance;video signal processing;surveillance;real time;distributed processing;distributed computing;video signal processing distributed processing feature extraction image recognition image sensors intelligent sensors surveillance;intelligent sensors humans video surveillance storage automation real time systems sensor systems feature extraction streaming media distributed processing time factors;image sensors;video recognition;feature extraction;automatic semantic understanding;distributed processing smart video semantic sensors video surveillance systems feature extraction automatic semantic understanding video recognition;video surveillance systems;smart video semantic sensors;intelligent sensors	While most video surveillance systems have centralized architectures that transmit videos to a central location for storage or real-time interpretation by human operators, a novel development of smart video sensors can significantly reduce the transmission load by extracting feature streams of videos that are enough for automatic semantic understanding. The overall video recognition processes are distributed into front-end sensors and back-end classifiers. Such distributed processing mechanism would significantly alleviate mundane or time-critical activities performed by human operators, and provide better network scalability. In this paper, we describe our implementation of smart video semantic sensors, which capture the context feature of the environments of the user. These sensors are used for recognizing the scenes, objects and events of the environment	centralized computing;closed-circuit television;distributed computing;real-time locating system;scalability;sensor;window of opportunity	Victor Sutan;Jason Cardillo;Ching-Yung Lin	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1692636	computer vision;speech recognition;feature extraction;computer science;front and back ends;video tracking;image sensor;multimedia;intelligent sensor	Embedded	-8.853342026567075	-63.66534168266673	126758
949888100600f4b16171931e4e4bce4c41a2975d	text modeling using multinomial scaled dirichlet distributions		The Dirichlet Compound Multinomial (DCM), the composition of the Dirichlet and the multinomial, is a widely accepted generative model for text documents that takes into account burstiness. However, recent research showed that the Dirichlet is not the best to be chosen as a prior to multinomial. In this paper, we propose a novel model called the Multinomial Scaled Dirichlet (MSD) distribution that is the composition of the scaled Dirichlet distribution and the multinomial. Moreover, we investigate the Expectation Maximization (EM) with the MSD mixture model as a new clustering algorithm for documents. Experiments show that the new model is competitive with the best state-of-the-art methods on different text data sets.	multinomial logistic regression	Nuha Zamzami;Nizar Bouguila	2018		10.1007/978-3-319-92058-0_7	mixture model;cluster analysis;generative model;expectation–maximization algorithm;dirichlet distribution;burstiness;multinomial distribution;data set;mathematics;artificial intelligence;pattern recognition	NLP	-16.954639047510074	-63.31384569102589	127731
264228e5420529c4b989330824452faba9ce09af	substructure searching on very large files by using multiple storage techniques	informatica;etude theorique;stockage donnee;subestructura;algorithme;algorithm;data storage;structure moleculaire;estructura datos;sous structure;computer aid;substructure;estudio teorico;almacenamiento datos;asistencia ordenador;informatique;structure donnee;computer science;theoretical study;estructura molecular;data structure;assistance ordinateur;algoritmo;molecular structure			Alexander Bartmann;Helmut Maier;Dirk Walkowiak;Bernard Roth;Martin G. Hicks	1993	Journal of Chemical Information and Computer Sciences	10.1021/ci00014a002	data structure;molecule;substructure;computer science;artificial intelligence;computer data storage;mathematics;algorithm;quantum mechanics	DB	-6.56949488123324	-54.37237838660378	127929
d7d388b210ce8bd95c601d5fd60a6bfd4f4e84cb	semantic consistency hashing for cross-modal retrieval	cross modal retrieval;semantic consistency;hashing;non negative matrix factorization;neighbor preserving	The task of cross-modal retrieval is to query similar objects in dataset of multi-modality, such as using text to query images and vice versa. However, most of existing works suffer from high computational complexity and storage cost in large-scale applications. Recently, hashing method mapping the high-dimensional data to compact binary codes has attracted a lot of concerns due to its efficiency and low storage cost over large-scale dataset. In this paper, we propose a Semantic Consistency Hashing (SCH) method for cross-modal retrieval. SCH learns a shared semantic space simultaneously taking both inter-modal and intra-modal semantic correlations into account. In order to preserve the inter-modal semantic consistency, an identical representation is learned using non-negative matrix factorization for the samples with different modalities. Meanwhile, neighbor preserving algorithm is adopted to preserve the semantic consistency in each modality. In addition, an effective optimal algorithm is proposed to reduce the time complexity from traditional O ( N 2 ) or higher to O(N). Extensive experiments on two public datasets demonstrate that the proposed approach significantly outperforms the existing schemes.	hash function;modal logic	Tao Yao;Xiangwei Kong;Haiyan Fu;Qi Tian	2016	Neurocomputing	10.1016/j.neucom.2016.02.016	hash function;computer science;theoretical computer science;machine learning;data mining;mathematics;non-negative matrix factorization;information retrieval	Web+IR	-15.420472846937884	-64.57624866730488	128063
ebb3bdd3d94c829207a158dbb083fb5ba94f21ec	automatic live sport video streams curation system from user generated media	supervised learning;real time video content curation;cgm consumer generated media;random forests;live sport broadcast	"""Emerging Internet of Things IoT technologies will allow spectators in a sport game to produce various video streams from various angles. With existing technologies, however, it is difficult to process massive and various data streams for multi-channel contents in real-time. To solve this problem, we aim to construct a software agent called """"Curator"""" that compiles video contents automatically according to his/her values. In this paper, we propose a system to automatically switch multiple video streams that general sports spectators have taken using Random Forests classifier. Meta data such as image feature data and game progress data is extracted for each video scene as the input of the classifier. For evaluation, we constructed a camera switching timing estimation model using the live TV broadcast of some baseball game data. A video of another baseball game was curated with the constructed model. As a result, our system predicted the camera switching timing with accuracy F-measure of 85.3% on weighted average for the base camera work and 99.7% for the fixed camera work."""	digital curation;streaming media	Kazuki Fujisawa;Yuko Hirabe;Hirohiko Suwa;Yutaka Arakawa;Keiichi Yasumoto	2016	IJMDEM	10.4018/IJMDEM.2016040103	random forest;computer vision;simulation;computer science;machine learning;video tracking;multimedia;video processing;supervised learning;world wide web	HPC	-15.172603357113006	-53.001908990600356	128141
77df56865255f195ee5122d857e7b3d6d3868349	identification of executable files on the basis of statistical criteria		The paper considers methods of identification of executable signatures using statistical criteria. Identification here should be understood as a process of file recognition by establishing its coincidence with a particular program. New ways to creation of executable file signatures are considered. A new approach to identification of elf-files based on the Chi-square and Kolmogorov-Smirnov criteria is offered. Restrictions and conditions of using these criteria are considered. The proposed method can be used to audit data-storage medium.	antivirus software;chi;executable	Irina E. Krivtsova;Ilya S. Lebedev;Kseniya I. Salakhutdinova	2017	2017 20th Conference of Open Innovations Association (FRUCT)	10.23919/FRUCT.2017.8071312	data mining;database;executable;computer science;audit	SE	-7.633916498599379	-53.582124424825196	128800
b0894a3fbe4d81d12878fae113de6cdfd5b9f57a	a video forensic framework for the unsupervised analysis of mp4-like file container		Video forensics keeps developing new technologies to verify the authenticity and the integrity of digital videos. While most of the existing methods rely on the analysis of the video data stream, recently, a new line of research was introduced to investigate video life cycle based on the analysis of the video container. Anyway, existing contributions in this field are based on manual comparison of video container structure and content, which is time demanding and error-prone. In this paper, we introduce a method for unsupervised analysis of video file containers, and present two main forensic applications of such method: the first one deals with video integrity verification, based on the dissimilarity between a reference and a query file container; the second one focuses on the identification and classification of the source device brand, based on the analysis of containers structure and content. Noticeably, the latter application relies on the likelihood-ratio framework, which is more and more approved by the forensic community as the appropriate way to exhibit findings in court. We tested and proved the effectiveness of both applications on a dataset composed by 578 videos taken with modern smartphones from major brands and models. The proposed approaches are proved to be valuable also for requiring an extremely small computational cost as opposed to all available techniques based on the video stream analysis or manual inspection of file containers.	adobe flash;algorithmic efficiency;atom;cognitive dimensions of notations;computation;digital video;experiment;lr parser;like button;smartphone;spatial variability;streaming media;video life;writing commons;xml	Massimo Iuliani;Dasara Shullani;Marco Fontani;Saverio Meucci;Alessandro Piva	2019	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2018.2859760	artificial intelligence;data stream;computer vision;data mining;metadata;computer science	Visualization	-9.755808481626326	-62.44268945154773	129018
89f6eb4366316d8e82a54bca6a78ef932cc138ff	basis set exchange: a community database for computational sciences	general and miscellaneous mathematics computing and information science;information systems;selected works;availability;computer model;web accessibility;internet;quantum mechanics;web portal;bepress;utility computing;websites	Basis sets are some of the most important input data for computational models in the chemistry, materials, biology, and other science domains that utilize computational quantum mechanics methods. Providing a shared, Web-accessible environment where researchers can not only download basis sets in their required format but browse the data, contribute new basis sets, and ultimately curate and manage the data as a community will facilitate growth of this resource and encourage sharing both data and knowledge. We describe the Basis Set Exchange (BSE), a Web portal that provides advanced browsing and download capabilities, facilities for contributing basis set data, and an environment that incorporates tools to foster development and interaction of communities. The BSE leverages and enables continued development of the basis set library originally assembled at the Environmental Molecular Sciences Laboratory.	basis set (chemistry);biological systems engineering;breast self-examination;browsing;community;computation;computational model;contribution;curation;download;encephalopathy, bovine spongiform;needle-exchange programs;quantum mechanics;science	Karen Schuchardt;Brett T. Didier;Todd Elsethagen;Lisong Sun;Vidhya Gurumoorthi;Jared Chase;Jun Li;Theresa L. Windus	2007	Journal of chemical information and modeling	10.1021/ci600510j	computer simulation;availability;the internet;computer science;bioinformatics;theoretical computer science;machine learning;web accessibility;data mining;utility computing;world wide web;information system;quantum mechanics	DB	-7.410761763299705	-57.612587008975545	129111
1b14e66cf5d79761b7c22c6549d101c05ac0bf66	a twofold-lda model for customer review analysis	unsupervised learning;generic model;topic modelling senitment analysis;computer model;resource manager;text analysis;latent dirichlet allocation;domain knowledge;mathematical model computational modeling resource management tv image quality analytical models markov processes;senitment analysis;image quality;user friendly chart twofold lda model customer review analysis latent dirichlet allocation model unsupervised generative model text modelling graphical form;markov process;mathematical model;unsupervised learning customer profiles text analysis;topic modelling;customer profiles;analytical model	The Latent Dirichlet Allocation model is an unsupervised generative model that is widely used for topic modelling in text. We propose to add supervision to the model in the form of domain knowledge to direct the focus of topics to more relevant aspects than the topics produced by standard LDA. Experimental results demonstrate the effectiveness of our method. We also propose a novel Twofold-LDA model to improve the current output of LDA in order to visualize results in graphical form, which can ultimately be used by potential customers. Experiments show the benefit of this new output, with the ability to produce topics focused on our desired aspects in a user friendly chart.	generative model;latent dirichlet allocation;linear discriminant analysis;usability	Nicola Burns;Yaxin Bi;Terry J. Anderson	2011	2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2011.73	image quality;latent dirichlet allocation;unsupervised learning;computer science;data science;machine learning;mathematical model;data mining;markov process;topic model;domain knowledge	AI	-17.158690481722093	-63.59382323758168	129574
e5442ca82d325d8224bb1d866bb2d6e593e759da	topic discovery from heterogeneous texts	rockets;companies;solid modeling;mobile communication;computer science;headphones;twitter	Recently many topic models such as Latent Dirich-let Allocation (LDA) have made important progress towards generating high-level knowledge from a large corpus. They assume that a text consists of a mixture of topics, which is usually the case for regular articles but may not hold for a short text that usually contains only one topic. In practice, a corpus may include both short texts and long texts, in this case neither methods developed for only long texts nor methods for only short texts can generate satisfying results. In this paper, we present an innovative method to discover latent topics from a heterogeneous corpus including both long and short texts. A new topic model based on collapsed Gibbs sampling algorithm is developed for modeling such heterogeneous texts. The experiments on real-world datasets validate the effectiveness of the proposed model in comparison with other state-of-the-art models.	algorithm;experiment;gibbs sampling;high- and low-level;sampling (signal processing);text corpus;topic model	Jipeng Qiang;Ping Chen;Wei Ding;Tong Wang;Fei Xie;Xindong Wu	2016	2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)	10.1109/ICTAI.2016.0039	natural language processing;mobile telephony;computer science;artificial intelligence;data science;machine learning;data mining;solid modeling	AI	-16.974429739519817	-64.36840232080557	129733
f6469489a0c95abbdbc8b2761d0b1ce0ffa3936b	linguistic geometries for unsupervised dimensionality reduction	high dimensionality;domain knowledge;dimensional reduction	Text documents are complex high dimensional objects. To effectively visualize such data it is important to reduce its dimensionality and visualize the low dimensional embedding as a 2-D or 3-D scatter plot. In this paper we explore dimensionality reduction methods that draw upon domain knowledge in order to achieve a better low dimensional embedding and visualization of documents. We consider the use of geometries specified manually by an expert, geometries derived automatically from corpus statistics, and geometries computed from linguistic resources.	dimensionality reduction	Yi Mao;Krishnakumar Balasubramanian;Guy Lebanon	2010	CoRR		computer vision;computer science;machine learning;data mining;domain knowledge	ML	-17.96932752380045	-60.51363224826302	129900
07f0b638b2109c19d18e89c5bc74ded73cb2117f	stanford i2v: a news video dataset for query-by-image experiments	video indexing;video dataset;query by image;video search	Reproducible research in the area of visual search depends on the availability of large annotated datasets. In this paper, we address the problem of querying a video database by images that might share some contents with one or more video clips. We present a new large dataset, called Stanford I2V. We have collected more than 3; 800 hours of newscast videos and annotated more than 200 ground-truth queries. In the following, the dataset is described in detail, the collection methodology is outlined and retrieval performance for a benchmark algorithm is presented. These results may serve as a baseline for future research and provide an example of the intended use of the Stanford I2V dataset. The dataset can be downloaded at http://purl.stanford.edu/zx935qw7203.	algorithm;baseline (configuration management);benchmark (computing);experiment;ground truth;stanford university centers and institutes;video clip	Andre F. de Araújo;Jason Chaves;David M. Chen;Roland Angst;Bernd Girod	2015		10.1145/2713168.2713197	computer science;data mining;world wide web;information retrieval	Vision	-15.98103718654193	-56.503267047946714	130054
3133b9e258400b0e1f38aee4ce3c6a8ebe624a36	object-based navigation: an intuitive navigation style for content-oriented integration environment	search engine;relationship among objects;information retrieval;content oriented integration;object level integration;multimedia data;world wide web;coir;object based navigation;directory service	In this paper, we present the idea of object-based navigation. Object-based navigation is a navigation style based upon the characteristics at the object level, that is contents of the objects and the relationship among the objects. With objectbased navigation, users can specify a set of objects and their relationship. The system creates queries from the users’ input and determines links dynamically based on matching between this query and indices. Various kinds of attributes including conceptual and media-based characteristics are integrated at the object level. We introduced this navigation style into the content-oriented integration environment to manage a large quantity of multimedia data. COIR (Content Oriented Information Retrieval tool), an object-based navigation tool for content-oriented integrated hypermedia systems is introduced. We show how this tool works in indexing and navigating multimedia data. Using COIR, we have developed the directory service systems for the World-Wide Web and have evaluated the navigational capability and extensibility of our tools. Multimedia search engines including COIR, extract the characteristics from multimedia data at any web site automatically. Extracted characteristics are connected with each other semiautomatically and utilized in the navigational stage. With this system, users can execute the navigation based on the relationship between objects as well as the contents of the objects. In this paper, we present how the COIR tool increases the navigational capabilities for hypermedia systems.	cluster analysis;dictionary;directory service;extensibility;hypermedia;information retrieval;matching (graph theory);object-based language;systems design;usability;web search engine;world wide web	Kyoji Hirata;Sougata Mukherjea;Yusaku Okamura;Wen-Syan Li;Yoshinori Hara	1997		10.1145/267437.267446	computer vision;directory service;computer science;multimedia;world wide web;mobile robot navigation;search engine	DB	-12.868157262246465	-57.64812522080341	130352
73be93b200930ede5a7bbc66ec324619a54c0223	image retrieval by ontological description of shapes (irons), early results	information retrieval;image retrieval ontologies shape iron information retrieval content based retrieval multimedia systems computer science animation internet;iron;visual information retrieval;multimedia systems;internet;shape;animation;ontologies;computer science;content based image retrieval;content based retrieval;image retrieval	This paper addresses the problem of retrieving documents that contain visual information. Current visual information retrieval systems sometimes retrieve irrelevant documents or documents unrelated to the user¿s query. This problem is caused by the use of low-level image descriptors; furthermore, these descriptors hardly have a semantic weight. In this work we address the image retrieval problem based on shape, since shape has a meaning by itself. On the other hand, an extension of the ontology concept, which is used in information retrieval based on text, is proposed in the image domain. Likewise, we present the Image Retrieval by Ontological Description of Shapes (IRONS) System. IRONS has been implemented and evaluated in order to analyze its utility, efficiency, and advantages comparing with well-known systems.	high- and low-level;image retrieval;information retrieval;relevance;visual descriptor	Alberto Chávez-Aragón;Oleg Starostenko	2004	First Canadian Conference on Computer and Robot Vision, 2004. Proceedings.	10.1109/CCCRV.2004.1301465	document retrieval;computer vision;query expansion;visual word;relevance;cognitive models of information retrieval;image retrieval;shape;computer science;artificial intelligence;concept search;adversarial information retrieval;multimedia;iron;automatic image annotation;vector space model;data retrieval;information retrieval;human–computer information retrieval	Vision	-13.415211342418363	-57.94493808075926	130417
263c9033357ea000a28d5227ce783c6534fc7051	multi-objective test report prioritization using image understanding	software;test report prioritization;spm multiobjective test report prioritization image understanding crowdsourced software testing software maintenance task text based test report classification mobile testing domain screenshots descriptive text natural language text information mobile applications spatial pyramid matching;image understanding;multi objective optimization;testing;inspection;mobile applications;text analysis image classification image matching mobile computing natural language processing program testing;multi objective optimization crowdsourced testing test report prioritization image understanding;image color analysis;mobile communication;testing mobile communication computer bugs software mobile applications image color analysis inspection;computer bugs;crowdsourced testing	In crowdsourced software testing, inspecting the large number of test reports is an overwhelming but inevitable software maintenance task. In recent years, to alleviate this task, many text-based test-report classification and prioritization techniques have been proposed. However in the mobile testing domain, test reports often consist of more screenshots and shorter descriptive text, and thus text-based techniques may be ineffective or inapplicable. The shortage and ambiguity of natural-language text information and the well defined screenshots of activity views within mobile applications motivate our novel technique based on using image understanding for multi-objective test-report prioritization. In this paper, by taking the similarity of screenshots into consideration, we present a multi-objective optimization-based prioritization technique to assist inspections of crowdsourced test reports. In our technique, we employ the Spatial Pyramid Matching (SPM) technique to measure the similarity of the screenshots, and apply the natural-language processing technique to measure the distance between the text of test reports. Furthermore, to validate our technique, an experiment with more than 600 test reports and 2500 images is conducted. The experimental results show that image-understanding techniques can provide benefit to test-report prioritization for most applications.	computer vision;crowdsourcing;mathematical optimization;mobile app;multi-objective optimization;natural language;screenshot;software maintenance;software testing;super paper mario;text-based (computing);whole earth 'lectronic link	Yang Feng;James A. Jones;Zhenyu Chen;Chunrong Fang	2016	2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)	10.1145/2970276.2970367	computer vision;software bug;mobile telephony;inspection;computer science;operating system;software engineering;multi-objective optimization;data mining;software testing;world wide web	SE	-16.818269020181955	-59.829843271617094	130603
872ddf5d3fd45e064ae8c959ff3dc3f558ecaa74	gps, compass, or camera?: investigating effective mobile sensors for automatic search-based image annotation	mobile sensors;smart phone;image annotation;image search;ranking algorithm;feature fusion;content based image retrieval;geolocation;image retrieval	Recently, more and more types of sensors are being equipped on the smart phones, which provide different aspects into conside-ration. When a user takes a photo, the information it provides like the image content, the location and even the direction the user faces can help us to understand the photo itself. Each factor mentioned above can be treated as an input to the image search system. However, most existing algorithms for image retrieval (or annotation) only focus on the content and location information of the images yet completely ignore the important direction-facing factor and lack of the insights of the capabilities for the sensors. In this paper, we propose a novel ranking algorithm that can leverage different sensors with traditional content-based image retrieval system, and further apply to annotate images. We evaluate different combinations of sensors and investigate how the geolocation, image content and compass direction influence on image retrieval.	algorithm;automatic image annotation;baseline (configuration management);content-based image retrieval;geolocation;global positioning system;inverted index;sensor;smartphone	An-Jung Cheng;Fang-Erh Lin;Yin-Hsi Kuo;Winston H. Hsu	2010		10.1145/1873951.1874086	computer vision;feature detection;visual word;image processing;image retrieval;computer science;pattern recognition;geolocation;automatic image annotation;world wide web;information retrieval	Vision	-16.994614134852508	-58.52740442912825	131558
35153483de60f09cbf5f8908f4cc4ae52358f297	chemast: a computer program for modelling molecular structures.	computer program;molecular structure			C. D. Barry;Robert A. Ellis;S. M. Graesser;Garland R. Marshall	1971			computational science;computer program;computer science	Logic	-7.165224463686981	-55.788684070813055	131947
51cffa81d8c491b9c18fb99bd27fe94cd6e62970	feature selection for automatic image annotation	analisis imagen;modelizacion;anotacion;keyword;analisis estadistico;recherche image;image databank;automatic image annotation;weighting;interrogation base donnee;image database;interrogacion base datos;annotation;palabra clave;mot cle;image annotation;ponderacion;selection automatique;modelisation;classification a vaste marge;statistical analysis;seleccion automatica;banco imagen;banque image;analyse statistique;feature weighting;visual features;pattern recognition;image analysis;feature selection;ponderation;reconnaissance forme;support vector machine;maquina ejemplo soporte;query by example;vector support machine;reconocimiento patron;modeling;analyse image;database query;automatic selection;image retrieval	Automatic image annotation empowers the user to search an image database using keywords, which is often a more practical option than a query-by-example approach. In this work, we present a novel image annotation scheme which is fast and effective and scales well to a large number of keywords. We first provide a feature weighting scheme suitable for image annotation, and then an annotation model based on the one-class support vector machine. We show that the system works well even with a small number of visual features. We perform experiments using the Corel Image Collection and compare the results with a wellestablished image annotation system.	automatic image annotation;experiment;feature selection;query by example;support vector machine	Lokesh Setia;Hans Burkhardt	2006		10.1007/11861898_30	support vector machine;computer vision;feature detection;systems modeling;image retrieval;computer science;query by example;data mining;weighting;automatic image annotation;information retrieval	Vision	-12.528467915185978	-61.06533515733127	132048
b4a6484ca621a63cb0cdc202194ed43ced618b7e	a quantitative analysis of the performance of functional distributed architectures				Sergiu Zaporojan	1996	The Computer Science Journal of Moldova		theoretical computer science;discrete mathematics;mathematics;quantitative analysis (chemistry)	Logic	-7.432287494326284	-55.57880506661796	132134
cc3fd70f33956691a22c3c71cbfe9055222df431	ad hoc structured search over complex, high-throughput data sets, expressed in a restructurable, integrated form	high throughput		hoc (programming language);throughput	Daniel Korytina;Kenneth M. Anderson;Peter A. Graf;Wesley B. Jones;Glenn Murray	2009				ML	-6.146353043752709	-62.09283686512465	132218
a31dc273ce8d0e0b732ed5780ba696c6d69122bc	image retrieval using topological structure of user sketch	visual databases content based retrieval;image retrieval image databases information retrieval content based retrieval visual databases image converters computer science spatial databases query processing painting;prime edge graph image retrieval topological structure user sketch content based image retrieval system database visual information imperfect queries user drawn query image;content based image retrieval;content based retrieval;visual databases;image retrieval	Content-based image retrieval system retrieves an image from a database using visual information. Among approaches to express visual aspects in queries, “query by sketch” is most convenient and expressive. However, the query drawn by the user is typically quite different from the original image and makes it difficult to retrieve the intended image effectively. In this paper, a new method to retrieve the intended image from imperfect queries is presented. The user-drawn query image is converted to a prime edge graph that represents the topological structure of the objects in the image. The experimental result show that the system retrieves the intended image even from a partial or shifted query.	content-based image retrieval;line graph	Sue J. Cho;Suk I. Yoo	1998		10.1109/ICSMC.1998.727574	computer vision;feature detection;query expansion;visual word;image map;image retrieval;computer science;database;automatic image annotation;information retrieval;query language;human–computer information retrieval	Web+IR	-12.194282372361638	-58.11189718305872	132284
c916eacdd7a8eec31be80937df319f1d11346a4f	tree structure operation for video editing utilizing image recognition technology	tree structure operation;recognition technology;utilizing image;image recognition;tree structure	This paper proposes an approach to integrate image recognition technology into nonlinear video editing system and discusses the results of a prototype development. The prototype consists of five support functions for video editing; automatic scene separation during disk recording, tree structure story editing, quick review with micon, film metaphor interface and integrated information management. The automatic scene separation is the exact solution for the complaint of the current system users. The tree structure story editing and the integrated information management provide methods to author video structure in several different detail levels and relieves the constrain of limited size of the window. The quick review with micon is a convenient shot comparison method. The film metaphor interface offers a intuitive and speedy operation for video strings.	computer vision;tree structure	Hirotada Ueda;Takafumi Miyatake	1997			computer vision;post-production;computer science;artificial intelligence;operating system;video tracking;multimedia;tree structure;computer graphics (images);non-linear editing system	Vision	-14.508894458242644	-54.45867583342006	133195
a2b5417120337c4ab4b1435c15ba8c28067469e6	dot plot sequence comparisons on macintosh computers	software;sequence comparison;representation graphique;logiciel;representacion grafica;estudio comparativo;secuencia nucleotido;nucleotide sequence;sequence nucleotide;etude comparative;homology;comparative study;logicial;acido nucleico;acide nucleique;homologia;nucleic acid;graphics;homologie	Dotty Plotter is a Macintosh program for viewing dot matrix comparisons of sequences in molecular biology. Dotty Plotter, written in MPW pascal and C, takes advantage of the excellent windowing and graphics capabilities of Apple Macintosh computers to provide an easy to use but sophisticated sequence comparison		D. G. Gilbert	1990	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/6.2.117	biology;nucleic acid;homology;nucleic acid sequence;computer science;bioinformatics;graphics;comparative research;genetics;algorithm;computer graphics (images)	Theory	-4.582836222967938	-56.41165609085177	133252
3bb75598f09cbfe66c6ab8754ede08459b54a3d4	temporal event clustering for digital photo collections	photo collection;temporal media indexing and segmentation;test collection;learning vector quantization;digital photo organization	We present similarity-based methods to cluster digital photos by time and image content. The approach is general, unsupervised, and makes minimal assumptions regarding the structure or statistics of the photo collection. We present results for the algorithm based solely on temporal similarity, and jointly on temporal and content-based similarity. We also describe a supervised algorithm based on learning vector quantization. Finally, we include experimental results for the proposed algorithms and several competing approaches on two test collections.	algorithm;cluster analysis;digital photography;learning vector quantization;unsupervised learning	Matthew L. Cooper;Jonathan Foote;Andreas Girgensohn;Lynn Wilcox	2003		10.1145/957013.957093	computer vision;learning vector quantization;computer science;machine learning;data mining;information retrieval	AI	-17.50010880067251	-58.77967380129074	133337
a9ba9ae5397e5c4c7df70e53c6b1295a2bbaddde	a general method for drawing area-proportional euler diagrams	hierarchical data;qa 76 software;information visualization;area proportional;non hierarchical data visualization;computer programming;general methods;g100 mathematics;venn diagrams;euler diagrams	Area-proportional Euler diagrams have many applications, for example they are often used for visualizing data in medical and biological domains. There have been a number of recent research efforts to automatically draw Euler diagrams when the areas of the regions are not considered, leading to a range of different drawing techniques. By contrast, substantially less progress has been made on the problem of automatically drawing area-proportional Euler diagrams, although some partial results have been derived. In this paper, we considerably advance the state-of-the-art in area-proportional Euler diagram drawing by presenting the first method that is capable of generating such a diagram given any area-proportional specification. Moreover, our drawing method is sufficiently flexible that it allows one to specify which of the typically enforced wellformedness conditions should be possessed by the to-be-drawn Euler diagram.	algorithm;contour line;diagram;emoticon;euler;euler–lagrange equation;expectation propagation;heuristic (computer science);inductive reasoning;universal quantification;user (computing)	Gem Stapleton;Peter Rodgers;John Howse	2011	J. Vis. Lang. Comput.	10.1016/j.jvlc.2011.07.001	venn diagram;information visualization;interaction overview diagram;computer science;theoretical computer science;computer programming;programming language;algorithm	AI	-7.526209197545494	-60.64867383593282	133664
aa6dff96f5d2901982c6de4d1ed330af38bcfa50	organization and retrieval of continuous media	nearest feature line nfl;continuous media;color histogram;table of contents;indexation;key frame extraction;content based retrieval	Because of the media digitization, a large amount of information such as speech, audio and video data is produced everyday. In order to retrieve data quickly and precisely from these databases, multimedia technologies for organizing and retrieving of speech, audio and video data are strongly required. In this paper, we overview the multimedia technologies such as organization and retrieval of speech, audio and video data, speaker indexing, audio summarization and cross media retrieval existing today. The main purpose of the organization is to produce tables of contents and indices from audio and video data automatically. In order to make these technologies feasible, first, processing units such as words on audio data and shots on video data are extracted. On a second step, they are meaningfully integrated into topics. Furthermore, the units extracted from different types of media are integrated for higher functions.	database;digital media;monkey's audio;organizing (structure);table (database)	Yasuo Ariki	2000		10.1145/357744.357945	audio mining;speech recognition;computer science;multimedia;information retrieval	DB	-13.84336915818758	-54.54422606207526	135075
94e9cf8ba166357198b1e7f8a8ef37c13eca0c10	text based approach for indexing and retrieval of image and video: a review		Text data present in multimedia contain useful information for automatic annotation, indexing. Extracted information used for recognition of the overlay or scene text from a given video or image. The Extracted text can be used for retrieving the videos and images. In this paper, firstly, we are discussed the different techniques for text extraction from images and videos. Secondly, we are reviewed the techniques for indexing and retrieval of image and videos by using extracted text.	algorithm;color;information extraction;java annotation;text corpus;text-based (computing);texture mapping	Avinash N. Bhute;B. B. Meshram	2014	CoRR		computer vision;visual word;noisy text analytics;multimedia;information retrieval	Vision	-13.927932424018454	-57.547535325279284	135121
2a97bcbd5576fe09bfd50b4464fac9e08f3278ce	video indexing: an approach based on moving object and track	databases;moving object;interfaces;multimedia;video indexing;visualization;indexation;man machine interface;video;access method	With the progression of multimedia technology and the trend of visualization of man-machine interface, video data will become a kind of fundamental resource of data as general as text and graphics. When the data size is large, retrieving data will become a time-consuming process. Much research has been done to facilitate the retrieval of data, e.g., indexes in a database. Similarly, the video data also encounter the same problem. It is very difficult to generate video indexes automatically, because the index is application-dependent and only the user knows what indexes he actually needs. In this paper a mechanism for video data indexing is proposed which is based on the concept of objects and object motion with interactive annotation. This mechanisms provides an efficient method to access video substance without browsing the whole video data. A motion representation for the track of a moving object is presented. The access methods of video queries are introduced. A prototype of the video indexing system is implemented.© (1993) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Suh-Yin Lee;Huan-Ming Kao	1993		10.1117/12.143653	video compression picture types;human–machine interface;microsoft video 1;video;visualization;computer science;video tracking;interface;database;multimedia;video processing;smacker video;motion compensation;video post-processing;access method;world wide web	Vision	-14.410816915145693	-54.34398036977982	135924
f6f1675e2993bb01d6549b0e2c548f580f350239	towards fusion of textual and visual modalities for describing audiovisual documents	recognition;localisation;semantic;description;neural network	Audiovisual documents provide a wide range of content description through more descriptors from different media types. Indeed, the extraction of these descriptions has received an increasing attention. But, the lack of semantic description always persists. In fact, this lack affects the retrieval process. To address this problem, this paper describes an automatic and semantic description of cinematic audiovisual documents. This description is based not only on the audiovisual flux in this post-production phase but also in the documentation in the pre-production phase by using textual and visual modalities. In this context, to extract content description, we find it is essential to extract texts superposed in the image. This process is mainly based on the neural network classifier. Moreover, an effective OCR (Tesseract) is adapted for texts recognition. Experiments results confirmed the interesting performance through two databases, namely, “ICDAR 2011” and our own created database from the Internet Movie Database Imdb. Towards Fusion of Textual and Visual Modalities for Describing Audiovisual Documents	artificial neural network;data descriptor;documentation;international conference on document analysis and recognition;internet movie database (imdb);optical character recognition;quantum superposition;tesseract	Manel Fourati;Anis Jedidi;Hanen Ben Hassin;Faïez Gargouri	2015	IJMDEM	10.4018/IJMDEM.2015040104	natural language processing;computer science;machine learning;multimedia;information retrieval;artificial neural network	Web+IR	-14.369165615974845	-57.830228977792984	136033
3ca2994a20b73eb6c056ce2c544b97ba2ec6e731	visual-semantic graphs: using queries to reduce the semantic gap in web image retrieval	semantic similarity;image features;search engine;user feedback;content based image features;query log analysis;web image search;semantic gap;graph representation;web image re ranking;image retrieval	We explore the application of a graph representation to model similarity relationships that exist among images found on the Web. The resulting similarity-induced graph allows us to model in a unified way different types of content-based similarities, as well as semantic relationships. Content-based similarities include different image descriptors, and semantic similarities can include relevance user feedback from search engines. The goal of our representation is to provide an experimental framework for combining apparently unrelated metrics into a unique graph structure, which allows us to enhance the results of Web image retrieval. We evaluate our approach by re-ranking Web image search results.	graph (abstract data type);image retrieval;relevance;visual descriptor;web search engine;world wide web	Barbara Poblete;Benjamin Bustos;Marcelo Mendoza;Juan Manuel Barrios	2010		10.1145/1871437.1871670	semantic similarity;visual word;semantic search;image retrieval;computer science;social semantic web;data mining;semantic web stack;graph;web search query;automatic image annotation;world wide web;feature;information retrieval;semantic gap;search engine	Web+IR	-15.929985132446314	-58.65331529964753	136174
80985b63ec30b8ad1d3d0c1f46d3c78621d0b4dd	scene extraction for video clips based on the relation of text, pointing region and temporal duration of user comments	video databases;video sharing web sites;multimedia;prototypes;user comments;video sharing web sites video clips extraction scene extraction user comments text relation pointing region temporal duration text analysis nontext analysis;video retrieval;text analysis;data mining;scene extraction;video clips extraction;pointing region;text relation;layout video sharing displays databases expert systems text analysis prototypes youtube games image analysis;web sites content based retrieval text analysis user interfaces video databases video retrieval;synchronization;feature extraction;games;web sites;video sharing;temporal duration multimedia video sharing scene extraction user comments pointing region;tv;nontext analysis;content based retrieval;user interfaces;temporal duration	Recently, video sharing websites that allow users to attach comments to video clips have attracted much attention. In this paper, we propose a method whereby users can easily retrieve video scenes relevant to their interest. Our system makes both a text and non-text analysis of a user's comment and then retrieves and displays relevant scenes for viewing of the scenes along with attached comments. The text analysis works in tandem with non-text features, namely, the pointing region and temporal duration of user comments. In this way, our system supports a better organized retrieval of scenes that have attached user comments with a higher degree of relevancy for the user than is currently available with conventional methods, for example, using matching keywords. We describe here our method and the relation between the scenes and discuss a prototype system.	pattern matching;prototype;relevance;video clip	Shoko Wakamiya;Daisuke Kitayama;Kazutoshi Sumiya	2009	2009 20th International Workshop on Database and Expert Systems Application	10.1109/DEXA.2009.54	games;synchronization;text mining;feature extraction;computer science;data mining;prototype;multimedia;user interface;world wide web;information retrieval	HCI	-15.313773334478036	-54.425280063784804	136325
f1dee718dd57098ae179add4fb7e1bf87b3d18c9	gemma - a grid environment for microarray management and analysis in bone marrow stem cells experiments	gene expression profile;microarray data;grid portal;drug discovery;bone marrow;large dataset;web interface;clinical diagnosis;stem cell;grid;microarray analysis;gene expression analysis;microarray;biological data;grid computing;mesenchymal stem cells;bioinformatics;mesenchymal stem cell	Microarray techniques are successfully used to investigate thousands gene expression profiling in a variety of genomic analyses such as gene identification, drug discovery and clinical diagnosis, providing a large amount of genomic data for the overall research community. A Grid based Environment for distributed Microarray data Management and Analysis (GEMMA) is being built. This platform is planned to provide shared, standardized and reliable tools for managing and analyzing biological data related to bone marrow stem cell cultures, in order to maximize the results of distributed experiments. Different microarray analysis algorithms may be offered to the end-user, through a web interface. A set of modular and independent applications may be published on the portal, and either single algorithms or a combination of them might be invoked by the user, through a workflow strategy. Services may be implemented within an existing Grid computing infrastructure to solve problems concerning both large datasets storage (data intensive problem) and large computational times (computing intensive problem). Moreover, experimental data annotation may be collected according to the same rules and stored through the Grid portal, by using a metadata schema, which allows a comprehensive and replicable sharing of microarray experiments among different researchers. The environment has been tested, so far, as regards performance results concerning Grid parallelization of a microarray based gene expression analysis. First results show a very promising speedup ratio. c © 2006 Elsevier B.V. All rights reserved.	algorithm;bioinformatics;computation;computer data storage;data-intensive computing;experiment;gene expression profiling;grid computing;microarray;parallel computing;speedup;user interface	Francesco Beltrame;Adam Papadimitropoulos;Ivan Porro;Silvia Scaglione;Andrea Schenone;Livia Torterolo;Federica Viti	2007	Future Generation Comp. Syst.	10.1016/j.future.2006.07.008	microarray analysis techniques;gene chip analysis;computer science;bioinformatics;data mining;mesenchymal stem cell;world wide web	HPC	-5.489275672263134	-53.29575890620496	136428
3c73f4c58da8127e590776283e7fa3976f17bd97	a multi-facetted visual analytics tool for exploratory analysis of human brain and function datasets	fmri;exploratory analysis;python;mri;exploratorory analysis;visual analytics;human brain;cohort studies;tractography;data driven research	Brain research typically requires large amounts of data from different sources, and often of different nature. The use of different software tools adapted to the nature of each data source can make research work cumbersome and time consuming. It follows that data is not often used to its fullest potential thus limiting exploratory analysis. This paper presents an ancillary software tool called BRAVIZ that integrates interactive visualization with real-time statistical analyses, facilitating access to multi-facetted neuroscience data and automating many cumbersome and error-prone tasks required to explore such data. Rather than relying on abstract numerical indicators, BRAVIZ emphasizes brain images as the main object of the analysis process of individuals or groups. BRAVIZ facilitates exploration of trends or relationships to gain an integrated view of the phenomena studied, thus motivating discovery of new hypotheses. A case study is presented that incorporates brain structure and function outcomes together with different types of clinical data.	brain;cognitive dimensions of notations;data sources;exploratory testing;facet (geometry);interactive visualization;neuroscience discipline;numerical analysis;numerous;programming tool;real-time transcription;visual analytics	Diego A. Angulo;Cyril Schneider;James H. Oliver;Nathalie Charpak;José T. Hernández	2016		10.3389/fninf.2016.00036	visual analytics;radiology;python;computer science;bioinformatics;data science;tractography;data mining	Visualization	-6.628639225061437	-61.472373406922635	136525
69b5827f5aeec6390b4464f6bb3700d4aac9afda	context-sensitive processing of semantic queries in an image database system	databases;base donnee;comparative analysis;image databank;user interface;information retrieval;abstract reasoning;relation semantique;query formulation;relacion semantica;image database;database;base dato;semantics;formulacion pregunta;image;matching function;formulation question;automatic recognition;recherche documentaire;mathematical formulas;imagen;banco imagen;banque image;recuperacion documental;tables data;pattern recognition;semantic relation;document retrieval;reconnaissance forme;reconocimiento patron;reconocimiento automatico;reconnaissance automatique;image retrieval	Abstract   In an image database environment, an image can be retrieved using common names (labels) of entities that appear in it (such as  door, book, car , …, etc.). In many cases, we specify further details of these entities and some relations between them. A semantic query is the formal expression method of label-based image retrieval requests. This paper shows how an image is abstracted into a hierarchy of entity names and  features  (such as brightness, length, …, etc.), and how relations are established between entities visible in the image. Semantic queries are also hierarchical. However, they are short and often overlook certain levels of the abstraction of the requested image. The core of this paper is a fuzzy matching technique that compares semantic queries to image abstractions by assessing the similarity of contexts between the query and the candidate image. An important objective of this matching technique is to distinguish between abstractions of different images that have the same labels but are different in context from each other. Each image is tagged with a matching degree (against the query) even when it does not provide an exact match of the query. Several experiments have been conducted to evaluate the strategy presented in this paper.		Hussain Sabri Shakir;Makoto Nagao	1996	Inf. Process. Manage.	10.1016/0306-4573(96)00011-8	document retrieval;qualitative comparative analysis;formula;image retrieval;computer science;image;data mining;database;semantics;abstraction;user interface;world wide web;information retrieval	DB	-12.058639965187881	-59.1822162543609	136577
2c3aef8b9f66d4e12bd7b228579e0ea298f7c2e3	a joint model for discovering and linking entities	entity linking;entity resolution;coreference	Entity resolution, the task of automatically determining which mentions refer to the same real-world entity, is a crucial aspect of knowledge base construction and management. However, performing entity resolution at large scales is challenging because (1) the inference algorithms must cope with unavoidable system scalability issues and (2) the search space grows exponentially in the number of mentions. Current conventional wisdom has been that performing coreference at these scales requires decomposing the problem by first solving the simpler task of entity-linking (matching a set of mentions to a known set of KB entities), and then performing entity discovery as a post-processing step (to identify new entities not present in the KB). However, we argue that this traditional approach is harmful to both entity-linking and overall coreference accuracy. Therefore, we embrace the challenge of jointly modeling entity-linking and entity-discovery as a single entity resolution problem. In order to make progress towards scalability we (1) present a model that reasons over compact hierarchical entity representations, and (2) propose a novel distributed inference architecture that does not suffer from the synchronicity bottleneck which is inherent in map-reduce architectures. We demonstrate that more test-time data actually improves the accuracy of coreference, and show that joint coreference is substantially more accurate than traditional entity-linking, reducing error by 75%.	algorithm;entity linking;knowledge base;mapreduce;scalability;synchronicity;video post-processing	Michael L. Wick;Sameer Singh;Harshal Pandya;Andrew McCallum	2013		10.1145/2509558.2509570	computer science;artificial intelligence;machine learning;data mining	ML	-16.61832623643816	-66.10995132700607	136600
81655d4a662a42f8fb4326f554159641b92d4028	applying virtual reality to molecular graphics system	molecular simulation;molecular modeling;real time;virtual reality;binding site;computational chemistry;intermolecular interaction;graphics system;van der waals force;molecular docking	Molecular graphics can be thought of as a window to the computer through which the chemist expresses ideas for computational evaluation and receives results in an understandable form. Furthermore, with beautiful graphic images it can give out the realistic molecular model like a real thing in real world. Molecule has various properties including volume, electronic, van der Waals forces, etc. These properties are very important to understand the molecular world. So if the virtual reality tools are used, then the imaginary world can be studied intuitively by touching and feeling a tremendous amount of data. Computational chemistry generates such amount of molecular property data through supercomputing with molecular simulation experiment. One of the objects to investigate the molecular world is to understand the intermolecular interaction such as drug-receptor interaction. Another thing is to measure the geometrical data in molecular architecture. Virtual reality system provides the easiest way to meet these objects. This kind of simple system changes a numerical data set, which is very difficult to deal with, into a visible and understandable data set. Recently two functions of such a system were improved to get an insight into biomolecular interaction. The first one is a real time force generation during navigation in macromolecular environment. an cylindrical arrow shows the magnitude and direction of molecular force. The second one is to see a molecular vibration such as a concerted motion of the binding site in protein molecule. So one can understand the molecular shape change for drug-receptor docking procedure. But some problems which are difficult to solve still remain.	computational chemistry;dna binding site;docking (molecular);imaginary time;level of measurement;molecular dynamics;molecular graphics;molecular modelling;simulation;supercomputer;virtual reality	Chang No Yoon;Myung Hwan Chi;Heedong Ko;Jongsei Park	1996	Journal of Computer Science and Technology	10.1007/BF02947218	molecular modelling;van der waals force;simulation;docking;computer science;binding site;molecular model;virtual reality	Visualization	-8.522034626360357	-56.721246919015016	136660
505ccdbda3165439c899534c082c7c03f19e6c66	automatic image semantic annotation based on image-keyword document model	busqueda informacion;document structure;analisis imagen;modelizacion;anotacion;image features;continuous time;discretisation;model based reasoning;lenguaje documental;semantic annotation;raisonnement base sur cas;text;raisonnement base sur modele;razonamiento fundado sobre caso;keyword;document model;image processing;estructura documental;customer relationship management;information re trieval;information retrieval;structure document;discretization;procesamiento imagen;temps continu;semantics;discretizacion;annotation;palabra clave;tiempo continuo;texte;mot cle;image annotation;semantica;semantique;traitement image;modelisation;langage documentaire;senal video;signal video;recherche information;gestion relation client;video signal;information language;image analysis;case based reasoning;texto;modeling;analyse image;language model	This paper presents a novel method of automatic image semantic annotation. Our approach is based on the Image-Keyword Document Model (IKDM) with image features discretization. According to IKDM, the image keyword annotation is conducted using image similarity measurement based on language model from text information retrieval domain. Through the experiments on a testing set of 5000 annotated images, our approach demonstrates great improvement of annotation performance compared with the known discretization-based image annotation model such as CMRM. Our approach also performs better in annotation time compared with the continuous model such as CRM.	information retrieval;java annotation	Xiangdong Zhou;Lian Chen;Jianye Ye;Qi Zhang;Baile Shi	2005		10.1007/11526346_22	natural language processing;computer vision;image analysis;image processing;image retrieval;computer science;artificial intelligence;discretization;semantics;temporal annotation;automatic image annotation;information retrieval;language model	NLP	-12.949782948840097	-61.524157182692534	136771
f38318d735643ab8258b20f3f68fba5d1f8727a0	co-occurrence based meta-analysis of scientific texts: retrieving biological relationships between genes	use;information biomedicale;hierarchical clustering;vocabulary controlled;information extraction;database management systems;vocabulary;cribado alta productividad;protein interaction mapping methods;biologia molecular;gen;proteins classification metabolism;methode;periodicals as topic;meta analysis;biomedical information;high throughput screening;artificial intelligent;meta analisis;utilisation;metaanalysis;information storage and retrieval methods;controlled;proteins;criblage haut debit;informacion biomedical;molecular biology;uso;protein classification;metaanalyse;text retrieval;gene;euclidean space;artificial intelligence;number;meta analysis as topic;protein interaction;protein interaction mapping;high throughput;nombre;metodo;database management system;information storage and retrieval;pubmed;method;natural language processing;numero;concept space;biologie moleculaire	MOTIVATION The advent of high-throughput experiments in molecular biology creates a need for methods to efficiently extract and use information for large numbers of genes. Recently, the associative concept space (ACS) has been developed for the representation of information extracted from biomedical literature. The ACS is a Euclidean space in which thesaurus concepts are positioned and the distances between concepts indicates their relatedness. The ACS uses co-occurrence of concepts as a source of information. In this paper we evaluate how well the system can retrieve functionally related genes and we compare its performance with a simple gene co-occurrence method.   RESULTS To assess the performance of the ACS we composed a test set of five groups of functionally related genes. With the ACS good scores were obtained for four of the five groups. When compared to the gene co-occurrence method, the ACS is capable of revealing more functional biological relations and can achieve results with less literature available per gene. Hierarchical clustering was performed on the ACS output, as a potential aid to users, and was found to provide useful clusters. Our results suggest that the algorithm can be of value for researchers studying large numbers of genes.   AVAILABILITY The ACS program is available upon request from the authors.	algorithm;cluster analysis;distance;experiment;extraction;hierarchical clustering;high-throughput computing;information source;test set;thesaurus;throughput;statistical cluster	Rob Jelier;Guido Jenster;Lambert C. J. Dorssers;C. Christiaan van der Eijk;Erik M. van Mulligen;Barend Mons;Jan A. Kors	2005	Bioinformatics	10.1093/bioinformatics/bti268	biology;meta-analysis;computer science;bioinformatics;artificial intelligence;data mining;mathematics;information extraction;statistics	Comp.	-6.0445525774999895	-55.85603640933935	136813
3d3cbf85f2a4c054dcebfdc91b4db3e31c4cea88	clipboard: a visual search and browsing engine for tablet and pc	visual concept;tablet pc;multi modal access;keyframe similarity	In this work, we present a handheld video browser that utilizes two methods of search; Concept Search and Keyframe Similarity. Concept Search allows a user to define a query using selected visual concepts and presents the user with a cluster of video segments based on extracted image features using OpponentSIFT. Keyframe Similarity has a dependance on the previous search for input criteria, allowing a user to select a keyframe for similarity search, returning three types of results; local keyframes from the current scene, global shot similarity based on visual features and text similarity of shots, based on frequently occurring words generated from ASR transcripts.	browsing;clipboard (computing);handheld game console;key frame;search algorithm;semantic similarity;similarity search;tablet computer;web search engine	David Scott;Jinlin Guo;Hongyi Wang;Yang Yang;Frank Hopfgartner;Cathal Gurrin	2012		10.1007/978-3-642-27355-1_65	computer vision;computer science;multimedia;world wide web	Vision	-15.688935030097326	-55.22432680589494	136953
337fab788f7afe7777002b86b91f7bd56dcddc51	classification of document pages using structure-based features	decision tree classifier;document structure;image features;estructura de documento;representation graphique;categorisation;text;domain specific modeling;decision tree;analisis estadistico;image databank;structure document;representacion grafica;layout problem;image database;probleme agencement;image classification;plant layout;texte;arbol decision;classification;similitude;planning installation;categorizacion;recherche documentaire;statistical analysis;banco imagen;banque image;analyse statistique;classification image;recuperacion documental;similarity;arreglo;autoorganizacion;problema disposicion;self organization;self organized map;document retrieval;arrangement;similitud;connected component;texto;proyecto instalacion;arbre decision;clasificacion;similarity search;autoorganisation;graphics;categorization	Searching for documents by their type or genre is a natural way to enhance the effectiveness of document retrieval. The layout of a document contains a significant amount of information that can be used to classify it by type in the absence of domain-specific models. Our approach to classification is based on “visual similarity” of layout structure and is implemented by building a supervised classifier, given examples of each class. We use image features such as percentages of text and non-text (graphics, images, tables, and rulings) content regions, column structures, relative point sizes of fonts, density of content area, and statistics of features of connected components which can be derived without class knowledge. In order to obtain class labels for training samples, we conducted a study where subjects ranked document pages with respect to their resemblance to representative page images. Class labels can also be assigned based on known document types, or can be defined by the user. We implemented our classification scheme using decision tree classifiers and self-organizing maps.	categorization;cellular automaton;color;column (database);connected component (graph theory);decision tree;document retrieval;experiment;graphics;machine learning;microsoft windows;organizing (structure);pixel density;relevance;self-organization;self-organizing map;semi-supervised learning	Christian K. Shin;David S. Doermann;Azriel Rosenfeld	2001	International Journal on Document Analysis and Recognition	10.1007/PL00013566	document retrieval;contextual image classification;self-organization;speech recognition;connected component;similarity;decision tree learning;biological classification;computer science;graphics;artificial intelligence;similitude;document structure description;machine learning;decision tree;document layout analysis;pattern recognition;data mining;feature;categorization	Web+IR	-11.95962653890742	-61.17043550032863	137005
36fdb1d3fb0f3ee59ebc775aaffe81937c25ed14	characteristic pattern discovery in videos	broadcast news;frequent pattern;frequent pattern mining;video mining;feature space;text classification;pattern discovery;frequency of occurrence;random forest	In this paper, we present an approach to discover characteristic patterns in videos. We characterize the videos based on frequently occurring patterns like scenes, characters, sequence of frames in an unsupervised setting. With our approach, we are able to detect the representative scenes and characters of movies. We also present a method for detecting video stop-words in broadcast news videos based on the frequency of occurrence of sequence of frames. These are analogous to stop-words in text classification and search. We employ two different video mining schemes; both aimed at detecting frequent and representative patterns. For one of our mining approaches, we use an efficient frequent pattern mining algorithm over a quantized feature space. Our second approach uses a Random Forest to first represent video data as sequences, and then mine the frequent patterns. We validate the proposed approaches on broadcast news videos and our database of 81 Oscar winning movies.	algorithm;data mining;database;document classification;feature vector;oscar;random forest;sensor;unsupervised learning	Mihir Jain;C. V. Jawahar	2010		10.1145/1924559.1924600	geography;pattern recognition;data mining;world wide web	ML	-18.13294315938224	-58.04363387887797	137771
2d4df1c504797d8cabc0d69c0105b969d204f162	understanding the genetic makeup of linux device drivers	composition;selected works;integration;metasystem;smalltalk;bepress;plan 9;binding;unix	Attempts have been made to understand driver development in terms of code clones. In this paper, we propose an alternate view, based on the metaphor of a gene. Guided by this metaphor, we study the structure of Linux 3.10 ethernet platform driver probe functions.	device driver;linux	Peter Senna Tschudin;Laurent Réveillère;Lingxiao Jiang;David Lo;Julia L. Lawall;Gilles Muller	2013		10.1145/2525528.2525536	embedded system;simulation;computer science;operating system	SE	-5.757833348219669	-58.24451008952784	138020
93c1b20b85518d860594129ca68569c90ea6cdd8	using concept recognition to annotate a video collection	multimedia data;video browsing;video database;domain specificity	In this paper, we propose a scheme based on an ontological framework, to recognize concepts in multimedia data, in order to provide effective content-based access to a closed, domain-specific multimedia collection. The ontology for the domain is constructed from high-level knowledge of the domain lying with the domain experts, and further fine-tuned and refined by learning from multimedia data annotated by them. MOWL, a multimedia extension to OWL, is used to encode the concept to media-feature associations in the ontology as well as the uncertainties linked with observation of the perceptual multimedia data. Media feature classifiers help recognize low-level concepts in the videos, but the novelty of our work lies in discovery of high-level concepts in video content using the power of ontological relations between the concepts. This framework is used to provide rich, conceptual annotations to the video database, which can further be used to create hyperlinks in the video collection, to provide an effective video browsing interface to the user.		Anupama Mallik;Santanu Chaudhury	2009		10.1007/978-3-642-11164-8_82	computer science;multimedia;world wide web;information retrieval	Vision	-14.870864869269075	-58.92535296353447	138318
8fdfd4c5039cf7d70470a2a3ac52bfd229bcd4e2	pushing the limits of radiology with joint modeling of visual and textual information		Recently, there has been increasing interest in the intersection of computer vision and natural language processing. Researchers have studied several interesting tasks, including generating text descriptions from images and videos and language embedding of images. More recent work has further extended the scope of this area to combine videos and language, learning to solve non-visual tasks using visual cues, visual question answering, and visual dialog. Despite a large body of research on the intersection of vision-language technology, its adaption to the medical domain is not fully explored. To address this research gap, we aim to develop machine learning models that can reason jointly on medical images and clinical text for advanced search, retrieval, annotation and description of medical images.	clinical decision support system;computer vision;language technology;machine learning;medical imaging;natural language processing;question answering;radiology;dialog	Sonit Singh	2018			multimedia;natural language processing;deep learning;artificial intelligence;computer science;health informatics;medical imaging	AI	-10.684956430020263	-66.07740616619456	138435
42b34666038790e19605f824760f655169c65def	enabling video privacy through computer vision	access control list;video streaming;authorisation;surveillance;video analysis;video processing;video analysis video processing automation;computer vision;closed circuit television;data privacy;privacy computer vision cameras video surveillance streaming media computerized monitoring explosion protection position measurement computer security data security;video stream video privacy computer vision closed circuit television cameras surveillance privacy intrusion privacy console operator access access control lists video derived data privacycam smart camera;authorisation surveillance closed circuit television computer vision video streaming data privacy;automation	Closed-circuit television cameras used today for surveillance sometimes enable privacy intrusion. The authors' privacy console manages operator access to different versions of video-derived data according to access-control lists. Additionally, their PrivacyCam is a smart camera that produces a video stream with privacy-intrusive information already removed.	access control list;closed-circuit television;computer vision;privacy;smart camera;streaming media	Andrew W. Senior;Sharath Pankanti;Arun Hampapur;Lisa M. Brown;Ying-li Tian;Ahmet Ekin;Jonathan H. Connell;Chiao-Fe Shu;Max Lu	2005	IEEE Security & Privacy Magazine	10.1109/MSP.2005.65	privacy software;information privacy;computer science;video capture;automation;video tracking;professional video camera;video processing;authorization;internet privacy;world wide web;computer security	Security	-11.97948541631286	-54.88263936738193	138892
a80f7d6018941621dd8835d7df8a04178e474b36	trev: a dna trace editor and viewer		Trev is a DNA trace editor and viewer, which is available free for UNIX and Microsoft Windows platforms. It can read all the commonly used file formats, including the new, compact ZTR files. Availability: ftp://ftp.mrc-lmb.cam.ac.uk/pub/staden/trev Contact: jkb@mrc-lmb.cam.ac.uk An increasing number of people need to check the evidence for individual DNA sequences by inspecting the chromatograms (more commonly known as trace files) from which the base calls were deduced. The first noncommercial trace editor and viewer ted (Gleeson and Hillier, 1991) was written as part of our sequencing project management package. Ted ran on UNIX systems using X Windows. Here we describe trev, our replacement for ted, which is written using C, Tcl and Tk and runs on Microsoft Windows platforms as well as UNIX. In addition to running on a variety of platforms, it is the first program able to read the new compact trace file format ZTR (Bonfield and Staden, 2002) and is available free to academic and commercial users (ftp://ftp.mrc-lmb.cam. ac.uk/pub/staden/trev). Trace files are stored in proprietary formats, such as those of ABI, or public formats such as SCF (Dear and Staden, 1992) or ZTR. These files contain the trace amplitudes, the base calls, their confidence values, and textual data about the particular sequencing experiment such as its chemistry, machine type and operating conditions, etc. An extensive list of the common textual data associated with individual trace files is given at National Center for Biotechnology Information trace repository (http://www.ncbi.nlm.nih.gov/Traces). Through its use of our publicly available library of C language routines io lib (ftp://ftp.mrc-lmb.cam.ac.uk/pub/staden/io lib), trev can read files written using these formats and display their contents. The program can be used to locate and mark the extent of low quality data at each end of the sequence and the positions of vector sequences. It also enables the user to edit the base calls, though any edits made are normally saved to the reading’s experiment file (Bonfield	microsoft windows;unix;format	James K. Bonfield;Kathryn F. Beal;Matthew J. Betts;Rodger Staden	2002	Bioinformatics	10.1093/bioinformatics/18.1.194	computer science;bioinformatics;operating system;database;world wide web	Security	-5.069727114383159	-58.53344023478047	138916
42e6723d8c880a5bf3c71f4fe610433957d398b1	linking genes to diseases with a snpedia-gene wiki mashup	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;data mining and knowledge discovery;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;bioinformatics	BACKGROUND A variety of topic-focused wikis are used in the biomedical sciences to enable the mass-collaborative synthesis and distribution of diverse bodies of knowledge. To address complex problems such as defining the relationships between genes and disease, it is important to bring the knowledge from many different domains together. Here we show how advances in wiki technology and natural language processing can be used to automatically assemble 'meta-wikis' that present integrated views over the data collaboratively created in multiple source wikis.   RESULTS We produced a semantic meta-wiki called the Gene Wiki+ that automatically mirrors and integrates data from the Gene Wiki and SNPedia. The Gene Wiki+, available at (http://genewikiplus.org/), captures 8,047 distinct gene-disease relationships. SNPedia accounts for 4,149 of the gene-disease pairs, the Gene Wiki provides 4,377 and only 479 appear independently in both sources. All of this content is available to query and browse and is provided as linked open data.   CONCLUSIONS Wikis contain increasing amounts of diverse, biological information useful for elucidating the connections between genes and disease. The Gene Wiki+ shows how wiki technology can be used in concert with natural language processing to provide integrated views over diverse underlying data sources.	browsing;gene wiki;human body;linked data;mashup (web application hybrid);natural language processing;snpedia;science	Benjamin M. Good;Erik L. Clarke;Salvatore Loguercio;Andrew I. Su	2012		10.1186/2041-1480-3-S1-S6	medical research;computer science;bioinformatics;data science;gene wiki;world wide web;algorithm	Comp.	-4.619080801128197	-62.8499266777596	139008
02c0fb4063b70171ad0a7ec1d5430b28bf317990	research on image fusion algorithm based on fuzzy clustering and semantics		Image fusion aims at integrating complementary or ambiguous information of different images. In order to bridge the semantic gap during the image fusion, a hierarchical semantic labeling model of images is proposed and an image fusion algorithm based on semantic labeling and fuzzy clustering is presented. Images are segmented into regions which are classified into different types using low-level features. Afterwards the labeling model learns to map region types with keywords. The fusion mechanism is based on the calculation of semantic similarity. Experimental results demonstrate that the image fusion algorithm proposed in the paper is more precise than the state-of-the-art methods, especially when noisy labels appear in semantic fusion.	algorithm;cluster analysis;fuzzy clustering;high- and low-level;image fusion;semantic similarity	Jingxiu Ni;Xu Qian;Guoying Zhang;Xinkai Xu	2017	2017 IEEE International Conference on Smart Cloud (SmartCloud)	10.1109/SmartCloud.2017.36	correlation clustering;semantic gap;flame clustering;semantic similarity;cluster analysis;fuzzy clustering;canopy clustering algorithm;machine learning;algorithm;image fusion;artificial intelligence;computer science;pattern recognition	Vision	-14.511569676234522	-59.743047689969956	139041
e274bbd76030b56671641b325c6d55cf626c6f6e	xml document retrieval system supporting multimedia web service for digital museum	document structure;multimedia web service;time measurement;information retrieval;web service;multimedia systems;porcelain;shape;humanities;indexing;system design;image colour analysis;xml document image processing humanities image colour analysis indexing information retrieval information retrieval systems web services;web services;performance analysis;xml;information retrieval systems;xml multimedia systems web services image retrieval content based retrieval indexing porcelain shape performance analysis time measurement;digital museum;document image processing;xml document;korean porcelain;xml document indexing;document image color;xml document retrieval system;similarity measure;content based retrieval;document image color xml document retrieval system multimedia web service digital museum xml document indexing korean porcelain;image retrieval	In this paper, we develop an XML document retrieval system supporting a multimedia Web service for a digital museum. It can support unified retrieval on XML documents based on both document structure and image content. To achieve it, we perform the indexing of XML documents describing Korean porcelains used for a digital museum, based on not only their basic unit of element but also their image color and shape features. In addition, we provide a similarity measure for a unified retrieval to a composite query, based on both document structure and image content. Finally, we implement our XML document retrieval system designed for a digital museum Web service and analyze its performance in terms of retrieval time, insertion time, storage overhead, as well as recall and precision measure.	document retrieval;information retrieval;international conference on web services;mpeg-7;overhead (computing);precision and recall;similarity measure;web service;xml	Jae-Woo Chang;Young-Jin Kim	2007	IEEE International Conference on Web Services (ICWS 2007)	10.1109/ICWS.2007.198	well-formed document;xml catalog;web service;xml validation;xml encryption;simple api for xml;visual word;xml;document clustering;xml schema;image retrieval;streaming xml;computer science;document type definition;document structure description;xml framework;xml schema;database;xml signature;law;world wide web;xml schema editor;information retrieval;efficient xml interchange	Web+IR	-13.188209160342993	-57.67194914879073	139165
81489624fd60b73676c132ab9a96805225cf30b0	knowledge-driven multidimensional indexing structure for biomedical media database retrieval	database indexing;databases;biomedical media database retrieval;search engine;knowledge driven multidimensional indexing;lung image database;real time protein tertiary structure search engine;ground truth knowledge;top down;molecular configurations;real time;k d tree;image database;index structure;visual databases computerised tomography content based retrieval database indexing decision trees entropy information theory lung medical computing molecular biophysics molecular configurations pattern recognition proteins statistical analysis;lung;medical computing;biomedical media;statistical properties;high resolution computed tomography;protein structure;large scale;proteins;statistical analysis;indexing;multidimensional systems indexing information retrieval image databases content based retrieval lungs proteins image retrieval entropy computed tomography;multidimensional signatures;indexation;indexing biomedical media content based retrieval databases;molecular biophysics;multidimensional signatures knowledge driven multidimensional indexing biomedical media database retrieval content based retrieval entropy balanced statistical k d tree high resolution computed tomography lung image database real time protein tertiary structure search engine statistical properties large scale biomedical media databases pattern recognition information theory decision tree induction retrieval precision ground truth knowledge;computerised tomography;abstracting and indexing as topic algorithms artificial intelligence biomedical engineering database management systems databases factual documentation information storage and retrieval pattern recognition automated;pattern recognition;entropy balanced statistical k d tree;ground truth;clinical research;entropy;decision tree induction;retrieval precision;decision trees;content based retrieval;biomedical application;similarity search;information theory;visual databases;large scale biomedical media databases	Today, biomedical media data are being generated at rates unimaginable only years ago. Content-based retrieval of biomedical media from large databases is becoming increasingly important to clinical, research, and educational communities. In this paper, we present the recently developed entropy balanced statistical (EBS) k-d tree and its applications to biomedical media, including a high-resolution computed tomography (HRCT) lung image database and the first real-time protein tertiary structure search engine. Our index utilizes statistical properties inherent in large-scale biomedical media databases for efficient and accurate searches. By applying concepts from pattern recognition and information theory, the EBS k-d tree is built through top-down decision tree induction. Experimentation shows similarity searches against a protein structure database of 53 363 structures consistently execute in less than 8.14 ms for the top 100 most similar structures. Additionally, we have shown improved retrieval precision over adaptive and statistical k-d trees. Retrieval precision of the EBS k-d tree is 81.6% for content-based retrieval of HRCT lung images and 94.9% at 10% recall for protein structure similarity search. The EBS k-d tree has enormous potential for use in biomedical applications embedded with ground-truth knowledge and multidimensional signatures	algorithm;anatomic node;best, worst and average case;ct scan;categories;class;community;content-based image retrieval;decision tree;directed graph;electronic signature;embedded system;embedding;emoticon;exemplification;feature vector;ground truth;high-resolution computed tomography;image resolution;index;indexes;information theory;nearest neighbor search;node - plant part;normal statistical distribution;nut hypersensitivity;optimization problem;organ;pattern recognition;priority queue;protein structure database;published database;real-time clock;real-time transcription;sensitivity and specificity;similarity search;single linkage cluster analysis;spatial database;staphylococcal protein a;structure of parenchyma of lung;traverse;tea tree oil;the 100;top-down and bottom-up design;tree (data structure);tree traversal;trees (plant);web search engine;x-ray computed tomography;tertiary	Grant J. Scott;Chi-Ren Shyu	2007	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2006.880551	clinical research;database index;computer vision;search engine indexing;protein structure;entropy;ground truth;information theory;computer science;data science;machine learning;decision tree;top-down and bottom-up design;k-d tree;data mining;world wide web;information retrieval;search engine;statistics;molecular biophysics	Comp.	-8.476295080173566	-61.627283255000705	140082
5909654507b9567e925358eeca505656a880ffc7	self-taught hashing for fast similarity search	semantic similarity;unsupervised learning;laplacian eigenmap;computer science and information systems;supervised learning;information retrieval;semantic hashing;large scale;hamming distance;support vector machine;similarity search	The ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal l-bit binary codes for all documents in the given corpus via unsupervised learning, and then train l classifiers via supervised learning to predict the l-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.	binary code;experiment;hamming distance;hash function;information retrieval;laplacian matrix;similarity search;supervised learning;support vector machine;unsupervised learning	Dell Zhang;Jun Wang;Deng Cai;Jinsong Lu	2010		10.1145/1835449.1835455	unsupervised learning;support vector machine;semantic similarity;hamming distance;computer science;machine learning;pattern recognition;supervised learning;information retrieval	Web+IR	-16.637380963790125	-65.493696426762	141034
1eae2db275021c9af30681d680ebd3ffb55008e3	ehipasiko: a content-based image indexing and retrieval system	digital library;image indexing;text retrieval;image indexing and retrieval	Presently, retrieving images from a digital library requires different retrieval techniques to those used to retrieve text documents. In this paper, we demonstrate the possibility of converting the contents of images into texts, which enables us to utilise text-base retrieval techniques for image retrieval. The potential advantages and applications of this approach are also illustrated in this paper.		Shyh Wei Teng;Kai Ming Ting	2006			computer vision;visual word;digital library;image retrieval;computer science;adversarial information retrieval;multimedia;automatic image annotation;world wide web;vector space model;information retrieval;human–computer information retrieval	Vision	-13.913663700834801	-57.65996218874378	141736
04d37b9602f4a204e52ef2ca5750572d3c4e84de	hyper questions: unsupervised targeting of a few experts in crowdsourcing		Quality control is one of the major problems in crowdsourcing. One of the primary approaches to rectify this issue is to assign the same task to different workers and then aggregate their answers to obtain a reliable answer. In addition to simple aggregation approaches such as majority voting, various sophisticated probabilistic models have been proposed. However, given that most of the existing methods operate by strengthening the opinions of the majority, these models often fail when the tasks require highly specialized knowledge and the ability of a large majority of the workers is inadequate. In this paper, we focus on an important class of answer aggregation problems in which majority voting fails and propose the concept of hyper questions to devise effective aggregation methods. A hyper question is a set of single questions, and our key idea is that experts are more likely to provide correct answers to all of the single questions included in a hyper question than non-experts. Thus, experts are more likely to reach consensus on the hyper questions than non-experts, which strengthen their influences. We incorporate the concept of hyper questions into existing answer aggregation methods. The results of our experiments conducted using both synthetic datasets and real datasets demonstrate that our simple and easily usable approach works effectively in cases where only a few experts are available.	aggregate data;crowdsourcing;experiment;hyper-heuristic;rectifier;synthetic intelligence	Jiyi Li;Yukino Baba;Hisashi Kashima	2017		10.1145/3132847.3132971	data mining;probabilistic logic;computer science;usable;majority rule;crowdsourcing	AI	-16.39800741509508	-65.60317565211322	141880
82f2d4d8b4268e10936fd2604abebec43fe364cf	network p2p for exploring and visualization of proteomic data: possibility of handling data and analysing them under different perspectives	databases;image segmentation;proteomic data visualization;p2p;data visualisation;p2p architecture;proteins;pattern matching;medical image processing;two dimensional electrophoresis;image registration;solid modeling;proteins data handling data visualisation image registration image segmentation medical image processing;clinical contextualization proteomic data visualization data handling two dimensional electrophoresis proteomics protein expression p2p architecture;clinical contextualization;protein expression;data handling;proteomics;data visualization proteomics data analysis proteins algorithm design and analysis image analysis electrokinetics automation pathology software tools;protein engineering	"""Our group has started a project aiming at the development of analysis algorithms devoted to images produced by two-dimensional electrophoresis (2-DE) for general applications in the field of proteomics. General analysis problems have been addressed, with the ultimate goal of the maximization of the """"automation level"""" of the analysis procedure, without reducing the accuracy now reachable only with manual intervention. For this, the group is analyzing 2-DE images that are already stored or that will be produced by means of the instrumentation and the know-how of the biologists participating to the project. It's obvious that the """"key"""" for the project success is primarily the availability of many images produced by different groups, but especially their """"comparability"""", and their significant """"clinical contextualization"""". For these reasons, the group has started the implementation of federation of heterogeneous bio banks of images founded on open Registry/Repository for P2P architecture (ebXML RR)[1], on images stored with standard metadata for their comparability (EFMI MIP) [2], and on standard electronic documents for their clinical contextualization (HL7 CDA) [3]. This paper summarizes the concepts of the initiative and describes possibility of handling data and analysing them under different perspectives."""	.cda file;british informatics olympiad;clinical decision support system;ebxml;expectation–maximization algorithm;health level 7;proteomics	Gregorio Mercurio;Silvio Maglio;Antonella Agrusti;Giorgio De Nunzio;Rosella Cataldo;Ivan De Mitri;Marco Favetta;Andrea Massafra;Giovanni Marsella;Daniele Vergara;Michele Maffia;Andrei Vasilateanu;Luca-Dan Serbanati	2008	2008 International Conference on Biocomputation, Bioinformatics, and Biomedical Technologies	10.1109/BIOTECHNO.2008.25	computer science;bioinformatics;image registration;data science;pattern matching;group method of data handling;peer-to-peer;data mining;database;protein engineering;image segmentation;solid modeling;proteomics;protein expression;genetics	DB	-6.031711897813968	-61.649699181644905	142346
af3424534e83969b77f0585fa15457c61be0d6e9	medical-image retrieval based on knowledge-assisted text and image indexing	database indexing;busqueda informacion;structure learning;aide diagnostic;concepcion modular;visual ontology;filtering;evaluation performance;filtrage;medical imagery;base donnee;medical image retrieval;performance evaluation;image processing;learning;support vector machines;image databases;recherche image;image databank;structured learning;indexation automatique;lenguaje uml;information retrieval;evaluacion prestacion;filtrado;medical image databases;maquina vector soporte;database;procesamiento imagen;base dato;base connaissance;langage modelisation unifie;pregunta documental;biomedical imaging;image indexing;indexing terms;thesauri;traitement image;thesauri content based retrieval database indexing image retrieval learning artificial intelligence medical image processing support vector machines;aprendizaje;unified medical language system;machine vecteur support;apprentissage;image generation;medical image;machine learning;indexing;recherche information;local features;medical image processing;unified modelling language;banco imagen;indexation;imaging;banque image;signal classification;biomedical imaging image retrieval indexing medical diagnostic imaging information retrieval image databases visual databases machine learning image generation medical diagnosis;automatic indexing;imagineria medica;imagerie medicale;query;classification signal;modular design;formation image;base conocimiento;ontologies;unified medical language system umls;knowledge assisted text;formacion imagen;support vector machine;visual ontology content based image retrieval knowledge based image indexing unified medical language system umls;learning artificial intelligence;analisis semantico;medical semantics;analyse semantique;content based image retrieval;medical image retrieval knowledge assisted text image indexing unified medical language system metathesaurus structured learning support vector machines medical semantics imageclefmed database;content based retrieval;recherche par contenu	Voluminous medical images are generated daily. They are critical assets for medical diagnosis, research, and teaching. To facilitate automatic indexing and retrieval of large medical-image databases, both images and associated texts are indexed using medical concepts from the Unified Medical Language System (UMLS) meta-thesaurus. We propose a structured learning framework based on support vector machines to facilitate modular design and learning of medical semantics from images. We present two complementary visual indexing approaches within this framework: a global indexing to access image modality and a local indexing to access semantic local features. Two fusion approaches are developed to improve textual retrieval using the UMLS-based image indexing. First, a simple fusion of the textual and visual retrieval approaches is proposed, improving significantly the retrieval results of both text and image retrieval. Second, a visual modality filtering is designed to remove visually aberrant images according to the query modality concept(s). Using the ImageCLEFmed database, we demonstrate the effectiveness of our framework which is superior when compared with the automatic runs evaluated in 2005 on the same medical-image retrieval task.	algorithm;cluster analysis;content-based image retrieval;database;lvm;machine learning;modal logic;modality (human–computer interaction);modular design;performance;scalability;sensor;structured prediction;support vector machine;thesaurus	Caroline Lacoste;Joo-Hwee Lim;Jean-Pierre Chevallet;Diem Thi Hoang Le	2007	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2007.897114	medical imaging;support vector machine;computer vision;visual word;image retrieval;computer science;machine learning;data mining;information retrieval	Vision	-12.708356916438799	-60.50909018877285	142418
db3f60ede2ad5f73a512c188191dda32005cc5e1	a critical examination of complex network file formats for bioinformatics data sources	complex networks;performance evaluation;storage management;complex adaptive systems;cognitive agent based computing complex networks bioinformatics complex adaptive systems;genetics;biological data sets complex network file formats bioinformatics data sources complex biological interactions gene expressions biochemical interactions nontrivial decision problem data storage data conversion performance analysis;storage management biochemistry bioinformatics complex networks electronic data interchange genetics performance evaluation;complex networks biology loading computational modeling bioinformatics adaptation models software;cognitive agent based computing;biochemistry;electronic data interchange;bioinformatics	Recent work has demonstrated the effectiveness of using complex networks for studying complex biological interactions. The process often involves conversion of biological data such as gene expressions or biochemical interactions into one of numerous complex network file formats. However, the exact selection of an appropriate file format for a particular dataset often poses a non-trivial decision problem, biologists are non-specialist end-users and find it difficult to select a particular format for data storage and conversion. In this paper, we propose a solution to this problem of the selection of a suitable network format by means of a critical evaluation based on performance analysis of empirical experiments on biological data sets of different sizes. Experimental results substantiate the hypothesis of being extra careful in the selection of a suitable complex network format based primarily on the size of the biological dataset.	bioinformatics;complex network;computer data storage;decision problem;experiment;interaction;profiling (computer programming)	Ammarah Ghaffar;Muaz A. Niazi;Farah Mustafa	2012	2012 10th International Conference on Frontiers of Information Technology	10.1109/FIT.2012.70	computer science;bioinformatics;theoretical computer science;data mining	HPC	-4.7615746109788235	-62.0295680781445	142972
067b7f5663fa9b079c0fc84107eaf57f6e789253	web page representations and data extraction with beryl		The web contains a huge amount of data, which can be primarily accessed with the use of web data extraction technology. With increasing complexity of the web development stack and the source code, a web page visual representation rendered by the browser is often the only source reflecting the semantics, functional role, and logical structure of elements. Thus, modern automatic approaches typically target visual cues and structures (e.g., DOM and CSSOM) constructed by the web browser. In this paper, we briefly analyse different representations of web pages, generic approaches, and introduce Open image in new window , a novel framework and language, which can consolidate two “worlds”, two main approaches: the rule-based approach and machine learning. The rule-based approach is used for feature engineering and pattern recognition, whilst machine learning is used for classification based on the inferred features. This is achieved through three stages including (1) feature computation, pattern construction, and application, (2) machine learning, and (3) refinement.		Andrey Kravchenko;Ruslan R. Fayzrakhmanov;Emanuel Sallinger	2018		10.1007/978-3-030-03056-8_3	world wide web;information retrieval;web page;computation;semantics;sensory cue;source code;structure (mathematical logic);feature engineering;data extraction;computer science	EDA	-13.872103232297137	-63.42837818380667	143355
2c953081eddb43d8f279f09d383f8968361a4af0	a fuzzy ontology strategy for multimedia data management	ecological database queries;multimedia data management;information retrieval system;query processing;search space;information retrieval;information retrieval techniques;ontologies birds information retrieval handheld computers spatial databases visual databases visual perception computer science usability multimedia systems;fuzzy ontology strategy;fuzzy set theory;ontologies artificial intelligence;bird database;multimedia data;multimedia databases;visual features;biodiversity fuzzy ontology strategy multimedia data management information retrieval techniques ecological database queries bird database;handheld device;visual perception;biodiversity;database query;query processing fuzzy set theory information retrieval multimedia databases ontologies artificial intelligence	Providing users with easy access to interesting information is one important goal of information retrieval. However, traditional information retrieval techniques are not suitable for ecological database queries since users are unable to clearly describe the target features. To overcome the problem, an information retrieval system running on handheld devices allowing users to issue queries according to their perceptions or impressions of the target bird is proposed. Six visual features allow users to express their visual perception of a bird and the query will be formulated based on the chosen features. Texture descriptions are also used when searching for the target in the bird database. A bird-information ontology based on the biodiversity is exploited to extend the search space. The methodology is illustrated in this paper. The experimental results demonstrate the effectiveness of the strategy and its applicability in other domains.	accessibility;database;information retrieval;mobile device	Yo-Ping Huang;Tsun-Wei Chang;Frode Eika Sandnes	2007	2007 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2007.4413738	biodiversity;visual perception;computer science;data mining;mobile device;database;fuzzy set;information retrieval	DB	-12.050842056903623	-57.96220023916338	143542
ff780b266238c1373c26ccf2b004bba824de075f	watsite: hydration site prediction program with pymol interface	software;hydration site;ligands;watsite;graphical user interface;binding sites;models chemical;proteins;protein binding;user computer interface;water;pymol	Water molecules that mediate protein-ligand interactions or are released from the binding site on ligand binding can contribute both enthalpically and entropically to the free energy of ligand binding. To elucidate the thermodynamic profile of individual water molecules and their potential contribution to ligand binding, a hydration site analysis program WATsite was developed together with an easy-to-use graphical user interface based on PyMOL. WATsite identifies hydration sites from a molecular dynamics simulation trajectory with explicit water molecules. The free energy profile of each hydration site is estimated by computing the enthalpy and entropy of the water molecule occupying a hydration site throughout the simulation. The results of the hydration site analysis can be displayed in PyMOL. A key feature of WATsite is that it is able to estimate the protein desolvation free energy for any user specified ligand. The WATsite program and its PyMOL plugin are available free of charge from http://people.pnhs.purdue.edu/~mlill/software.	computation (action);energy profile (chemistry);graphical user interface;interaction;ligand binding domain;ligands;molecular dynamics;pymol;simulation;thermodynamics;user interface device component;free energy	Bingjie Hu;Markus A. Lill	2014	Journal of computational chemistry	10.1002/jcc.23616	crystallography;water;plasma protein binding;chemistry;binding site;organic chemistry;graphical user interface;ligand;physics	Comp.	-5.686933786293283	-58.00507779873523	144329
74d6986ebf77c73d61339d1345802bd58b295242	co-retrieval: a boosted reranking approach for video retrieval	busqueda informacion;text;image processing;modele agrege;recherche image;information retrieval;interrogation base donnee;procesamiento imagen;interrogacion base datos;modelo agregado;video retrieval;aprendizaje probabilidades;texte;traitement image;base donnee multimedia;hierarchical classification;senal video;signal video;recherche information;multimedia databases;classification hierarchique;aggregate model;video signal;apprentissage probabilites;texto;clasificacion jerarquizada;database query;probability learning;test collection;image retrieval	Video retrieval compares multimedia queries to items in a video collection in multiple dimensions and combines all the similarity scores into a final retrieval ranking. Although text is the most reliable feature for video retrieval, features from other modalities can provide complementary information. A reranking framework for video retrieval to augment text feature based retrieval with other evidence is presented. A boosted reranking algorithm called co-retrieval is then introduced, which combines a boosting type learning algorithm and a noisy label prediction scheme to select automatically the most useful (weak) features from multiple modalities. The proposed approach is evaluated with queries and video from the 65 h test collection of the 2003 NIST TRECVID evaluation and it achieves considerable improvement over several baseline retrieval algorithms.	algorithm;baseline (configuration management);gradient boosting	Rong Yan;Alexander G. Hauptmann	2004		10.1007/978-3-540-27814-6_11	computer vision;visual word;image processing;image retrieval;computer science;pattern recognition;data mining;world wide web;information retrieval	Web+IR	-13.169167051364308	-61.06048017377455	144710
779c0713a86e27fbffe999017837a56cbcae09ed	weakly supervised extraction of computer security events from twitter	information extraction;text mining	Twitter contains a wealth of timely information, however staying on top of breaking events requires that an information analyst constantly scan many sources, leading to information overload. For example, a user might wish to be made aware whenever an infectious disease outbreak takes place, when a new smartphone is announced or when a distributed Denial of Service (DoS) attack might affect an organization's network connectivity. There are many possible event categories an analyst may wish to track, making it impossible to anticipate all those of interest in advance. We therefore propose a weakly supervised approach, in which extractors for new categories of events are easy to define and train, by specifying a small number of seed examples. We cast seed-based event extraction as a learning problem where only positive and unlabeled data is available. Rather than assuming unlabeled instances are negative, as is common in previous work, we propose a learning objective which regularizes the label distribution towards a user-provided expectation. Our approach greatly outperforms heuristic negatives, used in most previous work, in experiments on real-world data. Significant performance gains are also demonstrated over two novel and competitive baselines: semi-supervised EM and one-class support-vector machines. We investigate three security-related events breaking on Twitter: DoS attacks, data breaches and account hijacking. A demonstration of security events extracted by our system is available at: http://kb1.cse.ohio-state.edu:8123/events/hacked	baseline (configuration management);computer security;data breach;denial-of-service attack;experiment;heuristic;information overload;phishing;semiconductor industry;smartphone;supervised learning;support vector machine	Alan Ritter;Evan Wright;William Casey;Tom M. Mitchell	2015		10.1145/2736277.2741083	text mining;computer science;machine learning;data mining;database;world wide web;computer security;information extraction	Web+IR	-19.11369155074403	-55.47479475214025	144724
1a7d01e120140a3fd069eb0c3c60ba23afab9629	group non-negative matrix factorization with natural categories for question retrieval in community question answer archives		Community question answering (CQA) has become an important service due to the popularity of CQA archives on the web. A distinctive feature is that CQA services usually organize questions into a hierarchy of natural categories. In this paper, we focus on the problem of question retrieval and propose a novel approach, called group non-negative matrix factorization with natural categories (GNMFNC). This is achieved by learning the category-specific topics for each category as well as shared topics across all categories via a group non-negative matrix factorization framework. We derive an efficient algorithm for learning the factorization, analyze its complexity, and provide proof of convergence. Experiments are carried out on a real world CQA data set from Yahoo! Answers. The results show that our proposed approach significantly outperforms various baseline methods and achieves the state-of-the-art performance for question retrieval.	algorithm;archive;baseline (configuration management);categorization;distributed computing environment;learning to rank;mapreduce;mathematical optimization;non-negative matrix factorization;question answering;rm-odp;time complexity;word lists by frequency	Guangyou Zhou;Yubo Chen;Daojian Zeng;Jian Zhao	2014			data mining;world wide web;information retrieval	Web+IR	-15.63753218253217	-64.56784703770673	145034
223ce96bf168229281375100e11ff956f4f5d5ad	the development of an online video browing system	content based video retrieval;video encoding;webcasting	This paper presents a system designed to allow eff icient retrieving, browsing and real time playing of videos through the Internet using a web browser. The system consists of a web site as well as tools to facili tate browsing, searching and video streaming. At the website, users can view video structures and clip details, search for segments in a video by key words and play video clips in real time according to their own connection speeds. In this paper, various approaches to each component of the system are discussed. Issues encountered in the design and implementations of the system are described. Testing results on resource usage and system usability are also eval uated.	eval;internet;streaming media;usability;video clip	Jesse S. Jin;Ruiyi Wang	2001				Networks	-15.452532886068225	-54.5177122897052	145161
f5a86e71610b16abef2ae5eb1c7aa9b519395417	codessa version 2.13 for windows		CODESSA (Comprehensive Descriptors for Structural and Statistical Analysis) version 2.13 for Windows is a new software product destinated for the computation of a wide range of molecular descriptors and for their use in QSPR (Quantitative Structure -Property Relationships) and QSAR (Quantitative Structure -Activity Relationships) studies. CODESSA was developed under the direction of Professor A. R. Katritzky (University of Florida) and Professor M. Karelson (University of Tartu) and is distributed by Semichem. Semichem was founded in 1992 with the goal to sustain and promote the quantum chemistry models developed by Professor Michael J. S. Dewar and incorporated in AMPAC. CODESSA uses the quantum chemical results provided by the AMPAC output files and computes more than 450 molecular descriptors. The molecular descriptors can be used to develop QSPR/QSAR models by the use of various statistical techniques: MLR (Multi-Linear Regression), PCA (Principal Component Analysis), and PLS (Partial LeastSquares). For those interested in establishing quantitative structure property models, CODESSA is a flexible software tool which generates a large set of theoretical descriptors, allows an easy manipulation of the patterns, and uses sound statistical methods to obtain QSAR models.	ampac;computation;learning to rank;microsoft windows;molecular descriptor;principal component analysis;programming tool;quantitative structure–activity relationship	Ovidiu Ivanciuc	1997	Journal of Chemical Information and Computer Sciences	10.1021/ci950193n	combinatorics;computational science;mathematics	Comp.	-8.515505888725146	-52.63295573863443	145651
285f2820ecb5385fd4472dd180ebf9b224f48276	improving tensor based recommenders with clustering	semantic similarity;hosvd;tensor factorization;clustering;canonical decomposition;higher order singular value decomposition;sparse data;social tagging	Social tagging systems (STS) model three types of entities (i.e. tag-user-item) and relationships between them are encoded into a 3-order tensor. Latent relationships and patterns can be discovered by applying tensor factorization techniques like Higher Order Singular Value Decomposition (HOSVD), Canonical Decomposition etc. STS accumulate large amount of sparse data that restricts factorization techniques to detect latent relations and also significantly slows down the process of a factorization. We propose to reduce tag space by exploiting clustering techniques so that the quality of the recommendations and execution time are improved and memory requirements are decreased. The clustering is motivated by the fact that many tags in a tag space are semantically similar thus the tags can be grouped. Finally, promising experimental results are presented.	cluster analysis;entity;requirement;run time (program lifecycle phase);singular value decomposition;sparse matrix;unicode equivalence	Martin Leginus;Peter Dolog;Valdas Zemaitis	2012		10.1007/978-3-642-31454-4_13	theoretical computer science;machine learning;pattern recognition;mathematics	DB	-17.767221006196525	-65.57952529021509	146222
48adf94a825acece84f782236800d37323e09644	bioimax: a web 2.0 approach for easy exploratory and collaborative access to multivariate bioimage data	software;diagnostic imaging;image processing computer assisted;computational biology bioinformatics;cooperative behavior;computer assisted instruction;internet;algorithms;combinatorial libraries;computer appl in life sciences;r medicine general;microarrays;bioinformatics	"""Innovations in biological and biomedical imaging produce complex high-content and multivariate image data. For decision-making and generation of hypotheses, scientists need novel information technology tools that enable them to visually explore and analyze the data and to discuss and communicate results or findings with collaborating experts from various places. In this paper, we present a novel Web2.0 approach, BioIMAX, for the collaborative exploration and analysis of multivariate image data by combining the webs collaboration and distribution architecture with the interface interactivity and computation power of desktop applications, recently called rich internet application. BioIMAX allows scientists to discuss and share data or results with collaborating experts and to visualize, annotate, and explore multivariate image data within one web-based platform from any location via a standard web browser requiring only a username and a password. BioIMAX can be accessed at http://ani.cebitec.uni-bielefeld.de/BioIMAX with the username """"test"""" and the password """"test1"""" for testing purposes."""	computation;decision making;desktop computer;information sciences;interactivity;interface device component;login name;medical imaging;password;rich internet application;user (computing);web 2.0;web application	Christian Loyek;Nasir M. Rajpoot;Michael Khan;Tim W. Nattkemper	2011		10.1186/1471-2105-12-297	medical imaging;biology;the internet;dna microarray;computer science;bioinformatics;data science;data mining;world wide web	HCI	-5.284230115811809	-60.30584605555428	147616
f5b798d6617d56f8e306ccf00282e0f48aa7724b	short text hashing improved by integrating topic features and tags	会议论文	Hashing, as an efficient approach, has been widely used for large-scale similarity search. Unfortunately, many existing hashing meth- ods based on observed keyword features are not effective for short texts due to the sparseness and shortness. Recently, some researchers try to construct semantic relationship using certain granularity topics. How- ever, the topics of certain granularity are insufficient to preserve the optimal semantic similarity for different types of datasets. On the other hand, tag information should be fully exploited to enhance the similarity of related texts. We, therefore, propose a novel unified hashing approach that the optimal topic features can be selected automatically to be in- tegrated with original features for preserving similarity, and tags are fully utilized to improve hash code learning. We carried out extensive experiments on one short text dataset and even one normal text dataset. The results demonstrate that our approach is effective and significantly outperforms baseline methods on several evaluation metrics.	hash function;tag (metadata)	Jiaming Xu;Bo Xu;Jian Zhao;Guanhua Tian;Heng Zhang;Hongwei Hao	2014		10.1007/978-3-319-12640-1_36	feature hashing;computer science;machine learning;data mining;world wide web;information retrieval	AI	-17.483274633633357	-65.37150145698757	147722
44ed54bfcc81597eb9b74d1107872311997e1c55	modeling the semantics of 3d protein structures	genetique;modelizacion;entity relationship model;gestion memoire;hydrogen bond;structure secondaire;genetica;integration information;storage management;functional properties;interrogation base donnee;data management;conceptual analysis;biologia molecular;interrogacion base datos;semantics;hombre;modelo entidad relacion;modele entite relation;semantica;semantique;analisis conceptual;genetics;structure proteine;protein secondary structure;modelisation;protein structure;gestion memoria;information integration;complex data;estructura secundaria;molecular biology;secondary structure;genome;integracion informacion;human;life sciences;human genome project;algorithme evolutionniste;algoritmo evolucionista;genoma;biological data;information system;evolutionary algorithm;analyse conceptuelle;modeling;3d structure;database query;systeme information;protein requirement;homme;sistema informacion;biologie moleculaire	The post Human Genome Project era calls for reliable, integrated, flexible, and convenient data management techniques to facilitate research activities. Querying biological data that is large in volume and complex in structure such as 3D proteins requires expressive models to explicitly support and capture the semantics of the complex data. Protein 3D structure search and comparison not only enable us to predict unknown structures, but can also reveal distant evolutionary relationships that are otherwise undetectable, and perhaps suggest unsuspected functional properties. In this work, we model 3D protein structures by adding spatial semantics and constructs to represent the contributing forces such as hydrogen bonds and high-level structures such as protein secondary structures. This paper makes a contribution to modeling the specialty of life science data and develops methods to meet the novel challenges posed by such data.	high- and low-level;hydrogen	Sudha Ram;Wei Wei	2004		10.1007/978-3-540-30464-7_52	data management;computer science;bioinformatics;artificial intelligence;evolutionary algorithm;database;semantics;algorithm;protein secondary structure	Comp.	-6.6802103715353605	-54.55021909893301	147907
cbfd7d72e73e0109b4b7bbac87ac0d40e8f00b77	video retrieval: content analysis by imageminer	analisis imagen;object recognition;image processing;teneur;information retrieval;video analysis;technique video;video retrieval;tecnica video;similitude;computer vision;artificial intelligent;content analysis;still image;recherche information;content;agent intelligent;indexation;similarity;text retrieval;intelligent agent;video technique;artificial intelligence;system development;image fixe;image analysis;agente inteligente;recuperacion informacion;similitud;video;content based image retrieval;analyse image;proporcion;computer vision technology;time constraint	In this paper videos are analyzed to get a content-based decription of the video. The structure of a given video is useful to index long videos efficiently and automatically. A comparison between shots gives an overview about cut frequency, cut pattern, and scene bounds. After a shot detection the shots are grouped into clusters based on their visual similarity. A time-constraint clustering procedure is used to compare only those shots that are positioned inside a time range. Shots from different areas of the video (e.g., begin/end) are not compared. With this cluster information that contains a list about shots and their clusters it is possible to calculate scene bounds. A labeling of all clusters gives a declaration about the cut pattern. It is easy now to distinguish a dialogue from an action scene. The final content analysis is done by the ImageMiner* system. The ImageMiner system developed at the University of Bremen of the Image Processing Department of the Center for Computing Technology realizes content-based image retrieval for still images through a novel combination of methods and techniques of computer vision and artifical intelligence. The ImageMiner system consists of three analysis modules for computer vision, namely for color, texture, and contour analysis. Additionally exists a module for object recognition. The output of the object recognition module can be indexed by a text retrieval system. Thus, concepts like forestscene may be searched for. We combine the still image analysis with the results of the video analysis in order to retrieve shots or scenes.	artificial intelligence;cluster analysis;computer vision;content-based image retrieval;declaration (computer programming);document retrieval;image analysis;image processing;outline of object recognition;shot transition detection;texture mapping;video content analysis	Peter Alshuth;Thorsten Hermes;Lutz Voigt;Otthein Herzog	1998		10.1117/12.298457	computer vision;image analysis;video;similarity;content analysis;image processing;computer science;similitude;cognitive neuroscience of visual object recognition;multimedia;intelligent agent;computer graphics (images)	Vision	-13.315043028267235	-56.29368025617985	147915
e1db23f5b400f42099f7001a69ebbb0d73dcced4	semantic analysis of human visual attention in mobile eye tracking applications	mobile eye tracking;performance test;video signal processing;video signal processing object detection optical tracking;public transport;video analysis;semantics;public transportation;usability research;materials;visualization;semantic information;object localization;optical tracking;natural environment;feature extraction;automatic annotation;mobile communication;public media screen;semi automatic annotation video analysis object detection and recognition eye tracking;image analysis;semi automatic annotation;humans;mobile communication feature extraction semantics humans visualization materials usability;eye tracking;object detection and recognition;human visual attention;public transportation semantic analysis human visual attention mobile eye tracking video analysis usability research image analysis object detection object localization urban marketing analysis innovative method semantic information public media screen;usability;visual attention;urban marketing analysis;innovative method;object detection;market analysis;semantic analysis	This paper presents semantic analysis in mobile eye tracking studies as a novel application for video analysis in usability research and marketing analyses. Image analysis in the context of human attention within natural environments is recognized as a specific challenge on object detection and localization. In a characteristic study setting of urban marketing analysis, we propose an innovative method to extract semantic information from public media screens mediating content to passengers in public transportation. In an extensive performance test within a unique 100 subject study on real world data the method performed very successful in robustness and accuracy with respect to detection and thus proved being a valuable tool for semi-automated annotation of mobile eye tracking studies, requiring manual interaction in only ≈14% of image data.	eye tracking;image analysis;object detection;semiconductor industry;usability;video content analysis	Gerald Fritz;Lucas Paletta	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5653005	computer vision;image analysis;usability;computer science;semantics;public transport;multimedia	Robotics	-12.464667619519538	-54.8105279100091	148452
972984f4e68d184c237cb3e1b05cdf37f549ce73	hierarchical text categorization using neural networks	automatic text categorization;hierarchical structure;hierarchical neural networks;categorisation;text;applied neural networks;hierarchized structure;information retrieval;hierarchical mixture of experts;structure hierarchisee;methode;texte;neural network classifier;medical science;algorithme;algorithm;categorizacion;ciencia medica;recherche information;recuperacion informacion;reseau neuronal;texto;metodo;method;divide and conquer;red neuronal;text categorization;estructura jerarquizada;categorization;neural network;hierarchical classifiers;algoritmo;science medicale	This paper presents the design and evaluation of a text categorization method based on the Hierarchical Mixture of Experts model. This model uses a divide and conquer principle to define smaller categorization problems based on a predefined hierarchical structure. The final classifier is a hierarchical array of neural networks. The method is evaluated using the UMLS Metathesaurus as the underlying hierarchical structure, and the OHSUMED test set of MEDLINE records. Comparisons with an optimized version of the traditional Rocchio's algorithm adapted for text categorization, as well as flat neural network classifiers are provided. The results show that the use of the hierarchical structure improves text categorization performance with respect to an equivalent flat model. The optimized Rocchio algorithm achieves a performance comparable with that of the hierarchical neural networks.	artificial neural network;categorization;document classification;medline;neural network software;rocchio algorithm;test set	Miguel E. Ruiz;Padmini Srinivasan	2002	Information Retrieval	10.1023/A:1012782908347	method;divide and conquer algorithms;boosting methods for object categorization;computer science;artificial intelligence;machine learning;data mining;information retrieval;artificial neural network;categorization	Web+IR	-11.863933619369359	-61.14308585203877	148540
540ea52bf45168a1738344305232e2fd10d8ace4	database analysis of simulated and recorded electrophysiological datasets with pandora’s toolbox	software;animals;models neurological;ganglia invertebrate;multivariate analysis;rats;electric stimulation;neural model;large datasets;membrane potentials;database management systems;sql;large dataset;electrophysiological phenomena;simulation;database;electrophysiology;nephropidae;relational database;time factors;patch clamp techniques;data visualization;time use;neurons;pandora;databases factual;action potentials;globus pallidus;computer simulation;matlab;open source;automated analysis	Neuronal recordings and computer simulations produce ever growing amounts of data, impeding conventional analysis methods from keeping pace. Such large datasets can be automatically analyzed by taking advantage of the well-established relational database paradigm. Raw electrophysiology data can be entered into a database by extracting its interesting characteristics (e.g., firing rate). Compared to storing the raw data directly, this database representation is several orders of magnitude higher efficient in storage space and processing time. Using two large electrophysiology recording and simulation datasets, we demonstrate that the database can be queried, transformed and analyzed. This process is relatively simple and easy to learn because it takes place entirely in Matlab, using our database analysis toolbox, PANDORA. It is capable of acquiring data from common recording and simulation platforms and exchanging data with external database engines and other analysis toolboxes, which make analysis simpler and highly interoperable. PANDORA is available to be freely used and modified because it is open-source ( http://software.incf.org/software/pandora/home ).	computer simulation;electrophysiology (science);interoperability;matlab;open-source software;pandora <bivalve>;programming paradigm;relational database;whole earth 'lectronic link;orders - hl7publishingdomain	Cengiz Günay;Jeremy R. Edgerton;Su Li;Thomas Sangrey;Astrid A. Prinz;Dieter Jaeger	2009	Neuroinformatics	10.1007/s12021-009-9048-z	computer simulation;electrophysiology;sql;neuroscience;membrane potential;relational database;computer science;data science;machine learning;data mining;database;multivariate analysis;world wide web;action potential;data visualization	DB	-5.466156104349509	-61.04262853706248	148567
ba923251e4f63cb49fc4e51fac66c14ac98ebc81	a java program to create simulated microarray images	undergraduate biology course;simulated microarray images;microarray technology;java program;virtual microarray experiment;microarray image generation program;java	"""We have developed a microarray image generation program to create customized sets of images representing """"virtual microarray experiments"""" to teach microarray technology in undergraduate biology courses."""	experiment;glossary of computer graphics;java;microarray	Bill Martin;Robert M. Horton	2004	Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.	10.1109/CSB.2004.1332497	computer science;bioinformatics;theoretical computer science;java;computer graphics (images)	Visualization	-7.864210461720487	-56.797132372293255	148637
e0a55027d0c09a0cb00aa71a804cd517b5180592	representativeness of knowledge bases with the generalized benford's law		Knowledge bases (KBs) such as DBpedia, Wikidata, and YAGO contain a huge number of entities and facts. Several recent works induce rules or calculate statistics on these KBs. Most of these methods are based on the assumption that the data is a representative sample of the studied universe. Unfortunately, KBs are biased because they are built from crowdsourcing and opportunistic agglomeration of available databases. This paper aims at approximating the representativeness of a relation within a knowledge base. For this, we use the generalized Benford’s law, which indicates the distribution expected by the facts of a relation. We then compute the minimum number of facts that have to be added in order to make the KB representative of the real world. Experiments show that our unsupervised method applies to a large number of relations. For numerical relations where ground truths exist, the estimated representativeness proves to be a reliable indicator.	correctness (computer science);crowdsourcing;dbpedia;data quality;database;enigma machine;entity;experiment;knowledge base;machine learning;numerical analysis;unsupervised learning;wikidata;yago	Arnaud Soulet;Arnaud Giacometti;Béatrice Bouchou-Markhoff;Fabian M. Suchanek	2018		10.1007/978-3-030-00671-6_22	data mining;representativeness heuristic;benford's law;sampling (statistics);knowledge base;computer science;crowdsourcing;economies of agglomeration	DB	-16.475645582765207	-65.18160407811847	148788
4c2e36127f44817bd8ad98f192651565567bb729	logical formalization of multimedia interpretation	semantic annotation;multimedia retrieval;text indexing	Nowadays, many documents in local repositories as well as in resources on the web are multimedia documents that contain not only textual but also visual and auditory information. Despite this fact, retrieval techniquesthatrelyonlyon information fromtextualsourcesare stillwidely used due to the success of current text indexing technology. However, to increase precision and recall of multimedia retrieval, the exploitation of information from all modalities is indispensable, and high-level descriptions of multimedia content are required. These symbolic descriptions, also called deep-level semantic annotations, play a crucial role in facilitating expressive multimedia retrieval. Even for text-based retrieval systems, deep-level descriptions of content are useful (see, e.g., [7]).	high- and low-level;precision and recall;text-based (computing)	Irma Sofía Espinosa Peraldí;Atila Kaya;Ralf Möller	2011		10.1007/978-3-642-20795-2_5	natural language processing;computer science;multimedia;information retrieval	Web+IR	-15.341938592380853	-58.22226270767722	149082
89e78b81b9ba698e2f0ff3f8bd82a4838cec22d6	correlated multi-label refinement for semantic noise removal	double circles algorithm;cluster algorithm;clustering algorithm;image database;image annotation;multi label;web image search;image search;noise removal;image retrieval	Images are major source of Web content. Image annotation is an important issue which is adopted to retrieve images from large image collections based on the keyword annotations of images, which access a large image data-base with textual queries. With surrounding text of Web images increasing, there are generally noisy. So, an efficient image annotation approach for image retrieval is highly desired, which requires effective image search techniques. The developing clustering technologies allow the browsing and retrieval of images with low cost. Image search engines retrieved thousands of images for a given query. However, these results including a significant number of semantic noisy. In this paper, we proposed a new clustering algorithm Double-Circles that enable to remove noisy results and explicitly exploit more precise representative annotations. We demonstrate our approach on images collected from Flickr engine. Experiments conducted on real Web images present the effectiveness and efficiency of the proposed model.	multi-label classification	Tie Hua Zhou;Ling Wang;Ho-Sun Shon;Yang Koo Lee;Keun Ho Ryu	2010		10.1007/978-3-642-14932-0_39	image texture;feature detection;visual word;image analysis;image retrieval;computer science;digital image processing;data mining;cluster analysis;automatic image annotation;world wide web;information retrieval	Vision	-16.768595886087063	-58.14446864196634	149195
e2ada18cb15b84cf1353622c66f25d2dedc23f73	perceived visual motion descriptors from mpeg-2 for content-based hdtv annotation and retrieval	search and retrieval;video databases;video streaming;content based retrieval high definition television video databases;magnitude based video labels perceived visual motion descriptors mpeg 2 content based hdtv annotation and retrieval content based search video databases internet intranets high definition television;digital television;video compression hdtv transform coding content based retrieval high definition video information retrieval visual databases internet tv digital video broadcasting;visual motion;indexation;content management system;digital video;video database;computational efficiency;global motion;content based retrieval;high definition;high definition television	Efficient content-based search and retrieval of video databases has become an important industrial and consumer application due to rapid proliferation of compressed digital video data on the Internet and corporate Intranets, and due to the launch of high definition television (HDTV) broadcasts in 1998. We have developed the first HDTV video content management system that automatically analyzes motion occurring in MPEG-2 encoded videos within the compressed domain itself. Our system produces descriptors characterizing the global motion in videos for content retrieval and repurposing applications in a digital television studio. These motion-direction and magnitude based video labels can be directly, incorporated as annotation indexes into a database for querying, or used to construct higher level event descriptions of videos. Results from our ongoing experiments with tens of thousands of frames obtained from several MPEG-1,2 video streams of various genres demonstrate the good performance of our annotation system in terms of motion identification accuracy and computational efficiency.	mpeg-2	Chitra Dorai;Vikrant Kobla	1999		10.1109/MMSP.1999.793812	computer vision;digital television;telecommunications;computer science;multimedia;information retrieval	Vision	-14.921839032126835	-55.337077177469126	149203
d0567609da19ae90f1742800f1ff873b9f1bd411	extraction of text objects in video documents: recent progress	image recognition;handwriting recognition;performance evaluation;image resolution;recent progress;text analysis;text extraction;usa councils;indexing and retrieval;text analysis organizing usa councils image analysis character recognition handwriting recognition image recognition image resolution indexing document image processing;video documents;recent progress text extraction video documents;indexing;organizing;document image processing;image analysis;character recognition	Text extraction in video documents, as an important research field of content-based information indexing and retrieval, has been developing rapidly since 1990s. This has led to much progress in text extraction, performance evaluation, and related applications. By reviewing the approaches proposed during the past five years, this paper introduces the progress made in this area and discusses promising directions for future research.	information extraction;performance evaluation	Jing Zhang;Rangachar Kasturi	2008	2008 The Eighth IAPR International Workshop on Document Analysis Systems	10.1109/DAS.2008.49	search engine indexing;image analysis;speech recognition;image resolution;computer science;data mining;handwriting recognition;information retrieval	Web+IR	-15.57471174379148	-57.33918869880442	149514
483852f72dca5b499ad21ec33283728423f52bd7	visualizing co-occurrence of events in populations of viral genome sequences	j 3 life and medical sciences biology and genetics;biology and genetics;j 3 life and medical sciences;categories and subject descriptors according to acm ccs	Virologists are not only interested in point mutations in a genome, but also in relationships between mutations. In this work, we present a design study to support the discovery of correlated mutation events (called co-occurrences) in populations of viral genomes. The key challenge is to identify potentially interesting pairs of events within the vast space of event combinations. In our work, we identify analyst requirements and develop a prototype through a participatory process. The key ideas of our approach are to use interest metrics to create dynamic filtering that guides the viewer to interesting and relevant correlations of genome mutations, and to provide visual encodings designed to fit scientists’ mental map of the data, along with dynamic filtering techniques. We demonstrate the strength of our approach in virology-situated case studies, and offer suggestions for extending our strategy to other sequence-based domains.	furby;ibm notes;mental mapping;population;prototype;requirement;situated	Alper Sarikaya;M. Correli;Joao M. Dinis;David H. O'Connor;Michael Gleicher	2016	Comput. Graph. Forum	10.1111/cgf.12891	computational biology;bioinformatics	HCI	-6.606508690127657	-60.83447395695515	149560
12011dc70fa73b6f0745d95ced8f2ec27a6ae2ee	a java tool for the management of chemical databases and similarity analysis based on molecular graphs isomorphism	chemical database management;database management;computational chemistry;isomorphism;graph isomorphism;matching;similarity and diversity analysis;java language;java	This paper describes a computational chemistry solution for the management of large chemical databases of molecules and the performing of isomorphism calculation for the analysis of database similarity and diversity. The system has been fully developed using Java language and it uses other free and standard Java library. The system allows to the user the building of databases of molecules, store information about the molecules, the matching among molecules using different isomorphism paradigms and the similarity/diversity analysis of databases through a wide number of similarity	chemical database;computational chemistry;java	Irene Luque Ruiz;Miguel Ángel Gómez-Nieto	2008		10.1007/978-3-540-69387-1_41	matching;computer science;bioinformatics;theoretical computer science;database;graph isomorphism;isomorphism;programming language;java	DB	-5.773788816350926	-59.263857612249815	149634
f482f65ad6ad394fa0ec575490eb90424604a4c0	off-line automatic virtual director for lecture video		This research proposed an automatic mechanism to refine the lecture video by composing meaningful video clips from multiple cameras. In order to maximize the captured video information and produce a suitable lecture video for learners, video content should be analysed by considering both visual and audio information firstly. Meaningful events were then detected by extracting lecturer’s and learners’ behaviours according to teaching and learning principles in class. An event-driven camera switching strategy was derived to change the camera view to a meaningful one based on the finite state machine. The final lecture video was then produced by composing all meaningful video clips. The experiment results show that learners felt interested and comfortable while watching the lecture video, and also agreed with the meaningfulness of the selected video clips.		Di-Wei Huang;Yu-Tzu Lin;Greg C. Lee	2013		10.1007/978-94-007-7262-5_144	simulation;computer science;multimedia;computer graphics (images)	Vision	-13.043751195696263	-53.07333770333165	150063
7edfde8438daa27463be8fc09ad464d61d1bfa28	improving latent semantic indexing with concepts mapping based on domain ontology	concepts mapping;lsi;singular value decomposition information retrieval ontologies artificial intelligence;dimension reduction;information retrieval;probability density function;singular value decomposition;vector space;indexing ontologies large scale integration information retrieval space technology laboratories information technology computer science partial response channels data mining;data mining;singular value decomposition latent semantic indexing concepts mapping domain ontology information retrieval vector space;ontologies artificial intelligence;domain ontology latent semantic indexing lsi dimension reduction;distance measurement;large scale integration;indexing;matrix decomposition;latent semantic indexing;concept map;higher dimensions;ontologies;semantic relations;random projection;high dimension;domain ontology;concept space	ldquoCurse of dimensionalityrdquo is a common problem in the area of information retrieval. It was verified that points in a vector space are projected to a random subspace of suitably high dimension, and then the distances between the points are approximately preserved. Although such a random projection can be used to reduce the dimension of the document space, it does not bring together semantically related documents. Latent Semantic Indexing (LSI) projects documents to lower dimensional LSI space from higher dimensional term space with singular-value decomposition (SVD) for the purpose of reducing the dimensions of the document space and bringing together semantically related documents. But the computation time of SVD is a bottleneck because of the higher dimensions of documents. In this paper, a novel method of dimension reduction for improving LSI is provided. A term-to-concept projection matrix based on domain ontology was created in this method. This way documents were projected to lower dimensional concept space by the projection matrix. LSI pre-computation was performed not on the original term by document matrix, but on the lower dimensional concept by document matrix at great computational savings. Experiments indicate that this method improves the efficiency of LSI. And the similarity judgment between documents is not disturbed.	computation;dimensionality reduction;information retrieval;latent semantic analysis;ontology (information science);precomputation;random projection;singular value decomposition;time complexity	Jingmin Hao;Lejian Liao;Xiujie Dong	2008	2008 International Conference on Natural Language Processing and Knowledge Engineering	10.1109/NLPKE.2008.4906768	computer science;theoretical computer science;data mining;information retrieval	DB	-14.629149452135312	-63.04063276541168	150142
1d3b7e821ef5248924ab5dff572090abbf4cbbaa	automatic content-based retrieval of broadcast news	broadcast news;television news;multimedia;information retrieval;browsing;video retrieval;statistical method;information content;text subtitles;text retrieval;atm;content based retrieval	Recent years have seen a rapid increase in the availability and use of multimedia applications. These systems can generate large amounts of audio and video data which can be expensive to store and unwieldy to access. The Video Mail Retrieval (VMR) project at Cambridge University and Olivetti Research Limited (ORL), Cambridge, UK, is addressing these problems by developing systems to retrieve stored video material using the spoken audio soundtrack [1, 16]. Speci cally, the project focuses on the content-based location, retrieval, and playback of potentially relevant data. The primary goal of the VMR project is to develop a video mail retrieval application for the Medusa multimedia environment developed at ORL. Previous work on the VMR project demonstrated practical retrieval of audio messages using speech recognition for content identi cation [8 , 4]. Because of the limited number of available audio messages, a much larger archive of television news broadcasts (along with accompanying subtitle transcriptions) is currently being collected. This will serve as a testbed for new methods of storing and accessing large amounts of audio/video data. The enormous potential size of the news broadcast archive dramatically illustrates the need for ways of automatically nding and retrieving information from the archive. Quantitative experiments demonstrate that Information Retrieval (IR) methods developed for searching text archives can accurately retrieve multimedia data, given suitable subtitle transcriptions. In addition, the same techniques can be used to rapidly locate interesting areas within an individual news broadcast. Although large multimedia archives will be more common in the future, today they require a specialised and highperformance hardware infrastructure. The work presented here relies on the the Medusa system developed at ORL, which includes distributed, high-capacity multimedia repositories. This paper begins with an overview of the ORL Medusa technology. Subsequent sections describe the collection and storage of a BBC television broadcast news archive, a retrieval methodology for location of potentially relevant sections in response to users' requests, and a graphical user interface for content-based retrieval and browsing of news f g	archive;directshow;experiment;graphical user interface;information retrieval;location-based service;medusa4;return loss;speech recognition;television;testbed;video email	Martin G. Brown;Jonathan Foote;Gareth J. F. Jones;Karen Spärck Jones;Steve J. Young	1995		10.1145/217279.215080	document retrieval;self-information;computer science;atmosphere;multimedia;world wide web;information retrieval	Web+IR	-17.0005315184875	-56.38489861834053	150480
8cc5ed358764a68140550c1a7fcbafef31560164	understanding the message of images		We investigate the problem of understanding the message (gist) conveyed by images and their captions as found, for instance, on websites or news articles. To this end, we propose a methodology to capture the meaning of image-caption pairs on the basis of large amounts of machine-readable knowledge that have previously been shown to be highly effective for text understanding. Our method identifies the connotation of objects beyond their denotation: where most approaches to image or image-text understanding focus on the denotation of objects, i.e., their literal meaning, our work addresses the identification of connotations, i.e., iconic meanings of objects, to understand the message of images. We view image understanding as the task of representing an image-caption pair on the basis of a widecoverage vocabulary of concepts such as the one provided by Wikipedia, and cast gist detection as a concept-ranking problem with image-caption pairs as queries. Specifically, we approach the problem using a pipeline that: i) links detected object labels in the image and concept mentions in the caption to nodes of the knowledge base; ii) builds a semantic graph out of these ‘seed’ concepts; iii) applies a series of graph expansion and clustering steps on the original semantic graph to include additional concepts and topics within the semantic representation; iv) combines several graph-based and text-based features into a concept ranking model that pinpoints the gist concepts. Understanding the gist can be useful for tasks, such as image search and recommending images for texts. As gist detection is a novel task, to the best of our knowledge, there is no dataset available. Thus, we create a dataset allowing for simultaneous evaluation of literal and nonliteral image-caption pairs. The gold standard gist concepts are from a common knowledge base (Wikipedia) and the provided ranks are detailed with levels 0 to 5, which supports various benchmarking tasks, e.g., ranking according to different levels of granularity and classification. Furthermore, as our proposed gist detection pipeline touches on different research areas, we provide a detailed gold standard for each of our pipeline steps, such as entity linking or object detection in the images. Our gist detection pipeline is evaluated in a detailed ablation study, investigating aspects of twelve different research questions. These are elaborated in the evaluation section via human-assessment or cross-validation and provide detailed insights into the gist of image-caption pairs. Furthermore, we show in an end-to-end	cluster analysis;computer vision;cross-validation (statistics);end-to-end principle;entity linking;gist;human-readable medium;image retrieval;knowledge base;literal (computer programming);literal (mathematical logic);object detection;pipeline (computing);text-based (computing);vocabulary;wikipedia	Lydia Weiland	2018				Vision	-17.326423167676218	-60.587307398620645	150582
90f73d83227d1103e6fd08b537f854e4dd3f0311	image retrieval with semantic sketches	sketch interface;user study;semantic brushes;content based image retrieval;real time application	With increasingly large image databases, searching in them becomes an ever more difficult endeavor. Consequently, there is a need for advanced tools for image retrieval in a webscale context. Searching by tags becomes intractable in such scenarios as large numbers of images will correspond to queries such as “car and house and street”. We present a novel approach that allows a user to search for images based on semantic sketches that describe the desired composition of the image. Our system operates on images with labels for a few high-level object categories, allowing us to search very fast with a minimal memory footprint. We employ a structure similar to random decision forests which avails a data-driven partitioning of the image space providing a search in logarithmic time with respect to the number of images. This makes our system applicable for large scale image search problems. We performed a user study that demonstrates the validity and usability of our approach.	database;high- and low-level;image retrieval;memory footprint;scalability;time complexity;usability testing	David Engel;Christian Herdtweck;Björn Browatzki;Cristóbal Curio	2011		10.1007/978-3-642-23774-4_35	computer vision;image retrieval;computer science;artificial intelligence;automatic image annotation;world wide web;information retrieval	Vision	-16.55478542809869	-57.340616024129716	151230
62520e95256a4f2ef9a8da6a5c2c1df09ed0449a	genepath: a system for inference of genetic networks and proposal of genetic experiments	abduction;genetic networks;genetics;genetic network;functional genomics;background knowledge;dictyostelium discoideum;bioinformatics;knowledge discovery	A genetic network is a formalism that is often used in biology to represent causalities and reason about biological phenomena related to genetic regulation. We present GenePath, a computer-based system that supports the inference of genetic networks from a set of genetic experiments. Implemented in Prolog, GenePath uses abductive inference to elucidate network constraints based on background knowledge and experimental results. Additionally, it can propose genetic experiments that may further refine the discovered network and establish relations between genes that could not be related based on the original experimental data. We illustrate GenePath's approach and utility on analysis of data on aggregation and sporulation of the soil amoeba Dictyostelium discoideum.	abductive reasoning;amoeba genus;experiment;gene expression regulation;gene regulatory network;genetic algorithm;inference;prolog;real life;seamless3d;semantics (computer science);sporulation	Blaz Zupan;Ivan Bratko;Janez Demsar;Peter Juvan;Tomaž Curk;Urban Borstnik;J. Robert Beck;John A. Halter;Adam Kuspa;Gad Shaulsky	2003	Artificial intelligence in medicine	10.1016/S0933-3657(03)00048-4	functional genomics;computer science;bioinformatics;artificial intelligence;knowledge extraction;dictybase	AI	-6.472945979668122	-52.129460332568975	151321
3b63186a6a8760d9d279c414d974fd36ac161ad4	an event-based video retrieval system by combining broadcasting baseball video and web-casting text	video analysis;video retrieval;text analysis;broadcast baseball video;sports video;video annotation;system architecture;caption information;webcasting text;mpeg 7;semantic retrieval	In the paper, we proposed an event-based video analysis/retrieval system by integrating baseball videos with the corresponding webcasting texts to facilitate versatile video retrieval. The system architecture and the corresponding realized modules of the proposed system consist of four parts: (1) video analysis, (2) webcasting text analysis, (3) video/text alignment & annotation, and (4) video retrieval system. Furthermore, we also integrated several description schemes based on MPEG-7 to describe videos effectively for browsing, indexing and annotation. The experimental results on event retrieval in sport videos are encouraging and comparable to those selected manually. We thought the event-based video analysis/retrieval system is more convenient to conform to users' expectations.	mpeg-7;systems architecture;video content analysis	Yin-Fu Huang;Li-Wen Chen	2011		10.1145/1982185.1982369	video compression picture types;text mining;visual word;h.263;video production;computer science;video capture;video tracking;multimedia;video processing;smacker video;world wide web;pevq;information retrieval;systems architecture;multiview video coding;non-linear editing system	Vision	-14.745350060726533	-55.19065149963345	151396
b841cf727a652dbd1f9a20b12f4c4c275743a9ca	visualising biological data: a semantic approach to tool and database integration	distributed system;human computer interaction;real time;semantics;large data sets;database integration;data format;research method;computational biology bioinformatics;large scale;complex data;internet;software component;human in the loop;algorithms;biological data;user computer interface;databases factual;point of view;combinatorial libraries;computational biology;computer appl in life sciences;high performance;systems integration;information storage and retrieval;scripting language;microarrays;bioinformatics	In the biological sciences, the need to analyse vast amounts of information has become commonplace. Such large-scale analyses often involve drawing together data from a variety of different databases, held remotely on the internet or locally on in-house servers. Supporting these tasks are ad hoc collections of data-manipulation tools, scripting languages and visualisation software, which are often combined in arcane ways to create cumbersome systems that have been customised for a particular purpose, and are consequently not readily adaptable to other uses. For many day-to-day bioinformatics tasks, the sizes of current databases, and the scale of the analyses necessary, now demand increasing levels of automation; nevertheless, the unique experience and intuition of human researchers is still required to interpret the end results in any meaningful biological way. Putting humans in the loop requires tools to support real-time interaction with these vast and complex data-sets. Numerous tools do exist for this purpose, but many do not have optimal interfaces, most are effectively isolated from other tools and databases owing to incompatible data formats, and many have limited real-time performance when applied to realistically large data-sets: much of the user's cognitive capacity is therefore focused on controlling the software and manipulating esoteric file formats rather than on performing the research. To confront these issues, harnessing expertise in human-computer interaction (HCI), high-performance rendering and distributed systems, and guided by bioinformaticians and end-user biologists, we are building reusable software components that, together, create a toolkit that is both architecturally sound from a computing point of view, and addresses both user and developer requirements. Key to the system's usability is its direct exploitation of semantics, which, crucially, gives individual components knowledge of their own functionality and allows them to interoperate seamlessly, removing many of the existing barriers and bottlenecks from standard bioinformatics tasks. The toolkit, named Utopia, is freely available from http://utopia.cs.man.ac.uk/ .	abbreviations;addresses (publication format);application programming interface;bmc bioinformatics;bespoke;biological science disciplines;collections (publication);component-based software engineering;computation (action);computer data storage;dna integration;data sources;data model;display resolution;distributed computing;embrace;embnet.journal;european union;graphical user interface;graphics processing unit;heterogeneous database system;hoc (programming language);human–computer interaction;irgc gene;internet;interoperability;intuition;manuscripts;molecular biology;name;programmer device component;programming languages;prototype;published database;rdf query language;real-time clock;real-time locating system;requirement;resource description framework;smart;sparql;scientific publication;scripting language;structural bioinformatics;usability;web service definition language;web services description language;worldwide protein data bank;citation;contents - htmllinktype;format;funding grant;interest;mecarzole	Steve Pettifer;David Thorne;Philip McDermott;James Marsh;Alice Villéger;Douglas B. Kell;Terri K. Attwood	2009	BMC Bioinformatics	10.1186/1471-2105-10-S6-S19	the internet;dna microarray;biological data;computer science;bioinformatics;data science;theoretical computer science;component-based software engineering;data integration;data mining;semantics;scripting language;algorithm;system integration;complex data type	Visualization	-5.026728294941811	-61.27433371240404	151737
fbeec91583ecaf5a8d35eb78e7c689feb4cc6523	efficient content-based retrieval in image databases: a probabilistic approach	databases;image processing;query processing;query formulation;image database;probabilistic approach;signature file;image processing algorithms and systems;content based retrieval	"""This paper describes the retrieval process from image databases, based on a partial match between the query and the images. The proposed approach allows to measure the similarity between the query and the images in the database and to retrieve those having the highest probability to be relevant. The paper describes the query processing and the access structures, based on the """"signature method"""". Four levels of signature files are associated to the image database and a signature is associated to the query. The query signature is compared with the image signatures in a four step image processing algorithm. The result of the process is a set of images with an associated recognition degree, measured by using information provided by the user during query formulation (such as importance of the presence of each object) and by using the image structure and the recognition degree associated to each object. The retrieved images are presented to the user in decreasing relevance order. The method described so far is inefficient, since the selection of most relevant images is executed among all relevant images (even those having a low relevance). The paper presents two approaches for improving the efficiency of query processing by (a) reducing the number of accesses to the Image Database and (h) by reducing the number of accesses to the signature file. The two approaches are discussed in detail in the paper. The advantages and drawbacks of each method are illustrated."""	algorithm;database;digital signature;image processing;information;relevance;type signature	Fausto Rabitti;Pasquale Savino	1994		10.1117/12.171787	online aggregation;sargable;query optimization;query expansion;web query classification;ranking;computer science;query by example;digital image processing;data mining;database;rdf query language;web search query;view;information retrieval;query language	Vision	-11.636204372920993	-58.50282156650204	152028
18021e08bef4f5206c68aca5322c32aec6bb4edd	viteq: a generic framework for no-reference quality evaluation of video testimonials	measurement streaming media multimedia communication cameras visualization quality assessment conferences;video audio quality viteq no reference quality evaluation video testimonials audio metrics content related metrics temporal metrics spatial metrics global quality score;video signal processing;video testimonials;feedback;technology and engineering;quality analysis;video signal processing feedback;no refernece;video testimonials gamification no reference quality analysis user generated content;garnification;user generated content;gamification;quality ananlysis;no reference	This paper proposes a generic framework for no-reference quality evaluation of video testimonials. The global quality of the video testimonials is estimated by fusing the individual scores of a selection of spatial, temporal, audio and content-related metrics. Based on the global quality score, feedback is given to the user and the video/audio quality improver can be activated. Experiments on a large set of video testimonials show that the proposed objective evaluation closely matches the perception of users.		Steven Verstockt;Pieterjan De Potter;Wesley De Neve;Peter Lambert;Rik Van de Walle	2012	2012 Fourth International Workshop on Quality of Multimedia Experience	10.1109/QoMEX.2012.6263879	subjective video quality;computer vision;computer science;video quality;video tracking;feedback;multimedia;video processing;user-generated content;world wide web;pevq	Vision	-15.342715230180595	-52.90900335531399	152607
00b2afa04185721f317faa5c00e4acfd2fb0337f	fusing text and image for event detection in twitter		In this contribution, we develop an accurate and effective event detection method to detect events from a Twitter stream, which uses visual and textual information to improve the performance of the mining process. The method monitors a Twitter stream to pick up tweets having texts and images and stores them into a database. This is followed by applying a mining algorithm to detect an event. The procedure starts with detecting events based on text only by using the feature of the bag-of-words which is calculated using the term frequency-inverse document frequency (TF-IDF) method. Then it detects the event based on image only by using visual features including histogram of oriented gradients (HOG) descriptors, grey-level cooccurrence matrix (GLCM), and color histogram. K nearest neighbours (Knn) classification is used in the detection. The final decision of the event detection is made based on the reliabilities of text only detection and image only detection. The experiment result showed that the proposed method achieved high accuracy of 0.94, comparing with 0.89 with texts only, and 0.86 with images only.	bag-of-words model;color histogram;database;gradient;histogram of oriented gradients;k-nearest neighbors algorithm;sensor;tf–idf	Samar M. Alqhtani;Suhuai Luo;Brian Regan	2015	CoRR	10.5121/ijma.2015.7103	computer science;pattern recognition;data mining;information retrieval	Vision	-18.56422849332467	-57.95907949562386	152888
23f1a019050f4ab2b413fc3f1766f79a2b7b862e	using hybrid similarity methods for plagiarism detection notebook for pan at clef 2013		At PAN2013 we decided to focus entirely on Text Alignment subtask. Following our previous experience at PAN2012 and CLINSS2012, we decided to put together the approaches we used in previous year to face the new challenges of PAN2013. This year competition added new way of plagiarism obfuscation via text summarization. This particular feature required represents a wide variety of typical cases of plagiarism in the wild and thus attracted our scientific interest. At this year PAN we put forward two main goals: 1) to develop a unified approach that will allow us to merge results obtained by different analysis methods and then run a unified clusterization algorithm to tackle the problem of granularity and produce clean clusters of suspected plagiarism 2) develop a new method of detecting summarization within the suspected documents. As a starting point at PAN 2013 we utilized the prototype application we developed for PAN 2012 and another application developed for FIRE 2012 (CLINSS task). Two basic approaches are fingerprinting via 5gramm hashes with variable step as our main method and sliding window TFIDF weighting score for similarity detection of pre-processed summarization via custom text summarizer. Euclidian distance based clusterization with additional custom filters method was used as our cluster merging technique. During the training stage we used the PAN 2012\PAN2013 provided data and performance measures scripts incorporated with genetic algorithm for best parameter tuning and overall performance. Hardware used (training\ development): 6-core Intel i7990Ex with 6GB RAM PC, Vertex3 SSD. Software used: Windows 7 x64, Visual Studio 2010, .net framework, C#, vb.net. We obtained the 6th overall score at PAN2013 with final p-det 0,6152.	.net framework;automatic summarization;euclidean distance;fingerprint (computing);genetic algorithm;microsoft visual studio;microsoft windows;prototype;random-access memory;sensor;solid-state drive;tf–idf;visual basic[.net];x86-64	Yurii Palkovskii;Alexei Belov	2013			.net framework;microsoft visual studio;sliding window protocol;automatic summarization;genetic algorithm;software;information retrieval;tf–idf;computer science;plagiarism detection	Web+IR	-10.673747147355423	-64.76093196060293	153030
201d0ca0480f395472a5b383f2e1e91ed90ac280	guest editorial: analysis and retrieval of events/actions and workflows in video streams		AREA 2008 is the first ACM international workshop on analysis and retrieval of events, actions and workflows in video streams. Such research is nowadays critical for many real-life applications, such as area supervision, semantic characterization and annotation of video streams, quality assurance, and security. This workshop consists of 16 high quality papers organized in four thematic sessions. More specifically, the first session is dedicated to new objects tracking algorithms under complex environments and to object labeling techniques. The second session deals with methods, tools and architectures for detecting high level semantics (events, actions, and workflows) in video sequences. The third session presents new algorithms for analyzing video sequences oriented to detecting humans' actions or implicitly annotating multimedia content. Finally, the fourth includes a special session of the recent advantages of the ongoing research projects in the field of multimedia analysis, cognitive video supervision, personalized video annotation, fast retrieval of multimedia content in compressed domain and scheduling tools for interactive multimedia services. We hope that these proceedings will serve as a valuable reference for analysis of events in video streams.	algorithm;display resolution;high-level programming language;personalization;real life;scheduling (computing);sensor;streaming media	Anastasios D. Doulamis;Nikolaos D. Doulamis;Marco Bertini;Jordi Gonzàlez;Thomas B. Moeslund	2008	Multimedia Tools and Applications	10.1007/s11042-016-3813-4	computer science;data mining;world wide web;information retrieval	DB	-14.790955960206015	-54.695990046345905	153143
119ffd6221ceb58224de3ac6f4bbcb17ccce47ce	cave-technology for visualizing medical imagery	virtual environment;multiuser;medical imaging;cave;visualization;data acquisition	As medical data acquisition has become digital and tomographical scanners allow threedimensional reconstruction in ease, it is still standard to analyze the data plane by plane or in a multiplanar view. Both are limited to two-dimensional environments and cause difficulties in analyzing complex anatomical and pathological structures. Decreasing hardware prices and PCclusters, which can compare with more expensive super-computers, will help implementing virtual environments in medicine for teaching, simulation and interacting with medical image data. Using free open source software, such as 3D-Slicer, for segmentation and preparing the data for the CAVE is quick and suitable for clinical use as well as for education. For educational purposes, the use of very high-resolution data sets will be ideal and could be made available for everyone, based on the open source philosophy. D 2004 CARS and Elsevier B.V. All rights reserved.	3dslicer;cave automatic virtual environment;computer;data acquisition;forwarding plane;image resolution;interaction;medical imaging;open-source software;simulation;supercomputer;tomography;virtual reality	Florian Kral;Andreas H. Mehrle;Ron Kikinis;Wolfgang Freysinger	2004			computer vision;software;artificial intelligence;visualization;cave;medical imaging;data set;virtual machine;data acquisition;forwarding plane;computer science	Visualization	-9.573195435173425	-54.25773337550128	153285
d91300365753650d2a5971944bf3f40761fdcaba	image collection organization and its application to indexing, browsing, summarization, and semantic retrieval	busqueda informacion;modelizacion;image storage;interfase usuario;contenu image;image summarization;image content;linguistique;base donnee;human computer interaction;navegacion informacion;multimedia;software libraries;recherche image;image databank;user interface;information retrieval;navigation information;digital library;model generation;digital libraries;interrogation base donnee;moulage;information browsing;database;catalogs;indexing cataloguing human computer interaction image retrieval;interrogacion base datos;base dato;semantics;resumen;image indexing;cataloguing;probabilistic approach;catalogue;feature selection image collection organization image indexing image browsing image summarization image semantic retrieval tree based technique probabilistic framework hierarchical browsing catalog human computer interaction relevance feedback;semantica;semantique;searching;indexing image retrieval organizing navigation content based retrieval image storage computer science feedback software libraries information retrieval;man machine system;modelisation;navigation;biblioteca electronica;feedback;linguistica;probabilistic framework;indexing;recherche information;organizing;image semantic retrieval;resume;enfoque probabilista;approche probabiliste;banco imagen;indexation;semantic gap;banque image;image browsing;indizacion;molding;retroaction pertinence;query;moldeo;sistema hombre maquina;interface utilisateur;feature selection;electronic library;indexing searching retrieving query and archiving databases content understanding and knowledge molding digital libraries;retrieving;hierarchical browsing catalog;catalogo;computer science;image collection organization;and archiving databases;contenido imagen;abstract;modeling;content understanding and knowledge molding;relevance feedback;content based retrieval;database query;tree based technique;bibliotheque electronique;systeme homme machine;semantic retrieval;image retrieval;linguistics	In this paper, we present a new framework for organizing image collections into structures that can be used for indexing, browsing, retrieval and summarization. Instead of using tree-based techniques which are not suitable for images, we develop a new solution that is specifically designed for image collections. We consider both low-level image content and high-level semantics in an attempt to alleviate the semantic gap encountered by many systems. The fact that our model is based on a probabilistic framework makes it possible to combine it in a natural way with probabilistic techniques developed recently for image retrieval. The structure our model generates is applied for four purposes. The first is to provide retrieval module with an index, which allows it to improve retrieval time and accuracy, while the second is to provide users with a hierarchical browsing catalog that allows them to navigate the image collection by subject. This represents an additional step towards facilitating human-computer interaction in the context of image retrieval and navigation. The third aim is to provide users with a summarization of the general content of each class in the collection, and the fourth is a retrieval mechanism. Related issues such as relevance feedback and feature selection are also addressed. The experiments at the end of the paper show that the proposed framework yields some significant improvements	automatic summarization;browsing;experiment;feature selection;high- and low-level;human–computer interaction;image retrieval;information retrieval;organizing (structure);relevance feedback;rendering (computer graphics);usability	Mohammed Lamine Kherfi;Djemel Ziou	2007	IEEE Transactions on Multimedia	10.1109/TMM.2007.893349	search engine indexing;navigation;visual word;digital library;systems modeling;image retrieval;computer science;automatic summarization;feedback;database;user interface;automatic image annotation;world wide web;molding;information retrieval;semantic gap	Vision	-12.778909599299666	-58.93857822336049	153367
564504952be8e34fe890f4eb4abec36eb48868f6	an enhanced massively multi-agent system for discovering hiv population dynamics	genetique;modelizacion;hiv infection;time scale;medicament;multi agent system;infeccion;genetica;sistema inmunitario;mutation rate;intelligence artificielle;dinamica poblacion;genetics;paralelismo masivo;modelisation;phase transition;population dynamic;drug therapy;automate cellulaire;genome;immune system;population dynamics;artificial intelligence;medicamento;inteligencia artificial;genoma;drug;dynamique population;cellular automata;infection;modeling;parallelisme massif;cellular automaton;massive parallelism;systeme immunitaire;automata celular	In this paper, we present an enhanced massively multi-agent system based on the previous MMAS for discovering the unique dynamics of HIV infection [1]. The enhanced MMAS keeps the spacial characteristics of cellular automata (CA), and employs mathematical equations within sites. Furthermore, new features are incorporated into the model, such as the sequence representation of HIV genome, immune memory and agent remote diffusion among sites. The enhanced model is closer to the reality and the simulation captures two extreme time scales in the typical three stages dynamics of HIV infection, which make the model more convincing. The simulation also reveals two phase-transitions in the dynamics of the size of immune memory, and indicates that the high mutation rate of HIV is the fatal factor with which HIV destroys the immune system eventually. The enhanced MMAS provides a good tool to study HIV drug therapy for its characterizing the process of HIV infection.	multi-agent system;population dynamics	Shiwu Zhang;Jie Yang;Yuehua Wu;Jiming Liu	2005		10.1007/11538356_102	phase transition;cellular automaton;mutation rate;systems modeling;immune system;computer science;artificial intelligence;population dynamics;genome	AI	-4.929241199311573	-53.60747581711323	153425
c9f4ce4dd052a9bf478e9ace0c07379141aaeacc	multi-modal scene duplicate detection from news videos focusing on human faces	difference of viewpoints;news video;scene duplicate detection	In this paper, as a tool for structuring a large volume of archived news videos according to their semantic contents, we propose a method that e®ectively detects scene duplicates, assuming the presence of a person speaking in the videos. A scene duplicate is de ̄ned here as a pair of video segments taken at the same event from di®erent viewpoints. When considering scenes where a subject is speaking in news videos, referring to the audio channel could be e®ective to detect scene duplicates regardless of viewpoints. However, it cannot be relied on when external audio sources overlap the original one or when the subject is actually not speaking. In contrast, the image channel can be useful in most cases. However, signi ̄cant di®erence in viewpoints could prevent accurate detection. Therefore, we propose a method that combines the results obtained from both audio and image channels in order to improve the accuracy of scene duplicate detection from news videos. The proposed method was evaluated through an experiment with actual broadcast news videos by comparing it with a conventional method. As a result, we con ̄rmed that the detection accuracy signi ̄cantly improved by the proposed method in both recall and precision.	archive;channel (digital image);glossary of computer graphics;modal logic;naruto shippuden: clash of ninja revolution 3;precision and recall	Haruka Kumagai;Ichiro Ide;Hiroshi Murase;Keisuke Doman;Daisuke Deguchi	2015	Int. J. Semantic Computing	10.1142/S1793351X15400048	computer vision;computer science;multimedia;world wide web	Vision	-17.342181996346177	-56.18435844929029	153939
86e94d48a951e267d33b2229bef2c3770c18f9a5	automatic classification of web images as uml diagrams	rule induction;image processing;uml diagram recognition	Our purpose in this research is to develop a methodology to automatically and efficiently classify web images as UML static diagrams, and to produce a computer tool that implements this function. The tool receives as input a bitmap file (in different formats) and tells whether the image corresponds to a diagram. The tool does not require that the images are explicitly or implicitly tagged as UML diagrams. The tool extracts graphical characteristics from each image (such as grayscale histogram, color histogram and elementary geometric forms) and uses a combination of rules to classify it. The rules are obtained with machine learning techniques (rule induction) from a sample of 19000 web images manually classified by experts. In this work we do not consider the textual contents of the images.	bitmap;color histogram;diagram;grayscale;image histogram;machine learning;rule induction;unified modeling language	Valentin Moreno;Gonzalo Génova;Manuela Alejandres;Anabel Fraga	2016		10.1145/2934732.2934739	computer vision;computer science;machine learning;data mining	Graphics	-13.737961361404846	-59.98516457416216	154042
5bf935268af764654ec3212569d2f76ed4ff58f7	deep compositional cross-modal learning to rank via local-global alignment	local global alignment;learning to rank;compositional embedding	Cross-modal retrieval is a very hot research topic that is imperative to many applications involving multi-modal data. Discovering an appropriate representation for multi-modal data and learning a ranking function are essential to boost the cross-media retrieval. Motivated by the assumption that a compositional cross-modal semantic representation (pairs of images and text) is more attractive for cross-modal ranking, this paper exploits the existing image-text databases to optimize a ranking function for cross-modal retrieval, called deep compositional cross-modal learning to rank (C2MLR). In this paper, C2MLR considers learning a multi-modal embedding from the perspective of optimizing a pairwise ranking problem while enhancing both local alignment and global alignment. In particular, the local alignment (i.e., the alignment of visual objects and textual words) and the global alignment (i.e., the image-level and sentence-level alignment) are collaboratively utilized to learn the multi-modal embedding common space in a max-margin learning to rank manner. The experiments demonstrate the superiority of our proposed C2MLR due to its nature of multi-modal compositional embedding.	database;experiment;imperative programming;learning to rank;modal logic;ranking (information retrieval);smith–waterman algorithm;visual objects	Xinyang Jiang;Fei Wu;Xi Li;Zhou Zhao;Weiming Lu;Siliang Tang;Yueting Zhuang	2015		10.1145/2733373.2806240	computer science;machine learning;pattern recognition;data mining;learning to rank	AI	-15.693962138509596	-65.8745757478452	154403
be48780eb72d9624a16dd211d6309227c79efd43	interactive visual and semantic image retrieval		One direct consequence of recent advances in digital visual data generation and the direct availability of this information through the World-Wide Web, is a urgent demand for efficient image retrieval systems. The disclosure of the content of these millions of photos available on the internet is of great importance. The objective of image retrieval is to allow users to efficiently browse through this abundance of images. Due to the non-expert nature of the majority of the internet users, such systems should be user friendly, and therefore avoid complex user interfaces. Traditionally, two sources of information are exploited in the description of images on the web. The first approach, called text-based image retrieval, describes images by a set of labels or keywords [1]. These labels can be automatically extracted from for example the image name (e.g. ’car.jpg’ would provide information about the presence of a car in the image), or alternatively from the webpage text surrounding the image. Another, more expensive way would be to manually label images with a set of keywords. Shortcomings of the text-based approach to image retrieval are obvious: many objects in the scene will not be labeled, words suffer from the confusions in case of synonyms or homonyms, and words often fall short in describing the esthetics, composition and color scheme of a scene. However, until recently many image retrieval systems, such as e.g. Google-image search, were exclusively text based. A second approach to image description is called content-based image retrieval (CBIR). Here users are provided with feedback from an image-query purely based	browsing;computer vision;content-based image retrieval;feedback;floor and ceiling functions;internet;outline of object recognition;semantic role labeling;sensor;text-based (computing);usability;user interface;web page;world wide web	Joost van de Weijer;Fahad Shahbaz Khan;Marc Masana	2013		10.1007/978-3-642-35932-3_3	computer vision;visual word;image retrieval;computer science;multimedia;automatic image annotation;information retrieval;human–computer information retrieval	Vision	-15.986412869752192	-56.764443157718254	154524
2ef2b3cc3ad84b3dd6a199a445473689309af127	learning a concept hierarchy from multi-labeled documents		While topic models can discover patterns of word usage in large corpora, it is difficult to meld this unsupervised structure with noisy, human-provided labels, especially when the label space is large. In this paper, we present a model—Label to Hierarchy (L2H)—that can induce a hierarchy of user-generated labels and the topics associated with those labels from a set of multi-labeled documents. The model is robust enough to account for missing labels from untrained, disparate annotators and provide an interpretable summary of an otherwise unwieldy label set. We show empirically the effectiveness of L2H in predicting held-out words and labels for unseen documents. 1 Understanding Large Text Corpora through Label Annotations Probabilistic topic models [4] discover the thematic structure of documents from news, blogs, and web pages. Typical unsupervised topic models such as latent Dirichlet allocation [7, LDA] uncover topics from unannotated documents. In many settings, however, documents are also associated with additional data, which provide a foundation for joint models of text with continuous response variables [6, 48, 27], categorical labels [37, 18, 46, 26] or link structure [9]. This paper focuses on additional information in the form of multi-labeled data, where each document is tagged with a set of labels. These data are ubiquitous. Web pages are tagged with multiple directories,1 books are labeled with different categories or political speeches are annotated with multiple issues.2 Previous topic models on multi-labeled data focus on a small set of relatively independent labels [25, 36, 46]. Unfortunately, in many real-world examples, the number of labels— from hundreds to thousands—is incompatible with the independence assumptions of these models. In this paper, we capture the dependence among the labels using a learned tree-structured hierarchy. Our proposed model, L2H—Label to Hierarchy—learns from label co-occurrence and word usage to discover a hierarchy of topics associated with user-generated labels. We show empirically that L2H can improve over relevant baselines in predicting words or missing labels in two prediction tasks. L2H is designed to explicitly capture the relationships among labels to discover a highly interpretable hierarchy from multi-labeled data. This interpretable hierarchy helps improve prediction performance and also provides an effective way to search, browse and understand multi-labeled data [17, 10, 8, 12]. ∗Part of this work was done while the first author interned at Facebook. Open Directory Project (http://www.dmoz.org/) Policy Agenda Codebook (http://policyagendas.org/)	apple open directory;baseline (configuration management);blog;book;browsing;codebook;corpus linguistics;experiment;information;latent dirichlet allocation;meld (software);multi-label classification;perplexity;string interning;text corpus;user-generated content;web page	Viet-An Nguyen;Jordan L. Boyd-Graber;Philip Resnik;Jonathan Chang	2014			computer science;machine learning;pattern recognition;data mining	ML	-17.62096167617285	-64.39497979661503	154675
cb6cc37a1408332f21971df3ab560d0c7f6d709d	mining spatio-temporal patterns and knowledge structures in multimedia collection	time scale;satisfiability;real time data;statistical model;result merging;knowledge structure;multimedia data;temporal pattern;multimedia indexing;content based image retrieval;multi channel cbir	Detection and recognition of semantic events has been a major research challenge for multimedia indexing. An emerging direction in this field has been <u>unsupervised discovery (mining) of patterns</u> in spatial-temporal multimedia data. Patterns are recurrent, predictable occurrences of one or more entities that satisfy associative, statistical, or relational conditions. Patterns at the feature level may signify the occurrence of events (e.g., passing pedestrians). At the event level, patterns may represent multi-event transitions, e.g., play-break alternations in sports. Patterns in an annotated image collection may indicate collocations of related semantic concepts and perceptual clusters.Mining of patterns of different types at different levels offers rich benefits, including automatic discovery of salient events in a new domain, automatic alert generation from massive real-time data (such as surveillance data in a new environment), and discovery of novel event relationships.Many challenging issues emerge. What are the adequate representations and statistical models for patterns that may exist at different levels and different time scales? How to handle patterns that may have relatively sparse occurring frequencies? How do we evaluate the accuracy and quality of mining results given its unsupervised nature?In this talk, we will present results of our preliminary attempts in mining patterns in structured video sequences (such as sports and surveillance video) and large annotated image collections. Specifically, we will discuss the potential of statistical models like Hierarchical HMM for video mining, and the integrative exploration of electronic knowledge (such as WordNet) and statistical clustering for image knowledge mining.	closed-circuit television;cluster analysis;collocation;data mining;entity;hidden markov model;real-time data;recurrent neural network;sparse matrix;statistical model;wordnet	Shih-Fu Chang	2003		10.1145/951676.951677	computer science;data science;data mining;information retrieval	ML	-17.54706100974588	-57.72576808374022	154736
66be409861ae97fecb6c70ef160504574bba6dd7	towards human pose semantic synthesis in 3d based on query keywords		"""The work presented in this paper is part of a project to enable humanoid robots to build a semantic understanding of their environment adopting unsupervised self-learning techniques. Here, we propose an approach to learn 3-dimensional human-pose conformations, i.e. structural arrangements of a (simplified) human skeleton model, given only a minimal verbal description of a human posture (e.g. """"sitting"""", """"standing"""", """"tree pose""""). The only tools given to the robot are knowledge about the skeleton model, as well as a connection to the labeled images database """"google images"""". Hence the main contribution of this work is to filter relevant results from an images database, given a human-pose specific query words, and to transform the information in these (2D) images into a 3D pose that is the most likely to fit the human understanding of the keywords. Steps to achieve this goal integrate available 2D human-pose estimators using still images, clustering techniques to extract representative 2D human skeleton poses, and the 3D-pose from 2D-pose estimation. We evaluate the approach using different query keywords representing different postures."""		Mo'taz Al-Hami;Rolf Lakaemper	2015		10.5220/0005258704200427	natural language processing;computer vision;information retrieval	Robotics	-11.026273700453869	-56.49877986941594	155052
b6a15ae89b94db54701ee67a8f32717a685f40e4	semi-automated logging for professional media applications		We report a novel method for logging and annotating video footage specifically for professional post-production and archivist end users. SALSA – Semi-Automated Logging with Semantic Annotation – is a hybrid system that utilises automated footage analysis for cut detection and camera movement classification, in conjunction with a stenographic-like keyboard input system to enable the logging of higher-level semantic information. Output is presented in both standard printed log form, with the addition of mosaic visual representations of shots, and in a fully searchable database. Results from preliminary experiments are reported.	design rationale;eurographics;experiment;hybrid system;ncsa mosaic;plover;printing;salsa;semiconductor industry;shot transition detection	John W. Mateer;J. A. Robinson	2003			end user;world wide web;archivist;hybrid system;logging;salsa;computer science;annotation	Web+IR	-17.387815965855996	-54.967692762913494	155076
295855f89806cf9cf786daacff0e1c26c1297f23	pfge mapper: a tool to aid in the analysis of pulse field gel electrophoresis maps.	dna;software;outil logiciel;computer program;interfase usuario;carte restriction;software tool;logiciel;computerized processing;tratamiento informatico;user interface;apple macintosh;electroforesis campo pulsado;pulse field gel electrophoresis;electrophorese champ pulse;restriction map;herramienta controlada por logicial;computer aid;logicial;asistencia ordenador;interface utilisateur;mapa restriccion;programa computador;traitement informatique;assistance ordinateur;programme ordinateur;pulsed field electrophoresis	Pulse field gel electrophoresis mapping is an important technique for characterizing large segments of DNA and constructing long-range restriction maps. We have developed a tool, PFGE MAPPER, to aid in the construction of pulse field electrophoresis gel maps. This tool helps construct pulse field gel maps from single and double digest experiments visualized by hybridization with single copy probes. The program is written in Think C and runs on Macintosh computers. An intuitive interface allows the user to interactively modify fragment sizes or errors, select fragments for analysis and recalculate the maps. Maps can be printed or saved for later viewing. After constructing and saving several maps in a region, PFGE MAPPER can be used to refine and extend the overall map by merging individual maps. This tool should be useful for constructing long-range restriction maps of genomic DNA and yeast artificial chromosomes.		Mark A. Shifman	1993	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/9.5.511	biology;simulation;bioinformatics;restriction map;pulsed-field gel electrophoresis;user interface;genetics;dna	Comp.	-4.779927412339334	-56.85157028134193	155227
32f20fa2990c6ee06f61f1230f873cc93eba9c6d	using an image-extended relational database to support content-based image retrieval in a pacs	picture archiving and communication systems pacs;relational database;picture archiving and communication system;multimedia databases;metric structures;content based image retrieval;multimedia database	This paper presents a new Picture Archiving and Communication System (PACS), called cbPACS, which has content-based image retrieval capabilities. The cbPACS answers range and k-nearest- neighbor similarity queries, employing a relational database manager extended to support images. The images are compared through their features, which are extracted by an image-processing module and stored in the extended relational database. The database extensions were developed aiming at efficiently answering similarity queries by taking advantage of specialized indexing methods. The main concept supporting the extensions is the definition, inside the relational manager, of distance functions based on features extracted from the images. An extension to the SQL language enables the construction of an interpreter that intercepts the extended commands and translates them to standard SQL, allowing any relational database server to be used. By now, the system implemented works on features based on color distribution of the images through normalized histograms as well as metric histograms. Metric histograms are invariant regarding scale, translation and rotation of images and also to brightness transformations. The cbPACS is prepared to integrate new image features, based on texture and shape of the main objects in the image.		Caetano Traina;Agma J. M. Traina;Myrian R. B. Araujo;Josiane M. Bueno;Fabio Jun Takada Chino;Humberto Luiz Razente;Paulo Mazzoncini de Azevedo Marques	2005	Computer methods and programs in biomedicine	10.1016/S0169-2607(05)80008-2	data definition language;relational model;radiology;relational database;computer science;database model;data mining;database;picture archiving and communication system;information retrieval;alias;object-relational impedance mismatch;database design	DB	-10.601195428495435	-57.294613341445555	155420
9c5c5b8af38de3812b6024df86826ac74932708a	animated movie activity characterization by image and text information fusion	content based video retrieval system;animated movie activity characterization;video sequence;features extraction;motion pictures;image databases;information extraction;activity detection;local activities;image fusion;constitution;video analysis;video retrieval;text analysis;video sequences;text information fusion;testing;data mining;local activity measurement;information extraction activity detection information fusion video analysis;global activity measurement;indexing;feature extraction;animation;expert knowledge;information fusion;content based video retrieval;video retrieval computer animation content based retrieval feature extraction image fusion image sequences text analysis;computer animation;information analysis;content based retrieval;automatic summary;video sequence animated movie activity characterization image fusion text information fusion features extraction automatic summary content based video retrieval system global activity measurement local activity measurement;animation motion pictures data mining indexing testing information analysis image databases video sequences feature extraction constitution;image sequences	In the context of animated movie characterization, we present an information fusion approach mixing very different types of data related to the activity within a movie. These data are the features extracted from images, words extracted from the synopses and expert knowledge. The difficulty of this fusion is due to the very different semantic level of these data. The aim of this work is to get a movie activity characterization in order to help the constitution of automatic summary, content based video retrieval system, etc. Two strategies are proposed : a first one aiming at giving a global description of the activity within the movie, and a second one providing a local description of activity. Tests and results are proposed on animated movies from the Annecy International Animation Film Festival.		Grégory Païs;Françoise Deloule;Daniel Beauchêne;Patrick Lambert	2009	2009 12th International Conference on Information Fusion		computer vision;computer science;multimedia;information retrieval	Vision	-13.755821658055128	-55.6664447478843	155605
e2699ce05c6d0b0b730c369911ee32d39629c6dd	towards a multiscale, high-resolution model of the human brain	juser;websearch;publications database	To understand the microscopical organization including cellular and fiber architecture it is a necessary prerequisite to build models of the human brain on a sound biological basis. We have recently pushed the limits of current technology by creating the first ultra-high resolution 3D-model of the human brain at nearly cellular resolution of 20 microns, the BigBrain model. At the same time, 3D Polarized Light Imaging provides a window to analyze the fiber architecture, i.e., the way, how brain regions are inter-connected, with unprecedented spatial resolution at the micrometer level. Considering the complexity and the pure size of the human brain with its nearly 86 billion nerve cells, both approaches are most challenging with respect to data handling and analysis in the TeraByte to PetaByte range, and require supercomputers. Parallelization and automation of image processing steps open up new perspectives to speed up the generation of new, ultra-high resolution models of the human brain, to provide new insights into the three-dimensional micro architecture of the human brain.	3d modeling;acm/ieee supercomputing conference;archive;automatic parallelization;bigbrain;computation;cyberinfrastructure;data access;global variable;image processing;image resolution;modal logic;pl/i;parallel computing;petabyte;polarization (waves);requirement;supercomputer;terabyte;time complexity;unicore;voxel	Katrin Amunts;Oliver Bücker;Markus Axer	2013		10.1007/978-3-319-12084-3_1	bioinformatics;data science;data mining	ML	-8.51761785471657	-54.05824986855959	155631
69e1fddfa91bb9c6a844032c96ac18c239bad22c	3d atlas of the brain, head and neck in 2953 pieces		Brain atlasing is a vital field of research and development in neuroinformatics. Numerous brain atlases have been constructed in health and disease having a wide spectrum of use ranging from education to research to clinical applications. Some reviews of brain atlases are presented elsewhere. Our contribution to the field has been in brain atlas building and developing atlas-based applications. This work along with the taxonomy of the created atlases has been summarized in. Our efforts have resulted in 35 commercial brain atlases (along with numerous research prototypes), licensed to 67 companies and institutions, and made available to medical societies, organizations, medical schools and individuals in about 100 countries. These atlases have been employed in education, research and clinical applications. Hundreds of thousands of patients have been treated by using our atlases available in surgical workstations. The design of our atlases is top-down, holistic, and has been guided by research, clinical and market perspectives. After the development of several commercial 2D and 3D	3d computer graphics;atlases;brain atlas;brain implant;cervical atlas;holism;neuroinformatics;patients;review [publication type];school;schools, medical;societies;societies, medical;taxonomy;top-down and bottom-up design;workstation	Wieslaw Lucjan Nowinski	2017	Neuroinformatics	10.1007/s12021-017-9339-8	computer vision;brain atlas;artificial intelligence;computer science;atlas (anatomy)	ML	-9.107809564275199	-54.0592364645711	156055
047bc4c67b12c771baf145cd4ea9333dbf28eb83	the mpeg-7 visual standard for content description-an overview	search engine;video similarity measurement;image motion analysis;formal specification;norme iso;object shape;multimedia;image similarity measurement;image processing;video signal processing;data description;search engines;information retrieval;information visuelle;visual content description mpeg 7 visual standard content based descriptors search engines image similarity measurement video similarity measurement visual criteria object color object texture object shape global motion object motion features;norma iso;visual criteria;filters;content based descriptors;object texture;indexing terms;iso standard;similitude;image texture;specification formelle;especificacion formal;standards development;informacion visual;feature extraction telecommunication standards video signal processing image processing image texture image motion analysis;senal video;shape;signal video;indexing;recherche information;visual information;feature extraction;telecommunication standards;indexation;similarity;indizacion;video signal;object motion features;object color;mpeg 7 standard image retrieval information retrieval filters content based retrieval standards development shape measurement standards search engines standardization;recuperacion informacion;interoperability;similitud;content description;visual content description;measurement standards;mpeg 7 standard;global motion;content based retrieval;standardization;description donnee;mpeg 7;mpeg 7 visual standard;image retrieval	The MPEG-7 Visual Standard under development specifies content-based descriptors that allow users or agents (or search engines) to measure similarity in images or video based on visual criteria, and can be used to efficiently identify, filter, or browse images or video based on visual content. More specifically, MPEG-7 specifies color, texture, object shape, global motion, or object motion features for this purpose. This paper outlines the aim, methodologies, and broad details of the MPEG-7 Standard development for visual content description.	browsing;mpeg-7;web search engine	Thomas Sikora	2001	IEEE Trans. Circuits Syst. Video Techn.	10.1109/76.927422	computer vision;image processing;image retrieval;computer science;multimedia;information retrieval;search engine	Vision	-12.805912366386213	-57.03283505970604	156208
8450b87f939729ee930e1b9776e675c1cd306e67	content-based image retrieval through a multi-agent meta-learning framework	image distance weights;distance function;query processing;information retrieval content based image retrieval multiagent metalearning framework query processing image distance weights image queries;information retrieval;image queries;similarity solution;multi agent systems content based retrieval image retrieval learning artificial intelligence;learning systems;multi agent systems;image retrieval content based retrieval clustering algorithms government information retrieval image databases feedback computer science prediction algorithms humans;multiagent metalearning framework;learning artificial intelligence;content based image retrieval;content based retrieval;image retrieval	The objective of a general-purpose content-based image retrieval system is to find images in a database that match an external measure of relevance. Since users follow different and inconsistent relevance measures, processing queries in a task-specific manner has shown to be an effective approach. Viewing specialized image retrieval algorithms as agents, we propose a general-purpose image retrieval system that uses a new multi-agent meta-learning framework. The framework adapts a distance function defined over both image distance weights and image queries to identify clusters of algorithms that produce similar solutions to similar problems. Experiments compare our approach with a traditional information retrieval algorithm; results show that our framework provides better average relevance scores	adaptive filter;agent-based model;algorithm;cluster analysis;content-based image retrieval;general-purpose modeling;information retrieval;interaction;machine learning;matchware mediator;multi-agent system;relevance	Abraham Bagherjeiran;Ricardo Vilalta;Christoph F. Eick	2005	17th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'05)	10.1109/ICTAI.2005.50	computer vision;visual word;metric;image retrieval;computer science;artificial intelligence;data mining;automatic image annotation;information retrieval	Vision	-10.431572390242858	-58.49611680991198	156291
2a200432f71bf19c8efe19b686799e94226e2d32	action scene detection with support vector machines	scene classification;temporal dynamics;indexing terms;support vector;detection algorithm;video content analysis;support vector machine;semantic relations	To entice the target audience into paying to see the full movie, the production of movie trailers is an integral part of movie industry. Action scene is the main component of a movie trailer. In this paper, we propose an automatic action scene detection algorithm based on the analysis of high-level video structure. The input video is first decomposed into a number of basic components called shots. Then, shots are grouped into semantic-related scenes by taking into account the visual characteristics and temporal dynamics of video. Based on the filmmaking characteristics of action scene, some features of the scene are extracted to feed into the support vector machine for classification. Compared with related works which integrate visual and audio information, our visual-based approach is computationally simple yet effective.	algorithm;database;effective method;floor and ceiling functions;high- and low-level;sensor;support vector machine	Liang-Hua Chen;Chih-Wen Su;Chi-Feng Weng;Hong-Yuan Mark Liao	2009	Journal of Multimedia	10.4304/jmm.4.4.248-253	support vector machine;computer vision;computer science;machine learning;pattern recognition;multimedia	Vision	-13.843849324714062	-55.85503040780092	156787
4007643eddbea0af2c6337d360b6474652f32223	factorial lda: sparse multi-dimensional text models		Latent variable models can be enriched with a multi-dimensional structure to consider the many latent factors in a text corpus, such as topic, author perspective and sentiment. We introduce factorial LDA, a multi-dimensional model in which a document is influenced by K different factors, and each word token depends on a K-dimensional vector of latent variables. Our model incorporates structured word priors and learns a sparse product of factors. Experiments on research abstracts show that our model can learn latent factors such as research topic, scientific discipline, and focus (methods vs. applications). Our modeling improvements reduce test perplexity and improve human interpretability of the discovered factors.	experiment;jason;latent variable;linear discriminant analysis;local-density approximation;perplexity;sparse matrix;text corpus;text mining	Michael J. Paul;Mark Dredze	2012			latent variable;natural language processing;computer science;machine learning;pattern recognition;probabilistic latent semantic analysis;statistics	ML	-16.628550942610172	-63.90062959539144	157064
7a71abd69ba7d70048a4116780df626c7739ecb5	comparison of pneumolysin genes and proteins from streptococcus pneumoniae types 1 and 2	dna;streptococcaceae;bacterie;amino acid sequence;gen;micrococcales;secuencia nucleotido;journal article;nucleotide sequence;sequence nucleotide;clonacion molecular;science technology;streptolysins;sequence homology nucleic acid;life sciences biomedicine;clonage moleculaire;gene;biochemistry molecular biology;molecular cloning;pneumolysine;molecular sequence data;bacteria;base sequence;genes bacterial;streptococcus pneumoniae;bacterial proteins	Full textFull text is available as a scanned copy of the original print version. Get a printable copy (PDF file) of the complete article (78K), or click on a page image below to browse page by page. Links to PubMed are also available for Selected References.#R##N##R##N##R##N##R##N##R##N#4010#R##N##R##N##R##N##R##N##R##N##R##N#Selected References#R##N#These references are in PubMed. This may not be the complete list of references from this article. #R##N##R##N#Walker JA, Allen RL, Falmagne P, Johnson MK, Boulnois GJ. Molecular cloning, characterization, and complete nucleotide sequence of the gene for pneumolysin, the sulfhydryl-activated toxin of Streptococcus pneumoniae. Infect Immun. 1987 May;55(5):1184–1189. [PMC free article] [PubMed]#R##N#Paton JC, Berry AM, Lock RA, Hansman D, Manning PA. Cloning and expression in Escherichia coli of the Streptococcus pneumoniae gene encoding pneumolysin. Infect Immun. 1986 Oct;54(1):50–55. [PMC free article] [PubMed]#R##N#Kehoe MA, Miller L, Walker JA, Boulnois GJ. Nucleotide sequence of the streptolysin O (SLO) gene: structural homologies between SLO and other membrane-damaging, thiol-activated toxins. Infect Immun. 1987 Dec;55(12):3228–3232. [PMC free article] [PubMed]	pneumonia;streptococcus pneumoniae	Tim J Mitchell;F. Mendez;James C Paton;P. W. Andrew;G. J. Boulnois	1990	Nucleic acids research	10.1093/nar/18.13.4010	molecular cloning;biology;bacteria;nucleic acid sequence;bioinformatics;gene;peptide sequence;microbiology;genetics;dna	ML	-5.123018824591203	-57.036269425210534	157293
432bddc6cac678a91bc77a2115310a7dd262dddb	sequence prediction exploiting similary information		When data is scarce or the alphabet is large, smoothing the probability estimates becomes inescapable when estimating n-gram models. In this paper we propose a method that implements a form of smoothing by exploiting similarity information of the alphabet elements. The idea is to view the log-conditional probability function as a smooth function defined over the similarity graph. The algorithm that we propose uses the eigenvectors of the similarity graph as the basis of the expansion of the log conditional probability function whose coefficients are found by solving a regularized logistic regression problem. The experimental results demonstrate the superiority of the method when the similarity graph contains relevant information, whilst the method still remains competitive with state-of-the-art smoothing methods even in the lack of such information.	algorithm;basis function;bigram;coefficient;grams;information retrieval;language model;logistic regression;n-gram;norm (social);principle of maximum entropy;smoothing;spectral graph theory;string (computer science);while;whole earth 'lectronic link	István Bíró;Zoltán Szamonek;Csaba Szepesvári	2007				AI	-15.209539595436855	-66.06992793265604	157305
2261937b3f67689dc9fba75c781e90c6d20b44e7	automated identification and retrieval of moth images with semantically related visual attributes on the wings	biology computing;object recognition;object recognition biology computing content based retrieval image retrieval;attribute cooccurrence pattern detection entomological image identification and retrieval semantically related visual attribtues;entomology database automated moth image identification moth image retrieval semantically related visual attributes entomologists insect specimen images computer based processing techniques computer based analyzing techniques manually labeled training samples srv attribute detector image visual contents cooccurrence patterns wing structures species identification content based image retrieval;content based retrieval;image retrieval	A new automated identification and retrieval system is proposed that aims to provide entomologists, who manage insect specimen images, with fast computer-based processing and analyzing techniques. Several relevant image attributes were designed, such as the so-called semantically-related visual (SRV) attributes detected from the insect wings and the co-occurrence patterns of the SRV attributes which are uncovered from manually labeled training samples. A joint probabilistic model is used as SRV attribute detector working on image visual contents. The identification and retrieval of moth species are conducted by comparing the similarity of SRV attributes and their co-occurrence patterns. The prototype system used moth images while it can be generalized to any insect species with wing structures. The system performed with good stability and the accuracy reached 85% for species identification and 71% for content-based image retrieval on a entomology database.	biological specimen;content-based image retrieval;prototype;statistical model	Linan Feng;Bir Bhanu	2013	2013 IEEE International Conference on Image Processing	10.1109/ICIP.2013.6738531	computer vision;visual word;image retrieval;computer science;cognitive neuroscience of visual object recognition;automatic image annotation;information retrieval	Vision	-14.519733623649277	-58.607096546075	157406
86f8f53174524e331abf9eb814c39d253cf3be29	optimization-based automated home video editing system	analisis contenido;optimisation;non linear programming;audio signal processing;video summarization optimization automated home video editing system incidental music video segment temporal structure extraction beat extraction tempo extraction nonlinear 0 1 programming transition effects music analysis video content analysis;video summarization;edicion;optimizacion;nonlinear programming;video signal processing;programacion no lineal;edition;publishing;video segmentation;programmation non lineaire;indexing terms;satisfiability;content analysis;integer programming;music analysis;video editing;multimedia communication;video content analysis;analyse contenu video;video sharing video equipment programming profession joining processes watches turning algorithm design and analysis multimedia systems asia time measurement;optimization;analyse contenu;communication multimedia;content based retrieval;music;sommarisation;recherche par contenu;audio signal processing video signal processing music integer programming nonlinear programming;analyse musique	In this paper, we present an optimization-based system that automates home video editing. This system automatically selects suitable or desirable highlight segments from a set of raw home videos and aligns them with a given piece of incidental music to create an edited video segment to a desired length based on the content of the video and incidental music. We developed an approach for extracting temporal structure and determining the importance of a video segment in order to facilitate the selection of highlight segments. Additionally we extract a temporal structure, beats, and tempos from the incidental music. In order to create more professional-looking results, the selected highlight segments satisfy a set of editing rules and are matched to the content of the incidental music. This task is formulated as a nonlinear 0-1 programming problem and the rules, which are adjustable and increasable, are embedded as constraints. The output video is rendered by connecting the selected highlight video segments with transition effects and the incidental music. Under this framework, we can choose the best-matched music for a given video and support different output styles.	embedded system;mathematical optimization;nonlinear system	Xian-Sheng Hua;Lie Lu;HongJiang Zhang	2004	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2004.826750	computer vision;speech recognition;telecommunications;audio signal processing;nonlinear programming;computer science;machine learning;video tracking;music;mathematics;publishing;multimedia;algorithm;computer graphics (images)	HCI	-14.72031747884042	-53.831508594742516	157489
b3d7d38ea904f936187283fa5c2291eec5f86d29	multi-modal interactive approach to imageclef 2007 photographic and medical retrieval tasks by cindi	vector space model;information retrieval;data fusion;matching function;medical image;feature extraction;indexation;image search;query expansion;content based image retrieval;relevance feedback;multi modal interaction;image retrieval	This paper presents the contribution of CINDI group to the ImageCLEF 2007 ad-hoc retrieval tasks. We experiment with multi-modal (e.g., image and text) interaction and fusion approaches based on relevance feedback information for image retrieval tasks of photographic and medical image collections. For a text-based image search, keywords from the annotated files are extracted and indexed by employing the vector space model of information retrieval. For a content-based image search, various global, semi-global, region-specific and visual concept-based features are extracted at different levels of image abstraction. Based on relevance feedback information, multiple textual and visual query refinements are performed and user’s perceived semantics are propagated from one modality to another with query expansion. The feedback information also dynamically adjusts intra and inter-modality weights in linear combination of similarity matching functions. Finally, the top ranked images are obtained by performing both sequential and simultaneous retrieval approaches. The analysis of results of different runs are reported in this paper.	hoc (programming language);image retrieval;information retrieval;medical imaging;modal logic;modality (human–computer interaction);query expansion;relevance feedback;semiconductor industry;text-based (computing)	Md. Mahmudur Rahman;Bipin C. Desai;Prabir Bhattacharya	2007			computer vision;query expansion;visual word;image retrieval;computer science;concept search;pattern recognition;automatic image annotation;vector space model;information retrieval;human–computer information retrieval	Vision	-15.694185143027099	-59.4928092279496	158008
4b76935a2484f0737e55e62ae627f35335817320	comparing keyword extraction techniques for websom text archives	som labeling;data compression;text archives;webson;keyword extraction;lightsom method;random projection	The WEBSOM methodology for building very large text archives has a very slow method for extracting meaningful unit labels. This is due to the fact that the method computes for the relative frequencies of all the words of all the documents associated to each unit and then compares these to the relative frequencies of all the words of other units in the map. Since maps may have more than 100,000 units and the archieve may contain up to 7 million documents, the existing WEBSOM method is not practical. A fast alternative method, referred to as the liGHtSOM method, is based on the distribution of weights in the weight vectors of the trained map, plus a simple manipulation of the random projection matrix used for input data compression. Comparison made using a WEBSOM archieve of the Reuters text collection reveal that a high percentage of keywords extracted using this method match the keywords extracted for the same map units using the original WEBSOM method. A detailed time complexity analysis of the two methods is also provided.	keyword extraction	Arnulfo P. Azcarraga;Teddy N. Yap;Tat-Seng Chua	2002	International Journal on Artificial Intelligence Tools	10.1142/S0218213002000861	data compression;computer science;pattern recognition;data mining;information retrieval;statistics	DB	-15.29960754417079	-63.82665427518428	158029
8a3ac366fded1e789b9044511c1ca25c041841d5	robust scene recognition using language models for scene contexts	statistical approach;context information;hidden markov model;hmm;n gram model;sports video;indexing;indexation;language model;cbvir	We propose a robust scene recognition framework using scene context information for multimedia contents. Multimedia contents con-sist of scene sequences that are more likely to happen compared with other scene sequences. We employ a statistical approach to deal with this scene context information. We employ a hidden Markov model (HMM) to model each scene and n-gram language model to represent the contexts among scenes. We evaluated the proposed method in scene recognition experiments for 16 scenes in video data of 25 baseball games. The proposed method significantly improved the results compared to that without scene context information.	experiment;hidden markov model;language model;markov chain;n-gram;naruto shippuden: clash of ninja revolution 3	Ryoichi Ando;Koichi Shinoda;Sadaoki Furui;Takahiro Mochizuki	2006		10.1145/1178677.1178693	computer vision;search engine indexing;speech recognition;scene statistics;computer science;machine learning;pattern recognition;hidden markov model	Vision	-17.606418075027744	-58.263484151156256	158151
66fbc215a1e4d7a9854b962188125f80c22b1c96	learning to detect malicious urls	online learning;geoffrey m voelker ma justin tung;malicious web sites;computer science learning to detect malicious urls university of california san diego stefan savage	Malicious Web sites are a cornerstone of Internet criminal activities. The dangers of these sites have created a demand for safeguards that protect end-users from visiting them. This article explores how to detect malicious Web sites from the lexical and host-based features of their URLs. We show that this problem lends itself naturally to modern algorithms for online learning. Online algorithms not only process large numbers of URLs more efficiently than batch algorithms, they also adapt more quickly to new features in the continuously evolving distribution of malicious URLs. We develop a real-time system for gathering URL features and pair it with a real-time feed of labeled URLs from a large Web mail provider. From these features and labels, we are able to train an online classifier that detects malicious Web sites with 99% accuracy over a balanced dataset.	malware;online algorithm;online machine learning;real-time computing;real-time web	Justin Ma;Lawrence K. Saul;Stefan Savage;Geoffrey M. Voelker	2010	ACM TIST	10.1145/1961189.1961202	semantic url;artificial intelligence;machine learning;internet privacy;world wide web	ML	-19.032179314345534	-55.62781430857439	158160
07b601065684d04744e41bcac86112dbbce54b24	data mining based collaborative analysis of microarray data	databases;biology computing;groupware;text mining;collaboration;data integration data mining based collaborative analysis biomedical research multidisciplinary collaborations collaborative decision making support environment gene expression micro array data data repositories descriptive attributes;gene expression data;data mining;gene expression;groupware biology computing data integration data mining decision making decision support systems;collaboration data mining databases decision making gene expression bioinformatics;decision support systems;text mining decision making collaboration gene expression data;data integration;bioinformatics	Biomedical research has recently seen a vast growth in publicly and instantly available information, which are often complementary or overlapping. As the available resources become more specialized, there is a growing need for multidisciplinary collaborations between biomedical researchers to address complex research questions. We present an application of a data-mining algorithm to gene-expression data in a collaborative decision-making support environment, as a typical example of how multidisciplinary researchers can collaborate in analyzing and biologically interpreting gene-expression micro array data. Through the proposed approach, researchers can easily decide about which data repositories should be considered, analyze the algorithmic results, discuss the weaknesses of the patterns identified, and set up new iterations of the data mining algorithm by defining other descriptive attributes or integrating other relevant data.	algorithm;computer performance;data mining;data-intensive computing;interoperability;iteration;microarray;real life;usability;user interface	Georgia Tsiliki;Sophia Kossida;Natalja Friesen;Stefan Rüping;Manolis Tzagarakis;Nikos I. Karacapilidis	2012	2012 IEEE 24th International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2012.97	text mining;gene expression;computer science;bioinformatics;data science;data integration;data mining;collaboration	HPC	-6.24587153632712	-61.61068182343057	158491
dc87ff90f98beae59c03a88d99c73d19512138bd	integrated explorer for cosmological evolution		Our system design is motivated by the need to simultaneously observe multiple data modalities. The main output from the cosmological simulation is a set of particle data, where each particle represents a dark matter parcel which coalesces into larger structures over time. Next, the data is run through a halo finding algorithm (Rockstar [1]), which detects groups of gravitationally bound particles and identifies them as halos. Lastly, a merger tree generation tool (Consistent Trees [2]) analyzes the hierarchical evolution of halos as they continue to merge into larger structures. Although each of these data modalities are generated through an iterative process, an understanding of their interplay is essential. Since information about the raw particle data and the extracted halos inform one another, we designed a multi-view exploration tool and enhance these views with both qualitative and quantitative information. Because of the scale of the data and the multitude of features, we aim to provide capability to both locate and focus analysis on specific features of interest.	algorithm;dark matter;gravitational binding energy;iteration;simulation;systems design	Annie Preston;Franz Sauer;Ramyar Ghods;Nick Leaf;Jingrong Xie;Kwan-Liu Ma	2015	2015 IEEE Scientific Visualization Conference (SciVis)	10.1109/SciVis.2015.7429499	simulation;bioinformatics;physics	Visualization	-6.56753232990401	-60.69373661422163	158961
ccb08ad272cae4705a45c7a642a133b4bbbe49bc	leveraging knowledge-based inference for material classification	material classification;knowledge extraction;graphical model	Material classification is one of the fundamental problems for multimedia content analysis, computer vision and graphics. Existing efforts mostly focus on extracting representative visual features and training a classifier to recognize unknown materials. Compared with human visual recognition, automatic recognition cannot leverage common sense knowledge regarding material categories and contextual information such as object and scene. In this paper, we propose to first extract such knowledge on material, object and scene from heterogeneous sources, i.e. a public data set of 100 million Flickr images [13] and Bing search results. To improve the material classification task, the knowledge information is further exploited in a probabilistic inference framework. Our method is evaluated on OpenSurfaces [10], the largest public material data set which contains both visual features of physical properties as well as image context information. The quantitative evaluation demonstrates the superior performance of our proposed method.	commonsense knowledge (artificial intelligence);computer vision;flickr;graphics;information privacy;speech recognition;statistical classification	Jie Yu;Sandra Skaff;Liang Peng;Francisco H. Imai	2015		10.1145/2733373.2806327	computer vision;computer science;data science;machine learning;pattern recognition;data mining;graphical model;knowledge extraction;world wide web	Vision	-15.877347460569354	-60.616775790865	159188
41f178552a54b8fd1fbe9d45f3f89fee6157be2b	audio indexing: what has been accomplished and the road ahead	web search engine;indexation;language identification	This paper presents an overview of audio indexing, which has emerged very recently as a research topic with the development of Internet. A lot of data, including audio data, are currently not indexed by web search engines, and audio indexing consists in finding good descriptors of audio documents which can be used as indexes for archiving and search. We discuss speech/music segmentation, language identification, speaker tracking and speaker indexing, and propose some research directions for other audio descriptors which have not been used in the framework of audio indexing, namely key sounds detection, keywords detection, and themes detection. We finally conclude this overview and give a few promising and key perspectives.	archive;internet;language identification;web search engine	Ivan Magrin-Chagnolleau;Nathalie Vallès-Parlangeau	2002			the internet;audio mining;information retrieval;web search engine;search engine indexing;search engine;language identification;indexation;computer science	Web+IR	-15.776877505863249	-57.37577541274957	159451
02906a514ae06e9688c1e65cfd55cf5bc89f1821	microcomputer-based three-dimensional stereoscopic macromolecular graphics display	microordenador;biological macromolecule;proteine;conformation;macromolecula biologica;three dimensional;microordinateur;microcomputer;conformacion;proteins;macromolecule biologique;proteina;acido nucleico;acide nucleique;image stereoscopique;nucleic acid	Software which permits an IBM AT and two IBM Professional Graphics Displays to be used to display high-quality three-dimensional space-filling stereoscopic images of macromolecules is described. Stereo image pairs generated on two screens are visually fused using a simple mirror system to provide binocular depth perception. Images are colored to identify atomic type, residue type, charge or hydrophobicity according to user-specified codes and can be rotated and rescaled. Macromolecules containing over 16,000 atoms can be rapidly drawn using Brookhaven Protein Data Bank or user-supplied coordinates.	binocular vision;code;depth perception;graphics;ibm pc at (system unit 5170);inclusion body myositis (disorder);license;microcomputer;protein data bank;providing (action);stereopsis;stereoscopy;macromolecule	D. Shalloway;S. F. Sneddon;E. K. Little	1988	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/4.1.193	biology;three-dimensional space;biochemistry;nucleic acid;biophysics;computer science;bioinformatics;microcomputer;genetics	Graphics	-5.328530763848672	-56.917598243395055	159951
e79fb81879926491e52b0d58ead1688d81694cf8	fingerprinting for scanned comics content identification	content management;histograms;information retrieval;image sequences content management feature extraction fingerprint identification humanities;data mining;comics fingerprinting identification;internet;humanities;fingerprinting;fingerprint recognition;cut position sequence scanned comics content identification rate fingerprinting identification comic image cuts position information box frame detection cut information extraction cut sequence analysis normalized box frame image histogram;feature extraction;identification;comics;fingerprint recognition feature extraction histograms design methodology information retrieval data mining internet;fingerprint identification;image sequences;design methodology	In this paper, we propose a fingerprinting to identify comics content using cut information of a comic image. Based the characteristics of a comic image that it consists of several cuts, we design a fingerprinting method which uses the position information of cuts in comic images. Our fingerprinting includes box frame detection, cut information extraction, and cut sequence analyzing. Box frame detection is to detect a normalized box frame from each comic image. Cut information extraction is to extract cut positions using image histogram. We enhanced the identification rate using a sequence of cut positions.	fingerprint (computing);image histogram;information extraction	Jihyun Park;Sang-Kwang Lee;Young-Suk Yoon;Won-Yong Yoo	2012	2012 International Conference on ICT Convergence (ICTC)	10.1109/ICTC.2012.6386786	computer vision;computer science;multimedia;world wide web	Robotics	-13.634970378607816	-54.320528095755215	160205
dc031e639eb61084b54d994cbbd87cc7c46199a8	some heuristics for nearest-neighbor searching in chemical structure files	nearest neighbor search;chemical structure		heuristic (computer science)	Peter Willett	1983	Journal of Chemical Information and Computer Sciences	10.1021/ci00037a004	ball tree;best bin first;chemistry;computer science;organic chemistry;cover tree;chemical structure;nearest neighbor search	Theory	-6.295221449122336	-54.167657989604756	160238
1b06d2e7abd38d6bda186af2c12a6bc888904003	semi-supervised learning for detecting human trafficking	human trafficking;backpage;semi-supervised support vector machines;laplacian support vector machines	Human trafficking is one of the most atrocious crimes and among the challenging problems facing law enforcement which demands attention of global magnitude. In this study, we leverage textual data from the website “Backpage”—used for classified advertisement—to discern potential patterns of human trafficking activities which manifest online and identify advertisements of high interest to law enforcement. Due to the lack of ground truth, we rely on a human analyst from law enforcement, for hand-labeling a small portion of the crawled data. We extend the existing Laplacian SVM and present $$S^3VM-R$$ S 3 V M - R , by adding a regularization term to exploit exogenous information embedded in our feature space in favor of the task at hand. We train the proposed method using labeled and unlabeled data and evaluate it on a fraction of the unlabeled data, herein referred to as unseen data, with our expert’s further verification. Results from comparisons between our method and other semi-supervised and supervised approaches on the labeled data demonstrate that our learner is effective in identifying advertisements of high interest to law enforcement.	embedded system;feature vector;ground truth;iterative method;javascript;laplacian matrix;online advertising;ps (unix);semi-supervised learning;semiconductor industry;sensor;supervised learning;text corpus	Hamidreza Alvari;Paulo Shakarian;J. E. Kelly Snyder	2017	Security Informatics	10.1186/s13388-017-0029-8	labeled data;computer science;support vector machine;data mining;machine learning;artificial intelligence;semi-supervised learning;law enforcement;ground truth;feature vector;exploit	AI	-18.8382316120239	-55.51841391049583	160299
372fe6710e121fe5a4db9defefe9cec84fd1376e	wide and deep learning for peer-to-peer lending		Wide and Deep Learning for Peer-to-Peer Lending Kaveh Bastani*, Elham Asgari, Hamed Namavari Unifund CCR, LLC, Cincinnati, OH Pamplin College of Business, Virginia Polytechnic Institute, Blacksburg, VA Economics, College of Business, University of Cincinnati, Cincinnati, OH Abstract This paper proposes a two-stage scoring approach to help lenders decide their fund allocations in the peer-to-peer (P2P) lending market. The existing scoring approaches focus on only either probability of default (PD) prediction, known as credit scoring, or profitability prediction, known as profit scoring, to identify the best loans for investment. Credit scoring fails to deliver the main need of lenders on how much profit they may obtain through their investment. On the other hand, profit scoring can satisfy that need by predicting the investment profitability. However, profit scoring completely ignores the class imbalance problem where most of the past loans are non-default. Consequently, ignorance of the class imbalance problem significantly affects the accuracy of profitability prediction. Our proposed two-stage scoring approach is an integration of credit scoring and profit scoring to address the above challenges. More specifically, stage 1 is designed as credit scoring to identify non-default loans while the imbalanced nature of loan status is considered in PD prediction. The loans identified as non-default are then moved to stage 2 for prediction of profitability, measured by internal rate of return. Wide and deep learning is used to build the predictive models in both stages to achieve both memorization and generalization. Extensive numerical studies are conducted based on real-world data to verify the effectiveness of the proposed approach. The numerical studies indicate our two-stage scoring approach outperforms the existing credit scoring and profit scoring approaches.	algorithm;benchmark (computing);decision tree;deep learning;infinite impulse response;information privacy;inter-rater reliability;logistic regression;numerical analysis;oversampling;peer-to-peer lending;predictive modelling;sampling (signal processing);social media;tensorflow;undersampling	Kaveh Bastani;Elham Asgari;Hamed Namavari	2018	CoRR		machine learning;finance;profitability index;internal rate of return;deep learning;probability of default;peer-to-peer;memorization;loan;mathematics;artificial intelligence	AI	-18.918170315946607	-52.46207286925361	160361
31ce661dc2eb1fcad2597dbce89264edbd129cc8	image retrieval system based on machine learning and using color features	base donnee;learning algorithm;content based image retrieval cbir;computer and information science;database;base dato;image;algorithme apprentissage;apprentissage machine;systeme conversationnel;human face;machine learning;imagen;interactive system;sistema conversacional;query;visage human;content based image retrieval;algoritmo aprendizaje;forme couleur;requete;image retrieval	We describe an interactive system for content based image retrieval. The system presents the user with 15 randomly selected images from the database. The user grades the images with one of five possible grades (YES, yes, neutral, no, NO) according to what he is looking for. The system returns the first 15 images with the highest probability of YES grade. The attributes used are a combination of color features. Three different machine learning techniques are compared.	color;content-based image retrieval;database;face (geometry);interactivity;k-nearest neighbors algorithm;machine learning;randomness;web search engine	Janez Demsar;Dragan Radolovic;Franc Solina	1999		10.1007/3-540-48375-6_58	computer vision;image retrieval;computer science;artificial intelligence;machine learning;image;database;information retrieval	Web+IR	-12.513700169972585	-60.526066518186944	160834
be29b1216213b9643957ace3485d359500e20a88	naming persons in news video with label propagation	unlabeled data;iterative label propagation;video signal processing face recognition image classification iterative methods support vector machines;bbc news videos;learning process;label propagation;measurement;support vector machines;video signal processing;cross media mining;training;psi_visics;image classification;image annotation;iterative methods;support vector machine classifier;face recognition;streaming media;multimedia communication;video content identification;news video;video frames;clustering algorithms;face;image annotation cross media mining;support vector machine;face measurement labeling training streaming media clustering algorithms multimedia communication;video transcript;face classification techniques;support vector machine classifier news video label propagation video frames video transcript video content identification iterative label propagation face classification techniques bbc news videos;labeling	Labeling persons appearing in video frames with names detected from the video transcript helps improving the video content identification and search task. We develop a face naming method that learns from labeled and unlabeled examples using iterative label propagation in a graph of connected faces or name-face pairs. The advantage of this method is that it can use very few labeled data points and incorporate the unlabeled data points during the learning process. Anchor detection and metric learning for face classification techniques are incorporated into the label propagation process to help boosting the face naming performance. On BBC News videos, the label propagation algorithm yields better results than a Support Vector Machine classifier trained on the same labeled data.	data point;digital video;iterative method;label propagation algorithm;software propagation;support vector machine;unsupervised learning	Phi The Pham;Marie-Francine Moens;Tinne Tuytelaars	2010	2010 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2010.5583271	facial recognition system;support vector machine;computer vision;speech recognition;computer science;machine learning;multimedia;automatic image annotation	Vision	-17.03578936404752	-61.419194947847096	161120
d1589500f71b2918a91bfde663ad074671b373a5	the feedback approach to cartographic areal text placement	feedback approach;cartographic areal text placement	For proper labeling of a bounded region in a geographic map, the label (text) should normally be placed (and spread out) so as to conform to the size and shape of the region and be easily perceived. To accomplish this automatically has proved to be a challenging task because of the infinite variations in shape and size that can be encountered and the requirement for avoiding overlap with other text or features. This paper describes a new approach toward solving this problem. Rather than attempting to develop an algorithm for directly accomplishing the task, the method employs a feedback approach, wherein an initial placement is made using a general placement algorithm, the result is evaluated according to established placement criteria, and the placement is then progressively modified to reduce deviation from the ideal. The technique has potential application also to other complex, two-dimensional shape-understanding problems.		I. Pinto;Herbert Freeman	1996		10.1007/3-540-61577-6_35	computer science;theoretical computer science;data mining;information retrieval	NLP	-18.375305031543174	-60.113401951137426	161271
ee9561e41c03bc484806aebb35c09b0b71f927f7	size functions for image retrieval: a demonstrator on randomly generated curves	representacion conocimientos;donnee textuelle;recherche image;shape descriptor;dato textual;information retrieval;piecewise smooth;semantics;forma geometrica;semantica;semantique;internet;indexing;recherche information;indexation;geometrical shape;indizacion;textual data;forme geometrique;recuperacion informacion;knowledge representation;representation connaissances;image retrieval	Size functions, a class of topological-geometrical shape descriptors, are applied to the search of image datasets by a hand-drawn input: This is the core of a demonstrator accessible through the Internet. Two datasets are provided, of about 700 curves each; both are unstructured sets of randomly generated curves. One consists of piecewise smooth curves, the other of polygonals. The curve generator has been explicitly designed so that the curves have no semantic content; they don't have any kind of indexing or textual caption either. The characteristics of the demonstrator and some experimental results are presented.	image retrieval	Aldo Brucale;Michele d'Amico;Massimo Ferri;Luciano Gualandri;Alberto Lovato	2002		10.1007/3-540-45479-9_25	computer vision;search engine indexing;the internet;image retrieval;computer science;artificial intelligence;theoretical computer science;pattern recognition;database;mathematics;semantics;linguistics;information retrieval	Vision	-11.674228121605715	-59.23207100040251	161697
f94242cd59cedc73b43c13fa97cea7a34f454fa9	graph data management for molecular and cell biology	shortest path;database system;relational data;research needs;chemical reaction network;data management;graph matching;structured query language;system biology;graph algorithm;relational database management system;signaling pathway;spanning tree;high throughput;federated databases;gene regulatory network;biological network;cell biology;protein interaction network	As high-throughput biology begins to generate large volumes of systems biology data, the need grows for robust, efficient database systems to support investigations of metabolic and signaling pathways, chemical reaction networks, gene regulatory networks, and protein interaction networks. Network data is frequently represented as graphs, and researchers need to navigate, query and manipulate this data in ways that are not well supported by standard relational database management systems (RDBMSs). Current approaches to managing graphs in an RDBMS rely on either external procedural logic to execute the graph algorithms or clumsy and inefficient algorithms implemented in Structured Query Language (SQL). In this paper we describe the Systems Biology Graph Extender, a research prototype that extends the IBM RDBMS—DB2 Universal Database software—with graph objects and operations to support declarative SQL queries over biological networks and other graph structures. Supported operations include neighborhood queries, shortest path queries, spanning trees, graph transposition, and graph matching. In a federated database environment, graph operations may be applied to data stored in any format, whether remote or local, relational or nonrelational. A single federated query may include both graphbased predicates and predicates over related data sources, such as microarray expression levels, clinical prognosis and outcome, or the function of orthologous proteins (i.e., proteins that are evolutionarily related to those in another species) in mouse disease models.	algorithm;biological network;computer science;data structure;entity;federated database system;federated search;file spanning;gene regulatory network;graph (abstract data type);graph (discrete mathematics);graph operations;graph theory;high-throughput computing;homology (biology);list of algorithms;matching (graph theory);mathematical optimization;microarray;microsoft sql server;prototype;query language;query optimization;relational database management system;sql;scalability;select (sql);sequence homology;serializability;shortest path problem;sorting;spanning tree;systems biology;throughput	Barbara A. Eckman;Paul G. Brown	2006	IBM Journal of Research and Development	10.1147/rd.506.0545	high-throughput screening;gene regulatory network;sql;biological network;relational database management system;wait-for graph;spanning tree;data management;relational database;computer science;theoretical computer science;data mining;database;graph;shortest path problem;graph database;signal transduction;matching;graph rewriting	DB	-4.932123524064498	-62.75942884683453	162150
00a681252e3c454a53e68dff6a2ab3e3d0c32a71	text classification based on a novel bayesian hierarchical model	bayesian hierarchical model;text analysis bayes methods data reduction inference mechanisms maximum likelihood estimation pattern classification;generic model;support vector machines;text document representation;text processing;bayes methods;niobium;bayesian methods;text analysis;inference mechanisms;latent dirichlet allocation model;maximum likelihood estimation;maximum a posteriori estimation;latent dirichlet allocation;text classification;computational modeling;dimensionality reduction;latent dirichlet category model;variational inference;pattern classification;variational inference approach text classification bayesian hierarchical generative model text document representation text processing latent dirichlet allocation model dimensionality reduction latent dirichlet category model parameter estimation maximum a posteriori estimation;bayesian hierarchical generative model;approximation methods;data reduction;parameter estimation;document classification;probabilistic logic;dimensional reduction;text categorization;text categorization bayesian methods linear discriminant analysis indexing parameter estimation information retrieval large scale integration fuzzy systems computer science computational efficiency;variational inference approach	In the text literature, many Bayesian generative models were proposed to represent documents and words in order to process text effectively and accurately. As the most popular one of these models, Latent Dirichlet Allocation Model(LDA) did great job in dimensionality reduction for document classification. In this paper, inspiring by latent Dirichlet allocation model, we propose LDCM or latent Dirichlet category model for text classification rather than dimensionality reduction. LDCM estimate parameters of models by variational inference and use variational parameters to estimate maximum a posteriori of terms. As demonstrated by our experimental results, we report satisfactory categorization performances about our method on various real-world text documents.	additive smoothing;advice (programming);calculus of variations;categorization;dimensionality reduction;document classification;estimation theory;generative model;hierarchical database model;latent dirichlet allocation;performance;rocchio algorithm;support vector machine;variational method (quantum mechanics)	Shibin Zhou;Kan Li;Yushu Liu	2008	2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2008.666	latent dirichlet allocation;support vector machine;niobium;dynamic topic model;data reduction;text mining;bayesian probability;computer science;maximum a posteriori estimation;variational message passing;machine learning;pattern recognition;data mining;mathematics;maximum likelihood;probabilistic logic;bayesian hierarchical modeling;estimation theory;computational model;statistics;dimensionality reduction;hierarchical dirichlet process	ML	-16.853781702898228	-63.201322616551515	162376
7b0613a2f2f79f4a01ab285ad90470941d77d990	automatic categorization of shots in news videos based on the temporal relations		The development of new methods and technologies of video indexing and retrieval is stimulated by the growing amount of digital video data stored in Internet video collections, TV shows archives, video-on-demand systems, personal video archives offered by Web services, etc. The videos very frequently offered in the Web by broadcast channels are news videos and sports news videos. Content-based indexing of videos is based on the automatic detection of a video structure. A video shot is the main structural video unit. Shots can be of different categories such as intro or final animation, chart or table shots, anchor, reporter, statement, or interview shots, and finally the most informative report shots. The temporal aggregation results in grouping of shots into scenes of a given category. The paper examines the usefulness of the temporal aggregation method to select report shots and non-report shots in a news video.	archive;categorization;digital video;information;web service;world wide web	Kazimierz Choros	2015		10.1007/978-3-319-24306-1_2	computer vision;multimedia;information retrieval	Vision	-15.194498697841725	-54.536419807941826	162946
3c9aaeac56a7e5cb3032747e9185cba3bd2f92fd	enhancement of semantics in cbir	image processing;computational linguistics content based retrieval image retrieval;semantic algorithms semantics enhancement cbir content based image retrieval image content searching pattern recognition content understanding semantic content content based image processing;pattern recognition;computational linguistics;content based image retrieval;content based retrieval;shape thesauri content based retrieval relational databases image databases image retrieval pattern recognition histograms search engines computer vision;image retrieval	Although much research has been done in the area of content based image retrieval (CBIR), little progress has been made to fully implement an engine solely based on the search of image content. This paper examines one of the basic problems in pattern recognition which highlights the difficulty in the area of content understanding in CBIR, i.e. the inability of current systems to fully incorporate low level features of image, such as intensity, colour, texture, shape and spatial constraints characteristics, with the high level features such as semantic content. To further the development of content based image processing, semantic algorithms should be combined with low level features and be used to process the image objects.	algorithm;high-level programming language;image processing;pattern recognition	Ziqiang Feng;David Tien	2005	Third International Conference on Information Technology and Applications (ICITA'05)	10.1109/ICITA.2005.128	computer vision;visual word;image retrieval;computer science;multimedia;automatic image annotation;information retrieval	Vision	-14.447246687384567	-58.460247924950174	163018
de8d876a04789313046c1b2369c3b5efc989adec	an ontology-based comparative anatomy information system	mouse;software;representation;animals;query language;software testing;mice;information systems;rats;user interface;computer graphics;foundational model;semantics;comparative anatomy;protege;graph matching;isomorphism;terminology as topic;domain knowledge;homology;anatomy comparative;graph similarity;artificial intelligence;algorithms;humans;enhancements;information system;user computer interface;databases factual;foundational model of anatomy;genome database mgd;information storage and retrieval;ontology;anatomy;programming languages;network;species specificity;phenotypes;evolution;knowledge base;resource	INTRODUCTION This paper describes the design, implementation, and potential use of a comparative anatomy information system (CAIS) for querying on similarities and differences between homologous anatomical structures across species, the knowledge base it operates upon, the method it uses for determining the answers to the queries, and the user interface it employs to present the results. The relevant informatics contributions of our work include (1) the development and application of the structural difference method, a formalism for symbolically representing anatomical similarities and differences across species; (2) the design of the structure of a mapping between the anatomical models of two different species and its application to information about specific structures in humans, mice, and rats; and (3) the design of the internal syntax and semantics of the query language. These contributions provide the foundation for the development of a working system that allows users to submit queries about the similarities and differences between mouse, rat, and human anatomy; delivers result sets that describe those similarities and differences in symbolic terms; and serves as a prototype for the extension of the knowledge base to any number of species. Additionally, we expanded the domain knowledge by identifying medically relevant structural questions for the human, the mouse, and the rat, and made an initial foray into the validation of the application and its content by means of user questionnaires, software testing, and other feedback.   METHODS The anatomical structures of the species to be compared, as well as the mappings between species, are modeled on templates from the Foundational Model of Anatomy knowledge base, and compared using graph-matching techniques. A graphical user interface allows users to issue queries that retrieve information concerning similarities and differences between structures in the species being examined. Queries from diverse information sources, including domain experts, peer-reviewed articles, and reference books, have been used to test the system and to illustrate its potential use in comparative anatomy studies.   RESULTS 157 test queries were submitted to the CAIS system, and all of them were correctly answered. The interface was evaluated in terms of clarity and ease of use. This testing determined that the application works well, and is fairly intuitive to use, but users want to see more clarification of the meaning of the different types of possible queries. Some of the interface issues will naturally be resolved as we refine our conceptual model to deal with partial and complex homologies in the content.   CONCLUSIONS The CAIS system and its associated methods are expected to be useful to biologists and translational medicine researchers. Possible applications range from supporting theoretical work in clarifying and modeling ontogenetic, physiological, pathological, and evolutionary transformations, to concrete techniques for improving the analysis of genotype-phenotype relationships among various animal models in support of a wide array of clinical and scientific initiatives.		Ravensara S. Travillian;Kremena Diatchka;Tejinder K. Judge;Katarzyna Wilamowska;Linda G. Shapiro	2011	Artificial intelligence in medicine	10.1016/j.artmed.2010.10.001	knowledge base;comparative anatomy;computer science;bioinformatics;artificial intelligence;theoretical computer science;machine learning;ontology;data mining;semantics;information system	AI	-5.106707214425043	-63.83605377491162	163391
04ea820cb869c5353dda1cdaa69296098abcab18	similarity-based search and evaluation of environmentally relevant properties for organic compounds in combination with the group contribution approach	coefficient antoine;physicochemical properties;binary mixture;compuesto organico;base donnee;partition coefficient;organic compounds;vapor pressure;donnee factuelle;database;solubility;base dato;algorithme;algorithm;dato factografico;presion vapor;relacion estructura propiedad;structure moleculaire;melange binaire;thermodynamic properties;compose organique;solubilite;propiedad termodinamica;coeficiente reparticion;propriete thermodynamique;mezcla binaria;propiedad fisicoquimica;propriete physicochimique;estructura molecular;solubilidad;relation structure propriete;factual data;coefficient partage;property structure relationship;pression vapeur;organic compound;algoritmo;molecular structure			Axel Drefahl;Martin Reinhard	1993	Journal of Chemical Information and Computer Sciences	10.1021/ci00016a011	partition coefficient;chemistry;molecule;organic chemistry;solubility;physical chemistry;mineralogy;vapor pressure	Vision	-6.593462678815042	-54.436617652743784	163546
22c849826134b816192c23b439541ecca7523739	towards an effective semi-automatic technique for image annotation	link analysis;image annotation	In this paper we explore the opportunities offered by graphbased link analysis techniques in the development of a semi-automatic image captioning system. The approach we propose is appealing since predicted terms for an image: 1) are in variable number, depending on the image content, 2) represent correlated terms, and 3) can also represent abstract concepts. We present preliminary results on our prototype system and discuss possible extensions.	automatic image annotation;link analysis;ontology (information science);prototype;semiconductor industry	Ilaria Bartolini;Paolo Ciaccia	2007			automatic image annotation;computer vision;image retrieval;link analysis;artificial intelligence;closed captioning;computer science	SE	-15.210195388095679	-58.93517003266886	163891
8834c4ce7c37afd524eb1c085202202472a42513	knowledge propagation in large image databases using neighborhood information	semantic annotation;image database;image annotation;classification;matrix computation;classification image;neighborhood	The aim of this paper is to reduce to a minimum the level of human intervention in the semantic annotation process of images. Ideally, only one copy of each object of interest would be labeled manually, and the labels would then be propagated automatically to all other occurrences of the objects in the database. To that end, we propose a neighbor-based influence propagation approach KProp which builds a voting model and propagates the knowledge associated to some objects to similar objects. We show that KProp can perform efficiently through matrix computations and achieve better performance with fewer labeled examples per object.	computation;database;software propagation	Michael E. Houle;Vincent Oria;Shin'ichi Satoh;Jichao Sun	2011		10.1145/2072298.2071931	computer vision;biological classification;image retrieval;computer science;machine learning;pattern recognition;data mining;numerical linear algebra;automatic image annotation;world wide web;information retrieval	Vision	-14.64560193057146	-61.09991683806137	163926
6f3206233366510c21affa1107c8f03c86c91046	detection of tv commercials	tv commercials detection;image recognition;decoding;commercial shots;video signal processing;tv broadcasting;shot duration pattern recognition tv commercials detection tv shot labeling accuracy commercial shots program shots hmm viterbi decoder logo presence observation;hmm;law;legal factors;hidden markov models;monitoring;viterbi decoding video signal processing image recognition hidden markov models;viterbi algorithm;hidden markov models viterbi algorithm tv broadcasting decoding labeling system testing video recording monitoring law legal factors;shot duration;viterbi decoder;tv shot labeling accuracy;video recording;pattern recognition;program shots;system testing;logo presence observation;viterbi decoding;labeling	This paper presents a system that labels TV shots either as commercial or program shots. The system uses two observations: logo presence and shot duration. These observations are modeled using HMMs, and a Viterbi decoder is finally used for shot labeling. The system has been tested on several hours of real video, achieving more than 99% correct labeling.	logo;viterbi decoder	Alberto Albiol;María José Ch. Fullà;Antonio Albiol;Luis Torres	2004	2004 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2004.1326601	computer vision;speech recognition;computer science;multimedia;viterbi decoder;hidden markov model;statistics	Robotics	-13.88174596907266	-56.183968383257266	164019
4a26de0346b3ef23d255f63a67b54516af206750	rsviewer: an efficient video viewer for racquet sports focusing on rally scenes		This paper presents RSViewer, a video browsing system specialized for racquet sports, which reflects users’ interests. Methods to support users in browsing racquet sports matches by summarizing video composed of important rally shots have been discussed in a previous study. However, the method is not practical enough because the auditory events should be manually annotated in advance to detect such scenes. Therefore, we propose an automatic rally shot detection based on shot clustering method using white line detection. Our system calculates the importance of rally shots based on audio features. As the result, the summarized video can facilitate users find and review the information they need. The result of experiments shows that our method is effective in an aspect of efficient video browsing experience. Furthermore, we propose a high-speed playback method customized to racquet sports video and realize more efficient video browsing experience.	cluster analysis;edge detection;evaluation function;experiment;information;shot transition detection;user experience;user interface	Shunya Kawamura;Tsukasa Fukusato;Tatsunori Hirai;Shigeo Morishima	2016		10.5220/0005670802470254	computer vision;multimedia;computer graphics (images)	AI	-15.369205462238762	-54.41968511887935	164480
539ca9db570b5e43be0576bb250e1ba7a727d640	a large-scale database of images and captions for automatic face naming		We present a large scale database of images and captions, designed for supporting research on how to use captioned images from the Web for training visual classifiers. It consists of more than 125,000 images of celebrities from different fields downloaded from the Web. Each image is associated to its original text caption, extracted from the html page the image comes from. We coin it FAN-Large, for Face And Names Large scale database. Its size and deliberate high level of noise makes it to our knowledge the largest and most realistic database supporting this type of research. The dataset and its annotations are publicly available and can be obtained from http://www.vision. ee.ethz.ch/~calvin/fanlarge/. We report results on a thorough assessment of FAN-Large using several existing approaches for name-face association, and present and evaluate new contextual features derived from the caption. Our findings provide important cues on the strengths and limitations of existing approaches.	database;html;high-level programming language;world wide web	Mert Özcan;Jie Luo;Vittorio Ferrari;Barbara Caputo	2011		10.5244/C.25.29	computer vision;computer science;data mining;world wide web;information retrieval	Vision	-17.236708133249312	-60.440087839838924	164557
7ede3b7bbc5ef9ffdc52404497d19cf008ebb897	unified video annotation via multigraph learning	busqueda informacion;dimensionalidad;anotacion;iterative method;evaluation performance;iterative process;distance function;optimisation;evaluation image;control de calidad;nist;learning algorithm;performance evaluation;optimizacion;multimodal fusion;supervised learning;video signal processing;information retrieval;implementation;evaluacion prestacion;video compression;dimensionality;video retrieval iterative methods learning artificial intelligence;video retrieval;curse of dimensionality;annotation;algorithme apprentissage;semi supervised learning;metodo iterativo;multigraph;iterative methods;training data;recherche information;temporal consistency;dimensionnalite;methode iterative;multigrafo;feature extraction;controle qualite;traitement signal video;video annotation;evaluacion imagen;optimization;image evaluation;apprentissage supervise;multigraphe;learning artificial intelligence;implementacion;quality control;aprendizaje supervisado;algoritmo aprendizaje;distance functions;iterative process video annotation video retrieval optimized multigraph based semi supervised learning distance functions temporal consistency;video annotation multimodal fusion semi supervised learning;semisupervised learning video compression feature extraction nist costs training data optimization methods iterative methods large scale systems asia;semisupervised learning;large scale systems;asia;optimization methods;optimized multigraph based semi supervised learning	Learning-based video annotation is a promising approach to facilitating video retrieval and it can avoid the intensive labor costs of pure manual annotation. But it frequently encounters several difficulties, such as insufficiency of training data and the curse of dimensionality. In this paper, we propose a method named optimized multigraph-based semi-supervised learning (OMG-SSL), which aims to simultaneously tackle these difficulties in a unified scheme. We show that various crucial factors in video annotation, including multiple modalities, multiple distance functions, and temporal consistency, all correspond to different relationships among video units, and hence they can be represented by different graphs. Therefore, these factors can be simultaneously dealt with by learning with multiple graphs, namely, the proposed OMG-SSL approach. Different from the existing graph-based semi-supervised learning methods that only utilize one graph, OMG-SSL integrates multiple graphs into a regularization framework in order to sufficiently explore their complementation. We show that this scheme is equivalent to first fusing multiple graphs and then conducting semi-supervised learning on the fused graph. Through an optimization approach, it is able to assign suitable weights to the graphs. Furthermore, we show that the proposed method can be implemented through a computationally efficient iterative process. Extensive experiments on the TREC video retrieval evaluation (TRECVID) benchmark have demonstrated the effectiveness and efficiency of our proposed approach.	algorithm;algorithmic efficiency;benchmark (computing);convergence insufficiency;curse of dimensionality;experiment;iteration;iterative method;mathematical optimization;matrix regularization;multigraph;sms language;semi-supervised learning;semiconductor industry;supervised learning;text retrieval conference;transport layer security	Meng Wang;Xian-Sheng Hua;Richang Hong;Jinhui Tang;Guo-Jun Qi;Yan Song	2009	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2009.2017400	computer vision;curse of dimensionality;computer science;machine learning;pattern recognition;iterative method;supervised learning	Vision	-13.374518040377284	-61.52649549691833	164796
815582f8ebb3e88011e7d92f545d3999792cb5ba	exploring a new space of features for document classification: figure clustering	large applications;software testing;code coverage;image clustering;document classification;bag of words	Automatic document classification is an important step in organizing and mining documents. Information in documents is often conveyed using both text and images that complement each other. Typically, only the text content forms the basis for features that are used in document classification. In this paper, we explore the use of information from figure images to assist in this task. We explore image clustering as a basis for constructing visual words for representing documents. Once such visual words are formed, the standard bag-of-words representation along with commonly used classifiers, such as the naïve Bayes, can be used to classify a document. We report here results from classifying biomedical documents that were previously used in the TREC Genomics track, employing the image-based representation. Efforts are ongoing to improve image-based classification and analyze the relationships between text and images. The goal is to develop a new set of features to supplement current text-based features.	bag-of-words model;cluster analysis;computational genomics;document classification;naive bayes classifier;organizing (structure);text-based (computing)	Nawei Chen;Hagit Shatkay;Dorothea Blostein	2006		10.1145/1188966.1189013	document clustering;computer science;bag-of-words model;software engineering;pattern recognition;data mining;software testing;bag-of-words model in computer vision;code coverage;information retrieval	Web+IR	-14.02303638399786	-58.73464490054614	165251
bdc2ad8ca474a6d936bc393cfe5e754e6f9c70bf	exsight: highly accurate object based image retrieval system enhanced by redundant object extraction	analisis contenido;base donnee;systeme redondant;analisis datos;traitement image stereoscopique;redundancia;information retrieval;real time;extraction forme;database;base dato;systeme recherche;multidimensional data;search system;recherche image base contenu;prototipo;redundant system;data analysis;content analysis;redundancy;extraccion forma;indexing;sistema investigacion;recherche information;indexation;stereo image processing;object extraction;indizacion;analyse donnee;recuperacion informacion;analyse contenu;sistema redundante;content based image retrieval;prototype;pattern extraction;redondance;image retrieval	This paper describes ExSight, a prototype system for content-based image retrieval that will provide image retrieval facilities based on the indexing of component objects. We present a database centric approach to image retrieval and other techniques necessary for successfully implementing ExSight. The essential point of this approach is automatic image data analysis, emphasizing automatic object extraction that implies redundancy. The database module of ExSight coordinates multiple space indices in order to obtain an overall ranking based on several different features. The experimental results reveal that object-based contents retrieval achieves a higher level of retrieval correctness than color-region based retrieval and the implemented multidimensional data access engine achieves real-time response.	image retrieval	Kazuhiko Kushima;Hiroki Akama;Seiichi Kon'ya;Masashi Yamamuro	2000		10.1007/3-540-45151-X_32	computer vision;search engine indexing;visual word;content analysis;image retrieval;computer science;data mining;database;prototype;redundancy;data analysis;automatic image annotation;world wide web;data retrieval;information retrieval	Vision	-12.022784936365575	-59.02209065350956	165591
ce4d6d83d8a813a833262016ba7e86996b1d9597	integrating visual saliency and consistency for re-ranking image search results	visual saliency;search engine;visual saliency random walk re ranking visual consistency;web pages;query processing;search engines;edge detection;image retrieval visual saliency visual consistency image search result re ranking web image search real world web image dataset search engines;search engines image retrieval internet query processing;web image search;large scale;visualization;internet;image edge detection;image color analysis;random walk;visual consistency;feature extraction;visualization mathematical model feature extraction image color analysis equations search engines image edge detection;image search;mathematical model;re ranking;image retrieval;image similarity	The paper investigates two mechanisms, visual consistency and visual saliency, in web image search: (1) In most current web image search engines, such as Google Image Search and Yahoo Image Search, the images that closely related to the search query are typically visually similar. These visually consistent images which occur most frequently in the first few web pages will be given higher ranks. (2) From visual aspect, it is obvious that salient images would be easier to catch users' eyes and more likely to be clicked than the cluttered ones in low-level vision. In addition, we also observe the fact that the visually salient images in the front pages are often relevant to the user's query. The principal novelty of this paper is in combining visual saliency and consistency to re-rank the results from search engines to make the re-ranked images more satisfying in both vision and content. The experimental results on a real world web image dataset demonstrate that our approach can effectively improve the performance of image retrieval.	google search;high- and low-level;image retrieval;web page;web search engine	Jun Huang;Xiaokang Yang;Xiangzhong Fang;Weisi Lin;Rui Zhang	2010	2010 IEEE International Conference on Image Processing	10.1109/TMM.2011.2127463	computer vision;web query classification;image retrieval;computer science;pattern recognition;world wide web;information retrieval;search engine;statistics	Vision	-15.852821502518863	-58.61493926492845	166049
90a04c0db3c922abfc203cbc5b77c71abd29d1ef	location based semantic annotation for ward analysis	analytical models;object recognition;semantic annotation;location tracking;tracking system;information sources;space technology cameras semantic web analytical models medical services feedback information analysis computer science streaming media ontologies;hospitals;location based tracking system location based semantic annotation ward analysis information sources digital resources location tracking system semantic web annotation simulated ward environment;resource description framework;data mining;feedback;location tracking system;medical services;monitoring;streaming media;ward analysis;semantic web;ontologies;space technology;rt nursing;semantic web health care hospitals information analysis;digital resources;computer science;location based semantic annotation;information analysis;cameras;location based tracking system;simulated ward environment;semantic web annotation;qa76 computer software;health care	Semantic annotation has been used to combine varied information sources - gathered as unobtrusively as possible - and produce enhanced tools for working with digital resources. In this paper we describe trials carried out using a location tracking system and Semantic Web annotation technologies to analyse activities in a simulated ward environment. The motivation for semantic annotation of the space will be outlined along with the practicalities of the location based tracking system. The integration of location, annotations and video information will be discussed together with the technologies and approaches applicability to use in a real ward environment.	semantic web;tracking system	Mark J. Weal;Danius T. Michaelides;Kevin R. Page;David De Roure;Mary Gobbi;Eloise Monger;Fernando Martinez	2009	2009 3rd International Conference on Pervasive Computing Technologies for Healthcare	10.4108/ICST.PERVASIVEHEALTH2009.6009	tracking system;image retrieval;computer science;ontology;artificial intelligence;cognitive neuroscience of visual object recognition;semantic web;rdf;data mining;feedback;space technology;data analysis;world wide web;information retrieval;health care	SE	-12.369122982882724	-54.4750052369382	166274
abfa45667825b86a572d41f7eb912e45e4141fc5	a haptic-enhanced system for molecular sensing	haptic device;computational chemistry;development tool;research purpose;data visualization;geometric model	The science of haptics has received an enormous attention in the last decade. One of the major application trends of haptics technology is data visualization and training. In this paper, we present our work towards developing a hapticallyenhanced model for manipulation and tactile exploration of molecules. The graphic models of molecules is extracted using file formats widely used in chemical and biological field. The addition of haptic interface enables users to feel the interaction forces between the explored molecule and a simple probe molecule (such as water, or basic electronic charge). Since the interaction forces are very small, the forces felt by the user are scaled accordingly. The haptic device used is the Sensable PHANTOM R ©Omni. The developed tool can be used for teaching and scientific purposes due to its high reliance on both theoretical and experimental data.	computational chemistry;data visualization;haptic technology;level of measurement;numerical analysis	Sara Comai;Davide Mazza	2009		10.1007/978-3-642-03658-3_53	computer vision;simulation;human–computer interaction;computer science;artificial intelligence;geometric modeling;haptic technology;data visualization;computer graphics (images)	Robotics	-8.355101064559415	-56.831815524846654	166850
0d82edbf92db9b4dd780c869eadaabc69a4e2dbc	information-theoretic content selection for automated home video editing	image segmentation;video signal processing;content selection;information theoretic automated home video editing content selection co occurrence statistics;indexing terms;statistical analysis;layout statistics random variables entropy heuristic algorithms multimedia systems indexing content management singular value decomposition refining;n best heuristic algorithm information theory content selection automated home video editing footage segmentation cooccurrence statistics random variable optimal selection criterion joint entropy;video signal processing entropy image segmentation random processes statistical analysis;video editing;random processes;random variable;co occurrence statistics;entropy;contingency table;automated home video editing;information theoretic;heuristic algorithm	In automated home video editing, selecting out the most informative contents from the redundant footage is challenging. This paper proposes an information-theoretic approach to content selection by exploring the dependence relations between who (characters) and where (scenes) in the video. First the footage is segmented into basic units about the same characters at the same scene. To compactly represent the dependence relations between scenes and characters, contingency table is used to model their co-occurrence statistics. Suppose the contents about which characters at which scene are dominating by two random variables, an optimal selection criterion is proposed based on joint entropy. To improve the computation efficiency, a pruned N-Best heuristic algorithm is presented to search the most informative video units. Experimental results demonstrated the proposed approach is flexible and effective for automated content selection.	algorithm;computation;contingency table;heuristic (computer science);information theory;joint entropy	Patricia Peng Wang;Tao Wang;Jianguo Li;Yimin Zhang	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4380073	heuristic;random variable;stochastic process;computer vision;entropy;index term;contingency table;computer science;machine learning;pattern recognition;data mining;mathematics;image segmentation;statistics	Robotics	-13.62061117834847	-55.98597945907673	167081
16f9c9791eb29025c3832d49a4a0d34eae5c6304	learning on the test data: leveraging unseen features	web pages;hidden variables;probabilistic model	This paper addresses the problem of classification in situations where the data distribution is not homogeneous: Data instances might come from different locations or times, and therefore are sampled from related but different distributions. In particular, features may appear in some parts of the data that are rarely or never seen in others. In most situations with nonhomogeneous data, the training data is not representative of the distribution under which the classifier must operate. We propose a method, based on probabilistic graphical models, for utilizing unseen features during classification. Our method introduces, for each such unseen feature, a continuous hidden variable describing its influence on the class — whether it tends to be associated with some label. We then use probabilistic inference over the test data to infer a distribution over the value of this hidden variable. Intuitively, we “learn” the role of this unseen feature from the test set, generalizing from those instances whose label we are fairly sure about. Our overall probabilistic model is learned from the training data. In particular, we also learn models for characterizing the role of unseen features; these models use “meta-features” of those features, such as words in the neighborhood of an unseen feature, to infer its role. We present results for this framework on the task of classifying news articles and web pages, showing significant improvements over models that do not use unseen features.	bayesian network;graphical model;hidden variable theory;statistical model;test data;test set;web page	Ben Taskar;Ming Fai Wong;Daphne Koller	2003			machine learning;hidden variable theory;test data;probabilistic logic;test set;statistical model;artificial intelligence;inference;pattern recognition;classifier (linguistics);computer science;graphical model	ML	-14.42725029309405	-65.50792486693976	167129
aad67df865dd242031c17403c7af83f07e805e37	video indexing and understanding	video indexing	More and more video is generated every day While today much of this data is produced and stored in analog form the tendency is to use the digital form The digital form allows processing of the video data in order to generate appropriate data abstractions that enable content based retrieval of video In the future video databases will be able to be searched with combined text and visual queries Additionally video clips will be retrieved from longer sequences in large databases on the basis of the semantic video content Ide ally the video will also be automatically annotated as a result of the machine interpretation of the semantic content of the video Rowe et al characterized the types of video queries a user may ask and identi ed the following three types of metadata indexes that should be associated with the video data in order to satisfy a query	database;digital video;video clip	Michael S. Lew;Nicu Sebe;Paul C. Gardner	2001		10.1007/978-1-4471-3702-3_7	information retrieval;clips;search engine indexing;discrete cosine transform;computer science	DB	-14.131834419654208	-54.73376420395879	167137
b1615c511f668ca8a86cb5365047c79e9ef926eb	surface rendering versus volume rendering in medical imaging: techniques and applications		High resolution imaging modalities. combined with advances in computer technology has prompted renewed interest and led to significant progress in volumetric reconstruction of medical images. Clinical assessment of this technique and whether it can provide enhanced diagnostic interpretation is currently under investigation by various medical and scientific groups. The purpose of this panel is to evaluate the clinical utility of two major 3D rendering techniques that allow the user to “fly through” and around medical data-sets.	3d rendering;computer;medical imaging;volume rendering	William E. Lorensen;Ron Kikinis;Sandy Napel;Arie E. Kaufman;John Flynn	1996	Proceedings of Seventh Annual IEEE Visualization '96		3d rendering	Visualization	-9.349558639020648	-54.2216446438444	167153
efc63d7937f0c921e848288df22964bf8f3857b5	storage and processing of mass spectrometry data	data interchange;web front end;extensible markup language;mass spectrometry data storage;metabolomics;xml format;spectroscopy computing;mass spectrometry;java object;backend database;data model;input output;mass spectrometry data processing;software architecture;xml input output;xml input output mass spectrometry data storage mass spectrometry data processing metabolomics xml format extensible markup language data interchange model driven architecture backend database data standard model eclipse framework java object user friendly editor web front end;eclipse framework;xml;data standard model;xml data handling data models java mass spectroscopy software architecture spectroscopy computing;mass spectroscopy;data handling;mass spectroscopy databases metabolomics data models xml throughput memory unified modeling language plants biology biochemistry;user friendly editor;model driven architecture;data models;java	Mass spectrometry is the work-horse technology of the emerging field of metabolomics. Community-wide accepted data models and XML formats for data interchange such as mzData are currently in development. The information contained in these models is sufficient to create applications and databases in a model driven architecture (MDA). This allows to (re-)create the necessary code basis and backend database with minimal manual coding. We present an infrastructure to support the use of these data standards. It uses the Eclipse framework to generate Java objects, XML input/output, database persistence and a user-friendly editor for both the XML files and database content. A prototype of a Web frontend has been created to view, verify and upload to such a repository	data model;database;eclipse;input/output;java;mass spectrometry data format;metabolomics;model-driven architecture;persistence (computer science);prototype;upload;usability;xml	Sebastian Klie;Steffen Neumann	2006	17th International Workshop on Database and Expert Systems Applications (DEXA'06)	10.1109/DEXA.2006.131	xml validation;xml;mass spectrometry;streaming xml;computer science;xml framework;data mining;xml database;database;xml signature;programming language;world wide web;efficient xml interchange	DB	-4.811222027787686	-58.90281900315632	167695
1c128ed0dbfd01c2b5eebd19b8d77d2304369d95	visualising an image collection?	image databases;police data processing data visualisation thesauri feature extraction ontologies artificial intelligence;information retrieval;image collection visualisation;shape measurement;layout;thesauri;ontologies artificial intelligence;data visualisation;police data processing;visual thesaurus;feature extraction;indexation;data visualization;layout image retrieval terminology humans data visualization forensics image databases content based retrieval shape measurement information retrieval;scene of crime terminology extraction;terminology;humans;scene of crime ontology extraction image collection visualisation visual thesaurus scene of crime terminology extraction;content based retrieval;forensics;scene of crime ontology extraction;image retrieval	A system for the visualization of large collections of images, facilitated by an automatically constructed visual thesaurus, is reported. A corpus-based method for extraction of terminology and ontology of a specialist domain, scene-of-crime, is outlined. The challenge when capturing information in a crime scene is how to later visualise the scene, when all exhibits have been removed or altered. Experiments on experts dealing with describing a visual domain (the crime scene) suggest that the inter-indexer variability is limited.	experiment;scene graph;search engine indexing;spatial variability;text corpus;thesaurus	Khurshid Ahmad;Bogdan Vrusias;Meng Zhu	2005	Ninth International Conference on Information Visualisation (IV'05)	10.1109/IV.2005.141	computer vision;computer science;data mining;information retrieval	Visualization	-14.42871445271717	-58.41954704430387	167903
ee23696a516e08f29fffee43c3ce45a25cd838a6	automated image annotation system based on an open source object database	image segmentation;image annotation;ontology	Automated annotation of digital images is a challenging task being used for indexing, retrieving, and understanding of large collections of image data. Several machine-learning approached have been proposed to model the existing associations between words and images. Each approach is trying to assign to a test image some meaningful words taking into account a set of feature vectors extracted from that image. This paper presents an original image annotation system based on an open source object database called db4o. An object oriented model offers suport for storing complex objects as sets, lists, trees or other advanced data structures. The information needed for the annotation process is retrieved from the SAIAPR TC-12 Dataset - a set of annotated images having a vocabulary with a hierarchical structure. The annotation system is using an efficient annotation model called Cross Media Relevance Model.	automatic image annotation	Gabriel Mihai;Liana Stanescu;Dumitru Dan Burdescu;Cosmin Stoica Spahiu	2011		10.1007/978-3-642-23878-9_37	image retrieval;computer science;ontology;data mining;database;image segmentation;automatic image annotation;information retrieval	Vision	-14.147312908593019	-59.22670230272022	168156
bf276e5ffad227bcb871bf1ad2929cb55c65e4a6	making aggregate content of clinicaltrials.gov freely available to everyone			aggregate function	Sheri R. Tibbs;Karen Chiswell;Sara B Calvert	2017				Vision	-5.025951152787262	-59.86745704720303	168221
d3a090fe0feb78eb51fe9b07e45bf026732fa6d7	computer-assisted knowledge acquisition system for synthesis planning	programa;synthese;program;synthesis;sintesis;planificacion;knowledge acquisition;computer aid;programme;asistencia ordenador;planning;planification;assistance ordinateur	"""plementary material (Appendix A). This first program, INCOSI .FOR, extracts compound number, compound name, concentration, and flag. The second program, INCOS2.FOR, extracts date, station number, filename, level, matrix, dilution, and type, The third program, INCOS3.FOR, merges the data from the first two programs. And the fourth program, LOD.FOR, adds the limit of detection from an external table. The last file created by this part of OARS is INCOS2.DB2. This file is fixed-format, delimited by double quotes. The file is ready for direct importing into Dbase 111 plus. The second part of OARS is written in Dbase 111 plus2 and is comprised of five separate Dbase programs given in the supplementary material (Appendix B). The first Dbase program is a Dbase importation to get data into a file named INCOS. This program deletes compounds that have flag = """"U"""", eliminating compounds looked for but not found. As can be seen in Figure 2, compounds that are detected in some samples but not in others are treated differently. This is essential to characterizing a waste site. The second Dbase program adds results from the acid and base fractions. Many EPA methods for the analysis of semivolatile compounds in water samples call for sequential extraction of basic and acidic compounds. Some compounds may appear in both fractions. Hence the results are summed to give the concentration in the sample. The third Dbase program merges samples that were analyzed at different dilutions: it can accommodate up to three different dilutions. The fourth program averages the non-zero concentrations and calculates the percent relative difference or percent relative standard deviation. The analyst is then allowed to review the data on the screen and make corrections as necessary. Manual correction normally entails removing sample concentrations that were diluted below the instrument's limit of detection. Figure 4 shows an edit screen that is used at this stage. The last program then produces a final report in the matrix format. An example of this final report is shown in Figure 5 ."""	delimiter;http 404;knowledge acquisition;relative change and difference;the matrix;waste;dbase	Takashi Nakayama	1991	Journal of Chemical Information and Computer Sciences	10.1021/ci00004a011	planning;simulation;artificial intelligence;operations research	ML	-5.722708929778181	-56.11812386451804	168233
377119cc3bf86d37c8b313a6a663fea80d4d792f	neural query system	animals;models neurological;database management systems;data mining;network simulator;structured query language;single cell;network model;software package;relational database system;humans;neurons;user computer interface;simulation tool;computer simulation;information storage and retrieval	We have developed a simulation tool within the NEURON simulator to assist in organization, verification, and analysis of simulations. This tool, denominated Neural Query System (NQS), provides a relational database system, a query function based on the SELECT function of Structured Query Language, and data-mining tools. We show how NQS can be used to organize, manage, verify, and visualize parameters for both single cell and network simulations. We demonstrate an additional use of NQS to organize simulation output and relate outputs to parameters in a network model. The NQS software package is available at http://senselab. med.yale.edu/senselab/SimToolDB. *** DIRECT SUPPORT *** A11U5014 00003	data mining;electronic circuit simulation;nqs;network model;neuron;query language;relational database management system;sql	William W. Lytton	2006	Neuroinformatics	10.1385/NI:4:2:163	computer simulation;sql;relational database management system;computer science;theoretical computer science;network model;machine learning;data mining;database;network simulation	Visualization	-7.615111670081691	-59.60840530441904	168385
7b99829ffe655a2d00ed5a8b4ca370795e383172	pathrings: a web-based tool for exploration of ortholog and expression data in biological pathways	software;genomics;metabolic networks and pathways;computer graphics;signal transduction;computational biology bioinformatics;gene expression;internet;proteins;algorithms;humans;combinatorial libraries;proteomics;computer appl in life sciences;computer simulation;species specificity;microarrays;bioinformatics	High-throughput methods are generating biological data on a vast scale. In many instances, genomic, transcriptomic, and proteomic data must be interpreted in the context of signaling and metabolic pathways to yield testable hypotheses. Since humans can interpret visual information rapidly, a means for interactive visual exploration that lets biologists interpret such data in a comprehensive and exploratory manner would be invaluable. However, humans have limited memory capacity. Current visualization tools have limited viewing and manipulation capabilities to address complex data analysis problems, and visual exploratory tools are needed to reduce the high mental workload imposed on biologists. We present PathRings, a new interactive web-based, scalable biological pathway visualization tool for biologists to explore and interpret biological pathways. PathRings integrates metabolic and signaling pathways from Reactome in a single compound graph visualization, and uses color to highlight genes and pathways affected by input data. Pathways are available for multiple species and analysis of user-defined species or input is also possible. PathRings permits an overview of the impact of gene expression data on all pathways to facilitate visual pattern finding. Detailed pathways information can be opened in new visualizations while maintaining the overview, that form a visual exploration provenance. A dynamic multi-view bubbles interface is designed to support biologists’ analytical tasks by letting users construct incremental views that further reflect biologists’ analytical process. This approach decomposes complex tasks into simpler ones and automates multi-view management. PathRings has been designed to accommodate interactive visual analysis of experimental data in the context of pathways defined by Reactome. Our new approach to interface design can effectively support comparative tasks over substantially larger collection than existing tools. The dynamic interaction among multi-view dataset visualization improves the data exploration. PathRings is available free at http://raven.anr.udel.edu/~sunliang/PathRings and the source code is hosted on Github: https://github.com/ivcl/PathRings .	application program interface;gene expression;gene regulatory network;graph - visual representation;graph drawing;homology (biology);imagery;increment;interactive visual analysis;interface device component;large;license;metabolic process, cellular;numerous;orthologous gene;proteomics;reactome: a database of reactions, pathways and biological processes.;scalability;signal transduction;silo (dataset);source code;throughput;web application	Yongnan Zhu;Liang Sun;Alexander Garbarino;Carl J. Schmidt;Jinglong Fang;Jian Chen	2015		10.1186/s12859-015-0585-1	computer simulation;computational biology;biology;genomics;the internet;gene expression;dna microarray;computer science;bioinformatics;data science;proteomics;computer graphics;signal transduction	Visualization	-5.852304636060552	-60.018889524414426	168706
a8923ba6ceed37d2bee7f2070b4755df27f97d02	bio-imaging toolkit for indexing, searching, navigation, discovery and annotation	information retrieval system;image communication;image database;video segmentation;interactive multimedia;service model;shape similarity;indexation;video annotation;service oriented architecture;image retrieval	Bio-imaging toolkit is an application for biological imaging community that will bring in the latest efforts in indexing, searching, navigation, discovery, analysis and annotation for both biological image and video collections. This paper discusses both metadata-based and content-based representation, indexing, querying, navigation, discovery, and retrieval, as well as video segmentation and image/video annotations. It also discusses image retrieval by texture similarity, shape similarity, color similarity, and spatio-temporal relationships for the bio-imaging database. A highly interactive multimedia information retrieval system has been developed which is based on Service Oriented Architecture (SOA) that relies on the REST based web-service model to create efficient web components. Application designed is a light weight container application that can be deployed easily without any expertise and easy to understand for novice users.	british informatics olympiad;image retrieval;information retrieval;service-oriented architecture;web components	Afzal Godil;Benny Cheung;Asim Imdad Wagan;Xiaolan Li	2008		10.1007/978-3-540-89646-3_91	computer vision;visual word;image retrieval;computer science;service-oriented modeling;service-oriented architecture;interactive media;automatic image annotation;world wide web;information retrieval	Vision	-13.819331068391842	-57.420936259786735	169057
e02a7fe4b0d5a3cf5f69658297e6fd300590ae74	distant supervision for tweet classification using youtube labels	tweets;classification;distant supervision	We study an approach to tweet classification based on distant supervision, whereby we automatically transfer labels from one social medium to another. In particular, we apply classes assigned to YouTube videos to tweets linking to these videos. This provides for free a virtually unlimited number of labelled instances that can be used as training data. The experiments we have run show that a tweet classifier trained via these automatically labelled data substantially outperforms an analogous classifier trained with a limited amount of manu-	emoticon;experiment;multimedia framework;naive bayes classifier;social media	Walid Magdy;Hassan Sajjad;Tarek El-Ganainy;Fabrizio Sebastiani	2015			biological classification;computer science;data mining;multimedia;world wide web	ML	-18.81931437193204	-56.03982357966289	169315
a1e61e606fe5bdf574cf99c7092238b4c477b2db	semantic annotation of complex human scenes for multimedia surveillance	semantic annotation;surveillance system;comunicacion de congreso;human behavior;computer vision;fuzzy logic;dynamic information;part of book or chapter of book;pattern recognition computer vision	A Multimedia Surveillance System (MSS) is considered for automatically retrieving semantic content from complex outdoor scenes, involving both human behavior and traffic domains. To characterize the dynamic information attached to detected objects, we consider a deterministic modeling of spatio-temporal features based on abstraction processes towards fuzzy logic formalism. A situational analysis over conceptualized information will not only allow us to describe human actions within a scene, but also to suggest possible interpretations of the behaviors perceived, such as situations involving thefts or dangers of running over. Towards this end, the different levels of semantic knowledge implied throughout the process are also classified into a proposed taxonomy.	fuzzy logic;semantics (computer science);taxonomy (general)	Carles Fernández;Pau Baiget;F. Xavier Roca;Jordi Gonzàlez	2007		10.1007/978-3-540-74782-6_60	computer vision;computer science;multimedia;communication	Web+IR	-11.990952840133282	-52.5996087311632	169342
248f245056bc886275af4cad055cd5ec5f58f38f	biofoss: a survey of free/open source software in bioinformatic	medical computing;medical information systems;linux distributions open source software bioinformatics;open source software bioinformatics genomics humans biology computing dna proteins application software licenses linux;medical information systems linux medical computing;linux;free open source software;linux distributions;open source software;open source;bioinformatics	This paper discusses the current state of free/open source software (F/OSS) projects in the field of academic bioinformatics. The paper reports on a survey of the bioinformatics journal that enumerates the number of Application Notes published between volumes 2004-20-17 and 2005-21-7. The purpose of this survey is to determine what percentage of bioinformatics applications are made available under open source licenses. Bioinformatics includes tools, databases, and organizations to support them. An overview is given for the EMBOSS project, the Open Bioinformatics Foundation, and GenBank. In addition, a short discussion of Linux distributions tailored to the needs of bioinformaticians is provided	bioinformatics open source conference;computer;database;datasheet;emboss;emergence;genbank;hoc (programming language);linux;open bioinformatics foundation;open-source license;open-source software;requirement;string (computer science);workbench;workstation	Kirby Shabaga;Daniel M. Germán	2006	19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)	10.1109/CBMS.2006.60	gnu/linux;computer science;operating system;database;open system;world wide web;linux kernel	SE	-4.660681792510511	-60.363646420993604	169633
b6c309200dff117476ba4cfea8b1ecac4706f850	synthesizing imagined faces based on relevance feedback		In this paper, we propose a user-friendly system that can create a facial image from a corresponding image in the user’s mind. Unlike most of the existing methods, which require a sketch as input or the tedious work of selecting similar facial components from an example database, our method can synthesise a satisfying result without questioning the user on the explicit features of the face in his or her mind. Through a dialogic approach based on a relevance feedback strategy to translate facial features into input, the user only needs to look at several candidate face images and judge whether each image resembles the face that he or she is imagining. A set of sample face images that are based on users’ feedbacks are used to dynamically train an Optimum-Path Forest algorithm to classify the relevance of face images. Based on the trained Optimum-Path Forest classifier, candidate face images that best reflect the user’s feedback are retrieved and interpolated to synthesise new face images that are similar to those the user had imagined. The experimental results show that the proposed technique succeeded in generating images resembling a face a user had imagined or memorised.	relevance feedback	Caie Xu;Shota Fushimi;Masahiro Toyoura;Jiayi Xu;Xiaoyang Mao	2018	Trans. Computational Science	10.1007/978-3-662-56672-5_7	machine learning;imagination;classifier (linguistics);sketch;relevance feedback;artificial intelligence;computer science	Graphics	-10.175041459398498	-61.30877211732385	170035
73e9ce5a967279019d53d8a980501449f56abf5c	unsupervised method to generate page templates	4230;document image analysis;document analysis;classification non supervisee;0130c;correction erreur;optical character recognition;imagerie;analyse documentaire;imagery;couverture;error correction;clasificacion no supervisada;poursuite cible;unsupervised classification;analisis documental;coverage;imagineria;target tracking;reconnaissance optique caractere;cobertura	In this paper, we propose a method for automatically inferring the different page templates used to layout the document content. The first step of the method consists in performing a logical analysis of the document. Depending of the coverage of this step, a given number of document elements will be labeled. Then geometric relations are computed between these labeled elements, and page templates candidates are generated using frequent related elements. A fuzzy matching operation allows for selecting the most frequent and relevant page templates for a given document. Such page templates can be used to correct errors produced during the different previous steps of the document analysis: zoning, OCR, and logical analysis. Evaluation has been performed using the INEX book track collection.	optical character recognition;unsupervised learning	Hervé Déjean	2011		10.1117/12.873160	error detection and correction;speech recognition;computer science;data mining;optical character recognition	Web+IR	-12.129039109133828	-62.48295534572221	170279
40266208e7e17b187e18b683d8d9fde6f3fc7264	a video-based framework for the analysis of presentations/posters	vision ordenador;ontologie;donnee textuelle;image processing;dato textual;text processing;optical character recognition;extraction forme;procesamiento imagen;digital camera;application integration;traitement image;rectification;computer vision;image interpretation;reconnaissance caractere;interpretacion imagen;extraccion forma;traitement document;system integration;imaging;image sequence;reconocimento optico de caracteres;textual data;pattern recognition;visual impairment;formation image;ontologia;text detection;vision ordinateur;secuencia imagen;formacion imagen;document processing;digital image;interpretation image;reconnaissance forme;rectificacion;reconocimiento patron;character recognition;ontology;pattern extraction;reconocimiento caracter;sequence image;reconnaissance optique caractere;tratamiento documento	Detection and recognition of textual information in an image or video sequence is important for many applications. The increased resolution and capabilities of digital cameras and faster mobile processing allow for the development of interesting systems. We present an application based on the capture of information presented at a slide-show presentation or at a poster session. We describe the development of a system to process the textual and graphical information in such presentations. The application integrates video and image processing, document layout understanding, optical character recognition (OCR), and pattern recognition. The digital imaging device captures slides/poster images, and the computing module preprocesses and annotates the content. Various problems related to metric rectification, key-frame extraction, text detection, enhancement, and system integration are addressed. The results are promising for applications such as a mobile text reader for the visually impaired. By using powerful text-processing algorithms, we can extend this framework to other applications, e.g., document and conference archiving, camera-based semantics extraction, and ontology creation.	algorithm;archive;cluster analysis;computer vision;digital camera;digital imaging;edge detection;graph (discrete mathematics);graphical user interface;ibm notes;image processing;image rectification;key frame;mean shift;optical character recognition;pattern recognition;super-resolution imaging;system integration;text graph;video	Ali Zandifar;Ramani Duraiswami;Larry S. Davis	2004	International Journal of Document Analysis and Recognition (IJDAR)	10.1007/s10032-004-0137-0	computer vision;speech recognition;document processing;image processing;computer science;ontology;multimedia;optical character recognition;digital image;system integration;rectification;computer graphics (images)	Vision	-13.238873572250778	-56.72718840546741	170598
f5aac1195ea096560bb6cc476e75cc673fcb0c13	an in-depth evaluation of multimodal video genre categorization	performance evaluation;video retrieval image classification internet performance evaluation;video retrieval;genre categorization performance improvement in depth evaluation video descriptor performance evaluation multimodal video genre categorization late fusion technique design categorization accuracy 2012 video genre tagging task mediaeval benchmarking initiative for multimedia evaluation web media;image classification;internet;visualization support vector machines image color analysis histograms feature extraction tagging standards	In this paper we propose an in-depth evaluation of the performance of video descriptors to multimodal video genre categorization. We discuss the perspective of designing appropriate late fusion techniques that would enable to attain very high categorization accuracy, close to the one achieved with user-based text information. Evaluation is carried out in the context of the 2012 Video Genre Tagging Task of the MediaEval Benchmarking Initiative for Multimedia Evaluation, using a data set of up to 15.000 videos (3,200 hours of footage) and 26 video genre categories specific to web media. Results show that the proposed approach significantly improves genre categorization performance, outperforming other existing approaches. The main contribution of this paper is in the experimental part, several valuable interesting findings are reported that motivate further research on video genre classification.		Ionut Mironica;Bogdan Ionescu;Peter Knees;Patrick Lambert	2013	2013 11th International Workshop on Content-Based Multimedia Indexing (CBMI)	10.1109/CBMI.2013.6576545	computer vision;contextual image classification;the internet;computer science;multimedia;information retrieval	Web+IR	-16.154450119473367	-56.66924447459076	170993
840207fe23637b0626ea252d587ef1d2c95da117	probability based document clustering and image clustering using content-based image retrieval	document clustering;word frequency;major colour set;rgb histogram based image retrieval;hue saturation value;region of interest;distribution block signature;content based image retrieval;global colour signature	Clustering of related or similar objects has long been regarded as a potentially useful contribution of helping users to navigate an information space such as a document collection. Many clustering algorithms and techniques have been developed and implemented but as the sizes of document collections have grown these techniques have not been scaled to large collections because of their computational overhead. To solve this problem, the proposed system concentrates on an interactive text clustering methodology, probability based topic oriented and semi-supervised document clustering. Recently, as web and various documents contain both text and large number of images, the proposed system concentrates on content-based image retrieval (CBIR) for image clustering to give additional effect to the document clustering approach. It suggests two kinds of indexing keys, major colour sets (MCS) and distribution block signature (DBS) to prune away the irrelevant images to given query image. Major colour sets are related with colour information while distribution block signatures are related with spatial information. After successively applying these filters to a large database, only small amount of high potential candidates that are somewhat similar to that of query image are identified. Then, the system uses quad GB histogram-based image retrieval modelling method (QM) to set the initial weight of two-dimensional cells in query image according to each major colour and retrieve more similar images through similarity association function associated with the weights. The proposed system evaluates the system efficiency by implementing and testing the clustering results with Dbscan and K-means clustering algorithms. Experiment shows that the proposed document clustering algorithm performs with an average efficiency of 94.4% for various document categories.	algorithm;archive;cluster analysis;computation;content-based image retrieval;dbscan;direct-broadcast satellite;electronic signature;k-means clustering;overhead (computing);relevance;semiconductor industry	M. Karthikeyan;P. Aruna	2013	Appl. Soft Comput.	10.1016/j.asoc.2012.09.013	correlation clustering;data stream clustering;hsl and hsv;document clustering;fuzzy clustering;flame clustering;computer science;canopy clustering algorithm;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;word lists by frequency;cluster analysis;brown clustering;dbscan;information retrieval;clustering high-dimensional data;region of interest;conceptual clustering	Web+IR	-16.593710362278642	-58.45718842707194	171000
801ed7e9d9c1b1c2bb686a9f736ad86c10afc9e4	key to effective video retrieval: effective cataloging and browsing	digital library;video retrieval;cataloger;video segmentation;video search and browse;computer vision;video annotation;speech recognition;digital library creation;video search;multiview storyboard	1. ABSTRACT Mukirnedia data is an increasingly important information medium today. Providing intelligent access for effective use of this information continues to offer challenges in digital Iibrary research. As computer vision, image processing and speech recognition research continue to progress, we examine the effectiveness of these fully automated techniques in architecting effective video retrieval systems. We present semi-automated techniques that combine manual inpu~ and video and speech technology for automatic content characterization integrated into a single system we cdl CueVideo. CueVideo integrates voice and manual annotation, attachment of related da~ visual content search technologies (QBICti), and novel mukiview storyboard generation to provide a system where the user can incorporate the type of semantic information that automatic techniques would fail to obtain. 1.1	attachments;browsing;computer vision;image processing;semiconductor industry;speech recognition;speech technology;storyboard	Dulce B. Ponceleon;Savitha Srinivasan;Arnon Amir;Dragutin Petkovic;Dan Diklic	1998		10.1145/290747.290760	computer vision;digital library;computer science;video tracking;multimedia;smacker video;world wide web;non-linear editing system	Web+IR	-14.804622121839488	-55.86858405994311	171232
091f4fdee368736ccf933cc37a4df1da64304f7a	multi-modal retrieval for multimedia digital libraries: issues, architecture, and mechanisms	digital library	Supporting effective and efficient retrieval of multimedia data is a challenging problem in building a digital library. In this paper, we examine the issues related to accommodating multi-modal retrieval of multimedia data (text, image, video and audio), and propose 2M2Net as a generic framework for such versatile retrieval in multimedia digital libraries. The retrieval is conducted based on the integration of multi-modal features including both semantic keywords and media-specific low-level features. This framework is capable of progressive improvement of its retrieval performance, by applying the learning-from-elements strategy to propagate keyword annotations, as well as the query profiling strategy to facilitate effective retrieval using historic information of the previously processed queries.	digital library;high- and low-level;library (computing);modal logic	Jun Yang;Yueting Zhuang;Qing Li	2001			digital media;architecture;digital library;profiling (computer programming);information retrieval;multimedia;computer science	Web+IR	-14.637898236821076	-57.266887896290505	171599
0a1d483f219775d8a73f35f3216166411825a2a5	a pattern similarity scheme for medical image retrieval	content management;database system;expectation maximization algorithms;pattern similarity;medical image retrieval;block based low level feature extraction;content based image retrieval cbir;my publications;information retrieval;semantics;biomedical imaging;feature space;radiographic images;semantic interpretation;semantics content based image retrieval cbir feature extraction patterns pattern similarity;radiography;semantic interpretation medical image retrieval next generation database system framework block based low level feature extraction expectation maximization algorithm radiographic images;iterative methods;next generation database system framework;algorithms cluster analysis diagnostic imaging hand humans image processing computer assisted information storage and retrieval pattern recognition automated pelvis radiography thoracic;feature extraction;medical image processing;database systems;number of clusters;expectation maximization algorithm;next generation;biomedical imaging image retrieval information retrieval content based retrieval database systems content management feature extraction expectation maximization algorithms iterative methods radiography;patterns;medical image processing diagnostic radiography image retrieval;knowledge representation;content based image retrieval;content based retrieval;diagnostic radiography;image retrieval	In this paper, we propose a novel scheme for efficient content-based medical image retrieval, formalized according to the PAtterns for Next generation DAtabase systems (PANDA) framework for pattern representation and management. The proposed scheme involves block-based low-level feature extraction from images followed by the clustering of the feature space to form higher-level, semantically meaningful patterns. The clustering of the feature space is realized by an expectation-maximization algorithm that uses an iterative approach to automatically determine the number of clusters. Then, the 2-component property of PANDA is exploited: the similarity between two clusters is estimated as a function of the similarity of both their structures and the measure components. Experiments were performed on a large set of reference radiographic images, using different kinds of features to encode the low-level image content. Through this experimentation, it is shown that the proposed scheme can be efficiently and effectively applied for medical image retrieval from large databases, providing unsupervised semantic interpretation of the results, which can be further extended by knowledge representation methodologies.	academic medical centers;cluster analysis;content-based image retrieval;data sources;data mining;data structure;database;encode;expectation–maximization algorithm;experiment;feature extraction;feature vector;genetic heterogeneity;handling (psychology);high- and low-level;image retrieval;immunoradiometric assays;indexes;information extraction;irma board;iterative method;knowledge representation and reasoning;medical image;radiography;semantic interpretation;statistical cluster	Dimitrios K. Iakovidis;Nikos Pelekis;Evangelos E. Kotsifakos;Ioannis Kopanakis;Haralampos Karanikas;Yannis Theodoridis	2009	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2008.923144	medical imaging;computer vision;semantic interpretation;visual word;radiography;radiology;feature vector;expectation–maximization algorithm;feature extraction;content management;image retrieval;computer science;machine learning;pattern recognition;semantics;iterative method;pattern;information retrieval	Vision	-10.508453855512373	-60.141058981612304	171609
72cada170638de8ddec40c5e24e7e6349202dd4b	using closed captions to train activity recognizers that improve video retrieval	soccer videos;activity recognizers;support vector machines;training;video retrieval;video retrieval classification content based retrieval;humans cameras labeling content based retrieval multimedia communication broadcasting games multimedia systems training data dvd;data mining;classification;linguistic analysis;visualization;feature extraction;games;humans;closed captions;background clutter;human supervision;caption classifier;content based retrieval;caption classifier closed captions activity recognizers video retrieval background clutter automated activity recognition soccer videos human supervision;activity recognition;automated activity recognition	Recognizing activities in real-world videos is a difficult problem exacerbated by background clutter, changes in camera angle & zoom, rapid camera movements etc. Large corpora of labeled videos can be used to train automated activity recognition systems, but this requires expensive human labor and time. This paper explores how closed captions that naturally accompany many videos can act as weak supervision that allows automatically collecting `labeled' data for activity recognition. We show that such an approach can improve activity retrieval in soccer videos. Our system requires no manual labeling of video clips and needs minimal human supervision. We also present a novel caption classifier that uses additional linguistic information to determine whether a specific comment refers to an on-going activity. We demonstrate that combining linguistic analysis and automatically trained activity recognizers can significantly improve the precision of video retrieval.	activity recognition;clutter;finite-state machine;multimodal interaction;safe area (television);text corpus;video clip	Sonal Gupta;Raymond J. Mooney	2009	2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2009.5204202	games;support vector machine;computer vision;closed captioning;speech recognition;visualization;feature extraction;biological classification;computer science;machine learning;multimedia;activity recognition	Vision	-17.053182393719034	-56.738922868406725	171885
3a72fe61f59ad5428eefb86adc20dc6e87e335ac	a naive relevance feedback model for content-based image retrieval using multiple similarity measures	busqueda informacion;benchmarking;performance measure;iterative method;evaluation performance;similarity combination;performance evaluation;recherche image;information retrieval;evaluacion prestacion;evaluacion comparativa;analisis objetivos;pregunta documental;probabilistic approach;similitude;metodo iterativo;recherche information;busqueda por contenido;methode iterative;enfoque probabilista;approche probabiliste;similarity;query;similitud;content based image retrieval;user interaction;similarity measure;analyse objective;relevance feedback;content based retrieval;recherche par contenu;objective analysis;requete;image retrieval	This paper presents a novel probabilistic framework to process multiple sample queries in content based image retrieval (CBIR). This framework is independent from the underlying distance or (dis)similarity measures which support the retrieval system, and only assumes mutual independence among their outcomes. The proposed framework gives rise to a relevance feedback mechanism in which positive and negative data are combined in order to optimally retrieve images according to the available information. A particular setting in which users interactively supply feedback and iteratively retrieve images is set both to model the system and to perform some objective performance measures. Several repositories using different image descriptors and corresponding similarity measures have been considered for benchmarking purposes. The results have been compared to those obtained with other representative strategies, suggesting that a significant improvement in performance can be obtained.	content-based image retrieval;relevance feedback	Miguel Arevalillo-Herráez;Francesc J. Ferri;Juan Domingo	2010	Pattern Recognition	10.1016/j.patcog.2009.08.010	similarity;image retrieval;computer science;artificial intelligence;similitude;pattern recognition;data mining;mathematics;geometry;iterative method;information retrieval;benchmarking	Vision	-12.63689382962581	-60.384345861997005	172110
26534206831483d9f5434fe2fe0839afe83cfca3	ranking and retrieval of image sequences from multiple paragraph queries	text analysis document image processing image retrieval image sampling image sequences natural languages support vector machines;image segmentation blogs image sequences streaming media semantics training natural languages;support vector machine paragraph queries image sequences ranking image sequences retrieval natural language text query text only reviews tripadvisor yelp illustrative image sequences natural language sentence user generated resource blog posts text image parallel training data informative text representative images large scale photo streams image samples latent structural svm framework semantic relevance relations disneyland dataset	We propose a method to rank and retrieve image sequences from a natural language text query, consisting of multiple sentences or paragraphs. One of the method's key applications is to visualize visitors' text-only reviews on TRIPADVISOR or YELP, by automatically retrieving the most illustrative image sequences. While most previous work has dealt with the relations between a natural language sentence and an image or a video, our work extends to the relations between paragraphs and image sequences. Our approach leverages the vast user-generated resource of blog posts and photo streams on the Web. We use blog posts as text-image parallel training data that co-locate informative text with representative images that are carefully selected by users. We exploit large-scale photo streams to augment the image samples for retrieval. We design a latent structural SVM framework to learn the semantic relevance relations between text and image sequences. We present both quantitative and qualitative results on the newly created DISNEYLAND dataset.	blog;information;natural language;relevance;text-based user interface;user-generated content;world wide web	Gunhee Kim;Seungwhan Moon;Leonid Sigal	2015	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2015.7298810	natural language processing;visual word;image retrieval;computer science;pattern recognition;automatic image annotation;information retrieval	Vision	-17.708311942008415	-58.69647694465231	172452
3b869c7bc553c1fa51f2e5824e24848d05888c88	developmental models of multicellular organisms: a computer graphics perspective	computer graphic		computer graphics	Aristid Lindenmayer;Przemyslaw Prusinkiewicz	1987			computational biology;artificial intelligence;computer graphics;multicellular organism;computer science	Visualization	-8.125074686494221	-56.22060177031035	173809
e55bf1127e0890ec039933722ea29e2842862ebb	using non-parametric quantum theory to rank images	photonics;non parametric approach;programming language semantics;flickr;quantum measurement;social image search;flickr dataset nonparametric quantum theory rank images ranking model social image search low level visual features high level semantic concepts social image re ranking retrieved images quantum estimation photon polarization quantum measurement;vectors;estimation;quantum mechanics;quantum theory;feature extraction;quantum theory feature extraction image retrieval programming language semantics;flickr social image search non parametric approach quantum measurement;estimation vectors equations quantum mechanics image retrieval photonics;image retrieval	Recently learning to rank has become one of the popular means to create a ranking model for social image search. However, the results of existing approaches are not as satisfactory for the large gap between low-level visual features and high-level semantic concepts, and these sophisticated approaches require a significant amount of parameters tuning to be effective and efficient. In this paper, we propose a novel framework for social image re-ranking based on a non-parametric quantum technique, which reranks top retrieved images by considering the interrelationship between images through the quantum estimation and requires no explicit parameter tuning. The basic idea of the proposed framework is inspired by the photon polarization experiment supporting the theory of quantum measurement. Experimental results conducted on the Flickr dataset demonstrate the effectiveness and efficiency of the proposed framework.	flickr;high- and low-level;image retrieval;learning to rank;measurement in quantum mechanics;performance tuning;photon polarization	Songhao Zhu;Wang Baoyun;Yuncai Liu	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288066	computer vision;estimation;photonics;feature extraction;image retrieval;computer science;theoretical computer science;machine learning;mathematics;information retrieval	Robotics	-15.856314070550026	-62.00228184782319	174116
3922f46a1ecbf27bafa2a804b9a3156961b58500	automated forms-processing software and services	traitement automatise;camino mas corto;documento;shortest path;systeme intelligent;architecture systeme;image processing;improvement;sistema inteligente;procesamiento imagen;plus court chemin;clasificador;segmentation;traitement image;specification language;document;reconstruction image;classifier;reconnaissance caractere;reconstruccion imagen;image reconstruction;tratamiento automatizado;amelioration;intelligent system;pattern recognition;classificateur;mejoria;arquitectura sistema;lenguaje especificacion;reconnaissance forme;reconocimiento patron;system architecture;langage specification;character recognition;segmentacion;reconocimiento caracter;automated processing	"""While document-image systems for the management of collections of documents, such as forms, offer significant productivity improvements, the entry of information from documents remains a labor-intensive and costly task for most organizations. In this paper, we describe a software system for the machine reading of forms data from their scanned images. We describe its major components: form recognition and """"dropout,"""" intelligent character recognition (ICR), and contextual checking. Finally, we describe applications for which our automated forms reader has been successfully used."""	dropout (neural networks);forms processing;image scanner;intelligent character recognition;natural language understanding;optical character recognition;software system	Sandeep Gopisetty;Raymond A. Lorie;Jianchang Mao;K. Moidin Mohiuddin;Alexander Sorin;Eyal Yair	1996	IBM Journal of Research and Development	10.1147/rd.402.0211	iterative reconstruction;computer vision;classifier;specification language;image processing;computer science;engineering;artificial intelligence;shortest path problem;programming language;segmentation;systems architecture	ML	-11.785234437186494	-62.13030180899089	174327
a91688124b4c47f01c4a296d1109fb3186b0b0ba	datapipeline: automated importing and fitting of large amounts of biophysical data	mass spectrometry;import;data handling;curve fitting;kinetics	Raw data from experiments across the biological sciences comes in a large variety of text formats. In small or medium sized laboratories researchers often use an assorted collection of software to interpret, fit, and visualize their data. The spreadsheet is commonly the core component of such a workflow. The limitations of such programs for large amounts of heterogeneous data can be frustrating. We report the construction of DataPipeline, a desktop and command-line application that automates the tasks of importing, fitting, and plotting of text-based data. The software is designed to simplify the process of importing text data from various sources using simple configuration files to describe raw file formats. Once imported, curve fitting can be performed using custom fitting models designed by the user inside the application. Fitted parameters can be grouped together as new datasets to be fitted to other models and experimental uncertainties propagated to give error estimates. This software will be useful for processing of data from high through-put biological experiments or for rapid visualization of pilot data without the need for a chain of different programs to carry out each step. DataPipeline and source code is available under an open source license. The software can be freely downloaded at http://code.google.com/p/peat/downloads/list.		Damien Farrell;Jens Erik Nielsen	2012	Journal of computational chemistry	10.1002/jcc.23066	chemistry;mass spectrometry;group method of data handling;data mining;physics;kinetics;curve fitting	Comp.	-4.694985733489974	-58.72249310840376	174457
c52ca0644c8dbe3733beb415c581c5cdf3ebda28	enabling object based in-content placement for digital video television systems	digital video broadcasting;video object;prerecorded mpeg 2 video material;digital video broadcast;meta data object based in content placement digital video broadcast dvb television system prerecorded mpeg 2 video material object annotation synchronization scheme;synchronisation;service model;video coding;object annotation;meta data;digital video broadcasting data mining streaming media timing transform coding digital tv laboratories materials science and technology information retrieval content based retrieval;digital video;dvb television system;object based in content placement;synchronization scheme;transport stream;video coding digital video broadcasting meta data synchronisation	This paper presents a framework for object based interactivity in digital video broadcast (DVB) television systems. Based upon pre-recorded MPEG-2 video material an object annotation and synchronization scheme has been designed and implemented enabling the viewer to actively interact on previously marked video objects. The framework comprises an authoring process which extracts the necessary Meta data the introduction of a new timeline in the transport stream and the synchronization process at the client site. To show its feasibility at the client site the MHP platform was used. Obtained results of various content samples indicate that our approach is promising and effective thus offering new service models such as e.g. automatic in-program content placements	digital video broadcasting;h.262/mpeg-2 part 2;interactivity;mpeg transport stream;mpeg-2;object-based language;timeline	Rudolf Jaeger;Peter Dunker;Andreas Hanusch	2006	Eighth IEEE International Symposium on Multimedia (ISM'06)	10.1109/ISM.2006.70	synchronization;telecommunications;computer science;video capture;service-oriented modeling;video tracking;multimedia;video processing;internet privacy;metadata;world wide web;digital video broadcasting	Embedded	-15.013808105448938	-54.42953921818458	174508
0ddd35479ffc3cbf4ef0dabe1e4ae479aabb9179	mutual spotting retrieval between speech and video image using self-organized network databases	search and retrieval;video codec;degeneration;self organization	Video codec technology like MPEG and improved performance of microprocessors enable environments to be setup in which large volumes of video images can be stored. The ability to perform search and retrieve operations on stored video is therefore becoming more important. This paper proposes a technique for performing mutual spotting retrieval between speech and video images in which either speech or video is used as a query to retrieve the other. This technique makes use of a network that self organizes itself incrementally and represents redundant structures in degenerate form, which makes for efficient searches. As a result, the capacity of a database can be decreased by about one half for speech and by about three fourths for video when expressed in network form. Applying this technique to a database consisting of six-hours worth of speech and video, it was found that a search from video to speech could be performed in 0.5 seconds per frame.	database;network model	Takashi Endo;Jianxin Zhang;Masayuki Nakazawa;Ryuichi Oka	1998		10.1007/3-540-48962-2_8	video compression picture types;microsoft video 1;computer vision;speech recognition;uncompressed video;computer science;video tracking;block-matching algorithm;multimedia;video processing;smacker video;motion compensation;video post-processing;multiview video coding	Vision	-13.869161554985373	-54.70509632346551	174525
ede3cd0ef27a2bb27b1de27e20e8e3c6ebd3da53	association and temporal rule mining for post-filtering of semantic concept detection in video	analisis coocurrencia;anotacion;content based video retrieval and mining;association statistique;temporal rule mining;filtering;filtrage;analyse cooccurrence;semantic concept detection;association mining;medicion automatica;multimedia;recherche image;base donnee temporelle;filtrado;conceptual analysis;semantics;statistical association;post filtering framework;video retrieval;image classification;annotation;temporal rule mining association rule mining content based video retrieval and mining post filtering semantic concept detection;automatic measurement;mesure automatique;indexing terms;post filtering;data mining;semantica;semantique;classification;cooccurrence analysis;analisis conceptual;association rule mining;temporal filtering;asociacion estadistica;senal video;signal video;association rule;pattern classification automatic semantic concept detection temporal rule mining association rule mining content based video retrieval post filtering framework knowledge discovery;fouille donnee;busqueda por contenido;robustesse;decouverte connaissance;pattern classification;video signal;descubrimiento conocimiento;robustness;temporal databases;computational linguistics;content based video retrieval;analyse conceptuelle;automatic semantic concept detection;gunshot detection systems content based retrieval face detection robustness data mining association rules filters bridges terrorism computer science;video retrieval computational linguistics content based retrieval data mining filtering theory image classification;content based retrieval;busca dato;clasificacion;recherche par contenu;filtering theory;robustez;knowledge discovery;image retrieval	Automatic semantic concept detection in video is important for effective content-based video retrieval and mining and has gained great attention recently. In this paper, we propose a general post-filtering framework to enhance robustness and accuracy of semantic concept detection using association and temporal analysis for concept knowledge discovery. Co-occurrence of several semantic concepts could imply the presence of other concepts. We use association mining techniques to discover such inter-concept association relationships from annotations. With discovered concept association rules, we propose a strategy to combine associated concept classifiers to improve detection accuracy. In addition, because video is often visually smooth and semantically coherent, detection results from temporally adjacent shots could be used for the detection of the current shot. We propose temporal filter designs for inter-shot temporal dependency mining to further improve detection accuracy. Experiments on the TRECVID 2005 dataset show our post-filtering framework is both efficient and effective in improving the accuracy of semantic concept detection in video. Furthermore, it is easy to integrate our framework with existing classifiers to boost their performance.	association rule learning;coherence (physics);experiment;sensor;statistical classification;temporal logic	Ken-Hao Liu;Ming-Fang Weng;Chi-Yao Tseng;Yung-Yu Chuang;Ming-Syan Chen	2008	IEEE Transactions on Multimedia	10.1109/TMM.2007.911826	association rule learning;image retrieval;computer science;computational linguistics;pattern recognition;data mining;semantics;information retrieval	Vision	-14.55303559569024	-59.586598748702436	174694
2c2a9fcc582bf01cf06414378cc8411c389ec4b6	in tags we trust: trust modeling in social tagging of multimedia content	content management;search and retrieval;social network services;online services;social networking services;information retrieval;trust modeling;spam annotations trust modeling social tagging multimedia content retrieval online social networks;trust model;noise measurement;multimedia computing;trusted computing;social network services tagging information retrieval multimedia communication search problems online services content management noise measurement information analysis;multimedia communication;social networking online;unsolicited e mail information retrieval multimedia computing social networking online trusted computing;search problems;online social network;unsolicited e mail;social tagging;article;information analysis;reputation systems;spam combatting;tagging	Tagging in online social networks is very popular these days, as it facilitates search and retrieval of multimedia content. However, noisy and spam annotations often make it difficult to perform an efficient search. Users may make mistakes in tagging and irrelevant tags and content may be maliciously added for advertisement or self-promotion. This article surveys recent advances in techniques for combatting such noise and spam in social tagging. We classify the state-of-the-art approaches into a few categories and study representative examples in each. We also qualitatively compare and contrast them and outline open issues for future research.	database;folksonomy;relevance;social network;spamming;trust (emotion)	Ivan Ivanov;Peter Vajda;Jong-Seok Lee;Touradj Ebrahimi	2012	IEEE Signal Processing Magazine	10.1109/MSP.2011.942345	content management;computer science;noise measurement;internet privacy;data analysis;trustworthy computing;world wide web;information retrieval	Web+IR	-18.605820681222834	-55.17414733389339	174962
563aea341a342a6055a7a598cbab1837e8dabf3a	a microarray information database	dna;databases;mrna molecule;dna sequence microarray information database microarray technology open source web based information system bioinformatics laboratory information management systems gene expression mrna molecule;biology computing;databases probes laboratories sequences bioinformatics dna gene expression organisms protocols feature extraction;protocols;lims bioinformatics microarrays;information systems;web based information system;laboratory information management systems;open source web based information system;molecular biophysics biology computing dna genetics information systems internet;probes;genetics;gene expression;arrays;servers;internet;molecular biophysics;lims;microarray information database;microarray technology;dna sequence;open source;microarrays;bioinformatics	The development of microarray technology has been phenomenal, during the past years, and it is becoming a daily tool in many genomics research laboratories. However, the multi-step and data-intensive nature of this technology has created an unprecedented computational challenge. In fact, the full power of microarrays technology can only be achieved if researchers are able to efficiently store, analyse and share their results. In this article we describe a flexible and extensible platform that can be used to gather the natural workflow of microarray experiments. It is an open-source web-based information system that also integrates a set of statistical and processing methods to analyse and visualize the data. By doing this integration in a single system, we hope to speed up the research and discovery processes.	computation;data-intensive computing;experiment;information system;microarray;open-source software;web application	Joel Arrais;Laura Carreto;Manuel A. S. Santos;José Luís Oliveira	2008	2008 International Conference on Biocomputation, Bioinformatics, and Biomedical Technologies	10.1109/BIOTECHNO.2008.22	biology;communications protocol;dna sequencing;the internet;gene expression;dna microarray;computer science;bioinformatics;data mining;world wide web;genetics;dna;information system;server;molecular biophysics	DB	-5.031776650728211	-60.791346777316264	175001
7095f9493dfc46c201497a900c5369b192dd53c7	a database-centric virtual chemistry system		We describe an Oracle database application for general use within virtual chemistry. The application functions as a central hub and repository for chemical data with interfaces to external calculators. It deals with the general problems of merging data from disparate sources and with scheduling of computational tasks for parallel or sequential execution in a mixed environment. The central database is used for the storage of input, intermediary, and final data as well as for job control. A calculation job is split into distinct tasks, or units of work, which are put in a queue. Tasks are dequeued and handled by specialized calculators. These calculators are in-house or commercial programs for which adaptor modules for connection to the database must be written. Tasks are handled in a transactional fashion, so that uncompleted or failed tasks are left in the queue. This makes the system stable to many types of disturbances. Sorting, filtering, and merging operations are handled by the database itself. Usage is very general, but some specific examples are (1) as a back end for a chemical property calculator Web page, (2) in an automated quantitative structure-activity relationship system, and (3) in virtual screens.		Peter Lind;Markus Alm	2006	Journal of chemical information and modeling	10.1021/ci050360b	real-time computing;simulation;computer science;bioinformatics;machine learning;database;mathematics	DB	-5.124775133223194	-59.15718180617551	175097
aaad4a646141883b57e16e430fbe28d6e004b7ca	a modular framework for the automatic reconstruction of shredded documents	unshred;reconstruction;document;strip cut;cross cut;shredded;deshred	The unshredding problem is of interest in various domains such as forensics, investigative sciences and archeology, and has therefore been approached in many different ways. This paper tries to bridge the gap between previous, disparate, efforts by proposing a modular, probabilistic, solution. Novel approaches to two of the independent subproblems are presented and shown to both have good theoretical properties and to empirically outperform previously published methods.	computer forensics	Razvan Ranca	2013			signal reconstruction;computer science;artificial intelligence;machine learning;data mining	ML	-11.814043224630643	-65.30848392560063	175420
9c529f81a6f0e69e04765b8350fef867922a58c5	thermalized drude oscillators with the lammps molecular dynamics simulator	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	LAMMPS is a very customizable molecular dynamics simulation software, which can be used to simulate a large diversity of systems. We introduce a new package for simulation of polarizable systems with LAMMPS using thermalized Drude oscillators. The implemented functionalities are described and are illustrated by examples. The implementation was validated by comparing simulation results with published data and using a reference software. Computational performance is also analyzed.		Alain Dequidt;Julien Devémy;Agílio A. H. Pádua	2016	Journal of chemical information and modeling	10.1021/acs.jcim.5b00612	text mining;medical research;computer science;bioinformatics;data science;data mining	HPC	-7.249960402013649	-59.338940122062915	175603
4131bc7e8cc20607e38edc61d44e90d427b02f1a	coordinated graph and scatter-plot views for the visual exploration of microarray time-series data	time course;scatter plot view;query formulation;visual queries;disease treatment;information visualization;time series;scattering data visualization biology computing data acquisition time series analysis diseases information analysis displays chromium user interfaces;multiple views;information visualization techniques;requirement analysis;data visualisation;visualization;disease diagnosis;time series data acquisition data visualisation query formulation user interfaces;multiple views graph view scatter plot view visual exploration microarray time series data microarrays data acquisition biological phenomena investigation microarray experimentation microarray time course experiment disease diagnosis disease treatment disease prevention information visualization techniques requirements analysis visual queries time graph data representation bioinformatics;visual exploration;graph view;graph representation;disease prevention;time series data;microarray time series data;high throughput;time graph data representation;biological phenomena investigation;data acquisition;user interfaces;qh301 biology;microarray time course experiment;microarray experimentation;microarrays;bioinformatics;qa76 computer software;requirements analysis	Microarrays are relatively new, high-throughput data acquisition technology for investigating biological phenomena at the micro-level. One of the more common procedures for microarray experimentation is that of the microarray time-course experiment. The product of microarray time-course experiment is time-series data, which subject to proper analysis has the potential to have significant impact on the diagnosis, treatment, and prevention of diseases. While existing information visualization techniques go some way to making microarray time-series data more manageable, requirements analysis has revealed significant limitations. The main finding was that users were unable to uncover and quantify common changes in value over a specified time-period. This paper describes a novel technique that provides this functionality by allowing the user to visually formulate and modify measurable queries with separate time-period and condition components. These visual queries are supported by the combination of a traditional value against time graph representation of the data with a complementary scatter-plot representation of a specified time-period. The multiple views of the visualization are coordinated so that the user can formulate and modify queries with rapid reversible display of query results in the traditional value against time graph format.	dna microarray;data acquisition;direct manipulation interface;experiment;graph (abstract data type);high-throughput computing;information visualization;requirement;requirements analysis;throughput;time series;usability	Paul Craig;Jessie B. Kennedy	2003	IEEE Symposium on Information Visualization 2003 (IEEE Cat. No.03TH8714)	10.1109/INFVIS.2003.1249023	requirements analysis;information visualization;computer science;bioinformatics;data science;time series;data mining;data visualization;statistics	Visualization	-6.168889004555684	-60.13833265973747	175666
765b2cb322646c52e20417c3b44b81f89860ff71	poseshop: human image database construction and personalized content synthesis	image segmentation;image composition;image databases;skin;information filtering;image database;qa75 electronic computers computer science;internet;humans skin image segmentation image databases image color analysis shape;shape;image composition image database;indexing;image color analysis;bone;humans;vision application poseshop segmented human image database human image filtering internet human figures action semantic clothe attributes indexing pose shape silhouette sketch skeleton multiframe personalized content synthesis comic strips personalization head swapping action correlation analysis application;visual databases bone image segmentation indexing information filtering internet;visual databases	We present PoseShop - a pipeline to construct segmented human image database with minimal manual intervention. By downloading, analyzing, and filtering massive amounts of human images from the Internet, we achieve a database which contains 400 thousands human figures that are segmented out of their background. The human figures are organized based on action semantic, clothes attributes, and indexed by the shape of their poses. They can be queried using either silhouette sketch or a skeleton to find a given pose. We demonstrate applications for this database for multiframe personalized content synthesis in the form of comic-strips, where the main character is the user or his/her friends. We address the two challenges of such synthesis, namely personalization and consistency over a set of frames, by introducing head swapping and clothes swapping techniques. We also demonstrate an action correlation analysis application to show the usefulness of the database for vision application.	action potential;adobe photoshop;algorithm;download;drug vehicle;entity name part qualifier - adopted;frame (physical object);image analysis;index;indexes;interactivity;internet;machine learning;paging;personality character;personalization;precision medicine;strips;semantic analysis (compilers);sketch-based modeling;skin (computing);biologic segmentation	Tao Chen;Ping Tan;Li-Qian Ma;Ming-Ming Cheng;Ariel Shamir;Shi-Min Hu	2013	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2012.148	computer vision;search engine indexing;the internet;shape;computer science;geometry;multimedia;skin;image segmentation;information retrieval	Visualization	-11.727870614647403	-56.391227535218476	176171
425bb94845ebdffd54cdee60a79db8a0e371f7ef	human-robot information sharing with structured language generation from probabilistic beliefs	nonparametric dirichlet process mos generation human robot information sharing structured language generation probabilistic beliefs robot agent probability density function sensor fusion state estimation algorithms two way information exchange english sentences semantic correctness information preservation mixture of statements model;robot sensing systems;time measurement;probability density function;semantics;robot sensing systems information management probability density function semantics time measurement logistics;logistics;information management;state estimation belief networks human robot interaction language translation probability sensor fusion	This paper presents a framework for information sharing and fusion in cooperative tasks involving humans and robots. In this context, all information regarding the state of interest is recursively fused and maintained by each agent in a form of belief. For a robot agent, its belief is commonly and practically represented as a probability density function (pdf), formed by traditional sensor fusion and state estimation algorithms. In cooperative tasks with non-expert humans, a robot needs to effectively communicate its belief so that the gathered information can be easily processed and interpreted by the humans. The goal of this research is to provide two-way information exchange and fusion between robots and humans, the former operating on pdfs, while the latter on English sentences. This is achieved by considering two goodness measures: semantic correctness and information preservation. Based on the goodness measures studied, results show that the proposed framework is able to generate optimal statements describing the given belief pdfs and successfully recover the initial inputs used to generate them. Additionally, in order to describe complex belief pdfs, a Mixture of Statements (MoS) model is proposed such that the optimal expression can be generated through a composition of more than one statements. With a nonparametric Dirichlet Process MoS generation, it is found that the robot can determine correctly the number of statements as well as the corresponding reference parameters needed to describe all hypotheses underlying its belief.	algorithm;correctness (computer science);human–robot interaction;information exchange;natural language generation;portable document format;recursion;robot	Rina Tse;Mark E. Campbell	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7353528	logistics;computer vision;probability density function;computer science;artificial intelligence;machine learning;data mining;semantics;information management;statistics;time	Robotics	-11.699229797671926	-66.01560087527774	176277
6786bafa178bd9e5ac06b1d4334e4e3f8e1b0cf9	algorithm for rapid retrieval of elemental information	logiciel documentaire;information retrieval software;chemical element;base donnee;aplicacion;information retrieval;database;base dato;ibm pc;algorithme;algorithm;chimie;elemento quimico;recherche information;element chimique;chemistry;quimica;logicial documental;recuperacion informacion;application;algoritmo;fortran 5 0	During the past decades, more and more database and retrieval systems in chemistry have heen developed throughout the world (Ash ef al., 1985). In such systems, retrieval of elemental information (El) or using El as a screening method is often needed. Since El is in textual form, it is logical to use character data type to represent it (Wang & Neumann, 1989). But it is also evident that this method will need considerable extra disk space and lacks flexibility in the retrieval of the information. To avoid this deficiency, some systems (Jenkins & Holomany, 1987; Allen et al., 1991) have adopted bit mapping to build up the El index files. By using Boolean operations (Vernin & Chanon, 1986), it is very convenient to retrieve. various information. In this paper, the algorithm for the rapid retrieval of El is described in detail. The method has been used in our DRSPDF (Database and Retrieval System for X-Ray Powder Diffraction Files) with satisfactory performance. Other usefulness such as in the retrieval of organic functional group, name fragment, formula fragment and substructure is briefly outlined.	algorithm;angular defect;boolean operations on polygons;disk space;elemental;jenkins	Xiang-Jun Lu;Shao-Fan Lin;Jin-Bei Zhang	1993	Computers & Chemistry	10.1016/0097-8485(93)80017-8	computer science;theoretical computer science;ibm pc compatible;algorithm;chemical element	Web+IR	-5.3124725429977495	-55.83194319504553	176323
6700e88b32d13916a0f0443b49bec7dc405c5502	a classifier for semi-structured documents	generic model;vector space model;classification;semi structured document;structured vector;structured documents	In this paper, w edescribe a novel text classi er that can e ectiv ely cope with structured documents. We report experiments that compare its performance with that of a wellknown probabilistic classi er. Our novel classi er can take adv antage of the information in the structure of document that con ventional, purely term-based classi ers ignore.Conventional classi ers are mostly based on the vector space model of document, which views a document simply as an n-dimensional vector of terms. T o retain the information in the structure, w e ha ve dev eloped a structured vector model, which represents a document with a structured vector, whose elements can be either terms or other structured vectors. With this extended model, we also have improved the well-kno wn probabilistic classi cation method based on the Bernoulli document generation model. Our classi er based on these improvements performes signi cantly better on pre-classi ed samples from the web and the US Patent database than the usual classi ers.	bernoulli polynomials;experiment;naruto shippuden: clash of ninja revolution 3;semiconductor industry;whole earth 'lectronic link	Jeonghee Yi;Neel Sundaresan	2000		10.1145/347090.347164	biological classification;computer science;machine learning;pattern recognition;data mining;structured prediction;vector space model;structured support vector machine;information retrieval	DB	-17.280748792699026	-63.500301791703166	176646
fed90d780e530c4763ff628e588b2f206cc6b900	cloud-based benchmarking of medical image analysis		This book is open access under a CC BY-NC 2.5 license. This book presents the VISCERAL project benchmarks for analysis and retrieval of 3D medical images (CT and MRI) on a large scale, which used an innovative cloud-based evaluation approach where the image data were stored centrally on a cloud infrastructure and participants placed their programs in virtual machines on the cloud. The book presents the points of view of both the organizers of the VISCERAL benchmarks and the participants. The book is divided into five parts. Part I presents the cloud-based benchmarking and Evaluation-as-a-Service paradigm that the VISCERAL benchmarks used. Part II focuses on the datasets of medical images annotated with ground truth created in VISCERAL that continue to be available for research. It also covers the practical aspects of obtaining permission to use medical data and manually annotating 3D medical images efficiently and effectively. The VISCERAL benchmarks are described in Part III, including a presentation and analysis of metrics used in evaluation of medical image analysis and search. Lastly, Parts IV and V present reports by some of the participants in the VISCERAL benchmarks, with Part IV devoted to the anatomy benchmarks and Part V to the retrieval benchmark. This book has two main audiences: the datasets as well as the segmentation and retrieval results are of most interest to medical imaging researchers, while eScience and computational science experts benefit from the insights into using the Evaluation-as-a-Service paradigm for evaluation and benchmarking on huge amounts of data.	image analysis;medical image computing		2017		10.1007/978-3-319-49644-3	data science;benchmarking;cloud computing;medical imaging;computer science	Vision	-9.172276814242238	-53.927531129451495	176875
e64d2e44edffaa93d75e55d266d4d5f21c180ff7	new query refinement and semantics integrated image retrieval system with semiautomatic annotation scheme	databases;semantic integration;query refinement;feedback;content based image retrieval;relevance feedback;image retrieval;image similarity	 Relevance feedback is a powerful and widely used technique in content-based image retrieval systems. However, most relevance feedback approaches use only weighted feature sum of the feedback images to optimize the query for refining image similarity assessment. Such approaches do not work very well in most cases, especially when the user wants to express an &quot;OR&quot; relationship among the queries. In this paper, we propose three methods, weighted distance sum, minimal distance (MD), and minimal... 	image retrieval;refinement (computing)	Xingquan Zhu;HongJiang Zhang;Wenyin Liu;Chunhui Hu;Lide Wu	2001	J. Electronic Imaging	10.1117/1.1406504	query expansion;visual word;semantic integration;image retrieval;computer science;data mining;feedback;database;automatic image annotation;information retrieval;query language	Web+IR	-12.886563229984988	-59.80768901944881	176920
871f43a70f3171768734e0c2add1f263b8f47a70	manifold-ranking based image retrieval	similarity metric;manifold ranking;transductive learning;ucl;active learning;image database;discovery;theses;conference proceedings;feature space;digital web resources;ucl discovery;open access;ranking algorithm;ucl library;book chapters;open access repository;relevance feedback;ucl research;image retrieval	In this paper, we propose a novel transductive learning framework named manifold-ranking based image retrieval (MRBIR). Given a query image, MRBIR first makes use of a manifold ranking algorithm to explore the relationship among all the data points in the feature space, and then measures relevance between the query and all the images in the database accordingly, which is different from traditional similarity metrics based on pair-wise distance. In relevance feedback, if only positive examples are available, they are added to the query set to improve the retrieval result; if examples of both labels can be obtained, MRBIR discriminately spreads the ranking scores of positive and negative examples, considering the asymmetry between these two types of images. Furthermore, three active learning methods are incorporated into MRBIR, which select images in each round of relevance feedback according to different principles, aiming to maximally improve the ranking result. Experimental results on a general-purpose image database show that MRBIR attains a significant improvement over existing systems from all aspects.	algorithm;data point;feature vector;general-purpose modeling;image retrieval;relevance feedback;transduction (machine learning)	Jingrui He;Mingjing Li;HongJiang Zhang;Hanghang Tong;Changshui Zhang	2004		10.1145/1027527.1027531	ranking;feature vector;transduction;image retrieval;computer science;data science;machine learning;data mining;active learning;world wide web;information retrieval	Vision	-18.735145308027327	-62.250552197133736	177176
a95ef6f00f6fb6e56049ee115092025b8c07c40a	non-negative matrix factorization for overlapping clustering of customer inquiry and review data		Considering the complexity of clustering text datasets in terms of informal user generated content and the fact that there are multiple labels for each data point in many informal user generated content datasets, this paper focuses on Non-negative Matrix Factorization (NMF) algorithms for Overlapping Clustering of customer inquiry and review data, which has seldom been discussed in previous literature. We extend the use of Semi-NMF and Convex-NMF to Overlapping Clustering and develop a procedure of applying SemiNMF and Convex-NMF on Overlapping Clustering of text data. The developed procedure is tested based on customer review and inquiry datasets. The results of comparing SemiNMF and Convex-NMF with a baseline model demonstrate that they have advantages over the baseline model, since they do not need to adjust parameters to obtain similarly strong clustering performances. Moreover, we compare different methods of picking labels for generating Overlapping Clustering results from Soft Clustering algorithms, and it is concluded that thresholding by mean method is a simpler and relatively more reliable method compared to maximum n method.	algorithm;baseline (configuration management);cluster analysis;computer cluster;data point;non-negative matrix factorization;performance;text corpus;thresholding (image processing);user-generated content	Zekun Yang	2018		10.1145/3195106.3195110	machine learning;artificial intelligence;thresholding;fuzzy clustering;cluster analysis;matrix decomposition;computer science;pattern recognition;non-negative matrix factorization;document clustering	AI	-18.672873979340206	-64.15653103859339	177226
1492f1971a60a6f8c35b877b555c1d4109dc5b0b	generation of projector augmented-wave atomic data: a 71 element validated table in the xml format	abinit;paw atomic data;atompaw	In the Projector Augmented Wave (PAW) method developed by Blöchl (1994), a PAW data file is needed for each element, taking the role of the pseudopotential file used with the norm-conserving or ultrasoft formalisms. In this paper, we review methods for generating PAW data files and for evaluating their accuracy, transferability, and numerical efficiency in simulations of bulk solids.We have developed a new set of PAW atomic data files for most of the stable elements in the periodic table. These files are provided in a standard XML format for use in any PAW electronic structure code. The new dataset performs well as measured by the ‘‘∆’’ evaluation criterion introduced by Lejaeghere et al. (2014), and also performs well in a modified evaluation scheme proposed in the present paper. © 2014 Elsevier B.V. All rights reserved.	abinit;code;electronic structure;high-throughput computing;human-readable medium;numerical analysis;projector augmented wave method;pseudopotential;simulation;throughput;xml	François Jollet;Marc Torrent;N. A. W. Holzwarth	2014	Computer Physics Communications	10.1016/j.cpc.2013.12.023	abinit;computer hardware;computer science;theoretical computer science;database;physics	DB	-6.581143113307842	-58.78763494078697	177361
bc76bf143908d92ab7690b84e50c1b6ea6c2f16a	curtains up! lights, camera, action! documenting the creation of theater and opera productions with linked data and web technologies	opera;linked data fragments;hypervideo;theater;video analysis;rehearsal;web components;live production;audio analysis	For this paper, in the context of the French research project Spectacle en Ligne(s), we have recorded the entire set of rehearsals of one theater and one opera production using state-of-the-art video equipment. The resulting raw video and audio tracks as well as manually generated annotation data were then preprocessed in order to localize actors and detect their dialogues. Based on these preprocessing steps, we have built a Web-based hypervideo application that allows for navigation through performance time, performance space, and rehearsal time using modern HTML5 Web technologies like the emerging Web Components standard. We publish and consume the annotation data as so-called Linked Data Fragments, a novel way to make triple-based structured data available in a scalable way. As a direct outcome, researchers interested in the genetic analysis and the creation process of live performances can, thanks to this application, freely zoom in and out of scenes, rehearsal sessions, and stage locations in order to better understand the different steps on the way to a chef d’œuvre. A live demo of the application is publicly available at the URL http://spectacleenlignes.fr/hypervideo/.	animaniacs: lights, camera, action!;continuation;html;html5;hypervideo;interaction;linked data;machine code;multiplexing;open-source software;performance;point of interest;preprocessor;scalability;software documentation;synergy;timeline;uncompressed video;video clip;web components;web application;web developer;world wide web	Thomas Steiner;Rémi Ronfard;Pierre-Antoine Champin;Benoît Encelle;Yannick Prié	2015		10.1007/978-3-319-19890-3_34	opera;multimedia;world wide web;audio analyzer;computer graphics (images)	Web+IR	-15.726277633818214	-55.373612469596175	177795
888077a146c5c5f2202b703142383cee54c013a1	notes on a linguistic description as the basis for automatic image understanding	image processing;przetwarzanie obrazu;obraz cyfrowy;image understanding;semantics;computer vision;semantyka;automatic understanding;digital image;rozumienie automatyczne;widzenie komputerowe;digital images	The main paradigm of image understanding and a concept for its practical machine realisation are presented. The crucial elements of the presented approach are the formalisation of human knowledge about the class of images that are to be automatically interpreted, a linguistic description and the realization of cognitive resonance.	computer vision;programming paradigm;resonance	Ryszard Tadeusiewicz;Marek R. Ogiela;Piotr S. Szczepaniak	2009	Applied Mathematics and Computer Science	10.2478/v10006-009-0013-7	natural language processing;computer vision;image processing;computer science;theoretical computer science;semantics;automatic image annotation;digital image	AI	-14.239647630364447	-58.751696159300444	177967
0e4ccd00000bcf0a2d6350c255aad8e21185ffac	a framework for high level semantic annotation using trusted object annotated dataset	silicon;pattern clustering;semantic annotation;multimedia retrieval;information retrieval;digital library;digital libraries;video retrieval;high level semantic annotation;image annotation;labelme database;redundancy;trusted object annotated dataset;clustering;purification;semantic intensity high level semantics image annotation image similarity;automatic annotation;multimedia data;semantic description;multimedia databases;visual databases digital libraries information retrieval meta data multimedia databases pattern clustering semantic web;semantic web;meta data;multimedia resources;purification silicon redundancy;metadata tag;semantic intensity;labelme database high level semantic annotation trusted object annotated dataset multimedia data multimedia resources automatic annotation multimedia retrieval digital libraries semantic intensity image similarity metadata tag clustering;visual databases;high level semantics;image similarity	Dramatic expansion and eminence of the multimedia data from the last decades, culminates to a trouble in managing, accessing and annotating the data. The high level semantic annotation (HLS) of resources in general and multimedia resources in particular, is a resilient job. The Progression in automatic annotation mechanisms have not been able to comprehend with adequately accurate results. To outfit multimedia (e.g. image/video) retrieval capabilities, digital libraries have hung on manual annotation of images. Providing a track to enact high level semantic annotation automatically would be more worthwhile, efficient and scalable with magnifying image collections. This paper intent to equip the high level semantic annotation for images, and consequently, contributes to 1) calculating semantic intensity (SI) of each object in the image depicting the dominancy factor, (2) image similarity on the bases on metadata tag with the images, and (3) clustering approach based on the image similarity to tag set of images with a high level semantic description with their calculated similarity values. The experiment on a portion of randomly selected images from LabelMe database manifests stimulating outcomes.	cluster analysis;color gradient;digital library;experiment;high-level programming language;high-level synthesis;labelme;library (computing);randomness;scalability;tag (metadata)	Irfanullah;Nida Aslam;Jonathan Loo;Martin Loomes;Roohullah	2010	The 10th IEEE International Symposium on Signal Processing and Information Technology	10.1109/ISSPIT.2010.5711740	semantic similarity;digital library;image retrieval;computer science;semantic web;database;cluster analysis;redundancy;silicon;metadata;automatic image annotation;world wide web;information retrieval	Vision	-15.520095703215556	-59.29805636683142	178087
c84cf048e5b125ce10275bbbaa5599e0d68ec564	geo-based automatic image annotation	automatic image annotation;image annotation;statistical models;statistical model;geotagging;image retrieval	A huge number of user-tagged images are daily uploaded to the web. Recently, a growing number of those images are also geotagged. These provide new opportunities for solutions to automatically tag images so that efficient image management and retrieval can be achieved. In this paper an automatic image annotation approach is proposed. It is based on a statistical model that combines two different kinds of information: high level information represented by user tags of images captured in the same location as a new unlabeled image (input image); and low level information represented by the visual similarity between the input image and the collection of geographically similar images. To maximize the number of images that are visually similar to the input image, an iterative visual matching approach is proposed and evaluated. The results show that a significant recall improvement can be achieved with an increasing number of iterations. The quality of the recommended tags has also been evaluated and an overall good performance has been observed.	automatic image annotation;geotagging;high-level programming language;iteration;statistical model	Hatem Mousselly Sergieh;Gabriele Gianini;Mario Döller;Harald Kosch;Elöd Egyed-Zsigmond;Jean-Marie Pinon	2012		10.1145/2324796.2324850	image texture;statistical model;computer vision;feature detection;visual word;image analysis;image processing;image retrieval;computer science;digital image processing;pattern recognition;data mining;automatic image annotation;information retrieval	Vision	-16.778178636953406	-58.04246206469366	178291
8c37a2ac62254ad23295623ef8d4ec176944180b	dynamic hierarchical visualization of keyframes in endoscopic video		The after-inspection of endoscopic surgeries can be a tedious and time consuming task. Physicians have to search for important segments in the video recording of an intervention, which may have a duration of several hours. Automatically selected keyframes can support physicians in this task. The problem is that either too few keyframes are selected, missing some important information, or too many keyframes are selected, which overwhelms the user. Furthermore, keyframes of endoscopic videos typically show highly similar content. It is hence difficult to keep track of the temporal context of selected keyframes if they are presented in a grid view. To overcome these limitations, we present a dynamic hierarchical browsing technique for large sets of keyframes that preserves the temporal context in the visualization of the frames.	key frame;video	Jakub Lokoc;Klaus Schöffmann;Manfred del Fabro	2015		10.1007/978-3-319-14442-9_31	computer vision	Visualization	-14.386792904347667	-53.34172175908656	178804
26b54a36f248e8357891e8814dcf5b73d5eba766	fast extraction of semantic features from a latent semantic indexed text corpus	tratamiento automatico;proyeccion;representacion conocimientos;text;projection pursuit;procesamiento informacion;document analysis;high dimensionality;extraction forme;projection method;vector space;semantics;text analysis;texte;probabilistic approach;semantica;semantique;analyse documentaire;automatic processing;methode projection;extraccion forma;indexing;semantic feature extraction;feature extraction;projection;latent semantic indexing;indexation;metodo proyeccion;information processing;indizacion;pattern recognition;analisis documental;semantic space;reconnaissance forme;reconocimiento patron;knowledge representation;traitement automatique;traitement information;computational efficiency;texto;representation connaissances;pattern extraction;probabilistic latent semantic analysis	This paper proposes a projection-based symmetrical factorisation method for extracting semantic features from collections of text documents stored in a Latent Semantic space. Preliminary experimental results demonstrate this yields a comparable representation to that provided by a novel probabilistic approach which reconsiders the entire indexing problem of text documents and works directly in the original high dimensional vector-space representation of text. The employed projection index is derived here from the a priori constraints on the problem. The principal advantage of this approach is computational efficiency and is obtained by the exploitation of the Latent Semantic Indexing as a preprocessing stage. Simulation results on subsets of the 20-Newsgroups text corpus in various settings are provided.	3d projection;computation;fast fourier transform;indexed grammar;monoid factorisation;preprocessor;probabilistic latent semantic analysis;simulation;singular value decomposition;text corpus	Ata Kabán;Mark A. Girolami	2002	Neural Processing Letters	10.1023/A:1013801028884	natural language processing;projection pursuit;search engine indexing;semantic similarity;semantic computing;latent semantic indexing;explicit semantic analysis;latent semantic analysis;information processing;projection;vector space;feature extraction;computer science;machine learning;document-term matrix;pattern recognition;semantics;projection method;probabilistic latent semantic analysis;information retrieval	Web+IR	-12.048583756543824	-61.35281799637121	178975
c0ed318ac5afd2096411d531f1ad1dfcd86b3517	on fine-grained relevance scales		In Information Retrieval evaluation, the classical approach of adopting binary relevance judgments has been replaced by multi-level relevance judgments and by gain-based metrics leveraging such multi-level judgment scales. Recent work has also proposed and evaluated unbounded relevance scales by means of Magnitude Estimation (ME) and compared them with multi-level scales. While ME brings advantages like the ability for assessors to always judge the next document as having higher or lower relevance than any of the documents they have judged so far, it also comes with some drawbacks. For example, it is not a natural approach for human assessors to judge items as they are used to do on the Web (e.g., 5-star rating). In this work, we propose and experimentally evaluate a bounded and fine-grained relevance scale having many of the advantages and dealing with some of the issues of ME. We collect relevance judgments over a 100-level relevance scale (S100) by means of a large-scale crowdsourcing experiment and compare the results with other relevance scales (binary, 4-level, and ME) showing the benefit of fine-grained scales over both coarse-grained and unbounded scales as well as highlighting some new results on ME. Our results show that S100 maintains the flexibility of unbounded scales like ME in providing assessors with ample choice when judging document relevance (i.e., assessors can fit relevance judgments in between of previously given judgments). It also allows assessors to judge on a more familiar scale (e.g., on 10 levels) and to perform efficiently since the very first judging task.	bitwise operation;crowdsourcing;database normalization;document;estimation theory;experiment;information retrieval;relevance;world wide web	Kevin Roitero;Eddy Maddalena;Gianluca Demartini;Stefano Mizzaro	2018		10.1145/3209978.3210052	computer science;data mining;information retrieval;magnitude (mathematics);natural approach;bounded function;ir evaluation;crowdsourcing	Web+IR	-14.562256228784072	-64.68379288930109	179469
f469f0be7422548412f33b0a76383a29c3740c7a	automatic web-based efp studio system with xml documents	time triggered;audio streaming;xml cameras streaming media switches media servers internet;video streaming;real time;xml efp electronic field production;audio video;video quality;television broadcasting;real time broadcast;real time broadcast time triggered events streaming media xml efp electronic field production digital switcher;media;servers;internet;streaming media;video cameras;digital switcher;web sites;xml;xml document;personal network;video servers;electronic field production xml documents automatic web based efp studio system internet applications media technology time triggered event algorithm script object transformation real time editing video broadcasting audio broadcasting media server user access web multiple cameras av equipment web multipoint remote recording switch cameras digital switcher video quality web site personal network tv station distance video learning tv news real time broadcast;internet application;switches;cameras;text editing;xml audio streaming internet television broadcasting text editing video cameras video servers video streaming web sites;time triggered events	The rising wave of internet applications has led to the rapid development of streaming media technology. This paper proposes time-triggered events algorithm using a script object transformation to XML documents to create the automatic EFP studio system for real-time editing and broadcasting of audio/ video on media server. The system provides the user access to web multiple cameras and AV equipment through the internet to execute EFP tasks. The system can perform tasks such as to web multipoint remote recording, switch cameras, separate takes, change scenes, remove background, edit, integrate, add special effects on videos, the functionalities of a digital switcher, while getting superb video quality, and so on. At the same time, it can conjugate with web site to construct personal network TV station, distance video learning and TV news for real-time broadcast.	algorithm;apply;computer and network surveillance;deployment environment;event (computing);event-driven programming;internet television;media server;motion system;multipoint ground;personal network;real-time locating system;real-time transcription;rich internet application;server (computing);streaming media;swift (programming language);time series;video;xml	Wei Chen;Rong-Chi Chang	2012	2012 26th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2012.195	xml;computer science;operating system;database;multimedia;internet privacy;world wide web;computer network	Visualization	-15.51321496368656	-53.695170818109794	179542
fe1afb2134fa154d2d00d2842359b2d2c96f0559	trace transform based identifier for speech based image retrieval on mobile phones	speech processing;feature extraction;transforms;mobile handsets;retrieval time costs optimization trace transform based identifier speech based image retrieval mobile phones multimedia devices digital multimedia content image organization image storage retrieval algorithms user browsing user interaction speech spectrogram trace transformation image processing algorithms affine transforms feature extraction memory optimization;transforms feature extraction image retrieval mobile handsets speech processing;speech transforms spectrogram mobile handsets image retrieval multimedia communication robustness;image retrieval	Present day mobile phones have evolved as multimedia devices, where users can capture and store photos, videos on their mobile phones. As the amount of digital multimedia content expands, it becomes increasingly difficult to find specific images in the device, giving rise to problems of organization, storing and retrieval of images. To improve human access to a large unstructured data in their personal collections on mobile phones, there is a need for effective and precise retrieval algorithms for the user to search browse and interact with these collections in real time. Retrieval algorithms are highly complex and this characteristic becomes more intense on mobile platform due to restrictions in architecture and computing power. In this paper we propose a speech based image retrieval algorithm for personal collections optimized for porting on to a mobile phones. We have treated the speech spectrogram as an image and applied trace transformation to obtain an unique and robust identifier string that acts as a fingerprint for image retrieval systems. Trace transform is popular in image processing algorithms because it is robust to affine transforms for feature extraction. The proposed algorithm exhibits optimization in memory and retrieval time costs.	algorithm;browsing;feature extraction;fingerprint;identifier;image processing;image retrieval;information retrieval;mathematical optimization;mobile operating system;mobile phone;spectrogram	S. M. Meena;Sachin S. Shetty	2013	2013 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2013.6637307	computer vision;mobile search;visual word;speech recognition;feature extraction;image retrieval;computer science;speech processing;multimedia;automatic image annotation	Web+IR	-16.619889763654985	-54.72710119024667	179559
cec92e384cfb41df99626cab374b26578c62ef7d	foundations of intelligent systems		An increasing number of services are appearing both within agent communities and as Web Services on the World Wide Web. As these services proliferate, humans and agents need to be able to find, select, understand and invoke these services. Today, services (e.g. travel services, book selling services, stock reporting services etc) are discovered and invoked manually by human users. In the near future, such service discovery and use will be mediated by agents acting on behalf of their human users. Such use of agent technology will be the next Web revolution. Instead of populated with humanreadable documents, the Web will be populated with Agent-Mediated Services. For this to be accomplished, the Web must become agent-understandable, i.e. allow for semantic annotation of content. Up to now, this vision has been conceived and pursued mainly in academia and research labs. However, recent industrial interest in such services, and the availability of tools to enable service automation (e.g. UDDI, WSDL, X-lang, WSFL, e-speak, .NET etc) holds the promise of fast progress in the automation in the Web Services area. Agent Mediated discovery, selection, execution and monitoring of Web Services will be a crucial test of Agent Technology. Agent Mediated Web Services is a confluence of Agent Technology and the Semantic Web. In order to enable stable and scalable Agent Mediated Services, a widely used, widely accessible and extensible Multiagent (MAS) infrastructure is crucial. Part of this infrastructure should be languages for semantic annotation of content as well as for describing services, so that they can be discovered, invoked and composed. DAML-S is such a language for semantic descriptions of services. Another part of the MAS infrastructure should define communication and interoperability of agents. Various standards bodies (e.g. FIPA) are attempting to define standards for various aspects of MAS infrastructure, such as Agent Communications Languages.. However, there is no coherent account of what constitutes a MAS infrastructure, what functionality it supports, what characteristics it should have in order to enable various value-added abilities, such as Agent Based Mediation of Services, and what its possible relation with and requirements it may impose on the design and structure of single agents. In this talk, we will present a model of MAS infrastructure, and our implemented RETSINA system that is an example of the general infrastructure model. In addition, we will show how RETSINA implements Agent Mediated Web Services through a variety of tools and mechanisms. Moreover, we will present DAML-S and illustrate its utility in the area of Agent Mediated Services. Improving Classification by Removing or Relabeling Mislabeled Instances Stéphane Lallich, Fabrice Muhlenbach, and Djamel A. Zighed ERIC Laboratory – University of Lyon 2 5, av. Pierre Mendès-France F-69676 BRON Cedex – FRANCE {lallich, fabrice.muhlenbach, zighed}@univ-lyon2.fr Abstract. It is common that a database contains noisy data. An important source of noise consists in mislabeled training instances. We present a new approach that deals with improving classification accuracies in such a case by using a preliminary filtering procedure. An example is suspect when in its neighborhood defined by a geometrical graph the proportion of examples of the same class is not significantly greater than in the whole database. Such suspect examples in the training data can be removed or relabeled. The filtered training set is then provided as input to learning algorithm. Our experiments on ten benchmarks of UCI Machine Learning Repository using 1-NN as the final algorithm show that removing give better results than relabeling. Removing allows maintaining the generalization error rate when we introduce from 0 to 20% of noise on the class, especially when classes are well separable. It is common that a database contains noisy data. An important source of noise consists in mislabeled training instances. We present a new approach that deals with improving classification accuracies in such a case by using a preliminary filtering procedure. An example is suspect when in its neighborhood defined by a geometrical graph the proportion of examples of the same class is not significantly greater than in the whole database. Such suspect examples in the training data can be removed or relabeled. The filtered training set is then provided as input to learning algorithm. Our experiments on ten benchmarks of UCI Machine Learning Repository using 1-NN as the final algorithm show that removing give better results than relabeling. Removing allows maintaining the generalization error rate when we introduce from 0 to 20% of noise on the class, especially when classes are well separable.	agent-based model;bron–kerbosch algorithm;coherence (physics);confluence;daml-s;e-speak;experiment;generalization error;hybrid intelligent system;interoperability;machine learning;population;requirement;scalability;semantic web;service discovery;signal-to-noise ratio;test set;web services description language;web services discovery;web services flow language;web service;world wide web;eric	Jan van Leeuwen;Mohand-Saïd Hacid;Zbigniew W. Ras;Djamel A. Zighed;Yves Kodratoff	2002		10.1007/3-540-48050-1		ML	-18.567336924966988	-56.72403976685958	179662
a152e331a0025a3f813476839fa16322de275475	learning semantic multimedia representations from a small set of examples	explosion blast off;belief networks;explosion blast off semantic multimedia retrieval supervised learning lexicon interesting semantic concepts semantic queries discriminant learning techniques kernel based methods retrieval performance loosely coupled multimodal events auditory concepts visual concepts learning from examples semantic multimedia representations bayesian inference network rocket launch event;bayesian network;kernel;bayesian inference network;multimedia retrieval;supervised learning;query processing;search engines;information retrieval;lexicon;rockets;discriminant learning techniques;retrieval performance;inference mechanisms multimedia databases information retrieval learning by example query processing belief networks;bayesian methods;inference mechanisms;event detection;layout;visual concepts;loosely coupled multimodal events;interesting semantic concepts;auditory concepts;learning by example;semantic queries;discrimination learning;semantic multimedia retrieval;learning from examples;spatial databases;event detection rockets object detection search engines spatial databases layout supervised learning kernel face detection bayesian methods;multimedia databases;face detection;rocket launch event;kernel based methods;semantic multimedia representations;object detection	We approach the problem of semantic multimedia retrieval as a supervised learning problem. Defining a lexicon of a small number of interesting semantic concepts we can handle a number of semantic queries. Since the number of interesting concepts available for training is usually small we explore discriminant learning techniques. In particular, we examine the use of kernel based methods and demonstrate impressive retrieval performance using semantic concepts like rocket, outdoor, greenery, sky and face. We also show that loosely coupled multimodal events can be detected based on the late fusion of detection of related auditory and visual concepts. Using a Bayesian network for inference we show how a rocket-launch event can be detected based on the detection of a related visual concept (rocket object) and a related auditory concept (explosion/blast-off).		Milind R. Naphade;Ching-Yung Lin;John R. Smith	2002		10.1109/ICME.2002.1035661	natural language processing;layout;computer vision;face detection;semantic computing;kernel;bayesian probability;computer science;machine learning;pattern recognition;bayesian network;supervised learning;discrimination learning	ML	-15.576130080211248	-61.757066774926244	179811
1d64f1096f192cd19243039a8b09be1de8cd84ad	visexpress: visual exploration of differential gene expression data	interactive visual exploration;journal_article;expression data;differential gene expression;information visualization;design study;biological data;bioinformatics visualization;information visualization design study bioinformatics visualization interactive visual exploration biological data expression data gene expression profiling differential gene expression;gene expression profiling	Biologists are keen to understand how processes in cells react to environmental changes. Differential gene expression analysis allows biologists to explore functions of genes with data generated from different environments. However, this data and analysis leads to unique challenges since tasks are ill-defined, require implicit domain knowledge, comprise large volumes of data, and are, therefore, of explanatory nature. To investigate a scalable visualization-based solution, we conducted a design study with three biologists specialized in differential gene expression analysis. We stress our contributions in three aspects: First, we characterize the problem domain for exploring differential gene expression data and derive task abstractions and design requirements. Second, we investigate the design space and present an interactive visualization system, called VisExpress. Third, we evaluate the usefulness of VisExpress via a Pair Analytics study with real users and real data, and report on insights that were gained by our experts with VisExpress.	gene expression programming;interactive visualization;problem domain;requirement;scalability	Svenja Simon;Sebastian Mittelstädt;Bum Chul Kwon;Andreas Stoffel;Richard Landstorfer;Klaus Neuhaus;Anna Mühlig;Siegfried Scherer;Daniel A. Keim	2017	Information Visualization	10.1177/1473871615612883	information visualization;biological data;computer science;bioinformatics;data science;data mining;gene expression profiling	Visualization	-6.54988806401632	-61.55869674043141	180200
8afad7e5e00e039c217812c39f6cfcedd0666101	isolation and mapping of a polymorphic dna sequence pthh54 on chromosome 10 [d10s13]	deoxyribonuclease hpaii;genes dominant;isolation;hombre;secuencia nucleotido;nucleotide sequence;polymorphism genetic;sequence nucleotide;c10 chromosome;chromosomes human pair 10;fragmento restriccion;fragment restriction;isolement;dna restriction enzymes;polymorphism;human;cromosoma c10;chromosome c10;polymorphisme;humans;polimorfismo;dna sequence;polymorphism restriction fragment length;aislamiento;restriction fragment;homme	Full textFull text is available as a scanned copy of the original print version. Get a printable copy (PDF file) of the complete article (55K), or click on a page image below to browse page by page. Links to PubMed are also available for Selected References.#R##N##R##N##R##N##R##N##R##N#372#R##N##R##N##R##N##R##N##R##N##R##N#Selected References#R##N#These references are in PubMed. This may not be the complete list of references from this article. #R##N##R##N#Lathrop GM, Lalouel JM, Julier C, Ott J. Multilocus linkage analysis in humans: detection of linkage and estimation of recombination. Am J Hum Genet. 1985 May;37(3):482–498. [PMC free article] [PubMed]#R##N#Grzeschik KH, Kazazian HH. Report of the Committee on the Genetic Constitution of Chromosomes 10, 11, and 12. Cytogenet Cell Genet. 1985;40(1-4):179–205. [PubMed]#R##N#Litt M, Mueller OT, Shows TB, Litt R. A single copy subclone, p1-101, from cosmid 3-3B, defines three RFLPs on 10pter-q23 [HGM9 no. D10S4]. Nucleic Acids Res. 1987 Mar 25;15(6):2783–2783. [PMC free article] [PubMed]#R##N#Liou GI, Li Y, Wang C, Fong SL, Bhattacharya S, Bridges CD. Bgl II RFLP recognized by a human IRBP cDNA localized to chromosome 10. Nucleic Acids Res. 1987 Apr 10;15(7):3196–3196. [PMC free article] [PubMed]	chromosomes, human, pair 10	T. Holm;Y. Nakamura;L. Ballard;P. O'Connell;M. Leppert;G. M. Lathrop;J. M. Lalouel;R. White	1988	Nucleic acids research	10.1093/nar/16.1.372	biology;polymorphism;dna sequencing;isolation;nucleic acid sequence;bioinformatics;restriction fragment;genetics	Logic	-5.143013847758244	-56.99624169768329	180205
b8627a86038d492c25a9dce641606bf09ae520a4	representations of metabolic knowledge: pathways	automatic generation;molecular biology;algorithms;constraint satisfaction problem;metabolic pathway;biology and medicine basic studies;glycolysis;programming;biochemistry;metabolism;production rule;knowledge base;mathematics computers information science management law miscellaneous	The automatic generation of drawings of metabolic pathways is a challenging problem that depends intimately on exactly what information has been recorded for each pathway, and on how that information is encoded. The chief contributions of the paper are a minimized representation for biochemical pathways called the predecessor list, and inference procedures for converting the predecessor list into a pathway-graph representation that can serve as input to a pathway-drawing algorithm. The predecessor list has several advantages over the pathway graph, including its compactness and its lack of redundancy. The conversion between the two representations can be formulated as both a constraint-satisfaction problem and a logical inference problem, whose goal is to assign directions to reactions, and to determine which are the main chemical compounds in the reaction. We describe a set of production rules that solves this inference problem. We also present heuristics for inferring whether the exterior compounds that are substrates of reactions at the periphery of a pathway are side or main compounds. These techniques were evaluated on 18 metabolic pathways from the EcoCyc knowledge base.	algorithm;chemicals;constraint satisfaction problem;drawings (art);dysplastic nevus;ecocyc;gene regulatory network;graph (abstract data type);graph - visual representation;heuristics;inference;information systems;information system;kinetic data structure;knowledge acquisition;knowledge base;nadh;nf-kappa b;network access device;production (computer science);redundancy (engineering);rule (guideline);semantic reasoner	Peter D. Karp;Suzanne M. Paley	1994	Proceedings. International Conference on Intelligent Systems for Molecular Biology		biology;biochemistry;programming;metabolic pathway;glycolysis;knowledge base;computer science;bioinformatics;artificial intelligence;machine learning;mathematics;constraint satisfaction problem;metabolism;algorithm;statistics	Comp.	-6.051600220884245	-63.411796482887894	180284
38fa3a9eb2875b85d52f21de9844a2aa45b4c3ff	content-based video retrieval by integrating spatio-temporal and stochastic recognition of events	video databases;video signal processing;rule based;content based retrieval stochastic processes feature extraction data mining hidden markov models data models content management computer science libraries database systems;data model;stochastic processes;stochastic processes content based retrieval video databases video signal processing knowledge based systems feature extraction;feature extraction content based video retrieval spatio temporal event recognition stochastic event recognition video data data querying video data model low level features mapping rule based approach spatio temporal formalization hmm;feature extraction;content based video retrieval;content based retrieval;knowledge based systems	As amounts of publicly uvuiluble video dutu grow, the need to query this dutu efficiently becomes signijcunt. Consequently, content-bused retrievul of video datu turns out to be U chullenging and important problem. In this puper, we uddress the speclfic uspect of inferring semuntics automatically f iom ruw video dutu. In purticulur, we introduce U new video dutu model thut supports the integruted use of two different upprouches for mupping low-level feutures to high-level concepts. Firstly, the model is extended with U rule-bused upproach that supports sputio-temporal formulizution of high-level concepts, and then with a stochustic upprouch. Furthermore, results on reul tennis video dutu are presented demonsrrating the vulidity of both approaches, as well us udvuntuges of their integruted use.	high- and low-level	Milan Petkovic;Willem Jonker	2001		10.1109/EVENT.2001.938869	computer science;video tracking;pattern recognition;data mining;information retrieval	Vision	-13.328633520270381	-55.51648676327126	180473
47599e387393b8f5cec5d97067f506b410a30613	bilkent university multimedia database group at trecvid 2008	multimedia database	Bilkent University Multimedia Database Group (BILMDG) participated in two tasks at TRECVID 2008: content-based copy detection (CBCD) and high-level feature extraction (FE). Mostly MPEG-7 [1] visual features, which are also used as low-level features in our MPEG-7 compliant video database management system, are extracted for these tasks. This paper discusses our approaches in each task.	database;feature extraction;high- and low-level;mpeg-7	Onur Küçüktunç;Muhammet Bastan;Ugur Güdükbay;Özgür Ulusoy	2008			computer science;database;multimedia;world wide web	DB	-15.489888449242063	-56.2184689721194	181223
e18280c3cb9aad0edab37db6116006b5c3031ca0	automatic image representation and clustering on mobile devices	mobile device;automatic image annotation;cbir content based image retrieval;image representation;mobile devices	In this paper a novel approach for the automatic representation of pictures on mobile devices is proposed. With the wide diffusion of mobile digital image acquisition devices, the need for managing a large number of digital images is quickly increasing. In fact, the storage capacity of such devices allow users to store hundreds or even thousands, of pictures that, without a proper organization, become useless. Users may be interested in using (i.e., browsing, saving, printing and so on) a subset of stored data according to some particular picture properties. A content-based description of each picture is needed to perform on-board image indexing. In our work, the images are analyzed and described in three representation spaces, namely, faces, background and time of capture. Faces are automatically detected, and a face representation is produced by projecting the face itself in a common low dimensional eigenspace. Backgrounds are represented with low-level visual features based on RGB histogram and Gabor filter bank. Temporal data is obtained through the extraction of EXIF (Exchangeable Image File Format) data. Faces, background and time information of each image in the collection is automatically organized using a mean-shift clustering technique. Significance of clustering has been evaluated on a realistic set of about 1000 images and results are promising.		Marco La Cascia;Marco Morana;Filippo Vella	2010	J. Mobile Multimedia		computer vision;image retrieval;computer science;operating system;mobile device;multimedia;automatic image annotation;information retrieval;digital image	Web+IR	-16.637504229371828	-57.665971028485366	181265
f03d4f98dfa81b102b55135d78257c38e63b7b5c	music document layout analysis through machine learning and human feedback		Music documents often include musical symbols as well as other relevant elements such as staff lines, text, and decorations. To detect and separate these constituent elements, we propose a layout analysis framework based on machine learning that focuses on pixel-level classification of the image. For that, we make use of supervised learning classifiers trained to infer the category of each pixel. In addition, our scenario considers a human-aided computing approach in which the user is part of the recognition loop, providing feedback where relevant errors are made.	document layout analysis;feedback;machine learning;pixel;supervised learning	Jorge Calvo-Zaragoza;Ke Zhang;Zeyad Saleh;Gabriel Vigliensoni;Ichiro Fujinaga	2017	2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2017.259	computer science;task analysis;supervised learning;pixel;pattern recognition;multiple signal classification;machine learning;algorithm design;artificial intelligence;document layout analysis;text mining	Vision	-13.740337699383288	-64.31511597495343	181291
946b7a9bcf7b8630c4d3912528c1b4ed0d8bc62f	a semantic approach to film content analysis and retrieval	semantic representation;film representation;content enrichment;query answering;knowledge based systems	In this paper we present a system for the semantic representation, enrichment and querying of film content. The system combines state-of-the-art knowledge representation and reasoning techniques, adapted to film content, with visual analysis techniques for point of interest detection. The resulting system provides search services for specific objects and entities in film scenes and shots. The experimental results that we present illustrate the good performance of the proposed approach.	entity;gene ontology term enrichment;knowledge representation and reasoning;point of interest	Alexandros Chortaras;Stefanos D. Kollias;Konstantinos Rapantzikos;Giorgos B. Stamou	2016		10.1145/2903220.2903250	computer science;artificial intelligence;knowledge-based systems;data mining;multimedia;information retrieval	AI	-14.797072594826327	-59.12886435839258	181570
113d57a7375566ee3af0a216b61ad1fb4405823d	grounding spatial prepositions for video search	language use;video retrieval;test bed;natural language;spatial language;video search	"""Spatial language video retrieval is an important real-world problem that forms a test bed for evaluating semantic structures for natural language descriptions of motion on naturalistic data. Video search by natural language query requires that linguistic input be converted into structures that operate on video in order to find clips that match a query. This paper describes a framework for grounding the meaning of spatial prepositions in video. We present a library of features that can be used to automatically classify a video clip based on whether it matches a natural language query. To evaluate these features, we collected a corpus of natural language descriptions about the motion of people in video clips. We characterize the language used in the corpus, and use it to train and test models for the meanings of the spatial prepositions """"to,"""" """"across,"""" """"through,"""" """"out,"""" """"along,"""" """"towards,"""" and """"around."""" The classifiers can be used to build a spatial language video retrieval system that finds clips matching queries such as """"across the kitchen."""""""	computer;graphical user interface;minimum bounding box;modal logic;multimodal interaction;natural language understanding;natural language user interface;region of interest;robot;snapshot (computer storage);surround sound;testbed;text corpus;video clip	Stefanie Tellex;Deb Roy	2009		10.1145/1647314.1647369	natural language processing;language identification;semantic role labeling;computer vision;computer science;linguistics;multimedia;speech segmentation;natural language;testbed	NLP	-16.047034734357048	-59.37624792794264	181809
9e793bf551f668647d7c3d17760a8be9e849a9db	a tool for the interactive 3d visualization of electronic structure in molecules and solids	density functional calculation;direct manipulation user interface;electronic structure calculation;3d visualization;user interface;direct manipulation;electron localization function;first principle;charge density;quantum mechanics;design and implementation;numerical control;electronic structure;vasp	This paper presents the Vienna ab initio simulation package (VASP) data viewer, a desktop 3D visualization application for the analysis of valence electronic structure information derived from first-principles quantum-mechanical density functional calculations. This tool allows a scientist to directly view and manipulate the calculated charge density or electron localization function (ELF) from an electronic structure calculation, providing insight into the nature of chemical bonding. Particular attention was given to the design and implementation of the user interface (UI) for the data viewer. It provides for expert and novice usage, and both natural direct manipulation and precise numerical control. The data viewer has proven useful to chemical scientists for understanding the results of electronic structure calculations.	density functional theory;desktop computer;direct manipulation interface;electronic structure;imagery;numerical analysis;pyschological bonding;quantum mechanics;scanning electron microscopy;user interface device component;vienna ab initio simulation package;solid substance	Timothy B. Terriberry;David F. Cox;Doug A. Bowman	2002	Computers & chemistry	10.1016/S0097-8485(01)00120-6	visualization;human–computer interaction;first principle;charge density;computer science;electron localization function;theoretical computer science;computational chemistry;numerical control;user interface;physics;electronic structure;quantum mechanics	Visualization	-7.294755339206099	-57.61014935892916	182104
9fb9f85ae5a7d1d8576741e8690a950e5c9a6d0a	video annotation based on kernel linear neighborhood propagation	unlabeled data;anotacion;graph theory;graph based semisupervised learning algorithm;video databases;label propagation;semantic annotation;distribution donnee;learning algorithm;kernel semisupervised learning training data large scale systems databases humans information science asia automation machine learning;multimedia;nonlinear kernel mapped space;supervised learning;methode noyau;base donnee tres grande;automatic semantic video annotation;local linear embedding method;semantics;video retrieval;annotation;base donnee video;intelligence artificielle;algorithme apprentissage;semantica;semantique;semi supervised learning;data distribution;large scale;senal video;signal video;feature extraction;metodo nucleo;large scale video database annotation;video annotation;video signal;artificial intelligence;kernel method;kernel linear neighborhood propagation;inteligencia artificial;apprentissage supervise;video search automatic semantic video annotation large scale video database annotation kernel linear neighborhood propagation graph based semisupervised learning algorithm local linear embedding method nonlinear kernel mapped space feature extraction;very large databases;learning artificial intelligence;video annotation kernel method label propagation semi supervised learning;video database;aprendizaje supervisado;algoritmo aprendizaje;distribucion dato;video retrieval feature extraction graph theory learning artificial intelligence very large databases video databases;video search;local linear embedding	The insufficiency of labeled training data for representing the distribution of the entire dataset is a major obstacle in automatic semantic annotation of large-scale video database. Semi-supervised learning algorithms, which attempt to learn from both labeled and unlabeled data, are promising to solve this problem. In this paper, a novel graph-based semi-supervised learning method named kernel linear neighborhood propagation (KLNP) is proposed and applied to video annotation. This approach combines the consistency assumption, which is the basic assumption in semi-supervised learning, and the local linear embedding (LLE) method in a nonlinear kernel-mapped space. KLNP improves a recently proposed method linear neighborhood propagation (LNP) by tackling the limitation of its local linear assumption on the distribution of semantics. Experiments conducted on the TRECVID data set demonstrate that this approach outperforms other popular graph-based semi-supervised learning methods for video semantic annotation.	algorithm;arc diagram;coefficient;convergence insufficiency;experiment;java annotation;kernel (operating system);linear-nonlinear-poisson cascade model;machine learning;nonlinear dimensionality reduction;nonlinear system;semi-supervised learning;semiconductor industry;software propagation;supervised learning	Jinhui Tang;Xian-Sheng Hua;Guo-Jun Qi;Yan Song;Xiuqing Wu	2008	IEEE Transactions on Multimedia	10.1109/TMM.2008.921853	computer vision;kernel method;feature extraction;computer science;graph theory;machine learning;pattern recognition;semantics;supervised learning;world wide web	Vision	-13.420041535289297	-61.55891611179086	182118
c6010ca381de52efa06685f1fc8ebd1837faa0ce	exploring digital libraries with document image retrieval	image features;document image analysis;digital library;system integration;indexation;image retrieval	In this paper, we describe a system to perform Document Image Retrieval in Digital Libraries. The system allows users to retrieve digitized pages on the basis of layout similarities and to make textual searches on the documents without relying on OCR. The system is discussed in the context of recent applications of document image retrieval in the field of Digital Libraries. We present the different techniques in a single framework in which the emphasis is put on the representation level at which the similarity between the query and the indexed documents is computed. We also report the results of some recent experiments on the use of layout-based document image retrieval.	digital library;document retrieval;experiment;image retrieval;mental representation;optical character recognition	Simone Marinai;Emanuele Marino;Giovanni Soda	2007		10.1007/978-3-540-74851-9_31	visual word;digital library;document clustering;image retrieval;computer science;document layout analysis;digital image processing;multimedia;automatic image annotation;world wide web;feature;information retrieval;digital image;system integration	Web+IR	-13.677640810439094	-58.27942928055179	182171
29953da60f470fc21dc484863e601bd5b4c6cb15	robust frame and text extraction from comic books	connected component labeling;k means;comic books;segmentation;comics text extraction;comics frame extraction	Comic books constitute an important heritage in many countries. Nowadays, digitization allows to search directly from content instead of metadata only (e.g. album title or author name). Few studies have been done in this direction. Only frame and speech balloon extraction have been experimented in the case of simple page structure. In fact, the page structure depends on the author which is why many different structures and drawings exist. Despite the differences, drawings have a common characteristic because of design process: they are all surrounded by a black line. In this paper, we propose to rely on this particularity of comic books to automatically extract frame and text using a connectedcomponent labeling analysis. The approach is compared with some existing methods found in the literature and results are presented.	book;connected component (graph theory);connected-component labeling;linear algebra;semantic role labeling	Christophe Rigaud;Norbert Tsopzé;Jean-Christophe Burie;Jean-Marc Ogier	2011		10.1007/978-3-642-36824-0_13	computer vision;computer science;multimedia;segmentation;world wide web;connected-component labeling;k-means clustering	AI	-11.126484346295143	-63.6742920203944	182591
82e78f337a57c5e679fd1edca585ce7585be2e12	a knowledge representation meta-model for rule-based modelling of signalling networks		The study of cellular signalling pathways and their deregulation in disease states, such as cancer, is a large and extremely complex task. Indeed, these systems involve many parts and processes but are studied piecewise and their literatures and data are consequently fragmented, distributed and sometimes—at least apparently—inconsistent. This makes it extremely difficult to build significant explanatory models with the result that effects in these systems that are brought about by many interacting factors are poorly understood. The rule-based approach to modelling has shown some promise for the representation of the highly combinatorial systems typically found in signalling where many of the proteins are composed of multiple binding domains, capable of simultaneous interactions, and/or peptide motifs controlled by post-translational modifications. However, the rule-based approach requires highly detailed information about the precise conditions for each and every interaction which is rarely available from any one single source. Rather, these conditions must be painstakingly inferred and curated, by hand, from information contained in many papers—each of which contains only part of the story. In this paper, we introduce a graph-based meta-model, attuned to the representation of cellular signalling networks, which aims to ease this massive cognitive burden on the rule-based curation process. This meta-model is a generalization of that used by Kappa and BNGL which allows for the flexible representation of knowledge at various levels of granularity. In particular, it allows us to deal with information which has either too little, or too much, detail with respect to the strict rule-based meta-model. Our approach provides a basis for the gradual aggregation of fragmented biological knowledge extracted from the literature into an instance of the meta-model from which we can define an automated translation into executable Kappa programs.	cell signaling;data aggregation;digital curation;executable;interaction;knowledge representation and reasoning;logic programming;machine translation;metamodeling	Adrien Basso-Blandin;Walter Fontana;Russell Harmer	2015		10.4204/EPTCS.204.5	computer science;artificial intelligence;data mining;mathematics;algorithm	AI	-6.612573477356931	-52.19210384827942	182675
d9a98b4a9fcb4769de5bad5c0f5cea195efb7491	a multimedia database management system for medical data	management system	The paper presents a relational multimedia database management system for managing visual and alphanumerical information from the medical domain. The MMDBMS offers numerical and char data types for alphanumerical information, and Image data type used for storing in an original manner the visual information. An Image data type stores the image in a binary manner, its type, its dimensions and information about color and texture that are automatically extracted. This information will be used for content-based visual query process. The color information is represented by the color histogram quantified to 166 colors in the HSV color space. The texture information is represented by a vector with 12 values resulted from the method that uses Gabor filters for texture detection. This DBMS brings up as an element of originality the visual interface for building content-based image query using color and texture characteristics and a modified Select command. This MMDBMS, implemented using Java technologies is platform independent and can be easily used by the medical personnel.	color histogram;color space;database;gabor filter;java;management system;numerical analysis;referential integrity;sensor;text-based (computing);unique key	Liana Stanescu;Dumitru Dan Burdescu;Marius Brezovan;Cosmin Stoica Spahiu	2007			data management;data administration;database	Visualization	-10.657289123557222	-57.29425037904871	182697
3cd585cc9a93aaf151ce2d2d6af6981747bb8bda	an interactive tool for the management and visualization of mass-spectrometry proteomics data	software platform;mass spectrometry;spectra visualization;mzdata;proteomics	The paper presents a software platform for the management and visualization of mass spectrometry proteomics data. MALDI-TOF and LC-MS spectra can be visualized by considering different parameters or by focusing on portions of spectra. Spectra can also be converted using the XML-based mzData standard for storing or for transmission over the network.	proteomics	Mario Cannataro;Giovanni Cuda;Marco Gaspari;Pierangelo Veltri	2007		10.1007/978-3-540-73400-0_81	mass spectrometry;bioinformatics;mass spectrometry data format;proteomics;world wide web	Visualization	-4.974869910746141	-59.02756267474903	182808
22ca0e6593e3a5ca8aefa5d3b4aa9e75000e163b	an interactive video delivery and caching system using video summarization	content distribution network;video summarization;cooperative caching;streaming media delivery;high speed networks;interactive video;content analysis;streaming media;content distribution networks;video content analysis;face detection;web caching;shot boundary detection	With the advance of high-speed network technologies, the availability and popularity of streaming media content over the Internet has grown rapidly in recent years. The delivery and caching of streaming media must be handled in a different fashion than that of traditional non-streaming objects such as HTML or image files, because of its distinct characteristics and user viewing patterns. We propose a novel scheme that provides users with the video summary (a number of key-frame images) before they download the file, and options for them to select the starting playback position. We introduce the content analysis service to achieve these functionalities. The video content analysis performs shot boundary detection, key-frame selection, and face detection and tracking. The results of the processing are a segmented video sequence and an XML-based meta-data describing the video content. We also design a caching system that utilizes our video abstraction and summarization technique. Our integrated video delivery and caching system combines content-aware segmentation, prefix caching, prefetching, and cooperative caching. We describe how our scheme can be applied in three proposed caching architectures.	cpu cache;cache (computing);centralized computing;desktop computer;digital video;download;face detection;html;internet;key frame;locality of reference;mpeg-1;mpeg-2;microsoft foundation class library;microsoft windows;mobile device;page replacement algorithm;personal computer;prototype;shot transition detection;simulation;software development kit;streaming media;testbed;user interface;video content analysis;video file format;xml	Sung-Ju Lee;Wei-Ying Ma;Bo Shen	2002	Computer Communications	10.1016/S0140-3664(01)00414-5	face detection;content analysis;computer science;video tracking;multimedia;internet privacy;world wide web	Web+IR	-15.454233267436589	-54.972939737996946	184250
456b0dd51484f098a4d2f5e1b6272c9d3016e7e6	a vocabulary approach to partial streamline matching and exploratory flow visualization	user interfaces data analysis data visualisation feature extraction flow visualisation image classification image retrieval mechanical engineering computing pattern matching;windings;user interface;exploratory flow visualization;shape feature extraction vocabulary spirals data visualization windings diffusion tensor imaging;vocabulary;streamline similarity;user interface streamline similarity shape invariant features partial matching exploratory flow visualization;empirical expert evaluation customized search approximate search exact search flexible querying user interaction intuitive interface intrinsic streamline similarity retrieval querying shape characters local neighborhoods shape similarity resampled point classification local feature scales exploratory streamline analysis string based method shape invariant feature extraction flowstring visualization task flow data analysis integral curve similarity measurement exploratory flow visualization partial streamline matching vocabulary approach;shape;feature extraction;spirals;data visualization;partial matching;diffusion tensor imaging;data analysis data visualisation feature extraction flow visualisation image classification image retrieval mechanical engineering computing pattern matching user interfaces;streamline similarity shape invariant features partial matching exploratory flow visualization user interface;vocabulary approach empirical expert evaluation customized search approximate search exact search flexible querying user interaction intuitive interface intrinsic streamline similarity retrieval querying shape characters local neighborhoods shape similarity resampled point classification local feature scales exploratory streamline analysis string based method shape invariant feature extraction flowstring visualization task flow data analysis integral curve similarity measurement exploratory flow visualization partial streamline matching;shape invariant features	Measuring the similarity of integral curves is fundamental to many important flow data analysis and visualization tasks such as feature detection, pattern querying, streamline clustering, and hierarchical exploration. In this paper, we introduce FlowString, a novel vocabulary approach that extracts shape invariant features from streamlines and utilizes a string-based method for exploratory streamline analysis and visualization. Our solution first resamples streamlines by considering their local feature scales. We then classify resampled points along streamlines based on the shape similarity around their local neighborhoods. We encode each streamline into a string of well-selected shape characters, from which we construct meaningful words for querying and retrieval. A unique feature of our approach is that it captures intrinsic streamline similarity that is invariant under translation, rotation and scaling. We design an intuitive interface and user interactions to support flexible querying, allowing exact and approximate searches for partial streamline matching. Users can perform queries at either the character level or the word level, and define their own characters or words conveniently for customized search. We demonstrate the effectiveness of FlowString with several flow field data sets of different sizes and characteristics. We also extend FlowString to handle multiple data sets and perform an empirical expert evaluation to confirm the usefulness of this approach.	adobe streamline;approximation algorithm;cluster analysis;customize;encode;exploratory testing;feature detection (computer vision);feature detection (web development);image scaling;imagery;interaction;interface device component;matching;personality character;test scaling;vocabulary;statistical cluster	Jun Tao;Chaoli Wang;Ching-Kuang Shene;Raymond A. Shaw	2016	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2015.2440252	diffusion mri;computer vision;feature extraction;shape;computer science;machine learning;pattern recognition;data mining;mathematics;geometry;electromagnetic coil;user interface;data visualization;spiral	Visualization	-11.29786964641844	-56.52301396058412	184412
d5428650265fafcab3e55ebaddd00acd60e9c049	syntactic models to represent perceptually regular repetitive patterns in graphic documents	document structure;modelizacion;model based reasoning;texture;raisonnement base sur modele;gramatica grafo;image processing;estructura documental;structure document;periodic structure;procesamiento imagen;grammaire lineaire;estructura periodica;document graphique;linear grammar;grafismo;graphisme;traitement image;modelisation;gramatica lineal;documento grafico;grammaire graphe;indexing;graph grammar;reconocimiento grafico;indexation;textura;indizacion;pattern recognition;structure periodique;graphism;reconnaissance graphique;reconnaissance forme;reconocimiento patron;modeling;graphic document;graphical recognition	In this paper we propose syntactical models to represent repetitive regular structures in graphical documents. We refer to these structures as texture symbols and they usually contain hatched or tiled patterns. Our grammar-based models can be automatically inferred from the document and used as signatures to describe salient features con- sisting of regular repetitions of primitives. These signatures compactly describe texture symbols and its primitives can be used for indexing pur- poses. We describe different models suitable for a number of patterns. Particularly, a linear grammar to describe hatched patterns and a plex grammar and a graph grammar for different types of tiled patterns.		Gemma Sánchez;Josep Lladós	2003		10.1007/978-3-540-25977-0_15	natural language processing;computer vision;search engine indexing;speech recognition;systems modeling;image processing;computer science;document structure description;model-based reasoning;pattern recognition;texture;algorithm	ML	-11.242982175604604	-61.98027261729121	184426
28fc3a4a1b39e3f689c343571bacede4fe6a7f25	a spoken dialogue system utilizing spatial information	spatial reasoning;spoken dialogue system;engineering and technology;teknik och teknologier;spatial information	Spatial reasoning plays an important role in many spoken dialogue systems. One application area where it is especially important is timetable information for local bus trafc. Users of such systems often request information based on vague spatial descriptions and a usable system must be able to handle this. We have extended a dialogue system with abilities to transform vague spatial expressions into a form that can be used to access the information base. In our approach we use the power of a Geographical Information System (GIS) for the spatial reasoning.	dialog system;dialog tree;geographic information system;local bus;schedule;spatial–temporal reasoning;spoken dialog systems;vagueness	Annika Flycht-Eriksson;Arne Jönsson	1998			natural language processing;speech recognition;computer science;communication	AI	-16.52219517253048	-59.57879840206676	184530
f1cfe8721d36619c11a1f3631efa9c8659e1d2e5	content-based image retrieval	databases;multimedia;image retrieval;high resolution;indexation	This chapter provides an introduction to information retrieval and image retrieval. Types of image retrieval techniques, i.e., text-based image retrieval and content-based image retrieval techniques are introduced. A brief introduction to visual features like color, texture, and shape is provided. Similarity measures used in content-based image retrieval and performance evaluation of content-based image retrieval techniques are also given. Importance of user interaction in retrieval systems is also discussed.	content-based image retrieval;information retrieval;performance evaluation;text-based (computing)	Vipin Tyagi	2017		10.1007/978-981-10-6759-4	information retrieval;content-based image retrieval;mathematics	Vision	-13.525044738961236	-58.043126997253694	184777
11ddf1ad006c26f7f5586525755ca64db3a5851b	a study of the dirichlet priors for term frequency normalisation	dirichlet prior;dirichlet priors;term frequency normalisation;generic model;information retrieval;term frequency;probabilistic model;qa75 electronic computers computer science;parameter tuning;weighting model;divergence from randomness;language model;qa76 computer software	In Information Retrieval (IR), the Dirichlet Priors have been applied to the smoothing technique of the language modeling approach. In this paper, we apply the Dirichlet Priors to the term frequency normalisation of the classical BM25 probabilistic model and the Divergence from Randomness PL2 model. The contributions of this paper are twofold. First, through extensive experiments on four TREC collections, we show that the newly generated models, to which the Dirichlet Priors normalisation is applied, provide robust and effective performance. Second, we propose a novel theoretically-driven approach to the automatic parameter tuning of the Dirichlet Priors normalisation. Experiments show that this tuning approach optimises the retrieval performance of the newly generated Dirichlet Priors-based weighting models.	dirichlet kernel;experiment;information retrieval;language model;randomness;smoothing;statistical model;tf–idf	Ben He;Iadh Ounis	2005		10.1145/1076034.1076114	latent dirichlet allocation;dirichlet distribution;statistical model;computer science;machine learning;pattern recognition;tf–idf;information retrieval;statistics;language model	Web+IR	-17.736893299272847	-63.489722643350774	185087
925152ae4d3620fb2c80d80b2c9fdfb40c0659da	"""""""stretch"""": a system for document storage and retrieval by content"""	databases;docu base;image storage;document handling;content based retrieval indexing aging image storage image retrieval multimedia systems image analysis character recognition data mining databases;invoice archive;storage and retrieval by content of imaged documents;information extraction;complex queries;invoice;imaged multimedia document retrieval;information retrieval;search methods;search method;aging;structured document representation;document representation;data mining;multimedia systems;intelligent character recognition;produced document base;modified x y tree;indexing;object oriented;esprit project;information field;multimedia databases;document storage;invoicing content based retrieval multimedia databases information retrieval document handling object oriented databases;automatic indexing;heterogeneous documents;retrieval engine;invoicing;image analysis;object oriented databases;document processing;stretch;object oriented internal representation;structured documents;archiving;reading strategy;content based retrieval;character recognition;variable layout;correlation graph;invoice archive stretch document storage imaged multimedia document retrieval esprit project storage and retrieval by content of imaged documents archiving retrieval engine structured document representation heterogeneous documents variable layout complex queries produced document base docu base object oriented internal representation search methods;image retrieval	In this paper a system for storing and retrieving imaged multimedia documents by content is described. This system is being developed within the Esprit project STRETCH (STorage and RETrieval by Content of imaged documents). The core of STRETCH system is a powerful Archiving and Retrieval Engine, based on a structured document representation and capable of activating appropriate methods to characterise and automatically index heterogeneous documents with variable layout and subsequently retrieve them by answering to complex queries. The produced document base, or “Docu-base”, relies on an object-oriented internal representation and related characterisation and search methods. A prototype was implemented and successfully tested, in particular, in the creation of an invoice archive.	archive;estimation of signal parameters via rotational invariance techniques;prototype	Enrico Appiani;L. Boato;S. Bruzzo;Anna Maria Colla;M. Davite;Donatella Sciarra	1999		10.1109/DEXA.1999.795251	search engine indexing;image analysis;document processing;image retrieval;intelligent character recognition;computer science;data mining;database;object-oriented programming;world wide web;information extraction;information retrieval	Web+IR	-13.306082509050368	-57.73983238272686	185762
ef2ad37fd37a78f68529a3c6a388fc58326d110c	rdfx: audio effects utilising musical metadata	protocols;open sound control protocol;audio signal processing;descriptors accuracy;semantic audio;rdfx;protocols audio signal processing feature extraction meta data ontologies artificial intelligence;audio effects;semantics;delay effects;resource description framework;feature extraction algorithms;musical metadata;ontologies artificial intelligence;music ontology audio effects semantic audio;feature extraction;music ontology;ontologies feature extraction resource description framework data visualization production delay effects semantics;data visualization;audio signals;production;meta data;ontologies;sonic visualiser;processed signals;audio features ontology;open sound control protocol rdfx audio effects musical metadata processed signals audio features ontology audio signals descriptors accuracy feature extraction algorithms sonic visualiser	We present a system of audio effects capable of processing and predicting metadata associated with the processed signals. This new class of audio effects has additional inputs and outputs describing features in RDF using the Audio Features Ontology. This data is processed in parallel to the audio signals. We show that by deriving the changes in metadata resulting from audio processing directly from the effect parameters, we can increase the accuracy of descriptors and reduce the computational cost by omitting repeated application of feature extraction algorithms on the output signal. Our demonstration uses a modified version of Sonic Visualiser controlled via the Open Sound Control protocol (OSC) to display metadata at various stages of processing.	algorithm;audio signal processing;computation;computational complexity theory;feature extraction;sonic visualiser	Thomas Wilmering;Mark B. Sandler	2010	2010 IEEE Fourth International Conference on Semantic Computing	10.1109/ICSC.2010.88	natural language processing;communications protocol;audio mining;speech recognition;aes11;audio signal processing;feature extraction;computer science;ontology;artificial intelligence;audio signal;speech coding;rdf;semantics;linguistics;metadata;information retrieval;data visualization	Visualization	-12.998002669271326	-53.90349298457967	186360
4e5aaf3d718055bbfb9547cb2d4f91057ec158f9	correlated tag learning in topic model		It is natural to expect that the documents in a corpus will be correlated, and these correlations are reflected by not only the words but also the observed tags in each document. Most previous works model this type of corpus, which are called the semi-structured corpus, without considering the correlations among the tags. In this work, we develop a Correlated Tag Learning (CTL) model for semi-structured corpora based on the topic model to enable the construction of the correlation graph among tags via a logistic normal participation process. For the inference of the CTL model, we devise a variational inference algorithm to approximate the posterior. In experiments, we visualize the tag correlation graph generated by the CTL model on the DBLP corpus and for the tasks of document retrieval and classification, the correlation graph among tags is helpful to improve the generalization performance compared with the state-of-the-art baselines.	approximation algorithm;calculus of variations;document retrieval;expect;experiment;mathematical model;model checking;parallel algorithm;semiconductor industry;statistical model;text corpus;topic model	Shuangyin Li;Rong Pan;Yu Zhang;Qiang Yang	2016			ctl*;machine learning;computer science;topic model;document retrieval;inference;graph;artificial intelligence;pattern recognition	NLP	-16.529657666664857	-64.10837217140605	186375
bf145eef75741044c6840bc96dbb82126e0bc3c5	feature extraction and content analysis for sports videos annotation	sports videos;sports video;content analysis;feature extraction;automatic annotation;video annotation;content based video retrieval;video semantics;domain specificity	This paper illustrates an approach to semantic video annotation in the specific context of sports videos. Videos are automatically annotated according to elements of visual content at different layers of semantic significance. Unlike previous approaches, videos can include several different sports and can also be interleaved with non sport shots. Each shot is decomposed into its visual and graphic content elements, including foreground and background, objects, text captions, etc. Several different low-level visual primitives are combined together by domain-specific rules in order to capture semantic content at a higher level of significance. Results of experiments on typical sports videos are presented and discussed.	experiment;feature extraction;high- and low-level	Jürgen Assfalg;Marco Bertini;Carlo Colombo;Alberto Del Bimbo	2001		10.1145/500933.500953	computer vision;content analysis;feature extraction;computer science;machine learning;multimedia;information retrieval	Vision	-13.99343947949117	-56.14917288428714	186667
5c58bfe7e99bb05dc71d11ef7428fced05872264	choosing basic-level concept names using visual and language context	visualization context semantics mathematical model training equations context modeling;training;semantics;probability estimation theory image classification object recognition;conference paper;visualization;probability estimation basic level concept name visual context language context classification task ranking task natural image object categorization;mathematical model;context modeling;context	We study basic-level categories for describing visual concepts, and empirically observe context-dependant basic level names across thousands of concepts. We propose methods for predicting basic-level names using a series of classification and ranking tasks, producing the first large scale catalogue of basic-level names for hundreds of thousands of images depicting thousands of visual concepts. We also demonstrate the usefulness of our method with a picture-to-word task, showing strong improvement over recent work by Ordonez et al, by modeling of both visual and language context. Our study suggests that a model for naming visual concepts is an important part of any automatic image/video captioning and visual story-telling system.	categorization;context-sensitive language	Alexander Patrick Mathews;Lexing Xie;Xuming He	2015	2015 IEEE Winter Conference on Applications of Computer Vision	10.1109/WACV.2015.85	natural language processing;computer vision;visualization;computer science;machine learning;pattern recognition;mathematical model;semantics;context model	Vision	-15.927986906608865	-62.579006657198285	186680
9ac1568000550bd4fe0800fb342a77a515899b89	automatic ground-truth generation for document image analysis and understanding	truthed document image databases;synthesised document image;precise context;document image analysis;automatic generation;performance evaluation;automatic ground-truth generation;ground-truth information;complete system;generic algorithm;ground truth	Performance evaluation for document image analysis and understanding is a recurring problem. Many ground- truthed document image databases are now used to evaluate algorithms, but these databases are less useful for the design of a complete system in a precise context. This paper proposes an approach for the automatic generation of synthesised document images and associated ground-truth information based on a derivation of publishing tools. An implementation of this approach illustrates the richness of the produced information.	algorithm;database;ground truth;image analysis;performance evaluation	Pierre Héroux;Eugen Barbu;Sébastien Adam;Éric Trupin	2007	Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)	10.1109/ICDAR.2007.70	genetic algorithm;document clustering;ground truth;computer science;document layout analysis;digital image processing;data mining;database;automatic image annotation;information retrieval	Vision	-13.19180211375741	-58.43411634367682	186970
407f19e47737f9a5bc2e1e6367c07a4e3bfda003	automatically creating adaptive video summaries using constraint satisfaction programming: application to sport content	electronic mail;large scale user evaluation csp automatic video summarization sport content constraint satisfaction programming adaptive video summaries;constraint satisfaction problems sport video signal processing;constraint satisfaction programming csp video analysis video summarization;visualization;computational modeling;programming profession;feature extraction;visualization computational modeling programming profession electronic mail feature extraction tv;tv;csp video analysis video summarization	This paper addresses automatic video summarization. We propose a novel approach that relies on constraint satisfaction programming (CSP). An expert defines the general rules for summary generation. These rules are written as constraints. The (final) user can define additional constraints or enter high-level parameters of predefined constraints. This has many advantages. It clearly separates summary generation rules from the summary generation algorithm (the CSP solver here). The summary can hence be modified without reviewing the whole generation process. It also allows users to adapt the summary to the target application and to their preferences. The proposed approach is mainly dedicated to edited professional video (like TV programs). It has been extensively evaluated not only using objective measures but also through a large-scale user evaluation. This evaluation involved more than 60 people. Experiments have been performed within the challenging application of tennis match automatic summarization, using about 28.5 h of videos.	algorithm;automatic summarization;constraint (mathematics);constraint satisfaction;experiment;high- and low-level;high-level programming language;response time (technology);solver;usability testing	Haykel Boukadida;Sid-Ahmed Berrani;Patrick Gros	2017	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2015.2513678	computer vision;simulation;visualization;feature extraction;computer science;automatic summarization;machine learning;data mining;multimedia;computational model	Vision	-14.533523851111479	-53.55294412483528	187128
e70ddf5f9cf3099026f0d8a6c9ca0f7d8b32f041	non-deterministic behavior of ranking-based metrics when evaluating embeddings		Embedding data into vector spaces is a very popular strategy of pattern recognition methods. When distances between embeddings are quantized, performance metrics become ambiguous. In this paper, we present an analysis of the ambiguity quantized distances introduce and provide bounds on the effect. We demonstrate that it can have a measurable effect in empirical data in state-of-the-art systems. We also approach the phenomenon from a computer security perspective and demonstrate how someone being evaluated by a third party can exploit this ambiguity and greatly outperform a random predictor without even access to the input data. We also suggest a simple solution making the performance metrics, which rely on ranking, totally deterministic and impervious to such exploits.	computer security;kerrison predictor;pattern recognition;quantization (signal processing)	Anguelos Nicolaou;Sounak Dey;Vincent Christlein;Andreas Maier;Dimosthenis Karatzas	2018	CoRR		artificial intelligence;machine learning;ambiguity;vector space;pattern recognition;computer science;embedding;measure (mathematics);exploit;phenomenon;ranking	ML	-14.511170343430875	-64.65766151588501	187239
756b619a9086242f987a6f9804529f8a9a0cf081	gramm-x public web server for protein–protein docking	software;ligands;binding sites;models molecular;internet;protein protein docking;multiprotein complexes;user computer interface;computational biology;article	Protein docking software GRAMM-X and its web interface (http://vakser.bioinformatics.ku.edu/resources/gramm/grammx) extend the original GRAMM Fast Fourier Transformation methodology by employing smoothed potentials, refinement stage, and knowledge-based scoring. The web server frees users from complex installation of database-dependent parallel software and maintaining large hardware resources needed for protein docking simulations. Docking problems submitted to GRAMM-X server are processed by a 320 processor Linux cluster. The server was extensively tested by benchmarking, several months of public use, and participation in the CAPRI server track.	boat dock;computer cluster;docking (molecular);fast fourier transform;interface device component;linux;macromolecular docking;protein data bank;refinement (computing);score;server (computer);server (computing);simulation;smoothed-particle hydrodynamics;smoothing (statistical technique);user interface;web server;world wide web;x window system	Andrey Tovchigrechko;Ilya A. Vakser	2006	Nucleic Acids Research	10.1093/nar/gkl206	the internet;bioinformatics;binding site;ligand	Metrics	-6.40225778057004	-57.69632269913597	187352
8adb441d377177fe777c5199efd26dc1d741a6c4	discovery of hidden similarity on collaborative filtering to overcome sparsity problem	prediccion;parent;sibling;reseau homme;systeme filtrage collectif;hermandad;recherche similitude cachee;pariente;fratrie;similitude;collaborative filtering;similarity;representacion parsimoniosa;friend of a friend;similitud;information system;sparse representation;prediction;systeme information;calcul similitude;representation parcimonieuse;sistema informacion	This paper presents a method for overcoming sparsity problem of collaborative filtering system. The proposed method is based on an intuition on a network of human (such as a friendship network with friends of a friend). This method increases the density of similarity matrix and the coverage of predictions. We use sparse training data to test the sparsity of real-world situation. Consequently, experimental results show that this method increases coverage and f-measure especially for sparse training data.	collaborative filtering;sparse matrix	Sanghack Lee;Jihoon Yang;Sung-Yong Park	2004		10.1007/978-3-540-30214-8_36	similarity;prediction;computer science;artificial intelligence;similitude;collaborative filtering;friend of a friend;machine learning;sparse approximation;data mining;mathematics;information system	ECom	-13.623220723273729	-61.87148390412347	187404
e2f1d2be77a0518764a8b002b5fdd6a341681bfb	swivel: improving embeddings by noticing what's missing		We present Submatrix-wise Vector Embedding Learner (Swivel), a method for generating lowdimensional feature embeddings from a feature co-occurrence matrix. Swivel performs approximate factorization of the point-wise mutual information matrix via stochastic gradient descent. It uses a piecewise loss with special handling for unobserved co-occurrences, and thus makes use of all the information in the matrix. While this requires computation proportional to the size of the entire matrix, we make use of vectorized multiplication to process thousands of rows and columns at once to compute millions of predicted values. Furthermore, we partition the matrix into shards in order to parallelize the computation across many nodes. This approach results in more accurate embeddings than can be achieved with methods that consider only observed cooccurrences, and can scale to much larger corpora than can be handled with sampling methods.	amortized analysis;approximation algorithm;co-occurrence matrix;column (database);computation;document-term matrix;hinge loss;matrix multiplication;mutual information;parallel computing;requirement;richardson number;sampling (signal processing);samy (computer worm);scalability;shard (database architecture);stochastic gradient descent;text corpus;the matrix;word embedding	Noam Shazeer;Ryan Doherty;Colin Evans;Chris Waterson	2016	CoRR		artificial intelligence;theoretical computer science;machine learning;statistics	ML	-15.500861614376547	-63.90722219887589	187754
9975c198e77eaa22abee2f0afd7b2831e032bdff	using ancestral layout models for document digitization	palaeography;document layout analysis;layout model;margins;spaces;type area	In this article, we show how some concepts found in traditional and old layout practices used to layout text (ruling, grid) can improve document digitization. We will first present these basic layout methods, some used since the Antiquity, and explain how some of their key concepts can be 'translated' and used in today's document digitization. In particular, we will show that the traditional concept of type area is a key notion for modeling document layout. An algorithm to compute type area is detailed. We will then illustrate this work with several practical usages and evaluations, from OCR improvement to high-level logical segmentation.	algorithm;high- and low-level;optical character recognition	Hervé Déjean	2014		10.1145/2595188.2595219	layout;computer science;document layout analysis;data mining;database;comprehensive layout;engineering drawing	Theory	-13.253944698798577	-59.35423871086716	187767
771766b87b1aaaae13d94917818ca6298c455189	integrating computer vision algorithms and ontologies for spectator crowd behavior analysis		Abstract Capturing and understanding crowd dynamics is an important issue under diverse perspectives. From social, psychological, and political sciences to safety management, studying, modeling, and predicting the presence, behavior, and dynamics of crowds, possibly preventing dangerous activities, is absolutely crucial. In the literature, crowds have been classified under different categories depending on their size and focus of attention. This chapter focuses on spectator crowds, namely crowds formed by people whose behavior is constrained by a structured environment, whose focus of attention is mainly shared, directed to a specific event. We first propose the backbone of an ontology of spectator crowd behavior based on a foundational analysis of both related literature and S-Hock, a massive annotated video dataset on crowd behavior during hockey events. Then, we present a new methodological approach integrating ontological reasoning, performed with a new description logic-based temporal formalism, with computer vision algorithms, allowing for automatic recognition of events happening in the playground, based on the behavior of the crowd in the stands.	computer vision;ontology (information science)	Davide Conigliaro;Roberta Ferrario;Céline Hudelot;Daniele Porello	2017		10.1016/B978-0-12-809276-7.00016-3	computer vision;simulation;computer science;crowd simulation;multimedia	Vision	-11.944130207233087	-52.20049928444038	187774
e2dcd650e56daadaefbe48305d091b476a0b6b13	evaluating visual and textual features for predicting user ‘likes’	training;semantics;visualization;computational modeling;feature extraction;visualization feature extraction semantics probabilistic logic training sparse matrices computational modeling;visual based features flickr feature representation semantic representations likes text based features;probabilistic logic;sparse matrices;recommender systems image representation;image likes feature representation tags recommendation	Computationally modeling users `liking' for image(s) requires understanding how to effectively represent the image so that different factors influencing user `likes' are considered. In this work, an evaluation of the state-of-the-art visual features in multimedia understanding at the task of predicting user `likes' is presented, based on a collection of images crawled from Flickr. Secondly, a probabilistic approach for modeling `likes' based only on tags is proposed. The approach of using both visual and text-based features is shown to improve the state-of-the-art performance by 12%. Analysis of the results indicate that more human-interpretable and semantic representations are important for the task of predicting very subtle response of `likes'.	computer simulation;flickr;text-based (computing)	Sharath Chandra Guntuku;Sujoy Roy;Weisi Lin	2015	2015 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2015.7177381	computer vision;visualization;sparse matrix;feature extraction;computer science;machine learning;pattern recognition;data mining;semantics;probabilistic logic;computational model	Robotics	-15.965034336966013	-62.3358998596679	188321
6ab9c5ace5348fa60d5139d9366472891a9a62f3	robust detection of key captions for sports video understanding	key caption;game information jpeg2000 compressed video hierarchical motion side information robust key caption detection method sports video dual binarization method text segmentation color polarity sports navigation system video highlight content search;color polarity;video summarization;image segmentation;data compression;sports navigation system;video retrieval;sports video understanding;indexing terms;data mining;game information;system performance;sports video;jpeg2000 compressed video;video coding;accuracy;hierarchical motion side information;content search;robust key caption detection method;image edge detection;video highlight;image color analysis;dual binarization method;games;pixel;key caption sports video understanding video summarization text information;text information;robustness video compression data mining games broadcasting detectors multimedia communication layout flowcharts information retrieval;robustness;navigation system;video retrieval content based retrieval data compression image segmentation sport video coding;sport;content based retrieval;text segmentation	In sports videos, text information provides valuable game information such as scores, players, and so on. This text information plays an important role for sports video understanding, summarization, and retrieval. These texts which can be used for video highlight or content search are called key captions. In this paper, we provide a robust detection method of key captions in sports videos. We also provide a dual binarization method easily segmenting texts with different color polarities (i.e. dark and bright texts) from the background in the key captions. From this text information, we create the efficient sports navigation system. By conducting experiments on a large database, the system performance is demonstrated to be accurate and robust.	database;experiment;robustness (computer science)	Zhendong Zhang;Su Young Lee;Joongkyu Kim	2008	2008 15th IEEE International Conference on Image Processing	10.1109/ICIP.2008.4712306	data compression;text segmentation;computer vision;computer science;sport;computer performance;multimedia;image segmentation;internet privacy;pixel;statistics;robustness	Vision	-13.565241939352685	-54.13659153537854	188602
184375ec9e6d49ebc3df51077e996296ad460fc0	fast title extraction method for business documents	systeme gestion electronique document;relative position;titre;keyword;image processing;japonais;optical character recognition;chaine caractere;exploracion;palabra clave;mot cle;traitement image;titulo;reconnaissance caractere;title;file system;electronic document management system;cadena caracter;keyword extraction;balayage;scanning;character recognition;sistema gestion electronica documento;japones;natural language processing;extraction;extraction method;reconocimiento caracter;character string;japanese	Conventional electronic document filing systems are inconvenient because the user must specify the keywords in each document for later searches. To solve this problem, automatic keyword extraction methods using natural language processing and character recognition have been developed. However, these methods are slow, especially for japanese documents. To develop a practical electronic document filing system, we focused on the extraction of keyword areas from a document by image processing. Our fast title extraction method can automatically extract titles as keywords from business documents. All character strings are evaluated for similarity by rating points associated with title similarity. We classified these points as four items: character sitting size, position of character strings, relative position among character strings, and string attribution. Finally, the character string that has the highest rating is selected as the title area. The character recognition process is carried out on the selected area. It is fast because this process must recognize a small number of patterns in the restricted area only, and not throughout the entire document. The mean performance of this method is an accuracy of about 91 percent and a 1.8 sec. processing time for an examination of 100 Japanese business documents.© (1997) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Yutaka Katsuyama;Satoshi Naoi	1997		10.1117/12.270072	speech recognition;document processing;computer science;artificial intelligence;world wide web	DB	-11.720262239682135	-62.312034097043224	189713
0beb24a5fcebefb5a45a922ded9287cd493a6a08	vrml - enhanced learning in biology and medicine	software;cellular structure;cellular function;insect;simulation;biology;three dimensional;visualization;biological systems;vrml;medicine;cricket;three dimensional structure;medical education	Abstract   Biological systems are three-dimensional structures living in three-dimensional space. So it is natural to use VRML as a tool in the biological or medical educational process. Our group has been developing VRML biological worlds for several years (http://verbena.fe.uni-lj.si/∼tomaz/VRML/). We are visualizing biological structures which are difficult to observe without special instruments and processes which are difficult to understand from a textbook alone. We are investigating how to build optimal biological VRML worlds small in file size, but still expressive enough to serve as an effective “fast learning tool” in biology.	vrml	Tomaz Amon;Vojko Valencic	2000	Future Generation Comp. Syst.	10.1016/S0167-739X(99)00097-7	three-dimensional space;simulation;vrml;visualization;computer science;multimedia;computer graphics (images)	Arch	-8.3089364618359	-56.53575893233742	190011
ce402833c37ece3493ad6bd23df8cd19a2816c0f	efficient representation for natural language processing via kernelized hashcodes		Kernel similarity functions have been successfully applied in classification models such as Support Vector Machines, Gaussian Processes and k-Nearest Neighbors (kNN), but found to be computationally expensive for Natural Language Processing (NLP) tasks due to the cost of computing kernel similarities between discrete natural language structures. A well-known technique, Kernelized Locality Sensitive Hashing (KLSH), allows for an approximate computation of kNN graphs and significantly reduces the number of kernel computations; however, applying KLSH to other classifiers have not been explored. In this paper, we propose to use random subspaces of KLSH codes for constructing an efficient representation that preserves fine-grained structure of the data and is suitable for general classification methods. Further, we proposed an approach for optimizing KLSH model for supervised classification problems, by maximizing a variational lower bound on the mutual information between the KLSH codes (feature vectors) and the class labels. We apply the proposed approach to the task of extracting information about bio-molecular interactions from the semantic parsing of scientific papers. Our empirical results on a variety of datasets demonstrate significant improvements over the state of the art.	analysis of algorithms;approximation algorithm;british informatics olympiad;code;computation;decision tree;gaussian process;interaction;kernel (operating system);kernel method;locality of reference;locality-sensitive hashing;machine learning;mutual information;natural language processing;parsing;random forest;randomness;scientific literature;supervised learning;support vector machine;variational principle	Sahil Garg;Aram Galstyan;Irina Rish;Guillermo A. Cecchi;Shuyang Gao	2017	CoRR		machine learning;natural language processing;artificial intelligence;polynomial kernel;support vector machine;locality-sensitive hashing;parsing;computer science;graph kernel;feature vector;tree kernel;pattern recognition;radial basis function kernel	ML	-15.937266129027407	-65.26632079912034	190045
723d9e9dd909ff54a9bc105a32d84fcc7cd9d192	skymedia - uav-based capturing of hd/3d content with wsn augmentation for immersive media experiences	multimedia delivery;live events;wireless sensor;uav based capturing;skymedia uav based capturing;immersive media experiences;video signal processing;3d videos;real time;unmanned aerial vehicle;sky images;remotely operated vehicles;wireless sensor network;three dimensional displays sensors wireless sensor networks videos multimedia communication high definition video real time systems;3d processing;augmentation network;continuous improvement;unmanned aerial vehicle wsn augmentation skymedia uav based capturing hd 3d content immersive media experiences entertainment industry multimedia end to end architecture 3d videos sky images augmentation network multimedia service platform;multimedia communication;multimedia service platform;live events 3d processing uav based capturing wireless sensor networks multimedia delivery immersive and interactive services;multimedia end to end architecture;immersive and interactive services;side information;3d video;multimedia services;wireless sensor networks multimedia communication remotely operated vehicles video signal processing;wireless sensor networks;hd 3d content;wsn augmentation;entertainment industry	In the entertainment industry, technology advances are continuously improving and evolving the portfolio of services and distinguished features that can be experienced by the audience, whether it is attending the event on site or remotely. In this context, the SkyMedia system aims at exploring, designing, and demonstrating a novel multimedia end-to-end architecture that can provide unique immersive media experiences to audience during live events. UAV and WSN technologies play a central role as enabling technologies. UAVs capture HD and 3D videos and images from the sky, while wireless sensors form an augmentation network acquiring side-information to be fused with the main audiovisual contents. All technologies come together to form a very advanced Multimedia Service Platform able to manage in real-time HD/3D processing, and an immersive media experience demonstration is going to be performed during a public live event in order to prove the effectiveness of the system.	end-to-end principle;experience;real-time clock;sensor;unmanned aerial vehicle	Massimo Neri;Aldo Campi;Rosalba Suffritti;Francesco Grimaccia;Pedro Sinogas;Olivier Guye;Christophe Papin;Theodoros Michalareas;Laszlo Gazdag;Ismo Rakkolainen	2011	2011 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2011.6012133	embedded system;simulation;wireless sensor network;computer science;multimedia	Visualization	-14.201894089056108	-52.57919461279265	190214
08ff526efd65ed95f9f4140b622d049f398eaa5a	semi-supervised text classification using partitioned em	unlabeled data;bayes estimation;analyse amas;partition method;text;mixture;red www;melange;text mining;classification supervisee;supervised classification;reseau web;texte;satisfiability;semi supervised learning;bayesian method;text classification;estimacion bayes;hierarchical classification;cluster analysis;methode partition;internet;particion;expectation maximization;mixture model;partition;clasificacion supervisada;classification hierarchique;algorithme em;world wide web;analisis cluster;etiqueta;teoria mezcla;algoritmo em;metodo particion;etiquette;classification accuracy;label;mixture theory;texto;em algorithm;clasificacion jerarquizada;theorie melange;mezcla;estimation bayes	Text classification using a small labeled set and a large unlabeled data is seen as a promising technique to reduce the labor-intensive and time consuming effort of labeling training data in order to build accurate classifiers since unlabeled data is easy to get from the Web. In [16] it has been demonstrated that an unlabeled set improves classification accuracy significantly with only a small labeled training set. However, the Bayesian method used in [16] assumes that text documents are generated from a mixture model and there is a one-to-one correspondence between the mixture components and the classes. This may not be the case in many applications. In many real-life applications, a class may cover documents from many different topics, which violates the oneto-one correspondence assumption. In such cases, the resulting classifiers can be quite poor. In this paper, we propose a clustering based partitioning technique to solve the problem. This method first partitions the training documents in a hierarchical fashion using hard clustering. After running the expectation maximization (EM) algorithm in each partition, it prunes the tree using the labeled data. The remaining tree nodes or partitions are likely to satisfy the oneto-one correspondence condition. Extensive experiments demonstrate that this method is able to achieve a dramatic gain in classification performance.	bayesian network;cluster analysis;decision tree learning;document classification;expectation–maximization algorithm;experiment;mixture model;naive bayes classifier;naivety;one-to-one (data model);real life;recursion;semiconductor industry;statistical classification;test set;world wide web	Gao Cong;Wee Sun Lee;Haoran Wu;Bing Liu	2004		10.1007/978-3-540-24571-1_45	text mining;expectation–maximization algorithm;computer science;machine learning;pattern recognition;data mining	ML	-13.710073419084623	-61.84944484343244	190278
f4e5a331bc6cb283bd0825d36e779f1b703d1d5d	integration of visual temporal information and textual distribution information for news web video event mining	visualization trajectory feature extraction data mining correlation probabilistic logic noise measurement;youtube visual temporal information textual distribution information news web video event mining near duplicate keyframe detection ndk detection data preprocessing stage feature selection tag relevance learning multiple correspondence analysis probabilistic model;data mining;noise measurement;visualization;trajectory;feature extraction;correlation;probabilistic logic;visual feature trajectory cooccurrence multiple correspondence analysis mca near duplicate keyframes ndk news web video event mining;statistical analysis data mining feature selection learning artificial intelligence social networking online	News web videos exhibit several characteristics, including a limited number of features, noisy text information, and error in near-duplicate keyframes (NDK) detection. Such characteristics have made the mining of the events from news web videos a challenging task. In this paper, a novel framework is proposed to better group the associated web videos to events. First, the data preprocessing stage performs feature selection and tag relevance learning. Next, multiple correspondence analysis is applied to explore the correlations between terms and events with the assistance of visual information. Cooccurrence and visual near-duplicate feature trajectory induced from NDKs are combined to calculate the similarity between NDKs and events. Finally, a probabilistic model is proposed for news web video event mining, where both visual temporal information and textual distribution information are integrated. Experiments on the news web videos from YouTube demonstrate that the integration of visual temporal information and textual distribution information outperforms the existing methods in the news web video event mining.	android software development;data pre-processing;feature selection;key frame;multiple correspondence analysis;noisy text;preprocessor;relevance;statistical model;video clip	Chengde Zhang;Xiao Wu;Mei-Ling Shyu;Qiang Peng	2016	IEEE Transactions on Human-Machine Systems	10.1109/THMS.2015.2489681	visualization;feature extraction;computer science;noise measurement;trajectory;machine learning;pattern recognition;data mining;geometry;linguistics;probabilistic logic;correlation;information retrieval	Web+IR	-18.41857152647736	-57.95954896918254	190676
e464fb9609279c2672d69919f0ba25e94c8eaa6c	exploring inter-concept relationship with context space for semantic video indexing	context space;video indexing;context based concept fusion	Semantic concept detectors are often individually and independently developed. Using peripherally related concepts for leveraging the power of joint detection, which is referred to as context-based concept fusion (CBCF), has been one of the focus studies in recent years. This paper proposes the construction of a context space and the exploration of the space for CBCF. Context space considers the global consistency of concept relationship, addresses the problem of missing annotation, and is extensible for cross-domain contextual fusion. The space is linear and can be built by modeling the inter-concept relationship through annotation provided by either manual labeling or machine tagging. With context space, CBCF becomes a problem of concept selection and detector fusion, under which the significance of a concept/detector can be adapted when applied to a target domain different from where the detector is being developed. Experiments on TRECVID datasets of years 2005 to 2008 confirm the usefulness of context space for CBCF. We observe a consistent improvement of 2.8% to 38.8% for concept detection when context space is used, and more importantly, with significant speed-up compared to existing approaches.	experiment;sensor	Xiao-Yong Wei;Yu-Gang Jiang;Chong-Wah Ngo	2009		10.1145/1646396.1646416	computer vision;computer science;data mining;information retrieval	Vision	-15.367471752311832	-60.813419527907215	190902
c6222f92e6cfd360c4b9a94d32895a6003794077	coarse-grained and all-atom md simulations with gromacs based on cellmicrocosmos 2.2 model membranes	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;coarse grained;model membrane;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;md simulation;bioinformatics	The CELLmicrocosmos MembraneEditor (CmME) [1] enables researchers to generate PDB [2] based membrane structures in a convenient way. The lipid distribution is computed by algorithms working on the outer shapes of the molecules. For this reason, the computation and visualization process is very fast, while the atomistic structure of each single molecule remains unchanged. PDB membranes can be exported to Gromacs [3], a molecular dynamic simulation (MD) program. In this new approach the workflow between CmME and Gromacs has been improved. Two major strategies for the simulation of membranes are the all atom (AA) and coarse-grained (CG) approach. As a logical consequence of the shape-based principle of CmME, coarse-grained support has been implemented. The ongoing work is presented by comparing AA and CG structures generated with CmME, simulated with Gromacs and reverseparsed to CmME. Newly implemented features of the CmME MD Edition: • The Membrane Shifter Tool, enabling membrane model repositioning • Shape generation taking periodic boundaries into account • A Molecule Editor, supporting the definition of CG particles • Advanced raft support, allowing the analysis of lipid values and raft-restricted computation of lipid distributions. In addition, a GUI based on the CmME algorithm interface is being implemented, allowing the comfortable handling of CmME and Gromacs based workflows.	algorithm;atom;barrel shifter;computation;gromacs;graphical user interface;molecular dynamics;molecule editor;protein data bank;simulation	Björn Sommer;Tim Dingersen;Christian Gamroth;André J. Heissmann;Gunther Lukat;Ralf Rotzoll;Sebastian Rubert;Alexander Schäfer;Jens Krüger	2011		10.1186/1758-2946-3-S1-P43	biology;medical research;simulation;medicine;computer science;bioinformatics	HPC	-5.968124998144947	-58.82044906687833	191296
5826a39437e557767c7e1895bfdbee39af8dcac9	d-vasim: an interactive virtual laboratory environment for the simulation and analysis of genetic circuits		Simulation and behavioral analysis of genetic circuits is a standard approach of functional verification prior to their physical implementation. Many software tools have been developed to perform in silico analysis for this purpose, but none of them allow users to interact with the model during runtime. The runtime interaction gives the user a feeling of being in the lab performing a real world experiment. In this work, we present a user-friendly software tool named D-VASim (Dynamic Virtual Analyzer and Simulator), which provides a virtual laboratory environment to simulate and analyze the behavior of genetic logic circuit models represented in an SBML (Systems Biology Markup Language). Hence, SBML models developed in other software environments can be analyzed and simulated in D-VASim. D-VASim offers deterministic as well as stochastic simulation; and differs from other software tools by being able to extract and validate the Boolean logic from the SBML model. D-VASim is also capable of analyzing the threshold value and propagation delay of a genetic circuit model.   AVAILABILITY AND IMPLEMENTATION D-VASim is available for Windows and Mac OS and can be downloaded from bda.compute.dtu.dk/downloads/.   CONTACT haba@dtu.dk, jama@dtu.dk.		Hasan Baig;Jan Madsen	2017	Bioinformatics	10.1093/bioinformatics/btw592	human–computer interaction	SE	-4.795078123634249	-54.99164863520945	191334
3e062d10d7d7859abe6e6a697cb70db7fd0791b1	hierarchical access system for sequence libraries in europe (hassle): a tool to access sequence databases remotely	computadora;outil logiciel;reseau information;interfase usuario;secuencia aminoacido;software tool;base donnee;sequence aminoacide;aminoacid sequence;computerized processing;tratamiento informatico;user interface;ordinateur;electronic mailing;information retrieval;database;base dato;telecommunication network;correo electronico;secuencia nucleotido;computer;information network;nucleotide sequence;sequence nucleotide;courrier electronique;internet;recherche information;herramienta controlada por logicial;red telecomunicacion;reseau telecommunication;interface utilisateur;fortran;recuperacion informacion;traitement informatique;red informacion	Sequence databases in biology are growing exponentially. Not only are large sites needed to keep the data, but the number of customers is continuously increasing. Network access plays a key role in utilizing remote resources. However, both synchronous and asynchronous access require tools that are currently non-standard in molecular biology computing. Additionally, information discovery of today frequently focuses on centers rather a hierarchically interconnected facilities. HASSLE (Hierarchical Access System for Sequence Libraries in Europe) is an implementation of an application-independent, user-transparent access tool in molecular biology. It features tools for both clients and information providers to permit accounting and/or prioritization on various levels. HASSLE focuses on the network aspect of the molecular biology computing and assumes that it is possible to have database applications available as remote 'services' (programs, program packages or utilities) which can be started by a simple command script after a suitable feed of datafiles. The current system provides these services for searching with programs like FASTA or BLAST which are compiled as obtained from vendors or servers.	blast;compiler;computation (action);databases;embnet.journal;fasta;information discovery;library (computing);molecular biology;published database;sequence database	Reinhard Dölz	1994	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/10.1.31	the internet;telecommunications;nucleic acid sequence;computer science;user interface;world wide web;genetics;telecommunications network	HPC	-4.911516638605198	-56.38222473910421	191361
41cd7e3fcc81ec1d4238ac83a9399aefce39fb37	ontology-driven cyber-security threat assessment based on sentiment analysis of network activity data	analytical models;ontologies sentiment analysis computer security semantics analytical models context;threat assessment;semantic reconciliation;semantics;cyber security;semantic reconciliation cyber security ontology threat assessment sentiment analysis;computer security;security of data ontologies artificial intelligence;sentiment analysis;ontologies;ontology;context;consumer sentiments ontology driven cyber security threat assessment network activity data sentiment analysis models automated processes human responses ontological modeling probable attacks semantic reconciliation borderline cases ambiguous network activity	Sentiment analysis is gaining acceptance as a tool for automated understanding of consumer attitudes and preferences. Based on well-designed rule sets that describe how most people express their sentiments, sentiment analysis models enable automated processes to understand human responses. In this paper, we describe our vision of extending sentiment analysis to the novel domain of cyber-security. Our proposal combines: 1) ontological modeling of attacks, defenses, and attacker goals; 2) sentiment analysis of combinations of elements indicative of probable attacks; and 3) semantic reconciliation of borderline cases to more definitively classify ambiguous network activity as threatening or innocuous. This method has achieved good results (86% correct) in assessing consumer sentiments, and we believe that more detailed models can improve on this accuracy even in the complex domain of cyber-security.	computer security;ontology (information science);sentiment analysis	Doug Lundquist;Kunpeng Zhang;Aris M. Ouksel	2014	2014 International Conference on Cloud and Autonomic Computing	10.1109/ICCAC.2014.42	computer science;data mining;internet privacy;world wide web;sentiment analysis	SE	-12.003190086098476	-52.62422839903527	191813
e168d2f1f6dfbb47153ff24c923aac70eb525fa0	vcenter: a digital video management system with mobile search service	management system;digital library;content based video search;technology management;mobile search;camera phone;digital video;digital video library;video search	Digital video data have proliferated in recent years due to the rapid development of multimedia computing and computer technologies. Management of video data is thus becoming an indispensable part in digital library. However, currently most digital video library systems are lack of the support of content-based video search and an easy-to-use query interface. In this work, we develop a digital video management system called VCenter, which provides lightweight mobile search functionality based on image taken from camera phone. By the proposed framework, both end user and content owner are easier to enjoy the multimedia contents in digital video libraries.	camera phone;digital library;digital video;library (computing);web search engine	Jen-Hao Hsiao;Yu-Zheng Wang	2007		10.1145/1255175.1255308	mobile search;digital library;h.263;bink video;video production;uncompressed video;computer science;technology management;digital media;video capture;video tracking;management system;multimedia;videotelephony;video processing;camera phone;smacker video;internet privacy;world wide web;non-linear editing system	HCI	-15.462419952524028	-54.86850083463439	191931
69678e510ee50ac30ff19ccbac9b356fbbba1ffe	an interactive visual analysis tool for cellular behavior studies using large collections of microscopy videos	microscopy;layout;videos data visualization visualization microscopy feature extraction shape layout;visualization;shape;feature extraction;data visualization;video signal processing data visualisation interactive systems medical image processing microscopy;visualization tool interactive visual analysis tool cellular behavior microscopy videos video data microscopy imaging methods;videos	This paper presents an interactive visual analysis tool created for studying collections of video data. Our driving application is cellular behavior studies that use microscopy imaging methods. The studies routinely generate large amounts of videos with various experimental conditions. It is very time-consuming for the scientists to watch each video and manually extract features-of-interest for further comparative and quantitative studies. We show that with our visualization tool, scientists are now able to conveniently observe, select and isolate, and compare and analyze the cellular behaviors from different perspectives within one framework. The tremendous time and effort saved allow scientist to focus on deriving the actual meaning behind certain observed behaviors.	interactive visual analysis;video	Chuan Wang;Jia-Kai Chou;Kwan-Liu Ma;Árpád Karsai;Ying X. Liu;Evgeny Ogorodnik;Victoria Tran;Gang-Yu Liu	2016	2016 IEEE Second International Conference on Multimedia Big Data (BigMM)	10.1109/BigMM.2016.67	computer vision;visual analytics;information visualization;computer science;multimedia;biological data visualization;computer graphics (images)	Visualization	-5.410450973041459	-52.40177816065923	191943
763b49cdad67ed3e67f92723e071d89e25904e5c	an extension of stanag2022 for information scoring	information extraction;information retrieval;stanag2022;information scoring;information credibility;information likelihood;information extraction information scoring sensor evalutation;sensor evalutation;confidence scoring method;general methods;source trustworthiness;source proficiency;sensor evaluation;information extraction stanag2022 information scoring confidence scoring method source trustworthiness information credibility source proficiency information likelihood sensor evaluation	We introduce a new confidence scoring method based on an extension of STANAG2022. Our method uses the two parameters included in the STANAG, that is integrates source-trustworthiness to the computation of information-credibility, with two additional parameters: source-proficiency and information-likelihood. These parameters will be formally defined, as will our understanging of the existing criteria. A generic method for calculating a unique score, integrating trustworthiness, proficiency, likelihood and credibility is defined illustrated by two examples: sensor evaluation and information extraction.	computation;information extraction;trust (emotion)	Jérôme Besombes;Adrien Revault d'Allonnes	2008	2008 11th International Conference on Information Fusion		computer science;pattern recognition;data mining;information retrieval	Robotics	-11.743242284702948	-66.0216036484596	191992
124eabfdffb3e29bb0d34878f47bdb0d3a382d7d	sampling table configurations for the hierarchical poisson-dirichlet process	dirichlet process;latent variable;gibbs sampling;dirichlet processes;gibbs samplers;latent dirichlet allocation;conference paper;block gibbs sampler;hierarchical poisson dirichlet processes;hierarchical modeling;machine intelligence;keywords convergence speed;hdp lda;hierarchical dirichlet process;data items	•Discrete hierarchies are ubiquitous in intelligent systems. • The Poisson-Dirichlet process (PDP ) [1] allow statistical inference and learning on discrete hierarchies, e.g., hierarchy of Dirichlet distributions. • Applications of the PDP/HPDP include but not limited to: – Topic modeling: Finding meaningful topics discussed in large set of documents. Beneficial to automatic document analysis and understanding. – Computational linguistic: For example, the n-gram model. – Computer vision. Using PDP/HPDP to do image annotation, image segmentation, scene learning, and etc. – Others: Data compression, relational modeling, etc.	artificial intelligence;automatic image annotation;computation;computer vision;data compression;image segmentation;n-gram;programmed data processor;topic model	Changyou Chen;Lan Du;Wray L. Buntine	2011		10.1007/978-3-642-23780-5_29	latent dirichlet allocation;latent variable;gibbs sampling;dirichlet-multinomial distribution;computer science;machine learning;pattern recognition;data mining;statistics;hierarchical dirichlet process	AI	-16.344904253932192	-63.184421979170715	192612
6c0ef6487f3f7c64b5abbba174292f9ed0894e9c	mining the demographics of political sentiment from twitter using learning from label proportions		Opinion mining and demographic attribute inference have many applications in social science. In this paper, we propose models to infer daily joint probabilities of multiple latent attributes from Twitter data, such as political sentiment and demographic attributes. Since it is costly and time-consuming to annotate data for traditional supervised classification, we instead propose scalable Learning from Label Proportions (LLP) models for demographic and opinion inference using U.S. Census, national and state political polls, and Cook partisan voting index as population level data. In LLP classification settings, the training data is divided into a set of unlabeled bags, where only the label distribution of each bag is known, removing the requirement of instance-level annotations. Our proposed LLP model, Weighted Label Regularization (WLR), provides a scalable generalization of prior work on label regularization to support weights for samples inside bags, which is applicable in this setting where bags are arranged hierarchically (e.g., county-level bags are nested inside of state-level bags). We apply our model to Twitter data collected in the year leading up to the 2016 U.S. presidential election, producing estimates of the relationships among political sentiment and demographics over time and place. We find that our approach closely tracks traditional polling data stratified by demographic category, resulting in error reductions of 28-44% over baseline approaches. We also provide descriptive evaluations showing how the model may be used to estimate interactions among many variables and to identify linguistic temporal variation, capabilities which are typically not feasible using traditional polling methods.	baseline (configuration management);interaction;machine learning;matrix regularization;polling (computer science);population;scalability;statistical classification;supervised learning;wholesale line rental	Ehsan Mohammady Ardehaly;Aron Culotta	2017	2017 IEEE International Conference on Data Mining (ICDM)	10.1109/ICDM.2017.84	machine learning;artificial intelligence;sentiment analysis;robustness (computer science);data modeling;computer science;voting;joint probability distribution;population;inference;polling	ML	-18.04838758815965	-64.3300597827217	192883
67ce14513d5f5df5026633d61b89b7decc577a5c	chemical abstracts service chemical registry system. 13. enhanced handling of stereochemistry	compuesto organico;stereochimie;organic compounds;etude theorique;diagramme;algorithme;algorithm;diagram;estructura quimica;computer aid;estudio teorico;compose organique;estereoquimica;asistencia ordenador;chemical structure;theoretical study;structure chimique;assistance ordinateur;stereochemistry;algoritmo;diagrama		chemical vapor deposition	James E. Blackwood;Paul E. Blower;S. W. Layten;D. H. Lillie;Alan H. Lipkus;J. P. Peer;C. Qian;L. M. Staggenborg;Charles E. Watson	1991	Journal of Chemical Information and Computer Sciences	10.1021/ci00002a005	stereochemistry;chemistry;diagram;organic chemistry;chemical structure;mineralogy;algorithm	Theory	-6.576590403047904	-54.45260327047659	193141
4ce51c161f7e67ac0855d2736f5670cc9cff3b9c	differential influence of blogs across different stages of decision making: the case of venture capitalists	multistage;choice stage;ugc;econometric analysis;venture capital;it ventures;wom;multistage decision making;administracion de empresas;contract stage;economia y empresa;grupo a;blogs;screening stage;vc funding	In this work, we followed the sentiment analysis literature, and used supervised learning methods, which take manually classified data (corpus) as input and automatically extract features (combination of words and parts of speech of words) for sentiment analysis (Dave et al. 2003; Ghose and Ipeirotis 2011; Pang et al. 2002; Shanahan et al. 2006). These supervised methods do not rely on manually or semi-manually constructed discriminant-word lexicons. Prior research has shown that supervised methods perform better than lexicon-based approaches for sentiment analysis (Chaovalit and Zhou 2005; Pang et al. 2002).	blog;discriminant;lexicon;semiconductor industry;sentiment analysis;supervised learning;word lists by frequency	Rohit Aggarwal;Harpreet Singh	2013	MIS Quarterly		word of mouth;economics;venture capital;marketing;operations management;user-generated content;management	NLP	-18.850720045591427	-52.810777476202084	193203
f57635100c0b02007ed64c6143224aa2ad7ded43	a human-oriented mutual assistive framework using collaborative filtering towards disasters	collaboration filtering earthquakes image retrieval communities natural language processing government;collaborative filtering human oriented natural language processing content based image retrieval relevance feedback;text analysis collaborative filtering disasters emergency management image processing natural language processing relevance feedback sensor fusion social networking online;long term relevance feedback human oriented mutual assistive framework collaborative filtering disasters purchase recommendation systems social media knowledge based framework emergency situations high level data fusion text based natural language processing image based processing	Originally, collaborative filtering was adopted in purchase recommendation systems (e.g., Amazon.com) based on purchased history. In this paper, we apply collaborative filtering on the basis of accumulated feedbacks of the data extracted from social media from a community of users to build up a knowledge-based framework that can match offers to needs in disaster and emergency situations. This framework is constructed by high-level data fusion, i.e., incorporating text-based natural language processing with image-based processing using long-term relevance feedback, and learns user's preferences and adjusts their needs and offers accordingly. It can be deemed as a fundamental trial for timely mutual assist in disasters.	collaborative filtering;high- and low-level;natural language processing;recommender system;relevance feedback;social media;text-based (computing)	Jing Li;Mingru Zeng	2014	2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2014.6974253	computer science;collaborative filtering;data mining;multimedia;world wide web	Robotics	-18.39226876270651	-57.178350445848544	194015
992922b90be083bb5235205920ea7357cc93c118	adaptation of biochemical protocols to handle technology-change for digital microfluidics	reservoirs;protocols;sensors;clocks;computer architecture;digital microfluidic biochips dmfbs bioassays synthesis physical design formal techniques sat solvers;sat solvers digital microfluidic biochips dmfbs bioassays synthesis physical design formal techniques;synthesis bioassays digital microfluidic biochips formal techniques physical design sat solvers;scalability;protocols computer architecture reservoirs scalability sensors encoding clocks;encoding;on chip synthesis tool flow geometric techniques pertinent graph theoretic technique satisfiability solvers symbolic encoding actuation sequence adaptation method protocol resynthesis physical resources sensor inclusion mixer positions reservoir locations geometric changes mixer size clock frequency architectural parameters biochemical reaction medical diagnosis toxicity monitoring computational drug discovery parallel dna analysis dmf technologies digital microfluidics technology change handling biochemical protocol adaptation;biochemistry chemical reactions encoding graph theory microfluidics protocols	Advances in digital microfluidic (DMF) technologies offer a promising platform for a variety of biochemical applications, ranging from massively parallel DNA analysis and computational drug discovery to toxicity monitoring and medical diagnosis. In this paper, we address the migration problem that arises when the technology undergoes a change in the context of DMFs. Given a biochemical reaction synthesized for actuation on a given DMF architecture, we discuss how the same biochemical reaction can be ported seamlessly to an enhanced architecture, with possible modifications to the architectural parameters (e.g., clock frequency, mixer size, and mixing time) or geometric changes (e.g., change in reservoir locations or mixer positions, inclusion of new sensors or other physical resources). Complete resynthesis of the protocol for the new architecture may often become either inefficient or even infeasible due to scalability, proprietary, security, or cost issues. We propose an adaptation method for handling such technology-changes by modifying the existing actuation sequence through an incremental procedure. The foundation of our method lies in symbolic encoding and satisfiability-solvers, enriched with pertinent graph-theoretic and geometric techniques. This enables us to generate functionally correct solutions for the new target architecture without necessitating a complete resynthesis step, thereby enabling the utilization of these chips by users in biology who are not familiar with the on-chip synthesis tool-flow. We highlight the benefits of the proposed approach through extensive simulations on assay benchmarks.	benchmark (computing);boolean satisfiability problem;church encoding;clock rate;graph theory;relevance;scalability;sensor;simulation;test case	Sukanta Bhattacharjee;Sharbatanu Chatterjee;Ansuman Banerjee;Tsung-Yi Ho;Krishnendu Chakrabarty;Bhargab B. Bhattacharya	2017	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2016.2585622	embedded system;communications protocol;electronic engineering;scalability;computer science;bioinformatics;engineering;sensor;electrical engineering;theoretical computer science;operating system;algorithm;encoding;reservoir	EDA	-7.313728382846509	-52.96663142967356	194287
d73788d937341cd841a78a4453dbf9e3a51b588f	improving image retrieval effectiveness via multiple queries	feature space;system performance;result merging;semantic relations;content based image retrieval;relevance feedback;multi channel cbir;image retrieval	Conventional approaches to image retrieval are based on the assumption that relevant images are physically near the query image in some feature space. This is the basis of the cluster hypothesis. However, semantically related images are often scattered across several visual clusters. Although traditional Content-based Image Retrieval (CBIR) technologies may utilize the information contained in multiple queries (gotten in one step or through a feedback process), this is only a reformulation of the original query. As a result these strategies only get the images in some neighborhood of the original query as the retrieval result. This severely restricts the system performance. Relevance feedback techniques are generally used to mitigate this problem. In this paper, we present a novel approach to relevance feedback which can return semantically related images in different visual clusters by merging the result sets of multiple queries. Further research topics, such as achieving candidate queries' visual diversity, are also discussed. We also provide experimental results to demonstrate the effectiveness of our approach.	cluster hypothesis;content-based image retrieval;feature vector;relevance feedback	Xiangyu Jin;James C. French	2003	Multimedia Tools and Applications	10.1007/s11042-005-0453-5	computer vision;visual word;feature vector;image retrieval;computer science;data mining;automatic image annotation;information retrieval	Web+IR	-16.478233524641347	-58.626189271406226	194321
36054dbe7176672555a81e30fd4072957ae82b3e	a profile of today's sbml-compatible software	software tool;application software;systems biology;computer model;software systems;software standards systems biology bioinformatics computational systems biology data handling application software open source software software tools;software tools analytical models mathematical model software systems systems biology biological system modeling;specification languages;systems biology markup language;system biology;software package;specification languages bioinformatics data handling;computational systems biology;software standards;software tools;data handling sbml compatible software computational system software resource software package computational modeling systems biology markup language machine readable format software system bioinformatics;data handling;open source software;bioinformatics	Computational systems biologists today have a healthy selection of software resources to help them do research. Many software packages, especially those concerned with computational modeling, have adopted SBML (the Systems Biology Markup Language) as a machine-readable format to permit users to exchange models. Our group has a keen interest in understanding the landscape of SBML support. To help us ascertain the state of modern SBML-compatible software, in mid-2011 we initiated a survey of software packages that support SBML. Here we report the preliminary survey results. Based on 81 packages for which we have data so far, we summarize the trends in six areas: (1) What are the major types of functionality offered by the software systems? (2) What mathematical frameworks do they support? (3) What are their SBML-specific capabilities? (4) What other standards do they support besides SBML? (5) What are their characteristics with respect to run-time environments? And finally, (6) what are the availability and licensing terms?	human-readable medium;interoperability;markup language;minimum information required in the annotation of models;open-source software;sbml;software framework;software system;systems biology;testament	Michael Hucka;Frank T. Bergmann;Sarah M. Keating;Lucian P. Smith	2011	2011 IEEE Seventh International Conference on e-Science Workshops	10.1109/eScienceW.2011.28	computer science;theoretical computer science;software engineering	SE	-4.689744090205401	-60.32393028622103	194323
12a3abd9779fe123bd86e38e7dff44a33e298b21	dna modeller: an interactive program for modelling stacks of dna base pairs on a microcomputer	microordenador;modelizacion;image tridimensionnelle;computer program;base pairing;computerized processing;tratamiento informatico;dna bicatenaire;microordinateur;microcomputer;systeme conversationnel;modelisation;molecular parameter;double stranded dna;interactive system;ibm pc compatible;apareamiento base;appariement base;sistema conversacional;tridimensional image;dna bicatenario;parametro molecular;programa computador;modeling;traitement informatique;parametre moleculaire;base pair;programme ordinateur;langage turbopascal;imagen tridimensional	DNA Modeller is a microcomputer program for interactively manipulating up to 20 bp in a DNA double helical arrangement. It calculates the van der Waals and electrostatic energies of base-base interactions using the AMBER potential, minimizes the energy with respect to the pair (buckle, propeller, opening, shear, stretch, stagger) and step (tilt, roll, twist, shift, slide, rise) parameters, calculates lengths of the canonical hydrogen bonds between the complementary bases, and calculates interatomic distances between the successive base pairs. Input/output files are simple lists of the step and pair parameters or lists of the atom specifications (N1, C2, etc.) and their Cartesian coordinates (compatible with the Desktop Molecular Modeller*.mol files). The program is supplied with a readbrk utility which transforms PDB/NDB to the *.mol format readable by DNA Modeller. The DNA crystal structures deposited in the PDB or NDB databases can thus be analyzed, and their bases visualized and interactively manipulated. In addition, DNA Modeller can calculate the base pair and step geometrical parameters and interaction energies. A plotter utility creates wire mono or stereo pictures of the bases. This program is designed for IBM-compatible computers working under DOS or can run as a DOS application under MS Windows 3.x or Merge (SCO Unix DOS emulator).	assisted model building with energy refinement (amber);base pairing;computer;crystal structure;dna barcoding;dos;database;databases;distance;emulator;energy, physics;hydrogen;ibm pc compatible;inclusion body myositis (disorder);input/output;interaction;interactive computing;interactivity;modeller;microcomputer;microsoft windows;ndb cluster;picture;plotter device component;protein data bank;providing (action);specification;unix	J. Jursa	1994	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/10.1.61	biology;base pair;computer science;genetics;algorithm;computer graphics (images)	Comp.	-5.409368797903039	-57.00761981552697	194524
68f8dbae4e68daa7dec5776ab50a927c7e0f3c37	ag-mic: azure-based generalized flow for medical image classification	local medical image data sets azure based generalized flow ag mic medical image classification computational workload image analysis cloud based resources microsoft azure machine learning studio medical image based data analysis cloud based computing frameworks mamls binary classification multiclass learning multiclass regression feature selection model selection virtual machine bench marked flow feature ranking;machine learning algorithms;medical image processing cloud computing computerised tomography feature selection image classification learning artificial intelligence;biomedical imaging;computer architecture;data analysis;feature selection microsoft azure machine leaning medical image cloud computing hyper parameter search;predictive models;biomedical imaging cloud computing data models machine learning algorithms predictive models data analysis computer architecture;cloud computing;data models	Medical image-based research requires heavy computational workload associated with image analysis and collaborative device independent platforms to incorporate expert opinions from multiple institutions. Cloud-based resources such as Microsoft Azure Machine Learning Studio (MAMLS) provide such a platform that is conducive to the medical-image-based data analysis. This paper fosters the advantages of the cloud-based computing frameworks (such as MAMLS) and presents a practical work-flow well-suited for the standard machine learning tasks seen in medical image research viz., binary classification, multi-class learning, regression and so on. The proposed automated generalized workflow allows medical researchers/practitioners to focus on data inferencing rather than dealing with the intricate details of predictive modeling, such as feature and model selection. The scalable architecture of the proposed flow utilizes the MAMLS framework to processes data sets that require partial core storage space in the virtual machine to one complete core storage space in a common flow. Also, the proposed flow invokes multiple feature ranking and predictive models in parallel for automated selection and parameterization of the optimal data model. The performance of the proposed flow is bench-marked on 14 public data sets and four local medical image data sets (~0.12 MB-1.22 GB) using a single common flow, while ensuring better (~8% improvement) or atleast similar generalization capability with respect to existing works.	binary classification;cloud computing;core storage;data model;device independence;image analysis;information privacy;machine learning;map (parallel pattern);microsoft azure;model selection;predictive modelling;scalability;virtual machine;viz: the computer game	Sohini Roychowdhury;Matthew Bihis	2016	IEEE Access	10.1109/ACCESS.2016.2605641	medical imaging;data modeling;cloud computing;feature extraction;computer science;data science;operating system;machine learning;data mining;predictive modelling;data analysis;feature	ML	-8.984141553235101	-53.599602503618826	195039
afc56435bfdc2530b8a08da957e5c50c092cbf67	a data-flow modification of the muscle algorithm for multiprocessors and a web interface for it		Nucleotide and amino acid sequences research is actual for molecular biology and bioengineering. An important aspect of analysis of such sequences is multiple alignment. This article describes the implementations of the MUSCLE and ClustalW programs on multiprocessors and a web interface to them. The modification of the MUSCLE algorithm realize a data-flow manner of sequence alignment. It uses the PARUS system to build a data-flow graph and execute it on one multiprocessor. The data-flow algorithm has been tested on the sequences of human Long Terminal Repeats class five (LTR5) and several other examples.	algorithm;clustalw/clustalx;data-flow analysis;dataflow;muscle (alignment software);maximum flow problem;multiple sequence alignment;multiprocessing;user interface	Alexey N. Salnikov	2009		10.3233/978-1-60750-530-3-143	parallel computing;theoretical computer science;computer science;data flow diagram;distributed computing;user interface	Comp.	-4.547935660297949	-56.45802596301259	195076
7bf43e5f0fd43bc94f1d3a735f1fc18b08cd21ba	learning features from large-scale, noisy and social image-tag collection	visual semantic embedding;multimodal analysis;feature learning	Feature representation for multimedia content is the key to the progress of many fundamental multimedia tasks. Although recent advances in deep feature learning offer a promising route towards these tasks, they are limited in application to domains where high-quality and large-scale training data are hard to obtain. In this paper, we propose a novel deep feature learning paradigm based on large, noisy and social image-tag collections, which can be acquired from the inexhaustible social multimedia content on the Web. Instead of learning features from high-quality image-label supervision, we propose to learn from the image-word semantic relations, in a way of seeking a unified image-word embedding space, where the pairwise feature similarities preserve the semantic relations in the original image-word pairs. We offer an easy-to-use implementation for the proposed paradigm, which is fast and compatible for integrating into any state-of-the-art deep architectures. Experiments on NUSWIDE benchmark demonstrate that the features learned by our method significantly outperforms other state-of-the-art ones.	benchmark (computing);feature learning;programming paradigm;word embedding;world wide web	Hanwang Zhang;Xindi Shang;Huan-Bo Luan;Yang Yang;Tat-Seng Chua	2015		10.1145/2733373.2806286	feature learning;computer vision;computer science;data science;machine learning;pattern recognition;data mining;world wide web;feature	AI	-15.801505530909001	-65.55650468149899	195370
4d59b38521f3befc25aa4179a15186218dab3046	simulating biomolecules: festschrift to commemorate the 60th birthday of charles l. brooks iii				Jonathan D. Hirst;Wonpil Im;Joan-Emma Shea	2017	Journal of computational chemistry	10.1002/jcc.24790	biophysics;chemistry;computational chemistry	Crypto	-7.469244224230661	-55.5625969491709	196031
c086ceba742d0bfc6558e9e16cb77ba554901e21	verge: an interactive search engine for browsing video collections		This paper presents VERGE interactive video retrieval engine, which is capable of searching and browsing video content. The system integrates several content-based analysis and retrieval modules such as video shot segmentation and scene detection, concept detection, clustering and visual similarity search into a user friendly interface that supports the user in browsing through the collection, in order to retrieve the desired clip.	browsing;cluster analysis;digital video;similarity search;the verge;usability;web search engine	Anastasia Moumtzidou;Konstantinos Avgerinakis;Evlampios E. Apostolidis;Vera Aleksic;Fotini Markatopoulou;Christina Papagiannopoulou;Stefanos Vrochidis;Vasileios Mezaris;Reinhard Busch;Yiannis Kompatsiaris	2014		10.1007/978-3-319-04117-9_48	computer science;multimedia;world wide web;information retrieval	Vision	-15.346083680128832	-55.31052692030635	196047
8cba0534b8d1b9e89dd875e7c47f2ba552984e8c	e-commerce item recommendation based on field-aware factorization machine	gradient boosting decision tree;ensemble;top n recommendation;field aware factorization machine	The RecSys 2015 contest [1] seeks the best solution to a top-N e-commerce item recommendation problem. This paper describes the team Random Walker's approach to this challenge, which won the 3rd place in the contest. Our solution consists of the following components. Firstly, we cast the top-N recommendation task into a binary classification problem and extract original features from the raw data. Secondly, we learn derived features using field-aware factorization machines (FFM) and gradient boosting decision tree (GBDT). Lastly, we train 2 FFM models with different feature sets and combine them by a non-linear weighted blending. This solution is the result of numerous tests and the scheme turns out to be effective. Our final solution achieved a score of 61075.2, ranking in the third place on the public leaderboard.	alpha compositing;amiga walker;binary classification;decision tree;e-commerce;gradient boosting;nonlinear system;random walker algorithm;synapomorphy	Peng Yan;Xiaocong Zhou;Yitao Duan	2015		10.1145/2813448.2813511	ensembl;computer science;machine learning;pattern recognition;data mining;world wide web	AI	-18.29442414179267	-62.716675261538605	196575
c4072f2102a49aa7378f2da1f05c19a40ddc8ef5	using behavioral data to identify interviewer fabrication in surveys	curbstoning;data collection;supervised classification;behavioral data;hci4d;user logging;data quality;surveys	Surveys conducted by human interviewers are one of the principal means of gathering data from all over the world, but the quality of this data can be threatened by interviewer fabrication. In this paper, we investigate a new approach to detecting interviewer fabrication automatically. We instrument electronic data collection software to record logs of low-level behavioral data and show that supervised classification, when applied to features extracted from these logs, can identify interviewer fabrication with an accuracy of up to 96%. We show that even when interviewers know that our approach is being used, have some knowledge of how it works, and are incentivized to avoid detection, it can still achieve an accuracy of 86%. We also demonstrate the robustness of our approach to a moderate amount of label noise and provide practical recommendations, based on empirical evidence, on how much data is needed for our approach to be effective.	high- and low-level;machine learning;semiconductor device fabrication;sensor;supervised learning	Benjamin E. Birnbaum;Gaetano Borriello;Abraham D. Flaxman;Brian DeRenzi;Anna R. Karlin	2013		10.1145/2470654.2481404	data quality;computer science;data science;data mining;world wide web;data collection	HCI	-18.559426623342375	-53.79932512524384	196924
9ff979a5d334e0007b13b09c6b27cf28df05141c	max margin learning on domain-independent web information extraction	web data extraction;hierarchical structure;cutting plane;web pages;learning methods;belief propagation;structure prediction;approximate inference;max margin learning;loopy belief propagation;web information extraction	Domain-independent web information extraction can be addressed as a structured prediction problem where we learn a mapping function from an input web page to the structured and interdependent output variables, labeling each block on the page. In this paper, built upon an HTML parser of Internet Explorer that parses and renders a web page based on HTML tags and visual appearance, we propose a max margin learning approach for web information extraction. Specifically, the output of the parser is a vision tree, which is similar to a DOM tree but with visual information, i.e., how each node is displayed. Based on this hierarchical structure, we develop a max margin learning method for labeling each of its nodes. Due to the rich connections between blocks on the web page, we further introduce edges that connect spatially adjacent nodes on the vision tree, complicating the problem into a cyclic graph labeling task. A max margin learning method on cyclic graphs is developed for this problem, where loopy belief propagation is used for approximate inference. Experimental results on web data extraction show the feasibility and promise of our approach.	adaptive neuro fuzzy inference system;approximation algorithm;attribute–value pair;belief propagation;casio loopy;deep learning;graph labeling;html editor;hierarchical database model;ibm notes;information extraction;interdependence;internet explorer;rendering (computer graphics);software propagation;structured prediction;web page	Bin Zhao;Xiaoxin Yin;Eric P. Xing	2011		10.1145/2063576.2063765	natural language processing;computer science;artificial intelligence;machine learning;data mining;database;world wide web;information retrieval;belief propagation	AI	-13.25130276289483	-64.24944756016451	197957
d3366fce3084d4506e8f802c33b368927d789005	exploiting new sentiment-based meta-level features for effective sentiment analysis	meta features;sentiment analysis	In this paper we address the problem of automatically learning to classify the sentiment of short messages/reviews by exploiting information derived from meta-level features i.e., features derived primarily from the original bag-of-words representation. We propose new meta-level features especially designed for the sentiment analysis of short messages such as: (i) information derived from the sentiment distribution among the k nearest neighbors of a given short test document x, (ii) the distribution of distances of x to their neighbors and (iii) the document polarity of these neighbors given by unsupervised lexical-based methods. Our approach is also capable of exploiting information from the neighborhood of document x regarding (highly noisy) data obtained from 1.6 million Twitter messages with emoticons. The set of proposed features is capable of transforming the original feature space into a new one, potentially smaller and more informed. Experiments performed with a substantial number of datasets (nineteen) demonstrate that the effectiveness of the proposed sentiment-based meta-level features is not only superior to the traditional bag-of-word representation (by up to 16%) but is also superior in most cases to state-of-art meta-level features previously proposed in the literature for text classification tasks that do not take into account some idiosyncrasies of sentiment analysis. Our proposal is also largely superior to the best lexicon-based methods as well as to supervised combinations of them. In fact, the proposed approach is the only one to produce the best results in all tested datasets in all scenarios.	bag-of-words model;document classification;emoticon;experiment;feature vector;k-nearest neighbors algorithm;lexicon;sentiment analysis	Sérgio D. Canuto;Marcos André Gonçalves;Fabrício Benevenuto	2016		10.1145/2835776.2835821	computer science;machine learning;pattern recognition;data mining;world wide web;information retrieval;sentiment analysis	Web+IR	-18.998587001811977	-66.0150015226851	198012
97f7906f978ebba99382541b0e495e24074e2cf1	pic-a-topic: gathering information efficiently from recorded tv shows on travel	busqueda informacion;television;caption;user evaluation;equipement menager;domestic appliances;japonais;sous titrage;information retrieval;frase;digital tv;subtitulo;segmentation;table of contents;disco duro;hard disk;sentence;informational efficiency;recherche information;phrase;equipo domestico;japones;segmentacion;disque dur;japanese	We introduce a system called Pic-A-Topic, which analyses closed captions of Japanese TV shows on travel to perform topic segmentation and topic sentence selection. Our objective is to provide a table-of-contents interface that enables efficient viewing of desired topical segments within recorded TV shows to users of appliances such as hard disk recorders and digital TVs. According to our experiments using 14.5 hours of recorded travel TV shows, Pic-A-Topic’s F1-measure for the topic segmentation task is 82% of manual performance on average. Moreover, a preliminary user evaluation experiment suggests that this level of performance may be indistinguishable from manual performance.		Tetsuya Sakai;Tatsuya Uehara;Kazuo Sumita;Taishi Shimomori	2006		10.1007/11880592_33	computer vision;japanese;speech recognition;table of contents;computer science;artificial intelligence;operating system;database;multimedia;television;segmentation;computer security;information retrieval	NLP	-11.601553584137628	-62.503931881807695	198340
ff1b1f4d8e059311cf5aedbb95f9c1d6b325cb5a	a system for automatic broadcast news summarisation, geolocation and translation		An increasing amount of news content is produced in audiovideo form every day. To effectively analyse and monitoring this multilingual data stream, we require methods to extract and present audio content in accessible ways. In this paper, we describe an end-to-end system for processing and browsing audio news data. This fully automated system brings together our recent research on audio scene analysis, speech recognition, summarisation, named entity detection, geolocation, and machine translation. The graphical interface allows users to visualise the distribution of news content by entity names and story location. Browsing of news events is facilitated through extractive summaries and the ability to view transcripts in multiple languages.	browsing;end system;end-to-end encryption;geolocation;graphical user interface;machine translation;speech recognition	Peter Bell;Catherine Lai;Clare Llewellyn;Alexandra Birch;Mark Sinclair	2015			computer vision;telecommunications	NLP	-17.039774758518945	-56.3911764029005	198948
