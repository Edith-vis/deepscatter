id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
1a260d483c51fca6098158aa1dd876f6513371eb	feedback gmdh-type neural network self-selecting various functions and its application to medical image diagnosis of lung cancer	gmdh;cancer;input variables;lungs;lung;computer architecture;feedback loop;medical image processing;medical image diagnosis gmdh neural network;biological neural networks neurons feedback loop lungs input variables cancer computer architecture;medical image complexity feedback gmdh type neural network self selecting various functions medical image diagnosis lung cancer feedback group method data handling feedback gmdh type neural network algorithm feedback loops prediction error criterion akaike information criterion aic prediction sum of squares pss optimum neural network architecture;recurrent neural nets;neurons;recurrent neural nets cancer lung medical image processing;medical image diagnosis;biological neural networks;neural network	The feedback Group Method of Data Handling (GMDH) -type neural network algorithm is applied to the medical image diagnosis of lung cancer. In this feedback GMDH-type neural network algorithm, the structural parameters such as the number of feedback loops, the number of neurons in the hidden layers and the relevant input variables are automatically selected so as to minimize the prediction error criterion defined as Akaike's Information Criterion (AIC) or Prediction Sum of Squares (PSS). The identification results show that the feedback GMDH-type neural network algorithm is useful for the medical image diagnosis of lung cancer since the optimum neural network architecture is automatically organized so as to fit the complexity of the medical images.	akaike information criterion;algorithm;artificial neural network;backpropagation;feedback;group method of data handling;network architecture;physical symbol system;radiology;sigmoid function;software propagation	Tadashi Kondo;Junji Ueno;Shoichiro Takao	2012	2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing	10.1109/SNPD.2012.94	probabilistic neural network;computer science;artificial intelligence;machine learning;feedback loop;time delay neural network;artificial neural network;cancer	ML	12.92333446506693	-25.867076034308255	45747
3f5f986bdfbfcba4b97583861b7349fe0e996823	nonlinear partial least squares with hellinger distance for nonlinear process monitoring	measurement;computational modeling;monitoring;chemical;probability distribution;high definition video;predictive models;data models	This paper proposes an efficient data-based anomaly detection method that can be used for monitoring nonlinear processes. The proposed method merges advantages of nonlinear projection to latent structures (NLPLS) modeling and those of Hellinger distance (HD) metric to identify abnormal changes in highly correlated multivariate data. Specifically, the HD is used to quantify the dissimilarity between current NLPLS-based residual and reference probability distributions. The performances of the developed anomaly detection using NLPLS-based HD technique is illustrated using simulated plug flow reactor data.	anomaly detection;nonlinear programming;nonlinear system;open-source religion;partial least squares regression;performance;reactor (software);sensor	Fouzi Harrou;Muddu Madakyaru;Ying Sun	2016	2016 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2016.7849878	econometrics;pattern recognition;mathematics;statistics	Embedded	23.65869656422878	-24.04316731799036	45758
b7d4caf117d2ef15a43a7cb1775adfb53d63e79f	a comparative study of self-organizing clustering algorithms dignet and art2	simulation ordinateur;fast learning;unsupervised learning;gaussian noise;cluster algorithm;arquitectura red;algorithm analysis;detection signal;neural networks;dignet;learning;estudio comparativo;signal detection;art2;architecture reseau;aprendizaje;data clustering;etude comparative;apprentissage;deteccion senal;clustering;comparative study;statistical pattern recognition;pattern recognition;autoorganizacion;self organization;analyse algorithme;network architecture;simulacion computadora;reconnaissance forme;reseau neuronal;reconocimiento patron;signal to noise ratio;computer simulation;red neuronal;autoorganisation;analisis algoritmo;lower bound;adaptive resonance theory;neural network	"""A comparative study of two self-organizing clustering neural network algorithms, Dignet and ART2, has been conducted. The differences in architecture and learning procedures between the two models are compared. Comparative computer simulations on data clustering and signal detection problems with Gaussian noise were used for investigating the performance of Dignet and """"fast learning"""" ART2. The study shows that Dignet, with a simple architecture and straightforward dynamics, is more flexible with the choice of different metrics for the measure of similarity. The system parameters in Dignet can be analytically determined from a self-adjusting process; moreover, the initial threshold value used in Dignet is directly determined from a lower-bound of the desirable operational signal-to-noise ratio. Simulations show that Dignet generally exhibits faster learning and better clustering performance on statistical pattern recognition problems. A simplified ART2 model (SART2) is derived by adopting the structural concepts from Dignet. SART2 exhibits faster learning and eliminates a """"false conviction"""" problem that exists in the """"fast learning"""" ART2. The comparative study is benchmarked against statistical data clustering and signal detection problems. Copyright 1997 Elsevier Science Ltd."""	art1 gene;algorithm;artificial neural network;benchmark (computing);biological neural networks;cluster analysis;computer simulation;copyright;detection theory;exhibits as topic;noise-induced hearing loss;normal statistical distribution;organizing (structure);pattern recognition;self-organization;signal detection (psychology);signal-to-noise ratio;statistic (data);statistical cluster	Chin-Der Wann;Stelios C. A. Thomopoulos	1997	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(96)00084-6	simulation;computer science;artificial intelligence;machine learning;cluster analysis;artificial neural network	ML	11.459296989893689	-32.759032401759164	46040
722a5f1bc2b3b1e59b7b5cb2e6d9c05e14b38f02	a connectionist learning with high-order functional networks and its internal representation	hidden units;nonlinear mapping;history;neural networks;neural nets;computer architecture backpropagation feature extraction artificial intelligence artificial neural networks data mining computer science neural networks distributed processing history;extrema;distributed processing;training;connectionist learning;backpropagation;data mining;supervised neural network learning;curvatures;high order functional networks;input units;learning systems;computer architecture;artificial neural networks;internal representation;feature extraction;artificial intelligence;network architecture;nonlinear structures;computer science;functional unit;neural nets knowledge representation learning systems;knowledge representation;continuous mappings;back propagation;hidden units training connectionist learning high order functional networks internal representation supervised neural network learning network architecture continuous mappings input units back propagation nonlinear structures extrema curvatures;neural network	A novel architecture for supervised neural network learning is proposed. The necessary conditions of the network architecture for learning the structures of continuous mappings are obtained. The novel network architecture comprises high-order functional networks with some high-order functional units as input units. High-order functional networks trained with back-propagation can generalize and infer the highly nonlinear structures of the continuous mappings. The internal representation capability of the high-order functional networks is analyzed. Nonlinear mappings can be characterized by the features of their extrema and curvatures. The combination of the high order functional input units and the hidden units makes it possible to realize and learn a proper internal representation of the networks for extracting these features of the continuous mappings. On the basis of these internal representation capabilities, a methodology for determining the network architecture and parameters is proposed. >	connectionism	Akira Namatame	1989		10.1109/TAI.1989.65365	computer science;artificial intelligence;backpropagation;machine learning;pattern recognition;artificial neural network	ML	14.254076576123886	-29.9735190153641	46155
324fc9c732116fa81624faad07524039f193cede	an empirical exploration of recurrent network architectures		The Recurrent Neural Network (RNN) is an extremely powerful sequence model that is often difficult to train. The Long Short-Term Memory (LSTM) is a specific RNN architecture whose design makes it much easier to train. While wildly successful in practice, the LSTM’s architecture appears to be ad-hoc so it is not clear if it is optimal, and the significance of its individual components is unclear. In this work, we aim to determine whether the LSTM architecture is optimal or whether much better architectures exist. We conducted a thorough architecture search where we evaluated over ten thousand different RNN architectures, and identified an architecture that outperforms both the LSTM and the recently-introduced Gated Recurrent Unit (GRU) on some but not all tasks. We found that adding a bias of 1 to the LSTM’s forget gate closes the gap between the LSTM and the GRU.	hoc (programming language);long short-term memory;recurrent neural network	Rafal Józefowicz;Wojciech Zaremba;Ilya Sutskever	2015			simulation;artificial intelligence;machine learning	ML	17.335045111894274	-32.68370282581773	46178
5e35e3e3790bf29d0d4dc2ea766ac70b9e67c56b	finding needles in compressed haystacks	compressed learning;compressed sensing;image coding;support vector machines;sensors;support vector machines compressed sensing learning artificial intelligence signal classification;texture analysis compressed learning support vector machines delsarte goethals frames;delsarte goethals frames;support vector machines coherence compressed sensing vectors sensors image coding accuracy;linear dimensionality reduction technique compressed haystacks needles compressed domain learning problem linear kernel svm classifier probability linear threshold classifier data domain deterministic compressed sensing matrices texture analysis application measurement domain;accuracy;texture analysis;vectors;signal classification;coherence;learning artificial intelligence	In this paper, we investigate the problem of compressed learning, i.e. learning directly in the compressed domain. In particular, we provide tight bounds demonstrating that the linear kernel SVMs classifier in the measurement domain, with high probability, has true accuracy close to the accuracy of the best linear threshold classifier in the data domain. Furthermore, we indicate that for a family of well-known deterministic compressed sensing matrices, compressed learning is provided on the fly. Finally, we support our claims with experimental results in the texture analysis application.	compressed sensing;curse of dimensionality;data domain;dimensionality reduction;machine learning;model selection;on the fly;pattern recognition;with high probability	A. Robert Calderbank;Sina Jafarpour	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288656	support vector machine;speech recognition;coherence;computer science;sensor;machine learning;pattern recognition;mathematics;accuracy and precision;compressed sensing;statistics	Robotics	23.45979500598806	-37.09969679844391	46187
324acb08d73ebad775f784dae3434c43a898e46a	dropelm: fast neural network regularization with dropout and dropconnect	single hidden layer feedforward networks;dropconnect;regularization;extreme learning machine;dropout	In this paper, we propose an extension of the Extreme Learning Machine algorithm for Single-hidden Layer Feedforward Neural network training that incorporates Dropout and DropConnect regularization in its optimization process. We show that both types of regularization lead to the same solution for the network output weights calculation, which is adopted by the proposed DropELM network. The proposed algorithm is able to exploit Dropout and DropConnect regularization, without computationally intensive iterative weight tuning. We show that the adoption of such a regularization approach can lead to better solutions for the network output weights. We incorporate the proposed regularization approach in several recently proposed ELM algorithms and show that their performance can be enhanced without requiring much additional computational cost.		Alexandros Iosifidis;Anastasios Tefas;Ioannis Pitas	2015	Neurocomputing	10.1016/j.neucom.2015.04.006	regularization perspectives on support vector machines;regularization;mathematical optimization;computer science;machine learning;control theory	ML	15.99084382513735	-29.823755204842715	46331
284e1b9b2d7dda016a3f95fd323593d59e8d4e48	hidden semi-markov model for anomaly detection	segmental k means algorithm;analisis numerico;entropia;matematicas aplicadas;principio maximo;probability density;mathematiques appliquees;modelo markov;maximum entropy principle;analisis datos;loi probabilite;ley probabilidad;35b50;hidden markov model;anomaly detection;sistema informatico;hidden semi markov model;principe maximum;computer system;intrusion detection;analyse numerique;experimental result;algorithme;algorithm;data analysis;process monitoring;markov model;numerical analysis;probability distribution;entropie;resultado experimental;hidden semi markov model hsmm;analyse donnee;k means algorithm;systeme informatique;entropy;maximum principle;modele markov;information entropy;resultat experimental;applied mathematics;maximum entropy principle mep;intrusion detection system;training algorithm;algoritmo	In this paper, hidden semi-Markov model (HSMM) is introduced into intrusion detection. Hidden Markov model (HMM) has been applied in intrusion detection systems several years, but it has a major weakness: the inherent duration probability density of a state in HMM is exponential, which may be inappropriate for the modeling of audit data of computer systems. We can handle this problem well by developing an HSMM for perfect normal processes of computer systems. Based on this HSMM, an algorithm of anomaly detection is presented in this paper, which computes the distance between the processes monitored by intrusion detection system and the perfect normal processes. In this algorithm, we use the average information entropy (AIE) of fixed-length observed sequence as the anomaly detection metric based on maximum entropy principle (MEP). To improve accuracy, the segmental K-means algorithm is applied as training algorithm for the HSMM. By comparing the accurate rate with the experimental results of previous research, it shows that our method can perform a more accurate detection. 2008 Elsevier Inc. All rights reserved.	algorithm;anomaly detection;entropy (information theory);hidden semi-markov model;intrusion detection system;k-means clustering;markov chain;media-embedded processor;principle of maximum entropy;real-time computing;semiconductor industry;time complexity	Xiaobin Tan;Hongsheng Xi	2008	Applied Mathematics and Computation	10.1016/j.amc.2008.05.028	intrusion detection system;econometrics;entropy;anomaly detection;machine learning;mathematics;hidden markov model;statistics	Security	21.799777830223714	-26.16245509932029	46374
ad1c7047c0e4b9b680344907a2653150ce42b6ee	fast linearization of tree kernels over large-scale data	kernels w;reverse-kernel engineering;novel method;kernel engineering;approximate cutting plane training;explicit feature vector;fast linearization;convolution tree kernel;large-scale data;correct structural feature;efficient kernel;rich structured feature space	Convolution tree kernels have been successfully applied to many language processing tasks for achieving state-of-the-art accuracy. Unfortunately, higher computational complexity of learning with kernels w.r.t. using explicit feature vectors makes them less attractive for large-scale data. In this paper, we study the latest approaches to solve such problems ranging from feature hashing to reverse kernel engineering and approximate cutting plane training with model compression. We derive a novel method that relies on reverse-kernel engineering together with an efficient kernel learning method. The approach gives the advantage of using tree kernels to automatically generate rich structured feature spaces and working in the linear space where learning and testing is fast. We experimented with training sets up to 4 million examples from Semantic Role Labeling. The results show that (i) the choice of correct structural features is essential and (ii) we can speed-up training from weeks to less than 20 minutes.	approximation algorithm;baseline (configuration management);binary classification;central processing unit;computation;computational complexity theory;convolution;cutting-plane method;experiment;feature hashing;feature vector;high- and low-level;kernel (operating system);parsing;semantic role labeling;speedup;support vector machine;user space	Aliaksei Severyn;Alessandro Moschitti	2013			mathematical optimization;computer science;theoretical computer science;machine learning;tree kernel	AI	20.687355971259972	-37.94715327285773	46427
7d7d5d6c03703a8e23a5e10ab5e629afee9c2ed8	neural versus neurofuzzy systems for credit approval				Selwyn Piramuthu	1996			machine learning;artificial intelligence;computer science	Logic	10.453309170398288	-26.435683746099382	46526
249278150b773d9d53a7c5d07f3c46ab0b2b1d33	error estimation and model selection	model selection;error rate;error estimate	Machine learning algorithms search a space of possible hypotheses and estimate the error of each hypotheses using a sample. Most often, the goal of classification tasks is to find a hypothesis with a low true (or generalization) misclassification probability (or error rate); however, only the sample (or empirical) error rate can actually be measured and minimized. The true error rate of the returned hypothesis is unknown but can, for instance, be estimated using cross validation, and very general worst-case bounds can be given. This doctoral dissertation addresses a compound of questions on error assessment and the intimately related selection of a “good” hypothesis language, or learning algorithm, for a given problem. In the first part of this thesis, I present a new analysis of the generalization error of the hypothesis which minimizes the empirical error within a finite hypothesis language. I present a solution which characterizes the generalization error of the apparently best hypothesis in terms of the distribution of error rates of hypotheses in the hypothesis language. The distribution of error rates can, for any given problem, be estimated efficiently from the sample. Effectively, this analysis predicts how good the outcome of a learning algorithm would be without the learning algorithm actually having to be invoked. This immediately leads to an efficient algorithm for the selection of a good hypothesis language (or “model”). The analysis predicts (and thus explains) the shape of learning curves with a very high accuracy and thus contributes to a better understanding of the nature of over-fitting. I study the behavior of the model selection algorithm empirically (in particular, in comparison to cross validation) using both artificial problems and a large scale text categorization problem. In the next step, I study in which situations performing automatic model selection is actually beneficial; in particular, I study Occam algorithms and cross validation. Model selection techniques such as tree pruning, weight decay, or cross validation, are employed by virtually all “practical” learners and are generally believed to enhance the performance of learning algorithms. However, I show that this belief is equivalent to an assumption on the distribution of problems which the learning algorithm is exposed to. I specify these distributional assumptions and quantify the benefit of Occam algorithms and cross validations in these situations. When the distributional assumptions fail, cross-validation based model selection increases the generalization error of the returned hypothesis on average. When several distinct learners are assessed with respect to a particular problem (or one learner is assessed repeatedly with distinct parameter settings), an effect arises which is very similar to overfitting that occurs during error-minimization processes. The lowest observed error rate is an optimistic estimate of the corresponding generalization error. I quantify this bias. In particular, I study the bias which is imposed by repeated invocations of a learner with distinct parameter settings when n-fold cross validation is used to estimate the error rate. I pursue an information theoretic approach which does not require the assumption that empirical error rates measured in distinct cross validation folds are independent estimates. I discuss the implications of these results on the results of empirical studies which have been carried out in the past and propose an experimental setting which leads to almost unbiased results. Finally, I address complexity issues of model selection. In model selection based learning, the learning algorithm is restricted to a (small) model, chosen by the model selection algorithm. By contrast, in the boosting setting, the hypothesis is allowed to grow dynamically, often until the hypothesis is fitted to the data. By giving new worst-case time bounds for the AdaBoost algorithm I show that in many cases the restriction to small sets of hypotheses causes the high complexity of learning	adaboost;best, worst and average case;categorization;cross-validation (statistics);document classification;generalization error;human body weight;information theory;machine learning;model selection;overfitting;selection algorithm;occam	Tobias Scheffer	1999			error correction model;forecast error;coverage error;bayes error rate;mean integrated squared error	ML	19.05550847443284	-34.02497133555746	46532
70a7bf3b786d280c0ac1b8279ee9480235aea329	an integrated chaotic time series prediction model based on efficient extreme learning machine and differential evolution	reduced complete orthogonal decomposition;integrated parameter selection;differential evolution;efficient extreme learning machine;chaotic time series prediction	In this paper, an integrated model based on efficient extreme learning machine (EELM) and differential evolution (DE) is proposed to predict chaotic time series. In the proposed model, a novel learning algorithm called EELM is presented and used to model the chaotic time series. The EELM inherits the basic idea of extreme learning machine (ELM) in training single hidden layer feedforward networks, but replaces the commonly used singular value decomposition with a reduced complete orthogonal decomposition to calculate the output weights, which can achieve a much faster learning speed than ELM. Moreover, in order to obtain a more accurate and more stable prediction performance for chaotic time series prediction, this model abandons the traditional two-stage modeling approach and adopts an integrated parameter selection strategy which employs a modified DE algorithm to optimize the phase space reconstruction parameters of chaotic time series and the model parameter of EELM simultaneously based on a hybrid validation criterion. Experimental results show that the proposed integrated prediction model can not only provide stable prediction performances with high efficiency but also achieve much more accurate prediction results than its counterparts for chaotic time series prediction.	algorithm;benchmark (computing);common criteria;differential evolution;embedded system;feedforward neural network;heuristic;leo (computer);model selection;occam's razor;performance;random search;singular value decomposition;synthetic intelligence;time series	Wei Guo;Tao Xu;Zonglei Lu	2015	Neural Computing and Applications	10.1007/s00521-015-1903-2	differential evolution;mathematical optimization;computer science;artificial intelligence;machine learning	ML	12.313514689168775	-24.1918232327022	46549
e1478d432be7c3f9ad438231fd9f689a11775e4f	evolving reinforcement learning-like abilities for robots	continuous time;carga dinamica;reinforcement learning;temps continu;tiempo continuo;intelligence artificielle;robotics;charge dynamique;dynamic load;sinapsis;evolutionary robotics;apprentissage renforce;robotica;artificial intelligence;reseau neuronal recurrent;robotique;inteligencia artificial;recurrent neural networks;recurrent neural network;reseau neuronal;aprendizaje reforzado;red neuronal;embodied agent;neural network;synapse	In [8] Yamauchi and Beer explored the abilities of continuous time recurrent neural networks (CTRNNs) to display reinforcementlearning like abilities. The investigated tasks were generation and learning of short bit sequences. This “learning” came about without modifications of synaptic strengths, but simply from internal dynamics of the evolved networks. In this paper this approach will be extended to two embodied agent tasks, where simulated robots have acquire and retain “knowledge” while moving around different mazes. The evolved controllers are analyzed and the results are discussed.	artificial neural network;cognitive map;embodied agent;experiment;khepera mobile robot;recurrent neural network;reinforcement learning;robotics;simulation;situated;synaptic package manager;tracing (software)	Jesper Blynel	2003		10.1007/3-540-36553-2_29	simulation;computer science;artificial intelligence;recurrent neural network;machine learning;robotics;reinforcement learning;artificial neural network	Robotics	18.301466567262477	-23.96489144492509	46979
37351fd0394328e35759ae8b1bb632202b63789c	fractionally-supervised classification	weighted likelihood;fractionally supervised classification;discriminant analysis;model based classification;finite mixture models;model based clustering	Abstract: Traditionally, there are three species of classification: unsupervised, supervised, and semi-supervised. Supervised and semi-supervised classification differ by whether or not weight is given to unlabelled observations in the classification procedure. In unsupervised classification, or clustering, all observations are unlabeled and hence full weight is given to unlabelled observations. When some observations are unlabelled, it can be very difficult to a priori choose the optimal level of supervision, and the consequences of a sub-optimal choice can be non-trivial. A flexible fractionally-supervised approach to classification is introduced, where any level of supervision—ranging from unsupervised to supervised—can be attained. Our approach uses a weighted likelihood, wherein weights control the relative role that labelled and unlabelled data have in building a classifier. A comparison between our approach and the traditional species is presented using simulated and real data. Gaussian mixture models are used as a vehicle to illustrate our fractionally-supervised classification approach; however, it is broadly applicable and variations on the postulated model can be easily made.	cluster analysis;emoticon;machine learning;missing data;mixture model;optimization problem;programming paradigm;semi-supervised learning;semiconductor industry;statistical classification;supervised learning;unsupervised learning	Irene Vrbik;Paul D. McNicholas	2015	J. Classification	10.1007/s00357-015-9188-9	computer science;machine learning;linear classifier;pattern recognition;data mining;mathematics;linear discriminant analysis;one-class classification	ML	18.840379644617215	-36.30466436649184	47229
2a894be44d07a963c28893cc6f45d29fbfa872f7	strads: a distributed framework for scheduled model parallel machine learning	virtual machine;quantum;scheduler;multi core	Machine learning (ML) algorithms are commonly applied to big data, using distributed systems that partition the data across machines and allow each machine to read and update all ML model parameters --- a strategy known as data parallelism. An alternative and complimentary strategy, model parallelism, partitions the model parameters for non-shared parallel access and updates, and may periodically repartition the parameters to facilitate communication. Model parallelism is motivated by two challenges that data-parallelism does not usually address: (1) parameters may be dependent, thus naive concurrent updates can introduce errors that slow convergence or even cause algorithm failure; (2) model parameters converge at different rates, thus a small subset of parameters can bottleneck ML algorithm completion. We propose scheduled model parallelism (SchMP), a programming approach that improves ML algorithm convergence speed by efficiently scheduling parameter updates, taking into account parameter dependencies and uneven convergence. To support SchMP at scale, we develop a distributed framework STRADS which optimizes the throughput of SchMP programs, and benchmark four common ML applications written as SchMP programs: LDA topic modeling, matrix factorization, sparse least-squares (Lasso) regression and sparse logistic regression. By improving ML progress per iteration through SchMP programming whilst improving iteration throughput through STRADS we show that SchMP programs running on STRADS outperform non-model-parallel ML implementations: for example, SchMP LDA and SchMP Lasso respectively achieve 10x and 5x faster convergence than recent, well-established baselines.	algorithm;benchmark (computing);big data;converge;data parallelism;distributed computing;iteration;lasso;least squares;logistic regression;machine learning;parallel computing;scheduling (computing);sparse matrix;throughput;topic model;while	Jin Kyu Kim;Qirong Ho;Seunghak Lee;Xun Zheng;Wei Dai;Garth A. Gibson;Eric P. Xing	2016		10.1145/2901318.2901331	multi-core processor;quantum;computer science;virtual machine;theoretical computer science;operating system;machine learning;distributed computing;programming language	OS	19.408876975300434	-37.37535834492143	47352
78412dcea18e89da389fcbe36e9f9185914a1258	the extended piecewise quadratic neural network	non linear circuit;forme quadratique;neural networks;etude theorique;quadratic form;quadratic forms;circuit non lineaire;clasificador;forma cuadratica;conjugate gradient;classifier;synthetic test;prueba sintetica;estudio teorico;pattern recognition;classificateur;reconnaissance forme;essai synthetique;theoretical study;reseau neuronal;reconocimiento patron;circuito no lineal;red neuronal;non linear classifier;neural network	We present a new neural network for detection and classification problems that is capable of creating spherical, elliptical, hyperbolic and linear decision surfaces. This new classifier is called the extended piecewise quadratic neural network (E-PQNN) and uses complex-valued weights and a square-law non-linearity. We prove that our simple E-PQNN architecture is able to generate piecewise quadratic decision surfaces of arbitrary rank and we develop new methods for selecting the number of hidden-layer neurons in the E-PQNN. The weights are optimized using a modified perceptron error criterion and a conjugate gradient optimizer. We present results obtained for a synthetic problem.	artificial neural network;biological neural networks;conjugate gradient method;decision boundary;immunostimulating conjugate (antigen);mathematical optimization;nonlinear system;perceptron;synthetic intelligence;weight	David M. Weber;David Casasent	1998	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(98)00057-4	quadratic form;computer science;artificial intelligence;machine learning;mathematics;artificial neural network;algorithm	ML	13.95035305244228	-29.14323539671642	47440
1201cbc9dc0d8ecca46a418bf222ce5fbf01c354	neural network design and model reduction approach for black box nonlinear system identification with reduced number of parameters	nonlinear system identification;neural networks;black box;model reduction	In this paper a dedicated recurrent neural network design and a model reduction approach are proposed in order to improve the balance between complexity and quality of black box nonlinear system identification models. The proposed neural network design, based on a three-layers architecture, helps to reduce the number of parameters of the model after the training phase without any significant loss of estimation accuracy. Nevertheless, the proposed architecture remains sufficiently general to provide a wide range of models among the most encountered in the literature. This reduction, achieved by a convenient choice of the activation functions and the initial conditions of the synaptic weights, is developed in two steps. The first step is to train the proposed architecture under two reasonable assumptions. Then the recurrent three-layers neural network is transformed into a representation of two-layer with less number of neurons, that is, a significant reduced number of parameters. The constructed architecture provided models with reasonable reduced number of parameters with a convenient estimation accuracy. To validate the proposed approach, we identify the Wiener-Hammerstein benchmark nonlinear system proposed in SYSID2009 [1].	artificial neural network;black box;network planning and design;nonlinear system identification	Hector M. Romero Ugalde;Jean Claude Carmona;Victor M. Alvarado;Juan Reyes-Reyes	2013	Neurocomputing	10.1016/j.neucom.2012.08.013	black box;simulation;computer science;artificial intelligence;machine learning;nonlinear system identification;artificial neural network	EDA	18.217243635260004	-28.449488317666457	47457
878e600f32e80e4f54930656a32736fe120e12e4	second order cone programming formulations for handling data with perturbation	multi-class classification;robust support vector ordinal regression machine;second order cone programming	Ordinal regression problem and general multi-class classification problem are important and on-going research subject in machine learning. Support vector ordinal regression machine (SVORM) is an effective method for ordinal regression problem and has been used to deal with general multi-class classification problem. Up to now it is always assumed implicitly that the training data are known exactly . However, in practice, the training data subject to measurement noise. In this paper, we propose the robust versions of SVORM. Furthermore, we also propose a robust multi-class algorithm based on 3-class robust SVORM with Gaussian kernel for general multi-class classification problem with perturbation. The robustness of the proposed methods is validated by our preliminary numerical experiments.	algorithm;effective method;experiment;machine learning;multiclass classification;numerical analysis;ordinal data;ordinal regression;second-order cone programming	Zhixia Yang;Yingjie Tian	2010	JCIT		mathematical optimization;second-order cone programming;computer science	ML	21.50391961666352	-36.619895931996986	47465
99c5a215b1219825f7d087ffa593a7e5153b6a8f	parallel implementation of the givens rotations in the neural network learning algorithm		The paper describes a parallel feed-forward neural network training algorithm based on the QR decomposition with the use of the Givens rotation. The beginning brings a brief mathematical background on Givens rotation matrices and elimination step. Then the error criterion and its necessary transformations for the QR decomposition are presented. The paper’s core holds an essential explanation to accomplish hardware-based parallel implementation. The paper concludes with a theoretical description of speed improvement gained by parallel implementation of the Givens reduction in the QR decomposition process.	algorithm;artificial neural network;feedforward neural network;givens rotation;qr decomposition	Jaroslaw Bilski;Bartosz Kowalczyk;Jacek M. Zurada	2017		10.1007/978-3-319-59063-9_2	artificial intelligence;machine learning;computer science;theoretical computer science;feedforward neural network;artificial neural network;qr decomposition;givens rotation;matrix (mathematics);algorithm	ML	16.259384850976474	-28.231818881040432	47865
211f0c9b86c60039f7843821cadaf5cdce7058c6	exchange rate forecasting: comparison of various architectures of neural networks	experimental design;forecasting;prediccion;intercambio informacion;radial basis function rbf;calcul neuronal;arquitectura red;neural computation;prevision;62m10;62m20;multilayer perceptrons;fonction base radiale;plan experiencia;neural net architecture;62m45;time series;architecture reseau;trading strategy;perceptron multicouche;simulation experiment;radial basis function;forecasting theory;plan experience;echange information;information exchange;multi layer perceptron mlp;serie temporelle;architecture reseau neuronal;prediction accuracy;serie temporal;theorie prevision;taux change;exchange rate;multi layer perceptron;network architecture;reseau neuronal;funcion radial base;rbf network;prediction;red neuronal;computacion neuronal;neuron;tasa cambio;exchange rate series;neural network;predictive accuracy	This paper evaluates the predictive accuracy of neural networks in forecasting exchange rate. The multi-layer perceptron (MLP) and radial basis function (RBF) networks with different architectures are used to forecast five exchange rate time series. The results of each prediction are evaluated and compared according to the networks and architectures used. It is found that neural networks can be effectively used in forecasting exchange rate and hence in designing trading strategies. RBF networks performed better than MLP networks in our simulation experiment. This experiment suggests that it is possible to extract information hidden in the exchange rate and predict it into future.	higher-order function;memory-level parallelism;multilayer perceptron;neural networks;nonlinear system;quad flat no-leads package;radial (radio);radial basis function network;simulation;time series	Arnav Dhamija;V. K. Bhalla	2010	Neural Computing and Applications	10.1007/s00521-010-0385-5	radial basis function;simulation;network architecture;information exchange;prediction;forecasting;computer science;artificial intelligence;trading strategy;machine learning;time series;multilayer perceptron;design of experiments;artificial neural network;statistics;models of neural computation	ML	11.34187353440824	-29.129240196555248	47889
b554ce2482ff2712770e2cc9de8886104fb4cff2	sign-based learning schemes for pattern classification	feed forward neural network;supervised learning;rprop;nonlinear iterative methods;subminimization;simulation experiment;feed forward neural networks;nonlinear jacobi;pattern classification;iteration method;theoretical foundation;training algorithm;jacobi method;neural network	This paper introduces a new class of sign-based training algorithms for neural networks that combine the sign-based updates of the Rprop algorithm with the composite nonlinear Jacobi method. The theoretical foundations of the class are described and a heuristic Rprop-based Jacobi algorithm is empirically investigated through simulation experiments in benchmark pattern classification problems. Numerical evidence shows that this new modification of the Rprop algorithm exhibits improved learning speed in all cases tested, and compares favorably against the Rprop and a recently proposed modification, the improved Rprop. 2005 Elsevier B.V. All rights reserved.	algorithm;approximation;artificial neural network;benchmark (computing);bisection method;broyden–fletcher–goldfarb–shanno algorithm;experiment;heuristic;heuristic (computer science);jacobi method;nonlinear system;numerical method;pattern recognition;rprop;simulation;statistical classification	Aristoklis D. Anastasiadis;George D. Magoulas;Michael N. Vrahatis	2005	Pattern Recognition Letters	10.1016/j.patrec.2005.03.013	rprop;feedforward neural network;mathematical optimization;jacobi method;computer science;theoretical computer science;machine learning;pattern recognition;iterative method;supervised learning;artificial neural network	AI	16.257270440688195	-29.26346739909251	48053
3f5ffa762d2b4f1d53737f4be865d8405099fc25	image compression using a multilayer neural network	modelizacion;image processing;data compression;procesamiento imagen;traitement image;algorithme;modelisation;algorithm;image compression;pattern recognition;compresion dato;reconnaissance forme;reseau neuronal;reconocimiento patron;modeling;multilayer neural network;red neuronal;compression donnee;neural network;algoritmo	A property of neural networks is their ability to construct feature detectors as a result of supervised or unsupervised training. We demonstrate that a class of neural networks which produces topographic mappings [1] may be used to data compress SAR images. In Section II we summarise Kohonen's network learning algorithm, and we present an improved version of the algorithm in Section III. In Section IV we generalise the method to multilayer mappings and indicate how such networks might be implemented as table look-up operations. In Section V we apply such a multilayer network to the problem of data compressing SAR images.	algorithm;artificial neural network;data compression;feature vector;high- and low-level;image compression;image processing;lookup table;multilayer perceptron;sensor;springer (tank);supervised learning;teuvo kohonen;topography;unsupervised learning	Stephen P. Luttrell	1989	Pattern Recognition Letters	10.1016/0167-8655(89)90011-1	data compression;computer vision;systems modeling;image processing;image compression;computer science;artificial intelligence;machine learning;algorithm	ML	10.806565663528263	-30.279212358395846	48267
8b71375ac2e8a83020ad96fca043e99e511c1c23	learning rate of magnitude-preserving regularization ranking with dependent samples	learning rate;magnitude preserving regularization ranking;dependent samples	The generalization analysis is key to understand the theoretical foundation of learning to rank. However, the previous works for this subject are usually based on independent and identical distributed (i.i.d) samples. In this paper, we go beyond this restriction by investigating the generalization ability of magnitude-preserving regularization ranking (MPRank) with dependent samples. For the MPRank, we establish its upper bound for the excess ranking risk which demonstrates the satisfactory learning rate can be reached for dependent samples.	matrix regularization	Hong Chen	2016	IJWMIP	10.1142/S0219691316500016	mathematical optimization;machine learning;mathematics;statistics;generalization error	Crypto	21.262392726249455	-33.51604695626184	48330
25098861749fe9eab62fbe90c1ebeaed58c211bb	boosting as a regularized path to a maximum margin classifier	high dimensionality;support vector machines;boosting;regularized optimization;space use;margin maximization;support vector machine	In this paper we study boosting methods from a new perspective. We build on recent work by Efron et al. to show that boosting approximately (and in some cases exactly) minimizes its loss criterion with an l1 constraint on the coefficient vector. This helps understand the success of boosting with early stopping as regularized fitting of the loss criterion. For the two most commonly used criteria (exponential and binomial log-likelihood), we further show that as the constraint is relaxed—or equivalently as the boosting iterations proceed—the solution converges (in the separable case) to an “l1-optimal” separating hyper-plane. We prove that this l1-optimal separating hyper-plane has the property of maximizing the minimal l1-margin of the training data, as defined in the boosting literature. An interesting fundamental similarity between boosting and kernel support vector machines emerges, as both can be described as methods for regularized optimization in high-dimensional predictor space, using a computational trick to make the calculation practical, and converging to margin-maximizing solutions. While this statement describes SVMs exactly, it applies to boosting only approximately.	adaboost;approximation algorithm;boosting (machine learning);coefficient;constrained optimization;converge;dictionary;early stopping;entropy maximization;generalization error;global serializability;greedy algorithm;iteration;kerrison predictor;large margin nearest neighbor;line search;manifold regularization;margin classifier;mathematical optimization;matrix regularization;overfitting;signal-to-noise ratio;slack variable;support vector machine;time complexity	Saharon Rosset;Ji Zhu;Trevor J. Hastie	2004	Journal of Machine Learning Research		margin classifier;support vector machine;brownboost;mathematical optimization;computer science;machine learning;pattern recognition;mathematics;gradient boosting	ML	22.358551775156943	-34.99328841525963	48333
5b5edbb44412a3e9fdf9d6eecb79e539cbda05de	improved adaline networks for robust pattern classification		The Adaline network [1] is a classic neural architecture whose learning rule is the famous least mean squares (LMS) algorithm (a.k.a. delta rule or Widrow-Hoff rule). It has been demonstrated that the LMS algorithm is optimal in H∞ sense since it tolerates small (in energy) disturbances, such as measurement noise, parameter drifting and modelling errors [2,3]. Such optimality of the LMS algorithm, however, has been demonstrated for regression-like problems only, not for pattern classification. Bearing this in mind, we firstly show that the performances of the LMS algorithm and variants of it (including the recent Kernel LMS algorithm) in pattern classification tasks deteriorates considerably in the presence of labelling errors, and then introduce robust extensions of the Adaline network that can deal efficiently with such errors. Comprehensive computer simulations show that the proposed extension consistently outperforms the original version.	adaline;algorithm;binary classification;computer simulation;delta rule;experiment;learning rule;least mean squares filter;nonlinear system;pattern recognition;performance;statistical classification	César Lincoln C. Mattos;José Daniel A. Santos;Guilherme De A. Barreto	2014		10.1007/978-3-319-11179-7_73	computer science;artificial intelligence;machine learning;algorithm;statistics	ML	18.141251382474984	-37.19727219436062	48377
11f37958af8c236f42038caa314c4dc456a10c8d	a two-stage pretraining algorithm for deep boltzmann machines	deep learning;deep boltzmann machine;pretraining	A deep Boltzmann machine (DBM) is a recently introduced Markov random field model that has multiple layers of hidden units. It has been shown empirically that it is difficult to train a DBM with approximate maximum-likelihood learning using the stochastic gradient unlike its simpler special case, restricted Boltzmann machines (RBM). In this paper, we propose a novel pretraining algorithm that consists of two stages; obtaining approximate posterior distributions over hidden units from a simpler model and maximizing the variational lower-bound given the fixed hidden posterior distributions. We show empirically that the proposed method overcomes the difficulty in training DBMs from randomly initialized parameters and results in a better, or comparable, generative model when compared to the conventional pretraining algorithm.	approximation algorithm;calculus of variations;dbm;deep learning;generative model;gradient;hierarchical database model;machine learning;markov chain;markov random field;randomness;restricted boltzmann machine;variational method (quantum mechanics);variational principle	Kyunghyun Cho;Tapani Raiko;Alexander Ilin;Juha Karhunen	2013		10.1007/978-3-642-40728-4_14	boltzmann machine;computer science;artificial intelligence;machine learning;pattern recognition;deep learning;restricted boltzmann machine	ML	24.419424152214816	-30.76011627278633	48394
d132576aa682e1ea9ac76404bfdeebe3d0aa3593	sparse basis pursuit on automatic nonlinear circuit modeling	abstracts measurement uncertainty object recognition	In this paper, we propose a black-box nonlinear dynamic modeling algorithm that automatically selects essential basis functions to overcome the overfitting problem. Our automatic modeling algorithm, which is formulated as a convex optimization problem, guarantees model stability in transient simulation. Furthermore, we incorporate our algorithm with a sparsity induction mechanism, which improves model robustness and generalization capabilities, as shown in our example.	algorithm;basis function;basis pursuit;black box;convex optimization;inductive reasoning;mathematical optimization;nonlinear system;optimization problem;overfitting;simulation;sparse matrix	Yu-Chung Hsiao;Luca Daniel	2013	2013 IEEE 10th International Conference on ASIC	10.1109/ASICON.2013.6811858	mathematical optimization;computer science;theoretical computer science;machine learning	Robotics	22.910103926694642	-28.904938032025374	48406
304b797039e9046d964194f7cfbab38ce589d9e8	active learning for data streams under concept drift and concept evolution		Data streams classification is an important problem however, poses many challenges. Since the length of the data is theoretically infinite, it is impractical to store and process all the historical data. Data streams also experience change of its underlying distribution (concept drift), thus the classifier must adapt. Another challenge of data stream classification is the possible emergence and disappearance of classes which is known as (concept evolution) problem. On the top of these challenges, acquiring labels with such large data is expensive. In this paper, we propose a stream-based active learning (AL) strategy (SAL) that handles the aforementioned challenges. SAL aims at querying the labels of samples which results in optimizing the expected future error. It handles concept drift and concept evolution by adapting to the change in the stream. Furthermore, as a part of the error reduction process, SAL handles the sampling bias problem and queries the samples that caused the change i.e., drifted samples or samples coming from new classes. To tackle the lack of prior knowledge about the streaming data, non-parametric Bayesian modelling is adopted namely the two representations of Dirichlet process; Dirichlet mixture models and stick breaking process. Empirical results obtained on real-world benchmarks show the high performance of the proposed SAL method compared to the state-of-the-art methods.	active learning (machine learning);algorithm;bayesian network;concept drift;emergence;evolution;mixture model;pointing stick;sampling (signal processing);stream (computing);unbalanced circuit	Saad Mohamad;Moamar Sayed Mouchaweh;Abdelhamid Bouchachia	2016			machine learning;computer science;data mining;active learning;concept drift;artificial intelligence;data stream mining	AI	14.901160711072617	-37.88816171969687	48421
6a8227c948852810427e9250dddf715a6e0ed08f	conditional probability calculation using restricted boltzmann machine with application to system identification		There are many advantages to use probability method for nonlinear system identification, such as the noises and outliers in the data set do not affect the probability models significantly; the input features can be extracted in probability forms. The biggest obstacle of the probability model is the probability distributions are not easy to be obtained. In this paper, we form the nonlinear system identification into solving the conditional probability. Then we modify the restricted Boltzmann machine (RBM), such that the joint probability, input distribution, and the conditional probability can be calculated by the RBM training. Binary encoding and continue valued methods are discussed. The universal approximation analysis for the conditional probability based modelling is proposed. We use two benchmark nonlinear systems to compare our probability modelling method with the other black-box modeling methods. The results show that this novel method is much better when there are big noises and the system dynamics are complex.		Erick De la Rosa;Wen Yu	2018	CoRR		probability distribution;mathematical optimization;mathematics;conditional probability;outlier;joint probability distribution;system identification;nonlinear system identification;nonlinear system;restricted boltzmann machine	ML	24.461424702241324	-29.885280370856822	48436
4d5152686b8f4f7ee185ae0322c01f8757537788	fast convergent generalized back-propagation algorithm with constant learning rate	simulation ordinateur;gradient descent method;feedforward neural network;traitement signal;eficacia sistema;feedforward neural networks;learning rate;learning algorithm;convergence;feedforward;learning;activation function;gradient method;ordinary differential equation;performance systeme;constant learning rate;convergence rate;algorithme apprentissage;backpropagation;boucle anticipation;system performance;aprendizaje;methode gradient;retropropagation;convergencia;apprentissage;ciclo anticipacion;estimation erreur;metodo gradiente;gradient descent;error estimation;signal processing;estimacion error;back propagation algorithm;simulacion computadora;reseau neuronal;generalized back propagation;local minima;algoritmo aprendizaje;procesamiento senal;retropropagacion;computer simulation;back propagation;red neuronal;gradient descent algorithm;neural network	The conventional back-propagation algorithm is basically a gradient-descent method, it has the problems of local minima and slow convergence. A new generalized back-propagation algorithm which can effectively speed up the convergence rate and reduce the chance of being trapped in local minima is introduced. The new back-propagation algorithm is to change the derivative of the activation function so as to magnify the backward propagated error signal, thus the convergence rate can be accelerated and the local minimum can be escaped. In this letter, we also investigate the convergence of the generalized back-propagation algorithm with constant learning rate. The weight sequences in generalized back-propagation algorithm can be approximated by a certain ordinary differential equation (ODE). When the learning rate tends to zero, the interpolated weight sequences of generalized back-propagation converge weakly to the solution of associated ODE.	activation function;approximation algorithm;backpropagation;converge;gradient descent;interpolation;local convergence;maxima and minima;network topology;propagation of uncertainty;rate of convergence;simulation;software propagation	Sin Chun Ng;Shu Hung Leung;Andrew Luk	1999	Neural Processing Letters	10.1023/A:1018611626332	computer simulation;gradient descent;mathematical optimization;computer science;artificial intelligence;machine learning;signal processing;mathematics;artificial neural network	ML	16.865128830650562	-28.345130063635185	48562
9917803c59896979356e62b3621aa86c25c7f0dc	deep learning in spiking neural networks		In recent years, deep learning has revolutionized the field of machine learning, for computer vision in particular. In this approach, a deep (multilayer) artificial neural network (ANN) is trained in a supervised manner using backpropagation. Vast amounts of labeled training examples are required, but the resulting classification accuracy is truly impressive, sometimes outperforming humans. Neurons in an ANN are characterized by a single, static, continuous-valued activation. Yet biological neurons use discrete spikes to compute and transmit information, and the spike times, in addition to the spike rates, matter. Spiking neural networks (SNNs) are thus more biologically realistic than ANNs, and arguably the only viable option if one wants to understand how the brain computes. SNNs are also more hardware friendly and energy-efficient than ANNs, and are thus appealing for technology, especially for portable devices. However, training deep SNNs remains a challenge. Spiking neurons’ transfer function is usually non-differentiable, which prevents using backpropagation. Here we review recent supervised and unsupervised methods to train deep SNNs, and compare them in terms of accuracy, but also computational cost and hardware friendliness. The emerging picture is that SNNs still lag behind ANNs in terms of accuracy, but the gap is decreasing, and can even vanish on some tasks, while SNNs typically require many fewer operations.		Amirhossein Tavanaei;Masoud Ghodrati;Saeed Reza Kheradpisheh;Timothée Masquelier;Anthony S. Maida	2018	CoRR	10.1016/j.neunet.2018.12.002	machine learning;mathematics;deep learning;transfer function;artificial neural network;spiking neural network;backpropagation;artificial intelligence;neuromorphic engineering	ML	18.313442894144444	-31.654994872013457	48875
4edc0ae121a9bc9e0127fe397e001cf72a8d054c	an equivalence between the lasso and support vector machines		We investigate the relation of two fundamental tools in machine learning, that is the support vector machine (SVM) for classification, and the Lasso technique used in regression. We show that the resulting optimization problems are equivalent, in the following sense: Given any instance of an l2-loss softmargin (or hard-margin) SVM, we construct a Lasso instance having the same optimal solutions, and vice versa. In consequence, many existing optimization algorithms for both SVMs and Lasso can also be applied to the respective other problem instances. Also, the equivalence allows for many known theoretical insights for SVM and Lasso to be translated between the two settings. One such implication gives a simple kernelized version of the Lasso, analogous to the kernels used in the SVM setting. Another consequence is that the sparsity of a Lasso solution is equal to the number of support vectors for the corresponding SVM instance, and that one can use screening rules to prune the set of support vectors. Furthermore, we can relate sublinear time algorithms for the two problems, and give a new such algorithm variant for the Lasso.	artificial neural network;basis pursuit;computation;computational biology;convex optimization;coreset;entity–relationship model;frank–wolfe algorithm;international conference on machine learning;international standard book number;iterative method;journal of machine learning research;kernel method;lasso;mathematical optimization;microarray;nips;neural networks;regular expression;slot 1;sparse approximation;sparse matrix;supervised learning;support vector machine;symposium on computational geometry;symposium on foundations of computer science;time complexity;turing completeness;universal quantification	Martin Jaggi	2013	CoRR		machine learning;pattern recognition;data mining;mathematics	ML	21.582164207445693	-37.50988023142398	48943
d35015f6f99fd5baba8d4a86a95d0b57a6cb3075	learning rule for linear multilayer feedforward ann by boosted decision stumps		A novel method for learning a linear multilayer feedforward artificial neural network (ANN) by using ensembles of boosted decision stumps is presented. Network parameters are adapted through a layer-wise iterative traversal of neurons with weights of each neuron learned by using a boosting based ensemble and an appropriate reduction. Performances of several neural network models using the proposed method are compared for a variety of datasets with networks learned using three other algorithms, namely Perceptron learning rule, gradient decent back propagation algorithm, and Boostron learning.	feed forward (control);learning rule	Mubasher Baig;El-Sayed M. El-Alfy;Mian M. Awais	2015		10.1007/978-3-319-26532-2_38	boosting (machine learning);machine learning;perceptron;artificial intelligence;artificial neural network;tree traversal;feed forward;pattern recognition;gradient descent;backpropagation;computer science;learning rule	ML	14.632729076352549	-28.022831381977216	48966
f580b0e1020ad67bdbb11e8d99a59c21a8df1e7d	compressed sensing using generative models		The goal of compressed sensing is to estimate a vector from an underdetermined system of noisy linear measurements, by making use of prior knowledge on the structure of vectors in the relevant domain. For almost all results in this literature, the structure is represented by sparsity in a well-chosen basis. We show how to achieve guarantees similar to standard compressed sensing but without employing sparsity at all. Instead, we suppose that vectors lie near the range of a generative model G : R → R. Our main theorem is that, if G is L-Lipschitz, then roughly O(k logL) random Gaussian measurements suffice for an `2/`2 recovery guarantee. We demonstrate our results using generative models from published variational autoencoder and generative adversarial networks. Our method can use 5-10x fewer measurements than Lasso for the same accuracy.	autoencoder;compressed sensing;generative adversarial networks;generative model;lasso;sparse matrix;variational principle;vector graphics	Ashish Bora;Ajil Jalal;Eric Price;Alexandros G. Dimakis	2017			mathematical optimization;machine learning;pattern recognition;mathematics;statistics	ML	23.054782195501158	-32.599746457186306	49042
128537467165b8f2911111020773e36209fbc654	binary embeddings with structured hashed projections		We consider the hashing mechanism for constructing binary data embeddings, that involves pseudo-random projections followed by nonlinear (sign function) mappings. The pseudo-random projection is described by a matrix, where not all entries are independent random variables but instead a fixed “budget of randomness” is distributed across the matrix. Such matrices can be efficiently stored in sub-quadratic or even linear space, provide reduction in randomness usage (i.e. number of required random values), and very often lead to computational speed ups. We prove several theoretical results showing that projections via various structured matrices followed by nonlinear mappings accurately preserve the angular distance between input high-dimensional vectors. To the best of our knowledge, these results are the first that give theoretical ground for the use of general structured matrices in the nonlinear setting. Thus, they significantly generalize previous extensions of the Johnson-Lindenstrauss lemma and prove the plausibility of the approach that was so far only heuristically confirmed for some special structured matrices. Consequently, we show that many structured matrices can be used as an efficient information compression mechanism. Our findings also build a better understanding of certain deep architectures, which contain randomly weighted and untrained layers, and yet achieve high performance on different learning tasks. We are interested in how the action of random projection followed by non-linear transformation Equal contribution. may influence learning. We empirically verify our theoretical findings and show the dependence of learning via structured hashed projections on the network performance.	angularjs;binary data;computation;heuristic;network performance;nonlinear system;plausibility structure;pseudorandomness;random projection;randomness;the matrix	Anna Choromanska;Krzysztof Choromanski;Mariusz Bojarski;Tony Jebara;Sanjiv Kumar;Yann LeCun	2016			combinatorics;discrete mathematics;theoretical computer science;machine learning;mathematics;statistics	ML	18.8838993745182	-30.16869440594909	49048
0bdf823f37936ff42cfa543795c47da5f38b113b	a maximum partial entropy-based method for multiple-instance concept learning	instance-based learning;multiple instance learning;machine learning;weakly supervised learning;data mining;concept learning;partial entropy;knowledge extraction	Multiple instance (MI) learning aims at identifying the underlying concept from collectively labeled data. A training sample consists of a set, known as a bag, of unlabelled instances. The bag as a whole is labeled positive if at least one instance in the bag is positive, or negative otherwise. Given such training samples, the goal is to learn a description of the common instance(s) among the positive bags, i.e., the underlying concept that is responsible for the positive label. In this work, we introduce a learning scheme based on the notion of partial entropy for MI concept learning. Partial entropy accentuates the intra-class information by focusing on the information reflected from the positive class in proportion to the total entropy, maximization of which is to equalize the likelihoods of intra-class outcomes among the positive class, essentially reflecting the intended concept. When coupled with a distance-based probabilistic model for MI learning, it is equivalent to seeking out a concept estimate that equalizes the intra-class distances while the distance to negative bags is restrained. It produces patterns that are similar to at least one instance from each of the positive bags while dissimilar from all instances in negative bags. The generated patterns from the optimization process correspond to prototypical concepts. Maximum partial entropy is conceptually simple and experimental results on different MI datasets demonstrate its effectiveness in learning an explicit representation of the concept and its competitive performance when applied to classification tasks.	black box;concept learning;entropy maximization;expectation–maximization algorithm;hp multi-programming executive;mathematical optimization;statistical model;supervised learning;test set	Tao Xu;Iker Gondra;David K. Y. Chiu	2016	Applied Intelligence	10.1007/s10489-016-0873-0	artificial intelligence;machine learning;pattern recognition	AI	17.35918126413784	-37.715209423829634	49062
9870173dbe584bdb706697335ad36349bbdcfa9e	lp approximation of sigma-pi neural networks	lp norm;indexing terms;function approximation;neural networks feedforward neural networks terminology mathematics sufficient conditions polynomials;l sup p locally integrable function l sup p approximation sigma pi neural networks single hidden layer;integral functional;function approximation feedforward neural nets;feedforward neural nets;neural network	A feedforward Sigma-Pi neural network with a single hidden layer of m neurons is given by mSigma(j=1) cjg (nPi(k=1) xk-thetak(j)/lambdak(j)) where cj, thetak(j), lambdak are elements of R. In this paper, we investigate the approximation of arbitrary functions f: Rn-->R by a Sigma-Pi neural network in the Lp norm. An Lp locally integrable function g(t) can approximate any given function, if and only if g(t) can not be written in the form Sigma(j=1)n Sigma(k=0)m alphajk(ln/t/)(j-1)tk.	approximation algorithm;artificial neural network;biological neural networks;feedforward neural network;neural network simulation	Yue-Hu Luo;Shi-Yi Shen	2000	IEEE transactions on neural networks	10.1109/72.883481	index term;function approximation;computer science;machine learning;control theory;mathematics;lp space;artificial neural network	ML	18.03060571740024	-28.97775158713156	49340
c068e416333cec41835c4b0ffce4ed4e52b1ba10	hopfield neural network for scheduling non pre-emptive tasks			hopfield network;scheduling (computing)	Jean-Michel Gallone;François Charpillet	1996			artificial intelligence;bidirectional associative memory;probabilistic neural network;machine learning;artificial neural network;computer science;scheduling (computing);recurrent neural network;hopfield network;time delay neural network	Robotics	12.662396369377161	-26.959710510130016	49548
08197632189f8aec3a7b63894609cadbe5ed02a5	large-scale multi-label learning with missing labels		The multi-label classification problem has generated significant interest in recent years. However, existing approaches do not adequately address two key challenges: (a) the ability to tackle problems with a large number (say millions) of labels, and (b) the ability to handle data with missing labels. In this paper, we directly address both these problems by studying the multi-label problem in a generic empirical risk minimization (ERM) framework. Our framework, despite being simple, is surprisingly able to encompass several recent label-compression based methods which can be derived as special cases of our method. To optimize the ERM problem, we develop techniques that exploit the structure of specific loss functions such as the squared loss function to offer efficient algorithms. We further show that our learning framework admits formal excess risk bounds even in the presence of missing labels. Our risk bounds are tight and demonstrate better generalization performance for low-rank promoting trace-norm regularization when compared to (rank insensitive) Frobenius norm regularization. Finally, we present extensive empirical results on a variety of benchmark datasets and show that our methods perform significantly better than existing label compression based methods and can scale up to very large datasets such as the Wikipedia dataset.	algorithm;benchmark (computing);emoticon;empirical risk minimization;loss function;matrix multiplication;matrix regularization;multi-label classification;offset binary;wikipedia	Hsiang-Fu Yu;Prateek Jain;Inderjit S. Dhillon	2014			econometrics;machine learning;data mining;mathematics;statistics	ML	23.692366022139364	-36.04782971249537	49593
4482fc83619b08f34984183bc3f6ce0465eddfa7	control on landscapes with local minima and flat regions: a simulated annealing and gain scheduling approach	neural network control;landscapes;learning rate;numerical technique;activation function;closed loop systems;nonlinear control systems;multilayer perceptrons;gain;simulated annealing learning systems multilayer perceptrons neurocontrollers nonlinear control systems;simulated annealing;local minima region;learning systems;gain scheduling;artificial neural networks;nonlinear systems;trajectory;gain scheduled learning rate landscapes local minima region flat region simulated annealing multilayer neural network sigmoid like activation function neural network control nonlinear system;sigmoid like activation function;simulated annealing neural networks multi layer neural network control systems nonlinear control systems nonlinear systems system identification cost function convergence backpropagation;neurocontrollers;nonlinear system;local minima;multilayer neural network;noise;neural network;flat region;gain scheduled learning rate	Landscapes containing local minima and ¿flat¿ regions are frequently encountered in multi-layer neural networks that employ sigmoid-like activation function in the hidden layers. Numerous techniques in the neural network community have been proposed to address these issues. In this note, we extend these ideas to the neural network control of nonlinear systems. We propose a solution which employs simulated annealing and a gain scheduled learning rate.	activation function;artificial neural network;layer (electronics);maxima and minima;nonlinear system;scheduling (computing);sigmoid function;simulated annealing	Abraham K. Ishihara;Shahar Ben-Menahem	2008	2008 47th IEEE Conference on Decision and Control	10.1109/CDC.2008.4739457	stochastic neural network;mathematical optimization;simulated annealing;nonlinear system;gain;computer science;noise;trajectory;machine learning;maxima and minima;control theory;mathematics;landscape;gain scheduling;activation function;artificial neural network	Robotics	15.873784227324144	-25.253697733803616	49708
3a1c38d85e0179e26fd046169c8735bdd309de21	learning to predict the leave-one-out error of kernel based classifiers	modele geometrique;machine support vecteur;approximation error;classification;error aproximacion;programacion lineal;machine lineaire;maquina lineal;linear programming;programmation lineaire;vector support machine;learning artificial intelligence;linear machine;clasificacion;leave one out;erreur approximation;geometrical model;modelo geometrico;apprentissage intelligence artificielle	We propose an algorithm to predict the leave-one-out (LOO) error for kernel based classifiers. To achieve this goal with computational efficiency, we cast the LOO error approximation task into a classification problem. This means that we need to learn a classification of whether or not a given training sample - if left out of the data set - would be misclassified. For this learning task, simple data dependent features are proposed, inspired by geometrical intuition. Our approach allows to reliably select a good model as demonstrated in simulations on Support Vector and Linear Programming Machines. Comparisons to existing learning theoretical bounds, e.g. the span bound, are given for various model selection scenarios.	kernel (operating system)	Koji Tsuda;Gunnar Rätsch;Sebastian Mika;Klaus-Robert Müller	2001		10.1007/3-540-44668-0_47	approximation error;biological classification;computer science;linear programming;artificial intelligence;machine learning;mathematics;algorithm	ML	11.168359697837085	-33.14617820977235	49716
24906d76c0facede9063cac2b5f90200d67424ed	recursive functions in high-dimensional computing with random vectors	high definition video cognition computer architecture computational modeling neural networks associative memory pattern recognition;vectors data handling generalisation artificial intelligence inference mechanisms learning artificial intelligence neural nets recursive functions;modulo 10 subtraction recursive functions high dimensional computing random vectors machine learning holistic data representation connectionist computing model neural networks compositional learning computational operations generalization reasoning model modulo 10 addition	The primary aim of this work is to provide new tools for machine learning and reasoning within a framework of computing with holistic data representations. Specifically, we demonstrate recursive construction of mappings and functions in high-dimensional computing with random vectors - a connectionist computing model which provides benefits similar to neural networks, but allows compositional learning. The computational operations considered in this work are applicable in learning by generalizing from small sets of example data. We demonstrate their use by constructing a simple reasoning model which learns modulo 10 addition and subtraction from a minimal set of examples. Finally, we give examples on how the presented computational operations can be used to compose and manipulate more complex structures in computing with high-dimensional random vectors.	artificial neural network;computation;computer architecture;connectionism;content-addressable memory;holism;machine learning;modulo operation;neuromorphic engineering;reasoning system;recursion (computer science)	Jussi H. Poikonen;Eero Lehtonen;Mika Laiho	2016	2016 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2016.7727886	types of artificial neural networks;computer science;artificial intelligence;theoretical computer science;machine learning;artificial neural network	ML	13.891741363485554	-30.071230669174724	49823
5ee3ea53e6972fdb89108aadfc43ec43feb885f2	reduction to independent variables: from normal distribution to general statistical case to fuzzy	probabilistic;normal distribution;complex data;fuzzy;reduction to independent variable	In many practical problems, we must combine (“fuse”) data represented in different formats, e.g., statistical, fuzzy, etc. The simpler the data, the easier to combine them. Therefore, to combine complex data, it is desirable to “decompose” this complex data into simpler (easy-to-combine) data chunks. It is well known that when we have n random variables x1 xn with a joint Gaussian distribution, then we can reduce them to n independent variables by an appropriate linear transformation x1 xn y1 f1 x1 xn yn fn x1 xn It is not so well known but also true that when we have x1 xn with a known joint probability distribution (not necessarily Gaussian), then we can always reduce them to n independent variables by an appropriate non-linear transformation. In this paper, we show that a similar result holds for fuzzy uncertainty as well.	fuzzy logic;fuzzy set;nonlinear system	Mourad Oussalah;Hung T. Nguyen;Vladik Kreinovich	2001			multivariate normal distribution;discrete mathematics;illustration of the central limit theorem;fuzzy number;pattern recognition;mathematics;chi-squared distribution;matrix normal distribution;statistics	Theory	21.193437631589592	-29.46848166069724	49828
223b99b6007b52f97bdd5a4377ae6656fc081c1a	how many samples are needed to estimate a convolutional neural network?		A widespread folklore for explaining the success of Convolutional Neural Networks (CNNs) is that CNNs use a more compact representation than the Fullyconnected Neural Network (FNN) and thus require fewer training samples to accurately estimate their parameters. We initiate the study of rigorously characterizing the sample complexity of estimating CNNs. We show that for an m-dimensional convolutional filter with linear activation acting on a d-dimensional input, the sample complexity of achieving population prediction error of is r Opm{ q 2, whereas the sample-complexity for its FNN counterpart is lower bounded by Ωpd{ q samples. Since, in typical settings m ! d, this result demonstrates the advantage of using a CNN. We further consider the sample complexity of estimating a onehidden-layer CNN with linear activation where both the m-dimensional convolutional filter and the r-dimensional output weights are unknown. For this model, we show that the sample complexity is r O ` pm` rq{ 2 ̆ when the ratio between the stride size and the filter size is a constant. For both models, we also present lower bounds showing our sample complexities are tight up to logarithmic factors. Our main tools for deriving these results are a localized empirical process analysis and a new lemma characterizing the convolutional structure. We believe that these tools may inspire further developments in understanding CNNs.	artificial neural network;convolutional neural network;estimated;neural network simulation;sample complexity;weight	Simon S. Du;Yining Wang;Xiyu Zhai;Sivaraman Balakrishnan;Ruslan Salakhutdinov;Aarti Singh	2018				ML	19.289012660447096	-31.549705754448887	50091
0277171dafbf28843c805c203bb04292adf52124	black-box optimization in machine learning with trust region based derivative free algorithm		In this work, we utilize a Trust Region based Derivative Free Optimization (DFO-TR) method to directly maximize the Area Under Receiver Operating Characteristic Curve (AUC), which is a nonsmooth, noisy function. We show that AUC is a smooth function, in expectation, if the distributions of the positive and negative data points obey a jointly normal distribution. The practical performance of this algorithm is compared to three prominent Bayesian optimization methods and random search. The presented numerical results show that DFO-TR surpasses Bayesian optimization and random search on various blackbox optimization problem, such as maximizing AUC and hyperparameter tuning.	algorithm;bayesian optimization;benchmark (computing);black box;data point;derivative-free optimization;linear classifier;machine learning;mathematical optimization;numerical analysis;optimization problem;random search;self-tuning;transistor;trust region	Hiva Ghanbari;Katya Scheinberg	2017	CoRR		mathematical optimization;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;active learning	ML	21.342659582160866	-34.93589090784206	50180
93ecc69694c5459d99604c493394c674638e6c6b	the dynamics of hebbian synapses can be stabilized by a nonlinear decay term	equation differentielle;learning;hebbian learning rules;normalisation;stabilization;differential equation;ecuacion diferencial;stability;aprendizaje;apprentissage;sinapsis;conexion;raccordement;normalizacion;normalization;reseau neuronal;stabilite;connection;red neuronal;standardization;estabilidad;neural network;synapse	"""Abstract--In the field of neural networks, the dynamics of the connections (synapses) between neurones are often assumed to follow Hebb's rule. The corresponding differential equations are, however, unstable,"""" stability is usually achieved by introducing a subsequent step o f normalization or saturation. Here we propose a nonlinear decay term in the equation describing the dynamics of synaptical strengths. With this term the dynamics of synapses becomes intrinsically stable and subsequent normalization is not needed."""	artificial neural network;control theory;hebbian theory;nonlinear system;synapse	Helmut Riedel;Detlev Schild	1992	Neural Networks	10.1016/0893-6080(92)90007-6	stability;connection;computer science;synapse;artificial intelligence;machine learning;normalization;calculus;mathematics;differential equation;artificial neural network;standardization;algorithm;statistics	ML	18.783786963667747	-27.302760680259524	50244
1ef153f6c41ecb6316423253cf50a3b9b83525c8	gradient based method for symmetric and asymmetric multiagent reinforcement learning	multiagent system;fonction valeur;game theory;methode parametrique;asymmetry;proceso markov;gradient method;metodo parametrico;reinforcement learning;parametric method;teoria juego;intelligence artificielle;theorie jeu;asymetrie;funcion valor;approximation fonction;methode gradient;apprentissage renforce;function approximation;metodo gradiente;processus markov;markov process;asimetria;artificial intelligence;number;value function;inteligencia artificial;sistema multiagente;nombre;aprendizaje reforzado;numero;systeme multiagent	A gradient based method for both symmetric and asymmetric multiagent reinforcement learning is introduced in this paper. Symmetric multiagent reinforcement learning addresses the problem with agents involved in the learning task having equal information states. Respectively, in asymmetric multiagent reinforcement learning, the information states are not equal, i.e. some agents (leaders) try to encourage agents with less information (followers) to select actions that lead to improved overall utility value for the leaders. In both cases, there is a huge number of parameters to learn and we thus need to use some parametric function approximation methods to represent the value functions of the agents. The method proposed in this paper is based on the VAPS framework that is extended to utilize the theory of Markov games, i.e. a natural basis of multiagent reinforcement learning.	agent-based model;gradient;reinforcement learning	Ville Könönen	2003		10.1007/978-3-540-45080-1_9	game theory;error-driven learning;numero sign;function approximation;computer science;gradient method;artificial intelligence;machine learning;mathematics;markov process;bellman equation;reinforcement learning;grammatical number;algorithm;asymmetry	ML	19.536668989450146	-27.087400732692277	50289
458c3160d30c584852feff4205e3198f35cdac65	reinforcement learning for control: performance, stability, and deep approximators		Reinforcement learning (RL) offers powerful algorithms to search for optimal controllers of systems with nonlinear, possibly stochastic dynamics that are unknown or highly uncertain. This review mainly covers artificial-intelligence approaches to RL, from the viewpoint of the control engineer. We explain how approximate representations of the solution make RL feasible for problems with continuous states and control actions. Stability is a central concern in control, and we argue that while the control-theoretic RL subfield called adaptive dynamic programming is dedicated to it, stability of RL largely remains an open question. We also cover in detail the case where deep neural networks are used for approximation, leading to the field of deep RL, which has shown great success in recent years. With the control practitioner in mind, we outline opportunities and pitfalls of deep RL; and we close the survey with an outlook that – among other things – points out some avenues for bridging the gap between control and artificial-intelligence RL techniques.	approximation algorithm;artificial intelligence;artificial neural network;bridging (networking);control engineering;controllers;deep learning;dynamic programming;microsoft outlook for mac;neural network simulation;nonlinear system;published comment;reinforcement learning;stochastic process;theory	Lucian Buşoniua;Tim de Bruinb;Domagoj Tolićc;Jens Koberb;Ivana Palunkod	2018	Annual Reviews in Control	10.1016/j.arcontrol.2018.09.005	control engineering;engineering;dynamic programming;artificial neural network;function approximation;reinforcement learning;deep learning;nonlinear system;bridging (networking);optimal control;machine learning;artificial intelligence	ML	20.63694042861436	-23.971374053654124	50297
3b3fed10aa9996eed0313ddf4f5e1cd187062136	dynamic associative memory, based on open recurrent neural network	image recognition;feedback components;neural activity patterns;convergence;neural networks;recurrent neural nets content addressable storage control engineering computing feedback;training;data mining;activity pattern;software performance;open dynamic recurrent neural network;stability;brain modeling;dynamic attractors control;feedback;recurrent network;estimation;structure and function;non iterative method;attraction radius;neocortex;mathematical model;virtual static recurrent network;associative memory;generalized stability equation;dynamic attractors control dynamic associative memory open dynamic recurrent neural network virtual static recurrent network generalized stability equation non iterative method attraction radius training set size feedback components neural activity patterns neural activity patterns neocortex;control engineering computing;dynamic associative memory;recurrent neural nets;neurons;recurrent neural networks;recurrent neural network;neurofeedback;iteration method;content addressable storage;training set size;associative memory recurrent neural networks neurons neural networks software performance brain modeling stability equations neurofeedback image recognition	Mathematical model of open dynamic recurrent neural network, that hasn't hidden neurons, is described. Such network has dynamic attractors, that are sequences of transitions between one attractor state to another, according to input signal sequences. Concept of “freezing” of such dynamics with the use of virtual static recurrent network is proposed. Solution of generalized stability equation is used for development of non-iterative method for training dynamic recurrent networks. Estimations of attraction radius and training set size are obtained. Using of the open dynamic recurrent network as dynamic associative memory is studied and possibility of control of dynamic attractors by changing level of influence of different feedback components is shown. Software model of the network was developed, and experimental study of its behavior for reproducing of sequences of distorted vectors was performed. Analogy between dynamic attractors and neural activity patterns, that support hypothesis of local neural ensembles, with structure and functions similar to dynamic recurrent networks in neocortex, is remarked.	artificial neural network;content-addressable memory;experiment;iterative method;mathematical model;neural ensemble;recurrent neural network;test set	Alexander M. Reznik;Dmitry A. Dziuba	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178767	computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;time delay neural network;bidirectional associative memory;echo state network;artificial neural network;statistics	ML	16.057312033617904	-30.746080836664785	50477
6a7ba0e93e6dde386af989a3650a6d7ad0db83de	jncc2: an extension of naive bayes classifier suited for small and incomplete data sets	naive bayes;classification;naive bayes classifier;incomplete data;imprecise probability;machine learning;naive credal classifier 2	JNCC2 implements the Naive Credal Classifier 2 (NCC2), i.e., an extension of naive Bayes to imprecise probabilities, designed to return robust classification even on small and/or incomplete data sets, which is often the case in environmental case studies.	naive bayes classifier	Giorgio Corani;Marco Zaffalon	2008	Environmental Modelling and Software	10.1016/j.envsoft.2008.01.004	bayes classifier;naive bayes classifier;computer science;machine learning;pattern recognition;data mining;bayes error rate	AI	16.04519555796839	-37.584064180679206	50486
01b2bac0862100990cb405f0844708dfe7004dbd	designing committees of models through deliberate weighting of data points	committee design;different individual weight;data confidence;deliberate weighting;fixed weight;data point;different constituent model;committees;particular data point;committee formation;different committee approach;bagging;committee design matrix;ensembles;neural networks;mathematical model	In the adaptive derivation of mathematical models from data , each data point should contribute with a weight reflecting the amount of confidence one has in it. When no additional information for data confidence is available, all the data points should be consid ered equal, and are also generally given the same weight. In the formation of committees of models, ho wever, this is often not the case and the data points may exercise unequal, even random, influence over the committee formation. In this paper, a principled approach to committee design is p re ented. The construction of a committee design matrix is detailed through which each data point will contribute to the committee formation with a fixed weight, while contributing with diffe r nt individual weights to the derivation of the different constituent models, thus encouraging mode l div rsity whilst not biasing the committee inadvertently towards any particular data points. N ot distinctly an algorithm, it is instead a framework within which several different committee approa ches may be realised. Whereas the focus in the paper lies entirely on regression, t he principles discussed extend readily to classification.	algorithm;biasing;boosting (machine learning);bootstrap aggregating;cross-validation (statistics);data point;emulator;experiment;mathematical model;numerical analysis;pattern formation;span and div;while	Stefan W. Christensen;Ian Sinclair;Philippa A. S. Reed	2003	Journal of Machine Learning Research		computer science;artificial intelligence;machine learning;mathematical model;data mining;mathematics;statistics	AI	17.566809642098736	-37.79847118758588	50573
b21ae1a24e531563a69e6455972ab961250b1b77	color pattern recognition on the random neural network model	learning algorithm;algorithm performance;algorithme apprentissage;random neural network;gradient descent;resultado algoritmo;performance algorithme;pattern classification;pattern recognition;reseau neuronal recurrent;reconnaissance forme;recurrent neural networks;linear equations;reconocimiento patron;algoritmo aprendizaje;classification forme	The purpose of this paper is to describe the use of the multiple classes random neural network model to learn various patterns having different colors. We propose a learning algorithm for the recognition of color patterns based upon the non-linear equations of the multiple classes random neural network model using gradient descent of a quadratic error function. Our model is defined for nC parameters for the whole network, where C is the number of colors, n is the number of pixels of the image, and each neuron is used to obtain the color value of each pixel in the bit map plane.	algorithm;artificial neural network;color;computation;content-addressable memory;gradient descent;image resolution;linear equation;mimd;maxima and minima;nc (complexity);network model;neuron;nonlinear system;pattern recognition;pixel;random neural network;simd	José Aguilar;Valentina Rossell	2000		10.1007/3-540-45049-1_67	gradient descent;color quantization;random neural network;computer science;artificial intelligence;recurrent neural network;machine learning;time delay neural network;mathematics;linear equation;algorithm	ML	14.082537322853147	-29.1330129118341	50599
7c10ff688476ab459fbe6d6bb46f8c61e3e9a98f	learning with convex loss and indefinite kernels		We consider a kind of kernel-based regression with general convex loss functions in a regularization scheme. The kernels used in the scheme are not necessarily symmetric and thus are not positive semidefinite; l1−norm of the coefficients in the kernel ensembles is taken as the regularizer. Our setting in this letter is quite different from the classical regularized regression algorithms such as regularized networks and support vector machines regression. Under an established error decomposition that consists of approximation error, hypothesis error, and sample error, we present a detailed mathematical analysis for this scheme and, in particular, its learning rate. A reweighted empirical process theory is applied to the analysis of produced learning algorithms, which plays a key role in deriving the explicit learning rate under some assumptions.	algorithm;approximation error;coefficient;hearing loss, high-frequency;kernel (operating system);loss function;machine learning;mathematics;support vector machine	Hongzhi Tong;Di-Rong Chen;Fenghong Yang	2014	Neural Computation	10.1162/NECO_a_00535	regularization perspectives on support vector machines;mathematical optimization;discrete mathematics;machine learning;mathematics;statistics;generalization error	ML	21.714360709540834	-33.706456905666826	50652
0cb40a2cf80618d2ba61fdac5065aec21e227b12	meta continual learning		Using neural networks in practical settings would benefit from the ability of the networks to learn new tasks throughout their lifetimes without forgetting the previous tasks. This ability is limited in the current deep neural networks by a problem called catastrophic forgetting, where training on new tasks tends to severely degrade performance on previous tasks. One way to lessen the impact of the forgetting problem is to constrain parameters that are important to previous tasks to stay close to the optimal parameters. Recently, multiple competitive approaches for computing the importance of the parameters with respect to the previous tasks have been presented. In this paper, we propose a learning to optimize algorithm for mitigating catastrophic forgetting. Instead of trying to formulate a new constraint function ourselves, we propose to train another neural network to predict parameter update steps that respect the importance of parameters to the previous tasks. In the proposed meta-training scheme, the update predictor is trained to minimize loss on a combination of current and past tasks. We show experimentally that the proposed approach works in the continual learning setting.	algorithm;artificial neural network;catastrophic interference;constraint (mathematics);deep learning;experiment;kerrison predictor	Risto Vuorio;Dong-Yeon Cho;Daejoong Kim;Jiwon Kim	2018	CoRR		machine learning;artificial intelligence;artificial neural network;mathematics;forgetting	AI	17.28124008981841	-32.43410506085899	50771
26141e4ecd92c84db518b520aab782e3a00d1382	cost-sensitive classifier evaluation using cost curves	operant conditioning;perforation;machine learning	The evaluation of classifier performance in a cost-sensitive setting is straightforward if the operating conditions (misclassification costs and class distributions) are fixed and known. When this is not the case, evaluation requires a method of visualizing classifier performance across the full range of possible operating conditions. This talk outlines the most important requirements for cost-sensitive classifier evaluation for machine learning and KDD researchers and practitioners, and introduces a recently developed technique for classifier performance visualization – the cost curve – that meets all these requirements.	data mining;machine learning;requirement	Robert C. Holte;Chris Drummond	2008		10.1007/978-3-540-68125-0_4	margin classifier;margin;computer science;machine learning;operant conditioning;pattern recognition;data mining	ML	11.443078540450593	-37.68761072066254	50835
65dd106876784c9de3095231e540208fe35f81af	automatic algorithm selection in computational software using machine learning	software;machine learning algorithms;runtime;heuristic algorithms;mathematical model;software algorithms;algorithm design and analysis	Computational software programs, such as Maple and Mathematica, heavily rely on superfunctions and meta-algorithms to select the optimal algorithm for a given task. These meta-algorithms may require intensive mathematical proof to formulate, incur large computational overhead, or fail to consistently select the best algorithm. Machine learning demonstrates a promising alternative for automatic algorithm selection by easing the design process and overhead while also attaining high accuracy in selection. In a case study on the resultant superfunction, a trained neural network is able to select the best algorithm out of the four available 86% of the time in Maple and 78% of the time in Mathematica. When used as a replacement for pre-existing meta-algorithms, the neural network brings about a 68% runtime improvement in Maple and 49% improvement in Mathematica. Random forests, k-nearest neighbors, and both linear and RBF kernel SVMs are also compared to the neural network model, the latter of which offers the best performance out of the tested machine learning methods.	algorithm selection;approximation algorithm;artificial neural network;computation;ibm notes;k-nearest neighbors algorithm;machine learning;maple;mathematical optimization;multi-objective optimization;network model;overhead (computing);polynomial;radial basis function kernel;random forest;resultant;run time (program lifecycle phase);runtime system;wolfram mathematica	Matthew C. Simpson;Qing Yi;Jugal K. Kalita	2016	2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2016.0064	algorithm design;wake-sleep algorithm;weighted majority algorithm;computer science;artificial intelligence;theoretical computer science;machine learning;mathematical model;algorithm	ML	16.900188895361868	-24.511454472795545	50942
ac72be4a3b3ae4c0cc22ca3512d52bd2bf4eb203	consciousness in a self-learning, memory-controlled, compound machine	conditional memory cells;brain waves;analisis sistema;concepcion sistema;implementation;logarithmic changes in memory;intelligence artificielle;algorithme;algorithm;ejecucion;system design;consciousness;sensors and actuators;system analysis;conscience;artificial intelligence;analyse systeme;inteligencia artificial;conciencia;trinary encoders and decoders;interrogation signals;reseau neuronal;memory controlled machines;coma;red neuronal;conception systeme;anesthesia;neural network;algoritmo	A memory-controlled, sensor/actuator machine senses conditions in its environment at given moments, and attempts to produce an action based upon its memory. However, a sensor/actuator machine will stop producing new behavior if its environment is removed. A sensor/sensor unit can be added to the sensor/actuator machine, forming a compound machine. The sensor/sensor unit produces a stream of internally created sensed conditions, which can replace the sensed conditions from the environment. This illusion of an environment is similar to consciousness. In addition, actuator/sensor and actuator/actuator units can be added to this compound machine to further enhance its ability to function without an environment. Predetermined and empirical memory cells can be distributed throughout the control units of this compound machine to provide instinctive and learned behavior. The internal and exterior behavior of this compound machine can be modified greatly by changing the cycle start and ramp signals that activate these different kinds of memory cells. These signals are similar in form to brain waves.	activation action;actuator device component;adjudication;artificial neural network;brain waves;comatose;consciousness;control unit;esthesia;fuzzy control system;illusions;memory cell (binary);neural network simulation;ramp simulation software for modelling reliability, availability and maintainability;sensor;spinal cord;recurrent childhood brain stem glioma	Robert Alan Brown	1997	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(97)00057-9	simulation;plant;computer science;artificial intelligence;coma;machine learning;consciousness;conscience;system analysis;implementation;artificial neural network;systems design	ML	10.793120935828135	-29.13669465027446	51044
07af73981c0b58f7352930f23cd8e11dd13fb802	forced information and information loss in information-theoretic competitive learning	information loss;competitive learning;mutual information maximization;forced information;winner take all;information theoretic	In this paper, we propose a new type of computational method to accelerate a process of information maximization and a new technique to extract important features in input patterns by a concept of information loss. Information-theoretic competitive learning has been proposed to solve the fundamental problems of competitive learning such as the dead neuron problem with many practical applications. However, one of the major problems in information-theoretic competitive learning is slow in increasing information in competitive units, depending upon given problems. To overcome this shortcoming, we propose a new computational method in which maximum information is supposed to be already achieved before learning. By this computational method, we force networks to converge much faster. In addition, information loss is proposed in which difference in formation between an original network and network without an input unit is measured. If the information loss for the unit is large, the input unit should a very important role. By forced information with the information loss, information-theoretic competitive learning is expected to be applied to large-scale practical problems.		Ryotaro Kamimura	2007			simulation;computer science;artificial intelligence;machine learning;competitive learning;interaction information	ML	15.56772325159658	-32.29136962300659	51131
9b5443c4dd8c4a8381d118ebe3bba1ca6ac1e4c0	learning bayesian networks consistent with the optimal branching	prognostics and health management;preventive maintenance;cost saving;preventive maintenance computerised monitoring condition monitoring cost benefit analysis data mining;costs and benefits;data mining;model evaluation;machine learning;condition monitoring;costs benefits information prognostics and health management systems data mining prognostic models;prognostics and health management systems;computerised monitoring;costs benefits information;cost benefit analysis;data mining prognostic models;costs prognostics and health management data mining predictive models data envelopment analysis machine learning road safety condition monitoring sampling methods information technology	We introduce a polynomial-time algorithm to learn Bayesian networks whose structure is restricted to nodes with in-degree at most k and to edges consistent with the optimal branching, that we call consistent k-graphs (CkG). The optimal branching is used as an heuristic for a primary causality order between network variables, which is subsequently refined, according to a certain score, into an optimal CkG Bayesian network. This approach augments the search space exponentially, in the number of nodes, relatively to trees, yet keeping a polynomial-time bound. The proposed algorithm can be applied to scores that decompose over the network structure, such as the well known LL, MDL, AIC, BIC, K2, BD, BDe, BDeu and MIT scores. We tested the proposed algorithm in a classification task. We show that the induced classifier always score better than or the same as the Naive Bayes and Tree Augmented Naive Bayes classifiers. Experiments on the UCI repository show that, in many cases, the improved scores translate into increased classification accuracy.	akaike information criterion;algorithm;bayesian information criterion;bayesian network;blu-ray;causality;directed graph;experiment;heuristic;ll parser;mdl (programming language);naive bayes classifier;time complexity;whole earth 'lectronic link	Alexandra M. Carvalho;Arlindo L. Oliveira	2007	Sixth International Conference on Machine Learning and Applications (ICMLA 2007)	10.1109/ICMLA.2007.74	computer science;cost–benefit analysis;machine learning;data mining;prognostics	AI	17.197623425957538	-36.59770771695086	51312
cca4b20fd515cdb1b7a0d2d4fdb132f04a80de2a	forward only counter propagation network for balance scale weight & distance classification task	unsupervised learning;learning rate;learning efficiency forward only counter propagation network balance scale weight and distance classification task bswd classification task focpn psychological experiments learning rule;radiation detectors;training;focpn;neural net architecture;radiation detector;psychology;accuracy;artificial neural networks;vectors;psychology learning artificial intelligence neural net architecture;som;neurons;learning artificial intelligence;classification accuracy;learning rate focpn som;training vectors neurons accuracy radiation detectors artificial neural networks unsupervised learning;artificial neural network	This paper proposes the forward only counter propagation network (FOCPN) for solving the Balance Scale Weight & Distance (BSWD) classification task. Balance Scale Weight & Distance application is used for the psychological experiments and it is one of the challenging jobs. The forward only counter propagation network (FOCPN) has the architecture consisting of three layers as the input layer, the middle (kohonen) and the output layer and having different learning rule The Experiments are performed on different radius of the neighborhood and learning rate based on size of the map. Experimental results show that the forward only counter propagation network (FOCPN's) convergence is faster and it gives the improved learning efficiency and reliable prediction performance. Also, the classification accuracy is much higher than the other models used for this purpose.	experiment;learning rule;minimum-weight triangulation;self-organizing map;software propagation	Waqas Haider Bangyal;Jamil Ahmad;Imran Shafi;Qamar Abbas	2011	2011 Third World Congress on Nature and Biologically Inspired Computing	10.1109/NaBIC.2011.6089615	computer science;artificial intelligence;machine learning;pattern recognition;particle detector;artificial neural network	ML	14.235931088404495	-32.15119162612806	51599
d3a69b0f011747fbb73414b4de64ca3ba31424a0	phase transitions, optimal errors and optimality of message-passing in generalized linear models		Generalized linear models (GLMs) arise in high-dimensional machine learning, statistics, communications and signal processing. In this paper we analyze GLMs when the data matrix is random, as relevant in problems such as compressed sensing, error-correcting codes or benchmarks models in neural networks. We evaluate the mutual information (or “free entropy”) from which we deduce the Bayes-optimal inference and generalization errors. Our analysis applies to the highdimensional limit where both the number of samples and dimensions are large and their ratio is fixed. Non-rigorous predictions for the optimal inference and generalization errors existed for special cases of GLMs, e.g. for the perceptron in the field of statistical physics based on the so-called replica method. Our present paper rigorously establishes those decades old conjectures and brings forward their algorithmic interpretation in terms of performance of the generalized approximate message-passing algorithm. Furthermore, we tightly characterize, for many learning problems, regions of parameters for which this algorithm achieves the optimal performance, and locate the associated sharp phase transitions separating learnable and non-learnable regions1.	approximation algorithm;artificial neural network;code;compressed sensing;error detection and correction;forward error correction;generalized linear model;message passing;mutual information;perceptron;signal processing	Jean Barbier;Florent Krzakala;Nicolas Macris;Léo Miolane;Lenka Zdeborová	2017	CoRR		applied mathematics;interpolation;perceptron;random matrix;probabilistic logic;mutual information;generalized linear mixed model;hierarchical generalized linear model;mathematics;binary number	ML	21.336268126173163	-31.036544480472113	51610
6b5602f2aac83da7ce5dc8170dd531693ce61981	sparsity-based generalization bounds for predictive sparse coding		The goal of predictive sparse coding is to learn a representation of examples as sparse linear combinations of elements from a dictionary, such that a learned hypothesis linear in the new representation performs well on a predictive task. Predictive sparse coding has demonstrated impressive performance on a variety of supervised tasks, but its generalization properties have not been studied. We establish the first generalization error bounds for predictive sparse coding, in the overcomplete setting, where the number of features k exceeds the original dimensionality d. The learning bound decays as Õ( √ dk/m) with respect to d, k, and the size m of the training sample. It depends intimately on stability properties of the learned sparse encoder, as measured on the training sample. Consequently, we also present a fundamental stability result for the LASSO, a result that characterizes the stability of the sparse codes with respect to dictionary perturbations.	code;dictionary;encoder;generalization error;lasso;neural coding;sparse matrix	Nishant A. Mehta;Alexander G. Gray	2013			combinatorics;machine learning;pattern recognition;sparse approximation	ML	20.902819838009705	-33.83000570120636	51646
7ac3f13f93a2097ffc94f00402e4051f557c4151	special issue on computational intelligence and nature-inspired algorithms for real-world data analytics and pattern recognition		This special issue of Algorithms is devoted to the study of Computational Intelligence and Nature-Inspired Algorithms for Real-World Data Analytics and Pattern Recognition. The special issue considered both theoretical contributions able to advance the state-of-the-art in this field and practical applications that describe novel approaches for solving real-world problems.	algorithm;computation;computational intelligence;pattern recognition	Stefano Cagnoni;Mauro Castelli	2018	Algorithms	10.3390/a11030025	machine learning;computational mathematics;mathematics;numerical analysis;data analysis;algorithm;computational intelligence;artificial intelligence;pattern recognition	AI	20.352012212610873	-36.17584721651264	51689
743fbe4e69de4ae69257017d6d9919ea54f018ac	the neural movemap heuristic in chess	base donnee;game theory;algoritmo busqueda;image processing;chess game;algorithme recherche;relacion orden;speech processing;heuristic method;search algorithm;database;tratamiento palabra;procesamiento imagen;traitement parole;base dato;ouverture;ordering;teoria juego;metodo heuristico;theorie jeu;traitement image;devis estimatif;ajedrez;relation ordre;presupuesto estimativo;pattern recognition;abertura;jeu echecs;methode heuristique;reconnaissance forme;estimate;reseau neuronal;reconocimiento patron;red neuronal;opening;neural network	The efficiency of alpha-beta search algorithms heavily depends on the order in which the moves are examined. This paper investigates a new move-ordering heuristic in chess, namely the Neural MoveMap (NMM) heuristic. The heuristic uses a neural network to estimate the likelihood of a move being the best in a certain position. The moves considered more likely to be the best are examined first. We develop an enhanced approach to apply the NMM heuristic during the search, by using a weighted combination of the neural-network scores and the history-heuristic scores. Moreover, we analyse the influence of existing game databases and opening theory on the design of the training patterns. The NMM heuristic is tested for middle-game chess positions by the program CRAFTY. The experimental results indicate that the NMM heuristic outperforms the existing move ordering, especially when a weighted-combination approach is chosen.	alpha–beta pruning;artificial neural network;database;heuristic;search algorithm	Levente Kocsis;Jos W. H. M. Uiterwijk;Eric O. Postma;H. Jaap van den Herik	2002		10.1007/978-3-540-40031-8_11	consistent heuristic;null-move heuristic;game theory;computer vision;image processing;order theory;computer science;artificial intelligence;speech processing;incremental heuristic search;opening;operations research;artificial neural network;algorithm;search algorithm	AI	10.429742854415004	-33.72716227440034	51859
4b80e9bc2c4f131e3f441a4771e239658cfddef9	a competitive winner-takes-all architecture for classification and pattern recognition of structures	image processing;eliminacion;speech processing;tratamiento palabra;procesamiento imagen;traitement parole;traitement image;similitude;similarity;pattern classification;pattern recognition;reconnaissance forme;elimination;similitud;reconocimiento patron;winner take all;classification forme	We propose a winner-takes-all (WTA) classifier for structures represented by graphs. WTA classification follows the principle elimination of competition. The input structure is assigned to the class corresponding to the winner of the competition. In experiments we investigate the performance of the WTA classifier and compare it with the canonical maximum similarity (MS) classifier.	competitive learning;experiment;k-nearest neighbors algorithm;nearest neighbour algorithm;psi protein classifier;pattern recognition;structural similarity;synthetic data;weapon target assignment problem;winner-take-all (computing)	Brijnesh J. Jain;Fritz Wysotzki	2003		10.1007/3-540-45028-9_23	winner-take-all;speech recognition;similarity;image processing;computer science;artificial intelligence;similitude;machine learning;speech processing;elimination	ML	10.45133534347957	-33.963742598350564	51990
7e15dd479941c5668c2ceb77bd841566d0e33f65	degree of approximation results for feedforward networks approximating unknown mappings and their derivatives	feedforward;approximation error;activation function;boucle anticipation;satisfiability;error aproximacion;ciclo anticipacion;approximating mappings;nonsigmoid activation function;degree of approximation;reseau neuronal;red neuronal;erreur approximation;neural network	Recently Barron (1993) has given rates for hidden layer feedforward networks with sigmoid activation functions approximating a class of functions satisfying a certain smoothness condition. These rates do not depend on the dimension of the input space. We extend Barron's results to feedforward networks with possibly nonsigmoid activation functions approximating mappings and their derivatives simultaneously. Our conditions are similar but not identical to Barron's, but we obtain the same rates of approximation, showing that the approximation error decreases at rates as fast as n1/2, where n is the number of hidden units. The dimension of the input space appears only in the constants of our bounds.	approximation error;feed forward (control);feedforward neural network;sigmoid function	Kurt Hornik;Maxwell B. Stinchcombe;Halbert White;Peter Auer	1994	Neural Computation	10.1162/neco.1994.6.6.1262	mathematical optimization;approximation error;combinatorics;discrete mathematics;computer science;machine learning;mathematics;activation function;feed forward;artificial neural network;statistics;satisfiability	ML	18.892578952321585	-29.461437506122476	52057
a7a146f81a151aeba19232f4c1c15d257cece801	a rapid sparsification method for kernel machines in approximate policy iteration	reinforcement learning rl;kernel sparsification;approximate policy iteration api;least squares policy iteration lspi	Recently approximate policy iteration (API) has received increasing attention due to its good convergence and generalization abilities in solving difficult reinforcement learning (RL) problems, e.g. least-squares policy iteration (LSPI) and its kernelized version (KLSPI). However, the sparsification of feature vectors, especially the kernel-based features, costs much computation and greatly influences the performance of API methods. In this paper, a novel rapid sparsification method is proposed for sparsifying kernel machines in API. In this method, the approximation error of a new feature vector is computed prior in the original space to decide if it is added to the current kernel dictionary, so the computational cost becomes a little higher when the collected samples are sparse, but remarkably lower when the collected samples are dense. Experimental results on the swing-up control of an double-link pendulum verify that the computational cost of the proposed algorithm is lower than that of the previous kernel-based API algorithm, and this performance becomes more and more obvious when the number of the collected samples increases and when the level of sparsification increases.	iteration;kernel method;markov decision process	Chunming Liu;Zhenhua Huang;Xin Xu;Lei Zuo;Jun Wu	2012		10.1007/978-3-642-31346-2_60	mathematical optimization;theoretical computer science;machine learning;mathematics	ML	24.181888690181033	-35.08905784459906	52077
d503d8345cc130cba3fdbaa3e2a039efd75a2a62	discriminative training via minimization of risk estimates based on parzen smoothing	high dimensionality;hidden markov model;optimal method;generalized probabilistic descent;risk estimation;pattern recognition;speech recognition;multi layer perceptron;discriminative training;minimum classification error;theoretical foundation	We describe a new approach to estimating classification risk in the domain of a suitably defined transformation that can be used as the basis for optimization of generic pattern recognition systems, including hidden Markov models and Multi-Layer Perceptrons. The two formulations of risk estimate described here are closely tied to the Minimum Classification Error/Generalized Probabilistic Descent (MCE/GPD) framework for discriminative training that is well-known to the speech recognition community. In the new approach, high-dimensional and possibly variable-length training tokens are mapped to the centers of Parzen kernels which are then easily integrated to find the risk estimate. The utility of such risk estimates lies in the fact that they are explicit functions of the system parameters and hence suitable for use in practical optimization methods. The use of Parzen estimation makes it possible to establish convergence of the risk estimate to the true theoretical classification risk, a result that formally expresses the benefit of linking the degree of smoothing to the training set size. Convergence of the minimized risk estimate is also analyzed. The new approach establishes a more general theoretical foundation for discriminative training than existed before, supporting previous work and suggesting new variations for future work.	descent;discriminative model;hidden markov model;iso/iec 11404;kernel density estimation;markov chain;mathematical optimization;pattern recognition;perceptron;smoothing;speech recognition;test set;tinymce	Erik McDermott;Shigeru Katagiri	2006	Applied Intelligence	10.1007/s10489-006-8865-0	computer science;artificial intelligence;machine learning;pattern recognition;multilayer perceptron;hidden markov model	ML	21.404410007090323	-35.794525152582665	52205
77cd0c5d711db0ed558e53f47314214d905eb488	a full-function pavlov associative memory implementation with memristance changing circuit		Positive voltages and negative voltages are applied to adjust memristance in most memristive circuits. This paper presents a memristance changing circuit in which memristance is changed only by the positive voltage. A mathematical calculation method is proposed to analyze the memristance change approximately. Furthermore, memristance changing circuits are utilized as synapses to construct a neural network to imitate full-function Pavlov associative memory. Compared to the classical Pavlov associative memory, the full-function Pavlov associative memory contains additional f ood f orgetting and ring f orgetting processes. The f orgetting processes will be triggered in the condition that either the f ood or the ring is given to the dog after the learning processes. The learning and f orgetting time of the associative memory can be obtained by the proposed mathematical calculation method in advance approximately.	artificial neural network;content-addressable memory;memristor;microelectronics and computer technology corporation;simulation	Le Yang;Zhigang Zeng;Shiping Wen	2018	Neurocomputing	10.1016/j.neucom.2017.07.020	artificial intelligence;synapse;machine learning;content-addressable memory;electronic circuit;mathematics;artificial neural network;forgetting	ML	15.520519135539601	-27.15303096358237	52368
32e934094c4d17fe4d734b2e169ba5e3cd0ee05e	orthogonal random features		We present an intriguing discovery related to Random Fourier Features: in Gaussian kernel approximation, replacing the random Gaussian matrix by a properly scaled random orthogonal matrix significantly decreases kernel approximation error. We call this technique Orthogonal Random Features (ORF), and provide theoretical and empirical justification for this behavior. Motivated by this discovery, we further propose Structured Orthogonal Random Features (SORF), which uses a class of structured discrete orthogonal matrices to speed up the computation. The method reduces the time cost from O(d2) to O(d log d), where d is the data dimensionality, with almost no compromise in kernel approximation quality compared to ORF. Experiments on several datasets verify the effectiveness of ORF and SORF over the existing methods. We also provide discussions on using the same type of discrete orthogonal structure for a broader range of applications.	approximation algorithm;approximation error;computation;gaussian elimination;kernel (operating system);open reading frame;polynomial;transformation matrix	Felix X. Yu;Ananda Theertha Suresh;Krzysztof Choromanski;Daniel N. Holtmann-Rice;Sanjiv Kumar	2016			mathematical optimization;combinatorics;discrete mathematics;machine learning;mathematics;statistics	ML	23.929518006533414	-36.21195616603576	52373
04dae5b9f2a90610f844211624af988a6f0caec6	global, recurrent and smoothed-piecewise neural models for financial time series prediction			smoothing;time series	Serdar Yülü;Fikret S. Gürgen;Nesrin Okay	2005			time series;mathematical optimization;piecewise;mathematics	ML	11.592097129655746	-25.66722183257348	52392
07ae89193ac67ff56d5a95e266b6517f356a6dec	compressed fisher linear discriminant analysis: classification of randomly projected data	fisher linear discriminant analysis;compressed learning;high dimensionality;projective dimension;linear discriminate analysis;classification;upper bound;dimensionality reduction;random projection;linear discriminant analysis;dimensional reduction	We consider random projections in conjunction with classification, specifically the analysis of Fisher's Linear Discriminant (FLD) classifier in randomly projected data spaces.  Unlike previous analyses of other classifiers in this setting, we avoid the unnatural effects that arise when one insists that all pairwise distances are approximately preserved under projection. We impose no sparsity or underlying low-dimensional structure constraints on the data; we instead take advantage of the class structure inherent in the problem. We obtain a reasonably tight upper bound on the estimated misclassification error on average over the random choice of the projection, which, in contrast to early distance preserving approaches, tightens in a natural way as the number of training examples increases. It follows that, for good generalisation of FLD, the required projection dimension grows logarithmically with the number of classes. We also show that the error contribution of a covariance misspecification is always no worse in the low-dimensional space than in the initial high-dimensional space. We contrast our findings to previous related work, and discuss our insights.	dataspaces;linear discriminant analysis;random projection;randomness;sparse matrix	Robert J. Durrant;Ata Kabán	2010		10.1145/1835804.1835945	kernel fisher discriminant analysis;biological classification;computer science;machine learning;pattern recognition;optimal discriminant analysis;mathematics;upper and lower bounds;linear discriminant analysis;statistics;dimensionality reduction	ML	20.76013229327893	-33.9110661242971	52404
9d2a4abba20bc091a6668f3de765eeaec59cfcbb	plenary speaker 1: continuum fusion: a new theory of inference	support vector machines continuum fusion theory of inference composite hypothesis testing robust decision algorithms data driven methods artificial neural networks genetic algorithms;support vector machines;neural nets;composite hypothesis testing;inference mechanisms;theory of inference;artificial neural networks;data driven methods;genetic algorithm;genetic algorithms;support vector machine;robust decision algorithms;continuum fusion;support vector machines genetic algorithms inference mechanisms neural nets;artificial neural network	By exploiting human insight in the form of a model, methods of composite hypothesis (CH) testing can generate more robust decision algorithms, with a greater ability to generalize, than the alternative “data-driven methods.” The latter include artificial neural networks, genetic algorithms, support vector machines, etc.	artificial neural network;genetic algorithm;support vector machine;triune continuum paradigm	A. Schaum	2010	2010 2nd Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing	10.1109/WHISPERS.2010.5594828	quality control and genetic algorithms;computer science;machine learning;pattern recognition;data mining	ML	10.533914877898981	-26.947408990292885	52413
4de5587d2bc291d0edd08d6ab6271e520095c13d	online learning for structured loss spaces		We consider prediction with expert advice when the loss vectors are assumed to lie in a set described by the sum of atomic norm balls. We derive a regret bound for a general version of the online mirror descent (OMD) algorithm that uses a combination of regularizers, each adapted to the constituent atomic norms. The general result recovers standard OMD regret bounds, and yields regret bounds for new structured settings where the loss vectors are (i) noisy versions of vectors from a low-dimensional subspace, (ii) sparse vectors corrupted with noise, and (iii) sparse perturbations of low-rank vectors. For the problem of online learning with structured losses, we also show lower bounds on regret in terms of rank and sparsity of the loss vectors, which implies lower bounds for the above additive loss settings as well.	algorithm;h2 database engine;modulo operation;regret (decision theory);spaces;sparse matrix;universal instantiation;utility functions on indivisible goods	Siddharth Barman;Aditya Gopalan;Aadirupa Saha	2018			machine learning;mathematics;artificial intelligence;mathematical optimization;regret;subspace topology	AI	22.84728983492835	-31.683285915211094	52480
d6d635d5e44d0fec15e61a380f1120a09c1771a2	pcs: a classifier system that builds a predictive internal world model				Piet Spiessens	1990			machine learning;artificial intelligence;computer science;classifier (linguistics);margin classifier	ML	10.375081538713912	-26.42111291921361	52796
f3e5e18d0b424adb41c25e2c47afaddb9e2fd967	spiking neural network based asic for character recognition	asic design;parallel architecture spiking neural network based asic artificial neural networks snn hand written character recognition nearest neighbour classifier second generation feedforward neural network backpropagation algorithm;neurons biological neural networks feature extraction computational modeling biological system modeling support vector machine classification classification algorithms;neural nets backpropagation handwritten character recognition image classification;asic design spiking neural networks character recognition;spiking neural networks;character recognition	Spiking neural networks are the recent models of artificial neural networks. These networks use biologically similar neuron models as their basic computation units. This paper presents and compares a custom spiking neural network (SNN) with a conventional nearest neighbour classifier for hand written character recognition. The classifiers are designed and simulated in 90nm CMOS technology. The two algorithms are compared in terms of their success rates and their hardware requirements (based on the area and power estimates). The classification performance of the SNN is also compared with that of second generation feedforward neural network, with the same set of images. The robustness of SNN is demonstrated in this work by its ability to classify the 30 out of 32 noisy characters images presented as compared to the nearest neighbour algorithm, which correctly classified only 20 of them. The feedforward neural network using backpropagation algorithm was able to correctly identify 29 out of 32 noisy images in MATLAB. In terms of hardware, the ASIC realizing the nearest neighbour classifier dissipates power of 1.2mW and an area of 380μm × 380μm, while the SNN dissipates 16.7mW power and an area of 1mm × 1mm. The higher area and power requirements for the SNN stem from its inherent parallel architecture. Earlier works have focused on realization of a single spiking neuron and its variants while this work brings about the application using networks of these neurons and their suitability for custom realization.	application-specific integrated circuit;artificial neuron;backpropagation;biological neuron model;cmos;cognition;computation;continuation;feedforward neural network;handwriting recognition;matlab;multiplication algorithm;nearest neighbour algorithm;neuromorphic engineering;optical character recognition;parallel computing;pattern recognition;pipeline (computing);requirement;spiking neural network	Shruti R. Kulkarni;Maryam Shojaei Baghini	2013	2013 Ninth International Conference on Natural Computation (ICNC)	10.1109/ICNC.2013.6817969	types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;machine learning;pattern recognition;physical neural network;time delay neural network;deep learning	ML	14.786043626003552	-26.14188441111702	52896
1b3a6c405551b4a8ca9d8459385ddb7ada468422	sequential optimal design of neurophysiology experiments	experimental design;algorithme rapide;time average;metodo adaptativo;calcul neuronal;neural computation;sequential design;optimal design statistics;high dimensionality;methode parametrique;asymptotic normality;aproximacion optima;metodo parametrico;approximation algorithm;real time;active learning;parametric method;modele lineaire;plan experiencia;estimacion promedio;informacion mutual;adaptive optimization;optimization method;promedio temporal;metodo secuencial;methode adaptative;modelo lineal;calculo automatico;asymptotic analysis;sequential method;asymptotic behavior;espace parametre;comportement asymptotique;metodo optimizacion;statistical model;computing;biomedical engineering computer science sequential optimal design of neurophysiology experiments georgia institute of technology robert butera;convergence speed;calcul automatique;comportamiento asintotico;liam paninski lewi jeremy;neural system;information mutuelle;optimal approximation;approximation optimale;posterior distribution;plan experience;fast algorithm;neurofisiologia;adaptive method;linear model;espacio par metro;generalized linear model glm;dissertation;algoritmo aproximacion;parameter space;modele statistique;neurophysiologie;methode optimisation;ley a posteriori;optimal design;velocidad convergencia;plan optimal;methode sequentielle;mutual information;general linear model;modelo estadistico;neurophysiology;mean estimation;sequential optimal experimental design;reseau neuronal;algorithme approximation;estimation moyenne;vitesse convergence;asymptotic normal;loi a posteriori;calcul 2 dimensions;algoritmo rapido;red neuronal;computacion neuronal;normalidad asintotica;normalite asymptotique;moyenne temporelle;neural network;plan sequentiel;plan secuencial;two dimensional calculations	Adaptively optimizing experiments has the potential to significantly reduce the number of trials needed to build parametric statistical models of neural systems. However, application of adaptive methods to neurophysiology has been limited by severe computational challenges. Since most neurons are high-dimensional systems, optimizing neurophysiology experiments requires computing high-dimensional integrations and optimizations in real time. Here we present a fast algorithm for choosing the most informative stimulus by maximizing the mutual information between the data and the unknown parameters of a generalized linear model (GLM) that we want to fit to the neuron's activity. We rely on important log concavity and asymptotic normality properties of the posterior to facilitate the required computations. Our algorithm requires only low-rank matrix manipulations and a two-dimensional search to choose the optimal stimulus. The average running time of these operations scales quadratically with the dimensionality of the GLM, making real-time adaptive experimental design feasible even for high-dimensional stimulus and parameter spaces. For example, we require roughly 10 milliseconds on a desktop computer to optimize a 100-dimensional stimulus. Despite using some approximations to make the algorithm efficient, our algorithm asymptotically decreases the uncertainty about the model parameters at a rate equal to the maximum rate predicted by an asymptotic analysis. Simulation results show that picking stimuli by maximizing the mutual information can speed up convergence to the optimal values of the parameters by an order of magnitude compared to using random (nonadaptive) stimuli. Finally, applying our design procedure to real neurophysiology experiments requires addressing the nonstationarities that we would expect to see in neural responses; our algorithm can efficiently handle both fast adaptation due to spike history effects and slow, nonsystematic drifts in a neuron's activity.	acclimatization;algorithm;approximation;choose (action);complex adaptive system;computation (action);concave function;convergence (action);design of experiments;desktop computer;experiment;generalized linear model;hl7publishingsubsection <operations>;mutual information;neuron;neurons;neurophysiology - biologic function;normality unit;optimal design;population parameter;real-time clock;science of neurophysiology;simulation;speedup;statistical model;time complexity	Jeremy Lewi;Robert J. Butera;Liam Paninski	2009	Neural Computation	10.1162/neco.2008.08-07-594	statistical model;adaptive optimization;econometrics;computing;asymptotic analysis;optimal design;linear model;mathematics;active learning;parameter space;mutual information;algorithm;statistics;general linear model	ML	21.810632634798495	-27.01585729665274	53007
5c7d8cafc22d6b8150396572c043dbc8285c9473	artificial neural network trained by particle swarm optimization for non-linear channel equalization	particle swarm optimization;channel equalization;artificial neural network	Development of a learning method for optimization of network topology of ANN.Use of PSO trained ANN in channel equalization.PSO trained ANN equalizers performs better than PSO based equalizers as well as ANN based equalizers. In this paper, we apply Artificial Neural Network (ANN) trained with Particle Swarm Optimization (PSO) for the problem of channel equalization. Existing applications of PSO to Artificial Neural Networks (ANN) training have only been used to find optimal weights of the network. Novelty in this paper is that it also takes care of appropriate network topology and transfer functions of the neuron. The PSO algorithm optimizes all the variables, and hence network weights and network parameters. Hence, this paper makes use of PSO to optimize the number of layers, input and hidden neurons, the type of transfer functions etc. This paper focuses on optimizing the weights, transfer function, and topology of an ANN constructed for channel equalization. Extensive simulations presented in this paper shows that, as compared to other ANN based equalizers as well as Neuro-fuzzy equalizers, the proposed equalizer performs better in all noise conditions.	artificial neural network;nonlinear system;particle swarm optimization	Gyanesh Das;Prasant Kumar Pattnaik;Sasmita Kumari Padhy	2014	Expert Syst. Appl.	10.1016/j.eswa.2013.10.053	computer science;artificial intelligence;equalization;machine learning;particle swarm optimization;artificial neural network	ML	13.734120324582644	-24.37070682488951	53071
6f94a0542e7808252462fac769f3acd774000977	automatic generation of a neural network architecture using evolutionary computation	neural networks computer architecture evolutionary computation genetic programming network topology genetic algorithms biological cells systems engineering and theory knowledge engineering australia;optimal solution;genetic program;neural nets;neural net architecture;automatic generation;genetic algorithm;genetic algorithms;genetic algorithms neural net architecture neural nets;neural network;evolutionary computing;genetic programming automatic generation neural network architecture evolutionary computation	This paper reports the application of evolutionary computation in the automatic generation of a neural network architecture. It is a usual practice to use trial and error to find a suitable neural network architecture. This is not only time consuming but may not generate an optimal solution for a given problem. The use of evolutionary computation is a step towards automation in neural network architecture generation. In this paper a brief introducuon to the field is given as well as an implementation of automatic neural network generation using genetic programming.	artificial neural network;evolutionary computation;genetic programming;network architecture	E. Vonk;Lakhmi C. Jain;L. P. J. Veelenturf;R. P. Johnson	1995		10.1109/ETD.1995.403479	evolutionary programming;nervous system network models;interactive evolutionary computation;human-based evolutionary computation;computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;evolutionary acquisition of neural topologies;genetic representation;time delay neural network;intelligent control	AI	14.950038328451178	-24.84803777176533	53225
bdfce308800591f1833f6971d5cb494a31b9c8ad	ranking with features: algorithm and a graph theoretic analysis		We consider the problem of ranking a set of items from pairwise comparisons in the presence of features associated with the items. Recent works have established that O(n log(n)) samples are needed to rank well when there is no feature information present. However, this might be sub-optimal in the presence of associated features. We introduce a new probabilistic preference model called feature-Bradley-Terry-Luce (f-BTL) model that generalizes the standard BTL model to incorporate feature information. We present a new least squares based algorithm called fBTL-LS which we show requires much lesser than O(n log(n)) pairs to obtain a good ranking – precisely our new sample complexity bound is of O(α logα), where α denotes the number of ‘independent items’ of the set, in general α << n. Our analysis is novel and makes use of tools from classical graph matching theory to provide tighter bounds that sheds light on the true complexity of the ranking problem, capturing the item dependencies in terms of their feature representations. This was not possible with earlier matrix completion based tools used for this problem. We also prove an information theoretic lower bound on the required sample complexity for recovering the underlying ranking, which essentially shows the tightness of our proposed algorithms. The efficacy of our proposed algorithms are validated through extensive experimental evaluations on a variety of synthetic and real world datasets.	algorithm;bradley–terry model;information theory;least squares;matching (graph theory);mike lesser;sample complexity;synthetic intelligence	Aadirupa Saha;Arun Rajkumar	2018	CoRR		matching (graph theory);matrix completion;mathematical optimization;probabilistic logic;pairwise comparison;upper and lower bounds;least squares;algorithm;mathematics;graph;ranking	ML	23.43813382177422	-26.138797933096455	53260
a43fb1108b44cb2c8652d02e129c93f6da3b8693	an efficient parallel method for batched os-elm training using mapreduce		In this era of big data, more and more models need to be trained to mine useful knowledge from large scale data. It has become a challenging problem to train multiple models accurately and efficiently so as to make full use of limited computing resources. As one of ELM variants, online sequential extreme learning machine (OS-ELM) provides a method to learn from incremental data. MapReduce, which provides a simple, scalable and fault-tolerant framework, can be utilized for large scale learning. In this paper, we propose an efficient parallel method for batched online sequential extreme learning machine (BPOS-ELM) training using MapReduce. Map execution time is estimated with historical statistics, where regression method and inverse distance weighted interpolation method are used. Reduce execution time is estimated based on complexity analysis and regression method. Based on the estimations, BPOSELMgenerates aMap execution plan and aReduce execution plan. Finally, BPOS-ELM launches one MapReduce job to train multiple OS-ELM models according to the generated execution plan, and collects execution information to further improve estimation accuracy. Our proposal is evaluated with real and synthetic data. The experimental results show that the accuracy of BPOS-ELM is at the same level as those of OS-ELM and parallel OS-ELM (POS-ELM) with higher training efficiencies.	analysis of algorithms;big data;elm;fault tolerance;interpolation;mapreduce;operating system;query plan;run time (program lifecycle phase);scalability;synthetic data	Shan Huang;Botao Wang;Yuemei Chen;Guoren Wang;Ge Yu	2017	Memetic Computing	10.1007/s12293-016-0190-5	artificial intelligence;interpolation;machine learning;scalability;data mining;extreme learning machine;big data;synthetic data;sequence learning;multiple models;computer science	ML	13.536230637066602	-37.53570084024809	53288
45cac1aa2644a381d0cd7c00661596fdfe0a7a37	using alpha-beta associative memories to learn and recall rgb images	associative memory;color image	In this paper, an algorithm which enables Alpha-Beta associative memories to learn and recall color images is presented. The latter is done even though these memories were originally designed by Yáñez-Márquez [1] to work only with binary patterns. Also, an experimental study on the proposed algorithm is presented, showing the efficiency of the new memories.	algorithm;experiment;server name indication	Cornelio Yáñez-Márquez;María Elena Cruz-Meza;Flavio Arturo Sánchez-Garfias;Itzamá López-Yáñez	2007		10.1007/978-3-540-72395-0_101	computer vision;color image;computer science;artificial intelligence;machine learning	AI	14.044540850895446	-30.992243579164946	53587
72bd579ac237177dd30d1f6cc2c858e8d2f31f0e	performance comparison of different momentum techniques on deep reinforcement learning		ABSTRACTRecently, the popularity of deep artificial neural networks has increased considerably. Generally, the method used in the training of these structures is simple gradient descent. However, training a deep structure with simple gradient descent can take quite a long time. Some additional approaches have been utilized to solve this problem. One of these techniques is the momentum that accelerates gradient descent learning. Momentum techniques can be used for supervised learning as well as for reinforcement learning. However, its efficiency may vary due to the dissimilarities in two learning processes. While the expected values of inputs are clearly known in supervised learning, it may take long-running iterations to reach the exact expected values of the states in reinforcement learning. In an online learning approach, a deep neural network should not memorize and continue to converge with the more precise values that exist over time during these iterations. For this reason, it is necessary to use a ...	reinforcement learning	Mehmet Sarigul;Mutlu Avci	2018	J. Information Telecommunication	10.1080/24751839.2018.1440453	supervised learning;artificial neural network;reinforcement learning;machine learning;expected value;popularity;gradient descent;artificial intelligence;mathematics;momentum	NLP	17.382124360712854	-32.31505335814295	53624
eae8b3c3efeeb07a8ac36615149e3fe8b414c372	an alternative view: when does sgd escape local minima?		Stochastic gradient descent (SGD) is widely used in machine learning. Although being commonly viewed as a fast but not accurate version of gradient descent (GD), it always finds better solutions than GD for modern neural networks. In order to understand this phenomenon, we take an alternative view that SGD is working on the convolved (thus smoothed) version of the loss function. We show that, even if the function f has many bad local minima or saddle points, as long as for every point x, the weighted average of the gradients of its neighborhoods is one point convex with respect to the desired solution x∗, SGD will get close to, and then stay around x∗ with constant probability. Our result identifies a set of functions that SGD provably works, which is much larger than the set of convex functions. Empirically, we observe that the loss surface of neural networks enjoys nice one point convexity properties locally, therefore our theorem helps explain why SGD works so well for neural networks.	artificial neural network;convex function;convolution;loss function;machine learning;maxima and minima;smoothing;stochastic gradient descent	Robert D. Kleinberg;Yuanzhi Li;Yang Yuan	2018			mathematical optimization;artificial neural network;gradient noise;mathematics;gradient descent;maxima and minima;convex function;stochastic gradient descent;saddle point;phenomenon	ML	21.624942628239424	-32.23283382252833	53717
4af36dbf9b7f12e47d8a71ef51790580a8e75f92	time series prediction using support vector machines, the orthogonal and the regularized orthogonal least-squares algorithms	orthogonal least square;support vector machine;time series prediction	Generalization properties of support vector machines, orthogonal least squares and zero-order regularized orthogonal least squares algorithms are studied using simulation. For high signal-to-noise ratios (40 dB), mixed results are obtained, but for a low signal-to-noise ratio, the prediction performance of support vector machines is better than the orthogonal least squares algorithm in the examples considered. However, the latter can usually give a parsimonious model with very fast training and testing time. Two new algorithms are therefore proposed that combine the orthogonal least squares algorithm with support vector machines to give a parsimonious model with good prediction accuracy in the low signal-to-noise ratio case.	algorithm;least squares;support vector machine;time series	Kian Leong Lee;Stephen A. Billings	2002	Int. J. Systems Science	10.1080/0020772021000017317	total least squares;support vector machine;least squares support vector machine;mathematical optimization;machine learning;time series;pattern recognition;mathematics;non-linear least squares;least squares;orthogonal array	ML	22.471968191068026	-36.810890451213375	53950
d036e39250b5fb3c1ab541e6625c44f8276f5b6e	on the initialization and optimization of multilayer perceptrons	multilayer perceptrons network topology feedforward systems information systems input variables clustering algorithms neural networks feedforward neural networks pattern recognition pattern classification;optimisation;network topology feedforward neural nets optimisation pattern recognition;multilayer perceptron;backpropagation;standard error;network topology;technology and engineering;classification tasks initialization optimization multilayer perceptrons pattern recognition training optimum network size topology two layer perceptron error backpropagation training;pattern recognition;feedforward neural nets	Multilayer perceptrons are now widely used for pattern recognition, although the training remains a time consuming procedure often converging toward a local optimum. Moreover, as the optimum network size and topology are usually unknown, the search of this optimum requires a lot of networks to be trained. In this paper the authors propose a method for properly initializing the parameters (weights) of a two-layer perceptron, and for identifying (without the need for any error-backpropagation training) the most suitable network size and topology for solving the problem under investigation. The initialized network can then be optimized by means of the standard error-backpropagation (EBP) algorithm. The authors' method is applicable to any two-layer perceptron comprising concentric as well as squashing units on its hidden layer. The output units are restricted to squashing units, but direct connections from the input to the output layer are also accommodated. To illustrate the power of the method, results obtained for different classification tasks are compared to similar results obtained using a traditional error-backpropagation training starting from a random initial state.		Nico Weymaere;Jean-Pierre Martens	1994	IEEE transactions on neural networks	10.1109/72.317726	probabilistic neural network;computer science;artificial intelligence;backpropagation;machine learning;pattern recognition;time delay neural network;multilayer perceptron;standard error;network topology	Vision	14.81762180372716	-30.339274769803524	53991
adfda8e0000c6190dc82671f0c1d97255581637f	solving a system of nonlinear integral equations by an rbf network	system of nonlinear integral equations;gradient method;optimal method;newton s method;radial basis function network;nonlinear integral equation;continuous optimization;newton method;optimal algorithm;learning strategies;rbf network	In this paper, a novel learning strategy for radial basis function networks (RBFN) is proposed. By adjusting the parameters of the hidden layer, including the RBF centers and widths, the weights of the output layer are adapted by local optimization methods. A new local optimization algorithm based on a combination of the gradient and Newtonmethods is introduced. The efficiency of some local optimization methods to update the weights of RBFN is studied in solving systems of nonlinear integral equations. © 2009 Elsevier Ltd. All rights reserved.	algorithm;approximation;backpropagation;computation;gradient;local search (optimization);mathematical optimization;nonlinear system;radial (radio);radial basis function network;time complexity	A. Golbabai;Musa A. Mammadov;S. Seifollahi	2009	Computers & Mathematics with Applications	10.1016/j.camwa.2009.03.038	mathematical optimization;machine learning;calculus;control theory;newton's method in optimization;mathematics;continuous optimization;newton's method;nonlinear conjugate gradient method	AI	16.38464683080046	-28.749890866019165	54015
593cd4c7e29e12050e6a9dfdb366981fdcbf56db	bayesian neural networks	memoire;neurone;hebbian learning;aplicacion medical;learning;network performance;naive bayesian classifier;classification;activation;fixed point;aprendizaje;modelo;apprentissage;neurona;sinapsis;memoria;activacion;medical application;modele;reseau neuronal;models;clasificacion;red neuronal;neuron;memory;neural network;application medicale;synapse	A neural network that uses the basic Hebbian learning rule and the Bayesian combination function is defined. Analogously to Hopfield's neural network, the convergence for the Bayesian neural network that asynchronously updates its neurons' states is proved. The performance of the Bayesian neural network in four medical domains is compared with various classification methods. The Bayesian neural network uses more sophisticated combination function than Hopfield's neural network and uses more economically the available information. The “naive” Bayesian classifier typically outperforms the basic Bayesian neural network since iterations in network make too many mistakes. By restricting the number of iterations and increasing the number of fixed points the network performs better than the naive Bayesian classifier. The Bayesian neural network is designed to learn very quickly and incrementally.	artificial neural network;bayesian network;hebbian theory;hopfield network;iteration;learning rule;naive bayes classifier	Igor Kononenko	1994	Biological Cybernetics	10.1007/BF00200801	psychology;stochastic neural network;nervous system network models;feedforward neural network;probabilistic neural network;neuroscience;types of artificial neural networks;variable-order bayesian network;wake-sleep algorithm;hebbian theory;biological classification;computer science;synapse;artificial intelligence;recurrent neural network;machine learning;pattern recognition;time delay neural network;fixed point;memory;network performance;hopfield network;artificial neural network;dynamic bayesian network;intelligent control	ML	17.393062475692453	-27.51330398589617	54096
052c2a80dd9ec865787fcbea9de687aa3894fa5b	multidimensional splines with infinite number of knots as svm kernels	support vector machines;splines mathematics;support vector machines pattern classification radial basis function networks splines mathematics;radial basis function networks;pattern classification;kernel splines mathematics support vector machines polynomials approximation methods vectors training;classification datasets multidimensional splines infinite knot number svm kernels radial basis function kernels rbf kernels svm penalty parameter approximation function polynomial splines multidimensional normalized splines hyperparameter free kernel svm	Radial basis function (RBF) kernels for SVM have been routinely used in a wide range of classification problems, delivering consistently good performance for those problems where the kernel computations are numerically feasible (high-dimensional problems typically use linear kernels). One of the drawbacks of RBF kernels is the necessity of selecting the proper value of the hyperparameter γ in addition to the standard SVM penalty parameter C - this process can lead to overfitting. Another (more obscure) drawback of RBF is its inherent non-optimality as an approximation function. In order to address these issues, we propose to extend the concept of polynomial splines (designed explicitly for approximation purposes) to multidimensional normalized splines with infinite number of knots and use the resulting hyperparameter-free kernel SVMs instead of RBF kernel SVMs. We tested our approach for a number of standard classification datasets used in the literature. The results suggest that new kernels deliver mostly better classification performance than RBF kernel (for problems of moderately large dimensions), but allow faster computation (if measured on large cross-validation grids), with less chance of overfitting.	approximation;columbia (supercomputer);computation;cross-validation (statistics);eli;ink cartridge;loadable kernel module;numerical analysis;overfitting;polynomial;radial (radio);radial basis function kernel;radial basis function network;spline (mathematics);time complexity	Rauf Izmailov;Vladimir Vapnik;Akshay Vashist	2013	The 2013 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2013.6706860	support vector machine;mathematical optimization;radial basis function kernel;computer science;machine learning;pattern recognition;mathematics;box spline	ML	21.701317543489306	-37.59415001930377	54153
0a0d8432379abca12feb8da33c71a9982323c564	analog hardware model for morphological neural networks	neural network		neural networks	Jorge L. Ortiz;Camille T. Ocasio	2003			cellular neural network;types of artificial neural networks;time delay neural network;machine learning;nervous system network models;artificial neural network;artificial intelligence;physical neural network;computer science	ML	13.152218926640927	-27.01993966244587	54184
316c37a36e82e86c74d240f6a5bd81ae6b440186	simultaneous learning of several bayesian and mahalanobis discriminant functions by a neural network with memory nodes	simultaneous learning;discriminant function;bayesian;mahalanobis	We construct a one-hidden-layer neural network capable of learning simultaneously several Bayesian discriminant functions and converting them to the corresponding Mahalanobis discriminant functions in the two-category, normal-distribution case. The Bayesian discriminant functions correspond to the respective situations on which the priors and means depend. The algorithm is characterized by the use of the inner potential of the output unit and additional several memory nodes. It is remarkably simpler when compared with our previous algorithm.	artificial neural network;discriminant	Yoshifusa Ito;Hiroyuki Izumi;Cidambi Srinivasan	2012		10.1007/978-3-642-34500-5_4	probabilistic neural network;bayesian probability;mahalanobis distance;machine learning;pattern recognition;optimal discriminant analysis;discriminant function analysis;mathematics;multiple discriminant analysis;statistics	ML	17.617799482635373	-30.87586837497104	54209
40b0d8d62ac0d7079b2a58073b48747284705b4c	derivative delay embedding: online modeling of streaming time series	markov geographical model;streaming time series;online modeling and classification;delay embedding	The staggering amount of streaming time series coming from the real world calls for more efficient and effective online modeling solution. For time series modeling, most existing works make some unrealistic assumptions such as the input data is of fixed length or well aligned, which requires extra effort on segmentation or normalization of the raw streaming data. Although some literature claim their approaches to be invariant to data length and misalignment, they are too time-consuming to model a streaming time series in an online manner. We propose a novel and more practical online modeling and classification scheme, DDE-MGM, which does not make any assumptions on the time series while maintaining high efficiency and state-of-the-art performance. The derivative delay embedding (DDE) is developed to incrementally transform time series to the embedding space, where the intrinsic characteristics of data is preserved as recursive patterns regardless of the stream length and misalignment. Then, a non-parametric Markov geographic model (MGM) is proposed to both model and classify the pattern in an online manner. Experimental results demonstrate the effectiveness and superior classification accuracy of the proposed DDE-MGM in an online setting as compared to the state-of-the-art.	cellular automaton;dynamic data exchange;markov chain;recursion;stream (computing);time series	Zhifei Zhang;Yang Song;Wei Wang;Hairong Qi	2016		10.1145/2983323.2983715	real-time computing;simulation;computer science;machine learning;statistics	ML	14.68602902429847	-37.245186872242336	54578
c97a86acb8ae17194901be6bbb9c4cac486f3672	on agnostic learning with {0, *, 1}-valued and real-valued hypotheses	learning algorithm;learning model;algorithme apprentissage;classification;condition suffisante;condicion suficiente;scale factor;value function;sufficient condition;agnostic learning;learning artificial intelligence;algoritmo aprendizaje;facteur echelle;clasificacion;factor escala;apprentissage intelligence artificielle	"""We consider the problem of classification using a variant of the agnostic learning model in which the algorithm's hypothesis is evaluated by comparison with hypotheses that do not classify all possible instances. Such hypotheses are formalized as functions from the instance space X to {0, *, 1}, where * is interpreted as """"don't know"""". We provide a characterization of the sets of {0, *, 1}-valued functions that are learnable in this setting. Using a similar analysis, we improve on sufficient conditions for a class of real-valued functions to be agnostically learnable with a particular relative accuracy; in particular, we improve by a factor of two the scale at which scale-sensitive dimensions must be finite in order to imply learnability."""		Philip M. Long	2001		10.1007/3-540-44581-1_19	scale factor;biological classification;artificial intelligence;machine learning;mathematics;bellman equation;algorithm	ML	19.619599367698537	-31.470669603774926	54586
5286a44b9da55f5daf901dccdcb7cdb141e342b2	combination of supervised and unsupervised learning for training the activation functions of neural networks	partially supervised learning;co training;adaptive activation function	Standard feedforward neural networks benefit from the nice theoretical properties of mixtures of sigmoid activation functions, but they may fail in several practical learning tasks. These tasks would be better faced by relying on a more appropriate, problem-specific basis of activation functions. The paper presents a connectionist model which exploits adaptive activation functions. Each hidden unit in the network is associated with a specific pair (f(.),p(.)), where f(.) is the activation function and p(.) is the likelihood of the unit being relevant to the computation of the network output over the current input. The function f(.) is optimized in a supervised manner, while p(.) is realized via a statistical parametric model learned through unsupervised (or, partially supervised) estimation. Since f(.) and p(.) influence each other's learning process, the overall machine is implicitly a co-trained coupled model and, in turn, a flexible, non-standard neural architecture. Feasibility of the approach is corroborated by empirical evidence yielded by computer simulations involving regression and classification tasks.	activation function;artificial neural network;supervised learning;unsupervised learning	Ilaria Castelli;Edmondo Trentin	2014	Pattern Recognition Letters	10.1016/j.patrec.2013.06.013	unsupervised learning;computer science;artificial intelligence;machine learning;pattern recognition;supervised learning;multilayer perceptron;activation function	ML	17.953877937354704	-31.180717394806685	54781
776460663adc1172e71c1ea4810cb48761279b3e	training artificial neural networks using taguchi methods	statistical methods;statistical method;networked learning;process optimization;network training;taguchi methods;network learning;taguchi method;artificial neural network	This paper shows how the process optimization methods known as Taguchi methods may be applied to the training of Artificial Neural Networks. A comparison is made between the efficiency of training using Taguchi methods and the efficiency of conventional training methods; attention is drawn to the advantages of Taguchi methods. Further, it is shown that Taguchi methods offer potential benefits in evaluating network behaviour such as the ability to examine interaction of weights and neurons within a network.	algorithm;artificial neural network;interaction;mathematical optimization;neural networks;optical character recognition;process optimization;software propagation;taguchi methods	Christopher MacLeod;Geva Dror;Grant M. Maxwell	1999	Artificial Intelligence Review	10.1023/A:1006534203575	taguchi methods;computer science;artificial intelligence;machine learning;artificial neural network	AI	11.937280132921575	-24.924913289390023	54915
01dbf94c22064727ee77a2190c1b4816f151a47f	learning finite-state controllers for partially observable environments	search space;maquina estado finito;reinforcement learning;systeme numerique;digital system;apprentissage renforce;sistema numerico;algorithme evolutionniste;algoritmo evolucionista;partial observation;evolutionary algorithm;learning artificial intelligence;aprendizaje reforzado;machine etat fini;artificial evolution;finite state machine;state transition;apprentissage intelligence artificielle	Reactive (memoryless) policies are sufficient in completely observable Markov decision pro­ cesses (MDPs), but some kind of memory is usually necessary for optimal control of a par­ tially observable MDP. Policies with finite mem­ ory can be represented as finite-state automata. In this paper, we extend Baird and Moore's YAPS algorithm to the problem of learning gen­ eral finite-state automata. Because it performs stochastic gradient descent, this algorithm can be shown to converge to a locally optimal finite­ state controller. We provide the details of the algorithm and then consider the question of un­ der what conditions stochastic gradient descent will outperform exact gradient descent. We con­ clude with empirical results comparing the per­ formance of stochastic and exact gradient de­ scent, and showing the ability of our algorithm to extract the useful information contained in the sequence of past observations to compensate for the lack of observability at each time-step.	algorithm;automata theory;converge;experiment;finite-state machine;local optimum;markov chain;optimal control;partially observable system;run time (program lifecycle phase);stochastic gradient descent	Nicolas Meuleau;Leonid Peshkin;Kee-Eung Kim;Leslie Pack Kaelbling	1999		10.1007/3-540-45443-8_24	richards controller;searching the conformational space for docking;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;algorithm	AI	19.11225827672918	-25.13169388685733	54994
6e5f60c8743636f3c66880d856129ae956553bfe	fast conditional density estimation for quantitative structure-activity relationships	quantitative structure activity relationship;supervised learning;qsar modelling;chemoinformatics and qsar;conference contribution;density estimation;statistical analysis;computer science	Many methods for quantitative structure-activity relationships (QSARs) deliver point estimates only, without quantifying the uncertainty inherent in the prediction. One way to quantify the uncertainy of a QSAR prediction is to predict the conditional density of the activity given the structure instead of a point estimate. If a conditional density estimate is available, it is easy to derive prediction intervals of activities. In this paper, we experimentally evaluate and compare three methods for conditional density estimation for their suitability in QSAR modeling. In contrast to traditional methods for conditional density estimation, they are based on generic machine learning schemes, more specifically, class probability estimators. Our experiments show that a kernel estimator based on class probability estimates from a random forest classifier is highly competitive with Gaussian process regression, while taking only a fraction of the time for training. Therefore, generic machine-learning based methods for conditional density estimation may be a good and fast option for quantifying uncertainty in QSAR modeling.	experiment;gaussian process;kernel density estimation;kriging;machine learning;mathematical optimization;quantitative structure–activity relationship;radial basis function kernel;random forest;smoothing	Fabian Buchwald;Tobias Girschick;Eibe Frank;Stefan Kramer	2010			cluster-weighted modeling;density estimation;computer science;machine learning;supervised learning;quantitative structure–activity relationship;statistics	AI	23.635968014905124	-29.88459393052811	55061
9b64fbd395fa2256017da2c88bf5f1f7e9a73e1a	quantizing for minimum average misclassification risk	minimisation;quantization;metodo estadistico;erreur;learning algorithm;cuantificacion;probability;neural networks;nonparametric statistics;neural nets;high classification performance;minimum average misclassification risk;statistical method;random variables;risque;algorithme apprentissage;minimization methods;indexing terms;quantification;minimum average misclassification risk pattern classification decision rule labeled partition observation space vector quantizer high classification performance learning algorithm;observation space;riesgo;artificial neural networks;vector quantization;risk;methode statistique;feature extraction;decision theory;statistical pattern recognition;pattern classification;statistics;pattern recognition;neural nets pattern classification vector quantisation decision theory learning artificial intelligence probability nonparametric statistics minimisation;vector quantizer;reconnaissance forme;error;classification automatique;learning artificial intelligence;reseau neuronal;reconocimiento patron;vector quantisation;automatic classification;algoritmo aprendizaje;clasificacion automatica;labeled partition;red neuronal;decision rule;neural network;pattern classification pattern recognition random variables vector quantization neural networks artificial neural networks feature extraction statistics probability minimization methods	In pattern classification, a decision rule is a labeled partition of the observation space, where labels represent classes. A way to establish a decision rule is to attach a label to each code vector of a vector quantizer (VQ). When a labeled VQ is adopted as a classifier, we have to design it in such a way that high classification performance is obtained by a given number of code vectors. In this paper we propose a learning algorithm which optimizes the position of labeled code vectors in the observation space under the minimum average misclassification risk criterion.		Claudia Diamantini;Arnaldo Spalvieri	1998	IEEE transactions on neural networks	10.1109/72.655039	nonparametric statistics;random variable;minimisation;index term;quantization;decision theory;feature extraction;computer science;machine learning;pattern recognition;probability;decision rule;risk;mathematics;vector quantization;artificial neural network;statistics	ML	12.8705524965561	-33.651492671702684	55063
4a0c8c170648beb132bac25e87e16e60de1a516d	ranking data with ordinal labels: optimality and pairwise aggregation	volume under the roc surface;median ranking;empirical risk minimization;ordinal data;roc surface;k partite ranking	The paper describes key insights in order to grasp the nature of K-partite ranking. From the theoretical side, the various characterizations of optimal elements are fully described, as well as the likelihood ratio monotonicity condition on the underlying distribution which guarantees that such elements do exist. Then, a pairwise aggregation procedure based on Kendall tau is introduced to relate learning rules dedicated to bipartite ranking and solutions of the K-partite ranking problem. Criteria reflecting ranking performance under these conditions such as the ROC surface and its natural summary, the volume under the ROC surface (VUS), are then considered as targets for empirical optimization. The consistency of pairwise aggregation strategies are studied under these criteria and shown to be efficient under reasonable assumptions. Eventually, numerical results illustrate the relevance of the methodology proposed.	kendall tau distance;mathematical optimization;numerical analysis;ordinal data;relevance;review aggregator;social network aggregation	Stéphan Clémençon;Sylvain Robbiano;Nicolas Vayatis	2012	Machine Learning	10.1007/s10994-012-5325-4	empirical risk minimization;computer science;machine learning;pattern recognition;data mining;mathematics;ordinal data;ranking svm;statistics	ML	22.69098294802267	-26.385863495760418	55269
5a46aaafb9b60225c7867ff55032dc0b83e87fa2	learning with incomplete information in the committee machine	hebbian learning;generalization error;learning algorithm;reinforcement learning;committee machine;credit assignment;online learning;coarsegrained analysis;incomplete information;student teacher;initial condition;success rate;power law;coarse grained	We study the problem of learning with incomplete information in a student–teacher setup for the committee machine. The learning algorithm combines unsupervised Hebbian learning of a series of associations with a delayed reinforcement step, in which the set of previously learnt associations is partly and indiscriminately unlearnt, to an extent that depends on the success rate of the student on these previously learnt associations. The relevant learning parameter λ represents the strength of Hebbian learning. A coarse-grained analysis of the system yields a set of differential equations for overlaps of student and teacher weight vectors, whose solutions provide a complete description of the learning behavior. It reveals complicated dynamics showing that perfect generalization can be obtained if the learning parameter exceeds a threshold λ c , and if the initial value of the overlap between student and teacher weights is non-zero. In case of convergence, the generalization error exhibits a power law decay as a function of the number of examples used in training, with an exponent that depends on the parameter λ. An investigation of the system flow in a subspace with broken permutation symmetry between hidden units reveals a bifurcation point λ* above which perfect generalization does not depend on initial conditions. Finally, we demonstrate that cases of a complexity mismatch between student and teacher are optimally resolved in the sense that an over-complex student can emulate a less complex teacher rule, while an under-complex student reaches a state which realizes the minimal generalization error compatible with the complexity mismatch.	arabic numeral 0;bifurcation theory;committee machine;convergence (action);exhibits as topic;generalization (psychology);generalization error;hebbian theory;initial condition;mental association;partial;population parameter;weight;algorithm	Urs M. Bergmann;Reimer Kühn;Ion-Olimpiu Stamatescu	2009	Biological Cybernetics	10.1007/s00422-009-0345-2	semi-supervised learning;unsupervised learning;multi-task learning;instance-based learning;power law;wake-sleep algorithm;hebbian theory;computer science;artificial intelligence;theoretical computer science;online machine learning;machine learning;control theory;mathematics;leabra;learning classifier system;stability;competitive learning;reinforcement learning;active learning;complete information;initial value problem;probably approximately correct learning;statistics;generalization error	ML	16.948022479231174	-31.04672104850621	55466
60c2bb59e0f765fa4ea64a43f2a861a632df033d	boostvht: boosting distributed streaming decision trees		Online boosting improves the accuracy of classifiers for unbounded streams of data by chaining them into an ensemble. Due to its sequential nature, boosting has proven hard to parallelize, even more so in the online setting. This paper introduces BoostVHT, a technique to parallelize online boosting algorithms. Our proposal leverages a recently-developed model-parallel learning algorithm for streaming decision trees as a base learner. This design allows to neatly separate the model boosting from its training. As a result, BoostVHT provides a flexible learning framework which can employ any existing online boosting algorithm, while at the same time it can leverage the computing power of modern parallel and distributed cluster environments. We implement our technique on Apache SAMOA, an open-source platform for mining big data streams that can be run on several distributed execution engines, and demonstrate order of magnitude speedups compared to the state-of-the-art.	algorithm;big data;boosting (machine learning);computer cluster;data parallelism;decision tree;open-source software;parallel computing;run time (program lifecycle phase);scalability;thread (computing)	Theodore Vasiloudis;Foteini Beligianni;Gianmarco De Francisci Morales	2017		10.1145/3132847.3132974	boosting (machine learning);streams;big data;decision tree;computer science;machine learning;chaining;artificial intelligence;alternating decision tree	ML	13.682581793109868	-37.690973857433804	55605
ab443bd7e732374caabb5785b8d37bbfc724c845	fast matrix factorization for online recommendation with implicit feedback	matrix factorization;implicit feedback;online learning;als;coordinate descent;item recommendation	This paper contributes improvements on both the effectiveness and efficiency of Matrix Factorization (MF) methods for implicit feedback. We highlight two critical issues of existing works. First, due to the large space of unobserved feedback, most existing works resort to assign a uniform weight to the missing data to reduce computational complexity. However, such a uniform assumption is invalid in real-world settings. Second, most methods are also designed in an offline setting and fail to keep up with the dynamic nature of online data. We address the above two issues in learning MF models from implicit feedback. We first propose to weight the missing data based on item popularity, which is more effective and flexible than the uniform-weight assumption. However, such a non-uniform weighting poses efficiency challenge in learning the model. To address this, we specifically design a new learning algorithm based on the element-wise Alternating Least Squares (eALS) technique, for efficiently optimizing a MF model with variably-weighted missing data. We exploit this efficiency to then seamlessly devise an incremental update strategy that instantly refreshes a MF model given new feedback. Through comprehensive experiments on two public datasets in both offline and online protocols, we show that our implemented, open-source (https://github.com/hexiangnan/sigir16-eals) eALS consistently outperforms state-of-the-art implicit MF methods.	algorithm;computational complexity theory;experiment;feedback;incremental backup;least squares;missing data;online and offline;open-source software;uniform resource identifier	Xiangnan He;Hanwang Zhang;Min-Yen Kan;Tat-Seng Chua	2016		10.1145/2911451.2911489	coordinate descent;computer science;theoretical computer science;machine learning;data mining;matrix decomposition;world wide web	Web+IR	23.487720643101976	-35.05701917615526	55660
458f5aaf41b0accad0d96aa643c1c6d3314ec6f8	asymmetric boltzmann machines	stochastic networks;optimisation;feed forward;time dependent;learning algorithm;entropia;optimizacion;generic algorithm;learning;asymmetry;lyapunov function;rule based;network performance;asymetrie;proceso adquisicion;acquisition process;algorithme;aprendizaje;decision problem;relative entropy;algorithm;apprentissage;parallel evolution;entropie;cognition;cognicion;asimetria;boltzmann machine;optimization;entropy;stochastic model;reseau neuronal;point of view;combinatorial optimization;modelo estocastico;red neuronal;modele stochastique;processus acquisition;stochastic search;machine boltzmann;neural network;algoritmo	We study asymmetric stochastic networks from two points of view: combinatorial optimization and learning algorithms based on relative entropy minimization. We show that there are non trivial classes of asymmetric networks which admit a Lyapunov function ℒ under deterministic parallel evolution and prove that the stochastic augmentation of such networks amounts to a stochastic search for global minima of ℒ. The problem of minimizing ℒ for a totally antisymmetric parallel network is shown to be associated to an NP-complete decision problem. The study of entropic learning for general asymmetric networks, performed in the non equilibrium, time dependent formalism, leads to a Hebbian rule based on time averages over the past history of the system. The general algorithm for asymmetric networks is tested on a feed-forward architecture.	algorithm;class;combinatorial optimization;decision problem;hebbian theory;kullback–leibler divergence;lyapunov fractal;machine learning;mathematical optimization;maxima and minima;np-completeness;semantics (computer science);stochastic optimization	Bruno Apolloni;Alberto Bertoni;Paola Campadelli;Diego de Falco	1991	Biological Cybernetics	10.1007/BF00196453	entropy;mathematical optimization;combinatorial optimization;computer science;artificial intelligence;machine learning;mathematics;artificial neural network;statistics	ML	19.348383029410797	-27.093189773600205	55754
00d90b05aa857a3531acd30db23aca496734c1af	automatic implementation of totalistic cellular automata through polynomial cellular neural networks	quadratic programming;cellular neural nets;polynomials;polynomial cellular neural networks training performance generalized equation system quadratic programming algorithm totalistic cellular automata behavior polynomial term learning procedures;mathematical model polynomials quadratic programming cellular neural networks training automata;learning artificial intelligence;quadratic programming cellular automata cellular neural nets learning artificial intelligence polynomials;cellular automata;neural network training polynomial cellular neural networks quadratic programming generalized equation pcnn order	The learning procedures of cellular automata and cellular neural networks are not trivial tasks. They have been addressed previously with several techniques such as genetic algorithms, although they are computationally costly. As a contribution in the area of polynomial cellular neural networks, in this paper we present a novel method to determine automatically the optimum order of the polynomial term, and the generalized system of equations for a polynomial cellular neural network that implements any totalistic cellular automata behavior. Such advances can be coupled with a quadratic programming algorithm in order to radically boost training performance and dispense human intervention.	algorithmic efficiency;automata theory;categorization;cellular automaton;cellular neural network;computation;experiment;genetic algorithm;mathematical model;neural networks;polynomial;pulse-coupled networks;quadratic programming;software development process;synaptic package manager	Antonio Arista-Jalife;Eduardo Gómez-Ramírez;Giovanni Egidio Pazienza	2013	2013 IEEE Workshop on Hybrid Intelligent Models and Applications (HIMA)	10.1109/HIMA.2013.6615018	cellular neural network;discrete mathematics;theoretical computer science;asynchronous cellular automaton;machine learning;mathematics	Robotics	15.262685701993984	-25.192378138020793	55791
685a9d4019da3748224e6ae1cf0a6c53f626cc1b	on the relationship between the openai evolution strategy and stochastic gradient descent		Because stochastic gradient descent (SGD) has shown promise optimizing neural networks with millions of parameters and few if any alternatives are known to exist, it has moved to the heart of leading approaches to reinforcement learning (RL). For that reason, the recent result from OpenAI showing that a particular kind of evolution strategy (ES) can rival the performance of SGD-based deep RL methods with large neural networks provoked surprise. This result is difficult to interpret in part because of the lingering ambiguity on how ES actually relates to SGD. The aim of this paper is to significantly reduce this ambiguity through a series of MNIST-based experiments designed to uncover their relationship. As a simple supervised problem without domain noise (unlike in most RL), MNIST makes it possible (1) to measure the correlation between gradients computed by ES and SGD and (2) then to develop an SGD-based proxy that accurately predicts the performance of different ES population sizes. These innovations give a new level of insight into the real capabilities of ES, and lead also to some unconventional means for applying ES to supervised problems that shed further light on its differences from SGD. Incorporating these lessons, the paper concludes by demonstrating that ES can achieve 99% accuracy on MNIST, a number higher than any previously published result for any evolutionary method. While not by any means suggesting that ES should substitute for SGD in supervised learning, the suite of experiments herein enables more informed decisions on the application of ES within RL and other paradigms.	artificial neural network;evolution strategy;experiment;mnist database;reinforcement learning;stochastic gradient descent;supervised learning	Xingwen Zhang;Jeff Clune;Kenneth O. Stanley	2017	CoRR		artificial intelligence;supervised learning;artificial neural network;machine learning;mnist database;computer science;ambiguity;evolution strategy;population;reinforcement learning;stochastic gradient descent	ML	17.750934865332365	-32.94218936577344	55890
f956a35e9ae6a502fbd250f40adf1526a6061e3a	kernel factory: an ensemble of kernel machines	neural networks;ensemble learning;classification;random forests;regression;machine learning;random forest;classification learning algorithms;genetic algorithm;kernel factory;business and economics;prediction	0957-4174/$ see front matter 2012 Elsevier Ltd. A http://dx.doi.org/10.1016/j.eswa.2012.12.007 ⇑ Corresponding author. E-mail addresses: Michel.Ballings@UGent.be (M. UGent.be (D. Van den Poel). URL: http://www.crm.ugent.be (M. Ballings). We propose an ensemble method for kernel machines. The training data is randomly split into a number of mutually exclusive partitions defined by a row and column parameter. Each partition forms an input space and is transformed by an automatically selected kernel function into a kernel matrix K. Subsequently, each K is used as training data for a base binary classifier (Random Forest). This results in a number of predictions equal to the number of partitions. A weighted average combines the predictions into one final prediction. To optimize the weights, a genetic algorithm is used. This approach has the advantage of simultaneously promoting (1) diversity, (2) accuracy, and (3) computational speed. (1) Diversity is fostered because the individual K’s are based on a subset of features and observations, (2) accuracy is sought by automatic kernel selection and the genetic algorithm, and (3) computational speed is obtained because the computation of each K can be parallelized. Using five times twofold cross validation we benchmark the classification performance of Kernel Factory against Random Forest and Kernel-Induced Random Forest (KIRF). We find that Kernel Factory has significantly better performance than KernelInduced Random Forest. When the right kernel is selected Kernel Factory is also significantly better than Random Forest. In addition, an open-source R-software package of the algorithm (kernelFactory) is available from CRAN. 2012 Elsevier Ltd. All rights reserved.	benchmark (computing);binary classification;computation;genetic algorithm;kernel (operating system);kernel method;open-source software;parallel computing;random forest;randomness	Michel Ballings;Dirk Van den Poel	2013	Expert Syst. Appl.	10.1016/j.eswa.2012.12.007	kernel;principal component regression;random forest;kernel regression;kernel density estimation;kernel method;string kernel;kernel embedding of distributions;radial basis function kernel;kernel principal component analysis;computer science;machine learning;pattern recognition;data mining;graph kernel;mathematics;ensemble learning;tree kernel;variable kernel density estimation;polynomial kernel;artificial neural network;statistics;kernel smoother	AI	13.073987613685297	-37.38250291470309	56057
b84a977da5a1090d90b7d4e7833db1f834bd1e25	apply back propagation neural networks to the differential diagnosis of brain disease.	back propagation neural network;differential diagnosis		neural networks;software propagation	M. Gregson;Robert Ivor John;Briony Teather;R. Thompson	1994			computer science;artificial intelligence;machine learning	ML	12.324920131964296	-27.029088913526866	56114
0dc26a0e171301b8cc25efa2d9d5a2f4902113fd	genetic algorithm wrappers for feature subset selection in supervised inductive learning	inductive learning;feature subset selection;genetic algorithm	1. Inferential loss: Quality of the model produced by an inducer as detected through inferential loss evaluated over a holdout validation data set Dval ≡ D \ Dtrain 2. Model loss: “Size” of the model under a specified coding or representation 3. Ordering loss: Inference/classificationindependent and model-independent measure of data quality given only training and validation dataD and hyperparameters ÿ	data quality;genetic algorithm;inductive reasoning;inferential programming;inferential theory of learning;test set	William H. Hsu;Cecil P. Schmidt;James A. Louis	2002			multi-task learning;genetic algorithm;computer science;artificial intelligence;machine learning;pattern recognition;data mining;population-based incremental learning	AI	12.380940874449264	-34.17367532925365	56262
dc0f15686a8e959567b545ebd17b93f950f3829a	communication-efficient parallel block minimization for kernel machines		Kernel machines often yield superior predictive performance on various tasks; however, they suffer from severe computational challenges. In this paper, we show how to overcome the important challenge of speeding up kernel machines. In particular, we develop a parallel block minimization framework for solving kernel machines, including kernel SVM and kernel logistic regression. Our framework proceeds by dividing the problem into smaller subproblems by forming a block-diagonal approximation of the Hessian matrix. The subproblems are then solved approximately in parallel. After that, a communication efficient line search procedure is developed to ensure sufficient reduction of the objective function value at each iteration. We prove global linear convergence rate of the proposed method with a wide class of subproblem solvers, and our analysis covers strongly convex and some non-strongly convex functions. We apply our algorithm to solve large-scale kernel SVM problems on distributed systems, and show a significant improvement over existing parallel solvers. As an example, on the covtype dataset with half-a-million samples, our algorithm can obtain an approximate solution with 96% accuracy in 20 seconds using 32 machines, while all the other parallel kernel SVM solvers require more than 2000 seconds to achieve a solution with 95% accuracy. Moreover, our algorithm can scale to very large data sets, such as the kdd algebra dataset with 8 million samples and 20 million features.	approximation algorithm;computation;convex function;distributed computing;hessian;iteration;kernel (operating system);kernel method;line search;logistic regression;loss function;optimization problem;rate of convergence;turing machine	Cho-Jui Hsieh;Si Si;Inderjit S. Dhillon	2016	CoRR		kernel method;mathematical optimization;combinatorics;kernel embedding of distributions;radial basis function kernel;machine learning;mathematics;tree kernel;variable kernel density estimation;polynomial kernel	ML	21.100905317745553	-37.72159301490382	56338
6e7109494e92e0776b3351773e5d175da4386ca1	data splitting for artificial neural networks using som-based stratified sampling	data splitting;estensibilidad;modelizacion;variabilidad;sample size;statistical data;confiance;self organizing maps;validacion cruzada;large dataset;tamano muestra;random sampling;error sistematico;model performance;taille echantillon;kohonen algorithm;modelisation;algoritmo kohonen;artificial neural networks;confidence;conjunto diferencias;ensemble differences;function approximation;algorithme kohonen;confianza;bias;approximation d une fonction;muestreo aleatorio;validation croisee;donnee statistique;autoorganizacion;self organization;self organized map;difference set;cross validation;extensibilite;scalability;dato estadistico;reseau neuronal;variability;variabilite;echantillonnage aleatoire;modeling;aproximacion de funciones;red neuronal;stratified sampling;autoorganisation;erreur systematique;artificial neural network;variance;neural network;variancia	Data splitting is an important consideration during artificial neural network (ANN) development where hold-out cross-validation is commonly employed to ensure generalization. Even for a moderate sample size, the sampling methodology used for data splitting can have a significant effect on the quality of the subsets used for training, testing and validating an ANN. Poor data splitting can result in inaccurate and highly variable model performance; however, the choice of sampling methodology is rarely given due consideration by ANN modellers. Increased confidence in the sampling is of paramount importance, since the hold-out sampling is generally performed only once during ANN development. This paper considers the variability in the quality of subsets that are obtained using different data splitting approaches. A novel approach to stratified sampling, based on Neyman sampling of the self-organizing map (SOM), is developed, with several guidelines identified for setting the SOM size and sample allocation in order to minimize the bias and variance in the datasets. Using an example ANN function approximation task, the SOM-based approach is evaluated in comparison to random sampling, DUPLEX, systematic stratified sampling, and trial-and-error sampling to minimize the statistical differences between data sets. Of these approaches, DUPLEX is found to provide benchmark performance with good model performance, with no variability. The results show that the SOM-based approach also reliably generates high-quality samples and can therefore be used with greater confidence than other approaches, especially in the case of non-uniform datasets, with the benefit of scalability to perform data splitting on large datasets.		Robert J. May;Holger R. Maier;Graeme C. Dandy	2010	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2009.11.009	sample size determination;sampling;scalability;self-organization;systems modeling;self-organizing map;function approximation;computer science;artificial intelligence;machine learning;bias;stratified sampling;variance;confidence;artificial neural network;cross-validation;difference set;statistics	ML	10.140816762550461	-33.248541825884345	56342
958a8509cf214f9888582182b7189b55bf4013f9	comparison between real-time learning capabilities of the ids method and radial basis function networks	modeling technique;convergence;regression benchmark;soft computing;real time;regression benchmark real time learning capabilities ids method radial basis function networks ink drop spread soft computing paradigm artificial neural networks function approximation convergence;radial basis function networks;regression analysis convergence function approximation learning artificial intelligence radial basis function networks;artificial neural networks;ids method;function approximation;soft computing paradigm;radial basis function network;real time learning capabilities;ink drop spread;regression analysis;learning artificial intelligence;intrusion detection radial basis function networks artificial neural networks parallel processing fault tolerance training data ink brain modeling humans computer networks;human brain;artificial neural network	The ink drop spread (IDS) method is a modeling technique developed by algorithmically mimicking the information-handling processes of the human brain, and it has been proposed as a new soft computing paradigm. This study investigates the real-time performance of the IDS method. Radial basis function networks (RBFNs) are artificial neural networks that are characterized by the speed of learning. This study compares the real-time learning capability of the IDS method with that of RBFNs. In the approximation of five different functions used as a benchmark, the IDS method exhibits stable and fast convergence in terms of the learning time and the number of training examples used. This study also presents an effective approach to enhance the real-time performance of the IDS method.	approximation algorithm;artificial neural network;benchmark (computing);maxima and minima;online machine learning;programming paradigm;radial (radio);radial basis function;real-time clock;real-time computing;real-time transcription;soft computing	Masayuki Murakami;Nakaji Honda	2007	2007 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2007.4413837	convergence;function approximation;computer science;artificial intelligence;machine learning;data mining;radial basis function network;artificial neural network;regression analysis	Robotics	13.672644682688013	-31.251452681666258	56547
2f33d156e3482ca6c9ddb416ba24a2d453deb02d	an irwls procedure for svr	kernel;memory management;silicon;training data;support vector machines	In this paper we propose an Iterative Re-Weighted Least Square procedure in order to solve the Support Vector Machines for regression and function estimation. Furthermore, we include a new algorithm to train Support Vector Machines, covering both the proposed approach instead of the quadratic programming part and the most advanced methods to deal with large training data sets. Finally, the performance of the method is assessed by selected examples which show that the training time is much shorter and the memory requirements much less than the employed ones by current methods.	algorithm;computer memory;iterative method;iteratively reweighted least squares;quadratic programming;requirement;support vector machine	Fernando Pérez-Cruz;Ángel Navia-Vázquez;Pedro Luis Alarcón-Diana;Antonio Artés-Rodríguez	2000	2000 10th European Signal Processing Conference		least squares support vector machine;computer science;theoretical computer science;machine learning;data mining;sequential minimal optimization	HPC	20.946444148126588	-37.94883088550251	56596
3026863265849edeea4761171a59976a92bf4d06	critical points of an autoencoder can provably recover sparsely used overcomplete dictionaries		In Dictionary Learning one is trying to recover incoherent matrices A∗ ∈ Rn×h (typically overcomplete and whose columns are assumed to be normalized) and sparse vectors x∗ ∈ R with a small support of size h for some 0 < p < 1 while being given access to observations y ∈ R where y = A∗x∗. In this work we undertake a rigorous analysis of the possibility that dictionary learning could be performed by gradient descent on Autoencoders, which are R → R neural network with a single ReLU activation layer of size h. Towards the above objective we propose a new autoencoder loss function which modifies the squared loss error term and also adds new regularization terms. We create a proxy for the expected gradient of this loss function which we motivate with high probability arguments, under natural distributional assumptions on the sparse code x∗. Under the same distributional assumptions on x∗, we show that, in the limit of large enough sparse code dimension, any zero point of our proxy for the expected gradient of the loss function within a certain radius of A∗ corresponds to dictionaries whose action on the sparse vectors is indistinguishable from that of A∗. We also report simulations on synthetic data in support of our theory. ∗Equal Contribution †rangamani.akshay@jhu.edu ‡amukhe14@jhu.edu aarora8@jhu.edu ¶tganapathi@salesforce.com ‖basu.amitabh@jhu.edu ∗∗spchin@cs.bu.edu ††trac@jhu.edu 1 ar X iv :1 70 8. 03 73 5v 1 [ cs .L G ] 1 2 A ug 2 01 7	artificial neural network;autoencoder;column (database);dictionary;gradient descent;loss function;machine learning;mean squared error;neural coding;proxy server;rectifier (neural networks);simulation;sparse matrix;synthetic data;with high probability	Akshay Rangamani;Anirbit Mukherjee;Ashish Arora;Tejaswini Ganapathy;Amitabh Basu;Sang Peter Chin;Trac D. Tran	2017	CoRR		critical point (mathematics);autoencoder;mathematics;machine learning;artificial intelligence;pattern recognition	ML	22.824918398825755	-32.42799951294832	56772
19976abfe3ead5fa5536e0633a7f66be400a39d5	a neural network approach to approximating map in belief networks	mean field theory;neural networks;simulated annealing;probabilistic inference;bayesian belief networks;map problems;belief network;neural network	Bayesian belief networks (BBN) are a widely studied graphical model for representing uncertainty and probabilistic interdependence among variables. One of the factors that restricts the model's wide acceptance in practical applications is that the general inference with BBN is NP-hard. This is also true for the maximum a posteriori probability (MAP) problem, which is to find the most probable joint value assignment to all uninstantiated variables, given instantiation of some variables in a BBN. To circumvent the difficulty caused by MAP's computational complexity, we suggest in this paper a neural network approximation approach. With this approach, a BBN is treated as a neural network without any change or transformation of the network structure, and the node activation functions are derived based on an energy function defined over a given BBN. Three methods are developed. They are the hill-climbing style discrete method, the simulated annealing method, and the continuous method based on the mean field theory. All three methods are for BBN of general structures, with the restriction that nodes of BBN are binary variables. In addition, rules for applying these methods to noisy-or networks are also developed, which may lead to more efficient computation in some cases. These methods' convergence is analyzed, and their validity tested through a series of computer experiments with two BBN of moderate size and complexity. Although additional theoretical and empirical work is needed, the analysis and experiments suggest that this approach may lead to effective and accurate approximation for MAP problems.		Yun Peng;Miao Jin	2002	International journal of neural systems	10.1142/S0129065702001175	computer science;artificial intelligence;theoretical computer science;machine learning;bayesian network;artificial neural network	ML	18.91803869578567	-25.900477819858896	56870
c16f3de4a7228d7e91bc2434734c6edef89d4828	on the curse of dimensionality in supervised learning of smooth regression functions	minimax;supervised learning;high dimensional;nonparametric regression;van trees;analytic function	In this paper, the effect of dimensionality on the supervised learning of infinitely differentiable regression functions is analyzed. By invoking the Van Trees lower bound, we prove lower bounds on the generalization error with respect to the number of samples and the dimensionality of the input space both in a linear and non-linear context. It is shown that in non-linear problems without prior knowledge, the curse of dimensionality is a serious problem. At the same time, we speculate counter-intuitively that sometimes supervised learning becomes plausible in the asymptotic limit of infinite dimensionality.	asymptote;curse of dimensionality;generalization error;nonlinear system;supervised learning	Elia Liitiäinen;Francesco Corona;Amaury Lendasse	2011	Neural Processing Letters	10.1007/s11063-011-9188-7	semi-supervised learning;minimax;curse of dimensionality;computer science;analytic function;machine learning;pattern recognition;mathematics;supervised learning;nonparametric regression;statistics;dimensionality reduction	ML	21.21957628537209	-32.9453868467525	57007
3973abbbfcfe040baa7231e0aa79afac14568bb9	integrating models of discrimination and characterization for learning from examples in open domains	integrable model;real world application;learning from examples;datavetenskap datalogi;concept learning;computer science;statistical distribution	It is argued that in applications of concept learning from examples where not every possible category of the domain is present in the training set (i.e., most real world applications), classification performance can be improved by integrating suitable discriminative and characteristic classification schemes. The suggested approach is to first discriminate between the categories present in the training set and then characterize each of these categories against all possible categories. To show the viabil i ty of this approach, a number of different discriminators and characterizers are integrated and tested. In particular, a novel characterization method that makes use of the informat ion about the statistical distr ibution of feature values that can be extracted from the training examples is used. The experimental results strongly supports the thesis of the paper.	concept learning;test set	Paul Davidsson	1997			probability distribution;concept learning;computer science;artificial intelligence;machine learning;data mining;mathematics;statistics	AI	11.57329074483774	-36.669937095661204	57077
f8464f31bd0dd939d1cf1a35ac6e3a6d3cf2c3bf	inner and outer capture basin approximation with support vector machines	support vector machines;optimal control	We propose a new approach to solve target hitting problems, that iteratively approximates capture basins at successive times, using a machine learning algorithm trained on points of a grid with boolean labels. We consider two variants of the approximation (from inside and from outside), and we state the conditions on the machine learning procedure that guarantee the convergence of the approximations towards the actual capture basin when the resolution of the grid decreases to 0. Moreover, we define a control procedure which uses the set of capture basin approximations to drive a point into the target. When using the inner approximation, the procedure guarantees to hit the target, and when the resolution of the grid tends to 0, the controller tends to the optimal one (minimizing time to hit the target). We use Support Vector Machines as a particular learning method, because they provide parsimonious approximations, from which one can derive fast and efficient controllers. We illustrate the method on two simple examples, Zermelo and car on the hill problems.	algorithm;approximation;machine learning;occam's razor;support vector machine	Laetitia Chapel;Guillaume Deffuant	2011			engineering;control engineering;support vector machine;structural basin	ML	20.66428158141078	-24.422782786829465	57095
7b39b122daaf761cb040e7518a54987d2800c3ad	annealing by two sets of interactive dynamics	relaxation theory hopfield neural nets boltzmann machines simulated annealing stochastic processes correlation theory approximation theory;algorithms artificial intelligence models statistical nerve net nonlinear dynamics numerical analysis computer assisted;correlation theory;combinatorial optimization mean field annealing hopfield neural network boltzmann assumption interactive mean field equations mean correlation mean activation interactive dynamics mathematical framework kullback leibler divergence graph bisection problem numerical simulation;annealing equations stochastic processes hopfield neural networks boltzmann distribution numerical simulation independent component analysis mathematics statistics;hopfield neural nets;simulated annealing;hopfield neural network;approximation theory;mean field;stochastic processes;mean field approximation;relaxation theory;boltzmann machines;numerical simulation;kullback leibler	This work derives the mean field approximation to the mean configuration of a stochastic Hopfield neural network under the Boltzmann assumption. The new approximation is realized by two sets of interactive mean field equations, respectively estimating mean activations subject to mean correlations and mean correlations subject to mean activations. The two sets of interactive dynamics are derived based on two dual mathematical frameworks. Each aims to optimize the objective quantified by a combination of the Kullback-Leibler (KL) divergence and the correlation strength between any two distinct fluctuated variables subject to fixed mean correlations or activations. The new method is applied to the graph bisection problem. By numerical simulations, we show that the new method effectively improves in both performance and relaxation efficiency against the naive mean field equation.	approximation;artificial neural network;computer simulation;dual;estimated;graph - visual representation;graph partition;hopfield network;kullback–leibler divergence;linear programming relaxation;mathematics;mean field particle methods;neural network simulation;numerical analysis;restricted boltzmann machine;simulated annealing	Jiann-Ming Wu	2004	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2004.826395	computer simulation;stochastic process;mathematical optimization;artificial intelligence;theoretical computer science;mean field theory;machine learning;mathematics;statistics	ML	20.62016524687232	-26.42757243125313	57172
0a35181a9d729d18024bd29be8d938edc86d8b63	decoupling gradient-like learning rules from representations		In this appendix we provide intuition for what l̃ does relative to l, and show how Gi encodes the dissimilarity function in (1). We begin by considering the stochastic gradient descent learning rule as an example to understand what the ∂f(·, βi)/∂βi terms in a learning rule do, and how they should be changed to decouple the decisions of which learning rule to use and which parameterized function to use. For simplicity, in this appendix we consider the setting where βi := θi−1 and we use the shorthand θi := li(f, θ0, ω). Also, recall that in all appendices we use the shorthands: d := d x,θ0,ω i , and G x i := G x i . The stochastic gradient descent update to make f approximate some target function, f, can be written as:	approximation algorithm;coupling (computer programming);learning rule;stochastic gradient descent	Philip S. Thomas;Christoph Dann;Emma Brunskill	2018			machine learning;decoupling (cosmology);artificial intelligence;computer science	ML	19.64538470598732	-32.98517559386792	57232
ded8f35a0acb46641933a58052f4468443236338	a learning method for neural networks with a subordinate evaluation function	evaluation function;learning methods;neural network	A new learning algorithm, master learning algorithm (MLA), is proposed, which treats two evaluation functions for a neural networks, independently. In this method, the learning process is divided into two steps: optimization of total error function E for learning data, and that of subordinate evaluation function C. In the first step, the back propagation learning algorithm (BP) is applied to the learning data until the value of .E becomes small enough. In the second step, function C is minimized under a constraint of E. This method makes it possible to improve the network performance, such as generalization, robustness, and learnability for additional data, by using an appropriate subordinate function C. The applicability of this method is shown through the numerical experiments. This algorithm can be easily extended to cases with more than two evaluation functions.	algorithm;artificial neural network;backpropagation;evaluation function;experiment;learnability;mathematical optimization;network performance;numerical analysis;software propagation	Kenji Ohkuma	1992		10.1145/130069.130076	unsupervised learning;types of artificial neural networks;wake-sleep algorithm;artificial intelligence;recurrent neural network;machine learning;pattern recognition;time delay neural network;deep learning;competitive learning;artificial neural network	ML	16.1374759148488	-29.623958262820675	57358
05fd5edb47ec1fe6b628ed5cdf8d43f05b5f8605	prediction games and arcing algorithms	prediccion;optimisation;minimax problem;generalization error;tecnologia electronica telecomunicaciones;convergence;game theory;computacion informatica;serie taylor;optimizacion;problema minimax;erreur generalisation;grupo de excelencia;teoria juego;estrategia;theorie jeu;arcing algorithm;systeme adaptatif;kuhn tucker necessary condition;probleme minimax;algorithme;strategy;algorithm;convergencia;condition necessaire kuhn tucker;ciencias basicas y experimentales;algorithme adaboost;adaptive system;sistema adaptativo;adaptive reweighting and combining algorithm;optimization;tecnologias;grupo a;strategie;prediction;adaboost algorithm;algoritmo;taylor series	The theory behind the success of adaptive reweighting and combining algorithms (arcing) such as Adaboost (Freund & Schapire, 1996a, 1997) and others in reducing generalization error has not been well understood. By formulating prediction as a game where one player makes a selection from instances in the training set and the other a convex linear combination of predictors from a finite set, existing arcing algorithms are shown to be algorithms for finding good game strategies. The minimax theorem is an essential ingredient of the convergence proofs. An arcing algorithm is described that converges to the optimal strategy. A bound on the generalization error for the combined predictors in terms of their maximum error is proven that is sharper than bounds to date. Schapire, Freund, Bartlett, and Lee (1997) offered an explanation of why Adaboost works in terms of its ability to produce generally high margins. The empirical comparison of Adaboost to the optimal arcing algorithm shows that their explanation is not complete.	adaboost;algorithm;bartlett's bisection theorem;convergence (action);generalization (psychology);generalization error;minimax theorem;test set	Leo Breiman	1999	Neural Computation	10.1162/089976699300016106	adaboost;game theory;mathematical optimization;convergence;prediction;strategy;computer science;artificial intelligence;taylor series;adaptive system;machine learning;mathematics;algorithm;statistics;generalization error	ML	20.241106761784035	-30.52514170809177	57397
1ba0d258b91887e4cab6cc326d82f99afa45e5a6	resource allocation for a hybrid evolutionary learning system used for pattern recognition	pattern recognition;resource allocation		pattern recognition	Louis A. Tamburino;Mateen M. Rizki	1996			machine learning;computer science;artificial intelligence;pattern recognition;resource allocation	Vision	11.464253907800964	-26.856218002703358	57398
3f946f71e70387e98b515732de071f31cdbfd9b1	optimal continuous state pomdp planning with semantic observations		This work develops novel strategies for optimal planning with semantic observations using continuous state Partially Observable Markov Decision Processes (CPOMDPs). We propose two major innovations to Gaussian mixture (GM) CPOMDP policy approximation methods. While these state of the art methods have many theoretically nice properties, they are hampered by the inability to efficiently represent and reason over hybrid continuous-discrete probabilistic models. The first major innovation is the derivation of closed-form variational Bayes (VB) GM approximations of PBVI Bellman policy backups, using softmax models of continuous-discrete semantic observation probabilities. The second major innovation is a new clustering-based technique for mixture condensation that scales well to very large GM policy functions and belief functions. Simulation results for a target search and interception task with binary semantic observations show that the GM policies resulting from these innovations are more effective than those produced by other state of the art GM approximations, but require significantly less modeling overhead and runtime cost.		Luke Burks;Ian Loefgren;Nisar Ahmed	2017	2017 IEEE 56th Annual Conference on Decision and Control (CDC)	10.1109/CDC.2017.8263866	mathematical optimization;computer science;cluster analysis;observable;partially observable markov decision process;markov decision process;gaussian;bayes' theorem;probabilistic logic;softmax function	ML	23.625776553909724	-27.330678590951496	57466
118695570b3fcf8793a121ef3c5fb4424a029524	learning in hybrid noise environments using statistical queries	model combination;noisy data;learning environment;statistical query;probably approximately correct;hypothesis test	"""We consider formal models of learning from noisy data. Speciically, we focus on learning in the probability approximately correct model as deened by Valiant. Two of the most widely studied models of noise in this setting have been classiication noise and malicious errors. However, a more realistic model combining the two types of noise has not been formalized. We deene a learning environment based on a natural combination of these two noise models. We rst show that hypothesis testing is possible in this model. We next describe a simple technique for learning in this model, and then describe a more powerful technique based on statistical query learning. We show that the noise tolerance of this improved technique is roughly optimal with respect to the desired learning accuracy and that it provides a smooth tradeoo between the tolerable amounts of the two types of noise. Finally, we show that statistical query simulation yields learning algorithms for other combinations of noise models, thus demonstrating that statistical query speciication truly captures the generic fault tolerance of a learning algorithm. An important goal of research in machine learning is to determine which tasks can be automated, and for those which can, to determine their information and computation requirements. One way to answer these questions is through the development and investigation of formal models of machine learning which capture the task of learning under plausible assumptions. In this work, we consider the formal model of learning from examples called \probably approximately correct"""" (PAC) learning as deened by Valiant Val84]. In this setting, a learner attempts to approximate an unknown target concept simply by viewing positive and negative examples of the concept. An adversary chooses, from some speciied function class, a hidden f0; 1g-valued target function deened over some speciied domain of examples and chooses a probability distribution over this domain. The goal of the learner is to output in both polynomial time and with high probability, an hypothesis which is \close"""" to the target function with respect to the distribution of examples. The learner gains information about the target function and distribution by interacting with an example oracle. At each request by the learner, this oracle draws an example randomly according to the hidden distribution, labels it according to the hidden target function, and returns the labelled example to the learner. A class of functions F is said to be PAC learnable if 1996 Springer-Verlag."""	adversary (cryptography);approximation algorithm;fault tolerance;formal language;information and computation;interaction;machine learning;oracle database;probably approximately correct learning;randomness;requirement;signal-to-noise ratio;simulation;springer (tank);time complexity;with high probability	Scott E. Decatur	1995		10.1007/978-1-4612-2404-4_25	computer science;machine learning;pattern recognition;data mining	ML	18.48639541976394	-33.859046438904905	57559
30cb0fd496ef180d593f2d2af10cc2ab6adcda4e	on concentration of discrete distributions with applications to supervised learning of classifiers	discrete distribution;annan data och informationsvetenskap;mathematics;generic model;supervised learning;supervised classification;machine learning;matematik;other computer and information science	Computational procedures using independence assumptions in various forms are popular in machine learning, although checks on empirical data have given inconclusive results about their impact. Some theoretical understanding of when they work is available, but a definite answer seems to be lacking. This paper derives distributions that maximizes the statewise difference to the respective product of marginals. These distributions are, in a sense the worst distribution for predicting an outcome of the data generating mechanism by independence. We also restrict the scope of new theoretical results by showing explicitly that, depending on context, independent (’Näıve’) classifiers can be as bad as tossing coins. Regardless of this, independence may beat the generating model in learning supervised classification and we explicitly provide one such scenario.		Magnus Ekdahl;Timo Koski	2007		10.1007/978-3-540-73499-4_2	semi-supervised learning;probability distribution;computer science;artificial intelligence;machine learning;pattern recognition;data mining;mathematics;supervised learning;statistics;generalization error	ML	19.42628694673795	-33.80882582566741	57699
527a1d5f95040e4143c5fdb2821c0513e5cf5726	evaluating parallel logistic regression models	parallel computing;big data logistic regression model parallel computing sublinear method;sublinear method;approximation theory;algorithm design and analysis sparks logistics computational modeling machine learning algorithms approximation algorithms vectors;big data;design;regression analysis;performance requirement parallel logistic regression models machine learning linear model computation scalability big data distributed platform parallel algorithm sublinear approximation design guidelines;regression analysis approximation theory big data design learning artificial intelligence parallel algorithms;learning artificial intelligence;logistic regression model;parallel algorithms	Logistic regression (LR) has been widely used in applications of machine learning, thanks to its linear model. However, when the size of training data is very large, even such a linear model can consume excessive memory and computation time. To tackle both resource and computation scalability in a big-data setting, we evaluate and compare different approaches in distributed platform, parallel algorithm, and sublinear approximation. Our empirical study provides design guidelines for choosing the most effective combination for the performance requirement of a given application.	a library for support vector machines;apache hadoop;apache mahout;approximation;big data;computation;computer memory;experiment;gradient descent;lr parser;linear model;logistic regression;machine learning;mathematical optimization;online algorithm;parallel algorithm;spark;scalability;speedup;time complexity	Haoruo Peng;Ding Liang;Cyrus Choi	2013	2013 IEEE International Conference on Big Data	10.1109/BigData.2013.6691743	computer science;theoretical computer science;machine learning;data mining;logistic model tree	SE	19.359812442673437	-37.17379041419992	57816
6df222a496a033c08fbeed72bbac8b8186ab7740	hardware implementations of artificial neural networks	hardware implementation;artificial neural network;neural network	Many researches on Artificial Neural Networks ( A N N ) are carried out on neural systems built as software environments on workstations or PCs. Several such products are commercially available, and in some cases hardware accelerators can be added to enhance performance. On the other hand, very few neural systems are built using dedicated hardware, and there is no commercial widely diffused general purpose hardware neurocomputer.		Dante Del Corso	1993		10.1007/3-540-56798-4_181	nervous system network models;types of artificial neural networks;computer science;machine learning;physical neural network;time delay neural network;artificial neural network	ML	13.852649285356701	-26.304430846757274	57861
ba18247cd3ce9f711eecc7296f1c3561dbfb6cc2	learning long-term dependencies with gradient descent is difficult	optimisation;long term dependencies;long period;learning algorithm;neural networks;cost function;metodo descenso;gradient method;efficient learning long term dependencies gradient descent recognition production problems prediction problems recurrent neural network training temporal contingencies input output sequence mapping;prediction problems;delay effects;algorithme apprentissage;recurrent neural network training;computer networks;input output;systeme dynamique;methode gradient;temporal contingencies;reseaux neuronaux;efficient learning;recognition;numerical analysis;discrete transforms;metodo gradiente;gradient descent;displays;production problems;recurrent neural networks production delay effects intelligent networks neural networks discrete transforms computer networks cost function neurofeedback displays;pattern recognition;production;dynamical systems;optimization;input output sequence mapping;intelligent networks;recurrent neural nets;reconnaissance forme;recurrent neural networks;recurrent neural network;neurofeedback;learning artificial intelligence;descent method;methode descente;numerical analysis recurrent neural nets learning artificial intelligence	Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered.	algorithm;artificial neural network;gradient descent;input/output;machine learning;neural network simulation;recurrent neural network;span distance	Yoshua Bengio;Patrice Y. Simard;Paolo Frasconi	1994	IEEE transactions on neural networks	10.1109/72.279181	computer science;artificial intelligence;recurrent neural network;machine learning;artificial neural network;algorithm	ML	18.056940261720094	-27.21170106095501	57870
9e62f3a30f2855958358c7044dc9bea1d5835a17	'mechanical' neural learning and infomax orthonormal independent component analysis	principal component analysis neural nets learning artificial intelligence dynamics;neural nets;learning model;independent component analysis nonlinear dynamical systems signal processing algorithms mechanical systems nonlinear equations neural networks frequency estimation industrial engineering analytical models algorithm design and analysis;independent component analysis;dynamics;principal component analysis;learning rule learning models dynamics mechanical system orthonormal independent component analysis bell sejlunoski principle infomax;learning artificial intelligence;learning theory;mechanical systems	We present a new class of learning models for linear as well as nonlinear neural learners, deriving from the study of the dynamics of an abstract rigid mechanical system. The set of equations describing the motion of this system may be readily interpreted as a learning rule for orthogonal networks. As a simple example of how to use the learning theory, a case of the orthonormal independent component analysis based on the Bell-Sejlunoski's InfoMax principle is discussed through simulations.		Simone G. O. Fiori;Pietro Burrascano	1999		10.1109/IJCNN.1999.831088	infomax;independent component analysis;dynamics;computer science;artificial intelligence;machine learning;learning theory;pattern recognition;mechanical system;artificial neural network;principal component analysis	ML	20.918979963981315	-28.535690600333165	57917
0277bdd8e3a3ea452131271b2ba4ecec3511bf55	parallel training of an improved neural network for text categorization	parallel computing;neural networks;text categorization	This paper studies parallel training of an improved neural network for text categorization. With the explosive growth on the amount of digital information available on the Internet, text categorization problem has become more and more important, especially when millions of mobile devices are now connecting to the Internet. Improved back-propagation neural network (IBPNN) is an efficient approach for classification problems which overcomes the limitations of traditional BPNN. In this paper, we utilize parallel computing to speedup the neural network training process of IBPNN. The parallel IBNPP algorithm for text categorization is implemented on a Sun Cluster with 34 nodes (processors). The communication time and speedup for the parallel IBPNN versus various number of nodes are studied. Experiments are conducted on various data sets and the results show that the parallel IBPNN together with SVD technique achieves fast computational speed and high text categorization correctness.	algorithm;artificial neural network;backpropagation;categorization;central processing unit;computation;correctness (computer science);digital data;document classification;experiment;feature vector;internet;mobile device;parallel computing;run time (program lifecycle phase);singular value decomposition;software propagation;solaris cluster;speedup;time complexity	Chenghua Li;Laurence Tianruo Yang;Man Lin	2013	International Journal of Parallel Programming	10.1007/s10766-013-0245-x	parallel computing;computer science;theoretical computer science;machine learning;pattern recognition;artificial neural network	ML	12.38307899655413	-36.03462868432892	58075
1fcbf15898db36990f651c1e5cdc0b405855de2c	measuring classifier performance: a coherent alternative to the area under the roc curve	evaluation performance;performance evaluation;misclassification rate;evaluacion prestacion;auc;metric;intelligence artificielle;classification;roc curves;journal article;sensitivity;receiver operating characteristic curves;classification rules;loses;roc curve;error rate;artificial intelligence;metrico;inteligencia artificial;specificity;metodo roc;methode roc;loss;cost;clasificacion;metrique;roc curvet	The area under the ROC curve (AUC) is a very widely used measure of performance for classification and diagnostic rules. It has the appealing property of being objective, requiring no subjective input from the user. On the other hand, the AUC has disadvantages, some of which are well known. For example, the AUC can give potentially misleading results if ROC curves cross. However, the AUC also has a much more serious deficiency, and one which appears not to have been previously recognised. This is that it is fundamentally incoherent in terms of misclassification costs: the AUC uses different misclassification cost distributions for different classifiers. This means that using the AUC is equivalent to using different metrics to evaluate different classification rules. It is equivalent to saying that, using one classifier, misclassifying a class 1 point is p times as serious as misclassifying a class 0 point, but, using another classifier, misclassifying a class 1 point is P times as serious, where p≠P. This is nonsensical because the relative severities of different kinds of misclassifications of individual points is a property of the problem, not the classifiers which happen to have been chosen. This property is explored in detail, and a simple valid alternative to the AUC is proposed.	angular defect;coefficient;coherence (physics);convex hull;loss function;r language;receiver operating characteristic;sensitivity and specificity;smoothing;statistical classification;weight function;zero-point energy	David J. Hand	2009	Machine Learning	10.1007/s10994-009-5119-5	econometrics;computer science;machine learning;pattern recognition;mathematics;receiver operating characteristic;statistics	ML	10.68118876703784	-35.29505515346039	58119
37ec119418ed13b4808a9f3bc86ffc7eadb3e4c8	generalized connectionist associative memory	associative memory	This paper presents a generalized associative memory model, which stores a collection of tuples whose components are sets rather than scalars. It is shown that all library patterns are stored stably. On the other hand spurious memories may develop. Applications of this model to storage and retrieval of naturallyarising generalized sequences in bioinformatics are presented. The model is shown to work well for detection of novel generalized sequences against a large database of stored sequences, and for removal of noisy black pixels in a probe image against a very large set of stored images.	bidirectional associative memory;bioinformatics;colors of noise;connectionism;content-addressable memory;database;library classification;pixel	Nigel P. Duffy;Arun K. Jagota	1999			computer science;artificial intelligence;theoretical computer science;machine learning;content-addressable memory;bidirectional associative memory;memory map	DB	13.269487129854928	-30.01717058181816	58123
615eb518df966193b9d90834419b25117361d2d2	a new clustering method for improving plasticity and stability in handwritten character recognition systems	cenparmi isolated digit database;cluster algorithm;pattern clustering;clustering methods stability character recognition shape measurement clustering algorithms prototypes machine learning pattern recognition subspace constraints neural networks;pattern clustering handwritten character recognition learning artificial intelligence;online clustering algorithm;cenparmi isolated digit database handwritten character recognition systems online clustering algorithm incremental learning adaptive resonance theory;incremental learning;clustering method;number of clusters;handwritten character recognition systems;learning artificial intelligence;similarity measure;handwritten character recognition;adaptive resonance theory	This paper presents a new online clustering algorithm in order to improve plasticity and stability in handwritten character recognition systems. Our clustering algorithm is able to automatically determine the optimal number of clusters in the input data. An incremental learning technique similar to adaptive resonance theory (ART) is used to determine the best cluster for new data. Our technique also allows the previously learned clusters to be merged whenever the newly arrived data points push their centers close together. We also developed new features and similarity measures in order to describe and compare the shapes of handwritten digits to be used in our clustering algorithm. Results of our algorithm on clustering the shapes of the handwritten numerals from the CENPARMI isolated digit database are shown. Our method can incrementally learn new handwriting styles of digits, without forgetting the previous ones, therefore it can improve plasticity and stability	adaptive resonance theory;algorithm;data point;handwriting recognition;optical character recognition	Javad Sadri;Ching Y. Suen;Tien D. Bui	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.114	correlation clustering;speech recognition;fuzzy clustering;flame clustering;intelligent character recognition;computer science;adaptive resonance theory;intelligent word recognition;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;cluster analysis;stability;clustering high-dimensional data;conceptual clustering	Vision	13.745295915635884	-32.71168131026696	58295
15b22680f71dc48ed8ad2d2c840f61a1774667a6	universal approximation propriety of flexible beta basis function neural tree	trees mathematics approximation theory neural nets time series;time series approximation area universal approximation propriety flexible beta basis function neural tree fbbfnt model tree encoding method beta basis function neural network;function approximation transfer functions artificial neural networks indexes computers	In this paper, the universal approximation propriety is proved for the Flexible Beta Basis Function Neural Tree (FBBFNT) model. This model is a tree-encoding method for designing Beta basis function neural network. The performance of FBBFNT is evaluated for benchmark problems drawn from time series approximation area and is compared with other methods in the literature.	approximation algorithm;artificial neural network;basis function;benchmark (computing);jenkins;time series;universal approximation theorem	Souhir Bouaziz;Adel M. Alimi;Ajith Abraham	2014	2014 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2014.6889671	mathematical optimization;function approximation;machine learning;universal approximation theorem;mathematics;radial basis function network;algorithm	Robotics	14.674718204061588	-28.06384132603043	58368
db41674d0d340cf77d7f6b561797e37b4bf6207f	nonlinear bayesian filters for training recurrent neural networks	numerical stability;linear estimation;chaotic time series;kalman filter;dynamic system;bayesian filtering;recurrent neural network;state space model;neural network	In this paper, we present nonlinear Bayesian filters for training recurrent neural networks with a special emphasis on a novel, more accurate, derivative-free member of the approximate Bayesian filter family called the cubature Kalman filter. We discuss the theory of Bayesian filters, which is rooted in the state-space modeling of the dynamic system in question and the linear estimation principle. For improved numerical stability and optimal performance during training period, a number of techniques of how to tune Bayesian filters is suggested. We compare the predictability of various Bayesian filter-trained recurrent neural networks using a chaotic time-series. From the empirical results, we conclude that the performance may be greatly improved by the new square-root cubature Kalman filter.	approximation algorithm;artificial neural network;bayesian network;dynamical system;kalman filter;nonlinear system;numerical integration;numerical stability;recurrent neural network;state space;time series	Ienkaran Arasaratnam;Simon Haykin	2008		10.1007/978-3-540-88636-5_2	kalman filter;feedforward neural network;probabilistic neural network;types of artificial neural networks;variable-order bayesian network;computer science;state-space representation;recurrent neural network;dynamical system;machine learning;control theory;time delay neural network;deep learning;artificial neural network;numerical stability;dynamic bayesian network;intelligent control	ML	14.549964272863765	-27.373792787055542	58379
1dacfaccfc6959f7297e3056b124fca4b3d4004e	a modal learning adaptive function neural network applied to handwritten digit recognition	piecewise linear;supervised learning;natural computing;snap drift neural network;handwritten digit recognition;piecewise linear function;adaptive function neural network;active network;modal learning;machine learning;gradient descent;handwritten digits recognition;natural language;neuronal activity;on line learning;neural network	A novel combination of the adaptive function neural network (ADFUNN) and on-line snap-drift learning is presented in this paper and applied to optical and pen-based recognition of handwritten digits [E. Alpaydin, F. Alimoglu for Optical Recognition of Handwritten Digits and E. Alpaydin, C. Kaynak for Pen-Based Recognition of Handwritten Digits http://www.ics.uci.edu/~mlearn/databases/optdigits/http://www.ics.uci.edu/~mlearn/databases/pendigits/]. Snap-drift [S.W. Lee, D. Palmer-Brown, C.M. Roadknight, Performance-guided neural network for rapidly self-organising active network management (Invited Paper), Journal of Neurocomputing, 61C, 2004, pp. 5-20] employs the complementary concepts of common (intersection) feature learning (called snap) and LVQ (drift towards the input patterns) learning, and is a fast, unsupervised method suitable for on-line learning and non-stationary environments where new patterns are continually introduced. ADFUNN [M. Kang, D. Palmer-Brown, An adaptive function neural network (ADFUNN) for phrase recognition, in: The International Joint Conference on Neural Networks (IJCNN05), Montreal, Canada, 2005, D. Palmer-Brown, M. Kang, ADFUNN: An adaptive function neural network, in: The 7th International Conference on Adaptive and Natural Computing Algorithms (ICANNGA05), Coimbra, Portugal, 2005] is based on a linear piecewise neuron activation function that is modified by a novel gradient descent supervised learning algorithm. It has recently been applied to the Iris dataset, and a natural language phrase recognition problem, exhibiting impressive generalisation classification ability with no hidden neurons. The unsupervised single layer snap-drift is effective in extracting distinct features from the complex cursive-letter datasets, and the supervised single layer ADFUNN is capable of solving linearly inseparable problems rapidly. In combination within one network (SADFUNN), these two methods are more powerful and yet simpler than MLPs, at least on this problem domain. We experiment on SADFUNN with two handwritten digits datasets problems from the UCI Machine Learning repository. The problems are learned rapidly and higher generalisation results are achieved than with a MLP.	artificial neural network;modal logic	Miao Kang;Dominic Palmer-Brown	2008	Inf. Sci.	10.1016/j.ins.2008.05.011	speech recognition;piecewise linear function;computer science;artificial intelligence;machine learning;supervised learning;artificial neural network;algorithm	ML	13.257357511356787	-28.48427291875001	58665
a021f80bbd88aba7b606ba258f80e6d3b58fcb96	linear classifiers by window training and basis exchange	stochastic approximation;locally minimum error rate linear classifiers window training basis exchange stochastic approximation misclassification probability minimization statistically generated data perceptron training computationally convenient alternative;pattern classification;error rate;training algorithm;error analysis stochastic processes error correction bayesian methods algorithm design and analysis piecewise linear approximation approximation algorithms aggregates covariance matrix piecewise linear techniques	Window training, based on an extended form of stochastic approximation, offers a means of producing linear classifiers that minimize the probability of misclassification of statistically generated data. However, window training may produce a local minimum that exceeds the global minimum error rate. To overcome this defect it is useful to precede window training by perceptron training. When a significantly large set of exemplars of the data is available at the beginning of the training process, the basic exchange algorithm offers a computationally convenient alternative to the window training algorithm to achieve a locally minimum error rate.	linear classifier	Leon Bobrowski;Jack Sklansky	1994		10.1109/ICPR.1994.576999	stochastic approximation;mathematical optimization;approximation error;word error rate;computer science;machine learning;pattern recognition;statistics	Vision	15.311772599001081	-35.343550727773994	58777
7e0e5c9cce8d7bcb2abc50840b3658d776adff51	nonlinear backpropagation: doing backpropagation without derivatives of the activation function	nonlinear network synthesis;backpropagation algorithms neurons equations very large scale integration hardware numerical simulation neural networks recurrent neural networks read only memory biomedical optical imaging;evaluation performance;non linear programming;performance evaluation;metodo recurrencia;backpropagation neural network;learning;transfer functions;recurrence method;activation function;implementation;programacion no lineal;evaluacion prestacion;nonlinear gradient descent nonlinear backpropagation activation function neural processors recurrent backpropagation feedforward networks nettalk problem analog vlsi;circuit vlsi;programmation non lineaire;indexing terms;backpropagation;aprendizaje;analog very large scale integrated;ejecucion;neural chips;apprentissage;analogue integrated circuits;vlsi circuit;backpropagation algorithm;vlsi;analog vlsi;algorithme retropropagation;feedforward neural nets;nonlinear network synthesis backpropagation feedforward neural nets transfer functions analogue integrated circuits vlsi neural chips recurrent neural nets;recurrent neural nets;circuito vlsi;reseau neuronal;back propagation;red neuronal;methode recurrence;neural network;numerical simulation;algoritmo retropropagacion	The conventional linear backpropagation algorithm is replaced by a nonlinear version, which avoids the necessity for calculating the derivative of the activation function. This may be exploited in hardware realizations of neural processors. In this paper we derive the nonlinear backpropagation algorithms in the framework of recurrent backpropagation and present some numerical simulations of feedforward networks on the NetTalk problem. A discussion of implementation in analog very large scale integration (VLSI) electronics concludes the paper.	activation function;algorithm;analog;backpropagation;central processing unit;diffuse large b-cell lymphoma;feedforward neural network;integrated circuit;nonlinear system;numerical analysis;simulation;very-large-scale integration	John A. Hertz;Anders Krogh;Benny Lautrup;Torsten Lehmann	1997	IEEE transactions on neural networks	10.1109/72.641455	computer simulation;nonlinear programming;computer science;artificial intelligence;backpropagation;theoretical computer science;machine learning;artificial neural network	ML	17.179621949103257	-27.80637445568664	58814
880bacd3e2682015df59bed4086457e941c47793	impact of variances of random weights and biases on extreme learning machine				Xiao Tao;Xu Zhou;Yu-Lin He;Rana Aamir Raza	2016	JSW	10.17706/jsw.11.5.440-454	simulation;artificial intelligence	ML	10.814835710377691	-25.956668215039223	58867
b9c60b270f2e3e4fd00d55e68177bf7ec69efe64	bringing the grandmother back into the picture: a memory-based view of object recognition	biophysics;sgrandmother cells;representation;eficacia sistema;object recognition;vision ordenador;interpolation;image processing;learning;implementation;three dimensional shape;sistema informatico;aproximacion;fonction base radiale;performance systeme;computer system;system performance;forma tridimensional;approximation;computer vision;aprendizaje;ejecucion;apprentissage;nonlinear systems;recognition;forme tridimensionnelle;grand mere;pattern recognition;artificial intelligence;vision ordinateur;nonlinear interpolation;systeme informatique;reconnaissance forme;reseau neuronal;reconocimiento patron;vision;red neuronal;artificial neural network;neural network;radial basis functions	"""We describe experiments with a versatile pictorial prototype based learning scheme for 3D object recognition. The GRBF scheme seems to be amenable to realization in biophysical hardware because the only kind of computation it involves can be effectively carried out by combining receptive fields. Furthermore, the scheme is computationally attractive because it brings together the old notion of a """"grandmother"""" cell and the rigorous approximation methods of regularization and splines. @ Massachusetts Institute of Technology (1990) This report describes research done at the Massachusetts Institute of Technology within the Artificial Intelligence Laboratory and the Center for Biological Information Processing in the Department of Brain and Cognitive Sciences and Whitaker College. The Center's research is sponsored by grant N00014-88-K-0164 from the Office of Naval Research (ONR), Cognitive and Neural Sciences Division; by the Alfred P. Sloan Foundation; and by National Science Foundation grant IRI-8719392. The Artificial Intelligence Laboratory's research is sponsored by the Advanced Research Projects Agency of the Department of Defense under Army contract DACA76-85-C-0010 and in part by ONR contract N00014-85-K-0124. TP is supported by the Uncas and Helen Whitaker Chair at Whitaker College, MIT. SE is supported by a Chaim Weizmann Postdoctoral Fellowship from the Weizmann Institute of Science and by a NSF Presidential Young Investigator Award to Professor Ellen C. Hildreth. r"""	3d single-object recognition;approximation;artificial intelligence;computation;experiment;grandmother cell;ibm notes;image;information processing;outline of object recognition;prototype	Shimon Edelman;Tomaso A. Poggio	1992	IJPRAI	10.1142/S0218001492000035	vision;computer vision;radial basis function;interpolation;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;approximation;implementation;representation;artificial neural network;algorithm	AI	17.77436520408248	-27.986556090495057	58981
06cb6070c83f2c96a3611404a10ee7bdbf84d0f7	noisy softplus: a biology inspired activation function	activation function;biologically inspired;spiking neural network;noisy softplus;lif neurons	The Spiking Neural Network (SNN) has not achieved the recognition/classification performance of its non-spiking competitor, the Artificial Neural Network(ANN), particularly when used in deep neural networks. The mapping of a well-trained ANN to an SNN is a hot topic in this field, especially using spiking neurons with biological characteristics. This paper proposes a new biologically-inspired activation function, Noisy Softplus, which is well-matched to the response function of LIF (Leaky Integrate-and-Fire) neurons. A convolutional network (ConvNet) was trained on the MNIST database with Noisy Softplus units and converted to an SNN while maintaining a close classification accuracy. This result demonstrates the equivalent recognition capability of the more biologically-realistic SNNs and bring biological features to the activation units in ANNs.	activation function;rectifier (neural networks)	Qian Liu;Steve B. Furber	2016		10.1007/978-3-319-46681-1_49	computer science;artificial intelligence;machine learning;activation function;spiking neural network	AI	13.357892030989206	-27.690451061923397	59039
3970874cbd818e5a98a32888dad627dca28bab94	from cutting planes algorithms to compression schemes and active learning	optimisation;cutting planes algorithms;convergence;data compression;active learning methods;sparse classifiers;passive learning tasks;optimization problems;localization algorithms;pattern classification data compression learning artificial intelligence optimisation;cutting plane methods;machine learning;pattern classification;learning artificial intelligence;passive learning tasks cutting planes algorithms cutting plane methods localization algorithms machine learning optimization problems sparse classifiers compression schemes active learning methods;compression schemes	Cutting-plane methods are well-studied localization (and optimization) algorithms. We show that they provide a natural framework to perform machine learning -and not just to solve optimization problems posed by machine learning- in addition to their intended optimization use. In particular, they allow one to learn sparse classifiers and provide good compression schemes. Moreover, we show that very little effort is required to turn them into effective active learning methods. This last property provides a generic way to design a whole family of active learning algorithms from existing passive methods. We present numerical simulations testifying of the relevance of cutting-plane methods for passive and active learning tasks.	active learning (machine learning);algorithm;cutting-plane method;machine learning;mathematical optimization;numerical analysis;relevance;simulation;sparse matrix	Liva Ralaivola;Ugo Louche	2015	2015 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2015.7280694	data compression;semi-supervised learning;optimization problem;proactive learning;instance-based learning;algorithmic learning theory;convergence;computer science;theoretical computer science;online machine learning;machine learning;pattern recognition;stability;computational learning theory;active learning;generalization error	ML	22.906273446611436	-37.780307126427246	59045
10aa5baca367bbeae6870e601020175cc4dd6996	the sampling-and-learning framework: a statistical view of evolutionary algorithms	error target independence condition sampling and learning framework evolutionary algorithms purpose optimization algorithms probable absolute approximate query complexity paa query complexity learning subroutine binary classification sampling and classification algorithms sac algorithms learning theory uniform search;complexity theory approximation algorithms approximation methods minimization algorithm design and analysis upper bound error analysis;pattern classification evolutionary computation learning artificial intelligence	Evolutionary algorithms (EAs), a large class of general purpose optimization algorithms inspired from the natural phenomena, are widely used in various industrial optimizations and often show excellent performance. This paper presents an attempt towards revealing their general power from a statistical view of EAs. By summarizing a large range of EAs into the sampling-and-learning framework, we show that the framework directly admits a general analysis on the probable-absolute-approximate (PAA) query complexity. We particularly focus on the framework with the learning subroutine being restricted as a binary classification, which results in the sampling-and-classification (SAC) algorithms. With the help of the learning theory, we obtain a general upper bound on the PAA query complexity of SAC algorithms. We further compare SAC algorithms with the uniform search in different situations. Under the error-target independence condition, we show that SAC algorithms can achieve polynomial speedup to the uniform search, but not super-polynomial speedup. Under the one-side-error condition, we show that super-polynomial speedup can be achieved. This work only touches the surface of the framework. Its power under other conditions is still open.	amplifier;approximation algorithm;binary classification;decision tree model;evolutionary algorithm;mathematical optimization;polynomial;sampling (signal processing);speedup;subroutine	Yang Yu;Hong Qian	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900455	mathematical optimization;probabilistic analysis of algorithms;computer science;artificial intelligence;theoretical computer science;machine learning	Theory	20.83122182579851	-31.946410134635872	59479
ccfa02339b2d00469f1646d80ffc5ddb53588af1	interactive initialization of the multilayer perceptron	training;multilayer perceptron;feature mapping;multilayer perceptron mlp;foley sammon mapping;classification rules;data transformation;pattern classification;principal components;initialization;principal component	A new multilayer preceptor initialization method is proposed and compared experimentally with a traditional random initialization method. An operator maps training-set vectors into a two-variate space, inspects bi-variate training-set vectors and controls the complexity of the decision boundary. Simulations with sixteen real-world pattern classi®cation tasks have shown that in small-scale pattern classi®cation problems, often complex classi®cation rules and non-linear decision boundaries are not necessary. However, in cases where non-linear decision boundaries are required, the proposed weight initialization method is useful. Ó 2000 Elsevier Science B.V. All rights reserved.	decision boundary;experiment;map;multilayer perceptron;nonlinear system;simulation	Aistis Raudys	2000	Pattern Recognition Letters	10.1016/S0167-8655(00)00048-9	computer science;artificial intelligence;machine learning;pattern recognition;principal component analysis	AI	14.636453697815936	-32.11024168516616	59693
1143af7c80b7a787ace9d3c7ad204955b3b1fa2f	a new model of associative memories network	associative memory	An associative memory (AM) is a special kind of neural network that only allows associating an output pattern with an input pattern. However, some problems require associating several output patterns with a unique input pattern. Classical associative and neural models cannot solve this simple task. In this paper we propose a new network composed of several AMs aimed to solve this problem. By using this new model, AMs can be able to associate several output patterns with a unique input pattern. We test the accuracy of the proposal with a database of real images. We split this database of images into four collections of images and then we trained the network of AMs. During training we associate an image of a collection with the rest of the images belonging to the same collection. Once trained the network we expected to recover a collection of images by using as an input pattern any image belonging to the collection.	artificial neural network;associative model of data;content-addressable memory;interplanet	Roberto Antonio Vázquez;Juan Humberto Sossa Azuela	2007			bidirectional associative memory;autoassociative memory;memory map	ML	13.9197362575839	-30.26023216080439	60055
190b016821c415de3d0ec081a95fcf5f922028cf	weighted maximum likelihood loss as a convenient shortcut to optimizing the f-measure of maximum entropy classifiers		We link the weighted maximum entropy and the optimization of the expected Fβmeasure, by viewing them in the framework of a general common multi-criteria optimization problem. As a result, each solution of the expected Fβ-measure maximization can be realized as a weighted maximum likelihood solution a well understood and behaved problem. The specific structure of maximum entropy models allows us to approximate this characterization via the much simpler class-wise weighted maximum likelihood. Our approach reveals any probabilistic learning scheme as a specific trade-off between different objectives and provides the framework to link it to the expectedFβ-measure.	approximation algorithm;apriori algorithm;baseline (configuration management);expectation–maximization algorithm;experiment;instrumental convergence;keyboard shortcut;mathematical optimization;optimization problem;pareto efficiency;principle of maximum entropy;test set	Georgi Dimitroff;Laura Tolosi;Borislav Popov;Georgi Georgiev	2013			mathematical optimization;expectation–maximization algorithm;entropy maximization;maximum entropy probability distribution;maximum likelihood sequence estimation;maximum entropy spectral estimation	ML	21.501622025637303	-35.80080547777337	60243
a2a7749e8dc98c31d7279e3c4119d835c2251a50	independent component analysis and bayes' theorem for robotics and automation	independent component analysis robotics and automation inspection industrial training vectors pattern classification electrical equipment industry principal component analysis usa councils probability distribution;image processing independent component analysis bayes theorem robotics pattern classification;image processing;robots image processing independent component analysis pattern classification;training;bayes theorem;robotics;usa councils;independent component analysis;electrical equipment industry;inspection;ease of use;training data;bayes theorem pattern classification image processing ica industrial inspection visual inspection;vectors;industrial inspection;industrial training;visual inspection;principal component analysis;probability distribution;pixel;robots;classification algorithms;transforms;pattern classification;industrial application;ica;robotics and automation	Independent Component Analysis (ICA) provides a pragmatic means to perform pattern classification using Bayes' Theorem. Use of ICA with Bayes' Theorem is reviewed and illustrated with examples from classification of images. It is described how ICA with Bayes can create a pattern-classification system that is trainable merely by presenting examples. A specific algorithmic approach is advocated, and demonstrations of its versatility and ease of use show how this technique offers promise for industrial applications.	algorithm;independent computing architecture;independent component analysis;robotics;usability	Richard E. Hudson;Wyatt S. Newman	2010	2010 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2010.5509576	robot;probability distribution;independent component analysis;computer vision;training set;usability;inspection;bayesian programming;image processing;computer science;artificial intelligence;inductive probability;machine learning;pattern recognition;robotics;bayes' theorem;pixel;principal component analysis;visual inspection	Robotics	18.515380678102904	-35.115460080644	60392
ee413c664db7699d15e92f27bab358a85326dcb9	learning fuzzy rules for controllers with genetic algorithms	learning algorithm;control difusa;fuzzy rules;fuzzy control;inversed pendulum;intelligence artificielle;algorithme apprentissage;algoritmo genetico;algorithme genetique;artificial intelligence;genetic algorithm;inteligencia artificial;algoritmo aprendizaje;pendule inverse;commande floue;pendulo inverso	A genetic algorithm (GA)-based scheme for learning fuzzy rules for controllers, called an optimized fuzzy logic controller (OFLC) was proposed by Chan, Xie and Rad (2000). In this article we first analyze their OFLC and discuss some of its limitations. We also propose some modifications on an OFLC to eliminate those limitations. Then, for systems with symmetrical rule base we propose a new method to reduce the number of rules, which reduces the search space as well as the design time. We define a fitness function that reduces the number of rules maintaining the performance of the rule set. The trade-off between the number of rules and the performance can be decided by changing the parameters of our fitness function. We theoretically analyzed the properties of “one-step change mutation” and compared that with our mutation scheme. The proposed scheme, for the inverted pendulum problem can find rule sets containing 5% of all possible fuzzy rules, having good integral time absolute error (ITAE) and it takes only a few steps to balance the system over the entire input space. To show the superiority of our scheme, we compare it with other methods. © 2003 Wiley Periodicals, Inc.	approximation error;fitness function;fuzzy control system;fuzzy logic;genetic algorithm;inverted pendulum;john d. wiley;rule-based system;scheme;x image extension	Tandra Pal;Nikhil R. Pal;M. Pal	2003	Int. J. Intell. Syst.	10.1002/int.10104	genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;algorithm;fuzzy control system	DB	15.769474525665728	-29.2757000260798	60426
d2bcfdefaf7efbe83fd08b96d9464093ba78c0ea	towards understanding the invertibility of convolutional neural networks		Several recent works have empirically observed that Convolutional Neural Nets (CNNs) are (approximately) invertible. To understand this approximate invertibility phenomenon and how to leverage it more effectively, we focus on a theoretical explanation and develop a mathematical model of sparse signal recovery that is consistent with CNNs with random weights. We give an exact connection to a particular model of model-based compressive sensing (and its recovery algorithms) and random-weight CNNs. We show empirically that several learned networks are consistent with our mathematical analysis and then demonstrate that with such a simple theoretical framework, we can obtain reasonable reconstruction results on real images. We also discuss gaps between our model assumptions and the CNN trained for classification in practical scenarios.	approximation algorithm;artificial neural network;compressed sensing;convolutional neural network;detection theory;experiment;mathematical model;neural networks;sparse matrix;statistical classification	Anna C. Gilbert;Yi Zhang;Kibok Lee;Yuting Zhang;Honglak Lee	2017		10.24963/ijcai.2017/236	artificial intelligence	AI	23.136064872520137	-33.36210835510083	60475
0a21d49bf49255700abc25027764bac497b48125	towards designing neural network ensembles by evolution	systeme cooperatif;algorithm analysis;systeme apprentissage;neural network ensemble;learning systems;cooperative systems;algorithme evolutionniste;algoritmo evolucionista;analyse algorithme;evolutionary algorithm;reseau neuronal;evolutionary learning;red neuronal;analisis algoritmo;neural network	This paper proposes a co-evolutionary learning system, i.e., CELS, to design neural network (NN) ensembles. CELS addresses the issue of automatic determination of the number of individual NNs in an ensemble and the exploitation of the interaction between individual NN design and combination. The idea of CELS is to encourage diierent individual NNs in the ensemble to learn diierent parts or aspects of the training data so that the ensemble can learn the whole training data better. The cooperation and specialisation among diierent individual NNs are considered during the individual NN design. This provides an opportunity for diierent NNs to interact with each other and to specialise. Experiments on two real-world problems demonstrate that CELS can produce NN ensembles with good generalisation ability.	artificial neural network;experiment;neural ensemble;test set	Yong Huan Liu;Xin Yao	1998		10.1007/BFb0056904	computer science;artificial intelligence;machine learning;evolutionary algorithm;artificial neural network;algorithm	AI	10.39224880929897	-31.839103206572872	60502
b7fd8e6cc3fa7f16597e60cad4ef96c8225650c3	a comparison study for neural network characteristics based on activation function	activation function;neural network		activation function;artificial neural network	Basim Alhadidi;Khaldoun Bateha	2005			machine learning;artificial neural network;artificial intelligence;activation function;computer science	NLP	13.008491207920084	-27.264135936301006	60581
5cc6fd65cea6ff962de883cd8ee15b13727f2c10	evolving cascade-correlation networks for time-series forecasting	forecasting;time series forecasting;neural networks;learning;neural nets;evolution general;evolutionary search;input;searching;cascade correlation learning architecture;weight;time series analysis;mathematical models;reprints;mathematical prediction;time series models;systems approach	This investigations applies evolutionary search to the cascade-correlation learning network. Evolutionary search is used to find both the input weights and input connectivity of candidate hidden units. A time-series prediction example is used to demonstrate the capabilities of the proposed approach.	evolutionary computation;time series	John R. McDonell;Don E. Waagen	1994	International Journal on Artificial Intelligence Tools	10.1142/S0218213094000169	computer science;artificial intelligence;data science;machine learning;time series;artificial neural network;statistics	AI	12.636945929687949	-24.015672857961057	60746
715ad6e1409dd2d8c0036956c5e8ea37f645d2dd	evolving choice structures for genetic programming	genetique;genetic program;evolutionary computation;procesamiento informacion;programmation;algorithm analysis;structure programme;genetica;limitation;program derivation;derivation programme;genetic programming;genetics;structure function;programacion;estructura programa;limitacion;theoretical analysis;borne electrique;informatique theorique;information processing;borne electrico;termination;analyse algorithme;terminaison;traitement information;choice structure;program structure;programming;analisis algoritmo;computer theory;evolutionary computing;informatica teorica	"""a r t i c l e i n f o a b s t r a c t It is quite difficult but essential for Genetic Programming (GP) to evolve the choice structures. Traditional approaches usually ignore this issue. They define some """" if-structures """" functions according to their problems by combining """" if-else """" statement, conditional criterions and elemental functions together. Obviously, these if-structure functions depend on the specific problems and thus have much low reusability. Based on this limitation of GP, in this paper we propose a kind of termination criterion in the GP process named """" Combination Termination Criterion """" (CTC). By testing CTC, the choice structures composed of some basic functions independent to the problems can be evolved successfully. Theoretical analysis and experiment results show that our method can evolve the programs with choice structures effectively within an acceptable additional time."""	conditional (computer programming);elemental;experiment;genetic programming;naive bayes classifier	Shuaiqiang Wang;Jun Ma;Jiming Liu;Xiaofei Niu	2010	Inf. Process. Lett.	10.1016/j.ipl.2010.07.014	kolmogorov structure function;genetic programming;programming;computer science;artificial intelligence;mathematics;operations research;program derivation;algorithm;evolutionary computation	AI	20.079586189129387	-24.922417575797454	60765
3c34ac17ac9477874812a2ca294fcfe78d42e698	predictive complexity and information	predictive complexity;information loss;computational learning;apprentissage calcul;non commutative;expanding property;algorithmic prediction;aprendizaje probabilidades;kolmogorov complexity;machine learning;loss function;loss functions;apprentissage probabilites;predictive information;probability learning	"""A new notion of predictive complexity and corresponding amount of information are considered. Predictive complexity is a generalization of Kolmogorov complexity which bounds the ability of any algorithm to predict elements of a sequence of outcomes. We consider predictive complexity for a wide class of bounded loss functions which are generalizations of square-loss function. Relations between unconditional KG(x) and conditional KG(x|y) predictive complexities are studied. We define an algorithm which has some """"expanding property"""". It transforms with positive probability sequences of given predictive complexity into sequences of essentially bigger predictive complexity. A concept of amount of predictive information IG(y : x) is studied. We show that this information is non-commutative in a very strong sense and present asymptotic relations between values IG(y : x), IG(x : y), KG(x) and KG(y)."""		Michael V. Vyugin;Vladimir V. V'yugin	2001	Electronic Colloquium on Computational Complexity (ECCC)	10.1016/j.jcss.2004.10.005	combinatorics;discrete mathematics;average-case complexity;computer science;machine learning;mathematics;chain rule for kolmogorov complexity;algorithm;loss function	Theory	20.170721140260966	-30.77968089483753	60929
81c30ccf05cd40c9966e43bc275f8fcf07bfa043	a comparison of partial least square model and neural network model	neural network model		network model	Carl Lee;Xiaomin Lu	2004			artificial intelligence;machine learning;probabilistic neural network;artificial neural network;computer science;least squares	NLP	12.60537678739408	-26.914525357586967	61064
d15289b07f8f13ac22439845a45a41744511cd17	learning from noisy examples	concept learning;learning from examples;probably approximately correct learning;noisy data;theoretical limitations	The basic question addressed in this paper is: how can a learning algorithm cope with incorrect training examples? Specifically, how can algorithms that produce an “approximately correct” identification with “high probability” for reliable data be adapted to handle noisy data? We show that when the teacher may make independent random errors in classifying the example data, the strategy of selecting the most consistent rule for the sample is sufficient, and usually requires a feasibly small number of examples, provided noise affects less than half the examples on average. In this setting we are able to estimate the rate of noise using only the knowledge that the rate is less than one half. The basic ideas extend to other types of random noise as well. We also show that the search problem associated with this strategy is intractable in general. However, for particular classes of rules the target rule may be efficiently identified if we use techniques specific to that class. For an important class of formulas—the k-CNF formulas studied by Valiant—we present a polynomial-time algorithm that identifies concepts in this form when the rate of classification errors is less than one half.	algorithm;conjunctive normal form;noise (electronics);search problem;signal-to-noise ratio;time complexity	Dana Angluin;Philip D. Laird	1987	Machine Learning	10.1007/BF00116829	semi-supervised learning;concept learning;computer science;artificial intelligence;machine learning;data mining;mathematics;stability;probably approximately correct learning;algorithm;statistics	ML	18.673613464441182	-33.74489073730773	61088
a5a28a303418efed8edcec51785f3aea1e8563f5	novel designs of spiking neuron circuit and stdp learning circuit based on memristor		Abstract The pure circuit implementation of STDP is a worthwhile work. In this study, a novel spiking neuron circuit and STDP learning circuit based on memristors are designed. The proposed spiking neuron circuit, which is based on conventional leaky integrate-and-fire neuron and utilizes the nonlinear variation of memristance, is served to generate spikes. Different release thresholds and amplitudes of the spikes can be obtained through tuning circuit parameters. Extending on the spiking neuron circuit, a STDP learning circuit is built to perform unsupervised learning behaviors. Furthermore, a crossbar array architecture is finally considered to fabricate multi-input multi-output spiking neural network which also perform STDP learning effectively. Circuit simulation results in PSPICE prove the availability of the two proposed circuits.	memristor;neuron	Liang Zhao;Qinghui Hong;Xiaoping Wang	2018	Neurocomputing	10.1016/j.neucom.2018.06.062	spiking neural network;memristor;machine learning;electronic circuit;artificial intelligence;architecture;crossbar switch;unsupervised learning;mathematics;neuron	EDA	15.360865165406315	-27.079553978248498	61215
e5dbb1328062b9dc861a9d02c19ce3ecbf44b413	classification of communications signals using an advanced technique	swarm intelligence;higher order cumulants;higher order;higher order statistics;particle swarm optimizer;radial basis function neural network;signal classification;pattern recognition;higher order moments;cross validation;communication technology;cumulant;automatic classification;neural network	Because of rapid growing of radio communication technology of late years, importance of automatic classification of digital signal type is rising increasingly. This paper presents an advanced technique that identifies a variety of digital signal types. This method is a hybrid heuristic formed by a radial basis function neural networks (as a classifier) and particle swarm optimization technique. A suitable combination of higher order statistics up to eighth are proposed as the prominent characteristics of the considered signals. In conjunction with neural network we have used a cross-validation technique to improve the generalization ability. Experimental results indicate that the proposed technique has high eywords: attern recognition ignal classification eural network warm intelligence ross-validation percentage of correct classification to discriminate different types of digital signal even at low SNRs. © 2009 Elsevier B.V. All rights reserved. igher order moments igher order cumulants	artificial neural network;cross-validation (statistics);heuristic;mathematical optimization;particle swarm optimization;radial (radio);radial basis function	Ataollah Ebrahimzadeh;S. E. Mousavi	2011	Appl. Soft Comput.	10.1016/j.asoc.2009.12.001	information and communications technology;speech recognition;higher-order logic;swarm intelligence;computer science;artificial intelligence;machine learning;artificial neural network;cross-validation;cumulant	AI	11.00174165390192	-35.96356060501256	61387
68ec8a1e9aea1916e2280489729bab74d5bf6631	layered neural networks with gaussian hidden units as universal approximations	neural network	A neural network with a single layer of hidden units of gaussian type is proved to be a universal approximator for real-valued maps defined on convex, compact sets of Rn.	artificial neural network;map;neural network software;universal approximation theorem	Eric Hartman;James D. Keeler;Jacek M. Kowalski	1990	Neural Computation	10.1162/neco.1990.2.2.210	computer science;artificial intelligence;theoretical computer science;machine learning;time delay neural network;mathematics;artificial neural network	ML	14.71126603855733	-28.271128837096253	61471
5dab155a72ce4947f85e781b065f5f3299238e61	statistical mechanical analysis of the dynamics of learning in perceptrons	statistical mechanics;supervised learning;fokker planck equation;simulation experiment;learning dynamics;disordered system;generalization;neural network	We describe the application of tools from statistical mechanics to analyse the dynamics of various classes of supervised learning rules in perceptrons. The character of this paper is mostly that of a cross between a biased non-encyclopaedic review and lecture notes: we try to present a coherent and self-contained picture of the basics of this ®eld, to explain the ideas and tricks, to show how the predictions of the theory compare with (simulation) experiments, and to bring together scattered results. Technical details are given explicitly in an appendix. In order to avoid distraction we concentrate the references in a ®nal section. In addition this paper contains some new results: (i) explicit solutions of the macroscopic equations that describe the error evolution for on-line and batch learning rules; (ii) an analysis of the dynamics of arbitrary macroscopic observables (for complete and incomplete training sets), leading to a general Fokker±Planck equation; and (iii) the macroscopic laws describing batch learning with complete training sets. We close the paper with a preliminary exposeÂ of ongoing research on the dynamics of learning for the case where the training set is incomplete (i.e. where the number of examples scales linearly with the network size).	addendum;coherence (physics);experiment;observable;online and offline;perceptron;simulation;supervised learning;test set	C. W. H. Mace;Anthony C. C. Coolen	1998	Statistics and Computing	10.1023/A:1008896910704	generalization;simulation;statistical mechanics;computer science;artificial intelligence;machine learning;fokker–planck equation;mathematics;supervised learning;stability;statistics	ML	22.08266191597387	-28.487186606419122	61719
49f91d8c4419c69fa27af1f8b377c9d1b5b6d87a	detection using correlation bound in a linear mixture model	traitement signal;evaluation performance;mezcla senal;signal mixing;performance evaluation;spectrometrie raman;classification non supervisee;espectrometria raman;evaluacion prestacion;simulation;modele lineaire;simulacion;modelo lineal;detection;melange signal;raman spectroscopy;upper bound;correlation bound;signal processing;clasificacion no supervisada;detection limit;linear model;signal classification;classification signal;unsupervised classification;teoria mezcla;linear mixture;borne superieure;mixture theory;limite deteccion;procesamiento senal;theorie melange;linear mixture model;raman spectrometry;limite detection;cota superior	A detection approach, detection with a correlation bound (DCB), is introduced based on a linear mixture model. We use the upper bound of the correlation between the target and mixing components as the detection index, and derive the expression for this correlation bound using the observed data. The proposed method is an unsupervised approach and provides satisfactory detection performance without imposing strong assumptions. Simulation and experimental results are presented to demonstrate the effectiveness of the proposed method in Raman spectroscopy for the detection of surfacedeposited chemical agents. r 2006 Elsevier B.V. All rights reserved.	mixture model;raman scattering;simulation;unsupervised learning	Wei Wang;Tülay Adali	2007	Signal Processing	10.1016/j.sigpro.2006.10.007	raman spectroscopy;detection limit;computer science;signal processing;linear model;mathematics;upper and lower bounds;algorithm;statistics	AI	11.975103345975622	-34.69560205429124	61848
d1fb8212f1e522b5172bf9b875e3d8f368ad55fd	a new criterion of nn structure selection for financial forecasting	minimisation;time series finance forecasting theory neural net architecture minimisation;financial forecasting;generalization error;finance;dsw method nn structure selection criterion financial forecasting optimal neural net structure complexity approximation error minimization generalization error minimization minimum description length method mdl method stochastic time series previsions dynamic sampling window method;neural networks;approximation error;cost function;mdl method;minimum description length method;dynamic sampling window method;nn structure selection criterion;neural net architecture;length measurement;minimization methods;stochastic time series previsions;time series;dsw method;structural complexity;neural net;approximation error minimization;forecasting theory;stochastic processes;phase estimation;minimum description length;predictive models;generalization error minimization;optimal neural net structure complexity;sampling methods;neural networks minimization methods phase estimation cost function length measurement predictive models laboratories approximation error stochastic processes sampling methods	For the evaluation and the selection of the optimal neural net (NN) structure complexity, as a function of the minimization either of the approximation error or of the generalization error, we discuss briefly the minimum description length (MDL) method. Because of the theoretical and practical limitations of this criterion-overall for stochastic time series previsions-we shortly introduce our new dynamic sampling window (DSW) method for the optimal NN structure definition for financial forecasting.		Antonio L. Perrone;Gianfranco Basti	1999		10.1109/IJCNN.1999.830778	sampling;minimisation;mathematical optimization;structural complexity;approximation error;minimum description length;length measurement;computer science;machine learning;time series;mathematics;predictive modelling;artificial neural network;statistics;generalization error	Robotics	21.177413598412294	-28.2336229271591	62269
dc0f61cb747da0fb07fa0cf5c1f014bc44ac1a61	incremental weighted naive bays classifiers for data stream		A naive Bayes classifier is a simple probabilistic classifier based on applying Bayes’ theorem with naive independence assumption. The explanatory variables (Xi) are assumed to be independent from the target variable (Y ). Despite this strong assumption this classifier has proved to be very effective on many real applications and is often used on data stream for supervised classification. The naive Bayes classifier simply relies on the estimation of the univariate conditional probabilities P (Xi|C). This estimation can be provided on a data stream using a ”supervised quantiles summary”. The literature shows that the naive Bayes classifier can be improved (i) using a variable selection method (ii) weighting the explanatory variables. Most of these methods are related to batch (off-line) learning and need to store all the data in memory and/or require reading more than once each example. Therefore they cannot be used on data stream. This paper presents a new method based on a graphical model which computes the weights on the input variables using a stochastic estimation. The method is incremental and produces an Weighted Naive Bayes Classifier for data stream. This method will be compared to classical naive Bayes classifier on the Large Scale Learning challenge datasets.	feature selection;graphical model;machine learning;naive bayes classifier;online and offline;selection (genetic algorithm);stochastic optimization;supervised learning	Christophe Salperwyck;Vincent Lemaire;Carine Hue	2013		10.1007/978-3-662-44983-7_16	naive bayes classifier;feature selection;concept drift;probabilistic classification;conditional probability;bayes' theorem;artificial intelligence;pattern recognition;univariate;graphical model;mathematics	ML	16.407339819772087	-37.55321520489559	62288
b6ce7e53e7b3c30a0b651fe3794a36c8ea786153	"""simpler transfer learning (using """"bellwethers"""")"""		Transfer learning has been the subject of much recent research. In practice, that research means that the models are unstable since they are continually revised whenever new data arrives. This paper offers a very simple “bellwether” transfer learner. Given N datasets, we find which one produces the best predictions on all the others. This “bellwether” dataset is then used for all subsequent predictions (when its predictions start failing, one may seek another bellwether). Bellwethers are interesting since they are very simple to find (wrap a for-loop around standard data miners). They simplify the task of making general policies in software engineering since as long as one bellwether remains useful, stable conclusions for N datasets can be achieved by reasoning over that bellwether. This paper shows that this bellwether approach works for multiple datasets from various domains in SE. From this, we conclude that (1) bellwether method is a useful (and simple) transfer learner; (2) Unlike bellwethers, other complex transfer learners do not generalized to all domains in SE; (3) “bellwethers” are a baseline method against which future transfer learners should be compared; (4) When building increasingly complex automatic methods, researchers should pause and compare more sophisticated method against simpler alternatives.	baseline (configuration management);control theory;data mining;failure;for loop;loop around;software engineering	Rahul Krishna;Tim Menzies	2017	CoRR		machine learning;transfer of learning;artificial intelligence;computer science	NLP	14.783153122268269	-37.224216287620585	62307
0003d2e7b8365b120c31bfb02a658f6cf66ad3c6	kohonen networks application in speech analysis algorithms	kohonen networks application;speech analysis;kohonen network application;traditional kohonen network;weights initialization;speech analysis algorithm;neurons reduction	This article presents the Kohonen network application in the speech analysis. The Authors have modified the traditional Kohonen network learning process like weights initialization, neurons reduction and neurons sorting. The results will be presented using authors’ program – “WaveBlaster”.	algorithm;creative wave blaster;self-organizing map;sorting;teuvo kohonen;voice analysis	Ireneusz Codello;Wieslawa Kuniszyk-Józkowiak;Adam Kobus	2010	Annales UMCS, Informatica	10.2478/v10065-010-0048-2	speech recognition;computer science;artificial intelligence;machine learning;hybrid kohonen self-organizing map	ML	13.670932596834307	-25.410862597134514	62496
6d443455d7877d51ca0aed76b3432384ee8d903c	high performance lda through collective model communication optimization		LDA is a widely used machine learning technique for big data analysis. The application includes an inference algorithm that iteratively updates a model until it converges. A major challenge is the scaling issue in parallelization owing to the fact that the model size is huge and parallel workers need to communicate the model continually. We identify three important features of the model in parallel LDA computation: 1. The volume of model parameters required for local computation is high; 2. The time complexity of local computation is proportional to the required model size; 3. The model size shrinks as it converges. By investigating collective and asynchronous methods for model communication in different tools, we discover that optimized collective communication can improve the model update speed, thus allowing the model to converge faster. The performance improvement derives not only from accelerated communication but also from reduced iteration computation time as the model size shrinks during the model convergence. To foster faster model convergence, we design new collective communication abstractions and implement two Harp-LDA applicatons, “lgs” and “rtt”. We compare our new approach with Yahoo! LDA and Petuum LDA, two leading implementations favoring asynchronous communication methods in the field, on a 100-node, 4000-thread Intel Haswell cluster. The experiments show that “lgs” can reach higher model likelihood with shorter or similar execution time compared with Yahoo! LDA, while “rtt” can run up to 3.9 times faster compared with Petuum LDA when achieving similar model likelihood.	algorithm;big data;computation;converge;experiment;haswell (microarchitecture);image scaling;iteration;local-density approximation;machine learning;manycore processor;overhead (computing);parallel computing;routing;run time (program lifecycle phase);sampling (signal processing);time complexity	Bingjing Zhang;Bo Peng;Judy Qiu	2016		10.1016/j.procs.2016.05.300	mathematical optimization;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;data mining;mathematics;algorithm;statistics	ML	24.352858859498063	-34.32370449085576	62595
5092c4b4646aed5c0e3f80ebffdef3b5f57d5cdc	hybrid learning for interval type-2 intuitionistic fuzzy logic systems as applied to identification and prediction problems		This paper presents a novel application of a hybrid learning approach to the optimisation of membership and nonmembership functions of a newly developed interval type-2 intuitionistic fuzzy logic system (IT2 IFLS) of a Takagi–Sugeno–Kang (TSK) fuzzy inference system with neural network learning capability. The hybrid algorithms consisting of decoupled extended Kalman filter (DEKF) and gradient descent (GD) are used to tune the parameters of the IT2 IFLS for the first time. The DEKF is used to tune the consequent parameters in the forward pass while the GD method is used to tune the antecedents parts during the backward pass of the hybrid learning. The hybrid algorithm is described and evaluated, prediction and identification results together with the runtime are compared with similar existing studies in the literature. Performance comparison is made among the proposed hybrid learning model of IT2 IFLS, a TSK-type-1 intuitionistic fuzzy logic system (IFLS-TSK), and a TSK-type interval type-2 fuzzy logic system (IT2 FLS-TSK) on two instances of the datasets under investigation. The empirical comparison is made on the designed systems using three artificially generated datasets and three real world datasets. Analysis of results reveal that IT2 IFLS outperforms its type-1 variants, IT2 FLS and most of the existing models in the literature. Moreover, the minimal run time of the proposed hybrid learning model for IT2 IFLS also puts this model forward as a good candidate for application in real time systems.		Imo Eyoh;Robert John;Geert De Maere;Erdal Kayacan	2018	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2018.2803751	mathematics;machine learning;fuzzy logic;artificial intelligence;fuzzy set;hybrid algorithm;artificial neural network;gradient descent;extended kalman filter;inference	AI	11.957462466794787	-24.330953222739282	62646
58f7802295fb4c87db360ee0eaf3de85e453e193	an experimental comparison of three pca neural networks	simulation ordinateur;evaluation performance;analisis componente principal;hebbian learning;algorithm performance;performance evaluation;numerical method;estudio comparativo;evaluacion prestacion;simulacion numerica;adaptive principal component extraction;convergence speed;etude comparative;structure comparison;metodo numerico;resultado algoritmo;principal component analysis;simulation numerique;generalized hebbian learning;extraction composante principale adaptative;comparative study;performance algorithme;analyse composante principale;velocidad convergencia;simulacion computadora;reseau neuronal;vitesse convergence;computer simulation;red neuronal;methode numerique;neural network;numerical simulation;principal component	We present a numerical and structural comparison of three neural PCA techniques: The GHA by Sanger, the APEX by Kung and Diamantaras, and the ψ–APEX first proposed by the present author. Through computer simulations we illustrate the performances of the algorithms in terms of convergence speed and minimal attainable error; then an evaluation of the computational efforts for the different algorithms is presented and discussed. A close examination of the obtained results shows that the members of the new class improve the numerical performances of the considered existing algorithms, and are also easier to implement.	artificial neural network;blind signal separation;computation;computer simulation;generalized hebbian algorithm;image compression;neural network software;nonlinear system;numerical analysis;numerical linear algebra;performance;principal component analysis;sap fiori;source separation	Simone G. O. Fiori	2000	Neural Processing Letters	10.1023/A:1009663626444	computer simulation;computer science;artificial intelligence;machine learning;algorithm;principal component analysis	ML	19.236392619045102	-26.58582938499247	62799
4587ef64c2e5f42c349cc6d2988e4c60c4aead49	thompson sampling for online learning with linear experts		In this note, we present a version of the Thompson sampling algorithm for the problem of online linear generalization with full information (i.e., the experts setting), studied by Kalai and Vempala, 2005. The algorithm uses a Gaussian prior and time-varying Gaussian likelihoods, and we show that it essentially reduces to Kalai and Vempala’s Follow-thePerturbed-Leader strategy, with exponentially distributed noise replaced by Gaussian noise. This implies sqrt(T) regret bounds for Thompson sampling (with time-varying likelihood) for online learning with full information.	algorithm;regret (decision theory);sampling (signal processing);thompson sampling	Aditya Gopalan	2013	CoRR		mathematical optimization;machine learning;mathematics;statistics	ML	21.488303053057063	-30.64790512369495	62824
afb42208cc499ede10a65af0dbe598e08556370d	variational intrinsic control		In this paper we introduce a new unsupervised reinforcement learning method for discovering the set of intrinsic options available to an agent. This set is learned by maximizing the number of different states an agent can reliably reach, as measured by the mutual information between the set of options and option termination states. To this end, we instantiate two policy gradient based algorithms, one that creates an explicit embedding space of options and one that represents options implicitly. The algorithms also provide an explicit measure of empowerment in a given state that can be used by an empowerment maximizing agent. The algorithm scales well with function approximation and we demonstrate the applicability of the algorithm on a range of tasks.	algorithm;approximation;closed-loop transfer function;entropy maximization;experiment;gradient;mutual information;reinforcement learning;semantics (computer science);unsupervised learning;variational principle	Karol Gregor;Danilo Jimenez Rezende;Daan Wierstra	2016	CoRR		mathematical optimization;discrete mathematics;machine learning;mathematics	ML	22.62825103016746	-30.601133138805395	63393
79ccfee6213591198b455d10c9a488fe07bbfc25	introduction to special issue	time series analysis;data model;markov chain monte carlo;cross section;markov chain	In recent years, neural-based techniques have been proved effective in solving several applications by outperforming, whenever the world is non-linear and unspecified, traditional algorithmic-based approaches. In fact, if the equations ruling a generic application are unknown, and the only available information is a sequence of input-output couples, then learning by examples is the last chance to solve the problem. In other cases, the application might be completely defined but the complexity of a classic solution is impractical; in such cases neural techniques can be taken into account to provide a simpler solution approximating the optimal one.		Roque Marín;Eva Onaindia	1976	Molecular and Cellular Endocrinology	10.1016/0303-7207(76)90064-2		Robotics	23.440005566280583	-26.733129325190227	63573
447c6c09cc0051d56ff7020941fce6734a0fd3e7	local algorithms for pattern recognition and dependencies estimation	minimisation;local risk minimization;minimization;estimacion;local algorithm;learning algorithm;theoretical framework;extended induction principle;learning;theories of learning;structural risk minimization;convergencia uniforme;minimizacion;risque;dependence;dependance;algorithme;aprendizaje;convergence uniforme;algorithm;riesgo;apprentissage;performance improvement;uniform convergence;estimation;risk;pattern recognition;learning problems;reconnaissance forme;risk minimization;reconocimiento patron;dependencia;algoritmo	In previous publications (Bottou and Vapnik 1992; Vapnik 1992) we described local learning algorithms, which result in performance improvements for real problems. We present here the theoretical framework on which these algorithms are based. First, we present a new statement of certain learning problems, namely the local risk minimization. We review the basic results of the uniform convergence theory of learning, and extend these results to local risk minimization. We also extend the structural risk minimization principle for both pattern recognition problems and regression problems. This extended induction principle is the basis for a new class of algorithms.	algorithm;machine learning;pattern recognition;structural risk minimization	Vladimir Vapnik;Léon Bottou	1993	Neural Computation	10.1162/neco.1993.5.6.893	minimisation;mathematical optimization;uniform convergence;estimation;empirical risk minimization;structural risk minimization;computer science;machine learning;learning theory;risk;mathematics;algorithm;statistics	ML	20.894552652773324	-34.63266039390266	63895
050fe7d45b0771461d2209c83dddc5eb32d51a65	sequential monte carlo point-process estimation of kinematics from neural spiking activity for brain-machine interfaces	bayes estimation;desciframiento;estimation sequentielle;modelizacion;processus ponctuel;prediccion;complexite;metodo adaptativo;neurone;approximation normale;calcul neuronal;neural computation;train potentiel action;brain;test statistique;point estimation;metodo monte carlo;metodologia;filtro kalman;65c05;estimacion densidad;decodage;dynamique;decoding;bayesian approach;algoritmo adaptativo;adaptive filtering;filtrado adaptable;62m20;62f10;estimation densite;reconstruction;test estadistico;62e17;filtre kalman;point process;complejidad;modele lineaire;cinematica;statistical test;62l12;methode monte carlo;kalman filter;metodo secuencial;methode adaptative;complexity;modelo lineal;sequential method;kinematics;methodologie;dinamica;interfase;modelisation;spike;density estimation;accord frequence;adaptive algorithm;estimacion bayes;neurona;cerebro;spike timing;posterior distribution;algorithme adaptatif;tuning;dynamics;estimation ponctuelle;gaussian approximation;cerveau;monte carlo method;adaptive method;62j10;linear model;cinematique;interface;uct;ley a posteriori;brain machine interface;methode sequentielle;proceso puntual;spike train;sintonizacion frecuencia;filtrage adaptatif;sequential estimation;reseau neuronal;methodology;monte carlo;estimacion puntual;modeling;loi a posteriori;estimacion secuencial;prediction;adaptive filter;normal approximation;red neuronal;computacion neuronal;gaussian distribution;neuron;potentiel action;neuronal discharge;reconstruccion;estimation bayes;variance;sequential monte carlo;neural network;variancia;timing	Many decoding algorithms for brain machine interfaces' (BMIs) estimate hand movement from binned spike rates, which do not fully exploit the resolution contained in spike timing and may exclude rich neural dynamics from the modeling. More recently, an adaptive filtering method based on a Bayesian approach to reconstruct the neural state from the observed spike times has been proposed. However, it assumes and propagates a gaussian distributed state posterior density, which in general is too restrictive. We have also proposed a sequential Monte Carlo estimation methodology to reconstruct the kinematic states directly from the multichannel spike trains. This letter presents a systematic testing of this algorithm in a simulated neural spike train decoding experiment and then in BMI data. Compared to a point-process adaptive filtering algorithm with a linear observation model and a gaussian approximation (the counterpart for point processes of the Kalman filter), our sequential Monte Carlo estimation methodology exploits a detailed encoding model (tuning function) derived for each neuron from training data. However, this added complexity is translated into higher performance with real data. To deal with the intrinsic spike randomness in online modeling, several synthetic spike trains are generated from the intensity function estimated from the neurons and utilized as extra model inputs in an attempt to decrease the variance in the kinematic predictions. The performance of the sequential Monte Carlo estimation methodology augmented with this synthetic spike input provides improved reconstruction, which raises interesting questions and helps explain the overall modeling requirements better.	adaptive filter;algorithm;approximation;brain neoplasms;brain–computer interface;contain (action);kalman filter;leucaena pulverulenta;monte carlo method;neuron;neurons;normal statistical distribution;particle filter;point process;randomness;requirement;sample variance;synthetic intelligence;spike train	Yiwen Wang;António R. C. Paiva;José Carlos Príncipe;Justin C. Sanchez	2009	Neural Computation	10.1162/neco.2009.01-08-699	adaptive filter;econometrics;computer science;artificial intelligence;mathematics;artificial neural network;statistics;monte carlo method	ML	21.736686848501684	-27.00756969717635	63901
2eff2a04f4582056735c8c09a2395c57322a7542	mapping analytic functions using neural networks	analytic function;neural network	Artificial neural networks (ANNs) have been used for the analysis of a variety of chemical data. They have been used for the three main purposes of classifying patterns, including mass-spectral data,’ correlating chemical data with biological activity,2 and for fitting continuous f~nc t ions .~ It is this last use that is addressed here with a particular view to the automatic fitting of continuous spectral functions making use of a minimum number of parameters. ANNs are commonly used to classify patterns in many other life situations such as recognizing human faces in a crowd or the letters of the alphabet in a document. In such cases the ANN is trained on a large number of given patterns which are presented to the network in the expectation that the network will correctly classify an indistinct pattern, much as the human eye can distinguish one alphabetic character from another even when the character is presented at an angle or is blurred in some manner. It is an attempt to mimic the ability of the human mind to quickly process visual information by emulating the processing ability of neurons. In the second case, the attempt to discover quantitative structure-activity relationships (QSAR) between chemical structures, or physiochemical measurements, and biological activity, there is still an element of pattern matching with an overlay of quantitative correlation. The recent use of continuous functions to represent the neuronic activation function has enabled the quantitative aspect to be introduced with some success especially where the results were not expected to be accurate to better than about 5% and the functional relationships were of low order, perhaps only weakly quadratic. The further attempts to use ANNs to quantitatively represent more complex functions is founded on the Kolmorgorov-Sprecher theorem$s5 as interpreted by HechtNeilseq6 which indicates that any real continuous function can be exactly represented by an ANN with two hidden layers and a finite number of neurons. The theorem is of theoretical interest in that no method for constructing the activation function is given; however, Irie-Miyake’ has proven that an infinite three-layered network can represent an arbitrary function provided that the hidden-layer activation functions and the mapping function are bounded and absolutely integrable. There are some attempts in the chemical literature to fit spectral lines and simple functional forms with A ” s and with some claim to ~ u c c e s s . * ~ ~ On further investigation it is found that the root-mean-square error [RMS] is usually no better than 2-3% of the function maximumlo which may	activation function;contour line;emulator;mean squared error;mind;neural networks;pattern matching;quantitative structure–activity relationship	Frank R. Burden	1994	Journal of Chemical Information and Computer Sciences	10.1021/ci00022a001	stochastic neural network;probabilistic neural network;chemistry;types of artificial neural networks;computer science;analytic function;recurrent neural network;machine learning;rectifier;activation function;artificial neural network	ML	18.653421273001552	-30.330945339087666	63903
9edb0c656c33080bfeac152ff88268d4db85f66b	the incremental probabilistic neural network	exact probabilistic neural network probabilistic neural network incremental training method intrusion detection incremental probabilistic neural network exact training method;exact probabilistic neural network;training neurons artificial neural networks intrusion detection probabilistic logic real time systems error analysis;probability;incremental probabilistic neural network;network security;real time;training;exact training method;intrusion detection;incremental training method;radial basis function networks;error analysis;simulation experiment;artificial neural networks;incremental training method incremental probabilistic neural network internet intrusion detection network security radial basis function neural network;internet;radial basis function neural network;neurons;probabilistic logic;probabilistic neural network;security of data;real time systems;security of data internet probability radial basis function networks	With the development of the Internet, the Intrusion Detection has been gradually playing a more and more important role in Network Security. Radial Basis Function Neural Network are widely used in Intrusion Detection, especially Probabilistic Neural Network. However, the detection speed is a problem which impedes it to be applied to Real-time Intrusion Detection. In this paper, for increasing the Detection Speed, the Incremental Training Method replaces the Exact Training Method. The simulation experiment shows that the detection speed of Incremental Probabilistic Neural Network is much faster than that of Exact Probabilistic Neural Network. Therefore, the Incremental Probabilistic Neural Network is more suitable for real-time intrusion detection than Exact Probabilistic Neural Network.	artificial neural network;internet;intrusion detection system;network security;probabilistic neural network;radial basis function;real-time clock;simulation	Jialiang Kou;Shengwu Xiong;Shuzhen Wan;Hongbing Liu	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5583589	probabilistic neural network;computer science;machine learning;pattern recognition;data mining;time delay neural network	ML	15.426181089686514	-29.438936754728307	64030
fab2c02392c1f1c5cf07faec8162b45867ec7124	improvement of practical recurrent learning method and application to a pattern classification task	oscillations;learning algorithm;learning methods;pattern classification;recurrent neural network;real time recurrent learning;back propagation	Practical Recurrent Learning (PRL) has been proposed as a simple learning algorithm for recurrent neural networks[1][2]. This algorithm enables learning with practical order O(n) of memory capacity and computational cost, which cannot be realized by conventional Back Propagation Through Time (BPTT) or Real Time Recurrent Learning (RTRL). It was shown in the previous work[1] that 3-bit parity problem could be learned successfully by PRL, but the learning performance was quite inferior to BPTT. In this paper, a simple calculation is introduced to prevent monotonous oscillations from being biased to the saturation range of the sigmoid function during learning. It is shown that the learning performance of the PRL method can be improved in the 3-bit parity problem. Finally, this improved PRL is applied to a scanned digit pattern classification task for which the results are inferior but comparable to the conventional BPTT.	algorithm;algorithmic efficiency;backpropagation through time;computation;computational complexity theory;iteration;pattern recognition letters;sigmoid function;software propagation;statistical classification	Mohamad Faizal Bin Samsudin;Katsunari Shibata	2008		10.1007/978-3-642-03040-6_77	unsupervised learning;instance-based learning;wake-sleep algorithm;computer science;artificial intelligence;recurrent neural network;backpropagation;machine learning;leabra;competitive learning;oscillation;algorithm;generalization error	ML	15.816142451566543	-29.563095521625318	64115
38f1d13dd8f7e1af0edffb04c7658ffe72f729f4	can entropic regularization be replaced by squared euclidean distance plus additional linear constraints	disjunction;euclidean theory;entropia;loi probabilite;ley probabilidad;divergence;intelligence artificielle;euclidean distance;linear constraint;relative entropy;disyuncion;disjonction;probability distribution;entropie;theorie euclidienne;artificial intelligence;entropy;inteligencia artificial;on line algorithm;divergencia;teoria euclidiana	There are two main families of on-line algorithms depending on whether a relative entropy or a squared Euclidean distance is used as a regularizer. The difference between the two families can be dramatic. The question is whether one can always achieve comparable performance by replacing the relative entropy regularization by the squared Euclidean distance plus additional linear constraints. We formulate a simple open problem along these lines for the case of learning disjunctions. Assume the target concept is a k literal disjunction over n variables. The instances are bit vectors x ∈ {0, 1} and the disjunction Vi1 ∨ Vi2 ∨ . . . Vik is true on instance x iff at least one bit in the positions i1, i2, . . . , ik is one. We can represent the above disjunction as a weight vector w: all relevant weights wij are set to some threshold θ > 0 and the remaining n − k irrelevant weights are zero. Now the disjunction is a linear threshold function: the disjunction is true on x iff w · x ≥ θ. The following type of on-line algorithm makes at most O(k log n) mistakes on sequences of examples (x1, y1), (x2, y2), . . ., when the labels yt are consistent1 with a k-literal monotone disjunction: The algorithm predicts true on instance xt iff wt ·xt ≥ θ. The weight vector wt for predicting at trial t is determined by minimizing the relative entropy to the initial weight vector w1 subject to some linear constraints implied by the examples. Here the relative entropy is defined as Δ(w, w1) = ∑ i wi ln wi w1,i + w1,i − wi. More precisely, wt := minw Δ(w, w1) subject to the following example constraints (where θ, α > 0 are fixed): – w · xq = 0, for all 1 ≤ q < t and yt = false, – w · xq ≥ αθ, for all 1 ≤ q < t and yt = true. This algorithm is a variant of the Winnow algorithm [Lit88] which, for w1 = (1, . . . , 1), α = e and θ = ne , makes at most e + ke lnn mistakes on any sequence of examples that is consistent with a k out of n literal disjunction.2 The crucial fact is that the mistake bound of Winnow and its variants grows logarithmically in the number of variables, whereas the mistake bound of the Perceptron algorithm is Ω(kn) [KWA97]. The question is, what is responsible for this dramatic difference? 1 For the sake of simplicity we only consider the noise-free case. 2 An elegant proof of this bound was first given in [LW04] for the case when the additional constraint i wi = 1 is enforced: for w1 = ( 1 n , . . . , 1 n ), α = e and θ = 1 ek , this algorithm makes at most ek ln n mistakes. G. Lugosi and H.U. Simon (Eds.): COLT 2006, LNAI 4005, pp. 653–654, 2006. c © Springer-Verlag Berlin Heidelberg 2006	bit array;bregman divergence;colt;constraint (mathematics);euclidean distance;kullback–leibler divergence;lecture notes in computer science;literal (mathematical logic);manifold regularization;online algorithm;online and offline;perceptron;relevance;springer (tank);winnow (algorithm);monotone	Manfred K. Warmuth	2006		10.1007/11776420_48	entropy;mathematical optimization;calculus;euclidean distance;mathematics;geometry;euclidean distance matrix;statistics	Theory	19.477434467676222	-32.53099636860047	64255
4f56ec7864a2ff6ff6812fa8f202f8514aab2158	competitive learning algorithms and neurocomputer architecture	unsupervised learning;digital signal processing;field programmable gate array;learning algorithms;neuroordinateur;apprentissage competitif;processus non stationnaire;field programmable devices;neural networks;ordinateur parallele;flexible;neurocomputers;real time;real time processing;neural net architecture;algorithme apprentissage;red puerta programable;reseau porte programmable;parallel computation;competitive learning;chip;tratamiento tiempo real;computer architecture;artificial neural networks;traitement temps reel;calculo paralelo;architecture ordinateur;parallel architectures;self organising feature maps;self organizing feature maps;self organized feature map;nonstationary data competitive learning algorithms neurocomputer architecture artificial neural networks self organizing feature maps hardware implementations reconfigurable parallel neurocomputer architecture digital signal processing chips field programmable gate array devices fpga based message preprocessing postprocessing;signal processing algorithms artificial neural networks digital signal processing chips computer architecture field programmable gate arrays concurrent computing prototypes clustering algorithms neural network hardware signal design;ordenador paralelo;self organising feature maps unsupervised learning neural net architecture digital signal processing chips parallel architectures;parallel computer;autoorganizacion;self organization;digital signal processing chips;self organized map;non stationary process;reseau neuronal;calcul parallele;proceso no estacionario;hardware implementation;autoorganisation;parallel processing;artificial neural network	This paper begins with an overview of several competitive learning algorithms in artificial neural networks, including self-organizing feature maps, focusing on properties of these algorithms important to hardware implementations. We then discuss previously reported digital implementations of these networks. Finally, we report a reconfigurable parallel neurocomputer architecture we have designed using digital signal processing chips and field-programmable gate array devices. Communications are based upon a broadcast network with FPGA-based message preprocessing and postprocessing. A small prototype of this system has been constructed and applied to competitive learning in self-organizing maps. This machine is able to model slowly-varying nonstationary data in real time.	algorithm;competitive learning	Howard C. Card;G. K. Rosendahl;Dean K. McNeill;Robert D. McLeod	1998	IEEE Trans. Computers	10.1109/12.707586	chip;embedded system;parallel computing;self-organization;computer science;artificial intelligence;theoretical computer science;digital signal processing;machine learning;competitive learning;artificial neural network;field-programmable gate array	Vision	13.952526549788441	-26.649452045509182	64267
2f7a2b0ae73f01e6c769451d51b60a215627a3de	the restricted isometry property for echo state networks with applications to sequence memory capacity	eigenvalues and eigenfunctions;sequences;optimisation;compressed sensing;noise measurement;sequence memory;vectors;signal processing;sequence memory compressed sensing echo state networks;statistics;tractable optimization program restricted isometry property echo state networks sequence memory capacity networked system ability complex data processing compressed sensing tools network architecture linear node scalability input sequence statistics;statistics compressed sensing optimisation recurrent neural nets sequences;vectors sparse matrices biological neural networks neurons noise measurement eigenvalues and eigenfunctions signal processing;recurrent neural nets;neurons;sparse matrices;echo state networks;biological neural networks	The ability of networked systems (including artificial or biological neuronal networks) to perform complex data processing tasks relies in part on their ability to encode signals from the recent past in the current network state. Here we use Compressed Sensing tools to study the ability of a particular network architecture (Echo State Networks) to stably store long input sequences. In particular, we show that such networks satisfy the Restricted Isometry Property when the input sequences are compressible in certain bases and when the number of nodes scale linearly with the sparsity of the input sequence and logarithmically with its dimension. Thus, the memory capacity of these networks depends on the input sequence statistics, and can (sometimes greatly) exceed the number of nodes in the network. Furthermore, input sequences can be robustly recovered from the instantaneous network state using a tractable optimization program (also implementable in a network architecture).	cobham's thesis;compressed sensing;encode;echo state network;mathematical optimization;network architecture;restricted isometry property;sparse matrix	Han Lun Yap;Adam S. Charles;Christopher J. Rozell	2012	2012 IEEE Statistical Signal Processing Workshop (SSP)	10.1109/SSP.2012.6319765	electronic engineering;theoretical computer science;machine learning;mathematics	ML	20.97472436275448	-29.788608632487087	64949
5ee1df8c2aba8c012ca402b1a6704555b9e2341e	extreme logistic regression	kernel logistic regression;classification;least squares;preconditioner;extreme learning machine;62h30;62h12;kernel matrix	Kernel logistic regression (KLR) is a very powerful algorithm that has been shown to be very competitive with many state-of the art machine learning algorithms such as support vector machines (SVM). Unlike SVM, KLR can be easily extended to multi-class problems and produces class posterior probability estimates making it very useful for many real world applications. However, the training of KLR using gradient based methods or iterative re-weighted least squares can be unbearably slow for large datasets. Coupled with poor conditioning and parameter tuning, training KLR can quickly design matrix become infeasible for some real datasets. The goal of this paper is to present simple, fast, scalable, and efficient algorithms for learning KLR. First, based on a simple approximation of the logistic function, a least square algorithm for KLR is derived that avoids the iterative tuning of gradient based methods. Second, inspired by the extreme learning machine (ELM) theory, an explicit feature space is constructed through a generalized single hidden layer feedforward network and used for training iterative re-weighted least squares KLR (IRLS-KLR) and the newly proposed least squares KLR (LS-KLR). Finally, for large-scale and/or poorly conditioned problems, a robust and efficient preconditioned learning technique is proposed for learning the algorithms presented in the paper. Numerical results on a series of artificial and 12 real bench-mark datasets show first that LS-KLR compares favorable with SVM and traditional IRLS-KLR in terms of accuracy and learning speed. Second, the extension of ELM to KLR results in simple, scalable and very fast algorithms with comparable generalization performance to their original versions. Finally, the introduced preconditioned learning method can significantly increase the learning speed of IRLS-KLR.	logistic regression	Che Ngufor;Janusz Wojtusiak	2016	Adv. Data Analysis and Classification	10.1007/s11634-014-0194-2	mathematical optimization;kernel;biological classification;machine learning;pattern recognition;mathematics;preconditioner;least squares;statistics	ML	22.6504357248911	-35.91474228070223	65075
2dbdb256c1c8df1dba9451b65b2586dfab9cb9dd	what regularized auto-encoders learn from the data-generating distribution	denoising auto encoders;manifold learning;score matching;generative models;unsupervised representation learning;auto encoders;markov chains	What do auto-encoders learn about the underlying data-generating distribution? Recent work suggests that some auto-encoder variants do a good job of capturing the local manifold structure of data. This paper clarifies some of these previous observations by showing that minimizing a particular form of regularized reconstruction error yields a reconstruction function that locally characterizes the shape of the data-generating density. We show that the auto-encoder captures the score (derivative of the log-density with respect to the input). It contradicts previous interpretations of reconstruction error as an energy function. Unlike previous results, the theorems provided here are completely generic and do not depend on the parameterization of the auto-encoder: they show what the auto-encoder would tend to if given enough capacity and examples. These results are for a contractive training criterion we show to be similar to the denoising auto-encoder training criterion with small corruption noise, but with contraction applied on the whole reconstruction function rather than just encoder. Similarly to score matching, one can consider the proposed training criterion as a convenient alternative to maximum likelihood because it does not involve a partition function. Finally, we show how an approximate Metropolis-Hastings MCMC can be setup to recover samples from the estimated distribution, and this is confirmed in sampling experiments.	approximation algorithm;autoencoder;eisenstein's criterion;encoder;experiment;markov chain monte carlo;mathematical optimization;metropolis;metropolis–hastings algorithm;noise reduction;partition function (mathematics);sampling (signal processing)	Guillaume Alain;Yoshua Bengio	2014	Journal of Machine Learning Research		markov chain;mathematical optimization;computer science;machine learning;pattern recognition;mathematics;nonlinear dimensionality reduction;statistics	ML	23.196619042082567	-32.35216306975921	65164
5c0dfee527eab556122443aefad577441f0df19d	memory, learning and neuromediators	memory;diffusion;chemotaxis	We consider a model of a neural network where the individual cells interact only by releasing and absorbing the molecules of a neuromediator. We show that such a system can realize the function of associative memory. A learning mechanism based on the chemotaxis is proposed and numerically investigated.	artificial neural network;biological neural networks;chemotaxis;content-addressable memory;numerical analysis	Alexander S. Mikhailov	1991	Bio Systems		neuroscience;synapse;artificial intelligence;mathematical model;memory;cognitive science	ML	12.487497305397296	-27.444556675198587	65254
80641047beed084d431cd26d202edfac72ce9551	the usefulness of past knowledge when learning a new task in deep neural networks		In the current study we investigate the ability of a Deep Neural Network (DNN) to reuse, in a new task, features previously acquired in other tasks. The architecture we realized, when learning the new task, will not destroy its ability in solving the previous tasks. Such architecture was obtained by training a series of DNNs on different tasks and then merging them to form a larger DNN by adding new neurons. The resulting DNN was trained on a new task, with only the connections relative to the new neurons allowed to change. The architecture performed very well, requiring few new parameters and a smaller dataset in order to be trained efficiently and, on the new task, outperforming several DNNs trained from scratch.	deep learning;neural network software;neuron	Guglielmo Montone;J. Kevin O'Regan;Alexander V. Terekhov	2015			speech recognition;computer science;artificial intelligence;machine learning	NLP	16.85076755324016	-31.88761351095536	65353
a26af732ec5670c6d27c970f8788f70f961e4cee	improved orthogonal least-squares regression with tunable kernels using a tree structure search algorithm	least squares approximations;kernel;orthogonal least squares regression;regression tree analysis kernel tree data structures greedy algorithms matrix decomposition boosting training data signal processing algorithms least squares methods;tree structure search algorithm;search algorithm;regression model;tree data structures;tree searching least squares approximations regression analysis;repeating weighted boosting search;orthogonal least square;orthogonal least squares;tree structure search;search trees;tree structure;regression analysis;tree structure search orthogonal least squares repeating weighted boosting search;tree searching;algorithm design and analysis;least squares methods;tree structure search algorithm orthogonal least squares regression	Orthogonal least-squares (OLS) regression with tunable kernels has been recently introduced, in which a greedy scheme is utilized to tune the parameters of each individual regressor term by term using a global search algorithm. To improve the performance of the greedy-scheme-based OLS algorithm, a tree structure search algorithm is constructed. At each regressor stage, this proposed OLS algorithm is realized by keeping multiple best regressors rather than using the optimal one only. Numerical results show that this new scheme is capable of producing a much sparser regression model with better generalization than the conventional approaches.	computation;continuation;experiment;function model;greedy algorithm;numerical method;ordinary least squares;search algorithm;sparse approximation;sparse matrix;tree structure	Meng Zhang;Lihua Fu;Gaofeng Wang;Tingting He	2008	IEEE Signal Processing Letters	10.1109/LSP.2008.2004518	mathematical optimization;computer science;machine learning;pattern recognition;mathematics;regression analysis	Vision	23.32995650296988	-36.8389601158231	65395
9ea1331d6296468d036ea7984f79cb0701ff5e5e	"""exploring and comparing the best """"direct methods"""" for the efficient training of mlp-networks"""	metodo cuadrado menor;least squares backpropagation;methode moindre carre;feedforward neural networks;least squares approximations;decomposition valeur singuliere;neural networks;least squares method;learning;iterative algorithms;numerical method;gradient method;iterative conjugate gradient svd;estudio comparativo;multilayer perceptrons;benchmark problem;singular value decomposition;backpropagation;direct numerical methods;algorithme;aprendizaje;etude comparative;methode gradient;iterative methods;algorithm;retropropagation;conjugate gradient;apprentissage;red multinivel;metodo gradiente;matrix decomposition;backpropagation algorithm;analyse performance;least square;comparative study;performance analysis;backpropagation algorithms;decomposicion valor singular;neurons;multilayer network;reseau multicouche;reseau neuronal;conjugate gradient methods;local minima;retropropagacion;red neuronal;direct method;neural network;algoritmo;analisis eficacia	"""It is well known that the main difficulties of the algorithms based on backpropagation are the susceptibility to local minima and the slow adaptivity to the patterns during the training. In this paper, we present a class of algorithms, which overcome the above difficulties by utilizing some """"direct"""" numerical methods for the computation of the matrices of weights. In particular, we investigate the performances of the FBFBK-LSB (least-squares backpropagation) algorithms and iterative conjugate gradient singular-value decomposition (ICGSVD), respectively, introduced by Barmann and Biegler-Konig (1993) and by the authors. Numerical results on several benchmark problems show a major reliability and/or efficiency of our algorithm ICGSVD."""		M. Di Martino;Stefano Fanelli;Marco Protasi	1996	IEEE transactions on neural networks	10.1109/72.548177	mathematical optimization;computer science;backpropagation;machine learning;mathematics;least squares;artificial neural network;algorithm	Vision	17.086408021867246	-28.10214466476948	65636
1a700d6cce09f1711cdaf8f5f21b6ab2a8ce7bae	enhanced gradient and adaptive learning rate for training restricted boltzmann machines		Boltzmann machines are often used as building blocks in greedy learning of deep networks. However, training even a simplified model, known as restricted Boltzmann machine (RBM), can be extremely laborious: Traditional learning algorithms often converge only with the right choice of the learning rate scheduling and the scale of the initial weights. They are also sensitive to specific data representation: An equivalent RBM can be obtained by flipping some bits and changing the weights and biases accordingly, but traditional learning rules are not invariant to such transformations. Without careful tuning of these training settings, traditional algorithms can easily get stuck at plateaus or even diverge. In this work, we present an enhanced gradient which is derived such that it is invariant to bitflipping transformations. We also propose a way to automatically adjust the learning rate by maximizing a local likelihood estimate. Our experiments confirm that the proposed improvements yield more stable training of RBMs.	converge;data (computing);experiment;gradient;greedy algorithm;machine learning;restricted boltzmann machine;scheduling (computing)	Kyunghyun Cho;Tapani Raiko;Alexander Ilin	2011			mathematical optimization;computer science;theoretical computer science;machine learning	ML	17.789905177564	-31.50150471298239	65640
5eec55f8acbc7cda90c1c16fab90318591adf6fe	border pairs method - constructive mlp learning classification algorithm	multilayer perceptron;constructive neural network;algorithm;border pairs method;machine learning;artificial intelligence	In this paper we present the Border Pairs Method, a constructive learning algorithm for multilayer perceptron (MLP). During learning with this method a near-minimal network architecture is found. MLP learning is conducted separately by individual layers and neurons. The algorithm is tested in computer simulation with simple learning patterns (XOR and triangles image), with traditional learning patterns (Iris and Pen-Based Recognition of Handwritten Digits) and with noisy learning patterns. During the learning process we observed the following behaviour of BPM: capability to focus on global minima, good generalisation, no problems in learning with noisy, multi-dimensional and numerous learning patterns. The Border Pairs Method also supports incremental and online learning. Both are realized with or without MLP reconstruction and with or without forgetting (unlearning). The learning results with the BPM method are comparable with results from other methods.	algorithm;memory-level parallelism	Bojan Ploj;Robert Harb;Milan Zorman	2014	Neurocomputing	10.1016/j.neucom.2013.03.026	semi-supervised learning;unsupervised learning;instance-based learning;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;leabra;learning classifier system;multilayer perceptron;stability;competitive learning;computational learning theory;active learning;artificial neural network;generalization error	ML	14.6426196782836	-31.994519148824082	65710
cfc2c45465dd6d5b96dc64e039c11c72c2dd5dfe	neural networks for conditional probability estimation - forecasting beyond point predictions			artificial neural network	Dirk Husmeier	1999				ML	10.85677319568389	-25.92272811799699	65953
1fd253f0c30206b14b620970e96aa90ad1381239	a bayesian network classifier that combines a finite mixture model and a naive bayes model		In this paper we present a new Bayesian net­ work model for classification that combines the naive Bayes (NB} classifier and the fi­ nite mixture (FM} classifier. The resulting classifier aims at relaxing the strong assump­ tions on which the two component models are based, in an attempt to improve on their classification performance, both in terms of accuracy and in terms of calibration of the estimated probabilities. The proposed clas­ sifier is obtained by superimposing a finite mixture model on the set of feature variables of a naive Bayes modeL We present exper­ imental results that compare the predictive performance on real datasets of the new clas­ sifier with the predictive performance of the NB classifier and the FM classifier.	bayesian network;fm broadcasting;mixture model;naive bayes classifier	Stephano Monti;Gregory F. Cooper	1999				ML	16.444661606124335	-37.88264460295072	66233
ff45d185ecb51fc9480e1b144a2b6d96a7d164ff	universal learning network and its application to chaos control	simulation ordinateur;systeme commande;equation differentielle;sistema control;fuzzy neural network;exposant lyapunov;learning algorithm;chaotic behavior;ecuacion diferencias;neural networks;forme onde;complexite calcul;chaos;metodo control;caos;differential equation;difference equation;optimization method;algorithme apprentissage;sistema complejo;metodo optimizacion;time delay;learning networks;methode calcul;higher order;methode controle;experimental result;ecuacion diferencial;dynamical system;metodo calculo;systeme dynamique;complejidad computacion;control system;first order;forma onda;systeme complexe;chaos control;network connectivity;complex system;computational complexity;backpropagation algorithm;methode optimisation;resultado experimental;derivee;lyapunov exponent;algorithme retropropagation;exponente lyapunov;equation differences;waveform;simulacion computadora;sistema dinamico;higher order derivatives calculation;reseau neuronal;universal learning networks;resultat experimental;derivada;algoritmo aprendizaje;computer simulation;real time recurrent learning;back propagation;red neuronal;computing method;control method;derivative;neural network;algoritmo retropropagacion	Universal Learning Networks (ULNs) are proposed and their application to chaos control is discussed. ULNs provide a generalized framework to model and control complex systems. They consist of a number of inter-connected nodes where the nodes may have any continuously differentiable nonlinear functions in them and each pair of nodes can be connected by multiple branches with arbitrary time delays. Therefore, physical systems, which can be described by differential or difference equations and also their controllers, can be modeled in a unified way, and so ULNs may form a super set of neural networks and fuzzy neural networks. In order to optimize the ULNs, a generalized learning algorithm is derived, in which both the first order derivatives (gradients) and the higher order derivatives are incorporated. The derivatives are calculated by using forward or backward propagation schemes. These algorithms for calculating the derivatives are extended versions of Back Propagation Through Time (BPTT) and Real Time Recurrent Learning (RTRL) of Williams in the sense that generalized node functions, generalized network connections with multi-branch of arbitrary time delays, generalized criterion functions and higher order derivatives can be deal with. As an application of ULNs, a chaos control method using maximum Lyapunov exponent of ULNs is proposed. Maximum Lyapunov exponent of ULNs can be formulated by using higher order derivatives of ULNs, and the parameters of ULNs can be adjusted so that the maximum Lyapunov exponent approaches the target value. From the simulation results, it has been shown that a fully connected ULN with three nodes is able to display chaotic behaviors.	algorithm;artificial neural network;backpropagation through time;behavior;chaos control;chaos theory;complex systems;dynamical system;equivalent weight;excretory function;exponent;flow network;forward chaining;gradient;han unification;learning disorders;loss function;lyapunov fractal;mathematical optimization;neural network simulation;node - plant part;nonlinear system;numerous;random search;recurrence relation;recurrent neural network;software propagation;upper limit of normal;version	Kotaro Hirasawa;Xiaofeng Wang;Junichi Murata;Jinglu Hu;Chunzhi Jin	2000	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(99)00100-8	computer science;artificial intelligence;backpropagation;machine learning;calculus;mathematics;differential equation;artificial neural network;algorithm	ML	18.47634593484595	-27.393063507056855	66254
57ba482cea0d232404577ef0a1cf7b752dfd103d	a study of scaling and generalization in neural networks	neural network		artificial neural network;image scaling	Subutai Ahmad;Gerald Tesauro	1988	Neural Networks	10.1016/0893-6080(88)90045-7	stochastic neural network;nervous system network models;feedforward neural network;cellular neural network;probabilistic neural network;types of artificial neural networks;computer science;recurrent neural network;machine learning;physical neural network;time delay neural network;deep learning;rectifier;artificial neural network	ML	13.379338259800958	-27.338030633215006	66379
a4271a82869469d589c44c49a0f282801ea841c9	large-scale k-means clustering via variance reduction		Abstract With the increase of the volume of data such as images in web, it is challenging to perform k-means clustering on millions or even billions of images efficiently. One of the reasons is that k-means requires to use a batch of training data to update cluster centers at every iteration, which is time-consuming. Conventionally, k-means is accelerated by using one or a mini-batch of instances to update the centers, which leads to a bad performance due to the stochastic noise. In the paper, we decrease such stochastic noise, and accelerate k-means by using variance reduction technique. Specifically, we propose a position correction mechanism to correct the drift of the cluster centers, and propose a variance reduced k-means named VRKM. Furthermore, we optimize VRKM by reducing its computational cost, and propose a new variant of the variance reduced k-means named VRKM++. Comparing with VRKM, VRKM++ does not have to compute the batch gradient, and is more efficient. Extensive empirical studies show that our methods VRKM and VRKM++ outperform the state-of-the-art method, and obtain about 2 ×  and 4 ×  speedups for large-scale clustering, respectively. The source code is available at https://www.github.com/YaweiZhao/VRKM_sofia-ml .	cluster analysis;k-means clustering;variance reduction	Yawei Zhao;Yuewei Ming;Xinwang Liu;En Zhu;Kaikai Zhao;Jianping Yin	2018	Neurocomputing	10.1016/j.neucom.2018.03.059	empirical research;machine learning;source code;artificial intelligence;cluster analysis;k-means clustering;variance reduction;mathematics;pattern recognition;training set	AI	19.74510213122731	-37.201264483992816	66479
3d80efd5107f60563d422dfb1dd680b8aa2f2c96	pollutants time-series prediction using the gamma classifier	gamma classifier;mexico city;time series;air pollution;sulfur dioxide;mathematical model;nitrogen dioxide;nitrogen oxide;pattern classifier;associative models;environmental data prediction;ozone;time series prediction;carbon monoxide;nitrogen	In this work we predict time series of air pollution data taken in Mexico City and the Valley of Mexico, by using the Gamma Classifier which is a novel intelligent associative mathematical model, coupled with an emergent coding technique. Historical and current data about the concentration of specific pollutants, in the form of time series, were used. The pollutants of interest are: carbon monoxide (CO), ozone (O3), sulfur dioxide (SO2), and nitrogen oxides (NOx, including both nitrogen monoxide, NO, and nitrogen dioxide, NO2).	algorithm;atmospheric chemistry;carbon cycle;database;emergence;gamma correction;kerrison predictor;mathematical model;nl (complexity);nos/ve;naive bayes classifier;nitrogen-vacancy center;quasiperiodicity;scientific literature;server name indication;test card;time series	Itzamá López-Yáñez;Amadeo José Argüelles-Cruz;Oscar Camacho Nieto;Cornelio Yáñez-Márquez	2011	Int. J. Comput. Intell. Syst.	10.1080/18756891.2011.9727822	time series	ML	10.707052590991857	-24.765892694514854	66603
2f25b0abd3ec39edee87b77f543ce29547041328	integrating supervised and unsupervised learning in self organizing maps for gene expression data analysis	unsupervised learning;autoapprentissage;cluster;learning algorithm;supervised learning;analisis datos;amas;model selection criteria;prior knowledge;intelligence artificielle;apprentissage non supervise;algorithme apprentissage;gene expression data;model complexity;autodidactismo;self learning;gene expression;expression genique;data analysis;number of clusters;autoorganizacion;multiple model;artificial intelligence;self organization;analyse donnee;self organized map;monton;inteligencia artificial;reseau neuronal;gene expression data analysis;algoritmo aprendizaje;expresion genetica;red neuronal;autoorganisation;neural network	Recently, Self Organizing Maps have been a popular approach to analyze gene expression data. Our paper presents an improved SOM-based algorithm called Supervised Network Self Organizing Map (sNet-SOM), which overcomes the main drawbacks of existing techniques by adaptively determining the number of clusters with a dynamic extension process and integrating unsupervised and supervised learning in an effort to make use of prior knowledge on data. The process is driven by an inhomogeneous measure that balances unsupervised/supervised learning and model complexity criteria. Multiple models are dynamically constructed by the algorithm, each corresponding to an unsupervised/supervised balance, model selection criteria being used to select the optimum one. The design allows us to effectively utilize multiple functional class labeling.		Seferina Mavroudi;Andrei Dragomir;Stergios Papadimitriou;Anastasios Bezerianos	2003		10.1007/3-540-44989-2_32	semi-supervised learning;unsupervised learning;self-organization;gene expression;computer science;artificial intelligence;machine learning;data mining;supervised learning;data analysis;artificial neural network;cluster	ML	11.445656127160312	-31.994072756366226	66648
dd2c7e04f798044d778756d6954d371f12772a6a	on the bounds on optimal bayes error in the task of multiple data sources		Summary. The paper considers the problem of pattern recognition when we have multiple data sources. We assume that for each data source there are estimated parameters of statistical distributions. The model of classification is primarily based on the Bayes rule and secondarily on the notion of interval-valued fuzzy sets. The set of possible class-conditional probability density functions is represented by an intervalvalued fuzzy set. We consider the case where the uncertainty concerns the mean of Gaussian pdf. In the paper the bound on the optimal Bayess error is presented for a full probabilistic information.		Robert Burduk	2012		10.1007/978-3-642-32384-3_25	pattern recognition;data mining;bayes error rate;mathematics;statistics	ML	21.14742410560246	-29.56556390365803	66868
b61535c6aaa6d13c987dbbda564a68daade7fd5a	learning with confident examples: rank pruning for robust classification with noisy labels		P̃ Ñ learning is the problem of binary classification when training examples may be mislabeled (flipped) uniformly with noise rate ρ1 for positive examples and ρ0 for negative examples. We propose Rank Pruning (RP) to solve P̃ Ñ learning and the open problem of estimating the noise rates, i.e. the fraction of wrong positive and negative labels. Unlike prior solutions, RP is time-efficient and general, requiring O(T ) for any unrestricted choice of probabilistic classifier with T fitting time. We prove RP has consistent noise estimation and equivalent expected risk as learning with uncorrupted labels in ideal conditions, and derive closed-form solutions when conditions are non-ideal. RP achieves state-of-the-art noise estimation and F1, error, and AUC-PR for both MNIST and CIFAR datasets, regardless of the amount of noise and performs similarly impressively when a large portion of training examples are noise drawn from a third distribution. To highlight, RP with a CNN classifier can predict if an MNIST digit is a one or not with only 0.25% error, and 0.46% error across all digits, even when 50% of positive examples are mislabeled and 50% of observed positive labels are mislabeled negative examples.		Curtis G. Northcutt;Tailin Wu;Isaac L. Chuang	2017	CoRR		machine learning;pattern recognition	ML	19.10219478455029	-33.96476591829718	67086
2d13fe944f7ae57b10ba47a5f5f74ca081e3df43	a necessary condition of convergence for reinforcement learning with function approximation	reinforcement learning;function approximation		approximation;reinforcement learning	Artur Merke;Ralf Schoknecht	2002			function approximation;computer science;machine learning;reinforcement learning	ML	16.887296752792167	-25.887853677800017	67103
ba068e83d994db2cf7825e587f49425b1df3c367	semi-supervised clustering using similarity neural networks	pattern clustering;neural nets;prototypes;similarity neural networks;training;k means;backpropagation;data mining;k means clustering semisupervised clustering similarity neural networks binary supervision;distance measurement;artificial neural networks;neural networks clustering algorithms backpropagation algorithms partitioning algorithms iterative algorithms multi layer neural network computer architecture particle measurements extraterrestrial measurements iterative methods;semisupervised clustering;clustering algorithms;neural network model;pattern clustering neural nets;binary supervision;similarity measure;k means clustering;semi supervised clustering;neural network;generalization capability	Similarity Neural Networks (SNNs) are a novel neural network model designed to learn similarity measures for pairs of patterns, exploiting binary supervision. SNNs guarantee to compute non negative and symmetric measures, and show good generalization capabilities even if a small set of supervised pairs is used for training. The application of the new model to K-Means like semi-supervised clustering is investigated, introducing a technique that allows the algorithm to compute cluster centroids by means of Backpropagation on the input layer of the SNN, biased by a regularization function. The experiments carried out on some datasets from the UCI repository show that SNN based clustering almost always outperforms other methods proposed in the literature.	algorithm;backpropagation;cluster analysis;experiment;k-means clustering;network model;neural networks;semi-supervised learning;semiconductor industry;similarity learning;spiking neural network	Stefano Melacci;Marco Maggini;Lorenzo Sarti	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178667	computer science;machine learning;pattern recognition;data mining;artificial neural network;k-means clustering	ML	14.469086082435354	-31.943851652252693	67296
7882a8a0b79084ce80d1372ee0a68fa05ad25332	enhancing multi-label classification by modeling dependencies among labels	structure learning;bayesian network;multi label classification;maximum likelihood estimation;incomplete label assignments	In this paper, we propose a novel framework for multi-label classification, which directly models the dependencies among labels using a Bayesian network. Each node of the Bayesian network represents a label, and the links and conditional probabilities capture the probabilistic dependencies among multiple labels. We employ our Bayesian network structure learning method, which guarantees to find the global optimum structure, independent of the initial structure. After structure learning, maximum likelihood estimation is used to learn the conditional probabilities among nodes. Any current multi-label classifier can be employed to obtain the measurements of labels. Then, using the learned Bayesian network, the true labels are inferred by combining the relationship among labels with the labels' estimates obtained from a current multi-labeling method. We further extend the proposed multi-label classification method to deal with incomplete label assignments. Structural Expectation-Maximization algorithm is adopted for both structure and parameter learning. Experimental results on two benchmark multi-label databases show that our approach can effectively capture the co-occurrent and the mutual exclusive relation among labels. The relation modeled by our approach is more flexible than the pairwise or fixed subset labels captured by current multi-label learning methods. Thus, our approach improves the performance over current multi-label classifiers. Furthermore, our approach demonstrates its robustness to incomplete multi-label classification. & 2014 Elsevier Ltd. All rights reserved.	bayesian network;benchmark (computing);database;expectation–maximization algorithm;experiment;global optimization;graph (discrete mathematics);graphical model;multi-label classification	Shangfei Wang;Zhaoyu Wang;Qiang Ji	2014	Pattern Recognition	10.1016/j.patcog.2014.04.009	computer science;machine learning;pattern recognition;bayesian network;data mining;mathematics;maximum likelihood	AI	17.72915408352354	-36.51017197844515	67348
4ab24cf7dae784641b4ec501c25b8d3ef1c632db	a practical sub-space adaptive filter	piecewise linear;best approximation;smoothing parameter;common bandwidth radial basis function;approximate piecewise linear regression;integrated sensory intelligent system;modified probabilistic neural network;radial basis function;general regression neural network;intelligent system;data flow;sub space;probabilistic neural network;adaptive filter;nonlinear regression	A Sub-Space Adaptive Filter (SSAF) model is developed using, as a basis, the Modified Probabilistic Neural Network (MPNN) and its extension the Tuneable Approximate Piecewise Linear Regression (TAPLR) model. The TAPLR model can be adjusted by a single smoothing parameter continuously from the best piecewise linear model in each sub-space to the best approximately piecewise linear model over the whole data space. A suitable value in between ensures that all neighbouring piecewise linear models merge together smoothly at their boundaries. This model was developed by altering the form of the MPNN, a network used for general nonlinear regression. The MPNNs special structure allows it to be easily used to model a process by appropriately weighting piecewise linear models associated with each of the network's radial basis functions. The model has now been further extended to allow each piecewise linear model section to be adapted separately as new data flows through it. By doing this, the proposed SSAF model represents a learning/filtering method for nonlinear processes that provides one solution to the stability/plasticity dilemma associated with standard adaptive filters.	adaptive filter;dataspaces;flow;linear models;linear model;merge;neural network simulation;nevus sebaceous;nonlinear system;norm (social);piecewise linear continuation;population parameter;probabilistic neural network;radial (radio);radial basis function;smoothing (statistical technique);static single assignment form	A. Zaknich	2003	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(03)00096-0	adaptive filter;data flow diagram;mathematical optimization;radial basis function;proper linear model;probabilistic neural network;piecewise linear function;computer science;machine learning;linear model;control theory;mathematics;piecewise;nonlinear regression;log-linear model	Vision	14.701040000925682	-28.594477427972432	67359
b02ae3e694da3a98ae8eabafb196b69be07cf582	bayesian modelling of neural networks	bayesian modelling;arquitectura red;bayes methods;methode bayes;architecture reseau;statistical model;interconnection network;modele statistique;modelo estadistico;network architecture;reseau neuronal;red neuronal;red interconexion;neural network;reseau interconnexion	I. inlroduclhm Artificial neural models are currently receiving increased attention due to newly developed topologies and algorithms, advanced very large scale integration (VLSI) implementation techniques (Mutihae 1992, 1995, 1996), and the belief that massive parallelism is essential in data processing for pattern recognition and emulating of the brain's functions. A practical lt~yesian framework for neural networks (NNs) modeling aims to develop probabilistie models that fit the data and perlbnn optimal prediclions. Bayesian statistics naturally deals with uncertainty in the data, which is incorporated by mt~rgimdization in predictions of other variables. Newly acquired knowledge may be added in any stage of an experiment and more complex nmdels may be developed to extract further information from the data. Data overfitting and poor generalization are alleviated in Bayesian methods by incorporating the principle of Ockham's razor, which controls model complexity and set the preference for simple models. Bayesian inference satisfies the likelihood principle [Berger 1985] in the sense that inferences depend only on the probabilities assigned to the data tbat were measured and not on the properties of other admissible data that actually did not occur. NNs are parameterized non-linear models used for empirical regression and classification modeling. All neural-inspired models attempt to achieve computational performance by exploring many competing hypotheses simultaneously via dense interconnection of simple computational non-linear elements (neurons). Most neural algorithms adapt permanently the connection weights on the base of current results by relaxation, which iteratively approaches the optimum solution. Traditional statistical techniques are not adaptive but typically process all training data simultaneously before being used with the new data. Furthermore, NN classifiers are non-parametric and make weaker assumptions concerning the shapes of the underlying distributions. Accordingly,	algorithm;artificial neural network;bayesian network;emulator;integrated circuit;interconnection;linear model;linear programming relaxation;neural network software;nonlinear system;occam's razor;overfitting;parallel computing;pattern recognition;very-large-scale integration	Radu Mutihac;A. Cicuttin;A. Cerdeira Estrada;Alberto A. Colavita	1999		10.1007/BFb0098183	statistical model;network architecture;variable-order bayesian network;computer science;artificial intelligence;machine learning;bayesian hierarchical modeling;bayesian statistics;artificial neural network;statistics	ML	19.87239818950469	-27.91553116259896	67421
04340e8e191dace60e54761b8e9f01dc28fc17ae	what can a neuron learn with spike-timing-dependent plasticity?	spike timing dependent plasticity;simulation ordinateur;modelo dinamico;convergence theorem;calcul neuronal;neural computation;donnee experimentale;learning algorithm;neurone impulsionnel;cross correlation function;matriz correlacion;supervised learning;loi probabilite;cross correlation;ley probabilidad;condition necessaire suffisante;correlation croisee;dynamic model;estimacion promedio;dato experimental;spike time dependent plasticity;stdp;algorithme apprentissage;separability;spike;sinapsis;spiking neurons;separabilidad;apprentissage surveille;spiking neuron;necessary and sufficient condition;probability distribution;modele dynamique;convergence simple;analyse correlation;separabilite;matrice correlation;spike train;simulacion computadora;apprentissage supervise;mean estimation;perceptron;reseau neuronal;correlation matrix;estimation moyenne;aprendizaje supervisado;algoritmo aprendizaje;computer simulation;red neuronal;computacion neuronal;condicion necesaria suficiente;analisis correlacion;potentiel action;correlacion cruzada;neural network;correlation analysis;synapse;timing	Spiking neurons are very flexible computational modules, which can implement with different values of their adjustable synaptic parameters an enormous variety of different transformations F from input spike trains to output spike trains. We examine in this letter the question to what extent a spiking neuron with biologically realistic models for dynamic synapses can be taught via spike-timing-dependent plasticity (STDP) to implement a given transformation F. We consider a supervised learning paradigm where during training, the output of the neuron is clamped to the target signal (teacher forcing). The well-known perceptron convergence theorem asserts the convergence of a simple supervised learning algorithm for drastically simplified neuron models (McCulloch-Pitts neurons). We show that in contrast to the perceptron convergence theorem, no theoretical guarantee can be given for the convergence of STDP with teacher forcing that holds for arbitrary input spike patterns. On the other hand, we prove that average case versions of the perceptron convergence theorem hold for STDP in the case of uncorrelated and correlated Poisson input spike trains and simple models for spiking neurons. For a wide class of cross-correlation functions of the input spike trains, the resulting necessary and sufficient condition can be formulated in terms of linear separability, analogously as the well-known condition of learnability by perceptrons. However, the linear separability criterion has to be applied here to the columns of the correlation matrix of the Poisson input. We demonstrate through extensive computer simulations that the theoretically predicted convergence of STDP with teacher forcing also holds for more realistic models for neurons, dynamic synapses, and more general input distributions. In addition, we show through computer simulations that these positive learning results hold not only for the common interpretation of STDP, where STDP changes the weights of synapses, but also for a more realistic interpretation suggested by experimental data where STDP modulates the initial release probability of dynamic synapses.	action potential;algorithm;artificial neuron;best, worst and average case;column (database);computation;computer simulation;convergence (action);cross-correlation;dependent ml;learnability;linear separability;perceptron;programming paradigm;supervised learning;synapse;synapses;version;walter pitts;whole earth 'lectronic link;cell transformation	Robert A. Legenstein;Christian Naeger;Wolfgang Maass	2005	Neural Computation	10.1162/0899766054796888	computer simulation;computer science;artificial intelligence;cross-correlation;machine learning;mathematics;supervised learning;artificial neural network;algorithm;statistics	ML	19.875963780018836	-27.881413711923784	67489
142a8849ca833edc3dee930720378e09ca0a54ef	aggregating regressive estimators: gradient-based neural network ensemble	algoritmo busqueda;modele agrege;algorithme recherche;search algorithm;gradiente;neural network ensemble;modelo agregado;intelligence artificielle;gradient;classification;observador;observateur;regression estimator;aggregate model;artificial intelligence;inteligencia artificial;reseau neuronal;similarity function;observer;clasificacion;red neuronal;neural network	A gradient-based algorithm for ensemble weights modification is presented and applied on the regression tasks. Simulation results show that this method can produce an estimator ensemble with better generalization than those of bagging and single neural network. The method can not only have a similar function to GASEN of selecting many subnets from all trained networks, but also be of better performance than GASEN, bagging and best individual of regressive estimators.		Jiang Meng;Kun An	2006		10.1007/11925231_30	biological classification;computer science;artificial intelligence;machine learning;mathematics;gradient;observer;artificial neural network;statistics;search algorithm	ML	10.37723130687316	-31.542393873495815	67682
952d0c3503f4c0fb669d67006c5823cc641ce522	solving the clm problem by discrete-time linear threshold recurrent neural networks	competitive layer model;discrete time;energy function;optimization problem;recurrent network;recurrent neural network	The competitive layer model (CLM) can be described by the optimization problem that is formulated with the CLM energy function. The minimum points of CLM energy function can be achieved by running some proper recurrent neural networks. In other words, the CLM can be implemented by the recurrent neural networks. This paper proposes the discrete-time linear threshold recurrent networks to solve the CLM problem. The conditions for the stable attractors of the networks are obtained, which just correspond to the conditions of the minimum points of CLM energy function established in the literature before. Therefore, the proposed network can be used to implement the CLM.	channel length modulation;neural networks;recurrent neural network	Lei Zhang;Pheng-Ann Heng;Zhang Yi	2009		10.1007/978-3-642-04274-4_102	optimization problem;discrete time and continuous time;simulation;computer science;artificial intelligence;recurrent neural network;machine learning	ML	18.061442438097295	-26.99871475984363	67817
5c960d28d3dffccde7f7058d649d68fc0b3c9246	research on an improved bp neural network based on fast quantized orthogonal genetic algorithm	optimal solution;convergence;neural nets;training;evolving neural networks;high speed convergence;search problems backpropagation convergence genetic algorithms neural nets;backpropagation;logic operation;optimal solution searching;global property;artificial neural networks;biological cells;fast quantized orthogonal genetic algorithm;logic operation fast quantized orthogonal genetic algorithm bp neural network training algorithm global property high speed convergence optimal solution searching;neural networks genetic algorithms biological neural networks artificial neural networks logic testing computer networks educational institutions computer science parallel processing artificial intelligence;genetic algorithm;genetic algorithms;search problems;bp neural network training algorithm;verification and validation;encoding;high speed;biological neural networks;training algorithm;gallium;neural network	This paper mainly proposes a new improved BP neural network training algorithm based on fast quantized orthogonal genetic algorithm (FQOGA), so as to overcome the disadvantage of neural networks that their structure and parameters were decided stochastically or by someone's experience. In the algorithm, the global property and high-speed convergence of FQOGA and the parallelism of neural network were combined. FQOGA was used to evolve and design the structure, the initial weights and thresholds and the training ratio of neural network, and then the improved training samples were used to search for the optimal solution again by the evolved neural network. Test experiments run for the verification and validation of a logic operation, and the approach is proved to be effective and feasible especially in speeding up the convergence.		Tiehu Fan;Guihe Qin;Qi Zhao	2009		10.1109/ICNC.2009.254	stochastic neural network;probabilistic neural network;computer science;artificial intelligence;theoretical computer science;machine learning;time delay neural network	Robotics	14.872771837920329	-25.120664601835625	67911
c215b9ac79f07c8a43782b224f4416943837ffa8	on the convergence of a class of adam-type algorithms for non-convex optimization		"""This paper studies a class of adaptive gradient based momentum algorithms that update the search directions and learning rates simultaneously using past gradients. This class, which we refer to as the """"Adam-type"""", includes the popular algorithms such as the Adam [1], AMSGrad [2] and AdaGrad [3]. Despite their popularity in training deep neural networks, the convergence of these algorithms for solving nonconvex problems remains an open question. This paper provides a set of mild sufficient conditions that guarantee the convergence for the Adam-type methods. We prove that under our derived conditions, these methods can achieve the convergence rate of order O(log T/ √ T ) for nonconvex stochastic optimization. We show the conditions are essential in the sense that violating them may make the algorithm diverge. Moreover, we propose and analyze a class of (deterministic) incremental adaptive gradient algorithms, which has the same O(log T/ √ T ) convergence rate. Our study could also be extended to a broader class of adaptive gradient methods in machine learning and optimization."""	algorithm;artificial neural network;convex optimization;deep learning;machine learning;mathematical optimization;rate of convergence;stochastic gradient descent;stochastic optimization	Xiangyi Chen;Sijia Liu;Ruoyu Sun;Mingyi Hong	2018	CoRR		mathematical optimization;rate of convergence;stochastic optimization;artificial neural network;algorithm;computer science;convex optimization;momentum;convergence (routing)	ML	22.934278369656244	-33.04223809736752	67965
0cf94d21881e73d598491c70c6d315d577d9b563	an integrity constraint for database systems containing embedded neural networks	electrical capacitance tomography;database system;mathematics;probability;data integrity;neural networks;identity based encryption;neural nets;transfer functions;database management systems;probability database management systems data integrity neural nets pattern classification;computer networks;computer architecture;integrity problem;probablistic neural network integrity constraint database systems embedded neural networks misclassified objects integrity problem database administrator misclassifications mapping probabilities;ear;application specific integrated circuits;database administrator;embedded neural networks;integrity constraint;database systems;integrity constraints;probablistic neural network;pattern classification;mapping probabilities;misclassifications;database systems neural networks electrical capacitance tomography transfer functions computer networks computer architecture mathematics ear identity based encryption application specific integrated circuits;neural network;misclassified objects	Neural networks are used in some database systems to classify objects, but like traditional statistical classifiers they often misclassify. For some applications, it is necessary to bound the proportion of misclassified objects. This is clearly an integrity problem. We describe a new integrity constraint for database systems with embedded neural networks, with which Database Administrator can enforce a bound on the proportion of misclassifications in a class. The approach is based upon mapping probabilities generated by a probablistic neural network to the likely percentage of misclassifications.	data integrity;embedded system;neural networks	Iain Millns;Barry Eaglestone	1998		10.1109/DEXA.1998.707380	computer science;artificial intelligence;theoretical computer science;data integrity;data mining;database;artificial neural network	DB	13.051001282247933	-34.25862192365753	67996
19b413c59a2423c6709978e5a759149b2199b41d	inducing multi-target model trees in a stepwise fashion		Department of Knowledge Technologies, Joˇzef Stefan InstituteJamova 39 - Ljubljana, Slovenia 1000appice@di.uniba.it, Saso.Dzeroski@ijs.siAbstract. Model trees are tree-based models that associate leaves withmultiple linear models and are used to solve prediction problems in whichthe target variable is continuous. In this paper, we address the task ofinducing multi-target model trees, which predict the values of severaltarget variables simultaneously. Each leaf contains several linear models,each predicting the value of a diﬀerent target variable. We propose analgorithm for inducing such trees in a stepwise fashion. At each step oftree construction, we choose either to partition the current training set(split node) or to introduce a regression variable in the linear models,one for each target variable, to be associated with the leaves (regressionnode). Experiments show that multi-target model trees are much smallerthan the corresponding sets of single-target model trees, while achievingcomparable accuracies, and in addition are induced much faster.	stepwise regression	Annalisa Appice;Saso Dzeroski	2007			algorithm;linear model;smallerthan;partition (number theory);regression;training set;mathematics	Theory	17.339452924595815	-35.62712246397946	67999
95fbda4a29b42e6b0d2de710e4386755fa1ce576	stability of randomized learning algorithms	bootstrap method;generalization error;learning algorithm;learning methods;randomized algorithm;leave one out	We extend existing theory on stability, namely how much changes in the training data influence the estimated models, and generalization performance of deterministic learning algorithms to the case of randomized algorithms. We give formal definitions of stability for randomized algorithms and prove non-asymptotic bounds on the difference between the empirical and expected error as well as the leave-one-out and expected error of such algorithms that depend on their random stability. The setup we develop for this purpose can be also used for generally studying randomized learning algorithms. We then use these general results to study the effects of bagging on the stability of a learning method and to prove non-asymptotic bounds on the predictive performance of bagging which have not been possible to prove with the existing theory of stability for deterministic learning algorithms.1	machine learning;randomized algorithm	André Elisseeff;Theodoros Evgeniou;Massimiliano Pontil	2005	Journal of Machine Learning Research		randomized algorithms as zero-sum games;econometrics;empirical risk minimization;computer science;machine learning;mathematics;randomized algorithm;stability;computational learning theory;statistics;generalization error	ML	20.244121683059802	-32.144780708802514	68112
8750b1b3171922104169e83ee69051dbedd603f2	mining the customer credit using artificial neural networks and multivariate adaptive regression splines	artificial neural network;multivariate adaptive regression splines		artificial neural network;multivariate adaptive regression splines;neural networks;spline (mathematics)	Tian-Shyug Lee;I-Fei Chen	2004			multivariate adaptive regression splines;artificial neural network;artificial intelligence;machine learning;computer science;pattern recognition	ML	10.885777681427001	-25.87932253282632	68133
a592c7b3f3538293f0b39a9b8747f937877199c6	a relaxation algorithm influenced by self-organizing maps	restauration image;image processing;relacion orden;procesamiento imagen;ordering;image restoration;intelligence artificielle;fonction seuil;traitement image;restauracion imagen;relation ordre;funcion umbral;autoorganizacion;artificial intelligence;self organization;self organized map;threshold function;inteligencia artificial;autoorganisation	~[)=(bo(&Q& )Fo( XFO O  &() F %&A [  )¡((¢¡_£ ]¤¥t¦ §&=Au ̈ O&(©£GO( ]¤ a £ -_©£ ;F09/«Fj(9  (a« )o = ¬X¬¦   o ¡(&©&=(& ̈; ]¤ 9/  a (£¤ O%§]  ̈9/«F)­§® %]¤ ̄(°  9¬]©9; ̈b/-/F= X( O© «W&O±¤/£2d ©&( )&¡_ °(9( X©£  = &(¢°3©&(« 9 b «FF0¦gXj( ́§«o ¡( ¤/W©&X( ¬«WO&K= ̈μg9K]¤ a &&]=-_©£ ;F 9/« &()­ ~[) ££«F¶t¤¬9/« &(9G&·o© _tX a « a a £ ̄ ̄«W/& ̧=  ¡(% 1± a a X3&( );F ̧o( XFo]¤_¥ ̄£;¬( = ]¤ (bK»¬ ¤9/«WO££­$1⁄4 )¡_/o/9©&0%]¤ ̧    W©&FX ¡(& ) & a ° /_t;F - &( )«F a   KF ¤¬&=AX %= ̄X) &/F X0 X)¬ ́§«W ¡_ ©&(« 9¢F(­§1⁄2 &=(9W(c&W93⁄4]©_t](KX)K  ¿ «WO&aW %(¤ & =±X)GO&_£ a ¢°¬ ]¤ &W9&OW©&F­ ÀAÁÂÃ)Ä)Å)ÆÇXÈ Á§ÉÄ)ÊÌË=ÍË=Ã)Ë É=É=Î§Ï,Ð ÑoÑÒ9ÏFÓ)Ó ÔGÕWÕ Ö!×oØ	algorithm;linear programming relaxation;organizing (structure);relaxation (iterative method)	Michiharu Maeda	2003		10.1007/3-540-44989-2_65	image restoration;self-organization;image processing;order theory;computer science;artificial intelligence;algorithm	ML	12.16789826770565	-31.4644741489083	68157
194a244f12b4eb219603c5dfa465d57ccd84da3b	statistical analysis of neural network modeling and identification of nonlinear systems with memory	gaussian noise;nonlinear filters;convergence;neural networks;learning;convergence of numerical methods;zero memory nonlinear function;statistical analysis neural networks adaptive filters nonlinear filters nonlinear systems gaussian noise neurons backpropagation algorithms adaptive systems computer simulation;mean square error methods neural net architecture statistical analysis identification nonlinear systems discrete time filters gaussian noise adaptive filters backpropagation transient analysis convergence of numerical methods;neural network architecture;neural net architecture;discrete time;backpropagation;linear filtering;transient analysis;neural network training;nonlinear systems;adaptive filters;stationary points;statistical analysis;two layer nonlinear neural network;adaptive systems;backpropagation algorithm;identification;linear adaptive filter;adaptive system;backpropagation algorithms;mean square error methods;neural network modeling;mean transient behavior;network architecture;neurons;neural network model;discrete time filters;nonlinear system;mse surface;computer simulation;adaptive filter;discrete time linear filter;nonlinear systems identification;neural network;convergence statistical analysis neural network modeling nonlinear systems identification discrete time linear filter zero memory nonlinear function gaussian noise linear adaptive filter two layer nonlinear neural network neural network architecture neural network training backpropagation mse surface stationary points mean transient behavior learning;transient behavior	The paper presents a statistical analysis of neural network modeling and identification of nonlinear systems with memory. The nonlinear system model is comprised of a discrete-time linear filter H followed by a zero-memory nonlinear function g(.). The system is corrupted by input and output independent Gaussian noise. The neural network is used to identify and model the unknown linear filter H and the unknown nonlinearity g(.). The network architecture is composed of a linear adaptive filter and a two-layer nonlinear neural network (with an arbitrary number of neurons). The network is trained using the backpropagation algorithm. The paper studies the MSE surface and the stationary points of the adaptive system. Recursions are derived for the mean transient behavior of the adaptive filter coefficients and the neural network weights for slow learning. It is shown that the adaptive filter converges to a scaled version of the unknown filter H, and that the nonlinear neural network converges to an approximation of the unknown nonlinearity. Computer simulations show good agreement between theory and experimental results.	artificial neural network;nonlinear system	Mohamed Ibnkahla	2001		10.1109/ISSPA.2001.949841	adaptive filter;probabilistic neural network;kernel adaptive filter;computer science;backpropagation;machine learning;control theory;artificial neural network	ML	16.623243203285142	-27.642531234183426	68305
16ef68131556f60548c93258eaad71576959186f	event-driven simulations of nonlinear integrate-and-fire neurons	calcul neuronal;neural computation;exponential model;modele exponentiel;integrate and fire;62m45;non linear model;modele non lineaire;spiking neural network;modelo no lineal;neurone integrate and fire;integrate and fire neuron;reseau neuronal;58a25;exponential integrator;red neuronal;computacion neuronal;neural network	Event-driven strategies have been used to simulate spiking neural networks exactly. Previous work is limited to linear integrate-and-fire neurons. In this note, we extend event-driven schemes to a class of nonlinear integrate-and-fire models. Results are presented for the quadratic integrate-and-fire model with instantaneous or exponential synaptic currents. Extensions to conductance-based currents and exponential integrate-and-fire neurons are discussed.	artificial neural network;biological neuron model;computer simulation;conductance (graph);event-driven programming;exponential integrate-and-fire;neural network simulation;nonlinear system;spiking neural network;synaptic package manager	Arnaud Tonnelier;Hana Belmabrouk;Dominique Martinez	2007	Neural Computation	10.1162/neco.2007.19.12.3226	neuroscience;exponential integrator;computer science;artificial intelligence;machine learning;artificial neural network;models of neural computation;spiking neural network	ML	18.940892171810827	-27.446038746603463	68405
bb8aa3ce531e1a1a463ed75dc1d2c10b4a701c56	principal components analysis competitive learning	neurone;calcul neuronal;analisis componente principal;neural computation;tecnologia electronica telecomunicaciones;multisensor;apprentissage competitif;computacion informatica;neural model;grupo de excelencia;calculo automatico;computing;competitive learning;experimental result;calcul automatique;neurona;ciencias basicas y experimentales;principal component analysis;62h25;resultado experimental;analyse composante principale;reseau neuronal;tecnologias;resultat experimental;grupo a;dimensional reduction;capteur multiple;red neuronal;computacion neuronal;neuron;neural network	We present a new neural model that extends the classical competitive learning by performing a principal components analysis (PCA) at each neuron. This model represents an improvement with respect to known local PCA methods, because it is not needed to present the entire data set to the network on each computing step. This allows a fast execution while retaining the dimensionality-reduction properties of the PCA. Furthermore, every neuron is able to modify its behavior to adapt to the local dimensionality of the input distribution. Hence, our model has a dimensionality estimation capability. The experimental results we present show the dimensionality-reduction capabilities of the model with multisensor images.	artificial neural network;competitive learning;computation (action);dimensionality reduction;estimation theory;neural network simulation;neuron;population parameter;principal component analysis;sample variance	Ezequiel López-Rubio;Juan Miguel Ortiz-de-Lazcano-Lobato;José Muñoz-Pérez;José Antonio Gómez-Ruiz	2003	Neural Computation	10.1162/0899766041941880	computing;computer science;artificial intelligence;machine learning;competitive learning;operations research;artificial neural network;principal component analysis	ML	11.866913439183158	-30.627115900634365	68454
962823e2d3a65765ca69adcbe4a2595de848f7fb	discovering data structures using meta-learning, visualization and constructive neural networks	data model;machine learning;data transformation;data structure;neural network	Visualization methods are used to discover simplest data transformations implemented by constructive neural networks, revealing hidden data structures. In this way meta-learning, based on search for simplest models in the space of all data transformations, is facilitated.	algorithm;artificial neural network;computational intelligence;data model;data structure;decision tree;dimensionality reduction;linear classifier;linear separability;machine learning;naive bayes classifier;nonlinear system;quantum point contact;radial (radio);radial basis function;software framework	Tomasz Maszczyk;Marek Grochowski;Wlodzislaw Duch	2010		10.1007/978-3-642-05179-1_22	types of artificial neural networks;computer science;data science;machine learning;data mining;time delay neural network;deep learning	ML	13.198452400194446	-29.520704924720313	68520
5f296937ee831906b25f940ca52146741a0f3f53	training bidirectional recurrent neural network architectures with the scaled conjugate gradient algorithm		Predictions on sequential data, when both the upstream and downstream information is important, is a difficult and challenging task. The Bidirectional Recurrent Neural Network (BRNN) architecture has been designed to deal with this class of problems. In this paper, we present the development and implementation of the Scaled Conjugate Gradient (SCG) learning algorithm for BRNN architectures. The model has been tested on the Protein Secondary Structure Prediction (PSSP) and Transmembrane Protein Topology Prediction problems (TMPTP). Our method currently achieves preliminary results close to 73 % correct predictions for the PSSP problem and close to 79 % for the TMPTP problem, which are expected to increase with larger datasets, external rules, ensemble methods and filtering techniques. Importantly, the SCG algorithm is training the BRNN architecture approximately 3 times faster than the Backpropagation Through Time (BPTT) algorithm.	algorithm;conjugate gradient method;recurrent neural network	Michalis Agathocleous;Chris Christodoulou;Vasilis J. Promponas;Petros Kountouris;Vassilis Vassiliades	2016		10.1007/978-3-319-44778-0_15	mathematical optimization;computer science;theoretical computer science;machine learning	ML	17.152754245863687	-32.64282727876019	68562
eaeff2493e18041a0a060ac8b7bf21a6911c85e6	path relinking and grg for artificial neural networks	optimisation;scatter search;metaheuristics;non linear programming;evolutionary computation;algoritmo busqueda;neural networks;optimizacion;algorithme recherche;programacion no lineal;optimal method;search algorithm;calcul evolutionniste;programmation non lineaire;metaheuristique;path relinking;backpropagation algorithm;algorithme retropropagation;tabu search;optimization;reseau neuronal;back propagation;red neuronal;busqueda tabu;recherche tabou;artificial neural network;neural network;algoritmo retropropagacion	Artificial neural networks (ANN) have been widely used for both classification and prediction. This paper is focused on the prediction problem in which an unknown function is approximated. ANNs can be viewed as models of real systems, built by tuning parameters known as weights. In training the net, the problem is to find the weights that optimize its performance (i.e. to minimize the error over the training set). Although the most popular method for training these networks is back propagation, other optimization methods such as tabu search or scatter search have been successfully applied to solve this problem. In this paper we propose a path relinking implementation to solve the neural network training problem. Our method uses GRG, a gradient-based local NLP solver, as an improvement phase, while previous approaches used simpler local optimizers. The experimentation shows that the proposed procedure can compete with the best-known algorithms in terms of solution quality, consuming a reasonable computational effort.	approximation algorithm;artificial neural network;backpropagation;computation;experiment;feedforward neural network;gradient;mathematical optimization;natural language processing;software propagation;solver;tabu search;test set;whole earth 'lectronic link;eric	Abdellah El-Fallahi;Rafael Martí;Leon S. Lasdon	2006	European Journal of Operational Research	10.1016/j.ejor.2004.08.012	mathematical optimization;computer science;artificial intelligence;backpropagation;machine learning;artificial neural network	AI	16.75332196222326	-24.75108739095911	68592
2dc6f4291ff4f6ba039267749c95f6ddb6e30171	graysofm network for solving classification problems	traveling salesman problem;gray relational analysis;self organizing feature maps;self organized feature map;gray relational pattern analysis;pattern analysis;computer simulation	In this paper, we incorporate gray relational pattern analysis into the self-organizing feature maps (SOFM) network to develop a GraySOFM network. A hybrid neighborhood function is proposed to select the nodes that need to be updated. Only high-related neighboring nodes around the winning node are updated to reduce the computational load and to achieve a better convergence of the training process. In the learning rule, we also take the pattern relationships into account. The GraySOFM is applied to solve one classification problem and five traveling salesman problems as examples. Computer simulations show better results than that of other known SOFM networks. r 2005 Elsevier B.V. All rights reserved.	computation;computer simulation;learning rule;organizing (structure);pattern recognition;performance;problem solving;self-organization;self-organizing map;simulation	Ming-Feng Yeh;Kuang-Chiung Chang	2005	Neurocomputing	10.1016/j.neucom.2005.02.007	computer simulation;computer science;artificial intelligence;machine learning;data mining;travelling salesman problem	AI	14.245362388901919	-32.18345458576333	68672
bbd97187f10b7051ba8abd0373387aa710c4eedf	scaling of probability-based optimization algorithms	optimal algorithm	Population-based Incremental Learning is shown require very sensitive scaling of its learning rate. The learning rate must scale with the system size in a problem-dependent way. This is shown in two problems: the needle-in-a haystack, in which the learning rate must vanish exponentially in the system size, and in a smooth function in which the learning rate must vanish like the square root of the system size. Two methods are proposed for removing this sensitivity. A learning dynamics which obeys detailed balance is shown to give consistent performance over the entire range of learning rates. An analog of mutation is shown to require a learning rate which scales as the inverse system size, but is problem independent.	algorithm;analysis of algorithms;detailed balance;electronic design automation;graphical model;image scaling;independent set (graph theory);population-based incremental learning;regular expression;spatial variability;type constructor;vanish (computer science)	Jonathan L. Shapiro	2002			mathematical optimization;computer science;online machine learning;machine learning;mathematics;statistics;generalization error	ML	20.643337326972997	-32.57293974638176	68761
801b974aa6f6a3f62d2fc04d8e710c559e0f338e	a modified error backpropagation algorithm for complex-value neural networks	backpropagation;modified error function;backpropagation algorithm;local minima;complex value network;neural network	The complex-valued backpropagation algorithm has been widely used in fields of dealing with telecommunications, speech recognition and image processing with Fourier transformation. However, the local minima problem usually occurs in the process of learning. To solve this problem and to speed up the learning process, we propose a modified error function by adding a term to the conventional error function, which is corresponding to the hidden layer error. The simulation results show that the proposed algorithm is capable of preventing the learning from sticking into the local minima and of speeding up the learning.	algorithm;artificial neural network;backpropagation;image processing;maxima and minima;neural network simulation;speech recognition;speed (motion)	Xiaoming Chen;Zheng Tang;Catherine Vairappan;Songsong Li;Toshimi Okada	2005	International journal of neural systems	10.1142/S0129065705000426	computer science;artificial intelligence;backpropagation;machine learning;pattern recognition;artificial neural network;generalization error	ML	16.225806423914662	-28.643432443870854	68812
925e91ecf766af7237717d2da6e09a654baf24f4	prediction of time sequence using recurrent compensatory neuro-fuzzy systems	metodo adaptativo;learning algorithm;fuzzy reasoning;logique floue;logica difusa;methode adaptative;intelligence artificielle;algorithme apprentissage;logical programming;systeme adaptatif;recurrence;fuzzy logic;recurrent network;programmation logique;recurrencia;adaptive method;neuro fuzzy system;adaptive system;fuzzy logic system;sistema adaptativo;artificial intelligence;reseau neuronal recurrent;inteligencia artificial;recurrent neural nets;reseau neuronal;algoritmo aprendizaje;programacion logica;red neuronal;on line learning;neural network	In this paper, a recurrent compensatory neuro-fuzzy system (RCNFS) is proposed for prediction of time sequence. The compensatorybased fuzzy reasoning method is using adaptive fuzzy operations of neuro-fuzzy systems that can make the fuzzy logic systems more adaptive and effective. The recurrent network is embedded in the RCNFS by adding feedback connections in the second layer, where the feedback units act as memory elements. Also, an on-line learning algorithm is proposed to automatically construct the RCNFS. They are created and adapted as on-line learning proceeds via simultaneous structure and parameter learning.		ChiYung Lee;ChengJian Lin	2005		10.1007/11427445_100	fuzzy logic;computer science;artificial intelligence;adaptive system;machine learning;artificial neural network;algorithm	Logic	10.774848473988994	-29.48342735267866	68842
cb0dcbfe4b0095a2ae9fce4e72a54dfd4df3607c	simulated iterative classification a new learning procedure for graph labeling	classification algorithm;low complexity	Collective classification refers to the classification of interlinked and relational objects described as nodes in a graph. The Iterative Classification Algorithm (ICA) is a simple, efficient and widely used method to solve this problem. It is representative of a family of methods for which inference proceeds as an iterative process: at each step, nodes of the graph are classified according to the current predicted labels of their neighbors. We show that learning in this class of model suffers from a training bias. We propose a new family of methods, called Simulated ICA, which helps reducing this training bias by simulating inference during learning. Several variants of the method are introduced. They are both simple, efficient and scale well. Experiments performed on a series of 7 datasets show that the proposed methods outperform representative state-of-the-art algorithms while keeping a low complexity.	algorithm;experiment;graph labeling;independent computing architecture;iteration;iterative method;simulation	Francis Maes;Stéphane Peters;Ludovic Denoyer;Patrick Gallinari	2009		10.1007/978-3-642-04174-7_4	computer science;artificial intelligence;machine learning;pattern recognition;data mining;mathematics;one-class classification	ML	17.681217034048814	-36.754532642897516	68871
c9282390b4ebe10861d54a1066d5f3907a54608a	fir and iir synapses, a new neural network architecture for time series modeling	local recurrence;model performance;mean square error;time series modelling;neural network;time series model	A new neural network architecture involving either local feedforward global feedforward, and/or local recurrent global feedforward structure is proposed. A learning rule minimizing a mean square error criterion is derived. The performance of this algorithm (local recurrent global feedforward architecture) is compared with a local-feedforward global-feedforward architecture. It is shown that the localrecurrent global-feedforward model performs better than the localfeedforward global-feedforward model.	algorithm;artificial neural network;feedforward neural network;finite impulse response;infinite impulse response;learning rule;mean squared error;network architecture;synapse;time series	Andrew D. Back;Ah Chung Tsoi	1991	Neural Computation	10.1162/neco.1991.3.3.375	feedforward neural network;probabilistic neural network;computer science;artificial intelligence;machine learning;time series;control theory;time delay neural network;mathematics;mean squared error;artificial neural network;statistics	ML	14.918070578773733	-27.655435078760863	68904
4cc230ba96a40d0dc507db8b442a57c8806c2ab6	domain-independent feature extraction for multi-classification using multi-objective genetic programming	multiobjective programming;programmation multiobjectif;optimisation;genetic program;confiance;analisis estadistico;optimizacion;classification non supervisee;extraction forme;multi objective optimization;genetic programming;algoritmo genetico;confidence;statistical analysis;machine learning;extraccion forma;confianza;feature extraction;feature partitioning;clasificacion no supervisada;analyse statistique;algorithme genetique;pattern recognition;confidence measurement;unsupervised classification;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;optimization;reconnaissance forme;extraction caracteristique;evolutionary algorithm;classification automatique;reconocimiento patron;multi classification;automatic classification;clasificacion automatica;ge netic programming;pattern extraction;evolutionary computing;programacion multiobjetivo	We propose three model-free feature extraction approaches for solving the multiple class classification problem; we use multi-objective genetic programming (MOGP) to derive (near-)optimal feature extraction stages as a precursor to classification with a simple and fast-to-train classifier. Statistically-founded comparisons are made between our three proposed approaches and seven conventional classifiers over seven datasets from the UCI Machine Learning database. We also make comparisons with other reported evolutionary computation techniques. On almost all the benchmark datasets, the MOGP approaches give better or identical performance to the best of the conventional methods. Of our proposed MOGP-based algorithms, we conclude that hierarchical feature extraction performs best on multi-classification problems.	algorithm;benchmark (computing);evolutionary algorithm;evolutionary computation;feature extraction;feature selection;genetic programming;linear separability;machine learning;mathematical optimization;preprocessor	Yang Zhang;Peter Rockett	2009	Pattern Analysis and Applications	10.1007/s10044-009-0154-1	genetic programming;genetic algorithm;feature extraction;computer science;artificial intelligence;multi-objective optimization;machine learning;evolutionary algorithm;pattern recognition;confidence	AI	10.753938467240424	-34.42070840957642	69462
da382049a37113a1fc6ad10c99c4d1ce9b8f3132	applications of neural networks for industry in europe	neural network		neural networks	Andrew Chadwick	1989	Neurocomputing	10.1016/S0925-2312(89)80016-5	computer science;machine learning;artificial neural network	ML	11.585081413230263	-26.40604036864857	69493
8b2e83dc5fa967fe051ab0261b15822b86d7e2bd	an evolutionary algorithm for variable-sized ann ensemble construction	feedforward neural network;evolutionary computation;annealing;search algorithm;neural network ensemble;vsec evolutionary algorithm variable sized ann ensemble construction method artificial neural network systematic trajectory search algorithm stsa error function feedforward neural networks n bit parity problems neural network ensemble classifiers;ensemble;artificial neural networks;search problems evolutionary computation feedforward neural nets pattern classification;pattern classification;orthogonal array;feedforward neural nets;search problems;orthogonal array artificial neural networks evolutionary computation ensemble n bit parity problems;evolutionary algorithm;artificial neural network;n bit parity problems;evolutionary computing	For some difficult problems, artificial neural network (ANN) ensemble classifiers, instead of a single ANN classifier, are considered. The ensemble usually has better generalization performance than any individual network for classification problems. But, it is not easy to construct the ANN ensemble. In the previous study, the authors presented the systematic trajectory search algorithm (STSA) to train the ANN and the experimental results revealed the performance of the STSA is good. Based on the STSA, an evolutionary algorithm for variable-sized ANN ensemble construction, called the VSEC, is proposed in this paper. A penalty term is added to the error function in order to guarantee the diversity of the ensemble. Besides, a variable-sized ANN ensemble construction method, based on three operations, is proposed to update the ensemble members. The performance of the proposed algorithm is evaluated by applying it to train a class of feedforward neural networks to solve the large n-bit parity problems. By comparing with the previous studies, the experimental results revealed that the neural network ensemble classifiers trained by the VSEC have very good classification ability.	artificial neural network;ensemble kalman filter;evolutionary algorithm;feedforward neural network;search algorithm	Lin-Yu Tseng;Wen-Ching Chen	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5641955	ensembl;feedforward neural network;annealing;computer science;artificial intelligence;machine learning;pattern recognition;ensemble learning;orthogonal array;artificial neural network;evolutionary computation;search algorithm	Robotics	14.37895513906426	-24.4001678538275	69533
83e38b6b77968cf5196f663d9bda99f31a1dd8da	case based imprecision estimates for bayes classifiers with the bayesian bootstrap	bootstrap method;raisonnement base sur cas;razonamiento fundado sobre caso;validacion cruzada;bootstrap;normal distribution;asymmetric loss function;bayes methods;methode bayes;naive bayes;bayesian bootstrap;classification;validation croisee;autogeneration mutuelle;error rate;bootstrapping;cross validation;case based imprecision estimates;case based reasoning;bayes classifier;clasificacion;k fold cross validation	This article outlines a Bayesian bootstrap method for case based imprecision estimates in Bayes classification. We argue that this approach is an important complement to methods such as k-fold cross validation that are based on overall error rates. It is shown how case based imprecision estimates may be used to improve Bayes classifiers under asymmetrical loss functions. In addition, other approaches to making use of case based imprecision estimates are discussed and illustrated on two real world data sets. Contrary to the common assumption, Bayesian bootstrap simulations indicate that the uncertainty associated with the output of a Bayes classifier is often far from normally distributed.	bayesian network;bootstrapping (statistics);cross-validation (statistics);loss function;simulation	G. Niklas Norén;Roland Orre	2005	Machine Learning	10.1007/s10994-005-5010-y	normal distribution;case-based reasoning;econometrics;bayes classifier;naive bayes classifier;biological classification;word error rate;computer science;machine learning;pattern recognition;cross-validation;bootstrapping;statistics	ML	10.618535559879431	-35.188308640883164	69661
c116336862b6ab82f6374ca869d6493dfca702cc	investigation and reduction of discretization variance in decision tree induction	discretisation;complexite;decision tree;seuil;taux erreur;reduction;complejidad;discretization;threshold;discretizacion;complexity;arbol decision;interpretacion;accuracy;induccion;precision;induction;machine learning;estructura datos;error rate;interpretation;reduccion;structure donnee;umbral;decision tree induction;indice error;variance reduction;data structure;arbre decision;variance;variancia	This paper focuses on the variance introduced by the dis-cretization techniques used to handle continuous attributes in decision tree induction. Diierent discretization procedures are rst studied empirically , then means to reduce the discretization variance are proposed. The experiment shows that discretization variance is large and that it is possible to reduce it signiicantly without notable computational costs. The resulting variance reduction mainly improves interpretability and stability of decision trees, and marginally their accuracy. Decision trees ((1], 2]) can be viewed as models of conditional class probability distributions. Top down tree induction recursively splits the input space into non overlapping subsets, estimating class probabilities by frequency counts based on learning samples belonging to each subset. Tree variance is the variability of its structure and parameters resulting from the randomness of the learning set; it translates into prediction variance yielding classiication errors. In regression models, prediction variance can be easily separated from bias, using the well-known bias/variance decomposition of the expected square error. Unfortunately, there is no such decomposition for the expected error rates of classiication rules (e.g. see 3, 4]). Hence, we will look at decision trees as multidimensional regression models for the conditional class probability distributions and evaluate their variance by the regression variance resulting from the estimation of these probabilities. Denoting by ^ P N (C i jx) the conditional class probability estimates given by a tree built from a random learning set of size N at a point x of the input space, we can write this variance (for one class C i) : (1) where the innermost expectations are taken over the set of all learning sets of size N and the outermost expectation is taken over the whole input space. Friedman 4] has studied the impact of this variance on classiication error rates, concluding to the greater importance of this term as compared to bias. Sources of Tree Variance. A rst (important) variance source is related to the need for discretizing continuous attributes by choosing thresholds. In	agile software development;decision tree learning;discretization;ibm jx;lu decomposition;limbo;nat friedman;randomness;recursion;spatial variability;variance reduction;whole earth 'lectronic link	Pierre Geurts;Louis Wehenkel	2000		10.1007/3-540-45164-1_17	discretization error;econometrics;data structure;computer science;machine learning;discretization;mathematics;accuracy and precision;discretization of continuous features;statistics	ML	21.918458369348183	-28.815211747381188	69695
c2f3c329f2891724cfa25f4ee3d859c5e8753e94	a memetic accuracy-based neural learning classifier system	learning algorithm;neural nets;neural networks genetic algorithms backpropagation algorithms computer science multi layer neural network neurons evolutionary computation encoding fuzzy logic multilayer perceptrons;learning classifier system;backpropagation;genetic algorithms pattern classification backpropagation knowledge representation neural nets;pattern classification;genetic algorithm;genetic algorithms;knowledge representation;backpropagation memetic neural learning classifier systems neural network based representation complex problem domains genetic algorithm;local search;neural network	Learning classifier systems (LCS) traditionally use a binary string rule representation with wildcards added to allow for generalizations over the problem encoding. We have presented a neural network-based representation to aid their use in complex problem domains. Here each rule's condition and action are represented by a small neural network, evolved through the actions of the genetic algorithm. In this paper, we present results from the use of backpropagation to provide local search in conjunction with the global search of the genetic algorithm within XCS creating a memetic neural LCS. Significant decreases in the time taken to reach optimal behaviour are obtained from the incorporation of this local learning algorithm.	artificial neural network;backpropagation;genetic algorithm;learning classifier system;local search (optimization);memetics;problem domain;wildcard character	Toby O'Hara;Larry Bull	2005	2005 IEEE Congress on Evolutionary Computation	10.1109/CEC.2005.1554946	feedforward neural network;genetic algorithm;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;machine learning;genetic representation;pattern recognition;time delay neural network;deep learning;learning classifier system;artificial neural network;memetic algorithm	AI	14.779642235396825	-24.895762699699652	69722
d7e0ceb793dc0c6735d0f328d9ac0a703310af09	a fast semi-linear backpropagation learning algorithm	second order;learning process;learning algorithm;feed forward neural network;linear least square;backpropagation;gradient descent;backpropagation algorithm;training algorithm	Ever since the first gradient-based algorithm, the brilliant backpropagation proposed by Rumelhart, a variety of new training algorithms have emerged to improve different aspects of the learning process for feed-forward neural networks. One of these aspects is the learning speed. In this paper, we present a learning algorithm that combines linearleast-squares with gradient descent. The theoretical basis for the method is given and its performance is illustrated by its application to several examples in which it is compared with other learning algorithms and well known data sets. Results show the proposed algorithm improves the learning speed of the basic backpropagation algorithm in several orders of magnitude, while maintaining good optimization accuracy. Its performance and low computational cost makes it an interesting alternative even for second order methods, specially when dealing large networks and training sets.	algorithm;backpropagation;semiconductor industry	Bertha Guijarro-Berdiñas;Oscar Fontenla-Romero;Beatriz Pérez-Sánchez;Paula Fraguela	2007		10.1007/978-3-540-74690-4_20	semi-supervised learning;rprop;instance-based learning;delta rule;wake-sleep algorithm;weighted majority algorithm;computer science;artificial intelligence;backpropagation;theoretical computer science;online machine learning;machine learning;leabra;supervised learning;stability;active learning;artificial neural network;population-based incremental learning;generalization error	ML	16.109933679313922	-29.69617072084884	69830
5b6b776c090dc32f801fd2cf6222c21892f98217	a sufficient condition for convergences of adam and rmsprop		Adam and RMSProp, as two of the most influential adaptive stochastic algorithms for training deep neural networks, have been pointed out to be divergent even in the convex setting via a few simple counterexamples. Many attempts, such as decreasing an adaptive learning rate, adopting a big batch size, incorporating a temporal decorrelation technique, seeking an analogous surrogate, etc., have been tried to promote Adam/RMSProp-type algorithms to converge. In contrast with existing approaches, we introduce an alternative easy-to-check sufficient condition, which merely depends on the parameters of the base learning rate and combinations of historical second-order moments, to guarantee the global convergence of generic Adam/RMSProp for solving large-scale non-convex stochastic optimization. Moreover, we show that the convergences of several variants of Adam, such as AdamNC, AdaEMA, etc., can be directly implied via the proposed sufficient condition in the non-convex setting. In addition, we illustrate that Adam is essentially a specifically weighted AdaGrad with exponential moving average momentum, which provides a novel perspective for understanding Adam and RMSProp. This observation together with this sufficient condition gives much deeper interpretations on their divergences. At last, we validate the sufficient condition by applying Adam and RMSProp to tackle the counterexamples and train deep neural networks. Numerical results are exactly in accord with the analysis in theory.	algorithm;artificial neural network;converge;decorrelation;deep learning;local convergence;mathematical optimization;numerical method;stochastic gradient descent;stochastic optimization;time complexity	Fangyu Zou;Li Shen;Zequn Jie;Weizhong Zhang;Wei Liu	2018	CoRR			ML	23.38153875552167	-33.13904090082509	69912
b2c3aa4aa02ef1f2dc6b758c27a71fe58b538a92	complexity of probabilistic reasoning in directed-path singly-connected bayes networks	bayesian network;complexity;singly connected dags;computational complexity;most probable explanation;message passing;bayes networks;probabilistic reasoning	Directed-path (DP) singly-connected Bayesian networks are an interesting special case that, in particular, includes both polytrees and two-level networks. We analyze the computational complexity of these networks. The prediction problem is shown to be easy, as standard message passing can perform correct updating. However, diagnostic reasoning is hard even for DP singly-connected networks. In addition, finding the most-probable explanation (MPE) is hard, even without evidence. Finally, complexity of nearly DP singly-connected networks is analyzed.  2003 Elsevier B.V. All rights reserved.	bayesian network;computational complexity theory;message passing;path (graph theory)	Solomon Eyal Shimony;Carmel Domshlak	2003	Artif. Intell.	10.1016/S0004-3702(03)00110-3	message passing;complexity;computer science;artificial intelligence;theoretical computer science;machine learning;bayesian network;probabilistic logic;computational complexity theory;algorithm	AI	24.27694591661198	-27.143972087448358	70081
317cd4522b1f4a6f889743578143bb8823623f8b	vime: variational information maximizing exploration	mathematics and statistics	Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as -greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent’s belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards.	action potential;artificial neural network;bayesian network;expectation–maximization algorithm;heuristic (computer science);information gain in decision trees;kullback–leibler divergence;reinforcement learning;sparse matrix;variational principle	Rein Houthooft;Xi Chen;Yan Duan;John Schulman;Filip De Turck;Pieter Abbeel	2016			mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;statistics	ML	24.55260955006054	-30.914442388394768	70131
73c5c776f15fb90ccdd999698d46cffd535d22dd	toward a theory of generalization and learning in xcs	fondation ouvrage;estimacion sesgada;complexite;learning algorithm;evolutionary computation;learning complexity generalization xcs learning classifier system accurate maximally general classifiers effective fitness population size covering probability fitness pressure reward;guidage;recompense;foundations;learning classifier systems lcss;systeme apprentissage;learning systems generalisation artificial intelligence evolutionary computation;hypothese;complejidad;educational software program;population size;learning classifier system;intelligence artificielle;algorithme apprentissage;complexity;guiado;didacticiel;probabilistic approach;indexing terms;satisfiability;classification;xcs;learning systems;recompensa;fundacion obra;hipotesis;reward;enfoque probabilista;approche probabiliste;multiplexeur;guidance;artificial intelligence;multiplexer;algorithme evolutionniste;number;algoritmo evolucionista;programa didactico;inteligencia artificial;generalisation artificial intelligence;evolutionary algorithm;hypothesis;multiplexor;nombre;evolutionary learning;data analysis testing machine learning robots differential equations multiplexing psychology computer science java insurance;algoritmo aprendizaje;biased estimation;estimation biaisee;clasificacion;generalization;numero;evolutionary computing	"""Takes initial steps toward a theory of generalization and learning in the learning classifier system XCS. We start from Wilson's generalization hypothesis, which states that XCS has an intrinsic tendency to evolve accurate, maximally general classifiers. We analyze the different evolutionary pressures in XCS and derive a simple equation that supports the hypothesis theoretically. The equation is tested with a number of experiments that confirm the model of generalization pressure that we provide. Then, we focus on the conditions, termed """"challenges,"""" that must be satisfied for the existence of effective fitness or accuracy pressure in XCS. We derive two equations that suggest how to set the population size and the covering probability so as to ensure the development of fitness pressure. We argue that when the challenges are met, XCS is able to evolve problem solutions reliably. When the challenges are not met, a problem may provide intrinsic fitness guidance or the reward may be biased in such a way that the problem will still be solved. The equations and the influence of intrinsic fitness guidance and biased reward are tested on large Boolean multiplexer problems. The paper is a contribution to understanding how XCS functions and lays the foundation for research on XCS's learning complexity."""	effective fitness;experiment;fitness function;learning classifier system;multiplexer;sensitivity and specificity;software release life cycle;statistical classification;theory	Martin V. Butz;Tim Kovacs;Pier Luca Lanzi;Stewart W. Wilson	2004	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2003.818194	multiplexer;mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;algorithm;evolutionary computation	ML	19.441471928598816	-31.130811565332017	70214
9ef41c9d32f50c81c6941ff18ce54c11c9e1f098	protein loop classification using artificial neural networks	amino acid sequence;artificial neural network;learning vector quantization	We used Artificial Neural Network for protein loop classification based on the amino acid sequence alone. A new algorithm recently proposed, the Hidden Layer Learning Vector Quantization (HLVQ) was used and its accuracy compared with traditional Multilayer Preceptrons (MLP). The HLVQ algorithm achieved superior accuracy correctly classifying most loops. IV BSB 24 Favor ver os Anais do Simpósio em Springer Verlag, Lecture Notes in Bioinformatics (LNBI número 3594) para este trabalho. Please see the Symposium Proceedings in Lecture Notes in Bioinformatics (LNBI nr. 3594), Springer Verlag, for this paper.	algorithm;artificial neural network;learning vector quantization;multilayer perceptron;neural networks;peptide sequence;quad flat no-leads package	Armando Vieira;Baldomero Oliva	2005		10.1007/11532323_28	biology;types of artificial neural networks;learning vector quantization;computer science;artificial intelligence;machine learning;pattern recognition;time delay neural network;peptide sequence;artificial neural network	ML	12.294743213358931	-28.318056764279593	70273
162733f1f7f2af787c87e635144dcae3f38e2c14	determining the number of non-spurious arcs in a learned dag model: investigation of a bayesian and a frequentist approach	structure learning;false discovery rate;bayesian approach;learning model;posterior distribution;immune system;graphical model;synthetic data;computational biology	In many application domains, such as computational biology, the goal of graphical model structure learning is to uncover discrete relationships between entities. For example, in our problem of interest concerning HIV vaccine design, we want to infer which HIV peptides interact with which immune system molecules (HLA molecules). For problems of this nature, we are interested in determining the number of nonspurious arcs in a learned graphical model. We describe both a Bayesian and frequentist approach to this problem. In the Bayesian approach, we use the posterior distribution over model structures to compute the expected number of true arcs in a learned model. In the frequentist approach, we develop a method based on the concept of theFalse Discovery Rate . On synthetic data sets generated from models similar to the ones learned, we find that both the Bayesian and frequentist approaches yield accurate estimates of the number of non-spurious arcs. In addition, we speculate that the frequentist approach, which is non-parametric, may outperform the parametric Bayesian approach in situations where the models learned are less representative of the data. Finally, we apply the frequentist approach to our problem of HIV vaccine design.	computational biology;entity;graphical model;graphical user interface;synthetic data	Jennifer Listgarten;David Heckerman	2007			econometrics;false discovery rate;immune system;frequentist inference;bayesian probability;computer science;machine learning;mathematics;graphical model;posterior probability;bayesian hierarchical modeling;statistics;synthetic data	ML	24.56823623248946	-28.088425586425743	70329
9732c0c213e3491adbf1a97097cfcc99bdfa8aa8	variational dropout via empirical bayes		We study the Automatic Relevance Determination procedure applied to deep neural networks. We show that ARD applied to Bayesian DNNs with Gaussian approximate posterior distributions leads to a variational bound similar to that of variational dropout, and in the case of a fixed dropout rate, objectives are exactly the same. Experimental results show that the two approaches yield comparable results in practice even when the dropout rates are trained. This leads to an alternative Bayesian interpretation of dropout and mitigates some of the theoretical issues that arise with the use of improper priors in the variational dropout model. Additionally, we explore the use of the hierarchical priors in ARD and show that it helps achieve higher sparsity for the same accuracy.	approximation algorithm;artificial neural network;calculus of variations;deep learning;dropout (neural networks);relevance;sparse matrix;variational inequality;variational principle	Valery Kharitonov;Dmitry Molchanov;Dmitry Vetrov	2018	CoRR			ML	23.347695649220675	-32.54303269644836	70495
6aab4964c34270d176b724f083d51abb0e39c680	a functional link network with ordered basis functions	polynomial basis function;polynomials chebyshev approximation function approximation neural networks least squares approximation explosions data handling usa councils strontium training data;modified gram schmidt;radial basis function networks;function approximation;polynomial basis function functional link network modified gram schmidt orthonormalization one pass method;multi layer perceptron;electrical engineering a functional link network using ordered basis functions the university of texas at arlington michael t manry sureka;group method of data handling;one pass method;polynomial basis;functional link network;modified gram schmidt orthonormalization;saurabh	A procedure is presented for selecting and ordering the polynomial basis functions in the functional link net (FLN). This procedure, based upon a modified Gram Schmidt orthonormalization, eliminates linearly dependent and less useful basis functions at an early stage, reducing the possibility of combinatorial explosion. The number of passes through the training data is minimized through the use of correlations. A one-pass method is used for validation and network sizing. Function approximation and learning examples are presented. Results for the ordered FLN are compared with those for the FLN, group method of data handling, and multi-layer perceptron.	algorithmic efficiency;approximation;basis function;group method of data handling;mimo;mathematical optimization;multilayer perceptron;nonlinear system;optimization problem;polynomial basis;scalability;schmidt decomposition	Saurabh Sureka;Michael T. Manry	2007	2007 International Joint Conference on Neural Networks	10.1109/IJCNN.2007.4371215	mathematical optimization;function approximation;computer science;basis function;machine learning;group method of data handling;mathematics;multilayer perceptron;radial basis function network;algorithm	Vision	17.869503372879116	-28.952481854647235	70584
7d0dcd764308e81f6ecdd8fa5af685ba4830e9f3	a robust fuzzy cmac for function approximation	function approximation fuzzy cmac robust noises and outliers;cmac learning process;learning process;cybernetics;pattern clustering;cerebellar model arithmetic computers;equations mathematical model noise robustness function approximation artificial neural networks cybernetics;noises and outliers;cmac;pattern clustering cerebellar model arithmetic computers function approximation fuzzy set theory learning artificial intelligence;weight updating;fuzzy set theory;robust;nonlinear functions;fuzzy clustering;artificial neural networks;robust fuzzy cmac;robust fuzzy clustering;function approximation;outliers;fuzzy;mathematical model;cmac learning process robust fuzzy cmac function approximation cmac neural network nonlinear functions weight updating nonlinear system noise outliers robust fuzzy clustering;robustness;learning artificial intelligence;nonlinear system;cmac neural network;noise;neural network	This paper proposes a new robust fuzzy CMAC algorithm for function approximation. The advantages of CMAC neural network are fast learning convergence, capable of mapping nonlinear functions quickly due to its local generalization of weight updating. In this paper, in order to overcome the problems of function approximation for a nonlinear system with noise and outliers, a robust fuzzy clustering method is proposed to greatly mitigate the influence of noise and outliers and then a new CMAC learning process used to learn the nonlinear system's features for function approximation.	algorithm;approximation;artificial neural network;cluster analysis;fuzzy clustering;nonlinear system;one-key mac;whole earth 'lectronic link	Horng-Lin Shieh;Chin-Yun Bao	2010	2010 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2010.5580760	fuzzy logic;outlier;fuzzy clustering;function approximation;computer science;noise;artificial intelligence;machine learning;mathematical model;control theory;mathematics;fuzzy set;cmac;artificial neural network;robustness	Robotics	15.14619691060705	-29.267841629991562	70675
00b1a84062e10a886b7f666a3252fadb55ce039a	avoiding synchronization in first-order methods for sparse convex optimization		Parallel computing has played an important role in speeding up convex optimization methods for big data analytics and large-scale machine learning (ML). However, the scalability of these optimization methods is inhibited by the cost of communicating and synchronizing processors in a parallel setting. Iterative ML methods are particularly sensitive to communication cost since they often require communication every iteration. In this work, we extend well-known techniques from Communication-Avoiding Krylov subspace methods to first-order, block coordinate descent methods for Support Vector Machines and Proximal Least-Squares problems. Our Synchronization-Avoiding (SA) variants reduce the latency cost by a tunable factor of u0027su0027 at the expense of a factor of u0027su0027 increase in flops and bandwidth costs. We show that the SA-variants are numerically stable and can attain large speedups of up to 5.1x on a Cray XC30 supercomputer.	big data;binary-coded decimal;central processing unit;convex optimization;coordinate descent;cray xc30;flops;first-order predicate;iteration;krylov subspace;machine learning;mathematical optimization;numerical linear algebra;numerical stability;parallel computing;spark;scalability;sparse;supercomputer;support vector machine	Aditya Devarakonda;Kimon Fountoulakis;James Demmel;Michael W. Mahoney	2018	2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)	10.1109/IPDPS.2018.00051	latency (engineering);parallel computing;support vector machine;computer science;coordinate descent;scalability;convex optimization;krylov subspace;convex function;supercomputer	HPC	24.376259263259016	-34.23273862601981	70754
7fd36673cc9359ac2312548042fcea2c3916ce0e	spiking neural network self-configuration for temporal pattern recognition analysis	hardware implementation of genetic algorithms;neural networks;spiking neural network;design guideline;temporal pattern;genetic algorithm;spiking neural networks;hardware implementation;neural network	In this work we provide design guidelines for the hardware implementation of Spiking Neural Networks. The proposed methodology is applied to temporal pattern recognition analysis. For this purpose the networks are trained using a simplified Genetic Algorithm. The proposed solution is applied to estimate the processing efficiency of Spiking Neural Networks.	pattern recognition;spiking neural network	José Luis Rosselló;Ivan de Paúl;Vicent Canals;Antoni Morro	2009		10.1007/978-3-642-04274-4_44	stochastic neural network;genetic algorithm;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;physical neural network;time delay neural network;deep learning;artificial neural network;spiking neural network	Vision	13.878575345795648	-26.32021577268671	70952
3da9839379bc6cad9d35f725506547cc4f01a1a4	coupling dimensionality reduction with generative model for non-interactive private data release		A key challenge facing the design of differentially private systems in the non-interactive setting is to maintain the utility of the released data for general analytics applications. To overcome this challenge, we propose the PCA-Gauss system that leverages the novel combination of dimensionality reduction and generative model for synthesizing differentially private data. We present multiple algorithms that combine dimensionality reduction and generative models for a range of machine learning applications, including both unsupervised and supervised learning. Our key theoretical results prove that (a) our algorithms satisfy the strong -differential privacy guarantee, and (b) dimensionality reduction can quadratically lower the level of perturbation required for differential privacy, with minimal cost of information loss. Finally, we illustrate the effectiveness of PCA-Gauss under three common machine learning applications – clustering, classification, and regression – on three large real-world datasets. Our empirical results show that (a) PCA-Gauss outperforms previous approaches by an order of magnitude, and (b) loss in utility compared to the non-private real data is small. Thus, PCA-Gauss can serve as a key enabler for real-world deployment of privacypreserving data release.	algorithm;cluster analysis;differential privacy;dimensionality reduction;emoticon;gauss–kronrod quadrature formula;generative model;information privacy;interactivity;machine learning;software deployment;statistical classification;supervised learning	Thee Chanyaswad;Changchang Liu;Prateek Mittal	2017	CoRR		generative model;supervised learning;differential privacy;software deployment;cluster analysis;dimensionality reduction;machine learning;computer science;artificial intelligence;pattern recognition;analytics	ML	23.01208817603502	-35.328619942444746	71078
9774fdf2595fbcbf4a481f9137f7870c44d3d9cb	an intelligent method for modulation type identification	learning algorithms;learning algorithm;higher order cumulants;multilayer perceptron;higher order;modulation identification;statistical pattern recognition;higher order moments;genetic algorithm;optimization;cumulant;signal to noise ratio;back propagation;digital modulation;neural network	Automatic modulation type identification is needed in many applications. Most of modulation type identification methods can only recognize a few kinds of signals. They usually require high levels of signal to noise ratio (SNR). This paper proposes an intelligent digital modulation type identifier. This identifier uses a multilayer perceptron neural network with resilient back propagation learning algorithm as the classifier and higher order moments and cumulants (up to eighth) as the features. Genetic algorithm is utilized to finding the numbers of hidden layer nodes and selection of input features. Experiment results show that proposed identifier is able to discriminate the different kinds of digital modulation with high accuracy even at very low SNR values.	artificial neural network;backpropagation;genetic algorithm;identifier;modulation;multilayer perceptron;signal-to-noise ratio;software propagation	A. E. Zadeh;S. A. Seyedin;M. Dehghan	2006		10.1145/1292331.1292365	speech recognition;genetic algorithm;higher-order logic;computer science;backpropagation;machine learning;pattern recognition;multilayer perceptron;signal-to-noise ratio;artificial neural network;cumulant	AI	14.581598499646812	-30.617492844637198	71186
905b5cb8b97351c5682e97e3dfaa7e2e87e3385a	a connectionist learning algorithm with provable generalization and scaling bounds	learning algorithm;connectionism;learning;pac learning;conexionismo;connectionist;decision lists;algorithme;aprendizaje;algorithm;brd algorithm;connexionnisme;distributed method;apprentissage;valiant model;perceptron;reseau neuronal;k order distributed networks;computational learning theory;red neuronal;vapnik chervonenkis dimension;pocket algorithm;neural network;algoritmo	A connectionist learning algorithm, the bounded, randomized, distributed (BRD) algorithm, is presented and formally analyzed within the framework of computational learning theory. From a neural network viewpoint this framework gives clear definitions to commonly used terms such as “generalization” and “scaling up,” and addresses the following questions: #R##N#•#TAB##R##N#• What class of functions is being learned?#R##N##R##N#•#TAB##R##N#• How many training examples should be used?#R##N##R##N#•#TAB##R##N#• How many iterations are required?#R##N##R##N#•#TAB##R##N#• With what certainty can we be assured of learning a good model?#R##N##R##N##R##N##R##N##R##N#From a computational learning theory perspective, a new class of connectionist concepts is shown to be polynomially learnable using the BRD algorithm. Since a variant of the BRD algorithm is in current use for tasks such as pattern recognition, this makes it one of the few learning algorithms shown to be polynomial within the computational learning theory framework that is close to an “industrial strength” algorithm.#R##N##R##N#The algorithm can fail for several reasons: (a) noisy inputs; (b) underestimation of the difficulty of the concept being learned (i.e., larger concept class required); or (c) bad luck. Whenever the algorithm fails, there are several “fallback bounds” available.#R##N##R##N#Finally, the Appendix gives a learnable class of network functions that strictly enlarges a class of learnable functions, Rivest's k-decision lists.	algorithm;connectionism;provable security	Stephen I. Gallant	1990	Neural Networks	10.1016/0893-6080(90)90089-4	connectionism;computer science;artificial intelligence;perceptron;machine learning;mathematics;stability;decision list;probably approximately correct learning;algorithm;statistics	ML	19.286649294358327	-32.3876970382894	71237
528f6785f9cf9758f32cd99f14ad9f1d0ae3d5f0	multi-agent reinforcement learning: weighting and partitioning	optimisation;multiagent system;neural networks;optimizacion;multi agent reinforcement learning;weighted averaging;reinforcement learning;heuristic method;weighting;espace etat;partitioning;metodo heuristico;experimental result;apprentissage renforce;function approximation;pesaje;state space;gating;resultado experimental;optimization;partitionnement;pesage;methode heuristique;reseau neuronal;espacio estado;resultat experimental;sistema multiagente;aprendizaje reforzado;weighing;red neuronal;averaging;systeme multiagent;neural network	This article addresses weighting and partitioning, in complex reinforcement learning tasks, with the aim of facilitating learning. The article presents some ideas regarding weighting of multiple agents and extends them into partitioning an input/state space into multiple regions with differential weighting in these regions, to exploit differential characteristics of regions and differential characteristics of agents to reduce the learning complexity of agents (and their function approximators) and thus to facilitate the learning overall. It analyzes, in reinforcement learning tasks, different ways of partitioning a task and using agents selectively based on partitioning. Based on the analysis, some heuristic methods are described and experimentally tested. We find that some off-line heuristic methods perform the best, significantly better than single-agent models.	addresses (publication format);experiment;heuristic;online and offline;reinforcement learning;state space	Ron Sun;Todd Peterson	1999	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(99)00024-6	function approximation;computer science;state space;artificial intelligence;machine learning;gating;weighting;learning classifier system;artificial neural network;algorithm	AI	10.727580908690374	-30.133362012620402	71422
af59b48b6fb4738714888e547fc561a28ea2b5df	multi-steps prediction of chaotic time series based on echo state network	learning process;learning algorithm;echo state network;esn;learning;chaos;regularization method;chaotic time series;time series chaos learning artificial intelligence prediction theory radial basis function networks;time series;regularization;artificial neural networks predictive models computational modeling computer architecture adaptation model;radial basis function networks;phase space reconstruction;computer architecture;artificial neural networks;computational modeling;adaptation model;prediction theory;function approximation;phase space reconstruction chaos prediction echo state network regularization;ill posed problem;rbf network echo state network chaotic time series ill posed problem learning esn regularization method function approximation neural network prediction model;predictive models;prediction model;learning artificial intelligence;rbf network;chaos prediction;neural network	Considering of the ill-posed problem in learning process of echo state network(ESN), a new learning algorithm of ESN is proposed based on regularization method. The regularization term provides a stable solution to function approximation with a tradeoff between accuracy and smoothness of the solutions. So the redundant weights of neural network are damped and converged to the zero state. The structure of neural network will become more compact with a particular accuracy. The neural network has good generalization. The simulation results show that the proposed algorithm has higher accuracy than the prediction model based on RBF network in multi-steps prediction by Lorenz and Chen mapping.	approximation algorithm;artificial neural network;condition number;echo state network;entity–relationship model;matrix regularization;radial basis function network;simulation;time series;well-posed problem	Yong Song;Yibin Li;Qun Wang;Caihong Li	2010	2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA)	10.1109/BICTA.2010.5645205	mathematical optimization;probabilistic neural network;computer science;artificial intelligence;machine learning	ML	15.960799301586112	-28.20888861200778	71451
03945d433836d4acee6ec73e6f9bc38d86635732	incremental evolution of a signal classification hardware architecture for prosthetic hand control	high performance system;prosthetic hand control;electronic circuit;ordinary approach;signal classification hardware architecture;best circuit;new method;incremental evolution;sensor data;best performance;evolvable hardware;better training data;hardware architecture	Evolvable Hardware (EHW) is a new method for designing electronic circuits. However, there are several problems to solve for making high performance systems. One is the limited scalability of the ordinary approach. To reduce this problem, a novel digital signal classification architecture has been developed that allows for incremental evolution. This is based on initially evolving subcircuits for each category to be detected. The architecture is applied for classifying sensor data in a prosthetic hand controller. By applying the proposed method, the best performance achieved is substantially better than that obtained by more ordinary approaches. Analysis of the best circuit shows the importance of having an architecture containing some gates with random connections. Results of the analysis can also be used to collect better training data from users in the future.		Jim Tørresen	2008	KES Journal		reference architecture;space-based architecture;real-time computing;simulation;computer science;artificial intelligence;machine learning;hardware architecture	ML	14.27832136082672	-26.02081752233439	71512
4c50c81db39ed3964811818d1e647c82368fe9a1	simple and fast calculation of the second-order gradients for globalized dual heuristic dynamic programming in neural networks	dynamic programming;neural nets;matrix algebra;value gradient learning adaptive dynamic programming dual heuristic programming neural networks;qa75 electronic computers computer science;vectors;neural networks vectors heuristic algorithms backpropagation training equations trajectory;vectors dynamic programming matrix algebra neural nets;derivative calculation second order gradient globalized dual heuristic dynamic programming neural network mixed second order derivative input vector weight vector adaptive dynamic programming algorithm globalized dual heuristic programming value gradient learning second order matrix forward accumulation	We derive an algorithm to exactly calculate the mixed second-order derivatives of a neural network's output with respect to its input vector and weight vector. This is necessary for the adaptive dynamic programming (ADP) algorithms globalized dual heuristic programming (GDHP) and value-gradient learning. The algorithm calculates the inner product of this second-order matrix with a given fixed vector in a time that is linear in the number of weights in the neural network. We use a “forward accumulation” of the derivative calculations which produces a much more elegant and easy-to-implement solution than has previously been published for this task. In doing so, the algorithm makes GDHP simple to implement and efficient, bridging the gap between the widely used DHP and GDHP ADP methods.	algorithm;artificial neural network;biological neural networks;bridging (networking);dual;dual-energy x-ray absorptiometry;dynamic programming;heuristic;image gradient;neural network simulation;scientific publication;time complexity;tree accumulation;usb on-the-go;dihydropyridine	Michael Fairbank;Eduardo Alonso;Danil V. Prokhorov	2012	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2012.2205268	mathematical optimization;reactive programming;computer science;theoretical computer science;machine learning;dynamic programming;artificial neural network	ML	20.214231060773958	-25.83274077471473	71574
08751772c88872b742a11e9c64c20286befefe28	representational power of restricted boltzmann machines and deep belief networks	loi discrete;unsupervised learning;modelizacion;discrete distribution;ley discreta;calcul neuronal;neural computation;learning algorithm;51e24;algorithme glouton;layer model;fonction repartition;modelo capa;62m45;apprentissage non supervise;algorithme apprentissage;modele reseau neuronal;modelisation;probabilistic model;funcion distribucion;distribution function;unite cachee;modele couche;couche cachee;modele probabiliste;greedy algorithm;boltzmann machine;algoritmo gloton;estimation statistique;reseau neuronal;estimacion estadistica;algoritmo aprendizaje;modeling;statistical estimation;red neuronal;computacion neuronal;boltzmann machines;belief network;machine boltzmann;neural network;modelo probabilista	Deep belief networks (DBN) are generative neural network models with many layers of hidden explanatory factors, recently introduced by Hinton, Osindero, and Teh (2006) along with a greedy layer-wise unsupervised learning algorithm. The building block of a DBN is a probabilistic model called a restricted Boltzmann machine (RBM), used to represent one layer of the model. Restricted Boltzmann machines are interesting because inference is easy in them and because they have been successfully used as building blocks for training deeper models. We first prove that adding hidden units yields strictly improved modeling power, while a second theorem shows that RBMs are universal approximators of discrete distributions. We then study the question of whether DBNs with more layers are strictly more powerful in terms of representational power. This suggests a new and less greedy criterion for training RBMs within DBNs.	bayesian network;discrete distribution;greedy algorithm;inference;neural network simulation;representation (action);restricted boltzmann machine;statistical model;teh;unsupervised learning;anatomical layer;explanation	Nicolas Le Roux;Yoshua Bengio	2008	Neural Computation	10.1162/neco.2008.04-07-510	unsupervised learning;boltzmann machine;probability distribution;statistical model;greedy algorithm;systems modeling;computer science;artificial intelligence;distribution function;machine learning;bayesian network;mathematics;deep learning;restricted boltzmann machine;deep belief network;artificial neural network;algorithm;models of neural computation	ML	19.940886134390652	-27.9181250133981	71583
3bb376a3fa01e9029065e2313a248e3fafcece97	estimating quality of support vector machines learning under probabilistic and interval uncertainty: algorithms and computational complexity	computational complexity;support vector machine;interval uncertainty	Support Vector Machines (SVM) is one of the most widely used technique in machines leaning. After the SVM algorithms process the data and produce some classification, it is desirable to learn how well this classification fits the data. There exist several measures of fit, among them the most widely used is kernel target alignment. These measures, however, assume that the data are known exactly. In reality, whether the data points come from measurements or from expert estimates, they are only known with uncertainty. As a result, even if we know that the classification perfectly fits the nominal data, this same classification can be a bad fit for the actual values (which are somewhat different from the nominal ones). In this paper, we show how to take this uncertainty into account when estimating the quality of the resulting classification.	algorithm;analysis of algorithms;computational complexity theory;data point;fits;kernel (operating system);level of measurement;machine learning;np-hardness;statistical classification;support vector machine	Canh Hao Nguyen;Tu Bao Ho;Vladik Kreinovich	2008		10.1007/978-3-540-77664-2_6	mathematical optimization;probabilistic analysis of algorithms;average-case complexity;machine learning;pattern recognition;computational resource;mathematics;relevance vector machine;computational learning theory;asymptotic computational complexity	ML	16.611575343755298	-37.61510549199559	71592
cca9421b87daaa6e7efe4668b45c3206e6cad1e4	sketching linear classifiers over data streams		We introduce a new sub-linear space sketch---the Weight-Median Sketch---for learning compressed linear classifiers over data streams while supporting the efficient recovery of large-magnitude weights in the model. This enables memory-limited execution of several statistical analyses over streams, including online feature selection, streaming data explanation, relative deltoid detection, and streaming estimation of pointwise mutual information. Unlike related sketches that capture the most frequently-occurring features (or items) in a data stream, the Weight-Median Sketch captures the features that are most discriminative of one stream (or class) compared to another. The Weight-Median Sketch adopts the core data structure used in the Count-Sketch, but, instead of sketching counts, it captures sketched gradient updates to the model parameters. We provide a theoretical analysis that establishes recovery guarantees for batch and online learning, and demonstrate empirical improvements in memory-accuracy trade-offs over alternative memory-budgeted methods, including count-based sketches and feature hashing.	core data;data structure;feature hashing;feature selection;gradient;linear classifier;pointwise mutual information;sketch;streaming media	Kai Sheng Tai;Vatsal Sharan;Peter Bailis;Gregory Valiant	2018		10.1145/3183713.3196930	pointwise mutual information;computer science;data stream;machine learning;streams;artificial intelligence;feature selection;data stream mining;data structure;linear classifier;feature hashing	DB	14.998772357743851	-37.71516349337483	71611
0d9a6c013fdbff85d3a438304547e887b48b4062	rademacher observations, private data, and boosting	conference paper	The minimization of the logistic loss is a popular approach to batch supervised learning. Our paper starts from the surprising observation that, when fitting linear (or kernelized) classifiers, the minimization of the logistic loss is equivalent to the minimization of an exponential rado-loss computed (i) over transformed data that we call Rademacher observations (rados), and (ii) over the same classifier as the one of the logistic loss. Thus, a classifier learnt from rados can be directly used to classify observations. We provide a learning algorithm over rados with boostingcompliant convergence rates on the logistic loss (computed over examples). Experiments on domains with up to millions of examples, backed up by theoretical arguments, display that learning over a small set of random rados can challenge the state of the art that learns over the complete set of examples. We show that rados comply with various privacy requirements that make them good candidates for machine learning in a privacy framework. We give several algebraic, geometric and computational hardness results on reconstructing examples from rados. We also show how it is possible to craft, and efficiently learn from, rados in a differential privacy framework. Tests reveal that learning from differentially private rados can compete with learning from random rados, and hence with batch learning from examples, achieving non-trivial privacy vs accuracy tradeoffs.	algorithm;backup;differential privacy;experiment;kernel method;loss functions for classification;machine learning;rademacher complexity;requirement;supervised learning;time complexity	Richard Nock;Giorgio Patrini;Arik Friedman	2015			computer science;data science;machine learning;data mining;mathematics;statistics	ML	21.411290032382848	-34.2967577791938	71772
0103f5f06eb60880a2a638fd903292b5409e99b0	perceptual learning inspired model selection method of neural networks	top down method;methode descendante;modelizacion;goodness of fit;processus gauss;bottom up method;model selection;information model;bottom up;metodo ascendente;statistical manifold;analisis estadistico;complexite calcul;top down;courbure;probabilistic approach;methode geometrique;geometrical method;methode ascendante;calcul analogique;model complexity;modelisation;complejidad computacion;statistical analysis;computational complexity;metodo descendente;enfoque probabilista;approche probabiliste;analyse statistique;curvatura;curvature;perceptual learning;gaussian process;metodo geometrico;neural network model;reseau neuronal;proceso gauss;modeling;red neuronal;neural network;analog calculus;calculo analogico	Perceptual learning is the improvement in performance on a variety of simple sensory tasks. Current neural network models mostly concerned with bottom-up processes, and do not incorporate top-down information. Model selection is the crux of learning. To obtain good model we must make balance between the goodness of fit and the complexity of the model. Inspired by perceptual learning, we studied on the model selection of neuro-manifold, use the geometrical method. We propose that the Gauss-Kronecker curvature of the statistical manifold is the natural measurement of the nonlinearity of the manifold. This approach provides a clear intuitive understanding of the model complexity.	bottom-up proteomics;model selection;neural networks;neuro-fuzzy;nonlinear system;reinforcement learning;statistical manifold;top-down and bottom-up design	Ziang Lv;Siwei Luo;Yunhui Liu;Yu Zheng	2006		10.1007/11881070_6	artificial intelligence;machine learning;top-down and bottom-up design;mathematics;artificial neural network;statistics	ML	20.259666764754453	-27.94073595921806	71837
f52b9862c4ec0ee9ddc1b269682b0a6e7649b9c2	compressive tracking combined with sample weights and adaptive learning factor				Yong Jin;Hong-ying Li;Dan-Dan Zhang;Jing Wu;Maozhen Li	2018	Concurrency and Computation: Practice and Experience	10.1002/cpe.4398	computer science;distributed computing;machine learning;adaptive learning;artificial intelligence	ML	14.71377104732019	-31.055907265409967	71921
ec75b22ea4acef02a65ffcf712d7b616f914e6be	a multilayered feed forward neural network suitable for vlsi implementation	feed forward;learning algorithm;feed forward neural network;threshold logic;circuit complexity;gradient descent;multilayer neural network;back propagation;neural network	Abstract   A potentially simplified training strategy for feed forward type neural networks is developed in view of VLSI implementation. The gradient descent back propagation technique is simplified to train stochastic type neural hardware. The proposed learning algorithm uses ADD, SUBTRACT and LOGICAL operations only. This reduces circuit complexity with an increase in speed. The forward and reverse characteristics of perceptrons are generated using random threshold logic. The proposed hardware consists of 31 perceptrons per layer working in parallel with a programmable number of layers working in sequential mode.	artificial neural network;very-large-scale integration	Himanshu S. Mazumdar	1995	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(95)91862-X	gradient descent;circuit complexity;feedforward neural network;computer science;artificial intelligence;backpropagation;machine learning;time delay neural network;feed forward;artificial neural network	EDA	14.855715556183139	-27.518836508588546	72183
059f7168bcbf07c94e7e666a2852fe52c10cc7f6	a comparative study of rnn for outlier detection in data mining	recurrent neural networks data mining neural networks databases intelligent networks helium australia testing feedforward systems multi layer neural network;neural nets;statistical databases;data mining;scalability replicator neural networks outlier detection statistical datasets data mining datasets;outlier detection;statistical databases data mining neural nets very large databases;very large databases;neural network	We have proposed replicator neural networks (RNNs) for outlier detection [8]. Here we compare RNN for outlier detection with three other methods using both publicly available statistical datasets (generally small) and data mining datasets (generally much larger and generally real data). The smaller datasets provide insights into the relative strengths and weaknesses of RNNs. The larger datasets particularly test scalability and practicality of application.	anomaly detection;artificial neural network;data mining;random neural network	Graham J. Williams;Rohan A. Baxter;Hongxing He;Simon Hawkins;Lifang Gu	2002		10.1109/ICDM.2002.1184035	computer science;data science;machine learning;data mining;artificial neural network	ML	12.586269019139802	-34.98571295223398	72249
e3cd07ad64750cb153de9fd17e8da8bdcd0481e0	modified support vector machines in financial time series forecasting	support vector machines;regularized risk function;structural risk minimization;prior knowledge;time series;support vector;structural risk minimization principle;financial time series;non stationary financial time series;support vector machine;data consistency	This paper proposes a modi ed version of support vector machines, called C-ascending support vector machine, to model non-stationary nancial time series. The C-ascending support vector machines are obtained by a simple modi cation of the regularized risk function in support vector machines, whereby the recent -insensitive errors are penalized more heavily than the distant -insensitive errors. This procedure is based on the prior knowledge that in the non-stationary nancial time series the dependency between input variables and output variable gradually changes over the time, speci cally, the recent past data could provide more important information than the distant past data. In the experiment, C-ascending support vector machines are tested using three real futures collected from the Chicago Mercantile Market. It is shown that the C-ascending support vector machines with the actually ordered sample data consistently forecast better than the standard support vector machines, with the worst performance when the reversely ordered sample data are used. Furthermore, the C-ascending support vector machines use fewer support vectors than those of the standard support vector machines, resulting in a sparser representation of solution. c © 2002 Elsevier Science B.V. All rights reserved.	converge;futures and promises;loss function;simulation;stationary process;support vector machine;time series	Francis Eng Hock Tay;Lijuan Cao	2002	Neurocomputing	10.1016/S0925-2312(01)00676-2	margin classifier;support vector machine;least squares support vector machine;computer science;machine learning;pattern recognition;data mining;mathematics;relevance vector machine	ML	22.433249220512238	-27.613622109253683	72463
8e5109f918e7280e0334408b452972b3b46914b4	a large memory storage and retrieval neural network for adaptive retrieval and diagnosis	interpolation;neural networks;retrieval;stochastic weight modulation;forgetting;extrapolation;link weights;self organizing map som;neuropsychological models;large memory;fault detection;fault tolerance;winner take all wta;neurophysiological models;knowledge lines;storage;medical diagnosis;central nervous system cns;neural network;expert system	The neural network discussed in this paper is a self trained network for LArge Memory STorage And Retrieval (LAMSTAR) of information. It employs features such as forgetting, interpolation, extrapolation and filtering, to enhance processing and memory efficiency and to allow zooming in and out of memories. The network is based on modified SOM (Self-Organizing-Map) modules and on arrays of link-weight vectors to channel information vertically and horizontally throughout the network. Direct feedback and up/down counting serve to set these link weights as a higher-hierarchy performance evaluator element which also provides high level interrupts. Pseudo random modulation of the link weights prevents dogmatic network behavior. The input word is a coded vector of several sub-words (sub-vectors). These features facilitate very rapid intelligent retrieval and diagnosis of very large memories, that have properties of a self-adaptive expert system with continuously adjustable weights. The authors have applied the network to a simple medical diagnosis and fault detection problems.	artificial neural network	Daniel Graupe;Hubert Kordylewski	1998	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194098000091	fault tolerance;interpolation;computer science;artificial intelligence;theoretical computer science;machine learning;medical diagnosis;network simulation;extrapolation;forgetting;artificial neural network;fault detection and isolation	DB	13.617466760162655	-30.454508587371322	72566
12bea381cac764185cabf45fd73c61a5824676dd	parallel asynchronous stochastic variance reduction for nonconvex optimization		Nowadays, asynchronous parallel algorithms have received much attention in the optimization field due to the crucial demands for modern large-scale optimization problems. However, most asynchronous algorithms focus on convex problems. Analysis on nonconvex problems is lacking. For the Asynchronous Stochastic Descent (ASGD) algorithm, the best result from (Lian et al. 2015) can only achieve an asymptotic O( 1 2 ) rate (convergence to the stationary points, namely, ‖∇f(x)‖2 ≤ ) on nonconvex problems. In this paper, we study Stochastic Variance Reduced Gradient (SVRG) in the asynchronous setting. We propose the Asynchronous Stochastic Variance Reduced Gradient (ASVRG) algorithm for nonconvex finite-sum problems. We develop two schemes for ASVRG, depending on whether the parameters are updated as an atom or not. We prove that both of the two schemes can achieve linear speed up(a non-asymptotic O( 2 3 ) rate to the stationary points) for nonconvex problems when the delay parameter τ ≤ n 3 , where n is the number of training samples. We also establish a non-asymptotic O( 2 3 τ 1 3 ) rate (convergence to the stationary points) for our algorithm without assumptions on τ . This further demonstrates that even with asynchronous updating, SVRG has less number of Incremental First-order Oracles (IFOs) compared with Stochastic Gradient Descent and Gradient Descent. We also conduct experiments on a shared memory multi-core system to demonstrate the efficiency of our algorithm.	convex optimization;experiment;first-order predicate;mathematical optimization;multi-core processor;parallel algorithm;shared memory;stationary process;stochastic gradient descent;variance reduction	Cong Fang;Zhouchen Lin	2017			machine learning;mathematical optimization;stochastic optimization;artificial intelligence;variance reduction;computer science;asynchronous communication	AI	24.268967359435358	-34.08963671060522	72847
3ed8bcd33b9b600a465076606e96b035c333ebb5	coordinate-free sensorimotor processing: computing with population codes	hebbian learning;architecture systeme;motion control;goal orientation;principio modelo interno;speech synthesis;learning;habla;speech;robotics;topology representing network;cortical map;aprendizaje;commande mouvement;computer architecture;control movimiento;apprentissage;population coding;cortical dynamics;principe modele interne;cortex sensorimoteur;robotica;autoorganizacion;field computing;simulation study;self organization;arquitectura sistema;internal model principle;robotique;parole;corteza sensoriomotora;reseau neuronal;system architecture;sensorimotor cortex;red neuronal;autoorganisation;population code;neural network	The purpose of the study is to outline a computational architecture for the intelligent processing of sensorimotor patterns. The focus is on the nature of the internal representations of the outside world which are necessary for planning and other goal-oriented functions. A model of cortical map dynamics and self-organization is proposed that integrates a number of concepts and methods partly explored in the field. The novelty and the biological plausibility is related to the global architecture which allows one to deal with sensorimotor patterns in a coordinate-free way, using population codes as distributed internal representations of external variables and the coupled dynamics of cortical maps as a general tool of trajectory formation. The basic computational features of the model are demonstrated in the case of articulatory speech synthesis and some of the metric properties are evaluated by means of simple simulation studies.	code;computation (action);map;plausibility structure;self-organization;simulation;speech synthesis	Pietro G. Morasso;Vittorio Sanguineti;Francesco Frisone;Luca Perico	1998	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(98)00065-3	motion control;self-organization;hebbian theory;computer science;speech;artificial intelligence;machine learning;goal orientation;robotics;neural coding;speech synthesis;artificial neural network	ML	18.798085204965503	-24.263229069878218	72894
3fe32b24e30c18a408c5d0f1889b1d5a8d81122a	optimal training parameters in multilayer feedforward networks	minimisation;metaparameter configurations;dynamic programming;local fuzzy inference optimal training parameters multilayer feedforward networks exhaustive search method optimal parameter sets training cycles finite state network metaparameter configurations error criteria network training iterations metaparameter adaptation strategies rprop;feedforward neural networks;learning rate;training cycles;neural networks;rprop;transfer functions;network training iterations;multilayer feedforward networks;search space;optimal parameter sets;multilayer perceptrons;search methods;multilayer feedforward neural network;finite state network;metaparameter adaptation strategies;dynamic program;local fuzzy inference;minimization methods;backpropagation;multi layer neural network;nonhomogeneous media;error criteria;fuzzy inference;intelligent networks nonhomogeneous media multi layer neural network neural networks feedforward neural networks dynamic programming search methods minimization methods transfer functions backpropagation;feedforward neural nets;exhaustive search method;intelligent networks;learning artificial intelligence;learning artificial intelligence feedforward neural nets dynamic programming minimisation multilayer perceptrons;optimal training parameters;exhaustive search	We present a systematic investigation of the training behavior for multilayer feedforward neural networks. Usually learning is governed by three metaparameters, which are learning rate, momentum and offset. We apply a (nearly) exhaustive search method to find optimal parameter sets throughout the complete sequence of training cycles, regarding the training process as a finite state network in the space of metaparameter configurations. Minimization of training time is achieved by methods of dynamic programming. A detailed analysis is given for the choice of error criteria and necessary widths and prunings of network 'beams' in search space. It is shown for a representative set of training patterns, that the number of network training iterations is largely independent of both, the metaparameter initialization and the random weight initialization. Training is twice as fast as with conventional metaparameter adaptation strategies, such as RPROP or local fuzzy inference.		Andreas Wendemuth;Michael Gerke	1999		10.1109/IJCNN.1999.832667	rprop;minimisation;mathematical optimization;intelligent network;computer science;artificial intelligence;backpropagation;machine learning;dynamic programming;brute-force search;transfer function;artificial neural network	Vision	16.944469550447753	-29.071647421406517	73055
f78fa32fe2474bb3ba1016c12fa66489314ec0b0	learning beam search policies via imitation learning		Beam search is widely used for approximate decoding in structured prediction problems. Models often use a beam at test time but ignore its existence at train time, and therefore do not explicitly learn how to use the beam. We develop an unifying meta-algorithm for learning beam search policies using imitation learning. In our setting, the beam is part of the model, and not just an artifact of approximate decoding. Our meta-algorithm captures existing learning algorithms and suggests new ones. It also lets us show novel no-regret guarantees for learning beam search policies.	approximation algorithm;beam search;loss function;machine learning;metaheuristic;regret (decision theory);scoring functions for docking;structured prediction	Renato Negrinho;Matthew R. Gormley;Geoffrey J. Gordon	2018			machine learning;computer science;artificial intelligence;beam (structure);decoding methods;imitation;beam search;structured prediction	ML	22.494963816089864	-30.77577997840661	73073
bad9aeedc429862238cdf898430d08dcfb69eb2e	supervised and unsupervised co-training of adaptive activation functions in neural nets	partially unsupervised learning;co training;adaptive activation function	"""In spite of the nice theoretical properties of mixtures of lo- gistic activation functions, standard feedforward neural network with limited resources and gradient-descent optimization of the connection weights may practically fail in several, difficult learning tasks. Such tasks would be better faced by relying on a more appropriate, problem-specific basis of activation functions. The paper introduces a connectionist model which features adaptive activation functions. Each hidden unit in the net- work is associated with a specific pair (f (·),p(·)), where f (·) (the very activation) is modeled via a specialized neural network, and p(· )i s a probabilistic measure of the likelihood of the unit itself being relevant to the computation of the output over the current input. While f (·) is optimized in a supervised manner (through a novel backpropagation scheme of the target outputs which do not suffer from the traditional phenomenon of """"vanishing gradient"""" that occurs in standard backpropa- gation), p(·) is realized via a statistical parametric model learned through unsupervised estimation. The overall machine is implicitly a co-trained coupled model, where the topology chosen for learning each f (· )m ay vary on a unit-by-unit basis, resulting in a highly non-standard neural architecture."""	artificial neural network;co-training;neural oscillation;supervised learning	Ilaria Castelli;Edmondo Trentin	2011		10.1007/978-3-642-28258-4_6	computer science;artificial intelligence;machine learning;pattern recognition	ML	18.169017482020976	-31.296677272061793	73156
1ffcfd504b5b75f690cc39534057b3526865973a	a unified approach to minimum risk training and decoding	gibbs sampler;minimum bayes risk	We present a unified approach to performing minimum risk training and minimum Bayes risk (MBR) decoding with BLEU in a phrase-based model. Key to our approach is the use of a Gibbs sampler that allows us to explore the entire probability distribution and maintain a strict probabilistic formulation across the pipeline. We also describe a new sampling algorithm called corpus sampling which allows us at training time to use BLEU instead of an approximation thereof. Our approach is theoretically sound and gives better (up to +0.6%BLEU) and more stable results than the standard MERT optimization algorithm. By comparing our approach to lattice MBR, we are also able to gain crucial insights about both methods.	algorithm;approximation;bleu;dynamic programming;estimation theory;gibbs sampling;gradient;mathematical optimization;multi-environment real-time;sampling (signal processing);stable model semantics;standard translation	Abhishek Arun;Barry Haddow;Philipp Koehn	2010			machine learning;data mining;mathematics;statistics	ML	23.81065394496308	-32.315670558338645	73267
5b4f0400d7db38f0b196a151e6cf30c2a3ff6172	improved estimates for the accuracy of small disjuncts	satisfiability;learning system;estimation;prediction accuracy;empirical learning;error rate;disjunctive concepts	Learning systems often describe a target class as a disjunction of conjunctions of conditions. Recent work has noted that small disjuncts, i.e., those supported by few training examples, typically have poor predictive accuracy. One model of this accuracy is provided by the Bayes-Laplace formula based on the number of training examples covered by the disjunct and the number of them belonging to the target class. However, experiments show that small disjuncts associated with target classes of different relative frequencies tend to have different error rates. This note defines the context of a disjunct as the set of training examples that fail to satisfy at most one of its conditions. An empirical adaptation of the Bayes-Laplace formula is presented that also makes use of the relative frequency of the target class in this context. Trials are reported comparing the performance of the original formula and the adaptation in six learning tasks.	experiment	J. Ross Quinlan	1991	Machine Learning	10.1023/A:1022646118217	estimation;word error rate;computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics;satisfiability	ML	16.352218989921948	-36.67520085389369	73717
26f37f9dc29c9001ae80104d552cd9a680d64193	learning in high dimensions with projected linear discriminants	qa75 electronic computers computer science	The enormous power of modern computers has made possible the statistical modelling of data with dimensionality that would have made this task inconceivable only decades ago. However, experience in such modelling has made researchers aware of many issues associated with working in high-dimensional domains, collectively known as ‘the curse of dimensionality’, which can confound practitioners’ desires to build good models of the world from these data. When the dimensionality is very large, low-dimensional methods and geometric intuition both break down in these high-dimensional spaces. To mitigate the dimensionality curse we can use low-dimensional representations of the original data that capture most of the information it contained. However, little is currently known about the effect of such dimensionality reduction on classifier performance. In this thesis we develop theory quantifying the effect of random projection – a recent, very promising, non-adaptive dimensionality reduction technique – on the classification performance of Fisher’s Linear Discriminant (FLD), a successful and widely-used linear classifier. We tackle the issues associated with small sample size and high-dimensionality by using randomly projected FLD ensembles, and we develop theory explaining why our new approach performs well. Finally, we quantify the generalization error of Kernel FLD, a related non-linear projected classifier.	computer;curse of dimensionality;dimensionality reduction;generalization error;linear classifier;linear discriminant analysis;nonlinear system;random projection;randomness;statistical model	Robert J. Durrant	2013			computer science;artificial intelligence;machine learning;data mining	ML	18.052550727046786	-33.55188361910593	73721
1edf0119be0605189012b1ee370934e3b488de72	using probabilistic programs as proposals		Monte Carlo inference has asymptotic guarantees, but can be slow when using generic proposals. Handcrafted proposals that rely on user knowledge about the posterior distribution can be efficient, but are difficult to derive and implement. This paper proposes to let users express their posterior knowledge in the form of proposal programs, which are samplers written in probabilistic programming languages. One strategy for writing good proposal programs is to combine domain-specific heuristic algorithms with neural network models. The heuristics identify high probability regions, and the neural networks model the posterior uncertainty around the outputs of the algorithm. Proposal programs can be used as proposal distributions in importance sampling and Metropolis-Hastings samplers without sacrificing asymptotic consistency, and can be optimized offline using inference compilation. Support for optimizing and using proposal programs is easily implemented in a sampling-based probabilistic programming runtime. The paper illustrates the proposed technique with a proposal program that combines RANSAC and neural networks to accelerate inference in a Bayesian linear regression with outliers model.		Marco F. Cusumano-Towner;Vikash K. Mansinghka	2018	CoRR		computer science;machine learning;importance sampling;artificial intelligence;ransac;monte carlo method;artificial neural network;bayesian linear regression;probabilistic logic;inference;heuristics	ML	23.732705241715557	-28.070152668040425	73899
44bc52d51476348aa0e4913063376be0db21e5f0	slit: designing complexity penalty for classification and regression trees using the srm principle	minimisation;cuantificacion senal;classification and regression tree;minimization;model selection;decision tree;functional form;structural risk minimization;prise de decision;minimizacion;intelligence artificielle;aprendizaje probabilidades;arbol decision;classification;statistical learning;analisis regresion;signal quantization;statistical learning theory;quantification signal;analyse regression;apprentissage probabilites;artificial intelligence;regression analysis;inteligencia artificial;reseau neuronal;toma decision;arbre decision;clasificacion;red neuronal;probability learning;neural network	The statistical learning theory has formulated the Structural Risk Minimization (SRM) principle, based upon the functional form of risk bound on the generalization performance of a learning machine. This paper addresses the application of this formula, which is equivalent to a complexity penalty, to model selection tasks for decision trees, whereas the quantization of the machine capacity for decision trees is estimated using an empirical approach. Experimental results show that, for either classification or regression problems, this novel strategy of decision tree pruning performs better than alternative methods. We name classification and regression trees pruned by virtue of this methodology as Statistical Learning Intelligent Trees (SLIT).		Zhuo Yang;Wenjie Zhu;Liang Ji	2006		10.1007/11759966_131	minimisation;structural risk minimization;biological classification;computer science;artificial intelligence;machine learning;decision tree;pattern recognition;mathematics;higher-order function;artificial neural network;model selection;regression analysis	ML	10.175342564862824	-32.17288925979422	73974
215837db3372c017dcf423c57447d0037529fb53	dynamics of learning near singularities in layered networks	medida informacion;numerical stability;nudo estructura;calcul neuronal;neural computation;nodes;singularite;multilayer;comportement;champ vectoriel;stabilite dynamique;dynamique;learning;estabilidad numerica;mesure information;multilayer perceptrons;fonction base radiale;estabilidad dinamica;matrice information;couche multimoleculaire;informacion fisher;multilayer perceptron;dynamic stability;fisher information matrix;espace parametre;dinamica;permutation;aprendizaje;perceptron multicouche;campo vectorial;apprentissage;red multinivel;radial basis function;degeneration;conducta;radial basis function network;information measure;gradient descent;dynamics;permutacion;espacio par metro;stability analysis;parameter space;capa multimolecular;singularidad;modele hierarchique;noeud structure;stabilite numerique;multilayer network;information matrix;reseau multicouche;reseau neuronal;behavior;vector field;funcion radial base;information fisher;red neuronal;computacion neuronal;62b10;geometric structure;hierarchical model;fisher information;neural network;singularity	We explicitly analyze the trajectories of learning near singularities in hierarchical networks, such as multilayer perceptrons and radial basis function networks, which include permutation symmetry of hidden nodes, and show their general properties. Such symmetry induces singularities in their parameter space, where the Fisher information matrix degenerates and odd learning behaviors, especially the existence of plateaus in gradient descent learning, arise due to the geometric structure of singularity. We plot dynamic vector fields to demonstrate the universal trajectories of learning near singularities. The singularity induces two types of plateaus, the on-singularity plateau and the near-singularity plateau, depending on the stability of the singularity and the initial parameters of learning. The results presented in this letter are universally applicable to a wide class of hierarchical models. Detailed stability analysis of the dynamics of learning in radial basis function networks and multilayer perceptrons will be presented in separate work.	abnormal degeneration;activation function;approximation;backpropagation;bayesian network;behavior;black hole;borg scale rating of perceived exertion score 17;converge;convergence (action);dynamical system;excretory function;fisher information;formation matrix;gradient descent;gradient method;information geometry;jacobian matrix and determinant;maxima and minima;multilayer perceptron;plateau's problem;population parameter;radial (radio);radial basis function network;relevance;singularity project;the singularity;tree network;unified framework;anatomical layer	Haikun Wei;Jun Zhang;Florent Cousseau;Tomoko Ozeki;Shun-ichi Amari	2008	Neural Computation	10.1162/neco.2007.12-06-414	computer science;artificial intelligence;fisher information;machine learning;calculus;mathematics;geometry;artificial neural network;statistics	ML	19.440982068443482	-27.651530402146243	74010
baaeec7eca58e03e4158cf428cfa3f94fd791d2b	a neural network for signal decomposition problems	hopfield model;complexite;modele hopfield;concepcion circuito;interconnection;aplicacion;convertisseur an;ad converter;metodo descomposicion;circuit design;complejidad;methode decomposition;complexity;decomposition method;interconnexion;conception circuit;senal;signal;reseau neuronal;application;red neuronal;interconeccion;neural network;convertidor an	Abstract#R##N##R##N#This paper presents the design of a neural network for signal decomposition problems with application examples. For this class of problems the proposed network has the same dynamics as the Hopfield net, but it is shown to realize the O(M2) connection paths among the M neurons with a number of wires and conductances increasing only linearly with increasing M, i.e. reducing this number by one dimension with respect to the quadratically increasing number of wires and conductances required in the Hopfield net.#R##N##R##N##R##N##R##N#Other advantages of the proposed neural network are discussed in relation to classical examples of decomposition problems. In particular, a new architecture for an N-bit A/D converter is presented employing 4N conductances instead of the N(N + 1) Hopfield A/D conductances.	artificial neural network	Mauro Forti	1991	I. J. Circuit Theory and Applications	10.1002/cta.4490190108	complexity;decomposition method;computer science;electrical engineering;artificial intelligence;interconnection;machine learning;circuit design;mathematics;hopfield network;artificial neural network;algorithm;signal	Theory	15.81510263007509	-26.74027941952444	74023
bc743aedfd86d904b3b3ce3caf5ab4715c9b3a1d	rough neural networks for complex concepts	feedforward neural network;magnetic resonance image;rough neurons;multi dimensional;multi dimensional neurons;complex concepts;neural network	Rough neural networks aim at hierarchical construction of compound concepts. Although the structure of such concepts is assumed to be more complicated than numbers in case of standard feedforward neural networks, some mechanisms can be generalized to achieve efficient propagation and learning. One of possible generalizations, called the normalizing neural networks, enables to propagate vectors instead of single signals. Neurons take form of multidimensional functions, which model cross-dependencies among importance of particular vector components. In this way, we are able to represent some types of compound concepts using relatively simple neural network structure. As an illustration, we consider the case study related to the task of magnetic resonance images' segmentation. We put a special emphasis on how the nature of objects and attributes in a given decision system influences the network's architecture. We also compare our model to other rough-neural approaches.	artificial neural network;neural network software	Dominik Slezak;Marcin S. Szczuka	2007		10.1007/978-3-540-72530-5_69	stochastic neural network;nervous system network models;feedforward neural network;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;magnetic resonance imaging;machine learning;time delay neural network;deep learning;artificial neural network;algorithm	ML	14.536257106567666	-27.429809504300433	74084
7bece1af6952073894b8fe0fab99573ecb6934dd	silicon implementation of a fuzzy neuron	silicon;fabrication;concepcion circuito;fuzzy neural nets;handwriting recognition;fabricacion;learning;bicmos chip;implementation;circuit design;logique floue;circuit vlsi;fn305 fuzzy neuron chip;inner product;logica difusa;bicmos integrated circuits;design optimization;fuzzy sets;chip;fuzzy logic;ejecucion;neural chips;vlsi circuit;reconnaissance caractere;silicon wafer;fuzzy logic fuzzy neural nets neural chips bicmos integrated circuits mixed analogue digital integrated circuits character recognition;semiconductor device modeling;manufacturing;mixed analogue digital integrated circuits;excitatory connection;conception circuit;handwritten character recognition fn305 fuzzy neuron chip neuron model fuzzy logic fuzzy inner product excitatory connection learning bicmos chip;neurons;silicon neurons fuzzy logic fuzzy systems semiconductor device modeling character recognition design optimization bicmos integrated circuits handwriting recognition fuzzy sets;circuito vlsi;reseau neuronal;silicium;character recognition;high speed;red neuronal;fuzzy systems;silicio;handwritten character recognition;fuzzy inner product;reconocimiento caracter;neuron model;neural network	This paper describes a fuzzy neuron chip which is the modification of an ordinary neuron model by fuzzy logic. The algebraic product of scaler input and connective weights in synapse is replaced by a fuzzy inner product. An excitatory connection is represented by a MIN (minimum) operation and an inhibitory connection by fuzzy logic complement followed by a MIN operation. While an ordinary neuron model is established only by leaning, the fuzzy neuron can be designed and optimized by learning. The fuzzy neuron is implemented in silicon wafer by a standard BiCMOS process. The chip is applied to a handwritten character recognition system and it exhibits very high-speed recognition (less than 500 ns).	neuron	Takeshi Yamakawa	1996	IEEE Trans. Fuzzy Systems	10.1109/91.544307	fuzzy logic;chip;semiconductor device modeling;multidisciplinary design optimization;dot product;computer science;artificial intelligence;biological neuron model;machine learning;circuit design;handwriting recognition;fuzzy set;fuzzy associative matrix;manufacturing;silicon;fabrication;implementation;fuzzy control system;wafer	Embedded	15.879456743078286	-26.919711681479313	74118
356f669e595be11bc0e7648e8d3f57a06dd37f9e	a delay damage model selection algorithm for narx neural networks	recurrent neuronal network;prediccion;memoire;inference grammaticale;model selection;tapped delay line;modelo autorregresivo;systeme discret;laser;tache solaire;neural networks predictive models recurrent neural networks computer architecture national electric code memory architecture neurons computer networks system identification nonlinear systems;inference mechanisms;automaton;time series;indexing terms;inference mechanisms recurrent neural nets delays autoregressive processes identification time series prediction theory nonlinear systems;autoregressive model;inferencia gramatical;automata;nonlinear systems;prediction theory;recurrent network;memoria;mancha solar;system identification;autoregressive processes;gradient descent;sunspot;automate;identification;retard;serie temporelle;systeme non lineaire;serie temporal;grammatical inference;reseau neuronal recurrent;technical report;recurrent neural nets;recurrent neural network;neural network model;sistema discreto;nonlinear system;sistema no lineal;grammatical inference delay damage model selection algorithm narx neural networks recurrent neural networks system identification time series prediction nonlinear autoregressive models with exogenous inputs embedded memory intelligent memory order selection pruning initial heuristics generalization predictive performance nonlinear systems;modele autoregressif;retraso;prediction;non linear system;time series prediction;memory;discrete system;delays;neural network;order selection	Recurrent neural networks have become popular models for system identification and time series prediction. Nonlinear autoregressive models with exogenous inputs (NARX) neural network models are a popular subclass of recurrent networks and have been used in many applications. Although embedded memory can be found in all recurrent network models, it is particularly prominent in NARX models. We show that using intelligent memory order selection through pruning and good initial heuristics significantly improves the generalization and predictive performance of these nonlinear systems on problems as diverse as grammatical inference and time series prediction.	artificial neural network;autoregressive model;embedded system;grammar induction;heuristic (computer science);model selection;nonlinear autoregressive exogenous model;nonlinear system;recurrent neural network;selection algorithm;system identification;time series	Tsungnan Lin;C. Lee Giles;Bill G. Horne;Sun-Yuan Kung	1997	IEEE Trans. Signal Processing	10.1109/78.650098	nonlinear system;computer science;artificial intelligence;machine learning;time series;mathematics;automaton;algorithm;statistics	ML	17.09565435632628	-26.46378258721869	74165
5da3611582018eb3cf13f9760095682bf1affd03	blind equalization with a linear feedforward neural network	feedforward neural network;blind equalization		artificial neural network;blind equalization;feedforward neural network	Xi-Ren Cao;Jiang Zhu;J. Si	1997			artificial intelligence;machine learning;feedforward neural network;time delay neural network;pattern recognition;blind equalization;computer science	ML	13.1129796804396	-27.241219028113274	74314
02fdc2743f6c5ddddc39af8d3af1f04e301e17ef	neural networks with few multiplications		For most deep learning algorithms training is notoriously time consuming. Since most of the computation in training neural networks is typically spent on floating point multiplications, we investigate an approach to training that eliminates the need for most of these. Our method consists of two parts: First we stochastically binarize weights to convert multiplications involved in computing hidden states to sign changes. Second, while back-propagating error derivatives, in addition to binarizing the weights, we quantize the representations at each layer to convert the remaining multiplications into binary shifts. Experimental results across 3 popular datasets (MNIST, CIFAR10, SVHN) show that this approach not only does not hurt classification performance but can result in even better performance than standard stochastic gradient descent training, paving the way to fast, hardwarefriendly training of neural networks.	algorithm;artificial neural network;computation;deep learning;feedforward neural network;field-programmable gate array;generalization error;mnist database;machine learning;mathematical optimization;maxima and minima;overfitting;quantization (signal processing);recurrent neural network;sampling (signal processing);stochastic gradient descent	Zhouhan Lin;Matthieu Courbariaux;Roland Memisevic;Yoshua Bengio	2015	CoRR		computer science;artificial intelligence;theoretical computer science;machine learning	ML	18.03632938545666	-32.11499098308084	74389
cff0bb10ae6936c679ca880796631bbd3356ab3c	coupling weight elimination with genetic algorithms to reduce network size and preserve generalization	neural networks;pruning;genetic algorithm;genetic algorithms;weight elimination;fitness function;neural network	Recent theoretical results support that decreasing the number of free parameters in a neural network (i.e., weights) can improve generalization. These results have triggered the development of many approaches which try to determine an “appropriate” network size for a given problem. The main goal has been to find a network size just large enough to capture the general class properties of the data. In some cases, however, network size is not reduced significantly or the reduction is satisfactory but generalization is affected. In this paper, we propose the coupling of genetic algorithms with weight elimination. Our objective is not only to significantly reduce network size, by pruning larger size networks, but also to preserve generalization, that is, to come up with pruned networks which generalize as good or even better than their unpruned counterparts. The innovation of our work relies on a fitness function which uses an adaptive parameter to encourage reproduction of networks having small size and good generalization. The proposed approach has been tested using both artificial and real databases demonstrating good performance.	artificial neural network;database;experiment;fitness function;genetic algorithm;harris affine region detector;semantic network	George Bebis;Michael Georgiopoulos;Takis Kasparis	1997	Neurocomputing	10.1016/S0925-2312(97)00050-7	mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;artificial neural network	ML	14.170277138143947	-33.38226315116828	74493
066b8d7f06dcfd7d50bb77387cefb7b2e51ec97d	a theory of probabilistic boosting, decision trees and matryoshki	decision tree;science learning;theoretical analysis;error bound	We present a theory of boosting probabilistic classifiers. W e place ourselves in the situation of a user who only provides a stopping parame ter and a probabilistic weak learner/classifier and compare three types o f bo sting algorithms: probabilistic Adaboost, decision tree, and tree of trees of ... of trees, which we call matryoshka. “Nested tree,” “embedded tree” and “recursive tree” are al so ppropriate names for this algorithm, which is one of our contr ibu ions. Our other contribution is the theoretical analysis of the algorithms , in which we give training error bounds. This analysis suggests that the matryoshka le verages probabilistic weak classifiers more efficiently than simple decision trees .	adaboost;algorithm;boosting (machine learning);call of duty: black ops;decision tree;embedded system;probabilistic turing machine;recursion;sting;theory	Etienne Grossmann	2006	CoRR		probabilistic classification;probabilistic ctl;decision tree learning;computer science;machine learning;decision tree;pattern recognition;alternating decision tree;incremental decision tree;data mining;k-ary tree;mathematics;tree structure;tree traversal;decision stump	ML	12.652451548421368	-33.35012835646391	74552
56aa87c046490269ae6f990907d1d1fee5a53390	support vector machines for pattern classification	support vector machines;two-class svms;pattern classification;multiple kernel learning;sparse svms;active-set training method;explores incremental training;batch training;linear programming svms;discusses kernel method;semi-supervised learning;support vector regressors;pattern recognition;artificial intelligent;robot control;support vector machine	Support vector machines (SVMs), were originally formulated for two-class classification problems, and have been accepted as a powerful tool for developing pattern classification and function approximations systems. This...	approximation;statistical classification;support vector machine	Shigeo Abe	2005		10.1007/1-84628-219-5	random subspace method;margin classifier;machine learning;pattern recognition;data mining	ML	21.267382356126102	-37.81283883967936	75114
81a615cf5d999dd69f4ad99c94c19445addce9f0	value of information lattice: exploiting probabilistic independence for effective feature subset acquisition	expected misclassification cost;eficient feature subset acquisition;voila eficiently;misclassification cost;probabilistic independence;multiple feature;features greedily;cost-sensitive feature acquisition problem;missing feature;effective feature subset acquisition;information lattice;possible feature subsets;feature acquisition cost	We address the cost-sensitive feature acquisition problem, where misclassifying an instance is costly but the expected misclassification cost can be reduced by acquiring the values of the missing features. Because acquiring the features is costly as well, the objective is to acquire the right set of features so that the sum of the feature acquisition cost and misclassification cost is minimized. We describe the Value of Information Lattice (VOILA), an optimal and efficient feature subset acquisition framework. Unlike the common practice, which is to acquire features greedily, VOILA can reason with subsets of features. VOILA efficiently searches the space of possible feature subsets by discovering and exploiting conditional independence properties between the features and it reuses probabilistic inference computations to further speed up the process. Through empirical evaluation on five medical datasets, we show that the greedy strategy is often reluctant to acquire features, as it cannot forecast the benefit of acquiring multiple features in combination.	computation;conditional entropy;data structure;experiment;greedy algorithm	Mustafa Bilgic;Lise Getoor	2011	J. Artif. Intell. Res.	10.1613/jair.3200	machine learning;pattern recognition;data mining;mathematics	AI	15.260971473588844	-36.78782013274933	75130
91b357b035bde343e11b0504d6fc8e20925f63d3	non-functional regression: a new challenge for neural networks		Abstract This work identifies an important, previously unaddressed issue for regression based on neural networks – learning to accurately approximate problems where the output is not a function of the input (i.e. where the number of outputs required varies across input space). Such non-functional regression problems arise in a number of applications, and can not be adequately handled by existing neural network algorithms. To demonstrate the benefits possible from directly addressing non-functional regression, this paper proposes the first neural algorithm to do so – an extension of the Resource Allocating Network (RAN) which adds additional output neurons to the network structure during training. This new algorithm, called the Resource Allocating Network with Varying Output Cardinality (RANVOC), is demonstrated to be capable of learning to perform non-functional regression, on both artificially constructed data and also on the real-world task of specifying parameter settings for a plasma-spray process. Importantly RANVOC is shown to outperform not just the original RAN algorithm, but also the best possible error rates achievable by any functional form of regression.	artificial neural network	Peter Vamplew;Richard Dazeley;Cameron Foale;Tanveer Choudhury	2018	Neurocomputing	10.1016/j.neucom.2018.06.066	mathematics;artificial intelligence;cardinality;machine learning;pattern recognition;artificial neural network;functional regression;function approximation	ML	17.848308501763302	-31.484645308946842	75242
21ef015713a15db602f081a2a342c1a891490dcd	geometry and learning curves of kernel methods with polynomial kernels	support vector machine;kernel method;generalization error;learning curve	The properties of learning machines with polynomial kernel classifiers, such as support vector machines or kernel perceptrons, are examined. We first derive the number of effective examples which are related to generalization error. Next, we analyze the average prediction errors of several algorithms and show these errors do not depend on the apparent dimension of the feature space. This means that what is called the overfitting phenomena do not appear in kernel methods with polynomial kernels. © 2004 Wiley Periodicals, Inc. Syst Comp Jpn, 35(7): 41–48, 2004; Published online in Wiley InterScience (). DOI 10.1002&sol;scj.10629	kernel method;polynomial	Kazushi Ikeda	2004	Systems and Computers in Japan	10.1002/scj.10629	kernel;support vector machine;least squares support vector machine;kernel method;string kernel;kernel embedding of distributions;radial basis function kernel;kernel principal component analysis;computer science;machine learning;pattern recognition;graph kernel;mathematics;tree kernel;learning curve;variable kernel density estimation;polynomial kernel;statistics;kernel smoother;generalization error	ML	20.449400202461014	-34.342186787896004	75503
fbe9936fe40e129265f888e1fede2650fbfee372	nonlinear distributional gradient temporal-difference learning		We devise a distributional variant of gradient temporal-difference (TD) learning. Distributional reinforcement learning has been demonstrated to outperform the regular one in the recent study citep{bellemare2017distributional}. In the policy evaluation setting, we design two new algorithms called distributional GTD2 and distributional TDC using the Cram{u0027e}r distance on the distributional version of the Bellman error objective function, which inherits advantages of both the nonlinear gradient TD algorithms and the distributional RL approach. In the control setting, we propose the distributional Greedy-GQ using the similar derivation. We prove the asymptotic almost-sure convergence of distributional GTD2 and TDC to a local optimal solution for general smooth function approximators, which includes neural networks that have been widely used in recent study to solve the real-life RL problems. In each step, the computational complexities of above three algorithms are linear w.r.t. the number of the parameters of the function approximator, thus can be implemented efficiently for neural networks.	algorithm;artificial neural network;computational complexity theory;gradient;loss function;nonlinear system;optimization problem;real life;reinforcement learning;temporal difference learning	Chao Qu;Shie Mannor;Huan Xu	2018	CoRR		mathematical optimization;smoothness;artificial neural network;reinforcement learning;nonlinear system;temporal difference learning;computer science;convergence (routing)	ML	23.287714976113914	-32.79369582821546	75530
488fa151b863b4c5526b335d0a1dd1d5776d8a99	dyslexic behaviour of feedforward neural networks	feedforward neural network	A model is proposed in which the synaptic efficacies of a feedforward neural network are adapted with a cost function that vanishes if the boolean function that is represented has the same symmetry properties as the target one. The function chosen according to this procedure is thus taken as an archetype of the whole symmetry class. Several examples are presented showing how this type of partial learning can produce a behaviour of the net that is reminiscent of that of dyslexic persons.	feedforward neural network;neural networks	Edgardo A. Ferrán;Roberto P. J. Perazzo	1990	Int. J. Neural Syst.	10.1142/S0129065790000138	feedforward neural network;computer science;artificial intelligence;machine learning	ML	17.960568351942705	-26.72366285349102	75681
cdfd24ba6166ad14c8680b7d2cade0a313c94792	adversarial time-to-event modeling		Modern health data science applications leverage abundant molecular and electronic health data, providing opportunities for machine learning to build statistical models to support clinical practice. Time-to-event analysis, also called survival analysis, stands as one of the most representative examples of such statistical models. We present a deep-network-based approach that leverages adversarial learning to address a key challenge in modern time-to-event modeling: nonparametric estimation of event-time distributions. We also introduce a principled cost function to exploit information from censored events (events that occur subsequent to the observation window). Unlike most time-to-event models, we focus on the estimation of time-to-event distributions, rather than time ordering. We validate our model on both benchmark and real datasets, demonstrating that the proposed formulation yields significant performance gains relative to a parametric alternative, which we also propose.	artificial neural network;automatic frequency control;baseline (configuration management);benchmark (computing);censoring (statistics);data science;deep learning;entity–relationship model;event (computing);experiment;ibm notes;learning to rank;loss function;machine learning;statistical model	Paidamoyo Chapfuwa;Chenyang Tao;Chunyuan Li;Courtney Page;Benjamin Goldstein;Lawrence Carin;Ricardo Henao	2018			adversarial system;leverage (finance);machine learning;artificial intelligence;clinical practice;survival analysis;parametric statistics;pattern recognition;nonparametric statistics;computer science;exploit;statistical model	ML	23.592847747995602	-29.840553075886078	75802
411ff20f1cb0628b5934cedffed1f683f55da0bd	temperature analysis of coherent anti-stokes raman spectra using a neural network approach	temperatura vibracional;diffusion raman antistokes coherente;analisis datos;temperature vibrationnelle;coherent antistokes raman scattering;algorithme;algorithm;data analysis;cluster analysis;least square;analyse donnee;temperature measurement;classification automatique;reseau neuronal;difusion raman antistokes coherente;clustered data;red neuronal;raman spectra;vibrational temperature;neural network;nitrogen;algoritmo	A neural network trained with clustered data has been applied to the extraction of temperature from vibrational Coherent Anti-Stokes Raman (CARS) spectra of nitrogen. CARS is a non-intrusive thermometry technique applied in practical combustors in industry. The advantages of clustering of training data over training with unprocessed calculated spectra is described. The method is applied to CARS data from an isothermal furnace and a liquid kerosene fuelled aeroengine combustor sector rig. Resulting temperatures have been compared with values extracted from the data using conventional least squares fitting and, where possible, mean temperatures measured by pyrometer and blackbody cavity probe. The main advantage of the neural network method is speed, with the potential for online temperature extraction at the spectral acquisition rate of 10 Hz using standard PC hardware.	artificial neural network;cluster analysis;coherent;least squares;navier–stokes equations;raman scattering	H. J. L. van der Steen;John D. Black	1997	Neural Computing & Applications	10.1007/BF01424230	raman spectroscopy;telecommunications;temperature measurement;computer science;machine learning;nitrogen;cluster analysis;data analysis;least squares;artificial neural network	ML	11.73587781915483	-30.29800162179543	75883
f5c6de95c0e954da4f3daa48549b6e928037d95f	asymptotic performances of a constructive algorithm	learning algorithm;network performance;large data sets	We present a numerical study of a neural tree learning algorithm, the “triolearning≓ strategy. We study the behaviour of the algorithm as a function of the size of the training set. The results show that a limited number of examples can be used to estimate both the network performance and the network complexity that would result from running the algorithm on a large data set.	algorithm;network performance;numerical analysis;test set	Florence d'Alché-Buc;Jean-Pierre Nadal	1995	Neural Processing Letters	10.1007/BF02312347	mathematical optimization;suurballe's algorithm;wake-sleep algorithm;weighted majority algorithm;computer science;theoretical computer science;machine learning;brooks–iyengar algorithm;mathematics;fsa-red algorithm;stability;network performance;dinic's algorithm;id3 algorithm;nondeterministic algorithm;difference-map algorithm;output-sensitive algorithm;population-based incremental learning	ML	15.323991977033392	-31.108268311410736	75891
3f76a8ddee313b5e203605f817d68691e4f171ff	alternating multi-bit quantization for recurrent neural networks		Recurrent neural networks have achieved excellent performance in many applications. However, on portable devices with limited resources, the models are often too large to deploy. For applications on the server with large scale concurrent requests, the latency during inference can also be very critical for costly computing resources. In this work, we address these problems by quantizing the network, both weights and activations, into multiple binary codes {−1,+1}. We formulate the quantization as an optimization problem. Under the key observation that once the quantization coefficients are fixed the binary codes can be derived efficiently by binary search tree, alternating minimization is then applied. We test the quantization for two well-known RNNs, i.e., long short term memory (LSTM) and gated recurrent unit (GRU), on the language models. Compared with the full-precision counter part, by 2-bit quantization we can achieve ∼16× memory saving and ∼6× real inference acceleration on CPUs, with only a reasonable loss in the accuracy. By 3-bit quantization, we can achieve almost no loss in the accuracy or even surpass the original model, with ∼10.5× memory saving and ∼3× real inference acceleration. Both results beat the exiting quantization works with large margins. We extend our alternating quantization to image classification tasks. In both RNNs and feedforward neural networks, the method also achieves excellent performance.	artificial neural network;binary code;central processing unit;coefficient;color depth;computer vision;feedforward neural network;language model;long short-term memory;mathematical optimization;mobile device;neural networks;optimization problem;quantization (signal processing);recurrent neural network;search tree;server (computing)	Chen Xu;Jianqiang Yao;Zhouchen Lin;Wenwu Ou;Yuanbin Cao;Zhirong Wang;Hongbin Zha	2018	CoRR		artificial intelligence;binary search tree;machine learning;latency (engineering);computer science;feedforward neural network;quantization (signal processing);recurrent neural network;inference;language model;optimization problem	ML	18.147770864350562	-32.505342381602055	75914
0e630df014578a63f2f1c92b74fd9a4ea7b88280	on the convergence of bound optimization algorithms	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;ucl research	Many practitioners who use EM and related algorithms complain that they are sometimes slow. When does this happen, and what can be done about it? In this paper, we study the general class of bound optimization algorithms – including EM, Iterative Scaling, Non-negative Matrix Factorization, CCCP – and their relationship to direct optimization algorithms such as gradientbased methods for parameter learning. We derive a general relationship between the updates performed by bound optimization methods and those of gradient and second-order methods and identify analytic conditions under which bound optimization algorithms exhibit quasi-Newton behavior, and conditions under which they possess poor, first-order convergence. Based on this analysis, we consider several specific algorithms, interpret and analyze their convergence properties and provide some recipes for preprocessing input to these algorithms to yield faster convergence behavior. We report empirical results supporting our analysis and showing that simple data preprocessing can result in dramatically improved performance of bound optimizers in practice. 1 Bound Optimization Algorithms Many problems in machine learning and pattern recognition ultimately reduce to the optimization of a scalar valued function L(Θ) of a free parameter vector Θ. For example, in supervised and unsupervised probabilistic modeling the objective function may be the (conditional) data likelihood or the posterior over parameters. In discriminative learning we may use a classification or regression score; in reinforcement learning we may use average discounted reward. Optimization may also arise during inference; for example we may want to reduce the cross entropy between two distributions or minimize a function such as the Bethe free energy. Bound optimization (BO) algorithms take advantage of the fact that many objective functions arising in practice have a special structure. We can often exploit this structure to obtain a bound on the objective function and proceed by optimizing this bound. Ideally, we seek a bound that is valid everywhere in parameter space, easily optimized, and equal to the true objective function at one (or more) point(s). A general form of a bound maximizer which iteratively lower bounds the objective function is given below: General Bound Optimizer for maximizing L(Θ): • Assume: ∃ G(Θ, Ψ) such that for any Θ′ and Ψ′: 1. G(Θ′, Θ′) = L(Θ′) & L(Θ) ≥ G(Θ, Ψ′) ∀ Ψ′ 6= Θ 2. arg maxΘG(Θ, Ψ ′) can be found easily for any Ψ′. • Iterate: Θ = arg maxΘG(Θ, Θ ) • Guarantee: L(Θ) = G(Θ, Θ) ≥ G(Θ, Θ) ≥ G(Θ, Θ) = L(Θ) A bound optimizer does nothing more than coordinate ascent in the functional G(Θ, Ψ), alternating between maximizing G with respect to Ψ for fixed Θ and with respect to Θ for fixed Ψ. These algorithms enjoy a strong guarantee; they never worsen the objective function. Many popular iterative algorithms are bound optimizers, including the EM algorithm for maximum likelihood learning in latent variable models[2], iterative scaling (IS) algorithms for parameter estimation in maximum entropy models[1], non-negative matrix factorization (NMF)[3] and the recent CCCP algorithm for minimizing the Bethe free energy in approximate inference problems[10]. In this paper we explore two questions of theoretical and practical interest: when will bound optimization be fast or slow relative to other standard approaches, and what can be done to improve convergence rates of these algorithms when they are slow? 2 Convergence Behavior and Analysis How large are the steps that bound optimization methods take? Any bound optimizer implicitly defines a mapping: M : Θ → Θ from parameter space to itself, so that Θ = M(Θ). If iterates Θ converge to a fixed point Θ then Θ = M(Θ). If M(Θ) is continuous and differentiable, we can Taylor expand it in the neighborhood of the fixed point Θ: Θ − Θ∗ = M (Θ)(Θ − Θ∗) (1) where M (Θ) = ∂M ∂Θ |Θ=Θ∗ . Since M (Θ) is typically nonzero, a bound optimizer can essentially be seen as a linear iteration algorithm with a “convergence rate matrix” M (Θ). Near a local optimum, this matrix is related to the curvature of the functional G(Θ, Ψ): lim Θt→Θ∗ M (Θ) = − [ ∇G(Θ, Ψ∗) ][ ∇G(Θ) ] −1 (2) where we define the mixed partials and Hessian as:	approximation algorithm;converge;coordinate descent;cross entropy;data pre-processing;estimation theory;expanded memory;expectation–maximization algorithm;first-order predicate;fixed point (mathematics);gradient;hessian;iteration;iterative method;latent variable;local optimum;loss function;machine learning;mathematical optimization;newton;non-negative matrix factorization;optimization problem;pattern recognition;preprocessor;program optimization;rate of convergence;reinforcement learning;supervised learning;times ascent;unsupervised learning	Ruslan Salakhutdinov;Sam T. Roweis;Zoubin Ghahramani	2003			library science;computer science;world wide web	ML	22.472056732557917	-34.6684555246732	76219
dc5a797cb805af74d2bb3bef2be64015fdba8272	a neural network approach to the placement problem	circuit layout;2 dimensional;self organising feature maps;circuit layout cad;self organising map;neural network	| In this paper, we introduce a new neural network approach to the placement of gate array designs. The network used is a Kohonen self-organising map. An abstract speci cation of the design is converted to a set of appropriate input vectors fed to the network at random. At the end of the process, the map shows a 2-dimensional plane of the design in which the modules with higher connectivity are placed adjacent to each other, hence minimising total connection length in the design. The approach can consider external connections and is able to place modules in a rectilinear boundary. These features makes the approach capable of being used in hierarchical oorplanning algorithms.	adjacency matrix;algorithm;artificial neural network;gate array;regular grid;requirement;self-organization;self-organizing map;teuvo kohonen	Morteza Saheb Zamani;Graham R. Hellestrand	1995		10.1145/224818.224942	two-dimensional space;computer science;artificial intelligence;machine learning;engineering drawing;artificial neural network	Robotics	14.79407555831796	-25.75567677573652	76302
2688118e4ebc54a662b373fd9ce078845d321f6a	the structured weighted violations perceptron algorithm		We present the Structured Weighted Violations Perceptron (SWVP) algorithm, a new structured prediction algorithm that generalizes the Collins Structured Perceptron (CSP, (Collins, 2002)). Unlike CSP, the update rule of SWVP explicitly exploits the internal structure of the predicted labels. We prove the convergence of SWVP for linearly separable training sets, provide mistake and generalization bounds, and show that in the general case these bounds are tighter than those of the CSP special case. In synthetic data experiments with data drawn from an HMM, various variants of SWVP substantially outperform its CSP special case. SWVP also provides encouraging initial dependency parsing results.	algorithm;experiment;hidden markov model;linear separability;parsing;perceptron;structured prediction;synthetic data	Rotem Dror;Roi Reichart	2016			theoretical computer science;machine learning;mathematics;algorithm;statistics	NLP	21.97263464243427	-34.009625519921016	76327
5ef28d7b0aa4225dfb2034e2e120a5e6798b3085	on uniform deviations of general empirical risks with unboundedness, dependence, and high dimensionality	empirical risk;high dimensionality;uniform deviation;dependence;strong mixing;probability bound;variable selection;statistical learning theory;unbounded loss;dependence structure;dependent data;risk minimization;decision rule	The statistical learning theory of risk minimization depen ds heavily on probability bounds for uniform deviations of the empirical risks. Classical probabil ity bounds using Hoeffding’s inequality cannot accommodate more general situations with unbounded loss and dependent data. The current paper introduces an inequality that extends Hoeffding’s in equality to handle these more general situations. We will apply this inequality to provide probabili ty bounds for uniform deviations in a very general framework, which can involve discrete decision rul es, unbounded loss, and a dependence structure that can be more general than either martingale or str ng mixing. We will consider two examples with high dimensional predictors: autoregressio n (AR) with l1-loss, and ARX model with variable selection for sign classification, which uses both lagged responses and exogenous predictors.	arx;empirical risk minimization;feature selection;machine learning;social inequality;statistical learning theory;unbounded nondeterminism	Wenxin Jiang	2009	Journal of Machine Learning Research	10.1145/1577069.1577105	vysochanskij–petunin inequality;econometrics;mathematical optimization;empirical risk minimization;computer science;machine learning;hoeffding's inequality;decision rule;mathematics;feature selection;statistics	ML	21.087855408769812	-30.989400800866914	76467
69da7894f6d8dc4f8aba12dc60fbd6be8aafe3e7	a dc-programming algorithm for kernel selection	ucl;supervised learning;discovery;theses;conference proceedings;digital web resources;numerical analysis;convex function;ucl discovery;open access;greedy algorithm;ucl library;book chapters;open access repository;optimality theory;ucl research	We address the problem of learning a kernel for a given supervised learning task. Our approach consists in searching within the convex hull of a prescribed set of basic kernels for one which minimizes a convex regularization functional. A unique feature of this approach compared to others in the literature is that the number of basic kernels can be infinite. We only require that they are continuously parameterized. For example, the basic kernels could be isotropic Gaussians with variance in a prescribed interval or even Gaussians parameterized by multiple continuous parameters. Our work builds upon a formulation involving a minimax optimization problem and a recently proposed greedy algorithm for learning the kernel. Although this optimization problem is not convex, it belongs to the larger class of DC (difference of convex functions) programs. Therefore, we apply recent results from DC optimization theory to create a new algorithm for learning the kernel. Our experimental results on benchmark data sets show that this algorithm outperforms a previously proposed method.	benchmark (computing);convex function;convex hull;greedy algorithm;kernel (operating system);mathematical optimization;minimax;optimization problem;supervised learning	Andreas Argyriou;Raphael Hauser;Charles A. Micchelli;Massimiliano Pontil	2006		10.1145/1143844.1143850	convex function;convex analysis;mathematical optimization;greedy algorithm;kernel embedding of distributions;numerical analysis;computer science;theoretical computer science;machine learning;mathematics;supervised learning;tree kernel;variable kernel density estimation;statistics	ML	23.91878527557959	-37.277076743259606	76539
84ec090245a3454acc4ea71b5fe5315a2e968b06	on the faithfulness of simulated student performance data.	student performance	The validation of models for skills assessment is often conducted by using simulated students because their skills mastery can be predefined. Student performance data is generated according to the predefined skills and models are trained over this data. The accuracy of model skill predictions can thereafter be verified by comparing the predefined skills with the predicted ones. We investigate the faithfulness of different methods for generating simulated data by comparing the predictive performance of a Bayesian student model over real vs. simulated data for which the parameters are set to reflect those of the real data as closely as possible. A similar performance suggests that the simulated data is more faithful to the real data than for a dissimilar performace. The results of our simulations show that the latent trait model (IRT) is a relatively good candidate to simulate student performance data, and that simple methods that solely replicate mean and standard deviation distributions can fail drastically to reflect the characteristics of real data.	item response theory;latent variable model;self-replicating machine;simulation	Michel C. Desmarais;Ildikó Pelczer	2010			artificial intelligence;physics	ML	24.479395361917657	-25.088914561506957	76575
cb83a761e94d809046dc59e1fe6f4b9a20bcab4d	binary classification model inspired from quantum detection theory		Despite its long history, classification is still a subject of extensive research because new application domains require more effective algorithms than the state-of-the-art classification algorithms, which rely on the logical theory of sets, the theory of probability and the algebra of vector spaces. The combination of distinct theoretical frameworks may be the key to making an important step forward toward a stable and significant improvement in classification effectiveness and, to the same extent improved Quantum Mechanics (QM) signal detection. QM may give rise to a new theoretical framework for classification, since it essentially moves the optimal bound of effectiveness beyond the levels made possible by the state-of-the-art classification algorithms. In this paper, we propose a binary classification model inspired by quantum detection theory in an effort to investigate how much benefit it brings as compared to classical models. Our experiments suggest that the improvement in classification effectiveness can be obtained, although the potential of quantum detection can only be partially exploited.	algorithm;binary classification;detection theory;experiment;quantum mechanics;quantum probability;set theory	Emanuele Di Buccio;Qiuchi Li;Massimo Melucci;Prayag Tiwari	2018		10.1145/3234944.3234979	vector space;detection theory;binary classification;statistical classification;machine learning;quantum;artificial intelligence;mathematics	ML	19.870875089745578	-35.885301797487266	76681
a0229cfb3c6d633869bbfc84fc0d0cc0f728d11a	tight analyses for non-smooth stochastic gradient descent		Consider the problem of minimizing functions that are Lipschitz and strongly convex, but not necessarily differentiable. We prove that after T steps of stochastic gradient descent, the error of the final iterate is O(log(T )/T ) with high probability. We also construct a function from this class for which the error of the final iterate of deterministic gradient descent is Ω(log(T )/T ). This shows that the upper bound is tight and that, in this setting, the last iterate of stochastic gradient descent has the same general error rate (with high probability) as deterministic gradient descent. This resolves both open questions posed by Shamir [33]. An intermediate step of our analysis proves that the suffix averaging method achieves error O(1/T ) with high probability, which is optimal (for any first-order optimization method). This improves results of Rakhlin et al. [28] and Hazan and Kale [14], both of which achieved error O(1/T ), but only in expectation, and achieved a high probability error bound of O(log log(T )/T ), which is suboptimal. We prove analogous results for functions that are Lipschitz and convex, but not necessarily strongly convex or differentiable. After T steps of stochastic gradient descent, the error of the final iterate is O(log(T )/ √ T ) with high probability, and there exists a function for which the error of the final iterate of deterministic gradient descent is Ω(log(T )/ √ T ). ar X iv :1 81 2. 05 21 7v 1 [ cs .L G ] 1 3 D ec 2 01 8		Nicholas J. A. Harvey;Christopher Liaw;Yaniv Plan;Sikander Randhawa	2018	CoRR			ML	22.56671741309579	-32.65834021860536	76845
c523bef074cad638cfd3d07f3e22cf7dde037237	enhanced unit training for piecewise linear seperation incremental algorithms.			approximation algorithm;dynamic problem (algorithms);piecewise linear continuation	Juan Manuel Moreno;Francisco Castillo;Joan Cabestany	1993			mathematical optimization;machine learning;control theory	NLP	13.73838181401655	-27.902597327333847	76887
182e1b7feefed3468bebe34b46e703f5908aa106	global reinforcement learning in neural networks with stochastic synapses	intelligent networks neural networks stochastic processes artificial neural networks space exploration machine learning numerical simulation neurofeedback multilayer perceptrons neurons;reinforcement learning;benchmark problem;learning rules reinforcement learning stochastic synapses reinforce learning principle artificial neural networks stochastic cells boltzmann machines deterministic neural cells;stochastic processes;reinforcement learn ing;boltzmann machine;learning artificial intelligence;stochastic processes boltzmann machines learning artificial intelligence;boltzmann machines;artificial neural network;neural network	"""We have found a more general formulation of the REINFORCE learning principle which had been proposed by R. J. Williams for the case of artificial neural networks with stochastic cells (""""Boltzmann machines""""). This formulation has enabled us to apply the principle to global reinforcement learning in networks with deterministic neural cells but stochastic synapses, and to suggest two groups of new learning rules for such networks, including simple local rules. Numerical simulations have shown that at least for several popular benchmark problems one of the new learning rules may provide results on a par with the best known global reinforcement techniques."""	benchmark (computing);boltzmann machine;neural networks;numerical linear algebra;reinforcement learning;simulation;synapse	Xiaolong Ma;Konstantin Likharev	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.246658	unsupervised learning;boltzmann machine;stochastic neural network;feature learning;types of artificial neural networks;wake-sleep algorithm;computer science;artificial intelligence;recurrent neural network;theoretical computer science;online machine learning;machine learning;deep learning;learning classifier system;competitive learning;restricted boltzmann machine;evolutionary robotics;reinforcement learning;hyper-heuristic;artificial neural network;intelligent control	ML	16.872241987713988	-26.128148669036136	77353
48175dbf8969be3d0cebfdbaa68372beca26e30a	faster learning by reduction of data access time	systematic sampling;random sampling;cyclic sampling;big data;large-scale learning;stochastic learning;empirical risk minimization	Nowadays, the major challenge in machine learning is the ‘Big Data’ challenge. The big data problems due to large number of data points or large number of features in each data point, or both, the training of models have become very slow. The training time has two major components: Time to access the data and time to process (learn from) the data. So far, the research has focused only on the second part, i.e., learning from the data. In this paper, we have proposed one possible solution to handle the big data problems in machine learning. The idea is to reduce the training time through reducing data access time by proposing systematic sampling and cyclic/sequential sampling to select mini-batches from the dataset. To prove the effectiveness of proposed sampling techniques, we have used empirical risk minimization, which is commonly used machine learning problem, for strongly convex and smooth case. The problem has been solved using SAG, SAGA, SVRG, SAAG-II and MBSGD (Mini-batched SGD), each using two step determination techniques, namely, constant step size and backtracking line search method. Theoretical results prove similar convergence for systematic and cyclic sampling as the widely used random sampling technique, in expectation. Experimental results with bench marked datasets prove the efficacy of the proposed sampling techniques and show up to six times faster training.	access time;algorithm;backtracking line search;big data;data access;data point;empirical risk minimization;loss function;machine learning;monte carlo method;optimization problem;parallel computing;sql access group;sampling (signal processing)	Vinod Kumar Chauhan;Anuj Sharma;Kalpana Dahiya	2018	Applied Intelligence	10.1007/s10489-018-1235-x	empirical risk minimization;systematic sampling;machine learning;backtracking line search;computer science;artificial intelligence;pattern recognition;data point;sampling (statistics);big data;convex function;data access	ML	19.371141389036836	-37.32741941043125	77362
0591f3e3ff4138800a5fe096622f6c958810a9ef	nonlinear process monitoring using regression and reconstruction method	erbium;kernel;monitoring reconstruction algorithms principal component analysis fault diagnosis mathematical model erbium kernel;reconstruction algorithms;regression analysis annealing continuous production fault diagnosis principal component analysis process monitoring;monitoring;principal component analysis;mathematical model;fault detection nonlinear process monitoring regression method reconstruction method nonlinear regression algorithm output relevant variation extraction fault direction fault magnitude principal component fault diagnosis kernel partial least squares kpls method comparison continuous annealing process;output relevant variation fault diagnosis fault direction;fault diagnosis	In this paper, a new regression and reconstruction method for process monitoring is proposed. The main contributions of the proposed approaches are as follows: 1) a new nonlinear regression algorithm is proposed to extract the output-relevant variation, which, compared with the conventional algorithm, builds a more direct relationship between the input and output variables; 2) the fault direction is determined by possible fault magnitude of every possible principal component; and 3) the fault is effectively diagnosed compared with the conventional kernel partial least-squares (KPLS) method. The proposed method is applied to a continuous annealing process and is compared with the KPLS method. Experiment results show that the proposed method can more effectively detect fault compared with the KPLS method. In addition, the selection of fault direction is more accurate using the proposed reconstruction algorithm compared with the KPLS reconstruction approach.	algorithm;bidirectional texture function;emoticon;input/output;newton's method;nonlinear system;partial least squares regression;principal component analysis;relevance;simulated annealing	Yingwei Zhang;Yunpeng Fan;Wenyou Du	2016	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2016.2564442	econometrics;kernel;erbium;engineering;machine learning;pattern recognition;mathematical model;mathematics;statistics;principal component analysis	Robotics	23.17014750442032	-24.066031521573947	77379
e343cb6a13f0e5276a082bc43d357caf8669b49b	a hybrid genetic based functional link artificial neural network with a statistical comparison of classifiers over multiple datasets	genetique;calcul neuronal;optimisation;neural computation;test statistique;statistical simulation;parametric test;aplicacion;fonctionnelle;optimizacion;genetica;complexite calcul;non parametric test;test comparacion;test estadistico;65kxx;statistical test;optimization method;clasificador;62m45;nonparametric test;rbf;algoritmo genetico;65k10;data mining;classification;metodo optimizacion;apprentissage machine;genetics;62j15;funcional;49xx;resolucion problema;complejidad computacion;classifier;simulacion estadistica;machine learning;functional;62h30;fouille donnee;computational complexity;simulation statistique;prueba no parametrica;comparacion multiple;comparaison multiple;methode optimisation;test non parametrique;algorithme genetique;classificateur;prueba parametrica;non linearite;arquitectura;test parametrique;simulation study;no linealidad;genetic algorithm;nonlinearity;optimization;flann;reseau neuronal;comparison test;multiple comparison;application;architecture;busca dato;clasificacion;red neuronal;computacion neuronal;reseau neuronal artificiel;test comparaison;problem solving;resolution probleme;artificial neural network;neural network	This paper proposed a hybrid genetic based functional link artificial neural network (HFLANN) with simultaneous optimization of input features for the purpose of solving the problem of classification in data mining. The aim of the proposed approach is to choose an optimal subset of input features using genetic algorithm by eliminating features with little or no predictive information and increase the comprehensibility of resulting HFLANN. Using the functionally expanded of selected features, HFLANN overcomes the nonlinearity nature of problems, which is commonly encountered in single-layer neural networks. The features like simplicity of the architecture and low computational complexity of the network encourage us to use it in classification task of data mining. Further, the issue of statistical tests for comparison of algorithms on multiple datasets, which is even more essential to typical machine learning and data mining studies, has been all but ignored. In this work, we recommend a set of simple, yet safe and robust parametric and nonparametric tests for statistical comparisons of HFLANN with FLANN and RBF classifiers over multiple datasets by an extensive simulation studies.	artificial neural network;backpropagation;computational complexity theory;data mining;dual total correlation;genetic algorithm;linear classifier;machine learning;map;mathematical optimization;nonlinear system;radial basis function;simulation;software propagation	Satchidananda Dehuri;Sung-Bae Cho	2009	Neural Computing and Applications	10.1007/s00521-009-0310-y	nonparametric statistics;computer science;artificial intelligence;machine learning;artificial neural network;algorithm	ML	10.194174132523075	-31.130542359714607	77408
3950c7d6011d49167496b9121bb2166e37d4c6df	dynamic object identification with som-based neural networks	forecasting;neural networks;vectors neurons mathematical model biological neural networks benchmark testing;self organising feature maps;timeseries prediction;self organizing map dynamic object identification som based neural networks;dynamic object identification;dynamic object identification neural networks forecasting timeseries prediction	In this article a number of neural networks based on self organizing maps, that can be successfully used for dynamic object identification, is described. The structure and algorithms of learning and operation of such SOM-based neural networks are described in details, also some experimental results is given.	algorithm;modular neural network;neural networks;organizing (structure);self-organization;self-organizing map;time series	Aleksey Averkin;Veaceslav Albu;Sergey Ulyanov;Ilya Povidalo	2013	2013 BRICS Congress on Computational Intelligence and 11th Brazilian Congress on Computational Intelligence	10.1109/BRICS-CCI-CBIC.2013.12	types of artificial neural networks;forecasting;computer science;artificial intelligence;machine learning;data mining;mathematics;deep learning;artificial neural network;statistics	ML	13.148261452236685	-26.411589703991563	77478
5e565b980c31628f57f967000621501a718ae4cf	a weighting initialization strategy for weighted support vector machines	analisis estadistico;equilibrio de carga;equilibrage charge;inicializacion;data mining;classification;a priori knowledge;statistical analysis;fouille donnee;machine exemple support;analyse statistique;load balancing;pattern recognition;reconnaissance forme;support vector machine;maquina ejemplo soporte;vector support machine;reconocimiento patron;busca dato;clasificacion;initialization;initialisation	This paper presents a problem independent weighting strategy for weighted support vector machines (SVMs). SVMs can be applied with a weighting to each training vector to reflect the importance of different classes or training samples. Weightings are often assigned to the two classes inversely proportional to the sample count of each class, or according to a priori knowledge. Such a strategy can be applied to skewed data sets to balance the importance, error contribution and cost between the two classes. In this paper we propose a strategy to give each training pattern a weighting according to their distances to the classifier. The strategy regards the importance of the training patterns to the training process but not the importance of the data to the problem, thus it is suitable for general SVM applications. Experiments show that the performance of the proposed method is competitive to standard SVM while the training processes are even sped up.	support vector machine	Kuo-Ping Wu;Sheng-De Wang	2005		10.1007/11551188_31	support vector machine;initialization;a priori and a posteriori;biological classification;computer science;artificial intelligence;load balancing;machine learning;data mining;programming language;computer security	ML	10.053013908649676	-33.8502463636956	77530
7bb1adf784e614b1d905085b303384212c7f7162	hidden neuron pruning of multilayer perceptrons using a quantified sensitivity measure	neuron pruning;multilayer perceptron;computational complexity;relevance measure;sensitivity measure;neural network	In the design of neural networks, how to choose the proper size of a network for a given task is an important and practical problem. One popular approach to tackling this problem is to start with an oversized network and then prune it to a smaller size so as to achieve less computational complexity and better performance in generalization. This paper presents a pruning technique, by means of a quantified sensitivity measure, to remove as many neurons as possible, those with the least relevance, from the hidden layer of a multilayer perceptron (MLP). The sensitivity of an individual neuron is defined as the expectation of its output deviation due to expected input deviation with respect to overall inputs from a continuous interval, and the relevance of the neuron is defined as the multiplication of its sensitivity value by the summation of the absolute values of its outgoing weights. The basic idea for introducing such a relevance measure is that a neuron with less relevance ought to have less effect on its succeeding neurons and thus contribute less to the entire network. The pruning is performed by iteratively training a network to a certain performance criterion and then removing the hidden neuron with the lowest relevance value until no one can further be removed. The pruning technique is novel in its quantified sensitivity measure and so is its relevance measure. Experimental results demonstrate the effectiveness of the pruning technique.	multilayer perceptron;neuron;sensitivity and specificity	Xiaoqin Zeng;Daniel S. Yeung	2006	Neurocomputing	10.1016/j.neucom.2005.04.010	computer science;artificial intelligence;machine learning;pattern recognition;mathematics;multilayer perceptron;computational complexity theory;artificial neural network	Vision	16.5022199373893	-31.95043382746042	77598
ebda51cc0db6e76031cc1621d380d3b886130ddc	hyperplane algorithm - first step of the paired planes classification procedure	supervised learning;support vector machines;machine learning;pattern recognition;artificial intelligence	The objective of supervised learning is to estimate unknowns based on labeled training samples. If the unknown to be estimated is categorical or discrete, the problem is one of classification. Algorithms for supervised learning are useful tools in many areas of agriculture, medicine, and engineering, including prediction of malignant cancer, document analysis, and speech recognition. In general, Support Vector Machine algorithms have been successful in classification problems, but they have high computational complexity. In this paper, we present the Hyperplane Algorithm. It and two other related algorithms form an ensemble classifier for supervised classification. The Hyperplane Algorithm is reminiscent of a support vector machine but is low in computational complexity. It also has several other advantages compared to Support Vector Machines. Results for five real-life datasets results are shown.	algorithm	Dan Vance;Anca L. Ralescu	2007			semi-supervised learning;margin classifier;support vector machine;least squares support vector machine;learning vector quantization;perceptron;online machine learning;machine learning;linear classifier;pattern recognition;data mining;mathematics;supervised learning;stability;relevance vector machine;computational learning theory;active learning;structured support vector machine;generalization error	Vision	13.398333751830211	-35.80300236241681	77950
03b9c6c87cfab9845395abc6ee8d81a1af5664d8	learning minimum volume sets	rate of convergence;sample size;oracle inequality;decision tree;structural risk minimization;anomaly detection;confidence region;uniform convergence;statistical learning theory;performance bounds;sample complexity;probability measure;vc dimension	Given a probability measure P and a reference measure μ, one is often interested in the minimum μ-measure set with P -measure at least α. Minimum volume sets of this type summarize the regions of greatest probability mass of P , and are useful for detecting anomalies and constructing confidence regions. This paper addresses the problem of estimating minimum volume sets based on independent samples distributed according to P . Other than these samples, no other information is available regarding P , but the reference measure μ is assumed to be known. We introduce rules for estimating minimum volume sets that parallel the empirical risk minimization and structural risk minimization principles in classification. As in classification, we show that the performances of our estimators are controlled by the rate of uniform convergence of empirical to true probabilities over the class from which the estimator is drawn. Thus we obtain finite sample size performance bounds in terms of VC dimension and related quantities. We also demonstrate strong universal consistency, an oracle inequality, and rates of convergence. The proposed estimators are illustrated with histogram and decision tree set estimation rules.	decision tree;empirical risk minimization;p (complexity);performance;sensor;social inequality;structural risk minimization;vc dimension	Clayton D. Scott;Robert D. Nowak	2005	Journal of Machine Learning Research		sample size determination;mathematical optimization;uniform convergence;anomaly detection;combinatorics;structural risk minimization;probability measure;vc dimension;computer science;confidence region;machine learning;decision tree;mathematics;rate of convergence;statistics	ML	20.959077413987785	-31.10871048283177	78395
fb081ddad3e5f2f04d211ff6eaead540b34b51b1	the aggregating algorithm and regression		Our main interest is in the problem of making predictions in the online mode of learning where at every step in time a signal arrives and a prediction needs to be made before the corresponding outcome arrives. Loss is suffered if the prediction and outcome do not match perfectly. In the prediction with expert advice framework, this protocol is augmented by a pool of experts that produce their predictions before we have to make ours. The Aggregating Algorithm (AA) is a technique that optimally merges these experts so that the resulting strategy suffers a cumulative loss that is almost as good as that of the best expert in the pool. The AA was applied to the problem of regression, where outcomes are continuous real numbers, to get the AA for Regression (AAR) and its kernel version, KAAR. On typical datasets, KAAR’s empirical performance is not as good as that of Kernel Ridge Regression (KRR) which is a popular regression method. KAAR performs better than KRR only when the data is corrupted with lots of noise or contains severe outliers. To alleviate this we introduce methods that are a hybrid between KRR and KAAR. Empirical experiments suggest that, in general, these new methods perform as good as or better than both KRR and KAAR. In the second part of this dissertation we deal with a more difficult problem — we allow the dependence of outcomes on signals to change with time. To handle this we propose two new methods: WeCKAAR and KAARCh. WeCKAAR is a simple modification of one of our methods from the first part of the dissertation to include decaying weights. KAARCh is an application of the AA to the case where the experts are all the predictors that can change with time. We show that KAARCh suffers a cumulative loss that is almost as good as that of any expert that does not change very rapidly. Empirical results on data with changing dependencies demonstrate that WeCKAAR and KAARCh perform well in practice and are considerably better than Kernel Ridge Regression.	algorithm;association for automated reasoning;experiment;kernel (operating system);kerrison predictor	Steven Busuttil	2008			bootstrap aggregating	ML	15.148405880308289	-37.332915274623616	78479
5591d0a6958178ae0287d3925fea4932c8b74e4c	learning with limited numerical precision using the cascade-correlation algorithm	learning algorithms;empirical study;learning algorithm;limited numerical precision;neural networks;neural nets;simulacion numerica;algorithme apprentissage;correlation methods;computer networks;learning systems;computer architecture;accuracy;computational modeling;precision;dynamic rescaling;simulation numerique;neural networks algorithm design and analysis neural network hardware computational modeling computer networks predictive models computer science arithmetic computer architecture computer simulation;fixed point arithmetic;learning problems;arithmetic;neural network hardware;cascade correlation algorithm;predictive models;computer science;multilayer network;reseau multicouche;cascade correlation;reseau neuronal;computer simulation;materiel informatique;probabilistic rounding;material informatica;weight update calculations;red neuronal;algorithm design and analysis;probabilistic rounding cascade correlation algorithm neural networks fixed point arithmetic limited numerical precision learning algorithms weight update calculations dynamic rescaling;neural network;neural nets correlation methods learning systems;hardware;numerical simulation	A key question in the design of specialized hardware for simulation of neural networks is whether fixed-point arithmetic of limited numerical precision can be used with existing learning algorithms. An empirical study of the effects of limited precision in cascade-correlation networks on three different learning problems is presented. It is shown that learning can fail abruptly as the precision of network weights or weight-update calculations is reduced below a certain level, typically about 13 bits including the sign. Techniques for dynamic rescaling and probabilistic rounding that allow reliable convergence down to 7 bits of precision or less, with only a small and gradual reduction in the quality of the solutions, are introduced.	16-bit;24-bit;32-bit;8-bit;accumulator (computing);accumulator device component;algorithm;arabic numeral 0;artificial neural network;backpropagation;batch processing;cc system;cascade device component;clomiphene;computation;convergence (action);elegant degradation;ephrin type-b receptor 1, human;fixed-point number;fixed-point arithmetic;gradient descent;hardware random number generator;heart failure;heparin, low-molecular-weight;integer (number);machine learning;moderate response;neural network simulation;numerical analysis;quickprop;random number generation;rounding;sigmoid colon;sigmoid function;software propagation;solutions;variable-gain amplifier;weight	Markus Höhfeld;Scott E. Fahlman	1992	IEEE transactions on neural networks	10.1109/72.143374	computer science;false precision;artificial intelligence;theoretical computer science;machine learning;mathematics;accuracy and precision;artificial neural network;statistics	ML	16.94874494682597	-28.273908404911104	78494
d5a08048a2493d477b1dcadd9947d68b967c1424	a decision tree framework for spatiotemporal sequence prediction	sequence prediction;decision trees	We study the problem of learning to predict a spatiotemporal output sequence given an input sequence. In contrast to conventional sequence prediction problems such as part-of-speech tagging (where output sequences are selected using a relatively small set of discrete labels), our goal is to predict sequences that lie within a high-dimensional continuous output space. We present a decision tree framework for learning an accurate non-parametric spatiotemporal sequence predictor. Our approach enjoys several attractive properties, including ease of training, fast performance at test time, and the ability to robustly tolerate corrupted training data using a novel latent variable approach. We evaluate on several datasets, and demonstrate substantial improvements over existing decision tree based sequence learning frameworks such as SEARN and DAgger.	decision tree;kerrison predictor;latent variable;part-of-speech tagging	Taehwan Kim;Yisong Yue;Sarah L. Taylor;Iain A. Matthews	2015		10.1145/2783258.2783356	computer science;machine learning;decision tree;pattern recognition;incremental decision tree;data mining	ML	18.19325612707434	-37.75893557421175	78615
e01f3a068b71fa45492e38acb10c5031d8c5b8e1	protein secondary structure prediction using machine learning	belief networks;biology computing;learning (artificial intelligence);neural nets;proteins;bayesian inference;intelligent system;machine learning;protein data set;protein secondary structure prediction;trained neural networks;neural network;learning artificial intelligence	This paper presents an intelligent system for protein secondary structure prediction. The system consists of three pairwisely trained neural networks and a Bayesian inference function applied to the neural network outputs for accurate prediction. We tested our system on two well-known protein data set drawn from PDB, our system showed top performances on both data sets.	machine learning	Sriparna Saha;Asif Ekbal;Sidharth Sharma;Sanghamitra Bandyopadhyay;Ujjwal Maulik	2012		10.1007/978-3-642-32063-7_7	types of artificial neural networks;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;deep learning;competitive learning;computational learning theory;bayesian inference;artificial neural network;intelligent control	AI	13.29989625318623	-28.532214714010895	78875
2e6e0fea019a4f320a9a8d03a267cc8e0b6781b6	memory model with unsupervised sequential learning: the effect of threshold self-adjustment	unsupervised learning;integrated systems;web security;satisfiability;neural net;client server technology;bidirectional associative memory;back propagation;memory model	The goal of this research is the creation of a neural net-based autonomous AI system. Such a system, to be successful, should satisfy the following requirement: the learning must be unsupervised, consecutive and depend only on locally available knowledge. Adaptive Bidirectional Associative Memories (ABAM) provide unsupervised learning and flexibility of architecture, but they suffer from catastrophic interference when attempting to add some new knowledge after the completion of the initial training. The solution to this problem for backpropagation (BP) and Hopfield type nets is a pseudorehearsal of the base knowledge (Robins, 1998). This research applies this method to ABAM with attempt to pseudorehearse not the whole base population, but only the neighborhood of the new incoming knowledge. This allows the creation of pseudopatterns within the system without intervention of the experimenter, but requires the extension of conventional neural nets, which are currently viewed as sets of uniform simple units. The basis for this extension is provided by using the Cohen-Grossberg activation dynamics (Cohen & Grossberg, 1983) for the units and a SIMD computer that allows the user to change the parameters in this formula for a specific group of units in the net. Custom software has been written to achieve the required flexibility. The conceptual description of this software and parameters of the model are presented in this paper. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. ’99 ACM Southeast Regional Conference 1999 ACM 1-58113-128-3/99/0004 5.00 Each of those parameters requires individual study; this paper focuses on threshold self-adjustment, which makes each unit more responsive to the change of input and provides additional sensitivity to the net.	artificial neural network;autonomous robot;backpropagation;bidirectional associative memory;catastrophic interference;hopfield network;interference (communication);memory model (programming);simd;unsupervised learning	Anatoli Gorchetchnikov	1999		10.1145/306363.306385	unsupervised learning;computer science;theoretical computer science;machine learning;pattern recognition;flat memory model;competitive learning;memory map	AI	14.421408328216113	-31.43853183361127	79165
f48ab30003a35f27be5e119a2823cf2efa1ce5ba	a stochastic self-organizing map for proximity data	optimisation;learning algorithm;chaine markov;cadena markov;measurement;optimizacion;distance measure;maximum likelihood;echantillonnage gibbs;gibbs sampling;transition probability;efficient algorithm;aproximacion;maximum vraisemblance;algorithme apprentissage;simulated annealing;topographic map;approximation;codificacion;recuit simule;cuantificacion vectorial;vector quantization;medida;expectation maximisation method;mappage;coding;estimacion parametro;distancia;autoorganizacion;self organization;recocido simulado;self organized map;optimization;mapping;mesure;parameter estimation;estimation parametre;reseau neuronal;muestreo gibbs;algoritmo aprendizaje;methode expectation maximisation;red neuronal;autoorganisation;maxima verosimilitud;maximum entropy;distance;codage;neural network;markov chain;quantification vectorielle	We derive an efficient algorithm for topographic mapping of proximity data (TMP), which can be seen as an extension of Kohonen's self-organizing map to arbitrary distance measures. The TMP cost function is derived in a Baysian framework of folded Markov chains for the description of autoencoders. It incorporates the data by a dissimilarity matrix and the topographic neighborhood by a matrix of transition probabilities. From the principle of maximum entropy, a nonfactorizing Gibbs distribution is obtained, which is approximated in a mean-field fashion. This allows for maximum likelihood estimation using an expectation-maximization algorithm. In analogy to the transition from topographic vector quantization to the self-organizing map, we suggest an approximation to TMP that is computationally more efficient. In order to prevent convergence to local minima, an annealing scheme in the temperature parameter is introduced, for which the critical temperature of the first phase transition is calculated in terms of and . Numerical results demonstrate the working of the algorithm and confirm the analytical results. Finally, the algorithm is used to generate a connection map of areas of the cat's cerebral cortex.	approximation algorithm;cerebral cortex;convergence (action);distance matrix;expectation–maximization algorithm;loss function;markov chain;maxima and minima;numerical method;organizing (structure);phase transition;population parameter;principle of maximum entropy;probability;self-organization;self-organizing map;simulated annealing;star trek:;topography;vector quantization	Thore Graepel;Klaus Obermayer	1999	Neural Computation	10.1162/089976699300016854	markov chain;mathematical optimization;computer science;machine learning;mathematics;artificial neural network;statistics	ML	21.267215413475142	-26.55295013295764	79293
ef0f510d58e078b638b584aa50441f302358baef	local model optimization for time series prediction.	chaotic time series;prediction accuracy;leave one out cross validation;time series prediction;neural network	Local models have emerged as one of the leading methods of chaotic time series prediction. Ho wever, the accuracy of local models is sensitiv e to the c hoice of user-speci ed parameters, not unlike neural netw orks and other methods.This paper describes a method of optimizing these parameters so as to minimize the leave-one-out cross-validation error. This approach reduces the burden on the user to pick appropriate values and improves the prediction accuracy.	cross-validation (statistics);mathematical optimization;time series	James McNames	2000			econometrics;computer science;artificial intelligence;machine learning;time series;artificial neural network;cross-validation	ML	11.971454669833891	-24.008360349701807	79374
4371446918c5db6cf4dffd9b1bf69f296ebaf6dc	the modified self-organizing fuzzy neural network model for adaptability evaluation	layered architecture;fuzzy neural network;fuzzy rules;fuzzy logic;self organization;neural network	The author proposed a novel approach for evolving the architecture of a multi-layer neural network based on neural network and fuzzy logic technologies. The model is front-network which comprised with five layers architecture which composed of dynamic inference of fuzzy rules where the consequent sub-models are implemented by recurrent neural networks with internal feedback paths and dynamic neuron synapses. An optimal learning scheme with the evaluation guide line which error data embed is applied for training of LFDFNN models. The results of experiment demonstrate that new model have superior performance.	artificial neural network;network model;neuro-fuzzy;organizing (structure)	Zuohua Miao;Hong A Xu;Xianhua Wang	2007		10.1007/978-3-540-74771-0_39	control engineering;nervous system network models;fuzzy electronics;probabilistic neural network;adaptive neuro fuzzy inference system;fuzzy classification;computer science;artificial intelligence;recurrent neural network;neuro-fuzzy;machine learning;neural modeling fields;physical neural network;time delay neural network;fuzzy associative matrix;fuzzy set operations	NLP	14.336446723144018	-27.320656513108123	79408
e0e41bb4e6f27a20cfddff874751263d9c51f50c	piecewise linear classifiers using binary tree structure and genetic algorithm	piecewise linear;cell classification;misclassification rate;false alarm rate;clasificador;spectrum;algoritmo genetico;function optimization;sensitivity;classifier;estimation erreur;arbol binario;error estimation;arbre binaire;estimacion error;algorithme genetique;classificateur;genetic algorithm;cross validation;pap smear;classification automatique;multiple choice;automatic classification;clasificacion automatica;impurity;binary tree	A linear decision binary tree structure is proposed in constructing piecewise linear classifiers with the Genetic Algorithm (GA) being shaped and employed at each nonterminal node in order to search for a linear decision function, optimal in the sense of maximum impurity reduction. The methodology works for both the two-class and multi-class cases. In comparison to several other well-known methods, the proposed Binary Tree-Genetic Algorithm (BTGA) is demonstrated to produce a much lower cross validation misclassification rate. Finally, a modified BTGA is applied to the important pap smear cell classification. This results in a spectrum for the combination of the highest desirable sensitivity along with the lowest possible false alarm rate ranging from 27.34% sensitivity, 0.62% false alarm rate to 97.02% sensitivity, 50.24% false alarm rate from resubstitution validation. The multiple choices offered by the spectrum for the sensitivity-false alarm rate combination will provide the flexibility needed for the pap smear slide classification.	binary tree;genetic algorithm;linear classifier;piecewise linear continuation;tree structure	Bing-Bing Chai;Tong Huang;Xinhua Zhuang;Yunxin Zhao;Jack Sklansky	1996	Pattern Recognition	10.1016/0031-3203(96)00019-2	multiple choice;spectrum;econometrics;genetic algorithm;impurity;piecewise linear function;classifier;binary tree;sensitivity;computer science;machine learning;constant false alarm rate;mathematics;algorithm;cross-validation;statistics	Vision	10.846993257933274	-35.179837520040614	79487
86cee1dfefcc9128c56df8d19f5fb9f3f1fa8f77	quadratic discriminant revisited	benchmark data sets;quadratic discriminant analysis;mm algorithm;quadratic programming;parameter estimation;exponential family;block-coordinate descent algorithm;trust region method;qda;generative classifiers;iterative methods;mm optimization algorithm	In this study, we revisit quadratic discriminant analysis (QDA). For this purpose, we present a majorize-minimize (MM) optimization algorithm to estimate parameters for generative classifiers, of which conditional distributions are from the exponential family. Furthermore, we propose a block-coordinate descent algorithm to sequentially update parameters of QDA in each iteration of the MM algorithm, for each update, we apply a trust region method, of which each iteration has a simple closed form solution. Numerical experiments show that: when compared with conjugate gradient method, the new proposed method is faster in 9 of 10 benchmark data sets, when compared with other widely used quadratic classifiers in the literature, QDA trained with the proposed method is either the best or not statistically significantly different from the best ones in 8 of 10 benchmark data sets.	benchmark (computing);conjugate gradient method;coordinate descent;experiment;iteration;linear discriminant analysis;mm algorithm;mathematical optimization;numerical method;quadratic classifier;time complexity;trust region	Wenbo Cao;Robert M. Haralick	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.230	mathematical optimization;machine learning;mathematics;statistics	Robotics	23.730055625832694	-35.08713880142669	79501
4e348a80a1db729b33fe393c2cf3e731f7afa50f	discriminative structure learning of markov logic networks	structure learning;learning algorithm;generic algorithm;maximum likelihood;relational database;discrimination learning;markov network	Markov Logic Networks (MLNs) combine Markov networks and first-order logic by attaching weights to first-order formulas and viewing these as templates for features of Markov networks. Learning the structure of MLNs is performed by state-of-the-art methods by maximizing the likelihood of a relational database. This can lead to suboptimal results given prediction tasks. On the other hand better results in prediction problems have been achieved by discriminative learning of MLNs weights given a certain structure. In this paper we propose an algorithm for learning the structure of MLNs discriminatively by maximimizing the conditional likelihood of the query predicates instead of the joint likelihood of all predicates. The algorithm chooses the structures by maximizing conditional likelihood and sets the parameters by maximum likelihood. Experiments in two real-world domains show that the proposed algorithm improves over the state-of-the-art discriminative weight learning algorithm for MLNs in terms of conditional likelihood. We also compare the proposed algorithm with the state-of-the-art generative structure learning algorithm for MLNs and confirm the results in [22] showing that for small datasets the generative algorithm is competitive, while for larger datasets the discriminative algorithm outperfoms the generative one.	algorithm;discriminative model;experiment;first-order logic;first-order predicate;heuristic (computer science);iterated local search;iteration;local search (optimization);markov chain;markov logic network;markov random field;overfitting;relational database	Marenglen Biba;Stefano Ferilli;Floriana Esposito	2008		10.1007/978-3-540-85928-4_9	genetic algorithm;relational database;computer science;machine learning;pattern recognition;data mining;mathematics;maximum likelihood;discriminative model;statistics;discrimination learning;population-based incremental learning	ML	17.74160412853391	-36.317475956004834	79718
9f0c57260d75468ba3aaf132a98a41be39056a68	the regularized lvq1 algorithm	newton optimization;upper bound;nearest neighbour classifiers;lvq1 algorithm;gradient descent;pattern recognition;classification error;nearest neighbour;k means algorithm;online gradient descent	This paper introduces a straightforward generalization of the well-known LVQ1 algorithm for nearest neighbour classifiers that includes the standard LVQ1 and the k-means algorithms as special cases. It is based on a regularizing parameter that monotonically decreases the upper bound of the training classification error towards a minimum. Experiments using 10 real data sets show the utility of this simple extension of LVQ1. r 2006 Elsevier B.V. All rights reserved.	experiment;k-means clustering;k-nearest neighbors algorithm;lazy evaluation;loss function;machine learning;maxima and minima;neurocomputing;whole earth 'lectronic link	Sergio Bermejo	2006	Neurocomputing	10.1016/j.neucom.2005.12.123	gradient descent;mathematical optimization;computer science;machine learning;pattern recognition;mathematics;upper and lower bounds;k-means clustering	AI	21.644949133939228	-36.97135883852575	79800
fe2533594e01b374ee12f8d450069b21b572a675	active sampler: light-weight accelerator for complex data analytics at scale		Recent years have witnessed amazing outcomes from “Big Models” trained by “Big Data”. Most popular algorithms for model training are iterative. Due to the surging volumes of data, we can usually afford to process only a fraction of the training data in each iteration. Typically, the data are either uniformly sampled or sequentially accessed. In this paper, we study how the data access pattern can affect model training. We propose an Active Sampler algorithm, where training data with more “learning value” to the model are sampled more frequently. The goal is to focus training effort on valuable instances near the classification boundaries, rather than evident cases, noisy data or outliers. We show the correctness and optimality of Active Sampler in theory, and then develop a light-weight vectorized implementation. Active Sampler is orthogonal to most approaches optimizing the efficiency of large-scale data analytics, and can be applied to most analytics models trained by stochastic gradient descent (SGD) algorithm. Extensive experimental evaluations demonstrate that Active Sampler can speed up the training procedure of SVM, feature selection and deep learning, for comparable training quality by 1.6-2.2x.	algorithm;big data;correctness (computer science);data access;deep learning;feature selection;iteration;iterative method;sampling (signal processing);sequential access;signal-to-noise ratio;speedup;stochastic gradient descent;support vector machine	Jinyang Gao;H. V. Jagadish;Beng Chin Ooi	2015	CoRR		computer science;data science;machine learning;data mining;database;statistics	ML	19.224685826853815	-37.44331755218955	79808
509bf8d7ac8ff4334c5aee5771183da0fd9c7a42	stacked generalization	error estimation and correction;combining generalizers;learning set preprocessing;cross validation;generalization and induction	This paper introduces stacked generalization, a scheme for minimizing the generalization error rate of one or more generalizers. Stacked generalization works by deducing the biases of the generalizer(s) with respect to a provided learning set. This deduction proceeds by generalizing in a second space whose inputs are (for example) the guesses of the original generalizers when taught with part of the learning set and trying to guess the rest of it, and whose output is (for example) the correct guess. When used with multiple generalizers, stacked generalization can be seen as a more sophisticated version of cross-validation, exploiting a strategy more sophisticated than cross-vali-dation's crude winner-takes-all for combining the individual generalizers. When used with a single generalizer, stacked generalization is a scheme for estimating (and then correcting for) the error of a generalizer which has been trained on a particular learning set and then asked a particular question. After introducing stacked generalization and justifying its use, this paper presents two numerical experiments. The first demonstrates how stacked generalization improves upon a set of separate generalizers for the NETtalk task of translating text to phonemes. The second demonstrates how stacked generalization improves the performance of a single surface-fitter. With the other experimental evidence in the literature, the usual arguments supporting cross-validation, and the abstract justifications presented in this paper, the conclusion is that for almost any real-world generalization problem one should use some version of stacked generalization to minimize the generalization error rate. This paper ends by discussing some of the variations of stacked generalization, and how it touches on other fields like chaos theory.	chaos theory;cross-validation (statistics);ensemble learning;experiment;generalization error;nettalk (artificial neural network);natural deduction;numerical analysis	David H. Wolpert	1992	Neural Networks	10.1016/S0893-6080(05)80023-1	computer science;theoretical computer science;machine learning;mathematics;algorithm;cross-validation;statistics	ML	19.732341096667295	-33.4066100780766	79899
22c2698c15e0244bdda0f263910caec5a67fd2ab	breaking the curse of kernelization: budgeted stochastic gradient descent for large-scale svm training	budgeted sgd;online algorithm;multi-class svm training;large-scale svm training;sgd inapplicable;popular online svm algorithm;derive bsgd algorithm;stochastic gradient descent;sgd family;budget maintenance;large-scale kernel svm training;optimal svm solution;svm;kernel methods	Online algorithms that process one example at a time are advantageous when dealing with very large data or with data streams. Stochastic gradient descent (SGD) is such an algorithm and it is an attractive choice for online SVM training due to its simplicity and effectiveness. When equipped with kernel functions, similarly to other SVM learning algorithms, SGD is susceptible to “the curse of kernelization” that causes unbounded linear growth in model size and update time with data size. This may render SGD inapplicable to large data sets. We address this issue by presenting a class of Budgeted SGD (BSGD) algorithms for large-scale kernel SVM training which have constant space and time complexity per update. BSGD keeps the number of support vectors bounded during training through several budget maintenance strategies. We treat the budget maintenance as a source of the gradient error, and relate the gap between the BSGD and the optimal SVM solutions via the average model degradation due to budget maintenance. To minimize the gap, we study greedy budget maintenance methods based on removal, projection, and merging of support vectors. We propose budgeted versions of several popular online SVM algorithms that belong to the SGD family. We further derive BSGD algorithms for multi-class SVM training. Comprehensive empirical results show that BSGD achieves much higher accuracy than the state-of-the-art budgeted online algorithms and comparable to non-budget algorithms, while achieving impressive computational efficiency both in time and space during training and prediction.	computation;convex function;convex set;elegant degradation;experiment;greedy algorithm;image scaling;kernelization;linear function;machine learning;margin (machine learning);maxima and minima;norma;online algorithm;online and offline;pegasos;perceptron;reason maintenance;recursion;reduction (complexity);rewrite (programming);social inequality;stochastic gradient descent;subgradient method;support vector machine;time complexity;truth-table reduction	Zhuang Wang;Koby Crammer;Slobodan Vucetic	2012	Journal of Machine Learning Research		support vector machine;kernel method;mathematical optimization;computer science;machine learning;pattern recognition;stochastic gradient descent;statistics	ML	20.531601504989627	-37.74200359969297	80022
af7802a50a8c294ebfd539ad72158475e5ecd9f2	"""the """"moving targets"""" training algorithm"""	training algorithm	A simple method for training the dynamical behavior of a neural network is derived. It is applicable to any training problem in discrete-time networks with arbitrary feedback. The algorithm resembles back-propagation in that an error function is minimized using a gradient-based method, but the optimization is carried out in the hidden part of state space either instead of, or in addition to weight space. Computational results are presented for some simple dynamical training problems, one of which requires response to a signal 100 time steps in the past.	algorithm;artificial neural network;backpropagation;computation;dynamical system;feedback;gradient;mathematical optimization;software propagation;state space	Richard Rohwer	1989		10.1007/3-540-52255-7_31	simulation;computer science;theoretical computer science;machine learning	ML	18.888532908068054	-24.754905618864864	80155
52ec870b393ea57dbca47f4f21b99a3806f14e75	optimizing neural network hyperparameters with gaussian processes for dialog act classification	manuals;kernel;gaussian processes;artificial neural networks;computational modeling;optimization;natural language processing	Systems based on artificial neural networks (ANNs) have achieved state-of-the-art results in many natural language processing tasks. Although ANNs do not require manually engineered features, ANNs have many hyperparameters to be optimized. The choice of hyperparameters significantly impacts models' performances. However, the ANN hyperparameters are typically chosen by manual, grid, or random search, which either requires expert experiences or is computationally expensive. Recent approaches based on Bayesian optimization using Gaussian processes (GPs) is a more systematic way to automatically pinpoint optimal or near-optimal machine learning hyperparameters. Using a previously published ANN model yielding state-of-the-art results for dialog act classification, we demonstrate that optimizing hyperparameters using GP further improves the results, and reduces the computational time by a factor of 4 compared to a random search. Therefore it is a useful technique for tuning ANN models to yield the best performances for NLP tasks.	analysis of algorithms;artificial neural network;bayesian optimization;computation;gaussian process;machine learning;mathematical optimization;natural language processing;optimizing compiler;performance;random search;time complexity;dialog	Franck Dernoncourt;Ji Young Lee	2016	2016 IEEE Spoken Language Technology Workshop (SLT)	10.1109/SLT.2016.7846296	natural language processing;kernel;computer science;artificial intelligence;machine learning;pattern recognition;gaussian process;computational model;artificial neural network	ML	16.87063396430189	-24.600081887800958	80426
5445ecc1b1e354738d28a7d0ff2561fc3ab52668	tight sample complexity of large-margin learning	statistical machine learning;spectrum;science learning;upper and lower bounds;sample complexity;gaussian distribution;covariance matrix	We obtain a tight distribution-specific characterization o f the sample complexity of large-margin classification withL2 regularization: We introduce the γ-adapted-dimension, which is a simple function of the spect rum of a distribution’s covariance matrix, and show distribution-specific u pperand lower bounds on the sample complexity, both governed by the γ-adapted-dimension of the source distribution. We conclude that this new quantity tig htly characterizes the true sample complexity of large-margin classification. The bounds hold for a rich family of sub-Gaussian distributions.	sample complexity;tag (game)	Sivan Sabato;Nathan Srebro;Naftali Tishby	2010			normal distribution;estimation of covariance matrices;spectrum;covariance matrix;mathematical optimization;combinatorics;mathematics;upper and lower bounds;statistics	ML	20.86454143585909	-32.63610219734166	80470
c58ddbd6eacbde0596b5589d24eef80111fce248	development of genetic algorithm embedded knn for fingerprint recognition	biometrie;biometrics;biometria;algoritmo genetico;kohonen algorithm;algoritmo kohonen;image enhancement;algorithme kohonen;fingerprint recognition;dactyloscopie;algorithme genetique;autoorganizacion;self organization;genetic algorithm;reseau neuronal;red neuronal;autoorganisation;fingerprint identification;neural network	A Kohonen self-organizing neural network embedded with genetic algorithm for fingerprint recognition is proposed in this paper. The genetic algorithm is embedded to initiate the Kohonen classifers. By the proposed approach, the neural network learning performance and accuracy are greatly enhanced. In addition, the genetic algorithm can successfully avoid the neural network from being trapped in a local minimum. The proposed method was tested for the recognition of fingerprints. The results were promising to applications.	fingerprint recognition;genetic algorithm;k-nearest neighbors algorithm	H. R. Sudarshana Reddy;N. V. Subba Reddy	2004		10.1007/978-3-540-30176-9_2	fingerprint;self-organization;genetic algorithm;computer science;artificial intelligence;machine learning;time delay neural network;fingerprint recognition;artificial neural network;algorithm;biometrics	Robotics	10.529367335321657	-30.617501706855332	80509
b1db174463b0bbc54a61fcc83acfb89ad3e3d18f	loss functions for multiset prediction		We study the problem of multiset prediction. The goal of multiset prediction is to train a predictor that maps an input to a multiset consisting of multiple items. Unlike existing problems in supervised learning, such as classification, ranking and sequence generation, there is no known order among items in a target multiset, and each item in the multiset may appear more than once, making this problem extremely challenging. In this paper, we propose a novel multiset loss function by viewing this problem from the perspective of sequential decision making. The proposed multiset loss function is empirically evaluated on two families of datasets, one synthetic and the other real, with varying levels of difficulty, against various baseline loss functions including reinforcement learning, sequence, and aggregated distribution matching loss functions. The experiments reveal the effectiveness of the proposed loss function over the others.	baseline (configuration management);experiment;kerrison predictor;loss function;mnist database;machine learning;map;reinforcement learning;supervised learning;synthetic intelligence	Sean Welleck;Zixin Yao;Yu Gai;Jialin Mao;Zheng Zhang;Kyunghyun Cho	2018			machine learning;computer science;supervised learning;multiset;deep learning;reinforcement learning;ranking;artificial intelligence;structured prediction	ML	18.62749863459339	-36.23440957710244	80581
1aeee02f93e02e82753e2910aaac14ad7ff5ff64	networks of spiking neurons: the third generation of neural network models	modelizacion;formal model;complexite calcul;lower bounds;integrate and fire;integrate and fire neutron;sigmoidal neural nets;modelisation;complejidad computacion;spiking neurons;neural net;computational complexity;spiking neuron;network model;borne inferieure;neural network model;reseau neuronal;modeling;red neuronal;lower bound;cota inferior;neural network	"""-The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values o f its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list o f references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology. © 1997 Elsevier Science Ltd. All rights reserved. Keywords--Spiking neuron, Integrate-and-fire neutron, Computational complexity, Sigmoidal neural nets, Lower bounds. 1. D E F I N I T I O N S AND M O T I V A T I O N S If one classifies neural network models according to their computational units, one can distinguish three different generations. The f irst generation is based on M c C u l l o c h P i t t s neurons as computational units. These are also referred to as perceptrons or threshold gates. They give rise to a variety of neural network models such as multilayer perceptrons (also called threshold circuits), Hopfield nets, and Boltzmann machines. A characteristic feature of these models is that they can only give digital output. In fact they are universal for computations with digital input and output, and every boolean function can be computed by some multilayer perceptron with a single hidden layer. The second generation is based on computational units that apply an """"activation function"""" with a continuous set of possible output values to a weighted sum (or polynomial) of the inputs. Common activation functions are the s igmoid func t ion a(y) = 1/(1 + e -y) and the linear Acknowledgements: I would like to thank Eduardo Sontag and an anonymous referee for their helpful comments. Written under partial support by the Austrian Science Fund. Requests for reprints should be sent to W. Maass, Institute for Theoretical Computer Science, Technische Universit~it Graz, Klosterwiesgasse 32/2, A-8010, Graz, Austria; tel. +43 316 873-5822; fax: +43 316 873-5805; e-mail: maass@igi,tu-graz.ac.at saturated function 7r with 7r(y) = y for 0 --< y --< 1, 7r(y) = 0 for y < 0, lr(y) = 1 for y > 1. Besides piecewise polynomial activation functions we consider in this paper also """"piecewise exponential"""" activation functions, whose pieces can be defined by expressions involving exponentiation (such as the definition of a). Typical examples for networks from this second generation are feedforward and recurrent sigmoidal neural nets, as well as networks of radial basis function units. These nets are also able to compute (with the help of thresholding at the network output) arbitrary boolean functions. Actually it has been shown that neural nets from the second generation can compute certain boolean functions with f e w e r gates than neural nets from the first generation (Maass, Schnitger, & Sontag, 1991; DasGupta & Schnitger, 1993). In addition, neural nets from the second generation are able to compute functions with analog input and output. In fact they are universal for analog computations in the sense that any continuous function with a compact domain and range can be approximated arbitrarily well (with regard to uniform convergence, i.e., the L= norm) by a network of this type with a single hidden layer. Another characteristic feature of this second generation of neural network models is that they support learning algorithms that are based on gradient descent such as backprop."""	action potential;activation function;approximation algorithm;artificial neural network;backpropagation;boltzmann machine;computation;digital data;email;fax;feedforward neural network;gradient descent;hopfield network;input/output;machine learning;multilayer perceptron;neuron;polynomial;radial (radio);radial basis function;requests;second generation multiplex plus;spiking neural network;theoretical computer science;thresholding (image processing);time complexity;walter pitts;weight function	Wolfgang Maass	1996	Neural Networks	10.1016/S0893-6080(97)00011-7	winner-take-all;systems modeling;random neural network;computer science;artificial intelligence;network model;machine learning;upper and lower bounds;computational complexity theory;artificial neural network;spiking neural network	ML	17.76945384479115	-27.745677578671163	80631
1562f87551996ad6528dcfd297bd3cf3fbc04c96	bounds for vector-valued function estimation		We present a framework to derive risk bounds for vector-valued learning with a broad class of feature maps and loss functions. Multi-task learning and one-vs-all multi-category learning are treated as examples. We discuss in detail vector-valued functions with one hidden layer, and demonstrate that the conditions under which shared representations are beneficial for multitask learning are equally applicable to multi-category learning.	computer multitasking;concept learning;loss function;map;multi-task learning	Andreas Maurer;Massimiliano Pontil	2016	CoRR		semi-supervised learning;unsupervised learning;feature learning;multi-task learning;instance-based learning;mathematical optimization;algorithmic learning theory;empirical risk minimization;online machine learning;machine learning;pattern recognition;mathematics;stability;computational learning theory;active learning;generalization error	ML	21.48744087967424	-34.29492258678786	80861
95f5e3a5bfd4ee645f1cc5fd44e55b231689e31c	a max-piecewise-linear neural network for function approximation	piecewise linear;nonlinear circuit synthesis;piecewise linear approximation;functional form;activation function;function approximation;computational complexity;canonical pwl representation;back propagation algorithm;nonlinear circuits;pwl basis function;back propagation;hardware implementation;training algorithm;neural network	This paper proposes a Max-Piecewise-Linear (MPWL) Neural Network for function approximation. The MPWL network consists of a single hidden layer and employs the Piecewise-Linear (PWL) Basis Functions as the activation functions of hidden neurons. Since a PWL Basis Function possesses a simple functional form and universal representation capability, the MPWL network achieves a good balance between the computational simplicity and approximation accuracy. In addition, a PWL version of Back-Propagation (PBP) algorithm is developed, whose computational complexity is lower than the training algorithms for the Canonical PWL network, and the Back-Propagation algorithm for the sigmoid network with same number of training cycles. Another advantage of the MPWL network is its amenability to hardware implementation. This facilitates many applications such as nonlinear circuit synthesis, dynamic identification and control.	approximation;artificial neural network	Chengtao Wen;Xiaoyan Ma	2008	Neurocomputing	10.1016/j.neucom.2007.03.001	mathematical optimization;discrete mathematics;piecewise linear function;function approximation;computer science;backpropagation;machine learning;mathematics;activation function;computational complexity theory;higher-order function;artificial neural network	ML	15.056875226348701	-27.644381587497875	80937
59a6a65a635b8ff50689abfd98e3aa31df7d2327	mixture proportion estimation via kernel embedding of distributions		Mixture proportion estimation (MPE) is the problem of estimating the weight of a component distribution in a mixture, given samples from the mixture and component. This problem constitutes a key part in many “weakly supervised learning” problems like learning with positive and unlabelled samples, learning with label noise, anomaly detection and crowdsourcing. While there have been several methods proposed to solve this problem, to the best of our knowledge no efficient algorithm with a proven convergence rate towards the true proportion exists for this problem. We fill this gap by constructing a provably correct algorithm for MPE, and derive convergence rates under certain assumptions on the distribution. Our method is based on embedding distributions onto an RKHS, and implementing it only requires solving a simple convex quadratic programming problem a few times. We run our algorithm on several standard classification datasets, and demonstrate that it performs comparably to or better than other algorithms on most datasets.	algorithm;anomaly detection;correctness (computer science);crowdsourcing;kernel embedding of distributions;mixture model;quadratic programming;rate of convergence;supervised learning	Harish G. Ramaswamy;Clayton Scott;Ambuj Tewari	2016			mathematical optimization;machine learning;mathematics;statistics	ML	21.469858189413543	-34.41976563536914	81104
80a905983b57b130eb36432167bf75e7a042b1f9	building rbf neural network topology through potential functions	metodo adaptativo;cluster;learning algorithm;fonction potentiel;amas;fonction base radiale;methode adaptative;intelligence artificielle;algorithme apprentissage;classification;radial basis function;rbf neural network;adaptive method;funcion potencial;artificial intelligence;monton;inteligencia artificial;reseau neuronal;potential function;funcion radial base;algoritmo aprendizaje;clasificacion;red neuronal;neural network	In this paper we propose a strategy to shape adaptive radial basis functions through potential functions. DYPOF (DYnamic POtential Functions) neural network (NN) is designed based on radial basis functions (RBF) NN with a two-stage training procedure. Static (fixed number of RBF) and dynamic (ability to add or delete one or more RBF) versions of our learning algorithm are introduced. We investigate the change of cluster shape with the dimension of the input data, the choice of univariate potential function, and the construction of multivariate potential functions. Several data sets are considered to demonstrate the classification performance on the training and testing exemplars as well as compare DYPOF with other neural networks.	algorithm;artificial neural network;network topology;radial (radio);radial basis function	Natacha Gueorguieva;Iren Valova	2003		10.1007/3-540-44989-2_123	radial basis function;hierarchical rbf;biological classification;computer science;artificial intelligence;machine learning;mathematics;artificial neural network;algorithm;cluster	ML	11.770694264011288	-31.21078085076346	81325
79f176d104b4032d5a463682405f8eb2772ed619	blind equalization of constant modulus signals based on gaussian process for classification	blind equalization;gaussian process for classification;machine learning	Blind equalization can be combined with soft-input decoders to greatly improve the performance of communication system. However, most blind equalization algorithms are not designed to provide posterior probability, which is essential for soft-input decoders. In this paper, blind equalization based on Gaussian process for classification (GPC), which could output such information, is applied to optimally detect the constant modulus signals. The scheme is implemented by automatically selecting proper initial training data set and continuously incorporating more appropriate points into training data set with a iteration process. During the iteration process, we utilize all equalizer input symbols that can be assumed to be a certain class label at a high probability as training data to make prediction with GPC model, and give out posterior probability of each input symbol under a specific class label. The proposed blind equalizer has been proved to be able to provide a better performance in both linear channel and nonlinear channel compared with other blind equalizers.	algorithm;alphabet (formal languages);blind equalization;computer;equalization (communications);gaussian process;iteration;kriging;machine learning;modulus of continuity;nonlinear system;test set;x.690	Zhifei Sun;Tinghuan Chen;You Tong;Meng Zhang	2017	Wireless Personal Communications	10.1007/s11277-017-4824-9	communications system;computer science;modulus;nonlinear system;training set;blind equalization;artificial intelligence;gaussian process;pattern recognition;posterior probability;communication channel	ML	16.27560244710566	-31.007587173499694	81546
1272ed76c2fd9dd20bd75e24cc5a4166741297de	stochastic spectral descent for restricted boltzmann machines		Restricted Boltzmann Machines (RBMs) are widely used as building blocks for deep learning models. Learning typically proceeds by using stochastic gradient descent, and the gradients are estimated with sampling methods. However, the gradient estimation is a computational bottleneck, so better use of the gradients will speed up the descent algorithm. To this end, we first derive upper bounds on the RBM cost function, then show that descent methods can have natural advantages by operating in the `∞ and Shatten∞ norm. We introduce a new method called “Stochastic Spectral Descent” that updates parameters in the normed space. Empirical results show dramatic improvements over stochastic gradient descent, and have only have a fractional increase on the per-iteration cost.	algorithm;deep learning;iteration;loss function;restricted boltzmann machine;sampling (signal processing);stochastic gradient descent	David E. Carlson;Volkan Cevher;Lawrence Carin	2015			gradient descent;mathematical optimization;combinatorics;backpropagation;neighbourhood components analysis;machine learning;mathematics;stochastic gradient descent;restricted boltzmann machine	ML	24.04320266486741	-31.41100224081374	82052
5c10cf21fa95e33cf27d80daf2814f6116e79a25	a convex approach to validation-based learning of the regularization constant	lettre alphabet;metodo cuadrado menor;modelizacion;least squares support vector machines validation based learning regularization constant convex relaxation ridge regression regularization networks smoothing splines;methode moindre carre;smoothing methods support vector machines least squares methods learning systems least squares approximation kernel computational efficiency length measurement reproducibility of results councils;model selection;least squares approximations;regularization constant;ridge regression;regularization convex optimization model selection;analisis estadistico;least squares method;support vector machines;convex programming;regresion ridge;validacion;convex optimization;programmation convexe;aprendizaje probabilidades;splines mathematics;regularization;modelisation;aproximacion esplin;regression pseudo orthogonale;regression;learning methods;statistical analysis;spline approximation;smoothing;approximation spline;smoothing splines;machine exemple support;analyse statistique;alisamiento;least squares support vector machines;regularization networks;apprentissage probabilites;letra alfabeto;validation;regression analysis;cross validation;convex relaxation;maquina ejemplo soporte;vector support machine;reseau neuronal;letter;sista;modeling;lissage;red neuronal;smoothing spline;probability learning;algorithms artificial intelligence computer simulation decision support techniques information storage and retrieval models theoretical neural networks computer pattern recognition automated;support vector machines least squares approximations regression analysis splines mathematics;validation based learning;neural network;least squares support vector machine;programacion convexa	This letter investigates a tight convex relaxation to the problem of tuning the regularization constant with respect to a validation based criterion. A number of algorithms is covered including ridge regression, regularization networks, smoothing splines, and least squares support vector machines (LS-SVMs) for regression. This convex approach allows the application of reliable and efficient tools, thereby improving computational cost and automatization of the learning method. It is shown that all solutions of the relaxation allow an interpretation in terms of a solution to a weighted LS-SVM	algorithm;algorithmic efficiency;eisenstein's criterion;least squares;linear programming relaxation;matrix regularization;smoothing (statistical technique);smoothing spline;solutions;support vector machine	Kristiaan Pelckmans;Johan A. K. Suykens;Bart De Moor	2007	IEEE Transactions on Neural Networks	10.1109/TNN.2007.891187	convex analysis;regularization perspectives on support vector machines;regularization;mathematical optimization;proximal gradient methods for learning;convex optimization;convex combination;smoothing spline;computer science;machine learning;mathematics;statistics;proper convex function	ML	20.34230851934161	-30.24771465795624	82084
9d6b307c25b96a549a98acecadd55771768e1616	self-organizing neuro-fuzzy system for control of unknown plants	learning control;fuzzy neural nets;closed loop systems;optimal method;fuzzy control;unknown plants control self organizing neurofuzzy system cluster based system knowledge base systems input output training data data types linguistic meanings pseudo error learning control closed loop control;curse of dimensionality;closed loop control;data type;closed loop systems self organising feature maps fuzzy neural nets fuzzy control knowledge based systems;input output;self organising feature maps;neuro fuzzy system;self organization;fuzzy neural networks control systems clustering algorithms fuzzy systems backpropagation algorithms neural networks training data equations humans partitioning algorithms;knowledge based systems;fuzzy system;knowledge base	A cluster-based self-organizing neuro-fuzzy system (SO-NFS) is proposed for control of unknown plants. The neuro-fuzzy system can learn its knowledge base from input–output training data. A plant model is not required for training, that is, the plant is unknown to the SO-NFS. Using new data types, the vectors and matrices, a construction theory is developed for the organization process and the inference activities of the cluster-based SO-NFS. With the construction theory, a compact equation for describing the relation between the input base variables and inference results is established. This equation not only gives the inference relation between inputs and outputs but also specifies the linguistic meanings in the process. New pseudo-error learning control is proposed for closed-loop control applications. Using a cluster-based algorithm, the neuro-fuzzy system in its genesis can be generated by the stimulation of input/output training data to have its initial control policy (IF–THEN rules) for application. With the well-known random optimization method, the generated neuro-fuzzy system can learn its data base for specific applications. The proposed approach can be applied on control of unknown plants, and can levitate the curse of dimensionality in traditional fuzzy systems. Two examples are demonstrated.	algorithm;control theory;curse of dimensionality;database;fuzzy control system;genesis;input/output;knowledge base;mathematical optimization;neuro-fuzzy;organizing (structure);random optimization;self-organization;whole earth 'lectronic link	Chunshien Li;Chun-Yi Lee	2003	IEEE Trans. Fuzzy Systems	10.1109/TFUZZ.2002.805898	input/output;self-organization;curse of dimensionality;data type;computer science;artificial intelligence;machine learning;control theory;fuzzy control system	Robotics	11.28428164622378	-28.20880437220188	82093
a7363c02b935d6b7985569f96b3ec863cef73f68	an analytic center machine	interior point methods;convex polytope;support vector machines;analytic center;machine learning;center of gravity;support vector machine;interior point method;computational efficiency	Support vector machines have recently attracted much attention in the machine learning and optimization communities for their remarkable generalization ability. The support vector machine solution corresponds to the center of the largest hypersphere inscribed in the version space. Recently, however, alternative approaches (Herbrich, Graepel, & Campbell, In Proceedings of ESANN 2000) have suggested that the generalization performance can be further enhanced by considering other possible centers of the version space like the center of gravity. However, efficient methods for calculating the center of gravity of a polyhedron are lacking. A center that can be computed efficiently using Newton's method is the analytic center of a convex polytope. We propose an algorithm, that finds the hypothesis that corresponds to the analytic center of the version space. We refer to this type of classifier as the analytic center machine (ACM). Preliminary experimental results are presented for which ACMs outperform support vector machines.	algorithm;heuristic (computer science);machine learning;mathematical optimization;newton;newton's method;polyhedron;sparse matrix;statistical classification;support vector machine;version space learning	Theodore B. Trafalis;Alexander M. Malyscheff	2002	Machine Learning	10.1023/A:1012458531022	chebyshev center;support vector machine;mathematical optimization;combinatorics;computer science;machine learning;interior point method;mathematics	ML	21.5671851650894	-37.39808038555953	82099
b4bbf89f091edbeeae8b2e33d6d18c84cb15d7ee	neural arx models and pac learning	learning algorithm;algorithm complexity;cost function;pac learning;complejidad algoritmo;approximation algorithm;evolutionary programming;algorithme apprentissage;complexite algorithme;algorithme evolutionniste;algoritmo evolucionista;evolutionary algorithm;reseau neuronal;algorithme approximation;stochastic stability;learning theory;algoritmo aprendizaje;red neuronal;neural network	The PAC learning theory creates a framework to assess the learning properties of models such as the required size of the training samples and the similarity between the training and training performances. These properties, along with stochastic stability, form the main characteristics of a typical dynamic ARX modeling using neural networks. In this paper, an extension of PAC learning theory is defined which includes ARX modeling tasks, and then based on the new learning theory the learning properties of a family of neural ARX models are evaluated. The issue of stochastic stability of such networks is also addressed. Finally, using the obtained results, a cost function is proposed that considers the learning properties as well as the stochastic stability of a sigmoid neural network and creates a balance between the testing and training performances.	arx;probably approximately correct learning	Kayvan Najarian;Guy Albert Dumont;Michael S. Davies;Nancy E. Heckman	2000		10.1007/3-540-45486-1_25	evolutionary programming;computer science;artificial intelligence;online machine learning;machine learning;learning theory;evolutionary algorithm;stability;probably approximately correct learning;approximation algorithm;artificial neural network;algorithm	NLP	19.3712320205364	-28.751450789926636	82126
52c879bacf63acce5d93df8fc94f0557aec49619	deep generative stochastic networks trainable by backprop		We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution of the Markov chain is conditional on the previous state, generally involving a small move, so this conditional distribution has fewer dominant modes, being unimodal in the limit of small moves. Thus, it is easier to learn because it is easier to approximate its partition function, more like learning to perform supervised function approximation, with gradients that can be obtained by backprop. We provide theorems that generalize recent work on the probabilistic interpretation of denoising autoencoders and obtain along the way an interesting justification for dependency networks and generalized pseudolikelihood, along with a definition of an appropriate joint distribution and sampling mechanism even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. We validate these theoretical results with experiments on two image datasets using an architecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows training to proceed with simple backprop, without the need for layerwise pretraining. P(X)	algorithmic inference;approximation algorithm;autoencoder;backpropagation;boltzmann machine;experiment;gibbs sampling;gradient;hippi;markov chain;noise reduction;partition function (mathematics);sampling (signal processing);stationary process	Yoshua Bengio;Eric Thibodeau-Laufer;Jason Yosinski	2014			econometrics;machine learning;mathematics;statistics	ML	24.588675202468526	-30.21236818614609	82145
31fb016d0228b136306d270f8d245852851a860a	the design of a real-time neurocomputer based on rbf networks	avionics;rbf networks;neurocomputers;real time;real time pattern recognition;peak detection;pattern recognition;rbf network	The design of a real-time neurocomputer (RBF network) subsystem is described. The subsystem is integrated into an avionics system for surveillance and targeting functions. The design of a hardware module based on neurochips that directly support RBF networks, its use for signal peak detection, and the integrated training and testing environment used to train the RBF networks are presented.	radial basis function network;real-time clock	A. David Sánchez V.DavidSánchez;Shon Sloat;Joe Guerrero;David Shullo;Michael Lefebvre	1998	Neurocomputing	10.1016/S0925-2312(98)00023-X	avionics;embedded system;hierarchical rbf;computer science;artificial intelligence;machine learning	Embedded	13.030311544821824	-26.144409240842087	82196
759b62b114aa8b93126dfeb4876e60e1c6494eca	information maximization and independent component analysis: is there a difference?	kullback leibler information;metodo estadistico;models neurological;tecnologia electronica telecomunicaciones;linear independence;computacion informatica;probability;maximization;statistical independence;grupo de excelencia;statistical method;independent component analysis;methode statistique;ciencias basicas y experimentales;component analysis;algorithms;visual perception;pattern recognition automated;humans;theorie information;reseau neuronal;tecnologias;neural networks computer;grupo a;maximizacion;red neuronal;information theory;maximisation;neural network;pattern recognition visual;teoria informacion	This article provides a detailed and rigorous analysis of the two commonly used methods for redundancy reduction: linear independent component analysis (ICA) posed as a direct minimization of a suitably chosen redundancy measure and information maximization (InfoMax) of a continuous stochastic signal transmitted through an appropriate nonlinear network. The article shows analytically that ICA based on the Kullback-Leibler information as a redundancy measure and InfoMax lead to the same solution if the parameterization of the output nonlinear functions in the latter method is sufficiently rich. Furthermore, this work discusses the alternative redundancy measures not based on the Kullback-Leibler information distance. The practical issues of applying ICA and InfoMax are also discussed and illustrated on the problem of extracting statistically independent factors from a linear, pixel-by-pixel mixture of images.	expectation–maximization algorithm;geographic information systems;independent computing architecture;independent component analysis;infomax;kullback–leibler divergence;nonlinear system;pixel;disease transmission	Dragan Obradovic;Gustavo Deco	1998	Neural Computation	10.1162/089976698300016972	infomax;independence;independent component analysis;linear independence;visual perception;information theory;computer science;artificial intelligence;machine learning;probability;mathematics;artificial neural network;statistics	ML	20.462027776425053	-27.992537363264027	82220
10fb517f285e12c0cf320ece197bbf0f365bdb5a	pairwise neural network classifiers with probabilistic outputs	handwriting recognition;posterior probability;neural network classifier;multi class classification;point of view;neural network	Multi-class classification problems can be efficiently solved by partitioning the original problem into sub-problems involving only two classes: for each pair of classes, a (potentially small) neural network is trained using only the data of these two classes. We show how to combine the outputs of the two-class neural networks in order to obtain posterior probabilities for the class decisions. The resulting probabilistic pairwise classifier is part of a handwriting recognition system which is currently applied to check reading. We present results on real world data bases and show that, from a practical point of view, these results compare favorably to other neural network approaches.	artificial neural network;database;handwriting recognition;multiclass classification;statistical classification	David Price;Stefan Knerr;Léon Personnaz;Gérard Dreyfus	1994			probabilistic neural network;computer science;recurrent neural network;machine learning;multiclass classification;pattern recognition;data mining;time delay neural network;handwriting recognition;posterior probability;artificial neural network	ML	14.06776729753703	-35.94514725370776	82276
3ce1efd3bd6d388b7b36b2435b4348a66c98b3d1	worst-case bounds for the logarithmic loss of predictors	individual sequence;info eu repo semantics workingpaper;weighted averaging;universal coding;metric entropy;upper bound;empirical processes;loss function;statistics econometrics and quantitative methods;empirical process theory;empirical process;minimax regret;universal prediction;on line learning	We investigate on-line prediction of individual sequences. Given a class of predictors, the goal is to predict as well as the best predictor in the class, where the loss is measured by the self information (logarithmic) loss function. The excess loss (regret) is closely related to the redundancy of the associated lossless universal code. Using Shtarkov's theorem and tools from empirical process theory, we prove a general upper bound on the best possible (minimax) regret. The bound depends on certain metric properties of the class of predictors. We apply the bound to both parametric and nonparametric classes of predictors. Finally, we point out a suboptimal behavior of the popular Bayesian weighted average algorithm.	algorithm;bell's theorem;kerrison predictor;loss function;lossless compression;minimax;offset binary;online and offline;regret (decision theory);self-information;universal code (data compression)	Nicolò Cesa-Bianchi;Gábor Lugosi	2001	Machine Learning	10.1023/A:1010848128995	econometrics;mathematical optimization;computer science;machine learning;mathematics;upper and lower bounds;empirical process;regret;statistics;loss function	ML	21.04631015515888	-30.67854784847374	82305
b761fb4ed1b68e673c6a2d3b26b42fe081dba4ef	is-asgd: accelerating asynchronous sgd using importance sampling		Variance reduction (VR) techniques for convergence rate acceleration of stochastic gradient descent (SGD) algorithm have been developed with great efforts recently. VR's two variants, stochastic variance-reduced-gradient (SVRG-SGD) and importance sampling (IS-SGD) have achieved remarkable progresses. Meanwhile, asynchronous SGD (ASGD) is becoming more critical due to the ever-increasing scale of the optimization problems. The application of VR in ASGD to accelerate its convergence rate has therefore attracted much interest and SVRG-ASGDs were proposed. However, we found that SVRG suffers dissatisfying performance in accelerating ASGD when datasets are sparse and large-scale. In such case, SVRG-ASGD's iterative computation cost is magnitudes higher than plain ASGD which makes it very inefficient. On the other hand, IS achieves improved convergence rate with few extra computation cost and is invariant to the sparsity of datasets. These advantages make it very suitable for the acceleration of ASGD on large-scale sparse datasets. In this paper we propose a novel IS-combined ASGD for efficient convergence rate acceleration, namely, IS-ASGD. We theoretically prove the superior convergence bound of IS-ASGD. Experimental results also demonstrate our statements.	algorithm;asynchronous circuit;code;computation;importance sampling;iterative method;mathematical optimization;rate of convergence;sampling (signal processing);sparse matrix;stochastic gradient descent;variance reduction	Fei Wang;Xiaofeng Gao;Jun Ye;Guihai Chen	2018		10.1145/3225058.3225135	rate of convergence;importance sampling;mathematical optimization;acceleration;distributed computing;variance reduction;asynchronous communication;stochastic gradient descent;computer science;optimization problem;convergence (routing)	ML	24.36438667688025	-34.18376344715891	82364
5f1b954d92bda3b9158d1d739a5d61ce336baa4d	estimation with two hidden layer neural nets	minimisation;least squares approximations;best approximation;convergence of numerical methods;neural networks least squares approximation ellipsoids approximation error convergence feedforward neural networks educational technology probability distribution risk analysis entropy;convergence rate;minimisation feedforward neural nets parameter estimation function approximation least squares approximations convergence of numerical methods;penalized least square;neural net;function approximation;mean square error;feedforward neural nets;parameter estimation;convex hull;minimisation function estimation feedforward neural networks convex hull target function mean square prediction error convergence rate penalized least squares probability;mean squared prediction error;neural network	Our presentation deals with function estimation by neural networks. Mean square error bounds are given for the case when the target function is in the convex hull of ellipsoids multiplied by a scalar constant. When the target function is not in this class but is bounded, we bound the difference between the mean square prediction error compared to the best approximation error of the target function (the expected regret). We also give a general theorem that gives the convergence rate of the expected regret when the functions are estimated by penalized least squares criteria.	approximation error;artificial neural network;convex hull;least squares;mean squared error;rate of convergence;regret (decision theory);smoothing spline	Gerald H. L. Cheang;Andrew R. Barron	1999		10.1109/IJCNN.1999.831522	minimisation;mathematical optimization;function approximation;computer science;convex hull;machine learning;mean squared prediction error;mathematics;mean squared error;rate of convergence;estimation theory;artificial neural network;statistics	ML	19.847171976648674	-29.955971670162505	82409
fccaa2fc0f2687dc9738e36d436b8e083b42819b	a novel elliptical basis function neural networks model based on a hybrid learning algorithm	hybrid learning;shape parameter;neural network model	In this paper, a novel elliptical basis function neural networks model (EBFNN) based on a hybrid learning algorithm (HLA) is proposed. Firstly, a geometry analytic algorithm is applied to construct the hyper-ellipsoid units of hidden layer of the EBFNN, i.e., initial the structure of the EBFNN. Then, the hybrid learning algorithm (HLA) is further applied to adjust the centers and the shape parameters. The experimental results demonstrated the proposed hybrid learning algorithm for the EBFNN model is feasible and efficient, and the EBFNN is not only parsimonious but also has better generalization performance than the RBFNN.	algorithm;algorithmic learning theory;artificial neural network;basis function	Ji-Xiang Du;Guojun Zhang;Zengfu Wang	2007		10.1007/978-3-540-72383-7_135	computer science;artificial intelligence;machine learning;pattern recognition;shape parameter;artificial neural network	ML	14.688400645088167	-28.776591677978995	82421
52ddbcb98512d079ac4d4fdd622ee95bd5b23858	probabilistic approach to neural networks computation based on quantum probability model probabilistic principal subspace analysis example	quantum probability;hebbian learning;learning algorithm;probabilistic approach;probabilistic model;science learning;quantum physics;density matrix;artificial neural network;on line learning;neural network;evolutionary computing	Abstract—In this paper, we introduce elements of probabilistic model that is suitable for modeling of learning algorithms in biologically plausible artificial neural networks framework. Model is based on two of the main concepts in quantum physics – a density matrix and the Born rule. As an example, we will show that proposed probabilistic interpretation is suitable for modeling of on-line learning algorithms for PSA, which are preferably realized by a parallel hardware based on very simple computational units. Proposed concept (model) can be used in the context of improving algorithm convergence speed, learning factor choice, or input signal scale robustness. We are going to see how the Born rule and the Hebbian learning rule are connected.	artificial neural network;bach's algorithm;born rule;computation;density matrix;graphics processing unit;hebbian theory;image scaling;independent computing architecture;independent component analysis;learning rule;locality of reference;mathematical optimization;online and offline;online machine learning;optimization problem;parallel computing;point of view (computer hardware company);polar surface area;principal component analysis;probabilistic turing machine;quantum mechanics;quantum probability;robustness (computer science);semiconductor industry;statistical model;symmetric-key algorithm	Marko V. Jankovic	2010	CoRR		semi-supervised learning;statistical model;probabilistic analysis of algorithms;quantum probability;wake-sleep algorithm;hebbian theory;probabilistic relevance model;computer science;artificial intelligence;theoretical computer science;density matrix;machine learning;deep learning;leabra;learning classifier system;competitive learning;computational learning theory;generalized hebbian algorithm;artificial neural network;divergence-from-randomness model	ML	13.427979553568683	-28.856756040368616	82600
ad57292f1016bc525d80485eecc817a588c5b0a1	adaptive sampling for convex regression		In this paper, we introduce the first principled adaptive-sampling procedure for learning a convex function in the L∞ norm, a problem that arises often in the behavioral and social sciences. We present a function-specific measure of complexity and use it to prove that, for each convex function f?, our algorithm nearly attains the information-theoretically optimal, function-specific error rate. We also corroborate our theoretical contributions with numerical experiments, finding that our method substantially outperforms passive, uniform sampling for favorable synthetic and data-derived functions in low-noise settings with large sampling budgets. Our results also suggest an idealized “oracle strategy”, which we use to gauge the potential advance of any adaptive-sampling strategy over passive sampling, for any given convex function.	adaptive sampling;algorithm;blum axioms;convex function;experiment;numerical analysis;oracle nosql db;sampling (signal processing);synthetic intelligence	Max Simchowitz;Kevin G. Jamieson;Jordan W. Suchow;Thomas L. Griffiths	2018	CoRR		mathematical optimization;oracle;sampling (statistics);regular polygon;word error rate;mathematics;convex function;adaptive sampling	ML	23.694691893713888	-31.76092835717577	82823
aca710e040050dea5413a9e4ec26c281ea835a73	attractor dynamics in an electronic neural network	learning algorithm;algorithme apprentissage;capacidad memoria;microelectronique;microelectronica;capacite memoire;memory capacity;attractor neural network;microelectronics;reseau neuronal;algoritmo aprendizaje;red neuronal;neural network	LANN is an electronic device implementing in discrete elec tronics a neurons fully connected attractor neural network with stochas tic learning We summarize in this paper some key features emerged by extensive tests performed to elucidate the neuronal collective dynamics the learning dynamics and the memory capacity of the LANN device	artificial neural network;electrical engineering	Paolo Del Giudice;Stefano Fusi	1997		10.1007/BFb0020325	simulation;computer science;artificial intelligence;machine learning;microelectronics;artificial neural network	ML	15.789786249956963	-26.92370351593746	82874
cba8b7e82649474e71ebb029339b7504674888cb	nonlinear system identification based on an improved support vector regression estimator	nonlinear system identification;support vector regression	  An improved support vector regression estimator is presented for identifying nonlinear dynamic systems in which the states  and the control inputs are separable. The proposed method contains two nonlinear functions with respect to the states and  the control inputs respectively. Thus it can be used to estimate the two nonlinear functions in the separable nonlinear dynamic  system. The experimental results validate the efficiency of our method.    	nonlinear system identification;support vector machine	Li Zhang;Yugeng Xi	2004		10.1007/978-3-540-28647-9_96	support vector machine;computer science;machine learning;bayesian multivariate linear regression;polynomial regression;nonlinear system identification;relevance vector machine	ML	15.225268368558783	-28.552696578915782	82960
052816bbd6571929afa4d2eb483e53f305746012	efficient learning in multi-layered perceptron using the grow-and-learn algorithm	learning process;learning algorithm;hybrid system;back propagation algorithm;multi layer perceptron;back propagation	The well-known Multi-Layered Perceptron has gained power thanks to the Back Propagation Algorithm. The difficulty which still subsists is its time-wasting. In fact, the learning process can be improved by using the Grow-And-Learn (GAL) algorithm. In this paper, we present such a hybrid system: the cooperation between GAL and MLP networks. The obtained system is more rapid and more efficient than the classic Back Propagation which computes on the MLP.	algorithm;perceptron	Gildas Cherruel;Bassel Solaiman;Yvon Autret	1995		10.1007/3-540-60428-6_34	winnow;wake-sleep algorithm;computer science;artificial intelligence;backpropagation;perceptron;machine learning;pattern recognition;multilayer perceptron;hybrid system	NLP	13.75957649751898	-28.74287130850029	83285
c6ea7840aba1f88761b2cd3f8f31ba8c902471f7	hybridsom: a generic rule extraction framework for self-organizing feature maps	unsupervised learning;high dimensionality;gain;training;rule extraction;data mining;customized hybrid rule extractor generic rule extraction framework self organizing feature maps unsupervised neural network;generic rule extraction framework;self organising feature maps;self organizing feature maps;self organized feature map;unsupervised learning self organising feature maps;unsupervised neural network;data mining training data neurons neural networks helium humans data analysis statistical analysis guidelines computational intelligence;neurons;iris;algorithm design and analysis;labeling;customized hybrid rule extractor	The self-organizing feature map (SOM) is an unsupervised neural network. It preserves a high-dimensional training data space's approximate characteristics, while scaling it to a two-dimensional grid. Few SOM-based rule extraction methods exist, and little analysis has been done on their overall viability. This paper presents the novel HybridSOMframework, which allows the combination of a SOM with any standard rule extraction algorithm, creating a customized hybrid rule extractor. Some HybridSOMvariations and traditional rule extraction algorithms are empirically compared, and the framework is critically discussed. This analysis also points to new conclusions on the viability of SOM-based rule extraction, in general.	approximation algorithm;artificial neural network;dataspaces;image scaling;organizing (structure);randomness extractor;rule induction;self-organization;self-organizing map	Willem S. van Heerden;Andries Petrus Engelbrecht	2009	2009 IEEE Symposium on Computational Intelligence and Data Mining	10.1109/CIDM.2009.4938624	unsupervised learning;algorithm design;labeling theory;gain;computer science;machine learning;pattern recognition;data mining	AI	12.589269385424856	-34.92369781294944	83366
714a8206d1c4f642517d0a7af71570c7a2a48fa5	learning dynamic bayesian networks from multivariate time series with changing dependencies	bayes estimation;modelo dinamico;cambio variable;book chapter;real time;dynamic model;intelligence artificielle;time series;multivariate time series;reseau bayes;estimacion bayes;red bayes;dynamic bayesian network;temps reel;modele dynamique;changement variable;serie temporelle;bayes network;serie temporal;tiempo real;artificial intelligence;dependence structure;modele donnee;inteligencia artificial;variable transformation;data models;estimation bayes	Many examples exist of multivariate time series where dependencies between variables change over time. If these changing dependencies are not taken into account, any model that is learnt from the data will average over the different dependency structures. Paradigms that try to explain underlying processes and observed events in multivariate time series must explicitly model these changes in order to allow non-experts to analyse and understand such data. In this paper we have developed a method for generating explanations in multivariate time series that takes into account changing dependency structure. We make use of a dynamic Bayesian network model with hidden nodes. We introduce a representation and search technique for learning such models from data and test it on synthetic time series and real-world data from an oil refinery, both of which contain changing underlying structure. We compare our method to an existing EM-based method for learning structure. Results are very promising for our method and we include sample explanations, generated from models learnt from the refinery dataset.	control engineering;dependency grammar;deterministic algorithm;dynamic bayesian network;markov chain;network model;simulated annealing;smoothing;swift (programming language);synthetic intelligence;time series	Allan Tucker;Xiaohui Liu	2003		10.1007/978-3-540-45231-7_10	data modeling;econometrics;computer science;artificial intelligence;machine learning;time series;bayesian network;dynamic bayesian network;statistics	AI	22.287849476101492	-24.183299201744024	83433
3239233b0efa53fbe5e8dd50094310beb6afbb83	designing and building the mlpack open-source machine learning library		mlpack is an open-source C++ machine learning library with an emphasis on speed and flexibility. Since its original inception in 2007, it has grown to be a large project implementing a wide variety of machine learning algorithms, from standard techniques such as decision trees and logistic regression to modern techniques such as deep neural networks as well as other recently-published cutting-edge techniques not found in any other library. mlpack is quite fast, with benchmarks showing mlpack outperforming other libraries’ implementations of the same methods. mlpack has an active community, with contributors from around the world—including some from PUST. This short paper describes the goals and design of mlpack, discusses how the open-source community functions, and shows an example usage of mlpack for a simple data science problem.	algorithm;artificial neural network;c++;data science;decision tree;deep learning;http 404;logistic regression;machine learning;open-source software;mlpack	Ryan R. Curtin;Marcus Edel	2017	CoRR		theoretical computer science;artificial neural network;computer science;implementation;logistic regression;decision tree;machine learning;artificial intelligence	ML	12.411264590492863	-37.02525263577861	84069
ea8db1347bf4a33f91e61180ed8f78fa53866a5a	ms-baco: a new model selection algorithm using binary ant colony optimization for neural complexity and error reduction		Stabilizing the complexity of Feedforward Neural Networks (FNNs) for the given approximation task can be managed by defining an appropriate model magnitude which is also greatly correlated with the generalization quality and computational efficiency. However, deciding on the right level of model complexity can be highly challenging in FNN applications. In this paper, a new Model Selection algorithm using Binary Ant Colony Optimization (MS-BACO) is proposed in order to achieve the optimal FNN model in terms of neural complexity and cross-entropy error. MS-BACO is a metaheuristic algorithm that treats the problem as a combinatorial optimization problem. By quantifying both the amount of correlation exists among hidden neurons and the sensitivity of the FNN’s output to the hidden neurons using a sample-based sensitivity analysis method called, extended Fourier amplitude sensitivity test, the algorithm mostly tends to select the FNN model containing hidden neurons with most distinct hyperplanes and high contribution percentage. Performance of the proposed algorithm with three different designs of heuristic information is investigated. Comparison of the findings verifies that the newly introduced algorithm is able to provide more compact and accurate FNN model.	ant colony optimization algorithms;approximation;combinatorial optimization;computation;cross entropy;fast fourier transform;feedforward neural network;heuristic;mathematical optimization;metaheuristic;microsoft windows;model selection;optimization problem;selection algorithm	Saman Sadeghyan;Shahrokh Asadi	2018	CoRR		machine learning;hyperplane;fourier transform;mathematical optimization;combinatorial optimization;artificial intelligence;ant colony optimization algorithms;feedforward neural network;model selection;magnitude (mathematics);heuristic;algorithm;computer science	ML	14.432251655396911	-24.217703218403084	84092
305d7c097626617cf1f5437664fd523c8abd23c5	design choices and theoretical issues for relative feature importance, a metric for nonparametric discriminatory power	discriminator;analisis estadistico;methode non parametrique;analisis forma;extraction forme;clasificador;classifier;metodo no parametrico;statistical analysis;extraccion forma;feature extraction;analyse statistique;pattern classification;pattern recognition;classificateur;non parametric method;feature selection;discriminador;pattern analysis;discriminateur;reconnaissance forme;feature analysis;reconocimiento patron;pattern extraction;analyse forme;classification forme	We have developed relative feature importance (RFI), a metric for the classifier-independent ranking of features. Previously, we have shown the metric to rank accurately features for a wide variety of artificial and natural problems, for both two-class and multi-class problems. In this paper, we present the design of the metric, including both theoretical considerations and statistical analysis of the possible components.		Hilary J. Holz;Murray H. Loew	2000		10.1007/3-540-44522-6_72	pattern recognition;classifier;feature extraction;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;feature selection;statistics	Vision	10.723681064092158	-35.032330414203514	84288
899746ba46279cf2b842615ed38d998f9c4654df	a pac-bayesian bound for lifelong learning		Transfer learning has received a lot of attention in the machine learning community over the last years, and several effective algorithms have been developed. However, relatively little is known about their theoretical properties, especially in the setting of lifelong learning, where the goal is to transfer information to tasks for which no data have been observed so far. In this work we study lifelong learning from a theoretical perspective. Our main result is a PAC-Bayesian generalization bound that offers a unified view on existing paradigms for transfer learning, such as the transfer of parameters or the transfer of low-dimensional representations. We also use the bound to derive two principled lifelong learning algorithms, and we show that these yield results comparable with existing methods.	algorithm;bayesian network;exptime;farkas' lemma;kullback–leibler divergence;machine learning;markov chain;multimodal interaction;observable;social inequality;word lists by frequency	Anastasia Pentina;Christoph H. Lampert	2014			multi-task learning;instance-based learning;error-driven learning;algorithmic learning theory;simulation;computer science;artificial intelligence;machine learning;inductive transfer;stability;computational learning theory	ML	20.568491646352214	-32.01936779904011	84604
8f2e53f4552197b3e9ba70ed6be8e2d6113028c4	connectionist-symbolic machine intelligence using cellular automata based reservoir-hyperdimensional computing		We introduce a novel framework of reservoir computing, that is capable of both connectionist machine intelligence and symbolic computation. Cellular automaton is used as the reservoir of dynamical systems. Input is randomly projected onto the initial conditions of automaton cells and nonlinear computation is performed on the input via application of a rule in the automaton for a period of time. The evolution of the automaton creates a space-time volume of the automaton state space, and it is used as the reservoir. The proposed framework is capable of long short-term memory and it requires orders of magnitude less computation compared to Echo State Networks. We prove that cellular automaton reservoir holds a distributed representation of attribute statistics, which provides a more effective computation than local representation. It is possible to estimate the kernel for linear cellular automata via metric learning, that enables a much more efficient distance computation in support vector machine framework. Also, binary reservoir feature vectors can be combined using Boolean operations as in hyperdimensional computing, paving a direct way for concept building and symbolic processing.	artificial intelligence;artificial neural network;automata theory;cellular automaton;connectionism;dynamical system;echo state network;initial condition;long short-term memory;nonlinear system;randomness;reservoir computing;state space;support vector machine;symbolic computation	Özgür Yilmaz	2015	CoRR		model of computation;stochastic cellular automaton;reversible cellular automaton;block cellular automaton;nested stack automaton;elementary cellular automaton;continuous spatial automaton;computer science;artificial intelligence;theoretical computer science;asynchronous cellular automaton;two-way deterministic finite automaton;deterministic finite automaton;probabilistic automaton;machine learning;continuous automaton;deterministic automaton;reservoir computing;mobile automaton;timed automaton;pushdown automaton;algorithm	AI	13.884444358875658	-27.764734628171272	84855
baf3fe69cb1061ba36b4c4534fc9c88d3f03cde4	electing the most probable without eliminating the irrational: voting over intransitive domains		Picking the best alternative in a given set is a well-studied problem at the core of social choice theory. In some applications, one can assume that there is an objectively correct way to compare the alternatives, which, however, cannot be observed directly, and individuals’ preferences over the alternatives (votes) are noisy estimates of this ground truth. The goal of voting in this case is to estimate the ground truth from the votes. In this paradigm, it is usually assumed that the ground truth is a ranking of the alternatives by their true quality. However, sometimes alternatives are compared using not one but multiple quality parameters, which may result in cycles in the ground truth as well as in the preferences of the individuals. Motivated by this, we provide a formal model of voting with possibly intransitive ground truth and preferences, and investigate the maximum likelihood approach for picking the best alternative in this case. We show that the resulting framework leads to polynomial-time algorithms, and also approximates the correspondingNP-hard problems in the classic framework.	algorithm;formal language;ground truth;polynomial;programming paradigm;time complexity	Edith Elkind;Nisarg Shah	2014			data mining;mathematics	Web+IR	23.406291720395146	-26.039946747384516	84923
55f7028c13c1312da9739ba31ff24c94368879eb	using javasane to evolve neural network rainfall-runoff models			artificial neural network;typset and runoff	Linda M. See;Robert J. Abrahart;Alison J. Heppenstall	2005			machine learning;pattern recognition;computer science;artificial intelligence;artificial neural network;surface runoff;precipitation	ML	10.811849122655437	-24.939297977563843	85001
4109374aadc70645dedb1c2285e42de61900d918	one-d-r-a-g-som and its application to a hand shape instruction learning system	pl g som;reinforcement learning;hmi;som;hand shape instruction	In this paper, a novel self-organizing map (SOM) named “One-D-R-A-G-SOM” is proposed. It is a kind of one dimensional ring type growing SOM using asymmetric neighborhood function. As the topology of one dimensional ring type feature map is more suitable to increase or decrease the number of units, and the disorder of the map is available to be solved by the asymmetric neighborhood function, the proposed model gives priority of learning performance to the conventional two dimensional growing SOM. Additionally, One-D-R-A-G-SOM is introduced to a hand shape recognition and instruction learning system. Experiment results showed the effectiveness of the novel system comparing with systems using the conventional SOMs.		Takashi Kuremoto;Takuhiro Otani;Shingo Mabu;Masanao Obayashi;Kunikazu Kobayashi	2014	IJNDC	10.2991/ijndc.2014.2.3.6	computer vision;engineering;artificial intelligence;machine learning	ML	14.12473845624257	-32.047364116706845	85768
29e47b9c4fa348098c0a41f65b12728dfae2a2a6	recurrent fuzzy neural computation: modeling, learning and application	fuzzy rule based system;fuzzy neural network;nonlinear dynamic systems;t norms;neural model;fuzzy neurons;computer model;nonlinear dynamical systems;recurrent fuzzy neural computation;inference mechanisms;fuzzy sets;recurrent fuzzy neural network;artificial neural networks;finite impulse response;computer experiment;network connectivity;gradient descent;networked learning;network model;fuzzy inference;recurrent neurofuzzy network;gradient methods;s norms;vector quantisation fuzzy systems gradient methods inference mechanisms knowledge based systems nonlinear dynamical systems recurrent neural nets;vector quantizer;recurrent neural nets;neurons;recurrent neural networks;network structure;neurons artificial neural networks fuzzy sets fuzzy neural networks recurrent neural networks laser modes;network learning;fuzzy neural networks;vector quantisation;gradient projection method;modified vector quantization approach;laser modes;fuzzy systems;knowledge based systems;fuzzy system;nonlinear dynamic system;nonlinear dynamic systems recurrent fuzzy neural computation recurrent neurofuzzy network fuzzy system fuzzy neurons t norms s norms fuzzy rule based system fuzzy inference network learning modified vector quantization approach gradient descent gradient projection method recurrent fuzzy neural network;neural network	A novel recurrent neurofuzzy network is developed in this paper. The network model is composed by two strucutres: a fuzzy system and a neural network. The fuzzy system contains fuzzy neurons modeled using t-norms and s-norms. The neural network is composed by nonlinear elements placed in series with the fuzzy system. The network model implicitly encodes a fuzzy rule-based system and its recurrent multilayered structure performs fuzzy inference. The topology induces a clear relationship between the network structure and the associated fuzzy rule-based system. Network learning involves three main steps. The first step uses a modified vector quantization approach to granulate the input universes. The next step assembles the network connections and their initial, randomly chosen weights. The third step uses two main paradigms to update the network weights: gradient descent and gradient projection method. The recurrent fuzzy neural network is particularly suitable to model nonlinear dynamic systems and to learn sequences. Computational experiment with a classic prediction problem benchmark shows that the fuzzy neural model outperforms a finite impulse response neural network.	approximation algorithm;artificial neural network;benchmark (computing);computation;dynamical system;experiment;field electron emission;finite impulse response;fuzzy control system;fuzzy logic;fuzzy rule;fuzzy set;gradient descent;kerrison predictor;logic programming;network model;neuro-fuzzy;neuron;nonlinear system;randomness;recurrent neural network;requirement;rule-based system;series and parallel circuits;set theory;simulation;synaptic package manager;systems modeling;t-norm;vector quantization	Rosangela Ballini;Fernando A. C. Gomide	2010	International Conference on Fuzzy Systems	10.1109/FUZZY.2010.5584099	gradient descent;feedforward neural network;probabilistic neural network;computer experiment;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;computer science;artificial intelligence;fuzzy number;recurrent neural network;neuro-fuzzy;network model;machine learning;finite impulse response;control theory;time delay neural network;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;artificial neural network;fuzzy control system	AI	14.473343563269585	-27.393281708762792	85850
03b0e4cc22376f470fe8125e3c813f6f3abac27c	bayesian policy search with policy priors	structured policy;meta search bias;policy prior;search bias;bayesian policy search;abstract knowledge;adaptive search algorithm;latent variable;abstract prior knowledge;hill-climbing policy search algorithm;optimal policy	We consider the problem of learning to act in partially observable, continuous-state-and-action worlds where we have abstract prior knowledge about the structure of the optimal policy in the form of a distribution over policies. Using ideas from planning-as-inference reductions and Bayesian unsupervised learning, we cast Markov Chain Monte Carlo as a stochastic, hill-climbing policy search algorithm. Importantly, this algorithm’s search bias is directly tied to the prior and its MCMC proposal kernels, which means we can draw on the full Bayesian toolbox to express the search bias, including nonparametric priors and structured, recursive processes like grammars over action sequences. Furthermore, we can reason about uncertainty the search bias itselfby constructing a hierarchical prior and reasoning about latent variables that determine the abstract structure of the policy. This yields an adaptive search algorithm—our algorithm learns to learna structured policy efficiently. We show how inference over the latent variables in these policy priors enables intraand intertask transfer of abstract knowledge. We demonstrate the flexibility of this approach by learning meta search biases, by constructing a nonparametric finite state controller to model memory, by discovering motor primitives using a simple grammar over primitive actions, and by combining all three.	computation;encode;generic programming;latent variable;markov chain monte carlo;modeling language;monte carlo method;partially observable system;recursion;sampling (signal processing);search algorithm;stochastic hill climbing;unsupervised learning	David Wingate;Noah D. Goodman;Daniel M. Roy;Leslie Pack Kaelbling;Joshua B. Tenenbaum	2011		10.5591/978-1-57735-516-8/IJCAI11-263	computer science;artificial intelligence;machine learning;pattern recognition;data mining;statistics	AI	23.82993774565464	-27.95593325042771	86136
17351cfeac949c266f4d1ff86c515250b931bdc2	structure learning via parameter learning	structure learning;personalized pagerank;probabilistic prolog	A key challenge in information and knowledge management is to automatically discover the underlying structures and patterns from large collections of extracted information. This paper presents a novel structure-learning method for a new, scalable probabilistic logic called ProPPR. Our approach builds on the recent success of meta-interpretive learning methods in Inductive Logic Programming (ILP), and we further extends it to a framework that enables robust and efficient structure learning of logic programs on graphs: using an abductive second-order probabilistic logic, we show how first-order theories can be automatically generated via parameter learning. To learn better theories, we then propose an iterated structural gradient approach that incrementally refines the hypothesized space of learned first-order structures. In experiments, we show that the proposed method further improves the results, outperforming competitive baselines such as Markov Logic Networks (MLNs) and FOIL on multiple datasets with various settings; and that the proposed approach can learn structures in a large knowledge base in a tractable fashion.	abductive reasoning;cobham's thesis;experiment;first-order predicate;gradient;inductive logic programming;inductive reasoning;iteration;knowledge base;knowledge management;markov chain;markov logic network;scalability;theory	William Yang Wang;Kathryn Mazaitis;William W. Cohen	2014		10.1145/2661829.2662022	natural language processing;probabilistic ctl;statistical relational learning;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;database;probabilistic logic;world wide web;information retrieval	AI	17.242548461432197	-34.95685068210777	86275
12baeacf49334dc2ae7ec3001c81a5080098cded	data preprocessing for soft sensor using generative adversarial networks		Soft sensors have been widely used in industrial processes in the past two decades, using easy-to-measure process variables to predict hard-to-measure ones. Sufficient training data can significantly improve the prediction performance as well as speed up the computation with low cost in the modeling process of the soft sensor. However, data collection is often difficult due to the harsh environment of the industrial process. Generative adversarial networks (GANs) is a prominent method for learning generative models in recent years. In this paper, a generative model named DWGAN based on improved Wasserstein generative adversarial networks (WGAN) is proposed to generate new samples for soft sensors. For evaluating the proposed method, a practical industrial experiment is studied in the case of paucity of data, and three other state-of-the-art generative models are adopted for comparison. The experimental results show that the samples yielded by the proposed method behave more similarly with the real samples compared to samples provided by other methods. Additionally, these synthetic samples can make the training data sufficient and significantly improve the prediction accuracy of the soft sensors.		Xiao Wang	2018	2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)	10.1109/ICARCV.2018.8581249	data collection;control engineering;generative grammar;speedup;computation;adversarial system;machine learning;data pre-processing;generative model;computer science;soft sensor;artificial intelligence	Robotics	16.65359881282613	-33.484133127597005	86395
4f81fa50f526fd2b1527bee2e0275887445ab587	the bayes-optimal feature extraction procedure for pattern recognition using genetic algorithm	bayes estimation;modelizacion;optimal solution;solution optimale;analisis estadistico;extraction forme;probabilistic approach;algoritmo genetico;classification;modelisation;estimacion bayes;statistical analysis;extraccion forma;enfoque probabilista;approche probabiliste;feature extraction;solucion optima;analyse statistique;statistical pattern recognition;algorithme genetique;pattern recognition;genetic algorithm;reconnaissance forme;extraction caracteristique;reseau neuronal;reconocimiento patron;modeling;pattern extraction;clasificacion;red neuronal;estimation bayes;neural network	The paper deals with the extraction of features for statistical pattern recognition. Bayes probability of correct classification is adopted as the extraction criterion. The problem with complete probabilistic information is discussed and Bayes-optimal feature extraction procedure is presented in detail. The case of recognition with learning is also considered. As method of solution of optimal feature extraction a genetic algorithm is proposed. A numerical example demonstrating capability of proposed approach to solve feature extraction problem is presented.	feature extraction;genetic algorithm;pattern recognition	Marek Kurzynski;Edward Puchala;Aleksander Rewak	2006		10.1007/11840817_3	systems modeling;genetic algorithm;feature;feature extraction;biological classification;computer science;artificial intelligence;machine learning;kanade–lucas–tomasi feature tracker;pattern recognition;k-nearest neighbors algorithm;feature;artificial neural network;dimensionality reduction	Vision	11.052056768271905	-34.127930749504436	86685
082ae4a31c15881fd33aff50be3ceb1a65720e46	greed is good if randomized: new inference for dependency parsing	article	Dependency parsing with high-order features results in a provably hard decoding problem. A lot of work has gone into developing powerful optimization methods for solving these combinatorial problems. In contrast, we explore, analyze, and demonstrate that a substantially simpler randomized greedy inference algorithm already suffices for near optimal parsing: a) we analytically quantify the number of local optima that the greedy method has to overcome in the context of first-order parsing; b) we show that, as a decoding algorithm, the greedy method surpasses dual decomposition in second-order parsing; c) we empirically demonstrate that our approach with up to third-order and global features outperforms the state-of-the-art dual decomposition and MCMC sampling methods when evaluated on 14 languages of non-projective CoNLL datasets.1	emoticon;first-order predicate;greedy algorithm;lagrangian relaxation;local optimum;markov chain monte carlo;mathematical optimization;parsing;randomized algorithm;sampling (signal processing)	Yuan Zhang;Tao Lei;Regina Barzilay;Tommi S. Jaakkola	2014			computer science;artificial intelligence;data mining;algorithm	NLP	24.220509205651382	-32.48206880993605	86693
f3f974d13b00330d66c053a7a013a831c33326fc	learning with globally predictive tests	understandability;learning model;rule learning;bias	We introduce a new bias for rule learning systems. The bias only allows a rule learner to create a rule that predicts class membership if each test of the rule in isolation is predictive of that class. Although the primary motivation for the bias is to improve the understandability of rules, we show that it also improves the accuracy of learned models on a number of problems. We also introduce a related preference bias that allows creating rules that violate this restriction if they are statistically significantly better than alternative rules without such violations.	algorithm;biasing;iteration;machine learning;preference learning;synthetic data	Michael J. Pazzani	2000	New Generation Computing	10.1007/BF03037566	inductive bias;computer science;machine learning;bias;data mining	ML	16.3298522194362	-36.62394657681053	86728
dd06e62d03a065823c52c7a6b5a4500d7d67ef8f	consistent optimization of ams by logistic loss minimization		In this paper, we theoretically justify an approach popular among participants of the Higgs Boson Machine Learning Challenge to optimize approximate median significance (AMS). The approach is based on the following two-stage procedure. First, a real-valued function f is learned by minimizing a surrogate loss for binary classification, such as logistic loss, on the training sample. Then, given f , a threshold θ̂ is tuned on a separate validation sample, by direct optimization of AMS. We show that the regret of the resulting classifier (obtained from thresholding f on θ̂) measured with respect to the squared AMS, is upperbounded by the regret of f measured with respect to the logistic loss. Hence, we prove that minimizing logistic surrogate is a consistent method of optimizing AMS.	approximation algorithm;binary classification;loss function;loss functions for classification;machine learning;mathematical optimization;regret (decision theory);thresholding (image processing);vhdl-ams;verilog-ams	Wojciech Kotlowski	2014			econometrics;mathematical optimization;mathematics;statistics	ML	21.37738838172264	-36.371741175355524	86732
bee087d0981b907f344ddd856a9410dad3e78b8a	neural networks for solving on-line outlier detection problems	metodo cuadrado menor;simulation ordinateur;modelizacion;methode moindre carre;optimisation;algorithm performance;least squares method;optimizacion;surveillance;edge detection;real time;algoritmo recursivo;metodo penalidad;outlier;intelligence artificielle;outlier detection;deteccion contorno;modelisation;observacion aberrante;detection contour;penalty method;process monitoring;vigilancia;methode penalite;algorithme recursif;monitoring;resultado algoritmo;temps reel;least square;performance algorithme;optimality criteria;tiempo real;observation aberrante;artificial intelligence;optimization;recursive algorithm;simulacion computadora;inteligencia artificial;monitorage;reseau neuronal;high throughput;monitoreo;modeling;real time application;computer simulation;red neuronal;neural network	To implement on-line process monitoring techniques, a neural network approach to the on-line solution of outlier detection is considered. The first technique is based on the determination of the predictor coefficients on the variables. The coefficients are then solved using least squares (LS) optimization criteria. The second technique is a standard penalty method implemented as an analog neural network. A recursive algorithm is developed for estimating the weights of the ANN and parameters of LS model. The validity and performance of the proposed algorithms has been verified by computer simulation experiments. The analog neural networks are deemed to be particularly well suited for high throughput, real time applications.	algorithm;anomaly detection;coefficient;computer simulation;experiment;kerrison predictor;least squares;mathematical optimization;neural networks;online and offline;penalty method;recursion (computer science);throughput	Tianqi Yang	2005		10.1007/11427469_73	computer simulation;simulation;computer science;artificial intelligence;machine learning;least squares;artificial neural network;algorithm;statistics	ML	19.394553449994973	-26.23086594962149	87007
74a9a21d9e04a02af9b568618e94ace079a616b6	sparsityboost: a new scoring function for learning bayesian network structure		We give a new consistent scoring function for structure learning of Bayesian networks. In contrast to traditional approaches to scorebased structure learning, such as BDeu or MDL, the complexity penalty that we propose is data-dependent and is given by the probability that a conditional independence test correctly shows that an edge cannot exist. What really distinguishes this new scoring function from earlier work is that it has the property of becoming computationally easier to maximize as the amount of data increases. We prove a polynomial sample complexity result, showing that maximizing this score is guaranteed to correctly learn a structure with no false edges and a distribution close to the generating distribution, whenever there exists a Bayesian network which is a perfect map for the data generating distribution. Although the new score can be used with any search algorithm, we give empirical results showing that it is particularly effective when used together with a linear programming relaxation approach to Bayesian network structure learning.	bayesian network;data dependency;linear programming relaxation;mdl (programming language);polynomial;sample complexity;scoring functions for docking;search algorithm	Eliot Brenner;David A Sontag	2013	CoRR		machine learning;pattern recognition;mathematics;statistics	ML	24.339758107182554	-28.52267113094844	87019
dac2355f7f54640a9e5b7beb2f785d4134984227	pattern selection for support vector regression based on sparseness and variability	support vector machines;time complexity;support vector regression;data mining;deterministic algorithms;machine learning;function approximation;stochastic processes;support vector machines support vector machine classification quadratic programming risk management static var compensators machine learning data mining stochastic processes artificial neural networks learning systems;pattern recognition;support vector machines data mining deterministic algorithms learning artificial intelligence pattern recognition regression analysis stochastic processes;regression analysis;support vector machine;learning artificial intelligence;neural networks pattern selection support vector regression sparseness variability support vector machine machine learning data mining cubic time complexity uniqueness deterministic algorithms stochastic algorithms;neural network	Support Vector Machine has been well received in machine learning community with its theoretical as well as practical value. However, since its training time complexity is cubic, its use is limited in data mining involving problems with a huge pattern set with a cubic time complexity of its training time. In this paper, we propose a pattern selection method for support vector regression (SVR), using notions of sparseness, variability and uniqueness. Two versions of algorithms, deterministic and stochastic, are presented, which are then applied to an artificial data set and two well known real world data sets. Preliminary results justify further investigation. The proposed method should work well with non-SVM function approximators such as neural networks.	algorithm;artificial neural network;cubic function;data mining;heart rate variability;machine learning;neural coding;spatial variability;support vector machine;time complexity	Jiyoung Sun;Sungzoon Cho	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.246737	stochastic process;support vector machine;computer science;machine learning;pattern recognition;data mining;artificial neural network	ML	15.631441011337252	-33.400344117746904	87101
8b0bce23c67216ad9248d42ecb6b0a324bdd6ebe	prediction intervals in supervised learning for model evaluation and discrimination	reliability and robustness;visualization techniques and methodology;machine learning;statistical computing;prediction intervals;prediction aggregation	In this paper we explore prediction intervals and how they can be used for model evaluation and discrimination in the supervised regression setting of medium sized datasets. We review three different methods for making prediction intervals and the statistics used for their evaluation. How the prediction intervals look like, how different methods behave and how the prediction intervals can be utilized for the graphical evaluation of models is illustrated with the help of simple datasets. Afterwards we propose a combined method for making prediction intervals and explore its performance with two voting schemes for combining predictions of a diverse ensemble of models. All methods are tested on a large set of datasets on which we evaluate individual methods and aggregated variants for their abilities of selecting the best predictions. The analysis of correlations between the root mean squared error and our evaluation statistic show that both stability and reliability of the results increase as the techniques get more elaborate. We confirm that the methodology is suitable for the graphical comparison of individual models and is a viable way of discriminating among model candidates.	batch processing;bayesian network;data structure;display resolution;ensemble learning;expectation–maximization algorithm;graphical user interface;heart rate variability;heuristic (computer science);mean squared error;online and offline;online machine learning;ordered weighted averaging aggregation operator;overfitting;supervised learning;time complexity;web analytics	Darko Pevec;Igor Kononenko	2014	Applied Intelligence	10.1007/s10489-014-0632-z	prediction interval;computer science;machine learning;data mining;confidence and prediction bands;computational statistics	NLP	15.905788860794258	-37.46470006713078	87340
2388a77111f3bbd4e0673d1114df81444bb6c733	modèles de réseaux de neurones pour l'analyse des séries temporelles ou la régression - estimation, identification, méthode d'élagage ssm	asymptotic statistics;metodo paso a paso;statistical stepwise;step by step method;analisis estadistico;multilayer perceptrons;time series;asymptotic behavior;comportement asymptotique;network analysis;perceptron multicouche;comportamiento asintotico;analisis regresion;statistical analysis;identification;analyse statistique;serie temporelle;methode pas a pas;estimacion parametro;serie temporal;analyse regression;identificacion;regression analysis;parameter estimation;estimation parametre;learning artificial intelligence;reseau neuronal;analyse circuit;article;red neuronal;analisis circuito;neural network;almost sure identification;apprentissage intelligence artificielle	This paper deals with neural network modeling for time series analysis or regression. Based on recent results about the least-square estimation for non-linear time series, we propose a complete and feasible methodology for both parameter estimation (learning process) and model selection (architecture selection). In particular, we solve the pruning problem for multilayer perceptron models with a stepwise search method by using a BIC criterion which is proved to be consistent.	akaike information criterion;artificial neural network;bayesian information criterion;estimation theory;linear algebra;model selection;multilayer perceptron;nonlinear system;soft systems methodology;stepwise regression;time complexity;time series	Joseph Rynkiewicz;Marie Cottrell;Morgan Mangeas;Jian-Feng Yao	2001	Revue d'Intelligence Artificielle	10.3166/ria.15.317-332	identification;asymptotic analysis;network analysis;computer science;artificial intelligence;time series;estimation theory;artificial neural network;regression analysis;statistics	ML	20.491892143270533	-28.797898627578153	87481
1d931c30f53a2fe48348c9ac6c218846259e25c3	modeling cortical maps with feed-backs	biological neural networks retina biology computing computer vision neural networks computer networks convergence computer architecture biological information theory image edge detection;biology computing;partial differential equation;winner take all mechanism cortical map neural network regularization mechanism partial differential equation nonlinear map computation;optimization problem;partial differential equations;neurophysiology;winner take all;partial differential equations biology computing neurophysiology;neural network	"""High-level specification of how the brain represents and categorizes the causes of its sensory input allows to link """"what is to be done"""" (perceptual task) with """"how to do it"""" (neural network calculation). More precisely, a general class of cortical map computations can be specified representing what is to be done as an optimization problem, in order to derive the related neural network parameters considering regularization mechanisms (implemented using so-called partial-differential-equations). The present contribution revisits this framework with three add-ons. It is generalized to a larger class of (non-linear) map computations, including winner-take-all mechanisms. The capability to represent standard """"analog"""" neural network and guaranty their convergence, providing their weights are local and unbiased, is made explicit. The fact that not only one but several cortical maps can interact, with feed-backs, in a stable way is shown. Two experiments are provided as an illustration of this general framework."""	approximation;artificial neural network;coefficient;compiler;computation;experiment;high- and low-level;input impedance;map;mathematical optimization;matrix regularization;nonlinear system;optimization problem;resistive touchscreen;simulation;spiking neural network;synaptic package manager;synaptic weight;winner-take-all (computing)	Thierry Viéville;Pierre Kornprobst	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.246667	cellular neural network;computer science;artificial intelligence;theoretical computer science;machine learning;time delay neural network;mathematics;neurophysiology;partial differential equation;artificial neural network	Robotics	17.70690732223159	-25.29187557639658	87613
1f66351bbbee896067e5d09dd9dcf747a8ef0e87	on the window size for classification in changing environments	streaming data;concept drift;moving window size;training sample size	Classification in changing environments (commonly known as concept drift) requires adaptation of the classifier to accommodate the changes. One approach is to keep a moving window on the streaming data and constantly update the classifier on it. Here we consider an abrupt change scenario where one set of probability distributions of the classes is instantly replaced with another. For a fixed 'transition period' around the change, we derive a generic relationship between the size of the moving window and the classification error rate. We derive expressions for the error in the transition period and for the optimal window size for the case of two Gaussian classes where the concept change is a geometrical displacement of the whole class configuration in the space. A simple window resize strategy based on the derived relationship is proposed and compared with fixed-size windows on a real benchmark data set data set (Electricity Market).		Ludmila I. Kuncheva;Indrė Žliobaitė	2009	Intell. Data Anal.	10.3233/IDA-2009-0397	computer science;concept drift;machine learning;pattern recognition;data mining;mathematics	ML	15.174495131912131	-37.68705065947899	87678
2f901bda9fe9298ec9821beea9f518ac1aaa8f00	gaussian processes		In these notes, we will talk about a different flavor of learning algorithms, known as Bayesian methods. Unlike classical learning algorithm, Bayesian algorithms do not attempt to identify “best-fit” models of the data (or similarly, make “best guess” predictions for new test inputs). Instead, they compute a posterior distribution over models (or similarly, compute posterior predictive distributions for new test inputs). These distributions provide a useful way to quantify our uncertainty in model estimates, and to exploit our knowledge of this uncertainty in order to make more robust predictions on new test points. We focus on regression problems, where the goal is to learn a mapping from some input space X = R of n-dimensional vectors to an output space Y = R of real-valued targets. In particular, we will talk about a kernel-based fully Bayesian regression algorithm, known as Gaussian process regression. The material covered in these notes draws heavily on many different topics that we discussed previously in class (namely, the probabilistic interpretation of linear regression, Bayesian methods, kernels, and properties of multivariate Gaussians). The organization of these notes is as follows. In Section 1, we provide a brief review of multivariate Gaussian distributions and their properties. In Section 2, we briefly review Bayesian methods in the context of probabilistic linear regression. The central ideas underlying Gaussian processes are presented in Section 3, and we derive the full Gaussian process regression model in Section 4.	algorithm;bayesian network;curve fitting;gaussian process;kriging;machine learning	Herbert K. H. Lee	2011		10.1007/978-3-642-04898-2_271		ML	23.422295807073663	-29.144745445264423	87753
147a711a52f009cacf932e5c9f0208347a01dafa	a parallel computing platform for training large scale neural networks	parallel computing;distributed storage parallel computing neural network big data fast training;parallel processing backpropagation iterative methods learning artificial intelligence neural nets;neural nets;distributed storage;fast training;backpropagation;iterative methods;big data;learning artificial intelligence;load balancing large scale neural network training artificial neural networks anns pattern recognition data mining cneural customized parallel computing platform backpropagation algorithm parallel neural network training systems hbase large scale training dataset storage parallel in memory computing framework fast iterative training event driven messaging communication model heartbeat polling model instant messaging delivery hadoop mapreduce;training parallel processing training data loading neurons biological neural networks;parallel processing;neural network	Artificial neural networks (ANNs) have been proved to be successfully used in a variety of pattern recognition and data mining applications. However, training ANNs on large scale datasets are both data-intensive and computation-intensive. Therefore, large scale ANNs are used with reservation for their time-consuming training to get high precision. In this paper, we present cNeural, a customized parallel computing platform to accelerate training large scale neural networks with the backpropagation algorithm. Unlike many existing parallel neural network training systems working on thousands of training samples, cNeural is designed for fast training large scale datasets with millions of training samples. To achieve this goal, firstly, cNeural adopts HBase for large scale training dataset storage and parallel loading. Secondly, it provides a parallel in-memory computing framework for fast iterative training. Third, we choose a compact, event-driven messaging communication model instead of the heartbeat polling model for instant messaging delivery. Experimental results show that the overhead time cost by data loading and messaging communication is very low in cNeural and cNeural is around 50 times faster than the solution based on Hadoop MapReduce. It also achieves nearly linear scalability and excellent load balancing.	algorithm;apache hbase;apache hadoop;artificial neural network;backpropagation;bayesian network;clustered file system;computation;computer data storage;data mining;data-intensive computing;deep belief network;event-driven messaging;event-driven programming;graphical user interface;in-memory processing;instant messaging;iterative method;load balancing (computing);mapreduce;open-source software;overhead (computing);parallel computing;pattern recognition;scalability	Rong Gu;Shen Furao;Yihua Huang	2013	2013 IEEE International Conference on Big Data	10.1109/BigData.2013.6691598	computer science;theoretical computer science;machine learning;distributed computing	Vision	12.94820419946215	-36.505892792289494	87792
1554931d9ce2f18e5515b24601c3f18ebe76c80d	relative loss bounds for multidimensional regression problems	eigenvalues and eigenfunctions;distance function;transfer functions;bregman divergences;exponentiated gradient;generalized linear regression;relative loss bounds;linear regression;on line prediction;logistic regression;journal article;regression analysis bregman divergences;vectors;gradient descent;transfer function;loss function;generalized linear regressions;keywords algorithms;on line learning;neural network	We study on-line generalized linear regression with multidimensional outputs, i.e., neural networks with multiple output nodes but no hidden nodes. We allow at the final layer transfer functions such as the softmax function that need to consider the linear activations to all the output neurons. The weight vectors used to produce the linear activations are represented indirectly by maintaining separate parameter vectors. We get the weight vector by applying a particular parameterization function to the parameter vector. Updating the parameter vectors upon seeing new examples is done additively, as in the usual gradient descent update. However, by using a nonlinear parameterization function between the parameter vectors and the weight vectors, we can make the resulting update of the weight vector quite different from a true gradient descent update. To analyse such updates, we define a notion of a matching loss function and apply it both to the transfer function and to the parameterization function. The loss function that matches the transfer function is used to measure the goodness of the predictions of the algorithm. The loss function that matches the parameterization function can be used both as a measure of divergence between models in motivating the update rule of the algorithm and as a measure of progress in analyzing its relative performance compared to an arbitrary fixed model. As a result, we have a unified treatment that generalizes earlier results for the gradient descent and exponentiated gradient algorithms to multidimensional outputs, including multiclass logistic regression.	algorithm;artificial neural network;generalized linear model;gradient descent;human body weight;logistic regression;loss function;nonlinear system;online and offline;softmax function;transfer function	Jyrki Kivinen;Manfred K. Warmuth	1997	Machine Learning	10.1023/A:1017938623079	econometrics;mathematical optimization;computer science;backpropagation;machine learning;mathematics;stochastic gradient descent;transfer function;artificial neural network;statistics	ML	19.7512915580653	-30.298645740374607	88013
1c42f6b196f38673b7c679cea509135789dfbbc8	class noise handling for effective cost-sensitive learning by cost-guided iterative classification filtering	extraction information;iterative method;cost guided iterative classification filtering;real world environment;costs working environment noise filters machine learning iterative algorithms noise reduction data mining machine learning algorithms filtering algorithms error analysis;noisy environments;cs learning;analisis datos;information extraction;base donnee tres grande;noise handling data mining classification cost sensitive learning;noise handling;data mining;classification;journal article;apprentissage machine;metodo iterativo;iterative methods;data analysis;machine learning;fouille donnee;methode iterative;comparative study;pattern classification;analyse donnee;cost sensitive learning;very large databases;learning artificial intelligence;cicf;classification accuracy;busca dato;clasificacion;extraccion informacion;noisy environments cost sensitive learning cost guided iterative classification filtering machine learning data mining real world environment cicf cs learning;pattern classification iterative methods learning artificial intelligence	Recent research in machine learning, data mining, and related areas has produced a wide variety of algorithms for cost-sensitive (CS) classification, where instead of maximizing the classification accuracy, minimizing the misclassification cost becomes the objective. These methods often assume that their input is quality data without conflict or erroneous values, or the noise impact is trivial, which is seldom the case in real-world environments. In this paper, we propose a cost-guided iterative classification filter (CICF) to identify noise for effective CS learning. Instead of putting equal weights on handling noise in all classes in existing efforts, CICF puts more emphasis on expensive classes, which makes it attractive in dealing with data sets with a large cost-ratio. Experimental results and comparative studies indicate that the existence of noise may seriously corrupt the performance of the underlying CS learners and by adopting the proposed CICF algorithm, we can significantly reduce the misclassification cost of a CS classifier in noisy environments	algorithm;cs games;data mining;iteration;iterative method;machine learning;reinforcement learning;signal-to-noise ratio	Xingquan Zhu;Xindong Wu	2006	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2006.155	computer science;artificial intelligence;machine learning;pattern recognition;data mining;database;iterative method;world wide web;information extraction;algorithm;statistics	ML	14.72444794211562	-36.17279698335149	88042
7781b629d0013a1c8d933a0475c60e0728107045	perturbation method for deleting redundant inputs of perceptron networks	perturbation method;perceptron networks;model complexity;sensitivity to inputs;feature elimination;linear model;saliency measures;input layer pruning;continuous mapping	Multilayer feedforward networks are often used for modeling complex functional relationships between data sets. Should a measurable redundancy in training data exist, deleting unimportant data components in the training sets could lead to smallest networks due to reduced–size data vectors. This reduction can be achieved by analyzing the total disturbance of network outputs due to perturbed inputs. The search for redundant input data components proposed in the paper is based on the concept of sensitivity in linearized models. The mappings considered are I K with continuous and differentiable outputs. Criteria and algorithm for inputs’ pruning are formulated and illustrated with examples. INTRODUCTION Neural networks are often used to model complex functional relationships between sets of experimental data. Such modeling approach proves useful when analytical models of processes do not exist or are not known, but when sufficient data is available for embedding existing relationships into neural network structures. Multilayer feedforward neural networks (MFNN) consisting of continuous neurons have been found particularly useful for such model building [1–3]. Representative training data are used in such case for supervised training of a suitable user–selected MFNN architecture. Minimization of potential redundancy in data used for supervised training can take different forms. Duplicative data pairs are essentially removable from the training sets without a loss of accuracy. In contrast, special attention should be paid to data that carry conflicting information. Such data do not normally allow for unique mapping and should be eliminated. Our concern in this paper is This work was supported in part by the ONR Grant N00014–93–1–0855 to explore potential redundancy in input vector dimensionality. As such, this concern has only little in common with widely used notion of network pruning. By deleting superfluous inputs, if such inputs exist, the number of input nodes is reduced. The resulting network is still pruned as it contains no weights fanning out of deleted inputs. A popular objective of network pruning is to detect irrelevant weights and neurons. This can be achieved through evaluation of sensitivities of the error function to the weights which are the learning parameters [5–6]. Errors other than quadratic are often used to achieve identification of insensitive weights. Statistical moments of neural networks–built mappings, including sensitivities to inputs, are discussed in [7]. Our focus in the paper is mainly to develop clear and practical measures of sensitivities to inputs rather than to weights or neurons. Then, a systematic algorithmic approach has been developed to utilize these measures towards deletion of redundant inputs. To determine which inputs are necessary for the satisfactory neural network performance a metric known as saliency was introduced in [8]. Belue and Bauer developed an algorithm extending the saliency metric over the entire input space [9]. The approach involves multiple neural network training and superposition of noise on the training patterns to reduce the dependence of results on local minima. This method, however, is computationally intensive due to the required multiple training sessions and exhaustive coverage of the input space. The saliency method was developed to determine the irrelevant features for neural network classifiers [9]. The sensitivities of MFNN outputs with respect to inputs are calculated and used along with various metrics to evaluate importance of features. Such classifier networks in general are characterized by small sensitivities, when fully trained. Therefore saliency can be applied only with the addition of noise to the training patterns and with sampling of the input space over the whole domain. Multiple training is necessary to average the results and prevent dependence on local minima achieved during training. This paper focuses on the concept of sensitivity, or perturbation method, for pruning unimportant inputs for neural networks providing continuous mapping. This assumption and the proposed new sensitivity summation metrics allow application of the method directly to trained MFNNs without adding noise to the training patterns or multiple trainings. In fact, in case of continuous mapping the problem of local minima reached during training is not important if sufficient approximation accuracy is achieved. As a result the presence of local minima does not affect the Jacobian matrix used by this method. The Jacobian matrix is derived from the approximate neural network mapping over the training data set. This eliminates the need for computationally intensive repetitive training. In addition to mappings with continuous outputs the sensitivity method can be applied to the classification problems. However, in such cases an additional neural network has to be trained as described in one of the examples. Let us consider an MFNN with a single hidden layer. The network is assumed to perform a nonlinear, differentiable mapping : I K, o= (x), where o (Kx1), and x(Ix1) are output and input vectors, respectively. In further discussion it is assumed that certain inputs bear none, or little statistical or deterministic relationships to output vectors, and are therefore removable. The objective here is to reduce the original dimensionality of the input vector, x, so that a smaller network can be used as a model without loss of accuracy. Initial considerations published in [10–12] are extended below along with a formal framework for the perturbation approach as applied to the neural network models. Let o: I K with component functions o1, o2, ..., oK. Suppose x (n) , where is an open set. Since o is differentiable at x(n) we have o(x x) o x J x x g( x) (1)	algorithmic efficiency;alpha–beta pruning;approximation algorithm;basis (linear algebra);computation;emoticon;encoder;experiment;feedforward neural network;heuristic;image noise;jacobian matrix and determinant;maxima and minima;network mapping;network performance;neural networks;nonlinear system;numerical method;perceptron;perturbation theory;principal component analysis;relevance;removable media;sampling (signal processing);semantic network;supervised learning;test set	Jacek M. Zurada;Aleksander Malinowski;Shiro Usui	1997	Neurocomputing	10.1016/S0925-2312(96)00031-8	mathematical optimization;theoretical computer science;machine learning;linear model;mathematics;statistics	ML	18.41305811428339	-31.156774104081673	88118
d3944b8be045827b8ee6ed1e374416016bd611ce	radial basis function networks and complexity regularization in function learning	minimisation;rate of convergence;complexite;covering number;sample size;regularisation;funcion no lineal;learning;transfer functions;activation function;relacion convergencia;complejidad;function approximation feedforward neural nets transfer functions computational complexity learning artificial intelligence minimisation;non linear function;metric entropy;taux convergence;convergence rate;radial basis function networks intelligent networks convergence artificial neural networks approximation error estimation error entropy risk management neural networks probability distribution;complexity;regularization;empirical risk minimization;aprendizaje;apprentissage;radial basis function;fonction radiale base;function approximation;radial basis function network;computational complexity;loss function;estimation fonction;fonction non lineaire;convergence rates complexity regularization function learning estimation bounds nonlinear function estimation single hidden layer radial basis function network random covering numbers l sub 1 metric entropy activation functions empirical risk minimization expected risk loss functions;feedforward neural nets;regularizacion;learning artificial intelligence;reseau neuronal;functions of bounded variation;red neuronal;large classes;neural network	In this paper we apply the method of complexity regularization to derive estimation bounds for nonlinear function estimation using a single hidden layer radial basis function network. Our approach differs from previous complexity regularization neural-network function learning schemes in that we operate with random covering numbers and l(1) metric entropy, making it possible to consider much broader families of activation functions, namely functions of bounded variation. Some constraints previously imposed on the network parameters are also eliminated this way. The network is trained by means of complexity regularization involving empirical risk minimization. Bounds on the expected risk in terms of the sample size are obtained for a large class of loss functions. Rates of convergence to the optimal loss are also derived.	bounded variation;empirical risk minimization;loss function;matrix regularization;measure-preserving dynamical system;nonlinear system;radial (radio);radial basis function network;transfer function	Adam Krzyzak;Tamás Linder	1996	IEEE transactions on neural networks	10.1109/72.661120	regularization perspectives on support vector machines;mathematical optimization;radial basis function;computer science;machine learning;complexity index;mathematics;rate of convergence;radial basis function network;artificial neural network;statistics	ML	19.551597400066616	-30.086563098245474	88137
a3a2824c43738228b6200567f033c88638579366	three-term fuzzy back-propagation	generalization error;t technology general;local minima;back propagation	The disadvantages of the fuzzy BP learning are its low speed of error convergence and the high possibility of trapping into local minima. In this paper, a fuzzy proportional factor is added to the fuzzy BP’s iteration scheme to enhance the convergence speed. The added factor makes the proposed method more dependant on the distance of actual outputs and desired ones. Thus in contrast with the conventional fuzzy BP, when the slop of error function is very close to zero, the algorithm does not necessarily return almost the same weights for the next iteration. According to the simulation’s results, the proposed method is superior to the fuzzy BP in terms of generated error.	algorithm;iteration;iterative method;maxima and minima;simulation;slop (remote control);software propagation	M. Hadi Mashinchi;Siti Mariyam Hj. Shamsuddin	2009		10.1007/978-3-642-01082-8_6	mathematical optimization;defuzzification;computer science;artificial intelligence;fuzzy number;backpropagation;machine learning;maxima and minima;mathematics;generalization error	AI	15.932816962059725	-29.355948064742194	88391
70b1672dd2cbd1cf07ddf3872acaf2073ccb7e46	complexity issues in neural network computations	neural network	In this paper we described new results on the complexity of computing dichotomies and dichotomies on examples particularly on the number of units in the hidden layers. Traditionnally the number of units is bounded by functions of the number of examples. We have introduced a new parameter: the distance between the classes. These two parameters are complementary and it is still unknown if another parameters could be used. The bounds that we derived are not tight and should be improved.	artificial neural network;computation	Michel Cosnard;Pascal Koiran;Hélène Paugam-Moisy	1992		10.1007/BFb0023854	stochastic neural network;nervous system network models;types of artificial neural networks;computer science;recurrent neural network;physical neural network;time delay neural network;mathematics;deep learning	ML	18.019493916422043	-29.70308804850907	88458
a75ab6330edb343fbf2f09014315878b4f97e3a5	a fast partial memory approach to incremental learning through an advanced data storage framework	partial memory;advance data storage.;theory refinement;incremental learning;inductive concept learning;on-line learning;machine learning;data storage;concept learning	Inducing concept descriptions from examples has been thoroughly tackled by symbolic machine learning methods. However, on-line learning methods that acquire concepts from examples distributed over time, require great computational effort. This is not only due to the intrinsic complexity of the concept learning task, but also to the full memory approach that most learning systems adopt. Indeed, during learning, most of these systems consider all their past examples leading to expensive procedures for consistency verification. In this paper, we present an implementation of a partial memory approach through an advanced data storage framework and show through experiments that great savings in learning times can be achieved. We also propose and experiment different ways to select the past examples paving the way for further research in on-line partial memory learning agents.	computation;computer data storage;concept learning;data storage tag;experiment;online and offline;online machine learning;verification and validation	Marenglen Biba;Stefano Ferilli;Floriana Esposito;Nicola Di Mauro;Teresa Maria Altomare Basile	2007			online machine learning;instance-based learning;robot learning;active learning (machine learning);unsupervised learning;proactive learning;machine learning;multi-task learning;artificial intelligence;computational learning theory;computer science	AI	16.75661540834062	-34.57813394813522	88471
12eba1578cdff6ce92de84ac27b32993d3a78387	statistical model criticism using kernel two sample tests		We propose an exploratory approach to statistical model criticism using maximum mean discrepancy (MMD) two sample tests. Typical approaches to model criticism require a practitioner to select a statistic by which to measure discrepancies between data and a statistical model. MMD two sample tests are instead constructed as an analytic maximisation over a large space of possible statistics and therefore automatically select the statistic which most shows any discrepancy. We demonstrate on synthetic data that the selected statistic, called the witness function, can be used to identify where a statistical model most misrepresents the data it was trained on. We then apply the procedure to real data where the models being assessed are restricted Boltzmann machines, deep belief networks and Gaussian process regression and demonstrate the ways in which these models fail to capture the properties of the data they are trained on.	artificial neural network;bayesian network;deep belief network;discrepancy function;gaussian process;kriging;markov chain;mikumikudance;restricted boltzmann machine;sampling (signal processing);statistical model;synthetic data;the witness;time series	James Robert Lloyd;Zoubin Ghahramani	2015			econometrics;machine learning;mathematics;statistic;statistics	ML	23.882505004841313	-30.04675453296979	88542
b8f72acf84c2403a02e08927e7542a5b718e1371	neural control variates for variance reduction		In statistics and machine learning, approximation of an intractable integration is often achieved by using the unbiased Monte Carlo estimator, but the variances of the estimation are generally high in many applications. Control variates approaches are well-known to reduce the variance of the estimation. These control variates are typically constructed by employing predefined parametric functions or polynomials, determined by using those samples drawn from the relevant distributions. Instead, we propose to construct those control variates by learning neural networks to handle the cases when test functions are complex. In many applications, obtaining a large number of samples for Monte Carlo estimation is expensive, which may result in overfitting when training a neural network. We thus further propose to employ auxiliary random variables induced by the original ones to extend data samples for training the neural networks. We apply the proposed control variates with augmented variables to thermodynamic integration and reinforcement learning. Experimental results demonstrate that our method can achieve significant variance reduction compared with other alternatives.	approximation;artificial neural network;control variates;distribution (mathematics);machine learning;monte carlo method;overfitting;polynomial;reinforcement learning;thermodynamic integration;variance reduction	Zhanxing Zhu;Ruosi Wan;Mingjun Zhong	2018	CoRR		artificial intelligence;estimator;mathematics;overfitting;machine learning;artificial neural network;reinforcement learning;variance reduction;control variates;monte carlo method;random variable	ML	24.519274703775903	-30.15663480146975	88620
5ee54a472b1a9dffb36d7f7516136c877ebef847	evolution of hopfield model of associative memory by the breeder genetic algorithm	associative memory		content-addressable memory;genetic algorithm;hopfield network	Akira Imada;Keijiro Araki	1997			content-addressable memory;genetic algorithm;machine learning;breeder (animal);artificial intelligence;computer science	AI	12.527574279676175	-27.18756959751781	88686
71dca76b17b5de25c44970919ebaf32218940156	sliding mode online learning algorithm for type-2 fuzzy cmac networks	cerebellar model arithmetic computers;nonlinear control systems;fuzzy control;variable structure systems;tsk sliding mode online learning algorithm cerebellar model articulation controller complex dynamical systems computational simplicity generalization capability fuzzy cmac structures cmac weighting coefficients type 2 fuzzy logic systems stable incremental learning algorithm interval type 2 fuzzy cmac networks t2fcmac variable structure systems theory principles nonlinear systems takagi sugeno kang fuzzy neural networks;learning systems;neurocontrollers;vectors uncertainty fuzzy logic quantization signal fuzzy sets variable structure systems computational modeling;sliding mode control type 2 fuzzy sets associative memory networks cerebellar model articulation controller incremental learning variable structure systems;variable structure systems cerebellar model arithmetic computers fuzzy control learning systems neurocontrollers nonlinear control systems	Cerebellar model articulation controller (CMAC) networks have been widely applied to problems involving modeling and control of complex dynamical systems because of their computational simplicity, fast learning and good generalization capability. The integration of fuzzy logic systems and CMAC networks into fuzzy CMAC structures can help to improve their function approximation accuracy in terms of the CMAC weighting coefficients. Type-2 fuzzy logic systems are an area of growing interest over the last years. The ability to model uncertainties and to perform under noisy conditions in a better way than type-1 fuzzy systems increases their applicability. A new stable incremental learning algorithm for interval type-2 fuzzy CMAC (T2FCMAC) networks is proposed in this paper. The algorithm is based on the variable structure systems theory principles. It can tune online the parameters of the membership functions and the weights in the fourth and fifth layer of the T2FCMAC network. Simulation results from the identification of two nonlinear systems demonstrate the better performance of the T2FCMAC structure with the newly proposed algorithm in comparison to the on-line learning type-1 and type-2 Takagi-Sugeno-Kang (TSK) fuzzy neural networks.	algorithm;approximation;artificial neural network;biconnected component;cerebellar model articulation controller;coefficient;complex dynamics;dynamical system;formal system;fuzzy control system;fuzzy logic;nonlinear system;one-key mac;online and offline;online machine learning;simulation;systems theory;variable structure system	Sevil Ahmed;Kostadin Borisov Shiev;Andon V. Topalov;Nikola Georgiev Shakev;Okyay Kaynak	2013	2013 9th Asian Control Conference (ASCC)	10.1109/ASCC.2013.6606282	control engineering;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;fuzzy number;neuro-fuzzy;machine learning;control theory;mathematics;fuzzy associative matrix;fuzzy set operations	AI	15.123619980552002	-29.000191329731024	88842
50d1cf1c8ff13ab6e1a8c0b7c0c2fbdd46178c1c	interpretable distribution features with maximum testing power		Two semimetrics on probability distributions are proposed, given as the sum of differences of expectations of analytic functions evaluated at spatial or frequency locations (i.e, features). The features are chosen so as to maximize the distinguishability of the distributions, by optimizing a lower bound on test power for a statistical test using these features. The result is a parsimonious and interpretable indication of how and where two distributions differ locally. We show that the empirical estimate of the test power criterion converges with increasing sample size, ensuring the quality of the returned features. In real-world benchmarks on highdimensional text and image data, linear-time tests using the proposed semimetrics achieve comparable performance to the state-of-the-art quadratic-time maximum mean discrepancy test, while returning human-interpretable features that explain the test results.	discrepancy function;occam's razor;time complexity	Wittawat Jitkrittum;Zoltán Szabó;Kacper Chwialkowski;Arthur Gretton	2016			econometrics;data mining;mathematics;statistics	ML	23.7330892175501	-29.237102393673013	88938
7a466109d0649d9bbc786f11b8fc3d328874e153	connection pruning with static and adaptive pruning schedules	empirical study;pruning;early stopping;generalization;neural network	Neural network pruning methods on the level of individual network parameters (e.g. connection weights) can improve generalization, as is shown in this empirical study. However, an open problem in the pruning methods known today (e.g. OBD, OBS, autoprune, epsiprune) is the selection of the number of parameters to be removed in each pruning step (pruning strength). This work presents a pruning method lprune that automatically adapts the pruning strength to the evolution of weights and loss of generalization during training. The method requires no algorithm parameter adjustment by the user. Results of statistical signi cance tests comparing autoprune, lprune, and static networks with early stopping are given, based on extensive experimentation with 14 di erent problems. The results indicate that training with pruning is often signi cantly better and rarely signi cantly worse than training with early stopping without pruning. Furthermore, lprune is often superior to autoprune (which is superior to OBD) on diagnosis tasks unless severe pruning early in the training process is required.	algorithm;artificial neural network;early stopping;optical burst switching;schedule (computer science)	Lutz Prechelt	1997	Neurocomputing	10.1016/S0925-2312(96)00054-9	null-move heuristic;generalization;mathematical optimization;early stopping;computer science;pruning;machine learning;principal variation search;pattern recognition;killer heuristic;empirical research;artificial neural network;pruning	ML	16.585858778676016	-32.53911847121935	88954
4cf3a92ffffea7fac86617b0b969e8db7116825b	practical riemannian neural networks		We provide the first experimental results on non-synthetic datasets for the quasidiagonal Riemannian gradient descents for neural networks introduced in [Oll15]. These include the MNIST, SVHN, and FACE datasets as well as a previously unpublished electroencephalogram dataset. The quasi-diagonal Riemannian algorithms consistently beat simple stochastic gradient gradient descents by a varying margin. The computational overhead with respect to simple backpropagation is around a factor 2. Perhaps more interestingly, these methods also reach their final performance quickly, thus requiring fewer training epochs and a smaller total computation time. We also present an implementation guide to these Riemannian gradient descents for neural networks, showing how the quasi-diagonal versions can be implemented with minimal effort on top of existing routines which compute gradients. We present a practical and efficient implementation of invariant stochastic gradient descent algorithms for neural networks based on the quasi-diagonal Riemannian metrics introduced in [Oll15]. These can be implemented from the same data as RMSPropor AdaGrad-based schemes [DHS11], namely, by collecting gradients and squared gradients for each data sample. Thus we will try to present them in a way that can easily be incorporated on top of existing software providing gradients for neural networks. The main goal of these algorithms is to obtain invariance properties, such as, for a neural network, insensitivity of the training algorithm to whether a logistic or tanh activation function is used, or insensitivity to simple changes of variables in the parameters, such as scaling some parameters. Neither backpropagation nor AdaGrad-like schemes offer such properties. Invariance properties are important as they reduce the number of arbitrary design choices, and guarantee that an observed good behavior in one instance will transfer to other cases when, e.g., different scalings are involved. In some cases this may alleviate the burden associated to hyper-parameter tuning: in turn, sensible hyper-parameter values sometimes become invariant. Perhaps the most well-known invariant training procedure for statistical learning is the natural gradient promoted by Amari [Ama98]. However, the natural gradient is rarely used in practice for training neural networks. The main reason is that the Fisher information metric on which it relies is computationnally hard to compute. Different approximations have been proposed but can bring little benefits compared to the implementation effort; see for instance [RMB07, Mar14]. Moreover, it is not clear whether	activation function;algorithm;approximation;artificial neural network;backpropagation;computation;electroencephalography;epoch (reference date);fisher information;image scaling;information geometry;mnist database;machine learning;mind;overhead (computing);rectifier (neural networks);sigmoid function;stochastic gradient descent;synthetic intelligence;time complexity	Gaétan Marceau-Caron;Yann Ollivier	2016	CoRR		mathematical optimization;computer science;artificial intelligence;machine learning	ML	19.093797907797246	-31.709202079871826	88992
f7c6dadea4dc281123eeaaab0fb508c080ab4ac5	hardware prototypes of a boolean neural network and the simulated annealing optimization method		"""Boolean Neural Network is a neural network that operates with binary weight values of """"1"""" and """"0"""". Otherwise it is formally analogous to the Multilayer Perceptron (MLP). Simulated Annealing is a stochastic optimization methods that is suitable for performing nonlinear multivariable optimization tasks. Training a Boolean Neural Network is a well-suited problem to this algorithm. However, the Simulated Annealing method is computationally heavy, which makes the training procedure slow. The training speed can be improved by using custom designed hardware for the whole system including the optimization method and the neural network. Hardware prototypes of a Boolean Neural Network and the Simulated Annealing optimization method have been designed using discrete components. The Boolean Neural Network implementation is basically a dynamically configurable feedforward network of Boolean logic gates of two inputs. The Simulated Annealing implementation is a general purpose hardware tool for multivariable optimization tasks. Here it is applied to do supervised training of the Boolean Neural Network hardware."""		Jarkko Niittylahti	1996	International journal of neural systems	10.1142/S0129065796000051	stochastic neural network;boolean circuit;mathematical optimization;circuit minimization for boolean functions;probabilistic neural network;computer science;theoretical computer science;machine learning;time delay neural network	ML	14.407552664044431	-26.216332692684414	88995
09cd54f4a2f1b21b3bd7d17a13b7de2baab44473	dimensionality reduction for nonlinear regression with two predictor vectors		Many variables that we would like to predict depend nonlinearly on two types of attributes. For example, prices are influenced by supply and demand. Movie ratings are determined by demographic attributes and genre attributes. This paper addresses the dimensionality reduction problem in such regression problems with two predictor vectors. In particular, we assume a discriminative model where low-dimensional linear embeddings of the two predictor vectors are sufficient statistics for predicting a dependent variable. We show that a simple algorithm involving singular value decomposition can accurately estimate the embeddings provided that certain sample complexities are satisfied, surprisingly, without specifying the nonlinear regression model. These embeddings improve the efficiency and robustness of subsequent training, and can serve as a pre-training algorithm for neural networks. The main results establish sample complexities under multiple settings. Sample complexities for different regression models only differ by constant factors.	algorithm;artificial neural network;dimensionality reduction;discriminative model;kerrison predictor;nonlinear system;singular value decomposition	Yanjun Li;Yoram Bresler	2016	CoRR		econometrics;machine learning;mathematics;statistics	ML	22.539607199048916	-29.942710953789256	89143
7e21ee06d3a9b9fd7d1fd8b0c99ba4369092768f	a binary classifier with applications to poorly defined engineering problems	binary classifier;character recognition problem;radial-gaussian network;hamming network;comprehensive set;hidden neuron;engineering problem;binary network architecture;proposed system;complementary training algorithm;unambiguous training pattern;classifier	The paper proposes and evaluates a binary network architecture and complementary training algorithm designed for pattern classification, with applications in a variety of engineering problems. The advantages of the system are that it can always converge on zero error for a set of unambiguous training patterns (if required), converges rapidly, and circumvents the issue of how many hidden neurons to incorporate in a network. The main benefit of the proposed system over Hamming networks, its main counterpart, is that it can group patterns into different classes along any boundary. The system is shown to outperform 1) the Hamming network for a character recognition problem where the images are subject to both position change and noise; and 2) a radial-Gaussian network in a truck-type classification problem. A variant of the system, where hidden neuron thresholds are set to zero, is shown to further improve performance if a comprehensive set of noise-free input patterns are available for training.	binary classification	Ian Flood;Nabil A. Kartam	1998	AI EDAM		speech recognition;truck;classifier;image processing;biological classification;computer science;engineering;artificial intelligence;expert system	AI	13.651836098104686	-35.335813722773736	89246
044e38092ed9b481e1fabf120050b657845a8031	a classification paradigm for distributed vertically partitioned data	calcul neuronal;neural computation;classification algorithm;decision tree;decision aid;taux erreur;clasificador;62m45;ayuda decision;prise decision;arbol decision;synchronisation;classifier;estimation erreur;particion;62h30;error estimation;synchronization;algorithme reparti;estimacion error;partition;pattern classification;aide decision;classificateur;error rate;k nearest neighbor;algoritmo repartido;access control;sincronizacion;reseau neuronal;toma decision;indice error;distributed algorithm;arbre decision;red neuronal;computacion neuronal;neural network;classification forme	In general, pattern classification algorithms assume that all the features are available during the construction of a classifier and its subsequent use. In many practical situations, data are recorded in different servers that are geographically apart, and each server observes features of local interest. The underlying infrastructure and other logistics (such as access control) in many cases do not permit continual synchronization. Each server thus has a partial view of the data in the sense that feature subsets (not necessarily disjoint) are available at each server. In this article, we present a classification algorithm for this distributed vertically partitioned data. We assume that local classifiers can be constructed based on the local partial views of the data available at each server. These local classifiers can be any one of the many standard classifiers (e.g., neuralnetworks, decision tree, k nearest neighbor). Often these local classifiers are constructed to support decision making at each location, and our focus is not on these individual local classifiers. Rather, our focus is constructing a classifier that can use these local classifiers to achieve an error rate that is as close as possible to that of a classifier having access to the entire feature set. We empirically demonstrate the efficacy of the proposed algorithm and also provide theoretical results quantifying the loss that results as compared to the situation where the entire feature set is available to any single classifier.	access control;algorithm;decision making;decision tree;logistics;server (computer);server (computing);single linkage cluster analysis;statistical classification	Jayanta Basak;Ravi Kothari	2004	Neural Computation	10.1162/089976604323057470	random subspace method;synchronization;distributed algorithm;computer science;machine learning;linear classifier;pattern recognition;data mining;artificial neural network	ML	10.52924648815801	-32.83462861404828	89543
176f34b7bb07520f933b21b7924ca3213a63e679	error analysis for the semi-supervised algorithm under maximum correntropy criterion	semi supervised learning;correntropy;excess generalization error;manifold error	As a similarity measure, correntropy has been increasingly employed in machine learning research. While numerous experimental results have shown the effectiveness of correntropy based methods, the theoretical analysis in this area is still poorly understood. In this paper, we propose a novel semi-supervised algorithm under the maximum correntropy criterion, and present an elaborate error analysis for it. An excess generalization error bound is established, which demonstrates that the proposed method is consistent, and converges at a faster rate compared with the related studies. Moreover, experiments are implemented to show the efficiency of the proposed method.	algorithm;error analysis (mathematics);experiment;generalization error;machine learning;offset binary;semi-supervised learning;semiconductor industry;similarity measure	Ling Zuo;Yulong Wang	2017	Neurocomputing	10.1016/j.neucom.2016.10.023	semi-supervised learning;computer science;machine learning;pattern recognition;mathematics;statistics	AI	22.371955583214326	-36.517094299049795	89575
dd895f20900040d0f345dc02001ff629192d6b17	clustered recursive branching network	optimal solution;methode recursive;evaluation performance;optimisation;solution optimale;splitting method;performance evaluation;optimizacion;methode mesure;metodo descomposicion;evaluacion prestacion;branching;methode decomposition;metodo recursivo;recursive method;metodo medida;multilayer perceptron;reseau branchement recursif;classification;similitude;perceptron multicouche;data clustering;decomposition method;cuantificacion vectorial;vector quantization;clustering;ramificacion;solucion optima;similarity;structured perceptrons;ramification;optimization;recursive branching network;similitud;network structure;measurement method;perceptron;reseau neuronal;similarity measure;clasificacion;red neuronal;neural network;quantification vectorielle	Recursive branching network (RBN) was proposed in [1] to solve linearly non-separable problems using output-coded perceptrons. It relies on splitting the training patterns, at random, between parallel perceptrons. However, the random splitting mechanism can trap the perceptron with conflicting patterns. Optimizing the splitting methods, through clustering, is proposed here to ensure meaningful way of distributing the patterns between the perceptrons. We propose four splitting methods which use different similarity measures between patterns. We examine these methods on five standard data sets. In general, these methods enhance the performance of RBN and in many cases contribute to reducing the network complexity compared with random-splitting RBN.	boolean network;cluster analysis;multilayer perceptron;optimizing compiler;perceptron;recursion (computer science);russian business network;subnetwork;vector quantization	Khalid A. Al-Mashouq	2000	Neural Processing Letters	10.1023/A:1009665713438	computer science;artificial intelligence;machine learning;mathematics;cluster analysis;artificial neural network;algorithm	ML	10.987939856244811	-30.97239124717565	89617
55b474f71dbfa553c990314f4c9931d60618b45f	a proposal of multi-module network for association of patterns and symbols	associative memory;multi module network;non linear dynamics			Yoichiro Hattori;Takeshi Furuhashi;Yoshiki Uchikawa	1996	JRM	10.20965/jrm.1996.p0345	arithmetic;computer science;artificial intelligence;theoretical computer science;bidirectional associative memory	Vision	12.800320842863545	-29.303411802771485	89722
647ba2b5c7affb43f5e4d5055c7a5fc29259d040	the random neural network with a genetic algorithm and deep learning clusters in fintech: smart investment		This paper presents the Random Neural Network in a Deep Learning Cluster structure with a new learning algorithm based on the genetics according to the genome model, where information is transmitted in the combination of genes rather than the genes themselves. The proposed genetic model transmits information to future generations in the network weights rather than the neurons. The innovative genetic algorithm is implanted in a complex deep learning structure that emulates the human brain: Reinforcement Learning takes fast local current decisions, Deep Learning Clusters provide identity and memory, Deep Learning Management Clusters take final strategic decisions and finally Genetic Learning transmits the information learned to future generations. This proposed structure has been applied and validated in Fintech; a Smart Investment application: an Intelligent Banker that performs Buy and Sell decisions on several Assets with an associated market and risk. Our results are promising; we have connected the human brain and genetics with Machine Learning based on the Random Neural Network model where biology; similar as Artificial Intelligence is learning gradually and continuously while adapting to the environment.	deep learning;genetic algorithm;random neural network	Will Serrano	2018		10.1007/978-3-319-92007-8_26	artificial intelligence;computer science;genetic algorithm;machine learning;pattern recognition;deep learning;reinforcement learning;random neural network	AI	12.290478231642492	-27.448872978684133	89772
a5fdf8d7cd8bc12c1ae9dabb863f9fae4b3574db	fast high-dimensional kernel summations using the monte carlo multipole method	high dimensional dataset;high dimensionality;dimension reduction;relative error;approximation scheme;kernel method;monte carlo;data structure	We propose a new fast Gaussian summation algorithm for high-dimensional datasets with high accuracy. First, we extend the original fast multipole-type methods to use approximation schemes with both hard and probabilistic error. Second, we utilize a new data structure called subspace tree which maps each data point in the node to its lower dimensional mapping as determined by any linear dimension reduction method such as PCA. This new data structure is suitable for reducing the cost of each pairwise distance computation, the most dominant cost in many kernel methods. Our algorithm guarantees probabilistic relative error on each kernel sum, and can be applied to high-dimensional Gaussian summations which are ubiquitous inside many kernel methods as the key computational bottleneck. We provide empirical speedup results on low to high-dimensional datasets up to 89 dimensions. 1 Fast Gaussian Kernel Summation In this paper, we propose new computational techniques for efficiently approximating the following sum for each query point qi ∈ Q:	algorithm;approximation error;code page 437;computation;data point;data structure;dimensionality reduction;fast multipole method;gaussian blur;hierarchical database model;iterative method;kernel (operating system);kernel method;map;monte carlo method;principal component analysis;randomness;speedup	Dongryeol Lee;Alexander G. Gray	2008			kernel method;mathematical optimization;approximation error;combinatorics;kernel embedding of distributions;data structure;kernel principal component analysis;computer science;theoretical computer science;machine learning;mathematics;variable kernel density estimation;statistics;dimensionality reduction;monte carlo method	ML	24.238150683403386	-36.266763794673494	89885
615d84c086a13f08bb2e7a04e7255eb2c1554b3e	learning rates of lq coefficient regularization learning with gaussian kernel		Regularization is a well-recognized powerful strategy to improve the performance of a learning machine and lq regularization schemes with are central in use. It is known that different q leads to different properties of the deduced estimators, say, l2 regularization leads to a smooth estimator, while l1 regularization leads to a sparse estimator. Then how the generalization capability of lq regularization learning varies with q is worthy of investigation. In this letter, we study this problem in the framework of statistical learning theory. Our main results show that implementing lq coefficient regularization schemes in the sample-dependent hypothesis space associated with a gaussian kernel can attain the same almost optimal learning rates for all . That is, the upper and lower bounds of learning rates for lq regularization learning are asymptotically identical for all . Our finding tentatively reveals that in some modeling contexts, the choice of q might not have a strong impact on the generalization capability. From this perspective, q can be arbitrarily specified, or specified merely by other nongeneralization criteria like smoothness, computational complexity or sparsity.	apricot kernel oil;coefficient;computational complexity theory;generalization (psychology);machine learning;manifold regularization;matrix regularization;normal statistical distribution;sparse matrix;statistical learning theory	Shaobo Lin;Jinshan Zeng;Jian Fang;Zongben Xu	2014	Neural Computation	10.1162/NECO_a_00641	regularization perspectives on support vector machines;backus–gilbert method;regularization;mathematical optimization;proximal gradient methods for learning;early stopping;machine learning;mathematics;statistics;generalization error	ML	21.641047728568463	-33.60746909009535	89925
dd402dbf0d44add97f0a30c9294a842cbfb84a6c	a bi-layered parallel training architecture for large-scale convolutional neural networks		Benefitting from large-scale training datasets and the complex training network, Convolutional Neural Networks (CNNs) are widely applied in various fields with high accuracy. However, the training process of CNNs is very time-consuming, where large amounts of training samples and iterative operations are required to obtain high-quality weight parameters. In this paper, we focus on the time-consuming training process of large-scale CNNs and propose a Bi-layered Parallel Training (BPT-CNN) architecture in distributed computing environments. BPT-CNN consists of two main components: (a) an outer-layer parallel training for multiple CNN subnetworks on separate data subsets, and (b) an inner-layer parallel training for each subnetwork. In the outer-layer parallelism, we address critical issues of distributed and parallel computing, including data communication, synchronization, and workload balance. A heterogeneousaware Incremental Data Partitioning and Allocation (IDPA) strategy is proposed, where large-scale training datasets are partitioned and allocated to the computing nodes in batches according to their computing power. To minimize the synchronization waiting during the global weight update process, an Asynchronous Global Weight Update (AGWU) strategy is proposed. In the inner-layer parallelism, we further accelerate the training process for each CNN subnetwork on each computer, where computation steps of convolutional layer and the local weight training are parallelized based on task-parallelism. We introduce task decomposition and scheduling strategies with the objectives of thread-level load balancing and minimum waiting time for critical paths. Extensive experimental results indicate that the proposed BPT-CNN effectively improves the training performance of CNNs while maintaining the accuracy.	algorithm;computation;computer;convolutional neural network;data parallelism;deep learning;distributed computing;emoticon;iterative method;load balancing (computing);machine learning;mathematical optimization;neural network software;parallel computing;scalability;scheduling (computing);subnetwork;supercomputer;task parallelism;time series	Jianguo Chen;Keqin Li;Kashif Bilal;Xu Zhou;Keqin Li;Philip S. Yu	2018	CoRR		computer engineering;convolutional neural network;scheduling (computing);computer science;synchronization;deep learning;load balancing (computing);subnetwork;asynchronous communication;distributed computing;artificial intelligence;complex training	HPC	13.017028493129999	-36.55522917837232	90071
c8c726286fe191c4a32e5e31c428f73400319461	classifier combination for hand-printed digit recognition	generalization error;classifier combination;handwriting recognition;performance evaluation;bayesian combination;neural networks;hand printed digit recognition;bayes methods;classifier system;bayesian methods;image classification;high performance nearest neighbor hand printed digit classifiers;testing;dynamic classifier selection;error free classification;evidential reasoning;error free classification hand printed digit recognition high performance nearest neighbor hand printed digit classifiers combination methods bayesian combination dempster shafer evidential reasoning dynamic classifier selection error rate k nearest neighbor combination classifier combination error reject curves;error analysis;combination methods;vents;combining classifier;aggregates;error correction;nearest neighbor;k nearest neighbor combination;pattern recognition;error rate;dempster shafer;k nearest neighbor;handwriting recognition character recognition image classification bayes methods case based reasoning;case based reasoning;neural networks bayesian methods error analysis error correction testing performance evaluation costs pattern recognition vents aggregates;dempster shafer evidential reasoning;high performance;character recognition;error reject curves	Independent decisions by t w o high performance nearest-neighbour hand-printed digit classifiers are combined in a principled manner . Three combinat ion methods are investigated: Bayesian combination, Dempster-Shafer evidential reasoning, and dynamic classifier selection. O n a test set of 60,000 handprinted digits, dynamic classifier selection performs slightly better than Bayesian or Dempster-Shafer evidential reasoning, but the lowest error rate i s obtained by K-nearest-neighbour combination. Singleparameter classifier combination i s used t o generate error-reject curves. Essentially error-free classaficat ion i s obtained at the cost of 4% rejects! The zeroreject error rate decreases f r o m 1.18% for the best single classifier s y s t e m t o 0.6’7% for the combined classif ier .	printing;statistical classification;test set	Michael Sabourin;Amar Mitiche;Danny S. Thomas;George Nagy	1993		10.1109/ICDAR.1993.395758	margin classifier;bayes classifier;margin;speech recognition;quadratic classifier;computer science;machine learning;pattern recognition;bayes error rate;handwriting recognition;k-nearest neighbors algorithm	Vision	14.964306172240102	-36.11858590695028	90096
76cd2a76966726f02065d370ba3c142b6806b09d	an em based training algorithm for recurrent neural networks	dynamic system;time series;dynamical system identification;recurrent network;expectation maximization;transfer function;radiation therapy;recurrent neural networks;recurrent neural network;state space model;particle smoother;em;nonlinear dynamic system;time series prediction;training algorithm;state transition	Recurrent neural networks serve as black-box models for nonlinear dynamical systems identification and time series prediction. Training of recurrent networks typically minimizes the quadratic difference of the network output and an observed time series. This implicitely assumes that the dynamics of the underlying system is deterministic, which is not a realistic assumption in many cases. In contrast, statespace models allow for noise in both the internal state transitions and the mapping from internal states to observations. Here, we consider recurrent networks as nonlinear state space models and suggest a training algorithm based on Expectation-Maximization. A nonlinear transfer function for the hidden neurons leads to an intractable inference problem. We investigate the use of a Particle Smoother to approximate the E-step and simultaneously estimate the expectations required in the Mstep. The method is demonstrated for a sythetic data set and a time series prediction task arising in radiation therapy where it is the goal to predict the motion of a lung tumor during respiration.	approximation algorithm;artificial neural network;black box;dynamical system;expectation–maximization algorithm;neural networks;nonlinear system;optimization problem;quadratic function;recurrent neural network;state space;synthetic data;time series;transfer function	Jan Unkelbach;Yi Sun;Jürgen Schmidhuber	2009		10.1007/978-3-642-04274-4_99	computer science;artificial intelligence;recurrent neural network;machine learning;time series;control theory	ML	19.298423461565235	-25.297761079493377	90117
6d69a1c9e5d12b3f6c3662d225b24a8c8c98e717	classification of volcano-seismic signals with bayesian neural networks		Whilst recent advances in the field of artificial neural networks could be applied to monitor volcanoes, its direct application remains a challenge given the complex geodynamics involved and the size of available datasets. However, Bayesian Neural Networks (BNNs) are probabilistic models that could classify and provide uncertainty estimation for transient seismic sources, even under data scarcity conditions. This research focuses on practical applications of BNNs to classify volcano-seismic signals using two variational learning approaches: Bayes by back-prop and Monte-Carlo dropout. We evaluate classification performance on seven classes of isolated events registered at “Volcán de Fuego”, Colima. Experimental results show an overall improvement for Monte-Carlo dropout approximation when compared to Bayes by backprop. Being at the intersection of Bayesian learning and geophysics, we demonstrate that BNNs provide uncertainty estimations when internal volcano-seismic sources change, which undoubtedly helps to enhance current early warning systems at volcanic observatories.		Ángel Bueno;Manuel Titos;Luz García;Isaac Álvarez;Jesús Ibáñez;M. Carmen Benítez	2018	2018 26th European Signal Processing Conference (EUSIPCO)	10.23919/EUSIPCO.2018.8553358	geodynamics;machine learning;artificial neural network;probabilistic logic;signal processing;bayes' theorem;bayesian inference;artificial intelligence;warning system;computer science;bayesian probability	ML	23.02864643778801	-25.210554231380083	90181
210b98206ecd0ea92bcb41b3dbe61dbfb63f2f32	multiple-source adaptation for regression problems		We present a detailed theoretical analysis of the problem of multiple-source adaptation in the general stochastic scenario, extending known results that assume a single target labeling function. Our results cover a more realistic scenario and show the existence of a single robust predictor accurate for any target mixture of the source distributions. Moreover, we present an efficient and practical optimization solution to determine the robust predictor in the important case of squared loss, by casting the problem as an instance of DC-programming. We report the results of experiments with both an artificial task and a sentiment analysis task. We find that our algorithm outperforms competing approaches by producing a single robust model that performs well on any target mixture distribution.	algorithm;experiment;kerrison predictor;mathematical optimization;mean squared error;sentiment analysis	Judy Hoffman;Mehryar Mohri;Ningshan Zhang	2017	CoRR		sentiment analysis;mathematical optimization;square (algebra);mathematics;mixture distribution	ML	19.339122682990393	-36.27737010620642	90246
cad52eab9052df8a85517a5ea9fab87ea309496e	an empirical comparison of neural techniques for edge linking of images	eficacia sistema;optimisation;vision ordenador;liaison contour;learning algorithm;active contour;image processing;optimizacion;time complexity;etude experimentale;edge detection;travelling salesman problem;emastic net;active contours snakes;performance systeme;procesamiento imagen;algorithme apprentissage;system performance;traitement image;auto apprentissage;computer vision;deteccion contorno;problema viajante comercio;edge linking;detection contour;complexite temps;probleme commis voyageur;reseau elastique;vision ordinateur;optimization;contour actif;reseau neuronal;complejidad tiempo;algoritmo aprendizaje;estudio experimental;red neuronal;neural network	Edge linking is a fundamental computer vision task, yet presents difficulties arising from the lack of information in the image. Viewed as a constrained optimisation problem, it is NP hard — being isomorphic to the classical travelling salesman problem. Self-learning neural techniques boast the ability to solve hard, ill-defined problems, and hence offer promise for such an application. This paper examines the suitability of four well-known unsupervised techniques for the task of edge linking, by applying them to a test bed of edge point images and then evaluating their performance both quantitatively and qualitatively. Techniques studied are the elastic net, active contours, Kohonen map and Burr's modified elastic net. Of these, only the elastic net and the Kohonen map are realistic contenders for general edge-linking tasks. However, the other two exhibit behaviour which may make them particularly suited to some specific image-processing and computer vision applications.	active galactic nucleus;computer vision;edge detection;elastic map;elastic net regularization;image processing;mathematical optimization;np-hardness;self-organizing map;testbed;travelling salesman problem;unsupervised learning	Robert I. Damper;Stuart J. Gilson	1997	Neural Computing & Applications	10.1007/BF01414004	time complexity;edge detection;image processing;computer science;artificial intelligence;active contour model;mathematics;travelling salesman problem;artificial neural network;algorithm	Vision	11.986812068401147	-31.829316069197375	90282
6ddd19646af3d7aaf204503328bd1c61f54f3d91	lazy training of radial basis neural networks	condition initiale;learning algorithm;red local;radial basis neural networks;interrogation base donnee;interrogacion base datos;inicializacion;intelligence artificielle;algorithme apprentissage;time series;approche deterministe;lazy learning;deterministic approach;local network;condicion inicial;neural net work;serie temporelle;initial condition;enfoque determinista;serie temporal;pattern recognition;pattern selection;artificial intelligence;inteligencia artificial;reconnaissance forme;reseau neuronal;reconocimiento patron;reseau local;algoritmo aprendizaje;local learning;database query;red neuronal;initialization;initialisation;neural network	Usually, training data are not evenly distributed in the input space. This makes non-local methods, like Neural Networks, not very accurate in those cases. On the other hand, local methods have the problem of how to know which are the best examples for each test pattern. In this work, we present a way of performing a trade off between local and nonlocal methods. On one hand a Radial Basis Neural Network is used like learning algorithm, on the other hand a selection of the training patterns is used for each query. Moreover, the RBNN initialization algorithm has been modified in a deterministic way to eliminate any initial condition influence. Finally, the new method has been validated in two time series domains, an artificial and a real world one.	algorithm;artificial neural network;initial condition;lazy evaluation;neural network software;quantum nonlocality;radial (radio);test card;time series	José María Valls;Inés María Galván;Pedro Isasi Viñuela	2006		10.1007/11840817_21	local area network;initialization;computer science;artificial intelligence;machine learning;time series;programming language;deterministic system;initial value problem;artificial neural network;algorithm;statistics	ML	11.114612156041696	-30.200040206150643	90472
f890f1700ea672259506db0e1da7a176d02624ff	a neural algorithm for document clustering	document clustering;systeme documentaire;implementation;algorithme;algorithm;ejecucion;modelo;traitement document;sistema recuperacion documental;document retrieval system;modele;document processing;classification automatique;reseau neuronal;automatic classification;clasificacion automatica;models;red neuronal;tratamiento documento;neural network;algoritmo	A difficulty in implementing document clustering using algorithms based on sequential architectures is that a computational bottleneck arises eventually in the classification of documents. Neural networks have the potential to alleviate this problem. This paper reviews the fundamentals of a framework for describing neural nets. Next, the MacLeod algorithm, a neural network algorithm designed specifically for document clustering is presented. The features of this algorithm are examined. Experimental results from two small test collections are reported. Based on these results the algorithm exhibits effectiveness comparable to hierarchic (sequential) clustering algorithms. The MacLeod algorithm also appears to require time and space complexities of 0 (n * ) and O(n), respectively. Experimental results show that the algorithm’s performance is order independent.	algorithm;artificial neural network;cluster analysis;computer performance	Kevin J. Macleod;W. Robertson	1991	Inf. Process. Manage.	10.1016/0306-4573(91)90088-4	correlation clustering;data stream clustering;document processing;document clustering;fuzzy clustering;computer science;artificial intelligence;canopy clustering algorithm;machine learning;cure data clustering algorithm;cluster analysis;k-medoids;implementation;algorithm	ML	10.859788194481057	-32.70144888010424	90558
822f79e1f1a6bbb31aa5ed2ed1576ee4a00a72e7	brain emotional learning-based pattern recognizer	belbic;bel;amygdala;computational model	In this article, the brain emotional learning-based pattern recognizer BELPR is proposed to solve multiple input–multiple output classification and chaotic time series prediction problems. BELPR is based on an extended computational model of the human brain limbic system that consists of an emotional stimuli processor. The BELPR is model free and learns the patterns in a supervised manner and evaluates the outputs using the activation function tansig. In the numerical studies, various comparisons are made between BELPR and a multilayer perceptron MLP with a back-propagation learning algorithm. The methods are tested to classify 12 UCI University of California, Irvine machine learning data sets and to predict activity indices of the Earth's magnetosphere. The main features of BELPR are higher accuracy, decreased time and spatial complexity, and faster training.	finite-state machine	Ehsan Lotfi;Mohammad R. Akbarzadeh-Totonchi	2013	Cybernetics and Systems	10.1080/01969722.2013.789652	speech recognition;computer science;artificial intelligence;machine learning;computational model	NLP	13.196141428470694	-27.843692308653953	90647
3983d0c209a634f434b8372454931e659e5660bf	gaussian process kernels for noisy time series: application to housing price prediction		We study the prediction of time series using Gaussian processes as applied to realistic time series such as housing prices in Hong Kong. Since the performance of Gaussian processes prediction is strongly dependent on the functional form of the adopted kernel, we propose to determine the kernel based on the useful information extracted from the training data. However, the essential features of the time series are concealed by the presence of noises in the training data. By applying rolling linear regression, smooth and denoised time series of change rates of the data are obtained. Surprisingly, a periodic pattern emerges, enabling us to formulate an empirical kernel. We show that the empirical kernel performs better in predictions on quasi-periodic time series, compared to popular kernels such as spectral mixture, squared exponential, and rational quadratic kernels. We further justify the potential of the empirical kernel by applying it to predicting the yearly mean total sunspot number.		Juntao Wang;Wun Kwan Yam;Kin Long Fong;Siew Ann Cheong;K. Y. Michael Wong	2018		10.1007/978-3-030-04224-0_8	periodic graph (geometry);applied mathematics;time series;kernel (linear algebra);square (algebra);pattern recognition;quadratic equation;computer science;linear regression;gaussian process;artificial intelligence;exponential function	ML	22.577282185835532	-27.723227180853442	90788
6aab18553bf5b5a6cc5497cc038d2019c1a0924e	cooperative coevolutionary mixture of experts : a neuro ensemble approach for automatic decomposition of classification problems			ensemble learning	Minh Ha Nguyen	2006				AI	11.286367975447579	-26.95467642376279	91325
0e3bd3ca50a171f46563d1881de8fe48e3b2c422	visualising temporal data using reservoir computing		We create an artificial neural network which is a version of echo state machines, ESNs. ESNs are recurrent neural networks but unlike most recurrent networks, they come with an efficient training method. We adapt this method using ideas from the neuroscale algorithm so that the network is optimal for projecting multivariate time series data onto a low dimensional manifold so that the structure in the time series can be identified by eye. We illustrate the resulting projections on real and artificial data. Finally we compare visualisation by the technique described herein with visualisation with various standard techniques and demonstrate that the method described in this paper is better.	algorithm;artificial neural network;recurrent neural network;reservoir computing;scientific visualization;teaching method;time series	Tzai-Der Wang;Colin Fyfe	2013	J. Inf. Sci. Eng.		computer science;distributed computing;temporal database;machine learning;time series;finite-state machine;visualization;reservoir computing;artificial neural network;artificial intelligence;recurrent neural network;multivariate statistics	ML	13.562444970741325	-29.804291599964024	91363
d89b93fa65cf238160983039cb98eea7360992d7	greedy rule generation from discrete data and its use in neural network rule extraction	decision tree;discrete data;generic algorithm;neural nets;decision tree method greedy rule generation discrete data neural network rule extraction classification rules;rule extraction;greedy algorithms;classification rules;pattern classification;intelligent networks neural networks data mining artificial neural networks electronic mail classification algorithms machine learning algorithms cancer computer science computer networks;decision trees;pattern classification decision trees greedy algorithms neural nets;neural network	"""This paper proposes GRG (greedy rule generation) algorithm for generating classification rules from a data set with discrete attributes. The algorithm is """"greedy"""" in the sense that at every iteration, it searches for the best rule to generate. The criteria for the best rule include the number of samples that it covers, the number of attributes involved in the rule, and the size of the input subspace it covers. This method is applied for extracting rules from neural networks that have been trained and pruned for solving classification problems. Neural networks with one hidden layer are trained and the proposed GRG algorithm is applied to their discretized hidden unit activation values. Our results show that rule extraction with the GRG method produces rule sets that are more accurate and concise compared to those obtained by a decision tree method and an existing neural network rule extraction method."""		Koichi Odajima;Yoichi Hayashi;Rudy Setiono	2006		10.1109/IJCNN.2006.246902	delta rule;computer science;machine learning;decision tree;pattern recognition;data mining;artificial neural network	AI	13.723601012804686	-34.550781533186296	91382
bb3941919312d100502d9f3017840d182052501f	strategies for improving neural net generalisation	empirical study;learning algorithm;majority rule;algorithme apprentissage;multilayer perceptron;backpropagation;regla mayoria;neural net;backpropagation algorithm;regle majorite;algorithme retropropagation;multilayer network;reseau multicouche;perceptron;reseau neuronal;majority voting;red neuronal;neural network	We address the problem of training multilayer perceptrons to instantiate a target function. In particular, we explore the accuracy of the trained network on a test set of previously unseen patterns — the generalisation ability of the trained network. We systematically evaluate alternative strategies designed to improve the generalisation performance. The basic idea is to generate a diverse set of networks, each of which is designed to be an implementation of the target function. We then have a set of trained, alternative versions — a version set. The goal is to achieve ‘useful diversity’ within this set, and thus generate potential for improved generalisation performance of the set as a wholewhen compared to the performance of any individual version. We define this notion of ‘useful diversity’, we define a metric for it, we explore a number of ways of generating it, and we present the results of an empirical study of a number of strategies for exploiting it to achieve maximum generalisation performance. The strategies encompass statistical measures as well as a ‘selectornet’ approach which proves to be particularly promising. The selector net is a form of ‘metanet’ that operates in conjunction with a version set.	artificial neural network;multilayer perceptron;test set	Derek Partridge;Niall J. L. Griffith	1995	Neural Computing & Applications	10.1007/BF01414174	majority rule;computer science;artificial intelligence;backpropagation;machine learning;artificial neural network;algorithm	ML	15.685286573375615	-33.10976766272469	91461
59647f0ebbf5770bfd1a2c44cc0d32d243864e52	capacity control of relu neural networks by basis-path norm		Recently, path norm was proposed as a new capacity measure for neural networks with Rectified Linear Unit (ReLU) activation function, which takes the rescaling-invariant property of ReLU into account. It has been shown that the generalization error bound in terms of the path norm explains the empirical generalization behaviors of the ReLU neural networks better than that of other capacity measures. Moreover, optimization algorithms which take path norm as the regularization term to the loss function, like Path-SGD, have been shown to achieve better generalization performance. However, the path norm counts the values of all paths, and hence the capacity measure based on path norm could be improperly influenced by the dependency among different paths. It is also known that each path of a ReLU network can be represented by a small group of linearly independent basis paths with multiplication and division operation, which indicates that the generalization behavior of the network only depends on only a few basis paths. Motivated by this, we propose a new norm Basis-path Norm based on a group of linearly independent paths to measure the capacity of neural networks more accurately. We establish a generalization error bound based on this basis path norm, and show it explains the generalization behaviors of ReLU networks more accurately than previous capacity measures via extensive experiments. In addition, we develop optimization algorithms which minimize the empirical risk regularized by the basis-path norm. Our experiments on benchmark datasets demonstrate that the proposed regularization method achieves clearly better performance on the test set than the previous regularization approaches.	activation function;algorithm;artificial neural network;benchmark (computing);experiment;generalization error;loss function;mathematical optimization;rectifier (neural networks);test set	Shuxin Zheng;Qi Meng;Huishuai Zhang;Wei Chen;Nenghai Yu;Tie-Yan Liu	2018	CoRR		mathematical optimization;machine learning;artificial intelligence;artificial neural network;linear independence;mathematics;regularization (mathematics);multiplication;rectifier (neural networks);activation function;test set;norm (social)	ML	17.289914005520178	-31.725823507177356	91820
5f6fcf18593be853e2d891907c8c7f96b51aa401	algorithm optimization using features in svd & classification in eigenspace		Singular Value Decomposition (SVD) is ubiquitous in a range of applications including computer science, economics, engineering, geology, oceanography, psychology, social networking etc. It is an unsupervised modeling technique that creates latent vectors for a subspace that reduces the dimensionality of observed data from n to k (k<<n) dimensions. Latent variables are uncorrelated variation of attribute values that are correlated in the original space. Moreover, SVD can be used to detect/remove noise/outliers, cluster similar entities and make predictions. On the other hand, classification tree is a supervised technique that accomplishes the similar tasks. It models decision trees from training data in order to make intelligent predictions. There is a close connection between SVD and decision trees, but differ in purpose, algorithm design and error analysis techniques. We present a hybrid algorithm bridges the gap between these standalone algorithms and adaptively supersedes their outcomes. For experimental analysis, we use realworld benchmark data, wines, publicly available from UCI machine learning repository. The algorithm is implemented in Matlab, supported by decision trees in Weka software, on MacOS Seirra Version 10.12.3 8GB 160MHZ.	algorithm design;benchmark (computing);computer science;decision tree learning;dimensionality reduction;entity;error analysis (mathematics);hybrid algorithm;latent class model;matlab;machine learning;singular value decomposition;supervised learning;variable (computer science);weka	Chaman Lal Sabharwal	2017	Polibits	10.17562/PB-56-1	eigenvalues and eigenvectors;singular value decomposition;artificial intelligence;pattern recognition;mathematics	ML	13.023543679717832	-37.33227384056938	91888
f95fce5134662ad918e9391486fe3a2ab0619276	quality-relevant batch process fault detection using a multiway multi-subspace cva method		For batch process fault detection, regular data-driven methods cannot distinguish quality-irrelevant faults from quality-relevant faults. To solve such problem, we propose a multiway multi-subspace canonical variate analysis (MMCVA) method for the batch processes. First, the combination of batch-wise unfolding and variable-wise unfolding is adopted to unfold the three-way process and quality data in to two-way data. Then, we use CVA to project the process and quality data spaces to three subspaces, a process-quality correlated subspace, a quality-uncorrelated process subspace, and a process-uncorrelated quality subspace. Fault detection statistics are developed based on the three subspaces. The proposed MMCVA method is capable of indicating the normality or abnormality of the quality variables, while detecting a process fault. The simulation results of a fed-batch penicillin fermentation process illustrate the effectiveness of the proposed method.	batch processing;dataspaces;fault detection and isolation;relevance;sensor;simulation;unfolding (dsp implementation)	Yuping Cao;Yongping Hu;Xiaogang Deng;Xuemin Tian	2017	IEEE Access	10.1109/ACCESS.2017.2764538	random variate;linear subspace;batch processing;computer science;machine learning;subspace topology;fault detection and isolation;artificial intelligence	Robotics	23.539371830565166	-24.532960801193518	91902
b0b5abb838cef36e3a3ad9ebbfff0f852deaea9a	exterior penalty function method based ica algorithm for hybrid sources using gknn estimation	optimisation sous contrainte;metodo separacion;modelizacion;constrained optimization;traitement signal;mezcla senal;signal mixing;separation method;signal estimation;funcion densidad probabilidad;approximation plus proche voisin;probability density function;metodo penalidad;optimization method;blind;source signal;independent component analysis;melange signal;metodo optimizacion;optimizacion con restriccion;modelisation;fonction densite probabilite;penalty method;methode penalite;funcion penalidad;mathematical programming;signal processing;estimacion senal;separacion senal;methode optimisation;analyse composante independante;k nearest neighbor;signal sources;separation source;methode separation;reseau neuronal;fonction penalite;analisis componente independiente;source separation;constrained optimization problem;procesamiento senal;modeling;estimation signal;programmation mathematique;programacion matematica;red neuronal;ciego;nearest neighbor approximation;neural network;penalty function;aveugle	In the formulation of radial basis function (RBF) network, there are three factors mainly considered, i.e., centers, widths, and weights, which significantly affect the performance of the network. Within thus three factors, the placement of centers is proved theoretically and practically to be critical. In order to obtain a compact network, this paper presents an improved clustering (IC) scheme to obtain the location of the centers. What is more, since the location of the corresponding widths does affect the performance of the networks, a learning algorithms referred to as anisotropic gradient descent (AGD) method for designing the widths is presented as well. In the context of this paper, the conventional gradient descent method for learning the weights of the networks is combined with that of the widths to form an array of couple recursive equations. The implementation of the proposed algorithm shows that it is as efficient and practical as GGAP-RBF.	algorithm;cluster analysis;computational complexity theory;gradient descent;image scaling;independent computing architecture;integrated circuit;machine learning;penalty method;radial (radio);radial basis function network;recursion	Fasong Wang;Hongwei Li;Rui Li	2006		10.1007/11893028_123	constrained optimization;computer science;machine learning;signal processing;penalty method;mathematics;artificial neural network;algorithm;statistics	ML	19.519352434412166	-28.37416790955168	92031
c3e91a2fecc9805206cda42a32182aa2b68889a1	optimal oracle inequality for aggregation of classifiers under low noise condition	regularite;metodo adaptativo;minimax problem;oracle inequality;regularidad;problema minimax;metodo minimax;regularity;minimax method;methode adaptative;intelligence artificielle;satisfiability;classification;probleme minimax;low noise;adaptive method;methode minimax;artificial intelligence;binary classification;inteligencia artificial;clasificacion;oracle	We consider the problem of optimality, in a minimax sense, and adaptivity to the margin and to regularity in binary classification. We prove an oracle inequality, under the margin assumption (low noise condition), satisfied by an aggregation procedure which uses exponential weights. This oracle inequality has an optimal residual: (log M/n) where κ is the margin parameter, M the number of classifiers to aggregate and n the number of observations. We use this inequality first to construct minimax classifiers under margin and regularity assumptions and second to aggregate them to obtain a classifier which is adaptive both to the margin and regularity. Moreover, by aggregating plug-in classifiers (only log n), we provide an easily implementable classifier adaptive both to the margin and to regularity.	aggregate data;binary classification;minimax;oracle nosql db;plug-in (computing);social inequality;statistical classification;time complexity	Guillaume Lecué	2006		10.1007/11776420_28	binary classification;oracle;mathematical optimization;margin;biological classification;computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics;satisfiability	ML	20.321286108882838	-33.99858988572672	92084
26131dfbe8d41e498fdc5d30838ea40ec9a965ce	self-regulating neurons: a model for synaptic plasticity in artificial recurrent neural networks	evolutionary robotics;recurrent neural network;homeostasis		artificial neural network;recurrent neural network;synaptic package manager	Keyan Zahedi	2009				ML	12.557195654642806	-27.337432287907266	92256
6df2d4900053d256f392646df8c02dd14998cef0	semi-supervised learning for improved expression of uncertainty in discriminative classifiers.	semi supervised learning	Seeking classifier models that are not overconfident and that better represent the inherent uncertainty over a set of choices, we extend an objective for semi-supervised learning for neural networks to two models from the ratio semi-definite classifier (RSC) family. We show that the RSC family of classifiers produces smoother transitions between classes on a vowel classification task, and that the semi-supervised framework provides further benefits for smooth transitions. Finally, our testing methodology presents a novel way to evaluate the smoothness of classifier transitions (interpolating between vowels) by using samples from classes unseen during training time.	artificial neural network;convolutional code;discriminative model;interpolation;loss function;optimization problem;ordinal data;semi-supervised learning;semiconductor industry;supervised learning	Jonathan Malkin;Jeff A. Bilmes	2010			semi-supervised learning;unsupervised learning;computer science;machine learning;pattern recognition;discriminative model;generalization error	ML	20.899152941913304	-35.99926219107207	92448
ac2e20febe7ce71c2a6760d345829100ce2e5a19	an efficient algorithm for large-scale quasi-supervised learning	nearest neighbor rule;posterior probability estimation;transductive inference;quasi supervised learning;article;large scale pattern recognition	We present a novel formulation for quasi-supervised learning that extends the learning paradigm to large datasets. Quasi-supervised learning computes the posterior probabilities of overlapping datasets at each sample and labels those that are highly specific to their respective datasets. The proposed formulation partitions the data into sample groups to compute the dataset posterior probabilities in a smaller computational complexity. In experiments on synthetic as well as real datasets, the proposed algorithm attained significant reduction in the computation time for similar recognition performances compared to the original algorithm, effectively generalizing the quasi-supervised learning paradigm to applications characterized by very large datasets.	analysis of algorithms;cluster analysis;computation;computational complexity theory;dhrystone;experiment;futures studies;iteration;k-means clustering;k-nearest neighbors algorithm;mathematical optimization;numerical analysis;parallel computing;performance;perturbation theory;programming paradigm;randomness;refinement (computing);stationary process;supervised learning;synthetic intelligence;time complexity	Bilge Karaçali	2014	Pattern Analysis and Applications	10.1007/s10044-014-0401-y	semi-supervised learning;transduction;computer science;machine learning;pattern recognition;data mining;statistics	ML	24.034174452513692	-36.584725237954025	92557
abc308c574906937dc16a4230fff87568dc2582a	finding better topologies for deep convolutional neural networks by evolution		Due to the nonlinearity of artificial neural networks, designing topologies for deep convolutional neural networks (CNN) is a challenging task and often only heuristic approach, such as trial and error, can be applied. Evolutionary algorithm can solve optimization problems where the fitness landscape is unknown. However, evolutionary algorithm is computing resource intensive, which makes it difficult for problems when deep CNNs are involved. In this paper we propose an evolutionary strategy to find better topologies for deep CNNs. Incorporating the concept of knowledge inheritance and knowledge learning, our evolutionary algorithm can be executed with limited computing resources. We applied the proposed algorithm in finding effective topologies of deep CNNs for the image classification task using CIFAR10 dataset. After the evolution, we analyzed the topologies that performed well for this task. Our studies verify the techniques that have been commonly used in human designed deep CNNs. We also discovered that some of the graph properties greatly affect the system performance. We applied the guidelines learned from the evolution and designed new network topologies that outperform Residual Net with less layers on CIFAR-10, CIFAR100 and SVHN dataset.	artificial neural network;computer vision;connectivity (graph theory);convolutional neural network;epoch (reference date);evolution;evolutionary algorithm;experiment;graph property;heuristic;mathematical optimization;network topology;neural networks;nonlinear system	Honglei Zhang;Serkan Kiranyaz;Moncef Gabbouj	2018	CoRR		fitness landscape;convolutional neural network;machine learning;network topology;artificial intelligence;artificial neural network;contextual image classification;evolutionary algorithm;evolution strategy;optimization problem;computer science	AI	15.212704221594164	-24.027254065923813	92736
29424f75bc147780d8b08bf6d744e822d7ce4e0e	explicit learning curves for transduction and application to clustering and compression algorithms	compression algorithm;sums of random variables;learning curve;concentration inequality;prior distribution;support vector;artificial intelligent;data dependence;exact computation;inductive learning;support vector machine;error bound;sampling without replacement	Inductive learning is based on inferring a general rule from a finite data set and using it to label new data. In transduction one attempts to solve the problem of using a labeled training set to label a set of unlabeled points, which are given to the learner prior to learning. Although transduction seems at the outset to be an easier task than induction, there have not been many provably useful algorithms for transduction. Moreover, the precise relation between induction and transduction has not yet been determined. The main theoretical developments related to transduction were presented by Vapnik more than twenty years ago. One of Vapnik’s basic results is a rather tight error bound for transduction based on exact computation of the hypergeometric tail. While being tight, this bound is given implicitly via a computational routine. Our first contribution is a somewhat looser but explicit characterization of a slightly extended PAC-Bayesian version of Vapnik’s transductive bound. This characterization is obtained using concentration inequalities for the tail of sums of random variables obtained by sampling without replacement. We then derive error bounds for compression schemes such as (transductive) support vector machines and for transduction algorithms based on clustering. The main observation used for deriving these new error bounds and algorithms is that the unlabeled test points, which in the transductive setting are known in advance, can be used in order to construct useful data dependent prior distributions over the hypothesis space.	algorithm;cluster analysis;computation;loose coupling;mathematical induction;sampling (signal processing);support vector machine;test set;transduction (machine learning)	Philip Derbeko;Ran El-Yaniv;Ron Meir	2004	J. Artif. Intell. Res.	10.1613/jair.1417	semi-supervised learning;support vector machine;transduction;computer science;artificial intelligence;theoretical computer science;machine learning;pattern recognition;mathematics;statistics	ML	20.434835859051745	-32.80741581689633	92951
026153a6341f866e0e4fc3884aa4a1e620cfb06b	robust boosting algorithm against mislabeling in multiclass problems	calcul neuronal;neural computation;chauffe appoint;estimator robustness;divergence;classification;calentamiento complementario;algorithme;algorithm;boosting;robustez estimador;62h30;reseau neuronal;clasificacion;red neuronal;computacion neuronal;divergencia;neural network;algoritmo;robustesse estimateur	We discuss robustness against mislabeling in multiclass labels for classification problems and propose two algorithms of boosting, the normalized Eta-Boost.M and Eta-Boost.M, based on the Eta-divergence. Those two boosting algorithms are closely related to models of mislabeling in which the label is erroneously exchanged for others. For the two boosting algorithms, theoretical aspects supporting the robustness for mislabeling are explored. We apply the proposed two boosting methods for synthetic and real data sets to investigate the performance of these methods, focusing on robustness, and confirm the validity of the proposed methods.	algorithm;boost;dhrystone;multiclass classification	Takashi Takenouchi;Shinto Eguchi;Noboru Murata;Takafumi Kanamori	2008	Neural Computation	10.1162/neco.2007.11-06-400	biological classification;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;divergence;boosting;artificial neural network;models of neural computation	ML	10.586757900600833	-32.221159120436155	92965
ec3a43db407d53774aa09c052ae2534de0688a28	a gene-regulated nested neural network		Neural networks have always been a popular approach for intelligent machine development and knowledge discovery. Although, reports have featured successful neural network implementations, problems still exists with this approach, particularly its excessive training time. In this paper, we propose a Gene-Regulated Nested Neural Network (GRNNN) model as an improvement to existing neural network models to solve the excessive training time problem. We use a Gene Regulatory Training Engine (GRTE) to control and distribute the genes that regulate the proposed nested neural network. The proposed GRNNN is evaluated and validated through experiments to classify accurately the 8bit XOR parity problem. Experimental results show that the proposed model does not require excessive training time and meets the required objectives.	algorithm;artificial intelligence;exclusive or;experiment;neural networks	Romi Rahmat;Muhammad Fermi Pasha;Mohammad Syukur;Rahmat Budiarto	2015	Int. Arab J. Inf. Technol.		simulation;artificial intelligence;machine learning;data mining;time delay neural network;algorithm	AI	12.853239345567564	-25.490584018107334	92990
9adf9f708aa2fcab63e86c6742c2f363e7181893	hybrid neural-global minimization method of logical rule extraction	neural networks;computational intelligence;rule extraction;backpropagation;data mining;density estimation;hybrid approach;multi layer perceptron;extraction of logical rules;neural network	Methodology of extraction of optimal sets of logical rules using neural networks and global minimization procedures has been developed. Initial rules are extracted using density estimation neural networks with rectangular functions or multi-layered perceptron (MLP) networks trained with constrained backpropagation algorithm, transforming MLPs into simpler networks performing logical functions. A constructive algorithm called C-MLP2LN is proposed, in which rules of increasing specificity are generated consecutively by adding more nodes to the network. Neural rule extraction is followed by optimization of rules using global minimization techniques. Estimation of confidence of various sets of rules is discussed. The hybrid approach to rule extraction has been applied to a number of benchmark and real life problems with very good results.	algorithm;artificial neural network;backpropagation;benchmark (computing);feature selection;global optimization;init;ishikawa diagram;level of detail;loss function;machine learning;mathematical optimization;multilayer perceptron;ork;program optimization;quad flat no-leads package;real life;rule induction;sensitivity and specificity;sigmoid function	Wlodzislaw Duch;Rafal Adamczak;Krzysztof Grabczewski;Grzegorz Zal	1999	JACIII	10.20965/jaciii.1999.p0348	density estimation;delta rule;computer science;backpropagation;machine learning;pattern recognition;data mining;multilayer perceptron;artificial neural network	ML	14.42188965970567	-29.46515536485143	93094
9fd11b665872768f58ae432da257f194bdd00a28	a new neural associative memory model	memoire associative;storage system;sistema informatico;computer system;intelligence artificielle;memoire hamming;simulator;hamming distance;simulador;associative storage;systeme memoire;distance hamming;simulateur;associative memory;memoria asociativa;artificial intelligence;systeme informatique;inteligencia artificial;reseau neuronal;sistema memoria;red neuronal;distancia hamming;neural network	A neural network consists of processing elements, nodes, and weighted arcs, connections, between the nodes. Every node has an activity leuel, which is also the output from the node. The connections provide the node with some input and forward the result of the computation of the node to other nodes. An associative memory is a storage device that stores pairs of patterns (ui, ui), for i = 1, 2 , . . . , m, in such a way that upon presentation of an input pattern x, which (in some predefined metric) is near to ui, pattern ui will be brought from store. The resulting pattern ui is the output pattern. The memory is autoassociative if ui = ui for all i, otherwise it is heteroassociatiue. Observe that there are always two types of computations in an associative memory: the storage of the patterns, and the retrieval from store. Associative memories can perform error correction and pattern recognition. They can also be used in coding theory and for data compression. In Ref. 1, associative memories are suggested for searching large databases, large sets of rules in expert systems, or objects with similar attributes in object descriptions. The main advantage of artificial neural networks is the massive parallelism they offer. Thus the practical impact of neural associative memories, that is, associative memories realized as neural networks, depends much on the progress in hardware implementations of neural networks. Especially interesting is the possibility of optical implementations.	artificial neural network;coding theory;computation;content-addressable memory;data compression;database;error detection and correction;expert system;parallel computing;pattern recognition	Patrik Floréen	1992	Int. J. Intell. Syst.	10.1002/int.4550070505	distributed shared memory;hamming distance;computer science;artificial intelligence;content-addressable memory;bidirectional associative memory;flat memory model;artificial neural network;algorithm;cognitive science;computing with memory;memory map	AI	13.23676963578663	-30.255837428597857	93212
1d95e9a051f04ccb2e0fa9cae8b69f8f2f2112b2	a neural gripper for arbitrary object grasping	grasping;learning algorithm;image processing;neural networks;prensor robot;prension;procesamiento imagen;algorithme apprentissage;gripping;traitement image;prehenseur;prehension;reseau neuronal;gripper;algoritmo aprendizaje;dextrous gripper;red neuronal;neural network	This paper presents a two-stage neural system to determine the contact points between a three-® ngered gripper and an object of arbitrary shape. In the ® rst stage, a CCD camera captures the image of the object and such an image is transformed into a two-dimensional outline through a nearest neighbour algorithm. In the second phase, two neural networks, functioning in cascade, select three contact points in the outline. A competitive Hop® eld neural network de® nes an approximate polygon considering a reduced number of boundary points of the original outline. Then, a supervised neural network, either a multi-layer perceptron or a radial basis function (RBF) network, ® nd the contact points. The experiments suggest that the RBF network trained by the global ridge regression method is suitable for on-line applications and presents the best overall performance in terms of accuracy and robustness to noise. Moreover, this method is able to ® nd correctly the contact points for objects of arbitrary shapes.	approximation algorithm;artificial neural network;charge-coupled device;contact order;edge detection;experiment;hop;hop-by-hop transport;image processing;layer (electronics);mathematical model;memory-level parallelism;multilayer perceptron;nearest neighbour algorithm;online and offline;parallel computing;performance;radial (radio);radial basis function network;robot end effector;test set	C. M. O. Valente;Aluizio F. R. Araújo;Glauco Augusto de Paula Caurin;A. Schammass	1999	Connect. Sci.	10.1080/095400999116269	computer vision;computer science;artificial intelligence;machine learning;artificial neural network	Robotics	14.096125977983112	-29.29865518482644	93289
21ae18fd9f6d82f6e021e46cfee287bd44adf6dd	time series classification with shallow learning shepard interpolation neural networks		Time series classification (TSC) has been an ongoing machine learning problem with countless proposed algorithms spanning a multitude of fields. Whole series, intervals, shapelet, dictionary-based, and model-based are all different past approaches to solving TSC. Then there’s deep learning approaches that try to utilize all the success demonstrated by neural network’s (NN) architecture in image classification to TSC. Deep learning typically requires vast amounts of training data and computational power to have meaningful results. But, what if there was a network inspired not by a biological brain, but that of mathematics proven in theory? Or better yet, what if that network was not as computationally expensive as deep learning networks, which have billions of parameters and need a surplus of training data? This desired network is exactly what the Shepard Interpolation Neural Networks (SINN) provide - a shallow learning approach with minimal training samples needed and a foundation on a statistical interpolation technique to achieve great results. These networks learn metric features which can be more mathematically explained and understood. In this paper, we leverage the novel SINN architecture on a popular benchmark TSC data set achieving state-of-the-art accuracy on several of its test sets while being competitive against the other established algorithms. We also demonstrate that even when there is a lack of training data, the SINN outperforms other deep learning algorithms.	artificial neural network;interpolation;neural network software;time series	Kaleb E. Smith;Phillip Williams	2018		10.1007/978-3-319-94211-7_36	interpolation;architecture;deep learning;artificial neural network;training set;pattern recognition;artificial intelligence;contextual image classification;computer science	ML	18.340412159934466	-31.702052923453813	93350
300e4b3a713766fa760057ac94bfc9773a3cbc86	the role of neural network size in trap/hats feature extraction	trap architecture;neural network size;hats feature extraction;band nn size;band nns;sufficient size;hats architecture;increased size;merger nn;hidden activation traps architecture;arbitrary size output;final performance	We study the role of sizes of neural networks (NNs) in TRAP (TempoRAl Patterns) and HATS (Hidden Activation TRAPS architecture) probabilistic features extraction. The question of sufficient size of band NNs is linked with the question whether the Merger is able to compensate for lower accuracy of band NNs. For both architectures, the performance increases with increasing size of Merger NN. For TRAP architecture, it was observed, that increasing band NN size over some value has not further positive effect on final performance. The situation is different when HATS architecture is employed – increasing size of band NNs has mostly negative effect on final performance. This is caused by merger not being able to efficiently exploit the information hidden in its input with increased size. The solution is proposed in form of bottle-neck NN which allows for arbitrary size output.	artificial neural network;exception handling;feature extraction	Frantisek Grézl	2011		10.1007/978-3-642-23538-2_40	simulation;speech recognition;artificial intelligence	ML	14.368709315938778	-33.63279252359512	93407
5cd34abb1e96e0c11f427364e40b1e87d6fc62c2	greedy part-wise learning of sum-product networks		Sum-product networks allow to model complex variable interactions while still granting efficient inference. However, most learning algorithms proposed so far are explicitly or implicitly restricted to the image domain, either by assuming variable neighborhood or by assuming that dependent variables are related by their magnitudes over the training set. In this paper, we introduce a novel algorithm, learning the structure and parameters of sum-product networks in a greedy bottom-up manner. Our algorithm iteratively merges probabilistic models of small variable scope to larger and more complex models. These merges are guided by statistical dependence test, and parameters are learned using a maximum mutual information principle. In experiments our method competes well with the existing learning algorithms for sumproduct networks on the task of reconstructing covered image regions, and outperforms these when neither neighborhood nor correlations by magnitude can be assumed.	bottom-up parsing;bottom-up proteomics;database;dictionary;experiment;greedy algorithm;information bottleneck method;information science;interaction;machine learning;mutual information;programming paradigm;recursion;test set;top-down and bottom-up design;variable (computer science)	Robert Peharz;Bernhard C. Geiger;Franz Pernkopf	2013		10.1007/978-3-642-40991-2_39	mathematical optimization;artificial intelligence;machine learning;data mining;mathematics;statistics	ML	17.842044292038125	-36.395637996203924	93427
34e2d0941216084b6ffc03a6b768f835c2f1a868	a linearly convergent linear-time first-order algorithm for support vector classification with a core set result	support vector machines;approximation algorithms;support vector classification;linear convergence;frank wolfe algorithm;core sets	We present a simple, first-order approximation algorithm for the support vector classification problem. Given a pair of linearly separable data sets and ∈ (0, 1), the proposed algorithm computes a separating hyperplane whose margin is within a factor of (1 − ) of that of the maximum-margin separating hyperplane. We discuss how our algorithm can be extended to nonlinearly separable and inseparable data sets. The running time of our algorithm is linear in the number of data points and in 1/ . In particular, the number of support vectors computed by the algorithm is bounded above by O(ζ/ ) for all sufficiently small > 0, where ζ is the square of the ratio of the distances between the farthest and closest points in the two data sets. Furthermore, we establish that our algorithm exhibits linear convergence. We adopt the real number model of computation in our analysis.	approximation algorithm;data point;first-order predicate;linear separability;model of computation;nonlinear system;order of approximation;perturbation theory;proximity problems;rate of convergence;separable polynomial;support vector machine;time complexity	Piyush Kumar;E. Alper Yildirim	2011	INFORMS Journal on Computing	10.1287/ijoc.1100.0412	support vector machine;frank–wolfe algorithm;mathematical optimization;combinatorics;discrete mathematics;ramer–douglas–peucker algorithm;computer science;mathematics;rate of convergence;linde–buzo–gray algorithm;approximation algorithm	ML	21.609154349947325	-36.961108665553375	93496
453a25aca3c4118b3eb99c7fc410faaf5ea690a4	function approximation using fuzzy neural networks with robust learning algorithm	gradient descent method;learning process;spline;fuzzy neural network;learning algorithm;fuzzy neural nets;neural networks;approximation algorithms;b spline membership functions;two dimensions;fuzzy control;indexing terms;fuzzy set theory;multi layer neural network;splines mathematics;objective function;training data;function approximation fuzzy neural networks robustness approximation algorithms spline fuzzy set theory neural networks training data multi layer neural network fuzzy control;function approximation;outliers;membership function;robustness;learning artificial intelligence fuzzy set theory function approximation fuzzy neural nets splines mathematics;erroneous training data;tolerable error scope function approximation fuzzy neural networks robust learning algorithm b spline membership functions outliers training data robust objective function gradient descent method erroneous training data;learning artificial intelligence;fuzzy neural networks;robust objective function;robust learning algorithm;tolerable error scope	The paper describes a novel application of the B-spline membership functions (BMF's) and the fuzzy neural network to the function approximation with outliers in training data. According to the robust objective function, we use gradient descent method to derive the new learning rules of the weighting values and BMF's of the fuzzy neural network for robust function approximation. In this paper, the robust learning algorithm is derived. During the learning process, the robust objective function comes into effect and the approximated function will gradually be unaffected by the erroneous training data. As a result, the robust function approximation can rapidly converge to the desired tolerable error scope. In other words, the learning iterations will decrease greatly. We realize the function approximation not only in one dimension (curves), but also in two dimension (surfaces). Several examples are simulated in order to confirm the efficiency and feasibility of the proposed approach in this paper.		Wei-Yen Wang;Tsu-Tian Lee;Ching-Lang Liu;Chi-Hsu Wang	1997	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/3477.604123	gradient descent;spline;training set;mathematical optimization;outlier;two-dimensional space;index term;membership function;function approximation;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;fuzzy set;artificial neural network;robustness	ML	15.400892553143745	-29.94171129475841	93570
6169a6cb2f2f3ed90cce7b3ddd201437e471d229	a dynamic overproduce-and-choose strategy for the selection of classifier ensembles	dynamic programming;evaluation performance;appareillage essai;optimisation;programacion dinamica;classifier ensemble;performance evaluation;optimizacion;evaluacion prestacion;measures of confidence;dynamic classifier selection;aparato ensayo;signal classification;programmation dynamique;testing equipment;classification signal;optimization;overproduce and choose strategy;classification automatique;automatic classification;clasificacion automatica	The overproduce-and-choose strategy, which is divided into the overproduction and selection phases, has traditionally focused on finding the most accurate subset of classifiers at the selection phase, and using it to predict the class of all the samples in the test data set. It is therefore, a static classifier ensemble selection strategy. In this paper, we propose a dynamic overproduce-and-choose strategy which combines optimization and dynamic selection in a two-level selection phase to allow the selection of the most confident subset of classifiers to label each test sample individually. The optimization level is intended to generate a population of highly accurate candidate classifier ensembles, while the dynamic selection level applies measures of confidence to reveal the candidate ensemble with the highest degree of confidence in the current decision. Experimental results conducted to compare the proposed method to a static overproduce-and-choose strategy and a classical dynamic classifier selection approach demonstrate that our method outperforms both these selection-based methods, and is also more efficient in terms of performance than combining the decisions of all classifiers in the initial pool.	neural ensemble	Eulanda Miranda dos Santos;Robert Sabourin;Patrick Maupin	2008	Pattern Recognition	10.1016/j.patcog.2008.03.027	computer science;machine learning;dynamic programming;pattern recognition;data mining;mathematics	Vision	10.822199975136199	-34.45278661702116	93747
de1069b4b7da6fbb9e6670b234e8a692067f54a7	algorithm and implementation of a learning multiple-valued logic network	minimisation;minimization;many valued logics;neural networks;error function;piecewise linear techniques;least square error;logic circuits;distortion measurement;minimization methods;minimisation learning artificial intelligence logic circuits many valued logics;learning rule learning multiple valued logic network learning technique multiple valued logic minimization error function distortion gradient based least square error minimization;learning technique;distortion;cmos logic circuits piecewise linear techniques backpropagation algorithms arithmetic distortion measurement logic testing minimization methods current mode circuits logic functions neural networks;cmos logic circuits;backpropagation algorithm;logic functions;logic testing;backpropagation algorithms;current mode circuit;current mode circuits;learning problems;arithmetic;least square error minimization;gradient based;learning artificial intelligence;multiple valued;learning rule;learning multiple valued logic network;multiple valued logic	A learning technique and implementation for multiple-valued logic (MVL) networks are described. The learning problem is formulated as a minimization of an error function that represents a measure of distortion between actual and desired output. A gradient-based least-square-error minimization algorithm is used to minimize the error function, which in contrast to the backpropagation algorithm, does not involve a sigmoid function and requires only a simple sgn function in the learning rule. The algorithm trains the networks using examples and appears to be available in practice for most multiple-valued problems of interest. Circuit implementations of the learning MVL networks using CMOS current-mode circuits are described. >	algorithm	Qi-xin Cao;Okihiko Ishizuka;Zheng Tang;Hiroki Matsumoto	1993		10.1109/ISMVL.1993.289559	minimisation;discrete mathematics;empirical risk minimization;wake-sleep algorithm;distortion;logic gate;computer science;backpropagation;theoretical computer science;online machine learning;error function;machine learning;mathematics;supervised learning;stability;artificial neural network;statistics;population-based incremental learning;generalization error	Logic	16.26418376150318	-27.32211574742682	93775
5f7f650c39fe74f8eeb858532c94807a31698ceb	neurocomputing hardware: present and future	puce ocr synaptique;connectionism;conexionismo;connaissance;performance;circuit vlsi;intelligence artificielle;conocimiento;costo;connexionnisme;knowledge;ordinateur neuronal;vlsi circuit;contexto;contexte;systeme cnaps;artificial intelligence;inteligencia artificial;rendimiento;circuito vlsi;reseau neuronal;materiel informatique;material informatica;red neuronal;context;puce intel etann;neural network;hardware;cout	This paper discusses the current state of the art of industrial neurocomputing, and then speculates on its future. Three examples of commercial neuro-silicon are presented: the Adaptive Solutions CNAPS system, the Intel ETANN chip, and the Synaptics OCR chip. We then speculate on where commercial neurocomputing hardware is going. In particular we propose that commercial systems will evolve in the direction of capturing more contextual, knowledge level information. Some results of an industrial handwritten character recognition system created at Apple Computers will be presented which demonstrate the power of adding contextual knowledge to neural network based recognition. Also discussed will be some of the possible directions required for neural network algorithms needed to capture such knowledge and utilize it effectively, as well as results from experiments on capturing contextual knowledge using several different neural network algorithms. Finally, the issues involved in designing VLSI architectures for the efficient emulation of sparsely activated, sparsely connected contextual networks will be discussed. There are fundamental cost/performance limits when emulating such sparse structures in both the digital and analog domain.	algorithm;artificial neural network;computer;emulator;experiment;handwriting recognition;industrial pc;knowledge level;neurocomputing;optical character recognition;sparse matrix;very-large-scale integration	Dan W. Hammerstrom;Steven Rehfuss	1993	Artificial Intelligence Review	10.1007/BF00849056	connectionism;performance;computer science;artificial intelligence;knowledge;operations research;artificial neural network;algorithm	ML	15.296648167559589	-26.885904617692123	93848
7c78047c7839e980b8e3365f20c68d8037425931	feedforward neural network with adaptive reference pattern layer	feedforward neural network	A hybrid neural network architecture is investigated for modeling purposes. The proposed hybrid is based on the multilayer perceptron (MLP) network. In addition to the usual hidden layers, the first hidden layer is selected to be an adaptive reference pattern layer. Each unit in this new layer incorporates a reference pattern that is located somewhere in the space spanned by the input variables. The outputs of these units are the component wise-squared differences between the elements of a reference pattern and the inputs. The reference pattern layer has some resemblance to the hidden layer of the radial basis function (RBF) networks. Therefore the proposed design can be regarded as a sort of hybrid of MLP and RBF networks. The presented benchmark experiments show that the proposed hybrid can provide significant advantages over standard MLPs and RBFs in terms of fast and efficient learning, and compact network structure.		Mikko Lehtokangas	1999	International journal of neural systems	10.1142/S0129065799000022	feedforward neural network;probabilistic neural network;computer science;artificial intelligence;machine learning;multilayer perceptron	ML	14.571914379819574	-27.40303306535094	93970
2ef60690c63b3c24f9b44fdc7ebd6745b694a897	localized complexities for transductive learning		We show two novel concentration inequalities for suprema of empirical processes when sampling without replacement, which both take the variance of the functions into account. While these inequalities may potentially have broad applications in learning theory in general, we exemplify their significance by studying the transductive setting of learning theory. For which we provide the first excess risk bounds based on the localized complexity of the hypothesis class, which can yield fast rates of convergence also in the transductive learning setting. We give a preliminary analysis of the localized complexities for the prominent case of kernel classes.	exemplification;offset binary;sampling (signal processing);transduction (machine learning)	Ilya O. Tolstikhin;Gilles Blanchard;Marius Kloft	2014			semi-supervised learning;econometrics;transduction;machine learning;mathematics;statistics	ML	21.380490533910226	-31.382274486955236	94056
9e720ba64b5b902044775fa73453450293e9ecee	on the use of different loss functions in statistical pattern recognition applied to machine translation	traduccion automatica;statistical machine translation;heuristic method;metodo heuristico;tratamiento lenguaje;fonction perte;funcion perdida;teoria decision;traduction automatique;language processing;loss function;theorie decision;bayes risk;classification rules;decision theory;traitement langage;statistical pattern recognition;pattern recognition;methode heuristique;reconnaissance forme;reconocimiento patron;direct translation rule;machine translation;automatic translation	In pattern recognition, an elegant and powerful way to deal with classification problems is based on the minimisation of the classification risk. The risk function is defined in terms of loss functions that measure the penalty for wrong decisions. However, in practice a trivial loss function is usually adopted (the so-called 0-1 loss function) that do no make the most of this framework. This work is focused on the study of different loss functions, and specially on those loss functions that do not depend on the class proposed by the system. Loss functions of this kind have allowed us to theoretically explain heuristics that are successfully used with very complex pattern recognition problem, such as (statistical) machine translation. A comparative experimental work has also been carried out to compare different proposals of loss functions in the practical scenario of machine translation.	loss function;machine translation;pattern recognition	Jesús Andrés-Ferrer;Daniel Ortiz-Martínez;Ismael García-Varea;Francisco Casacuberta	2008	Pattern Recognition Letters	10.1016/j.patrec.2007.06.015	speech recognition;decision theory;computer science;artificial intelligence;machine learning;pattern recognition;machine translation;algorithm;statistics;loss function	Vision	20.338799595391812	-35.08489226623002	94214
5f7308ea1735cdeadc84c960a5769abb49792609	a random matrix approach to neural networks		1 T Σ T Σ, Σ = σ(W X), classically found in random neural networks, where X = [x1,. .. , xT ] ∈ R p×T is a (data) matrix of bounded norm, W ∈ R n×p is a matrix of independent zero-mean unit variance entries, and σ : R → R is a Lipschitz continuous (activation) function — σ(W X) being understood entry-wise. We prove that, as n, p, T grow large at the same rate, the resolvent Q = (G + γIT) −1 , for γ > 0, has a similar behavior as that met in sample covariance matrix models, involving notably the moment Φ = T n E[G], which provides in passing a deterministic equivalent for the empirical spectral measure of G. This result, established by means of concentration of measure arguments, enables the estimation of the asymptotic performance of single-layer random neural networks. This in turn provides practical insights into the underlying mechanisms into play in random neural networks, entailing several unexpected consequences, as well as a fast practical means to tune the network hyperparameters. 1. Introduction. Artificial neural networks, developed in the late fifties (Rosenblatt, 1958) in an attempt to develop machines capable of brain-like behaviors, know today an unprecedented research interest, notably in its applications to computer vision and machine learning at large (Krizhevsky, Sutskever and Hinton, 2012; Schmidhuber, 2015) where superhuman performances on specific tasks are now commonly achieved. Recent progress in neural network performances however find their source in the processing power of modern computers as well as in the availability of large datasets rather than in the development of new mathematics. In fact, for lack of appropriate tools to understand the theoretical behavior of the non-linear activations and de-terministic data dependence underlying these networks, the discrepancy between mathematical and practical (heuristic) studies of neural networks has kept widening. A first salient problem in harnessing neural networks lies in their being completely designed upon a deterministic training dataset X = [x 1 ,. .. , x T ] ∈ R p×T , so that their resulting performances intricately	activation function;computer vision;data dependency;discrepancy function;frank rosenblatt;heuristic;machine learning;neural networks;nonlinear system;performance;random neural network;resolution (logic);unintended consequences	Cosme Louart;Zhenyu Liao;Romain Couillet	2017	CoRR		combinatorics;discrete mathematics;mathematics;statistics	ML	21.58977755647612	-31.921230435613296	94240
dd5d74ef70fc3e039fa449a8d012d3d4bd5059ea	target transfer q-learning and its convergence analysis		Reinforcement Learning (RL) technologies are powerful to learn how to interact with environments and have been successfully applied to variants of important applications. Q-learning is one of the most popular methods in RL, which uses temporal difference method to update the Q-function and can asymptotically learn the optimal Q-function. Transfer Learning aims to utilize the learned knowledge from source tasks to help new tasks. For supervised learning, it has been shown that transfer learning has the potential to significantly improve the sample complexity of the new tasks. Considering that data collection in RL is both more time and cost consuming and Q-learning converges slowly comparing to supervised learning, different kinds of transfer RL algorithms are designed. However, most of them are heuristic with no theoretical guarantee of the convergence rate. Therefore, it is important for us to clearly understand when and how will transfer learning help RL method and provide the theoretical guarantee for the improvement of the sample complexity. In this paper, we propose to transfer the Q-function learned in the source task to the target in the Q-learning of the new task when certain safe conditions are satisfied. We call this new transfer Q-learning method target transfer Q-Learning. The safe conditions are necessary to avoid the harm to the new tasks brought by the transfer target and thus ensure the convergence of the algorithm. We study the convergence rate of the target transfer Q-learning. We prove that if the two tasks are similar with respect to the MDPs, the optimal Q-functions of the two tasks are similar which means the error of the transferred target Q-function in the new task is small. Also, the convergence rate analysis shows that the target transfer Q-Learning will converge faster than Q-learning if the error of the transferred target Q-function is smaller than the current Q-function in the new task. Based on our theoretical results and the relationship between the Q error and the Bellman error, we design the safe condition as the Bellman error of the transferred target Q-function is less than the current Q-function. Our experiments are consistent with our theoretical founding and verified the effectiveness of our proposed target transfer Q-learning method. ∗This work was done when the first author was visiting Microsoft Research Asia. Copyright c © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Introduction Reinforcement Learning (RL) (Sutton, Barto, and others 1998) technologies are very powerful to learn how to interact with environments and have been successfully applied to variants of important applications, such as robotics, computer games and so on (Kober, Bagnell, and Peters 2013; Mnih et al. 2015; Silver et al. 2016; Bahdanau et al. 2016). Q-learning (Watkins 1989) is one of the most popular RL algorithms which uses temporal difference method to update the Q-function. To be specific, Q-learning maps the current Q-function to a new Q-function by using Bellman operator and use the difference between these two Q-functions to update the Q-function. Since Bellman operator is a contractive mapping, Q-learning will converge to the optimal Q-function (Jaakkola, Jordan, and Singh 1994). Comparing to supervised learning algorithms, Q-learning converges much slower due to the interactions with the environment. At the same time, the data collection is both very time and cost consuming in RL. Thus, it is crucial for us to utilize available information to save the sample complexity of Q-Learning. Transfer learning aims to improve the learning performance on a new task by utilizing knowledge/model learned from source tasks. Transfer learning has a long history in supervised learning (Li, Yang, and Xue 2009; Pan, Yang, and others 2010; Oquab et al. 2014). Recently, by leveraging the experiences from supervised transfer learning, researchers developed different kinds of transfer learning methods for RL, which can be categorized into three classes: (1) instance transfer in which old data will be reused in the new task (Sunmola and Wyatt 2006; Zhan and Taylor 2015); (2) representation transfer such as reward shaping and basis function extraction (Konidaris and Barto 2006; Barreto et al. 2017); (3) parameter transfer (Song et al. 2016) in which the parameters of the source task will be partially merged into the model of the new task. While supervised learning is a pure optimization problem, reinforcement learning is a more complex control problem. To the best of our knowledge, most of the existing transfer reinforcement learning algorithms are heuristic with no theoretical guarantee of the convergence rate (Bone 2008), (Taylor and Stone 2009) and (Lazaric 2012). As mentioned by (Spector and Belongie 2017), the transfer learning method potentially do not work or even harm to the new tasks and we do not know the reason since the absence of the theory. Therefore, it is very important ar X iv :1 80 9. 08 92 3v 1 [ cs .L G ] 2 1 Se p 20 18 for us to clearly understand how and when transfer learning will help reinforcement learning save sample complexity. In this paper, we design a novel transfer learning method for Q-learning in RL with theoretical guarantee. Different from the existing transfer RL algorithms, we propose to transfer the Q-function learned in the source task as the temporal difference update target of the new task when certain safe conditions are satisfied. We call this new transfer Q-learning method target transfer Q-learning. The intuitive motivation is that when the two RL tasks are similar to each other, their optimal Q-function will be similar which means the transferred target is better ( the error is smaller than the current Q-function ). Combine it with that a better target Q-function in Q-learning will help to accelerate the convergence, we may expect that the target transfer Q-learning method will outperform the Q-learning. The safe conditions are necessary to avoid the harm to the new tasks and thus ensure the convergence of the algorithm. We prove that target transfer Q-learning has the theoretical guarantee of convergence rate. Furthermore, if the two MDPs and thus the optimal Q-functions in the source and new RL tasks are similar, the target transfer Q-learning converges faster than Q-learning. To be specific, we prove the error of target transfer Q-learning consists of two errors: the initialization error and the sampling error. Both of the errors are increasing with the the product of discount factor γ and the relative Q-function error ratio β (error ratio for simplicity) which measures the relative error of the target Q-function comparing with the current Q-function in the new task. We called γβ discounted relative Q-function error ratio(discounted error ratio for simplicity). The smaller the discounted error ratio is, the faster the convergence is. And if the discounted error ratio is larger than 1, the convergence will no longer guaranteed. If the two RL tasks are similar, the learned Q-function in the source task will be close to the optimal Q-function comparing to the current Q-function in the new task. Thus, the discounted error ratio γβ will be small(especially for the early stage) when we transfer the learned Q-function from the source task to the target of the new task. Please note that the traditional Q-learning is a special case for target transfer Q-learning with constant discounted error ratio γ. Therefore, our convergence analysis for target transfer Qlearning help us design the safe condition. We can transfer the target if it will lead the discounted error ratio γβ smaller than 1 . We call it error ratio safe condition. Specifically, in the early stage of the training, the Q-function in the new task is not fully trained, the learned Q-function in the source task it a better choice with a smaller error ratio. With the updating of the Q-function in the new task, its error ratio becomes larger. When its discounted error ratio is close or larger than 1, the safe condition will not be satisfied, and we will stop transferring the target to avoid the harm brought by the transfer learning. Following the standard way in Qlearning, we estimate the error ratio about the error of the Q-function w.r.t the optimal Q-function by the Bellman error. Our experiments on synthetic MDPs fully support our convergence analysis and verify the effectiveness of our proposed target transfer Q-Learning with error ratio safe condition. Related Work This section briefly outline related work in transfer learning in reinforcement learning. Transfer Learning in RL(Taylor and Stone 2009) (Lazaric 2012) aims to improve learning in new MDP tasks by borrowing knowledge from a related but different learned MDP tasks. In paper (Laroche and Barlier 2017), the authors propose to use instance transfer in the Transfer Reinforcement Learning with Shared Dynamics (TRLSD) setting in which only the reward function is different between MDPs. In paper (Gupta et al. 2017), the authors propose to use the representation transfer and learned the invariant feature space. The papers (Karimpanal and Bouffanais 2018; Song et al. 2016) propose to use the parameter transfer to guide the exploration or to initialize the Q-function of the new task directly. In paper (Al-Shedivat et al. 2017), the authors propose to use the meta-learning method to do transfer learning in RL. All these works are empirically evaluated and no theoretical analysis for the convergence rate. There are few works that have the convergence analysis. In paper (Barreto et al. 2017), the authors use the representation transfer but only consider the TRLSD setting. (Zhan and Taylor 2015) propose a method by using instance transfer. They gives the theoretical analysis of the asymptotic convergence and no finite sample performance guarantee. Q Learning Background Consider the reinforcement learning prob	algorithm;andrew barto;approximation error;artificial intelligence;artificial neural network;basis function;bellman equation;bit error rate;categorization;converge;experiment;feature vector;heuristic;interaction;learning with errors;machine learning;map;mathematical optimization;microsoft research;noise shaping;optimization problem;pc game;q-learning;rate of convergence;reinforcement learning;robotics;sample complexity;sampling (signal processing);supervised learning;synthetic intelligence;temporal difference learning;word lists by frequency;yang	Yue Wang;Qi Meng;Wei Chen;Yuting Liu;Zhiming Ma;Tie-Yan Liu	2018	CoRR		machine learning;rate of convergence;mathematical optimization;transfer of learning;supervised learning;data collection;q-learning;reinforcement learning;mathematics;artificial intelligence;heuristic;convergence (routing)	ML	22.848158306387713	-32.88667138729807	94477
b9b836a8aa41da4b2b282f9eb3ed6ed5d64f9d3c	reducing the training times of neural classifiers with dataset condensing	multilayer perceptrons;clasificador;perceptron multicouche;classifier;reconnaissance caractere;edition donnee;pattern classification;pattern recognition;classificateur;multi layer perceptron;k nearest neighbour;reconnaissance forme;reseau neuronal;reconocimiento patron;character recognition;red neuronal;reconocimiento caracter;neural network;classification forme	In this paper we apply a k-nearest-neighbour-based data condensing algorithm to the training sets of multi-layer perceptron neural networks. By removing the overlapping data and retaining only training exemplars adjacent to the decision boundary we are able to significantly speed the network training time while achieving an undegraded misclassification rate compared to a network trained on the unedited training set. We report results on a range of synthetic and real datasets which indicate that a speed-up of an order of magnitude in the network training time is typical.		Se-Ho Choi;Peter Rockett	2000		10.1007/3-540-44522-6_67	classifier;computer science;artificial intelligence;machine learning;pattern recognition;multilayer perceptron;artificial neural network	NLP	11.716885954361306	-31.620932165575642	94511
1a3381c421b61bb1a133d96168fbd8634f6af331	deep q-networks for accelerating the training of deep neural networks		In this paper, we propose a principled deep reinforcement learning (RL) approach that is able to accelerate the convergence rate of general deep neural networks (DNNs). With our approach, a deep RL agent (synonym for optimizer in this work) is used to automatically learn policies about how to schedule learning rates during the optimization of a DNN. The state features of the agent are learned from the weight statistics of the optimizee during training. The reward function of this agent is designed to learn policies that minimize the optimizee’s training time given a certain performance goal. The actions of the agent correspond to changing the learning rate for the optimizee during training. As far as we know, this is the first attempt to use deep RL to learn how to optimize a large-sized DNN. We perform extensive experiments on a standard benchmark dataset and demonstrate the effectiveness of the policies learned by our approach. All source code for reproducing the experiments can be downloaded from https://github.com/bigaidreamprojects/qan .	artificial neural network;benchmark (computing);deep learning;experiment;mathematical optimization;neural network software;rate of convergence;reinforcement learning;scalability	Jie Fu	2016	CoRR		speech recognition;computer science;artificial intelligence;machine learning	AI	17.54996350318345	-32.02966206945251	94731
71e5b27ee516c4f527ca34ac76ae48b5530593a5	mathematical and computational foundations of learning theory (dagstuhl seminar 11291)	004;learning theory non smooth optimization convex and non convex signal processing;learning theory machine learning sparsity high dimensional geometry manifold learning online learning	Machine learning has become a core field in computer science. Over#R##N#the last decade the statistical machine learning approach has been successfully applied in many areas such as bioinformatics, computer vision, robotics and information retrieval. The main  reasons for the  success of machine learning  are its strong theoretical foundations and its#R##N#multidisciplinary approach integrating aspects of computer science, applied mathematics, and statistics among others. The goal of the seminar was to bring together again experts from computer science, mathematics and statistics to discuss the state of the art in machine learning and identify and formulate the key challenges in learning which have to be addressed in the future.#R##N#The main topics of this seminar were:#R##N#- Interplay between Optimization and Learning,#R##N#- Learning Data Representations.	computation	Matthias Hein;Gábor Lugosi;Lorenzo Rosasco;Stephen Smale	2011	Dagstuhl Reports	10.4230/DagRep.1.7.53	robot learning;multi-task learning;instance-based learning;algorithmic learning theory;computer science;artificial intelligence;machine learning;inductive transfer;stability;computational learning theory;reinforcement learning;active learning	Theory	20.5902647173405	-36.019505329687576	94807
3847897e4a15d1078499466087ea7885061c6465	neural networks - algorithms, applications, and programming techniques			algorithm;neural networks	James A. Freeman;David M. Skapura	1991				Theory	12.98131971998963	-27.025413301857196	94816
ed8be9ba879d4b31d870a81fb0fc9d97f7c9287c	decoupled classifiers for fair and efficient machine learning		When it is ethical and legal to use a sensitive attribute (such as gender or race) in machine learning systems, the question remains how to do so. We show that the naive application of machine learning algorithms using sensitive attributes leads to an inherent tradeoff in accuracy between groups. We provide a simple and efficient decoupling technique, that can be added on top of any black-box machine learning algorithm, to learn different classifiers for different groups. Transfer learning is used to mitigate the problem of having too little data on any one group. The method can apply to a range of fairness criteria. In particular, we require the application designer to specify as joint loss function that makes explicit the trade-off between fairness and accuracy. Our reduction is shown to efficiently find the global optimum loss as long as the objective has a certain natural monotonicity property. Monotonicity may be of independent interest in the study of fairness in algorithms.	algorithm;black box;coupling (computer programming);fairness measure;global optimization;loss function;machine learning	Cynthia Dwork;Nicole Immorlica;Adam Tauman Kalai;Max D. M. Leiserson	2017	CoRR			ML	18.967842324093102	-35.52475262639983	94829
47f1b4ce7674b15d293f5a3c53d6da44bc8e137e	signal recovery from pooling representations		In this work we compute lower Lipschitz bounds of lp pooling operators for p = 1, 2,∞ as well as lp pooling operators preceded by halfrectification layers. These give sufficient conditions for the design of invertible neural network layers. Numerical experiments on MNIST and image patches confirm that pooling layers can be inverted with phase recovery algorithms. Moreover, the regularity of the inverse pooling, controlled by the lower Lipschitz constant, is empirically verified with a nearest neighbor regression.	algorithm;artificial neural network;carrier recovery;coupling constant;expect;experiment;information needs;mnist database;rectifier;whole earth 'lectronic link;word lists by frequency	Joan Bruna;Arthur Szlam;Yann LeCun	2014			mathematical optimization;combinatorics;discrete mathematics;mathematics;statistics	ML	19.23121255273265	-29.85714620666537	94943
9a2e87c9bd5c33ecd1b8c60271fd02c9298b0b04	bayesian classification and feature reduction using uniform dirichlet priors	dirichlet distribution;dirichlet prior;bayesian classification;error conditioned classification bayesian data reduction algorithm discrete features feature selection neural networks noninformative prior uci repository 13dra;neural nets;bayes methods;probability of error;indexing terms;bayesian methods training data iris quantization histograms performance analysis neural networks testing laboratories contracts;feature reduction;pattern classification;feature selection;data reduction;neural nets bayes methods pattern classification;neural network	"""In this paper, a method of classification referred to as the Bayesian data reduction algorithm (BDRA) is developed. The algorithm is based on the assumption that the discrete symbol probabilities of each class are a priori uniformly Dirichlet distributed, and it employs a """"greedy"""" approach (which is similar to a backward sequential feature search) for reducing irrelevant features from the training data of each class. Notice that reducing irrelevant features is synonymous here with selecting those features that provide best classification performance; the metric for making data-reducing decisions is an analytic for the probability of error conditioned on the training data. To illustrate its performance, the BDRA is applied both to simulated and to real data, and it is also compared to other classification methods. Further, the algorithm is extended to deal with the problem of missing features in the data. Results demonstrate that the BDRA performs well despite its relative simplicity. This is significant because the BDRA differs from many other classifiers; as opposed to adjusting the model to obtain a """"best fit"""" for the data, the data, through its quantization, is itself adjusted."""		Robert S. Lynch;Peter Willett	2003	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/TSMCB.2003.811121	dirichlet distribution;computer science;machine learning;pattern recognition;data mining;artificial neural network;statistics	ML	15.372775368362628	-35.69193268615577	94978
85d5edb5e8511d8eaafddc2a11742ead135242c5	eddi: efficient dynamic discovery of high-value information with partial vae		Making decisions requires information relevant to the task at hand. Many real-life decision making situations allow acquiring further relevant information at a specific cost. For example, in assessing the health status of a patient we may decide to take additional measurements such as diagnostic tests or imaging scans before making a final assessment. More information that is relevant allows for better decisions but it may be costly to acquire all of this information. How can we trade off the desire to make good decisions with the option to acquire further information at a cost? To this end, we propose a principled framework, named EDDI (Efficient Dynamic Discovery of high-value Information), based on the theory of Bayesian experimental design. In EDDI we propose a novel partial variational autoencoder (Partial VAE), to efficiently handle missing data over varying subsets of known information. EDDI combines this Partial VAE with an acquisition function that maximizes expected information gain on a set of target variables. EDDI is efficient and demonstrates that dynamic discovery of high-value information is possible; we show cost reduction at the same decision quality and improved decision quality at the same cost in benchmarks and in two health-care applications. We believe there is great potential for realizing these gains in real-world decision support systems.	autoencoder;bayesian experimental design;decision quality;decision support system;design of experiments;information gain in decision trees;kullback–leibler divergence;missing data;real life;variational principle	Chao Ma;Sebastian Tschiatschek;Konstantina Palla;Jose Miguel Hernandez Lobato;Sebastian Nowozin;Cheng Zhang	2018	CoRR		autoencoder;artificial intelligence;decision support system;machine learning;diagnostic test;bayesian experimental design;missing data;decision quality;cost reduction;computer science	ML	15.177964715168288	-36.656049831636615	95071
18d10045ec2d0119a330167c70ccbd8f6c960344	fuzzy transfer learning: methodology and application	intelligent environment;sensor network;68t05;fuzzy logic;online adaptation;transfer learning;94d05;article;context	Producing a methodology that is able to predict output using a model is a well studied area in Computational Intelligence (CI). However, a number of real-world applications require a model but have little or no data available of the specific environment. Predominantly, standard machine lea rning approaches focus on a need for training data for such models to come from the same domain as the target task. Such re strictions can severely reduce the data acquisition making it extremely costly, or in certain situations, impos sible. This impedes the ability of these approaches to model such environments. It is on this particular problem that thi s paper is focussed. In this paper two concepts, Transfer Learning (TL) and Fuzzy Logic (FL) are combined in a framework, Fuzzy Transfer Learning (FuzzyTL), to address the problem of lear ning tasks that have no prior direct contextual knowledge. Through the use of a FL based learning method, uncertainty th a is evident in dynamic environments is represented. By applying a TL approach through the combining of labelled d ata from a contextually related source task, and little or no unlabelled data from a target task, the framework is shown t be able to accomplish predictive tasks using models learned from contextually di fferent data.	computation;computational intelligence;data acquisition;fuzzy logic;transform, clipping, and lighting	Jethro Shell;Simon Coupland	2015	Inf. Sci.	10.1016/j.ins.2014.09.004	fuzzy logic;semi-supervised learning;multi-task learning;error-driven learning;wireless sensor network;transfer of learning;computer science;artificial intelligence;online machine learning;machine learning;data mining;inductive transfer;active learning;algorithm	AI	14.385156345239658	-36.52062919224237	95171
946ee9f8776f740062d97887194b4eeaa09576fc	piecewise approximations of black box models for model interpretation		Recent literature interprets the predictions of “black-box” machine learning models (Neural Networks, Random Forests, etc.) by approximating these models in terms of simpler models such as piecewise linear or piecewise constant models. Existing literature does not provide guarantees on whether these approximations reflect the nature of the predictive model well, which can result in poor interpretations thus establishing mistrust in the model. We provide a tractable dynamic programming algorithm that partitions the feature space into subsets and assigns a local model (constant/linear model) to provide piecewise constant/piecewise linear interpretations of an arbitrary predictive model. When approximation loss (between the interpretation and the predictive model) is measured in terms of mean squared error, our approximation is optimal; for more general loss functions, our interpretation is approximately optimal, i.e., it probably approximately correctly (PAC) learns the predictive model. Experiments with real and synthetic data show that it provides significant improvements (in terms of mean squared error) over competing approaches. We also show real use cases to establish the utility of the proposed approach over competing approaches.	algorithm;approximation;artificial neural network;black box;cobham's thesis;distrust;dynamic programming;experiment;feature vector;gradient;linear model;loss function;machine learning;mean squared error;neural network software;piecewise linear continuation;predictive modelling;random forest;synthetic data	Kartik Ahuja;William R. Zame;Mihaela van der Schaar	2018	CoRR		supervised learning;piecewise;mathematical optimization;feature vector;partition (number theory);dynamic programming;synthetic data;mathematics;piecewise linear function;mean squared error	ML	21.983111626076365	-31.85758764322798	95342
7a81d42603e44bda5d8c30bc5638fd250559e3ba	minimax nonparametric classification - part i: rates of convergence	loss measurement;feature variable;rate of convergence;estimation theory;convergence;probability;lipschitz function;neural networks;bounded variation;density measurement;nonparametric statistics;convergence rates;bayes methods;minimax nonparametric classification;convergence of numerical methods;monotone function;minimax rates of convergence;minimax methods;nonparametric classification;mean error;metric entropy;sparse approximation;indexing terms;satisfiability;bayes decision;suboptimal rate;sufficient conditions;sobolev function;approximation;neural network classes;misclassification probability;upper bound;approximation theory;minimax techniques;conditional probability estimation;signal classification;approximation minimax nonparametric classification convergence rates minimax estimation conditional probability class label feature variable general nonparametric class minimax convergence rate metric entropy misclassification probability bayes decision upper bound suboptimal rate monotone functions sufficient condition bounded variation besov function sobolev function lipschitz function;besov function;pattern recognition;mean error probability regret;minimax estimation;minimax convergence rate;error probability;entropy;estimation error;sufficient condition;approximation theory minimax techniques signal classification convergence of numerical methods probability estimation theory nonparametric statistics bayes methods entropy;monotone functions;conditional probability;general nonparametric class;class label;neural network	— This paper studies minimax aspects of nonparametric classification. We first study minimax estimation of the conditional probability of a class label, given the feature variable. This function, say f, is assumed to be in a general nonparametric class. We show the minimax rate of convergence under square L2 loss is determined by the massiveness of the class as measured by metric entropy. The second part of the paper studies minimax classification. The loss of interest is the difference between the probability of misclassification of a classifier and that of the Bayes decision. As is well known, an upper bound on risk for estimating f gives an upper bound on the risk for classification, but the rate is known to be suboptimal for the class of monotone functions. This suggests that one does not have to estimate f well in order to classify well. However, we show that the two problems are in fact of the same difficulty in terms of rates of convergence under a sufficient condition, which is satisfied by many function classes including Besov (Sobolev), Lipschitz, and bounded variation. This is somewhat surprising in view of a result of Devroye, Gyorfi,  ̈ and Lugosi (1996).	bounded variation;measure-preserving dynamical system;minimax;rate of convergence;regular expression;monotone	Yuhong Yang	1999	IEEE Trans. Information Theory	10.1109/18.796368	nonparametric statistics;bounded variation;entropy;mathematical optimization;index term;convergence;conditional probability;monotonic function;probability of error;approximation;pattern recognition;probability;sparse approximation;mathematics;mean squared error;lipschitz continuity;rate of convergence;upper and lower bounds;estimation theory;artificial neural network;statistics;satisfiability;approximation theory	ML	20.585376108989635	-31.452516493896894	95378
3d66ca119ce8eaaa857b548175936993366e8b86	a risk minimization principle for a class of parzen estimators	learning algorithm;large dataset;risk minimization;sista;ordinal regression	This paper 1 explores the use of a Maximal Average Margin (MAM) optimalit y principle for the design of learning algorithms. It is shown that the application of this risk minimization principle results in a class of (co mputationally) simple learning machines similar to the classical Parzen window cl assifier. A direct relation with the Rademacher complexities is established, as su ch facilitating analysis and providing a notion of certainty of prediction. This anal ysis is related to Support Vector Machines by means of a margin transformation. Th e power of the MAM principle is illustrated further by application to ordi nal regression tasks, resulting in anO(n) algorithm able to process large datasets in reasonable time .	algorithm;computation;comstock–needham system;experiment;kernel density estimation;machine learning;maximal set;microsoft windows;ordinal data;ordinal regression;rademacher complexity;support vector machine;window function	Kristiaan Pelckmans;Johan A. K. Suykens;Bart De Moor	2007			ordinal regression;empirical risk minimization;computer science;machine learning;pattern recognition;mathematics;statistics	ML	21.21590866797808	-35.72891462941288	95453
e37ca88d2bd10d130f69a16f71b64637248347e8	global artificial bee colony algorithm for boolean function classification	global artificial bee colony algorithm;artificial bee colony algorithm;back propagation	This paper proposed Global Artificial Bee Colony algorithm for training Neural Network (NN), which is a globalised form of standard Artificial Bee Colony algorithm. NN trained with the standard backpropagation (BP) algorithm normally utilizes computationally intensive training algorithms. One of the crucial problems with the BP algorithm is that it can sometimes yield the networks with suboptimal weights because of the presence of many local optima in the solution space. To overcome, GABC algorithm used in this work to train MLP learning for classification problem, the performance of GABC is benchmarked against MLP training with the typical BP, ABC and Particle swarm optimization for boolean function classification. The experimental result shows that MLP-GABC performs better than that standard BP, ABC and PSO for the classification task.	artificial bee colony algorithm	Habib Shah;Rozaida Ghazali;Nazri Mohd Nawi	2013		10.1007/978-3-642-36546-1_2	computer science;artificial intelligence;backpropagation;machine learning;data mining;artificial bee colony algorithm	EDA	14.127689853998964	-24.784060544479225	95490
e29b3f2805f8e974725b2385ddae9d252c1f73ec	density estimation over data streams		A growing number of real-world applications share the property that they have to deal with transient data arriving in massive volumes, so-called data streams. The characteristics of these data streams render their analysis by means of conventional techniques extremely difcult, in the majority of cases even impossible. In fact, to be applicable to data streams, a technique has to meet rigid processing requirements such as a single pass over the stream and strict limitations on the available memory. With respect to these requirements, an adequate real-time mining and analysis of a data stream has turned out to be a highly demanding task, which can only be tackled by developing tailored techniques. In this work, we delve more deeply into an important building block of many data mining and analysis approaches, namely density estimation, with the objective to adapt it to the data stream scenario. Density estimation, a vital research topic in mathematical statistics, aims to capture the unknown distribution of a real-valued data set by estimating its underlying probability density function. A suitable density estimate can be exploited to gain insight into the main features of the data; it can also prepare the ground for a variety of further analysis tasks. Due to the importance of density estimation, various methods have been developed in recent decades. Among the most promising methods are the nonparametric ones. They stand out from the parametric approaches as they only make very weak assumptions on the data; they let the data speak for themselves. Two important members of the class of nonparametric methods are based on kernels and wavelets. Kernel as well as wavelet density estimators are theoretically founded and practically approved, but their computational burden severely impedes their applicability. In particular, neither kernel nor wavelet density estimators can be computed over real-valued data streams because their computational complexity collides with the processing requirements for streams. However, as density estimation can be a crucial component of data stream analysis, we devoted ourselves to the adaptation of kernel and wavelet density estimators to data streams in compliance with the processing requirements for streams. Our solution for wavelet density estimators, termed compressed-cumulative WDEs, relies on processing blocks of data of the stream, where each data block is associated with a separate estimator. While processing the stream, the block estimators are successively merged into one estimator. Our solution for kernel density estimators utilizes speci c building blocks, termed Cluster Kernels, to derive an estimator for the stream on demand. These Cluster Kernels summarize already processed elements in terms of local statistics, which are used for an approximate resampling of elements. Both solutions exhibit a generic design to facilitate the integration of new strategies for their main processing steps. In order to assess them, we conducted an extensive experimental study, including a thorough comparison with competitive techniques. As the results of this study reveal, our techniques outperform all competitors. Overall, they succeed in estimating the unknown density of a data stream.	approximation algorithm;computation;computational complexity theory;data mining;experiment;kernel (operating system);real-time clock;real-time operating system;requirement;wavelet	Christoph Heinz	2007			statistics;data stream mining;density estimation;computer science	ML	13.855693927031943	-37.26950117988074	95562
0e28412521097c582badd210dc7ff3b4fad6a002	boosting with the logistic loss is consistent		This manuscript provides optimization guarantees, generalization bounds, and statistical consistency results for AdaBoost variants which replace the exponential loss with the logistic and similar losses (specifically, twice differentiable convex losses which are Lipschitz and tend to zero on one side). The heart of the analysis is to show that, in lieu of explicit regularization and constraints, the structure of the problem is fairly rigidly controlled by the source distribution itself. The first control of this type is in the separable case, where a distribution-dependent relaxed weak learning rate induces speedy convergence with high probability over any sample. Otherwise, in the nonseparable case, the convex surrogate risk itself exhibits distribution-dependent levels of curvature, and consequently the algorithm’s output has small norm with high probability.	adaboost;algorithm;explicit and implicit methods;mathematical optimization;matrix regularization;time complexity;with high probability	Matus Telgarsky	2013			mathematical optimization;combinatorics;discrete mathematics;machine learning;mathematics;statistics	ML	21.777213395536652	-33.11560102212964	95746
b572af540d7bdc48a3deb5c9ecd184760162cc84	consistency versus realizable h-consistency for multiclass classification		A consistent loss function for multiclass classification is one such that for any source of labeled examples, any tuple of scoring functions that minimizes the expected loss will have classification accuracy close to that of the Bayes optimal classifier. While consistency has been proposed as a desirable property for multiclass loss functions, we give experimental and theoretical results exhibiting a sequence of linearly separable data sources with the following property: a multiclass classification algorithm which optimizes a loss function due to Crammer and Singer (which is known not to be consistent) produces classifiers whose expected error goes to 0, while the expected error of an algorithm which optimizes a generalization of the loss function used by LogitBoost (a loss function which is known to be consistent) is bounded below by a positive constant. We identify a property of a loss function, realizable consistency with respect to a restricted class of scoring functions, that accounts for this difference. As our main technical results we show that the Crammer–Singer loss function is realizable consistent for the class of linear scoring functions, while the generalization of LogitBoost is not. Our result for LogitBoost is a special case of a more general theorem that applies to several other loss functions that have been proposed for multiclass classification. Proceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR: W&CP volume 28. Copyright 2013 by the author(s).	algorithm;international conference on machine learning;journal of machine learning research;linear separability;logitboost;loss function;multiclass classification;scoring functions for docking	Philip M. Long;Rocco A. Servedio	2013			mathematical optimization;hinge loss;machine learning;pattern recognition;mathematics;statistics	ML	20.786422700137994	-33.897496078337944	95808
4e4e0bc09c2ac55bb1cbbed4ed162f68ef584bd4	persistence fisher kernel: a riemannian manifold kernel for persistence diagrams		Algebraic topology methods have recently played an important role for statistical analysis with complicated geometric structured data such as shapes, linked twist maps, and material data. Among them, persistent homology is a well-known tool to extract robust topological features, and outputs as persistence diagrams (PDs). However, PDs are point multi-sets which can not be used in machine learning algorithms for vector data. To deal with it, an emerged approach is to use kernel methods, and an appropriate geometry for PDs is an important factor to measure the similarity of PDs. A popular geometry for PDs is the Wasserstein metric. However, Wasserstein distance is not negative definite. Thus, it is limited to build positive definite kernels upon the Wasserstein distance without approximation. In this work, we rely upon the alternative Fisher information geometry to propose a positive definite kernel for PDs without approximation, namely the Persistence Fisher (PF) kernel. Then, we analyze eigensystem of the integral operator induced by the proposed kernel for kernel machines. Based on that, we derive generalization error bounds via covering numbers and Rademacher averages for kernel machines with the PF kernel. Additionally, we show some nice properties such as stability and infinite divisibility for the proposed kernel. Furthermore, we also propose a linear time complexity over the number of points in PDs for an approximation of our proposed kernel with a bounded error. Throughout experiments with many different tasks on various benchmark datasets, we illustrate that the PF kernel compares favorably with other baseline kernels for PDs.	algorithm;anatomy, regional;approximation;baseline (configuration management);benchmark (computing);diagram;experiment;fisher information;fisher kernel;generalization (psychology);generalization error;hemoglobin f disease;homologous gene;homology (biology);infinite divisibility;information geometry;kernel (operating system);kernel method;machine learning;map;numerous;persistence (computer science);persistent homology;rademacher complexity;tarp syndrome;time complexity;manifold	Tam Le;Makoto Yamada	2018			riemannian manifold;discrete mathematics;mathematics;fisher kernel;kernel (linear algebra);mathematical optimization;positive-definite matrix;twist;kernel method;wasserstein metric;positive-definite kernel	ML	20.962989679841442	-33.281883884185056	95903
a0e856da98df08efdf21dafb4264c0ea0f77c50a	accelerating training of feedforward neural networks	feedforward neural networks;training;stabilization;acceleration	We review methods and techniques for training feedforward neural networks that avoid problematic behavior, accelerate the convergence, and verify the training. Adaptive step gain, bipolar activation functions, and conjugate gradients are powerful stabilizers. Random search techniques circumvent the local minimum trap and avoid specialization due to overtraining. Testing assures quality learning.	feedforward neural network;neural networks	Carl G. Looney	1994	International Journal on Artificial Intelligence Tools	10.1142/S0218213094000170	acceleration;computer science;artificial intelligence;machine learning	Robotics	15.985634543437397	-29.55147770547379	95976
274bce19f6dd41cfa3eff71a92cdb4f5a52470b2	stochastic optimization with variance reduction for infinite datasets with finite-sum structure		Stochastic optimization algorithms with variance reduction have proven successful for minimizing large finite sums of functions. Unfortunately, these techniques are unable to deal with stochastic perturbations of input data, induced for example by data augmentation. In such cases, the objective is no longer a finite sum, and the main candidate for optimization is the stochastic gradient descent method (SGD). In this paper, we introduce a variance reduction approach for these settings when the objective is composite and strongly convex. The convergence rate outperforms SGD with a typically much smaller constant factor, which depends on the variance of gradient estimates only due to perturbations on a single example.	algorithm;convolutional neural network;mathematical optimization;rate of convergence;stochastic gradient descent;stochastic optimization;variance reduction	Alberto Bietti;Julien Mairal	2017			mathematical optimization;combinatorics;stochastic optimization;mathematics;statistics	AI	23.87335885370612	-33.38468410384574	96080
b26a4d2a82718ab55945d8e0479a57ec2d6ab5dd	vector quantization and projection neural network	data analysis;parameter space;self organization;kohonen map;expert knowledge;vector quantizer;model fitting;data analysis techniques;neural network	Classical data analysis techniques are generally linear. They fail to reduce the dimension of data sets where dependence between observed variables is non-linear. However, for numerous scientific, industrial and economic areas, it should be desirable to obtain a low-dimensional parametric representation of the data set. Model fitting is a way to obtain a usable representation of an observed phenomenon, but it requires expert knowledge about the phenomenon. Moreover, hidden relations between observables could be not revealed. Kohonen maps are shown to be an alternative techniques, able to map even strongly non-linear data sets [1]. Unfortunately, they have an a priori fixed shape and neighbourhood structure, thus their use requires some informations about the shape and the dimension of the underlying parameters space. We propose here a new self-organizing neural network, composed of two connections layers. The first one quantizes an input data set, and the second one progressively constructs the projected shape and neighbourhood on an output space of any chosen dimension. We illustrate the algorithm for various applications.	algorithm;artificial neural network;neighbourhood (graph theory);nonlinear gameplay;nonlinear system;observable;organizing (structure);self-organization;self-organizing map;vector quantization	Pierre Demartines;Jeanny Hérault	1993		10.1007/3-540-56798-4_168	neural gas;learning vector quantization;computer science;machine learning;pattern recognition;data mining;time delay neural network;data analysis;vector quantization;artificial neural network;statistics	ML	23.025619900608273	-29.752994175320495	96200
02dcae660b672ca63007f3f476901d7267a52e45	smoothed bagging with kernel bandwidth selectors	nivel ruido;processus gauss;evaluation performance;densite probabilite;largeur bande;kernel bandwidth selector;performance evaluation;noise factor;probability density;medicion densidad;density measurement;estimation method;numerical method;noisy data;evaluacion prestacion;estimation non parametrique;kernel function;niveau bruit;facteur bruit;smoothed bagging;densidad probabilidad;non parametric estimation;noise level;metodo numerico;noise addition;factor ruido;network committee;anchura banda;funcion nucleo;fonction noyau;kernel density estimate;bandwidth;selecteur;mesure densite;rapport signal bruit;relacion senal ruido;gaussian process;estimacion no parametrica;reseau neuronal;signal to noise ratio;proceso gauss;selector;red neuronal;methode numerique;boostrapping;variance;neural network;variancia	Recently, a combined approach of bagging (bootstrap aggregating) and noise addition was proposed and shown to result in a significantly improved generalization performance. But, the level of noise introduced, a crucial factor, was determined by trial and error. The procedure is not only ad hoc but also time consuming since bagging involves training a committee of networks. Here we propose a principled procedure of computing the level of noise, which is also computationally less expensive. The idea comes from kernel density estimation (KDE), a non-parametric probability density estimation method where appropriate kernel functions such as Gaussian are imposed on data. The kernel bandwidth selector is a numerical method for finding the width of a kernel function (called bandwidth). The computed bandwidth can be used as the variance of added noise. The proposed approach makes the trial and error procedure unnecessary, and thus provides a much faster way of finding an appropriate level of noise. In addition, experimental results show that the proposed approach results in an improved performance over bagging, particularly for noisy data.	bootstrap aggregating;hoc (programming language);kernel (operating system);kernel density estimation;numerical method;signal-to-noise ratio;smoothed analysis;smoothing	Shinjae Lee;Sungzoon Cho	2001	Neural Processing Letters	10.1023/A:1012403711980	kernel;kernel density estimation;econometrics;probability density function;speech recognition;numerical analysis;gaussian process;mathematics;variance;noise figure;signal-to-noise ratio;variable kernel density estimation;artificial neural network;bandwidth;statistics	ML	20.30032998709401	-28.748221104873465	96225
b8b638780fc428c025b31121543063e59cd30d06	self-generating prototypes for pattern classification	processus gauss;evaluation performance;learning rate;posicionamiento;performance evaluation;data compression;learning;implementation;evaluacion prestacion;localization;localizacion;aprendizaje;prototipo;accuracy;vecino mas cercano;positioning;apprentissage;gaussian mixture model;cuantificacion vectorial;self generating neural trees;precision;localisation;vector quantization;gaussian mixture models;nearest neighbor;signal classification;prototype classifiers;pattern classification;pattern recognition;classification signal;plus proche voisin;nearest neighbour;k nearest neighbor;teoria mezcla;compresion dato;reconnaissance forme;gaussian process;classification automatique;reconocimiento patron;classification accuracy;implementacion;proceso gauss;automatic classification;mixture theory;clasificacion automatica;theorie melange;prototype;compression donnee;learning vector quantization;positionnement;classification forme;quantification vectorielle	Prototype classifiers are a type of pattern classifiers, whereby a number of prototypes are designed for each class so as they act as representatives of the patterns of the class. Prototype classifiers are considered among the simplest and best performers in classification problems. However, they need careful positioning of prototypes to capture the distribution of each class region and/or to define the class boundaries. Standard methods, such as learning vector quantization (LVQ), are sensitive to the initial choice of the number and the locations of the prototypes and the learning rate. In this article, a new prototype classification method is proposed, namely self-generating prototypes (SGP). The main advantage of this method is that both the number of prototypes and their locations are learned from the training set without much human intervention. The proposed method is compared with other prototype classifiers such as LVQ, self-generating neural tree (SGNT) and K-nearest neighbor (K-NN) as well as Gaussian mixture model (GMM) classifiers. In our experiments, SGP achieved the best performance in many measures of performance, such as training speed, and test or classification speed. Concerning number of prototypes, and test classification accuracy, it was considerably better than the other methods, but about equal on average to the GMM classifiers. We also implemented the SGP method on the well-known STATLOG benchmark, and it beat all other 21 methods (prototype methods and non-prototype methods) in classification accuracy. 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	benchmark (computing);experiment;google map maker;k-nearest neighbors algorithm;learning vector quantization;mixture model;pattern recognition;prototype;self-organization;simplified perturbations models;software prototyping;symposium on geometry processing;test set;whole earth 'lectronic link	Hatem A. Fayed;Sherif Hashem;Amir F. Atiya	2007	Pattern Recognition	10.1016/j.patcog.2006.10.018	random subspace method;speech recognition;computer science;machine learning;pattern recognition;mixture model;mathematics;accuracy and precision;k-nearest neighbors algorithm;statistics	AI	11.157577211285357	-33.98524828463666	96265
c79b7f6450c39db643cef54805ac20fab49e882d	conditional quantile regression with ℓ1-regularization and e-insensitive pinball loss	kernel;convergence;approximation error;e insensitive pinball loss learning theory conditional quantile regression l1 regularization;hilbert space;error analysis;yttrium;kernel error analysis convergence yttrium approximation error algorithm design and analysis hilbert space;conditional quantile regression learning convergence rate operator decomposition technique l2 empirical covering number hypothesis error kernel function data dependent hypothesis space e insensitive pinball loss l 1 regularization;regression analysis learning artificial intelligence;algorithm design and analysis	This paper considers the regularized learning schemes based on ℓ1-regularizer and the ε-insensitive pinball loss in a data dependent hypothesis space. The target is the error analysis for the conditional quantile regression learning. Except for continuity and boundedness, the kernel function is not necessary to satisfy any further regularity conditions. The data dependent nature of the algorithm leads to an extra error term called hypothesis error. By concentration inequality with ℓ2-empirical covering numbers and operator decomposition techniques, satisfied error bounds and convergence rates are explicitly derived.	algorithm;error analysis (mathematics);scott continuity;social inequality	Meng Li;Meijian Zhang;Hongwei Sun	2015	2015 8th International Conference on Biomedical Engineering and Informatics (BMEI)	10.1109/BMEI.2015.7401620	algorithm design;econometrics;mathematical optimization;approximation error;kernel;convergence;computer science;yttrium;mathematics;statistics;generalization error;hilbert space	ML	21.61330396689254	-33.409607671888644	96298
337087e898336292c27355d7cf161d03d2c5c77b	accelerated parallel optimization methods for large scale machine learning		The growing amount of high dimensional data in different machine learning applications requires more efficient and scalable optimization algorithms. In this work, we consider combining two techniques, parallelism and Nesterov’s acceleration, to design faster algorithms for L1-regularized loss. We first simplify BOOM [11], a variant of gradient descent, and study it in a unified framework, which allows us to not only propose a refined measurement of sparsity to improve BOOM, but also show that BOOM is provably slower than FISTA [1]. Moving on to parallel coordinate descent methods, we then propose an efficient accelerated version of Shotgun [3], improving the convergence rate from O(1/t) to O(1/t). Our algorithm enjoys a concise form and analysis compared to previous work, and also allows one to study several connected work in a unified way.	algorithm;coordinate descent;gradient descent;machine learning;mathematical optimization;paradiseo;parallel computing;rate of convergence;scalability;sparse matrix;unified framework	Haipeng Luo;Patrick Haffner;Jean-François Paiement	2014	CoRR		mathematical optimization;computer science;theoretical computer science;machine learning	ML	24.44442905399044	-34.026463318484375	96354
64880774323ac3f414711c8e93ac206c860d1cf4	gwmf: gradient weighted matrix factorisation for recommender systems		In this paper, we developed a new algorithm, Gradient Weighted Matrix Factorisation (GWMF), for matrix factorisation. GWMF uses weights to focus the approximation in the matrix factorisation to the higher approxmation residual. Therefore, it improves the matrix factorisation accuracy and increases the speed of convergence. We also introduce a regularisation parameter to control overfitting. We applied our algorithm to a movie recommendation problem and GWMF performs better than ordinal gradient descent-based matrix factorisation (GMF) on Movielens dataset. GWMF converges faster than GMF and it guarantees lower root mean square error (RMSE) at earlier iterations on both training and testing.	gradient;recommender system	Nipa Chowdhury;Xiongcai Cai	2013		10.1007/978-3-642-37401-2_73	data mining;residual;overfitting;mathematical optimization;recommender system;movielens;matrix (mathematics);computer science;gradient descent;factorization;mean squared error	ML	24.490713786803415	-35.41822633694417	96444
db6a44f8eedbc7073e2fa7e555320b768ffd65dd	an adaptation module with growing and adjustment rbfnn using a long-term memory	cybernetics;handwriting recognition;interference;writing;neurons;algorithm design and analysis;conferences	In this paper we proposed a writer adaptation system based on an adaptation module that is a plug-in for any writer-independent handwriting recognition systems. The adaptation module is a radial basis function neural network (RBF-NN) that is built using an incremental learning algorithm named GALTM-AM algorithm (Growing-Adjustment with Long-Term Memory). GALTM-AM train a new given data with some LTM data to suppress the interference. Therefore, we design two procedures to manage the LTM data. The first is produce and store. The second is retrieve and learn. This new learning algorithm is evaluated by the adaptation of a writer-independent handwriting recognition system. Moreover, the results using a benchmark database named LaViola prove the efficiency of the proposed GALTM-AM. Performance comparison of GALTM-AM algorithm over the existing approaches is presented.	algorithm;artificial neural network;benchmark (computing);handwriting recognition;interference (communication);plug-in (computing);radial (radio);radial basis function	Lobna Haddad;Tarek M. Hamdani;Adel M. Alimi	2016	2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2016.7844651	algorithm design;speech recognition;cybernetics;computer science;artificial intelligence;machine learning;interference;handwriting recognition;writing	Robotics	13.529537228498754	-32.76688996336617	96672
a64da723ef55eb57893c72dbcbc2aa9190fe72c9	a class discriminality measure based on feature space partitioning	stopping criteria;optimisation;image processing;optimizacion;distance measure;variable selection criterion;class separability measure;procesamiento imagen;feature space;classification;traitement image;class discriminability measure;interclass distance measure;variable selection;feature selection criterion function;temps calcul;feature evaluation;feature subset selection;pattern recognition;evaluation;feature selection;optimization;reconnaissance forme;evaluacion;tiempo computacion;computation time;reconocimiento patron;clasificacion	-This paper presents a new class discriminability measure based on an adaptive partitioning of the feature space according to the available class samples. It is intended to be used as a criterion in a classifier-independent feature selection procedure. The partitioning is performed according to a binary splitting rule and appropriate stopping criteria. Results from several tests with Gaussian and non-Gaussian, multidimensional and multiclass computer-generated samples, were very similar to those obtained using a Bayes error criterion function, i.e. the optimal feature subsets selected by both criterion functions-were the same. The main advantage of the new measure is that it is computationally efficient. Class discriminability measure Feature selection criterion function Variable selection criterion Feature evaluation Interclass distance measure Class separability measure	adaptive grammar;algorithmic efficiency;binary splitting;computation;computer-generated holography;emoticon;feature selection;feature vector;linear separability;loss function;real life;selection algorithm;space partitioning	André F. Kohn;Luis G. M. Nakano;Miguel Oliveira e Silva	1996	Pattern Recognition	10.1016/0031-3203(95)00122-0	feature vector;biological classification;computer science;evaluation;machine learning;pattern recognition;mathematics;feature selection;statistics	Vision	10.793721169025577	-34.6632749361116	96727
1089a879afdfc49637dd995c6a5365c402004393	sublinear models for graphs		This contribution extends linear models for feature vectors to sublinear models for graphs and analyzes their properties. The results are (i) a geometric interpretation of sublinear classifiers, (ii) a generic learning rule based on the principle of empirical risk minimization, (iii) a convergence theorem for the margin perceptron in the sublinearly separable case, and (iv) the VC-dimension of sublinear functions. Empirical results on graph data show that sublinear models on graphs have similar properties as linear models for feature vectors.	empirical risk minimization;feature vector;learning rule;linear model;perceptron;vc dimension	Brijnesh J. Jain	2014	CoRR		mathematical optimization;combinatorics;discrete mathematics;mathematics;sublinear function	ML	20.967639534621068	-33.242197270990566	97000
36db9f16f4ab1f973f73bf7fd86d34d847091dfd	deep learning with adaptive learning rate using laplacian score	gradient descent;deep learning;laplacian score;adaptive learning rate	Adaptive learning rate has been proposed for Deep Learning in MLP.Technique for updating learning rate is free of hyper-parameters.Learning rate is a function of a parameter called learning parameter.Learning parameter is updated based on error gradient.Learning rate is further updated based on the Laplacian score of activation values. An attempt has been made to improve the performance of Deep Learning with Multilayer Perceptron (MLP). Tuning the learning rate or finding an optimum learning rate in MLP is a major challenge. Depending on the value of the learning rate, classification accuracy can vary drastically. This issue has been taken as a challenge in this paper. In this paper, a new approach has been proposed to combine adaptive learning rate in conjunction with the concept of Laplacian score for varying the weights. Learning rate is taken as a function of parameter which itself is updated on the basis of error gradient by forming mini-batches. Laplacian score of the neuron isfurther used for updating the incoming weights. This removes the bottleneck involved in finding the optimum value for the learning rate in Deep Learning by using MLP. It is observed on benchmark datasets that this approach leads to increase in classification accuracy as compared to the existing benchmark levels achieved by the well known methods of deep learning.	deep learning;laplacian matrix	Bala Chandra;Rajesh Kumar Sharma	2016	Expert Syst. Appl.	10.1016/j.eswa.2016.05.022	semi-supervised learning;gradient descent;unsupervised learning;multi-task learning;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;deep learning;stability;active learning;probably approximately correct learning;statistics;generalization error	ML	16.60537133200266	-31.892695658196015	97159
ca14af129fa09f97d148003895326204e5a80430	biologically inspired motion detection neural network models evolved using genetic algorithms	feedforward neural network;chromosome;probability;probability cellular biophysics genetic algorithms iterative methods motion estimation neural nets;feed forward neural network;neural nets;activation function;reichardt model;motion detection neural networks biological system modeling genetic algorithms artificial neural networks biological information theory biological cells feedforward neural networks evolution biology feedforward systems;crossover;evolving neural networks;motion estimation;optimal network;reichardt model genetic algorithm recurrent neural networks;weight matrix;spatial filters;iterative methods;artificial neural networks;image edge detection;activation function motion detection artificial neural network feedforward neural network genetic algorithm chromosome weight matrix crossover mutation iteration optimal network reichardt model;pixel;iteration;genetic algorithm;genetic algorithms;neurons;recurrent neural networks;recurrent neural network;neural network model;encoding;motion detection;cellular biophysics;mutation;artificial neural network;fitness function;neural network	In this paper we describe a method to evolve biologically inspired motion detection systems utilizing artificial neural networks (ANN's). Previously, the evolution of neural networks has focused on feed-forward neural networks or networks with predefined architectures. The purpose of this paper is to present a novel method for evolving neural networks with no predefined architectures to solve various problems including motion detection models. The neural network models are evolved with genetic algorithms using an encoding that defines a functional network with no restriction on recurrence, activation function types, or the number of nodes that compose the final ANN. The genetic algorithm operates on a population of potential solutions where each potential network is represented in a chromosome. The structure of each chromosome in the population is defined with a weight matrix which allows for efficient simulation of outputs. Each chromosome is evaluated by a fitness function that scores how well the actual output of an ANN compares to the expected output. Crossovers and mutations are made with specified probabilities between population members to evolve new members of the population. After a number of iterations a near optimal network is evolved that solves the problem at hand. The approach has proven to be sufficient to create biologically realistic motion detection neural network models with results that are comparable to results obtained from the standard Reichardt model.	activation function;artificial neural network;feedforward neural network;fitness function;function type;genetic algorithm;iteration;simulation	Sherif Azary;Peter G. Anderson;Roger S. Gaborski	2009	2009 IEEE Applied Imagery Pattern Recognition Workshop (AIPR 2009)	10.1109/AIPR.2009.5466326	nervous system network models;computer science;artificial intelligence;theoretical computer science;machine learning;time delay neural network	Vision	16.128986232384804	-24.00197393056841	97186
e1b6d643a1601c60c878452c300f89fdd653645a	linearly convergent stochastic heavy ball method for minimizing generalization error		In this work we establish the first linear convergence result for the stochastic heavy ball method. The method performs SGD steps with a fixed stepsize, amended by a heavy ball momentum term. In the analysis, we focus on minimizing the expected loss and not on finite-sum minimization, which is typically a much harder problem. While in the analysis we constrain ourselves to quadratic loss, the overall objective is not necessarily strongly convex.		Nicolas Loizou;Peter Richtárik	2017	CoRR		rate of convergence;quadratic equation;expected loss;generalization error;mathematical optimization;convex function;mathematics;momentum	ML	22.698554921953725	-32.82822039424353	97190
dc93f2c8bea8e0c73e04785e0bb8409e61bd6548	sia: a supervised inductive algorithm with genetic search for learning attributes based concepts	decision tree;search space;rule learning;genetics;learning system;data analysis	Abst rac t . This paper describes a genetic learning system called SIA, which learns attributes based rules from a set of preclassified examples. Examples may be described with a variable number of attributes, which can be numeric or symbolic, and examples may belong to several classes. SIA algorithm is somewhat similar to the AQ algorithm because it takes an example as a seed and generalizes it, using a genetic process, to find a rule maximizing a noise tolerant rule evaluation criterion. The SIA approach to supervised rule learning reduces greatly the possible rule search space when compared to the genetic Michigan and Pitt approaches. SIA is comparable to AQ and decision trees algorithms on two learning tasks. Furthermore, it has been designed for a data analysis task in a large and complex justice domain.	decision tree;genetic algorithm;heuristic;inductive reasoning;learnability;missing data;oracle advanced queuing;signal-to-noise ratio	Gilles Venturini	1993		10.1007/3-540-56602-3_142	semi-supervised learning;unsupervised learning;multi-task learning;instance-based learning;preference learning;algorithmic learning theory;contrast set learning;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;inductive transfer;information fuzzy networks;learning classifier system;supervised learning;stability;id3 algorithm;active learning	AI	14.24394825517263	-35.99576174596403	97350
6aaa54079b3dcabb711bfd3aeef9b40b6809e77f	a new error function at hidden layers for past training of multilayer perceptrons	hidden variable theory;optimisation;learning rate;layer by layer;learning algorithm;convergence;neural networks;learning;etude theorique;error function;layer model;by layer;modelo capa;multilayer perceptrons;multilayer perceptrons maximum likelihood estimation equalizers bit error rate convolution digital communication adaptive signal processing time varying channels delay estimation radial basis function networks;teoria variable escondida;handwritten digit recognition;multilayer perceptron;indexing terms;backpropagation;algorithme;aprendizaje;algorithm;error analysis;apprentissage;red multinivel;backpropagation algorithm;modele couche;theorie variable cachee;estudio teorico;funcion error;word recognition;pattern recognition;speech recognition error function past training multilayer perceptrons error backpropagation optimum learning rates handwritten digit recognition isolated word recognition convergence layer by layer algorithm;optimisation multilayer perceptrons backpropagation handwritten character recognition speech recognition error analysis convergence;speech recognition;fonction erreur;reconnaissance forme;multilayer network;reseau multicouche;theoretical study;perceptron;reconocimiento patron;article;handwritten character recognition;algoritmo	This letter proposes a new error function at hidden layers to speed up the training of multilayer perceptrons (MLP's). With this new hidden error function, the layer-by-layer (LBL) algorithm approximately converges to the error backpropagation algorithm with optimum learning rates. Especially, the optimum learning rate for a hidden weight vector appears approximately as a multiplication of two optimum factors, one for minimizing the new hidden error function and the other for assigning hidden targets. Effectiveness of the proposed error function was demonstrated for handwritten digit recognition and isolated-word recognition tasks. Very fast learning convergence was obtained for MLP's without the stalling problem experienced in conventional LBL algorithms.		Sang-Hoon Oh;Soo-Young Lee	1999	IEEE transactions on neural networks	10.1109/72.774272	speech recognition;computer science;artificial intelligence;backpropagation;machine learning;artificial neural network	ML	16.985521902008546	-28.316346005656527	97356
8d9a18a90b75c27e04796a185963ad4bc2c1ac5a	adaptive critic for sigma-pi networks	modelizacion;dynamic programming;adaptive critic;programacion dinamica;learning rate;learning;reforzamiento;reinforcement;dynamic program;temporal information;aprendizaje;modelisation;apprentissage;sigma pi;programmation dynamique;renforcement;output error;multi cube;associative reward penalty;reseau neuronal;modeling;red neuronal;neural network	"""-This article presents an investigation which studied how training o f sigma-pi networks with the associative reward-penalty ( A R-p ) regime may be enhanced by using two networks in parallel. The technique uses what has been termed an unsupervised """"'adaptive critic element"""" (ACE) to give critical advice to the supervised sigma-pi network. We utilise the conventions that the sigma-pi neuron model uses (i.e., quantisation o f variables) to obtain an implementation we term the """"'quantised adaptive critic"""", which is hardware realisable. The associative rewardpenalty training regime either rewards, r = 1, the neural network by incrementing the weights o f the net by a delta term times a learning rate, ~, or penalises, r = O, the neural network by decrementing the weights by an inverse delta term times the product o f the learning rate and a penalty coefficient, ~ × Arp. Our initial research, utilising a """"'bounded"""" reward signal, r* E { 0 , . . . , 1}, found that the critic provides advisory information to the sigma--pi net which augments its training efficiency. This led us to develop an extension to the adaptive critic and associative reward-penalty methodologies, utilising an """"unbounded"""" reward signal, r* E { 1 , . . . , 2}, which permits penalisation o f a net even when the penalty coefficient, Arp, is set to zero, A,p = O. One should note that with the standard associative reward-penalty methodology the net is normally only penalised i f the penalty coefficient is non-zero (i.e., 0 < Arp ~< 1). One o f the enigmas o f associative reward-penalty (AR-I,) training is that it broadcasts sparse information, in the form o f an instantaneous binary reward signal, that is only dependent on the present output error. Here we put forward ACE and AR-I, methodologies for sigma-pi nets, which are based on tracing the frequency o f • """"stimuli"""" occurrence, and then using this to derive a prediction o f the reinforcement. The predictions are then used to derive a reinforcement signal which uses temporal information. Hence one may use more precise information to enable more efficient training. Copyright ©1996 Elsevier Science Ltd Keywords--Sigma-pi, Adaptive critic, Associative reward-penalty, Multi-cube, Reinforcement, Dynamic programming."""	ace;arp spoofing;artificial neural network;biological neuron model;coefficient;dynamic programming;penalty method;quantization (physics);reinforcement learning;sparse matrix;unsupervised learning	Richard Stuart Neville;T. John Stonham	1996	Neural Networks	10.1016/0893-6080(96)00015-9	reinforcement;simulation;systems modeling;computer science;artificial intelligence;machine learning;dynamic programming;artificial neural network	ML	18.082013010701633	-27.47919142739223	97427
7d976f1a9edfae3b5168b77cce8ab732c5496554	on sample complexity for computational pattern recognition	vc dimension;data compression;computational complexity;pattern recognition	In this work we consider the task of pattern recognition in which the target (labelling) function is known to be computable on some Turing machine. It is easy to show that there exist a pattern recognition method for which the number of examples needed to approximate the target function with certain accuracy is linear in the length of the (unknown) program computing the target function. We investigate the question whether any bounds of this kind exist if we consider only computable pattern recognition methods. We find that the number of examples required for a computable method to approximate an unknown computable function not only is not linear, but grows faster (in the length of the target function) than any computable function. No time or space constraints are put on the predictors or target functions; the only resource we consider is the training examples. The task of pattern recognition is considered in conjunction with another learning problem — data compression. An impossibility result for the task of data compression allows us to estimate the sample complexity for pattern recognition.	approximation algorithm;computable function;data compression;existential quantification;pattern recognition;sample complexity;turing machine	Daniil Ryabko	2005	CoRR			Vision	20.13807126796511	-31.74594463119095	97503
37cde7aef01d6f672e15ed9e74349aac944b31f5	neural information processing. theory and algorithms	simulation and modeling;data mining;computer vision;artificial intelligent;information processing;pattern recognition;knowledge discovery		algorithm;information processing		2010		10.1007/978-3-642-17537-4	computer vision;intelligent character recognition;computer science;data science;machine learning;data mining	ML	10.692142932163536	-27.58189711671902	97624
e8bcc0ffa9cfb9b8e9b77f5b386ed5eb34d9400c	a new adaptive momentum algorithm for split-complex recurrent neural networks	variable learning rate;convergence;split complex neural networks;variable gain factor;momentum term	The momentum method is a commonly used method to accelerate the learning of neural networks. In this paper, a new adaptive momentum algorithm is proposed for split-complex recurrent neural networks training. Different from other momentum methods, this new algorithm uses a variable gain factor and a variable learning rate to speed up the convergence and smooth the weight trace. The global convergence of the new algorithm is proved under mild conditions. Numerical results show that the algorithm is efficient for the given test problems.	algorithm;artificial neural network;recurrent neural network	Dongpo Xu;Hongmei Shao;Huisheng Zhang	2012	Neurocomputing	10.1016/j.neucom.2012.03.013	mathematical optimization;convergence;computer science;artificial intelligence;machine learning;mathematics	ML	16.266925221816564	-29.256335863359258	97657
7de1cb39ff7f1f26d073baf26a943eaa379afeb4	online learnability of statistical relational learning in anomaly detection	anomaly detection online learning learning stability statistical relational learning bayesian logic programs;analytical models;surveillance;bayes methods;anomaly detection;training;human supervision online learnability statistical relational learning security related application online learning stability learning process bayesian logic programs learning algorithm false predictor tentative stability requirement masquerade reliable anomaly detection context knowledge base;bayesian methods;random variables;online learning;learning systems;learning stability;statistical relational learning;stability analysis;learning artificial intelligence;knowledge based systems;training stability analysis bayesian methods random variables knowledge based systems surveillance analytical models;learning systems bayes methods learning artificial intelligence;bayesian logic programs	Statistical Relational Learning (SRL) methods for anomaly detection are introduced via a security-related application. Operational requirements for online learning stability are outlined and compared to mathematical definitions as applied to the learning process of a representative SRL method - Bayesian Logic Programs (BLP). Since a formal proof of online stability appears to be impossible, tentative common sense requirements are formulated and tested by theoretical and experimental analysis of a simple and analytically tractable BLP model. It is found that learning algorithms in initial stages of online learning can lock on unstable false predictors that nevertheless comply with our tentative stability requirements and thus masquerade as bona fide solutions. The very expressiveness of SRL seems to cause significant stability issues in settings with many variables and scarce data. We conclude that reliable anomaly detection with SRL-methods requires monitoring by an overarching framework that may involve a comprehensive context knowledge base or human supervision.	algorithm;anomaly detection;cobham's thesis;control theory;formal proof;knowledge base;learnability;machine learning;requirement;statistical relational learning	Magnus Jändel;Pontus Svenson;Niclas Wadströmer	2012	2012 15th International Conference on Information Fusion		computer science;artificial intelligence;machine learning;data mining	ML	17.659926526305703	-34.859913896631	97830
0f90f8fda399e4207ce74ad3e31bbaf2ebb38c5f	a semi-parametric hybrid neural model for nonlinear blind signal separation	neural model;blind signal separation	"""Nonlinear blind signal separation is an important but rather difficult problem. Any general nonlinear independent component analysis algorithm for such a problem should specify which solution it tries to find. Several recent neural networks for separating the post nonlinear blind mixtures are limited to the diagonal nonlinearity, where there is no cross-channel nonlinearity. In this paper, a new semi-parametric hybrid neural network is proposed to separate the post nonlinearly mixed blind signals where cross-channel disturbance is included. This hybrid network consists of two cascading modules, which are a neural nonlinear module for approximating the post nonlinearity and a linear module for separating the predicted linear blind mixtures. The nonlinear module is a semi-parametric expansion made up of two sub-networks, one of which is a linear model and the other of which is a three-layer perceptron. These two sub-networks together produce a """"weak"""" nonlinear operator and can approach relatively strong nonlinearity by tuning parameters. A batch learning algorithm based on the entropy maximization and the gradient descent method is deduced. This model is successfully applied to a blind signal separation problem with two sources. Our simulation results indicate that this hybrid model can effectively approach the cross-channel post nonlinearity and achieve a good visual quality as well as a high signal-to-noise ratio in some cases."""	antibody to islet cells of pancreas measurement;approximation;artificial neural network;blind signal separation;entropy maximization;expectation–maximization algorithm;gradient descent;hybrid neural network;independent computing architecture;independent component analysis;linear model;multitier architecture;nonlinear programming;nonlinear system;parametric model;perceptron;programming paradigm;semiconductor industry;signal-to-noise ratio;solutions;visually impaired persons;wakefulness;mixture	Hanchuan Peng;Zheru Chi;Wan-Chi Siu	2000	International journal of neural systems	10.1142/S0129065700000089	mathematical optimization;computer science;machine learning;control theory;mathematics;blind signal separation	ML	17.73836573318896	-26.468256515135852	97927
df75426aa1894c26a5092bef659c59a8bd6eebf9	artificial intelligence: methodology, systems, and applications		In data mining, an important early decision for a user to make is to choose an appropriate technique for analyzing the dataset at hand so that generalizations can be learned. Intuitively, a trial-and-error approach becomes impractical when the number of data mining algorithms is large while experts’ advice to choose among them is not always available and affordable. Our approach is based on meta-learning, a way to learn from prior learning experience. We propose a new approach using regression to obtain a ranked list of algorithms based on data characteristics and past performance of algorithms in classification tasks. We consider both accuracy and time in generating the final ranked result for classification, although our approach can be extended to regression problems.	algorithm selection;artificial intelligence;big data;data mining;ensemble learning;lecture notes in computer science;list of algorithms;meta learning (computer science);p (complexity);predictive modelling;run time (program lifecycle phase);sigkdd;springer (tank);weka	Asma Trabelsi;Zied Elouedi;Eric Lefevre	2016		10.1007/978-3-319-44748-3	artificial architecture;artificial intelligence system;artificial intelligence, situated approach	ML	11.510137987652246	-37.57081715322787	98475
bacb78a08252349bd6c0ccfbfd5c29685f4d3f3a	an efficient sequential learning algorithm for growing and pruning rbf (gap-rbf) networks	sequential learning;piecewise linear approximation;learning algorithm;my publications;benchmark problem;function approximation gaussian distribution learning artificial intelligence radial basis function networks generalisation artificial intelligence approximation theory;growing and pruning gap rbf;indexing terms;approximation theory;radial basis function networks;algorithms artificial intelligence computer simulation models statistical neural networks computer;radial basis function;function approximation;sequential learning growing and pruning gap rbf radial basis function rbf networks;neurons radio access networks radial basis function networks piecewise linear techniques distributed computing resource management least squares approximation piecewise linear approximation root mean square;artificial intelligence generalization growing and pruning algorithm rbf radial basis function networks piecewise linear approximation gaussian function sequential learning algorithms;generalisation artificial intelligence;learning artificial intelligence;rbf network;gaussian distribution;radial basis function rbf networks	"""This work presents a simple sequential growing and pruning algorithm for radial basis function (RBF) networks. The algorithm referred to as growing and pruning (GAP)-RBF uses the concept of """"Significance"""" of a neuron and links it to the learning accuracy. """"Significance"""" of a neuron is defined as its contribution to the network output averaged over all the input data received so far. Using a piecewise-linear approximation for the Gaussian function, a simple and efficient way of computing this significance has been derived for uniformly distributed input data. In the GAP-RBF algorithm, the growing and pruning are based on the significance of the """"nearest"""" neuron. In this paper, the performance of the GAP-RBF learning algorithm is compared with other well-known sequential learning algorithms like RAN, RANEKF, and MRAN on an artificial problem with uniform input distribution and three real-world nonuniform, higher dimensional benchmark problems. The results indicate that the GAP-RBF algorithm can provide comparable generalization performance with a considerably reduced network size and training time."""	abalone (dietary);algorithm;algorithmic efficiency;benchmark (computing);checking (action);computation (action);gap theorem;generalization (psychology);linear approximation;machine learning;neuron;normal statistical distribution;radial (radio);radial basis function network;ranitidine;small;total peripheral resistance	Guang-Bin Huang;Paramasivan Saratchandran;Narasimhan Sundararajan	2004	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2004.834428	normal distribution;mathematical optimization;radial basis function;index term;sequence learning;function approximation;computer science;machine learning;pattern recognition;approximation theory	ML	16.90536780177039	-29.018274093971534	98682
8a9e9a298d9a8a50dd5b57c0f24db35f8d91dce4	nonparametric classification using matched binary decision trees	optimal solution;solution optimale;decision tree;methode non parametrique;concepcion sistema;optical character recognition;sistema informatico;nonparametric classification;computer system;arbol decision;classification;metodo no parametrico;reconnaissance caractere;arbol binario;system design;solucion optima;arbre binaire;pattern recognition;non parametric method;systeme informatique;reconnaissance forme;reconocimiento patron;decision trees;character recognition;arbre decision;clasificacion;conception systeme;reconocimiento caracter;binary tree	Abstract   The paper describes a new technique for designing binary decision tree classifiers. Decision features are chosen at each node in such a way that the classifier formed by combining the decision trees behaves in an optimal fashion.	decision tree	Seymour Shlien	1992	Pattern Recognition Letters	10.1016/0167-8655(92)90037-Z	random binary tree;influence diagram;decision tree learning;computer science;artificial intelligence;machine learning;decision tree;alternating decision tree;incremental decision tree;algorithm;decision stump	Vision	11.112641250404296	-33.55369876173114	98784
480057a588f77f53f4aa056fd77ac28950396705	sufficient conditions for agnostic active learnable		We study pool-based active learning in the presence of noise, i.e. the agnostic setting. Previous works have shown that the effectiveness of agnostic active learning depends on the learning problem and the hypothesis space. Although there are many cases on which active learning is very useful, it is also easy to construct examples that no active learning algorithm can have advantage. In this paper, we propose intuitively reasonable sufficient conditions under which agnostic active learning algorithm is strictly superior to passive supervised learning. We show that under some noise condition, if the Bayesian classification boundary and the underlying distribution are smooth to a finite order, active learning achieves polynomial improvement in the label complexity; if the boundary and the distribution are infinitely smooth, the improvement is exponential.	active learning (machine learning);algorithm;bayesian network;polynomial;supervised learning;time complexity	Liwei Wang	2009			semi-supervised learning;mathematical optimization;artificial intelligence;machine learning;mathematics;active learning;generalization error	ML	20.138489539215996	-32.827420208014686	98814
dbdc89ee45413196a7f36e3d4d1cde2263caf764	reduced polynomial classifier using within-class standardizing transform	higher order mixed sample moments;resource limitation;polynomial regression;projection operator;approximation method;higher order data statistics;training;regression analysis higher order statistics pattern classification polynomial approximation;feature space;polynomials;higher order;higher order statistics;matrices;projection operation;prc flexibility;vectors;polynomial regression based classifier;computational complexity;within class standardizing transform;reduced polynomial classifier;polynomials vectors approximation methods matrices training numerical simulation computational complexity;polynomial approximation order;pattern classification;reduced dimension classifier;regression analysis;classification problem;approximation methods;feature space dimensionality;classification problem reduced polynomial classifier within class standardizing transform polynomial regression based classifier higher order data statistics projection operation higher order mixed sample moments polynomial approximation order feature space dimensionality reduced dimension classifier numerical simulation prc flexibility;real time application;polynomial approximation;numerical simulation	In this paper we introduce a novel, reduced dimension, Polynomial Regression based Classifier (PRC). The classical PRC expands the observed feature data set by considering higher order data statistics. The herein presented novel PRC preliminary performs projections of the data on suitable subspaces associated with the different classes. The projection operation is followed by discarding the contributions due to the higher order mixed sample moments evaluated on the data. Thereby, the overall polynomial approximation order is maintained while the dimensionality of the expanded feature space exploited by the reduced dimension classifier is drastically reduced. We assess the performance of both the full and the reduced PRC by numerical simulations on different scenarios. The reduced dimension PRC performs at least as well as the classical PRC with a significantly lower number of involved terms. This paves the way for extensively exploiting the PRC flexibility and applicability to complex classification problem although in resource limited system environments, such as, for instance, real-time applications on FPGAs.	computation;computational complexity theory;computational resource;feature data;feature vector;field-programmable gate array;independent computing architecture;numerical analysis;order of approximation;polynomial;preprocessor;real-time clock;real-time computing;simulation;whitening transformation;whole earth 'lectronic link	Gaetano Scarano;Laura Forastiere;Stefania Colonnese;Stefano Rinauro	2012	2012 5th International Symposium on Communications, Control and Signal Processing	10.1109/ISCCSP.2012.6217825	mathematical optimization;discrete mathematics;machine learning;mathematics	Arch	23.655807545004098	-37.66837968459228	99614
2fa48b177f5071d8e2f12bf57e5fcc31a2860660	latent class models for algorithm portfolio methods	portfolio methods;latent class models;satisfiability;sat;latent class model	Different solvers for computationally difficult problems such as satisfiability (SAT) perform best on different instances. Algorithm portfolios exploit this phenomenon by predicting solvers’ performance on specific problem instances, then shifting computational resources to the solvers that appear best suited. This paper develops a new approach to the problem of making such performance predictions: natural generative models of solver behavior. Two are proposed, both following from an assumption that problem instances cluster into latent classes: a mixture of multinomial distributions, and a mixture of Dirichlet compound multinomial distributions. The latter model extends the former to capture burstiness, the tendency of solver outcomes to recur. These models are integrated into an algorithm portfolio architecture and used to run standard SAT solvers on competition benchmarks. This approach is found competitive with the most prominent existing portfolio, SATzilla, which relies on domain-specific, hand-selected problem features; the latent class models, in contrast, use minimal domain knowledge. Their success suggests that these models can lead to more powerful and more general algorithm portfolio methods.	algorithm;benchmark (computing);boolean satisfiability problem;computation;computational problem;computational resource;dicom;embedded system;generative model;mathematical model;mixture model;multinomial logistic regression;problem solving;solver	Bryan Silverthorn;Risto Miikkulainen	2010			latent class model;mathematical optimization;machine learning;satisfiability	AI	23.705508866597686	-28.583646995468968	99639
45c462ad4e87240af6515e6d240019d43d94fc32	locally weighted interpolating growing neural gas	locally weighted learning;modelizacion;theorie locale;interpolation;local theory;high dimensionality;function approximation neurons least squares approximation piecewise linear approximation linear regression approximation algorithms self organizing feature maps learning information analysis information systems;radial basis function extension;algorithms information storage and retrieval information theory neural networks computer pattern recognition automated signal processing computer assisted;fonction base radiale;growing neural gas;local weighted interpolation;growing neural gas gng;locally weighted projection regression function approximation growing neural gas self organizing map local weighted interpolation nonstationary input distributions radial basis function extension;self organising feature maps function approximation interpolation;approximation fonction;modelisation;radial basis functions rbfs;radial basis function;function approximation;self organising feature maps;locally weighted projection regression;weighted sums;non stationary condition;self organizing maps soms function approximation growing neural gas gng locally weighted learning radial basis functions rbfs;self organizing map;self organizing maps soms;autoorganizacion;self organization;condition non stationnaire;self organized map;teoria local;condicion no estacionaria;reseau neuronal;funcion radial base;modeling;nonstationary input distributions;red neuronal;autoorganisation;neural network	"""In this paper, we propose a new approach to function approximation based on a growing neural gas (GNG), a self-organizing map (SOM) which is able to adapt to the local dimension of a possible high-dimensional input distribution. Local models are built interpolating between values associated with the map's neurons. These models are combined using a weighted sum to yield the final approximation value. The values, the positions, and the """"local ranges"""" of the neurons are adapted to improve the approximation quality. The method is able to adapt to changing target functions and to follow nonstationary input distributions. The new approach is compared to the radial basis function (RBF) extension of the growing neural gas and to locally weighted projection regression (LWPR), a state-of-the-art algorithm for incremental nonlinear function approximation"""	algorithm;appendix;approximation;curse of dimensionality;gradient descent;increment;interpolation;interpolation imputation technique;learning rule;linear interpolation;microsoft outlook for mac;neural gas;neuron;neurons;nonlinear system;organizing (structure);paper;projections and predictions;radial (radio);radial basis function;reinforcement learning;self-organization;self-organizing map;weight function	F. Flentge	2006	IEEE Transactions on Neural Networks	10.1109/TNN.2006.879771	mathematical optimization;radial basis function;self-organization;systems modeling;self-organizing map;function approximation;interpolation;computer science;artificial intelligence;machine learning;mathematics;artificial neural network	ML	14.495594225505393	-28.888613381181123	99709
a36eed33d84420ddc3aa114e9b2d34352114ed97	reconstructing damaged complex networks based on neural networks		Despite recent progress in the study of complex systems, reconstruction of damaged networks due to random and targeted attack has not been addressed before. In this paper, we formulate the network reconstruction problem as an identification of network structure based on much reduced link information. Furthermore, a novel method based on multilayer perceptron neural network is proposed as a solution to the problem of network reconstruction. Based on simulation results, it was demonstrated that the proposed scheme achieves very high reconstruction accuracy in small-world network model and a robust performance in scale-free network model.	complex systems;multilayer perceptron;network model;neural networks;reconstruction conjecture;simulation	Ye Hoon Lee;Insoo Sohn	2017	Symmetry	10.3390/sym9120310	artificial neural network;machine learning;complex system;network model;small-world network;combinatorics;mathematics;complex network;multilayer perceptron;scale-free network;artificial intelligence	AI	18.227207579984444	-25.297577710298455	99739
5740585a10f2426d31d4f4f4da53facf41623a5d	a fast identification algorithm with skewness noises under box-cox transformation-based annealing robust fuzzy neural networks		This paper proposes Box-Cox transformation-based annealing robust fuzzy neural networks (ARFNNs) that can be used effectively for function approximated problem with skewness noises. In order to overcome the skewness noises problem, the Box-Cox transformation that its object is usually to make residuals more homogeneous in regression, or transform data to be normally distributed has been added to the annealing robust fuzzy neural networks. That is, the proposed approach uses Box-Cox transformation for skewness noises problem and support vector regression (SVR) for the number of rule in the simplified fuzzy inference systems. After the initialization, an annealing robust learning algorithm (ARLA) is then applied to adjust the parameters of the Box-Cox transformation-based annealing robust fuzzy neural networks. Simulation results show that the proposed approach has a fast convergent speed and more generalization capability for the function approximated problem with skewness noises.	algorithm;artificial neural network;neural networks;simulated annealing	Pi-Yun Chen;Yu-Yi Fu;Jin-Tsong Jeng;Kuo-Lan Su	2011		10.1007/978-3-642-23147-6_24	mathematical optimization;machine learning;mathematics;statistics	ML	15.523263248490974	-29.066202475987517	99742
743dae31f5bc65da060f37d8debb2aa9c3ba0220	loss functions to combine learning and decision in multiclass problems	cross entropy;learning algorithm;posterior class probabilities;posterior probability;feature space;decision problem;local estimation;loss function;learning object;stochastic gradient;support vector machine;learning objective functions;asymmetric classification problems	The design of structures and algorithms for non-MAP multiclass decision problems is discussed in this paper. We propose a parametric family of loss functions that provides accurate estimates for the posterior class probabilities near the decision regions. Moreover, we discuss learning algorithms based on the stochastic gradient minimization of these loss functions. We show that these algorithms behave like sample selectors: samples near the decision regions are the most relevant during learning. Moreover, it is shown that these loss functions can be seen as an alternative to support vector machines (SVM) classifiers for low-dimensional feature spaces. Experimental results on some real data sets are also provided to show the effectiveness of this approach versus the classical cross entropy (based on a global posterior probability estimation).	loss function;multiclass classification	Alicia Guerrero-Curieses;Rocío Alaíz-Rodríguez;Jesús Cid-Sueiro	2005	Neurocomputing	10.1016/j.neucom.2005.02.011	support vector machine;mathematical optimization;hinge loss;feature vector;empirical risk minimization;computer science;online machine learning;machine learning;linear classifier;decision problem;pattern recognition;mathematics;posterior probability;cross entropy;statistics;loss function	Vision	21.015817320092815	-35.118625637297306	99760
07fc2a0e06bc6d89c566143018b414f5162c0d5d	monotone learning with rectifier networks		We introduce a new neural network model, together with a tractable and monotone online learning algorithm. Our model describes feed-forward networks for classification, with one output node for each class. The only nonlinear operation is rectification using a ReLU function with a bias. However, there is a rectifier on every edge rather than at the nodes of the network. There are also weights, but these are positive, static, and associated with the nodes. Our rectified wire networks are able to represent arbitrary Boolean functions. Only the bias parameters, on the edges of the network, are learned. Another departure in our approach, from standard neural networks, is that the loss function is replaced by a constraint. This constraint is simply that the value of the output node associated with the correct class should be zero. Our model has the property that the exact norm-minimizing parameter update, required to correctly classify a training item, is the solution to a quadratic program that can be computed with a few passes through the network. We demonstrate a training algorithm using this update, called sequential deactivation (SDA), on MNIST and some synthetic datasets. Upon adopting a natural choice for the nodal weights, SDA has no hyperparameters other than those describing the network structure. Our experiments explore behavior with respect to network size and depth in a family of sparse expander networks.	algorithm;artificial neural network;cobham's thesis;experiment;loss function;mnist database;network model;nonlinear system;quadratic programming;rectifier (neural networks);sparse matrix;synthetic intelligence;monotone	Veit Elser;Dan Schmidt;Jonathan S. Yedidia	2018	CoRR		mathematical optimization;machine learning;rectification;boolean function;monotone polygon;artificial neural network;hyperparameter;quadratic programming;artificial intelligence;mathematics;mnist database;nonlinear system	ML	18.502369252660117	-31.296063127925656	99989
14d812fd8e066a881ffb130e3c374e4f6bd357f2	the anns approach to dem reconstruction			digital elevation model	Paolo Massimo Buscema;Giulia Massini;Marco Fabrizi;Marco Breda;Francesca Della Torre	2018	Computational Intelligence	10.1111/coin.12151	speech recognition;computer science;artificial neural network	Vision	10.99737011930557	-25.482748418861352	100046
0bb50c7d4220705a4a35de5bd195e0ad1ce4b16f	skeletonization: a technique for trimming the fat from a network via relevance assessment		"""This paper proposes a means of using the knowledge in a network to determine the functionality or relevance of individual units, both for the purpose of understanding the network's behavior and improving its performance. The basic idea is to iteratively train the network to a certain performance criterion, compute a measure of relevance that identifies which input or hidden units are most critical to performance, and automatically trim the least relevant units. This skeletonization technique can be used to simplify networks by eliminating units that convey redundant information; to improve learning performance by first learning with spare hidden units and then trimming the unnecessary ones away, thereby constraining generalization; and to understand the behavior of networks in terms of minimal """"rules."""""""	relevance feedback;topological skeleton	Michael C. Mozer;Paul Smolensky	1988			artificial intelligence;machine learning	ML	15.113526964540046	-33.800210824756526	100155
593d4aae674d116730ce9b27953847b81eb0e6d0	landmarking manifolds with gaussian processes		We present an algorithm for finding landmarks along a manifold. These landmarks provide a small set of locations spaced out along the manifold such that they capture the low-dimensional nonlinear structure of the data embedded in the high-dimensional space. The approach does not select points directly from the dataset, but instead we optimize each landmark by moving along the continuous manifold space (as approximated by the data) according to the gradient of an objective function. We borrow ideas from active learning with Gaussian processes to define the objective, which has the property that a new landmark is “repelled” by those currently selected, allowing for exploration of the manifold. We derive a stochastic algorithm for learning with large datasets and show results on several datasets, including the Million Song Dataset and articles from the New York Times.	approximation algorithm;embedded system;gaussian process;gradient;greedy algorithm;heuristic;loss function;mathematical optimization;nonlinear system;optimization problem;the circle (file system);the new york times	Dawen Liang;John William Paisley	2015			machine learning;pattern recognition;data mining;mathematics;statistics;manifold alignment	ML	24.19181714070435	-37.1379318559233	100193
4d218fb5d8f923dddecd3a2bd6ee3118251449f8	two approaches to optimal annealing		We employ both master equation and order parameter approaches to analyze the asymptotic dynamics of on-line learning with different learning rate annealing schedules. We examine the relations between the results obtained by the two approaches and obtain new results on the optimal decay coefficients and their dependence on the number of hidden nodes in a two layer architecture.	coefficient;online and offline;online machine learning;simulated annealing	Todd K. Leen;Bernhard Schottky;David Saad	1997			econometrics;mathematical optimization;machine learning;mathematics	ML	19.900174472652857	-26.57565504071053	100586
2bd34cbbcade64be90a071625b33da119460c5c9	path-sgd: path-normalized optimization in deep neural networks		We revisit the choice of SGD for training deep neural networks by reconsidering the appropriate geometry in which to optimize the weights. We argue for a geometry invariant to rescaling of weights that does not affect the output of the network, and suggest Path-SGD, which is an approximate steepest descent method with respect to a path-wise regularizer related to max-norm regularization. Path-SGD is easy and efficient to implement and leads to empirical gains over SGD and AdaGrad.	approximation algorithm;artificial neural network;deep learning;neural networks;stochastic gradient descent	Behnam Neyshabur;Ruslan Salakhutdinov;Nathan Srebro	2015			mathematical optimization;computer science;artificial intelligence;machine learning	ML	21.994552385030044	-32.36278496728448	100809
51d0935136e710a9cea2ab345a822566daa06346	pool-based active learning in approximate linear regression	metodo cuadrado menor;modelizacion;optimal solution;alignement;methode moindre carre;solution optimale;entrada salida;semiconducteur;learning algorithm;sistema activo;least squares method;weighted least square;juguete;active learning;alice;exact solution;linear regression;search strategy;intelligence artificielle;algorithme apprentissage;solucion exacta;semiconductor material;systeme actif;active system;input output;modelisation;semiconductor materials;wafer;estimation erreur;analisis regresion;jouet;error estimation;solucion optima;estimacion error;toy;regresion lineal;alineamiento;strategie recherche;importance weighted least squares;analyse regression;artificial intelligence;regression analysis;pastilla electronica;covariate shift;inteligencia artificial;pastille electronique;solution exacte;algoritmo aprendizaje;modeling;pool based active learning;regression lineaire;alignment;entree sortie;estrategia investigacion;approximate linear regression	The goal of pool-based active learning is to choose the best input points to gather output values from a ‘pool’ of input samples. We develop two pool-based active learning criteria for linear regression. The first criterion allows us to obtain a closed-form solution so it is computationally very efficient. However, this solution is not necessarily optimal in the single-trial generalization error analysis. The second criterion can give a better solution, but it does not have a closed-form solution and therefore some additional search strategy is needed. To cope with this problem, we propose a practical procedure which enables us to efficiently search for a better solution around the optimal solution of the first method. Simulations with toy and benchmark datasets show that the proposed active learning method compares favorably with other active learning methods as well as the baseline passive learning scheme. Furthermore, the usefulness of the proposed active learning method is also demonstrated in wafer alignment in semiconductor exposure apparatus.	active learning (machine learning);approximation algorithm;baseline (configuration management);benchmark (computing);computer simulation;error analysis (mathematics);generalization error;semiconductor;wafer (electronics)	Masashi Sugiyama;Shinichi Nakajima	2009	Machine Learning	10.1007/s10994-009-5100-3	semi-supervised learning;input/output;econometrics;simulation;systems modeling;computer science;linear regression;artificial intelligence;machine learning;active learning;least squares;active learning;wafer;regression analysis;statistics;generalization error	ML	12.316503092565704	-32.751160561974615	100847
087f04c322e67f7c2999f511c6b57b2b3df3fca7	optimization of modular neural network, using genetic algorithms: the case of face and voice recognition	optimization problem;voice recognition;genetic algorithm;hierarchical genetic algorithm;modular neural network;artificial neural network	This paper deals with two optimization problems as the architecture (modules, layers and neurons) and the best training of  an artificial neural network (ANN). For that matter is used a Hierarchical Genetic Algorithm, which theorically has the capacity  to bring the optimal architecture and the training result of the ANN, for a particular task; in this case the recognition  of an individual is via voice and face.  	genetic algorithm;modular neural network;optimizing compiler;speech recognition	José M. Villegas;Alejandra Mancilla;Patricia Melin	2008		10.1007/978-3-540-70812-4_9	optimization problem;probabilistic neural network;genetic algorithm;computer science;artificial intelligence;recurrent neural network;machine learning;pattern recognition;time delay neural network;artificial neural network	AI	13.760027722222237	-25.486566084935475	101277
0be03c2ab5c98ad51322d9d9c4c64e41aea932b3	bernoulli mixture models for markov blanket filtering and classification	search method;mixture model;feature subset selection;feature selection;binary data	This paper presents the use of Bernoulli mixture models for Markov blanket filtering and classification of binary data. Bernoulli mixture models can be seen as a tool for partitioning an n-dimensional hypercube, identifying regions of high data density on the corners of the hypercube. Once Bernoulli mixture models are computed from a training dataset we use them for determining the Markov blanket of the target variable. An algorithm for Markov blanket filtering was proposed by Koller and Sahami (1996), which is a greedy search method for feature subset selection and it outputs an approximation to the optimal feature selection criterion. However, they use the entire training instances for computing the conditioning sets and have to limit the size of these sets for computational efficiency and avoiding data fragmentation. We have adapted their algorithm to use Bernoulli mixture models instead, hence, overcoming the short comings of their algorithm and increasing the efficiency of this algorithm considerably. Once a feature subset is identified we perform classification using these mixture models. We have applied this algorithm to the causality challenge datasets. Our prediction scores were ranked fourth on SIDO and our feature scores were ranked the best for test sets 1 and 2 of the same dataset.	approximation;areal density (computer storage);bernoulli polynomials;binary data;causality;computation;feature selection;fragmentation (computing);greedy algorithm;grid network;markov blanket;markov chain;mixture model	Mehreen Saeed	2008			computer science;machine learning;pattern recognition;mixture model;mathematics;feature selection;statistics	ML	15.626447854415176	-36.37344286767809	101410
400f3adba1fcd332071b75d8c9893064899114e3	a bayesian approach to policy recognition and state representation learning		Learning from demonstration (LfD) is the process of building behavioral models of a task from demonstrations provided by an expert. These models can be used, e.g., for system control by generalizing the expert demonstrations to previously unencountered situations. Most LfD methods, however, make strong assumptions about the expert behavior, e.g., they assume the existence of a deterministic optimal ground truth policy or require direct monitoring of the expert's controls, which limits their practical use as part of a general system identification framework. In this work, we consider the LfD problem in a more general setting where we allow for arbitrary stochastic expert policies, without reasoning about the optimality of the demonstrations. Following a Bayesian methodology, we model the full posterior distribution of possible expert controllers that explain the provided demonstration data. Moreover, we show that our methodology can be applied in a nonparametric context to infer the complexity of the state representation used by the expert, and to learn task-appropriate partitionings of the system state space.	bayesian programming;ground truth;inference;machine learning;policy;state space;system identification	Adrian &#x0160;o&#x0161;i&#x0107;;Abdelhak M. Zoubir;Heinz Koeppl	2018	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2017.2711024	computer science;pattern recognition;data modeling;ground truth;state space;machine learning;feature learning;markov process;generalization;gibbs sampling;system identification;artificial intelligence	Vision	23.9574870767909	-29.52786168292347	101444
8bc423b1a4d7687851ac537b3d13b4ad8697d570	a novel network for nonlinear modeling of neural systems with arbitrary point-process inputs	volterra series;simulation ordinateur;processus ponctuel;poisson process;nonlinear modeling;point process inputs;metodologia;filter bank;neural networks;cross correlation;forme onde;banc filtre;activation function;fonction polynomiale;correlation croisee;point process;serie volterra;non linear model;modele non lineaire;methodologie;experimental result;fonction laguerre;mode ordre eleve;laguerre function;input output;modelo no lineal;neural system;forma onda;neural systems;volterra model;backpropagation algorithm;banco filtro;resultado experimental;proceso puntual;non linearite;algorithme retropropagation;no linealidad;nonlinearity;proceso poisson;funcion laguerre;waveform;simulacion computadora;reseau neuronal;laguerre functions;funcion polinomial;methodology;resultat experimental;poisson point process;polynomial function;estimacion adaptativa;computer simulation;red neuronal;adaptive estimation;dentate gyrus;modo orden elevado;processus poisson;correlacion cruzada;estimation adaptative;neural network;nonlinear model;high order mode;algoritmo retropropagacion	This paper address the issue of nonlinear model estimation for neural systems with arbitrary point-process inputs using a novel network that is composed of a pre-processing stage of a Laguerre filter bank followed by a single hidden layer with polynomial activation functions. The nonlinear modeling problem for neural systems has been attempted thus far only with Poisson point-process inputs and using cross-correlation methods to estimate low-order nonlinearities. The specific contribution of this paper is the use of the described novel network to achieve practical estimation of the requisite nonlinear model in the case of arbitrary (i.e. non-Poisson) point-process inputs and high-order nonlinearities. The success of this approach has critical implications for the study of neuronal ensembles, for which nonlinear modeling has been hindered by the requirement of Poisson process inputs and by the presence of high-order nonlinearities. The proposed methodology yields accurate models even for short input-output data records and in the presence of considerable noise. The efficacy of this approach is demonstrated with computer-simulated examples having continuous output and point-process output, and with real data from the dentate gyrus of the hippocampus.	activation function;additive white gaussian noise;algorithm;attempt;awards;backpropagation;computational complexity theory;computer simulation;cross-correlation;filter bank;network architecture;neural oscillation;nonlinear system;point process;polynomial;preprocessor;software propagation;spontaneous order;structure of dentate gyrus;united states national institutes of health;utility functions on indivisible goods;funding grant	Konstantinos Alataris;Theodore W. Berger;Vasilis Z. Marmarelis	2000	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(99)00092-1	input/output;poisson point process;waveform;poisson process;computer science;backpropagation;cross-correlation;machine learning;calculus;filter bank;methodology;control theory;point process;mathematics;activation function;artificial neural network;statistics	ML	18.859679183513222	-27.807373279370587	101514
175d37cd240593033e626292b9d2401e43333939	the research of codeword based on fuzzy hopfield neural network		Hopfield neural networks are known to cluster analysis and unsuper- vised learning programs. In this paper, a new Hopfield-model net called Corrected Fuzzy Hopfield Neural Network (CFHNN) is proposed for vector quantization in image correction. In CFHNN, the Correct Fuzzy C-means (CFC) algorithm, modified from penalized fuzzy c-means, is embedded into Hopfield neural network so that the parallel implementation for codeword de- sign is feasible. The proposed network also proposed to avoid the network to determine the weight factors of the energy function value. In addition, it plans to make e-learning training more quickly than FC and PFC, more effectively. In the experimental results, CFHNN method shows the FC and PFC method is rel- atively encouraging results.	code word;hopfield network	Xian Fu;Yi Ding	2014		10.1007/978-3-319-09333-8_32	computer science;artificial intelligence;machine learning;hopfield network;algorithm	Vision	13.964124271732999	-32.56065334346127	101595
fc1064244a638489b063acf14ab4467216be9c48	universal approximation in p-mean by neural networks	layer;neural networks;algebra universal;multilayer feedforward networks;etude experimentale;l_p approximation;couche;lp approximation;capa;universal transfer functions;aproximacion lp;approximation lp;approximation theory;approximation par fonction;neural net;transfer function;funcion traspaso;single hidden layer network;fonction transfert;reseau neuronal;approximation by function;algebre universelle;universal algebra;l p approximation;estudio experimental;red neuronal;aproximacion por funcion;moment condition;neural network	A feedforward neural net with d input neurons and with a single hidden layer of n neurons is given byg(x(1), em leader,x(d))= summation operator j=1na(j)sigma,where a(j), theta(j), w(ji) in R. In this paper we study the approximation of arbitrary functions F:R(d)-->R by a neural net in an L(p)(&mgr;) norm for some finite measure &mgr; on R(d). We prove that under natural moment conditions, a neural net with non-polynomial function can approximate any given function.	approximation algorithm;artificial neural network;ephrin type-b receptor 1, human;feedforward neural network;neural network simulation;neurons;polynomial;universal approximation theorem	Robert M. Burton;Herold Dehling	1998	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(98)00009-4	universal algebra;computer science;machine learning;layer;calculus;mathematics;transfer function;artificial neural network;algorithm;approximation theory	ML	18.355393136580357	-28.25991374844252	101703
dc0c7da6508c859eee97e3dc9b9fee207810b701	a cooperative and penalized competitive learning approach to gaussian mixture clustering	competitive strategy;gaussian mixture;learning algorithm;cooperation;penalization;competitive learning;data clustering;gaussian mixture clustering;number of clusters	Competitive learning approaches with penalization or cooperation mechanism have been applied to unsupervised data clustering due to their attractive ability of automatic cluster number selection. In this paper, we further investigate the properties of different competitive strategies and propose a novel learning algorithm called Cooperative and Penalized Competitive Learning (CPCL), which implements the cooperation and penalization mechanisms simultaneously in a single competitive learning process. The integration of these two different kinds of competition mechanisms enables the CPCL to have good convergence speed, precision and robustness. Experiments on Gaussian mixture clustering are performed to investigate the proposed algorithm. The promising results demonstrate its superiority.	algorithm;cluster analysis;competitive learning	Yiu-ming Cheung;Hong Jia	2010		10.1007/978-3-642-15825-4_58	correlation clustering;econometrics;computer science;machine learning;pattern recognition;cluster analysis;competitive learning;cooperation;competitive advantage	AI	12.042569944474968	-32.33708649235251	101802
bf9258d218f1838e9685f420b9a9e478eeb1efc6	a hybrid method for searching near-optimal artificial neural networks	hybrid method;transfer function;genetic algorithm;artificial neural network;neural network	This paper describes a method for searching nearoptimal neural networks using Genetic Algorithms. The method uses an evolutionary search with the simultaneous selection of initial weights, transfer functions, architectures and learning rules. Experimental results have shown that the method is able to produce compact, efficient networks with satisfactory generalization power and shorter training times in comparison to other algorithms.	complex network;continuation;experiment;genetic algorithm;genetic operator;neural networks;performance;software release life cycle;time series	Leandro M. Almeida;Teresa Bernarda Ludermir	2006	2006 Sixth International Conference on Hybrid Intelligent Systems (HIS'06)	10.1109/HIS.2006.4	stochastic neural network;types of artificial neural networks;computer science;artificial intelligence;theoretical computer science;machine learning;time delay neural network;deep learning;intelligent control	Robotics	14.082056326232312	-24.397975446112458	101979
9d6bc0c4098f0521cd95781640e1297ae615b045	theoretical analysis and improved decision criteria for the n-tuple classifier	leave one out cross validation tests;probability;performance evaluation;neural networks;maximum likelihood;helium;bayes methods;probability distributions;leave one out cross validation tests decision criteria classification system probability distributions bayes estimator;ram net;bayesian methods;bayes methods pattern classification probability;testing;maximum likelihood estimation;bayes estimator;theoretical analysis;probability distribution;performance analysis;n tuple classifier;classification system;pattern classification;pattern recognition;bayes;performance analysis testing maximum likelihood estimation neural networks bayesian methods probability distribution performance evaluation pattern recognition table lookup;cross validation;table lookup;leave one out cross validation;decision criteria	The anticipated behavior of the n-tuple classification system is that it gives the highest output score for the class to which the input example actually belongs. By performing a theoretical analysis of how the output scores are related to the underlying probability distributions of the data, this paper shows that this in general is not to be expected. The theoretical results are able to explain the behavior that is observed in experimental studies. The theoretical analysis also give valuable insight into how the n-tuple classifier can be improved to deal with skewed training priors, which until now have been a hard problem for the architecture to tackle. It is shown that by relating an output score to the probability that a given class generates the data makes it possible to design the n-tuple net to operate as a close approximation to the Bayes estimator. It is specifically illustrated that this approximation can be obtained by modifying the decision criteria. In real cases, the underlying example distributions are unknown and accordingly the optimum way to treat the output scores cannot be calculated theoretically. However, it is shown that the feasibility of performing leave-one-out cross-validation tests in n-tuple networks makes it possible to obtain proper processing of the scores in such cases.	approximation;computation;cross-validation (statistics);decision theory;exptime;np (complexity);netware;performance;prototype;statistical classification;weapon target assignment problem	Thomas Martini Jørgensen;Christian Linneberg	1999	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.761264	probability distribution;computer science;machine learning;pattern recognition;mathematics;maximum likelihood;artificial neural network;cross-validation;statistics	ML	14.790085439919672	-35.97924689126645	102054
59409cc7a486cb88b693ee5aec15eab69db9f6d3	adaptive on-line learning in changing environments	loss function;on line algorithm;on line learning	An adaptive on-line algorithm extending the learning of learning idea is proposed and theoretically motivated. Relying only on gradient flow information it can be applied to learning continuous functions or distributions, even when no explicit loss function is given and the Hessian is not available. Its efficiency is demonstrated for a non-stationary blind separation task of acoustic signals.	acoustic cryptanalysis;blind signal separation;gradient;hessian;loss function;online algorithm;online and offline;stationary process	Noboru Murata;Klaus-Robert Müller;Andreas Ziehe;Shun-ichi Amari	1996			semi-supervised learning;unsupervised learning;multi-task learning;empirical risk minimization;wake-sleep algorithm;double loop learning;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;stability;competitive learning;active learning;loss function;generalization error	ML	22.965969640187886	-34.22253273323459	102430
c5b2fbe6c0f059b9c79af3fc560b01458579a36f	dynamic tunneling technique for efficient training of multilayer perceptrons	search problems feedforward neural nets multilayer perceptrons learning artificial intelligence;arquitectura red;learning algorithm;dispositif effet tunnel;feedforward;computational techniques;metodo descenso;point equilibre;gradient method;multilayer perceptrons;multilayer feedforward neural network;global minimum point dynamic tunneling technique multilayer feedforward neural networks local search gradient descent direct search scheme;dispositivo efecto tunel;algorithme apprentissage;tunneling device;multilayer perceptron;indexing terms;boucle anticipation;architecture reseau;equilibrium point;perceptron multicouche;methode gradient;punto equilibrio;ciclo anticipacion;reconnaissance caractere;red multinivel;metodo gradiente;gradient descent;weighted space;condition lipschitz;feedforward neural nets;network architecture;search problems;multilayer network;lipschitz condition;reseau multicouche;perceptron;learning artificial intelligence;reseau neuronal;descent method;direct search;algoritmo aprendizaje;tunneling multilayer perceptrons neurons computer architecture multi layer neural network neural networks testing optimization methods computer networks feedforward neural networks;local search;character recognition;red neuronal;reconocimiento caracter;methode descente;neural network	A new efficient computational technique for training of multilayer feedforward neural networks is proposed. The proposed algorithm consists two learning phases. The first phase is a local search which implements gradient descent, and the second phase is a direct search scheme which implements dynamic tunneling in weight space avoiding the local trap thereby generates the point of next descent. The repeated application of these two phases alternately forms a new training procedure which results into a global minimum point from any arbitrary initial choice in the weight space. The simulation results are provided for five test examples to demonstrate the efficiency of the proposed method which overcomes the problem of initialization and local minimum point in multilayer perceptrons.	algorithm;artificial neural network;feedforward neural network;gradient descent;local search (optimization);maxima and minima;multilayer perceptron;tunneling protocol	Pinaki Roy Chowdhury;Yashwant Prasad Singh;R. A. Chansarkar	1999	IEEE transactions on neural networks	10.1109/72.737492	gradient descent;equilibrium point;network architecture;index term;computer science;gradient method;artificial intelligence;local search;perceptron;machine learning;lipschitz continuity;multilayer perceptron;feed forward;artificial neural network;algorithm	Vision	16.40687649994719	-28.2316774814141	102448
dd63c27ef07e5a1e10d90efce88874da12f76df1	the accuracy of concepts learned from induction	expert systems;pac learning;inductive learning;concept learning;predictive accuracy	Inductive learning methods identify a concept from a training sample consisting of positive and negative examples of a target concept. Several studies have shown how such methods could be used to determine rules for expert systems. The question addressed in this paper is: how accurate is the induced concept when used to classify the original domain or another close domain? We derive results that can be used to determine the accuracy of an induced concept. Two previously published applications of inductive learning are used to illustrate our results.	expert system;inductive reasoning;mathematical induction	Li-Hui Tsai;Gary J. Koehler	1993	Decision Support Systems	10.1016/0167-9236(93)90036-3	natural language processing;unsupervised learning;multi-task learning;concept learning;computer science;artificial intelligence;machine learning;probably approximately correct learning	AI	11.647778514976503	-36.69755660141735	102631
d68d28d43151320142faed2956870c19e6290a20	supervised learning and co-training	supervised learning;pac learning;co training	Co-training under the Conditional Independence Assumption is among the models which demonstrate how radically the need for labeled data can be reduced if a huge amount of unlabeled data is available. In this paper, we explore how much credit for this saving must be assigned solely to the extra assumptions underlying the Co-training Model. To this end, we compute general (almost tight) upper and lower bounds on the sample size needed to achieve the success criterion of PAC-learning in the realizable case within the model of Co-training under the Conditional Independence Assumption in a purely supervised setting. The upper bounds lie significantly below the lower bounds for PAC-learning without Co-training. Thus, Co-training saves labeled data even when not combined with unlabeled data. On the other hand, the saving is much less radical than the known savings in the semi-supervised setting.	co-training;supervised learning	Malte Darnstädt;Hans Ulrich Simon;Balázs Szörényi	2014	Theor. Comput. Sci.	10.1016/j.tcs.2013.09.020	semi-supervised learning;combinatorics;computer science;artificial intelligence;machine learning;data mining;mathematics;supervised learning;probably approximately correct learning;algorithm;statistics	ECom	21.162124501262138	-34.24762643133265	102780
3af1af58d9d17cc180ef4ea1c212003755a41f6f	unbiased online recurrent optimization		The novel emph{Unbiased Online Recurrent Optimization} (UORO) algorithm allows for online learning of general recurrent computational graphs such as recurrent network models. It works in a streaming fashion and avoids backtracking through past activations and inputs. UORO is computationally as costly as emph{Truncated Backpropagation Through Time} (truncated BPTT), a widespread algorithm for online learning of recurrent networks cite{jaeger2002tutorial}. UORO is a modification of emph{NoBackTrack} cite{DBLP:journals/corr/OllivierC15} that bypasses the need for model sparsity and makes implementation easy in current deep learning frameworks, even for complex models. Like NoBackTrack, UORO provides unbiased gradient estimates; unbiasedness is the core hypothesis in stochastic gradient descent theory, without which convergence to a local optimum is not guaranteed. On the contrary, truncated BPTT does not provide this property, leading to possible divergence. On synthetic tasks where truncated BPTT is shown to diverge, UORO converges. For instance, when a parameter has a positive short-term but negative long-term influence, truncated BPTT diverges unless the truncation span is very significantly longer than the intrinsic temporal range of the interactions, while UORO performs well thanks to the unbiasedness of its gradients.	algorithm;backpropagation through time;backtracking;deep learning;gradient;image noise;interaction;mathematical optimization;recurrent neural network;sparse matrix;streaming media;synthetic intelligence;truncation	Corentin Tallec;Yann Ollivier	2017	CoRR		mathematical optimization;computer science;machine learning;network model;local optimum;backtracking;backpropagation through time;divergence;truncation;deep learning;stochastic gradient descent;artificial intelligence	ML	23.066203312046074	-31.91795460596573	102795
6ab1e81f409656046695bf7d8ef6498ad2bb2a63	on the appropriateness of complex-valued neural networks for speech enhancement		Although complex-valued neural networks (CVNNs) – networks which can operate with complex arithmetic – have been around for a while, they have not been given reconsideration since the breakthrough of deep network architectures. This paper presents a critical assessment whether the novel tool set of deep neural networks (DNNs) should be extended to complex-valued arithmetic. Indeed, with DNNs making inroads in speech enhancement tasks, the use of complex-valued input data, specifically the short-time Fourier transform coefficients, is an obvious consideration. In particular when it comes to performing tasks that heavily rely on phase information, such as acoustic beamforming, complex-valued algorithms are omnipresent. In this contribution we recapitulate backpropagation in CVNNs, develop complex-valued network elements, such as the split-rectified non-linearity, and compare realand complexvalued networks on a beamforming task. We find that CVNNs hardly provide a performance gain and conclude that the effort of developing the complex-valued counterparts of the building blocks of modern deep or recurrent neural networks can hardly be justified.	acoustic cryptanalysis;algorithm;backpropagation;beamforming;bellman equation;coefficient;computation;deep learning;experiment;feature extraction;field electron emission;gradient;ibm notes;image scaling;imaginary time;network computing system;neural networks;nonlinear system;norm (social);principal component analysis;rectifier (neural networks);recurrent neural network;short-time fourier transform;speech enhancement;while	Lukas Drude;Bhiksha Raj;Reinhold Häb-Umbach	2016		10.21437/Interspeech.2016-300	speech recognition	ML	22.227177363330146	-32.970463151829634	102916
8b9c282ceaa3341f638c2bfebb982e3717f6b9c2	a neural network for bass functional harmonization	neural network	This paper presents the design, implementation and testing of a neural network for the functional harmonization of a bass line. The overall network consists of three base networks that are used in parallel under the control of an additional network that, at each step, chooses the best output from the three base networks.#R##N##R##N#All the neural networks have been trained using J.S. Bach's chorales. In order to evaluate the networks, a metric measuring the distance of the output from the original J.S. Bach's harmonization is defined.	artificial neural network;beneath a steel sky	Roberto De Prisco;Antonio Eletto;Antonio La Torre;Rocco Zaccagnino	2010		10.1007/978-3-642-12242-2_36	telecommunications;engineering;artificial intelligence;data mining;time delay neural network	ML	14.655190319198052	-25.992025152999933	103015
84d82ae4e60ba3c5cf34a3e0e6619f8f8ce1e58e	mixing numerical and categorical data in a self-organizing map by means of frequency neurons	big data;self organizing map;categorical data;mixed data	Graphical abstractDisplay Omitted HighlightsSelf-Organizing Maps (SOMs) are powerful tools with many applications. Nevertheless, they cannot deal directly with categorical variables.In order to present categorical variables to SOMs, they are usually transformed by binarization. This increases dramatically the dataset dimensionality.NCSOM has been presented in order to cope with categorical or mixed data. However, it presents some drawbacks: categorical and numerical variables are not equally balanced and the method is not convergent.A novel SOM variant, called FMSOM, is presented which is able to deal with numerical and categorical variables, giving the same weight to them and ensuring convergence. A scalable implementation of the method is fully described.FMSOM is applied to a benchmark of well known datasets, composed of categorical and mixed data. The results show the potential of the method to analyze this kind of datasets. Even though Self-Organizing Maps (SOMs) constitute a powerful and essential tool for pattern recognition and data mining, the common SOM algorithm is not apt for processing categorical data, which is present in many real datasets. It is for this reason that the categorical values are commonly converted into a binary code, a solution that unfortunately distorts the network training and the posterior analysis. The present work proposes a SOM architecture that directly processes the categorical values, without the need of any previous transformation. This architecture is also capable of properly mixing numerical and categorical data, in such a manner that all the features adopt the same weight. The proposed implementation is scalable and the corresponding learning algorithm is described in detail. Finally, we demonstrate the effectiveness of the presented algorithm by applying it to several well-known datasets.	categorical variable;numerical analysis;organizing (structure);self-organizing map	Carmelo del Coso;Diego Fustes;Carlos Dafonte;Francisco J. Nóvoa;José M. Rodríguez-Pedreira;Bernardino Arcay Varela	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.06.058	big data;self-organizing map;categorical variable;computer science;artificial intelligence;data science;machine learning;data mining;statistics	Robotics	12.86253333835658	-35.51234870051146	103186
fde95f04d21873fce75a39e0f663b6939c1f9d2a	a neural net framework for accumulative feature-based matrix completion		In this paper, we propose a novel multimodal framework for matrix completion where the missing values are accumulatively estimated with feature-based neural networks. Speciftcally, for each individual feature, a different model is trained to predict the missing values in the observations using the remaining features as input to provide an initial estimate. These estimates are then used to initiate the next round of model training to iteratively converge to the ftnal prediction of the missing value. The weight parameters of the networks are propagated through these accumulative iterations which leads to a computationally efftcient algorithm where training times become progressively shorter with each round. Unlike traditional algorithms relying on matrix factorization, separating the model building and exploiting steps also enables more effective deployment in online applications. Results show that the proposed algorithm outperforms prior work in 80% of the test scenarios when compared to four universally accepted methods on a combination of different datasets and missing data ratios.	.net framework;algorithm;algorithmic efficiency;artificial neural network;computation;computational complexity theory;converge;gene prediction;iteration;mathematical optimization;missing data;multimodal interaction;network topology;software deployment;test case	Mehmet Aktukmak;Samuel Mercier;Ismail Uysal	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489050	matrix completion;software deployment;machine learning;artificial neural network;missing data;model building;scenario testing;pattern recognition;artificial intelligence;matrix decomposition;computer science	ML	22.99906895253069	-34.45827568411155	103291
1e51854d66f90540c2cd9c377151832b285ef810	a method of accelerating neural network learning	tecnologia electronica telecomunicaciones;computacion informatica;neural networks;method of learning;levenberg marqurdt;ciencias basicas y experimentales;backpropagation algorithm;back propagation algorithm;algorithme retropropagation;reseau neuronal;tecnologias;grupo a;back propagation;red neuronal;neural network;algoritmo retropropagacion	The article presents of accelerating neural network learning by the Back Propagation algorithm and one of its fastest modifications – the Levenberg–Marqurdt method. The learning is accelerated by introducing the ‘single-direction’ coefficient of the change of x for calculating its new values (the number of iterations is decreased by approximately 30%). Simulation results of learning neural networks by applying both the classic method and the method of accelerating the procedure are presented.	algorithm;artificial neural network;coefficient;fastest;iteration;newton's method;simulation;software propagation	Sotir Sotirov	2005	Neural Processing Letters	10.1007/s11063-005-3094-9	computer science;artificial intelligence;backpropagation;machine learning;artificial neural network;algorithm	ML	16.190446033758775	-28.535331887958023	103527
e3e768fdae83e220c048f41ab5385c21b3967404	meta-learning with latent embedding optimization		Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems. However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes. We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this lowdimensional latent space. The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters. Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks. Further analysis indicates LEO is able to capture uncertainty in the data, and can perform adaptation more effectively by optimizing in latent space.	data dependency;gradient;mathematical optimization;meta learning (computer science)	Andrei A. Rusu;Dushyant Rao;Jakub Sygnowski;Oriol Vinyals;Razvan Pascanu;Simon Osindero;Raia Hadsell	2018	CoRR		machine learning;generative grammar;decoupling (cosmology);artificial intelligence;computer science;embedding	ML	19.116001674434866	-32.03042518975401	103606
55d2546e01fff8e573bbc1e98cd1dbe90fa38a13	how to solve the n-bit encoder problem with just one hidden unit	minimal network;n bit encoder;multi layer perceptrons;n bit parity;winner take all network	We demonstrate that it is possible to construct a three-layer network of the standard feedforward architecture that can solve the  N  input- N  output encoder problem employing just one (linear)hidden unit.	encoder	David G. Stork;James D. Allen	1993	Neurocomputing	10.1016/0925-2312(93)90033-Y	real-time computing;computer science;theoretical computer science;machine learning	Robotics	15.328701353900751	-27.15570091187897	103620
d4bba26c23a2dfc8ccf171b072d0dd23f8465c2a	air pollution prediction via multi-label classification	air pollution prediction;multi label classification;statistical classification;bayesian networks	A Bayesian network classifier can be used to estimate the probability of an air pollutant overcoming a certain threshold. Yet multiple predictions are typically required regarding variables which are stochastically dependent, such as ozone measured in multiple stations or assessed according to by different indicators. The common practice (independent approach) is to devise an independent classifier for each class variable being predicted; yet this approach overlooks the dependencies among the class variables. By appropriately modeling such dependencies one can improve the accuracy of the forecasts. We address this problem by designing a multilabel classifier, which simultaneously predict multiple air pollution variables. To this end we design a multilabel classifier based on Bayesian networks and learn its structure through structural learning. We present experiments in three different case studies regarding the prediction of PM2.5 and ozone. The multi-label classifier outperforms the independent approach, allowing to take better decisions.	bayesian network;experiment;multi-label classification;naive bayes classifier;norm (social);statistical classification	Giorgio Corani;Mauro Scanagatta	2016	Environmental Modelling and Software	10.1016/j.envsoft.2016.02.030	statistical classification;margin classifier;bayes classifier;quadratic classifier;computer science;machine learning;pattern recognition;bayesian network;data mining	AI	17.432889886851452	-37.68465242003761	103810
26e8d4f16b43935d15b1ba0e3fb40cb478e97ca2	multilayer perceptrons to approximate complex valued functions	multilayer perceptron;value function	In this paper the approximation capabilities of different structures of complex feedforward neural networks, reported in the literature, have been theoretically analyzed. In particular a new density theorem for Complex Multilayer Perceptrons with complex valued non-analytical sigmoidal activation functions has been proven. Such a result makes Multilayer Perceptrons with complex valued neurons universal interpolators of continuous complex valued functions. Moreover the approximation properties of superpositions of analytic activation functions have been investigated, proving that such combinations are not dense in the set of continuous complex valued functions. Several numerical examples have also been reported in order to show the advantages introduced by Complex Multilayer Perceptrons in terms of computational complexity with respect to the classical real MLP.	activation function;approximation algorithm;artificial neural network;computational complexity theory;feedforward neural network;memory-level parallelism;multilayer perceptron;numerical analysis;sigmoid function	Paolo Arena;Luigi Fortuna;R. Re;Maria Gabriella Xibilia	1995	International journal of neural systems	10.1142/S0129065795000299	computer science;artificial intelligence;machine learning;mathematics;bellman equation;multilayer perceptron;algorithm	ML	17.963671981717326	-28.940758996885798	103914
b3619dca1e4e1b7c2af86a61ce615fbee7d53e83	intelligent initialization of resource allocating rbf networks	reseau fonction base radiale;unsupervised clustering;north america;america del norte;amerique du nord;amerique;classification non supervisee;resource allocation;complex network;wisconsin;inicializacion;resource allocating networks;etats unis;ionosphere;estados unidos;radial basis function networks;multi dimensional;clasificacion no supervisada;unsupervised classification;asignacion recurso;network structure;allocation ressource;america;regroupement;rbf network;initialization;ionosfera;initialisation;compact model;neural network	In any neural network system, proper parameter initialization reduces training time and effort, and generally leads to compact modeling of the process under examination, i.e. less complex network structures and better generalization. However, in cases of multi-dimensional data, parameter initialization is both difficult and time consuming. In the proposed scheme a novel, multi-dimensional, unsupervised clustering method is used to properly initialize neural network architectures, focusing on resource allocating networks (RAN); both the hidden and output layer parameters are determined by the output of the clustering process, without the need for any user interference. The main contribution of this work is that the proposed approach leads to network structures that are compact, efficient and achieve best classification results, without the need for manual selection of suitable initial network parameters. The efficiency of the proposed method has been tested on several classes of publicly available data, such as iris, Wisconsin and ionosphere data.	architecture as topic;artificial neural network;best practice;biological neural networks;class;cluster analysis;complex network;ehrlich units per deciliter;emoticon;generalization (psychology);interference (communication);multimedia;numerous;population parameter;radial basis function network;ranitidine;resource allocation;soft computing;user (computing);algorithm;basic research;statistical cluster	Manolis Wallace;Nicolas Tsapatsoulis;Stefanos D. Kollias	2005	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2004.11.005	initialization;resource allocation;computer science;artificial intelligence;machine learning;ionosphere;operations research;artificial neural network;complex network	ML	10.834724599556719	-32.47678785003521	103959
84269d12e2fbb785e0bc63f739d4893fe95a0d43	analysis of distributed representation of constituent structure in connectionist systems	distributed representation	A general method, the tensor product representation, is described for the distributed representation of value/variable bindings. The method allows the fully distributed representation of symbolic structures: the roles in the structures, as well as the fillers for those roles, can be arbitrarily non-local. Fully and partially localized special cases reduce to existing cases of connectionist representations of structured data; the tensor product representation generalizes these and the few existing examples of fuUy distributed representations of structures. The representation saturates gracefully as larger structures are represented; it penn its recursive construction of complex representations from simpler ones; it respects the independence of the capacities to generate and maintain multiple bindings in parallel; it extends naturally to continuous structures and continuous representational patterns; it pennits values to also serve as variables; it enables analysis of the interference of symbolic structures stored in associative memories; and it leads to characterization of optimal distributed representations of roles and a recirculation algorithm for learning them.	algorithm;artificial neural network;connectionism;interference (communication);recursion	Paul Smolensky	1987			discrete mathematics;computer science;theoretical computer science;machine learning;mathematics;algorithm	ML	18.089775012858397	-29.82442527667403	104024
9b98b464233efe8a0a9ce2ecd9b96bc6f6ac04ad	image classification using a module rbf neural network	modular rbf neural network;self organising feature maps image classification image texture learning artificial intelligence multimedia computing pattern clustering radial basis function networks;radial basis function based methods;pattern clustering;self organizing map neural network;texture feature extraction;rbf clustering;image classification;image classification neural networks image texture analysis discrete wavelet transforms image analysis wavelet analysis statistical analysis feature extraction prototypes image generation;multimedia processing;image texture;mrbf neural network;multimedia computing;radial basis function networks;radial basis function;self organising feature maps;rbf neural network;tree structure;multimedia processing image classification modular rbf neural network radial basis function based methods rbf clustering self organizing map neural network som neural network mrbf neural network texture feature extraction;self organized map;learning artificial intelligence;rbf network;som neural network;neural network	Image classification is an interesting topic in multimedia processing. Recently, there were many researchers proposed radial basis function-based (RBF) methods to deal with image classification. However, the traditional RBF neural networks were sensitive to center initialization. To obtain appropriate centers, it needs to find the significant features for further RBF clustering. In addition, the training procedure of the traditional RBF is time-consuming. In order to cope with these problems, a self-organizing map (SOM) neural network is proposed to select more appropriate centers for RBF network, and a modular RBF (MRBF) neural network is proposed to improve the classification rate and speed up the training time. The experimental results show that the proposed MRBF network has better performance than DWT-based method, traditional RBF neural network and the tree structured wavelet (TWS) in image classification. The experimental results also show that the training time of proposed MRBF neural network is much faster than the traditional RBF neural network	artificial neural network;cluster analysis;computer vision;discrete wavelet transform;ibm tivoli workload scheduler;organizing (structure);radial (radio);radial basis function network;self-organization;self-organizing map;speedup	Chuan-Yu Chang;Shih-Yu Fu	2006	First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC'06)	10.1109/ICICIC.2006.295	image texture;contextual image classification;radial basis function;probabilistic neural network;hierarchical rbf;computer science;artificial intelligence;machine learning;pattern recognition;tree structure;artificial neural network	ML	12.745995227968574	-36.10445383424858	104050
a75bbedbc0d13360712960aad2ca2d129a86d882	support vector machines for computing action mappings in learning classifier systems	inf;support vector machines learning artificial intelligence;support vector machines;learning classifier system;optimal performance support vector machines computing action mappings learning classifier systems parameterized function binary functions;support vector machine;learning artificial intelligence;support vector machines support vector machine classification machine learning supervised learning computer networks genetic algorithms laboratories quadratic programming kernel testing	XCS with computed action, briefly XCSCA, is a recent extension of XCS to tackle problems involving a large number of discrete actions. In XCSCA the classifier action is computed with a parameterized function learned in a supervised fashion. In this paper, we introduce XCSCAsvm that extends XCSCA using support vector machines to compute classifier action. We compared XCSCAsvm and XCSCA on the learning of several binary functions. The experimental results show that XCSCAsvm reaches the optimal performance faster than XCSCA.	action (physics);artificial neural network;bitwise operation;computational complexity theory;ieee congress on evolutionary computation;overhead (computing);perceptron;quadratic programming;shallow parsing;supervised learning;support vector machine;whole earth 'lectronic link	Daniele Loiacono;Andrea Marelli;Pier Luca Lanzi	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424737	semi-supervised learning;margin classifier;support vector machine;least squares support vector machine;kernel method;learning vector quantization;quadratic classifier;computer science;artificial intelligence;perceptron;online machine learning;machine learning;linear classifier;pattern recognition;learning classifier system;relevance vector machine;computational learning theory;active learning;structured support vector machine	Vision	14.906729489488901	-31.12536372283229	104085
f4d385a003c58490f9e838212f2b7edbb51cb626	ortho-system of kernels in rbf neural networks			artificial neural network;neural network software;radial basis function	Pawel Strumillo;Wladyslaw Kaminski	1998			probabilistic neural network;artificial intelligence;machine learning;mathematics;artificial neural network;time delay neural network	Robotics	12.79655284160387	-27.198532063305805	104266
685218d44881f5b1a41cfe172fdbe52c3ae9e170	growing cell structures--a self-organizing network for unsupervised and supervised learning	unsupervised learning;modelizacion;visualizacion;learning;supervised learning;feature map;two spiral problem;performance;classification;aprendizaje;modelisation;visualization;apprentissage;radial basis function;incremental learning;visualisation;clustering;data visualization;pattern classification;self organization;vector quantizer;rendimiento;neural network model;reseau neuronal;modeling;clasificacion;red neuronal;neural network	Alrstract-We present a new self-organizing neural network model that has two variants. The first variant performs unsupervised learning and can be used for data visualization, clustering, and vector quantization. The main advantage over existing approaches ( e.g., the Kohonen feature map) is the ability o f the model to automatically find a suitable network structure and size. This is achieved through a controlled growth process that also includes occasional removal o f units. The second variant of the model is a supervised learning method that results from the combination of the above-mentioned self-organizing network with the radial basis function (RBF) approach. In this model it is possible--in contrast to earlier approaches--to perform the positioning of the RBF units and the supervised training of the weights in parallel. Therefore, the current classification error can be used to determine where to insert new RBF units. This leads to small networks that generalize very well. Results on the two-spirals benchmark and a vowel classification problem are presented that are better than any results previously published.	artificial neural network;benchmark (computing);cluster analysis;data visualization;feature model;graphics processing unit;network model;organizing (structure);radial (radio);radial basis function;self-organization;self-organizing map;statistical classification;supervised learning;unsupervised learning;vector quantization	Bernd Fritzke	1994	Neural Networks	10.1016/0893-6080(94)90091-4	unsupervised learning;visualization;learning vector quantization;computer science;artificial intelligence;machine learning;pattern recognition;artificial neural network	ML	11.739436107246167	-31.465742326894233	104285
17d218b9a579247acfdc31e7eb5de0afd70b2538	infgmn - incremental neuro-fuzzy gaussian mixture network		A NFS that learns incrementally using a single scan over the training data.The learning process can proceed in perpetuity as new training data become available.A MamdaniLarsen fuzzy rule base is defined automatically and incrementally.Attempts to provide the best trade-off between accuracy and interpretability.Is unaffected by catastrophic interference (Stability-Plasticity dilemma). Accuracy and interpretability are contradictory objectives that conflict in all machine learning techniques and achieving a satisfactory balance between these two criteria is a major challenge. The objective is not only to maximize interpretability, but also to guarantee a high degree of accuracy. This challenge is even greater when it is considered that the model will have to evolve and adapt itself to the dynamics of the underlying environment, i.e. it will have to learn incrementally. Little research has been published about incremental learning using MamdaniLarsen (ML) fuzzy models under these conditions. This article presents a novel proposal for a Neuro-Fuzzy System (NFS) with an incremental learning capability, the Incremental Neuro-Fuzzy Gaussian Mixture Network (INFGMN), that attempts to generate incremental models that are highly interpretable and precise. The principal characteristics of the INFGMN are as follows: (i) the INFGMN learns incrementally using a single sweep of the training data (each training pattern can be immediately used and discarded); (ii) it is capable of producing reasonable estimates based on few training data; (iii) the learning process can proceed in perpetuity as new training data become available (learning and recalling phases are not separate); (iv) the INFGMN can deal with the Stability-Plasticity dilemma and is unaffected by catastrophic interference (rules are added or removed whenever necessary); (v) the fuzzy rule base is defined automatically and incrementally (new rules are added whenever necessary); and (vi) the INFGMN maintains an ML-type fuzzy rule base that attempts to provide the best trade-off between accuracy and interpretability, thereby dealing with the Accuracy-Interpretability dilemma. The INFGMNs performance in terms of learning and modelling is assessed using a variety of benchmark applications and the results are promising.	neuro-fuzzy	Tiago Mazzutti;Mauro Roisenberg;Paulo José de Freitas Filho	2017	Expert Syst. Appl.	10.1016/j.eswa.2017.07.032	fuzzy logic;artificial intelligence;machine learning;neuro-fuzzy;dilemma;data mining;perpetuity;fuzzy rule;gaussian;interpretability;computer science;catastrophic interference	Theory	13.893902148765088	-35.12417080056062	104479
d0e2c41df4960399b06c5fc5d4a0c08e637daabb	experiments with adaptive transfer rate in reinforcement learning	reinforcement learning;optimization problem;transfer learning	"""Transfer algorithms allow the use of knowledge previously learned on related tasks to speed-up learning of the current task. Recently, many complex reinforcement learning problems have been successfully solved by efficient transfer learners. However, most of these algorithms suffer from a severe flaw: they are implicitly tuned to transfer knowledge between tasks having a given degree of similarity. In other words, if the previous task is very dissimilar (resp. nearly identical) to the current task, then the transfer process might slow down the learning (resp. might be far from optimal speed-up). In this paper, we address this specific issue by explicitly optimizing the transfer rate between tasks and answer to the question : """"can the transfer rate be accurately optimized, and at what cost ?"""". We show that this optimization problem is related to the continuum bandit problem. We then propose a generic adaptive transfer method (AdaTran), which allows to extend several existing transfer learning algorithms to optimize the transfer rate. Finally, we run several experiments validating our approach."""	reinforcement learning	Yann Chevaleyre;Aydano Machado;Jean-Daniel Zucker	2008		10.1007/978-3-642-01715-5_1	optimization problem;multi-task learning;error-driven learning;simulation;transfer of learning;computer science;artificial intelligence;machine learning;inductive transfer;reinforcement learning	ML	17.340073009899754	-32.102604055151794	104531
446779f9a56e368563668e907336d35d001b7461	integrated use of ica and ann to recognize the mixture control chart patterns in a process	control chart pattern;statistical process control;independent component analysis;artificial neural network	The quality of a product is important to the success of an enterprise. In process designs, statistical process control (SPC) charts provide a comprehensive and systematic approach to ensure that products meet or exceed customer expectations. The primary function of SPC charts is to identify the assignable causes when the process is out-of-control. The unusual control chart patterns (CCPs) are typically associated with specific assignable causes which affect the operation of a process. Consequently, the effective recognition of CCPs has become a very promising research area. Many studies have assumed that the observed process outputs which need to be recognized are basic or single types of abnormal patterns. However, in most practical applications, the observed process outputs could exhibit mixed patterns which combine two basic types of abnormal patterns in the process. This seriously raises the degree of difficulty in recognizing the basic types of abnormal patterns from a mixture of CCPs. In contrast to typical approaches which applied individually artificial neural network (ANN) or support vector machine (SVM) for the recognition tasks, this study proposes a two-step integrated approach to solve the recognition problem. The proposed approach includes the integration of independent component analysis (ICA) and ANN. The proposed ICA-ANN scheme initially applies ICA to the mixture patterns for generating independent components (ICs). The ICs then serve as the input variables of the ANN model to recognize the CCPs. In this study, different operating modes of the combination of CCPs are investigated and the results prove that the proposed approach could achieve superior recognition capability.	independent computing architecture	Yuehjen E. Shao;Yini Lin;Ya-Chi Chan	2011		10.1007/978-3-642-23184-1_17	independent component analysis;computer science;artificial intelligence;machine learning;data mining;artificial neural network;statistical process control;statistics	HCI	10.416992076378548	-36.712382285007116	104578
b0b1202b54eaa0f2885b4bb2792d622a39e2e1a4	invited talk: counting rankings		In this talk, I present a recursive algorithm to calculate the number of rankings that are consistent with a set of data (optimal candidates) in the framework of Optimality Theory (OT; Prince and Smolensky 1993).1 Computing this quantity, which I call r-volume, makes possible a simple and effective Bayesian heuristic in learning – all else equal, choose candidates that are preferred by the highest number of rankings consistent with previous observations. This heuristic yields an r-volume learning algorithm (RVL) that is guaranteed to make fewer than k lg k errors while learning rankings of k constraints. This log-linear error bound is an improvement over the quadratic bound of Recursive Constraint Demotion (RCD; Tesar and Smolensky 1996) and it is within a logarithmic factor of the best possible mistake bound for any OT learning algorithm. Computing r-volume: The violations in an OT tableau can be given as a [n × k] array of integers in which the first row t1 corresponds to the winner. Following Prince (2002), the ranking information can be extracted by comparing t1 with each ‘losing’ row t2, ..., tn to create an Elementary Ranking Condition as follows: erc(t1, ti) = 〈α1, ..., αk〉 where αj = L if t1,j < ti,j , αj = W if t1,j > ti,j , and αj = e otherwise. The meaning of α is that at least one constraint associated with W dominates all those associated with L. input C1 C2 C3 candidate t1 * ** winner candidate t2 ** * erc(t1, t2) = 〈W, L, e 〉 i.e. t1 beats t2 if C1 outranks C2 candidate t3 ** erc(t1, t3) = 〈L, L, W〉 i.e. t1 beats t3 if C3 outranks C1 and C2 candidate t4 *** * erc(t1, t4) = 〈L, W, W〉 i.e. t1 beats t4 if C2 or C3 outranks C1 For a set E of length-k ERCs, E−wi denotes a set E′ derived from E by removing ERCs with W in column i and removing column i. r-vol ( Ek ) = ∑ 1≤i≤k ⎧⎨ ⎩ 0 if xi = L for any x ∈ E (k − 1)! if xi = W for all x ∈ E r (E − wi) otherwise Mistake bounds: To make predictions, RVL selects in each tableau the candidate that yields the highest r-volume when the ERCs that allow it to win are combined with E (the ERCs for past winners). To establish a mistake bound, assume that the RVL chooses candidate e when, in fact, candidate o was optimal according to the target ranking RT . Assuming e = o, the rankings that make o optimal must be half or fewer of the rankings consistent with E or else RVL would have chosen o. Because all rankings that make candidates other than o optimal will be eliminated once the ERCs for o are added to E, each error reduces the number of rankings consistent with all observed data by at least half and thus there can be no more than lg k! errors. Applications: The r-volume seems to encode ‘restrictiveness’ in a way similar to Tesar and Prince’s (1999) r-measure. As a factor in learning, it predicts typological frequency (cf. Bane and Riggle 2008) and priors other than the ‘flat’ distribution over rankings can easily be included to test models of ranking bias. More generally, this research suggests the concept of g-volume for any parameterized model of grammar. Full bibliography available on the Rutgers Optimality Archive (roa.rutgers.edu) with the paper Counting Rankings.	algorithm;archive;encode;heuristic;list of minor characters in the matrix series;log-linear model;long division;method of analytic tableaux;prince;recursion (computer science);turing test;via c3;winnow (algorithm)	Jason Riggle	2008			artificial intelligence;combinatorics;machine learning;optimality theory;computer science;prior probability;logarithm;parameterized complexity;recursion;ranking;heuristic;integer	AI	24.359850626058257	-26.59971097985323	104979
88acce81ac5d09b3f11b650d0309796c95934f2f	on the universality of the logistic loss function		A loss function measures the discrepancy between the true values (observations) and their estimated fits, for a given instance of data. A loss function is said to be proper (unbiased, Fisher consistent) if the fits are defined over a unit simplex, and the minimizer of the expected loss is the true underlying probability of the data. Typical examples are the zero-one loss, the quadratic loss and the Bernoulli log-likelihood loss (log-loss). In this work we show that for binary classification problems, the divergence associated with smooth, proper and convex loss functions is bounded from above by the Kullback-Leibler (KL) divergence, up to a multiplicative normalization constant. It implies that by minimizing the log-loss (associated with the KL divergence), we minimize an upper bound to any choice of loss functions from this set. This property justifies the broad use of log-loss in regression, decision trees, deep neural networks and many other applications. In addition, we show that the KL divergence bounds from above any separable Bregman divergence that is convex in its second argument (up to a multiplicative normalization constant). This result introduces a new set of divergence inequalities, similar to the well-known Pinsker inequality.	artificial neural network;bernoulli polynomials;binary classification;bregman divergence;decision tree;deep learning;discrepancy function;fits;kl-one;kullback–leibler divergence;loss function;pinsker's inequality;social inequality;universality probability;whole earth 'lectronic link	Amichai Painsky;Gregory W. Wornell	2018	2018 IEEE International Symposium on Information Theory (ISIT)	10.1109/ISIT.2018.8437786	mathematical optimization;kullback–leibler divergence;divergence;multiplicative function;normalizing constant;mathematics;bounded function;expected loss;bregman divergence;upper and lower bounds	ML	21.512269048070365	-32.480455654850466	105035
de45b19db07a70e51f5bb99764f109c68e6f4f06	short-term traffic flow forecasting using expanded bayesian network for incomplete data	bayesian network;traffic flow;incomplete data;gaussian mixture model;principal component analysis;probability distribution;em algorithm	  In this paper expanded Bayesian network method for short-term traffic flow forecasting in case of incomplete data is proposed.  Expanded Bayesian network model is constructed to describe the causal relationship among traffic flows, and then the joint  probability distribution between the cause and effect nodes with dimension reduced by Principal Component Analysis (PCA) is  approximated through Gaussian Mixture Model (GMM). The parameters of the GMM are learned through Competitive EM algorithm.  Experiments show that the expanded Bayesian network method is appropriate and effective for short-term traffic flow forecasting  with incomplete data.    	bayesian network	Changshui Zhang;Shiliang Sun;Guoqiang Yu	2004		10.1007/978-3-540-28648-6_151	probability distribution;econometrics;variable-order bayesian network;expectation–maximization algorithm;computer science;machine learning;traffic flow;pattern recognition;bayesian network;mixture model;statistics;principal component analysis	AI	22.40601479934596	-24.913623290836295	105056
1d42b728bbf2eacd7e7148a4998b9b4b15d734d8	large-scale pattern storage and retrieval using generalized brain-state-in-a-box neural networks	busqueda informacion;autoasociacion;hypercube;image storage;brain;haute performance;algorithms brain computer simulation humans image interpretation computer assisted information storage and retrieval memory neural networks computer pattern recognition automated pattern recognition visual;memoire associative;storage system;network synthesis;pattern sequence retrieval;systeme nerveux central;neural networks;associative memory large scale pattern storage large scale pattern retrieval generalized brain state in a box neural network pattern sequence storage pattern sequence retrieval large scale image storage large scale image retrieval gbsb based hybrid neural network pattern decomposition deadbeat stability stability property hypercube;neural nets;recherche image;hybrid network;information retrieval;storage management;image storage and retrieval;pattern sequence storage;distributed computing;hombre;alimentacion maquina;encefalo;stockage image;large scale pattern retrieval;large scale image retrieval;self association;stability;generalized brain state in a box neural network;sistema nervioso central;large scale;cerebro;neural system;pattern sequence storage and retrieval associative memory brain state in a box bsb image storage and retrieval neural networks pattern decomposition;encephale;large scale pattern storage;large scale systems biological neural networks associative memory image storage image retrieval stability hypercubes pattern recognition network synthesis neural networks;gbsb based hybrid neural network;amenage piece;recherche information;cerveau;systeme memoire;brain state in a box bsb;machine feed;human;autoassociation;pattern recognition;alimentation machine;alto rendimiento;deadbeat stability;associative memory;hypercubes;calculo repartido;memoria asociativa;large scale image storage;pattern sequence storage and retrieval;alimentacion pieza;encephalon;pattern decomposition;reseau neuronal;content addressable storage;sistema memoria;high performance	In this paper, a generalized Brain-State-in-a-Box (gBSB)-based hybrid neural network is proposed for storing and retrieving pattern sequences. The hybrid network consists of autoassociative and heteroassociative parts. Then, a large-scale image storage and retrieval neural system is constructed using the gBSB-based hybrid neural network and the pattern decomposition concept. The notion of the deadbeat stability is employed to describe the stability property of the vertices of the hypercube to which the trajectories of the gBSB neural system are constrained. Extensive simulations of large scale pattern and image storing and retrieval are presented to illustrate the results obtained.	algorithm;biological neural networks;computation (action);content-addressable memory;hybrid neural network;hybrids;iteration;iterative reconstruction;neural network simulation;noise (electronics);randomness;refinement (computing);small	Cheolhwan Oh;Stanislaw H. Zak	2010	IEEE Transactions on Neural Networks	10.1109/TNN.2010.2040291	computer science;artificial intelligence;theoretical computer science;machine learning;artificial neural network;hypercube	Vision	13.176652585251658	-30.241064578606657	105074
40f9f318dc49edce330d716344a1cc8d1edaf860	on learnability, complexity and stability		We consider the fundamental question of learnability of a hy potheses class in the supervised learning setting and in the general learning setting introduced by Vladimir Vapnik. We survey classic results characterizing learnability in term of suitable notions of complexity, as well as more recent resul ts that establish the connection between learnability and stability of a learnin g algorithm.	algorithm;learnability;supervised learning	Silvia Villa;Lorenzo Rosasco;Tomaso A. Poggio	2013		10.1007/978-3-642-41136-6_7	machine learning;mathematics;algorithm	ML	20.20548322423	-32.150718149168746	105139
2781ca82cb885bd8eda1dae6e14b6e468051af96	self-annealing and self-annihilation: unifying deterministic annealing and relaxation labeling	self amplification;softassign;deterministic annealing;linear assignment problem;dynamic system;self annihilation;energy function;softmax;symmetry breaking;relaxation labeling;winner take all;self annealing	Deterministic annealing and relaxation labeling algorithms for classification and matching are presented and discussed. A new approach—self annealing—is introduced to bring deterministic annealing and relaxation labeling into accord. Self annealing results in an emergent linear schedule for winner-take-all and linear assignment problems. Self annihilation, a generalization of self annealing is capable of performing the useful function of symmetry breaking. The original relaxation labeling algorithm is then shown to arise from an approximation to either the self annealing energy function or the corresponding dynamical system. With this relationship in place, self annihilation can be introduced into the relaxation labeling framework. Experimental results on synthetic matching and labeling problems clearly demonstrate the three-way relationship between deterministic annealing, relaxation labeling and self annealing.	algorithm;approximation;dynamical system;emergence;lagrangian relaxation;linear programming relaxation;mathematical optimization;quantum field theory;sequence labeling;simulated annealing;symmetry breaking;synthetic intelligence	Anand Rangarajan	2000	Pattern Recognition	10.1016/S0031-3203(99)00077-1	winner-take-all;mathematical optimization;symmetry breaking;combinatorics;computer science;dynamical system;machine learning;mathematics;assignment problem;softmax function	Vision	20.520664452238353	-26.30963280413276	105555
8ace27eb785d64ab19046cd8f4d7eb07f4426d2e	grammatical inference algorithms in matlab	machine learning;grammatical inference	Although MATLAB has become one of the mainstream languages for the machine learning community, there is still skepticism among the Grammatical Inference (GI) community regarding the suitability of MATLAB for implementing and running GI algorithms. In this paper we will present implementation results of several GI algorithms, e.g., RPNI (Regular Positive and Negative Inference), EDSM (Evidence Driven State Merging), and k-testable machine. We show experimentally based on our MATLAB implementation that state merging algorithms can successfully be implemented and manipulated using MATLAB in the similar fashion as other machine learning tools. Moreover, we also show that MATLAB provides a range of toolboxes that can be leveraged to gain parallelism, speedup etc.	algorithm;experiment;grammar induction;matlab;machine learning;parallel computing;speedup	Hasan Ibne Akram;Colin de la Higuera;Huang Xiao;Claudia Eckert	2010		10.1007/978-3-642-15488-1_22	grammar induction;computer science;artificial intelligence;theoretical computer science;machine learning;programming language;algorithm	ML	13.490250790088703	-34.283896562018555	105583
c605507f8b28e4e2e449b961f5a18ac582db6f2a	learning in the recurrent random neural network	gradient descent method;learning algorithm;connectionism;learning;conexionismo;random networks;backpropagation;random neural network;recurrence;input output;algorithme;aprendizaje;algorithm;connexionnisme;retropropagation;apprentissage;gradient descent;recurrencia;learning from examples;nonlinear equation;neural network model;reseau neuronal;neuronal network;quadratic error function;retropropagacion;red neuronal;neural network;algoritmo	"""The capacity to learn from examples is one of the most desirable features of neural network models. We present a learning algorithm for the recurrent random network model (Gelenbe 1989, 1990) using gradient descent of a quadratic error function. The analytical properties of the model lead to a """"backpropagation"""" type algorithm that requires the solution of a system of n linear and n nonlinear equations each time the n-neuron network """"learns"""" a new input-output pair."""	algorithm;backpropagation;erdős–rényi model;gradient descent;network model;neuron;nonlinear system;random graph;random neural network	Erol Gelenbe	1992	Neural Computation	10.1162/neco.1993.5.1.154	gradient descent;feedforward neural network;random neural network;computer science;artificial intelligence;recurrent neural network;machine learning;time delay neural network;artificial neural network;algorithm	ML	17.938272332440242	-27.820604135771212	105596
6a61cf2cbde8805039efe02e2dfb6b81c574e663	learning to predict non-deterministically generated strings	learning in the limit;kolmogorov complexity;minimum description length;prediction	In this article we present an algorithm that learns to predict non-deterministically generated strings. The problem of learning to predict non-deterministically generated strings was raised by Dietterich and Michalski (1986). While their objective was to give heuristic techniques that could be used to rapidly and effectively learn to predict a somewhat limited class of strings, our objective is to give an algorithm which, though impractical, is capable of learning to predict a very general class. Our algorithm is meant to provide a general framework within which heuristic techniques can be effectively employed.	brute-force search;computation;deterministic algorithm;heuristic;language identification in the limit;multiple-instance learning;nondeterministic algorithm;occam's razor;ray solomonoff	Moshe Koppel	1991	Machine Learning	10.1023/A:1022671126433	minimum description length;prediction;artificial intelligence;machine learning;mathematics;algorithm;statistics	ML	22.317962017532718	-30.35150669939241	105637
43bde6e423d438f86f0c65eef106188a60417ea3	clam: a new model of associative memory	associative memory	We present a new associative memory model that stores arbitrary bipolar patterns without the problems we can find in other models like BAM or LAM. After identifying those problems we show the new memory topology and we explain its learning and recall stages. Mathematical demonstrations are provided to prove that the new memory model guarantees the perfect retrieval of every stored pattern and also to prove that whatever the input of the memory is, it operates as a nearest neighbor classifier. Q 2000 John Wiley & Sons, Inc.	content-addressable memory;cycle (graph theory);john d. wiley;machine learning;nearest neighbour algorithm	Antonio B. Bailón;Miguel Delgado;Waldo Fajardo Contreras	2000	Int. J. Intell. Syst.	10.1002/(SICI)1098-111X(200006)15:6%3C549::AID-INT5%3E3.0.CO;2-U	computer science;content-addressable memory	ML	13.214782210535018	-29.927654210768935	105655
a33fb26964cba93005b32e2c6a62912e5dc73509	efficient agnostic pac-learning with simple hypothesis	empirical study;approximate algorithm;pac learning;efficient algorithm;machine learning;point of view	We exhibit efficient algorithms for agnostic PAC-learning with rectangles, unions of two rectangles, and unions of k intervals as hypotheses. These hypothesis classes are of some interest from the point of view of applied machine learning, because empirical studies show that hypotheses of this simple type (in just one or two of the attributes) provide good prediction rules for various real-world classification problems. In addition, optimal hypotheses of this type may provide valuable heuristic insight into the structure of a real world classification problem. The algorithms that are introduced in this paper make it feasible to compute optimal hypotheses of this type for a training set of several hundred examples. We also exhibit an approximation algorithm that can compute nearly optimal hypotheses for much larger datasets.	approximation algorithm;heuristic;machine learning;probably approximately correct learning;test set	Wolfgang Maass	1994		10.1145/180139.181016	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;empirical research;probably approximately correct learning;algorithm;statistics	ML	20.091430049722916	-32.26808893640586	105876
01a27d77257c47a24daaa969f258ea844b9cbff8	balancing exploration and exploitation: a new algorithm for active machine learning	machine learning algorithms machine learning humans sampling methods labeling region 4 feedback computer science application software text categorization;decision boundary active machine learning unlabeled examples;active learning;machine learning;learning artificial intelligence	Active machine learning algorithms are used when large numbers of unlabeled examples are available and getting labels for them is costly (e.g. requiring consulting a human expert). Many conventional active learning algorithms focus on refining the decision boundary, at the expense of exploring new regions that the current hypothesis misclassifies. We propose a new active learning algorithm that balances such exploration with refining of the decision boundary by dynamically adjusting the probability to explore at each step. Our experimental results demonstrate improved performance on data sets that require extensive exploration while remaining competitive on data sets that do not. Our algorithm also shows significant tolerance of noise.	active learning (machine learning);algorithm;decision boundary;experiment;like button;machine learning;synthetic intelligence	Thomas Takeo Osugi;Kun Deng;Stephen D. Scott	2005	Fifth IEEE International Conference on Data Mining (ICDM'05)	10.1109/ICDM.2005.33	semi-supervised learning;unsupervised learning;robot learning;proactive learning;multi-task learning;instance-based learning;error-driven learning;algorithmic learning theory;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;data mining;inductive transfer;active learning;ensemble learning;learning classifier system;stability;competitive learning;computational learning theory;active learning;hyper-heuristic;generalization error	ML	14.903540205374885	-35.821500984098314	105965
50aa8a62adead4712e81460c2a3ed2863898054e	efficient computation of entropy gradient for semi-supervised conditional random fields	additional term;successful method;semi-supervised conditional random field;present efficient generalization;label entropy;active learning;entropy gradient;published method;supervised crf training;entropy regularization;semi-supervised learning;efficient computation;dynamics;random variables;objective function;semi supervised learning;conditional random field;efficiency;entropy;gradients;time complexity;computations	Entropy regularization is a straightforward and successful method of semi-supervised learning that augments the traditional conditional likelihood objective function with an additional term that aims to minimize the predicted label entropy on unlabeled data. It has previously been demonstrated to provide positive results in linear-chain CRFs, but the published method for calculating the entropy gradient requires significantly more computation than supervised CRF training. This paper presents a new derivation and dynamic program for calculating the entropy gradient that is significantly more efficient—having the same asymptotic time complexity as supervised CRF training. We also present efficient generalizations of this method for calculating the label entropy of all sub-sequences, which is useful for active learning, among other applications.	asymptotic computational complexity;computation;conditional random field;entropy (information theory);forward–backward algorithm;gradient;ibm notes;loss function;matrix regularization;optimization problem;semi-supervised learning;semiconductor industry;supervised learning;time complexity	Gideon S. Mann;Andrew McCallum	2007			semi-supervised learning;time complexity;random variable;entropy;dynamics;binary entropy function;transfer entropy;computer science;principle of maximum entropy;theoretical computer science;machine learning;computation;pattern recognition;efficiency;active learning;differential entropy;cross entropy;gradient;maximum entropy spectral estimation;conditional random field;conditional entropy;statistics	ML	23.92577609282169	-33.428165113369914	106297
f069e1bee8d3fefee98128a3dc39742a4be57978	adaptation and learning of a fuzzy system by nearest neighbor clustering	cluster algorithm;multiple models;dr scheme;cluster;control difusa;learning;amas;fuzzy control;adaptation and learning;fuzzy learning;systeme adaptatif;apprentissage flou;multiple model approach;modele multiple;algorithme;aprendizaje;algorithm;adaptive algorithm;vecino mas cercano;apprentissage;algorithme cluster;data reinitialization scheme;nearest neighbor;adaptive system;smooth transition;clustering algorithms;multiple model;sistema adaptativo;plus proche voisin;simulation study;nearest neighbour;sistema difuso;hill climbing;monton;systeme flou;real time application;fuzzy system;commande floue;algoritmo	Conventional hill-climbing type adaptive algorithms su1er from large transient error in abrupt changing environments. In this paper, we suggest a novel idea to address this problem. A data re-initialization (DR) scheme is proposed using multiple models approach with special initialization technique to smooth transition between di1erent environments. The design is based on adaptive fuzzy nearest neighbor clustering algorithm with on-line enhancements. The fast adaptation is realized by the data re-initialization and switching between di1erent models; learning is realized by recording and retrieving the trained up models. The algorithm is conceptually simple and feasible for real-time applications. The performance of the algorithm is tested with simulation studies. c © 2002 Elsevier Science B.V. All rights reserved.	algorithm;cluster analysis;fuzzy control system;hill climbing;online and offline;real-time clock;real-time computing;simulation;single-linkage clustering	P. T. Chan;Ahmad B. Rad	2002	Fuzzy Sets and Systems	10.1016/S0165-0114(01)00057-4	nearest-neighbor chain algorithm;computer science;artificial intelligence;hill climbing;machine learning;mathematics;cluster analysis;k-nearest neighbors algorithm;algorithm;fuzzy control system;cluster	AI	10.999408673482	-29.81003715731974	106395
c6158360e08b0eebf0d0769cf1effd8fcb6ce9e9	on training rbf neural networks using input-output fuzzy clustering and particle swarm optimization	radial basis function neural networks;particle swarm optimization;input output fuzzy clustering;fitness function	This paper elaborates on the use of particle swarm optimization in training Gaussian type radial basis function neural networks under the umbrella of input–output fuzzy clustering. The problem being investigated concerns the selection of basis function centers that contribute most in network’s performance, given that the clustering process in the input space is guided by the clustering in the output space. To accomplish this task, we quantify the effect of the input space fuzzy partition upon network’s square error in terms of an objective function that describes the ability of the partition to accurately reconstruct the input training samples. We, then, theoretically prove that the minimization of the above function acts to minimize an upper bound of the network’s square error. Therefore, the resulting solution corresponds to a minimal square error, while at the same time it maintains the structure of the input data. Due to the peculiarity of the aforementioned objective function, we treat it as the fitness function used by the particle swarm optimizer. The proposed methodology encompasses three design steps. The first step implements an independent fuzzy clustering in the output space to obtain a set of cluster centers. In the second step, unlike other approaches, the above centers are directly involved in the estimation of the membership degrees in the input–output space. In the third step, these membership degrees are used by the particle swarm optimizer in order to obtain optimal values for the centers. To summarize, the novelty of our contribution lies in: (a) the way we handle the information flow from output to input space, and (b) the way we handle the effect of the input space partition upon network’s performance. The experiments indicate that the fitness function decreases as the number of hidden node increases. Finally, a comparison between the proposed method and other sophisticated approaches shows its statistically significant superiority. © 2012 Elsevier B.V. All rights reserved.	artificial neural network;cluster analysis;emoticon;experiment;fitness function;fuzzy clustering;loss function;mathematical optimization;optimization problem;particle swarm optimization;radial (radio);radial basis function	George E. Tsekouras;John Tsimikas	2013	Fuzzy Sets and Systems	10.1016/j.fss.2012.10.004	mathematical optimization;fuzzy clustering;computer science;artificial intelligence;machine learning;mathematics;particle swarm optimization;fitness function	AI	15.218913962148108	-33.76801316288705	106516
8dce0739b25f9b98d1cdc28ac944ec94e0d152ca	online kernel selection with multiple bandit feedbacks in random feature space		Online kernel selection is critical to online kernel learning, and must address the exploration-exploitation dilemma, where we explore new kernels to find the best one and exploit the kernel that showed the best performance in the past. In this paper, we propose a novel multi-armed bandit solution to the exploration-exploitation dilemma in online kernel selection. We first correspond each candidate kernel to an arm of a multi-armed bandit problem. Different from typical multi-armed bandit models where only one kernel is selected at each round, we sample multiple kernels with replacement according to a probability distribution. Then, we make prediction with the hypotheses learned in the random feature spaces specified by the selected kernels, and incur multiple losses referred to as multiple bandit feedbacks. Finally, we use all the feedbacks to update the probability distribution. We prove that the proposed approach enjoys a sub-linear expected regret bound. Experimental results on benchmark datasets show that the proposed approach has a comparable performance with existing online kernel selection methods.	feature vector;kernel (operating system)	Junfan Li;Shizhong Liao	2018		10.1007/978-3-319-99247-1_27	kernel (linear algebra);probability distribution;dilemma;machine learning;artificial intelligence;feature vector;exploit;computer science;regret	ML	24.105710637614585	-32.1671311668068	106625
21b029c22ee7fe1422ea771127e909d70569086f	hilbert space embeddings of predictive state representations		Predictive State Representations (PSRs) are an expressive class of models for controlled stochastic processes. PSRs represent state as a set of predictions of future observable events. Because PSRs are defined entirely in terms of observable data, statistically consistent estimates of PSR parameters can be learned efficiently by manipulating moments of observed training data. Most learning algorithms for PSRs have assumed that actions and observations are finite with low cardinality. In this paper, we generalize PSRs to infinite sets of observations and actions, using the recent concept of Hilbert space embeddings of distributions. The essence is to represent the state as one or more nonparametric conditional embedding operators in a Reproducing Kernel Hilbert Space (RKHS) and leverage recent work in kernel methods to estimate, predict, and update the representation. We show that these Hilbert space embeddings of PSRs are able to gracefully handle continuous actions and observations, and that our learned models outperform competing system identification algorithms on several prediction benchmarks.	algorithm;hilbert space;kernel method;machine learning;observable;stochastic process;system identification	Byron Boots;Geoffrey J. Gordon;Arthur Gretton	2013	CoRR		combinatorics;mathematical analysis;discrete mathematics;machine learning;mathematics;statistics	ML	24.564726791630697	-29.62984078283683	106673
bbe60b8e712080bc73363f6d47d9245fc59bba52	decentralized high-dimensional bayesian optimization with factor graphs		This paper presents a novel decentralized high-dimensional Bayesian optimization (DEC-HBO) algorithm that, in contrast to existing HBO algorithms, can exploit the interdependent effects of various input components on the output of the unknown objective function f for boosting the BO performance and still preserve scalability in the number of input dimensions without requiring prior knowledge or the existence of a low (effective) dimension of the input space. To realize this, we propose a sparse yet rich factor graph representation of f to be exploited for designing an acquisition function that can be similarly represented by a sparse factor graph and hence be efficiently optimized in a decentralized manner using distributed message passing. Despite richly characterizing the interdependent effects of the input components on the output of f with a factor graph, DEC-HBO can still guarantee no-regret performance asymptotically. Empirical evaluation on synthetic and real-world experiments (e.g., sparse Gaussian process model with 1811 hyperparameters) shows that DEC-HBO outperforms the state-of-the-art HBO algorithms.		Trong Nghia Hoang;Quang Minh Hoang;Ruofei Ouyang;Kian Hsiang Low	2018			bayesian optimization;scalability;boosting (machine learning);message passing;machine learning;artificial intelligence;factor graph;computer science;hyperparameter;gaussian process;exploit	AI	24.32845776497843	-31.720222741025836	106728
facdeb8e772d43204d7c6eacc30409df1bf76f24	training anfis using the enhanced bees algorithm and least squares estimation	anfis;hybrid learning;bees algorithm;fuzzy systems	This paper presents the result of research in developing a novel training model for Adaptive NeuroFuzzy Inference Systems (ANFIS). ANFIS integrates the learning ability of Artificial Neural Networks with the Takagi-Sugeno Fuzzy Inference System to approximate nonlinear functions. Therefore, it is considered as a Universal Estimator. The original algorithm used in ANFIS training process has a hybrid model that uses Steepest Decent Derivative; therefore, it inherits low convergence rate and local minima during training. In this study, a training algorithm is proposed that combines Bees Algorithm (BA) and Least Square Estimation (LSE) (BA-LSE). The local and global exploration of BA as integrates with the best-fit solution of the LSE improves current shortcomings of ANFIS training process. The proposed training algorithm is examined under three different scenarios of function approximation, time series prediction, and classification experiments in order to verify the promising improvements in the training process of ANFIS. The experimental results validate high generalization capabilities of the BA-LSE training algorithm in comparison to the original hybrid training model of ANFIS. The new training model also enhances local minima avoidance and has high convergence rate.	adaptive neuro fuzzy inference system;approximation algorithm;artificial neural network;bees algorithm;business architecture;curve fitting;experiment;least squares;maxima and minima;nonlinear system;rate of convergence;time series	Hosein Marzi;Ahmed Haj Darwish;Humam Helfawi	2017	Intelligent Automation & Soft Computing	10.1080/10798587.2016.1196880	mathematical optimization;adaptive neuro fuzzy inference system;computer science;artificial intelligence;machine learning;bees algorithm;fuzzy control system	AI	12.32134231767266	-24.568334022914165	106733
14c8277f1740898b3ea30d95664290b0cad43373	the complexity of learning halfspaces using generalized linear methods		Many popular learning algorithms (E.g. Kernel SVM, logistic regression, Lasso, and Fourier-Transform based algorithms) operate by reducing the problem to a convex optimization problem over a set of functions. These methods offer the currently best approach to several central problems such as learning halfspaces and learning DNF’s. In addition they are widely used in numerous application domains. Despite their importance, there are still very few proof techniques to show limits on the power of these algorithms. We study the performance of this approach in the problem of (agnostically and improperly) learning halfspaces with margin γ. Let D be a distribution over labeled examples. The γ-margin error of a hyperplane h is the probability of an example to fall on the wrong side of h or at a distance ≤ γ from it. The γ-margin error of the best h is denoted Errγ(D). An α(γ)-approximation algorithm receives γ, as input and, using i.i.d. samples of D, outputs a classifier with error rate ≤ α(γ) Errγ(D) + . Such an algorithm is efficient if it uses poly( 1 γ , 1 ) samples and runs in time polynomial in the sample size. The best approximation ratio achievable by an efficient algorithm is O ( 1/γ √ log(1/γ) ) and is achieved using an algorithm from the above class. Our main result shows that the approximation ratio of every efficient algorithm from this family must be ≥ Ω ( 1/γ poly(log(1/γ)) ) , essentially matching the best known upper bound. © 2014 A. Daniely & S. Shalev-Shwartz. Daniely Shalev-Shwartz	application domain;approximation algorithm;convex optimization;lasso;logistic regression;machine learning;mathematical optimization;optimization problem;polynomial;statistical classification	Amit Daniely;Nathan Linial;Shai Shalev-Shwartz	2014			mathematical optimization;combinatorics;discrete mathematics;machine learning;mathematics;statistics	ML	20.978095527134755	-33.86674253799206	106905
9494c29fedc7021972b163f91fb3d3191535b4c9	support vector committee machines	machines a vecteurs supports svm;support vector;support vector machines svm	This paper proposes a mathematical programming framew ork for combining SVMs with possibly di erent kernels. Compared to single SVMs, the advantage of this approach is tw ofold: it creates SVMs with local domains of expertise leading to local enlargements of the margin, and it allows the use of simple linear kernels combined with a xed boolean operation that is particularly well suited for building dedicated hardware.	algorithm;boolean operations on polygons;cluster analysis;decision tree;list of algorithms;mahdiyar;mathematical optimization;maxima and minima;ork;principle of least action;randomness;support vector machine;very-large-scale integration	Dominique Martinez;Gilles Millerioux	2000			support vector machine;computer science;artificial intelligence;machine learning;data mining;mathematics	ML	12.03217575215801	-34.86319714030243	107033
d66d75c6c0e3319b404166844913399b57d67e2f	learning methods for radial basis function networks	benchmarking;supervised learning;benchmark problem;multilayer perceptron;radial basis function networks;hybrid approach;learning methods;radial basis function network;genetic algorithm;genetic algorithms;evolutionary algorithm;rbf network;hybrid supervised learning;neural network	RBF networks represent a vital alternative to the widely used multilayer perceptron neural networks. In this paper we present and examine several learning methods for RBF networks and their combinations. A gradient-based learning, the three-step algorithm with unsupervised part, and an evolutionary algorithms are introduced, and their performance compared on benchmark problems from the Proben 1 database. The results show that the three-step learning is usually the fastest, while the gradient learning achieves better precision. The best results can be achieved by employing hybrid approaches that combine presented methods.	radial (radio);radial basis function	Roman Neruda;Petra Kudová	2005	Future Generation Comp. Syst.	10.1016/j.future.2004.03.013	semi-supervised learning;unsupervised learning;instance-based learning;genetic algorithm;types of artificial neural networks;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;evolutionary algorithm;pattern recognition;deep learning;learning classifier system;supervised learning;multilayer perceptron;stability;competitive learning;artificial neural network;generalization error	Arch	14.275643611167284	-28.95760238446369	107043
63d440eb606c7aa4ee3c7fcd94d65af3f5c92c96	efficient projections onto the l1-ball for learning in high dimensions	exponentiated gradient;efficient algorithm;projection method;online learning;feature space;high dimensional data;stochastic gradient;interior point method;high dimension;text categorization	We describe efficient algorithms for projecting a vector onto the l1-ball. We present two methods for projection. The first performs exact projection in O(n) expected time, where n is the dimension of the space. The second works on vectors k of whose elements are perturbed outside the l1-ball, projecting in O(k log(n)) time. This setting is especially useful for online learning in sparse feature spaces such as text categorization applications. We demonstrate the merits and effectiveness of our algorithms in numerous batch and online learning tasks. We show that variants of stochastic gradient projection methods augmented with our efficient projection procedures outperform interior point methods, which are considered state-of-the-art optimization techniques. We also show that in online settings gradient updates with l1 projections outperform the exponentiated gradient algorithm while obtaining models with high degrees of sparsity.	algorithm;average-case complexity;batch processing;categorization;document classification;gradient;interior point method;mathematical optimization;online machine learning;sparse matrix	John C. Duchi;Shai Shalev-Shwartz;Yoram Singer;Tushar Chandra	2008		10.1145/1390156.1390191	mathematical optimization;combinatorics;feature vector;computer science;machine learning;interior point method;mathematics;proximal gradient methods;projection method;statistics;clustering high-dimensional data	ML	24.023838360285513	-37.05771092116759	107128
53ecb1f4cee4ce825b3a10ce0542b470c56eab5c	using genetic algorithm to improve the performance of speech recognition based on artificial neural network	neural nets;bpnn;steepest descent method;backpropagation;back propagation neural network;genetic algorithms speech recognition artificial neural networks speech processing computer science signal detection speaker recognition neural networks hidden markov models statistics;speaker recognition;speech recognition backpropagation genetic algorithms neural nets;backpropagation genetic algorithm speech recognition artificial neural network steepest descent method bpnn;speech recognition;genetic algorithm;genetic algorithms;artificial neural network;neural network	The goal of this paper is to apply artificial neural network (ANN) to recognize speech. We use genetic algorithm (GA) to replace the steepest descent method (SDM) for the training of BPNN such that a global search of optimal weight in neural network can be. Thus, the performance of speech recognition was improved by the proposed method in this paper. The non-specific speaker recognition, which is trained by SDM, the recognition rate achieve up to 91% in this experiment. This paper shows that if BPNN is trained by genetic algorithm, higher recognition rate is attained	artificial neural network;genetic algorithm;gradient descent;software release life cycle;speaker recognition;speech recognition	Min-Lun Lan;Shing-Tai Pan;Chih-Chin Lai	2006	First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC'06)	10.1109/ICICIC.2006.372	neural gas;feedforward neural network;speech recognition;genetic algorithm;computer science;recurrent neural network;machine learning;pattern recognition;time delay neural network;deep learning;neocognitron;artificial neural network	Robotics	13.811603576059206	-25.532518958854638	107142
2eee666ded087706bd48f910f72d66190dc49ab2	unsupervised feature learning classification with radial basis function extreme learning machine using graphic processors	kernel;support vector machines;training;graphics processing units instruction sets kernel training support vector machines machine learning;machine learning;graphics processing units;instruction sets;support vector machine svm compute unified device architecture cuda extreme learning machine elm neural network radial basis function rbf	Ever-increasing size and complexity of data sets create challenges and potential tradeoffs of accuracy and speed in learning algorithms. This paper offers progress on both fronts. It presents a mechanism to train the unsupervised learning features learned from only one layer to improve performance in both speed and accuracy. The features are learned by an unsupervised feature learning (UFL) algorithm. Then, those features are trained by a fast radial basis function (RBF) extreme learning machine (ELM). By exploiting the massive parallel computing attribute of modern graphics processing unit, a customized compute unified device architecture (CUDA) kernel is developed to further speed up the computing of the RBF kernel in the ELM. Results tested on Canadian Institute for Advanced Research and Mixed National Institute of Standards and Technology data sets confirm the UFL RBF ELM achieves high accuracy, and the CUDA implementation is up to 20 times faster than CPU and the naive parallel approach.	algorithm;cpu (central processing unit of computer system);cuda;central processing unit;code;computation (action);computer graphics;customize;deep learning;elm;feature learning;graphics processing unit;hierarchical rbf;k-means clustering;kernel (operating system);lapack;linear algebra;mnist database;machine learning;parallel computing;radial (radio);radial basis function kernel;unsupervised learning;standards characteristics	Dao Lam;Donald C. Wunsch	2017	IEEE Transactions on Cybernetics	10.1109/TCYB.2015.2511149	semi-supervised learning;unsupervised learning;support vector machine;kernel method;instance-based learning;kernel;radial basis function kernel;wake-sleep algorithm;computer science;theoretical computer science;online machine learning;machine learning;instruction set;pattern recognition;computational learning theory;active learning;polynomial kernel	ML	12.7450350325321	-36.22782819280145	107348
f6d653c7ac616f3b4e347a1bfbefb102a4c5b0d0	an evolutionary morphological approach for software development cost estimation	software development cost estimation;mathematical morphology;dilation erosion perceptrons;genetic algorithms;evolutionary learning	In this work we present an evolutionary morphological approach to solve the software development cost estimation (SDCE) problem. The proposed approach consists of a hybrid artificial neuron based on framework of mathematical morphology (MM) with algebraic foundations in the complete lattice theory (CLT), referred to as dilation-erosion perceptron (DEP). Also, we present an evolutionary learning process, called DEP(MGA), using a modified genetic algorithm (MGA) to design the DEP model, because a drawback arises from the gradient estimation of morphological operators in the classical learning process of the DEP, since they are not differentiable in the usual way. Furthermore, an experimental analysis is conducted with the proposed model using five complex SDCE problems and three well-known performance metrics, demonstrating good performance of the DEP model to solve SDCE problems.	artificial neuron;cocomo;clinical prediction rule;computational complexity theory;cost estimation in software engineering;database;databases;dilation (morphology);erosion (morphology);evaluation function;executable space protection;foundations;genetic algorithm;gradient;hercules graphics card;hierarchical rbf;linear algebra;mathematical morphology;mathematics;media resource locator;nonlinear system;pathological dilatation;perceptron;radial basis function network;software development;software release life cycle;statistic (data);total peripheral resistance	Ricardo de A. Araújo;Adriano Lorena Inácio de Oliveira;Sérgio Soares;Silvio Romero de Lemos Meira	2012	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2012.02.040	mathematical morphology;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics	Robotics	13.925672087967516	-24.829237245145556	107536
b0736b208a52ead4d9e130f452c79f53b1728fe0	the accuracy of a procedural approach to specifying feedforward neural networks for forecasting	feedforward neural network;forecasting;time series forecasting;metodo estadistico;model specification;prevision;learning rate;validacion cruzada;neural networks;backpropagation neural network;benchmark;estudio comparativo;statistical method;time series;backpropagation;ensayo normalizado;essai normalise;etude comparative;retropropagation;specification modele;especificacion modelo;methode statistique;backpropagation algorithm;serie temporelle;validation croisee;comparative study;benchmarks;serie temporal;algorithme retropropagation;standard test;cross validation;reseau neuronal;comparative forecasting accuracy;retropropagacion;red neuronal;forecast accuracy;neural network;algoritmo retropropagacion	The comparative accuracy of feedforward neural networks (NN) when applied to time series forecasting problems remains uncertain. This is because most studies suffer from either of two defects – they choose the NN from a wide range of alternatives in order to present the forecast accuracy results in the best light, or they do not compare the results with suitable benchmarks. In order to overcome both these objections this paper proposes an objective procedure for specifying a feedforward neural network models and evaluates its effectiveness by examining its forecasting performance compared with established benchmarks. After the selection of input nodes based on cross-validation, a 3-Stage procedure is proposed here which consists of sequentially selecting first the learning rate followed by the number of nodes and the initial weights. This paper shows that neural networks only perform robustly if they are built by considering these three factors jointly. In an empirical demonstration of the strength of the approach, those neural network models, built by considering all three factors, performed better than other competitive statistical methods when evaluated rigorously on a standard test data set.	artificial neural network;benchmark (computing);cross-validation (statistics);feedforward neural network;procedural programming;test data;time series	Kua-Ping Liao;Robert Fildes	2005	Computers & OR	10.1016/j.cor.2004.02.006	econometrics;computer science;artificial intelligence;backpropagation;machine learning;time series;mathematics;artificial neural network	ML	10.398511904141447	-31.263024116834174	107549
4b3e4cc6bd0decc063770fcf44d0fde648b645bb	filtering noise in regression problems using a multiobjective leaning algorithm	multiobjective leaning algorithm;empirical risk;network output gradient;learning algorithm;complexity theory;neural networks;neural nets;gradient method;multiobjective training algorithms;regularization method;training;snr;filtering noise;signal processing filtering theory gradient methods learning artificial intelligence neural nets regression analysis;snr filtering noise regression problems multiobjective leaning algorithm neural networks minimum gradient method empirical risk function complexity network output gradient cross validation error signal to noise ratio;artificial neural networks;minimum gradient method;inverse problem;filtering algorithms;cross validation error;regression problems;filtering algorithms neural networks working environment noise gradient methods signal to noise ratio humans function approximation artificial intelligence artificial neural networks learning;function complexity;signal processing;regularization methods regression problems inverse problems noise neural networks multiobjective training algorithms;process control;gradient methods;regression analysis;cross validation;regularization methods;learning artificial intelligence;signal to noise ratio;adaptive filter;filtering theory;training algorithm;noise;inverse problems;neural network	This paper applies a neural networks (NN) multiobjective learning algorithm called the Minimum Gradient Method (MGM) to filter noise in regression problems. This method is based on the concept that the learning is a bi-objective problem aiming at minimizing the empirical risk (training error) and the function complexity. The complexity is modeled as the norm of the network output gradient. After training, the NN behaves as an adaptive filter which minimizes the cross-validation error. The NN trained with this method can be used to pre-process the data and help reduce the signal-to-noise ratio (SNR). Some results are presented and they show the effectiveness of the proposed approach.	adaptive filter;algorithm;artificial neural network;cross-validation (statistics);gradient method;pl/p;preprocessor;signal-to-noise ratio	Douglas A. G. Vieira;X. L. Travassos;Vasile Palade;Rodney R. Saldanha	2008	2008 20th IEEE International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2008.17	mathematical optimization;computer science;inverse problem;machine learning;pattern recognition;signal-to-noise ratio;artificial neural network	Robotics	16.474684549786183	-30.09197167002646	107825
8ba3af558ac366c5ee64f4d2a285fc8d6e8127df	svm-maj: a majorization approach to linear support vector machines with different hinge errors	i splines;support vector machines;absolute hinge error;optimal scaling;quadratic hinge error;loss function;support vector machine;iterative majorization;huber hinge error	Support vector machines (SVM) are becoming increasingly popular for the prediction of a binary dependent variable. SVMs perform very well with respect to competing techniques. Often, the solution of an SVM is obtained by switching to the dual. In this paper, we stick to the primal support vector machine (SVM) problem, study its effective aspects, and propose varieties of convex loss functions such as the standard for SVM with the absolute hinge error as well as the quadratic hinge and the Huber hinge errors. We present an iterative majorization algorithm that minimizes each of the adaptations. In addition, we show that many of the features of an SVM are also obtained by an optimal scaling approach to regression. We illustrate this with an example from the literature and do a comparison of different methods on several empirical data sets.	algorithm;huber loss;image scaling;iterative method;loss function;support vector machine	Patrick J. F. Groenen;Georgi I. Nalbantov;Jan C. Bioch	2008	Adv. Data Analysis and Classification	10.1007/s11634-008-0020-9	support vector machine;mathematical optimization;hinge loss;computer science;machine learning;mathematics;huber loss;statistics	ML	22.464074989404015	-35.36159728185709	107855
696e54d8e9762e4042a022200147612e9419cdd3	maximum entropy distribution estimation with generalized regularization	utilisation information;distributed estimation;performance guarantee;uso informacion;fonction potentiel;metodo entropia maxima;information use;divergence;error sistematico;intelligence artificielle;compacite;general techniques;feature space;bias;convex function;funcion potencial;artificial intelligence;compactness;inteligencia artificial;sample selection bias;complete convergence;potential function;methode entropie maximum;method of maximum entropy;fonction convexe;maximum entropy;divergencia;erreur systematique;funcion convexa;compacidad	We present a unified and complete account of maximum entropy distribution estimation subject to constraints represented by convex potential functions or, alternatively, by convex regularization. We provide fully general performance guarantees and an algorithm with a complete convergence proof. As special cases, we can easily derive performance guarantees for many known regularization types, including `1, `2, `2 and `1 + `2 style regularization. Furthermore, our general approach enables us to use information about the structure of the feature space or about sample selection bias to derive entirely new regularization functions with superior guarantees. We propose an algorithm solving a large and general subclass of generalized maxent problems, including all discussed in the paper, and prove its convergence. Our approach generalizes techniques based on information geometry and Bregman divergences as well as those based more directly on compactness.	algorithm;boosting (machine learning);bregman divergence;feature vector;ibm notes;information geometry;kullback–leibler divergence;logistic regression;matrix regularization;maximum entropy probability distribution;rate of convergence;selection bias	Miroslav Dudík;Robert E. Schapire	2006		10.1007/11776420_12	convex function;mathematical optimization;selection bias;feature vector;artificial intelligence;principle of maximum entropy;bias;calculus;mathematics;compact space;divergence;statistics	ML	21.39942057998548	-33.902728865873726	107894
7cff09afd062bfd7b9348538a9e46e4632a788be	a learning, representation and diagnostic methodology for engine fault diagnosis	fault diagnosis		feature learning	Min Ke;Moonis Ali	1989		10.1145/67312.67353	computer science	AI	10.63348462421708	-26.448359571822554	108178
063da889b70e5bf9d6a6ceaa0ad60927967c06a6	advanced methods to analyse the complexity of the brain				Nadia Mammone;Gaoxiang Ouyang;Hamed Azami	2018	Complexity	10.1155/2018/8971891	machine learning;artificial intelligence;mathematics	Theory	10.568722633169873	-26.382906820110566	108283
f332b044855984cd71ecbc86304b93501aac207b	geometric insights into support vector machine behavior using the kkt conditions		The Support Vector Machine (SVM) is a powerful and widely used classification algorithm. Its performance is well known to be impacted by a tuning parameter which is frequently selected by cross-validation. This paper uses the Karush-Kuhn-Tucker conditions to provide rigorous mathematical proof for new insights into the behavior of SVM in the large and small tuning parameter regimes. These insights provide perhaps unexpected relationships between SVM and naive Bayes and maximal data piling directions. We explore how characteristics of the training data affect the behavior of SVM in many cases including: balanced vs. unbalanced classes, low vs. high dimension, separable vs. non-separable data. These results present a simple explanation of SVM’s behavior as a function of the tuning parameter. We also elaborate on the geometry of complete data piling directions in high dimensional space. The results proved in this paper suggest important implications for tuning SVM with cross-validation.	algorithm;cross-validation (statistics);karush–kuhn–tucker conditions;maximal set;naive bayes classifier;support vector machine;tucker decomposition;unbalanced circuit	Iain Carmichael;J. S. Marron	2017	CoRR		mathematical optimization;machine learning;pattern recognition	ML	19.87791188291388	-35.090873586860575	108295
2ff8bf47930edbbba1189b107c093919472a8ab2	accuracy at the top		We introduce a new notion of classification accuracy based on the top ⌧ -quantile values of a scoring function, a relevant criterion in a number of problems arising for search engines. We define an algorithm optimizing a convex surrogate of the corresponding loss, and discuss its solution in terms of a set of convex optimization problems. We also present margin-based guarantees for this algorithm based on the top ⌧ -quantile value of the scores of the functions in the hypothesis set. Finally, we report the results of several experiments in the bipartite setting evaluating the performance of our solution and comparing the results to several other algorithms seeking high precision at the top. In most examples, our solution achieves a better performance in precision at the top.	algorithm;augmented lagrangian method;convex optimization;experiment;loss function;matlab;mathematical optimization;merge sort;scoring functions for docking;web search engine	Stephen P. Boyd;Corinna Cortes;Mehryar Mohri;Ana Radovanovic	2012			mathematical optimization;combinatorics;data mining;mathematics	ML	22.390565447435765	-37.34159360825048	108395
0073a1284260305b59fd4eae899b6fc00dd7eb18	stochastic particle gradient descent for infinite ensembles		The superior performance of ensemble methods with infinite models are well known. Most of these methods are based on optimization problems in infinite-dimensional spaces with some regularization, for instance, boosting methods and convex neural networks use L1-regularization with the non-negative constraint. However, due to the difficulty of handling L1-regularization, these problems require early stopping or a rough approximation to solve it inexactly. In this paper, we propose a new ensemble learning method that performs in a space of probability measures, that is, our method can handle the L 1-constraint and the non-negative constraint in a rigorous way. Such an optimization is realized by proposing a general purpose stochastic optimization method for learning probability measures via parameterization using transport maps on base models. As a result of running the method, a transport map to output an infinite ensemble is obtained, which forms a residual-type network. From the perspective of functional gradient methods, we give a convergence rate as fast as that of a stochastic optimization method for finite dimensional nonconvex problems. Moreover, we show an interior optimality property of a local optimality condition used in our analysis.	approximation;artificial neural network;boosting (machine learning);early stopping;ensemble learning;gradient descent;local optimum;map;mathematical optimization;matrix regularization;rate of convergence;stochastic optimization	Atsushi Nitanda;Taiji Suzuki	2017	CoRR		boosting (machine learning);rate of convergence;mathematics;mathematical optimization;stochastic optimization;ensemble learning;artificial neural network;gradient descent;early stopping;optimization problem	ML	22.684156330290048	-33.1449835318727	108424
bd3a2cd815df554ec151e663cf36a07d9e7ffe84	pattern classification by evolutionary rbf networks ensemble based on multi-objective optimization	evolutionary computation;ensemble method;ensemble learning;benchmark problem;multi objective optimization;model complexity;objective function;radial basis function pattern classification evolutionary rbf networks ensemble multi objective optimization ensemble learning;radial basis function networks;radial basis function networks evolutionary computation pattern classification;pattern classification;pattern classification radial basis function networks neurons neural networks optimization methods multilayer perceptrons artificial neural networks learning systems machine learning evolutionary computation;rbf network;pareto optimality	In this paper, evolutionary multi-objective selection method of RBF networks structure and its application to the ensemble learning is considered. The candidates of RBF network structure are encoded into the chromosomes in GAs. Then, they evolve toward Pareto-optimal front defined by several objective functions concerning with model accuracy, model complexity and model smoothness. RBF network ensemble is constructed of the obtained Pareto-optimal models since such models are diverse. This method is applied to the pattern classification problem. Experiments on the benchmark problem demonstrate that the proposed method has comparable generalization ability to conventional ensemble methods.	benchmark (computing);dynamical system;ensemble learning;evolutionary algorithm;evolutionary computation;experiment;multi-objective optimization;nonlinear system;norm (social);numerical analysis;pareto efficiency;radial basis function network;software release life cycle;statistical classification;system identification	Nobuhiko Kondo;Toshiharu Hatanaka;Katsuji Uosaki	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.247224	hierarchical rbf;computer science;artificial intelligence;multi-objective optimization;machine learning;pattern recognition;ensemble learning;evolutionary computation	Vision	13.996463706320373	-24.045483802098666	108445
3879eea69ad84a76ebfee67e0dad4e70ffb3c0a1	improved learning algorithms of slfn for approximating periodic function	learning algorithm;fourier series;best approximation;convergence rate;extreme learning machine;neuronal activity;neural network	In this paper, three improved Extreme Learning Machines (ELMs) are proposed to approximating periodic function. According to Fourier series expansion theory, the hidden neurons activation functions in the improved ELM are a class of sine and cosine functions. In addition, the improved ELM analytically determines the output weights of neural networks. In theory, the new algorithm tends to provide the best approximation performance at extremely fast learning speed. The proposed ELMs have better approximation accuracies and faster convergence rate than traditional ELM and gradient-based learning algorithms. Finally, experimental results are given to verify the efficiency and effectiveness of the proposed ELMs.	algorithm	Fei Han	2008		10.1007/978-3-540-85984-0_78	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;rate of convergence;artificial neural network;premovement neuronal activity;fourier series	Theory	16.111893019607862	-29.196643963859824	108458
8298ee214fe9d9aa13d209b2371412ad2cbb02a6	high-dimensional function approximation with neural networks for large volumes of data	manifolds biological neural networks neurons linear approximation approximation error distributed databases;neural networks big data function approximation high dimensional data manifold mapping	Approximation of high-dimensional functions is a challenge for neural networks due to the curse of dimensionality. Often the data for which the approximated function is defined resides on a low-dimensional manifold and in principle the approximation of the function over this manifold should improve the approximation performance. It has been show that projecting the data manifold into a lower dimensional space, followed by the neural network approximation of the function over this space, provides a more precise approximation of the function than the approximation of the function with neural networks in the original data space. However, if the data volume is very large, the projection into the low-dimensional space has to be based on a limited sample of the data. Here, we investigate the nature of the approximation error of neural networks trained over the projection space. We show that such neural networks should have better approximation performance than neural networks trained on high-dimensional data even if the projection is based on a relatively sparse sample of the data manifold. We also find that it is preferable to use a uniformly distributed sparse sample of the data for the purpose of the generation of the low-dimensional projection. We illustrate these results considering the practical neural network approximation of a set of functions defined on high-dimensional data including real world data as well.	approximation algorithm;approximation error;big data;biologic preservation;biological neural networks;curse of dimensionality;dataspaces;dimensionality reduction;linear approximation;maxima and minima;maximum;neural network simulation;projections and predictions;sparse matrix;manifold	Peter Andras	2018	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2017.2651985	mathematical optimization;types of artificial neural networks;computer science;theoretical computer science;machine learning;universal approximation theorem;rectifier	ML	18.842908545118586	-30.26465136253084	108590
140101737fca01e76691a3bc77333571d7fdaa1e	sequential competitive learning and the fuzzy c-means clustering algorithms	optimisation;fuzzy c mean;optimizacion;learning;logique floue;logica difusa;minimizacion funcion;competitive learning;algorithme;aprendizaje;fuzzy logic;algorithm;apprentissage;function minimization;gradient descent;stochastic approximation;fuzzy c means;approximation stochastique;gradient based fuzzy c means;optimization;aproximacion estocastica;fuzzy c means clustering;grouped coordinate minimization;alternating optimization;alternating optimazation;minimisation fonction;learning vector quantization;algoritmo	Several recent papers have described sequential competitive learning algorithms that are curious hybrids of algorithms used to optimize the fuzzy c-means (FCM) and learning vector quantization (LVQ) models. First, we show that these hybrids do not optimize the FCM functional. Then we show that the gradient descent conditions they use are not necessary conditions for optimization of a sequential version of the FCM functional. We give a numerical example that demonstrates some weaknesses of the sequential scheme proposed by Chung and Lee. And finally, we explain why these algorithms may work at times, by exhibiting the stochastic approximation problem that they unknowingly attempt to solve. Copyright 1996 Published by Elsevier Science Ltd	algorithm;competitive learning;copyright;exhibits as topic;fuzzy clustering;fuzzy cognitive map;gradient descent;hybrids;learning vector quantization;machine learning;mathematical optimization;numerical analysis;paper;scheme;scientific publication;stochastic approximation;weakness	Nikhil R. Pal;James C. Bezdek;Richard J. Hathaway	1996	Neural networks : the official journal of the International Neural Network Society	10.1016/0893-6080(95)00094-1	fuzzy logic;gradient descent;stochastic approximation;mathematical optimization;learning vector quantization;computer science;machine learning;mathematics;competitive learning;algorithm	ML	19.104586286018264	-26.24676332506571	108624
1a0d51048ce373d01ecc354671a1d21b243f285a	hebbian learning with winner take all for spiking neural networks	simple cell;hebbian learning;time dependent;learning algorithm;bell shaped tuning curves;neural nets;training;biological system modeling;leaky integrate and fire;gabor filters;homeostasis;backpropagation;competitive learning;firing;mammalian brain;gabor filter;spiking neural network;c language;computational modeling;spiking neurons;learning methods;object oriented;hebbian theory neural networks neurons biological neural networks object oriented modeling biological information theory backpropagation algorithms learning systems artificial neural networks timing;synaptic modification;c object oriented code;winner take all mechanism hebbian learning method spiking neural network backpropagation learning algorithm synaptic modification c object oriented code gabor filters bell shaped tuning curves mammalian brain homeostasis;hebbian learning method;neural nets backpropagation c language gabor filters hebbian learning;neurons;backpropagation learning algorithm;winner take all;striate cortex;back propagation;object oriented modeling;winner take all mechanism;neural network	Learning methods for spiking neural networks are not as well developed as the traditional rate based networks, which widely use the back-propagation learning algorithm. We propose and implement an efficient Hebbian learning method with homeostasis for a network of spiking neurons. Similar to STDP, timing between spikes is used for synaptic modification. Homeostasis ensures that the synaptic weights are bounded and the learning is stable. The winner take all mechanism is also implemented to promote competitive learning among output neurons. We have implemented this method in a C++ object oriented code (called CSpike). We have tested the code on four images of Gabor filters and found bell-shaped tuning curves using 36 test set images of Gabor filters in different orientations. These bell-shapes curves are similar to those experimentally observed in the V1 and MT/V5 area of the mammalian brain.	algorithm;artificial neural network;backpropagation;c++;competitive learning;epoch (reference date);experiment;gabor filter;hebbian theory;homeostasis;neuron;scalability;software propagation;spiking neural network;synaptic package manager;synaptic weight;test set	Ankur Gupta;Lyle N. Long	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178751	computer science;artificial intelligence;backpropagation;theoretical computer science;machine learning;leabra;competitive learning;artificial neural network	ML	14.324447391920701	-28.17636473161741	108748
0a41156d1bccc0688ce5bc6438e04bd41d03aec3	robust learning via cause-effect models		We consider the problem of function estimation in the case where the data distribution may shift between training and test time, and additional information about it may be available at test time. This relates to popular scenarios such as covariate shift, concept drift, transfer learning and semisupervised learning. This working paper discusses how these tasks could be tackled depending on the kind of changes of the distributions. It argues that knowledge of an underlying causal direction can facilitate several of these tasks.	causal filter;concept drift;semi-supervised learning	Bernhard Schölkopf;Dominik Janzing;Jonas Peters;Kun Zhang	2011	CoRR		multi-task learning;simulation;computer science;artificial intelligence;machine learning;statistics	ML	15.705835650620637	-37.68110447581408	108828
303521a6f8cda95df5dc1193a9c930a591e3cb17	drug design with artificial neural networks	drug design;artificial neural network	Artificial neuron An artificial neuron is a mathematical 18 function that simulates in a simplified form the func19 tions of biological neurons. Usually, an artificial neu20 ron has four computational functions, namely receives 21 signals through input connections from other neurons 22 or from the environment, sums the input signals, ap23 plies a nonlinear functions (transfer function or activa24 tion function) to the sum, and sends the result to other 25 neurons or as output from the neural network. 26 Counterpropagation neural network The counterprop27 agation neural network is a hybrid network that con28 sists of a self-organizing map as the hidden layer and 29 an output layer that has as output a computed value for 30 the modeled property. The network implements a su31 pervised learning algorithm that converges to a unique 32 solution. 33 Multilayer feedforward artificial neural network 34 A multilayer feedforward (MLF) artificial neural net35 work consists of artificial neurons organized in layers. 36 The MLF network has an input layer that receives the 37 structural descriptors for each molecule, an output 38 layer that provides one or more computed properties, 39 and one or more hidden layers situated between the 40 input and the output layers. Each neuron in a hidden 41 layer receives signals from neurons in the preceding 42 layer and sends signals to the neurons in the next layer. 43 Perceptron A perceptron is a linear classifier that consists 44 of a layer of input neurons and an output neuron. Each 45 connection between an input neuron and the output 46 neuron has a weight. Depending on the sum of the sig47 nals received by the output neuron, its output is +1 or 48 1. 49 Quantitative structure-activity relationships 50 Quantitative structure-activity relationships (QSAR) 51 represent regression models that define quantita52 tive correlations between the chemical structure of 53 molecules and their physical properties (boiling point, 54 melting point, aqueous solubility), chemical properties 55 and reactivities (chromatographic retention, reaction 56 rate), or biological activities (cell growth inhibition, 57 enzyme inhibition, lethal dose). The fundamental 58 hypotheses of QSAR is that similar chemicals have 59 similar properties, and small structural changes result 60 in small changes in property values. The general form 61 of a QSAR equation is P(i) D f (SDi ), where P(i) is 62 a physical, chemical, or biological property of com63 pound i; SDi is a vector of structural descriptors of i, 64 and f is a mathematical function such as linear regres65 sion, partial least squares, artificial neural networks, or 66 support vector machines. A QSAR model for a prop67 erty P is based on a dataset of chemical compounds 68 with known values for the property P, and a matrix of 69 structural descriptors computed for all chemicals. The 70 learning (training) of the QSAR model is the process 71 of determining the optimum parameters of the re72 gression function f . After the training phase, a QSAR 73 model may be used to predict the property P for novel 74 compounds that are not present in the learning set of 75 molecules. 76 Radial basis function network The radial basis function 77 (RBF) neural network has three layers, namely an in78 put layer, a hidden layer with a non-linear RBF activa79 tion function and a linear output layer. 80 Self-organizing map A self-organizing map (SOM) is an 81 artificial neural network that uses an unsupervised 82 learning algorithm to project a high dimensional input 83 space into a two dimensional space called a map. The 84 topology of the input space is preserved in SOM, and 85 points that are close to each other in the SOM grid cor86 respond to input vectors that are close to each other in 87 the input space. A SOM consists of neurons arranged 88 usually in a rectangular or hexagonal grid. Each neu89 ron has a position on the map and a weight vector of 90 the same dimension as the input vectors. 91 Structural descriptor A structural descriptor (SD) is 92 a numerical value computed from the chemical struc93 ture of a molecule, which is invariant to the number94	algorithm;artificial neural network;artificial neuron;data descriptor;feedforward neural network;grid computing;like button;linear classifier;multilayer perceptron;nonlinear system;numerical analysis;organizing (structure);partial least squares regression;ply (game theory);quantitative structure–activity relationship;radial (radio);radial basis function network;rise of nations;self-organization;self-organizing map;sion's minimax theorem;situated;support vector machine;transfer function	Ovidiu Ivanciuc	2009		10.1007/978-0-387-30440-3_134	physical neural network	ML	12.475201899824398	-28.077941342542957	108904
82c3665d54aeb16d19af683d9af49b643eaa1af8	a classification approach using multi-layered neural networks	neural networks;classification;gradient search;back propagation;neural network	There has been an increasing interest in the applicability of neural networks in disparate domains. In this paper, we describe the use of multi-layered perceptrons, a type of neural-network topology, for financial classification problems, with promising results. Back-propagation, which is the learning algorithm most often used in multi-layered perceptrons, however, is inherently an inefficient search procedure. We present improved procedures which have much better convergence properties. Using several financial classification applications as examples, we show the efficacy of using multilayered perceptrons with improved learning algorithms. The modified learning algorithms have better performance, in terms of classification/prediction accuracies, than the methods previously used in the literature, such as probit analysis and similarity-based learning techniques.	algorithm;artificial neural network;machine learning;network topology;perceptron;probit model;software propagation	Selwyn Piramuthu;Michael J. Shaw;James A. Gentry	1994	Decision Support Systems	10.1016/0167-9236(94)90022-1	biological classification;computer science;artificial intelligence;backpropagation;machine learning;pattern recognition;data mining;artificial neural network	ML	14.283961298985089	-29.28781063956159	109194
1bfc5dc0486535394c4753c0c98ffd945c94880b	forward and reverse gradient-based hyperparameter optimization		We study two procedures (reverse-mode and forward-mode) for computing the gradient of the validation error with respect to the hyperparameters of any iterative learning algorithm such as stochastic gradient descent. These procedures mirror two methods of computing gradients for recurrent neural networks and have different trade-offs in terms of running time and space requirements. Our formulation of the reverse-mode procedure is linked to previous work by Maclaurin et al. (2015) but does not require reversible dynamics. The forward-mode procedure is suitable for real-time hyperparameter updates, which may significantly speed up hyperparameter optimization on large datasets. We present experiments on data cleaning and on learning task interactions. We also present one large-scale experiment where the use of previous gradient-based methods would be prohibitive.	algorithm;artificial neural network;experiment;interaction;iterative method;mathematical optimization;plasma cleaning;real-time transcription;recurrent neural network;requirement;stochastic gradient descent;time complexity	Luca Franceschi;Michele Donini;Paolo Frasconi;Massimiliano Pontil	2017			mathematical optimization;computer science;artificial intelligence;machine learning;hyperparameter optimization	ML	24.450448962231064	-32.14280716671516	109310
afa61cc5aa4d9ff982a01bf7e2c9616fcb4a310d	adaptive radial basis decomposition by learning vector quantization	temporal difference;decomposition;mobile robot;reinforcement learning;learning methods;function approximation;gradient descent;rbf neural network;radial basis function neural network;state space;rbf neural network reinforcement learning;value function;learning vector quantization	A method for function approximation in reinforcement learning settings is proposed. The action-value function of the Q-learning method is approximated by the radial basis function neural network and learned by the gradient descent. Those radial basis units that are unable to fit the local action-value function exactly enough are decomposed into new units with smaller widths. The local temporal-difference error is modelled by a two-class learning vector quantization algorithm, which approximates distributions of the positive and of the negative error and provides the centers of the new units. This method is especially convenient in cases of smooth value functions with large local variation in certain parts of the state space, such that non-uniform placement of basis functions is required. In comparison with four related methods, it has the smallest requirements of basis functions when achieving a comparable accuracy.	approximation algorithm;artificial neural network;bellman equation;gradient descent;learning vector quantization;q-learning;radial (radio);radial basis function;reinforcement learning;requirement;state space	Branko Ster;Andrej Dobnikar	2003	Neural Processing Letters	10.1023/A:1026242620248	gradient descent;mobile robot;feedforward neural network;mathematical optimization;radial basis function;radial basis function kernel;learning vector quantization;function approximation;computer science;state space;basis function;machine learning;pattern recognition;mathematics;bellman equation;decomposition;reinforcement learning;radial basis function network;artificial neural network	ML	17.28178636088062	-29.75534702383668	109430
df6eb063db25e313f2e6dad4b7b352e3b62db873	rank, trace-norm and max-norm	generalization error;borne erreur;low complexity;intelligence artificielle;complexity measure;mesure complexite;artificial intelligence;inteligencia artificial;error bound;medida complexidad;limite error	We study the rank, trace-norm and max-norm as complexity measures of matrices, focusing on the problem of fitting a matrix with matrices having low complexity. We present generalization error bounds for predicting unobserved entries that are based on these measures. We also consider the possible relations between these measures. We show gaps between them, and bounds on the extent of such gaps.	generalization error;t-norm	Nathan Srebro;Adi Shraibman	2005		10.1007/11503415_37	computer science;artificial intelligence;machine learning;mathematics;statistics;generalization error	ML	19.97075283153245	-30.886800473005845	109588
bdd46459102967fed8c9ce41f81ce4d18b33c38e	addressing function approximation error in actor-critic methods		In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.	algorithm;approximation error;q-learning;reinforcement learning	Scott Fujimoto;Herke van Hoof;Dave Meger	2018			machine learning;function approximation;reinforcement learning;artificial intelligence;pattern recognition;computer science;restrict	ML	17.772015076115817	-32.12601224665907	109676
6645c185546d7038f017737fc9668f32ec76420d	error surface of recurrent neural networks	spurious valleys error surface fibonacci polynomials recurrent neural networks;polynomials;network architecture error surface recurrent neural networks general layered digital dynamic networks;recurrent neural nets polynomials;recurrent neural nets	We found in previous work that the error surfaces of recurrent networks have spurious valleys that can cause significant difficulties in training these networks. Our earlier work focused on single-layer networks. In this paper, we extend the previous results to general layered digital dynamic networks. We describe two types of spurious valleys that appear in the error surfaces of these networks. These valleys are not affected by the desired network output (or by the problem that the network is trying to solve). They depend only on the input sequence and the architecture of the network. The insights gained from this analysis suggest procedures for improving the training of recurrent neural networks.	artificial neural network;gain;neural network simulation;neural tube defects;recurrent neural network;anatomical layer	Manh Cong Phan;Martin T. Hagan	2013	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2013.2258470	computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;time delay neural network;mathematics;polynomial	ML	17.86432517377363	-28.176242520802866	109734
562a596836f42714d81e1f861671959ba12e0246	machine learning methods for predicting failures in hard drives: a multiple-instance application	distributed data;unsupervised clustering;multiple instance;multiple instance learning;naive bayes;false alarm rate;naive bayesian classifier;nonparametric statistic;time series;machine learning;rare event;learning problems;time series data;non parametric statistics;support vector machine;normal approximation;failure prediction	We compare machine learning methods applied to a difficult re a -world problem: predicting computer hard-drive failure using attributes monitored inter ally by individual drives. The problem is one of detecting rare events in a time series of noisy and nonp arametrically-distributed data. We develop a new algorithm based on the multiple-instance lear ning framework and the naive Bayesian classifier (mi-NB) which is specifically designed for the low false-alarm case, and is shown to have promising performance. Other methods compared are support vector machines (SVMs), unsupervised clustering, and non-parametric statistical tests (r ank-sum and reverse arrangements). The failure-prediction performance of the SVM, rank-sum and mi -NB algorithm is considerably better than the threshold method currently implemented in driv es, while maintaining low false alarm rates. Our results suggest that nonparametric statistical tests should be considered for learning problems involving detecting rare events in time series dat a. An appendix details the calculation of rank-sum significance probabilities in the case of discre te, tied observations, and we give new recommendations about when the exact calculation should be used instead of the commonly-used normal approximation. These normal approximations may be p articularly inaccurate for rare event problems like hard drive failures.	algorithm;approximation;bayesian network;cma-es;cluster analysis;extreme value theory;failure;hard disk drive;machine learning;naive bayes classifier;rare events;sensor;support vector machine;time series	Joseph F. Murray;Gordon F. Hughes;Kenneth Kreutz-Delgado	2005	Journal of Machine Learning Research		computer science;machine learning;time series;pattern recognition;data mining;mathematics;statistics	ML	15.77057397569416	-37.24528466596547	109763
aad791574100ad816a4fb121bc0604e7ef2c3ddc	a modified gradient-based backpropagation training method for neural networks	resilient propagation method;barzilai and borwein steplength;learning rate;convergence;barzilai steplength update;neural networks;neural nets;resilient propagation method modified gradient based backpropagation training method neural networks barzilai steplength update borwein steplength update;approximation algorithms;neural networks artificial neural networks backpropagation algorithms mathematics convergence iterative algorithms computer science testing information processing biology;training;backpropagation training method barzilai and borwein steplength resilient propagation method;borwein steplength update;backpropagation training method;backpropagation;data mining;artificial neural networks;success rate;gradient methods;neural nets backpropagation gradient methods;neurons;modified gradient based backpropagation training method;neural network	A improved gradient-based backpropagation training method is proposed for neural networks in this paper. Based on the Barzilai and Borwein steplength update and some technique of Resilient Propagation method, we adapt the new learning rate to improves the speed and the success rate. Experimental results show that the proposed method has considerably improved convergence speed, and for the chosen test problems, outperforms other well-known training methods.	algorithm;artificial neural network;backpropagation;epoch (reference date);gradient;rprop;software propagation;teaching method	Xuewen Mu;Yaling Zhang	2009	2009 IEEE International Conference on Granular Computing	10.1109/GRC.2009.5255081	convergence;computer science;artificial intelligence;backpropagation;theoretical computer science;machine learning;artificial neural network	Robotics	15.902126341044525	-29.160069003125585	109817
0416c7419e5d8de54b19481cfeb253b9e5d4c3c0	k-nearest neighbors by means of sequence to sequence deep neural networks and memory networks		k-Nearest Neighbors is one of the most fundamental but effective classification models. In this paper, we propose two families of models built on a sequence to sequence model and a memory network model to mimic the k-Nearest Neighbors model, which generate a sequence of labels, a sequence of out-of-sample feature vectors and a final label for classification, and thus they could also function as oversamplers. We also propose ‘out-of-core’ versions of our models which assume that only a small portion of data can be loaded into memory. Computational experiments show that our models outperform k-Nearest Neighbors, a feed-forward neural network and a memory network, due to the fact that our models must produce additional output and not just the label. As an oversample on imbalanced datasets, the sequence to sequence kNN model often outperforms Synthetic Minority Over-sampling Technique and Adaptive Synthetic Sampling.	artificial neural network;benchmark (computing);computation;deep learning;experiment;feedforward neural network;gibbs sampling;k-nearest neighbors algorithm;network model;neural networks;out-of-core algorithm;oversampling;sampling (signal processing);synthetic data;synthetic intelligence;test set	Yiming Xu;Diego Klabjan	2018	CoRR		machine learning;artificial intelligence;artificial neural network;network model;feature vector;sampling (statistics);mathematics;k-nearest neighbors algorithm	ML	13.27788040206091	-29.14471317179264	109991
163b191fcf8814ef82214f372050642383dcad54	a maximizing-discriminability-based architecture for fuzzy-neural-network hardware		A maximizing-discriminability-based architecture for fuzzy-neural-network (FNN) hardware is proposed in this paper. The major contribution of this proposed FNN hardware is to increase the discriminative capability among different classes in classification problems by combining linear discriminant analysis (LDA) and Gaussian mixture model (GMM). In LDA, the weights are updated by seeking directions that are efficient for discrimination. In GMM, the parameter learning adopts the gradient descent method to reduce the cost function. Furthermore, this FNN can be reconfigured by the instruction of the external processer.	artificial neural network;google map maker;gradient descent;linear discriminant analysis;loss function;mixture model	Gin-Der Wu;Zhen-Wei Zhu	2017		10.1145/3055635.3056593	computer hardware;artificial intelligence;mixture model;machine learning;architecture;discriminative model;artificial neural network;computer science;pattern recognition;gradient descent;linear discriminant analysis	ML	15.494431602003097	-31.708849771423047	110177
a0c351633081426dd9934b557c0e949712323b8d	identification of the human arm kinetics using dynamic recurrent neural networks			artificial neural network;kinetics internet protocol;recurrent neural network	Jean-Philippe Draye;Guy Cheron;Marc Bourgeois;Davor Pavisic;Gaetan Libert	1995			artificial intelligence;machine learning;pattern recognition;kinetics;computer science;recurrent neural network	Robotics	12.460297079443821	-27.375380748896294	110349
3f605f702ca54939c9e7d5851f90eaf1a4651f43	a hyper ellipsoidal incremental learning algorithm	classification algorithm;text analysis;extension factor hyper ellipsoidal incremental learning;incremental learning;classification precision hyper ellipsoidal incremental learning algorithm reuters 21578 classification speed;machine learning;training classification algorithms testing machine learning support vector machines text categorization machine learning algorithms;pattern classification;text analysis learning artificial intelligence pattern classification;support vector machine;learning artificial intelligence;text categorization	A sample and class incremental learning algorithm based on hyper ellipsoidal is proposed. For every class, the smallest hyper ellipsoidal that surrounds most samples of the class is structured, which can divide the class samples from others. In the process of incremental learning, only the hyper ellipsoidal of every new class is trained and the history hyper ellipsoidals that increment new samples are retrained. For the sample to be classified, its class be confirmed by the hyper ellipsoidal that surrounds it. If the sample is not surrounded by all hyper ellipsoidals, the membership is used to confirmed its class. The experiments are done on Reuters 21578, and the experiment results show that the algorithm has a higher performance on classification speed and classification precision compare with hyper sphere algorithm.	algorithm;experiment;hyper cd-rom;hyper-heuristic;hyper-threading;kernal;precision and recall	Yuping Qin;Shuxian Lun;Qiangkui Leng;Yandong Guo	2011	2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2011.6019921	support vector machine;text mining;computer science;artificial intelligence;machine learning;pattern recognition;population-based incremental learning	Robotics	12.843242428348628	-36.01058037857154	110773
18099f0d3b856a301c3d4bd47024f91ce17fec93	sketching and neural networks		High-dimensional sparse data present computational and statistical challenges for supervised learning. We propose compact linear sketches for reducing the dimensionality of the input, followed by a single layer neural network. We show that any sparse polynomial function can be computed, on nearly all sparse binary vectors, by a single layer neural network that takes a compact sketch of the vector as input. Consequently, when a set of sparse binary vectors is approximately separable using a sparse polynomial, there exists a single-layer neural network that takes a short sketch as input and correctly classifies nearly all the points. Previous work has proposed using sketches to reduce dimensionality while preserving the hypothesis class. However, the sketch size has an exponential dependence on the degree in the case of polynomial classifiers. In stark contrast, our approach of using improper learning, using a larger hypothesis class allows the sketch size to have a logarithmic dependence on the degree. Even in the linear case, our approach allows us to improve on the pesky O(1/γ) dependence of random projections. We empirically show that our approach leads to more compact neural networks than related methods such as feature hashing at equal or better performance. ∗Email: amitdaniely@google.com †Email: nevena@google.com ‡Email: singer@google.com §Email: kunal@google.com. Author for correspondences. ar X iv :1 60 4. 05 75 3v 1 [ cs .L G ] 1 9 A pr 2 01 6	artificial neural network;computation;email;feature hashing;polynomial;random projection;sparse matrix;supervised learning;time complexity	Amit Daniely;Nevena Lazic;Yoram Singer;Kunal Talwar	2016	CoRR		theoretical computer science;machine learning;pattern recognition;sparse approximation;mathematics;statistics	ML	20.57099728900749	-33.72977835150651	110776
5879f88707805311522fd27173bf3de4bb5bf20d	k-tablet structures and crossover on latent variables for real-coded ga	latent variable		latent variable;software release life cycle;tablet computer	Jun Sakuma;Shigenobu Kobayashi	2002			latent variable model;artificial intelligence;machine learning;crossover;computer science;latent class model;latent variable	NLP	11.146095087781879	-25.98997694230981	110810
a30860bd2654c68f3784810ca1070bcf890f78c3	machine learning for event selection in high energy physics	evolutionary computation;neural networks;supervised learning;higgs boson;universiteitsbibliotheek;stochastic optimization;machine learning;high energy physics;event selection;classification accuracy;neural network;evolutionary computing;top quark	The field of high energy physics aims to discover the underlying structure of matter by searching for and studying exotic particles, such as the top quark and Higgs boson, produced in collisions at modern accelerators. Since such accelerators are extraordinarily expensive, extracting maximal information from the resulting data is essential. However, most accelerator events do not produce particles of interest, so making effective measurements requires event selection, in which events producing particles of interest (signal) are separated from events producing other particles (background). This article studies the use of machine learning to aid event selection. First, we apply supervised learning methods, which have succeeded previously in similar tasks. However, they are suboptimal in this case because they assume the selector with the highest classification accuracy will yield the best final analysis; this is not true in practice, as such analyses are more sensitive to some backgrounds than others. Second, we present a new approach that uses stochastic optimization techniques to directly search for selectors that maximize either the precision of top quark mass measurements or sensitivity to the presence of the Higgs boson. Empirical results confirm that stochastically optimized selectors result in substantially better analyses. We also describe a case study in which the best selector is applied to real data from the Fermilab Tevatron accelerator, resulting in the most precise top quark mass measurement of this type to date. Hence, this new approach to event selection has already contributed to our knowledge of the top quark’s mass and our understanding of the larger questions upon which it sheds light.	boson sampling;interaction;machine learning;mathematical optimization;maximal set;stochastic optimization;supervised learning	Shimon Whiteson;Daniel Whiteson	2009	Eng. Appl. of AI	10.1016/j.engappai.2009.05.004	higgs boson;computer science;machine learning;top quark;artificial neural network;evolutionary computation	AI	17.63579948923402	-34.94373773839809	110848
fbeee161a5ea72c8235b0bd78b034fdc74e3325e	the interactive feature selection method development for an ann based emotion recognition system	learning algorithm;ingenierie connaissances;reinforcement learning;emotion recognition;intelligence artificielle;algorithme apprentissage;simulator;apprentissage renforce;simulador;emotion emotionality;simulateur;pattern recognition;artificial intelligence;emotion emotivite;feature selection;emocion emotividad;inteligencia artificial;reconnaissance forme;reseau neuronal;reconocimiento patron;aprendizaje reforzado;algoritmo aprendizaje;red neuronal;neural network;knowledge engineering	This paper presents an original feature selection method for Emotion Recognition which includes many original elements. Feature selection has some merit regarding pattern recognition performance. Thus, we implemented a simulator called an 'IFS system' and the results of the IFS were applied to an emotion recognition system(ERS). Our innovative feature selection method was based on a Reinforcement Learning Algorithm and since it required responses from human users, it was denoted an 'Interactive Feature Selection'. By performing an IFS, we were able to obtain three top features and apply them to the ERS.	emotion recognition;feature selection	Chang-Hyun Park;Kwee-Bo Sim	2006		10.1007/11893011_31	feature;computer science;artificial intelligence;machine learning;knowledge engineering;feature selection;reinforcement learning;feature;artificial neural network	AI	10.77374153202447	-30.598920530428956	110935
21716fc1908a54c9989855561ed6ff77edf59e40	optimal experiment design for coevolutionary active learning	shannon information criterion optimal experiment design active learning competitive coevolution;random variables;regression analysis genetic algorithms iterative methods learning artificial intelligence;computational modeling;data models entropy predictive models computational modeling noise optimization random variables;passive machine learning baseline performance optimal experiment design coevolutionary active learning teacher learner type coevolution shannon information theory iterative coevolutionary framework symbolic regression model inference genetic algorithm complex symbolic expressions noise corruption local information content high dimensional systems concrete compression strength;predictive models;optimization;entropy;noise;data models	This paper presents a policy for selecting the most informative individuals in a teacher-learner type coevolution. We propose the use of the surprisal of the mean, based on Shannon information theory, which best disambiguates a collection of arbitrary and competing models based solely on their predictions. This policy is demonstrated within an iterative coevolutionary framework consisting of symbolic regression for model inference and a genetic algorithm for optimal experiment design. Complex symbolic expressions are reliably inferred using fewer than 32 observations. The policy requires 21% fewer experiments for model inference compared to the baselines and is particularly effective in the presence of noise corruption, local information content as well as high dimensional systems. Furthermore, the policy was applied in a real-world setting to model concrete compression strength, where it was able to achieve 96.1% of the passive machine learning baseline performance with only 16.6% of the data.	active learning (machine learning);approximation;baseline (configuration management);data point;design of experiments;experiment;genetic algorithm;information theory;iterative method;machine learning;optimal design;optimality criterion;s-expression;self-information;shannon (unit);symbolic regression;test bench;type inference	Daniel Le Ly;Hod Lipson	2014	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2013.2281529	random variable;data modeling;entropy;mathematical optimization;computer science;noise;artificial intelligence;theoretical computer science;machine learning;mathematics;predictive modelling;computational model;algorithm;statistics	ML	23.55411553681148	-27.934879175863028	111008
f8aef0f07f1a963e4eba195948aa8a62099d581e	accelerating event based simulation for multi-synapse spiking neural networks	event simulation;simulation ordinateur;modelizacion;sistema reactivo;modelisation;spiking neural network;sinapsis;technology and engineering;reactive system;systeme reactif;simulacion computadora;reseau neuronal;spiking neural networks;multi synapse model;modeling;computer simulation;red neuronal;neural network;synapse	The simulation of large spiking neural networks (SNN) is still a very time consuming task. Therefore most simulations are limited to rather unrealistic small or medium sized networks (typically hundreds of neurons). In this paper, some methods for the fast simulation of large SNN are discussed. Our results equally amongst others show that event based simulation is an efficient way of simulating SNN, although not all neuron models are suited for an event based approach. We compare some models and discuss several techniques for accelerating the simulation of more complex models. Finally we present an algorithm that is able to handle multi-synapse models efficiently.	algorithm;neural networks;neuron;simulation;spiking neural network;synapse	Michiel D'Haene;Benjamin Schrauwen;Dirk Stroobandt	2006		10.1007/11840817_79	simulation;systems modeling;reactive system;computer science;synapse;artificial intelligence;machine learning;spiking neural network	AI	17.840897506150643	-25.82994754849991	111017
5ed2c32ba7fc4cf9260d12a3ad5cd2ae0cca8ba7	active learning with logged data		Author(s): Yan, Songbai; Chaudhuri, Kamalika; Javidi, Tara | Abstract: We consider active learning with logged data, where labeled examples are drawn conditioned on a predetermined logging policy, and the goal is to learn a classifier on the entire population, not just conditioned on the logging policy. Prior work addresses this problem either when only logged data is available, or purely in a controlled random experimentation setting where the logged data is ignored. In this work, we combine both approaches to provide an algorithm that uses logged data to bootstrap and inform experimentation, thus achieving the best of both worlds. Our work is inspired by a connection between controlled random experimentation and active learning, and modifies existing disagreement-based active learning algorithms to exploit logged data.	active learning (machine learning);algorithm;booting;experiment;generalization error;ibm notes;importance sampling;loose coupling;machine learning;microsoft customer care framework;sampling (signal processing);social inequality	Songbai Yan;Kamalika Chaudhuri;Tara Javidi	2018			machine learning;active learning;artificial intelligence;logging;bootstrapping (electronics);computer science;classifier (linguistics);exploit;population	ML	22.28190461589724	-30.593611938305852	111142
642b8a0555887571a40b79b066cdce0fb6eca292	a neural network based method for classification of meteorological data	meteorologie;localization;fonction base radiale;meteorologia;localizacion;separability;classification;neural gas;transformation donnee;transformacion dato;localisation;separabilidad;radial basis function;data transformation;separabilite;reseau neuronal;funcion radial base;meteorology;clasificacion;red neuronal;neural network	A neural network based method for classification of meteorological data is proposed in the paper. The method consists of two phases. First, a non-linear projection of the data space is performed by means of radial basis functions. The neural gas algorithm is used for determining locations of the basis functions. Second, a nonlinearly projected data is allocated to different classes by means of a competitive network layer. Nonlinear data transformation was necessary for obtaining linear separability of 6 classes of the meteorological data defined in 8 dimensions.	artificial neural network	Kamil Kaminski;Wladyslaw Kaminski;Pawel Strumillo	2004		10.1007/978-3-540-24844-6_93	neural gas;radial basis function;internationalization and localization;biological classification;computer science;artificial intelligence;machine learning;mathematics;data transformation;artificial neural network;algorithm	ML	11.918187330551712	-30.254701965278752	111320
efe4ae5850e647e2472252f7c2a713d17ffb5530	an investigation of neural network classifiers with unequal misclassification costs and group sizes	modelizacion;sample size;aplicacion medical;neural networks;asymmetry;cout developpement;misclassification costs;enfermedad;disease;tamano muestra;development cost;dimension groupe;diagnostico;error sistematico;taille echantillon;hombre;thyroid disease;prise de decision;clasificador;neural network classifier;effet de groupe;asymetrie;classification;effet dimensionnel;group sizes;regime desequilibre;modelisation;classifier;bias;efecto grupal;size effect;human;regimen desequilibrado;classificateur;asimetria;medical application;group size;efecto dimensional;reseau neuronal;unbalanced conditions;toma decision;diagnosis;modeling;clasificacion;red neuronal;medical diagnosis;dimension grupo;maladie;erreur systematique;artificial neural network;homme;neural network;application medicale;diagnostic;group effect	Despite a larger number of successful applications of artificial neural networks for classification in business and other areas, published research has not considered the effects of misclassification costs and group sizes. Without the consideration of uneven misclassification costs, the classifier development will be compromised in minimizing the total misclassification errors. The use of this simplified model will not only result in poor decision capability when misclassification errors are significantly unequal, but also increase the model bias in favor of larger groups. This paper explores the issues of asymmetric misclassification costs and imbalanced group sizes through an application of neural networks to thyroid disease diagnosis. The results show that both asymmetric misclassification costs and imbalanced group sizes have significant effects on the neural network classification performance. In addition, we find that increasing the sample size and resampling are two effective approaches to counteract the problems.	artificial neural network	Jyhshyan Lan;Michael Y. Hu;B. Eddy Patuwo;Guoqiang Peter Zhang	2010	Decision Support Systems	10.1016/j.dss.2009.11.008	computer science;artificial intelligence;machine learning;medical diagnosis;artificial neural network;statistics	Web+IR	10.060829573908535	-33.22333658204881	111343
346952becc4523cae74073cc10ab94443f1cfceb	associative memories with multi-valued cellular neural networks and their application to disease diagnosis	nonlinear element;hopfield model;multivalued cnn model;diagnosis of disease;piecewise linear;piecewise linear techniques;multivalued piecewise linear function output characteristic;cellular neural network;hopfield neural nets;cellular neural nets;liver diseases;piecewise linear techniques cellular neural nets content addressable storage diseases hopfield neural nets medical diagnostic computing pattern classification;multivalued cellular neural network;interconnected neural network;multi valued cellular neural networks;computer experiment;matrix decomposition;pattern classification associative memory multivalued cellular neural network multivalued cnn model disease diagnosis problem interconnected neural network hopfield model multivalued piecewise linear function output characteristic nonlinear element computer experiment autoassociative recall;blood;associative memory cellular neural networks piecewise linear techniques design methodology neural networks hopfield neural networks liver diseases blood testing inspection;pattern classification;mathematical model;diseases;associative memory;autoassociative recall;classification accuracy;content addressable storage;medical diagnostic computing;diagnosis of disease multi valued cellular neural networks associative memory;neural network;disease diagnosis problem	Cellular neural networks (CNNs) are one type of interconnected neural network and differ from the well-known Hopfield model in that each cell has a piecewise linear output characteristic. In this paper, we present a multi-valued CNN model in which each nonlinear element consists of a multi-valued output function. The function is defined by a linear combination of piecewise linear functions. We conduct computer experiments of auto-associative recall to verify our multi-valued CNN's ability as an associative memory. In addition, we also apply our multivalued CNN to a disease diagnosis problem. The results obtained show that the multi-valued CNN improves classification accuracy by selecting the output level q properly. Moreover, these results also show that the multi-valued associative memory can expand both the flexibility of designing the memory pattern and its applicability.	artificial neural network;autoassociative memory;computer experiment;content-addressable memory;error detection and correction;hopfield network;linear function;nonlinear element;piecewise linear continuation;whole earth 'lectronic link	Takuma Akiduki;Zhong Zhang;Takashi Imamura;Tetsuo Miyake	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346618	cellular neural network;computer experiment;piecewise linear function;computer science;artificial intelligence;theoretical computer science;machine learning;mathematical model;bidirectional associative memory;matrix decomposition;artificial neural network	Robotics	15.92865313255753	-26.595934934156446	111409
768a054f6e144300d5a4664f005bedd466c9b24c	adaptive value function approximations in classifier systems	distributed representation;hyperplane coding;approximation error;reinforcement learning;classifier system;learning classifier systems;learning classifier system;optimal policy;function approximation;adaptive management;gradient descent;value function approximation;value function;resource availability;tile coding	"""Considerable attention has been paid to the issue of valuefunction approximation in the reinforcement learning literature[3]. One of the fundamental assumptions underlying algorithms forsolving reinforcement learning problems is that states andstate-action pairs have well-defined values that can beapproximated and used to help determine an optimal policy. Thequality of those approximations is a critical factor in determiningthe success of many algorithms in solving reinforcement learningproblems. In most classifier systems, the information about the valuefunction is stored and computed by individual rules. Each rulemaintains an independent estimate of the value of taking itsdesignated action in the states that match its condition. From thisstandpoint, each rule is treated as a separate functionapproximator. The quality of the approximations that can beachieved by simple estimates like this is not very good. Even whenthose estimates are pooled together to compute a more reliablecollective estimate, it is still questionable how good the overallapproximation will be. It is also not clear what the best way is toimprove the quality of those approximations. One approach to improving approximation quality is to increasethe computational abilities of individual rules so that they becomemore capable function approximators [4]. Another idea is to lookback to the original concepts underlying the classifier systemframework and seek to take advantage of the properties ofdistributed representations in classifier systems [2]. This paperfollows in the spirit of the latter approach, looking for ways totap the distributed representational power present in a collectionof rules to improve the quality of value functionapproximations. Previous work [1] introduced a new approach to value functionapproximation in classifier systems called <i>hyperplanecoding.</i> Hyperplane coding is a closely related variationof tile coding [3] in which classifier rule conditions fill therole of tiles, and there are few restrictions on the way those""""tiles"""" are organised. The basic idea is to treat rules as featuresthat collectively specify a linear gradient-descent functionapproximator. The hypothesis behind this idea is that classifierrules can be more effective as function approximators if they worktogether to implement a distributed, coarse-coded representation ofthe value function. Experiments with hyperplane coding have shown that by carefullyusing the resources available in a random population ofclassifiers, continuous value functions can be approximated with ahigh degree of accuracy. This approach computes much betterapproximations than more conventional classifier system methods inwhich individual rules compute approximations independently. Theresults to date also demonstrate that hyperplane coding can achievelevels of performance comparable to those achieved by morewellknown approaches to function approximation such as tile coding.High quality value function approximations that provide both datarecovery and generalisation are a critically important component ofmost approaches to solving reinforcement learning problems. Becausehyperplane coding substantially improves the quality of theapproximations that can be computed by a classifier system usingrelatively small populations of classifiers, it may provide thefoundation for significant improvements in classifier systemperformance. One open question remaining about hyperplane coding is how thequality of the approximation is affected by the set of classifiersin the population. A random population of classifiers is sufficientto obtain good results. Would a more carefully chosen population doeven better? The obvious next step in this research is to use theapproximation resources available in a random population as astarting point for a more refined approach to approximation thatreallocates resources adaptively to gain greater precision in thoseregions of the input space where it is needed. This paper shows howto compute such an adaptive function approximation. The goal islearn a population of classifiers that <i>reflects thestructure of the input space</i> (Dean &amp; Wellman,1991). This means more rules (ie. more tiles) should be used toapproximate regions which are sampled often and in which thefunction values vary a great deal. Fewer rules should be used inregions which are rarely sampled and in which the function isnearly constant. We discuss how to adaptively manage the space inthe population, as well as how to structure the search for tilesthat reduce the approximation error."""	ampersand;approximation algorithm;approximation error;attribute–value pair;bellman equation;gradient descent;learning classifier system;population;reinforcement learning	Lashon B. Booker	2005		10.1145/1102256.1102276	gradient descent;margin classifier;mathematical optimization;approximation error;function approximation;computer science;artificial intelligence;machine learning;mathematics;bellman equation;learning classifier system;reinforcement learning	ML	15.66711188624345	-35.35100447080266	111421
456a7d1e550a708b4a200acfacc8cf463cc12e6f	generalization error bound of semi-supervised learning with ℓ1 regularization in sum space		This paper proposes a semi-supervised algorithm for least square regularized regression problem with 1 regularizer in sum space of reproducing kernel Hilbert spaces (RKHSs). By the fact that the sum space has stronger approximation capability than a single hypothesis space and the unlabeled samples can improve the estimation of regression function, an excess error bound for this algorithm can be derived under some assumptions on the kernel, the input space, the marginal distribution, and the regression function. Under some mild conditions, the learning rate of our semi-supervised algorithm can attain l − with arbitrarily close to 1. © 2017 Elsevier B.V. All rights reserved.	algorithm;approximation;generalization error;hilbert space;marginal model;matrix regularization;offset binary;semi-supervised learning;semiconductor industry;supervised learning	Chao Liu;Di-Rong Chen	2018	Neurocomputing	10.1016/j.neucom.2017.10.020		AI	21.534903014116825	-33.37986491479188	111623
5b16651251f38a16f384a09214323a923ad5e196	training pattern replication and weighted class allocation in artificial neural network classification	teledetection;image recognition;analyse multivariable;reconocimiento imagen;feedforward;multivariate analysis;backpropagation neural network;radar abertura sintetica;image classification;logiciel neuraldesk ncs;etude methode;prior knowledge;backpropagation;estudio metodo;boucle anticipation;estimacion a priori;classification;discriminant analysis;analyse discriminante;a priori estimation;retropropagation;analisis discriminante;ciclo anticipacion;relative abundance;remote sensing;teledeteccion;reconnaissance image;estimation a priori;analisis multivariable;method study;reseau neuronal;classification accuracy;retropropagacion;radar ouverture synthetique;clasificacion;red neuronal;artificial neural network;neural network;synthetic aperture radar	In some image classifications the importance of classes varies, and it is desirable to weight allocation to selected classes. Often the desire is to weight allocation in favour of classes that are abundant in the area represented by an image at the expense of the less abundant classes. If there is prior knowledge on the distribution of class occurrence, this weighting can be achieved with widely used statistical classifiers by setting appropriate a prioriprobabilities of class membership. With an artificial neural network, the incorporation of prior knowledge is more problematic. An approach to weight class allocation in an artificial neural network classification by replicating selected training patterns is presented. This investigation focuses on a series of classifications in which some classes were more abundant than others, but the same number of training cases were available for each class. By replicating the training patterns of abundant classes the representation of the abundant classes in the training set is increased, reflecting more closely the relative abundance of the classes in an image. Significant increases in classification accuracy were obtained by replicating the training patterns of abundant classes. Furthermore, in comparison against a discriminant analysis for the classification of synthetic aperture radar imagery, the results showed that training pattern replication could be used to weight class allocation with an effect similar to that of incorporating a prioriprobabilities of class membership into the discriminant analysis, and resulted in a significant 20.88%, increase in classification accuracy. This increase in classification accuracy was obtained without any new information, but was the result of making fuller use of what was available.	artificial neural network;file allocation table;linear discriminant analysis;statistical classification;statistical model;synthetic intelligence;test set	Giles M. Foody	1995	Neural Computing & Applications	10.1007/BF01414080	relative species abundance;contextual image classification;synthetic aperture radar;biological classification;computer science;artificial intelligence;backpropagation;machine learning;classification rule;pattern recognition;multivariate analysis;one-class classification;feed forward;artificial neural network;statistics	ML	10.458416836784327	-33.055010974446056	111971
01637de8d1f80631a3560cef1beeefd2cfabe0cc	inlier-based outlier detection via direct density ratio estimation	probability density function;data mining;ratio estimator;outlier detection;data analysis;statistical analysis;density ratio;machine learning inlier based outlier detection direct density ratio estimation statistical approach semiparametric fashion high dimensional problem natural cross validation procedure regularization parameter kernel width closed form solution closed form formula leave one out error;importance outlier detection density ratio;learning artificial intelligence;statistical analysis data analysis learning artificial intelligence;importance;conferences	We propose a new statistical approach to the problem of inlier-based outlier detection, i.e.,finding outliers in the test set based on the training set consisting only of inliers. Our key idea is to use the ratio of training and test data densities as an outlier score; we estimate the ratio directly in a semi-parametric fashion without going through density estimation. Thus our approach is expected to have better performance in high-dimensional problems. Furthermore, the applied algorithm for density ratio estimation is equipped with a natural cross-validation procedure, allowing us to objectively optimize the value of tuning parameters such as the regularization parameter and the kernel width. The algorithm offers a closed-form solution as well as a closed-form formula for the leave-one-out error. Thanks to this, the proposed outlier detection method is computationally very efficient and is scalable to massive datasets. Simulations with benchmark and real-world datasets illustrate the usefulness of the proposed approach.	algorithm;anomaly detection;benchmark (computing);cross-validation (statistics);leave-one-out error;scalability;semiconductor industry;simulation;test data;test set	Shohei Hido;Yuta Tsuboi;Hisashi Kashima;Masashi Sugiyama;Takafumi Kanamori	2008	2008 Eighth IEEE International Conference on Data Mining	10.1109/ICDM.2008.49	ratio estimator;econometrics;probability density function;anomaly detection;outlier;computer science;machine learning;pattern recognition;data mining;mathematics;data analysis;statistics	ML	24.30466252140818	-37.48502331592021	112142
6b9b2eb31a8743c4a7a1c018648293d8a7630ebb	unsupervised networks, stochasticity and optimization in deep learning	g5 artikkelivaitoskirja		deep learning;stochastic process	Mathias Berglund	2017			unsupervised learning;artificial intelligence;machine learning;pattern recognition;competitive learning	ML	13.210081090832261	-27.952980775125823	112385
834faeeea25a2396aabb5b45a8ded8f4ee2eedb8	a novel approach to distributed multi-class svm		With data sizes constantly expanding, and with classical machine learning algorithms that analyze such data requiring larger and larger amounts of computation time and storage space, the need to distribute computation and memory requirements among several computers has become apparent. Although substantial work has been done in developing distributed binary SVM algorithms and multi-class SVM algorithms individually, the field of multi-class distributed SVMs remains largely unexplored. This research proposes a novel algorithm that implements the Support Vector Machine over a multi-class dataset and is efficient in a distributed environment (here, Hadoop). The idea is to divide the dataset into half recursively and thus compute the optimal Support Vector Machine for this half during the training phase, much like a divide and conquer approach. While testing, this structure has been effectively exploited to significantly reduce the prediction time. Our algorithm has shown better computation time during the prediction phase than the traditional sequential SVM methods (One vs. One, One vs. Rest) and out-performs them as the size of the dataset grows. This approach also classifies the data with higher accuracy than the traditional multiclass algorithms.	apache hadoop;approximation algorithm;computation;computer;machine learning;recursion;requirement;support vector machine;time complexity	Aruna Govada;Shree Ranjani;Aditi Viswanathan;Sanjay Kumar Sahay	2015	CoRR	10.14738/tmlai.25.562	computer science;theoretical computer science;machine learning;data mining	ML	13.382247269228788	-37.913472456601475	112395
cecc5059c1b23edd844ff1bc0458a836c7248088	consistency of multiclass empirical risk minimization methods based on convex loss	classification algorithm;rule based;empirical risk minimization;statistical learning theory;convex function;classification error;multiclass classification	The consistency of classification algorithm plays a central role in statistical learning theory. A consistent algorithm guarantees us that taking more samples essentially suffices to roughly reconstruct the unknown distribution. We consider the consistency of ERM scheme over classes of combinations of very simple rules (base classifiers) in multiclass classification. Our approach is, under some mild conditions, to establish a quantitative relationship between classification errors and convex risks. In comparison with the related previous work, the feature of our result is that the conditions are mainly expressed in terms of the differences between some values of the convex function.	algorithm;convex function;empirical risk minimization;machine learning;multiclass classification;statistical learning theory	Di-Rong Chen;Tao Sun	2006	Journal of Machine Learning Research		rule-based system;convex function;mathematical optimization;empirical risk minimization;computer science;machine learning;linear classifier;multiclass classification;classification rule;pattern recognition;mathematics;statistics	ML	19.47439582790361	-35.31347313073256	112455
e85a68602abf92fcc1efb8b7aa90d27d141a80c2	automatic pattern recognition: a study of the probability of error	fourier series classifiers;probability;fourier series;analisis estadistico;asymptotic optimality;probability of error;computerised pattern recognition;pattern recognition smoothing methods classification tree analysis testing nearest neighbor searches histograms binary trees fourier series error analysis probability;smoothing parameter;automatic recognition;estimation erreur;statistical analysis;binary tree classifiers;parameter selection;histogram rules;error estimation;nearest neighbor;analyse statistique;estimacion error;training sequence;pattern recognition;fourier series classifiers automatic pattern recognition error statistics artificial intelligence probability training sequence linear discriminators nearest neighbor rules kernel based rules histogram rules binary tree classifiers;probability artificial intelligence computerised pattern recognition error statistics;error statistics;artificial intelligence;k nearest neighbor;kernel based rules;nearest neighbor rules;automatic pattern recognition;error estimate;linear discriminators;vapnik chervonenkis;reconocimiento automatico;reconnaissance automatique;binary tree	A test sequence is used to select the best rule from a rich class of discrimination rules defined in terms of the training sequence . The Vapnik-Chervonenkis and related inequalities are used to obtain distribution-free bounds on the difference between the probability of error o€ the selected rule and the probability of error of the best rule in the given class . The bounds are used to prove the consistency and asymptotic optimality for several popular classes, including linear discriminators, nearest neighbor rules, kernel-based rules, histogram rules, binary tree classifiers, and Fourier series classifiers . In particular, the method can be used to choose the smoothing parameter in kernel-based rules, to choose k in the k-nearest neighbor rule, and to choose between parametric and nonparametric rules.	alexey chervonenkis;asymptotically optimal algorithm;binary tree;k-nearest neighbors algorithm;kernel (operating system);pattern recognition;smoothing	Luc Devroye	1988	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.3915	computer science;machine learning;pattern recognition;mathematics;k-nearest neighbors algorithm;statistics	ML	19.755359423119355	-34.554798761997155	112584
fd7dc7f2302e6736537443685bdf3c4c62de6fc5	neural dynamics with stochasticity	neural dynamics	Our interest is in computers called artificial neural networks. These consist of assemblies of simple processors, or “neurons”, each of which computes a scalar activation function of its input. The scalar value produced by a neuron is, in turn, broadcast to the successive neurons involved in a given computation. Some of the signals originate from outside the network and act as inputs to the entire system, while some of the output signals are communicated back to the environment and are thus used to encode the end result of the computation. These networks can be thought of either as functional units or as reactive systems, as they are able to both approximate input-output mappings and adapt to new environments. The networks are thus of great use as automatic learning tools and as adaptive and optimal controllers, e.g. in applications to vision, speech processing, robotics, signal processing, and many other fields (see [16],[45],[27],[38]). Herein we perceive neural nets as abstract functional devices able to perform exact computations rather than approximations only.	activation function;approximation algorithm;artificial neural network;central processing unit;computation;computer;encode;neuron;robotics;signal processing;speech processing;stochastic process	Hava T. Siegelmann	1997		10.1007/BFb0054004	complexity class;network architecture;data structure;computer science;artificial intelligence;machine learning;programming language;algorithm	ML	18.803870256026016	-24.191012613452124	112737
bae7ce95de43d6793270aa0464c32ecef69a4248	a convergence theory for deep learning via over-parameterization		Deep neural networks (DNNs) have demonstrated dominating performance in many fields; since AlexNet, the neural networks used in practice are going wider and deeper. On the theoretical side, a long line of works have been focusing on why we can train neural networks when there is only one hidden layer. The theory of multi-layer networks remains somewhat unsettled. In this work, we prove why simple algorithms such as stochastic gradient descent (SGD) can find global minima on the training objective of DNNs in polynomial time. We only make two assumptions: the inputs do not degenerate and the network is over-parameterized. The latter means the number of hidden neurons is sufficiently large: polynomial in L, the number of DNN layers and in n, the number of training samples. As concrete examples, on the training set and starting from randomly initialized weights, we show that SGD attains 100% accuracy in classification tasks, or minimizes regression loss in linear convergence speed ε ∝ e−Ω(T , with a number of iterations that only scales polynomial in n and L. Our theory applies to the widely-used but non-smooth ReLU activation, and to any smooth and possibly non-convex loss functions. In terms of network architectures, our theory at least applies to fully-connected neural networks, convolutional neural networks (CNN), and residual neural networks (ResNet). ∗V1 appears on arXiv on this date and no new result is added since then. V2 adds citations and V3 polishes writing and corrects some minor mistake. This work was done when Yuanzhi Li and Zhao Song were 2018 summer interns at Microsoft Research Redmond. When this work was performed, Yuanzhi Li was also affiliated with Princeton, and Zhao Song was also affiliated with UW and Harvard. We would like to specially thank Greg Yang for many enlightening discussions, thank Ofer Dekel, Sebastien Bubeck, and Harry Shum for very helpful conversations, and thank Jincheng Mei for carefully checking the proofs of this paper. ar X iv :1 81 1. 03 96 2v 3 [ cs .L G ] 2 9 N ov 2 01 8	algorithm;artificial neural network;convolutional neural network;deep learning;iteration;layer (electronics);long line (telecommunications);loss function;maxima and minima;microsoft research;polynomial;randomness;rate of convergence;rectifier (neural networks);stochastic gradient descent;test set;time complexity;yang	Zeyuan Allen-Zhu;Yuanzhi Li;Zhao Song	2018	CoRR			ML	21.948263486066377	-32.505148852037294	112801
e99fdd7e56e90c1072a82204f5d28f0b97c449bd	robust recursive least squares learning algorithm for principal component analysis	minimisation;robustness least squares methods principal component analysis signal processing algorithms convergence minimization methods data mining neurons algorithm design and analysis resonance light scattering;autoassociation recursive least squares learning algorithm principal component analysis minimization convergence hebbian rule oja rule neural networks;recursive least square;minimization;time varying;least squares approximations;learning rate;learning algorithm;convergence;neural networks;neural nets;convergence of numerical methods;direction of arrival;resonance light scattering;recursive least squares;minimization methods;indexing terms;data mining;oja rule;input output;principal component analysis;normal weight;least square;autoassociation;hebbian rule;robustness;neurons;least squares approximations neural nets principal component analysis learning artificial intelligence convergence of numerical methods minimisation;learning artificial intelligence;signal processing algorithms;principal com ponent analysis;algorithm design and analysis;least squares methods;neural network;principal component	A learning algorithm for the principal component analysis is developed based on the least-square minimization. The dual learning rate parameters are adjusted adaptively to make the proposed algorithm capable of fast convergence and high accuracy for extracting all principal components. The proposed algorithm is robust to the error accumulation existing in the sequential principal component analysis (PCA) algorithm. We show that all information needed for PCA can be completely represented by the unnormalized weight vector which is updated based only on the corresponding neuron input-output product. The updating of the normalized weight vector can be referred to as a leaky Hebb's rule. The convergence of the proposed algorithm is briefly analyzed. We also establish the relation between Oja's rule and the least squares learning rule. Finally, the simulation results are given to illustrate the effectiveness of this algorithm for PCA and tracking time-varying directions-of-arrival.	algorithm;convergence (action);dual;erkki oja;learning rule;neuron;oja's rule;principal component analysis;recursion;recursive least squares filter;simulation;tree accumulation	Shan Ouyang;Zheng Bao;Guisheng Liao	2000	IEEE transactions on neural networks	10.1109/72.822524	mathematical optimization;non-linear iterative partial least squares;ramer–douglas–peucker algorithm;computer science;machine learning;pattern recognition;oja's rule;mathematics;fsa-red algorithm;generalized hebbian algorithm;artificial neural network;statistics;principal component analysis;population-based incremental learning	ML	15.811814294834248	-28.887324173708933	112827
6a77401ee98f15d9e63e848c09dd70ebca373c49	training convolutional networks with weight-wise adaptive learning rates		Current state–of–the–art Deep Learning classification with Convolutional Neural Networks achieves very impressive results, which are, in some cases, close to human level performance. However, training these methods to their optimal performance requires very long training periods, usually by applying the Stochastic Gradient Descent method. We show that by applying more modern methods, which involve adapting a different learning rate for each weight rather than using a single, global, learning rate for the entire network, we are able to reach close to state–of–the–art performance on the same architectures, and improve the training time and accuracy.	convolutional neural network;deep learning;neural network software;stochastic gradient descent	Alan Mosca;George D. Magoulas	2017				ML	17.371516234876445	-32.435897022905195	112922
8823ea9fe521258d78e09584ab9f8d5b8d05cfcd	considerations of sample and feature size	sample size;multivariate normal distribution;probability distribution;pattern classification;common knowledge;error rate;practice pattern	In many practical pattern-classification problems the underlying probability distributions are not completely known. Consequently, the classification logic must be determined on the basis of vector samples gathered for each class. Although it is common knowledge that the error rate on the design set is a biased estimate of the true error rate of the classifier, the amount of bias as a function of sample size per class and feature size has been an open question. In this paper, the design-set error rate for a two-class problem with multivariate normal distributions is derived as a function of the sample size per class (N) and dimensionality (L). The design-set error rate is compared to both the corresponding Bayes error rate and the test-set error rate. It is demonstrated that the design-set error rate is an extremely biased estimate of either the Bayes or test-set error rate if the ratio of samples per class to dimensions (N/L) is less than three. Also the variance of the design-set error rate is approximated by a function that is bounded by Ij8N. I N MANY practical pattern-recognition problems, the underlying class conditional probability densities are either partially or completely unknown. Consequently, the classification logic must be designed from information based on representative samples from each class. The difficult question of how many samples are needed for an adequate classifier design naturally arises and has received some attention. The deleterious effects of inadequate sample size have been discussed in the past. For multivariate normal distributions with common covariance, John [l] and Sitgreaves [2] discuss the distribution of the Fisher linear discriminant.l Estes [3] shows that the error rate using the Fisher linear discriminant deviates severely from the theoretical optimum when the ratio of sample size (N) to feature2 size (L) is small. For the related problem of linear prediction, assuming normal statistics, Allais [4] derives a comparable result. Hughes [S) and Abend et al. [6] show that the average probability of correct classification over all possible discrete class distributions deteriorates as the ratio of samples to measurement states decreases. Ullman [7] has reported a similar phenomenon occurring in his experiments in the numeric handprint character-recognition problem. All of these results pertain to the expected performance of a classifier on future test samples when the classifier has been designed using a design set of finite size. Manuscript received January 27, 1971,; revised January I?, 1972. This paper is part of a dissertation submitted to Syracuse University, Syracuse, N.Y., in partial fulfillment of the requirements for the Ph.D. degree. The author was with the Rome Air Development Center, Griffiss Air-Force Base, Rome, N.Y. He is now with Pattern Analysis and Recognition, Inc., Rome, N.Y., and with the Department of Systems and Information Sciences, Syracuse University, Syracuse, N.Y. 1 The Fisher linear discriminant d is Z-l@-, &) where Z, jil, and jiZ are the estimated common covariance and the estimated means of class 1 and 2. 2 In the literature, the terms feature, measurement, variable, and dimensionality are used interchangeably. A number of people have noticed that the error rate on the design set gives an optimistically biased estimate of the true performance or error rate of the classifier. Hills [8] showed for multivariate normal distributions that the expected value of the estimated error rate of a classifier that was designed and tested on the same data (i.e., the design set) is always less than the true error rate. Lachenbruch and Mickey [9], Lachenbruch [lo], and Fukunaga [I I] have experimentally verified this result. Cover [12] has derived some results, which may be interpreted as follows: regardless of the true performance of a two-class classifier, if the total number of samples is less than twice the number of features, there exists a linear hyperplane such that the probability of error on the design set is always zero.3 Kanal and Chandrasekaran [13] have considered two questions. 1) What is the best way to design a classification system and evaluate its performance given a fixed sample size? 2) When a finite number of samples is available, how many features should be used? In answering the first question, Kanal recommends the “hold-one-out” method originally proposed by Lachenbruch [IO]. In this method, a classifier is designed on N 1 samples and tested on the one remaining sample. This procedure is then repeated for all N samples. In answering the second question, Kanal [l 31 points out that the number of features that can be used for a fixed sample size depends upon the probability structure assumed for the problem. Generally speaking, the greater the knowledge of the underlying probability structure, the greater the number of features that can be used without degrading the performance of the classifier. In this paper, the error rate on the design set as a function of the number of samples per class (N) and the number of features (L) is derived and related to both the true error rate of the classifier and the Bayes error rate for the corresponding minimum-probability-of-error classifier. The underlying probability structure consists of a) a two-class problem with equal a priori probabilities; b) a cost of 1 for any error and zero for any correct decision; c) N independent and identically distributed samples for each class from two multivariate normal distributions with common covariance. The emphasis on the design set is for two reasons. First, although a number of authors have noted that the error rate on the design set is a biased estimate of the true error rate of the classifier, the amount of the bias as a function of sample size per class (N) and feature size (L) has been an open question until now. Secondly, in some problems the 3 Actually, Cover [12] shows that the design-set error rate cd is zero when (2N/L) < I and that Ed rapidly approaches zero when (2N/L) -c 2 and L increases without bound. Also note that Cover refers to the total number of samples in a two-class problem. This is equivalent to 2N in this paper since N is the sample size per class. FOLEY: SAMPLE AND FEATURE SIZE 619 hold-one-out method of estimating the error rate of a classifier is too time consuming. Consequently, the data must be divided into a design set and a test set. Unfortunately, this makes poor use of the data since a classifier designed on the entire data set will on the average perform better than a classifier designed on only a portion of the data. Therefore, if a designer is satisfied with the test-set results, he would normally recombine the two data sets and redesign the classifier based on all the samples. Although this makes better use of the data for design purposes, the evaluation of the performance must be based only on design-set results. Consequently, knowledge of both the amount of the bias and the relationship between the design estimate and true performance is required. EXPERIMENTAL ILLUSTRATION In this section, some new experimental results point out a statistical trap involved in using the error rate on the design set 8, as a measure of the true performance of the classifier when the ratio of the sample size per class (N) to feature size (L) is small. In addition, the average error rate on the design set is computed for a number of experimental runs. The results indicate that the ratio of the sample size to feature size (N/L) can be related to the amount of bias between the error rates on the design and test sets. Suppose that a researcher has selected L features that hopefully contain enough information to allow two classes to be reasonably distinguished. N representative samples are gathered from each class. One possible classification procedure would be to orthogonally project the samples from the two classes onto the optimal discriminant plane4 [14]. Next, the researcher could attempt to construct a piecewise linear boundary in the discriminant plane that would separate the samples from the two classes. In one particular experiment, ten samples for each of two classes were randomly generated from their twenty eightdimensional class-conditional distributions. The OLPARS 5 system [15] was used to project the samples onto the discriminant plane, shown in Fig. 1. It is obvious that a linear boundary will separate the two classes perfectly. Consequently, on the basis of these results, a researcher might conclude that he had selected a useful set of features and an excellent decision rule for this particular problem. However, in this experiment the samples for these two classes were generated from identical uniform distributions! In effect, a class has been perfectly distinguished from itself. This contradiction glaringly illustrates the deceiving results on the design set when the ratio N/L is small. The results are deceiving in this case since the true error rate (assuming equal a priori probabilities) for any classifier without reject regions is 0.5. This “statistical trap” may have been the source of some exaggerated claims in the past. These results are compatible with Cover’s results [ 121 since the ratio of the total number of samples to features (2N/L) is less than two. Fig. 2 shows the resulting discriminant plane when a larger ratio of sample size to feature size is used. No matter what linear boundary is drawn in this plane, the resulting error rate on the design set will give a more realistic indication of the true error rate. Since it is only hypothesized by the designer that he has selected a useful set of features, the example is not unreasonable. For instance, in a signal-recognition problem, the first L discrete power spectrum coefficients may be selected as features. If the difference between the two classes lies in higher frequencies than represented by the Lth coefficient, then the two class-conditional densities are iden	abnormal end;approximation algorithm;bit error rate;emoticon;experiment;fingerprint;handwriting recognition;input/output;linear discriminant analysis;mickey;matthews correlation coefficient;pattern language;pattern recognition;piecewise linear continuation;procedural generation;requirement;sethi–ullman algorithm;spectral density;statistical classification;test set	Donald H. Foley	1972	IEEE Trans. Information Theory	10.1109/TIT.1972.1054863	probability distribution;sample size determination;sampling error;econometrics;multivariate normal distribution;margin of error;word error rate;coverage error;probability of error;error bar;round-off error;pattern recognition;bayes error rate;mathematics;error exponent;common knowledge;statistics	ML	14.543576950674977	-35.737585375036474	112945
adeb96a704371371d4e54b1d7747b42b09d6eb65	a class of type-2 fuzzy neural networks for nonlinear dynamical system identification		This paper presents the ability of the interval type-2 Takagi–Sugeno–Kang fuzzy neural networks (IT2-TSK-FNN) for nonlinear dynamical system identification. The proposed IT2-TSK-FNN has seven layers. The first two layers consist of type-2 fuzzy neurons with uncertainty in the mean of Gaussian membership functions. Third layer is rule layer. Type-reduction is done in fourth layer. In the fifth, sixth, and seventh layers, consequent left–right firing points, two end points, and output are evaluated, respectively. In this paper, gradient descent with adaptive learning rate backpropagation is used in learning phase. IT2-TSK-FNN is used for the identification of three nonlinear systems, and then results are compared with adaptive-network-based fuzzy inference system (ANFIS).	adaptive neuro fuzzy inference system;artificial neural network;backpropagation;communication endpoint;dynamical system;fuzzy control system;fuzzy logic;gradient descent;inference engine;neuro-fuzzy;nonlinear system;simulation;system identification	Jafar Tavoosi;Mohammad Ali Badamchizadeh	2012	Neural Computing and Applications	10.1007/s00521-012-0981-7	adaptive neuro fuzzy inference system;fuzzy classification;fuzzy number;neuro-fuzzy;machine learning;control theory;mathematics	ML	14.267202630925544	-27.579695981052087	113092
9f00d66392d1a7ed388ee55d53eebe5b3381e36e	probably approximately metric-fair learning		We study fairness in machine learning. A learning algorithm, given a training set drawn from an underlying population, learns a classifier that will be used to make decisions about individuals. The concern is that this classifieru0027s decisions might be discriminatory, favoring certain subpopulations over others. The seminal work of Dwork et al. [ITCS 2012] introduced fairness through awareness, positing that a fair classifier should treat similar individuals similarly. Similarity between individuals is measured by a task-specific similarity metric. In the context of machine learning, however, this fairness notion faces serious difficulties, as it does not generalize and can be computationally intractable. rnWe introduce a relaxed notion of approximate metric-fairness, which allows a small fairness error: for a random pair of individuals sampled from the population, with all but a small probability of error, if they are similar then they are treated similarly. In particular, this provides discrimination-protections to every subpopulation that is not too small. We show that approximate metric-fairness does generalize from a training set to the underlying population, and we leverage these generalization guarantees to construct polynomial-time learning algorithms that achieve competitive accuracy subject to fairness constraints.		Guy N. Rothblum;Gal Yona	2018			leverage (finance);probability of error;machine learning;artificial intelligence;classifier (linguistics);computer science;training set;population	Theory	19.115384356103224	-34.987660201343985	113105
0a91832df36f7dd029646059e7090fa4b29b8bca	an rkhs for multi-view learning and manifold co-regularization	multi-view semi-supervised kernel method;reproducing kernel;rademacher complexity;algorithmic scope;kernel method;algorithmic alternative;chosen function;single rkhs;semi-supervised task;multi-view learning;manifold co-regularization;rkhs formulation	"""Inspired by co-training, many multi-view semi-supervised kernel methods implement the following idea: find a function in each of multiple Reproducing Kernel Hilbert Spaces (RKHSs) such that (a) the chosen functions make similar predictions on unlabeled examples, and (b) the average prediction given by the chosen functions performs well on labeled examples. In this paper, we construct a single RKHS with a data-dependent """"co-regularization"""" norm that reduces these approaches to standard supervised learning. The reproducing kernel for this RKHS can be explicitly derived and plugged into any kernel method, greatly extending the theoretical and algorithmic scope of coregularization. In particular, with this development, the Rademacher complexity bound for co-regularization given in (Rosenberg & Bartlett, 2007) follows easily from wellknown results. Furthermore, more refined bounds given by localized Rademacher complexity can also be easily applied. We propose a co-regularization based algorithmic alternative to manifold regularization (Belkin et al., 2006; Sindhwani et al., 2005a) that leads to major empirical improvements on semi-supervised tasks. Unlike the recently proposed transductive approach of (Yu et al., 2008), our RKHS formulation is truly semi-supervised and naturally extends to unseen test data."""	bartlett's bisection theorem;co-training;data dependency;emoticon;hilbert space;kernel method;manifold regularization;matrix regularization;rademacher complexity;semi-supervised learning;semiconductor industry;spaces;supervised learning;test data;window function	Vikas Sindhwani;David S. Rosenberg	2008		10.1145/1390156.1390279	mathematical optimization;combinatorics;machine learning;reproducing kernel hilbert space;mathematics;statistics	ML	22.018385746822858	-34.22194563606515	113113
12ada269364200877d18479946a1915151c47784	maintaining chaos in an associative chaotic neural network exhibiting intermittency	associative memory;intelligent networks;maintenance engineering;bifurcation;neural nets;neural networks;control systems	The paper presents an attempt to maintain chaos in an associative chaotic neural network, which exhibits intermittency without control. The network to be controlled is composed of 16 chaotic neurons with synaptic weights that are determined by a conventional auto-associative matrix to store three orthogonal patterns. The network shows intermittency with certain parameter values without control. In this paper, the network with the intermittency is controlled in order to maintain chaos in the network. The control is applied only when the state vector comes to the neighborhood of the point just before it falls into the laminar phase. Perturbations are applied so that the state vector may not fall into the laminar phase. An example of maintaining chaos with the control is shown in the paper.	artificial neural network;chaos theory;quantum state;synaptic package manager;synaptic weight	Masaharu Adachi	2004	2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No.04CH37512)		computer science;artificial intelligence;machine learning;control theory;synchronization of chaos;artificial neural network	Arch	15.370225431358708	-26.613918975138805	113136
5799253024a2c8d4ea08a6062c01d2ef0a866e07	lcd: a fast contrastive divergence based algorithm for restricted boltzmann machine	acceleration;contrastive divergence;rbm	Restricted Boltzmann Machine (RBM) is the building block of Deep Belief Nets and other deep learning tools. Fast learning and prediction are both essential for practical usage of RBM-based machine learning techniques. This paper proposes Lean Contrastive Divergence (LCD), a modified Contrastive Divergence (CD) algorithm, to accelerate RBM learning and prediction without changing the results. LCD avoids most of the required computations with two optimization techniques. The first is called bounds-based filtering, which, through triangle inequality, replaces expensive calculations of many vector dot products with fast bounds calculations. The second is delta product, which effectively detects and avoids many repeated calculations in the core operation of RBM, Gibbs Sampling. The optimizations are applicable to both the standard contrastive divergence learning algorithm and its variations. In addition, this paper presents how to implement these optimizations effectively on massively parallel processors. Results show that the optimizations can produce several-fold (up to 3X for training and 5.3X for prediction) speedups.	algorithm;central processing unit;computation;deep learning;gibbs sampling;machine learning;mathematical optimization;parallel computing;restricted boltzmann machine;social inequality	Lin Ning;Randall Pittman;Xipeng Shen	2018	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2018.08.018	mathematical optimization;massively parallel;mathematics;filter (signal processing);deep learning;dot product;divergence;algorithm;triangle inequality;artificial intelligence;gibbs sampling;restricted boltzmann machine	ML	24.167303076364412	-31.050622198421536	113446
75249a19783692a4ddf97973713c5c7661486c19	conditions under which conditional independence and scoring methods lead to identical selection of bayesian network models	cross entropy;conditional independence;bayesian network;conditional independence test;structural learning;scoring metric;bayesian networks	It is often stated in papers tackling the task of selecting a Bayesian network structure from data that there are these two distinct approaches: (i) Apply conditional indepen­ dence tests . when testing for the presence or otherwise of edges; (ii) Search the model space using a scoring metric. Here I argue that for complete data and a given node ordering this division is largely a myth, by showing that cross entropy methods for checking conditional independence are mathematically identical to methods based upon discriminating between models by their overall goodness-of-fit logarithmic scores.	bayesian network;conditional entropy;cross entropy	Robert G. Cowell	2001			variable-order bayesian network;computer science;conditional variance;machine learning;pattern recognition;bayesian network;mathematics;statistics	AI	16.976432956724754	-37.1164817844651	113476
659bdb26b62640233166a1f2a266ce8a624a9a83	hybrid neural network and genetic algorithm based machining feature recognition	feature recognition;hybrid approach;computational complexity;genetic algorithm;network architecture;neural network	In this research, neural networks (NNs) and genetic algorithms (GAs) are used together in a hybrid approach to reduce the computational complexity of feature recognition problem. The proposed approach combines the characteristics of evolutionary technique and NN to overcome the shortcomings of feature recognition problem. Consideration is given to reduce the computational complexity of network with specific interest to design the optimum network architecture using GA input selection approach. In order to evaluate the performance of the proposed system, experimental results are compared with previous NN based feature recognition research.	artificial neural network;feature recognition;genetic algorithm;hybrid neural network	Nursel Öztürk;Ferruh Öztürk	2004	J. Intelligent Manufacturing	10.1023/B:JIMS.0000026567.63397.d5	neural gas;feature recognition;network architecture;genetic algorithm;feature;computer science;artificial intelligence;machine learning;pattern recognition;time delay neural network;computational complexity theory;artificial neural network	Robotics	13.98404470385959	-24.70110357412769	113487
08c2b7bf302fea22341e9a36e9ce8e9bcbf6aed9	feature vector regression with efficient hyperparameters tuning and geometric interpretation	hyperparameters tuning;feature vector regression;regression;computational complexity;feature vector selection;kernel method;prediction	Machine learning methods employing positive kernels have been developed and widely used for classification, regression, prediction and unsupervised learning applications, whereby the estimate function takes the form of a weighted-sum kernel expansion. Unacceptable computational burden with large datasets and difficulty in tuning hyperparameters are usually the drawbacks of kernel methods. In order to reduce the computational burden, this paper presents a modified version of the Feature Vector Selection (FVS) method, proposing an approximation of the estimate function as a weighted sum of the predicted values of the Feature Vectors (FVs), where the weights are computed as the oblique projections of the new data points on the FVs in the feature space. Such approximation is, then, obtained by optimizing only the predicted values of the FVs. By defining a least square error optimization problem with equal constraints, analytic solutions of the predicted values of the FVs can be obtained. The proposed method is named Feature Vector Regression (FVR). The tuning of hyperparameters in FVR is also explained in the paper and shown to be less complicated than for other kernel methods. Comparisons with some other popular kernel methods for regression on several public datasets show that FVR, with a small subset of the training dataset (i.e. selected FVs), gives results comparable with those of the methods which give best results in terms of the prediction accuracy. The main contribution of this paper is the new kernel method (i.e. FVR), capable of achieving satisfactory results with reduced efforts because of the small number of hyperparameters to be tuned and the reduced training dataset size used. & 2016 Elsevier B.V. All rights reserved.	approximation;benchmark (computing);data point;fastest;feature vector;kernel (operating system);kernel method;machine learning;mathematical optimization;oblique projection;optimization problem;performance tuning;unsupervised learning;weight function	Jie Liu;Enrico Zio	2016	Neurocomputing	10.1016/j.neucom.2016.08.093	kernel method;regression;prediction;computer science;machine learning;pattern recognition;mathematics;computational complexity theory;statistics	ML	21.58406109842261	-37.96111679550879	113619
83d5e9e590946b94a787c353c8d5a4904ae3b95a	supervised learning extensions to the clam network	unsupervised learning;bhattacharyya distance;linear order;automatic node generation;memoire associative;learning;supervised learning;probabilidad condicional;probabilite conditionnelle;alutomatic node generation;conditional probabilities;association mapping;classification;algorithme;aprendizaje;linear order training;algorithm;bhattacharyya;apprentissage;hierarchical classification;red multinivel;analyse performance;associative mapping;performance analysis;associative memory;memoria asociativa;multilayer network;reseau multicouche;reseau neuronal;conditional probability;clasificacion;red neuronal;distance;neural network;algoritmo;analisis eficacia	The contextual layered associative memory (CLAM) has been developed as a self-generating structure which implements a probabilistic encoding scheme. The training algorithms are geared towards the unsupervised generation of a layerable associative mapping ([Thacker and Mayhew, 1989]). We show here that the resulting structure will support layers which can be trained to produce outputs that approximate conditional probabilities of classification. Unsupervised and supervised learning algorithms operate independently permitting the unsupervised representational layer to be developed before supervision is available. The system thus supports learning which is inherently more flexible than conventional node labelling schemes. Copyright 1997 Elsevier Science Ltd. All Rights Reserved.	anatomic node;approximation algorithm;content-addressable memory;copyright;digital rights management;line code;machine learning;memory disorders;representation (action);self-organization;supervised learning;unsupervised learning;anatomical layer	Neil A. Thacker;Ian Abraham;Patrick Courtney	1997	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(96)00074-3	unsupervised learning;bhattacharyya distance;conditional probability;computer science;artificial intelligence;machine learning;supervised learning;artificial neural network;algorithm	AI	10.869104386534675	-30.335685931795922	113638
b705c5d0dea0061958840433deb394001bef87e6	the decrease of fuzzy label number using self-organization competition network	self organization		self-organization	Shuang Cong;Gang Wu;Guodong Li	1998			machine learning;mathematics;fuzzy logic;artificial intelligence;self-organization	ML	11.309460185956972	-27.2736856549793	114042
8f880afbfea328c496d1ab96a123bb57d4b506b5	a systematic dnn weight pruning framework using alternating direction method of multipliers		Weight pruning methods for deep neural networks (DNNs) have been investigated recently, but prior work in this area is mainly heuristic, iterative pruning, thereby lacking guarantees on the weight reduction ratio and convergence time. To mitigate these limitations, we present a systematic weight pruning framework of DNNs using the alternating direction method of multipliers (ADMM). We first formulate the weight pruning problem of DNNs as a nonconvex optimization problem with combinatorial constraints specifying the sparsity requirements, and then adopt the ADMM framework for systematic weight pruning. By using ADMM, the original nonconvex optimization problem is decomposed into two subproblems that are solved iteratively. One of these subproblems can be solved using stochastic gradient descent, the other can be solved analytically. Besides, our method achieves a fast convergence rate. The weight pruning results are very promising and consistently outperform the prior work. On the LeNet-5 model for the MNIST data set, we achieve 71.2× weight reduction without accuracy loss. On the AlexNet model for the ImageNet data set, we achieve 21× weight reduction without accuracy loss. When we focus on the convolutional layer pruning for computation reductions, we can reduce the total computation by five times compared with the prior work (achieving a total of 13.4× weight reduction in convolutional layers). Our models and codes are released at https://github.com/KaiqiZhang/admm-pruning.		Tianyun Zhang;Shaokai Ye;Kaiqi Zhang;Jian Tang;Wujie Wen;Makan Fardad;Yanzhi Wang	2018		10.1007/978-3-030-01237-3_12	pruning;computer science;mathematical optimization;rate of convergence;artificial intelligence;machine learning;artificial neural network;stochastic gradient descent;heuristic;convergence (routing);optimization problem	AI	23.516413555366118	-33.95718424730023	114278
af30bcbf9b39cf078873ae3352b9c47997dd4462	local discriminative learning for pattern recognition	recursive partitioning;feature space;feature relevance;input output;discrimination learning;pattern classification;pattern recognition;discriminative learning;statistical pattern classification;local learning	Local discriminative learning methods approximate a target function (a posteriori class probability function) directly by partitioning the feature space into a set of local regions, and appropriately modeling a simple input}output relationship (function) in each one. This paper presents a new method for judiciously partitioning the input feature space in order to accurately represent the target function. The method accomplishes this by approximating not only the target function itself but also its derivatives. As such, the method partitions the input feature space along those dimensions for which the class probability function changes most rapidly, thus minimizing bias. The e$cacy of the method is validated using a variety of simulated and real-world data. ( 2000 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	approximation algorithm;computation;experiment;feature vector;machine learning;norm (social);pattern recognition;relevance;simulation	Jing Peng;Bir Bhanu	2001	Pattern Recognition	10.1016/S0031-3203(99)00209-5	input/output;feature learning;feature vector;feature;computer science;machine learning;pattern recognition;data mining;mathematics;k-nearest neighbors algorithm;feature;discriminative model;discrimination learning;recursive partitioning	Vision	15.528411121167991	-34.036640125011765	114367
b31f7ee650604bae63bd7eb5b243be98ca14403a	an all-at-once unimodal svm approach for ordinal classification	support vector machines generalisation artificial intelligence pattern classification;kernel;support vector machines;error analysis;artificial neural networks;generalisation;machine learning;generalisation all at once unimodal svm approach ordinal classification support vector machine;all at once unimodal svm approach;pattern classification;optimization;support vector machines kernel optimization machine learning error analysis context artificial neural networks;generalisation artificial intelligence;support vector machine;context;ordinal classification	Support vector machines (SVMs) were initially proposed to solve problems with two classes. Despite the myriad of schemes for multiclassification with SVMs proposed since then, little work has been done for the case where the classes are ordered. Usually one constructs a nominal classifier and a posteriori defines the order. The definition of an ordinal classifier leads to a better generalisation. Moreover, most of the techniques presented so far in the literature can generate ambiguous regions. All-at-Once methods have been proposed to solve this issue. In this work we devise a new SVM methodology based on the unimodal paradigm with the All-at-Once scheme for the ordinal classification.	ambiguity function;ambiguous grammar;analysis of algorithms;computation;experiment;iterative method;kendall tau distance;level of measurement;mathematical optimization;multiclass classification;nominal type system;ordinal data;performance;programming paradigm;statistical classification;support vector machine;synthetic intelligence	Joaquim F. Pinto da Costa;Ricardo Gamelas Sousa;Jaime S. Cardoso	2010	2010 Ninth International Conference on Machine Learning and Applications	10.1109/ICMLA.2010.16	support vector machine;computer science;machine learning;pattern recognition;data mining;mathematics;artificial neural network	DB	20.32284611074166	-35.49706339086203	114482
6ce713ae11e323b79ccdf1eaec47d82aef8dfdf7	research on parallelization of knn locally weighted linear regression algorithm based on mapreduce			automatic parallelization;k-nearest neighbors algorithm;mapreduce;parallel computing	Tao Xue;Ting-ting Li;Bingshuai Sun	2015	JCM	10.12720/jcm.10.11.864-869	machine learning;pattern recognition;data mining	DB	12.517030036993814	-36.938693047567064	114499
baa64f2aaa7547217b5efc8591f204f745ab35c1	distributed, event driven simulation of spiking neural networks	network topology;spiking neural network	We present the architecture of a simulator that is able to simulate large networks of spiking neurons using a distributed event driven simulation. Contrary to a time driven simulation, which is usually used to simulate spiking neural networks, our simulation needs less computational resources because of the low average activity of typical networks. The simulator is divided into a set of communicating sub-simulators running concurrently on several workstations, where each sub-simulator handles a part of the network. The paper addresses the problems of synchronisation between the sub-simulators and how information contained in the network topology and properties of neuron models are used to solve them. Preliminary results are presented for two simple model networks illustrating the speed up gained by a distribution of the simulation.	algorithm;artificial neural network;computation;computational resource;logic simulation;network topology;neuron;scalability;simulation;speedup;spiking neural network;workstation	Cyprian Grassmann;Joachim K. Anlauf	1998			artificial intelligence;machine learning;mathematics;codi;types of artificial neural networks;spiking neural network;physical neural network;network topology;random neural network;time delay neural network	Metrics	17.902027159341074	-25.57178631343776	114518
0451f9d1a79c4fc4594e5a9fb7abbf5405bab08e	combinative neural network and its applications	nonlinear approximation;partial least squares pls analysis;feed forward;neural networks nn;partial least square;combinative neural network cn;pattern classification;neural network	A new approach named combinative neural network (CN) using partial least squares (PLS) analysis to modify the hidden layer in the multi-layered feed forward (MLFF) neural networks (NN) was proposed in this paper. The significant contributions of PLS in the proposed CN are to reorganize the outputs of hidden nodes such that the correlation of variables could be circumvented, to make the network meet the non-linear relationship best between the input and output data of the NN, and to eliminate the risk of over-fitting problem at the same time. The performance of the proposed approach was demonstrated through two examples, a well defined nonlinear approximation problem, and a practical nonlinear pattern classification problem with unknown relationship between the input and output data. The results were compared with those by conventional MLFF NNs. Good performance and time-saving implementation make the proposed method an attractive approach for non-linear mapping and classification.	approximation algorithm;artificial neural network;biological neural networks;computation (action);epilepsies, partial;input/output;mathematics;name;natural science disciplines;neural network simulation;nonlinear system;numerous;overfitting;papillon-lefevre disease;partial least squares regression;sensor;statistical classification;anatomical layer	Yaqiu Chen;Shangxu Hu;Dezhao Chen	2003	Computational biology and chemistry	10.1016/S0097-8485(02)00072-4	computer science;artificial intelligence;machine learning;pattern recognition;feed forward;artificial neural network	ML	14.797198022486965	-28.331810206631804	114599
999548f40956410961fe2c5454774bcb6297463b	robust ν-support vector machine based on worst-case conditional value-at-risk minimization	97r40;conditional value at risk;kernel methods;conditional expectation;90c20;ν support vector machine;kernel method;90c15;support vector machine;robust programming	By minimizing the conditional expectation of random loss in the 1 − β worst case, the performance of the ν-support vector machine (SVM) severely depends on its assumption on the underlying distribution. This paper proposes a robust ν-SVM based on worst-case conditional value-at-risk (WCCVaR) minimization, which assumes that the underlying distribution comes from a certain set of potential distributions and minimizes the maximum CVaR associated with these distributions. The problem can be transformed into a quadratic programme and handle nonlinear classification problems. Experiments on six data sets clearly show that the robust approach can achieve superior results than the ν-SVM.	algorithm;best, worst and average case;cvar;duality (optimization);experiment;interior point method;kernel method;nonlinear programming;nonlinear system;value at risk	Yongqiao Wang	2012	Optimization Methods and Software	10.1080/10556788.2011.614608	conditional probability distribution;kernel regression;kernel method;mathematical optimization;machine learning;pattern recognition;mathematics;relevance vector machine;structured support vector machine	ML	21.705113049520964	-36.19259788499121	114603
bf0638d96e3bc09dc4d5764b349d131610401485	information theoretic competitive learning in self-adaptive multi-layered networks	multi layered networks;feature detection;donnee iris;apprentissage competitif;aplicacion medical;analisis datos;intelligence artificielle;line detection;competitive learning;detection caracteristique;data analysis;iris data;red multinivel;phonology;maximisation information;feature extraction;information maximization;artificial intelligence;analyse donnee;fonologia;medical application;phonologie;inteligencia artificial;multilayer network;extraction caracteristique;reseau multicouche;reseau neuronal;cumulant;information theoretic;red neuronal;neural network;application medicale	In this paper, we propose self-adaptive multi-layered networks in which information in each processing layer is always maximized. Using these multi-layered networks, we can solve complex problems and discover salient features that single-layered networks fail to extract. In addition, this successive information maximization enables networks gradually to extract important features. We applied the new method to the Iris data problem, the vertical–horizontal lines detection problem, a phonological data analysis problem and a medical data problem. Experimental results confirmed that information can repeatedly be maximized in multi-layered networks and that the networks can extract features that cannot be detected by single-layered networks. In addition, features extracted in successive layers are cumulatively combined to detect more macroscopic features.	competitive learning;emoticon;expectation–maximization algorithm;experiment;nl (complexity);numerical aperture;semantic network;sensor;theory;tom	Ryotaro Kamimura	2003	Connect. Sci.	10.1080/0954009031000090749	speech recognition;feature extraction;iris flower data set;computer science;artificial intelligence;machine learning;feature detection;competitive learning;data analysis;artificial neural network;phonology;cumulant	ML	11.581408003554458	-31.933381323986794	114764
a10ec7cc6c42c7780ef631c038b16c49ed865038	optimization and applications of echo state networks with leaky- integrator neurons	vitesse;velocity;optimisation;entrada salida;optimizacion;learning;stochastic method;metodo descenso;activation function;taux erreur;japonais;gradient method;gauchissement;funcion actividad;pattern generation;optimum global;optimization method;velocidad;time series;global optimum;proceso adquisicion;metodo optimizacion;effet dimensionnel;acquisition process;vocal;dynamical system;input output;aprendizaje;systeme dynamique;methode gradient;apprentissage;gradient bajada;retroaccion;speaker classification;retroaction;metodo gradiente;gradient descent;fonction activation;integrator;size effect;integrador;serie temporelle;torcimiento;descente gradient;estimacion parametro;methode optimisation;feedback regulation;serie temporal;error rate;methode stochastique;voyelle;optimization;recurrent neural networks;parameter estimation;estimation parametre;efecto dimensional;sistema dinamico;descent method;indice error;vowel;optimo global;japones;processus acquisition;warping;methode descente;integrateur;entree sortie;japanese;metodo estocastico	Standard echo state networks (ESNs) are built from simple additive units with a sigmoid activation function. Here we investigate ESNs whose reservoir units are leaky integrator units. Units of this type have individual state dynamics, which can be exploited in various ways to accommodate the network to the temporal characteristics of a learning task. We present stability conditions, introduce and investigate a stochastic gradient descent method for the optimization of the global learning parameters (input and output feedback scalings, leaking rate, spectral radius) and demonstrate the usefulness of leaky-integrator ESNs for (i) learning very slow dynamic systems and replaying the learnt system at different speeds, (ii) classifying relatively slow and noisy time series (the Japanese Vowel dataset--here we obtain a zero test error rate), and (iii) recognizing strongly time-warped dynamic patterns.	activation function;algorithmic efficiency;approximation;arabic numeral 0;block cipher mode of operation;brain;classification;computational neuroscience;dynamical system;echo state network;euler method;gesture recognition;humans;image scaling;input/output;leaky bucket;mathematical optimization;neuron;neuroscience discipline;nonlinear system;random neural network;rendering (computer graphics);reservoir device component;sigmoid colon;sigmoid function;silo (dataset);stochastic gradient descent;time series;utility functions on indivisible goods;velocity (software development)	Herbert Jaeger;Mantas Lukosevicius;Dan Popovici;Udo Siewert	2007	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2007.04.016	gradient descent;japanese;integrator;computer science;gradient method;artificial intelligence;dynamical system;machine learning;calculus;time series;mathematics;global optimum;velocity;activation function;algorithm	ML	18.889680995687048	-24.797054767077064	114861
9924ee7b74327f0bae9769e25e46d1d5864f5354	support vector machines for company failure prediction	financial data processing;learning algorithm;neural networks;support vector machines;neural nets learning automata learning artificial intelligence financial data processing construction industry statistical analysis;neural nets;construction companies;construction industry;learning automata;statistical model;company failure prediction;power engineering and energy;failure analysis;artificial neural networks;linear statistical models;ear;neural network models support vector machines company failure prediction learning algorithm construction companies svm linear statistical models;statistical analysis;machine learning;support vector machines neural networks failure analysis predictive models artificial neural networks costs computer science power engineering and energy ear machine learning;predictive models;neural network models;svm;computer science;support vector machine;neural network model;learning artificial intelligence;neural network;failure prediction	This paper applies support vector machines (SM), a new powerful learning algorithm, to company failure prediction based on 2048 UK construction companies. The study shows that the SVM model outperforms linear statistical models and other neural network models.	support vector machine	Zheng Rong Yang	2003		10.1109/CIFER.2003.1196241	support vector machine;computer science;artificial intelligence;machine learning;data mining;artificial neural network	NLP	11.924235934498931	-25.225396330226804	114872
55d88cd54912e4988180196e0f1f711fb0d3358d	entropy-based pruning for learning bayesian networks using bic		For decomposable score-based structure learning of Bayesian networks, existing approaches first compute a collection of candidate parent sets for each variable and then optimize over this collection by choosing one parent set for each variable without creating directed cycles while maximizing the total score. We target the task of constructing the collection of candidate parent sets when the score of choice is the Bayesian Information Criterion (BIC). We provide new non-trivial results that can be used to prune the search space of candidate parent sets of each node. We analyze how these new results relate to previous ideas in the literature both theoretically and empirically. We show in experiments with UCI data sets that gains can be significant. Since the new pruning rules are easy to implement and have low computational costs, they can be promptly integrated into all state-ofthe-art methods for structure learning of Bayesian networks.	algorithmic efficiency;bayesian information criterion;bayesian network;computation;experiment;f1 score;solver	Cassio Polpo de Campos;Mauro Scanagatta;Giorgio Corani;Marco Zaffalon	2018	Artif. Intell.	10.1016/j.artint.2018.04.002	machine learning;pruning;mathematics;bayesian network;bayesian information criterion;artificial intelligence;data set;pattern recognition	ML	17.534819477851922	-36.697191182273855	115077
1ce512c9897e46c692c9fcd69b9664a68264a5e1	using neural networks to model conditional multivariate densities	time dependent;probabilidad condicional;ley n variables;funcion densidad probabilidad;probability density function;probabilite conditionnelle;fonction densite probabilite;multivariate distribution;reseau neuronal;loi n variables;conditional probability;statistical distribution;red neuronal;conditional distribution;multivariate data;neural network	Neural network outputs are interpreted as parameters of statistical distributions. This allows us to fit conditional distributions in which the parameters depend on the inputs to the network. We exploit this in modeling multivariate data, including the univariate case, in which there may be input-dependent (e.g., time-dependent) correlations between output components. This provides a novel way of modeling conditional correlation that extends existing techniques for determining input-dependent (local) error bars.	artificial neural network;neural network simulation;neural tube defects;neural network software;statistical distributions;density	P. M. Williams	1996	Neural Computation	10.1162/neco.1996.8.4.843	probability distribution;conditional probability distribution;econometrics;multivariate statistics;multivariate normal distribution;probability density function;conditional probability;conditional variance;machine learning;mathematics;artificial neural network;statistics	ML	22.010019983537095	-26.081101843435707	115194
ff19816d81a78128e3767c7352566500613e6a27	an application of hamiltonian neurodynamics using pontryagin's maximum (minimum) principle		Classical optimal control methods, notably Pontryagin's Maximum (Minimum) Principle (PMP) can be employed, together with Hamiltonians, to determine optimal system weights in Artificial Neural dynamical systems. A new learning rule based on weight equations derived using PMP is shown to be suitable for both discrete- and continuous-time systems, and moreover, can also be applied to feedback networks. Preliminary testing shows that this PMP learning rule compares favorably with Standard BackPropagations (SBP) on the XOR problem.	dynamical system;hamiltonian (quantum mechanics);learning rule;neural oscillation;optimal control;pontryagin's maximum principle;sbp;weight;xor;promegapoietin	Takamasa Koshizen;John Fulcher	1995	International journal of neural systems	10.1142/S0129065795000287	mathematical optimization;hamiltonian;machine learning;calculus;control theory;mathematics	ML	18.026451640743584	-26.800803563162006	115210
d4e3c8f38d625f0c1815eedc337526f333217eaa	self-organizing feature maps with self-adjusting learning parameters	learning artificial intelligence kalman filters nonlinear filters self organising feature maps filtering theory;kalman filtering;nonlinear filters;carte electronique;topology;filtering;learning algorithm;convergence;filtrage kalman;etude theorique;system modeling;numerical method;helium;convergence of numerical methods;kalman filters;topologie;institut fur flugfuhrung;linear kalman filters;indexing terms;topologia;neurons organizing filtering parameter estimation topology clustering methods predictive models convergence of numerical methods kalman filters;convergencia;extended kalman filters;self adjusting learning parameters;metodo numerico;self organising feature maps;organizing;self organizing feature maps;linear kalman filters self organizing feature maps self adjusting learning parameters convergence neighborhood preserving maps learning algorithm extended kalman filters;self organized feature map;neighborhood preserving maps;tarjeta electronica;estudio teorico;estimacion parametro;autoorganizacion;self organization;predictive models;printed circuit board;neurons;parameter estimation;estimation parametre;theoretical study;learning artificial intelligence;extended kalman filter;clustering methods;filtrado kalman;autoorganisation;methode numerique;filtering theory	This paper presents an extension of the self-organizing learning algorithm of feature maps in order to improve its convergence to neighborhood preserving maps. The Kohonen learning algorithm is controlled by two learning parameters, which have to be chosen empirically because there exists neither rules nor a method for their calculation. Consequently, often time consuming parameter studies have to precede before a neighborhood preserving feature map is obtained. To circumvent those lengthy numerical studies, here, a method is presented and incorporated into the learning algorithm which determines the learning parameters automatically. Therefore, system models of the learning and organizing process are developed in order to be followed and predicted by linear and extended Kalman filters. The learning parameters are optimal within the system models, so that the self-organizing process converges automatically to a neighborhood preserving feature map of the learning data.	algorithm;convergence (action);extended kalman filter;map;numerical analysis;organizing (structure);population parameter;rule (guideline);self-organization;teuvo kohonen	Karin Haese	1998	IEEE transactions on neural networks	10.1109/72.728376	semi-supervised learning;unsupervised learning;kalman filter;feature learning;computer vision;instance-based learning;self-organizing map;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;leabra;stability;competitive learning;active learning;feature;generalization error	ML	16.241627970437374	-28.6498458416661	115397
8983469ed13e2daeb6584864e8565171b6bf14c2	learning vine copula models for synthetic data generation		A vine copula model is a flexible high-dimensional dependence model which uses only bivariate building blocks. However, the number of possible configurations of a vine copula grows exponentially as the number of variables increases, making model selection a major challenge in development. In this work, we formulate a vine structure learning problem with both vector and reinforcement learning representation. We use neural network to find the embeddings for the best possible vine model and generate a structure. Throughout experiments on synthetic and real-world datasets, we show that our proposed approach fits the data better in terms of loglikelihood. Moreover, we demonstrate that the model is able to generate high-quality samples in a variety of applications, making it a good candidate for synthetic data generation.		Yi Sun;Alfredo Cuesta-Infante;Kalyan Veeramachaneni	2018	CoRR		artificial intelligence;bivariate analysis;vine;artificial neural network;vine copula;reinforcement learning;model selection;machine learning;computer science;synthetic data	ML	24.044702079344194	-30.310169094218793	115643
401e30f9ecc149add6ecec3574c3fa1963c6d511	beyond graphs: a new synthesis	terminal graph;network inference;complex networks;network synthesis;neural networks;complex network;t graph;gene network;gene networks;computational method;network representation;social network;evolutionary robotics;graph;terminal graph t graph;biological network;artificial neural network;neural network	Artificial neural networks, electronic circuits, and gene networks are some examples of systems that can be modeled as networks, that is, as collections of interconnected nodes. In this paper we introduce the concept of the terminal graph (t-graph for short), which improves on the concept of graph as a unifying principle for the representation, computational synthesis, and inference of technological and biological networks. We begin by showing how to use the t-graph concept to better understand the working of existing methods for the computational synthesis of networks. Then, we discuss the issue of the “missing methods”, that is, of new computational methods of network synthesis whose existence can be inferred using the perspective provided by the concept of t-graph. Finally, we comment on the application of the t-graph perspective to problems of network inference, to the field of complex networks, social networks, and to the understanding of biological networks and developmental processes. © 2011 Elsevier B.V. All rights reserved.	artificial neural network;biological network;complex network;computation;electronic circuit;gene regulatory network;graph (abstract data type);network synthesis filters;social network	Claudio Mattiussi;Peter Dürr;Daniel Marbach;Dario Floreano	2011	J. Comput. Science	10.1016/j.jocs.2011.01.007	network science;gene regulatory network;evolving networks;computer science;artificial intelligence;theoretical computer science;machine learning;geometric networks;artificial neural network;complex network	AI	16.05740724689312	-26.34148851361705	115682
deb42cdcbd0bd94a83b62f0ddfaee35849223158	globally optimal gradient descent for a convnet with gaussian inputs		Deep learning models are often successfully trained using gradient descent, despite the worst case hardness of the underlying non-convex optimization problem. The key question is then under what conditions can one prove that optimization will succeed. Here we provide a strong result of this kind. We consider a neural net with one hidden layer and a convolutional structure with no overlap, and a ReLU activation function. For this architecture we show that learning is NP-complete in the general case, but that when the input distribution is Gaussian, gradient descent converges to the global optimum in polynomial time. To the best of our knowledge, this is the first global optimality guarantee of gradient descent on a convolutional neural network with ReLU activations.	activation function;artificial neural network;best, worst and average case;convex optimization;convolutional neural network;deep learning;global optimization;gradient descent;mathematical optimization;np-completeness;optimization problem;polynomial;rectifier (neural networks);time complexity	Alon Brutzkus;Amir Globerson	2017			gradient descent;mathematical optimization;delta rule;backpropagation;machine learning;mathematics;stochastic gradient descent;algorithm	ML	21.598749170495292	-32.28461275950624	115793
185525dd90e0e3c6cfdf2df4ceffe8ea7222f9ce	choosing in support vector regression with different noise models: theory and experiments	generalization error;asymptotic efficiency;neural nets;support vector regression;neural nets support vector regression noise models sv regression generalization error asymptotic efficiency learning;predictive models constraint optimization kernel statistical learning australia machine learning pattern recognition testing error correction lagrangian functions;statistical analysis neural nets learning artificial intelligence generalisation artificial intelligence;support vector;statistical analysis;generalisation artificial intelligence;learning artificial intelligence;model theory	In support vector (SV) regression, a parameter /spl nu/ controls the number of support vectors and the number of points that come to lie outside of the so-called /spl epsi/-insensitive tube. For various noise models and SV parameter settings, we experimentally determine the values of /spl nu/ that lead to the lowest generalization error. We find good agreement with the values that had previously been predicted by a theoretical argument based on the asymptotic efficiency of a simplified model of SV regression.	experiment;support vector machine	Athanassia Chalimourda;Bernhard Schölkopf;Alexander J. Smola	2000		10.1109/IJCNN.2000.861457	support vector machine;computer science;machine learning;pattern recognition;mathematics;artificial neural network;statistics;generalization error	ML	15.859587977405026	-32.939797148451916	115842
f6f1ee01d41c363d62b966840419b668c0b222d1	constant rate approximate maximum margin algorithms	learning rate;ucl;discovery;theses;conference proceedings;intelligence artificielle;classification a vaste marge;digital web resources;ucl discovery;open access;artificial intelligence;ucl library;inteligencia artificial;book chapters;open access repository;maquina ejemplo soporte;vector support machine;perceptron;reseau neuronal;red neuronal;neural network;ucl research	We present a new class of perceptron-like algorithms with margin in which the “effective” learning rate, defined as the ratio of the learning rate to the length of the weight vector, remains constant. We prove that the new algorithms converge in a finite number of steps and show that there exists a limit of the parameters involved in which convergence leads to classification with maximum margin.	approximation algorithm;converge;perceptron	Petroula Tsampouka;John Shawe-Taylor	2006		10.1007/11871842_42	computer science;artificial intelligence;perceptron;machine learning;data mining;database;operations research;artificial neural network;algorithm	ML	19.854091853907946	-30.468005157655437	115848
979d950a0b9f8d7f90967c956e98eb8e2f53ef66	monitoring the formation of kernel-based topographic maps in a hybrid som-kmer model	self organising feature maps learning artificial intelligence maximum entropy methods;maximum entropy methods;metodo entropia maxima;hybrid som kmer model;carte topographique;methode noyau;kernel based topographic map;kernel based maximum entropy learning rule kernel based topographic maps hybrid som kmer model lattice disentangling monitoring algorithm self organizing map;topographic map;carte autoorganisatrice;monitoring entropy prototypes lattices acceleration data visualization neural networks network topology surface topography data mining;kernel based topographic maps;self organizing map som;self organising feature maps;metodo nucleo;self organizing map;kernel based maximum entropy learning rule kmer;topological defect;algorithms artificial intelligence cluster analysis computing methodologies information storage and retrieval neural networks computer pattern recognition automated;kernel method;self organized map;lattice disentangling;learning artificial intelligence;reseau neuronal;self organizing map som kernel based maximum entropy learning rule kmer kernel based topographic map lattice disentangling;methode entropie maximum;kernel based maximum entropy learning rule;lattice disentangling monitoring algorithm;method of maximum entropy;red neuronal;maximum entropy;plano topografico;neural network	A new lattice disentangling monitoring algorithm for a hybrid self-organizing map-kernel-based maximum entropy learning rule (SOM-kMER) model is proposed. It aims to overcome topological defects owing to a rapid decrease of the neighborhood range over the finite running time in topographic map formation. The empirical results demonstrate that the proposed approach is able to accelerate the formation of a topographic map and, at the same time, to simplify the monitoring procedure	algorithm;anatomy, regional;biologic preservation;burst mode clock and data recovery;computer cooling;kernel;kernel (operating system);learning rule;microtubule-associated proteins;normal statistical distribution;organizing (structure);radio frequency;self-organization;self-organizing map;software bug;subject reduction;test set;time complexity;topography	Chee Siong Teh;Chee Peng Lim	2006	IEEE Transactions on Neural Networks	10.1109/TNN.2006.877536	kernel method;topographic map;generative topographic map;self-organizing map;computer science;artificial intelligence;principle of maximum entropy;machine learning;pattern recognition;mathematics;topological defect;artificial neural network	ML	12.802408348884645	-31.801121033075386	115874
ac3b3918dc095e6f51c042c8cd8ee792fcb0a79d	recurrent classifier based on an incremental metacognitive-based scaffolding algorithm	complexity theory;online learning meta cognitive learning evolving neuro fuzzy system evolving fuzzy system;training;delamination;annotation effort incremental metacognitive based scaffolding algorithm metacognitive based scaffolding classifier recurrent classifier rclass human learning what to learn recurrent network takagi sugeno kang fuzzy system rule layer local feedback active learning based conflict measure when to learn learning scenario how to learn module schema concepts cognitive psychology learning principles single pass local learning modes plug and play learning foundation statistical tests rule base burden computational load;journal article;chebyshev approximation delamination training complexity theory merging vectors covariance matrices;vectors;recurrent neural nets fuzzy systems learning artificial intelligence pattern classification;covariance matrices;merging;chebyshev approximation	This paper outlines our proposal for a novel metacognitive-based scaffolding classifier, namely recurrent classifier (rClass). rClass is capable of emulating three fundamental pillars of human learning in terms of what-to-learn, how-to-learn, and when-to-learn. The cognitive constituent of rClass is underpinned by a recurrent network based on a generalized version of the Takagi-Sugeno-Kang fuzzy system possessing a local feedback of the rule layer. The main basis of the what-to-learn component relies on the new active learning-based conflict measure. Meanwhile, the when-to-learn learning scenario makes use of the standard sample reserved strategy. The how-to-learn module actualizes the Schema and Scaffolding concepts of cognitive psychology. All learning principles are committed in the single-pass local learning modes and create a plug-and-play learning foundation minimizing additional pre- or post-training phases. The efficacy of rClass has been scrutinized by means of rigorous empirical studies, statistical tests, and benchmarks with state-of-the-art classifiers, which demonstrate the rClass potency in producing reliable classification rates, while retaining low complexity in terms of the rule base burden, computational load, and annotation effort.	algorithm;emulator;fuzzy control system;plug and play;recurrent neural network;rule-based system	Mahardhika Pratama;Sreenatha G. Anavatti;Jie Lu	2015	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2015.2402683	semi-supervised learning;error-driven learning;algorithmic learning theory;simulation;computer science;artificial intelligence;machine learning;mathematics;learning classifier system;stability;computational learning theory;delamination;active learning;approximation theory;generalization error	ML	16.315489000014406	-34.67264812175853	115892
bfe3404b09d3746b4927d8bbb659a49367526021	efficiency analysis of parallel batch pattern nn training algorithm on general-purpose supercomputer	parallel algorithm;parallelization efficiency;multilayer perceptron;batch pattern training;parallel computer;efficiency analysis;back propagation;training algorithm;neural network	The theoretic and algorithmic description of the parallel batch pattern back propagation (BP) training algorithm of multilayer perceptron is presented in this paper. The efficiency research of the developed parallel algorithm is fulfilled at progressive increasing of the dimension of parallelized problem on general-purpose parallel computer NEC TX-7.	algorithm;general-purpose markup language;supercomputer	Volodymyr Turchenko;Lucio Grandinetti	2009		10.1007/978-3-642-02481-8_31	computer science;backpropagation;theoretical computer science;machine learning;distributed computing;parallel algorithm;multilayer perceptron;artificial neural network;cost efficiency	HPC	13.924463726130712	-26.56781607726463	115946
fbfbba4fb276b1f43a4d448f5308ae611f3c292d	open problem: improper learning of mixtures of gaussians		We ask whether there exists an efficient unsupervised learning algorithm for mixture of Gaussians in the over-complete case (number of mixtures is larger than the dimension). The notion of learning is taken to be worst-case compression-based, to allow for improper learning.	algorithm;best, worst and average case;mixture model;unsupervised learning	Elad Hazan;Roi Livni	2018			machine learning;artificial intelligence;open problem;computer science	ML	19.809776916305207	-33.47839048778141	116006
a2f30c2a06f1a4d29e84d3ff0edbc17452d3f0eb	extending learning classifier system with cyclic graphs for scalability on complex, large-scale boolean problems	learning classifier systems;genetic programming;xcs;finite state machines;pattern recognition;scalability	Evolutionary computational techniques have had limited capabilities in solving large-scale problems, due to the large search space demanding large memory and much longer training time. Recently work has begun on automously reusing learnt building blocks of knowledge to scale from low dimensional problems to large-scale ones. An XCS-based classifier system has been shown to be scalable, through the addition of tree-like code fragments, to a limit beyond standard learning classifier systems. Self-modifying cartesian genetic programming (SMCGP) can provide general solutions to a number of problems, but the obtained solutions for large-scale problems are not easily interpretable. A limitation in both techniques is the lack of a cyclic representation, which is inherent in finite state machines. Hence this work introduces a state-machine based encoding scheme into scalable XCS, for the first time, in an attempt to develop a general scalable classifier system producing easily interpretable classifier rules. The proposed system has been tested on four different Boolean problem domains, i.e. even-parity, majority-on, carry, and multiplexer problems. The proposed approach outperformed standard XCS in three of the four problem domains. In addition, the evolved machines provide general solutions to the even-parity and carry problems that are easily interpretable as compared with the solutions obtained using SMCGP.	boolean algebra;boolean satisfiability problem;finite-state machine;genetic programming;learning classifier system;line code;multiplexer;parity bit;problem domain;scalability	Muhammad Iqbal;Will N. Browne;Mengjie Zhang	2013		10.1145/2463372.2463500	genetic programming;mathematical optimization;scalability;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;finite-state machine;algorithm	ML	15.81005418698523	-24.136987106357928	116075
5a714e9e1081aff0c5d312616892ab621f0c4ab6	periodic step-size adaptation in second-order gradient descent for single-pass on-line structured learning	second order;jacobian matrix;structure learning;modelizacion;optimisation;matrice jacobi;learning algorithm;high dimensionality;optimizacion;sequence labeling;probabilidad condicional;convolution;on line;en linea;probabilite conditionnelle;internal structure;convolucion;multidimensional analysis;algorithme apprentissage;conditional random fields;fonction perte;funcion perdida;feature space;stochastic gradient descent;modelisation;classification a vaste marge;jacobi matrix;large scale;inverse matrix;gradient bajada;analyse n dimensionnelle;gradient descent;loss function;matriz jacobi;matrice inverse;structure prediction;descente gradient;analisis n dimensional;conditional random field;en ligne;optimization;estructura interna;support vector machine;convolutional neural networks;maquina ejemplo soporte;vector support machine;reseau neuronal;algoritmo aprendizaje;modeling;conditional probability;matriz inversa;matrice hessienne;structure interne;red neuronal;on line learning;hessian matrices;neural network	It has been established that the second-order stochastic gradient descent (SGD) method can potentially achieve generalization performance as well as empirical optimum in a single pass through the training examples. However, second-order SGD requires computing the inverse of the Hessian matrix of the loss function, which is prohibitively expensive for structured prediction problems that usually involve a very high dimensional feature space. This paper presents a new second-order SGD method, called Periodic Step-size Adaptation (PSA). PSA approximates the Jacobian matrix of the mapping function and explores a linear relation between the Jacobian and Hessian to approximate the Hessian, which is proved to be simpler and more effective than directly approximating Hessian in an on-line setting. We tested PSA on a wide variety of models and tasks, including large scale sequence labeling tasks using conditional random fields and large scale classification tasks using linear support vector machines and convolutional neural networks. Experimental results show that single-pass performance of PSA is always very close to empirical optimum.	approximation algorithm;artificial neural network;bioinformatics;conditional random field;convolutional neural network;feature vector;hessian;iteration;jacobian matrix and determinant;kernel method;loss function;online and offline;polar surface area;sequence labeling;stochastic gradient descent;structured prediction;support vector machine;test set	Chun-Nan Hsu;Han-Shen Huang;Yu-Ming Chang;Yuh-Jye Lee	2009	Machine Learning	10.1007/s10994-009-5142-6	jacobian matrix and determinant;combinatorics;quasi-newton method;computer science;machine learning;mathematics;convolutional neural network;conditional random field;artificial neural network;algorithm	ML	19.81848915852445	-31.26895398566648	116153
5898719c4098c8afeb41a0753c0cda657e6a09ca	an empirical study of hoeffding racing for model selection in k-nearest neighbor classification	modelizacion;model selection;empirical study;learning algorithm;confidence level;methode empirique;intervalo confianza;incertidumbre;780101 mathematical sciences;uncertainty;metodo empirico;empirical method;intelligence artificielle;algorithme apprentissage;theory methods;classification;modelisation;vecino mas cercano;confidence interval;machine learning;intervalle confiance;performance model;plus proche voisin;artificial intelligence;nearest neighbour;k nearest neighbor;incertitude;inteligencia artificial;computer science;algoritmo aprendizaje;modeling;clasificacion;280212 neural networks genetic alogrithms and fuzzy logic;optimization model	Racing algorithms have recently been proposed as a general-purpose method for performing model selection in machine learning algorithms. In this paper, we present an empirical study of the Hoeffding racing algorithm for selecting the k parameter in a simple k-nearest neighbor classifier. Fifteen widely-used classification datasets from UCI are used and experiments conducted across different confidence levels for racing. The results reveal a significant amount of sensitivity of the k-nn classifier to its model parameter value. The Hoeffding racing algorithm also varies widely in its performance, in terms of the computational savings gained over an exhaustive evaluation. While in some cases the savings gained are quite small, the racing algorithm proved to be highly robust to the possibility of erroneously eliminating the optimal models. All results were strongly dependent on the datasets used.	computation;experiment;general-purpose modeling;genetic algorithm;k-nearest neighbors algorithm;lazy evaluation;learning classifier system;machine learning;model selection;nearest neighbour algorithm;optimal design;selection algorithm;spatial variability;transponder timing	Flora Yu-Hui Yeh;Marcus Gallagher	2005		10.1007/11508069_29	confidence interval;computer science;artificial intelligence;machine learning;data mining;empirical research;statistics	ML	10.761928091585643	-32.73577056570101	116389
2a70843e3275aff8120cb258c2ebe85eb3d66544	iterative parameter estimate with batched binary-valued observations	binary valued observation maximum likelihood estimate strongly convex system identication exponential rate;期刊论文;binary valued observation maximum likelihood estimate strongly convex system identification exponential rate	In this paper, we consider linear system identification with batched binary-valued observations. We constructed an iterative parameter estimate algorithm to achieve the maximum likelihood (ML) estimate. The first interesting result was that there exists at most one finite ML solution for this specific maximum likelihood problem, which was induced by the fact that the Hessian matrix of the log-likelihood function was negative definite under binary data and Gaussian system noises. The global concave property and local strongly concave property of the log-likelihood function were obtained. Under mild conditions on the system input, we proved that the ML function has a unique maximum point. The second main result was that the ML estimate was consistent under persistent excitation inputs, which infers the effectiveness of ML estimate. Finally, the proposed iterative estimate algorithm converged to a fixed vector with an exponential rate that was proved by constructing a Lyapunov function. A more interesting result was that the limit of the iterative algorithm achieved the maximization of the ML function. Numerical simulations are illustrated to support the theoretical results obtained in this paper well. 针对给定二值观测样本数据的参数辨识问题, 我们构造了一种迭代算法并进行了相关的理论研究。 首先, 找出了一个似然函数存在极大值点的充分必要条件, 并通过计算对数似然函数的 Hessian 矩阵, 证明了该问题最多只有一个极大似然估计点。 然后, 通过构建Lyapunov函数, 证明了在持续激励条件下, 该迭代算法能达到指数收敛速度, 而且迭代的极限点就是似然函数唯一的最大值点, 这说明了迭代算法具有极强的稳健性。	binary data;concave function;expectation–maximization algorithm;hessian;iterative method;linear system;lyapunov fractal;numerical linear algebra;simulation;system identification;time complexity	Yanlong Zhao;Wenjian Bi;Ting Wang	2015	Science China Information Sciences	10.1007/s11432-015-5304-z	econometrics;mathematical optimization;mathematics;quasi-maximum likelihood;statistics	ML	22.380607795735536	-31.196234350233876	116566
c721374b47879b3bacb81f8e3baa264530090dbc	fault tolerant training algorithm for multi-layer neural networks focused on hidden unit activities	fault tolerance neural networks multi layer neural network large scale integration minimization methods artificial neural networks proposals acceleration indium tin oxide hardware;fault tolerant;neural nets;fault tolerance;learning artificial intelligence;neural nets fault tolerance learning artificial intelligence;training algorithm;weight minimization algorithm fault tolerant training algorithm multi layer neural networks hidden unit activities;neural network	We propose a new training algorithm that en- hances fault tolerance of multi-layer neural networks (MLNs). Faults mean physical defects or noise in MLNs. Some studies on fault tolerance pointed out that faults on the connections that connected to an output unit bring worse damage than other faults, and proposed training algorithms that enhance fault tolerance of MLNs based on this idea. In this paper, we reveal that it is not always true. Based on this idea, we improved our previous method (weight minimization algorithm).	algorithm;artificial neural network;layer (electronics)	Haruhiko Takase;Hidehiko Kita;Terumine Hayashi	2006		10.1109/IJCNN.2006.246616	fault tolerance;real-time computing;computer science;artificial intelligence;machine learning;time delay neural network;artificial neural network	ML	15.54045612764309	-26.39712331867597	116801
d85a11b046f1e0247d71972d8147581bf05713fa	an initialization method for feedforward artificial neural networks using polynomial bases	neural networks;neurocomputing;function approximation;weight initialization;mathematical modeling;polynomial bases	We propose an initialization method for feedforward artificial neural networks (FFANNs) trained to model physical systems. A polynomial solution of the physical system is obtained using a mathematical model and then mapped into the neural network to initialize its weights. The network can next be trained with a dataset to refine its accuracy. We focus attention on an elliptical partial differential equation modeled using a feedforward backpropagation network. We present a numerical example and compare our method with other initialization methods. Our method converges nearly 90% faster compared to random weights, with higher probability of convergence to an acceptable local minimum.	artificial neural network;backpropagation;feed forward (control);feedforward neural network;mathematical model;maxima and minima;numerical analysis;polynomial	Thanasis M. Varnava;Andrew J. Meade	2011	Advances in Adaptive Data Analysis	10.1142/S1793536911000684	feedforward neural network;mathematical optimization;function approximation;computer science;artificial intelligence;machine learning;mathematical model;time delay neural network;artificial neural network	ML	16.513375512116834	-28.171743469364436	117073
771990a90f48544de431ced64352a7c44eafd37e	note on free lunches and cross-validation	learning community;tecnologia electronica telecomunicaciones;estimator robustness;learning algorithm;computacion informatica;validacion cruzada;maximum likelihood;maximum vraisemblance;grupo de excelencia;algorithme apprentissage;estimator;estimador;robustez estimador;ciencias basicas y experimentales;validation croisee;cross validation;reseau neuronal;tecnologias;grupo a;algoritmo aprendizaje;red neuronal;maxima verosimilitud;no free lunch;neural network;robustesse estimateur;estimateur	The no-free-lunch theorems (Wolpert & Macready, 1995) have sparked heated debate in the computational learning community. A recent communication (Zhu & Rohwer, 1996) attempts to demonstrate the inefficiency of cross-validation on a simple problem. We elaborate on this result by considering a broader class of cross-validation. When used more strictly, cross-validation can yield the expected results on simple examples.	computation;cross-validation (statistics);no free lunch in search and optimization	Cyril Goutte	1997	Neural Computation	10.1162/neco.1997.9.6.1245	learning community;no free lunch in search and optimization;econometrics;estimator;computer science;artificial intelligence;machine learning;mathematics;maximum likelihood;artificial neural network;cross-validation;statistics	ML	20.15864140629764	-30.307850800517617	117170
0f55ddb8b330db348a1213a1158c4246ca5c72fb	a divide-and-conquer solver for kernel support vector machines		The kernel support vector machine (SVM) is one of the most widely used classification methods; however, the amount of computation required becomes the bottleneck when facing millions of samples. In this paper, we propose and analyze a novel divide-andconquer solver for kernel SVMs (DC-SVM). In the division step, we partition the kernel SVM problem into smaller subproblems by clustering the data, so that each subproblem can be solved independently and efficiently. We show theoretically that the support vectors identified by the subproblem solution are likely to be support vectors of the entire kernel SVM problem, provided that the problem is partitioned appropriately by kernel clustering. In the conquer step, the local solutions from the subproblems are used to initialize a global coordinate descent solver, which converges quickly as suggested by our analysis. By extending this idea, we develop a multilevel Divide-and-Conquer SVM algorithm with adaptive clustering and early prediction strategy, which outperforms state-of-the-art methods in terms of training speed, testing accuracy, and memory usage. As an example, on the covtype dataset with half-a-million samples, DC-SVM is 7 times faster than LIBSVM in obtaining the exact SVM solution (to within 10−6 relative error) which achieves 96.15% prediction accuracy. Moreover, with our proposed early prediction strategy, DCSVM achieves about 96% accuracy in only 12 minutes, which is more than 100 times faster than LIBSVM.	adaptive filter;algorithm;approximation error;cluster analysis;computation;coordinate descent;kernel (operating system);norm (social);solver;support vector machine	Cho-Jui Hsieh;Si Si;Inderjit S. Dhillon	2014			mathematical optimization;kernel embedding of distributions;radial basis function kernel;machine learning;pattern recognition;mathematics;variable kernel density estimation;polynomial kernel	ML	20.16511781755109	-37.999916675775275	117226
c3198909f95456f667abcf8b6668fda015b98be6	a sequential learning algorithm for a spiking neural classifier	sequential learning;2 dimensional coding;spiking neural network;pattern classification	Graphical abstractOverview of the sequential learning algorithm for a spiking neural classifier. SLSNC consists of a two layered fully connected spiking neural network and a separate decision block. The input layer in the neural network encodes the presented real valued features into spike patterns consisting of varying amplitude and firing times. These spike patterns generated by the input layer neurons is the presynaptic input for the intermediate neurons which are modelled as 'Integrate-and-Fire' neurons. The decision block intercepts the output of the intermediate neurons and estimates the predicted class label according to the neuron which fires first. Display Omitted HighlightsLSNC automatically evolves the architecture.Real valued data is encoded using a 2-D encoding having spike amplitude and time.Sequential learning algorithm developed for SLSNC.Learning algorithm relies on computationally inexpensive operations. This paper presents a biologically inspired, sequential learning spiking neural classifier (SLSNC) for pattern classification problems. It consists of a two layered neural network and a separate decision block which estimates the predicted class label. Inspired by observations in the neuroscience literature, the input layer employs a new neuron model which converts real valued stimuli into spikes with varying amplitudes and firing times. The intermediate layer neurons are modeled as integrate-and-fire spiking neurons. The decision block identifies that intermediate neuron which fires first and returns the class label associated with that neuron as the predicted class label. The sequential learning algorithm for the spiking neural network automatically determines the network structure from the training samples and adapts its synaptic weights by long term potentiation and long term depression. Performance of SLSNC has been evaluated using a number of benchmark classification problems and the results have been compared with other well-known spiking neural network classifiers in the literature as well as with the standard support vector machine (SVM) with a Gaussian kernel and the fast learning Extreme Learning Machine (ELM) classifiers. The results clearly indicate that the described spiking neural network produces similar or better generalization performance with a smaller network.	algorithm;neural oscillation	Shirin Dora;Sundaram Suresh;Narasimhan Sundararajan	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.06.062	types of artificial neural networks;random neural network;computer science;artificial intelligence;machine learning;pattern recognition;time delay neural network;spiking neural network	NLP	13.80859133634651	-28.129868294541673	117253
10093d8027f7c5e05e44ee02616844c531b5b6c3	dropout regularization in hierarchical mixture of experts		Dropout is a very effective method in preventing overfitting and has become the go-to regularizer for multi-layer neural networks in recent years. Hierarchical mixture of experts is a hierarchically gated model that defines a soft decision tree where leaves correspond to experts and decision nodes correspond to gating models that softly choose between its children, and as such, the model defines a soft hierarchical partitioning of the input space. In this work, we propose a variant of dropout for hierarchical mixture of experts that is faithful to the tree hierarchy defined by the model, as opposed to having a flat, unitwise independent application of dropout as one has with multi-layer perceptrons. We show that on a synthetic regression data and on MNIST and CIFAR-10 datasets, our proposed dropout mechanism prevents overfitting on trees with many levels improving generalization and providing smoother fits.		Ozan Irsoy;Ethem Alpaydin	2018	CoRR			ML	18.26885726097673	-33.675883346749444	117267
ba462112e7b755e90868cb49bcaade0aa0482480	artificial neural networks in incomplete data sets processing	artificial neural network	This paper presents some results obtained in experiments with artificial neural networks trained with different learning algorithms in case of lack of some data in training and testing sets.	artificial neural network;neural networks	Magdalena Alicja Tkacz	2005			stochastic neural network;nervous system network models;types of artificial neural networks;computer science;neuro-fuzzy;machine learning;pattern recognition;data mining;time delay neural network;deep learning;competitive learning;artificial neural network	ML	13.370525331892509	-28.557191914446975	117284
412f79c190d19659b8c114da553dceb3c45a596a	dynamic bayesian networks for student modeling	bayesian networks parameter learning constrained optimization error measures instructional policies;predictive models adaptation models mathematical model hidden markov models bayes methods optimization indexes	Intelligent tutoring systems adapt the curriculum to the needs of the individual student. Therefore, an accurate representation and prediction of student knowledge is essential. Bayesian Knowledge Tracing (BKT) is a popular approach for student modeling. The structure of BKT models, however, makes it impossible to represent the hierarchy and relationships between the different skills of a learning domain. Dynamic Bayesian networks (DBN) on the other hand are able to represent multiple skills jointly within one model. In this work, we suggest the use of DBNs for student modeling. We introduce a constrained optimization algorithm for parameter learning of such models. We extensively evaluate and interpret the prediction accuracy of our approach on five large-scale data sets of different learning domains such as mathematics, spelling learning, and physics. We furthermore provide comparisons to previous student modeling approaches and analyze the influence of the different student modeling techniques on instructional policies. We demonstrate that our approach outperforms previous techniques in prediction accuracy on unseen data across all learning domains and yields meaningful instructional policies.	algorithm;constrained optimization;dynamic bayesian network;experiment;mathematical optimization;network topology	Tanja K&#x00E4;ser;Severin Klingler;Alexander G. Schwing;Markus Gross	2017	IEEE Transactions on Learning Technologies	10.1109/TLT.2017.2689017	computer science;bayesian knowledge tracing;variable-order bayesian network;constrained optimization;dynamic bayesian network;hidden markov model;hierarchy;machine learning;spelling;bayesian statistics;artificial intelligence	ML	16.566086660290825	-34.24922619800027	117386
bbacdf015aeeaf05bba9719c6b49caa9c1dbdd94	an examination of qubit neural network in controlling an inverted pendulum	control application;tecnologia electronica telecomunicaciones;computacion informatica;funcion no lineal;qubit;inversed pendulum;non linear function;swing up controll;quantum computation;compression image;image compression;commande non lineaire;ciencias basicas y experimentales;fonction non lineaire;non linear control;inverted pendulum;neural network model;calcul quantique;reseau neuronal;tecnologias;grupo a;kinetics;calculo cuantico;back propagation;quantum neural network;red neuronal;pendule inverse;control no lineal;neural network;compresion imagen;pendulo inverso	The Qubit neuron model is a new non-standard computing scheme that has been found by simulations to have efficient processing abilities. In this paper we investigate the usefulness of the model for a non linear kinetic control application of an inverted pendulum on a cart. Simulations show that a neural network based on Qubit neurons would swing up and stabilize the pendulum, yet it also requires a shorter range over which the cart moves as compared to a conventional neural network model.	artificial neural network;biological neuron model;computer simulation;effective method;grayscale;image compression;inverted pendulum;network model;nonlinear system;parity bit;quantum neural network;qubit	Noriaki Kouda;Nobuyuki Matsui;Haruhiko Nishimura;Ferdinand Peper	2005	Neural Processing Letters	10.1007/s11063-005-8337-2	inverted pendulum;image compression;computer science;artificial intelligence;backpropagation;machine learning;control theory;mathematics;qubit;quantum computer;artificial neural network;kinetics	ML	16.2177484557743	-28.019324099455662	117495
a3ec0785245a3dfcf9bee7285fb21d34c25a2f99	an efficient pruning algorithm for robust isotonic regression		We study a generalization of the classic isotonic regression problem where we allow separable nonconvex objective functions, focusing on the case where the functions are estimators used in robust regression. One can solve this problem to within -accuracy (of the global minimum) in O(n/ ) using a simple dynamic program, and the complexity of this approach is independent of the underlying functions. We introduce an algorithm that combines techniques from the convex case with branchand-bound ideas that naturally exploits the shape of the functions. Our algorithm achieves the best known bounds for both the convex case (O(n log(1/ ))) and the general nonconvex case. Our experiments show that this algorithm performs much faster than the dynamic programming approach on robust estimators, especially as the desired accuracy increases.	bridging (networking);davis–putnam algorithm;dhrystone;discrete optimization;disk mirroring;dynamic programming;experiment;generalization (psychology);ibm notes;image scaling;isotonic regression;keneth alden simons;large;maxima and minima;nephrogenic systemic fibrosis;optimization problem;rule (guideline);submodular set function;test scaling	Cong Han Lim	2018			isotonic regression;pruning;mathematical optimization;estimator;artificial intelligence;machine learning;robust regression;computer science;dynamic programming;separable space;algorithm	ML	23.978885570309398	-32.2383235335219	117694
7295d441e9c565b229fc5bee039d5f602128ced2	the identification of context-sensitive features: a formal definition of context for concept learning	learning algorithm;supervised learning;statistical models;feature space;multi dimensional;machine learning;science learning;pattern recognition;concept learning;artificial intelligence	A large body of research in machine learning is concerned with supervised learning from examples. The examples are typically represented as vectors in a multi-dimensional feature space (also known as attribute-value descriptions). A teacher partitions a set of training examples into a finite number of classes. The task of the learning algorithm is to induce a concept from the training examples. In this paper, we formally distinguish three types of features: primary, contextual, and irrelevant features. We also formally define what it means for one feature to be context-sensitive to another feature. Context-sensitive features complicate the task of the learner and potentially impair the learner’s performance. Our formal definitions make it possible for a learner to automatically identify context-sensitive features. After context-sensitive features have been identified, there are several strategies that the learner can employ for managing the features; however, a discussion of these strategies is outside of the scope of this paper. The formal definitions presented here correct a flaw in previously proposed definitions. We discuss the relationship between our work and a formal definition of relevance.	algorithm;concept learning;context-sensitive grammar;context-sensitive help;context-sensitive language;feature vector;flaw hypothesis methodology;machine learning;relevance;robustness (computer science);supervised learning	Peter D. Turney	1996	CoRR		semi-supervised learning;natural language processing;unsupervised learning;statistical model;feature learning;multi-task learning;error-driven learning;algorithmic learning theory;concept learning;feature vector;feature;computer science;online machine learning;machine learning;pattern recognition;supervised learning;stability;active learning;feature	AI	16.276838648602077	-35.125993003087125	117737
27b453bb1bf0ad9fccacfd50e2519e3b2e9ff723	linear concepts and hidden variables	unsupervised learning;linear functionals;probabilistic model;expectation maximization;hidden variables;naire bayes;learning problems;winnow;linear functions;em algorithm	We study a learning problem which allows for a “fair” comparison between unsupervised learning methods—probabilistic model construction, and more traditional algorithms that directly learn a classification. The merits of each approach are intuitively clear: inducing a model is more expensive computationally, but may support a wider range of predictions. Its performance, however, will depend on how well the postulated probabilistic model fits that data. To compare the paradigms we consider a model which postulates a single binary-valued hidden variable on which all other attributes depend. In this model, finding the most likely value of any one variable (given known values for the others) reduces to testing a linear function of the observed values. We learn the model with two techniques: the standard EM algorithm, and a new algorithm we develop based on covariances. We compare these, in a controlled fashion, against an algorithm (a version of Winnow) that attempts to find a good linear classifier directly. Our conclusions help delimit the fragility of using a model that is even “slightly” simpler than the distribution actually generating the data, vs. the relative robustness of directly searching for a good predictor.	approximation algorithm;binary data;expectation–maximization algorithm;expressive power (computer science);fits;hidden variable theory;inductive reasoning;information security;kerrison predictor;linear classifier;linear function;mixture model;model selection;sampling (signal processing);statistical model;unsupervised learning;winnow (algorithm)	Adam J. Grove;Dan Roth	2001	Machine Learning	10.1023/A:1007655119445	unsupervised learning;winnow;econometrics;expectation–maximization algorithm;computer science;artificial intelligence;machine learning;mathematics;statistics	ML	23.800636262090396	-29.209958386167393	117769
9cc7492f8aaffea134ea9457f974585fadc32383	polynomial neural network modeling of reactive ion etching process using gmdh method	experimental design;autoapprentissage;modelizacion;distributed system;metodo polinomial;plate;proceso concepcion;factorial design;process variation;feed forward;attaque chimique;learning algorithm;systeme reparti;design process;error back propagation;engine control;manipulacion dato;control maquina;polynomial neural network;plan experiencia;plaque;intelligence artificielle;algorithme apprentissage;ataque quimico;placa;autodidactismo;process design;preparacion serie fabricacion;propagation erreur;machine control;self learning;modelisation;gas flow;sistema repartido;chemical etching;learning methods;machine learning;plan experience;polynomial method;backpropagation algorithm;reactive ion etching;autoorganizacion;algorithme retropropagation;plasma;artificial intelligence;self organization;inteligencia artificial;commande machine;process planning;propagacion error;data handling;neural network model;growth of error;reseau neuronal;nonlinear system;group method of data handling;methode polynomiale;preparation gamme fabrication;algoritmo aprendizaje;modeling;maniement donnee;red neuronal;autoorganisation;plan factorial;neural network;processus conception;algoritmo retropropagacion;plan factoriel	The construction of models for prediction and control of initially unknown, potentially nonlinear system is a difficult, fundamental problem in machine learning and engineering control. Since the neural network as a tool for machine learning was introduced, significant progress has been made on data handling and learning algorithms. Currently, the most popular learning algorithm in neural network training is feed forward error back-propagation (FFEBP) algorithm. Aside from the success of the FFEBP algorithm, a polynomial neural networks (PNN) learning has been proposed as a new learning method. The PNN learning is a self-organizing process designed to determine an appropriate set of Ivakhnenko polynomials that allow the activation of many neurons to achieve a desired state of activation that mimics a given set of sampled patterns. These neurons are interconnected in such a way that the knowledge is stored in Ivakhnenko coefficients. In this paper, PNN model has been developed using the nonlinear reactive ion etching (RIE) experimental data utilizing Group Method of Data Handling (GMDH). To characterize the RIE process using PNN, a low-k dielectric polymer benzocyclobutene (BCB) is etched in an SF6 and O2 plasma in parallel plate system. Data from 2 4 factorial experimental design to characterize etch process variation with controllable input factors consisting of the two gas flows, RF power and chamber pressure are used to build PNN models of etch rate, uniformity, selectivity and anisotropy. The modeling and prediction performance of PNN is compared with those of FFEBP. The results show that the prediction capability of the PNN models is at least 16.9% better than that of the conventional neural network models.	algorithm;artificial neural network;backpropagation;c++builder;circuit complexity;coefficient;complex systems;computation;condition number;debian;design of experiments;etching (microfabrication);group method of data handling;interaction;machine learning;network synthesis filters;nonlinear programming;nonlinear system;organizing (structure);plasma active;polymer;polynomial;radio frequency;reactive-ion etching;selectivity (electronic);self-organization;software propagation;time complexity	Seung Soo Han;Sang Hong	2006		10.1007/11760191_152	probabilistic neural network;computer science;artificial intelligence;backpropagation;machine learning;group method of data handling;artificial neural network;algorithm	ML	16.91990125029386	-27.253805674934302	117779
8fb65933cfe48eca39c0151ce675027394a6564d	low-precision random fourier features for memory-constrained kernel approximation		We investigate how to train kernel approximation methods that generalize well under a memory budget. Building on recent theoretical work, we define a measure of kernel approximation error which we find to be much more predictive of the empirical generalization performance of kernel approximation methods than conventional metrics. An important consequence of this definition is that a kernel approximation matrix must be high-rank to attain close approximation. Because storing a high-rank approximation is memory-intensive, we propose using a low-precision quantization of random Fourier features (LP-RFFs) to build a high-rank approximation under a memory budget. Theoretically, we show quantization has a negligible effect on generalization performance in important settings. Empirically, we demonstrate across four benchmark datasets that LP-RFFs can match the performance of full-precision RFFs and the Nyström method, with 3x-10x and 50x-460x less memory, respectively.	approximation algorithm;approximation error;benchmark (computing);kernel (operating system);lp-type problem;nyström method;quantization (signal processing)	Jian Zhang;Avner May;Tri Dao;Christopher R'e	2018	CoRR		kernel (linear algebra);algorithm;fourier transform;mathematical optimization;quantization (signal processing);nyström method;computer science;approximation error;matrix (mathematics)	ML	22.202152115969227	-32.0319869232025	117781
28383f33dbcbe82ae0a79e00c346e585c651d038	a new artificial neural network structure for solving high-order linear fractional differential equations	power series method;artificial neuralnetwork;high order fractional differential equation;back propagation learning algorithm;criterion function	Artificial neural networks (ANNs) afford great potential in learning and stability against small perturbations of input data. Using artificial intelligence techniques and modeling tools offers an ever-greater number of practical applications. In the present study, an iterative algorithm, which was based on the combination of a power series method and a neural network approach, was used to approximate a solution for high-order linear and ordinary differential equations. First, a suitable truncated series of the solution functions were substituted into the algorithm's equation. The problem considered here had a solution as a series expansion of an unknown function, and the proper implementation of an appropriate neural architecture led to an estimate of the unknown series coefficients. To prove the applicability of the concept, some illustrative examples were provided to demonstrate the precision and effectiveness of this method. Comparing the proposed methodology with other available traditional techniques...	artificial neural network	Fariba Rostami;Ahmad Jafarian	2018	Int. J. Comput. Math.	10.1080/00207160.2017.1291932	mathematical optimization;mathematical analysis;machine learning;calculus;mathematics	Theory	16.247018065270158	-28.755476185294874	117835
cbf2d5d44f39f792e79723dfcf1461a5ecb71d96	experimental study of ergodic learning curve in hidden markov models	time dependent;generalization error;learning curve;hidden markov model;informing science;learning theory;fisher information	A number of learning machines used in information science are not regular, but rather singular, because they are non-identifiable and their Fisher information matrices are singular. Even for singular learning machines, the learning theory was developed for the case in which training samples are independent. However, if training samples have time-dependency, then learning theory is not yet established. In the present paper, we define an ergodic generalization error for a time-dependent sequence and study its behavior experimentally in hidden Markov models. The ergodic generalization error is clarified to be inversely proportional to the number of training samples, but the learning coefficient depends strongly on time-dependency.	ergodic theory;ergodicity;hidden markov model;markov chain	Masashi Matsumoto;Sumio Watanabe	2008		10.1007/978-3-642-02490-0_84	semi-supervised learning;unsupervised learning;econometrics;algorithmic learning theory;computer science;fisher information;machine learning;learning theory;hidden semi-markov model;mathematics;stability;learning curve;computational learning theory;probably approximately correct learning;hidden markov model;statistics;generalization error	ML	20.281243152867624	-33.15616655720881	118085
103c3fbbfe3951af39f513ab0e9c846435f5325b	foundations of coupled nonlinear dimensionality reduction		In this paper we introduce and analyze the learning scenario ofcoupled nonlinear dimensionality reduction, which combines two major steps of machine learning pipeline: projection onto a manifold and subsequent supervised learning. First, we present new generalization bounds for this scenario and, second, we introduce an algorithm that follows from these bounds. The generalization error bound is based on a careful analysis of the empirical Rademacher complexity of the relevant hypothesis set. In particular, we show an upper bound on the Rademacher complexity that is inÕ( √ Λ(r)/m), wherem is the sample size and Λ(r) the upper bound on the KyFanr-norm of the associated kernel matrix. We give both upper and lower bound guarantees in terms of that Ky-Fanr-norm, which strongly justifies the definition of our hypothesis set. To the best of our knowledge, these are the first learning guarantees for the problem of coupled dimensionality reduction. Our analysis and learning guarantees further apply to several special cases, such as that of using a fixed kernel with supervised dimensionality reduction or that of unsupervised learning of a kernel for dimensionality reduction followed by a supervised learning algorithm. Based on theoretical analysis, we suggest a structural risk minimization algorithm consisting of the coupled fitting of a low dimensional manifold and a separation function on that manifold.	algorithm;generalization error;kernel (operating system);machine learning;nonlinear dimensionality reduction;nonlinear system;rademacher complexity;structural risk minimization;supervised learning;t-norm;unsupervised learning	Dmitry Storcheus;Mehryar Mohri;Afshin Rostamizadeh	2015	CoRR		mathematical optimization;machine learning;pattern recognition;mathematics;statistics;dimensionality reduction	ML	21.430166276179097	-34.11587443389922	118092
e991ad0415d6806ed37f4c32f453e60e583b5dd4	combining classifiers using dependency-based product approximation with bayes error rate	bayes estimation;traitement signal;entropia;borne erreur;high dimensionality;approximation error;loi probabilite;ley probabilidad;caracter manuscrito;taux erreur;manuscript character;classification;error aproximacion;upper bound;estimacion bayes;reconnaissance caractere;combining classifier;signal processing;probability distribution;entropie;conditional entropy;error rate;entropy;error bound;borne superieure;indice error;discriminacion;procesamiento senal;caractere manuscrit;character recognition;clasificacion;reconocimiento caracter;erreur approximation;discrimination;cota superior;estimation bayes;limite error	Combining classifiers using Bayesian formalism deals with a high dimensional probability distribution composed of a class and the decisions of classifiers. Thus product approximation is needed for the probability distribution. Bayes error rate is upper bounded by the conditional entropy of the class and decisions, so the upper bound should be minimized for raising the class discrimination. By considering the dependency between class and decisions, dependency-based product approximation is proposed in this paper together with its related combination method. The proposed method is evaluated with the recognition of unconstrained handwritten numerals.	approximation	Hee-Joong Kang	2004		10.1007/978-3-540-25966-4_11	econometrics;entropy;computer science;signal processing;pattern recognition;mathematics;statistics	NLP	19.906393400700868	-34.46860122279554	118160
dc2c1201fe48851dbee9858200f19a8427362097	eigenvalue analysis on singularity in rbf networks	eigenvalues and eigenfunctions;overlap singularity;learning process;gradient learning process;radial basis function networks eigenvalues and eigenfunctions hessian matrices learning artificial intelligence;eigenvalues and eigenfunctions radial basis function networks neural networks multi layer neural network multilayer perceptrons symmetric matrices vectors usa councils stability analysis computer networks;hessian matrix;overlap singularity eigenvalue analysis radial basis function network gradient learning process neural network multilayer perceptron hessian matrix;multilayer perceptron;eigenvalues;radial basis function networks;radial basis function network;initial condition;learning artificial intelligence;rbf network;eigenvalue analysis;hessian matrices;neural network	It has long been observed that strange behaviors happen in the gradient learning process of neural networks including multilayer perceptrons (MLPs) and RBF networks because of the singularities arisen from the symmetric structure in these models. The learning behaviors nearby are crucially dependant on the stability of the singularity. For RBF networks, this paper analyzes the stability by investigating the eigenvalues of the Hessian matrix on the overlap singularities. We show that the overlap singularity is a partially stable critical line, and there is only one nonzero eigenvalue on the singularity. The influence of the teacher parameters and initial conditions on eigenvalues is also discussed.	artificial neural network;gradient;hessian;initial condition;multilayer perceptron;radial basis function network;technological singularity	Haikun Wei;Shun-ichi Amari	2007	2007 International Joint Conference on Neural Networks	10.1109/IJCNN.2007.4371040	mathematical optimization;combinatorics;eigenvalues and eigenvectors;computer science;machine learning;mathematics;multilayer perceptron;radial basis function network;hessian matrix;initial value problem;artificial neural network;singularity function	ML	16.40692864621619	-30.790815443682696	118340
0a41ca65a80b5644d23649043f2f625b4002a225	adaptive soft weight tying using gaussian mixtures	gaussian mixture	Geoffrey E. Hinton Department of Computer Science . U ni versi ty of Toran to Toronto, Canada M5S lA4 One way of simplifying neural networks so they generalize better is to add an extra t.erm 10 the error fUll c tion that will penalize complexit.y. \Ve propose a new penalt.y t.erm in which the dist rihution of weight values is modelled as a mixture of multiple gaussians . C nder this model, a set of weights is simple if the weights can be clustered into subsets so that the weights in each cluster have similar values . We allow the parameters of the mixture model to adapt at t.he same time as t.he network learns. Simulations demonstrate that this complexity term is more effective than previous complexity terms.	artificial neural network;computer science;computer simulation;gaussian (software);mixture model	Steven J. Nowlan;Geoffrey E. Hinton	1991			computer science	ML	23.471774575195692	-31.038403280173675	118463
e50be5fca2a8c2199d7f7bdbc44014285552405a	a note on the universal approximation capability of support vector machines	feedforward neural network;kernel;machine support vecteur;classification;approximation;universal approximation capability;reseau neuronal non boucle;feedforward neural nets;capabilite approximation universelle;support vector machine;vector support machine;reseau neuronal;clasificacion;red neuronal;neural network	The approximation capability of support vector machines (SVMs) is investigated. We show the universal approximation capability of SVMs with various kernels, including Gaussian, several dot product, or polynomial kernels, based on the universal approximation capability of their standard feedforward neural network counterparts. Moreover, it is shown that an SVM with polynomial kernel of degree p − 1 which is trained on a training set of size p can approximate the p training points up to any accuracy.	approximation algorithm;artificial neural network;feedforward neural network;pollard's p − 1 algorithm;polynomial kernel;support vector machine;test set;universal approximation theorem	Barbara Hammer;Kai Gersmann	2003	Neural Processing Letters	10.1023/A:1022936519097	support vector machine;feedforward neural network;mathematical optimization;kernel;biological classification;computer science;machine learning;approximation;pattern recognition;mathematics;artificial neural network	ML	19.89359999034567	-34.06307752035821	118477
83fe8f9d9d94bae9cd8628045be9be16369461c1	an analysis of high-capacity discrete exponential bam	stability high capacity discrete exponential bam exponential bidirectional associative memory exponential encoding scheme pattern pair storage capacity energy function exponential nonlinearity evolution equations signal to noise ratio recall process;memoire associative;neural networks;capacite stockage;energy function;stability;evolution equation;associative storage;capacidad almacenaje;storage capacity;analyse performance;performance analysis;associative memory;stability content addressable storage encoding;rapport signal bruit;reseau neuronal;signal to noise ratio;content addressable storage;encoding;bidirectional associative memory;magnesium compounds associative memory encoding nonlinear equations stability autocorrelation voltage very large scale integration councils reverberation;analisis eficacia	An exponential bidirectional associative memory (eBAM) using an exponential encoding scheme is discussed. It has a higher capacity for pattern pair storage than conventional BAMs. A new energy function is defined. The associative memory takes advantage of the exponential nonlinearity in the evolution equations such that the signal-to-noise ratio (SNR) is significantly increased. The energy of the eBAM decreases as the recall process proceeds, ensuring the stability of the system. The increase of SNR consequently enhances the capacity of the BAM. The capacity of the exponential BAM is estimated.	bcl-2-like protein 11, human;bidirectional associative memory;content-addressable memory;line code;mathematical optimization;memory disorders;nonlinear system;smc3 gene;signal-to-noise ratio;exponential	Chua-Chin Wang;Hon-Son Don	1995	IEEE transactions on neural networks	10.1109/72.363485	exponential error;stability;computer science;artificial intelligence;machine learning;content-addressable memory;bidirectional associative memory;signal-to-noise ratio;artificial neural network;algorithm;encoding	Embedded	16.40134900812396	-25.798977935929397	119081
3d676791081e7b16a4ead9924fc03bac587d181d	inductive learning of answer set programs from noisy examples		In recent years, non-monotonic Inductive Logic Programming has received growing interest. Specifically, several new learning frameworks and algorithms have been introduced for learning under the answer set semantics, allowing the learning of common-sense knowledge involving defaults and exceptions, which are essential aspects of human reasoning. In this paper, we present a noise-tolerant generalisation of the learning from answer sets framework. We evaluate our ILASP3 system, both on synthetic and on real datasets, represented in the new framework. In particular, we show that on many of the datasets ILASP3 achieves a higher accuracy than other ILP systems that have previously been applied to the datasets, including a recently proposed differentiable learning framework.	algorithm;inductive logic programming;inductive reasoning;stable model semantics;synthetic intelligence	Mark Law;Alessandra Russo;Krysia Broda	2018	CoRR		differentiable function;artificial intelligence;computer science;machine learning;semantics;inductive logic programming;generalization	ML	16.914861231802963	-34.531561492695815	119127
36ae8d37289dd858f628f11c4be696e38291e9d4	mlpnn training via a multiobjective optimization of training error and stochastic sensitivity	training;accuracy;sensitivity;multilayer perceptron neural network mlpnn multiobjective sensitivity training algorithm;biobjective functions mlpnn training multiobjective optimization training error multilayer perceptron neural network training connection weights penalty term smoothness control generalization capability vapnik chervonenkis dimension generalization capabilities stochastic sensitivity measure st sm q neighborhoods mlpnns output fluctuation measurement two phase pareto based multiobjective training algorithm;stochastic processes generalisation artificial intelligence multilayer perceptrons pareto optimisation;training algorithm multilayer perceptron neural network mlpnn multiobjective sensitivity;linear programming;training neurons optimization linear programming sensitivity accuracy biological neural networks;optimization;neurons;mlpnn training multiobjective optimization training error multilayer perceptron neural network training connection weights penalty term smoothness control generalization capability vapnik chervonenkis dimension generalization capabilities stochastic sensitivity measure st sm q neighborhoods mlpnns output fluctuation measurement two phase pareto based multiobjective training algorithm biobjective functions;generalisation artificial intelligence multilayer perceptrons pareto optimisation stochastic processes;biological neural networks	The training of a multilayer perceptron neural network (MLPNN) concerns the selection of its architecture and the connection weights via the minimization of both the training error and a penalty term. Different penalty terms have been proposed to control the smoothness of the MLPNN for better generalization capability. However, controlling its smoothness using, for instance, the norm of weights or the Vapnik-Chervonenkis dimension cannot distinguish individual MLPNNs with the same number of free parameters or the same norm. In this paper, to enhance generalization capabilities, we propose a stochastic sensitivity measure (ST-SM) to realize a new penalty term for MLPNN training. The ST-SM determines the expectation of the squared output differences between the training samples and the unseen samples located within their Q -neighborhoods for a given MLPNN. It provides a direct measurement of the MLPNNs output fluctuations, i.e., smoothness. We adopt a two-phase Pareto-based multiobjective training algorithm for minimizing both the training error and the ST-SM as biobjective functions. Experiments on 20 UCI data sets show that the MLPNNs trained by the proposed algorithm yield better accuracies on testing data than several recent and classical MLPNN training methods.	alexey chervonenkis;algorithm;artificial neural network;biological neural networks;categorical variable;generalization (psychology);molybdenum;morphology findings domain;multi-objective optimization;multilayer perceptron;multimedia;pareto efficiency;quantum fluctuation;response surface methodology;two-phase locking;vc dimension;weight	Daniel S. Yeung;Jin-Cheng Li;Daniel S. Yeung;Patrick P. K. Chan	2016	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2015.2431251	mathematical optimization;sensitivity;linear programming;artificial intelligence;machine learning;mathematics;accuracy and precision	ML	13.875481719876587	-23.9876170838561	119300
03428bd9425bd280826c47296e742fa194d3c013	analysis of hidden nodes for multi-layer perceptron neural networks	tolerancia falta;simulation;simulacion;back propagation neural network;hidden nodes;fault tolerance;multi layer perceptron;multilayer perceptron neural networks;reseau neuronal propagation arriere;reseau neuronal;red neuronal;tolerance faute;neural network	Abstract   The fault tolerance of the multi-layer perceptron is strongly related to its redundant hidden nodes. Increasing redundant hidden nodes may provide the advantage of higher degree of fault tolerance but have the disadvantage of higher computation and hardware complexities. The analysis of the relationship between the hidden nodes and the fault tolerance of the multi-layer perceptron is given. Fault tolerance is first discussed. Then, a new strategy for the reduction of redundant hidden nodes is proposed. It can give the maximum number of crashed nodes allowed within a given error for the neural network. In addition, some redundant hidden nodes can be removed for simple computation. Simulation results are also given to verify the method.	artificial neural network;layer (electronics);multilayer perceptron	I-Chang Jou;Shih-Shien You;Long-Wen Chang	1994	Pattern Recognition	10.1016/0031-3203(94)90170-8	fault tolerance;computer science;artificial intelligence;machine learning;multilayer perceptron;artificial neural network;algorithm	ML	10.81551645221766	-28.85170086828868	119386
e6cd4946088dd87b43419e972097b1b7bdf135d8	pattern-aided regression modeling and prediction model analysis	optimal regression models pattern aided regression modeling prediction model analysis pxr models interpretable prediction models contrast pattern aided regression cpxr method regression modeling applications;predictive models computational modeling data models linear regression analytical models prediction algorithms regression tree analysis;regression analysis pattern classification	This paper first introduces pattern aided regression (PXR) models, a new type of regression models designed to represent accurate and interpretable prediction models. This was motivated by two observations: (1) Regression modeling applications often involve complex diverse predictor-response relationships, which occur when the optimal regression models (of given regression model type) fitting two or more distinct logical groups of data are highly different. (2) State-of-the-art regression methods are often unable to adequately model such relationships. This paper defines PXR models using several patterns and local regression models, which respectively serve as logical and behavioral characterizations of distinct predictor-response relationships. The paper also introduces a contrast pattern aided regression (CPXR) method, to build accurate PXR models. In experiments, the PXR models built by CPXR are very accurate in general, often outperforming state-of-the-art regression methods by big margins. Usually using (a) around seven simple patterns and (b) linear local regression models, those PXR models are easy to interpret; in fact, their complexity is just a bit higher than that of (piecewise) linear regression models and is significantly lower than that of traditional ensemble based regression models. CPXR is especially effective for high-dimensional data. The paper also discusses how to use CPXR methodology for analyzing prediction models and correcting their prediction errors.	baseline (configuration management);coefficient;emoticon;experiment;fixed-point iteration;interaction;kerrison predictor;model f keyboard;test set	Guozhu Dong;Vahid Taslimitehrani	2015	IEEE Transactions on Knowledge and Data Engineering	10.1109/ICDE.2016.7498398	proper linear model;marginal model;multivariate adaptive regression splines;computer science;machine learning;bayesian multivariate linear regression;linear model;errors-in-variables models;regression diagnostic;logistic regression;path coefficient;factor regression model;nonparametric regression;regression analysis;statistics	ML	22.581196217408753	-29.82038978647049	119409
f2a56196fa5044d51f07be0c6a157964b9afb98e	model clustering for neural network ensembles	bootstrap;loi probabilite;ley probabilidad;neural network ensemble;probability distribution;autogeneration mutuelle;bootstrapping;modele donnee;neural network model;learning artificial intelligence;reseau neuronal;part of book or chapter of book;red neuronal;data models;neural network;apprentissage intelligence artificielle	We show that large ensembles of (neural network) models, obtained e.g. in bootstrapping or sampling from (Bayesian) probability distributions, can be effectively summarized by a relatively small number of representative models. We present a method to find representative models through clustering based on the models’ outputs on a data set. We apply the method on models obtained through bootstrapping (Boston housing) and on a multitask learning example.	artificial neural network;bootstrapping (compilers);cluster analysis;computer multitasking;sampling (signal processing)	Bart Bakker;Tom Heskes	2002		10.1007/3-540-46084-5_62	probability distribution;data modeling;variable-order bayesian network;computer science;artificial intelligence;machine learning;data mining;artificial neural network;bootstrapping	ML	11.538980436634517	-31.19468511725659	119468
f9b4f1cea91ef1424a42647ad40f74389fd0a75d	learning contiguity with layered neural networks	neural network		artificial neural network	Sara A. Solla	1988	Neural Networks	10.1016/0893-6080(88)90260-2	nervous system network models;probabilistic neural network;types of artificial neural networks;computer science;recurrent neural network;machine learning;physical neural network;time delay neural network;deep learning;artificial neural network	ML	13.18494968909862	-27.490682269036206	119471
6ff3535f8962e1df116543d0d8338a732088672d	algebraic machine learning		Machine learning algorithms use error function minimization to fit a large set of parameters in a preexisting model. However, error minimization eventually leads to a memorization of the training dataset, losing the ability to generalize to other datasets. To achieve generalization something else is needed, for example a regularization method or stopping the training when error in a validation dataset is minimal. Here we propose a different approach to learning and generalization that is parameter-free, fully discrete and that does not use function minimization. We use the training data to find an algebraic representation with minimal size and maximal freedom, explicitly expressed as a product of irreducible components. This algebraic representation is shown to directly generalize, giving high accuracy in test data, more so the smaller the representation. We prove that the number of generalizing representations can be very large and the algebra only needs to find one. We also derive and test a relationship between compression and error rate. We give results for a simple problem solved step by step, hand-written character recognition, and the Queens Completion problem as an example of unsupervised learning. As an alternative to statistical learning, algebraic learning may offer advantages in combining bottom-up and top-down information, formal concept derivation from data and large-scale parallelization.		Fernando Martin-Maroto;Gonzalo G. de Polavieja	2018	CoRR		mathematical optimization;algebraic number;machine learning;unsupervised learning;algebra representation;artificial intelligence;word error rate;generalization;derivation;formal concept analysis;mathematics;error function	ML	19.2031348471127	-36.699414499342495	119533
1f8dbbc1d9aa05c5895290349a3f96070aab2796	support vector machines using bayesian-based approach in the issue of unbalanced classifications	unbalanced;bayesian approach;prior distribution;class imbalance;classification;bayesian decision theory;learning methods;classification error;imbalance;support vector machine	There have been a lot of reports about the fact that the characteristics of datasets will strongly affect the performance of different classifiers. A study in the cognition is thus conceived, and it is natural to propose the Bayesian approach. As is well known, valuable quantitative features from datasets are easily captured and then to update these previous classification problems to guarantee well class separability. The purpose of this learning method is to give an attractive pragmatic feature of the Bayesian approach in the quantitative description of class imbalance problem. Thus, a programming problem of mixing probability information: Bayesian Support Vector Machines (BSVMs) is discussed. In addition, we first change some of the aims and conditions of the original programming problems and then explore what effect will be acquired due to the change. The experiments on several existing datasets show that, if prior distributions are assigned to the programming problem, the estimated classification errors will be reduced. 2011 Elsevier Ltd. All rights reserved.	algorithm;cognition;decision theory;experiment;left 4 dead 2;linear separability;normal (geometry);support vector machine;unbalanced circuit	Hung-Yuan Chung;Chih-Hsiang Ho;Che-Chang Hsu	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.03.018	bayesian average;support vector machine;prior probability;bayes estimator;biological classification;bayesian probability;computer science;artificial intelligence;machine learning;pattern recognition;data mining;bayesian statistics;statistics	AI	16.257984505647535	-37.664355507024695	119764
df8fe29c75f634ce5cec9049b8efeb1b534dfd3f	information geometry and information theory in machine learning	asymptotic equipartition property;reinforcement learning;exponential family;information geometry;machine learning;riemannian manifold;mutual information;markov decision process;potential function;information theoretic;information theory	Information geometry is a general framework of Riemannian manifolds with dual affine connections. Some manifolds (e.g. the manifold of an exponential family) have natural connections (e.g.  e - and  m -connections) with which the manifold is dually-flat. Conversely, a dually-flat structure can be introduced into a manifold from a potential function. This paper shows the case of quasi-additive algorithms as an example.#R##N##R##N#Information theory is another important tool in machine learning. Many of its applications consider information-theoretic quantities such as the entropy and the mutual information, but few fully recognize the underlying essence of them. The asymptotic equipartition property is one of the essence in information theory.#R##N##R##N#This paper gives an example of the property in a Markov decision process and shows how it is related to return maximization in reinforcement learning.	information geometry;information theory;machine learning	Kazushi Ikeda;Kazunori Iwata	2007		10.1007/978-3-540-69162-4_31	markov decision process;variation of information;statistical manifold;mathematical optimization;combinatorics;exponential family;asymptotic equipartition property;information theory;computer science;machine learning;mathematics;mutual information;reinforcement learning;interaction information;coherent information;information geometry;statistics;manifold alignment	ML	22.073985209109676	-31.056560170899807	119775
3ad6153cb47a5201db67f82bc31fc10d04050817	an incremental neural learning framework and its application to vehicle diagnostics	vehicle diagnostics;neural networks;noisy data;prior knowledge;backpropagation;learning system;incremental learning;machine learning;intelligent system;parallel implementation;incremental algorithm;neural network;generalization capability	This paper presents a framework for incremental neural learning (INL) that allows a base neural learning system to incrementally learn new knowledge from only new data without forgetting the existing knowledge. Upon subsequent encounters of new data examples, INL utilizes prior knowledge to direct its incremental learning. A number of critical issues are addressed including when to make the system learn new knowledge, how to learn new knowledge without forgetting existing knowledge, how to perform inference using both the existing and the newly learnt knowledge, and how to detect and deal with aged learnt systems. To validate the proposed INL framework, we use backpropagation (BP) as a base learner and a multi-layer neural network as a base intelligent system. INL has several advantages over existing incremental algorithms: it can be applied to a broad range of neural network systems beyond the BP trained neural networks; it retains the existing neural network structures and weights even during incremental learning; the neural network committees generated by INL do not interact with one another and each sees the same inputs and error signals at the same time; this limited communication makes the INL architecture attractive for parallel implementation. We have applied INL to two vehicle fault diagnostics problems: end-of-line test in auto assembly plants and onboard vehicle misfire detection. These experimental results demonstrate that the INL framework has the capability to successfully perform incremental learning from unbalanced and noisy data. In order to show the general capabilities of INL, we also applied INL to three general machine learning benchmark data sets. The INL systems showed good generalization capabilities in comparison with other well known machine learning algorithms.	algorithm;artificial neural network;backpropagation;benchmark (computing);dynamic problem (algorithms);embedded system;experiment;ibm notes;layer (electronics);machine learning;os-tan;reinforcement learning;scalability;signal-to-noise ratio;test set;time series;unbalanced circuit	Yi Lu Murphey;ZhiHang Chen;Lee A. Feldkamp	2007	Applied Intelligence	10.1007/s10489-007-0040-8	computer science;artificial intelligence;backpropagation;machine learning;data mining;artificial neural network	AI	15.001466036862157	-30.832798977511885	119815
766a9e09b454d6c663257296e37df3193a86a4da	artificial bee colony training of neural networks: comparison with back-propagation		The Artificial Bee Colony (ABC) is a swarm intelligence algorithm for optimization that has previously been applied to the training of neural networks. This paper examines more carefully the performance of the ABC algorithm for optimizing the connection weights of feed-forward neural networks for classification tasks, and presents a more rigorous comparison with the traditional Back-Propagation (BP) training algorithm. The empirical results for benchmark problems demonstrate that using the standard “stopping early” approach with optimized learning parameters leads to improved BP performance over the previous comparative study, and that a simple variation of the ABC approach provides improved ABC performance too. With both improvements applied, the ABC approach does perform very well on small problems, but the generalization performances achieved are only significantly better than standard BP on one out of six datasets, and the training times increase rapidly as the size of the problem grows. If different, evolutionary optimized, BP learning rates are allowed for the two layers of the neural network, BP is significantly better than the ABC on two of the six datasets, and not significantly different on the other four.	artificial bee colony algorithm;artificial neural network;backpropagation;benchmark (computing);feedforward neural network;mathematical optimization;performance;software propagation;swarm intelligence	John A. Bullinaria;Khulood Alyahya	2014	Memetic Computing	10.1007/s12293-014-0137-7	artificial intelligence;machine learning;operations research	ML	14.385507122895778	-24.14536963074723	119999
7cfd0cc714dd2f508dd78343f7e9f1129d143c1f	the theoretical foundations of statistical learning theory based on fuzzy number samples	rate of convergence;learning process;fuzzy empirical risk minimization principle;fuzzy numbers;fuzzy number;random sampling;small samples;empirical risk minimization;statistical learning;fuzzy empirical risk functional;statistical learning theory;theoretical foundation;learning theory;fuzzy expected risk functional	Statistical learning theory based on real-valued random samples has been regarded as a better theory on statistical learning with small sample. The key theorem of learning theory and bounds on the rate of convergence of learning processes are important theoretical foundations of statistical learning theory. In this paper, the theoretical foundations of the statistical learning theory based on fuzzy number samples are discussed. The concepts of fuzzy expected risk functional, fuzzy empirical risk functional and fuzzy empirical risk minimization principle are redefined. The key theorem of learning theory based on fuzzy number samples is proved. Furthermore, the bounds on the rate of convergence of learning processes based on fuzzy number samples are discussed.	fuzzy number;machine learning;statistical learning theory	Ming-Hu Ha;Jing Tian	2008	Inf. Sci.	10.1016/j.ins.2008.03.025	fuzzy logic;econometrics;mathematical optimization;algorithmic learning theory;empirical risk minimization;membership function;defuzzification;type-2 fuzzy sets and systems;fuzzy classification;computer science;artificial intelligence;fuzzy number;machine learning;fuzzy measure theory;mathematics;stability;computational learning theory;statistics;generalization error	AI	20.409023947430484	-31.271686888585553	120029
2dd28974ccca10fe7ba102063531c8da328d9c38	a new xml-based language for neural solution interchange	neural model;network structure;neural network model;markup language;neural network	This article introduces a framework for interchange of trained neural network models. An XML-based language (Neural Network Markup Language) for the neural network model description is offered. It allows to write down all components of neural network model, which are necessary for its reproduction. We propose to use XML notation for full description of neural models, including data dictionary, properties of training sample, preprocessing methods, details of network structure and parameters, method for network output interpretation.	artificial neural network;data dictionary;markup language;multilayer perceptron;network model;preprocessor;radial (radio);radial basis function;xml	Denis V. Rubtsov;Sergei V. Butakov	2002			natural language processing;nervous system network models;probabilistic neural network;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;machine learning;data mining;time delay neural network;network simulation;deep learning;markup language;artificial neural network	ML	13.453763939843123	-28.249090408881845	120132
790ed36bf4cacea03fcb9ae5043feba6320126e4	protocol for secure quantum machine learning at a distant place	quantum computation;quantum machine learning;secure machine learning	The application of machine learning to quantum information processing has recently attracted keen interest, particularly for the optimization of control parameters in quantum tasks without any pre-programmed knowledge. By adapting the machine learning technique, we present a novel protocol in which an arbitrarily initialized device at a learner’s location is taught by a provider located at a distant place. The protocol is designed such that any external learner who attempts to participate in or disrupt the learning process can be prohibited or noticed. We numerically demonstrate that our protocol works faithfully for single-qubit operation devices. A trade-off between the inaccuracy and the learning time is also analyzed.	information processing;mathematical optimization;numerical analysis;quantum information science;quantum machine learning;qubit	Jeongho Bang;Seung-Woo Lee;Hyunseok Jeong	2015	Quantum Information Processing	10.1007/s11128-015-1089-7	robot learning;multi-task learning;instance-based learning;error-driven learning;algorithmic learning theory;theoretical computer science;stability;quantum computer;computational learning theory;active learning;physics;quantum mechanics	ML	17.142661189598964	-31.806692591708124	120136
fdf1f018e9d1693757ad70fd12d76b36d12e3a77	balanced sensitivity functions for tuning multi-dimensional bayesian network classifiers	balanced sensitivity functions;higher order sensitivity functions;multi dimensional classifiers;network tuning;bayesian networks	Multi-dimensional Bayesian network classifiers are Bayesian networks of restricted topological structure, which are tailored to classifying data instances into multiple dimensions. Like more traditional classifiers, multi-dimensional classifiers are typically learned from data and may include inaccuracies in their parameter probabilities. We will show that the graphical properties and dedicated use of these classifiers induce higher-order sensitivity functions of a highly constrained functional form in these parameters. We then introduce the concept of balanced sensitivity function in which multiple parameters are functionally related by the odds ratios of their original and new values, and argue that these functions provide for a suitable heuristic for tuning multi-dimensional classifiers with guaranteed bounds on the effects on their output probabilities. We demonstrate the practicability of our heuristic by means of a classifier for a real-world application in the veterinary field. N-way sensitivity functions which can be established efficiently are given for MDCs.Balanced functions, capturing BN output in multiple, tied, parameters are introduced.Balanced tuning of multi-dimensional Bayesian classifiers is formalised.	bayesian network	Janneke H. Bolt;Linda C. van der Gaag	2017	Int. J. Approx. Reasoning	10.1016/j.ijar.2016.07.011	random subspace method;computer science;machine learning;pattern recognition;bayesian network;data mining;mathematics;statistics	AI	17.25434339889627	-37.84994943991382	120142
d8c3ec541ddd624d8a0c506386a3c8cf6954e56a	learning unbelievable marginal probabilities	learning algorithm;positive definite;artificial intelligent;science learning;belief propagation;probability distribution;graphical model;approximate inference;free energy;loopy belief propagation	Loopy belief propagation performs approximate inference on graphical models with loops. One might hope to compensate for the approximation by adjusting model parameters. Learning algorithms for this purpose have been explored previously, and the claim has been made that every set of locally consistent marginals can arise from belief propagation run on a graphical model. On the contrary, here we show that many probability distributions have marginals that cannot be reached by belief propagation using any set of model parameters or any learning algorithm. We call such marginals ‘unbelievable.’ This problem occurs whenever the Hessian of the Bethe free energy is not positive-definite at the target marginals. All learning algorithms for belief propagation necessarily fail in these cases, producing beliefs or sets of beliefs that may even be worse than the pre-learning approximation. We then show that averaging inaccurate beliefs, each obtained from belief propagation using model parameters perturbed about some learned mean values, can achieve the unbelievable marginals.	approximation algorithm;belief propagation;casio loopy;graphical model;hessian;machine learning;marginal model;software propagation	Zachary Pitkow;Yashar Ahmadian;Kenneth D. Miller	2011	CoRR		computer science;artificial intelligence;machine learning;pattern recognition;mathematics;statistics;belief propagation	ML	24.305207738886224	-29.108768935598793	120151
2990934ec693cd98f6bb99760d9341539b2191b8	a median variant of generalized learning vector quantization		We introduce a median variant of the Generalized Learning Vector Quantization (GLVQ) algorithm. Thus, GLVQ can be used for classification problem learning, for which only dissimilarity information between the objects to be classified is available. For this purpose, the cost function of GLVQ is reformulated as a probabilistic model such that a generalized expectation maximization scheme can be applied as learning procedure. We give a rigorous mathematical proof for the new approach. Exemplary examples demonstrate the performance and the behavior of the algorithm.	expectation–maximization algorithm;learning vector quantization;loss function;statistical model	David Nebel;Barbara Hammer;Thomas Villmann	2013		10.1007/978-3-642-42042-9_3	mathematical optimization;machine learning;pattern recognition;mathematics	ML	21.40577319558183	-35.872062299327276	120264
0dc94dab3cf1e6d101469b631e89372c255e7eb2	improved loss bounds for multiple kernel learning	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;ucl research	We propose two new generalization error bounds for multiple kernel learning (MKL). First, using the bound of Srebro and BenDavid (2006) as a starting point, we derive a new version which uses a simple counting argument for the choice of kernels in order to generate a tighter bound when 1-norm regularization (sparsity) is imposed in the kernel learning problem. The second bound is a Rademacher complexity bound which is additive in the (logarithmic) kernel complexity and margin term. This dependence is superior to all previously published Rademacher bounds for learning a convex combination of kernels, including the recent bound of Cortes et al. (2010), which exhibits a multiplicative interaction. We illustrate the tightness of our bounds with simulations.	generalization error;kernel (operating system);math kernel library;matrix regularization;multiple kernel learning;rademacher complexity;simulation;sparse matrix;utility functions on indivisible goods	Zakria Hussain;John Shawe-Taylor	2011			computer science;artificial intelligence;theoretical computer science	ML	22.079600135007375	-33.83298640206062	120515
c56cbfa164ca2f640ed74b9c5ed8778af10b10d1	medical dynamic data series prediction using neural network methods	neural network;dynamic data		artificial neural network;dynamic data	Wieslaw Wajs	2003			machine learning;artificial intelligence;probabilistic neural network;pattern recognition;artificial neural network;computer science;dynamic data;time delay neural network	ML	12.658351118746511	-27.02171783724367	120522
836e0f292897144d30ae0cab2cacbf55cd1a32ca	optimality of community structure in complex networks		Community detection is one of the pivotal tools for discovering the structure of complex networks. Majority of community detection methods rely on optimization of certain quality functions characterizing the proposed community structure. Perhaps, the most commonly used of those quality functions is modularity. Many heuristics are claimed to be efficient in modularity maximization, which is usually justified in relative terms through comparison of their outcomes with those provided by other known algorithms. However as all the approaches are heuristics, while the complete brute-force is not feasible, there is no known way to understand if the obtained partitioning is really the optimal one. In this article we address the modularity maximization problem from the other side — finding an upper-bound estimate for the possible modularity values within a given network, allowing to better evaluate suggested community structures. Moreover, in some cases when then upper bound estimate meets the actually obtained modularity score, it provides a proof that the suggested community structure is indeed the optimal one. We propose an efficient algorithm for building such an upper-bound estimate and illustrate its usage on the examples of well-known classical and synthetic networks, being able to prove the optimality of the existing partitioning for some of the networks including well-known Zachary’s Karate Club.	brute-force search;complex network;entropy maximization;expectation–maximization algorithm;heuristic (computer science);mathematical optimization;modularity (networks);synthetic intelligence;zachary lemnios	Stanislav Sobolevsky;Alexander Belyi;Carlo Ratti	2017	CoRR		relative term;machine learning;artificial intelligence;computer science;complex network;heuristics;maximization;community structure;modularity;upper and lower bounds	AI	23.280908553442487	-26.0757159404333	120570
acc6c587f1fceaa2b6bed7f896e0cff0ef3f5709	one-class classifier based on extreme value statistics		In recent years, interest in one-class classification methods has soared due to its wide applicability in many practical problems in which classification in the absence of counterexamples is needed. In this paper, a new one class classification rule based on order statistics is presented. It only relies on embedding the classification problem into a metric space, so it is suitable for Euclidean or other structured mappings. The suitability of the proposed method is assessed through a comparison both for artificial and real life data sets. The good results obtained pave the road for its application on practical novelty detection problems.	instance-based learning;k-nearest neighbors algorithm;maxima and minima;novelty detection;one-class classification;real life;software metric	David Martínez-Rego;Evan Kriminger;José Carlos Príncipe;Oscar Fontenla-Romero;Amparo Alonso-Betanzos	2012			artificial intelligence;pattern recognition;machine learning;extreme value theory;rule-based system;order statistic;metric space;one-class classification;data set;novelty detection;embedding;mathematics	ML	11.475067233637633	-37.904898519797335	120586
b6c820a81bcc9917395a6f0ac58c12d740158229	bayesian approach to rough set	bayesian framework;metropolis algorithm;mcmc methods;bayesian approach;prior knowledge;artificial intelligent;markov chain monte carlo;rough set	This paper proposes an approach to training rough set models using Bayesian framework trained using Markov Chain Monte Carlo (MCMC) method. The prior probabilities are constructed from the prior knowledge that good rough set models have fewer rules. Markov Chain Monte Carlo sampling is conducted through sampling in the rough set granule space and Metropolis algorithm is used as an acceptance criteria. The proposed method is tested to estimate the risk of HIV given demographic data. The results obtained shows that the proposed approach is able to achieve an average accuracy of 58% with the accuracy varying up to 66%. In addition the Bayesian rough set give the probabilities of the estimated HIV status as well as the linguistic rules describing how the demographic parameters drive the risk of HIV.	computation;granule (oracle dbms);markov chain monte carlo;metropolis;metropolis–hastings algorithm;monte carlo method;rough set;sampling (signal processing)	Tshilidzi Marwala;Bodie Crossingham	2007	CoRR		bayesian average;metropolis–hastings algorithm;econometrics;rough set;variable-order bayesian network;hybrid monte carlo;markov chain monte carlo;bayesian probability;computer science;pattern recognition;mathematics;rejection sampling;bayesian statistics;statistics	ML	15.562858688754147	-36.824944079149965	120742
2eb2183ebb4fcc342d60b6183e3f2288c6087483	efficiency of deep networks for radially symmetric functions		Abstract We prove that radially symmetric functions in d dimensions can be approximated by a deep network with fewer neurons than the previously best known result. Our results are much more efficient in terms of the support radius of the radial function and the error of approximation. Our proofs are all constructive and we specify the network architecture and almost all of the weights. The method relies on space-folding transformations that allow us to approximate the norm of a high dimensional vector using relatively few neurons.		Brendan McCane;Lech Szymanski	2018	Neurocomputing	10.1016/j.neucom.2018.06.003	machine learning;artificial intelligence;constructive;discrete mathematics;mathematics;radial function;mathematical proof;network architecture;symmetric function	Logic	18.56337820904945	-29.98844838670473	121052
4e66bbada9d3179bc3a5be6796ac94864b6be1bd	a new k-winners-take-all neural network and its array architecture	red sistolica;memoire;arquitectura red;learning;etude theorique;distributed computing;systolic array;neural net architecture;intelligence artificielle;convergence rate;indexing terms;architecture reseau;data distribution;competitive learning;aprendizaje;apprentissage;parallel architectures;memoria;systolic network;distributed arithmetic;estudio teorico;neural net architecture parallel architectures;pattern recognition;reseau systolique;calculo repartido;artificial intelligence;network architecture;neural networks convergence computer architecture hardware computational modeling artificial neural networks pattern recognition analog circuits neurons arithmetic;inteligencia artificial;reconnaissance forme;theoretical study;neural network model;reseau neuronal;reconocimiento patron;winner take all;calcul reparti;red neuronal;memory;computing speed winners take all neural network array architecture winstron competitive learning algorithm coarse fine competition data distributions hardware complexity;artificial neural network;neural network	In this paper, a new neural-network model called WINSTRON and its novel array architecture are proposed. Based on a competitive learning algorithm that is originated from the coarse-fine competition, WINSTRON can identify the k larger elements or the k smaller ones in a data set. We will then prove that WINSTRON converges to the correct state in any situation. In addition, the convergence rates of WINSTRON for three special data distributions will be derived. In order to realize WINSTRON, its array architecture with low hardware complexity and high computing speed is also detailed. Finally, simulation results are included to demonstrate its effectiveness and its advantages over three existing networks.		Jui-Cheng Yen;Jiun-In Guo;Hun-Chen Chen	1998	IEEE transactions on neural networks	10.1109/72.712163	winner-take-all;network architecture;index term;systolic array;computer science;artificial intelligence;theoretical computer science;machine learning;rate of convergence;memory;competitive learning;artificial neural network	ML	16.38221067056626	-28.07102387067643	121121
2b9a2f7d2c56e9a842035a76e3ab11389f92154a	classification in presence of drift and latency	unlabeled data;concept drift;drift models;supervised learning;drift adaptive classification concept drift population drift change mining systematic drift verification latency drift models;pattern classification expectation maximisation algorithm learning artificial intelligence;population drift;drift adaptive classification;adaptation models systematics data models training context vectors adaptive systems;adaptive learning;time lag;pattern classification;expectation maximisation algorithm underlying distributions supervised learning incremental model updates verification latency change mining paradigm explicit models drift models exemplary drift adaptive learning strategy;model updating;verification latency;learning artificial intelligence;expectation maximisation;systematic drift;change mining;expectation maximisation algorithm	Changes in underlying distributions over time are a challenging problem in supervised learning. While this problem of drift is subject to an increasing effort in research, some definitions required for proper distinction of types of drift remain ambiguous. Furthermore, the approaches discussed in literature so far require new, labelled data for incremental model updates. However, there are domains in which such data is scarce or only available with a considerable time lag, a so-called verification latency. This issues are addressed in this paper: First, the different notations used in literature are related, and an overview over types of drift is given. Second, following the change mining paradigm, explicit models of drift are introduced. These drift models can be employed when actual, labelled data is scarce or not available at all, as they allow to anticipate changes in distributions over time. Third, an exemplary drift-adaptive learning strategy that employs such a drift model is presented: Using an expectation-maximisation algorithm, a mixture of subpopulations is tracked. As a result, the classification model can be updated using solely new, unlabelled data.	expectation–maximization algorithm;interrupt latency;programming paradigm;supervised learning;verification and validation	Georg Krempl;Vera Hofer	2011	2011 IEEE 11th International Conference on Data Mining Workshops	10.1109/ICDMW.2011.47	computer science;artificial intelligence;concept drift;machine learning;pattern recognition;data mining;supervised learning;adaptive learning;statistics	DB	15.238473953509487	-37.6568809327885	121174
43452a72fdf30e84b1e03a8deb4341a19ab5eb9e	supervised neural networks with memristor binary synapses.				Jacopo Secco;Mauro Poggio;Fernando Corinto	2018	I. J. Circuit Theory and Applications	10.1002/cta.2429	synapse;memristor;electronic engineering;mathematics;artificial neural network;binary number;artificial intelligence	ML	13.366865099783949	-27.2994956740579	121296
95e3c215a84d46a199ed65a6b8009d62f904f29e	chemical separation process monitoring based on nonlinear principal component analysis	nonlinear principal component analysis;process monitoring;principal component analysis;neural network;principal component	  Principal component analysis (PCA) is a useful tool to deal with linear relationship among process variables. For many industrial  processes with variables containing nonlinear relationship, conventional PCA methods lose their power. Instead, applying neural  network technique, some generalized linear PCA methods are presented. Motivated by the results of [1], this paper discusses  monitoring and diagnosis for a chemical separation process. Two neural networks are employed, one of which is used to model  nonlinear loading functions, and another to map principal components onto corrected data set.    	nonlinear programming;principal component analysis	Fei Liu;Zhong-Gai Zhao	2004		10.1007/978-3-540-28647-9_131	computer science;machine learning;artificial neural network;principal component analysis	ML	23.021848310603286	-24.106648346564427	121888
61b311d1aefde1cc224679a0530252730a66b818	a behavioral approach to testability analysis for neural networks	behavioral approach;neural network	Abstract   The present trend towards design of VLSI (or WSI) neural chips introduces — among other problems — that of testing such complex architectures or, even better, of adopting design alternatives provided with known testability. Up to now, such problems has not been considered in a general way, as related to the specific class of high-level architecture envisioned, but rather (if at all) afforded with respect to a specific design and a particular technology.  We propose a behavioral-level approach, starting from the abstract definition of the neural computation for a particular class of neural networks; on this general model, we introduce a philosophy by which testability (as the compound of controllability and observability) can be analyzed. More precisely, we take into account  dedicated  multi-layered feed-forward networks, such that both their abstract topology and their weight distribution have been totally defined.  The conditions granting testability of such networks are derived; these can then be adopted as guidelines in the design of a VLSI implementation, through a suitable mapping of the physical faults associated with the implementation onto the behavioral errors defined on the abstract model.	artificial neural network	Vincenzo Piuri;Mariagiovanna Sami;Donatella Sciuto;Renato Stefanelli	1992	Microprocessing and Microprogramming	10.1016/0165-6074(92)90314-W	parallel computing;computer science;artificial intelligence;theoretical computer science;distributed computing;artificial neural network;algorithm	ML	16.45201710525963	-26.445032126081998	121971
5571c16f244ba8169ed88d4524827f6e42bd4ca6	a modified hopfield auto-associative memory with improved capacity	hebbian learning;vector space;hopfield neural nets;matrix algebra;fixed point;statistical deviation modified hopfield auto associative memory memory capacity recurrent neural network rnn learning mechanism hebb law synaptic matrix graph weight matrix tetrahedral matrices multidimensional state vector space classification parameter vector;statistical analysis;statistical analysis content addressable storage hopfield neural nets hebbian learning matrix algebra;associative memory;prototypes neurons recurrent neural networks learning systems weight control optimization methods neural networks equations;recurrent neural network;content addressable storage;complete graph	This paper describes a new procedure to implement a recurrent neural network (RNN), based on a new approach to the well-known Hopfield autoassociative memory. In our approach a RNN is seen as a complete graph G and the learning mechanism is also based on Hebb's law, but with a very significant difference: the weights, which control the dynamics of the net, are obtained by coloring the graph G. Once the training is complete, the synaptic matrix of the net will be the weight matrix of the graph. Any one of these matrices will fulfill some spatial properties, for this reason they will be referred to as tetrahedral matrices. The geometrical properties of these tetrahedral matrices may be used for classifying the n-dimensional state-vector space in n classes. In the recall stage, a parameter vector is introduced, which is related with the capacity of the network. It may be shown that the bigger the value of the ith component of the parameter vector is, the lower the capacity of the [i] class of the state-vector space becomes. Once the capacity has been controlled, a new set of parameters that uses the statistical deviation of the prototypes to compare them with those that appear as fixed points is introduced, eliminating thus a great number of parasitic fixed points.		V. Gimenez-Martinez	2000	IEEE transactions on neural networks	10.1109/72.857768	hebbian theory;vector space;computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;mathematics;fixed point;bidirectional associative memory;hopfield network;complete graph	ML	16.087376575006505	-26.669239777027013	122220
3fee7b836b71125a5f6a3696b9c383dae18c21e8	a study on overfitting in deep reinforcement learning		Recent years have witnessed significant progresses in deep Reinforcement Learning (RL). Empowered with large scale neural networks, carefully designed architectures, novel training algorithms and massively parallel computing devices, researchers are able to attack many challenging RL problems. However, in machine learning, more training power comes with a potential risk of more overfitting. As deep RL techniques are being applied to critical problems such as healthcare and finance, it is important to understand the generalization behaviors of the trained agents. In this paper, we conduct a systematic study of standard RL agents and find that they could overfit in various ways. Moreover, overfitting could happen “robustly”: commonly used techniques in RL that add stochasticity do not necessarily prevent or detect overfitting. In particular, the same agents and learning algorithms could have drastically different test performance, even when all of them achieve optimal rewards during training. The observations call for more principled and careful evaluation protocols in RL. We conclude with a general discussion on overfitting in RL and a study of the generalization behaviors from the perspective of inductive bias.	algorithm;artificial neural network;inductive bias;lazy evaluation;machine learning;overfitting;parallel computing;reinforcement learning	Chiyuan Zhang;Oriol Vinyals;Rémi Munos;Samy Bengio	2018	CoRR		overfitting;massively parallel;machine learning;artificial neural network;reinforcement learning;artificial intelligence;inductive bias;mathematics	ML	17.8774206046612	-33.181904426788876	122728
aaad6195a84b3489a9f9307c121c7818a4b0401c	on the complexity of learning for spiking neurons with temporal coding	fonction booleenne;membrane potential;arquitectura red;potentiel postsynaptique;potentiel membrane;learning;pac learning;complexite calcul;boolean function;systeme neuronal biologique;architecture reseau;potencial postsinaptico;dimension reseau vapnik chervonenkis;aprendizaje;upper bound;codificacion;complejidad computacion;apprentissage;spiking neurons;potencial membrana;computational complexity;funcion booliana;coding;vlsi;potencial accion;temporal coding;network architecture;reseau neuronal;borne superieure;action potential;probably approximately correct learning;vapnik chervonenkis network dimension;red neuronal;vapnik chervonenkis dimension;biological neural system;vc dimension;postsynaptic potential;potentiel action;codage;cota superior;neural network	Spiking neurons are models for the computational units in biological neural systems where information is considered to be encoded mainly in the temporal patterns of their activity. In a network of spiking neurons a new set of parameters becomes relevant which has no counterpart in traditional neural network models: the time that a pulse needs to travel through a connection between two neurons (also known as delay of a connection). It is known that these delays are tuned in biological neural systems through a variety of mechanisms. In this article we consider the arguably most simple model for a spiking neuron, which can also easily be implemented in pulsed VLSI. We investigate the Vapnik Chervonenkis (VC) dimension of networks of spiking neurons, where the delays are viewed as programmable parameters and we prove tight bounds for this VC dimension. Thus, we get quantitative estimates for the diversity of functions that a network with fixed architecture can compute with different settings of its delays. In particular, it turns out that a network of spiking neurons with k adjustable delays is able to compute a much richer class of functions than a threshold circuit with k adjustable weights. The results also yield bounds for the number of training examples that an algorithm needs for tuning the delays of a network of spiking neurons. Results about the computational complexity of such algorithms are also given. ] 1999 Academic Press Article ID inco.1999.2806, available online at http: www.idealibrary.com on	action potential;alexey chervonenkis;algorithm;artificial neuron;boolean circuit;caller id;computation;computational complexity theory;computational model;hypertext transfer protocol;id-wsf;neural coding;provable security;spiking neural network;supervised learning;tagged union;vc dimension;vapnik–chervonenkis theory	Wolfgang Maass;Michael Schmitt	1997	Inf. Comput.	10.1006/inco.1999.2806	random neural network;computer science;artificial intelligence;machine learning;mathematics;probably approximately correct learning;artificial neural network;algorithm;spiking neural network	ML	17.94671500897503	-27.64685687967462	122734
115cef4adbd350c532666eb923d66b8f069c5d1e	recognizing and simulating neuronal spike patterns with hidden markov models	hidden markov model		hidden markov model;markov chain	G. Radons;J. D. Becker	1993			maximum-entropy markov model;markov model	ML	21.843178180918606	-25.21077823866963	122797
582c6c555dce97964438cf6f95c5474cdfbd58db	selecting features by learning markov blankets	conditional independence;bayesian network;learning;feature selection;bayesian networks	In this paper I propose a novel feature selection technique based on Bayesian networks. The main idea is to exploit the conditional independencies entailed by Bayesian networks in order to discard features that are not directly relevant for classification tasks. An algorithm for learning Bayesian networks and its use in feature selection are illustrated. The advantages of this algorithm with respect to other ones are then discussed. Finally, experimental results are offered which confirm the reliability of the algorithm.	algorithm;bayesian network;feature selection;markov chain	Antonino Freno	2007		10.1007/978-3-540-74819-9_9	variable-order bayesian network;wake-sleep algorithm;bayesian programming;computer science;machine learning;causal markov condition;pattern recognition;data mining;graphical model;bayesian statistics;feature selection	AI	16.78949338467945	-37.24860293028443	122817
47d540eaa09d5f060b620146a319b5556805e08e	why deep neural networks?		Recently there has been much interest in understanding why deep neural networks are preferred to shallow networks. In this paper, we show that, for a large class of piecewise smooth functions, the number of neurons needed by a shallow network to approximate a function is exponentially larger than the corresponding number of neurons needed by a deep network for a given degree of function approximation. First, we consider univariate functions on a bounded interval and require a neural network to achieve an approximation error of ε uniformly over the interval. We show that shallow networks (i.e., networks whose depth does not depend on ε) require Ω(poly(1/ε)) neurons while deep networks (i.e., networks whose depth grows with 1/ε) require O(polylog(1/ε)) neurons. We then extend these results to certain classes of important multivariate functions. Our results are derived for neural networks which use a combination of rectifier linear units (ReLUs) and binary step units, two of the most popular type of activation functions. Our analysis builds on this simple observation that the binary approximation of a real number in the interval [0, 1] can be represented by a deep neural network which uses a “small” number of neurons.	activation function;approximation algorithm;approximation error;artificial neural network;deep learning;neural networks;neuron;rectifier (neural networks)	Shiyu Liang;R. Srikant	2016	CoRR			ML	18.749319589978672	-30.238999742479404	122822
761bbc9336e9c0bceb557aef7118d04b6b0a396c	matched-field source localization using sparsely-coded neural network and data-model mixed training		Source localization is a basic problem in underwater acoustics. Many solving approaches have been developed, and the matched-field processing (MFP) is one of the mostly-studied. However, MFP is sensitive to the mismatch problem and performs well only when the knowledge of ocean environment is accurate. Machine learning learns directly from the observation and can be designed to learn a generic model suitable for different scenarios. In this paper, source localization is viewed as a machine learning problem and a matched-field source localization model is learned by training a sparsely-coded feed-forward neural network with mixed environment models and data. Sparsely-coded network can prevent the model from over-learning. Results on SWellEx-96 experiment show that the learned model achieves good positioning performance in source range estimation for varying sound-speed profiles (SSP). Compared with Bartlett matched-field processing, machine learning model is more robust and thus has potential advantages in underwater source localization.	acoustic cryptanalysis;artificial neural network;bartlett's bisection theorem;basis function;control theory;data model;dataspaces;feedforward neural network;machine learning;naive bayes classifier;nonlinear acoustics;simulation	Shougui Cai;Wen Xu	2017		10.1145/3148675.3148717	underwater acoustics;real-time computing;computer science;data model;artificial neural network;probabilistic neural network;time delay neural network;artificial intelligence;machine learning	AI	17.882924949602714	-30.747539524649973	122831
aac56bfec9785b5f2cda77c03cb6906d80834463	non-linear classification of massive datasets with a parallel algorithm of local support vector machines		We propose a new parallel algorithm of local support vector machines, called kSVM for the effectively non-linear classification of large datasets. The learning strategy of kSVM uses kmeans algorithm to partition the data into k clusters, followed which it constructs a non-linear SVM in each cluster to classify the data locally in the parallel way on multi-core computers. The kSVM algorithm is faster than the standard SVM in the non-linear classification of large datasets while maintaining the classification correstness. The numerical test results on 4 datasets from UCI repository and 3 benchmarks of handwritten letters recognition showed that our proposal is efficient compared to the standard SVM.	linear classifier;parallel algorithm;support vector machine	Thanh-Nghi Do	2015		10.1007/978-3-319-17996-4_21	support vector machine;nonlinear system;parallel algorithm;k-means clustering;artificial intelligence;pattern recognition;computer science	ML	13.12859751764121	-36.931349531977574	122842
05c8590b8ed480852891a12fb6259c914b0b2ca4	linear unlearning for cross-validation	network model;cross validation;leave one out cross validation;leave one out	The leave-one-out cross-validation scheme for generalization assessment of neural network models is computationally expensive due to replicated training sessions. In this paper we suggest linear unlearning of examples as an approach to approximative cross-validation. Further, we discuss the possibility of exploiting the ensemble of networks o ered by leave-one-out for performing ensemble predictions. We show that the generalization performance of the equally weighted ensemble predictor is identical to that of the network trained on the whole training set. Numerical experiments on the sunspot time series prediction benchmark demonstrates the potential of the linear unlearning technique.	analysis of algorithms;benchmark (computing);cross-validation (statistics);data validation;experiment;kerrison predictor;test set;time series	Lars Kai Hansen;Jan Larsen	1996	Adv. Comput. Math.	10.1007/BF02124747	computer science;artificial intelligence;machine learning;data mining;mathematics;cross-validation	ML	11.404897119285506	-24.009134404568318	122848
48ae39347fe985987ea5059e328ad3739fd0041f	predicting residual weld stress distribution with an adaptive neuro-fuzzy inference system			adaptive neuro fuzzy inference system;inference engine;neuro-fuzzy	Houichi Kitano;Terumi Nakamura	2018	IJAT	10.20965/ijat.2018.p0290	adaptive neuro fuzzy inference system;residual;computer science;artificial intelligence;pattern recognition	NLP	10.417393005950384	-25.36598184246687	122963
de6fb2d1cd56de7e6d90f5148fe8d3668983fe05	reliable on-line machine learning for regression tasks in presence of uncertainties			machine learning;online and offline	Andreas Buschermöhle	2014				AI	10.458733821693734	-26.040729608817692	123023
e1f76061a0e04ab7bacc641552b4bf76e9d24700	"""comments on """"accelerated learning algorithm for multilayer perceptrons: optimization layer by layer"""""""	optimisation;layer by layer;learning algorithm;performance evaluation;neural networks;multilayer perceptrons;multilayer perceptron;indexing terms;multi layer neural network;acceleration;conjugate gradient;matrix decomposition;performance evaluation multilayer perceptrons learning artificial intelligence optimisation;character generation;acceleration multilayer perceptrons neural networks optimization methods equations matrix decomposition algorithm design and analysis multi layer neural network character generation performance analysis;performance analysis;accelerated learning algorithm;optimization layer by layer;learning artificial intelligence;algorithm design and analysis;training algorithm;conjugate gradient accelerated learning algorithm multilayer perceptrons optimization layer by layer performance evaluation;neural network;optimization methods	This letter analyzes the performance of the neural network training method known as optimization layer by layer. We show, from theoretical considerations, that the amount of work required with OLL-Learning scales as the third power of the network size, compared with the square of the network size for commonly used conjugate gradient training algorithms. This theoretical estimate is confirmed through a practical example. Thus, although OLL is shown to function very well for small neural networks (less than about 500 weights per layer), it is slower than CG for large neural networks. Second, we show that OLL does not always improve on the accuracy that can be obtained with CG. It seems that the final accuracy that can be obtained depends strongly on the initial network weights.		B. Ph. Van Milligen;V. Tribaldos;J. A. Jimenez;Carlos Santa Cruz	1998	IEEE transactions on neural networks	10.1109/72.661128	acceleration;layer by layer;algorithm design;index term;computer science;artificial intelligence;theoretical computer science;machine learning;conjugate gradient method;multilayer perceptron;matrix decomposition;artificial neural network	ML	16.804467220650672	-28.572259662053117	123070
09bcfb61ae05c3c35f666132953629a3e57dbbd4	causal inference by stochastic complexity		e algorithmic Markov condition states that the most likely causal direction between two random variables X and Y can be identied as that direction with the lowest Kolmogorov complexity. Due to the halting problem, however, this notion is not computable. We hence propose to do causal inference by stochastic complexity. at is, we propose to approximate Kolmogorov complexity via the Minimum Description Length (MDL) principle, using a score that is mini-max optimal with regard to the model class under consideration. is means that even in an adversarial seing, such as when the true distribution is not in this class, we still obtain the optimal encoding for the data relative to the class. We instantiate this framework, which we call cisc, for pairs of univariate discrete variables, using the class of multinomial distributions. Experiments show that cisc is highly accurate on synthetic, benchmark, as well as real-world data, outperforming the state of the art by a margin, and scales extremely well with regard to sample and domain sizes.	adversary (cryptography);approximation algorithm;benchmark (computing);causal filter;causal inference;computable function;dhrystone;experiment;halting problem;information theory;kolmogorov complexity;markov chain;minimum description length;multinomial logistic regression	Kailash Budhathoki;Jilles Vreeken	2017	CoRR		kolmogorov structure function;econometrics;combinatorics;machine learning;mathematics;statistics	ML	24.051255414018453	-29.11969676262018	123100
3cfdec1ee3866d09616187c2e7659e3161a6e6f6	an application of neural networks for harmonic coefficients and relative phase shifts detection	feed forward neural network;scaled conjugate gradient;phase shift;harmonic phase detection;harmonic compensation;harmonic coefficients detection;active filter;active filters;training algorithm;uniform distribution;neural network	The varying the phase shifts will completely change the shape of the distorted wave, and may thus greatly affect the ability of the neural network to recognize harmonics. In this study, feed forward neural networks were used for the detection of the harmonic coefficients and relative phase shifts. The distorted wave including uniform distributed 5th, 7th, 11th, 13th, 17th, 19th, 23rd, 25th harmonics with up to 20^o relative phase shifts were simulated and used. Two neural networks were used for this purpose. One of the neural networks was used for the detection of the 5th, 7th, 11th, 13th harmonic coefficients and the other was used for the detection of the relative phase shifts of these harmonics. Scaled conjugate gradient algorithm was used as training algorithm for the weights update of the neural networks. The results show that these neural networks are applicable to detect each harmonic coefficient and relative phase shift effectively.	artificial neural network;coefficient	Hasan Temurtas;Fevzullah Temurtas	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.08.131	computer science;machine learning;control theory;mathematics;active filter;artificial neural network	ML	20.6714063093769	-25.842438900505606	123215
92d621a603cda8c32214d70953e180fe5a442f3e	n2n learning: network to network compression via policy gradient reinforcement learning		While bigger and deeper neural network architectures continue to advance the state-of-the-art for many computer vision tasks, real-world adoption of these networks is impeded by hardware and speed constraints. Conventional model compression methods attempt to address this problem by modifying the architecture manually or using pre-defined heuristics. Since the space of all reduced architectures is very large, modifying the architecture of a deep neural network in this way is a difficult task. In this paper, we tackle this issue by introducing a principled method for learning reduced network architectures in a data-driven way using reinforcement learning. Our approach takes a larger u0027teacheru0027 network as input and outputs a compressed u0027studentu0027 network derived from the u0027teacheru0027 network. In the first stage of our method, a recurrent policy network aggressively removes layers from the large u0027teacheru0027 model. In the second stage, another recurrent policy network carefully reduces the size of each remaining layer. The resulting network is then evaluated to obtain a reward -- a score based on the accuracy and compression of the network. Our approach uses this reward signal with policy gradients to train the policies to find a locally optimal student network. Our experiments show that we can achieve compression rates of more than 10x for models such as ResNet-34 while maintaining similar performance to the input u0027teacheru0027 network. We also present a valuable transfer learning result which shows that policies which are pre-trained on smaller u0027teacheru0027 networks can be used to rapidly speed up training on larger u0027teacheru0027 networks.	actor model;algorithm;artificial neural network;baseline (configuration management);bellman equation;computation;computer vision;control theory;converge;deep learning;experiment;gradient;heuristic (computer science);local optimum;long short-term memory;mnist database;rate of convergence;reinforcement learning	Anubhav Ashok;Nicholas Rhinehart;Fares N. Beainy;Kris M. Kitani	2017	CoRR		computer science;architecture;transfer of learning;deep learning;machine learning;network architecture;artificial neural network;pattern recognition;speedup;heuristics;reinforcement learning;artificial intelligence	ML	17.45198314352281	-32.407574271526364	123365
90d97586a2e71fc04ac7909dd678b32a855634fc	a convergence theorem for hierarchies of model neurones	convergence theorem;perceptron;learning machine;model neurones	"""The threshold logic unit (T.L.U.) has been proposed as a model for a single neurone; other substantially cognate terms are """"perceptron"""" and """"adaline"""". Networks of these elements have been advanced as tentative models of some aspects of brain functioning. In particular, hierarchical nets appear to exhibit a sufficient flexibility to make them iteresting both as plausible models of learning in the central nervous system and also as general objects of study in connection with pattern recognition and artificial intelligence. In this paper, we discuss the well-known """"perceptron convergence theorem"""" in a fairly general setting, and consider variations appropriate to nets of such units. A certain familiarity with the relevant chapters of Nilsson’s Learning Machines [1] and also with current mathematical formalism is"""	adaline;artificial intelligence;artificial neuron;pattern recognition;perceptron;semantics (computer science);whole earth 'lectronic link	Michael D. Alder	1975	SIAM J. Comput.	10.1137/0204042	mathematical optimization;combinatorics;computer science;artificial intelligence;perceptron;machine learning;mathematics;algorithm	AI	17.531366815733012	-26.983053193259067	123509
7b47df505a1a00f2e7a464321f6033bd88f0b2b1	induction of recursive bayesian classifiers	bayesian classifier;simple bayesian classifier;recursive algorithm	1. I n t r o d u c t i o n In recent years, there has been growing interest in probabilistic methods for induction. Although much of the recent work in this area [e.g., 6] has focused on unsupervised learning, the approach applies equally well to supervised tasks. Such methods have long been used within the field of pattern recognition [4], but they have only recently received attention within the machine learning community [3, 7, 8, 9]. In this paper we review the most straightforward probabilistic approach to supervised learning the induction of simple Bayesian classifiers. We also examine this method's apparent drawbacks and propose a revised algorithm that constructs a hierarchy of probabilistic summaries. We present an illustrative domain that this approach can handle but that the simpler scheme cannot, and we report experimental studies of the two algorithms on both natural and artificial induction tasks. Finally, we discuss work on related approaches and some directions for future research. 2. T h e induction of s i m p l e B a y e s i a n c l a s s i f i e r s The most straightforward and widely tested method for probabilistic induction is known as the simple Bayesian classifier. This scheme represents each concept with a single probabilistic summary. In particular, each description has an associated class probability or base rate, p(Ck), which specifies the prior probability that one will observe a member of class Ck. Each description also has an associated set of conditional probabilities, specifying a probability distribution for each attribute. In nominal domains, one typically stores a discrete distribution	algorithm;base rate;bayesian network;inductive reasoning;machine learning;mathematical induction;naive bayes classifier;pattern recognition;recursion (computer science);supervised learning;unsupervised learning	Pat Langley	1993		10.1007/3-540-56602-3_134	naive bayes classifier;recursive bayesian estimation;variable-order bayesian network	ML	17.481027875082614	-33.83446171857556	123662
aacbf97fbcd17ae3319ac2aca25c2d4daccaf97b	genetic selection algorithm and cloning for data mining with gmdh method		The Group Method Data Handling Multilayer Iterative Algorithm (GMDH MIA) is modified by use of the selection procedure from  genetic algorithms while including cloning of the best neurons generated to obtain even less error. The selection procedure  finds parents for a new neuron among already existing neurons according to the fitness and also with some probability from  the network inputs. The essence of cloning is slight modifying the parameters of the copies of the best neuron, i.e. the neuron  with the largest fitness. The genetically modified GMDH network with cloning (GMC GMDH) can outperform other powerful methods.  It is demonstrated on some tasks from the Machine Learning Repository.  	data mining;genetic algorithm;group method of data handling;selection algorithm	Marcel Jirina;Marcel Jirina	2009		10.1007/978-3-642-01536-6_14	machine learning;pattern recognition;data mining	ML	15.239584500005526	-30.364392708442175	123749
590602999c964a3457f22cf26c43c6efffdb02d6	sparsely interconnected artificial neural networks for associative memories	associative memory;artificial neural network;neural network	We develop in the present paper a design procedure for neural networks with sparse coefficient matrices. Our results guarantee that the synthesized neural networks have predetermined sparse interconnection structures and store any set of desired memory patterns as reachable memory vectors. We show that a sufficient condition for the existence of a sparse neural network design is self feedback for every neuron in the network. Our design procedure for neural networks with sparse interconnecting structure can take into account various problems encountered in VLSI realizations of such networks. For example, our procedure can be used to design neural networks with few or without any line-crossings resulting from the network interconnections. Several specific examples are included to demonstrate the applicability of the methodology advanced herein.	artificial neural network;neural networks	Derong Liu;Anthony N. Michel	1993		10.1007/3-540-56798-4_140	nervous system network models;types of artificial neural networks;computer science;recurrent neural network;machine learning;physical neural network;content-addressable memory;time delay neural network;bidirectional associative memory;autoassociative memory;artificial neural network	ML	15.93859672804419	-26.59803879110156	124310
f40d3620c06c07a0b18d42a9c95c43e5e2330fff	a unified constructive network model for problem-solving	traveling salesman problem;optimization problem;computer experiment;pattern matching;network model;pattern classification;neural network model;problem solving	Abstract   We develop a neural network model that relieves time-consuming trial-and-error computer experiments usually performed in problem-solving with networks where problems, including the traveling salesman problem, pattern matching and pattern classification/learning, are formulated as optimization problems with constraint. First, we specify and uniquely distinguish the model as a set of constituent functions that should comply with restrictive conditions. Next, we demonstrate that it is unified, i.e., it yields most current networks. Finally, we verify that it is constructive, i.e. we show a standard method that systematically constructs from a given optimization problem a particular network in that model to solve it.	network model	Yoshikane Takahashi	1996	Theor. Comput. Sci.	10.1016/0304-3975(95)00134-4	optimization problem;2-opt;mathematical optimization;computer experiment;computer science;network model;machine learning;pattern matching;mathematics;programming language;travelling salesman problem;artificial neural network;algorithm;3-opt;bottleneck traveling salesman problem	ECom	18.584535733314368	-26.022071756235214	124546
22c383acce4a94da53de5226b77c42019a2c2430	ensemble robustness of deep learning algorithms		The question why deep learning algorithms perform so well in practice has attracted increasing research interest. However, most of well-established approaches, such as hypothesis capacity, robustness or sparseness, have not provided complete explanations, due to the high complexity of the deep learning algorithms and their inherent randomness. In this work, we introduce a new approach – ensemble robustness – towards characterizing the generalization performance of generic deep learning algorithms. Ensemble robustness concerns robustness of the population of the hypotheses that may be output by a learning algorithm. Through the lens of ensemble robustness, we reveal that a stochastic learning algorithm can generalize well as long as its sensitiveness to adversarial perturbation is bounded in average, or equivalently, the performance variance of the algorithm is small. Quantifying ensemble robustness of various deep learning algorithms may be difficult analytically. However, extensive simulations for seven common deep learning algorithms for different network architectures provide supporting evidence for our claims. Furthermore, our work explains the good performance of several published deep learning algorithms.	algorithm;deep learning;machine learning;neural coding;randomness;robustness (computer science);simulation	Jiashi Feng;Tom Zahavy;Bingyi Kang;Huan Xu;Shie Mannor	2016	CoRR		computer science;theoretical computer science;machine learning;data mining;ensemble learning;statistics;generalization error	ML	18.92383771051609	-35.948621015017075	124734
ac6fe21d5461197096a299eb15120296d97f715c	inductive pattern learning	unsupervised learning;learning systems;humans analytical models unsupervised learning stability intelligent agent current supplies costs artificial intelligence pattern recognition neural networks;formal logic learning systems learning by example unsupervised learning;learning by example;inductive learning;formal logic;analytical model;learning machine computational analytical model unsupervised learning inductive learning xor parity problems inductive agent metric model	A general (nonheuristic) computational analytical model to tackle the difficult unsupervised inductive learning problem is proposed by making some additions and modifications to an existing metric model so that the model is more elegant and able to handle the unsupervised case. It turns out that it is instructive to treat, in essence, the supervised problem with noise as an unsupervised problem. We demonstrate the success of the new model on the benchmark XOR (exclusive-or) and parity problems by showing how the inductive agent successfully learns the weights in a dynamic manner that would allow it to distinguish between bit-strings of any length and unknown labels.		Tony Y. T. Chan	1999	IEEE Trans. Systems, Man, and Cybernetics, Part A	10.1109/3468.798072	semi-supervised learning;unsupervised learning;multi-task learning;instance-based learning;error-driven learning;algorithmic learning theory;inductive bias;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;inductive transfer;stability;competitive learning;computational learning theory;logic;active learning;artificial neural network;generalization error	Robotics	16.009320162894035	-33.60241058097882	124915
74fa8db75f8f07d2eb15f13cee4535351fd0a5e3	automatic construction of radial-basis function networks through an adaptive partition algorithm		Radial-Basis Function Neural Networks (RBFN) are a well known formulation to solve classification problems. In this approach, a feedforward neural network is built, with one input layer, one hidden layer and one output layer. The processing is performed in the hidden and output layers. To adjust the network for any given problem, certain parameters have to be set. The parameters are: the centers of the radial functions associated to the hidden layer and the weights of the connections to the output layer. Most of the methods either require a lot of experimentation or may demand a lot of computational time. In this paper we present a novel method based on a partition algorithm to automatically compute the amount and location of the centers of the radial-basis functions. Our results, obtained by running it in seven public databases, are comparable and even better than some other approaches.	algorithm;automatic taxonomy construction;radial (radio);radial basis function	Ricardo Ocampo-Vega;Gildardo Sánchez-Ante;Luis E. Falcón-Morales;Juan Humberto Sossa Azuela	2016		10.1007/978-3-319-39393-3_20	machine learning	Vision	13.759080744842764	-25.689636367219727	124969
6acd0c6af314f9e3fde978d31891f7a4a7c1bd78	a ga-based fuzzy adaptive learning control network	structure learning;systeme commande;space partition;sistema control;user needs;sistema experto;learning algorithm;control difusa;expert systems;connectionism;suite chaotique;conexionismo;fuzzy control;fuzzy logic control;logique floue;logica difusa;algorithme apprentissage;associative learning;fuzzy logic controller;control network;backpropagation;algoritmo genetico;autonomic system;input output;fuzzy logic;fuzzy adaptive learning control network;connexionnisme;fuzzy clustering;retropropagation;control system;fuzzy art;partition spatiale;fonction appartenance;backpropagation algorithm;adaptive learning;hybrid learning;membership function;algorithme genetique;chaotic sequence;genetic algorithm;sistema difuso;systeme flou;funcion pertenencia;systeme expert;network structure;reseau neuronal;algoritmo aprendizaje;retropropagacion;article;computer simulation;red neuronal;fuzzy system;commande floue;falcon;neural network;expert system	This paper addresses the structure and an associated learning algorithm of a feedforward multilayered connectionist network for realizing the basic elements and functions of a traditional fuzzy logic controller. The proposed fuzzy adaptive learning control network (FALCON) can be contrasted with the traditional fuzzy logic control systems in their network structure and learning ability. A structure=parameter learning algorithm, called FALCON-GA, is proposed for constructing the FALCON automatically. The FALCON-GA is a three-phase hybrid learning algorithm. In the rst phase, the fuzzy ART algorithm is used to do fuzzy clustering in the input=output spaces according to the supervised training data. In the second phase, the genetic algorithm (GA) is used to nd proper fuzzy logic rules by associating input clusters and output clusters. Finally, in the third phase, the backpropagation algorithm is used for tuning input=output membership functions. Hence, the FALCONGA combines the backpropagation algorithm for parameter learning and both the fuzzy ART and GAs for structure learning. It can partition the input=output spaces, tune membership functions and nd proper fuzzy logic rules automatically. The proposed FALCON has two important features. First, it reduces the combinatorial demands placed by the standard methods for adaptive linearization of a system. Second, the FALCON is a highly autonomous system. In its learning scheme, only the training data need to be provided from the outside world. The users need not give the initial fuzzy partitions, membership functions and fuzzy logic rules. Computer simulations have been conducted to illustrate the performance and applicability of the proposed system. c © 2000 Elsevier Science B.V. All rights reserved.	autonomous robot;autonomous system (internet);backpropagation;cluster analysis;computer simulation;connectionism;falcon (video game series);feedforward neural network;fuzzy clustering;fuzzy control system;fuzzy logic;genetic algorithm;input/output;logic control;maxima and minima;membership function (mathematics);neuro-fuzzy;software release life cycle	I-Fang Chung;Cheng-Jian Lin;Chin-Teng Lin	2000	Fuzzy Sets and Systems	10.1016/S0165-0114(98)00095-5	fuzzy logic;fuzzy electronics;membership function;defuzzification;adaptive neuro fuzzy inference system;fuzzy transportation;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;backpropagation;neuro-fuzzy;machine learning;information fuzzy networks;fuzzy set;fuzzy associative matrix;expert system;fuzzy set operations;algorithm;fuzzy control system	AI	10.457195942867093	-29.35369294511529	125303
fad05ed37159201af2212f239b3d2a2bfb262f75	calculation of the learning curve of bayes optimal classification algorithm for learning a perceptron with noise	training example;instance space dimension;bayes optimal algorithm;noisy random training example;large training sample size;learning curve;learning a perceptron;bayes optimal classification algorithm;canonical stochastic;certain assumption;certain learning algorithm;large instance space dimension;thermodynamics;statistical mechanics	"""The learning curve of Bayes optimal classii-cation algorithm when learning a perceptron from noisy random training examples is calculated exactly in the limit of large training sample size and large instance space dimension using methods of statistical mechanics. It is shown that under certain assumptions, in this \thermodynamic"""" limit, the probability of misclassiication of Bayes optimal algorithm is less than that of a canonical stochas-tic learning algorithm, by a factor approaching p 2 as the ratio of number of training examples to instance space dimension grows. Exact asymptotic learning curves for both algorithms are derived for particular distributions. In addition, it is shown that the learning performance of Bayes optimal algorithm can be approximated by certain learning algorithms that use a neural net with a layer of hidden units to learn a perceptron."""	approximation algorithm;artificial neural network;machine learning;perceptron	Manfred Opper;David Haussler	1991			semi-supervised learning;unsupervised learning;winnow;bayes classifier;wake-sleep algorithm;weighted majority algorithm;statistical mechanics;computer science;online machine learning;machine learning;pattern recognition;mathematics;ensemble learning;supervised learning;stability;learning curve;statistics;population-based incremental learning;generalization error	ML	20.24043851079408	-33.01819093433213	125394
6c52c875d7517463afb0c62bfbc768c7bd0349cf	zeroing polynomials using modified constrained neural network approach	backpropagation networks bpns;laguerre s and muller s methods;learning algorithm;moment method;cost function;neural nets;complexite calcul;multilayer perceptrons;algorithme apprentissage;backpropagation;polynomials;algorithms computer simulation feedback neural networks computer numerical analysis computer assisted signal processing computer assisted stochastic processes;perceptron multicouche;simulation experiment;retropropagation;perturbacion;complejidad computacion;computational complexity;methode laguerre muller;modified constrained learning algorithm mcla;polynomials neural networks signal processing algorithms backpropagation algorithms cost function computational complexity machine intelligence computer science computational modeling multilayer perceptrons;error cost function modified constrained learning neural root finder backpropagation network zeroing polynomials root moments;constraint handling;polynomials constraint handling neural nets backpropagation;perturbation;reseau neuronal;root finder backpropagation networks bpns computational complexity laguerre s and muller s methods modified constrained learning algorithm mcla perturbation polynomials;algoritmo aprendizaje;retropropagacion;root finder;red neuronal;neural network	This paper proposes new modified constrained learning neural root finders (NRFs) of polynomial constructed by backpropagation network (BPN). The technique is based on the relationships between the roots and the coefficients of polynomial as well as between the root moments and the coefficients of the polynomial. We investigated different resulting constrained learning algorithms (CLAs) based on the variants of the error cost functions (ECFs) in the constrained BPN and derived a new modified CLA (MCLA), and found that the computational complexities of the CLA and the MCLA based on the root-moment method (RMM) are the order of polynomial, and that the MCLA is simpler than the CLA. Further, we also discussed the effects of the different parameters with the CLA and the MCLA on the NRFs. In particular, considering the coefficients of the polynomials involved in practice to possibly be perturbed by noisy sources, thus, we also evaluated and discussed the effects of noises on the two NRFs. Finally, to demonstrate the advantage of our neural approaches over the nonneural ones, a series of simulating experiments are conducted.	area striata structure;artificial neural network;backpropagation;biological neural networks;blurred vision;brompheniramine;business process network;clarithromycin;coefficient;computation (action);computer simulation;computers;experiment;fortran;learning disorders;linear algebra;machine learning;numerical analysis;oracle bpa suite;parallel algorithm;plant roots;polynomial;root-finding algorithm;von neumann architecture;wetware computer	De-shuang Huang;Horace Ho-Shing Ip;Ken Chee-keung Law;Zheru Chi	2005	IEEE Transactions on Neural Networks	10.1109/TNN.2005.844912	perturbation;computer science;artificial intelligence;backpropagation;theoretical computer science;machine learning;mathematics;computational complexity theory;artificial neural network;statistics;polynomial	ML	17.04454447588281	-27.976323263644275	125415
0ccc895fd086647cd8ce501300e71fea9b9f8d33	trainable and dynamic computing: error backpropagation through physical media	photonics;biological patents;networks;biomedical journals;text mining;europe pubmed central;citation search;states;citation networks;backpropagation reservoir;technology and engineering;machine learning;research articles;abstracts;open access;life sciences;parallel;clinical guidelines;full text;accoustics;reservoir computing;rest apis;orcids;europe pmc;analog computing;biomedical research;bioinformatics;literature search	Neural networks are currently implemented on digital Von Neumann machines, which do not fully leverage their intrinsic parallelism. We demonstrate how to use a novel class of reconfigurable dynamical systems for analogue information processing, mitigating this problem. Our generic hardware platform for dynamic, analogue computing consists of a reciprocal linear dynamical system with nonlinear feedback. Thanks to reciprocity, a ubiquitous property of many physical phenomena like the propagation of light and sound, the error backpropagation-a crucial step for tuning such systems towards a specific task-can happen in hardware. This can potentially speed up the optimization process significantly, offering important benefits for the scalability of neuro-inspired hardware. In this paper, we show, using one experimentally validated and one conceptual example, that such systems may provide a straightforward mechanism for constructing highly scalable, fully dynamical analogue computers.	analog computer;artificial neural network;backpropagation;computation (action);computers;computers, analog;dynamical system;experiment;generic drugs;information processing;inspiration function;mathematical optimization;neural network simulation;nonlinear system;parallel computing;physical phenomena;scalability;software propagation;speedup;von neumann architecture;benefit	Michiel Hermans;Michael Burm;Joni Dambre;Peter Bienstman	2015	Nature communications	10.1038/ncomms7729	analog computer;text mining;photonics;bioinformatics;reservoir computing;parallel	ML	17.33940751204907	-24.96439928930637	125452
4eafb08b4e4247e055815c9d05d9bcfe0316dd2d	learning with box kernels	propositional rules;kernel machines;box kernels;constrained variational calculus	Supervised examples and prior knowledge on regions of the input space have been profitably integrated in kernel machines to improve the performance of classifiers in different real-world contexts. The proposed solutions, which rely on the unified supervision of points and sets, have been mostly based on specific optimization schemes in which, as usual, the kernel function operates on points only. In this paper, arguments from variational calculus are used to support the choice of a special class of kernels, referred to as box kernels, which emerges directly from the choice of the kernel function associated with a regularization operator. It is proven that there is no need to search for kernels to incorporate the structure deriving from the supervision of regions of the input space, because the optimal kernel arises as a consequence of the chosen regularization operator. Although most of the given results hold for sets, we focus attention on boxes, whose labeling is associated with their propositional description. Based on different assumptions, some representer theorems are given that dictate the structure of the solution in terms of box kernel expansion. Successful results are given for problems of medical diagnosis, image, and text categorization.	abnormal degeneration;acclimatization;algorithm;calculi;calculus of variations;categorization;choice behavior;document classification;experiment;kernel (operating system);kernel method;mathematical optimization;nuclease sensitive element binding protein 1;paper;reuse (action);rule (guideline);semi-supervised learning;semiconductor industry;solutions;supervised learning;tomaso poggio;variational principle	Stefano Melacci;Marco Gori	2011	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1007/978-3-642-24958-7_60	mathematical optimization;discrete mathematics;machine learning;mathematics	ML	21.693061421451723	-35.09067766772951	125686
8c1a46c401c69387d3a29d20ae6c32b73c20a888	multi-task classification with sequential instances and tasks		Abstract In this paper, we propose a novel multi-task classification framework, called Multi-Task classification with Sequential Instances and Tasks (MTSIT). Different from previous works, which treat all tasks and instances equally, MTSIT is inspired by the cognitive process of human brain that often learns from easier tasks to harder tasks. Specifically, the method attempts to jointly learn the task curriculum (learning order of tasks) and the instance curriculum (learning order of instances) by introducing a self-paced item for the instances of each task in the existing multi-task learning framework Sequential Multi-Task learning (SeqMT), which transfers information from the previously learned tasks to the next ones through shared task parameters. To effectively solve MTSIT, we also propose an optimization algorithm in which the instance curriculum and the task curriculum alternate between two paradigms, Tasks-to-Instances and Instances-to-Tasks (TIIT). In the tasks-to-instances step, the learner conducts the instance curriculum when the task curriculum has been fixed, while in the instances-to-tasks step, the task curriculum is learned when the instance curriculum in each task has been settled down. Our TIIT method is based on an error bound of the proposed MTSIT. Experimental results on three real world datasets demonstrate the effectiveness of our method.		Wei Xu;Wei Liu;Haoyuan Chi;Xiaolin Huang;Jie Yang	2018	Sig. Proc.: Image Comm.	10.1016/j.image.2018.02.013	theoretical computer science;curriculum;machine learning;cognition;computer science;artificial intelligence	ML	17.82206797168713	-36.69746992460348	125742
6a2d7f0e65cd2d58364727906a38e6f81dda4698	ann application in end depth computation for inverted semicircular channels			computation	Rajkumar V. Raikar	2003			computer science;machine learning;artificial intelligence;computation;communication channel	Crypto	12.652696010043368	-26.97485879955411	126138
061e5b528e16a2a015f6db1e1b7c25fd5f038955	linear convergence of gradient and proximal-gradient methods under the polyak-łojasiewicz condition		In 1963, Polyak proposed a simple condition that is sufficient to show a global linear convergence rate for gradient descent. This condition is a special case of the Lojasiewicz inequality proposed in the same year, and it does not require strong convexity (or even convexity). In this work, we show that this much-older PolyakLojasiewicz (PL) inequality is actually weaker than the main conditions that have been explored to show linear convergence rates without strong convexity over the last 25 years. We also use the PL inequality to give new analyses of randomized and greedy coordinate descent methods, sign-based gradient descent methods, and stochastic gradient methods in the classic setting (with decreasing or constant step-sizes) as well as the variancereduced setting. We further propose a generalization that applies to proximal-gradient methods for non-smooth optimization, leading to simple proofs of linear convergence of these methods. Along the way, we give simple convergence results for a wide variety of problems in machine learning: least squares, logistic regression, boosting, resilient backpropagation, L1-regularization, support vector machines, stochastic dual coordinate ascent, and stochastic variance-reduced gradient methods.	backpropagation;boosting (machine learning);convex function;coordinate descent;gradient descent;greedy algorithm;least squares;leggett–garg inequality;logistic regression;machine learning;mathematical optimization;pl/sql;randomized algorithm;rate of convergence;rprop;social inequality;subgradient method;support vector machine;times ascent	Hamed Karimi;Julie Nutini;Mark W. Schmidt	2016		10.1007/978-3-319-46128-1_50	mathematical optimization;combinatorics;mathematical analysis;mathematics;stochastic gradient descent	ML	22.722273072804175	-33.36965484325726	126187
18026b95f9e12fbd8ce503f694ed90fe160f746c	developmental self-organisation in artificial neural networks			artificial neural network;self-organization	Alistair Gibson Rust	1998				Robotics	11.706196535413168	-27.402802044746224	126308
1c1a4ac1a6058ccfe53f38fa1fb0c0205b9ba88b	semi-supervised learning: when and why it works		Semi-supervised learning deals with the problem of how, if possible, to take advantage of a huge amount of unclassified data, to perform a classification in situations when, typically, there is little labelled data. Even though this is not always possible (it depends on how useful, for inferring the labels, it would be to know the distribution of the unlabelled data), several algorithm have been proposed recently. A new algorithm is proposed, that under almost necessary conditions, attains asymptotically the performance of the best theoretical rule as the amount of unlabelled data tends to infinity. The set of necessary assumptions, although reasonable, show that semi-parametric classification only works for very well conditioned problems. The performance of the algorithm is assessed in the well known “Isolet” real-data of phonemes, where a strong dependence on the choice of the initial training sample is shown.	algorithm;semi-supervised learning;semiconductor industry;supervised learning;whole earth 'lectronic link	Alejandro Cholaquidis;Ricardo Fraiman;Mariela Sued	2018	CoRR		artificial intelligence;machine learning;mathematics;infinity;semi-supervised learning	ML	18.700036038418908	-35.974445614306916	126439
ed3d7c4a5f607201f3848d4c02dd9ba17c791fc2	a model selection criterion for classification: application to hmm topology optimization	model selection;optimisation;generic model;information criterion;hidden markov model;bayes methods;bayes methods hidden markov models optimisation image classification handwritten character recognition;image classification;topology optimization;hidden markov models;hidden markov models topology bayesian methods handwriting recognition pattern recognition information theory signal processing filters statistics testing;bayesian information criterion;bayesian information criterion model selection criterion classification problems hmm topology optimization occam razor principle discriminative information criterion hidden markov model topology cursively handwritten digit recognition;handwritten character recognition	This paper proposes a model selection criterion for classification problems. The criterion focuses on selecting models that are discriminant instead of models based on the Occam’s razor principle of parsimony between accurate modeling and complexity. The criterion, dubbed Discriminative Information Criterion (DIC), is applied to the optimization of Hidden Markov Model topology aimed at the recognition of cursively-handwritten digits. The results show that DICgenerated models achieve 18% relative improvement in performance from a baseline system generated by the Bayesian Information Criterion (BIC).	akaike information criterion;approximation error;baseline (configuration management);bayesian information criterion;deviance information criterion;discriminant;hidden markov model;markov chain;mathematical optimization;maximum parsimony (phylogenetics);model selection;occam's razor;topology optimization;occam	Alain Biem	2003		10.1109/ICDAR.2003.1227641	contextual image classification;topology optimization;computer science;machine learning;pattern recognition;markov model;bayesian information criterion;hidden markov model;model selection;statistics	ML	21.373250121891722	-36.00355800536539	126462
407ceecdd2ed627be7d69e033d7b73fa6724189e	delta learning rule for the active sites model	memory retrieval;active site;neural network;evolutionary computing	This paper reports the results on methods of comparing the memory retrieval capacity of the Hebbian neural network which implements the B-Matrix approach, by using the WidrowHoff rule of learning. We then, extend the recently proposed Active Sites model by developing a delta rule to increase memory capacity. Also, this paper extends the binary neural network to a multi-level (non-binary) neural network.	artificial neural network;biological network;delta rule;hebbian theory;learning rule;self-organizing map	Krishna Chaithanya Lingashetty	2010	CoRR		nervous system network models;probabilistic neural network;delta rule;computer science;artificial intelligence;recurrent neural network;active site;machine learning;data mining;time delay neural network;artificial neural network;evolutionary computation	ML	13.733133958652186	-27.243714530798353	126474
329458ba2f3ed763d65c1071951ee974711494ef	regularized neural networks: some convergence rate results	continuous function;relacion convergencia;aproximacion;mean square;fonction continue;taux convergence;convergence rate;approximation;sobolev space;funcion continua;reproducing kernel hilbert space;learning problems;reseau neuronal;red neuronal;neural network	In a recent paper, Poggio and Girosi (1990) proposed a class of neural networks obtained from the theory of regularization. Regularized networks are capable of approximating arbitrarily well any continuous function on a compactum. In this paper we consider in detail the learning problem for the one-dimensional case. We show that in the case of output data observed with noise, regularized networks are capable of learning and approximating (on compacta) elements of certain classes of Sobolev spaces, known as reproducing kernel Hilbert spaces (RKHS), at a nonparametric rate that optimally exploits the smoothness properties of the unknown mapping. In particular we show that the total squared error, given by the sum of the squared bias and the variance, will approach zero at a rate of n(-2m)/(2m+1), where m denotes the order of differentiability of the true unknown function. On the other hand, if the unknown mapping is a continuous function but does not belong to an RKHS, then there still exists a unique regularized solution, but this is no longer guaranteed to converge in mean square to a well-defined limit. Further, even if such a solution converges, the total squared error is bounded away from zero for all n sufficiently large.	arabic numeral 0;class;converge;hilbert space;mean squared error;neural network simulation;neural networks;sample variance;tomaso poggio	Valentina Corradi;Halbert White	1995	Neural Computation	10.1162/neco.1995.7.6.1225	continuous function;mathematical optimization;mathematical analysis;sobolev space;machine learning;approximation;calculus;reproducing kernel hilbert space;mathematics;rate of convergence;artificial neural network;statistics	ML	19.64625687756236	-29.887646907500038	126492
26e3cacaf4c1f7b9046f628552d6d9181fc33774	a quantum-statistical approach toward robot learning by demonstration	gaussian processes;statistical machine learning quantum statistics robot learning by demonstration;trajectory based robot learning by demonstration quantum statistical approach statistical machine learning gaussian mixture regression gmr based learning by demonstration model quantum mechanics quantum states quantum statistics inspired mixture regression algorithm;trajectory predictive models machine learning quantum mechanics gaussian mixture model;journal article;learning systems;quantum statistics;learning by example;robots;regression analysis;computer science;quantum computing;robots gaussian processes learning by example learning systems quantum computing quantum statistical mechanics regression analysis;article;quantum statistical mechanics	Statistical machine learning approaches have been at the epicenter of the ongoing research work in the field of robot learning by demonstration over the past few years. One of the most successful methodologies used for this purpose is a Gaussian mixture regression (GMR). In this paper, we propose an extension of GMR-based learning by demonstration models to incorporate concepts from the field of quantum mechanics. Indeed, conventional GMR models are formulated under the notion that all the observed data points can be assigned to a distinct number of model states (mixture components). In this paper, we reformulate GMR models, introducing some quantum states constructed by superposing conventional GMR states by means of linear combinations. The so-obtained quantum statistics-inspired mixture regression algorithm is subsequently applied to obtain a novel robot learning by demonstration methodology, offering a significantly increased quality of regenerated trajectories for computational costs comparable with currently state-of-the-art trajectory-based robot learning by demonstration approaches. We experimentally demonstrate the efficacy of the proposed approach.	algorithm;computation;data point;experiment;machine learning;quantum mechanics;quantum state;robot learning	Sotirios P. Chatzis;Dimitrios Korkinof;Yiannis Demiris	2012	IEEE Transactions on Robotics	10.1109/TRO.2012.2203055	algorithmic learning theory;computer science;artificial intelligence;theoretical computer science;online machine learning;machine learning;mathematics;ensemble learning;active learning;quantum statistical mechanics;quantum mechanics;statistics;generalization error	Robotics	22.482577087412537	-28.3833907732377	126565
6e08cb3b780d85e3931015564e5fd98c048a9a91	selection and consolidation of memorized information for distributed associative memories	proyeccion ortogonal;memoire associative;generalized inverse matrix;inverse generalise;inverse matrix;methode jacobi;matrice inverse;metodo jacobi;orthogonal projection;associative memory;memoria asociativa;generalized inverse;inverso generalizado;matriz inversa;projection orthogonale;jacobi method	Abstract#R##N##R##N#Numerous studies have been made on the method of constructing the distributed-type associative memory. This paper discusses the method which selectively memorizes or memorizes by consolidation the information stored in multiple associative memories in a new associative memory.#R##N##R##N##R##N##R##N#In the distributed associative memory, the information (vector) to be stored is memorized in a distributed way in the form of a matrix (called memorization matrix). Then, in general, it is difficult to know precisely the original memorized information from the already constructed associative memory.#R##N##R##N##R##N##R##N#This paper proposes a method which can realize the selection and consolidation of the memorized information by constructing directly the memorization matrix of the new associative memory, using the memorization matrices of the already constructed multiple associative memories. The proposed method has the feature that it is not necessary to derive the information memories in each associative memory or to reconstruct the associative memory from the start using the memorized information (relearning). It is a requirement which arises frequently in the construction, update and use of the associative memory to memorize selectively or in a consolidated form the information memorized in multiple associative memories, in an associative memory. For such a purpose, the proposed method will be useful.		Kenji Murakami;Masanori Izumida;Hirochika Takechi	1995	Systems and Computers in Japan	10.1002/scj.4690260210	arithmetic;jacobi method;generalized inverse;artificial intelligence;mathematics;bidirectional associative memory;orthographic projection;algorithm;memory map	HPC	13.793514909417118	-30.720851997031197	126616
b9d1126921d93add246a93d69bd2dd204a9fe8b7	a qos-satisfied prediction model for cloud-service composition based on hidden markov model	cloud-service;composition;hidden markov model;qos-satisfied		hidden markov model;markov chain;quality of service	Qingtao Wu;Mingchuan Zhang;Ruijuan Zheng;Wangyang Wei	2013	iJOE		forward algorithm;maximum-entropy markov model;markov kernel;markov property;viterbi algorithm;hidden semi-markov model;markov process;markov model;hidden markov model;variable-order markov model	ML	21.883780901790104	-25.091715857617146	126870
877168db5c6c11d196b6a5d0f406aae083c207c8	multikernel recursive least-squares temporal difference learning		Traditional least-squares temporal difference (LSTD) algorithms provide an efficient way for policy evaluation, but their performance is greatly influenced by the manual selection of state features and their approximation ability is often limited. To overcome these problems, we propose a multikernel recursive LSTD algorithm in this paper. Different from the previous kernel-based LSTD algorithms, the proposed algorithm uses Bellman operator along with projection operator, and constructs the sparse dictionary online. To avoid caching all history samples and reduce the computational cost, it uses the sliding-window technique. To avoid overfitting and reduce the bias caused by the sliding window, it also considers ( L_{2} ) regularization. In particular, to improve the approximation ability, it uses the multikernel technique, which may be the first time to be used for value-function prediction. Experimental results on a 50-state chain problem show the good performance of the proposed algorithm in terms of convergence speed and prediction accuracy.	multikernel;recursive least squares filter;temporal difference learning	Chunyuan Zhang;Qingxin Zhu;Xinzheng Niu	2016		10.1007/978-3-319-42297-8_20	machine learning	Vision	24.137241546738267	-35.07137259422624	127149
2792cf5cb3124059defeb07e751c00a27ca5ea82	batch is not heavy: learning word representations from all samples		Stochastic Gradient Descent (SGD) with negative sampling is the most prevalent approach to learn word representations. However, it is known that sampling methods are biased especially when the sampling distribution deviates from the true data distribution. Besides, SGD suffers from dramatic fluctuation due to the onesample learning scheme. In this work, we propose AllVec that uses batch gradient learning to generate word representations from all training samples. Remarkably, the time complexity of AllVec remains at the same level as SGD, being determined by the number of positive samples rather than all samples. We evaluate AllVec on several benchmark tasks. Experiments show that AllVec outperforms samplingbased SGD methods with comparable efficiency, especially for small training corpora.	approximation;benchmark (computing);deep learning;experiment;mathematical optimization;sampling (signal processing);stochastic gradient descent;text corpus;time complexity;universal conductance fluctuations;word embedding	Xiangnan He;Xin Xin;Fajie Yuan;Joemon M. Jose	2018			natural language processing;artificial intelligence;machine learning;computer science	NLP	18.723280123563793	-37.615326933409946	127301
a89e4f0acecea2f9202b486fdd2279d5b9be1ca4	agnostic pointwise-competitive selective classification		A pointwise competitive classifier from class F is required to classify identically to the best classifier in hindsight from F . For noisy, agnostic settings we present a strategy for learning pointwise-competitive classifiers from a finite training sample provided that the classifier can abstain from prediction at a certain region of its choice. For some interesting hypothesis classes and families of distributions, the measure of this rejected region is shown to be diminishing at rate β1 · O ( (polylog(m) · log(1/δ)/m)2 ) , with high probability, where m is the sample size, δ is the standard confidence parameter, and β1, β2 are smoothness parameters of a Bernstein type condition of the associated excess loss class (related to F and the 0/1 loss). Exact implementation of the proposed learning strategy is dependent on an ERM oracle that is hard to compute in the agnostic case. We thus consider a heuristic approximation procedure that is based on SVMs, and show empirically that this algorithm consistently outperforms a traditional rejection mechanism based on distance from decision boundary.	algorithm;approximation;decision boundary;heuristic;offset binary;phil bernstein;rejection sampling;with high probability	Yair Wiener;Ran El-Yaniv	2015	J. Artif. Intell. Res.	10.1613/jair.4439	artificial intelligence;machine learning;pattern recognition;mathematics;statistics	ML	19.369041246842347	-34.34496074440016	127327
552f79924baad00fadc78f7f9a4122b962140e31	conditional generative moment-matching networks		Maximum mean discrepancy (MMD) has been successfully applied to learn deep generative models for characterizing a joint distribution of variables via kernel mean embedding. In this paper, we present conditional generative moment-matching networks (CGMMN), which learn a conditional distribution given some input variables based on a conditional maximum mean discrepancy (CMMD) criterion. The learning is performed by stochastic gradient descent with the gradient calculated by back-propagation. We evaluate CGMMN on a wide range of tasks, including predictive modeling, contextual generation, and Bayesian dark knowledge, which distills knowledge from a Bayesian model by learning a relatively small CGMMN student network. Our results demonstrate competitive performance in all the tasks.	backpropagation;bayesian network;discrepancy function;mikumikudance;predictive modelling;software propagation;stochastic gradient descent	Yong Ren;Jialian Li;Yucen Luo;Jun Zhu	2016			machine learning;pattern recognition;chain rule;mathematics;generative model;discriminative model;statistics	ML	23.68075679274805	-30.34694231810746	127348
18a7821dc12f467a32992e1bfc3e50aac5784229	dynamic fuzzy semisupervised multitask learning	histograms;heuristic algorithms machine learning classification algorithms histograms error analysis semisupervised learning;classification algorithm;learning algorithm;fuzzy set;semisupervised fuzzy pattern matching algorithm dynamic fuzzy semisupervised multitask learning machine learning field dynamic fuzzy possibility membership functions;fuzzy pattern matching dynamic fuzzy sets dynamic fuzzy possibility multitask learning semisupervsed learning;dynamic fuzzy possibility;fuzzy set theory;semisupervsed learning;error analysis;machine learning;possibility theory fuzzy set theory learning artificial intelligence pattern matching;fuzzy pattern matching;pattern matching;heuristic algorithms;classification algorithms;membership function;possibility theory;learning artificial intelligence;dynamic fuzzy sets;multitask learning;semisupervised learning;heuristic algorithm	Semi supervised multitask learning has been one of the hotest problems in the machine learning field in recent years. In this paper a dynamic fuzzy semi supervised multitask learning algorithm has been proposed to deal with the dynamic fuzzy problems. Our goal is to learn dynamic fuzzy possibility of each class with a limited initial data set, and the dynamic fuzzy possibility is numerically equal to the membership functions of each class. So the dynamic fuzzy possibility needs to be adapted with new data incoming. Experiment results shows that our method has performed much better, compared with the semi supervised fuzzy pattern matching algorithm proposed in [9].	algorithm;computer multitasking;machine learning;numerical analysis;pattern matching;semi-supervised learning;semiconductor industry	Meiyin Dai;Fanzhang Li	2011	2011 Seventh International Conference on Computational Intelligence and Security	10.1109/CIS.2011.106	statistical classification;defuzzification;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;data mining;mathematics;information fuzzy networks;fuzzy set;fuzzy set operations	AI	14.5860348872476	-34.39011805297488	127592
6ebaa5d3e2fd6565cf7ae2198d7b5de7328607a1	near infrared spectrum detection of soybean fatty acids based on ga and neural network	fatty acid;spectrum;satisfiability;genetics;near infrared;network model;soybean;mathematical model;genetic algorithm;neural network	This paper represented a way to build mathematical model on genetic multilevel forward neural network. Building the relationship between chemistry measurement values and near infrared spectrum datum. The near infrared spectrum data was input in this network, five kinds of content of fatty acids, which measured by chemistry method, were output. Training the weight of multilevel forward neural network by genetic algorithms, building the soybean fatty acids neural network detection model, and exploring the network model which can realize near infrared spectrum detection exactly and efficiently. The authors designed a multilevel forward neural network trained by genetic algorithms. Test showed that relative coefficient in five fatty acids of soybean can be round about 0.9, and can satisfy init detection of soybean breeding.	artificial neural network;coefficient;cooperative breeding;full-spectrum light;genetic algorithm;geodetic datum;init;intuitionistic logic;mathematical model;network model;os-tan;reason;software release life cycle	Changli Zhang;Kezhu Tan;Yuhua Chai;Junlong Fang;Shuqiang Liu	2007		10.1007/978-0-387-77253-0_47	biology;biochemistry;botany;biotechnology	AI	12.437366428056382	-28.165389403578477	127707
dd7bab9f0cb7e310facdc206c86a7feddf9a50c1	a user-specific machine learning approach for improving touch accuracy on mobile devices	gaussian processes;probabilistic modelling;touch;regression;machine learning	We present a flexible Machine Learning approach for learning user-specific touch input models to increase touch accuracy on mobile devices. The model is based on flexible, non-parametric Gaussian Process regression and is learned using recorded touch inputs. We demonstrate that significant touch accuracy improvements can be obtained when either raw sensor data is used as an input or when the device's reported touch location is used as an input, with the latter marginally outperforming the former. We show that learned offset functions are highly nonlinear and user-specific and that user-specific models outperform models trained on data pooled from several users. Crucially, significant performance improvements can be obtained with a small (≈200) number of training examples, easily obtained for a particular user through a calibration game or from keyboard entry data.	computable function;gaussian process;kriging;machine learning;mobile device;nonlinear system	Daryl Weir;Simon Rogers;Roderick Murray-Smith;Markus Löchtefeld	2012		10.1145/2380116.2380175	computer vision;simulation;regression;computer science;machine learning;gaussian process	HCI	22.991453330143166	-35.17312372967695	127841
c5fb94a54e86543716e606e8b002135c43bfa82e	a continuous information gain measure to find the most discriminatory problems for ai benchmarking		This paper introduces an information-theoretic method for selecting a small subset of problems which gives us the most information about a group of problem-solving algorithms. This method was tested on the games in the General Video Game AI (GVGAI) framework, allowing us to identify a smaller set of games that still gives a large amount of information about the game-playing agents. This approach can be used to make agent testing more efficient in the future. We can achieve almost as good discriminatory accuracy when testing on only a handful of games as when testing on more than a hundred games, something which is often computationally infeasible. Furthermore, this method can be extended to study the dimensions of effective variance in game design between these games, allowing us to identify which games differentiate between agents in the most complementary ways. As a side effect of this investigation, we provide an up-to-date comparison on agent performance for all GVGAI games, and an analysis of correlations between scores and win-rates across both games and agents. Introduction Competitions and challenges are regularly used within AI as a way of evaluating algorithms, and also for promoting interest into specific problems. However, if the challenge poses a large set of possible problems it can often be impractical or even impossible to evaluate a new algorithm on every problem within this set. Comparing a new algorithm with the state of the art on the full set of problems can require immense computational resources, which are not available to many researchers. Therefore, a smaller set of problems is usually selected that intends to be representative of the entire problem space. This leads to the fundamental question: how should we select this subset of problems? This question is critical, as selecting a poorly representative subset of the problems available might leave out key aspects of the challenge, resulting in an unintentional bias that leads to specific solutions performing better than they would have on the entire problem set. If you have good knowledge of the domain, you could choose a set of problems with interestingly difficult design features, but there is no guarantee that these differences in design translate to meaningfully different challenges. Also in many cases, you do not have deep knowledge about the design of the different problems. This issue is prevalent in any situation where it may be computationally prohibitive to test a new algorithm on all sub-problems presented. Examples of competitions or challenges where this is the case include the GVGAI (PerezLiebana et al. 2016b), ALE (Bellemare et al. 2013) and Kaggle competitions (Carpenter 2011), each of which have hundreds of separate problems. There are also other sets of machine learning benchmarks that contain a multitude of disparate tasks, such as the OpenAI Gym (Brockman et al. 2016) or the UCI repository of supervised learning tasks (Dheeru and Karra Taniskidou 2017). Many of the participants in these challenges cherry-pick benchmarks where their new algorithm performs well. This will continue to happen as long as benchmark sets are so large that it is computationally infeasible to test on all benchmarks available. However, we should not simply reject good papers simply because the authors lack the resources to perform full evaluations on every benchmark possible. The solution to this dilemma is to test new algorithms on problems that are most relevant given the current set of well-performing algorithms, not simply those where the new algorithm performs best. This paper therefore proposes an approach for selecting a small number of problems out of a larger set for accurately testing an algorithm, and has great potential to revolutionize AI benchmarking across many different AI challenges. As a first approach to the task of selecting which problems to test an algorithm on, we look at the correlations between different algorithm’s performance for different problems. After testing an algorithm on one problem, another problem could be selected with an anti-correlated performance profile (i.e. one where other algorithms perform differently). This is an incomplete solution however, most importantly because it does not tell us which problem to test on first and does not factor in the potential variability in agent performance. We instead propose an information-theoretic measure for determining which problems are best at telling a given set of algorithms apart; a measure that also takes into account the concept of noise when analyzing performance measures. By recursively applying this measure, we can find problems that are maximally informative considering previously selected problems, meaning that we can identify problems that discriminate among a set of algorithms in different ways (Martınez-Plumed and Hernández-Orallo 2016). We use the General Video Game AI (GVGAI) framear X iv :1 80 9. 02 90 4v 2 [ cs .A I] 1 1 Se p 20 18 work as a testbed for our method. The GVGAI library includes more than a hundred mini video games (Bontrager et al. 2016), and several dozen different agents that can play these games (Soemers et al. 2016; Gaina, Lucas, and Perez-Liebana 2017; Weinstein and Littman 2012; Pérez-Liébana et al. 2016c; Mendes, Togelius, and Nealen 2016) have been submitted to the associated GVGAI competition (Perez-Liebana et al. 2016a). We present a formalised analysis on the correlations between agent performances across different games, and use our informationtheoretic measure to select a subset of the GVGAI game library that accurately represents the full discriminative scope when testing on all games available (i.e. provides a diverse range of problems that best distinguishes between agents). Background General Video Game Playing (GVGP) is an area of research that looks to expand upon the success of the General Game Playing (GGP) competition. The GGP competition offers a platform for researchers to create agents that can play a wide range of board games (Genesereth, Love, and Pell 2005). While board games offer an interesting variety of problems, they do not offer real-time situations where rapid decision making is key, which is what the GVGP competition does by providing a library of video games as a research platform (Levine et al. 2013). The GVGAI competition has been running annually since 2014 and provides a Video Game Description Language (VGDL) with which to quickly design games, and a common API for agents to access those games (Ebner et al. 2013). Each year ten games are selected to evaluate the submitted agents, which often covers a wide range of game types from role-playing to puzzle games (Perez-Liebana et al. 2018a). One of the key elements of this competition is that the games being played by the agents for each year’s competition are unknown to both the developers and agents beforehand. Many of the GVGAI games and most of the agents include some form of stochasticity, meaning that performance evaluation is inherently noisy. Playing a GVGAI game will also give two signals of performance, whether an agent won the game or not and what score was obtained (Perez-Liebana et al. 2016b). The competition currently offers multiple tracks, including a single and multi-player planning track (Gaina, Prez-Libana, and Lucas 2016), which provides a forward model for analyzing future game states, and a learning track which removes the forward model but allocates a training time to agents before submission (Pérez-Liébana et al. 2018b). For this paper, we only consider the games and agents used in the single-player planning track. One of the issues that we set out to tackle with this work is that the games within the GVGAI framework are currently not well documented. A few previous papers attempted to evaluate how certain agents perform on different GVGAI games (Bontrager et al. 2016; Nelson 2016), but none have investigated the different discrimination profiles presented by the full game corpus, or how this information could be used to help design better agents and games in the future. The fact that different GVGAI games pose different types of problems to agents, may lead to biases towards a particular type of algorithm when selecting game subsets. Understanding what bias may exist in a given set of games, and being able to select ten games which minimize any particular bias, is desirable for ensuring that the competition is genuinely evaluating general problem-solving capabilities.	algorithm;application programming interface;artificial intelligence (video games);benchmark (computing);computation;computational complexity theory;computational resource;earl levine;game description language;general game playing;general video game playing;information theory;kullback–leibler divergence;machine learning;performance evaluation;problem domain;problem solving;real-time clock;recursion;spatial variability;stochastic process;supervised learning;testbed;video game design;word lists by frequency	Matthew Stephenson;Damien Anderson;Ahmed Khalifa;John Levine;Jochen Renz;Julian Togelius;Christoph Salge	2018	CoRR		machine learning;artificial intelligence;data mining;computer science;benchmarking;game design	AI	17.746023770067247	-35.126601152598525	127844
5547c4b276bae497a849fb294d2016f0078dac7f	bayesian fault diagnosis using principal component analysis approach with continuous evidence	会议论文	For fault diagnosis problems where the historical data is from a number of monitors, conventional likelihood estimation approaches for Bayesian diagnosis are typically independent or lumped approach. However, for most chemical processes the monitor outputs are often not independent, but exhibit correlations to some extent; as for the lumped approach, it is infeasible due to the curse of dimensionality and the limited size of historical dataset. Also there is another limitation to the accuracy of the diagnosis that the continuous monitor readings are commonly discretized to discrete values, therefore information of the continuous data cannot be fully utilized. In this paper principal component analysis (PCA) approach is proposed to transform the evidence into independent pieces, and kernel density estimation is used to improve the diagnosis performance. The application to the Tennessee Eastman Challenge process using the benchmark data demonstrates the effectiveness of the proposed approach.	principal component analysis	Wenbing Zhu;Zixuan Li;Sun Zhou;Guoli Ji	2015		10.1007/978-3-319-38789-5_36	principal component analysis;curse of dimensionality;kernel density estimation;discretization;artificial intelligence;bayesian probability;pattern recognition;mathematics	Robotics	23.15321434630904	-25.05138112860626	128026
6e4ee83821324d5497fc6abb2818ae9d8261b0c4	a learning algorithm for evolving cascade neural networks	switching networks;cascade circuit;learning algorithm;cascade architecture;electroencefalografia;cascade architecture electroencephalogram;algorithme apprentissage;electroencephalographie;reseau commutation;circuit cascade;artificial intelligent;reseau neuronal non boucle;feature selection;feedforward neural nets;electroencephalography;reseau neuronal;algoritmo aprendizaje;electroencephalogram;red neuronal;evolving;circuito cascada;neural network;evolutionary computing	A new learning algorithm for Evolving Cascade Neural Networks (ECNNs) is described. An ECNN starts to learn with one input node and then adding new inputs as well as new hidden neurons evolves it. The trained ECNN has a nearly minimal number of input and hidden neurons as well as connections. The algorithm was successfully applied to classify artifacts and normal segments in clinical electroencephalograms (EEGs). The EEG segments were visually labeled by EEG-viewer. The trained ECNN has correctly classified 96.69% of the testing segments. It is slightly better than a standard fully connected neural network.	algorithm;algorithmic learning theory;artifact (software development);artificial neural network;electroencephalography;feedforward neural network;neural network software;preprocessor;relevance	Vitaly Schetinin	2003	Neural Processing Letters	10.1023/A:1022935810223	electroencephalography;computer science;artificial intelligence;machine learning;feature selection;artificial neural network;algorithm	ML	13.577462205686857	-28.07972009130142	128059
1d7924017f48934a44dbae3887394b244b8be273	adapting hierarchical multiclass classification to changes in the target concept		Machine learning models often need to be adapted to new contexts, for instance, to deal with situations where the target concept changes. In hierarchical classification, the modularity and flexibility of learning techniques allows us to deal directly with changes in the learning problem by readapting the structure of the model, instead of having to retrain the model from the scratch. In this work, we propose a method for adapting hierarchical models to changes in the target classes. We experimentally evaluate our method over different datasets. The results show that our novel approach improves the original model, and compared to the retraining approach, it performs quite competitive while it implies a significantly smaller computational cost.	multiclass classification	Daniel Silva-Palacios;César Ferri;María José Ramírez-Quintana	2018		10.1007/978-3-030-00374-6_12	retraining;novelty;scratch;modularity;machine learning;artificial intelligence;computer science;multiclass classification	Vision	14.109444047227708	-37.74250185772185	128090
433350b7037190a511fe3ce7d911cd67e58e1a9b	support vector machines and the bayes rule in classification	rate of convergence;tecnologia electronica telecomunicaciones;bayes rule;regularization method;statistical method;classification;higher order;loss function;reproducing kernel hilbert space;classification rules;reproducing kernel;the bayes rule;odd ratio;support vector machine;regularization methods;tecnologias;grupo a;large margin classifier	The Bayes rule is the optimal classification rule if the underlying distribution of the data is known. In practice we do not know the underlying distribution, and need to “learn” classification rules from the data. One way to derive classification rules in practice is to implement the Bayes rule approximately by estimating an appropriate classification function. Traditional statistical methods use estimated log odds ratio as the classification function. Support vector machines (SVMs) are one type of large margin classifier, and the relationship between SVMs and the Bayes rule was not clear. In this paper, it is shown that the asymptotic target of SVMs are some interesting classification functions that are directly related to the Bayes rule. The rate of convergence of the solutions of SVMs to their corresponding target functions is explicitly established in the case of SVMs with quadratic or higher order loss functions and spline kernels. Simulations are given to illustrate the relation between SVMs and the Bayes rule in other cases. This helps understand the success of SVMs in many classification studies, and makes it easier to compare SVMs and traditional statistical methods.	computer simulation;loss function;margin classifier;rate of convergence;spline (mathematics);statistical classification;support vector machine	Yi Lin	2002	Data Mining and Knowledge Discovery	10.1023/A:1015469627679	support vector machine;bayes classifier;higher-order logic;biological classification;computer science;machine learning;classification rule;pattern recognition;reproducing kernel hilbert space;data mining;bayes error rate;mathematics;rate of convergence;bayes' theorem;statistics;odds ratio;loss function	ML	20.703384099860266	-34.35596390186839	128122
c75c1014da7c871477cf95245d529ca2d82a06a7	modelling of polymerization reactors: deterministic and by neural networks			artificial neural network	Sheila Contant	2007				ML	11.703279370010817	-25.58381213825873	128386
c46fea728e1e1967ed8047ff487ee5083308949c	object recognition by a hopfield neural network	object recognition;best solution;neural networks;hopfield network;neural nets;object recognition hopfield neural networks layout service robots neurons computer vision testing parallel processing neural networks robot vision systems;model graph;service robots;testing;computerised pattern recognition;layout;scene graph object recognition optimization problem energy function best solution best match two dimensional binary hopfield neural network minimize neuron node model graph;energy function;computer vision;hopfield neural network;optimization problem;scene graph;hopfield neural networks;neural nets computer vision computerised pattern recognition computerised picture processing;computerised picture processing;minimize;neurons;best match;two dimensional binary hopfield neural network;node;robot vision systems;parallel processing;neuron	A model-based recognition method is introduced which is formulated as an optimization problem. An energy function is derived which represents the constraints on the best solution in order to find the best match. A two-dimensional binary Hopfield neural network is implemented to minimize the energy function. The state of each neuron in the Hopfield network represents the possibility of a match between a node in the model graph and a node in the scene graph. >	artificial neural network;hopfield network;outline of object recognition	Nasser M. Nasrabadi;Wei Li;Chang Y. Choo	1990		10.1109/ICCV.1990.139542	layout;optimization problem;computer vision;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;software testing;scene graph;node;hopfield network;artificial neural network	Vision	19.69274487507057	-24.793159937009584	128422
270f75b1500ce1a643622c2580ea13dddf71b483	parity with two layer feedforward nets	parite;feedforward;neural networks;parity;boucle anticipation;ciclo anticipacion;paridad;minimum nodes;reseau neuronal;red neuronal;parity mapping;neural network	A key issue about neural net functionality is the parity mapping function which is related to high order multiplication. This paper shows a simple two layer neural net function for mapping parity and proving minimum number of necessary hidden units.	feed forward (control);feedforward neural network	J. M. Minor	1993	Neural Networks	10.1016/S0893-6080(05)80114-5	parity;computer science;artificial intelligence;machine learning;mathematics;feed forward;artificial neural network;algorithm	ML	15.409723788968147	-27.086535354676542	128452
ef7b86a30a52d64d111d44ba4a6fb714dfca58a5	randomized clustered nystrom for large-scale kernel machines		The Nystrom method has been popular for generating the low-rank approximation of kernel matrices that arise in many machine learning problems. The approximation quality of the Nystrom method depends crucially on the number of selected landmark points and the selection procedure. In this paper, we present a novel algorithm to compute the optimal Nystrom low-approximation when the number of landmark points exceed the target rank. Moreover, we introduce a randomized algorithm for generating landmark points that is scalable to large-scale data sets. The proposed method performs K-means clustering on low-dimensional random projections of a data set and, thus, leads to significant savings for high-dimensional data sets. Our theoretical results characterize the tradeoffs between the accuracy and efficiency of our proposed method. Extensive experiments demonstrate the competitive performance as well as the efficiency of our proposed method.	approximation;cluster analysis;experiment;k-means clustering;kernel (operating system);kernel method;landmark point;machine learning;numerical analysis;nyström method;randomized algorithm;scalability;turing machine	Farhad Pourkamali Anaraki;Stephen Becker;Michael B. Wakin	2018			machine learning;artificial intelligence;scalability;mathematical optimization;kernel (linear algebra);cluster analysis;computer science;nyström method;matrix (mathematics);data set;randomized algorithm	AI	24.20589293016846	-36.40399534075258	128579
b00a8247b66afb4d4d6f28f291008e2d959f7105	adaptive minimax regret against smooth logarithmic losses over high-dimensional ε1-balls via envelope complexity		We develop a new theoretical framework, the envelope complexity, to analyze the minimax regret with logarithmic loss functions and derive a Bayesian predictor that adaptively achieves the minimax regret over highdimensional `1-balls within a factor of two. The prior is newly derived for achieving the minimax regret and called the spike-andtails (ST) prior as it looks like. The resulting regret bound is so simple that it is completely determined with the smoothness of the loss function and the radius of the balls except with logarithmic factors, and it has a generalized form of existing regret/risk bounds. In the preliminary experiment, we confirm that the ST prior outperforms the conventional minimax-regret prior under non-highdimensional asymptotics.	kerrison predictor;loss function;minimax;the spike (1997)	Kohei Miyaguchi;Kenji Yamanishi	2018	CoRR			ML	21.383124436963655	-30.785174604309404	128610
05eb25b9b945ec6cd37af3fc80dd36b6be4711e0	fast rates for support vector machines	learning rate;distribution donnee;analisis estadistico;approximation error;error function;intelligence artificielle;satisfiability;error aproximacion;data distribution;sobolev space;approximation fonction;espacio sobolev;statistical analysis;function approximation;bayes risk;machine exemple support;analyse statistique;funcion error;artificial intelligence;fonction erreur;inteligencia artificial;support vector machine;maquina ejemplo soporte;vector support machine;espace sobolev;distribucion dato;erreur approximation	We establish learning rates to the Bayes risk for support vector machines (SVMs) using a regularization sequence λn = n −α, where α ∈ (0, 1) is arbitrary. Under a noise condition recently proposed by Tsybakov these rates can become faster than n−1/2. In order to deal with the approximation error we present a general concept called the approximation error function which describes how well the infinite sample versions of the considered SVMs approximate the data-generating distribution. In addition we discuss in some detail the relation between the “classical” approximation error and the approximation error function. Finally, for distributions satisfying a geometric noise assumption we establish some learning rates when the used RKHS is a Sobolev space.	approximation algorithm;approximation error;support vector machine	Ingo Steinwart;Clint Scovel	2005		10.1007/11503415_19	support vector machine;mathematical optimization;approximation error;function approximation;sobolev space;computer science;error function;machine learning;calculus;mathematics;statistics;satisfiability	ML	20.08445200888903	-34.13890381336381	128694
06656b85e9df9f26e0fe959faf7e2899c0dafb9d	conditional distribution learning with neural networks and its application to universal image denoising		A simple and scalable denoising algorithm is proposed that can be applied to a wide range of source and noise models. At the core of the proposed CUDE algorithm is symbol-by-symbol universal denoising used by the celebrated DUDE algorithm, whereby the optimal estimate of the source from an unknown distribution is computed by inverting the empirical distribution of the noisy observation sequence by a deep neural network, which naturally and implicitly aggregates multi-pie contexts of similar characteristics and estimates the conditional distribution more accurately. The performance of CUDE is evaluated for grayscale images of varying bit depths, which improves upon DUDE and its recent neural network based extension, Neural DUDE.	algorithm;artificial neural network;deep learning;grayscale;neural oscillation;noise reduction;scalability	Jongha Ryu;Young-Han Kim	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451573	grayscale;empirical distribution function;noise measurement;artificial intelligence;noise reduction;scalability;artificial neural network;pattern recognition;computer science;context model;conditional probability distribution	Robotics	24.353969926104945	-30.53744358313965	128729
b0bf4f39ba3d883cf90dab7c2bd0a2730f555200	minimax estimation of neural net distance		An important class of distance metrics proposed for training generative adversarial networks (GANs) is the integral probability metric (IPM), in which the neural net distance captures the practical GAN training via two neural networks. This paper investigates the minimax estimation problem of the neural net distance based on samples drawn from the distributions. We develop the first known minimax lower bound on the estimation error of the neural net distance, and an upper bound tighter than an existing bound on the estimator error for the empirical neural net distance. Our lower and upper bounds match not only in the order of the sample size but also in terms of the norm of the parameter matrices of neural networks, which justifies the empirical neural net distance as a good approximation of the true neural net distance for training GANs in practice.	approximation;artificial neural network;estimation theory;generative adversarial networks;minimax	Kaiyi Ji;Yingbin Liang	2018			machine learning;mathematical optimization;estimator;sample size determination;artificial neural network;artificial intelligence;matrix (mathematics);mathematics;upper and lower bounds;minimax	ML	21.262145858913033	-32.34468437039024	128909
7cbae3bf85685b0a0961b4318214e4e1bfc5692b	robust segmentation of noisy images using a neural network model	learning algorithm;image processing;learning;refining segmentation;procesamiento imagen;segmentation;algorithme apprentissage;image bruitee;traitement image;aprendizaje;imagen sonora;apprentissage;initial segmentation;noisy image;segmentation image;neural network model;reseau neuronal;red neuronal;segmentacion;neural network	In this paper we present a robust algorithm for .segmentation of noisy images using a neural network. A neural network model is employed to represent a segmented image in such a way that the region type of each pixel simply corresponds to the neuron state. The image segmentation procedure consists of two phases: initial segmentation, and refining segmentation. The initial segmentation is implemented iteratively by using a dynamic evolution algorithm to minimize the energy function of the neural network. During the second phase, a learning procedure is described to determine the interconnection weights based on a multi-layer logic neural network, and the refining segmentation is achieved by a retrieval procedure. Several experimental results involving both synthetic and real images are reported.	algorithm;artificial neural network;image segmentation;interconnection;layer (electronics);mathematical optimization;network model;neuron;pixel;synthetic intelligence	Tao Wang;Xinhua Zhuang;Xiaoliang Xing	1992	Image Vision Comput.	10.1016/0262-8856(92)90054-7	computer vision;computer science;artificial intelligence;machine learning;segmentation-based object categorization;time delay neural network;region growing;image segmentation;scale-space segmentation;segmentation;artificial neural network	Vision	12.268251679557277	-31.42500746834717	128948
92808d23b8c78359e563cf80f36eb3b24095c106	a high bit resolution fpga implementation of a fnn with a new algorithm for the activation function	feedforward neural network;feedforward neural networks;activation function;fpga;fpga implementation;vhdl;hardware	Several implementations of Feedforward Neural Netw orks have been reported in scientific papers. These implementations do not allow the direct use o f off-line trained networks. Usually the problem is the lower precision (compared to the software used for traini ng) or modifications in the activation function. In the present work a hardware solution called Artificial Neural N etwork Processor, using a FPGA, fits the requiremen ts for a direct implementation of Feedforward Neural Network s, because of the high precision and accurate activ ation function that were obtained. The resulting hardware solution is tested with data from a real system to confirm that it can correctly implement the models prepared offline with MATLAB.	activation function;algorithm;fits;feed forward (control);feedforward neural network;field-programmable gate array;interactive whiteboard;matlab;neural oscillation;online and offline;scientific literature	Pedro Ferreira;Pedro Ribeiro;Ana Antunes;Fernando Morgado Dias	2007	Neurocomputing	10.1016/j.neucom.2006.11.028	feedforward neural network;computer architecture;real-time computing;computer science;theoretical computer science;machine learning;time delay neural network;activation function	ML	16.777662804502103	-25.233714119227294	128958
5336c461a75706624d25ab99fa9caa3321bb2060	spin orbit torque device based stochastic multi-bit synapses for on-chip stdp learning		As a large number of neurons and synapses are needed in spike neural network (SNN) design, emerging devices have been employed to implement synapses and neurons. In this paper, we present a stochastic multi-bit spin orbit torque (SOT) memory based synapse, where only one SOT device is switched for potentiation and depression using modified Gray code. The modified Gray code based approach needs only N devices to represent 2N levels of synapse weights. Early read termination scheme is also adopted to reduce the power consumption of training process by turning off less associated neurons and its ADCs. For MNIST dataset, with comparable classification accuracy, the proposed SNN architecture using 3-bit synapse achieves 68.7% reduction of ADC overhead compared to the conventional 8-level synapse.	artificial neural network;mnist database;overhead (computing);spiking neural network;synapse	Gyuseong Kang;Yunho Jang;Jongsun Park	2018		10.1145/3218603.3218654	chip;architecture;synapse;electronic engineering;computer science;spiking neural network;artificial neural network;spin-½;mnist database;gray code	ML	15.348583281866492	-27.544783554934547	129130
c6e1a9a6e78adb6d771b5516982c4051ff6059e4	learning dynamic bayesian network models via cross-validation	sample size;learning;technology;teknikvetenskap;engineering and technology;teknik och teknologier;dynamic bayesian network;dynamic bayesian network models;cross validation;bayesian information criterion	We study cross-validation as a scoring criterion for learning dynamic Bayesian network models that generalize well. We argue that cross-validation is more suitable than the Bayesian scoring criterion for one of the most common interpretations of generalization. We confirm this by carrying out an experimental comparison of cross-validation and the Bayesian scoring criterion, as implemented by the Bayesian Dirichlet metric and the Bayesian information criterion. The results show that cross-validation leads to models that generalize better for a wide range of sample sizes.	bayesian information criterion;cross-validation (statistics);dynamic bayesian network	José M. Peña;Johan Björkegren;Jesper Tegnér	2005	Pattern Recognition Letters	10.1016/j.patrec.2005.04.005	bayesian average;econometrics;bayesian experimental design;variable-order bayesian network;wake-sleep algorithm;bayesian programming;computer science;machine learning;causal markov condition;pattern recognition;mathematics;bayesian linear regression;bayesian hierarchical modeling;bayesian statistics;bayesian econometrics;bayesian information criterion;dynamic bayesian network;statistics;technology	ML	20.25587890307718	-34.71312396107231	129176
240afb795f4e2a156f275d7dc60f2e87ee96b2a8	training restricted boltzmann machines with multi-tempering: harnessing parallelization	restricted boltzmann machines;neural networks;mathematics and statistics;machine learning;markov chain monte carlo	Restricted Boltzmann Machines (RBM’s) are unsupervised probabilistic neural networks that can be stacked to form Deep Belief Networks. Given the recent popularity of RBM’s and the increasing availability of parallel computing architectures, it becomes interesting to investigate learning algorithms for RBM’s that benefit from parallel computations. In this paper, we look at two extensions of the parallel tempering algorithm, which is a Markov Chain Monte Carlo method to approximate the likelihood gradient. The first extension is directed at a more effective exchange of information among the parallel sampling chains. The second extension estimates gradients by averaging over chains from different temperatures. We investigate the efficiency of the proposed methods and demonstrate their usefulness on the MNIST dataset. Especially the weighted averaging seems to benefit Maximum Likelihood learning.	approximation algorithm;artificial neural network;bayesian network;computation;deep belief network;generative model;gradient;machine learning;markov chain monte carlo;monte carlo method;parallel computing;parallel tempering;restricted boltzmann machine;sampling (signal processing)	Philemon Brakel;Sander Dieleman;Benjamin Schrauwen	2012		10.1007/978-3-642-33266-1_12	boltzmann machine;mathematical optimization;markov chain monte carlo;computer science;theoretical computer science;machine learning;deep learning;restricted boltzmann machine;artificial neural network;statistics	ML	24.60612606752735	-30.635974839102666	129391
bfd22dc6771de24825c97b24cb6bc49ccae5c328	a localized forgetting method for gaussian rbfn model adaptation	chemical reactors;metodo cuadrado menor;processus gauss;methode moindre carre;olvido;nonlinear models;least squares method;dissolved oxygen;algoritmo recursivo;fonction base radiale;erreur quadratique moyenne;model adaptation;forgetting;non linear model;modele non lineaire;operator space;orthogonal least square;radial basis function networks;modelo no lineal;algorithme recursif;radial basis function;radial basis function network;reacteur chimique;mean square error;difference in differences;recursive algorithm;oubli;gaussian process;error medio cuadratico;nonlinear system;proceso gauss;funcion radial base;localized forgetting;reactor quimico;chemical reactor;nonlinear model	In this paper a localized forgetting method is proposed for on-line adaptation of Gaussian radial basis function network models. It is realised that the commonly used exponential forgetting applies to the past data from the entire operating space uniformly and therefore, is not correct for nonlinear systems where dynamics are different in different operating regions. The new method proposed in this paper sets different forgetting factors in different regions according to the response of the local centre to the current measurement data. The method is applied in conjunction with the recursive orthogonal Least Squares algorithm and the computing is consequently very efficient. The developed method is applied to modelling of dissolved oxygen in a chemical reactor rig. It shows a smaller mean squared error for one-step-ahead prediction than using the uniform forgetting.	algorithm;b-spline;display resolution;least squares;mean squared error;nonlinear system;online and offline;radial basis function network;reactor (software);recursion;time complexity	Dingli Yu	2004	Neural Processing Letters	10.1007/s11063-004-0636-5	nonlinear system;computer science;artificial intelligence;machine learning;calculus;chemical reactor;mathematics;algorithm;statistics	ML	12.196670368414601	-29.87414480584086	129392
d1256fe027ffdb1fdb5f394f6f090e240645fd99	improved policy networks for computer go		Golois uses residual policy networks to play Go. Two improvements to these residual policy networks are proposed and tested. The first one is to use three output planes. The second one is to add Spatial Batch Normalization.	computer go;value network	Tristan Cazenave	2017		10.1007/978-3-319-71649-7_8	computer engineering;residual;artificial intelligence;machine learning;computer science;normalization (statistics);computer go	ML	11.555500849652955	-24.718799897397925	129612
c26ceb3ba219aa4df6b281c364b03b9e9463e4fa	feature selection in genetic fuzzy discretization for the pattern classification problems	methode discretisation;traitement signal;discretisation;filtering;optimisation;filtrage;tecnologia electronica telecomunicaciones;information loss;optimizacion;filtrado;fuzzy discretization;discretization;discretizacion;algoritmo genetico;metodo discretizacion;accuracy;precision;perdida informacion;feature extraction;signal processing;pattern classification;algorithme genetique;pattern recognition;algorithme evolutionniste;genetic algorithm;discretization method;feature selection;algoritmo evolucionista;optimization;reconnaissance forme;extraction caracteristique;evolutionary algorithm;tecnologias;reconocimiento patron;classification accuracy;grupo a;procesamiento senal;perte information;classification forme	We propose a new genetic fuzzy discretization method with feature selection for the pattern classification problems. Traditional discretization methods categorize a continuous attribute into a number of bins. Because they are made on crisp discretization, there exists considerable information loss. Fuzzy discretization allows overlapping intervals and reflects linguistic classification. However, the number of intervals, the boundaries of intervals, and the degrees of overlapping are intractable to get optimized and a discretization process increases the total amount of data being transformed. We use a genetic algorithm with feature selection not only to optimize these parameters but also to reduce the amount of transformed data by filtering the unconcerned attributes. Experimental results showed considerable improvement on the classification accuracy over a crisp discretization and a typical fuzzy discretization with feature selection. key words: genetic algorithm, fuzzy discretization, feature selection, pattern classification	categorization;discretization;feature selection;genetic algorithm;statistical classification	Yoon-Seok Choi;Byung Ro Moon	2007	IEICE Transactions	10.1093/ietisy/e90-d.7.1047	discretization error;computer science;machine learning;evolutionary algorithm;signal processing;pattern recognition;discretization;mathematics;accuracy and precision;feature selection;discretization of continuous features;algorithm	ML	10.725555165911278	-34.54502519846599	129801
98aa08ce48d773935ca79bfbd185513ee1abc935	forward and backward selection in regression hybrid network	forward backward;bayes estimation;model selection;analyse amas;regularisation;analisis estadistico;analisis datos;hybrid network;model selection criteria;fonction base radiale;nested models;regularization;data analysis;estimacion bayes;cluster analysis;red multinivel;radial basis function;statistical analysis;clustering;analyse statistique;pattern recognition;analyse donnee;analisis cluster;regularizacion;reconnaissance forme;multilayer network;reseau multicouche;reseau neuronal;reconocimiento patron;hybrid network architecture;funcion radial base;rbf network;red neuronal;smlp;estimation bayes;neural network	We introduce a Forward Backward and Model Selection algorithm (FBMS) for constructing a hybrid regression network of radial and perceptron hidden units. The algorithm determines whether a radial or a perceptron unit is required at a given region of input space. Given an error target, the algorithm also determines the number of hidden units. Then the algorithm uses model selection criteria and prunes unnecessary weights. This results in a final architecture which is often much smaller than a RBF network or a MLP. Results for various data sizes on the Pumadyn data indicate that the resulting architecture competes and often outperform best known results for this data set.	memory-level parallelism;model selection;perceptron;radial (radio);radial basis function network;selection algorithm	Shimon Cohen;Nathan Intrator	2002		10.1007/3-540-45428-4_10	forward algorithm;computer science;artificial intelligence;machine learning;cluster analysis;artificial neural network;statistics	ML	11.576159954532232	-30.747744398422025	130050
3d18b74b221ce6f4f4875ed48380c7395f556b1d	an l1 regularization framework for optimal rule combination	empirical analysis;l 1 regularization;rule learning;optimization problem;path following algorithm;prediction accuracy;global optimization;relational learning;path following	In this paper  l  1 regularization is introduced into relational learning to produce sparse rule combination. In other words, as few as possible rules are contained in the final rule set. Furthermore, we design a rule complexity penalty to encourage rules with fewer literals. The resulted optimization problem has to be formulated in an infinite dimensional space of horn clauses  R   m  associated with their corresponding complexity $\mathcal{C}_m$. It is proved that if a locally optimal rule is generated at each iteration, the final obtained rule set will be globally optimal. The proposed meta-algorithm is applicable to any single rule generator. We bring forward two algorithms, namely,  l  1 FOIL and  l  1 Progol. Empirical analysis is carried on ten real world tasks from bioinformatics and cheminformatics. The results demonstrate that our approach offers competitive prediction accuracy while the interpretability is straightforward.	matrix regularization	Yanjun Han;Jue Wang	2009		10.1007/978-3-642-04180-8_50	optimization problem;mathematical optimization;computer science;artificial intelligence;machine learning;data mining;mathematics;global optimization	ML	18.603409137202387	-36.80218669586052	130240
0246dbd40e894df76190db7aa8f8e8c8a8da7e2c	shortest common superstring problem with discrete neural networks	neural model;combinatorial optimization problem;artificial neural network;neural network	In this paper, we investigate the use of artificial neural networks in order to solve the Shortest Common Superstring Problem. Concretely, the neural network used in this work is based on a multivalued model, MREM, very suitable for solving combinatorial optimization problems. We describe the foundations of this neural model, and how it can be implemented in the context of this problem, by taking advantage of a better representation than in other models, which, in turn, contributes to ease the computational dynamics of the model. Experimental results prove that our model outperforms other heuristic approaches known from the specialized literature.	neural networks	Domingo López-Rodríguez;Enrique Mérida Casermeiro	2009		10.1007/978-3-642-04921-7_7	stochastic neural network;nervous system network models;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;machine learning;mathematics;deep learning;artificial neural network;algorithm	ML	15.6884623388227	-24.445752373072953	130293
138574f63680e1dd9bd7e222c2cb16a3f41a4d6c	multi-class classifier-independent feature analysis	discriminatory power;ranking;feature selection;feature analysis	In ( Holz and Loew, 1994a  ;   Holz and Loew, 1994b ), we presented a metric for use in classifier-independent feature analysis called relative feature importance (RFI). RFI was shown to correctly rank features on a variety of two-class multi-cluster, mixed-distribution problems, including problems that cannot be solved using the marginal distributions of the features. We present here a complete design for RFI, including new results on parameter settings and calculation details determined on two-class problems. We then show that, using the design arising from exploration of two-class problems, RFI extends naturally and successfully to multi-class problems.		Hilary J. Holz;Murray H. Loew	1997	Pattern Recognition Letters	10.1016/S0167-8655(97)00118-9	pattern recognition;ranking;computer science;artificial intelligence;machine learning;mathematics;feature selection;operations research	Vision	10.868366105417415	-35.20839675703326	130911
5a5b51565a8ebfe972a61924fdb3acc63ccabcee	dimensionality dependent pac-bayes margin bound	会议论文	Margin is one of the most important concepts in machine learning. Previous margin bounds, both for SVM and for boosting, are dimensionality independent. A major advantage of this dimensionality independency is that it can explain the excellent performance of SVM whose feature spaces are often of high or infinite dimension. In this paper we address the problem whether such dimensionality independency is intrinsic for the margin bounds. We prove a dimensionality dependent PAC-Bayes margin bound. The bound is monotone increasing with respect to the dimension when keeping all other factors fixed. We show that our bound is strictly sharper than a previously well-known PAC-Bayes margin bound if the feature space is of finite dimension; and the two bounds tend to be equivalent as the dimension goes to infinity. In addition, we show that the VC bound for linear classifiers can be recovered from our bound under mild conditions. We conduct extensive experiments on benchmark datasets and find that the new bound is useful for model selection and is usually significantly sharper than the dimensionality independent PAC-Bayes margin bound as well as the VC bound for linear classifiers.	benchmark (computing);experiment;feature vector;machine learning;model selection;vc dimension;monotone	Chi Jin;Liwei Wang	2012			mathematical optimization;combinatorics;computer science;chapman–robbins bound;machine learning;mathematics	ML	20.805039793252774	-33.867719745348246	130936
44f1804e32e4bffe383713fb1d165f1d68b03850	a bp neural network text categorization method optimized by an improved genetic algorithm	back propatation neural network;back propagation neural network bp neural network text categorization method genetic algorithm;optimize;text categorization genetic algorithms biological cells neural networks neurons training vectors;optimize back propatation neural network text categorization genetic algorithm;text analysis backpropagation genetic algorithms neural nets;genetic algorithm;text categorization	The back propagation(BP) neural network is widely used for text categorization and could achieve high performance. However, the greatest disadvantage of this network is its long training time. The genetic algorithm is often used to generate useful solutions for optimization. In this paper we combined the genetic algorithm and the back propagation neural network for text categorization. We use the genetic algorithm to optimize weights of connections in the back propagation neural network instead of back-propagating. At the same time, we improved the genetic algorithm to increase its efficiency. Through this method, we overcome the traditional disadvantage of the BP neural network. Our experiments show that our method outperforms the traditional method for text categorization.	artificial neural network;backpropagation;categorization;document classification;experiment;genetic algorithm;mathematical optimization;nonlinear system;software propagation;text corpus	Rongze Xia;Yan Jia;Hu Li	2013	2013 Ninth International Conference on Natural Computation (ICNC)	10.1109/ICNC.2013.6817981	probabilistic neural network;computer science;artificial intelligence;machine learning;pattern recognition;time delay neural network	Robotics	13.486762966666888	-24.51371953990002	131120
614265e26a32c380d975b5183445e3976b3f3446	incremental tractable reasoning about qualitative temporal constraints	interval algebra;satisfiability;input constraint;temporal constraints;temporal reasoning	In this paper, we consider semi-supervised classification on evolutionary data, where the distribution of the data and the underlying concept that we aim to learn change over time due to shortterm noises and long-term drifting, making a single aggregated classifier inapplicable for long-term classification. The drift is smooth if we take a localized view over the time dimension, which enables us to impose temporal smoothness assumption for the learning algorithm. We first discuss how to carry out such assumption using temporal regularizers defined in a structural way with respect to the Hilbert space, and then derive the online algorithm that efficiently finds the closed-form solution to the classification functions. Experimental results on real-world evolutionary mailing list data demonstrate that our algorithm outperforms classical semi-supervised learning algorithms in both algorithmic stability and classification accuracy.	cobham's thesis;hilbert space;online algorithm;performance;semi-supervised learning;semiconductor industry;stability (learning theory);supervised learning	Alfonso Gerevini	2003			mathematical optimization;combinatorics;discrete mathematics;interval temporal logic;mathematics;linguistics;satisfiability	ML	22.839499494823027	-33.467855012411746	131255
259cbb06f981ccddc2056262c1ea325f22d038f3	fault diagnosis and prediction of complex system based on hidden markov model			complex system;hidden markov model;markov chain	Chen Li;Fajie Wei;Cheng Wang;Shenghan Zhou	2017	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-169344	mathematics;artificial intelligence;machine learning;complex system;hidden markov model;maximum-entropy markov model;markov model;forward algorithm	Robotics	21.85609728644854	-25.010221206369447	131261
b09f5f2a16177520197bf7b74e28907fc04872fd	volterra models and three-layer perceptrons	volterra series;modelizacion;nonlinear mapping;transfer functions;activation function;fonction polynomiale;multilayer perceptrons;aproximacion;serie volterra;discrete time;backpropagation;polynomials;approximation;high order volterra systems three layer perceptrons feedforward artificial neural networks polynomial activation functions discrete time volterra models nonlinear physical systems physiological systems stimulus response data low order nonlinearities input output nonlinear mappings tapped delay inputs separable volterra networks backpropagation laguerre expansion technique;input output;modelisation;nonlinear systems;red multinivel;systeme non lineaire;backpropagation feedforward neural nets multilayer perceptrons transfer functions polynomials nonlinear systems volterra series;feedforward neural nets;multilayer network;multilayer perceptrons polynomials nonlinear systems kernel multi layer neural network artificial neural networks biomedical engineering neural networks context modeling yield estimation;reseau multicouche;perceptron;reseau neuronal;funcion polinomial;nonlinear system;sistema no lineal;polynomial function;modeling;computer simulation;red neuronal;non linear system;artificial neural network;neural network	"""This paper proposes the use of a class of feedforward artificial neural networks with polynomial activation functions (distinct for each hidden unit) for practical modeling of high-order Volterra systems. Discrete-time Volterra models (DVMs) are often used in the study of nonlinear physical and physiological systems using stimulus-response data. However, their practical use has been hindered by computational limitations that confine them to low-order nonlinearities (i.e., only estimation of low-order kernels is practically feasible). Since three-layer perceptrons (TLPs) can be used to represent input-output nonlinear mappings of arbitrary order, this paper explores the basic relations between DVMs and TLPs with tapped-delay inputs in the context of nonlinear system modeling. A variant of TLP with polynomial activation functions-termed """"separable Volterra networks"""" (SVNs)-is found particularly useful in deriving explicit relations with DVM and in obtaining practicable models of highly nonlinear systems from stimulus-response data. The conditions under which the two approaches yield equivalent representations of the input-output relation are explored, and the feasibility of DVM estimation via equivalent SVN training using backpropagation is demonstrated by computer-simulated examples and compared with results from the Laguerre expansion technique (LET). The use of SVN models allows practicable modeling of high-order nonlinear systems, thus removing the main practical limitation of the DVM approach."""	artificial neural network;backpropagation;computation;computer simulation;doctor of veterinary medicine;feedforward neural network;lupus erythematosus tumidus;multitier architecture;nonlinear system;perceptron;polynomial;systems modeling;task parallelism;thin layer chromatography	Vasilis Z. Marmarelis;Xiao Zhao	1997	IEEE transactions on neural networks	10.1109/72.641465	input/output;discrete time and continuous time;systems modeling;nonlinear system;computer science;backpropagation;perceptron;machine learning;approximation;control theory;transfer function;activation function;artificial neural network;polynomial	Robotics	18.43889804554879	-28.228574368443983	131424
7bb7c59dabd0bc53e95d8846294da4819944e301	offline recognition of handwritten numeral characters with polynomial neural networks using topological features	performance measure;prediction error;polynomial neural network;rule based;multilayer perceptron;radial basis function;machine learning;pattern recognition;handwritten numeral character recognition;tmdh;support vector machine;neural network model;classification accuracy;group method of data handling;dimensional reduction;non gaussian topological features;polynomial networks	Group-Method of Data Handling (GMDH) has been recognized as a powerful tool in machine learning It has the potential to build predictive neural network models of polynomial functions using only a reduced set of features which minimizes the prediction error This paper explores the offline recognition of isolated handwritten numeral characters described with non-Gaussian topological features using GMDH-based polynomial networks In order to study the effectiveness of the proposed approach, we apply it on a publicly available dataset of isolated handwritten numerals and compare the results with five other state-of-the-art classifiers: multilayer Perceptron, support-vector machine, radial-basis function, naive Bayes and rule-based classifiers In addition to improving the classification accuracy and the per-class performance measures, using GMDH-based polynomial neural networks has led to significant feature dimensionality reduction.	artificial neural network;online and offline;polynomial	El-Sayed M. El-Alfy	2010		10.1007/978-3-642-13059-5_18	rule-based system;support vector machine;radial basis function;speech recognition;computer science;machine learning;group method of data handling;mean squared prediction error;pattern recognition;multilayer perceptron;artificial neural network	ML	13.977541641571124	-35.831134156429975	131849
06b62152b601edf6bde466dcc5336cde858ca7fd	a general memory-bounded learning algorithm		In an era of big data there is a growing need for memory-bounded learning algorithms. In the last few years researchers have investigated what cannot be learned under memory constraints. In this paper we focus on the complementary question of what can be learned under memory constraints. We show that if a hypothesis class fulfills a combinatorial condition defined in this paper, there is a memory-bounded learning algorithm for this class. We prove that certain natural classes fulfill this combinatorial property and thus can be learned under memory constraints.	algorithm;big data;machine learning	Michal Moshkovitz;Naftali Tishby	2017	CoRR		machine learning;artificial intelligence;mathematics;big data;algorithm;bounded function	ML	19.96584759485738	-32.04446514856414	132208
579a57f3b9938a24f05fe3c73292aa17e7fabaee	improving the stability for spiking neural networks using anti-noise learning rule		Most of the existing SNNs only consider training the noise-free data. However, noise extensively exists in actual SNNs. The stability of networks is affected by noise perturbation during the training period. Therefore, one research challenge is to improve the stability and produce reliable outputs under the present of noises. In this paper, the training method and the exponential method are employed to enhance the neural network ability of noise tolerance. The comparison of conventional and anti-noise SNNs under various tasks shows that the anti-noise SNN can significantly improve the noise tolerance capability.	artificial neural network;learning rule;spiking neural network	Yuling Luo;Qiang Fu;Junxiu Liu;Yongchuang Huang;Xuemei Ding;Yi Cao	2018		10.1007/978-3-319-97310-4_4	spiking neural network;machine learning;artificial neural network;artificial intelligence;pattern recognition;computer science;learning rule	ML	16.21612361091088	-25.905315220075458	132209
ce63190b68089b7398f6f8c7392e29106c253704	hybridizing extreme learning machines and genetic algorithms to select acoustic features in vehicle classification applications	extreme learning machine;genetic algorithm;feature selection;vehicle classification	Currently traffic noise has become an important factor that affects human health, and thus, an application able to classify vehicles on the basis of the sound they produce becomes important in the effort of fulfilling recommendations that aim at reducing traffic noise and improving intelligent transportation systems. This paper focuses on the problem of selecting those sound-describing features that make the vehicle classifier work properly. In particular, the goal of this paper is to evaluate the feasibility of a novel feature selection method based on a special class of Genetic Algorithm (with restricted search) hybridized with a Extreme Learning Machine. Because of its great generalization performance at a very fast learning speed, the Extreme Learning Machine plays the key role of providing the fitness of candidate solutions in each generation of the Genetic Algorithm. After a number of experiments comparing its performance to that of other fast learning algorithms, our approach has been found to be the most feasible for the application at hand. The proposed method help the Extreme Learning Machinebased classifier increase its performance from a mean probability of correct classification of 74.83% (with no feature selection) up to 93.74% (when using the optimum subset of selected features).	acoustic cryptanalysis;bayesian network;circa;covox speech thing;decision tree;digraphs and trigraphs;elm;experiment;feature selection;genetic algorithm;horner's method;lu decomposition;linear algebra;machine learning;our world;portable c compiler;radial basis function;selection algorithm;software release life cycle;source separation;statistical classification;support vector machine	Enrique Alexandre;Lucas Cuadra;Sancho Salcedo-Sanz;Á. Pastor-Sánchez;Carlos Casanova-Mateo	2015	Neurocomputing	10.1016/j.neucom.2014.11.019	semi-supervised learning;feature learning;instance-based learning;genetic algorithm;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;linear classifier;pattern recognition;learning classifier system;stability;computational learning theory;feature selection;active learning;population-based incremental learning;generalization error	AI	13.288471700595977	-24.95503313188714	132295
a414f4dd302ce27cb0bfadea2b6b90f40a22ee28	exploiting chaos in learning system identification for nonlinear state space models	neural networks;learning;chaos;system identification;state space	The paper presents two learning methods for nonlinear system identification. Both methods employ neural network models for representing state and output functions. The first method of learning nonlinear state space is based on using chaotic or noise signals in the training of state neural network so that the state neural network is designed to produce a sequence in a recursive way under the excitement of the system input. The second method of learning nonlinear state space has an observer neural network devoted to estimate the states as a function of the system inputs and the outputs of the output neural network. This observer neural network is trained to produce a state sequence when the output neural network is forced by the same sequence and then the state neural network is trained to produce the estimated states in a recursive way under the excitement of the system input. The developed identification methods are tested on a set of benchmark plants including a non-autonomous chaotic system, i.e. Duffing oscillator. Both proposed methods are observed much superior than well-known identification methods including nonlinear ARX, nonlinear ARMAX, Hammerstein, Wiener, Hammerstein–Wiener, Elman network, state space models with subspace and prediction error methods.	algorithm;arx;artificial neural network;autonomous robot;benchmark (computing);chaos theory;chief security officer;convolutional neural network;crystal oscillator;experiment;memory-level parallelism;network model;nonlinear autoregressive exogenous model;nonlinear system identification;performance;radial (radio);radial basis function;recurrent neural network;recursion;state space;support vector machine	Mehmet Ölmez;Cüneyt Güzelis	2013	Neural Processing Letters	10.1007/s11063-013-9332-7	feedforward neural network;probabilistic neural network;system identification;random neural network;computer science;state space;recurrent neural network;machine learning;control theory;time delay neural network;nonlinear system identification;artificial neural network	ML	14.339368143649589	-27.38806502022693	132321
05e638aa37912ec3630bd773b1d6e21caef0256e	towards optimal quantization of neural networks		Due to the unprecedented success of deep neural networks in inference tasks like speech and image recognition, there has been increasing interest in using them in mobile and in-sensor applications. As most current deep neural networks are very large in size, a major challenge lies in storing the network in devices with limited memory. Consequently there is growing interest in compressing deep networks by quantizing synaptic weights, but most prior work is heuristic and lacking theoretical foundations. Here we develop an approach to quantizing deep networks using functional high-rate quantization theory. Under certain technical conditions, this approach leads to an optimal quantizer that is computed using the celebrated backpropagation algorithm. In all other cases, a heuristic quantizer with certain regularization guarantees can be computed.	algorithm;artificial neural network;backpropagation;computer vision;deep learning;heuristic;optimal control;quantization (signal processing);random graph;real-time clock;synaptic package manager	Avhishek Chatterjee;Lav R. Varshney	2017	2017 IEEE International Symposium on Information Theory (ISIT)	10.1109/ISIT.2017.8006711	information theory;computer science;artificial neural network;deep learning;quantization (signal processing);heuristic;machine learning;artificial intelligence;backpropagation;inference	ML	21.001625888648444	-30.48797337534842	132431
15d39dd1ec8d71b17ea10909202b33b95c847f1a	automatic spike sorting using tuning information	utilisation information;classification automatique statistiques;automatic;poisson process;animals;neurone;calcul neuronal;models neurological;uso informacion;neural computation;firing rate;taux interet;taux decharge;taux tirs;maximum likelihood;forme onde;information use;maximization;sorting;implementation;maximum vraisemblance;modulacion;automatico;tria;spike sorting;interest rate;algorithme;signal processing computer assisted;spike;algorithm;accord frequence;neurona;forma onda;tuning;expectation maximization;62h30;clustering;mauvaise classification;triage;covariate;automatique;algorithms;nerve net;proceso poisson;sintonizacion frecuencia;covariable;waveform;tasa interes;neurons;bad classification;cluster analysis statistics;reseau neuronal;action potentials;58a25;implementacion;maximizacion;automatic data processing;red neuronal;computacion neuronal;maxima verosimilitud;neuron;potentiel action;processus poisson;maximisation;neural network;algoritmo;modulation	Current spike sorting methods focus on clustering neurons' characteristic spike waveforms. The resulting spike-sorted data are typically used to estimate how covariates of interest modulate the firing rates of neurons. However, when these covariates do modulate the firing rates, they provide information about spikes' identities, which thus far have been ignored for the purpose of spike sorting. This letter describes a novel approach to spike sorting, which incorporates both waveform information and tuning information obtained from the modulation of firing rates. Because it efficiently uses all the available information, this spike sorter yields lower spike misclassification rates than traditional automatic spike sorters. This theoretical result is verified empirically on several examples. The proposed method does not require additional assumptions; only its implementation is different. It essentially consists of performing spike sorting and tuning estimation simultaneously rather than sequentially, as is currently done. We used an expectation-maximization maximum likelihood algorithm to implement the new spike sorter. We present the general form of this algorithm and provide a detailed implementable version under the assumptions that neurons are independent and spike according to Poisson processes. Finally, we uncover a systematic flaw of spike sorting based on waveform information only.	bitonic sorter;cluster analysis;expectation–maximization algorithm;flaw hypothesis methodology;modulation;sense of identity (observable entity);sorting algorithm;waveform;statistical cluster	Valérie Ventura	2009	Neural Computation	10.1162/neco.2009.12-07-669	waveform;poisson process;covariate;expectation–maximization algorithm;computer science;sorting;artificial intelligence;machine learning;interest rate;mathematics;maximum likelihood;cluster analysis;implementation;automatic transmission;action potential;artificial neural network;algorithm;statistics;models of neural computation;modulation	ML	21.706875804781593	-26.870651491205784	132656
1f66f55d66a162f3cd3543c7b2afd48a4523cfdd	cost sensitive online multiple kernel classification	multiple kernel learning;online learning;cost sensitive learning	Learning from data streams has been an important open research problem in the era of big data analytics. This paper investigates supervised machine learning techniques for mining data streams with application to online anomaly detection. Unlike conventional machine learning tasks, machine learning from data streams for online anomaly detection has several challenges: (i) data arriving sequentially and increasing rapidly, (ii) highly class-imbalanced distributions; and (iii) complex anomaly patterns that could evolve dynamically. To tackle these challenges, we propose a novel Cost-Sensitive Online Multiple Kernel Classification (CSOMKC) scheme for comprehensively mining data streams and demonstrate its application to online anomaly detection. Specifically, CSOMKC learns a kernel-based cost-sensitive prediction model for imbalanced data streams in a sequential or online learning fashion, in which a pool of multiple diverse kernels is dynamically explored. The optimal kernel predictor and the multiple kernel combination are learnt together, and simultaneously class imbalance issues are addressed. We give both theoretical and extensive empirical analysis of the proposed algorithms.	algorithm;anomaly detection;big data;gradient descent;kernel (operating system);kerrison predictor;machine learning;nonlinear system;open research;scalability;supervised learning	Doyen Sahoo;Steven C. H. Hoi;Peilin Zhao	2016			semi-supervised learning;instance-based learning;online machine learning;machine learning;pattern recognition;data mining;active learning;generalization error	ML	14.003263040951017	-37.86805988505989	132913
edd986c63153bd00753ba9985e4107b57612a2f5	intrinsic plasticity for reservoir learning algorithms.	intrinsic plasticity;learning algorithm;echo state network;benchmark problem;spectral radius;online learning;backpropagation;signal processing	One of the most difficult problems in using dynamic reservoirs like echo state networks for signal processing is the choice of reservoir network parameters like connectivity or spectral radius of the weight matrix. In this article, we investigate the properties of an unsupervised intrinsic plasticity rule for signal specific adaptive shaping of the reservoir, which is local in space and time and aims at maximizing input–to–output information transmission for each neuron. We show that the rule consistently regulates the neurons’ mean outputs and variances and is robust to learning parameter changes. Simulations reveals that this reservoir adaptation robustly enhances online learning of Backpropagation–Decorrelation recurrent learning for a tenth–order nonlinear NARMA benchmark problem.	algorithm;backpropagation;benchmark (computing);computer simulation;decorrelation;echo state network;experiment;machine learning;neuron;noise shaping;nonlinear system;signal processing;time complexity	Marion Wardermann;Jochen J. Steil	2007			computer science;artificial intelligence;backpropagation;machine learning;signal processing;pattern recognition;spectral radius;echo state network	ML	19.200837150245633	-29.01433617361067	132929
1649eb3b7b5d6092bfbe3bbf17277c530609ca78	a neural network based on subnets - snn	neural network		artificial neural network;subnetwork	Feng Liu;Jianxin Jiang;Jun Cheng;Kechu Yi	1992			artificial intelligence;pattern recognition;artificial neural network;computer science	ML	12.666901611560125	-27.23318377787681	133745
17ea3c890a3c1b1a447d170a534b034da545b8c5	a fast winner-take-all neural networks with the dynamic ratio	convergence speed;decimal system;neural network;mutual inhibition;winner-take-all;winner take all	In this paper, we propose a fast winner-take-all (WTA) neural network. The fast winner-take-all neural network with the dynamic ratio in mutual-inhibition is developed from the general mean-based neural network (GEMNET), which adopts the mean of the active neurons as the threshold of mutual inhibition. Furthermore, the other winner-take-all neural network enhances the convergence speed to become a decimal system. The proposed WTA neural networks statistically achieve the large ratio of mutual inhibition. The new WTA Neural Networks converge faster than the existing WTA neural networks for a large number of competitors based on both theoretical analyses and simulation results.	converge;convolutional neural network;neural networks;simulation;weapon target assignment problem;winner-take-all (computing)	Chi-Ming Chen;Ming-Hung Hsu;Tien-Yo Wang	2002	J. Inf. Sci. Eng.		winner-take-all;stochastic neural network;computer science;artificial intelligence;theoretical computer science;machine learning;decimal;time delay neural network;artificial neural network	ML	15.924945931419447	-28.131410827990784	133762
9582ac16e38a851c6bacf85719b5525cd2e4833a	generalization-aware structured regression towards balancing bias and variance		Attaining the proper balance between underfitting and overfitting is one of the central challenges in machine learning. It has been approached mostly by deriving bounds on generalization risks of learning algorithms. Such bounds are, however, rarely controllable. In this study, a novel bias-variance balancing objective function is introduced in order to improve generalization performance. By utilizing distance correlation, this objective function is able to indirectly control a stability-based upper bound on a model’s expected true risk. In addition, the Generalization-Aware Collaborative Ensemble Regressor (GLACER) is developed, a model that bags a crowd of structured regression models, while allowing them to collaborate in a fashion that minimizes the proposed objective function. The experimental results on both synthetic and real-world data indicate that such an objective enhances the overall model’s predictive performance. When compared against a broad range of both traditional and structured regression models GLACER was ∼10-56% and ∼49-99% more accurate for the task of predicting housing prices and hospital readmissions, respectively.	algorithm;bias–variance tradeoff;generalization error;loss function;machine learning;mathematical optimization;optimization problem;overfitting;synthetic intelligence	Martin Pavlovski;Fang Zhou;Nino Arsov;Ljupco Kocarev;Zoran Obradovic	2018		10.24963/ijcai.2018/363	machine learning;artificial intelligence;computer science;regression	AI	22.892752520078957	-34.20309100613414	133798
b294041b903f64f39a4918e88ff8e389123de69a	application of a self-organizing fuzzy neural network controller with group-based genetic algorithm to greenhouse	structure learning;group based genetic algorithm;parameter learning algorithm self organizing fuzzy neural network ebf unit genetic algorithm structure learning algorithm;fuzzy neural network;learning algorithm;fuzzy neural nets;rule number;elman neural network;pollution control;green products;fuzzy control green products genetic algorithms fuzzy neural networks biological cells humidity input variables;nonlinear control systems;input variables;fuzzy control;structure learning algorithm;biological cells;self organising feature maps;elman neural network self organizing fuzzy neural network controller group based genetic algorithm complex nonlinear system greenhouse internal climate soffnnc structure learning algorithm rule number;humidity;parameter learning algorithm;self organization;self organising feature maps fuzzy control fuzzy neural nets genetic algorithms large scale systems learning artificial intelligence neurocontrollers nonlinear control systems pollution control;genetic algorithm;genetic algorithms;complex nonlinear system;self organizing fuzzy neural network controller;neurocontrollers;learning artificial intelligence;ebf unit;fuzzy neural networks;self organizing fuzzy neural network;soffnnc;greenhouse internal climate;large scale systems	As a complex nonlinear system, greenhouse can not be controlled perfectly by traditional control strategies. This paper proposes a self-organizing fuzzy neural network controller (SOFNNC) with group-based genetic algorithm (GGA) to drive the internal climate of the greenhouse. SOFFNNC is a hybrid control strategy which combines fuzzy control and neural network organically. It generates or prunes neurons automatically by the structure learning algorithm, which can adaptively strike a balance between the rule number and the desired performance. In other to avoid the shortage of the original learning algorithm to SOFNNC, we come up with an improved structure learning method and a new parameter learning method with GGA. Based on a greenhouse model established by an Elman neural network (ENN), we test the performance of SOFNNC. Simulation and comparison results prove that SOFNNC can achieve outstanding control effect with high efficiency.	artificial neural network;complex systems;control theory;fuzzy control system;genetic algorithm;gradient descent;local convergence;network interface controller;neuro-fuzzy;nonlinear system;organizing (structure);self-organization;simulation;software release life cycle	Yuan Yao;Kailong Zhang;Xingshe Zhou	2011	2011 Seventh International Conference on Natural Computation	10.1109/ICNC.2011.6022188	control engineering;engineering;artificial intelligence;machine learning	Robotics	12.756499805691421	-24.50059596805007	133806
32ec4451a0b22f22403e5ba7d5beb8d23f54997c	active relational rule learning in a constrained confidence rated boosting framework		In this dissertation, I investigate the potential of boosting within the framework of relational rule learning. Boosting is a particularly robust and powerful technique to enhance the prediction accuracy of systems that learn from examples. Although boosting has been extensively studied in the last years for propositional learning systems, only little attention has been paid to boosting in relational learning. In this work, I identify the particular challenges brought about by boosting relational rule learners. I show that boosting can be accomplished successfully for relational rule learning, where success is defined in terms of prediction accuracy, learning time complexity and the interpretability of learning results. To this end, I propose C2RIB, an efficient, effective and usable boosted ILP learner which is based on a boosting framework and a relational rule learner, which together account for learning time complexity and understandability of learning results as the two specific challenges we are confronted with when boosting relational rule learners. A thorough empirical evaluation of C2RIB indicates that this particular boosted relational rule learner performs competitively with state-of-the-art ILP systems with respect to learning time, predictive accuracy, and interpretability of learning results. Furthermore, I investigate the potential of boosting for active relational feature selection. Feature selection, the search for a subset of most relevant features among the available ones, constitutes an important technique for systems that learn from examples to improve their efficiency and enhance the quality and interpretability of their results. Most feature selection methods in relational learning transform the given examples from a relational into a propositional representation in order to utilise a propositional feature selection algorithm. Moreover, existing approaches are passive in so far as they determine feature subsets to be used for learning prior to the actual learning process. In contrast, here I propose C2RIBD, a learning system that successfully embeds active feature selection into a boosted ILP learner, and selects relevant features on the basis of the current learning process without performing a change of representation. C2RIBD yields significant reductions of learning time complexity, while maintaining both the predictive accuracy and the intelligibility of the hypotheses that are learned.	boosting (machine learning);feature selection;intelligibility (philosophy);selection algorithm;time complexity	Susanne Hoche	2005				ML	17.12356160667657	-36.3097933907899	133943
061c05faf3d68a7bdade9d4debeab369e2f9746c	loss-sensitive generative adversarial networks on lipschitz densities		In this paper, we present the Lipschitz regularization theory and algorithms for a novel Loss-Sensitive Generative Adversarial Network (LS-GAN). Specifically, it trains a loss function to distinguish between real and fake samples by designated margins, while learning a generator alternately to produce realistic samples by minimizing their losses. The LS-GAN further regularizes its loss function with a Lipschitz regularity condition on the density of real data, yielding a regularized model that can better generalize to produce new data from a reasonable number of training examples than the classic GAN. We will further present a Generalized LS-GAN (GLS-GAN) and show it contains a large family of regularized GAN models, including both LS-GAN and Wasserstein GAN, as its special cases. Compared with the other GAN models, we will conduct experiments to show both LS-GAN and GLS-GAN exhibit competitive ability in generating new images in terms of the Minimum Reconstruction Error (MRE) assessed on a separate test set. We further extend the LS-GAN to a conditional form for supervised and semi-supervised learning problems, and demonstrate its outstanding performance on image classification tasks.	areal density (computer storage);cobham's thesis;data point;discriminative model;experiment;generative adversarial networks;least squares;loss function;network architecture;performance;sample complexity;semi-supervised learning;semiconductor industry;supervised learning;vanishing gradient problem	Guo-Jun Qi	2017	CoRR		mathematical optimization;combinatorics;discrete mathematics;machine learning;mathematics;statistics	ML	22.265570401867212	-32.33078020418718	134104
c1d506f78da4b72872e0999ae63140b72e58bbc8	noisy inference and oracles	noisy data;partial identification;inductive inference	A learner noisily infers a function or set, if every correct item is presented infinitely often while in addition some incorrect data (”noise”) is presented a finite number of times. It is shown that learning from a noisy informant is equal to finite learning with K-oracle from a usual informant. This result has several variants for learning from text and using different oracles. Furthermore, partial identification of all r.e. sets can cope also with noisy input.	oracle machine	Frank Stephan	1997	Theor. Comput. Sci.	10.1016/S0304-3975(97)00018-2	inductive reasoning;machine learning;pattern recognition;statistics	ECom	18.94869131068799	-33.692917346612326	134174
9fb6d673c69abfb91805e1aef671b72c562d27a3	a study on the performance improvement of the hierarchical neural network by the fitness selection			artificial neural network	Do-Hyeon Kim;Min-Kyeong Kang;Seong-Woo Kim;Eui-Young Cha	2002			machine learning;artificial neural network;performance improvement;computer science;artificial intelligence	NLP	12.935958916142562	-25.45345599055264	134359
e6fba22c6b0734a917b9cebf617c9d9d1fc517ed	improved self-organization with an alternative inhibition gradient in calmmap networks	competition;learning;aprendizaje;apprentissage;inhibition gradient;autoorganizacion;gradient inhibition;self organization;reseau neuronal;modular neural network;red neuronal;autoorganisation;competencia;neural network	Phaf, Den Dulk, Tijsseling & Lebert (2001) described a self-organizing variant of the CALM modular neural network model (Murre, Phaf, & Wolters, 1992), which has been coined CALMMap. The selforganization mechanism is driven by a specific inhibition gradient formula. The disadvantage of this formula is that it introduces new parameters and is not optimally adjusted to the size of a module. This research note provides an alternative for this inhibition gradient formula with the benefits that it performs autonomously. In other words, no extra parameters are introduced and the strength of inhibition adapts to the size of a module. Simulations are described to show the effectiveness of the alternative inhibition gradient function.	artificial neural network;computer simulation;gradient descent;list of astronomical catalogues;modular neural network;network model;organizing (structure);self-organization	Adriaan G. Tijsseling	2003	Connect. Sci.	10.1080/0954009031000105605	self-organization;competition;computer science;artificial intelligence;machine learning;artificial neural network;algorithm	ML	17.70858948695389	-24.10937978514723	134383
b7614da79cbd78565cd5c9630128460d42a26c1f	"""erratum: """"the uniqueness theorem for complex-valued neural networks with threshold parameters and the redundancy of the parameters"""""""			neural networks	Tohru Nitta	2009	Int. J. Neural Syst.	10.1142/S0129065709001902		ML	13.101711463245515	-27.283169349432896	134390
11a250a05eb73aedd6e1241786867d8373555655	an information-maximization approach to blind separation and blind deconvolution	learning algorithm;procesamiento informacion;blind deconvolution;maximization;statistical independence;algorithme apprentissage;time delay;higher order;desconvolucion;information transfer;transfer function;signal processing;principal component analysis;information processing;deconvolution;self organization;network architecture;reseau neuronal;traitement information;source separation;maximizacion;red neuronal;maximisation;neural network	"""We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in """"blind"""" signal processing."""	arabic numeral 0;blind deconvolution;blind signal separation;expectation–maximization algorithm;generalization (psychology);http 404;network architecture;nonlinear system;organizing (structure);principal component analysis;self-organization;signal processing;source separation;transfer function;visually impaired persons;mixture	Anthony J. Bell;Terrence J. Sejnowski	1995	Neural Computation	10.1162/neco.1995.7.6.1129	independence;self-organization;information transfer;network architecture;higher-order logic;information processing;computer science;deconvolution;machine learning;signal processing;mathematics;blind signal separation;blind deconvolution;transfer function;artificial neural network;statistics;principal component analysis	ML	19.67515328924495	-28.078867954334324	134394
ed6d7b577108821a28e7796c7ce019c79f08ada9	neural predictive hidden markov model	hidden markov model		hidden markov model;markov chain	Eiichi Tsuboka;Yoshihiro Takada;Hisashi Wakita	1990			artificial intelligence;markov property;pattern recognition;partially observable markov decision process;hidden markov model;hidden semi-markov model;maximum-entropy markov model;markov process;markov model;computer science;variable-order markov model	ML	21.895666664949818	-25.169381653415968	134398
b8bec0261cd678d84d05aab821587d35b7f7994b	experiences of modeling the activity of neuronal networks by the means of electronic digital computers	neuronal network			Dan Farcas	1966	Elektronische Informationsverarbeitung und Kybernetik		theoretical computer science;discrete mathematics;mathematics;biological neural network	HCI	12.366985701020742	-26.330403336610427	134465
44d9b0b509f1d2a9d663cbde0c83fef4258f8672	structure-based categorisation of bayesian network parameters		Bayesian networks typically require thousands of probability parameters for their specification, many of which are bound to be inaccurate. Knowledge of the direction of change in an output probability of a network occasioned by changes in one or more of its parameters, i.e. the qualitative effect of parameter changes, has been shown to be useful both for parameter tuning and in pre-processing for inference in credal networks. In this paper we identify classes of parameter for which the qualitative effect on a given output of interest can be identified based upon graphical considerations.	bayesian network;categorization;graphical user interface;preprocessor	Janneke H. Bolt;Silja Renooij	2017		10.1007/978-3-319-61581-3_8	computer science;machine learning;artificial intelligence;variable-order bayesian network;inference;bayesian network	AI	11.510117580987643	-35.75248173006636	134475
cfa61e4c44ce3e37995bb047fffa42b9741778a2	using mega-trend-diffusion and artificial samples in small data set learning for early flexible manufacturing system scheduling knowledge	gestion des connaissances;small sample;small data set;backpropagation neural network;atelier flexible;knowledge management;dynamical system;mega trend diffusion;systeme dynamique;machine learning;flexible manufacturing system;scheduling;backpropagation algorithm;algorithme retropropagation;sistema flexible produccion;pequena muestra;sistema dinamico;learning artificial intelligence;reseau neuronal;simulation model;gestion conocimiento;red neuronal;ordonnancement;petit echantillon;reglamento;neural network;algoritmo retropropagacion;apprentissage intelligence artificielle	Neural networks are widely utilized to extract management knowledge from acquired data, but having enough real data is not always possible. In the early stages of dynamic flexible manufacturing system (FMS) environments, only a litter data is obtained, and this means that the scheduling knowledge is often unreliable. The purpose of this research is to utilize data expansion techniques for an obtained small data set to improve the accuracy of machine learning for FMS scheduling. This research proposes a mega-trend-diffusion technique to estimate the domain range of a small data set and produce artificial samples for training the modified backpropagation neural network (BPNN). The tool used is the Pythia software. The results of the FMS simulation model indicate that learning accuracy can be significantly improved when the proposed method is applied to a very small data set.	scheduling (computing)	Der-Chiang Li;Chih-Sen Wu;Tung-I Tsai;Yao-San Lin	2007	Computers & OR	10.1016/j.cor.2005.05.019	simulation;test set;computer science;artificial intelligence;backpropagation;dynamical system;machine learning;simulation modeling;scheduling;artificial neural network	Robotics	10.42324203760198	-24.334574016999966	134532
ba0f9771f85249805137e2a9e3468ee05a4e9edb	quantile regression with multilayer perceptrons		We consider nonlinear quantile regression involving multilayer perceptrons (MLP). In this paper we investigate the asymptotic behavior of quantile regression in a general framework. First by allowing possibly non-identifiable regression models like MLP's with redundant hidden units, then by relaxing the conditions on the density of the noise. In this paper, we present an universal bound for the overfitting of such model under weak assumptions. The main application of this bound is to give a hint about determining the true architecture of the MLP quantile regression model. As an illustration, we use this theoretical result to propose and compare effective criteria to find the true architecture of such regression model.	common criteria;memory-level parallelism;multilayer perceptron;nonlinear system;overfitting	Joseph Rynkiewicz;Solohaja-Faniaha Dimby	2012			perceptron;overfitting;asymptotic analysis;architecture;regression analysis;econometrics;machine learning;artificial intelligence;nonlinear system;statistics;quantile regression;mathematics	ML	21.372029724794658	-33.0941408421714	134787
77faa4a15221c1c7deba0a385d3e832604d49648	coarse models for bird migrations using clustering and non-stationary markov chains			computer cluster;markov chain;stationary process	Nitin Jain;Bistra N. Dilkina	2015			machine learning;artificial intelligence;computer science;cluster analysis;markov chain	Logic	21.74528818950109	-25.226338469319103	134812
23a5010db85c779cf50eca53a2bdac067ceb96ef	build correlation awareness in negative correlation learning		This paper proposed to implement negative correlation learning (NCL) in optimizing the two different learning functions on the two separated subsets without overlapping. Because the two subsets could be randomly generated for each individual neural network (NN), they would be different for every pair of individual NNs in an neural network ensemble (NNE). When the two learning functions in NCL could be optimized separately, each individual NN could avoid the conflicts in learning by always having the unique learning direction on a given data sample. Therefore, each individual NN is clearly aware of its own learning direction on every training data. Such self-awareness is essential to create a set of cooperative NNs for an NNE. Experimental results show that the individual NNs by NCL with such separate learning could remain the difference, and have the stable performance even in the longer training process.	artificial neural network;nested context language;procedural generation;randomness;self-awareness	Yong Liu	2017	2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2017.8393287	artificial intelligence;artificial neural network;machine learning;training set;computer science;correlation	Robotics	15.031042152128766	-34.70476327622683	134852
a03fd7b6401c84e5882c8dad7b860ad2fe32a5dc	artificial intelligence and neural networks	artificial intelligence;neural network	International conference on advances in pattern recognition and digital techniques : proceedings of P.C.Mahalanobis birth centenary volume(1993).	artificial intelligence;artificial neural network;neural network software		2006		10.1007/11803089	nervous system network models;physical neural network;artificial intelligence system	AI	12.100068502028305	-26.824148068556255	134910
74c44f2444e3c695b2dbb02f6e8463a42cebb2e6	function approximation using generalized adalines	gradient descent method;adalines;learning algorithm;generic model;supervised learning;gradient descent methods;transfer functions;multiple generative components optimization;fonction base radiale;supervised learning adalines generative models mean field annealing perceptron postnonlinear projection potts encoding;algorithme apprentissage;fonction seuil;approximation fonction;function approximation transfer functions learning systems neural networks stochastic processes annealing encoding cost function design optimization computer science;red multinivel;learning methods;radial basis function;programacion mixta entera;generalized adalines;function approximation;mixed integer linear programming;integer programming;transfer function;funcion umbral;stochastic predictor oriented target generation;algorithms artificial intelligence information storage and retrieval neural networks computer pattern recognition automated systems theory;linear programming;potts encoding;k posterior independent normal variables;gradient methods;programmation partiellement en nombres entiers;linear program;mixed integer programming;postnonlinear projection;approximation methods;receptive field;threshold function;transfer functions function approximation gradient methods integer programming linear programming;multilayer network;generative models;apprentissage supervise;adaptive linear elements;reseau multicouche;perceptron;reseau neuronal;k binary values;funcion radial base;aprendizaje supervisado;algoritmo aprendizaje;learning strategies;data driven function approximation;red neuronal;mean field annealing;adaptive linear elements data driven function approximation generalized adalines neural organization k state transfer function k binary values k posterior independent normal variables stochastic predictor oriented target generation mixed integer linear programming mean field annealing gradient descent methods leave one out learning strategy multiple generative components optimization	This paper proposes neural organization of generalized adalines (gadalines) for data driven function approximation. By generalizing the threshold function of adalines, we achieve the K-state transfer function of gadalines which responds a unitary vector of K binary values to the projection of a predictor on a receptive field. A generative component that uses the K-state activation of a gadaline to trigger K posterior independent normal variables is employed to emulate stochastic predictor-oriented target generation. The fitness of a generative component to a set of paired data mathematically translates to a mixed integer and linear programming. Since consisting of continuous and discrete variables, the mathematical framework is resolved by a hybrid of the mean field annealing and gradient descent methods. Following the leave-one-out learning strategy, the obtained learning method is extended for optimizing multiple generative components. The learning result leads to parameters of a deterministic gadaline network for function approximation. Numerical simulations further test the proposed learning method with paired data oriented from a variety of target functions. The result shows that the proposed learning method outperforms the MLP and RBF learning methods for data driven function approximation	adaline;approximation;cartesian closed category;computation;dimensionality reduction;embedded system;embedding;epilepsy, generalized;gauss;generativecomponents;gradient descent;integer (number);interference (communication);kerrison predictor;knot (unit);linear programming;map;mathematics;mean field annealing;memory-level parallelism;multilayer perceptron;neural network simulation;nonlinear system;numerical analysis;numerical linear algebra;population parameter;projections and predictions;radial (radio);radial basis function network;sensor;simulated annealing;stochastic modelling (insurance);system identification;transfer function;vii	Jiann-Ming Wu;Zheng-Han Lin;Pei-Hsun Hsu	2006	IEEE Transactions on Neural Networks	10.1109/TNN.2006.873284	mathematical optimization;integer programming;computer science;linear programming;machine learning;mathematics;transfer function;algorithm;statistics	ML	18.213203106223478	-26.649588907574067	135181
42a86f70a20d4a35577b61ff9c788574aaf27009	stochastic gradient made stable: a manifold propagation approach for large-scale optimization	manifold propagation;convergence;standards;manifolds;semi stochastic gradient descent;convex functions;estimation;stochastic processes;optimization;large scale optimization	Stochastic gradient descent (SGD) holds as a classical method to build large scale machine learning models over big data. A stochastic gradient is typically calculated from a limited number of samples (known as mini-batch), which potentially incurs a high variance and causes the estimated parameters to bounce around the optimal solution. To improve the stability of stochastic gradient, recent years have witnessed the proposal of several semi-stochastic gradient descent algorithms, which distinguish themselves from standard SGD by incorporating global information into gradient computation. In this paper, we contribute a novel stratified semi-stochastic gradient descent (S3GD) algorithm to this nascent research area, accelerating the optimization of a large family of composite convex functions. Though theoretically converging faster, prior semi-stochastic algorithms are found to suffer from high iteration complexity, which makes them even slower than SGD in practice on many datasets. In our proposed S3GD, the semi-stochastic gradient is calculated based on efficient manifold propagation, which can be numerically accomplished by sparse matrix multiplications. This way S3GD is able to generate a highly-accurate estimate of the exact gradient from each mini-batch with largely-reduced computational complexity. Theoretic analysis reveals that the proposed S3GD elegantly balances the geometric algorithmic convergence rate against the space and time complexities during the optimization. The efficacy of S3GD is also experimentally corroborated on several large-scale benchmark datasets.	algorithm;benchmark (computing);big data;computation;computational complexity theory;convex function;experiment;iteration;machine learning;mathematical optimization;numerical analysis;rate of convergence;semiconductor industry;software propagation;sparse matrix;stochastic gradient descent	Yadong Mu;Wei Liu;Wei Fan	2017	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2016.2604302	gradient descent;convex function;stochastic process;mathematical optimization;estimation;combinatorics;convergence;manifold;gradient method;backpropagation;neighbourhood components analysis;machine learning;mathematics;stochastic gradient descent;proximal gradient methods;conjugate gradient method;nonlinear conjugate gradient method;statistics	ML	24.388287710038636	-33.91964416719567	135315
6c4785ea99d9a235090b129cb0f0754c1def1bb7	generalized ambiguity decompositions for classification with applications in active learning and unsupervised ensemble pruning		Error decomposition analysis is a key problem for ensemble learning. Two commonly used error decomposition schemes, the classic Ambiguity Decomposition and Bias-VarianceCovariance decomposition, are only suitable for regression tasks with square loss. We generalized the classic Ambiguity Decomposition from regression problems with square loss to classification problems with any loss functions that are twice differentiable, including the logistic loss in Logistic Regression, the exponential loss in Boosting methods, and the 01 loss in many other classification tasks. We further proved several important properties of the Ambiguity term, armed with which the Ambiguity terms of logistic loss, exponential loss and 0-1 loss can be explicitly computed and optimized. We further discussed the relationship between margin theory, “good” and “bad” diversity theory and our theoretical results, and provided some new insights for ensemble learning. We demonstrated the applications of our theoretical results in active learning and unsupervised ensemble pruning, and the experimental results confirmed the effectiveness of our methods. Introduction Previous work As a sub-field of machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone (Rokach 2010). To achieve good performance, the base learners should be both accurate and diverse. It is widely accepted that the generalization error of an ensemble depends on a term related to diversity (Zhou 2012). Thus, error decomposition analysis has long been considered as a key problem in ensemble learning. Two commonly used error decomposition schemes are the classic Ambiguity Decomposition and Bias-Variance-Covariance decomposition. Both the two decompositions are only suitable for regression tasks with square loss. In this work, we generalized the classic Ambiguity Decomposition to classification tasks with a variety of loss functions, including the logistic loss, exponential loss, 0-1 loss, etc. Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. The classic Ambiguity Decomposition revealed the relationship between the loss of base learners and that of the ensemble for ensemble regression (Krogh and Vedelsby 1995). Its form for a single sample (Brown et al. 2005) is	active learning (machine learning);algorithm;artificial intelligence;boosting (machine learning);ensemble learning;generalization error;logistic regression;loss function;loss functions for classification;machine learning;mathematical optimization;qr decomposition;time complexity;unsupervised learning;word lists by frequency	Zhengshen Jiang;Hongzhi Liu;Bin Fu;Zhonghai Wu	2017				AI	18.617346493009922	-37.07762951517964	135412
399ef3cf8d291eb19695b81af5edb6ed7120c1a2	roles of back-propagating action potential in synaptic modifications	back propagation;action potential		action potential;synaptic package manager	Tatsuo Kitajima;Ken-ichi Hara	1998			artificial intelligence;machine learning;artificial neural network;backpropagation;computer science	ML	12.819526244990211	-27.443552340482853	135578
33d3ea07ab6a0843e42f315a32aec9d474414b81	on robustness properties of convex risk minimization methods for pattern recognition	sensitivity curve;influence function;kernel logistic regression;adaboost loss function;statistical learning;robustness;total variation;support vector machine	The paper brings together methods from two disciplines: machine learning theory and robust statistics. We argue that robustness is an important aspect and we show that many existing machine learning methods based on the convex risk minimization principle have − besides other good properties − also the advantage of being robust. Robustness properties of machine learning methods based on convex risk minimization are investigated for the problem of pattern recognition. Assumptions are given for the existence of the influence function of the classifiers and for bounds of the influence function. Kernel logistic regression, support vector machines, least squares and the AdaBoost loss function are treated as special cases. Some results on the robustness of such methods are also obtained for the sensitivity curve and the maxbias, which are two other robustness criteria. A sensitivity analysis of the support vector machine is given.	adaboost;least squares;logistic regression;loss function;machine learning;pattern recognition;robustness (computer science);support vector machine	Andreas Christmann;Ingo Steinwart	2004	Journal of Machine Learning Research		support vector machine;least squares support vector machine;kernel method;feature vector;radial basis function kernel;empirical risk minimization;online machine learning;machine learning;pattern recognition;mathematics;stochastic gradient descent;relevance vector machine;polynomial kernel;structured support vector machine;statistics;loss function	ML	21.079347063965642	-35.703401509111465	135719
4d08fa35932a950f188a14303d06ff25549f849b	efficient bregman range search		We develop an algorithm for efficient range search when the notion of dissimilarity is given by a Bregman divergence. The range search task is to return all points in a potentially large database that are within some specified distance of a query. It arises in many learning algorithms such as locally-weighted regression, kernel density estimation, neighborhood graph-based algorithms, and in tasks like outlier detection and information retrieval. In metric spaces, efficient range search-like algorithms based on spatial data structures have been deployed on a variety of statistical tasks. Here we describe an algorithm for range search for an arbitrary Bregman divergence. This broad class of dissimilarity measures includes the relative entropy, Mahalanobis distance, Itakura-Saito divergence, and a variety of matrix divergences. Metric methods cannot be directly applied since Bregman divergences do not in general satisfy the triangle inequality. We derive geometric properties of Bregman divergences that yield an efficient algorithm for range search based on a recently proposed space decomposition for Bregman divergences.	algorithm;anomaly detection;bregman divergence;data structure;information retrieval;itakura–saito distance;kernel density estimation;kullback–leibler divergence;machine learning;phylogenetic tree;proximity search (text);range searching;social inequality	Lawrence Cayton	2009			mathematical optimization;pattern recognition;mathematics;statistics;bregman divergence	ML	24.59103740109581	-37.669680092766804	135890
338c8d2200e86b04ec82b402ac21eb9df139b9c1	self-organization hybrid evolution learning algorithm for recurrent wavelet-based neuro-fuzzy identifier design	group based symbiotic evolution;identification;control;article;fuzzy model;fp growth	In this paper, a recurrent wavelet-based neuro-fuzzy identifier RWNFI with a self-organization hybrid evolution learning algorithm SOHELA is proposed for solving various identification problems. In the proposed SOHELA, the group-based symbiotic evolution GSE is adopted such that each group in the GSE represents a collection of only one fuzzy rule. The proposed SOHELA consists of structure learning and parameter learning. In structure learning, the proposed SOHELA uses the self-organization algorithm SOA to determine a suitable rule number in the RWNFI. In parameter learning, the proposed SOHELA uses the data mining-based selection method DMSM and the data mining-based crossover method DMCM to determine groups and parent groups using the data mining method called the frequent pattern growth FP-Growth method. Based on identification simulations, the excellent performance of the proposed SOHELA compares with other various existing models.	algorithm;identifier;neuro-fuzzy;recurrent neural network;self-organization;wavelet	Yung-Chi Hsu;Sheng-Fuu Lin	2013	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-2012-0540	identification;computer science;artificial intelligence;machine learning;data mining;scientific control	Robotics	11.026161493711902	-28.5047096818804	136006
3157ed1fbad482520ca87045b308446d8adbdedb	communication-efficient learning of deep networks from decentralized data		Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10–100× as compared to synchronized stochastic gradient descent.	algorithm;cynthia dwork;data center;deep learning;differential privacy;experiment;iterative and incremental development;iterative method;language model;long short-term memory;mobile device;multilayer perceptron;privacy;realms of the haunting;secure multi-party computation;speech recognition;stochastic gradient descent;test data;unbalanced circuit;user experience	H. Brendan McMahan;Eider Moore;Daniel Ramage;Seth Hampson;Blaise Agüera y Arcas	2017			simulation;computer science;machine learning;data mining;statistics	ML	22.999917369035277	-35.23083867436355	136188
cf53b4c67bff051efd65f91943be9d6c5897bf69	a new method of multilayer perceptron encoding	genetic operator;search space;multilayer perceptron;genetics;network topology;evolutionary process;neural network	One of the central issues in neural network research is how to find an optimal MultiLayer Perceptron architecture. The number of neurons, their organization in layers, as well as their connection scheme have a considerable influence on network learning, and on the capacity for generalization [7]. A solution to find out these parameters is needed: The neuro-evolution ([1,2,4,5]). The novelty is to emphasize the network performance aspects, and the network simplification achieved by reducing the network topology. All these genetic manipulations on the network architecture should not decrease the neural network performance.	artificial neural network;codi;multilayer perceptron;network architecture;network performance;network topology;text simplification	Emmanuel Blindauer;Jerzy J. Korczak	2003		10.1007/3-540-45105-6_42	probabilistic neural network;computer science;artificial intelligence;theoretical computer science;perceptron;genetic operator;machine learning;multilayer perceptron;artificial neural network;network topology	ML	15.453056307595311	-24.003954472677425	136210
8c8edcaa7e166d5daaa2d815661404ca17bda322	declarative modeling for machine learning and data mining	data mining;declarative modeling;constraint programming;constraint satisfaction;optimization problem;itemset mining;probabilistic programming;particular solution;data mining problem;constraint programming methodology;data mining technique	Despite the popularity of machine learning and data mining today, it remains challenging to develop applications and software that incorporates machine learning or data mining techniques. This is because machine learning and data mining have focussed on developing high-performance algorithms for solving particular tasks rather than on developing general principles and techniques. I propose to alleviate these problems by applying the constraint programming methodology to machine learning and data mining and to specify machine learning and data mining problems as constraint satisfaction and optimization problems. What is essential is that the user be provided with a way to declaratively specify what the machine learning or data mining problem is rather than having to outline how that solution needs to be computed. This corresponds to a model + solver-based approach to machine learning and data mining, in which the user specifies the problem in a high level modeling language and the system automatically transforms such models into a format that can be used by a solver to efficiently generate a solution. This should be much easier for the user than having to implement or adapt an algorithm that computes a particular solution to a specific problem. Throughout the talk, I shall use illustrations from our work on constraint programming for itemset mining and probabilistic programming.	data mining;declarative programming;machine learning	Luc De Raedt	2012		10.1007/978-3-642-33460-3_2	semi-supervised learning;multi-task learning;instance-based learning;text mining;error-driven learning;algorithmic learning theory;computer science;artificial intelligence;data science;online machine learning;machine learning;data mining;data pre-processing;data stream mining;stability;computational learning theory;active learning;hyper-heuristic	ML	14.291988804262635	-36.69410678793261	136371
d7382818bd48087fa7a6bab2c831c6a40a776898	building adaptive basis functions with a continuous self-organizingmap	modelizacion;eficacia sistema;continuous function;interpolation;learning algorithm;feedforward;neural networks;implementation;continuous function approximation;estudio comparativo;interpolacion;performance systeme;fonction continue;algorithme apprentissage;boucle anticipation;system performance;competitive learning;experimental result;modelisation;etude comparative;ejecucion;ciclo anticipacion;function approximation;funcion continua;basis functions;comparative study;self organizing map;resultado experimental;autoorganizacion;self organization;self organized map;basic functions;technical report;reseau neuronal;resultat experimental;algoritmo aprendizaje;modeling;red neuronal;autoorganisation;on line learning;neural network	This paper introduces CSOM, a continuous version of the Self-Organizing Map(SOM). The CSOM network generates maps similar to those created with theoriginal SOM algorithm but, due to the continuous nature of the mapping,CSOM outperforms the SOM on function approximation tasks. CSOM integratesself-organization and smooth prediction into a single process. This is adeparture from previous work that required two training phases, one toself-organize a map using the SOM algorithm, and another to learn a smoothapproximation of a function. System performance is illustrated with threeexamples.	algorithm;approximation;basis function;map	Marcos M. Campos;Gail A. Carpenter	2000	Neural Processing Letters	10.1023/A:1009622004201	interpolation;computer science;artificial intelligence;machine learning;mathematics;artificial neural network;algorithm	ML	11.1356949655043	-29.725267194659867	136541
4f432125069a3dd6c6a39169b0454859e82f27b4	application of variable selection techniques to a modified sais for generating practical scorecards	scorecards;simple artificial intelligence system;general practice;credit scoring;airs;financial risk management;stepwise regression;logistic regression;variable selection;artificial immune recognition system;gini coefficient;performance measures;sais	Selecting better predictive variables is fundamental for scorecards to perform well. This study makes use of a large credit scoring dataset and investigates the application of several variable selection techniques for scorecard development. The scorecards are developed using a statistical technique (logistic regression) and two AI methods (SAIS and AIRS). SAIS, which we previously developed can predict class outcomes accurately and has good classification accuracy which is the percentage of correctly classified data. However, since an unbalanced dataset was obtained, the Gini coefficient which is the main performance measure used in industry and which is insensitive to changes in class distribution needs be used instead. SAIS is modified to generate a Gini coefficient and an investigation of its suitability for practical scorecard development is made. We found that further modifications are needed in order for it to perform as well as logistic regression. Moreover, among the different variable selection techniques used, stepwise regression was found to perform best.	algorithm;coefficient;feature selection;logistic regression;statistical model;stepwise regression;unbalanced circuit	Kevin Leung;France Cheong;Christopher Cheong;Sean O'Farrell;Robert Tissington	2009	IJADS	10.1504/IJADS.2009.027930	econometrics;economics;computer science;machine learning;stepwise regression;data mining;logistic regression;statistics;financial risk management	ML	10.963550990135545	-37.797797724243885	136611
29b5b0fa838c76935b7b719c838bb2d5648c1551	partition-based and sharp uniform error bounds	probability;validation error bounds probabilistic bounds in sample data probability out of sample data vapnik chervonenkis bounds machine learning;sampling error;indexing terms;machine learning;error statistics;error bound;learning artificial intelligence;probability learning artificial intelligence error statistics;error analysis virtual colonoscopy machine learning upper bound concrete computational intelligence x ray imaging injuries computer science;learning theory;vapnik chervonenkis	This paper develops probabilistic bounds on out-of-sample error rates for several classifiers using a single set of in-sample data. The bounds are based on probabilities over partitions of the union of in-sample and out-of-sample data into in-sample and out-of-sample data sets. The bounds apply when in-sample and out-of-sample data are drawn from the same distribution. Partition-based bounds are stronger than Vapnik-Chervonenkis (VC) bounds, but they require more computation.	alexey chervonenkis;computation;probability;vapnik–chervonenkis theory	Eric Bax	1999	IEEE transactions on neural networks	10.1109/72.809077	sampling error;index term;computer science;theoretical computer science;probability of error;machine learning;learning theory;pattern recognition;probability;mathematics;statistics;generalization error	ML	20.643488226381606	-31.658725183366343	136709
136707fbff0ee633a84187f57126101b8641ce13	investigating generalization in parallel evolutionary artificial neural networks	artificial neural networks;parallelization;evolutionary algorithms;generalization;artificial neural network	In this paper we study how the parallelization of a learning algorithm affects the generalization ability of Evolutionary Artificial Neural Networks (EANNs). The newly proposed evolutionary algorithm (EA), which improves chromosomes according to characteristics of their genotype and phenotype, was used for evolving ANNs. The EA has been parallelized by two schemes: the migration approach, which periodically exchanges the best individuals between all parallel populations, and the recently developed migration-strangers strategy, which extends search space during evolution by the replacement of worst chromosomes in parallel populations with the randomly generated new ones, called strangers. The experiments have been provided on the Mackey-Glass chaotic time series problem in order to determine the best and the average prediction errors on training and testing data for small and large ANNs, evolved by both parallel evolutionary algorithms (PEAs). The results showed that PEAs enable to produce compact ANNs with high precision of prediction, which have insignificant distinctions between training and testing errors.	artificial neural network	Kristina Davoian;Wolfram-Manfred Lippe	2007			computer science;artificial intelligence;theoretical computer science;machine learning;evolutionary acquisition of neural topologies	ML	14.350498430668795	-24.024537935008915	136805
d94b7cedb30cab4fd528053997ab3a68a3390938	brave new modeling: cellular automata and artificial neural networks for mastering complexity in economics	cellular automata;artificial neural network		artificial neural network;automata theory;bus mastering;cellular automaton	Janette Aschenwald;Stefan Fink;Gottfried Tappeiner	2001	Complexity	10.1002/cplx.10011	cellular neural network;computer science;artificial intelligence;machine learning;mathematics;artificial neural network	ML	12.129225585870865	-26.24654949270388	136845
245fb718503f92fffdca3c4e9a0fc3d4d21fa2b2	sparse learning with stochastic composite optimization	convergence;standards;training;sparse learning;stochastic optimization;stochastic processes;linear programming;optimization;stochastic composite optimization sparse learning stochastic optimization;stochastic composite optimization;optimization convergence algorithm design and analysis standards linear programming stochastic processes training;algorithm design and analysis;sparse learning stochastic optimization stochastic composite optimization	"""In this paper, we study Stochastic Composite Optimization (SCO) for sparse learning that aims to learn a sparse solution from a composite function. Most of the recent SCO algorithms have already reached the optimal expected convergence rate <inline-formula><tex-math notation=""""LaTeX"""">$\mathcal {O}(1/\lambda T)$</tex-math><alternatives> <inline-graphic xlink:href=""""zhang-ieq1-2578323.gif""""/></alternatives></inline-formula>, but they often fail to deliver sparse solutions at the end either due to the limited sparsity regularization during stochastic optimization (SO) or due to the limitation in online-to-batch conversion. Even when the objective function is strongly convex, their high probability bounds can only attain <inline-formula><tex-math notation=""""LaTeX"""">$\mathcal {O}(\sqrt{\log (1/\delta)/T})$ </tex-math><alternatives><inline-graphic xlink:href=""""zhang-ieq2-2578323.gif""""/></alternatives></inline-formula> with <inline-formula><tex-math notation=""""LaTeX"""">$\delta$</tex-math><alternatives> <inline-graphic xlink:href=""""zhang-ieq3-2578323.gif""""/></alternatives></inline-formula> is the failure probability, which is much worse than the expected convergence rate. To address these limitations, we propose a simple yet effective two-phase Stochastic Composite Optimization scheme by adding a novel powerful sparse online-to-batch conversion to the general Stochastic Optimization algorithms. We further develop three concrete algorithms, OptimalSL, LastSL and AverageSL, directly under our scheme to prove the effectiveness of the proposed scheme. Both the theoretical analysis and the experiment results show that our methods can really outperform the existing methods at the ability of sparse learning and at the meantime we can improve the high probability bound to approximately <inline-formula> <tex-math notation=""""LaTeX"""">$\mathcal {O}(\log (\log (T)/\delta)/\lambda T)$</tex-math><alternatives> <inline-graphic xlink:href=""""zhang-ieq4-2578323.gif""""/></alternatives></inline-formula>."""	algorithm;batch processing;code for the japanese graphic character set for information interchange (jis x 0208-1990),;concise resin;convergence (action);equation:equ:pt:gestational age estimation formula:nar;hearing loss, high-frequency;loss function;mathematical optimization;optimization problem;program optimization;rate of convergence;solutions;sparse matrix;spindle cell oncocytoma of the adenohypophysis;stochastic optimization;two-phase locking;xlink	Weizhong Zhang;Lijun Zhang;Zhongming Jin;Rong Jin;Deng Cai;Xuelong Li;Ronghua Liang;Xiaofei He	2014	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2016.2578323	stochastic programming;algorithm design;mathematical optimization;convergence;computer science;linear programming;theoretical computer science;stochastic optimization;machine learning;sparse approximation;mathematics;statistics	ML	23.778140295766704	-34.24919531674144	136869
806708420256f7dcb4cc4341f2cb8a385b83888c	estimation of prediction reliability in regression based on a transductive approach.				Zoran Bosnic;Igor Kononenko	2005			machine learning;pattern recognition	ML	10.650852579378036	-26.115367152839674	136972
87fe0b1f86da3ffaba65df924226ce83dfce9371	fast distributed asynchronous sgd with variance reduction		With the recent proliferation of large-scale learning problems, there have been a lot of interest on distributed machine learning algorithms, particularly those that are based on stochastic gradient descent (SGD) and its variants. Howe v r, existing algorithms either suffer from slow convergence du e to the inherent variance of stochastic gradients, or have a fas t linear convergence rate but at the expense of poorer solutio n quality. In this paper, we combine their merits together by proposing a distributed asynchronous SGD-based algorithmwith variance reduction. A constant learning rate can be used, an d it is also guaranteed to converge linearly to the optimal solut ion. Experiments on the Google Cloud Computing Platform demonstrate that the proposed algorithm outperforms state-of-t he-art distributed asynchronous algorithms in terms of both wall clock time and solution quality.	algorithm;cloud computing;converge;feedback arc set;machine learning;rate of convergence;stochastic gradient descent;variance reduction	Ruiliang Zhang;Shuai Zheng;James T. Kwok	2015	CoRR		real-time computing;computer science;machine learning;distributed computing	AI	24.19022109612275	-34.22933743116834	136987
00a0e3206a4f1fba87c384ef31df3be42727308d	function approximation capability of a novel fuzzy flip-flop based neural network	multilayer perceptrons flip flops function approximation fuzzy set theory;multilayer perceptrons;training;flip flops;multilayer perceptron;fuzzy set theory;function approximation capability;artificial neural networks;function approximation;neurons;multiple variable function;function approximation fuzzy neural networks flip flops neural networks;multiple variable function function approximation capability fuzzy flip flop based neural network multilayer perceptron neural network;fuzzy neural networks;fuzzy flip flop based neural network;flip flop;multilayer perceptron neural network;neural network	The function approximation capability of various connectionist systems has been one of the most interesting problems. A method for constructing Multilayer Perceptron Neural Networks (MLP NN) with the aid of fuzzy operations based flip-flops able to approximate single and multiple variable functions is proposed. This paper introduces the concept of fuzzy flip-flop based neural network, particularly by deploying three types of fuzzy flip-flops as neurons. A comparative study of feedbacked fuzzy J-K and two kinds of fuzzy D flip-flops used as neurons, based on fuzzy algebraic, Yager, Dombi, Hamacher and Frank operations is given. Simulation results are presented for several test functions.	approximation algorithm;artificial neural network;connectionism;distribution (mathematics);flops;flip-flop (electronics);memory-level parallelism;multilayer perceptron;simulation	Rita Lovassy;László T. Kóczy;László Gál	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178849	defuzzification;adaptive neuro fuzzy inference system;function approximation;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;fuzzy set;fuzzy associative matrix;multilayer perceptron;fuzzy set operations;artificial neural network	Robotics	14.090186564987624	-27.326942348604224	136991
44ccc02c645bbef710c605bc74f5ebbc09c87ee6	a supervised multi-spike learning algorithm for recurrent spiking neural networks		The recurrent spiking neural networks include complex structures and implicit nonlinear mechanisms, the formulation of efficient supervised learning algorithm is difficult and remains an important problem in the research area. This paper proposes a new supervised multi-spike learning algorithm for recurrent spiking neural networks, which can implement the complex spatiotemporal pattern learning of spike trains. Using information encoded in precisely timed spike trains and their inner product operators, the error function is firstly constructed. Furthermore, the proposed algorithm defines the learning rules of synaptic weights based on inner product of spike trains. The algorithm is successfully applied to learn spike train patterns, and the high learning accuracy and efficiency are shown by the experimental results. In addition, the network structure parameters are analyzed, such as the neuron number and connectivity degree in the recurrent layer of spiking neural networks.	algorithm;algorithmic learning theory;artificial neural network;neural network software;spiking neural network;supervised learning	Xianghong Lin;Guoyong Shi	2018		10.1007/978-3-030-01418-6_22	pattern recognition;operator (computer programming);supervised learning;spiking neural network;train;artificial intelligence;spatiotemporal pattern;error function;nonlinear system;algorithm;spike train;computer science	AI	14.977596511015602	-27.980523453723976	137016
296563b5e98fedf430c3381c75ae692f371ba28d	a structure-aware online learning algorithm for markov decision processes		To overcome the curse of dimensionality and curse of modeling in Dynamic Programming (DP) methods for solving classical Markov Decision Process (MDP) problems, Reinforcement Learning (RL) algorithms are popular. In this paper, we consider an infinite-horizon average reward MDP problem and prove the optimality of the threshold policy under certain conditions. Traditional RL techniques do not exploit the threshold nature of optimal policy while learning. In this paper, we propose a new RL algorithm which utilizes the known threshold structure of the optimal policy while learning by reducing the feasible policy space. We establish that the proposed algorithm converges to the optimal policy. It provides a significant improvement in convergence speed and computational and storage complexity over traditional RL algorithms. The proposed technique can be applied to a wide variety of optimization problems that include energy efficient data transmission and management of queues. We exhibit the improvement in convergence speed of the proposed algorithm over other RL algorithms through simulations.	algorithm;algorithmic learning theory;curse of dimensionality;dynamic programming;markov chain;markov decision process;mathematical optimization;optimization problem;reinforcement learning;simulation	Arghyadip Roy;Vivek S. Borkar;Abhay Karandikar;Prasanna Chaporkar	2018	CoRR		mathematical optimization;computer science;reinforcement learning;dynamic programming;efficient energy use;algorithm;markov decision process;curse of dimensionality;stochastic approximation;optimization problem;convergence (routing)	ML	23.412745349470736	-32.85989264611277	137146
6280639ba5a8cff9092a9675661883a243cd68a8	the adaptive complexity of maximizing a submodular function		In this paper we study the adaptive complexity of submodular optimization. Informally, the adaptive complexity of a problem is the minimal number of sequential rounds required to achieve a constant factor approximation when polynomially-many queries can be executed in parallel at each round. Adaptivity is a fundamental concept that is heavily studied in computer science, largely due to the need for parallelizing computation. Somewhat surprisingly, very little is known about adaptivity in submodular optimization. For the canonical problem of maximizing a monotone submodular function under a cardinality constraint, to the best of our knowledge, all that is known to date is that the adaptive complexity is between 1 and Ω( n ). Our main result in this paper is a tight characterization showing that the adaptive complexity of maximizing a monotone submodular function under a cardinality constraint is Θ( log n ): - We describe an algorithm which requires O ( log n ) sequential rounds and achieves an approximation that is arbitrarily close to 1/3; - We show that no algorithm can achieve an approximation better than O (1 / log n ) with fewer than O ( log n / log log n ) rounds. Thus, when allowing for parallelization, our algorithm achieves a constant factor approximation exponentially faster than any known existing algorithm for submodular maximization. Importantly, the approximation algorithm is achieved via adaptive sampling and complements a recent line of work on optimization of functions learned from data. In many cases we do not know the functions we optimize and learn them from labeled samples. Recent results show that no algorithm can obtain a constant factor approximation guarantee using polynomially-many labeled samples as in the PAC and PMAC models, drawn from any distribution. Since learning with non-adaptive samples over any distribution results in a sharp impossibility, we consider learning with adaptive samples where the learner obtains poly ( n ) samples drawn from a distribution of her choice in every round. Our result implies that in the realizable case, where there is a true underlying function generating the data, Θ( log n ) batches of adaptive samples are necessary and sufficient to approximately “learn to optimize” a monotone submodular function under a cardinality constraint.	adaptive sampling;approximation algorithm;cardinality (data modeling);computation;computer science;expectation–maximization algorithm;mathematical optimization;pmac (cryptography);parallel computing;sampling (signal processing);submodular set function;monotone	Eric Balkanski;Yaron Singer	2018		10.1145/3188745.3188752	cardinality;monotone polygon;submodular set function;discrete mathematics;adaptive sampling;exponential growth;approximation algorithm;binary logarithm;parallel algorithm;computer science	Theory	20.663045256537014	-32.73642016711017	137206
17ba2199eea4fae42dcb86f7060e090ace7540b2	multifeedback-layer neural network	processing element;modelizacion;levenberg marquardt;neural networks neurofeedback recurrent neural networks neurons output feedback delay backpropagation algorithms chaos nonlinear dynamical systems system identification;mise a jour;nonlinear dynamic system identification multifeedback layer neural network recurrent neural network nonlinear processing backpropagation through time algorithm chaotic time series prediction;feedforward;intervalo confianza;activation function;chaos;multilayer perceptrons;algorithms artificial intelligence feedback information storage and retrieval neural networks computer pattern recognition automated;funcion actividad;time series backpropagation chaos multilayer perceptrons nonlinear systems recurrent neural nets;caos;structure sandwich;chaotic time series;analyse temporelle;time series;backpropagation;boucle anticipation;analisis temporal;time analysis;dynamical system;recurrence;actualizacion;identificacion sistema;modelisation;systeme dynamique;sandwich structure;retropropagation;confidence interval;ciclo anticipacion;trust region;nonlinear systems;recurrent network;system identification;adjoint model;fonction activation;weighted sums;recurrencia;backpropagation algorithm;identification;intervalle confiance;retard;serie temporelle;serie temporal;recurrent neural network rnn adjoint model backpropagation through time bptt identification levenberg marquardt lm prediction;algorithme retropropagation;backpropagation through time bptt;reseau neuronal recurrent;recurrent neural nets;recurrent neural network;information system;levenberg marquardt lm;sistema dinamico;reseau neuronal;estructura sandwich;retraso;modeling;retropropagacion;prediction;red neuronal;systeme information;identification systeme;nonlinear dynamic system;updating;neural network;recurrent neural network rnn;sistema informacion;algoritmo retropropagacion	The architecture and training procedure of a novel recurrent neural network (RNN), referred to as the multifeedback-layer neural network (MFLNN), is described in this paper. The main difference of the proposed network compared to the available RNNs is that the temporal relations are provided by means of neurons arranged in three feedback layers, not by simple feedback elements, in order to enrich the representation capabilities of the recurrent networks. The feedback layers provide local and global recurrences via nonlinear processing elements. In these feedback layers, weighted sums of the delayed outputs of the hidden and of the output layers are passed through certain activation functions and applied to the feedforward neurons via adjustable weights. Both online and offline training procedures based on the backpropagation through time (BPTT) algorithm are developed. The adjoint model of the MFLNN is built to compute the derivatives with respect to the MFLNN weights which are then used in the training procedures. The Levenberg-Marquardt (LM) method with a trust region approach is used to update the MFLNN weights. The performance of the MFLNN is demonstrated by applying to several illustrative temporal problems including chaotic time series prediction and nonlinear dynamic system identification, and it performed better than several networks available in the literature	activation function;artificial neural network;backpropagation through time;biological neural networks;cardiomyoplasty;dynamical system;feed forward (control);feedback;feedforward neural network;levenberg–marquardt algorithm;mycobacterium phage marquardt;nonlinear system;online and offline;random neural network;recurrence (disease attribute);recurrence relation;recurrent neural network;system identification;time series;trust region;weight;anatomical layer	Aydogan Savran	2007	IEEE Transactions on Neural Networks	10.1109/TNN.2006.885439	nonlinear system;computer science;artificial intelligence;backpropagation;machine learning;echo state network;artificial neural network;algorithm	ML	15.288674692193306	-27.56383127139246	137226
0a314f32dadc9d46a376d66f5ca89773d1e67937	asymptotic level density of the elastic net self-organizing feature map	kohonen self organizing map;approximation asymptotique;densite probabilite;loi puissance;self organizing maps;sensory processing;probability density;ley poder;numerical method;carte autoorganisatrice;genetics;densidad probabilidad;elastic net;metodo numerico;self organized feature map;reseau elastique;lateral inhibition;self organization;kohonen map;asymptotic approximation;power law;theorie information;topology preservation;disordered system;methode numerique;information theory;aproximacion asintotica;neural network;teoria informacion	Whileas the Kohonen Self Organizing Map shows an asymptotic level density following a power law with a magnification exponent 2/3, it would be desired to have an exponent 1 in order to provide optimal mapping in the sense of information theory. In this paper, we study analytically and numerically the magnification behaviour of the Elastic Net algorithm as a model for self-organizing feature maps. In contrast to the Kohonen map the Elastic Net shows no power law, but for onedimensional maps nevertheless the density follows an universal magnification law, i.e. depends on the local stimulus density only and is independent on position and decouples from the stimulus density at other positions. Self Organizing Feature Maps map an input space, such as the retina or skin receptor fields, into a neural layer by feedforward structures with lateral inhibition. Biological maps show as defining properties topology preservation, error tolerance, plasticity (the ability of adaptation to changes in input space), and self-organized formation by a local process, since the global structure cannot be coded genetically. The self-organizing feature map algorithm proposed by Kohonen [1] has become a successful model for topology preserving primary sensory processing in the cortex [2], and an useful tool in technical applications [3]. The Kohonen algorithm for Self Organizing Feature Maps is defined as follows: Every stimulus v of an euclidian input space V is mapped to the neuron with the position s in the neural layer R with the highest neural activity, given by the condition |ws − v| = minr∈R |wr − v| (1) where |.| denotes the euclidian distance in input space. In the Kohonen model the learning rule for each synaptic weight vector wr is given by w new r = w r + η · grs · (v − w r ) (2) with grs as a gaussian function of euclidian distance |r − s| in the neural layer. The function grs describes the topology in the neural layer. The parameter η determines the speed of learning and can be adjusted during the learning process. Topology preservation is enforced by the common update of all weight vectors whose neuron r is adjacent to the center of excitation s.	algorithm;asymptote;elastic net regularization;error-tolerant design;euclidean distance;feedforward neural network;information theory;lateral thinking;learning rule;neuron;numerical analysis;organizing (structure);self-organization;self-organizing map;synaptic package manager;synaptic weight	Jens Christian Claussen;Heinz G. Schuster	2002		10.1007/3-540-46084-5_152	self-organizing map;information theory;computer science;artificial intelligence;machine learning;calculus;mathematics;artificial neural network;statistics	ML	19.456270033847108	-27.768152504348354	137390
b8b99664fa321ae33f647c8e50517161e3dbdc72	a normalised real time recurrent learning algorithm	learning rate;learning algorithm;convergence;non linear filtering;metodo recurrencia;recurrence method;activation function;adaptive filtering;filtrado adaptable;real time;filtrado no lineal;intelligence artificielle;algorithme apprentissage;convergencia;degeneration;computational complexity;adaptive learning rate;temps reel;tiempo real;artificial intelligence;filtrage adaptatif;inteligencia artificial;recurrent neural networks;recurrent neural network;normalised least mean square;reseau neuronal;neuronal network;algoritmo aprendizaje;real time recurrent learning;adaptive filter;red neuronal;methode recurrence;filtrage non lineaire;nonlinear adaptive filtering;neural network	"""A real time recurrent learning (RTRL) algorithm with an adaptive-learning rate for nonlinear adaptive """"lters realised as fully connected recurrent neural networks (RNNs) is derived. The algorithm is obtained by minimising the instantaneous squared error at the output neuron for every time instant while the network is running. The algorithm normalises the learning rate with the L 2 norm of the external input vector and a measure of the gradients at the neurons within the network, and is hence referred to as the normalised RTRL (NRTRL) algorithm. Indeed, the algorithm degenerates into the normalised least mean square (NLMS) algorithm for a linear-single-neuron network. For a neuron with a contractive nonlinear activation function, the algorithm is shown to impose additional stability and faster convergence to the RTRL, without signi""""cant demands on additional computational complexity. The bounds imposed on the learning rate which preserve convergence of the algorithm are also provided. ( 2000 Elsevier Science B.V. All rights reserved."""	activation function;algorithm;artificial neural network;computational complexity theory;gradient;least mean squares filter;mean squared error;neuron;nonlinear system;recurrent neural network;significand	Danilo P. Mandic;Jonathon A. Chambers	2000	Signal Processing	10.1016/S0165-1684(00)00101-8	adaptive filter;biological neural network;telecommunications;computer science;artificial intelligence;recurrent neural network;machine learning;artificial neural network;algorithm	ML	18.62324334282252	-28.59545531446578	137863
4bb913bff25e1db88ceaa34126de066194a6f5c5	a self-organizing map with homeostatic synaptic scaling	hebbian learning;learning rate;weight normalization;homeostasis;synaptic scaling;self organizing map;self organized map;network architecture;neural network model;cortical neurons	Hebbian learning has been a staple of neural-network models for many years. It is well known that the most straight-forward implementations of this popular learning rule lead to unconstrained weight growth. A newly discovered property of cortical neurons is that they try to maintain a preset average firing rate [G.G. Turrigiano, S.B. Nelson, Homeostatic plasticity in the developing nervous system, Nat. Rev. Neurosci. 5 (2004) 97–107]. We use this property to control the Hebbian learning process in a self-organizing map network. In this article, the practicality of this type of learning rule is expanded by deriving a scaling equation for the learning rates for various network architectures. r 2006 Elsevier B.V. All rights reserved.	hebbian theory;homeostasis;learning rule;network address translation;organizing (structure);pictbridge;self-organization;self-organizing map;synaptic package manager	Thomas J. Sullivan;Virginia R. de Sa	2006	Neurocomputing	10.1016/j.neucom.2005.12.071	homeostasis;network architecture;self-organizing map;hebbian theory;anti-hebbian learning;computer science;artificial intelligence;machine learning;leabra;competitive learning;generalized hebbian algorithm;artificial neural network;synaptic scaling	ML	15.90207523195649	-27.769249236517233	137902
d67e80c729a68e704fe64d5b8e69ad6d059786a5	a cost-sensitive paradigm for multiclass to binary decomposition schemes	multiclass;categorisation;error correcting code;analisis estadistico;codigo corrector error;multiclase;classification;categorizacion;multiclasse;statistical analysis;analyse statistique;pattern recognition;reconnaissance forme;reconocimiento patron;code correcteur erreur;clasificacion;error correcting output code;categorization	An established technique to face a multiclass categorization problem is to reduce it into a set of two-class problems. To this aim, the main decomposition schemes employed are one vs. one, one vs. all and Error Correcting Output Coding. A point not yet considered in the research is how to apply these methods to a cost-sensitive classification that represents a significant aspect in many real problems. In this paper we propose a novel method which, starting from the cost matrix for the multi-class problem and from the code matrix employed, extracts a cost matrix for each of the binary subproblems induced by the coding matrix. In this way, it is possible to tune the single two-class classifier according to the cost matrix obtained and achieve an output from all the dichotomizers which takes into account the requirements of the original multi-class cost matrix. To evaluate the effectiveness of the method, a large number of tests has been performed on real data sets. The experiments results have shown a significant improvement in terms of classification cost, specially when using the ECOC scheme.		Claudio Marrocco;Francesco Tortorella	2004		10.1007/978-3-540-27868-9_82	error detection and correction;biological classification;computer science;artificial intelligence;machine learning;data mining;algorithm;statistics;categorization	Crypto	10.189441984971559	-33.78860200344079	137985
d0c77efc789b5cf7a917f2528cf7548d21cf10d8	influence of learning rates and neighboring functions on self-organizing maps	self organizing map som;learning rates;neighboring functions;quantization error	In the article, the influence of neighboring functions and learning rates on self-organizing maps (SOM) has been investigated. The target of a selforganizing map is data clustering and their graphical presentation. Bubble, Gaussian, and heuristic neighboring functions and four learning rates (linear, inverse-of-time, power series, and heuristics) have been analyzed here. The learning rate has been changed according to epochs and iterations. A comparative analysis has been made with three data sets: glass, wine, and zoo. The quantization error has been measured in order to estimate the SOM quality.	organizing (structure);self-organizing map	Pavel Stefanovic;Olga Kurasova	2011		10.1007/978-3-642-21566-7_14	computer science;artificial intelligence;theoretical computer science;machine learning	ML	12.238047890778557	-24.113395645044974	138356
9a19b3381287061d10120e2fca28a6c963b248d6	author's reply and revision for time-varying weights	eigenvalues and eigenfunctions;time varying;convergence;neural networks;sufficient conditions;safety;backpropagation algorithms;neurons;sampling methods;convergence backpropagation algorithms neural networks neurons sampling methods sufficient conditions safety eigenvalues and eigenfunctions equations	We appreciate Mr. Liang’s interest in our above-mentioned paper and his pointing out the conditions on diagonal weights for convergence in Theorems 2 and 4 in [1]. However, there are some misunderstanding of the theory in his part, and we hope to clarify these points. 1) Mr. Liang is confused about the weight limitation in Theorem 2. The weight limitation,0 < jW I;j j < 1, is only asufficient condition, but not a necessary condition, for convergence. In other words, even if the weight limit is not satisfied, the dynamic backpropagation algorithm may still converge. In fact, for a finite number of time steps, the convergence can be ensured by an appropriate choice of the learning rates, which are much smaller then the ones in the theorem. The motivation for the weight limitation is for safety in general neural networks, where linear neurons might be used. For a linear neuron, if the weight is greater than unity in magnitude, i.e., jW I;j j 1, then the eigenvalue is in the outside of the unit circle and the network becomes unstable. 2) It is very easy to implement the weight limitation, 0 < jW I;j j < 1, in the simulation program. The gradient descent technique,WI(k + 1) = WI(k) + I( @E (k) @W (k) ), could of course drive the weight out of the limits, but we can always limit the growth by imposing a hard limiter in the program whenever it exceeds the limit. We did not mention this much detail in the paper, but it is how we have implemented. 3) He is also confused about the concept of convergence in [1, (26)]. He says that, since (26) contains the prediction for W (k + 1) rather than the actual point, the convergence in [1] refers to the gradient descent process while the learning set keeps unchanged, and not to the whole process of DRNN on-line learning. Learning implies weight adjustment, and weight adjustment involves the selection of learning rates for convergence. We want to select the best learning rate I which will give the new weightW (k + 1) fast without divergence, and this is reflected in (27). 4) He diligently revised our Theorems 2 and 4 by allowing all the weightstime-varying and removing the weight limit on the diagonal weights. Unfortunately, he made elementary, but serious mistakes in his derivation of (14a, revised) and (14b, revised) in his comments. In [1], weights of neural networks DRNI and DRNC are assumed to be constant or pseudoconstant, and the dynamic backpropagation algorithm adjusts the weights. The weight adjustment can be done at any stage of training; i.e., after each epoch or at each sampling time. If the weights are to be adjusted at each sampling time, then the weights becometime-varyingand the convergence requirements (Theorems 2 and 4) are relaxed. This work extends [1] to include time-varying weights. In the following work, all symbols, equation numbers, and Theorem numbers are kept the same as in [1]. If the weights are time-varying, by adding k, the DRNN model in	algorithm;artificial neural network;artificial neuron;backpropagation;belief revision;control theory;converge;gradient descent;limiter;online and offline;online machine learning;requirement;sampling (signal processing);simulation;vergence	Kwang Y. Lee	1997	IEEE Trans. Neural Networks	10.1109/TNN.1997.572121	sampling;mathematical optimization;discrete mathematics;convergence;computer science;machine learning;mathematics;artificial neural network	ML	16.86304980856085	-30.851113560919327	138404
64c30d53831686a4e86887f5b57ac32f072f0bdb	reinforcement learning algorithms for solving classification problems	support vector machine reinforcement learning classification problem rl algorithm classification markov decision process max min acla algorithm actor critic learning automaton multilayer perceptrons function approximator;classification markov decision process;learning;support vector machines;max min acla algorithm;multilayer perceptrons;reinforcement learning;training;testing;function approximator;accuracy;minimax techniques;artificial neural networks;multi agent systems;rl algorithm;function approximation;pattern classification;classification problem;support vector machines function approximation learning artificial intelligence markov processes minimax techniques multi agent systems multilayer perceptrons pattern classification;markov processes;support vector machine;learning artificial intelligence;actor critic learning automaton;training markov processes support vector machines learning testing artificial neural networks accuracy	We describe a new framework for applying reinforcement learning (RL) algorithms to solve classification tasks by letting an agent act on the inputs and learn value functions. This paper describes how classification problems can be modeled using classification Markov decision processes and introduces the Max-Min ACLA algorithm, an extension of the novel RL algorithm called actor-critic learning automaton (ACLA). Experiments are performed using 8 datasets from the UCI repository, where our RL method is combined with multi-layer perceptrons that serve as function approximators. The RL method is compared to conventional multi-layer perceptrons and support vector machines and the results show that our method slightly outperforms the multi-layer perceptron and performs equally well as the support vector machine. Finally, many possible extensions are described to our basic method, so that much future research can be done to make the proposed method even better.	algorithm;automaton;layer (electronics);machine learning;markov chain;markov decision process;multilayer perceptron;reinforcement learning;support vector machine	Marco Wiering;Hado van Hasselt;Auke-Dirk Pietersma;Lambert Schomaker	2011	2011 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)	10.1109/ADPRL.2011.5967372	computer science;artificial intelligence;machine learning;pattern recognition	ML	14.784527699975461	-31.478693438807888	138532
2c03edacf48aa2ee6c1fd015e8cef357ae809e7e	widely linear complex-valued kernel methods for regression		In this paper, we propose a widely linear reproducing kernel Hilbert space (WL-RKHS) for nonlinear regression with complex-valued signals. Our approach is a nonlinear extension of WL signal processing that has been proven to be more versatile than linear systems for dealing with complex-value signals. To be able to use the WL concept in kernel methods, we need to introduce a pseudo-kernel to complement the standard kernel in RKHS, which is not defined in previous RKHS approaches in the existing literature. In this paper, we present WL-RKHS, its properties, and the kernel and pseudo-kernel designs. We illustrate the need of the pseudo-kernel with simply verifiable examples that allow understanding the intuitions behind this kernel. We conclude this paper, showing that in the all-relevant nonlinear equalization problem the pseudo-kernel plays a significant role and previous approaches that do not rely on this kernel clearly underperform.	formal verification;hilbert space;kernel (operating system);kernel method;linear system;nonlinear system;signal processing;wetting layer	Rafael Boloix-Tortosa;Juan José Murillo-Fuentes;Irene Santos Velázquez;Fernando Pérez-Cruz	2017	IEEE Transactions on Signal Processing	10.1109/TSP.2017.2726991	polynomial kernel;mathematical optimization;kernel principal component analysis;kernel embedding of distributions;kernel method;representer theorem;mathematics;tree kernel;machine learning;reproducing kernel hilbert space;artificial intelligence;radial basis function kernel	Vision	22.470691035532155	-33.43803145107179	138577
ab430d9e3e250ab5dc61e12f9e7e40c83227b8a0	on different facets of regularization theory	bayesian theory;operador lineal;operador integral;fonction green;calcul neuronal;neural computation;tecnologia electronica telecomunicaciones;problema mal planteado;learning algorithm;regularisation;computacion informatica;operateur differentiel;funcion green;analyse fourier;numerical method;complexite kolmogorov;teoria shannon;probleme mal pose;rasoir occam;regularisation tikhonov;grupo de excelencia;algorithme apprentissage;regularization;etat actuel;reseau bayes;operateur integral;linear operator;kolmogorov complexity;metodo numerico;red bayes;statistical learning theory;ciencias basicas y experimentales;shannon theory;state of the art;differential operator;ill posed problem;integral operator;theorie shannon;bayes network;fourier analysis;estado actual;analisis fourier;regularizacion;tikhonov regularization;theorie information;information entropy;reseau neuronal;tecnologias;grupo a;occam razor;algoritmo aprendizaje;operateur lineaire;occam s razor;red neuronal;methode numerique;green function;information theory;operador diferencial;neural network;prospective study;teoria informacion	This review provides a comprehensive understanding of regularization theory from different perspectives, emphasizing smoothness and simplicity principles. Using the tools of operator theory and Fourier analysis, it is shown that the solution of the classical Tikhonov regularization problem can be derived from the regularized functional defined by a linear differential (integral) operator in the spatial (Fourier) domain. State-ofthe-art research relevant to the regularization theory is reviewed, covering Occam's razor, minimum length description, Bayesian theory, pruning algorithms, informational (entropy) theory, statistical learning theory, and equivalent regularization. The universal principle of regularization in terms of Kolmogorov complexity is discussed. Finally, some prospective studies on regularization theory and beyond are suggested.	algorithm;entropy (information theory);fourier analysis;kolmogorov complexity;machine learning;matrix regularization;occam's razor;prospective search;pruning (morphology);statistical learning theory;occam	Zhe Chen;Simon Haykin	2002	Neural Computation	10.1162/089976602760805296	regularization perspectives on support vector machines;backus–gilbert method;regularization;proximal gradient methods for learning;information theory;computer science;occam's razor;machine learning;zeta function regularization;calculus;mathematics;tikhonov regularization;algorithm;statistics	ML	20.41078899534584	-27.999358196912738	138775
4639d255c55dbcd6a13c31473df42f9a398332b5	active learning with expert advice		Conventional learning with expert advice methods assume a learner is always receiving the outcome (e.g., class labels) of every incoming training instance at the end of each trial. In real applications, acquiring the outcome from oracle can be costly or time consuming. In this paper, we address a new problem of active learning with expert advice, where the outcome of an instance is disclosed only when it is requested by the online learner. Our goal is to learn an accurate prediction model by asking the oracle the number of questions as small as possible. To address this challenge, we propose a framework of active forecasters for online active learning with expert advice, which attempts to extend two regular forecasters, i.e., Exponentially Weighted Average Forecaster and Greedy Forecaster, to tackle the task of active learning with expert advice. We prove that the proposed algorithms satisfy the Hannan consistency under some proper assumptions, and validate the efficacy of our technique by an extensive set of experiments.	active learning (machine learning);consistency model;experiment;greedy algorithm;loss function;oracle database;regret (decision theory);semi-supervised learning;semiconductor industry;supervised learning	Peilin Zhao;Steven C. H. Hoi;Jinfeng Zhuang	2013	CoRR		computer science;artificial intelligence;machine learning;data mining	ML	16.572953678227975	-35.794568672291845	138820
c9d838ad14bc924ea77361be74df39a08cdd2994	algorithms and networks for accelerated convergence of adaptive lda	convergence analysis;newton raphson optimization;optimization technique;variable step size;convergence rate;newton raphson method;linear discriminate analysis;conjugate direction optimization;adaptive algorithm;gradient descent;adaptive principal component analysis;principal component analysis;adaptive method;gradient descent optimization;adaptive computing;self organization;newton raphson;adaptive linear discriminant analysis;self organizing neural network;steepest descent optimization;steepest descent;neural network	We introduce and discuss new accelerated algorithms for linear discriminant analysis (LDA) in unimodal multiclass Gaussian data. These algorithms use a variable step size, optimally computed in each iteration using (i) the steepest descent, (ii) conjugate direction, and (iii) Newton–Raphson methods in order to accelerate the convergence of the algorithm. Current adaptive methods based on the gradient descent optimization technique use a fixed or a monotonically decreasing step size in each iteration, which results in a slow convergence rate. Furthermore, the convergence of these algorithms depends on appropriate choices of the step sizes. The new algorithms have the advantage of automatic optimal selection of the step size using the current data samples. Based on the new adaptive algorithms, we present self-organizing neural networks for adaptive computation of −1/2 and use them in cascaded form with a PCA network for LDA. Experimental results demonstrate fast convergence and robustness of the new algorithms and justify their advantages for on-line pattern recognition applications with stationary and non-stationary multidimensional input data. 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	algorithm;artificial neural network;computation;gradient descent;iteration;linear discriminant analysis;mathematical optimization;newton's method;online and offline;organizing (structure);pattern recognition;principal component analysis;rate of convergence;self-organization;series acceleration;stationary process	Hamid Abrishami Moghaddam;M. Matinfar;Sajad Sadough;Kh. Amiri Zadeh	2005	Pattern Recognition	10.1016/j.patcog.2004.07.003	gradient descent;mathematical optimization;computer science;machine learning;mathematics;newton's method;artificial neural network;statistics	ML	16.14598261516456	-34.53669743360977	139123
2300698c7566c714ee624b6e9e779cfaa2d5ff51	exploration vs. exploitation in active learning : a bayesian approach	belief networks;predictive models noise measurement probabilistic logic data models noise labeling training;probability;supervised learning;probabilistic dichotomy active learning supervised learning bayesian formalism;bayesian approach;active learning;training;noise measurement;probability belief networks formal logic learning artificial intelligence;probabilistic dichotomy;formal logic;experimental validation;predictive models;prediction model;probabilistic logic;learning artificial intelligence;bayesian formalism;labeling;noise;data models	The labeling of training examples could be a costly task in numerous cases of supervised learning. Active learning strategies address this problem and select unlabeled examples which are considered as the most useful for the training of a predictive model. The choice of examples to be labeled can be considered as a dilemma between the exploration and the exploitation of the input data space. In this article, a new active learning strategy that manages this compromise is proposed. This strategy is based on a Bayesian formalism that minimizes assumptions on data. An experimental validation is conducted on a unidimensional dataset, the objective is to assess the position of a step function from noisy examples. Our approach is favorably compared to an ad hoc strategy : the probabilistic dichotomy.	active learning (machine learning);dataspaces;hoc (programming language);predictive modelling;semantics (computer science);supervised learning	Alexis Bondu;Vincent Lemaire;Marc Boullé	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596815	semi-supervised learning;computer science;artificial intelligence;machine learning;pattern recognition;predictive modelling;supervised learning	ML	23.094522155823462	-27.56444303069231	139317
65ef54d52e10beb64681bea69cc1469685e809ff	a system of recognition of characters based on paraconsistent artificial neural networks	neural nets;neuro computation;paraconsistent annotated logic;paraconsistent artificial neural networks;artificial neural network;paraconsistent logic	In this paper we presented a System capable to realize a recognition of characters with base in the theoretical concepts of the Paraconsistent Annotated Logic. The Paraconsistent Annotated Logic PAL as shown in [1] is a class of the Non-Classic Logic which allows to manipulate contradictory signals. In [5] were presented the Paraconsistent Artificial Neural Cells built with Algorithms based on PAL. These Cells showed the capacity of learning certain signals in form of functions applied in their inputs. In this work, based on these Cells, were made connections and groupings among the algorithms to create a Recognizer of Characters Paraconsistent System (RCPS) capable of to learning and recognizing different types of alphabet letters or sources of signals. After the learning characters, the RPCS can recognize the letter with a high efficiency and further compares it to the group of characters learned previously. The results of tests demonstrate that the RPCS can be used as Specialist Systems of words and images Recognition	artificial neural network;neural networks;paraconsistent logic	Luís Fernando Pompeo Ferrara;Keiji Yamanaka;João Inácio da Silva Filho	2005			artificial intelligence;machine learning;mathematics;algorithm	Robotics	13.09246241201372	-28.31487601391166	139413
4b1546116e21b7b0de63698503f84cd7da344d7c	optimally regularised kernel fisher discriminant analysis	regularisation parameter;discriminant analysis;kernel parameter;fisher discriminant analysis;linear discriminant;inner loop;optimally regularised kernel fisher;usual regularisation parameter;leave-one-out cross-validation error;outer loop;leave-one-out procedure;kernel trick;kernel fisher discriminant analysis;statistical analysis;leave one out cross validation;computational complexity	"""Mika et al. (1999) introduce a non-linear formulation of Fisher's linear discriminant, based the now familiar """"kernel trick"""", demonstrating state-of-the-art performance on a wide range of real-world benchmark datasets. In this paper, we show that the usual regularisation parameter can be adjusted so as to minimise the leave-one-out cross-validation error with a computational complexity of only O(/spl lscr//sup 2/) operations, where /spl lscr/ is the number of training patterns, rather than the O(/spl lscr//sup 4/) operations required for a naive implementation of the leave-one-out procedure. This procedure is then used to form a component of an efficient hierarchical model selection strategy where the regularisation parameter is optimised within the inner loop while the kernel parameters are optimised in the outer loop."""	benchmark (computing);computational complexity theory;cross-validation (statistics);hierarchical database model;inner loop;kernel (operating system);kernel method;linear discriminant analysis;model selection;nonlinear system	Kamel Saadi;Nicola L. C. Talbot;Gavin C. Cawley	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1334245	kernel fisher discriminant analysis;computer science;machine learning;pattern recognition;mathematics;linear discriminant analysis;computational complexity theory;variable kernel density estimation;cross-validation;fisher kernel;statistics	ML	22.27675510740415	-36.52963952892014	139414
1aae8fc6704ad4dff5b26f59766923db1e64f235	fault detection and isolation in robotic manipulators and the radial basis function network trained by the kohonen's self-organizing map	manipulators;fault detection and isolation;generalization error;forward selection;multilayer perceptrons manipulators fault location self organising feature maps radial basis function networks;fault detection intelligent networks robots radial basis function networks manipulator dynamics artificial neural networks electrical fault detection mathematical model orbital robotics environmental economics;residual vector;multilayer perceptrons;manipulator dynamics;multilayer perceptron;orbital robotics;robot manipulator;radial basis function networks;artificial neural networks;radial basis function network;self organising feature maps;fault detection;robots;environmental economics;puma 560 manipulator;two link manipulator;self organizing map;subset selection;mathematical model;radial unit centers;self organized map;intelligent networks;puma 560 manipulator fault detection robotic manipulators radial basis function network self organizing map artificial neural networks multilayer perceptron manipulator dynamical behavior residual vector fault isolation forward selection subset selection radial unit centers two link manipulator;fault isolation;robotic manipulators;electrical fault detection;artificial neural network;fault location;dynamic behavior;manipulator dynamical behavior	In this work, artificial neural networks are employed in a fault detection and isolation scheme for robotic manipulators. Two networks are utilized: a multilayer perceptron is employed to reproduce the manipulator dynamical behavior, generating a residual vector that is classified by a radial basis function network, giving the fault isolation. Two methods are utilized to choose the radial unit centers in this network. The first method, forward selection, employs subset selection to choose the radial units from the training patterns. The second employs the Kohonen's self-organizing map to fix the radial unit centers in more interesting positions. Simulations employing a two link manipulator and the Puma 560 manipulator indicate that the second method gives a smaller generalization error.	fault detection and isolation;organizing (structure);radial (radio);radial basis function network;self-organizing map	Renato Tinós;Marco H. Terra	1998		10.1109/SBRN.1998.730999	computer science;machine learning;control theory;radial basis function network;artificial neural network;fault detection and isolation	ML	14.69796063057332	-26.407230534281894	139475
5a69a5ba2fe5d58a14cfdd408764fdd5579315e5	kernel bandwidth selection for svdd: the sampling peak criterion method for large data		Support vector data description (SVDD) provides a useful approach, with various practical applications, for constructing a description of multivariate data for single-class classification and outlier detection. The Gaussian kernel that is used in SVDD formulation allows a flexible data description defined by observations that are designated as support vectors. The data boundary of such a description is nonspherical and conforms to the geometric features of the data. By varying the Gaussian kernel bandwidth parameter, the SVDD-generated boundary can be made either smoother (more spherical, which might lead to underfitting), or tighter and more jagged (which might result in overfitting). Kakde et al. [1] proposed a peak criterion for selecting an optimal value of the kernel bandwidth to strike a balance between the data boundary smoothness and a method's ability to capture the general geometric shape of the data. The peak criterion approach involves training the SVDD at various values of the kernel bandwidth parameter. When training data sets are large, the time required to obtain the optimal value of the Gaussian kernel bandwidth parameter according to the peak method can become prohibitively large. This paper proposes an extension of the peak method for the case of large data. The proposed method produces good results when applied to several data sets. Two existing alternative methods of computing the Gaussian kernel bandwidth parameter (coefficient of variation and distance to the farthest neighbor) were modified in order to allow comparison with the proposed method on convergence. Empirical comparison demonstrates the advantage of the proposed method.	anomaly detection;approximation;coefficient;emoticon;kernel (operating system);lagrange multiplier;loss function;maxima and minima;newton's method;optimization problem;overfitting;sampling (signal processing);slack variable;smoothing	Sergiy Peredriy;Deovrat Kakde;Arin Chaudhuri	2017	2017 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2017.8258344	gaussian function;algorithm;overfitting;kernel (linear algebra);data mining;support vector machine;kernel bandwidth;computer science;geometric shape;data set;bandwidth (signal processing)	Robotics	24.169583863302083	-37.543397498330506	139771
e0b85ec24ccdc746e806568910613e9556838777	a heuristically enhanced gradient approximation (hega) algorithm for training neural networks	weight perturbation;benchmark problem;gradient approximation;backpropagation algorithm;neural networks learning;local search;training algorithm;artificial neural network;neural network	In this article we study artificial neural network training under the following two conditions: (a) the training algorithm must not rely on direct computation of gradients and (b) the algorithm must be efficient in training on-line. We review various relevant algorithms that are currently available in the literature and we propose a new algorithm that is further improved with respect to the second condition. We test and compare these algorithms by using commonly used benchmark problems in the literature and compare their efficiency against the popular backpropagation algorithm. Also, we introduce a realistic problem incorporating a robotic elbow manipulator and continue testing the algorithms against this problem.	algorithm;approximation;artificial neural network;gradient;heuristic	Dimokritos Panagiotopoulos;Christos Orovas;Dimitrios Syndoukas	2010	Neurocomputing	10.1016/j.neucom.2009.12.014	rprop;mathematical optimization;computer science;artificial intelligence;local search;backpropagation;machine learning;time delay neural network;deep learning;artificial neural network	ML	16.7622734249078	-24.888410165531745	139789
3de686e35b9791408b61cfd240f50e3a76340bdf	an associative memory system for sequential learning using reliability of memorized patterns	associative memory;sequential learning;neural network;oja s rule	Most conventional associative memory systems deal with input patterns that are known in advance. On the contrary, the proposed system memorizes input patterns and recalls memorized patterns sequentially. In the system, a new measure, reliability of the memorized pattern, is introduced. Using the measure, a problem of sequential learning is solved. Memorized patterns with high reliability are treated as important ones and are not removed from the memory of the system. They are recalled with high priority. Memorized patterns with low reliability are replaced by new important input patterns. In this way, sequential learning and recall in the on-line mode are possible by using the measure of reliability. The effectiveness of the proposed system is shown in a simulation. © 1999 Scripta Technica, Syst Comp Jpn, 30(9): 816, 1999	content-addressable memory;digi-comp i;online and offline;risk management plan;simulation	Shinichi Yoshizawa;Shinji Doki;Shigeru Okuma	1999	Systems and Computers in Japan	10.1002/(SICI)1520-684X(199908)30:9%3C8::AID-SCJ2%3E3.0.CO;2-C	sequence learning;computer science;artificial intelligence;machine learning;oja's rule;bidirectional associative memory;artificial neural network	ML	13.880880032436796	-30.713004128024085	140143
d54283185c52ef1e1c9a4e5d344d0b31bfbbeeb7	size-noise tradeoffs in generative networks		This paper investigates the ability of generative networks to convert their input noise distributions into other distributions. Firstly, we demonstrate a construction that allows ReLU networks to increase the dimensionality of their noise distribution by implementing a “space-filling” function based on iterated tent maps. We show this construction is optimal by analyzing the number of affine pieces in functions computed by multivariate ReLU networks. Secondly, we provide efficient ways (using polylog(1/ ) nodes) for networks to pass between univariate uniform and normal distributions, using a Taylor series approximation and a binary search gadget for computing function inverses. Lastly, we indicate how high dimensional distributions can be efficiently transformed into low dimensional distributions.	approximation;artificial neural network;binary search algorithm;box–muller transform;experiment;generative model;graphics processing unit;ibm notes;iteration;mnist database;map;muller's method;rectifier (neural networks);space-filling curve;thinking outside the box	Yi Xiang;Matus Telgarsky	2018			machine learning;artificial intelligence;iterated function;mathematical optimization;artificial neural network;gadget;function approximation;curse of dimensionality;affine transformation;mathematics;univariate;taylor series	ML	18.666799262423623	-30.310565460471295	140240
11931aadd9be35ed9812b5f8dfb6d1fea47afe9e	nonlinear l-1 support vector machines for learning using privileged information	support vector machines learning artificial intelligence linear programming quadratic programming;1 norm;quadratic programming;kernel;support vector machines;linear programming nonlinear l 1 support vector machines privileged information svm learning using privileged information lupi human teaching machine learning quadratic programming;training;computational modeling;machine learning;time series analysis;linear programming;mathematical model;binary classification 1 norm support vector machine kernel privileged information;binary classification;support vector machine;learning artificial intelligence;support vector machines kernel training machine learning mathematical model computational modeling time series analysis;privileged information	Based on L-2 Support Vector Machines(SVMs), Vapnik and Vashist introduced the concept of Learning Using Privileged Information(LUPI). This new paradigm takes into account the elements of human teaching during the process of machine learning. However, with the utilization of privileged information, the extended L-2 SVM model given by Vapnik and Vashist doubles the number of parameters used in the standard L-2 SVM. Lots of computing time would be spent on tuning parameters. In order to reduce this workload, we proposed using L-1 SVM instead of L-2 SVM for LUPI in our previous work. Different from LUPI with L-2 SVM, which is formulated as quadratic programming, LUPI with L-1 SVM is essentially a linear programming and is computationally much cheaper. On this basis, we discuss how to employ the wisdom from teachers better and more flexible by LUPI with L-1 SVM in this paper. By introducing kernels, an extended L-1 SVM model, which is still a linear programming, is proposed. With the help of nonlinear kernels, the new model allows the privileged information be explored in a transformed feature space instead of the original data domain. Numerical experiment is carried out on both time series prediction and digit recognition problems. Experimental results also validate the effectiveness of our new method.	data domain;feature vector;linear programming;machine learning;nonlinear system;numerical linear algebra;performance tuning;programming paradigm;quadratic programming;support vector machine;time series	Lingfeng Niu;Jianmin Wu	2012	2012 IEEE 12th International Conference on Data Mining Workshops	10.1109/ICDMW.2012.79	support vector machine;computer science;linear programming;artificial intelligence;machine learning;pattern recognition;quadratic programming	Vision	23.367130234918825	-37.60802143662275	140402
5f6a05b2065a05fa413a93dc29b0fc1ad4e5c5e1	applications of feedforward neural networks to transportation research	feedforward neural network		feedforward neural network;neural networks	Livio Florio;Lorenzo Mussone	1998			probabilistic neural network;mathematics;artificial intelligence;machine learning;feedforward neural network;time delay neural network;recurrent neural network;physical neural network	ML	12.510572468142275	-26.82841420810489	140436
9da90bb8ccd61aac235aba40627f07428da979e0	reservoir computing with an ensemble of time-delay reservoirs	reservoir computing;time-delay reservoirs;decoupled reservoir;coupled reservoir;ensemble	Reservoir computing (RC) has attracted a lot of attention in the field of machine learning because of its promising performance in a broad range of applications. However, it is difficult to implement standard RC in hardware. Reservoir computers with a single nonlinear neuron subject to delayed feedback (delay-based RC) allow efficient hardware implementation with similar performance to standard RC. We propose and study two different ways to build ensembles of delay-based RC with several delayed neurons (time-delay reservoirs): one using decoupled neurons and the other using coupled neurons through the feedback lines. In both cases, the outputs of the different neurons are linearly combined to solve some benchmark tasks. Simulation results show that these schemes achieve better performance than the single-neuron case. Moreover, the proposed architectures boost the RC processing speed with respect to the single-neuron case. Both schemes are found to be robust against small mismatches between delayed neuron parameters.	benchmark (computing);computer;machine learning;neuron;nonlinear system;reservoir computing;simulation	Silvia Ortin;Luis Pesquera	2017	Cognitive Computation	10.1007/s12559-017-9463-7	simulation;computer science;artificial intelligence;theoretical computer science;machine learning	ML	16.33136953373806	-25.638707448035714	140465
d639ba2d4d45666f73960a7c4fc2fe242296152c	low-rank matrix approximation with stability		Low-rank matrix approximation has been widely adopted in machine learning applications with sparse data, such as recommender systems. However, the sparsity of the data, incomplete and noisy, introduces challenges to the algorithm stability – small changes in the training data may significantly change the models. As a result, existing low-rank matrix approximation solutions yield low generalization performance, exhibiting high error variance on the training dataset, and minimizing the training error may not guarantee error reduction on the testing dataset. In this paper, we investigate the algorithm stability problem of low-rank matrix approximations. We present a new algorithm design framework, which (1) introduces new optimization objectives to guide stable matrix approximation algorithm design, and (2) solves the optimization problem to obtain stable low-rank approximation solutions with good generalization performance. Experimental results on real-world datasets demonstrate that the proposed work can achieve better prediction accuracy compared with both state-ofthe-art low-rank matrix approximation methods and ensemble methods in recommendation task.	algorithm design;approximation algorithm;ensemble learning;low-rank approximation;machine learning;mathematical optimization;newton's method;optimization problem;recommender system;singular value decomposition;sparse matrix	Dongsheng Li;Chao Chen;Qin Lv;Junchi Yan;Li Shang;Stephen M. Chu	2016			mathematical optimization;computer science;theoretical computer science;machine learning;minimax approximation algorithm;approximation algorithm;statistics	ML	24.424250518526843	-35.50974976277163	140925
61424825238425d5bbb38d2a2eb751cddaf28ead	adaptive and iterative least squares support vector regression based on quadratic renyi entropy	adaptive iterative least squares support vector regression;least squares approximations;support vector machines;support vector machines entropy iterative methods learning artificial intelligence least squares approximations regression analysis set theory;training;support vector regression;testing;set theory;quadratic renyi entropy;support vector;iterative methods;support vector machines entropy training artificial neural networks classification algorithms testing equations;large scale;artificial neural networks;incremental learning;working set selection;classification algorithms;regression analysis;entropy;incremental learning adaptive iterative least squares support vector regression quadratic renyi entropy working set selection;learning artificial intelligence;renyi entropy	An adaptive and iterative LSSVR algorithm based on quadratic Renyi entropy is presented in this paper. LS-SVM loses the sparseness of support vector which is one of the important advantages of conventional SVM. The proposed algorithm overcomes this drawback. The quadratic Renyi entropy is the evaluating criterion for working set selection, and the size of working set is determined at the process of iteration adaptively. The regression parameters are calculated by incremental learning and the calculation of inversing a large scale matrix is avoided. So the running speed is improved. This algorithm reserves well the sparseness of support vector and improves the learning speed.	iterative method;least squares;rényi entropy;support vector machine	Jingqing Jiang;Chuyi Song;Haiyan Zhao;Chunguo Wu;Yanchun Liang	2008		10.1109/GRC.2008.4664732	statistical classification;support vector machine;mathematical optimization;computer science;machine learning;pattern recognition;mathematics;artificial neural network	ML	20.641198615316775	-37.309887450474314	141164
63c848aaf8774a698f72eb53f66f51c9f53565e8	implementation of neural network algorithms on the p3 parallel associative processor	neural network		artificial neural network	Konstantinos I. Diamantaras;David L. Heine;Isaac D. Scherson	1990				ML	13.123739006117738	-27.013732804279602	141481
e5ec72fd246b22a9079dc3be8630f63d7b1bc703	learning decision theoretic utilities through reinforcement learning	reinforcement learning;decision theoretic	Probability models can be used to predict outcomes and compensate for missing data, but even a perfect model cannot be used to make decisions unless the utility of the outcomes, or preferences between them, are also provided. This arises in many real-world problems, such as medical diagnosis, where the cost of the test as well as the expected improvement in the outcome must be considered. Relatively little work has been done on learning the utilities of outcomes for optimal decision making. In this paper, we show how temporal-difference reinforcement learning (TO(A» can be used to determine decision theoretic utilities within the context of a mixture model and apply this new approach to a problem in medical diagnosis. TO( A) learning of utilities reduces the number of tests that have to be done to achieve the same level of performance compared with the probability model alone, which results in significant cost savings and increased efficiency.	decision theory;missing data;mixture model;reinforcement learning	Magnus Stensmo;Terrence J. Sejnowski	1996			computer science;artificial intelligence;machine learning;reinforcement learning	ML	15.08539437810231	-36.457747850138134	141579
827153ac39e699eddcb03fe4d9827fe103bd2be3	distributed and parallel time series feature extraction for industrial big data applications		The all-relevant problem of feature selection is the identification of all strongly and weakly relevant attributes. This problem is especially hard to solve for time series classification and regression in industrial applications such as predictive maintenance or production line optimization, for which each label or regression target is associated with several time series and meta-information simultaneously. Here, we are proposing an efficient, scalable feature extraction algorithm for time series, which filters the available features in an early stage of the machine learning pipeline with respect to their significance for the classification or regression task, while controlling the expected percentage of selected but irrelevant features. The proposed algorithm combines established feature extraction methods with a feature importance filter. It has a low computational complexity, allows to start on a problem with only limited domain knowledge available, can be trivially parallelized, is highly scalable and based on well studied non-parametric hypothesis tests. We benchmark our proposed algorithm on all binary classification problems of the UCR time series classification archive as well as time series from a production line optimization project and simulated stochastic processes with underlying qualitative change of dynamics.	algorithm;archive;benchmark (computing);big data;binary classification;computational complexity theory;feature extraction;feature selection;machine learning;mathematical optimization;parallel programming model;relevance;scalability;stochastic process;time series	Maximilian Christ;Andreas W. Kempa-Liehr;Michael Feindt	2016	CoRR		computer science;machine learning;pattern recognition;data mining;feature;statistics	ML	14.571204093523804	-37.679244158240344	141595
e06aab923535317e7856b8a1cef4cafabf7daabe	the dialog state tracking challenge with bayesian approach		Generative model has been one of the most common approaches for solving the Dialog State Tracking Problem with the capabilities to model the dialog hypotheses in an explicit manner. The most important task in such Bayesian networks models is constructing the most reliable user models by learning and reflecting the training data into the probability distribution of user actions conditional on networks’ states. This paper provides an overall picture of the learning process in a Bayesian framework with an emphasize on the state-of-the-art theoretical analyses of the Expectation Maximization learning algorithm.	bayesian network;expectation–maximization algorithm;generative model;dialog	Quan Nguyen	2017	CoRR		artificial intelligence;machine learning;computer science;probability distribution;expectation–maximization algorithm;generative model;training set;bayesian network;dialog box;bayesian probability	AI	24.129861612538182	-27.970811541489613	141635
2f70e8dc5c673820b7b315f70ec9b00c782d3e5d	foreign exchange rates forecasting with a c-ascending least squares support vector regression model	regularization parameter;foreign exchange rates forecasting;least square error;support vector regression;prior knowledge;foreign exchange rate;least squares support vector regression	In this paper, a modified least squares support vector regression (LSSVR) model, called  C  -ascending least squares support vector regression ( C  -ALSSVR), is proposed for foreign exchange rates forecasting. The generic idea of the proposed  C  -ALSSVR model is based on the prior knowledge that different data points often provide different information for modeling and more weights should be given to those data points containing more information. The  C  -ALSSVR can be obtained by a simple modification of the regularization parameter in LSSVR, whereby more weights are given to the recent least squares errors than the distant least squares errors while keeping the regularized terms in its original form. For verification purpose, the performance of the  C  -ALSSVR model is evaluated using three typical foreign exchange rates. Experimental results obtained demonstrated that the  C  -ALSSVR model is very promising tool in foreign exchange rates forecasting.	foreign exchange service (telecommunications);least squares;support vector machine	Lean Yu;Xun Zhang;Shouyang Wang	2009		10.1007/978-3-642-01973-9_68	generalized least squares;total least squares;iteratively reweighted least squares;support vector machine;least squares support vector machine;simple linear regression;econometrics;least trimmed squares;computer science;machine learning;mathematics;partial least squares regression;explained sum of squares;non-linear least squares;least squares;robust regression;linear least squares;nonlinear regression;statistics	ML	22.395460210496932	-27.619549696847532	141756
cb3b88638c692153846c4f3e630e5b4ca3ef5f2d	adaptive teaching: improving the efficiency of learning through hypothesis-dependent selection of training data	social and behavioral sciences	Active machine learning research shows that training of classifiers can be improved when the learning algorithm itself selects training data (e.g., choosing examples for which it is uncertain). Recent work with humans documents similar improvements whereby ”active” learners who can select their own training examples are faster at learning simple classification rules than ”passive” learners who observe data selected by another source. One explanation for this advantage is that active learners are able to choose data that tests the hypothesis they are currently considering, whereas for passive learners, data is independent of the learner’s belief. We explore whether the efficiency of passive learning can be improved with ”adaptive teachers” that estimate a learner’s current hypothesis and generate training data that is expected to be most helpful. Our successes and failures with this approach highlight the need to consider principles of human learning in the design of effective adaptive teachers.	algorithm;machine learning	Patricia Angie Chan;Douglas Markant;Brenden M. Lake;Todd M. Gureckis	2014			psychology;computer science;knowledge management;data science;machine learning	ML	16.307461387518842	-35.59288389078113	141805
3f1fdab57ba96a1aca3c54eddbbc5ccf676f575d	intrusion detection using an ensemble of intelligent paradigms	information systems security;support vector machines;computational techniques;network security;soft computing;securite informatique;reseau ordinateur;maquina vector soporte;intrusion detection;classification;support vector;computer network;computer security;machine vecteur support;analisis regresion;seguridad informatica;intrusion detection systems;red informatica;analyse regression;regression analysis;support vector machine;reseau neuronal;clasificacion;red neuronal;systeme detection intrusion;problem solving;artificial neural network;neural network	Soft computing techniques are increasingly being used for problem solving. This paper addresses using an ensemble approach of different soft computing and hard computing techniques for intrusion detection. Due to increasing incidents of cyber attacks, building effective intrusion detection systems are essential for protecting information systems security, and yet it remains an elusive goal and a great challenge. We studied the performance of Artificial Neural Networks (ANNs), Support Vector Machines (SVMs) and Multivariate Adaptive Regression Splines (MARS). We show that an ensemble of ANNs, SVMs and MARS is superior to individual approaches for intrusion detection in terms of classification accuracy. q 2004 Published by Elsevier Ltd.	576i;additive model;artificial neural network;backpropagation;converge;epoch (reference date);ibm notes;information security;information system;intrusion detection system;multivariate adaptive regression splines;network packet;neural networks;problem solving;rp (complexity);rapid refresh;scalability;significant figures;smoothing spline;soft computing;software propagation;support vector machine;synergy;test engineer;time complexity	Srinivas Mukkamala;Andrew H. Sung;Ajith Abraham	2005	J. Network and Computer Applications	10.1016/j.jnca.2004.01.003	anomaly-based intrusion detection system;support vector machine;computer science;artificial intelligence;machine learning;data mining;artificial neural network	ML	10.082654324702993	-30.470030638934688	142063
7742928c91535487665c41d26eb7cfb89e7d3d26	approximation to continuous functionals and operators using adaptive higher-order feedforward neural networks	feedforward neural network;learning algorithm;activation function;adaptive systems feedforward neural nets learning artificial intelligence function approximation;dynamic system;higher order;function approximation;adaptive systems;feedforward neural nets;learning artificial intelligence;function approximation neurons neural networks feedforward neural networks computer networks approximation algorithms information systems design engineering australia pattern recognition;continuous dynamical systems functional approximation feedforward neural networks neuron adaptive activation function learning algorithms steepest descent rule connection weights;steepest descent	The approximation capabilities of adaptive higher-order feedforward neural network (AHFNN) with neuron-adaptive activation function (NAF) to any nonlinear continuous functional and any nonlinear continuous operator are studied. Universal approximation theorems of AHFNN to continuous functionals and continuous operators are given, and learning algorithms based on the steepest descent rule are derived to tune the free parameters in NAF as well as connection weights between neurons. We apply the algorithms to approximate continuous dynamical systems.	approximation;artificial neural network;feedforward neural network	Shuxiang Xu;Ming Zhang	1999		10.1109/IJCNN.1999.831521	gradient descent;feedforward neural network;mathematical optimization;probabilistic neural network;higher-order logic;types of artificial neural networks;function approximation;computer science;artificial intelligence;recurrent neural network;adaptive system;dynamical system;machine learning;time delay neural network;deep learning;activation function;artificial neural network;intelligent control	ML	15.385165988978653	-28.210709404116173	142130
473e789a8491714a7eedc794128acdc9ddf92cc6	predicting the performance of learning algorithms using support vector machines as meta-regressors	learning algorithm;kernel function;support vector;machine learning;learning problems;support vector machine	In this work, we proposed the use of Support Vector Machines (SVM) to predict the performance of machine learning algorithms based on features of the learning problems. This work is related to the Meta-Regression approach, which has been successfully applied to predict learning performance, supporting algorithm selection. Experiments were performed in a case study in which SVMs with different kernel functions were used to predict the performance of Multi-Layer Perceptron (MLP) networks. The SVMs obtained better results in the evaluated task, when compared to different algorithms that have been applied as meta-regressors in previous work.	algorithm selection;benchmark (computing);experiment;machine learning;memory-level parallelism;numerical analysis;perceptron;polynomial;quad flat no-leads package;qualitative comparative analysis;radial basis function network;support vector machine	Silvio B. Guerra;Ricardo B. C. Prudêncio;Teresa Bernarda Ludermir	2008		10.1007/978-3-540-87536-9_54	semi-supervised learning;unsupervised learning;support vector machine;least squares support vector machine;kernel method;instance-based learning;radial basis function kernel;wake-sleep algorithm;computer science;perceptron;online machine learning;machine learning;pattern recognition;data mining;ensemble learning;learning classifier system;stability;relevance vector machine;computational learning theory;active learning;polynomial kernel;structured support vector machine;generalization error	AI	13.788938749909383	-34.43542868617987	142185
95bd32672e9211ad33c670e72ea5341cd642b25a	output partitioning of neural networks	learning algorithm;neural networks;output partitioning;research paper;constructive learning algorithm;classification error;network structure;neural network	Many constructive learning algorithms have been proposed to find an appropriate network structure for a classification problem automatically. Constructive learning algorithms have drawbacks especially when used for complex tasks and modular approaches have been devised to solve these drawbacks. At the same time, parallel training for neural networks with fixed configurations has also been proposed to accelerate the training process. A new approach that combines advantages of constructive learning and parallelism, output partitioning, is presented in this paper. Classification error is used to guide the proposed incremental-partitioning algorithm, which divides the original dataset into several smaller sub-datasets with distinct classes. Each sub-dataset is then handled in parallel, by a smaller constructively trained sub-network which uses the whole input vector and produces a portion of the final output vector where each class is represented by one unit. Three classification datasets are used to test the validity of this method, and results show that this method reduces the classification test error. Index Terms ⎯ constructive learning algorithm, neural networks, output partitioning ∗ Corresponding author, e-mail address: eleguans@nus.edu.sg. The authors are with the Department of Electrical and Computer Engineering, National University of Singapore, 10 Kent Ridge Crescent, Singapore 119260.	algorithm;artificial neural network;computation;computer engineering;email;interference (communication);machine learning;non-volatile memory;parallel computing;space partitioning;subnetwork	Steven Guan;Yinan Qi;Syn Kiat Tan;Shanchun Li	2005	Neurocomputing	10.1016/j.neucom.2005.02.002	computer science;artificial intelligence;machine learning;mathematics;artificial neural network;algorithm	ML	14.69580553306442	-31.163020585482656	142237
12b7c9e08e4098cd915f4fad4543aacf2348414e	a convolutional neural network tolerant of synaptic faults for low-power analog hardware	erreur calcul;distributed system;iterative method;feed forward;analyse amas;base donnee;computation error;arquitectura circuito;systeme reparti;feedforward;network on chip;caracter manuscrito;manuscript character;database;base dato;circuit architecture;boucle anticipation;classification;system on a chip;hardware architecture;chip;metodo iterativo;ciclo anticipacion;fault tolerant system;sinapsis;sistema repartido;cluster analysis;low power;sistema sobre pastilla;methode iterative;architecture circuit;sistema tolerando faltas;puissance faible;pattern recognition;systeme tolerant les pannes;analisis cluster;error calculo;systeme sur puce;reconnaissance forme;information system;perceptron;reseau neuronal;reconocimiento patron;caractere manuscrit;clasificacion;red neuronal;systeme information;neural network;sistema informacion;potencia debil;synapse	Recently, the authors described a training method for a convolutional neural network of threshold neurons. Hidden layers are trained by by clustering, in a feed-forward manner, while the output layer is trained using the supervised Perceptron rule. The system is designed for implementation on an existing low-power analog hardware architecture, exhibiting inherent error sources affecting the computation accuracy in unspecified ways. One key technique is to train the network on-chip, taking possible errors into account without any need to quantify them. For the hidden layers, an on-chip approach has been applied previously. In the present work, a chip-in-the-loop version of the iterative Perceptron rule is introduced for training the output layer. Influences of various types of errors are thoroughly investigated (noisy, deleted, and clamped weights) for all network layers, using the MNIST database of hand-written digits as a benchmark.	artificial neural network;benchmark (computing);clamping (graphics);cluster analysis;computation;convolutional neural network;iterative method;low-power broadcasting;mnist database;network on a chip;perceptron;synaptic package manager;teaching method	Johannes Fieres;Karlheinz Meier;Johannes Schemmel	2006		10.1007/11829898_11	telecommunications;computer science;artificial intelligence;machine learning;hardware architecture;feed forward;artificial neural network;algorithm	ML	11.291072055809549	-28.886344452181667	142263
9bf2e85ab9bcc9624a6241f1175e68b4cfcd6072	notice of violation of ieee publication principlesparameters selection and noise estimation of svm regression	support vector machines noise training data kernel noise level estimation training;estimation theory;least squares approximations;kernel;support vector machines;training;support vector machine regression;support vector machine regression loss function parameter selection prediction accuracy;training data;noise level;estimation;parameter selection;loss function;prediction accuracy;support vector machines estimation theory least squares approximations regression analysis sampling methods;regression analysis;sampling methods;additive noise parameters selection noise estimation svm regression hyper parameters support vector machines regression analytic parameter selection training data resampling approaches analytical prescription insensitive zone training sample size low dimensional regression high dimensional regression vapnik insensitive loss finite samples least modulus loss standard squared loss superior generalization performance sparse sample settings;noise	We investigate practical selection of hyper parameters for support vector machines (SVM) regression. The proposed methodology advocates analytic parameter selection directly from the training data, rather than re-sampling approaches commonly used in SVM applications. In particular, we describe a new analytical prescription for setting the value of insensitive zone, as a function of training sample size. Good generalization performance of the proposed parameter selection is demonstrated empirically using several low-dimensional and high-dimensional regression problems. Further, we point out the importance of Vapnik insensitive loss for regression problems with finite samples. To this end, we compare generalization performance of SVM regression with regression using least-modulus loss and standard squared loss. These comparisons indicate superior generalization performance of SVM regression under sparse sample settings, for various types of additive noise.	additive white gaussian noise;application domain;mean squared error;modulus robot;noise (electronics);polynomial kernel;radial basis function network;sampling (signal processing);sparse matrix;support vector machine;utility functions on indivisible goods	Jifu Nong	2012	2012 Fifth International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2012.33	support vector machine;sampling;training set;estimation;kernel;computer science;noise;machine learning;polynomial regression;pattern recognition;mathematics;estimation theory;regression analysis;statistics;loss function	ML	21.01850633640116	-35.80591817681545	142420
14d11e00f85ad0723134921c15c13147ece3d04b	a partially supervised learning algorithm for linearly separable systems	regle inference;learning algorithm;algorithm analysis;learning;supervised learning;complexite calcul;complejidad calculo;limite inferior;classification supervisee;partially supervised learning;sistema informatico;supervised classification;computer system;prior knowledge;intelligence artificielle;computing complexity;linearly separable systems;supervised learning vectors algorithm design and analysis machine learning algorithms machine learning humans computational complexity neural networks laboratories computer science;aprendizaje;inference rule;apprentissage;computational complexity;lower bound partially supervised learning linearly separable systems computational complexity;clasificacion supervisada;echantillon;selection effect;artificial intelligence;separabilite;analyse algorithme;systeme informatique;sample;inteligencia artificial;learning artificial intelligence computational complexity;learning artificial intelligence;limite inferieure;muestra;analisis algoritmo;lower bound;regla inferencia	An important aspect of human learning is the ability to select effective samples to learn and utilize the experience to infer the outcomes of new events. This type of learning is characterized as partially supervised learning. A learning algorithm of this type is suggested for linearly separable systems. The algorithm selects a subset S from a finite set X of linearly separable vectors to construct a linear classifier that can correctly classify all the vectors in X. The sample set S is chosen without any prior knowledge of how the vectors in X-S are classified. The computational complexity of the algorithm is analyzed, and the lower bound on the size of the sample set is established. >	algorithm;algorithmic learning theory;linear separability;supervised learning	S. J. Wan;S. K. Michael Wong	1992	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.159907	semi-supervised learning;selection bias;cover's theorem;sample;computer science;artificial intelligence;perceptron;machine learning;pattern recognition;supervised learning;upper and lower bounds;stability;computational complexity theory;rule of inference;population-based incremental learning;generalization error	ML	10.687369010836626	-32.30722742202487	142478
c453e6e3187f504218b9ad62fa45eb799e6bd8b8	density based grid clustering partition of the input space for rbf neural network	density based grid clustering;radial basis function;partition;modeling;neural network	Selecting proper centers is important for constructing a radial basis function (RBF) neural network. Motivated by the idea of clustering according to density for data mining applications, the algorithm of unevenly partition of the input space is proposed in the paper. By combining the neighboring subsets with low density data, the ultimate clustering centers are selected as the hidden layer centers in RBF neural network. An example is presented to demonstrate the method proposed, and the results illustrate the comparative high accuracy RBF neural network with comparative short training time can be created by selecting the initial partition set and the upper limit for the number of data in one subinterval properly.	artificial neural network;radial basis function	Ping Wei;Wenbo Liu;Xin Zuo;Xionglin Luo	2012		10.1007/978-3-642-33478-8_79	partition;mathematical optimization;radial basis function;probabilistic neural network;systems modeling;hierarchical rbf;computer science;machine learning;data mining;mathematics;artificial neural network	HPC	13.227374847437591	-30.52707938641155	142510
7c211cf1ec536c9bb39f5523fa9c071b0405ae6d	analog circuit fault diagnosis based on distributed neural network	hebb rule;analog circuit;distributed neural network;fault diagnosis	In order to solve the problems caused by large dataset, such as the network scale and the training time, a new method of analog circuit fault diagnosis based on distributed neural network is presented in this paper. The model of distributed neural network is simply introduced. The arithmetic mechanism is depicted in detail and the arithmetic description is given. Simulation results show that this method can improve learning speed and carry out fault diagnosis of analog circuit accurately.	analogue electronics;artificial neural network;simulation	Long Wang;Yanheng Liu;Xiaoguang Li;Jian Guan;Qi Song	2010	JCP	10.4304/jcp.5.11.1747-1754	analogue electronics;computer science;artificial intelligence;stuck-at fault;theoretical computer science;machine learning;time delay neural network	AI	14.381751683109101	-26.22269517269328	142525
ff14afe8afd2f97a76f7398589cf21aae3e3c229	nonmetric multidimensional scaling: neural networks versus traditional techniques	monotone regression;neural networks;nonmetric multidimensional scaling;sequential quadratic programming;multidimensional scaling;data visualization;mds;neural network	In this paper we consider various methods for nonmetric multidimensional scaling. We focus on the nonmetric phase, for which we consider various alternatives: Kruskal’s nonmetric phase, Guttman’s nonmetric phase, monotone regression by monotone splines, and monotone regression by a monotone neural network. All methods are briefly described. We use sequential quadratic programming to estimate the weights of the neural network. An experimental comparison of the methods is given for various synthetic and real-life datasets. The monotone neural network performs comparable to the traditional methods.	artificial neural network;backpropagation;experiment;fortran;i-spline;image scaling;interpolation;kruskal's algorithm;multidimensional scaling;real life;sequential quadratic programming;spline (mathematics);synthetic intelligence;monotone	Michiel C. van Wezel;Walter A. Kosters	2004	Intell. Data Anal.		mathematical optimization;multidimensional scaling;computer science;machine learning;mathematics;artificial neural network;statistics	AI	21.693976601807	-24.0408667074138	142555
ff6da29158036969da61763a30d9d54d28f90e80	sirens: a simple reconfigurable neural hardware structure for artificial neural network implementations	time dependent;fault tolerant;integrated circuit;neural net architecture;mathematical principles simple reconfigurable neural hardware structure artificial neural network function approximation tasks complex classification fault tolerance integrated circuits;approximation theory;function approximation;fault tolerance;neural network hardware artificial neural networks biological system modeling integrated circuit modeling acceleration circuit simulation function approximation mathematical model systems biology computational biology;neural net architecture approximation theory fault tolerance;artificial neural network	Artificial neural networks are used in various applications and research areas. Mathematically inspired approaches use these types of networks to solve complex classification or function approximation tasks whereas biologically motivated models attempt to adapt desired properties from biology such as robustness or fault tolerance to technical systems and architectures. Therefore, a great variety of different models have been proposed in literature which can be separated in time-dependent and time-independent models. To verify these models and to accelerate simulations prototypes are often implemented in integrated circuits using digital or analog designs. In this work, a simple reconfigurable neural hardware structure (SIRENS) is introduced which is capable to represent several different models of neurons, time-independent and time-dependent models as well. Therefore, this system can be used for several applications (classification or simulation) and purposes (acceleration or operation). The underlying mathematical principles are presented and, furthermore, design considerations are given in this paper.	approximation;approximation algorithm;artificial neural network;backpropagation;basis function;computation;digital data;digital electronics;fault tolerance;field-programmable gate array;fixed-point arithmetic;horner's method;integrated circuit;machine learning;neuron;nonlinear system;numerical stability;polynomial;rounding;simulation;statistical classification;transfer function;vhdl	Ralf Eickhoff;Tim Kaulmann;Ulrich Rückert	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.247211	stochastic neural network;nervous system network models;fault tolerance;types of artificial neural networks;computer science;artificial intelligence;theoretical computer science;machine learning;physical neural network;time delay neural network;artificial neural network	Robotics	15.069601936596936	-26.12840380722689	142660
2ddabba3415b5218e2db70e63acaf1c8d25937bf	online training for high-performance analogue readout layers in photonic reservoir computers	reservoir computing;opto-electronics;analogue readout;fpga;online training	Reservoir computing is a bio-inspired computing paradigm for processing time-dependent signals. The performance of its hardware implementation is comparable to state-of-the-art digital algorithms on a series of benchmark tasks. The major bottleneck of its implementations is the readout layer, based on slow offline post-processing. Few analogue solutions have been proposed, but all suffered from noticeable decrease in performance due to added complexity of the setup. Here, we propose the use of online training to solve these issues. We study the applicability of this method using numerical simulations of an experimentally feasible reservoir computer with an analogue readout layer. We also consider a nonlinear output layer, which would be very difficult to train with traditional methods. We show numerically that online learning allows to circumvent the added complexity of the analogue layer and obtain the same level of performance as with a digital layer. This work paves the way to high-performance fully analogue reservoir computers through the use of online training of the output layers.	algorithm;analog-to-digital converter;benchmark (computing);bio-inspired computing;block cipher mode of operation;british informatics olympiad;complexity;computer simulation;digital-to-analog converter;experiment;gradient descent;linear algebra;microtransaction;nonlinear system;numerical analysis;online and offline;online machine learning;programming paradigm;rc circuit;reservoir computing;revision control system;video post-processing	Piotr Antonik;Marc Haelterman;Serge Massar	2017	Cognitive Computation	10.1007/s12559-017-9459-3	simulation;computer science;artificial intelligence;theoretical computer science;machine learning;reservoir computing;distributed computing	AI	16.790002745354958	-25.390842774082415	142720
6f21a17ae3318097b5241cfdd07ed063e6df87fa	fat tails and non-linearity in volatility models: what is more important?	neural network community;financial data processing;conditional non gaussian distributions;numerical experiments;arch model;conditional variances;probability;performance evaluation;neural networks;fat tail;very large return data set;multilayer perceptrons;series mathematics financial data processing economic cybernetics multilayer perceptrons recurrent neural nets probability;statistical test;testing;prediction performance;multi layer perceptrons;functional dependency;multi layer neural network;mixture density networks;likelihood framework;heteroskedastic return series models;nonlinear specifications;garch effects;error measures;non gaussian conditional distributions;volatility models;shape;series mathematics;probability distribution;prediction performance volatility models heteroskedastic return series models functional dependence conditional variances conditional distribution neural network community multi layer perceptrons mixture density networks mdns garch effects recurrent mdns non gaussian conditional distributions numerical experiments very large return data set statistical tests conditional non gaussian distributions nonlinear specifications likelihood framework error measures nonlinear neural networks;conditional variance;statistical tests;mdns;predictive models;multi layer perceptron;recurrent neural nets;numerical experiment;tail neural networks predictive models shape multi layer neural network multilayer perceptrons performance evaluation testing gaussian distribution probability distribution;recurrent mdns;nonlinear neural networks;gaussian distribution;economic cybernetics;conditional distribution;tail;functional dependence;neural network	Since the seminal works of Engle [7] and Bollerslev [3] about heteroskedastic return series models, many extensions of their (G)ARCH models have been proposed in the literature. In particular, the functional dependenc e of conditional variances and the shape of the conditional distribution of returns hav e been varied in several ways (see [1] and [5] for an extensive overview). These two issues have been addressed by the neural network co mmunity using multi-layer perceptrons (MLPs) and mixture density networ ks (MDNs) (see, e.g., [6, 8, 10]). In this paper we extend the concept of MDNs in a recurrent way to allow for “GARCH effects”. These recurrent MDNs (RMDNs) off er a consistent framework to analyze the impact of non-linearity and of nongaussian (leptokurtic) conditional distributions on the explanatory power of vola tility models. We present numerical experiments on a very large return data set the siz e of which allows to perform detailed statistical tests to compare the obtained results. In summary, conditional non-gaussian distributions (fat t ails in the conditional distributions) tend to be more important than non-linear sp ecifications for conditional means and variances in the likelihood framework. With respect to other error measures however, the application of non-linear neur al networks seems to be promising. We think that the choice of a particular model for predicting volatility	artificial neural network;experiment;file allocation table;layer (electronics);multilayer perceptron;nonlinear system;numerical analysis;recurrent neural network;semantic network;tails;volatility	Christian Schittenkopf;Georg Dorffner;Engelbert J. Dockner	1999		10.1109/CIFER.1999.771126	econometrics;conditional variance;machine learning;mathematics;statistics	ML	22.324312640141397	-25.779710238009887	142834
048ea2f4a6ebcc3769d42bc099b356c11e684495	extraction of crisp logical rules using constrained backpropagation networks	backpropagation algorithm;backpropagation;neural network	Two recently developed methods for extraction of crisp logical rules from neural networks trained with backpropagation algorithm are compared. Both methods impose constraints on the structure of the network by adding regularization terms to the error function. Networks with minimal number of connections are created, leading to a small number of crisp logical rules. The two methods are compared on the Iris and mushroom classification problems, generating the simplest logical description of this data published so far.	algorithm;artificial neural network;backpropagation	Wlodzislaw Duch;Rafal Adamczak;Krzysztof Grabczewski;Masumi Ishikawa;Hiroki Ueda	1997			machine learning;artificial neural network;artificial intelligence;small number;regularization (mathematics);backpropagation;error function;pattern recognition;computer science	ML	14.740449027096883	-29.519366225559324	142869
7ff28265a7be0134923268af37ba29f5b110f791	local recurrent sigmoidal-wavelet neurons in feed-forward neural network for forecasting of dynamic systems: theory	lyapunov stability;recurrent;wavelet network;neural network;universal approximation	In this paper different structure of the neurons in the hidden layer of a feed-forward network, for forecasting of the dynamic systems, are proposed. Each neuron in the network is a combination of the sigmoidal activation function (SAF) and wavelet activation function (WAF). The output of the hidden neuron is the product of the output from these two activation functions. A delay element is used to feedback the output of the sigmoidal and the wavelet activation function to each other. This arrangement leads to proposed five possible configurations of recurrent neurons. Besides proposing these neuron models, the presented eural network avelet network ecurrent yapunov stability niversal approximation paper tries to compare the performance of wavelet function with sigmoid function. To guarantee the stability and the convergence of the learning process, upper bound for the learning rates has been investigated using the Lyapunov stability theorem. A two-phase adaptive learning rate ensures this upper bound. Universal approximation property of the feed-forward network with the proposed neurons has also been investigated. Finally, the applicability and comparison of the proposed recurrent networks has ench been weathered on two b	activation function;approximation;artificial neural network;dynamical system;dynamical systems theory;feedforward neural network;lyapunov fractal;neuron;recurrent neural network;sigmoid function;store and forward;two-phase locking;waf;wavelet	Ahmad Banakar;Mohammad Fazle Azeem	2012	Appl. Soft Comput.	10.1016/j.asoc.2011.10.019	mathematical optimization;computer science;artificial intelligence;machine learning;control theory;mathematics;artificial neural network	ML	15.43160619905299	-27.52517420536702	142888
32683f6c719ece0ac6656f9204e83d0fed8ecfcf	learning partial ordinal class memberships with kernel-based proportional odds models	performance measure;distributions;partial class membership;latent variable;fuzzy models;mathematics and statistics;proportional odds model;kernel methods;natural extension;logistic regression;classification;machine learning;multi class classification;linear model;simplex;kernel method;optimization;proportional odds models;ordinal regression	As an extension of multi-class classification, machine learning algorithms have been proposed that are able to deal with situations in which the class labels are defined in a non-crisp way. Objects exhibit in that sense a degree of membership to several classes. In a similar setting, models are developed here for classification problems where an order relation is specified on the classes (i.e., non-crisp ordinal regression problems). As for traditional (crisp) ordinal regression problems, it is argued that the order relation on the classes should be reflected by the model structure as well as the performance measure used to evaluate the model. These arguments lead to a natural extension of the wellknown proportional odds model for non-crisp ordinal regression problems, in which the underlying latent variable is not necessarily restricted to the class of linearmodels (by using kernel methods). © 2010 Elsevier B.V. All rights reserved.	algorithm;kernel (operating system);kernel method;latent variable;machine learning;multiclass classification;ordered logit;ordinal data;ordinal regression	Jan Verwaeren;Willem Waegeman;Bernard De Baets	2012	Computational Statistics & Data Analysis	10.1016/j.csda.2010.12.007	ordinal regression;kernel method;econometrics;machine learning;pattern recognition;mathematics;ordinal data;statistics	AI	19.29353245894189	-35.63176884193567	143038
df4ad9499f1e676066dfe8f5d260d81bd573e1b3	low-power perceptron branch predictor	low power	Perceptron based predictors are highly accurate. This high accuracy is the result of exploiting long history lengths [1] and is achieved at the expense of high complexity. The dot product of two vectors is used as prediction. The first vector is the branch outcome history where the second vector is composed of per branch weights, which represent the correlation between branch outcome and previously encountered branch instruction outcomes. The sign of the dot product determines the prediction. A non-negative value represents taken and a negative value represents not taken.	branch (computer science);branch predictor;perceptron	Kaveh Aasaraai;Amirali Baniasadi	2006	J. Low Power Electronics	10.1166/jolpe.2006.089	computer science	Arch	17.892211604566874	-32.15193198891241	143291
cc0ba17f1c316007512aeabcabbb0d43e27cb9e9	efficient implementation of gaussian mixture models using vote count circuit	random access memory;complexity theory;training;search problems gaussian processes mixture models pattern classification;error analysis;hidden markov models;vectors;classification error rate gaussian mixture models vote count circuit search algorithm similarity search random access memory ram memory structures nand flash memory nor flash memory data dimensionality posterior probability calculation gmm vc circuit;data models;training hidden markov models vectors complexity theory error analysis data models random access memory	Vote count (VC) is a fast search algorithm originally designed for similarity search on large scale data set. VC can be efficiently implemented using simple modification to the Random Access Memory (RAM) or other memory structures such as NOR or NAND Flash memory, such that the search complexity reduces to O(1) regardless of the dimensionality of data or the size of the data set. This paper proposes a low complexity implementation for the posterior probability calculation of Gaussian Mixture Models (GMM) using the VC circuit. The performance of the proposed implementation is evaluated in terms of both accuracy of the posterior probability calculation, and classification error rate if GMM is used as a classifier.	flash memory;google map maker;mixture model;parallel computing;random access;random-access memory;search algorithm;similarity search;synthetic data;test set	Wenxian Yang;Rongshan Yu;Wenyu Jiang;Haiyan Shu	2014	Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific	10.1109/APSIPA.2014.7041519	computer science;theoretical computer science;machine learning;pattern recognition	HPC	23.64269555293835	-36.141308126994616	143293
7c00f4c0972089aa30a0bed361e2fa0ab6346847	on the partition cells formed by hyperspheres	decision functions partition cells sharp translated decision functions neural networks theory fuzzy systems hyperspheres;mathematics;neural networks;neural nets;partition cell;decision functions;strontium;polynomials;upper bound;manganese;artificial neural networks;polynomials neural networks upper bound neurons space technology fuzzy systems boolean functions computer networks computer science feedforward neural networks;neural networks theory;partition cells;hyperspheres;sharp translated decision functions;neurons;hyperplane;neural nets fuzzy systems;fuzzy systems;neural networks partition cell hypersphere hyperplane;fuzzy system;hypersphere;lower bound;neural network	This paper deals with the partition cells formed by m hyperspheres in an n-dimensional real space Rn. Such partition cells are in a direct correspondence to single threshold or sharp translated decision functions which appear in the theory of neural networks and fuzzy systems. Both the least upper bound and the greatest lower bound on the number of the partition cells formed by the hyperspheres are derived and formulated. Compared with the bounds on the number of partition cells formed by the same number of hyperplanes, partition cells formed by the hyperspheres could be much more complex than those by the hyperplanes when m is much greater than n, whereas the decision functions corresponding to the hyperspheres may have the same number of parameters as those to the hyperplanes.	artificial neural network;fuzzy control system	Guomin Zhang;Jianping Yin;En Zhu;Ling Mao	2008	2008 Fourth International Conference on Natural Computation	10.1109/ICNC.2008.240	combinatorics;discrete mathematics;machine learning;mathematics	DB	17.694150931532086	-29.17593898903178	143368
c91e45c676e591eccc50d9d72fd165b91f67b88f	learning experiments with cmos artificial neuron	learning experience;integrated circuit;learning;circuito integrado;tecnologia mos complementario;aprendizaje;apprentissage;reseau neuronal;technologie mos complementaire;red neuronal;circuit integre;complementary mos technology;neural network	One of the key problems in designing analog/digital implementations of artificial neuron is the problem of its limiting functional power, i.e. the question about what class of threshold function the neuron can be taught to produce. In problems of this kind, the class of threshold functions is determined by a certain criterion of complexity, for example, number of variables, sum of input weights (as for vCMOS neuron [1,2]), maximum threshold (as for β-driven CMOS neuron [3,4]), etc.	artificial neuron;cmos	Victor Varshavsky;Vyacheslav Marakhovsky	1999		10.1007/3-540-48774-3_84	computer science;artificial intelligence;integrated circuit;machine learning;artificial neural network	Robotics	16.07910093069695	-27.018376523614887	143481
b2fb8676621bf6553e309cf63d8db189444e1a15	constructing and training feed-forward neural networks for pattern classification	feed forward neural network;neural networks;classification;local and global training;data clustering;clustering;pattern classification;pattern recognition;generalization;neural network	A new approach of constructing and training neural networks for pattern classi$cation is proposed. Data clusters are generated and trained sequentially based on distinct local subsets of the training data. Obtained clusters are then used to construct a feed-forward network, which is further trained using standard algorithms operating on the global training set. The network obtained using this approach e6ectively inherits the knowledge from the local training procedure before improving on its generalization ability through the subsequent global training. Various experiments demonstrate the superiority of this approach over competing methods. ? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	algorithm;artificial neural network;benchmark (computing);cluster analysis;computer cluster;convolutional neural network;data structure;dhrystone;experiment;feedforward neural network;lattice gauge theory;litecoin;pattern recognition;resultant;test set	Xudong Jiang;Alvin Harvey Kam Siew Wah	2003	Pattern Recognition	10.1016/S0031-3203(02)00087-0	computer science;machine learning;pattern recognition;data mining;time delay neural network;cluster analysis;artificial neural network	AI	13.310289603546924	-36.689457734726176	143509
44f9a801e34cac473db7aa901411de50e7b7246c	art2/bp architecture for adaptive estimation of dynamic processes	dynamical processes;adaptive estimation	"""The goal has been to construct a supervised artificial neural network that learns incrementally an unknown mapping. As a result a network consisting of a combination of ART2 and backpropagation is proposed and is called an """"ART2/BP"""" network. The ART2 network is used to build and focus a supervised backpropagation network. The ART2/BP network has the advantage of being able to dynamically expand itself in response to input patterns containing new information. Simulation results show that the ART2/BP network outperforms a classical maximum likelihood method for the estimation of a discrete dynamic and nonlinear transfer function."""		Einar Sørheim	1990			computer science;artificial intelligence;machine learning;control theory;multilayer perceptron	Arch	15.05600909606003	-27.91160893556282	143528
2a8a536e53a91a7e129d428266ce8dd536ecafe0	hardware solutions for implementation of neural networks in high energy physics triggers	high energy physics;neural network			Jean-Christophe Prévotet;Bruce Denby;Patrick Garda;Bertrand Granado;Christian Kiesling	2002			artificial intelligence;machine learning;artificial neural network;computer science	EDA	12.727290711313922	-27.017056276264626	143776
8cca37c46a7a9757295e52b2ba298d5a3691564d	gurls: a least squares library for supervised learning	linear algebra;regularized least squares;big data;article	We present GURLS, a least squares, modular, easy-to-extend software library for efficient supervised learning. GURLS is targeted to machine learning practitioners, as well as non-specialists. It offers a number state-of-the-art training strategies for medium and large-scale learning, and routines for efficient model selection. The library is particularly well suited for multi-output problems (multi-category/multi-label). GURLS is currently available in two independent implementations: Matlab and C++. It takes advantage of the favorable properties of regularized least squares algorithm to exploit advanced tools in linear algebra. Routines to handle computations with very large matrices by means of memory-mapped storage and distributed task execution are available. The package is distributed under the BSD license and is available for download at https://github.com/LCSL/GURLS.	algorithm;bsd;c++;computation;download;fock state;least squares;library (computing);linear algebra;matlab;machine learning;model selection;multi-label classification;supervised learning	Andrea Tacchetti;Pavan Kumar Mallapragada;Matteo Santoro;Lorenzo Rosasco	2013	Journal of Machine Learning Research		big data;computer science;theoretical computer science;linear algebra;machine learning;data mining;mathematics	ML	22.848008520015604	-36.289934599017556	143898
f88bd711ff04d648d6b66eff11b90e21ac7581cf	learning of neural networks based on weighted mean squares error function	weighted mean squares error wmse function;weighted mean squares error function;neural nets mean square error methods;neural networks;cost function;learning;neural nets;approximation algorithms;weighted mean squared error;bp neural networks;probability density function;weighted least square;sampling error;training;weighted least squares method bp neural networks mean squares error mse function weighted mean squares error wmse function;smoothing parameter;artificial neural networks;mean square error;learning neural networks weighted mean squares error function;linear model;neural networks mean square error methods cost function error correction multi layer neural network least squares methods kernel computational intelligence design engineering robustness;mean squares error mse function;mean square error methods;neurons;weighted least squares method;noise;neural network	In weighted mean squares error (WMSE) function, each sample error multiplies a weighting coefficient, then it can make noise error have a smaller proportion in the cost function, even the outliers can’t affect the learning of the neural networks by tuning the smooth parameter , which enhances the anti-noise ability of neural networks. If the samples don’t have noise samples, weighted mean squares error function can make neural networks avoid over-fitting. When the neural networks are linear models, the new cost function turns into a realization of weighted least squares method, the simulation results show the advantages and application conditions of the weighted squares error function.	artificial neural network	Sai Yang;Jinxia Ren;Zhongxia Li	2009		10.1109/ISCID.2009.67	generalized least squares;sampling error;probability density function;computer science;noise;machine learning;linear model;pattern recognition;mathematics;mean squared error;non-linear least squares;artificial neural network;statistics;recursive least squares filter	ML	16.680772159462133	-29.91141240209954	143906
c353551e8431ef8f4c73a66c4757fb70afb9383c	rosen's projection method for svm training	conferenceobject;bookpart	In this work we will give explicit formulae for the application of Rosen’s gradient projection method to SVM training that leads to a very simple implementation. We shall experimentally show that the method provides good descent directions that result in less training iterations, particularly when large precision is wanted. However, a naive kernelization may end up in a procedure requiring more KOs than SMO and further work is needed to arrive at an efficient implementation.	descent;experiment;gradient;iteration;kernelization;projection method (fluid dynamics);sequential minimal optimization	Jorge López Lázaro;José R. Dorronsoro	2009			computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics	ML	21.431186324498245	-37.36667812287321	143925
d91895c3329e0d416c8dfe5c9856e4da88126d33	modeling of x-ray ct image by using revised gmdh-type neural networks with sigmoid functions	heuristic self organization method x ray ct image computerised tomography revised gmdh type neural network group method of data handling sigmoid functions feedback loop prediction error criterion medical image recognition;prediction error;x ray ct image;computed tomography;neural networks;x ray imaging;biomedical imaging x ray imaging self organising feature maps computerised tomography feedback;input variables;biomedical imaging;x ray imaging computed tomography neural networks feedback loop neurons multi layer neural network structural engineering input variables computer architecture training data;multi layer neural network;training data;computer architecture;feedback;medical image;self organising feature maps;x ray ct;complex system;feedback loop;structural engineering;computerised tomography;sigmoid functions;medical image recognition;neurons;heuristic self organization method;group method of data handling;revised gmdh type neural network;prediction error criterion;neural network	In this paper, X-ray CT image is identified by using a revised GMDH-type neural network with sigmoid functions. The revised GMDH-type neural network algorithm with sigmoid functions proposed in this paper is developed based on the conventional GMDH-type neural network algorithm with a feedback loop. The revised GMDH-type neural networks can identify nonlinear complex systems very accurately because the complexity of the neural networks increase gradually by the feedback loop calculations and the structural parameters such as the number of neurons, the useful input variables and the number of feedback loop calculations are automatically determined so as to minimize the prediction error criterion defined as AIC.	artificial neural network;ct scan;group method of data handling;sigmoid function	Tadashi Kondo;Abhijit S. Pandya	2003		10.1109/CIRA.2003.1222164	stochastic neural network;computer vision;feedforward neural network;training set;types of artificial neural networks;computer science;artificial intelligence;machine learning;group method of data handling;mean squared prediction error;feedback loop;time delay neural network;feedback;sigmoid function;rectifier;activation function;artificial neural network	ML	12.980501626483894	-25.845665398014244	143985
41773912622c5fe992cdf629acca00140f489c05	selective training of feedforward artificial neural networks using matrix perturbation theory	feedforward neural network;optimisation;feedforward;optimizacion;learning;supervised learning;perturbation theory;boucle anticipation;selective training;algorithme;aprendizaje;algorithm;artificial neural networks;apprentissage;ciclo anticipacion;feedforward networks;efficient training;pattern recognition;optimization;reconnaissance forme;reseau neuronal;reconocimiento patron;nonlinear optimization;theorie perturbation;red neuronal;training algorithm;teoria perturbacion;new training algorithm;artificial neural network;neural network;algoritmo	"""-Many training algorithms for feedforward neural networks suffer from slow convergence. A new training method is presented which exploits results from matrix perturbation theory for significant training time improvement. This theory is used to assess the effect o f a particular training pattern on the weight estimates prior to its inclusion in any iteration. Data which do not significantly change the weights are not used in that iteration obviating the computational expense o f updating. Keywords--Selective training, Efficient training, Feedforward networks, Artificial neural networks, Perturbation theory, Nonlinear optimization, Supervised learning, New training algorithm, Pattern recognition. 1. I N T R O D U C T I O N This paper is concerned with training time improvement for feedforward artificial neural networks (FNNs). F N N s have shown promise in solving problems in areas of pattern classificiation and associative memories (e.g., L ippmann, 1987; Widrow et al., 1988; Reber & Lyman, 1987) but the time required to train the F N N remains a serious problem in many applications. Many methods for making the process more efficient have been proposed (e.g., Parker, 1987; Hush & Salas, 1988; Kollias & Anastassiou, 1989; I-Iuang & Huang, 1990). The method used in this paper reduces the training problem to a set of linear least squares equations. These linear equations allow the implementation of the data reduction technique presented. The algori thm identifies which training patterns are significant in terms of weight change and which are not at each iteration. By excluding the training patterns that are Acknowledgements: This research was conducted at Michigan State University and the University of Puerto Rico at Mayaguez, and was supported in part by the National Science Foundation under Grants No. MIP-9016734, No. CDA-8913486 and in part by the Office of Naval Research under Contract No. N00014-91-J1329. SDH was also supported by a fellowship from the University of Puerto Rico, and JRD was also supported by an Ameritech Faculty Fellowship. Requests for reprints should be sent to S. D. Hunt, University of Puerto Rico, RUM, Department of Electrical and Computer Engineering, Mayaguez, puerto Rico 00683. not significant, the number of computat ions per iteration is reduced. The selective updating (SU) of the network will be shown to have significant benefits in terms of both estimation quality and training time. The underlying layer-wise training (LWT) algor i thm is sketched in the next section, with a brief comparison with backpropagat ion (BP) and other more recently reported methods. The technical and performance details are left for the reader 's pursuit of the previous papers. The third section describes the featured issue o f improved training time, while the fourth presents simulation results using this new technique. 2. LAYER-WISE T R A I N I N G A L G O R I T H M 2.1 . N e t w o r k N o t a t i o n An F N N is a multilayer network consisting of nodes grouped into layers. In this paper we consider a twolayer network, l The generalization of the method to an arbitrary number of layers is straightforward. The number of nodes in layer i is denoted Nj, with No indicating the number of input nodes at the bot tom I Some authors might choose to call this a three-layer network. We shall designate the bottom layer of nodes as """"layer zero"""" and not count it in the total number of layers. Layer zero is a set of linear nodes which simply pass the inputs unaltered. For this reason we choose not to show circular nodes in the diagram."""	algorithm;analysis of algorithms;artificial neural network;chow–liu tree;computation;computer engineering;diagram;feedforward neural network;iteration;linear equation;linear least squares (mathematics);mathematical optimization;multitier architecture;nonlinear programming;pattern recognition;perturbation theory;requests;rico;simulation;supervised learning;synchronous optical networking;teaching method;tom;word lists by frequency	S. D. Hunt;John R. Deller	1995	Neural Networks	10.1016/0893-6080(95)00030-4	feedforward neural network;computer science;artificial intelligence;machine learning;perturbation theory;feed forward;artificial neural network;algorithm	AI	17.442706754301476	-28.36178247849862	143986
245cfc79705c8272b0004814f6847f33e4c69496	predicting the household power consumption using cnn-lstm hybrid networks			long short-term memory	Tae-Young Kim;Sung-Bae Cho	2018		10.1007/978-3-030-03493-1_50	machine learning;computer science;artificial intelligence;pattern recognition	HCI	11.949700689335796	-26.73829705249179	144002
5a32830570ee304912ae5cd9cdf5cba793fa7721	deep quantum networks for classification	unsupervised learning;exponential loss function;quantum neuron;fuzzy set;dqn architecture;feed forward neural network;supervised learning;quantum network;training;greedy layer wise unsupervised learning;feature space;classification;fuzzy set theory;error analysis;computer architecture;artificial neural networks;global gradient descent procedure;deep quantum networks;gradient descent;deep learning;loss function;neuro fuzzy;classification algorithms;parameter space;pattern classification;unsupervised learning fuzzy set theory gradient methods pattern classification quantum computing;gradient methods;deep architecture;euclidean space;quantum representation;neurons;sigmoid neuron;deep quantum networks deep learning classification;artificial neural networks neurons computer architecture training error analysis classification algorithms wireless sensor networks;quantum computing;wireless sensor networks;exponential loss function deep quantum network classification deep learning feature space fuzzy set dqn architecture quantum neuron sigmoid neuron euclidean space greedy layer wise unsupervised learning parameter space deep architecture quantum representation global gradient descent procedure;deep quantum network	This paper introduces a new type of deep learning method named Deep Quantum Network (DQN) for classification. DQN inherits the capability of modeling the structure of a feature space by fuzzy sets. At first, we propose the architecture of DQN, which consists of quantum neuron and sigmoid neuron and can guide the embedding of samples divisible in new Euclidean space. The parameter of DQN is initialized through greedy layer-wise unsupervised learning. Then, the parameter space of the deep architecture and quantum representation are refined by supervised learning based on the global gradient-descent procedure. An exponential loss function is introduced in this paper to guide the supervised learning procedure. Experiments conducted on standard datasets show that DQN outperforms other feed forward neural networks and neuro-fuzzy classifiers.	artificial neural network;deep learning;experiment;feature vector;fuzzy classification;fuzzy set;gradient descent;greedy algorithm;loss function;neuro-fuzzy;neuron;quantum network;quantum neural network;sigmoid function;supervised learning;time complexity;unsupervised learning	Shusen Zhou;Qingcai Chen;Xiaolong Wang	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.707	unsupervised learning;computer science;theoretical computer science;machine learning;pattern recognition;mathematics;deep learning;fuzzy set;supervised learning;artificial neural network	ML	14.698893088577165	-31.37785517758581	144082
82123cb046c0f63a9100109c1be5ca0e4a8a3fe8	genetic optimization of grnn for pattern recognition without feature extraction	handwritten digit recognition;genetics;3d object recognition;general regression neural network;general regression neural networks;feature extraction;pattern recognition;genetic algorithm;critical parameter	This paper describes an approach for pattern recognition using genetic algorithm and general regression neural network (GRNN). The designed system can be used for both 3D object recognition from 2D poses of the object and handwritten digit recognition applications. The system does not require any preprocessing and feature extraction stage before the recognition. In GRNN, placement of centers has significant effect on the performance of the network. The centers and widths of the hidden layer neuron basis functions are coded in a chromosome and these two critical parameters are determined by the optimization using genetic algorithms. Experimental results show that the optimized GRNN provides higher recognition ability compared with that of unoptimized GRNN. 2007 Elsevier Ltd. All rights reserved.	3d single-object recognition;artificial neural network;basis function;feature extraction;genetic algorithm;handwriting recognition;image scaling;mnist database;mathematical optimization;neuron;optical character recognition;outline of object recognition;pattern recognition;preprocessor;rough set;software release life cycle	Övünç Polat;Tülay Yildirim	2008	Expert Syst. Appl.	10.1016/j.eswa.2007.04.006	genetic algorithm;feature;feature extraction;computer science;artificial intelligence;machine learning;pattern recognition	AI	13.77621512052452	-25.69018910174121	144267
54430fa3df42708bae1476a79dff156cd39c6f83	haram: a hierarchical aram neural network for large-scale text classification	neural networks;multilabel classification tasks haram hierarchical aram neural network large scale text classification large data volumes bags of words input space output space neural classifiers large scale data fuzzy adaptive resonance associative map neural network high dimensional large data classification speed art layer clustering method classification time reduction;prototypes;training;prototypes subspace constraints training neural networks acceleration conferences data mining;data mining;acceleration;subspace constraints;text analysis art neural nets fuzzy neural nets learning artificial intelligence pattern classification pattern clustering;inproceedings;conferences	With the rapid development of the Web, the need for text classification of large data volumes is permanently growing. Texts represented as bags-of-words possess usually very high dimensionality in the input space and often also in the output space if labeled with many categories. As a result, neural classifiers should be adapted to such large-scale data. We present here a well scalable extension to the fuzzy Adaptive Resonance Associative Map (ARAM) neural network which was specially developed for high-dimensional and large data. This extension aims at increasing the classification speed by adding an extra ART layer for clustering learned prototypes into large clusters. In this case the activation of all prototypes can be replaced by the activation of a small fraction of them, leading to a significant reduction of the classification time. This extension can be especially useful for multi-label classification tasks.	algorithm;artificial neural network;cluster analysis;document classification;eur-lex;eurovoc;experiment;lex (software);multi-label classification;on the fly;prototype;resonance;scalability;speedup;standard ml;world wide web	Fernando Benites;Elena P. Sapozhnikova	2015	2015 IEEE International Conference on Data Mining Workshop (ICDMW)	10.1109/ICDMW.2015.14	acceleration;computer science;machine learning;pattern recognition;data mining;time delay neural network;prototype;artificial neural network	ML	12.80078452754724	-35.93769217858698	144319
c5380ff8f4489174c82cfb84c6dc3612a460b5a2	one-match-ahead forecasting in two-team sports with stacked bayesian regressions				Max W. Y. Lam	2018	J. Artif. Intell. Soft Comput. Res.	10.1515/jaiscr-2018-0011	artificial intelligence;machine learning;computer science;bayesian probability	AI	10.496064457706575	-25.998687679981973	144321
eecfb3524dfa82a1148b9d6018565364f2c73413	unsupervised learning using phase-change synapses and complementary patterns		Neuromorphic systems using memristive devices provide a brain-inspired alternative to the classical von Neumann processor architecture. In this work, a spiking neural network (SNN) implemented using phase-change synapses is studied. The network is equipped with a winner-take-all (WTA) mechanism and a spike-timing-dependent synaptic plasticity rule realized using crystal-growth dynamics of phase-change memristors. We explore various configurations of the synapse implementation and we demonstrate the capabilities of the phase-change-based SNN as a pattern classifier using unsupervised learning. Furthermore, we enhance the performance of the SNN by introducing an input encoding scheme that encodes information from both the original and the complementary pattern. Simulation and experimental results of the phasechange-based SNN demonstrate the learning accuracies on the MNIST handwritten digits benchmark.	benchmark (computing);conductance (graph);line code;mnist database;memristor;neuromorphic engineering;nonlinear system;simulation;spiking neural network;synapse;synapse;synaptic package manager;unsupervised learning;weapon target assignment problem;winner-take-all (computing)	Severin Sidler;Angeliki Pantazi;Stanislaw Wozniak;Yusuf Leblebici;Evangelos Eleftheriou	2017		10.1007/978-3-319-68600-4_33	artificial intelligence;synapse;machine learning;pattern recognition;von neumann architecture;spiking neural network;competitive learning;unsupervised learning;mnist database;microarchitecture;computer science;neuromorphic engineering	ML	14.948254721553836	-27.26843270456057	144464
78adfee440f4a7adb80efe684ee1a24a1b5b6d2b	minimax statistical learning and domain adaptation with wasserstein distances		As opposed to standard empirical risk minimization (ERM), distributionally robust optimization aims to minimize the worst-case risk over a larger ambiguity set containing the original empirical distribution of the training data. In this work, we describe a minimax framework for statistical learning with ambiguity sets given by balls in Wasserstein space. In particular, we prove a generalization bound that involves the covering number properties of the original ERM problem. As an illustrative example, we provide generalization guarantees for domain adaptation problems where the Wasserstein distance between the source and target domain distributions can be reliably estimated from unlabeled samples.	best, worst and average case;discounted maximum loss;domain adaptation;empirical risk minimization;machine learning;mathematical optimization;minimax;robust optimization	Jaeho Lee;Maxim Raginsky	2017	CoRR		mathematical optimization;machine learning;statistics	ML	22.73064716269072	-31.609520157843487	144480
24df44644e772d499a5c78ebbd5502cadf24fbe5	residual activity in the neurons allows soms to learn temporal order	analyse amas;learning algorithm;algorithme apprentissage;activite residuelle;carte autoorganisatrice;cluster analysis;self organising feature maps;error cuantificuacion;apprentissage sequence temps;indexation;self organized map;analisis cluster;som;intrinsic dimensionality;time sequence learning;reseau neuronal;algoritmo aprendizaje;erreur quantification;red neuronal;dimensionalite intrinseque;quantization error;neural network	A novel activity associated to the neurons of a SOM, called Residual Activity (RA), is defined in order to enlarge into the temporal domain the capabilities of a Self-Organizing Map for clustering and classifying the input data when it offers a temporal relationship. This novel activity is based on the biological plausible idea of partially retaining the activity of the neurons for future stages, that increases their probability to become the winning neuron for future stimuli. The proposed paper also proposes two quantifiable parameters for evaluating the performances of algorithms that aim to exploit temporal relationship of the input data for classification. Special designed benchmarks with spatio-temporal relationship are presented in which the proposed new algorithm, called TESOM (acronym for Time Enhanced SOM), has demonstrated to improve the temporal index without decreasing the quantization error.		Pascual Campoy Cervera;Carlos J. Vicente	2005		10.1007/11550822_59	quantization;computer science;artificial intelligence;machine learning;cluster analysis;artificial neural network	ML	11.376313620990299	-31.8304730544263	144544
a2a1131ad528b9297aee03ba45b36195ab84693d	knowledge incorporated support vector machines to detect faults in tennessee eastman process	translation invariant;computacion informatica;support vector machines;benchmark problem;grupo de excelencia;chemical engineering;knowledge;ciencias basicas y experimentales;fault detection;quimica;tennessee eastman process;support vector machine	A support vector machine with knowledge incorporation is applied to detect the faults in Tennessee Eastman Process, a benchmark problem in chemical engineering. The knowledge incorporated algorithm takes advantage of the information on horizontal translation invariance in tangent direction of the instances in dataset. This essentially changes the representation of the input data while training the algorithm. These local translations do not alter the class membership of the instances in the dataset. The results on binary as well as multiple fault detection justify the use of knowledge incorporation.	support vector machine	Abhijit J. Kulkarni;Vaidyanathan K. Jayaraman;Bhaskar D. Kulkarni	2005	Computers & Chemical Engineering	10.1016/j.compchemeng.2005.06.006	support vector machine;computer science;engineering;artificial intelligence;machine learning;algorithm	SE	15.442024247593483	-34.47042604438995	144634
9644c160a22d359b3593dbf8e384ae617a344dae	stochastic normalizations as bayesian learning		In this work we investigate the reasons why Batch Normalization (BN) improves the generalization performance of deep networks. We argue that one major reason, distinguishing it from data-independent normalization methods, is randomness of batch statistics. This randomness appears in the parameters rather than in activations and admits an interpretation as a practical Bayesian learning. We apply this idea to other (deterministic) normalization techniques that are oblivious to the batch size. We show that their generalization performance can be improved significantly by Bayesian learning of the same form. We obtain test performance comparable to BN and, at the same time, better validation losses suitable for subsequent output uncertainty estimation through approximate Bayesian posterior.	approximation algorithm;randomness	Alexander Shekhovtsov;Boris Flach	2018	CoRR			ML	19.418756932284182	-33.9542946537041	144635
54f94b5f884b0cc969caef21d30e36e67233e8b6	conducting credit assignment by aligning local representations		Using back-propagation and its variants to train deep networks is often problematic for new users. Issues such as exploding gradients, vanishing gradients, and high sensitivity to weight initialization strategies often make networks difficult to train, especially when users are experimenting with new architectures. Here, we present Local Representation Alignment (LRA), a training procedure that is much less sensitive to bad initializations, does not require modifications to the network architecture, and can be adapted to networks with highly nonlinear and discrete-valued activation functions. Furthermore, we show that one variation of LRA can start with a null initialization of network weights and still successfully train networks with a wide variety of nonlinearities, including tanh, ReLU-6, softplus, signum and others that may draw their inspiration from biology. A comprehensive set of experiments on MNIST and the much harder Fashion MNIST data sets show that LRA can be used to train networks robustly and effectively, succeeding even when back-propagation fails and outperforming other alternative learning algorithms, such as target propagation and feedback alignment.	activation function;algorithm;backpropagation;experiment;gradient;mnist database;machine learning;network architecture;nonlinear system;rectifier (neural networks);software propagation	Alexander Ororbia;Ankur Mali;Daniel Kifer;C. Lee Giles	2018	CoRR		machine learning;network architecture;artificial intelligence;initialization;mnist database;nonlinear system;mathematics	ML	17.756006652463114	-31.271620574217973	144828
6b3cb67d5afaccfb8981c0bcc7d95db8e9c75ec9	efficient benchmarking of hyperparameter optimizers via surrogates	exploitation of benchmarks and experimentation;sequential model based bayesian optimization;performance modeling;hyperparameter optimization	Hyperparameter optimization is crucial for achieving peak performance with many machine learning algorithms; however, the evaluation of new optimization techniques on real-world hyperparameter optimization problems can be very expensive. Therefore, experiments are often performed using cheap synthetic test functions with characteristics rather different from those of real benchmarks of interest. In this work, we introduce another option: cheap-to-evaluate surrogates of real hyperparameter optimization benchmarks that share the same hyperparameter spaces and feature similar response surfaces. Specifically, we train regression models on data describing a machine learning algorithm’s performance depending on its hyperparameter setting, and then cheaply evaluate hyperparameter optimization methods using the model’s performance predictions in lieu of running the real algorithm. We evaluated a wide range of regression techniques, both in terms of how well they predict the performance of new hyperparameter settings and in terms of the quality of surrogate benchmarks obtained. We found that tree-based models capture the performance of several machine learning algorithms well and yield surrogate benchmarks that closely resemble real-world benchmarks, while being much easier to use and orders of magnitude cheaper to evaluate.	algorithm;algorithmic efficiency;benchmark (computing);distribution (mathematics);experiment;machine learning;mathematical optimization;meta-optimization;noether's theorem;overhead (computing);response surface methodology;surrogates;synthetic intelligence	Katharina Eggensperger;Frank Hutter;Holger H. Hoos;Kevin Leyton-Brown	2015			computer science;machine learning;pattern recognition;hyperparameter optimization	AI	23.511903777282573	-31.434591304666352	144858
97af3e7963d0f8af656601944030f3ee6a7ad878	stochastic processes and neuronal modelling: quantum harmonic oscillator dynamics in neural structures	mecanique quantique;wiener process;attractors;attracteur;gestion memoire;learning algorithm;memoire associative;processus wiener;stochastic process;quantum oscillator;memory management;neural networks;neural model;harmonics;brownian motion;equation schrodinger;oscillateur harmonique;stochastic convergence;equation langevin;aprendizaje probabilidades;langevin equation;capacite stockage;wiener processes;modelisation;oscilador cuantico;weight;mouvement brownien;harmonique;stochastic processes;convergence stochastique;quantum physics;quantum mechanics;oscillateur quantique;convergencia estocastica;harmonic oscillators;capacidad almacenaje;schrodinger s equation;storage capacity;poids;processus stochastique;associative memory;apprentissage probabilites;schroedinger equation;reseau neuronal;content addressable storage;diffusion;quantum associative memories;quantum harmonic oscillator;probability learning;neural network;harmonic oscillator	This paper studies neural structures with weights that follow the model of the quantum harmonic oscillator (Q.H.O.). The proposed neural networks have stochastic weights which are calculated from the solution of Schrödinger’s equation under the assumption of a parabolic (harmonic) potential. These weights correspond to diffusing particles, which interact to each other as the theory of Brownian motion (Wiener process) predicts. The learning of the stochastic weights (convergence of the diffusing particles to an equilibrium) is analyzed. In the case of associative memories the proposed neural model results in an exponential increase of patterns storage capacity (number of attractors). Finally, it is shown that conventional neural networks and learning algorithms based on error gradient can be conceived as a subset of the proposed quantum neural structures. Thus, the complementarity between classical and quantum physics is also validated in the field of neural computation.	algorithm;artificial neural network;complementarity (physics);computation;gradient;ground state;lyapunov fractal;machine learning;numerical analysis;observable;parabolic antenna;quantum harmonic oscillator;schrödinger;severo ornstein;simulation;stationary process;stochastic process;the principles of quantum mechanics;time complexity	Gerasimos G. Rigatos	2010	Neural Processing Letters	10.1007/s11063-010-9151-z	stochastic neural network;stochastic process;quantum harmonic oscillator;mathematical analysis;harmonic oscillator;calculus;mathematics;artificial neural network	ML	19.905970619876697	-26.630038106368612	144891
9f67b3edc67a35c884bd532a5e73fa3a7f3660d8	count-based exploration with the successor representation		The problem of exploration in reinforcement learning is well-understood in the tabular case and many sample-efficient algorithms are known. Nevertheless, it is often unclear how the algorithms in the tabular setting can be extended to tasks with large state-spaces where generalization is required. Recent promising developments generally depend on problem-specific density models or handcrafted features. In this paper we introduce a simple approach for exploration that allows us to develop theoretically justified algorithms in the tabular case but that also give us intuitions for new algorithms applicable to settings where function approximation is required. Our approach and its underlying theory is based on the substochastic successor representation, a concept we develop here. While the traditional successor representation is a representation that defines state generalization by the similarity of successor states, the substochastic successor representation is also able to implicitly count the number of times each state (or feature) has been observed. This extension connects two until now disjoint areas of research. We show in traditional tabular domains (RiverSwim and SixArms) that our algorithm empirically performs as well as other sample-efficient algorithms. We then describe a deep reinforcement learning algorithm inspired by these ideas and show that it matches the performance of recent pseudo-count-based methods in hard exploration Atari 2600 games.	algorithm;approximation;atari;feature engineering;reinforcement learning;table (information)	Marlos C. Machado;Marc G. Bellemare;Michael H. Bowling	2018	CoRR		machine learning;successor cardinal;function approximation;artificial intelligence;reinforcement learning;disjoint sets;mathematics;intuition	ML	17.32738837401848	-33.36373527835406	144945
1d343e1e8c8d1ed913b8059730674cab64042ab7	boundary region sensitive classification for the counterpropagation neural network	unsupervised learning;pattern classification sensitive classification counter propagation neural network supervised learning unsupervised learning codebook vectors boundary regions;neural nets;requirements management;sensitivity analysis;pattern classification;learning artificial intelligence;sensitivity analysis neural nets learning artificial intelligence pattern classification;neural networks counting circuits unsupervised learning fault diagnosis education information technology technology management clustering algorithms classification algorithms uncertainty;neural network	The basic problem of classification priori unknown faults is related to re-arrangement of existing classes and/or introduction of new classes that requires management of uncertain regions where input pattern vectors may belong to several classes. The counter-propagation neural network (CPN) was selected to investigate the classification problems because it integrates both supervised and unsupervised learning to support diagnosis of both priori known and unknown faults. The CPN network is taught to have clusters that are described by codebook vectors in the training phase. To diagnose unknown faults the codebook vector distribution density should be increased in the inhomogeneous regions, i.e., in class boundary regions and decreased in homogenous regions. The basic CPN algorithm was modified incorporating the class homogeneity to provide the rearrangement of codebook vector to manage uncertain regions and to diagnose priori unknown faults.	artificial neural network	László Kovács;Gábor Terstyánszky	2000		10.1109/IJCNN.2000.857819	unsupervised learning;requirements management;computer science;machine learning;pattern recognition;data mining;competitive learning;sensitivity analysis;artificial neural network	ML	13.135705130428931	-33.32347774819391	145258
1891322084148b4561d4a205b5c20e9eac1b7ae6	training restricted boltzmann machines		Restricted Boltzmann Machines (RBMs), two-layered probabilistic graphical models that can also be interpreted as feed forward neural networks, enjoy much popularity for pattern analysis and generation. Training RBMs however is challenging. It is based on likelihood maximization, but the likelihood and its gradient are computationally intractable. Therefore, training algorithms such as Contrastive Divergence (CD) and learning based on Parallel Tempering (PT) rely on Markov chain Monte Carlo methods to approximate the gradient. The presented thesis contributes to understanding RBM training methods by presenting an empirical and theoretical analysis of the bias of the CD approximation and a bound on the mixing rate of PT. Furthermore, the thesis improves RBM training by proposing a new transition operator leading to faster mixing Markov chains, by investigating a different parameterization of the RBM model class referred to as centered RBMs, and by exploring estimation techniques from statistical physics to approximate the likelihood. Finally, an analysis of the representational power of deep belief networks with real-valued visible variables is given.	approximation algorithm;artificial neural network;bayesian network;computational complexity theory;deep belief network;expectation–maximization algorithm;gradient;graphical model;markov chain monte carlo;monte carlo method;parallel tempering;pattern recognition;restricted boltzmann machine	Asja Fischer	2015	KI - Künstliche Intelligenz	10.1007/s13218-015-0371-2	speech recognition;computer science;artificial intelligence;machine learning	ML	24.495452072845232	-30.688819088323253	145291
3553602e453728f1880dadb387cd80cf8a03bd31	a solution for missing data in recurrent neural networks with an application to blood glucose prediction	forward backward;maximum likelihood;blood glucose;linear model;prediction model;kalman lter;missing data;recurrent neural network;neural network model;real time recurrent learning;nonlinear dynamic system;neural network	We consider neural network models for stochastic nonlinear dynamical systems where measurements of the variable of interest are only available at irregular intervals i.e. most realizations are missing. Difficulties arise since the solutions for prediction and maximum likelihood learning with missing data lead to complex integrals, which even for simple cases cannot be solved analytically. In this paper we propose a specific combination of a nonlinear recurrent neural predictive model and a linear error model which leads to tractable prediction and maximum likelihood adaptation rules. In particular, the recurrent neural network can be trained using the real-time recurrent learning rule and the linear error model can be trained by an EM adaptation rule, implemented using forward-backward Kalman filter equations. The model is applied to predict the glucose/insulin metabolism of a diabetic patient where blood glucose measurements are only available a few times a day at irregular intervals. The new model shows considerable improvement with respect to both recurrent neural networks trained with teacher forcing or in a free running mode and various linear models.	artificial neural network;cobham's thesis;dynamical system;kalman filter;learning rule;linear model;missing data;neural networks;nonlinear system;real-time locating system;recurrent neural network	Volker Tresp;Thomas Briegel	1997			feedforward neural network;missing data;computer science;artificial intelligence;recurrent neural network;machine learning;linear model;time delay neural network;mathematics;deep learning;predictive modelling;maximum likelihood;artificial neural network;statistics	ML	19.22461522644802	-25.43417834610111	145373
e0b19553358852e20afefce12864f2a7e811ea24	using metaheuristics for hyper-parameter optimization of convolutional neural networks		Convolutional neural networks (CNNs) have attracted researchers’ increasing attention for almost three decades now, achieving superior results in such domains as computer vision, signal processing etc. Their success can be mainly attributed to a specific network architecture, which is conceived by assigning values to a large number of hyper-parameters, each influencing the resulting error rate. Yet a search for good hyper-parameter values is a challenging task, being usually done manually and taking a considerable amount of work. This paper is dedicated to the problem of designing automated hyper-parameter search algorithms for convolutional architectures. We propose two algorithms based on such meta-heuristics as evolutionary computation and local search. To our knowledge, they have never been applied to the case of CNN architectures before. Using image recognition datasets, we compare the algorithms and show that they can produce CNNs with nearly state of the art performance without any user interference, saving much tedious effort.	artificial neural network;computer vision;convolutional neural network;evolutionary computation;heuristic (computer science);interference (communication);local search (optimization);metaheuristic;network architecture;neural networks;search algorithm;signal processing	Victoria Bibaeva	2018	2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)	10.1109/MLSP.2018.8516989	convolutional neural network;evolutionary computation;artificial intelligence;machine learning;simulated annealing;metaheuristic;signal processing;local search (optimization);search algorithm;memetic algorithm;computer science	Vision	14.138420754995085	-24.428782919584126	145529
4a9666819cbd8405591d87b553302a52277e97cf	neural network implementation of a mesoscale meteorological model		Numerical weather prediction is a computationally expensive task that requires not only the numerical solution to a complex set of non-linear partial differential equations, but also the creation of a parameterization scheme to estimate sub-grid scale phenomenon. This paper outlines an alternative approach to developing a mesoscale meteorological model – a modified recurrent neural network that learns to simulate the solution to these equations. Along with an appropriate time integration scheme and learning algorithm, this method can be used to create multi-day forecasts for a large region. The learning method presented in this paper is an extended form of Backpropagation Through Time for a recurrent network with outputs that feed back through as inputs only after undergoing a fixed transformation.	algorithm;analysis of algorithms;artificial intelligence;artificial neural network;backpropagation through time;carr–benkler wager;inferring horizontal gene transfer;nonlinear system;numerical methods for ordinary differential equations;numerical partial differential equations;numerical weather prediction;recurrent neural network;simulation	Robert Firth;Jianhua Chen	2014		10.1007/978-3-319-08326-1_17	machine learning;parametrization;mesoscale meteorology;artificial intelligence;artificial neural network;partial differential equation;numerical weather prediction;computer science;phenomenon;recurrent neural network	ML	17.99789700855244	-25.01786813354401	145669
35c247ae8bc0cf785bf211e5da108b556201e447	ls-draughts - a draughts learning system based on genetic algorithms, neural network and temporal differences	temporal difference;learning process;neural nets;reinforcement learning;learning systems genetic algorithms neural networks evolutionary computation;automatic generation;learning systems;learning system;minimax techniques;neural nets genetic algorithms learning systems minimax techniques;game board state draughts learning system genetic algorithms temporal differences learning system artificial neural network temporal differences reinforcement learning methods minimax algorithm;genetic algorithm;genetic algorithms;artificial neural network;neural network	The objective of this paper is the proposal of a learning system - the LS-Draughts - which aims at using genetic algorithms (GAs) to automatically generate a concise and efficient set of features which are relevant in representing the game board states and for optimizing the training of a draught player agent. This agent consists of an Artificial Neural Network whose weights are updated by the temporal differences (TD) reinforcement learning methods. The NET-FEATUREMAP mapping is used to represent a game board state in the Network input. The network output corresponds to a real number (prediction) that indicates to what extent the input state is favorable to the agent. The agent is trained by self-play coupled with a cloning technique. The minimax algorithm is used to choose the best action to be executed considering the current game board state. Such a learning process is close to that proposed by Mark Lynch (NeuroDraughts). However, the LS-Draughts expands the NeuroDraughts as it automatically generates an effective and concise set of features to be used in the NET-FEATUREMAP mapping, whereas the latter uses a fixed and manually defined set of features. A tournament was promoted between the best player obtained by the LS-Draughts and the best available player of the NeuroDraughts. The tournament was won by the player of the LS-Draughts, which confirms that the GAs can be an important tool for improving the general performance of automatic players.	artificial neural network;automatic differentiation;genetic algorithm;least squares;minimax;reinforcement learning	Henrique Castro Neto;Rita Maria da Silva Julia	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424788	temporal difference learning;semi-supervised learning;unsupervised learning;mathematical optimization;simulation;genetic algorithm;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;time delay neural network;learning classifier system;competitive learning;reinforcement learning;artificial neural network;q-learning;generalization error	AI	16.286213410356364	-24.629782613604892	145775
9ea70740c7fcd6e4e4a7f7c16d228031a2acb331	online optimization with gradual variations		We study the online convex optimization problem, in which an online algorithm has to make repeated decisions with convex loss functions and hopes to achieve a small regret. We consider a natural restriction of this problem in which the loss functions have a small deviation, measured by the sum of the distances between every two consecutive loss functions, according to some distance metrics. We show that for the linear and general smooth convex loss functions, an online algorithm modified from the gradient descend algorithm can achieve a regret which only scales as the square root of the deviation. For the closely related problem of prediction with expert advice, we show that an online algorithm modified from the multiplicative update algorithm can also achieve a similar regret bound for a different measure of deviation. Finally, for loss functions which are strictly convex, we show that an online algorithm modified from the online Newton step algorithm can achieve a regret which is only logarithmic in terms of the deviation, and as an application, we can also have such a logarithmic regret for the portfolio management problem.	convex function;convex optimization;gradient;loss function;mathematical optimization;newton;online algorithm;online optimization;optimization problem;program optimization;regret (decision theory)	Chao-Kai Chiang;Tianbao Yang;Chia-Jung Lee;Mehrdad Mahdavi;Chi-Jen Lu;Rong Jin;Shenghuo Zhu	2012			mathematical optimization;combinatorics;machine learning;mathematics	ML	21.265782400224897	-30.641317041670845	145777
055a70992496c1918d162a155149fbb2c37f3619	parallel ensemble of online sequential extreme learning machine based on mapreduce	sequential learning;parallel learning;ensemble;extreme learning machine;mapreduce	In this era of big data, analyzing large scale data efficiently and accurately has become a challenging problem. As one of the ELM variants, online sequential extreme learning machine (OS-ELM) provides a method to analyze incremental data. Ensemble methods provide a way to learn from data more accurately. MapReduce, which provides a simple, scalable and fault-tolerant framework, can be utilized for large scale learning. In this paper, we first propose an ensemble OS-ELM framework which supports any combination of bagging, subspace partitioning and cross validation. Then we design a parallel ensemble of online sequential extreme learning machine (PEOS-ELM) algorithm based on MapReduce for large scale learning. PEOS-ELM algorithm is evaluated with real and synthetic data with the maximum number of training data 5120K and the maximum number of attributes 512. The speedup of this algorithm reaches as high as 40 on a cluster with maximum 80 cores. The accuracy of PEOS-ELM algorithm is at the same level as that of ensemble OS-ELM executing on a single machine, which is higher than that of the original OS-ELM. & 2015 Elsevier Ltd. All rights reserved.	algorithm;big data;cross-validation (statistics);elm;fault tolerance;mapreduce;operating system;scalability;speedup;synthetic data	Shan Huang;Botao Wang;Junhao Qiu;Jitao Yao;Guoren Wang;Ge Yu	2016	Neurocomputing	10.1016/j.neucom.2015.04.105	semi-supervised learning;ensembl;sequence learning;wake-sleep algorithm;computer science;online machine learning;machine learning;pattern recognition;data mining;ensemble learning;stability;active learning;generalization error	AI	13.786719537403133	-37.8437016299543	145863
056ab08d8cb2153ef20f072a501e45f08db76a3d	a hybrid algorithm for determining protein structure	biology computing;inference mechanisms proteins biology computing multilayer perceptrons backpropagation statistics;proteins neural networks amino acids multi layer neural network multilayer perceptrons backpropagation algorithms artificial intelligence;multilayer perceptrons;amino acid sequence;inference mechanisms;multilayer perceptron;backpropagation;protein structure;proteins;backpropagation algorithm;secondary structure;hybrid system;statistics;protein folding;protein folding problem hybrid algorithm protein structure determination neural network statistical module memory based reasoner combiner amino acid sequences 3d protein structures secondary structure prediction accuracy multilayer perceptrons backpropagation algorithm training;hybrid algorithm;neural network	At Thinking Machines, my colleagues and I have developed a hybrid system combining a neural network, a statistical module, and a memory-based reasoner, each of which makes its own prediction. A combiner then blends these results to produce the final predictions. This hybrid system improves its ability to determine how amino acid sequences fold into 3D protein structures. It predicts secondary structures with 66.4% accuracy. Both the neural network and the combiner are multilayer perceptrons trained with the standard backpropagation algorithm; this article focuses on the other two components, and on how we trained the hybrid system and used it for prediction. I also discuss how future work in AI and other sciences might meet the challenge of the protein folding problem. >	hybrid algorithm	Xiru Zhang	1994	IEEE Expert	10.1109/64.336147	computer science;artificial intelligence;backpropagation;theoretical computer science;machine learning;artificial neural network	Vision	13.69258670539677	-27.7615689412369	146041
ea4cfec63bbd6cb42602dd3af9f639d3d2ae8786	using classifier systems to design neural nets	neural networks convergence fires pattern matching accuracy neurons testing liver diseases genetics;neural nets;classifier system;neural net architecture;neural net;genetic algorithm;genetic algorithms;genetic algorithms neural net architecture neural nets;training algorithm;network links classifier systems neural network design neural network training algorithm genetic algorithms weights;neural network	A new neural network training algorithm, based on the use of genetic algorithms and classifier systems, is presented. The algorithm not only calculates the weights of the network links, but also automates the traditionally ad hoc, trial and error method for finding the most appropriate architecture of the neural net. >	artificial neural network	Christos Nikolopoulos	1994		10.1109/TAI.1994.346395	neural gas;stochastic neural network;feedforward neural network;probabilistic neural network;genetic algorithm;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;machine learning;pattern recognition;time delay neural network;deep learning;artificial neural network	EDA	14.231107371328976	-25.558235112631174	146399
c7ec956cb69ee85269067bdaa3c06a8aa63f04ac	on optimal generalizability in parametric learning		We consider the parametric learning problem, where the objective of the learner is determined by a parametric loss function. Employing empirical risk minimization with possibly regularization, the inferred parameter vector will be biased toward the training samples. Such bias is measured by the cross validation procedure in practice where the data set is partitioned into a training set used for training and a validation set, which is not used in training and is left to measure the outof-sample performance. A classical cross validation strategy is the leave-one-out cross validation (LOOCV) where one sample is left out for validation and training is done on the rest of the samples that are presented to the learner, and this process is repeated on all of the samples. LOOCV is rarely used in practice due to the high computational complexity. In this paper, we first develop a computationally efficient approximate LOOCV (ALOOCV) and provide theoretical guarantees for its performance. Then we use ALOOCV to provide an optimization algorithm for finding the regularizer in the empirical risk minimization framework. In our numerical experiments, we illustrate the accuracy and efficiency of ALOOCV as well as our proposed framework for the optimization of the regularizer.	approximation algorithm;computational complexity theory;cross-validation (statistics);empirical risk minimization;experiment;loss function;mathematical optimization;numerical analysis;test set	Ahmad Beirami;Meisam Razaviyayn;Shahin Shahrampour;Vahid Tarokh	2017			artificial intelligence;machine learning;computer science;cross-validation;generalizability theory;parametric statistics;computational complexity theory;training set;regularization (mathematics);empirical risk minimization	ML	22.92395788369889	-34.09627705885895	146666
a8c2818fe77ebf458a37346d9fcbb9b5e7a880a5	learning activation functions from data using cubic spline interpolation		Neural networks require a careful design in order to perform properly on a given task. In particular, selecting a good activation function (possibly in a data-dependent fashion) is a crucial step, which remains an open problem in the research community. Despite a large amount of investigations, most current implementations simply select one fixed function from a small set of candidates, which is not adapted during training, and is shared among all neurons throughout the different layers. However, neither two of these assumptions can be supposed optimal in practice. In this paper, we present a principled way to have data-dependent adaptation of the activation functions, which is performed independently for each neuron. This is achieved by leveraging over past and present advances on cubic spline interpolation, allowing for local adaptation of the functions around their regions of use. The resulting algorithm is relatively cheap to implement, and overfitting is counterbalanced by the inclusion of a novel damping criterion, which penalizes unwanted oscillations from a predefined shape. Experimental results validate the proposal over two well-known benchmarks.	activation function;algorithm;benchmark (computing);cubic hermite spline;cubic function;data dependency;mathematical optimization;neural networks;neuron;nonlinear system;overfitting;spline interpolation	Simone Scardapane;Michele Scarpiniti;Danilo Comminiello;Aurelio Uncini	2016	CoRR		mathematical optimization;simulation;artificial intelligence;machine learning;mathematics;statistics	ML	18.78990575866649	-31.59035829794836	146712
38a9427a7599e9fc97e95f57ebe368b4de92c0cb	parseval networks: improving robustness to adversarial examples		We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1. Parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation. The most important feature of Parseval networks is to maintain weight matrices of linear and convolutional layers to be (approximately) Parseval tight frames, which are extensions of orthogonal matrices to non-square matrices. We describe how these constraints can be maintained efficiently during SGD. We show that Parseval networks match the state-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House Numbers (SVHN), while being more robust than their vanilla counterpart against adversarial examples. Incidentally, Parseval networks also tend to train faster and make a better usage of the full capacity of the networks.	algorithm;artificial neural network;deep learning;google street view;stochastic gradient descent	Moustapha Cissé;Piotr Bojanowski;Edouard Grave;Yann Dauphin;Nicolas Usunier	2017			combinatorics;theoretical computer science;machine learning;mathematics;statistics	ML	22.148313062246725	-32.401239443817346	146766
79c15eae001da2c540d72e46ab61aedfe588b02b	shape approximation of arc patterns using dynamic neural networks	dynamic neural net;image processing;shape approximation;edge detection;procesamiento imagen;imagen nivel gris;traitement image;deteccion contorno;algorithme;algorithm;detection contour;shape representation;neural net;self organized feature map;image niveau gris;arc de cercle;dynamic neural network;self organization;skeletonization;arc patterns;reseau neuronal;grey level image;red neuronal;neural network;algoritmo	Une technique de representation de forme de gabarits bi-dimensionnels utilisant une variante dynamique des reseaux de Kohonen auto-organisants est discutee. Dans le reseau de Kohonen, le nombre de processeurs est fixe et doit etre specifie a priori. Ce nombre, s'il n'est pas correctement choisi, peut causer soit un gaspillage soit un manque de processeurs. Ce probleme est resolu, dans cet article, en incorporant une capacite dynamique de croissance et de diminution dans ce reseau. La seule forme consideree ici est l'arc de cercle	approximation;artificial neural network	Swapan K. Parui;Amitava Datta;Tamaltaru Pal	1995	Signal Processing	10.1016/0165-1684(94)00130-R	skeletonization;computer vision;self-organization;edge detection;computer science;artificial intelligence;artificial neural network;algorithm	ML	12.144043050980958	-31.026930114204838	146951
4d09d93b754a6715b12bc0b080fdf09c81a6cff4	associative memory via a sparse recovery model		An associative memory is a structure learned from a dataset M of vectors (signals) in a way such that, given a noisy version of one of the vectors as input, the nearest valid vector from M (nearest neighbor) is provided as output, preferably via a fast iterative algorithm. Traditionally, binary (or q-ary) Hopfield neural networks are used to model the above structure. In this paper, for the first time, we propose a model of associative memory based on sparse recovery of signals. Our basic premise is simple. For a dataset, we learn a set of linear constraints that every vector in the dataset must satisfy. Provided these linear constraints possess some special properties, it is possible to cast the task of finding nearest neighbor as a sparse recovery problem. Assuming generic random models for the dataset, we show that it is possible to store super-polynomial or exponential number of n-length vectors in a neural network of size O(n). Furthermore, given a noisy version of one of the stored vectors corrupted in near-linear number of coordinates, the vector can be correctly recalled using a neurally feasible algorithm.	algorithm;artificial neural network;bidirectional associative memory;compressed sensing;content-addressable memory;hopfield network;iterative method;polynomial;sparse matrix;time complexity	Arya Mazumdar;Ankit Singh Rawat	2015			computer science;theoretical computer science;machine learning;pattern recognition;statistics	ML	16.86073891689303	-31.080268473412918	147030
8b0cb1114fe5613348d3152765a537da8be9acda	hard learning the easy way: backpropagation with deformation		T he backpropagation algorithm for feed-forwa rd layer ed neural networks is ap plied to a problem domain of vari abl e difficulty. The algori thm in its basic form is shown to be very sens itive to stepsize and momentum parameters as problem di fficulty is increased. To counter this we suggest a way of changing them during learning for a faster and more stable gradient descent . A technique for the deform ation of the error surface is introduced as a way of using t he algorithm to learn hard problem domai ns by gr adually changing the shape of the error sur face from a gentle to the final craggy form . This deformation procedure is applied to a second problem domain and is shown to improve the learn ing performan ce by gradually increasing the difficulty of th e problem domain so that the net may build upon past exp erience, rather than being subjecte d to a complicated set of assoc iat ions from the st ar t .	algorithm;artificial neural network;backpropagation;digital-to-analog converter;exptime;gradient descent;problem domain	Frank J. Smieja;Gareth D. Richards	1988	Complex Systems		mathematics;machine learning;deformation (mechanics);backpropagation;artificial intelligence	ML	17.20765142137937	-27.452868850283007	147041
65d8b7a4609249fe007cd2daf6d215bd04fde390	on the stability and convergence of stochastic gradient descent with momentum		While momentum-based methods, in conjunction with the stochastic gradient descent, are widely used when training machine learning models, there is little theoretical understanding on the generalization error of such methods. In practice, the momentum parameter is often chosen in a heuristic fashion with little theoretical guidance. In the first part of this paper, for the case of general loss functions, we analyze a modified momentum-based update rule, i.e., the method of early momentum, and develop an upper-bound on the generalization error using the framework of algorithmic stability. Our results show that machine learning models can be trained for multiple epochs of this method while their generalization errors are bounded. We also study the convergence of the method of early momentum by establishing an upper-bound on the expected norm of the gradient. In the second part of the paper, we focus on the case of strongly convex loss functions and the classical heavy-ball momentum update rule. We use the framework of algorithmic stability to provide an upper-bound on the generalization error of the stochastic gradient method with momentum. We also develop an upper-bound on the expected true risk, in terms of the number of training steps, the size of the training set, and the momentum parameter. Experimental evaluations verify the consistency between the numerical results and our theoretical bounds and the effectiveness of the method of early momentum for the case of non-convex loss functions.	artificial neural network;convex function;deep learning;effective method;generalization error;gradient method;heuristic;loss function;machine learning;mathematical optimization;maxima and minima;numerical analysis;second generation multiplex;stability (learning theory);stochastic gradient descent;subspace gaussian mixture model;test set	Ali Ramezani-Kebrya;Ashish Khisti;Ben Liang	2018	CoRR		mathematical optimization;gradient method;stochastic gradient descent;convex function;bounded function;mathematics;heuristic;convergence (routing);momentum;stability (learning theory)	ML	22.734822165076814	-33.01337135887878	147066
e1fc74e58178749f2ccfbac1f0738f8352b1b3c9	online symbolic-sequence prediction with discrete-time recurrent neural networks	occupation time;evaluation performance;etude temps;time study;performance evaluation;filtro kalman;maquina estado finito;estudio tiempo;real time;evaluacion prestacion;filtre kalman;kalman filter;discrete time;temps occupation;recurrent network;tiempo ocupacion;reseau neuronal recurrent;sequence prediction;systeme chaotique;recurrent neural networks;recurrent neural network;learning artificial intelligence;tiempo discreto;temps discret;extended kalman filter;machine etat fini;real time recurrent learning;finite state machine;chaotic systems;neural network;apprentissage intelligence artificielle	This paper studies the use of discrete-time recurrent neural networks for predicting the next symbol in a sequence. The focus is on online prediction, a task much harder than the classical offline grammatical inference with neural networks. The results obtained show that the performance of recurrent networks working online is acceptable when sequences come from finite-state machines or even from some chaotic sources. When predicting texts in human language, however, dynamics seem to be too complex to be correctly learned in real-time by the net. Two algorithms are considered for network training: real-time recurrent learning and the decoupled extended Kalman filter.	algorithm;artificial neural network;extended kalman filter;finite-state machine;grammar induction;neural networks;online and offline;real-time clock;real-time locating system;recurrent neural network	Juan Antonio Pérez-Ortiz;Jorge Calera-Rubio;Mikel L. Forcada	2001		10.1007/3-540-44668-0_100	simulation;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;machine learning;finite-state machine;artificial neural network	ML	18.665451899678818	-25.759248324892436	147076
a72f8c532f77a761d425824ce97ca8dddc7838b5	deep prior		The recent literature on deep learning offers new tools to learn a rich probability distribution over high dimensional data such as images or sounds. In this work we investigate the possibility of learning the prior distribution over neural network parameters using such tools. Our resulting variational Bayes algorithm generalizes well to new tasks, even when very few training examples are provided. Furthermore, this learned prior allows the model to extrapolate correctly far from a given task’s training data on a meta-dataset of periodic signals. 1 Learning a Rich Prior Bayesian Neural Networks [1, 2, 3, 4] are now scalable and can be used to estimate prediction uncertainty and model uncertainty [5]. While many efforts focus on better approximation of the posterior, we believe that the quality of the uncertainty highly depends on the choice of the prior. Hence, we consider learning a prior from previous tasks by learning a probability distribution p(w|α) over the weights w of a network, parameterized by α, and leveraging this learned prior to reduce sample complexity on new tasks. More formally we consider a hierarchical Bayes approach across N tasks, with hyper-prior p(α). Each task has its own parameters wj , withW = {wj}j=1. Using all datasets D = {Sj}j=1, we have the following posterior:1 p(W, α|D) = p(α|D) ∏ j p(wj |α, Sj) ∝ p(D|W)p(W|α)p(α) ∝ ∏	algorithm;approximation;deep learning;extrapolation;neural networks;sample complexity;scalability;variational principle	Alexandre Lacoste;Thomas Boquet;Negar Rostamzadeh;Boris N. Oreshkin;Wonchang Chung;David Krueger	2017	CoRR			ML	24.02351876006403	-30.293349724267145	147469
65abf1c70da9d6903e9ca3255382761e821c3aae	utilizing fused features to mine unknown clusters in training data	dirichlet distribution;pattern clustering;sensor fusion data mining error statistics pattern classification pattern clustering probability;investments;mine unknown cluster;probability;discrete data;classification information mine unknown cluster training data data mining technique bayesian data reduction algorithm mean field bdra fused multidimensional feature space discrete symbol probability dirichlet distribution primary metric error probability;sorting;primary metric;probability of error;bayesian methods;unknown data distribution;discrete symbol probability;unknown data distribution adaptive classification level two fusion discrete data;testing;data fusion;data mining;feature space;classification;data distribution;bayesian data reduction algorithm;data clustering;training data;symposia;mean field;classification information;target recognition;clustering;fused multidimensional feature space;multidimensional signal processing;pattern classification;adaptive classification;clustering algorithms;error statistics;error probability;data reduction;sensor fusion;signal processing algorithms;level two fusion;dimensional reduction;mean field bdra;training data investments signal processing algorithms multidimensional signal processing data mining testing target recognition bayesian methods clustering algorithms sorting;data mining technique	In this paper, a previously introduced data mining technique, utilizing the mean field Bayesian data reduction algorithm (BDRA), is extended for use in finding unknown data clusters in a fused multidimensional feature space. In the BDRA the modeling assumption is that the discrete symbol probabilities of each class are a priori uniformly Dirichlet distributed, and where the primary metric for selecting and discretizing all relevant features is an analytic formula for the probability of error conditioned on the training data. In extending the BDRA for this application, notice that its built-in dimensionality reduction aspects are exploited for isolating and automatically sorting out and mining all points contained in each unknown data cluster. To illustrate performance, results are demonstrated using simulated data containing multiple clusters, and where the fused feature space contains relevant classification information	algorithm;canonical account;cluster analysis;data mining;data point;dimensionality reduction;feature vector;sorting;test set	Robert S. Lynch;Peter Willett	2006	2006 9th International Conference on Information Fusion	10.1109/ICIF.2006.301761	machine learning;pattern recognition;data mining;mathematics	ML	15.235640919580328	-35.27844960637566	147682
e92e0ea5a40d9bbc2bfa330f421d250aa6735911	incremental on-line clustering with a topology-learning hierarchical art neural network using hyperspherical categories		Contribution: Hypersphere TopoART • Adaptive Resonance Theory (ART) neural network → capable of stable incremental learning • based on the TopoART architecture → topology learning and hierarchical clustering → insensitive to noise • learning mechanisms and representations adopted from Hypersphere ART → processing of arbitrary real-valued input → no normalisation to [0,1] required → moderate changes of the input domain possible → Euclidean similarity measures → hyperspherical categories	adaptive resonance theory;artificial neural network;cluster analysis;cognitive science;content-addressable memory;online and offline;online machine learning;taxicab geometry	Marko Tscherepanow	2012			artificial intelligence;machine learning;pattern recognition;mathematics	ML	13.222175200528177	-31.08024991027098	147690
45eeee4e13639f33b6655795ac4929732faa9352	sequential behavior and learning in evolved dynamical neural networks	learning algorithm;neural networks;dynamic systems theory;reinforcement learning;sequential behavior;dynamic neural network;genetic algorithm;network dynamics;genetic algorithms;continuous time recurrent neural network;neural network	This paper explores the use of a real-valued modular genetic algorithm to evolve continuous-time recurrent neural networks capable of sequential behavior and learning. We evolve networks that can generate a fixed sequence of outputs in response to an external trigger occurring at varying intervals of time. We also evolve networks that can learn to generate one of a set of possible sequences based upon reinforcement from the environment. Finally, we utilize concepts from dynamical systems theory to understand the operation of some of these evolved networks. A novel feature of our approach is that we assume neither an a priori discretization of states or time nor an a priori learning algorithm that explicitly modifies network parameters during learning. Rather, we merely expose dynamical neural networks to tasks that require sequential behavior and learning and allow the genetic algorithm to evolve network dynamics capable of accomplishing these tasks.	discretization;dynamical system;dynamical systems theory;genetic algorithm;neural networks;recurrent neural network	Brian Yamauchi;Randall D. Beer	1994	Adaptive Behaviour	10.1177/105971239400200301	genetic algorithm;types of artificial neural networks;wake-sleep algorithm;computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;time delay neural network;deep learning;learning classifier system;competitive learning;artificial neural network	ML	18.660667167135454	-24.002125436851127	147724
348140c16ec7bdc4a6e8b0c92690fefccb5ba1a2	high throughput computing for neural network simulation	neural network	Publisher Summary Artificial neural networks (ANNs) are densely interconnected networks of processing nodes that provide robust methods for learning real, discrete, and vectored valued functions from example training sets and have been widely applied to problems in control, prediction and pattern recognition. Processing nodes are organized into layers of input units Ni, layers of hidden units Nh and a layer of output units No. Interconnections between processing units are represented by a matrix of adjustable weight parameters W, which can be tuned by a gradient decent algorithm to learn functions presented by the training set data. However, neural network learning is computationally expensive and training can take the order of days or weeks for large training sets. Training sets for applications, such as character recognition and speech recognition can require the order of 106 training samples and 106 network parameters. This chapter discusses these computational requirements by exploiting neural network parallelism in a high throughput meta computing environment.	high-throughput computing;simulation;throughput	J. Culloty;P. Walsh	2003			parallel computing;computer science;artificial intelligence;theoretical computer science;machine learning;time delay neural network;artificial neural network;algorithm	Arch	13.786314689165186	-27.33622438670933	147759
5be926f4d6f67101c746c3826a5ea2b7b6708b32	a neural network approach for image reconstruction in electron magnetic resonance tomography	feed forward;algebraic reconstruction technique;time complexity;electron magnetic resonance tomography;iterative reconstruction;artificial neural networks;object oriented;image reconstruction;network configuration;filtered back projection;networked learning;back propagation algorithm;biological systems;electron magnetic resonance;multiplicative algebraic reconstruction technique;back propagation;artificial neural network;neural network;free radical	An object-oriented, artificial neural network (ANN) based, application system for reconstruction of two-dimensional spatial images in electron magnetic resonance (EMR) tomography is presented. The standard back propagation algorithm is utilized to train a three-layer sigmoidal feed-forward, supervised, ANN to perform the image reconstruction. The network learns the relationship between the 'ideal' images that are reconstructed using filtered back projection (FBP) technique and the corresponding projection data (sinograms). The input layer of the network is provided with a training set that contains projection data from various phantoms as well as in vivo objects, acquired from an EMR imager. Twenty five different network configurations are investigated to test the ability of the generalization of the network. The trained ANN then reconstructs two-dimensional temporal spatial images that present the distribution of free radicals in biological systems. Image reconstruction by the trained neural network shows better time complexity than the conventional iterative reconstruction algorithms such as multiplicative algebraic reconstruction technique (MART). The network is further explored for image reconstruction from 'noisy' EMR data and the results show better performance than the FBP method. The network is also tested for its ability to reconstruct from limited-angle EMR data set.	algebraic reconstruction technique;algorithm;artificial neural network;backpropagation;biological system;electron;excalibur: morgana's revenge;flow-based programming;free radicals;generalization (psychology);image sensor;imager device component;iterative method;iterative reconstruction;multitier architecture;phantoms, imaging;projections and predictions;resonance;sigmoid function;software propagation;test set;time complexity;tomography;video-in video-out	D. Christopher Durairaj;Murali C. Krishna;Ramachandran Murugesan	2007	Computers in biology and medicine	10.1016/j.compbiomed.2007.01.010	iterative reconstruction;computer vision;computer science;artificial intelligence;machine learning;artificial neural network	ML	12.649289366120483	-25.575716308867165	147766
70dc27d57c340a070fb830df1cbd68b62e57c891	towards increasing the learning speed of gradient descent method in fuzzy system	gradient descent method;learning process;oscillations;learning algorithm;fuzzy learning algorithm;gradient descent;learning speed;local minima;article;modified momentum;fuzzy system	Abstract   It is investigated in this paper that how learning algorithm of fuzzy system can be arranged by gradient descent method and how the learning speed can be increased in this method. First, the optimal range of learning speed coefficient not to be trapped in local minima and not to provide too slow learning speed is investigated. With the optimal range of learning speed coefficient, the optimal value of learning speed coefficient is suggested. With this value, the learning algorithm should not give learning oscillations and not provide too slow learning speed in any system to be approximated. Modified momentum is developed and applied to the learning scheme of gradient descent method in order to increase the learning speed. Simulation results assure that this modified momentum provides fast learning speed and also can converge to the optimal point within stable learning process without selecting the momentum coefficient arbitrarily.	fuzzy control system;gradient descent	Gee-Yong Park;Poong-Hyun Seong	1996	Fuzzy Sets and Systems	10.1016/0165-0114(95)00081-X	gradient descent;feature learning;mathematical optimization;wake-sleep algorithm;computer science;online machine learning;machine learning;control theory;mathematics;stochastic gradient descent;stability;fuzzy control system;generalization error	ML	16.135657962788873	-29.239310276321255	148067
f8b91e3eb31892c312107bdf54c9839f584ed6ec	nonlinear time series prediction weighted by marginal likelihoods: a hierarchical bayesian approach	neural networks;bayesian approach;uncertainty;marginal likelihood;bayes methods;nonlinear dynamical systems;multilayer perceptrons;distributed computing;bayesian methods;dynamic system;multilayer perceptron;time series;nonlinear time series;noise level;yttrium;predictive models;markov processes;parameter estimation;parameter estimation time series prediction marginal likelihood hierarchical bayesian algorithm nonlinear dynamical systems multilayer perceptron;bayesian methods nonlinear dynamical systems predictive models uncertainty distributed computing markov processes yttrium noise level neural networks equations;bayes methods parameter estimation time series multilayer perceptrons nonlinear dynamical systems;time series prediction;hierarchical bayesian algorithm	A nonlinear time series prediction scheme is proposed with a combination of model dynamical systems weighted by marginal likelihoods. The scheme outperforms prediction with a single model prediction with the highest marginal likelihood.	marginal model;time series	T. Matsumoto;Hideo Saito;J. Sugi	1999		10.1109/IJCNN.1999.833486	econometrics;bayesian probability;computer science;machine learning;time series;artificial neural network;statistics	ML	21.923046121449524	-25.03644942850044	148115
099d11219f524453c22adff3da81008a16642599	boltzmann machine learning using mean field theory and linear response correction	mean field theory;learning algorithm;linear response;first order;gibbs free energy;boltzmann machine;part of book or chapter of book	We present a new approximate learning algorithm for Boltzmann Machines, using a systematic expansion of the Gibbs free energy to second order in the weights. The linear response correction to the correlations is given by the Hessian of the Gibbs free energy. The computational complexity of the algorithm is cubic in the number of neurons. We compare the performance of the exact BM learning algorithm with first order (Weiss) mean field theory and second order (TAP) mean field theory. The learning task consists of a fully connected Ising spin glass model on 10 neurons. We conclude that 1) the method works well for paramagnetic problems 2) the TAP correction gives a significant improvement over the Weiss mean field theory, both for paramagnetic and spin glass problems and 3) that the inclusion of diagonal weights improves the Weiss approximation for paramagnetic problems , but not for spin glass problems.	approximation algorithm;boltzmann machine;computational complexity theory;cubic function;hessian;ising model;machine learning;quantum field theory	Hilbert J. Kappen;Francisco de Borja Rodríguez Ortiz	1997			boltzmann machine;mathematical optimization;combinatorics;gibbs free energy;computer science;mean field theory;machine learning;first-order logic;mathematics;statistics	ML	18.875093904201357	-29.468928064916607	148325
153a8174d1b417dc336369276ae89e3cd3e6d2c4	stochastic trapping in a solvable model of on-line independent component analysis	optimal solution;hebbian learning;solution optimale;on line processing;learning rate;closed form solution;learning;melangeage;simulation;matrice covariance;simulacion;punto fijo;matriz covariancia;independent component analysis;asymptotic behavior;asymptotic stability;comportement asymptotique;dynamique asymptotique;data model;fixed point;algorithme;aprendizaje;tratamiento en linea;algorithm;comportamiento asintotico;apprentissage;point fixe;solucion optima;analyse composante independante;traitement en ligne;analisis componente independiente;mixing;ica;mezclado;disordered system;fix point;asymptotic dynamics;apprentissage hebbien;covariance matrix;neural network;algoritmo	Previous analytical studies of on-line independent component analysis (ICA) learning rules have focused on asymptotic stability and efficiency. In practice, the transient stages of learning are often more significant in determining the success of an algorithm. This is demonstrated here with an analysis of a Hebbian ICA algorithm, which can find a small number of nongaussian components given data composed of a linear mixture of independent source signals. An idealized data model is considered in which the sources comprise a number of nongaussian and gaussian sources, and a solution to the dynamics is obtained in the limit where the number of gaussian sources is infinite. Previous stability results are confirmed by expanding around optimal fixed points, where a closed-form solution to the learning dynamics is obtained. However, stochastic effects are shown to stabilize otherwise unstable suboptimal fixed points. Conditions required to destabilize one such fixed point are obtained for the case of a single nongaussian component, indicating that the initial learning rate required to escape successfully is very low ( = O (N2) where N is the datadimension), resulting in very slow learning typically requiring O (N3) iterations. Simulations confirm that this picture holds for a finite system.	algorithm;computer simulation;control theory;data model;decision problem;fixed point (mathematics);fixed-point number;hebbian theory;independent computing architecture;independent component analysis;iteration;normal statistical distribution;online and offline;rule (guideline);stochastic process;unstable medical device problem	Magnus Rattray	2002	Neural Computation	10.1162/08997660252741185	independent component analysis;covariance matrix;closed-form expression;combinatorics;asymptotic analysis;hebbian theory;data model;computer science;machine learning;calculus;mathematics;fixed point;mixing;artificial neural network;algorithm;statistics	ML	20.226389853009366	-27.796978155058977	148422
1b850423fb552a357aac187ec2373aec0e9bf544	self-enhancement learning: self-supervised and target-creating learning	quantization;gaussian processes;data mining;firing;artificial neural networks;neural networks neurons temperature machine learning entropy cooling learning systems iris semisupervised learning probability;self organising feature maps gaussian processes learning artificial intelligence;learning methods;gaussian width;self organising feature maps;self supervised learning;relaxed state;relaxed state self enhancement learning self supervised learning target creating learning gaussian width som;entropy;som;neurons;neural network model;learning artificial intelligence;iris;self enhancement learning;target creating learning	In this paper, we propose a new learning method called “self-enhancement learning.” In this model, a network enhances its state by itself, and this enhanced state is to be imitated by another state of the network. The word “target” in our model means that a target is created spontaneously by a network, which must try to attain the target. Enhancement is realized by changing the Gaussian width or enhancement parameter. With different enhancement parameters, we can set up the different states of a network. In particular, we set up an enhanced and a relaxed state, and the relaxed state tries to imitate the enhanced state as much as possible. To demonstrate the effectiveness of this method, we apply the self-enhancement learning to the SOM. For this purpose, we introduce collectiveness into an enhanced state in which all neurons collectively respond to input patterns. Then, this enhanced and collective state should be imitated by the other non-enhanced and relaxed state. We applied the method to the Iris problem. Experimental results showed that the U-matrices obtained were significantly similar to those produced by the conventional SOM. However, much better performance could be obtained in terms of quantitative and topological errors. The experimental results suggest the possibility for the self-enhancement learning to be applied to many different neural network models.		Ryotaro Kamimura	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178677	entropy;quantization;computer science;artificial intelligence;machine learning;pattern recognition;gaussian process;artificial neural network	ML	16.253436767660748	-31.816614599838356	148542
1fe13e6930bc187f00fd635a3caeee8207e5b42f	asymptotic learnability of reinforcement problems with arbitrary dependence	processus melangeant;modelizacion;approximation asymptotique;mixing condition;recompense;proceso mezclante;proceso markov;operating conditions;reinforcement learning;keywords asymptotic stability;decision markov;intelligence artificielle;probabilistic approach;optimal policy;conference paper;modelisation;learning systems;recompensa;reward;mixing process;intelligent agents;apprentissage renforce;condition operatoire;enfoque probabilista;approche probabiliste;processus markov;decision theory;markov process;artificial intelligence;markov decision;inteligencia artificial;asymptotic approximation;markov processes;markov decision process;aprendizaje reforzado;condicion operatoria;modeling;asymptotic learnability;problem solving;aproximacion asintotica;markov decision processes mdp	We address the problem of reinforcement learning in which observations may exhibit an arbitrary form of stochastic dependence on past observations and actions. The task for an agent is to attain the best possible asymptotic reward where the true generating environment is unknown but belongs to a known countable family of environments. We find some sufficient conditions on the class of environments under which an agent exists which attains the best asymptotic reward for any environment in the class. We analyze how tight these conditions are and how they relate to different probabilistic assumptions known in reinforcement learning and related fields, such as Markov Decision Processes and mixing conditions.	asymptote;learnability;markov chain;markov decision process;mixing (mathematics);reinforcement learning	Daniil Ryabko;Marcus Hutter	2006		10.1007/11894841_27	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;markov process;reinforcement learning;statistics	ML	20.65524544188123	-27.307602205039277	148607
8ec31717f781874b48729410e61034580858802b	application of self-organisation neural network for direct shape from shading	rate of convergence;shape from shading;integrated circuit;shape reconstruction;neural network	In this paper, a supervised self-organisation Neural Network (NN) for direct shape from shading is developed. The structure of the NN for the inclined light source model is derived based on the maximum uphill direct shape from shading approach. The major advantage of the NN model presented is the parallel learning or weight evolution for the direct shading. Here the proved convergent learning rule, the rate of convergence and a zero initialisation condition are shown. To increase the rate of convergence, the momentum factor is introduced. Furthermore, the application of the network on IC (Integrated Circuit) component shape reconstruction is presented.	artificial neural network;integrated circuit;learning rule;open-source software;photometric stereo;rate of convergence;self-organization;shading	W. P. Cheung;C. K. Lee	2001	Neural Computing & Applications	10.1007/s521-001-8049-5	computer vision;photometric stereo;computer science;integrated circuit;machine learning;rate of convergence;artificial neural network	ML	13.841875229786169	-28.023416074072003	148715
575c689cea8cefa7d2d1857c143854dbe6f18108	the complexity of language recognition by neural networks	power series;learning;non commutative;complexity;upper bound;automata;grammars;grammatical inference;counters;recurrent neural network;languages;neural network	Neural networks are frequently used as adaptive classifiers. This research represents an attempt to measure the “neural complexity” of any regular set of binary strings, that is, to quantify the size of a recurrent continuous-valued neural network that is needed for correctly classifying the given regular set. Our estimate provides a predictor that is superior to the size of the minimal automaton that was used as an upper bound so far. Moreover, it is easily computable, using techniques from the theory of rational power series in non-commuting variables.	language identification;neural networks	Hava T. Siegelmann;Eduardo D. Sontag;C. Lee Giles	1992	Neurocomputing	10.1016/S0925-2312(97)00015-5	feedforward neural network;discrete mathematics;complexity;types of artificial neural networks;computer science;recurrent neural network;machine learning;time delay neural network;mathematics;automaton;deep learning;upper and lower bounds;power series;artificial neural network;algorithm	NLP	17.809433103381213	-29.713396999535703	148856
f716380fd7b1f20ae355dd490cb0db44bb5ef340	novel second-order techniques and global optimisation methods for supervised training of multi-layer perceptrons			global optimization;mathematical optimization;multilayer perceptron;supervised learning	Adrian J. Shepherd	1995				Vision	13.545058244386459	-28.165487253504992	149065
302066c22612807d584ca328ab8f4f970b7fa579	approximation of functions by gaussian rbf networks with bouded number of hidden units			linear approximation;radial basis function	Vera Kurková	1995			artificial intelligence;machine learning;pattern recognition;gaussian;computer science	ML	14.2949255331839	-28.24077524347673	149159
296908adebc82f59c04775c17b521a0c5442dcc0	statistical modelling of artificial neural networks using the multi-layer perceptron	object recognition;fisher scoring algorithm;hierarchical mixture of experts;statistical modelling;robert foxall;eprints newcastle university;computational science and engineering;process monitoring;emeritus professor murray aitkin;open access;multi layer perceptron;em algorithm;artificial neural network	Multi-layer perceptrons (MLPs), a common type of artificial neural networks (ANNs), are widely used in computer science and engineering for object recognition, discrimination and classification, and have more recently found use in process monitoring and control. “Training” such networks is not a straightforward optimisation problem, and we examine features of these networks which contribute to the optimisation difficulty.#R##N##R##N#Although the original “perceptron”, developed in the late 1950s (Rosenblatt 1958, Widrow and Hoff 1960), had a binary output from each “node”, this was not compatible with back-propagation and similar training methods for the MLP. Hence the output of each node (and the final network output) was made a differentiable function of the network inputs. We reformulate the MLP model with the original perceptron in mind so that each node in the “hidden layers” can be considered as a latent (that is, unobserved) Bernoulli random variable. This maintains the property of binary output from the nodes, and with an imposed logistic regression of the hidden layer nodes on the inputs, the expected output of our model is identical to the MLP output with a logistic sigmoid activation function (for the case of one hidden layer).#R##N##R##N#We examine the usual MLP objective function—the sum of squares—and show its multi-modal form and the corresponding optimisation difficulty. We also construct the likelihood for the reformulated latent variable model and maximise it by standard finite mixture ML methods using an EM algorithm, which provides stable ML estimates from random starting positions without the need for regularisation or cross-validation. Over-fitting of the number of nodes does not affect this stability. This algorithm is closely related to the EM algorithm of Jordan and Jacobs (1994) for the Mixture of Experts model.#R##N##R##N#We conclude with some general comments on the relation between the MLP and latent variable models.	artificial neural network;layer (electronics);multilayer perceptron	Murray Aitkin;Rob Foxall	2003	Statistics and Computing	10.1023/A:1024218716736	statistical model;expectation–maximization algorithm;computer science;artificial intelligence;computational science and engineering;cognitive neuroscience of visual object recognition;machine learning;data mining;mathematics;multilayer perceptron;activation function;artificial neural network;statistics	AI	17.850247316641347	-31.148407938567182	149339
2fe9c9077fb20d5f82ab90a4267bf1af2dda38ee	application of support vector machine in queuing system	queuing system;support vector regression;machine learning;statistical learning theory;probability distribution;support vector machine;density functional	  The solution to performances of queuing system is based on knowing the distributions of customers arrival or service time.  Support vector machine (SVM) based on statistical learning theory has been used generally in machine learning because of its  good generalization ability. By using SVM we can classify and identity some probability distributions appeared in queuing  system and solve the density function regression problem through using support vector regression (SVR). Some other problems  needed to be solved are formulated in the end.    	support vector machine	Gensheng Hu;Feiqi Deng	2004		10.1007/978-3-540-28647-9_94	margin classifier;support vector machine;least squares support vector machine;kernel method;computer science;theoretical computer science;online machine learning;machine learning;pattern recognition;relevance vector machine;computational learning theory;active learning;structured support vector machine	ML	19.70293330724238	-34.63597779706631	149403
0e28768f1590d6c7dc08078c5aed7c38916e6876	training error, generalization error and learning curves in neural learning	minimisation;gaussian noise;stochastic resonance;network parameters;feedforward neural networks;model selection;generalization error;neural networks;fluctuations;overtraining problem;neural nets;learning curve;information criterion;probability distribution least squares methods fluctuations feeds neural networks feedforward neural networks stochastic processes stochastic resonance gaussian noise covariance matrix;training error;feeds;minimisation neural nets learning artificial intelligence generalisation artificial intelligence;regularization terms training error generalization error learning curves neural learning neural network network parameters statistical fluctuation universal asymptotic evaluation model selection information criterion overtraining problem minimum training error learning method cross validated early stopping;regularization terms;minimum training error learning method;statistical fluctuation;stochastic processes;probability distribution;universal asymptotic evaluation;generalisation artificial intelligence;learning artificial intelligence;neural learning;learning curves;least squares methods;overtraining;covariance matrix;cross validated early stopping;neural network	A ,neural ‘nM?tUJOrk is tro.in,ed by using CL set of ~Z’lJaib nble exn.m,ples to minimize the twining error sv.ch th,nt the network pnra,meters ,fit the eznmples well. However, it is desired to min.imize the generalization error to which no direct access is possible. There are discrepa,ncies between the training error an.d the gen,eralization error due to th,e statistical fluctuation of exnmples. The prese,nt talk focusses on this problem! from th,e statistical point of view. When th,e number of tr,ining exa,mSples is large, we hnve a urzieersal asym,ptotic ewalua,tion on, the discrepclncies of th,e two errors. This can be u,sed for model selection based on the infor,mation criterionb Wh.en th,e nu,mber of training exam.pies is smnll. their discrepancies are big, ca.using a seriou.s oueyfitting or orrertmi,nin,g problem,. We annlyze th,is phenom,enon by usin,g a, simple m,odel. It is s’urprisin,g tha.t the genernlizntion error even increases as the number o,f exa,m,ples kcreases in a certain range. This shows th,e in,a.dequ.acy of the minimum tminGng error 1earnin.g m.ethod. We eva,luate various means overcoming th,e overtrain,in,g such as cross-valida,ted early stopping o,f tmining, introdwtion of th.e regulnrizntion terms, model selection, and oth,ers. Let N(w) 1~ a multilayer feed forward neural net,work which is specified by a modifiable parameter vect,or w. The network is t,rained by a number of examples in t,he t,raining set, Dj = {(al, %I),. . . , (zt, %,)I, where 2; is the input and d; is t,lie corresponding output of t,lie ith example. Learning is a sequential procedure t,o search for W which fit,s t,lie examples well. This can be att,ained by minimizing the training error et,raill(W) = f $l(zi,%i.; W) t=l where l(z;, zj,; w) is t,lir error or loss function whose typical case is the least square error l(z;,%&W) = ;I% f(z,w)12 in terms of the output f(z, w) of the network S(w). However, learning is necessary for processing future examples, so that it is desired to minimize the generalization error egf3l(w) = E[l(z, %; w>l, where the expectation is taken over the possible future examples. To minimize the generalization error is clifferent from to minimize the training error cvcn when the training examples and future examples are snhject to the same probability distribution. To analyze their discrepancy, we use the stochastic srtting such that input z is generated randomly from a fixed (but unknown) probability distribution q(z) and tllat the behavior of network N(w) is stochastic, t,hc nut.put z being randomly generated from the conditional distribution ~I(z~z; w). When z is a noisy version of the output f(z, w), we have	artificial neural network;discrepancy function;exa;early stopping;generalization error;loss function;model selection;point of view (computer hardware company);procedural generation;random access;randomness;sed;universal conductance fluctuations	Shun-ichi Amari	1995		10.1109/ANNES.1995.499426	early stopping;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;supervised learning;learning curve;artificial neural network;statistics;generalization error	ML	17.849533977291415	-30.72114093926543	149844
6964c0789f1adaecbc0ae78398dd9e1dc3a4be5c	improving information-theoretic competitive learning by accentuated information maximization	r th power;computational method;information content;competitive learning;data analysis;mutual information maximization;mutual information;winner take all;information theoretic;accentuated information maximization	In this paper, we propose a new computational method for information-theoretic competitive learning. We have so far developed information-theoretic methods for competitive learning in which competitive processes can be simulated by maximizing mutual information between input patterns and competitive units. Though the methods have shown good performance, networks have had difficulty in increasing information content, and learning is very slow to attain reasonably high information. To overcome the shortcoming, we introduce the rth power of competitive unit activations used to accentuate actual competitive unit activations. Because of this accentuation, we call the new computational method “accentuated information maximization”. In this method, intermediate values are pushed toward extreme activation values, and we have a high possibility to maximize information content. We applied our method to a vowel–consonant classification problem in which connection weights obtained by our methods were similar to those obtained by standard competitive learning. The second experiment was to discover some features in a dipole problem. In this problem, we showed that as the parameter r increased, less clear representations could be obtained. For the third experiment of economic data analysis, much clearer representations were obtained by our method, compared with those obtained by the standard competitive learning method.	competitive learning;computation;conscience;entropy maximization;euclidean distance;expectation–maximization algorithm;information theory;mutual information;self-information;supervised learning;unsupervised learning;value (computer science)	Ryotaro Kamimura	2005	Int. J. General Systems	10.1080/03081070500065759	winner-take-all;simulation;self-information;computer science;artificial intelligence;machine learning;mathematics;mutual information;competitive learning;data analysis;interaction information;statistics	ML	15.613952787807996	-32.309102161415055	149851
22dc9ed6cdf00d45122aabb89d6b93a5cd2d6396	a hybrid system for probability estimation in multiclass problems combining svms and neural networks	artificial neural networks classification algorithms support vector machines estimation feature extraction neurons complexity theory;one vs all reduction;complexity theory;probability;cost function;support vector machines;neural nets;data mining;support vector;multiclass probability estimation;entropy cost function;artificial neural networks;softmax transfer function;estimation;transfer function;feature extraction;classification algorithms;support vector machines data mining entropy neural nets pattern classification probability;pattern classification;hybrid system;class membership;svm;entropy;neurons;support vector machine;multiclass classification task;multiclass problem;multiclass classification;multiclass classification artificial neural networks support vector machines multiclass probability estimation;artificial neural network;neural network;multiclass probability estimation hybrid system multiclass problem svm neural network multiclass classification task data mining support vector machine one vs all reduction entropy cost function softmax transfer function class membership	This paper addresses the problem of probability estimation in multiclass classification tasks combining two well known data mining techniques: support vector machines and neural networks. We present an algorithm which uses both techniques in a two-step procedure. The first step employs support vector machines within a one-vs-all reduction from multiclass to binary approach to obtain the distances between each observation and the support vectors representing the classes. The second step uses these distances as inputs for a neural network, built with an entropy cost function and softmax transfer function for the output layer where class membership is used for training. Consequently, this network estimates probabilities of class membership for new observations. A benchmark using different databases demonstrates that the proposed algorithm is highly competitive with the most recent techniques for multiclass probability estimation.	algorithm;artificial neural network;benchmark (computing);data mining;database;estimation theory;hybrid system;loss function;multiclass classification;softmax function;support vector machine;transfer function	Cristián Bravo;Jose Luis Lobato;Richard Weber;Gaston L'Huillier	2008	2008 Eighth International Conference on Hybrid Intelligent Systems	10.1109/HIS.2008.112	computer science;machine learning;multiclass classification;pattern recognition;data mining	ML	13.55951116333626	-35.485907382080896	149859
063e95e1657feaf4c421d5b01ae8ae7c1e80494f	efficient second order online learning via sketching		We propose Sketched Online Newton (SON), an online second order learning algorithm that enjoys substantially improved regret guarantees for ill-conditioned data. SON is an enhanced version of the Online Newton Step, which, via sketching techniques enjoys a running time linear in the dimension and sketch size. We further develop sparse forms of the sketching methods (such as Oja’s rule), making the computation linear in the sparsity of features. Together, the algorithm eliminates all computational obstacles in previous second order online learning approaches.	algorithm;computation;condition number;erkki oja;newton;newton's method;oja's rule;sparse matrix;time complexity	Haipeng Luo;Alekh Agarwal;Nicolò Cesa-Bianchi;John Langford	2016				ML	24.199704774379075	-34.671944698699626	149950
e6747e093098550234f3293393e6b0ed3d41404e	advancing gradient base neural network training			artificial neural network;gradient	Jennie Si;Guian Zhou	1999	Neural Parallel & Scientific Comp.		artificial neural network;machine learning;artificial intelligence;computer science	ML	13.167347599166694	-27.68417450058654	150120
607af1984795e489e13ac6f3b5ad87f0e580765a	2d neural hardware versus 3d biological ones	silicon;general and miscellaneous mathematics computing and information science;neural networks;accuracy;dimensions;neural net;optical interconnect;artificial neural net;hardware implementation;99 general and miscellaneous mathematics computing and information science;neural network;nerve cells	This paper will present important limitations of hardware neural nets as opposed to biological neural nets (i.e. the real ones). The author starts by discussing neural structures and their biological inspirations, while mentioning the simplifications leading to artificial neural nets. Going further, the focus will be on hardware constraints. The author will present recent results for three different alternatives of implementing neural networks: digital, threshold gate, and analog, while the area and the delay will be related to neurons' fan-in and weights' precision. Based on all of these, it will be shown why hardware implementations cannot cope with their biological inspiration with respect to their power of computation: the mapping onto silicon lacking the third dimension of biological nets. This translates into reduced fan-in, and leads to reduced precision. The main conclusion is that one is faced with the following alternatives: (1) try to cope with the limitations imposed by silicon, by speeding up the computation of the elementary silicon neurons; (2) investigate solutions which would allow one to use the third dimension, e.g. using optical interconnections.		Valeriu Beiu	1998			nervous system network models;mathematical optimization;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;accuracy and precision;silicon;dimension;artificial neural network;algorithm	NLP	15.006429682221613	-25.991361265107344	150140
3f6d9c7aba13b64baedfa7485782444050d58cd7	fnn (feedforward neural network) training method based on robust recursive least square method	recursive least square;feedforward neural network;feed forward neural network;computer simulation	We present a robust recursive least squares algorithm for multilayer feed-forward neural network training. So far, recursive least squares (RLS) has been successfully applied to training multilayer feed-forward neural networks. However, RLS method has a tendency to become diverse due to the instability in the recursive inversion procedure. In this paper, we propose a numerically robust recursive least square type algorithm using prewhitening. The proposed algorithm improves the performance of RLS in infinite numerical precision as well as in finite numerical precision. The computer simulation results in the various precision cases show that the proposed algorithm improves the numerical robustness of RLS training.	feedforward neural network;recursion (computer science);recursive least squares filter	Jun-Seok Lim;Koeng-Mo Sung	2007		10.1007/978-3-540-72393-6_48	computer simulation;feedforward neural network;computer science;machine learning;control theory;recursive least squares filter	ML	16.11604675296144	-28.951380495778768	150159
5115f3ff1ac45486a50ad3834a40490f9ca4bcea	on the number of linear regions of deep neural networks	input space partition;rectifier;maxout;deep learning;neural network	We study the complexity of functions computable by deep feedforward neural networks with piecewise linear activations in terms of the symmetries and the number of linear regions that they have. Deep networks are able to sequentially map portions of each layer’s input-space to the same output. In this way, deep models compute functions that react equally to complicated patterns of different inputs. The compositional structure of these functions enables them to re-use pieces of computation exponentially often in terms of the network’s depth. This paper investigates the complexity of such compositional maps and contributes new theoretical results regarding the advantage of depth for neural networks with piecewise linear activation functions. In particular, our analysis is not specific to a single family of models, and as an example, we employ it for rectifier and maxout networks. We improve complexity bounds from pre-existing work and investigate the behavior of units in higher layers.	activation function;artificial neural network;computable function;computation;convolution;convolutional neural network;deep learning;feedforward neural network;linear logic;machine learning;map;microsoft outlook for mac;neural network software;piecewise linear continuation;rectifier (neural networks);recursion;time complexity;voronoi diagram	Guido Montúfar;Razvan Pascanu;Kyunghyun Cho;Yoshua Bengio	2014			mathematical optimization;discrete mathematics;computer science;machine learning;mathematics;deep learning;rectifier;artificial neural network	ML	18.10934723046127	-29.869351603979972	150208
7d588a996cbfa41066ecf264a99cde027831c805	two-sided exponential concentration bounds for bayes error rate and shannon entropy		We provide a method that approximates the Bayes error rate and the Shannon entropy with high probability. The Bayes error rate approximation makes possible to build a classifier that polynomially approaches Bayes error rate. The Shannon entropy approximation provides provable performance guarantees for learning trees and Bayesian networks from continuous variables. Our results rely on some reasonable regularity conditions of the unknown probability distributions, and apply to bounded as well as unbounded variables.	approximation;bayesian network;entropy (information theory);provable security;shannon (unit);with high probability	Jean Honorio;Tommi S. Jaakkola	2013			entropy power inequality;econometrics;shannon's source coding theorem;rényi entropy;transfer entropy;pattern recognition;min entropy;statistics	ML	21.034134748084938	-31.114208823997885	150236
ecf9cf8faafb78e4f91823920c799a61880b466a	on a novel unsupervised competitive learning algorithm for scalar quantization	unsupervised learning;univariate probability density functions unsupervised competitive learning algorithm scalar quantization boundary adaptation rule equiprobable quantizations;nearest neighbor searches;quantization;image recognition;boundary adaptation rule;learning algorithm;probability;neural networks;neural nets;image converters;funcion densidad probabilidad;probability density function;probability neural nets unsupervised learning;speech coding;algorithme apprentissage;quantification;data communication;unsupervised competitive learning algorithm;competitive learning;fonction densite probabilite;reseaux neuronaux;quantization neurons nearest neighbor searches probability density function image converters image recognition speech recognition speech coding statistical analysis data communication;scalar quantization;statistical analysis;quantification scalaire;speech recognition;equiprobable quantizations;neurons;adaptive pattern classification;univariate probability density functions	This letter presents a novel unsupervised competitive learning rule called the boundary adaptation rule (BAR), for scalar quantization. It is shown both mathematically and by simulations that BAR converges to equiprobable quantizations of univariate probability density functions and that, in this way, it outperforms other unsupervised competitive learning rules.	acclimatization;algorithm;competitive learning;learning rule;quantization (signal processing);rule (guideline);simulation;unsupervised learning	Marc M. Van Hulle;Dominique Martinez	1994	IEEE transactions on neural networks	10.1109/72.286923	unsupervised learning;probability density function;speech recognition;quantization;computer science;machine learning;speech coding;pattern recognition;probability;mathematics;competitive learning;artificial neural network;statistics	ML	13.011580585051899	-32.01246253403333	150341
2482c75aa4b919bba0963e2f42948341d169f021	non-stochastic best arm identification and hyperparameter optimization		Motivated by the task of hyperparameter optimization, we introduce the non-stochastic bestarm identification problem. Within the multiarmed bandit literature, the cumulative regret objective enjoys algorithms and analyses for both the non-stochastic and stochastic settings while to the best of our knowledge, the best-arm identification framework has only been considered in the stochastic setting. We introduce the nonstochastic setting under this framework, identify a known algorithm that is well-suited for this setting, and analyze its behavior. Next, by leveraging the iterative nature of standard machine learning algorithms, we cast hyperparameter optimization as an instance of non-stochastic bestarm identification, and empirically evaluate our proposed algorithm on this task. Our empirical results show that, by allocating more resources to promising hyperparameter settings, we typically achieve comparable test accuracies an order of magnitude faster than baseline methods.		Kevin G. Jamieson;Ameet S. Talwalkar	2016			mathematical optimization;computer science;machine learning;pattern recognition;hyperparameter optimization;statistics	AI	24.400228282300244	-32.4077496043114	150695
ed5d7ae46bd58b93ebba722d10fb956685679bcc	a new method of dynamic latent-variable modeling for process monitoring	subspace identification method contribution plots dynamic latent variable model dynamic principal component analysis process monitoring and fault diagnosis;journal;vectors;monitoring;heuristic algorithms;principal component analysis;期刊论文;fault detection;correlation;principal component analysis heuristic algorithms monitoring correlation data models vectors fault detection;data models	Dynamic principal component analysis (DPCA) is widely used in the monitoring of dynamic multivariate processes. In traditional DPCA where a time window is used, the dynamic relations among process variables are implicit and difficult to interpret in terms of variables. To extract explicit latent variables that are dynamically correlated, a dynamic latent-variable model is proposed in this paper. The new structure can improve the modeling and the interpretation of dynamic processes and enhance the performance of monitoring. Fault detection strategies are developed, and contribution analysis is available for the proposed model. The case study on the Tennessee Eastman Process is used to illustrate the effectiveness of the proposed methods.	algorithm;autoregressive model;dlv;fault detection and isolation;iteration;latent variable model;mathematical optimization;principal component analysis;sensor;monotone	Gang Li;S. Joe Qin;Donghua Zhou	2014	IEEE Transactions on Industrial Electronics	10.1109/TIE.2014.2301761	data modeling;econometrics;computer science;machine learning;pattern recognition;mathematics;correlation;fault detection and isolation;statistics;principal component analysis	SE	23.58950191800587	-24.108946722211062	150717
2d6cea103467d6df6a4774d4cd2b739133b62bdd	adjoint-functions and temporal learning algorithms in neural networks	learning algorithm;neural network	The development of learning algorithms is generally based upon the minimization of an energy function. It is a fundamental requirement to compute the gradient of this energy function with respect to the various parameters of the neural architecture, e.g., synaptic weights, neural gain,etc. In principle, this requires solving a system of nonlinear equations for each parameter of the model, which is computationally very expensive. A new methodology for neural learning of time-dependent nonlinear mappings is presented. It exploits the concept of adjoint operators to enable a fast global computation of the network's response to perturbations in all the systems parameters. The importance of the time boundary conditions of the adjoint functions is discussed. An algorithm is presented in which the adjoint sensitivity equations are solved simultaneously (Le., forward in time) along with the nonlinear dynamics of the neural networks. This methodology makes real-time applications and hardware implementation of temporal learning feasible.	algorithm;artificial neural network;computation;gradient;machine learning;mathematical optimization;neural network software;nonlinear system;perturbation theory;real-time clock;synaptic package manager;synaptic weight;temporal logic	Nikzad Benny Toomarian;Jacob Barhen	1990			mathematical optimization;types of artificial neural networks;wake-sleep algorithm;computer science;artificial intelligence;recurrent neural network;machine learning;mathematics;deep learning;artificial neural network	ML	17.73668997791705	-25.31159370602974	150821
b899c67061db068f257ac9ca32a1246fd0b6f831	probabilistic evolving spiking neural network optimization using dynamic quantum-inspired particle swarm optimization		This paper proposes a novel Probabilistic Evolving Spiking Neural Network (PESNN) based on Kasabov’s#N# Probabilistic Neuron Model. The features, connections and parameters are optimized using Dynamic Quantum-#N#inspired Particle Swarm Optimization (DQiPSO). The features and connections are modeled as a quantum bit vector#N# while the parameter values are presented as real numbers. An improved search strategy is also being introduced to#N# probe the most relevant features and eliminate irrelevant ones. The proposed method is evaluated using a synthetic#N# dataset for classification problems. The results show that the proposed method is promising, with better accuracy and#N# capability to identify the most significant features while obtaining the best combination of PESNN’s connections and#N# parameters.	particle swarm optimization;program optimization;quantum;spiking neural network	Haza Nuzly Abdul Hamed;Nikola K. Kasabov;Siti Mariyam Hj. Shamsuddin	2010	Austr. J. Intelligent Information Processing Systems		multi-swarm optimization;computer science;artificial intelligence;machine learning;data mining	ML	14.27318534324908	-25.588525837614995	150964
20cd6677d30d28b3081f5d82c0d6640518468ec0	the cost of fairness in classification		We study the problem of learning classifiers with a fairness constraint, with three main contributions towards the goal of quantifying the problem’s inherent tradeoffs. First, we relate two existing fairness measures to cost-sensitive risks. Second, we show that for cost-sensitive classification and fairness measures, the optimal classifier is an instance-dependent thresholding of the class-probability function. Third, we show how the tradeoff between accuracy and fairness is determined by the alignment between the class-probabilities for the target and sensitive features. Underpinning our analysis is a general framework that casts the problem of learning with a fairness requirement as one of minimising the difference of two statistical risks.	fairness measure;thresholding (image processing);type conversion	Aditya Krishna Menon;Robert C. Williamson	2017	CoRR		fairness measure;max-min fairness	ML	19.019776253356746	-35.47705067967023	151232
1ff4f1eaeebfb1c858a8e84601dc47d580bca9d4	error weighting in artificial neural networks learning interpreted as a metaplasticity model	backpropagation training algorithm;metaplasticity;neural networks;network performance;mean error;multilayer perceptron;backpropagation;objective function;it value;learning methods;binary detection;training algorithm;artificial neural network;neural network	Many Artificial Neural Networks design algorithms or learning methods imply the minimization of an error objective function. During learning, weight values are updated following a strategy that tends to minimize the final mean error in the Network performance. Weight values are classically seen as a representation of the synaptic weights in biological neurons and their ability to change its value could be interpreted as artificial plasticity inspired by this biological property of neurons. In such a way, metaplasticity is interpreted in this paper as the ability to change the efficiency of artificial plasticity giving more relevance to weight updating of less frequent activations and resting relevance to frequent ones. Modeling this interpretation in the training phase, the hypothesis of an improved training is tested in the Multilayer Perceptron with Backpropagation case. The results show a much more efficient training maintaining the Artificial Neural Network performance.	artificial neural network	Diego Andina;Aleksandar Jevtic;Alexis Marcano-Cedeño;J. Miguel Barrón-Adame	2007		10.1007/978-3-540-73053-8_24	stochastic neural network;catastrophic interference;feedforward neural network;types of artificial neural networks;delta rule;computer science;artificial intelligence;backpropagation;machine learning;pattern recognition;physical neural network;time delay neural network;mean squared error;deep learning;metaplasticity;multilayer perceptron;network performance;artificial neural network	ML	15.96880697487825	-30.081274537304488	151259
7dfac646bcacce4d4b6ef0bd916a6b2314740162	"""correction to """"partial simultaneous updating in hopfield memories"""""""	high dimensionality;linear functionals;symmetric matrices;robot control;linear matrix inequalities;neural network	a simple one. It happened that both were chosen to be linear functions and the resulting DTNNSuIOF is presented in Fig. 2. For the researchers from the robot control field it might be amusing to look at this totally linear (delay element is irrelevant) DTNNSuIOF as a proposal for the robot control. Precision of the order O(10 10) in the training is guaranteed. (See the paper.) The appearance of the constant gains equaling 50 is also an intriguing one. The matrices L andD were not given in this example. Therefore, there is no comment on this part. At this point without any additional information, we may say that the whole algorithm failed. DTNNSuIOF cannot generalize. This is the real curse for any NN indeed. The author personally admitted that but, understandably, he put it much more softly: “ The high accuracy of the testing results does not guarantee the high stage of neural network robustness, which will be investigated and discussed in the next paper. ” Few basic remarks are needed here. In the world of NN, both the test, i.e., validation phase and generalization properties are defined in terms of previously unseen inputs. However, there are no test results in the paper at all. The highly accurate results presented in Fig. 5 of the paper are the outputs of the DTNNSuIOF on training inputs. The fact that the very error during the training is of the order O(10 ) does not say anything about the generalization properties of NN. In the NN field, the stories about the overtrained NN having high variance and low bias are very well known. (Here, the bias 0!) Let us paraphrase the author correctly—it is highly likely that the high accuracy of testing results does guarantee the high stage of neural network robustness, which does not have to be investigated and discussed in the next paper. One thing is obvious, the whole algorithm relies on and believes in overwhelming power of the ( pseudo) inversion operation. The accuracy in training phase presented in the paper shows merely the accuracy of the supporting software in calculation of a matrix pseudo inverse. In highly nonlinear, high-dimensional and noisy environment, DTNNSuIOF approach as given in the paper cannot result with any useful NN design algorithm.	artificial neural network;biological neural networks;chylomicron retention disease;generalization (psychology);hopfield network;hospital admission;linear function;memory, episodic;nonlinear system;occur (action);pseudo brand of pseudoephedrine;published comment;relevance;robot control;robustness of complex networks;sample variance;algorithm	Bruno Cernuschi-Frías	2000	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/TSMCB.2000.826969	mathematical optimization;computer science;artificial intelligence;machine learning;control theory;mathematics;robot control;artificial neural network;algorithm;statistics;symmetric matrix	Robotics	16.817202061609038	-31.040197106122495	151279
875211d6527da1a07bd426ae8f77f4ad7f2f265e	gans for sequences of discrete elements with the gumbel-softmax distribution		Generative Adversarial Networks (GAN) have limitations when the goal is to generate sequences of discrete elements. The reason for this is that samples from a distribution on discrete objects such as the multinomial are not differentiable with respect to the distribution parameters. This problem can be avoided by using the Gumbel-softmax distribution, which is a continuous approximation to a multinomial distribution parameterized in terms of the softmax function. In this work, we evaluate the performance of GANs based on recurrent neural networks with Gumbel-softmax output distributions in the task of generating sequences of discrete elements.	approximation;artificial neural network;generative adversarial networks;multinomial logistic regression;recurrent neural network;softmax function	Matt J. Kusner;José Miguel Hernández-Lobato	2016	CoRR		mathematical optimization;combinatorics;discrete mathematics;categorical distribution;mathematics;statistics	ML	24.192840865078235	-30.400482294869825	151457
d5edf2af4c37d47ccaf3281a3d7102edb1d1495f	para-active learning		Training examples are not all equally informative. Active learning strategies leverage this observation in order to massively reduce the number of examples that need to be labeled. We leverage the same observation to build a generic strategy for parallelizing learning algorithms. This strategy is effective because the search for informative examples is highly parallelizable and because we show that its performance does not deteriorate when the sifting process relies on a slightly outdated model. Parallel active learning is particularly attractive to train nonlinear models with non-linear representations because there are few practical parallel learning algorithms for such models. We report preliminary experiments using both kernel SVMs and SGD-trained neural networks.	active learning (machine learning);algorithm;artificial neural network;experiment;information;machine learning;merge sort;nonlinear system;parallel computing;support vector machine	Alekh Agarwal;Léon Bottou;Miroslav Dudík;John Langford	2013	CoRR		semi-supervised learning;simulation;computer science;artificial intelligence;machine learning	ML	19.704325390008982	-38.00108881812248	151473
9fc36e3151d8ec7f4465b5bd4a38bb5b68ed1bc1	neuro-resistive grid approach to trainable controllers: a pole balancing example	learning control;learning algorithm;nonlinear control;algorithme apprentissage;pendulo;dynamical system;systeme dynamique;control problem;reinforce ment learning;inverted pendulum;pendule;sistema dinamico;reseau neuronal;algoritmo aprendizaje;red neuronal;pendulum;neural network	A new neural network approach is described for the task of pole-balancing, considered a benchmark learning control problem. This approach combines Barto, Sutton and Anderson's [1] Associative Search Element (ASE) with a Neuro-Resistive Grid (NRG) [2] acting as Adaptive Critic Element (ACE). The novel feature in NRG is that it provides evaluation of a state based on propagation of the failure information to the neighbours in the grid. NRG is updated only on a failure, and provides ASE with a continuous internal reinforcement signal by comparing the value of the present state to the previous state. The resulting system learns more rapidly and with fewer computations than that of Barto et al.[1]. To establish a uniform basis of comparison of algorithms for pole balancing, both the systems are simulated using benchmark parameters and tests specified in Geva and Sitte [3].	ace;adaptive server enterprise;algorithm;andrew barto;artificial neural network;bellman equation;benchmark (computing);computation;dynamic programming;dynamic range;heuristic;initial condition;lateral computing;lateral thinking;mountain car;optimization problem;reinforcement learning;software propagation;temporal difference learning	Raju S. Bapi;Brendan D'Cruz;Guido Bugmann	1997	Neural Computing & Applications	10.1007/BF01414101	inverted pendulum;pendulum;simulation;nonlinear control;computer science;artificial intelligence;dynamical system;machine learning;control theory;artificial neural network	ML	17.80568364232578	-24.160097254406377	151839
ad270de62ffd4c842053cda31e2b5a18ca0ba892	using directional fibers to locate fixed points of recurrent neural networks		We introduce mathematical objects that we call “directional fibers,” and show how they enable a new strategy for systematically locating fixed points in recurrent neural networks. We analyze this approach mathematically and use computer experiments to show that it consistently locates many fixed points in many networks with arbitrary sizes and unconstrained connection weights. Comparison with a traditional method shows that our strategy is competitive and complementary, often finding larger and distinct sets of fixed points. We provide theoretical groundwork for further analysis and suggest next steps for developing the method into a more powerful solver.	artificial neural network;computer experiment;fixed point (mathematics);large;mathematics;neural network simulation;neural networks;physical object;recurrent neural network;solver;tissue fiber;weight	Garrett E. Katz;James A. Reggia	2018	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2017.2733544	artificial intelligence;manifold;machine learning;computer science;computer experiment;recurrent neural network;fixed point;solver	ML	15.490970144754387	-28.091350449648544	152231
1058aa88407cc67384ca0db3e078c1a67ef13df0	regularization and suboptimal solutions in learning from data	supervised learning;optimization problem;qa75 electronic computers computer science;learning problems	Supervised learning from data is investigated from an optimization viewpoint. Ill-posedness issues of the learning problem are discussed and its Tikhonov, Ivanov, Phillips, and Miller regularizations are analyzed. Theoretical features of the optimization problems associated with these regularization techniques and their use in learning tasks are considered. Weight-decay learning is investigated, too. Exploiting properties of the functionals to be minimized in the various regularized problems, estimates are derived on the accuracy of suboptimal solutions formed by linear combinations of n-tuples of computational units, for values of n smaller than the number of data.		Giorgio Gnecco;Marcello Sanguineti	2009		10.1007/978-3-642-04003-0_6	semi-supervised learning;unsupervised learning;multi-task learning;instance-based learning;mathematical optimization;algorithmic learning theory;artificial intelligence;online machine learning;machine learning;mathematics;supervised learning;stability;computational learning theory;active learning;generalization error	ML	21.717917880290774	-34.95437862888701	152255
fb31d8a4aee78f27d9ab093ca17d572ee54a48f2	do we really need all these neurons		Restricted Boltzmann Machines (RBMs) are generative neural networks that have received much attention recently. In particular, choosing the appropriate number of hidden units is important as it might hinder their representative power. According to the literature, RBM require numerous hidden units to approximate any distribution properly. In this paper, we present an experiment to determine whether such amount of hidden units is required in a classification context. We then propose an incremental algorithm that trains RBM reusing the previously trained parameters using a trade-off measure to determine the appropriate number of hidden units. Results on the MNIST and OCR letters databases show that using a number of hidden units, which is one order of magnitude smaller than the literature estimate, suffices to achieve similar performance. Moreover, the proposed algorithm allows to estimate the required number of hidden units without the need of training many RBM from scratch.	approximation algorithm;artificial neural network;converge;epoch (reference date);mnist database;optical character recognition;restricted boltzmann machine	Adriana Romero;Carlo Gatta	2013		10.1007/978-3-642-38628-2_54	speech recognition;computer science;artificial intelligence;machine learning;pattern recognition	ML	17.572400283472394	-32.24955332376645	152369
a54861d19e41782aacd87be24153871b50699a8e	expressive power of outer product manifolds on feed-forward neural networks		Hierarchical neural networks are exponentially more efficient than their corresponding “shallow” counterpart with the same expressive power, but involve huge number of parameters and require tedious amounts of training. Our main idea is to mathematically understand and describe the hierarchical structure of feedforward neural networks by reparametrization invariant Riemannian metrics. By computing or approximating the tangent subspace, we better utilize the original network via sparse representations that enables switching to shallow networks after a very early training stage. Our experiments show that the proposed approximation of the metric improves and sometimes even surpasses the achievable performance of the original network significantly even after a few epochs of training the original feedforward network.	approximation;artificial neural network;convolutional neural network;experiment;feedforward neural network;gradient;hessian;outer product;pushforward (differential);restricted boltzmann machine;sparse matrix	Bálint Daróczy;Rita Aleksziev;András A. Benczúr	2018	CoRR		outer product;manifold;feed forward;feedforward neural network;tangent;artificial neural network;topology;invariant (mathematics);subspace topology;computer science	ML	18.761923026535655	-30.62705563771648	152767
1e5ce02f9bebd0b09126a93e90c855d79f5ae450	density-based clustering with topographic maps	bayes estimation;unsupervised learning;nonparametric density estimation;empirical study;maximum entropy methods;learning algorithm;probability;topographic maps;metodo entropia maxima;bayesian statistics;estimacion densidad;bayes methods neural nets unsupervised learning maximum entropy methods network topology pattern recognition probability;methode non parametrique;neural nets;carte topographique;bayes methods;estimation densite;relacion convergencia;taux convergence;convergence rate;algorithme apprentissage;indexing terms;topographic map;competitive learning;topology topographic maps density based clustering unsupervised learning competitive learning kernel based maximum entropy learning rule bayes method equiprobabilistic map nonparametric density estimation probability;network topology;density estimation;estimacion bayes;metodo no parametrico;fonction densite;vector quantization;density function;funcion densidad;equiprobabilistic maps;nonparametric clustering;pattern recognition;phase transitions;non parametric method;algorithms;radio frequency neurons clustering algorithms entropy neural networks density functional theory bayesian methods statistical distributions cost function resonance;conscience learning;reseau neuronal;methode entropie maximum;algoritmo aprendizaje;method of maximum entropy;red neuronal;maximum entropy;plano topografico;estimation bayes;neural network;asymptotic level density	A new unsupervised competitive learning rule is introduced, called the kernel-based Maximum Entropy learning Rule (kMER), for equiprobabilistic topographic map formation. The application envisaged is density-based clustering. An empirical study is conducted to compare the clustering performance of kMER with that of a number of other unsupervised competitive learning rules.	cluster analysis;competitive learning;learning rule;map;rule (guideline);topography;statistical cluster	Marc M. Van Hulle	1999	IEEE transactions on neural networks	10.1109/72.737510	unsupervised learning;topographic map;computer science;machine learning;pattern recognition;mathematics;cluster analysis;artificial neural network;statistics;conceptual clustering	ML	12.86941095306114	-31.946438950076544	152850
207bc9a2ac37e4abbf45354e90707078be13c7bb	maximum relative margin and data-dependent regularization	text classification;data dependence;affine transformation;kernel method;support vector machine;computational efficiency;large data	Leading classification methods such as support vector machines (SVMs) and their counterparts achieve strong generalization performance by maximizing the margin of separation between data classes. While the maximum margin approach has achieved promising performance, this article identifies its sensitivity to affine transformations of the data and to directions with large data spread. Maximum margin solutions may be misled by the spread of data and preferentially separate classes along large spread directions. This article corrects these weaknesses by measuring margin not in the absolute sense but rather only relative to the spread of data in any projection direction. Maximum relative margin corresponds to a data-dependent regularization on the classification function while maximum absolute margin corresponds to an l2 norm constraint on the classification function. Interestingly, the proposed improvements only require simple extensions to existing maximum margin formulations and preserve the computational efficiency of SVMs. Through the maximization of relative margin, surprising performance gains are achieved on real-world problems such as digit, text classification and on several other benchmark datasets. In addition, risk bounds are derived for the new formulation based on Rademacher averages.	benchmark (computing);data dependency;document classification;expectation–maximization algorithm;matrix regularization;maximum cut;rademacher complexity;support vector machine	Pannagadatta K. Shivaswamy;Tony Jebara	2010	Journal of Machine Learning Research	10.1145/1756006.1756031	support vector machine;kernel method;mathematical optimization;margin;computer science;machine learning;pattern recognition;affine transformation;mathematics;statistics	ML	23.319511050491897	-36.654455427674186	152871
f40d01a8d79003dda58bc74e59748c460a8e59f5	using knowledge-based neural networks to improve algorithms: refining the chou-fasman algorithm for protein folding	chou fasman algorithm;neural networks;multistrategy learning;theory refinement;backpropagation;empirical evidence;finite state automata;protein folding;large classes;artificial neural network;neural network;knowledge base	This article describes a connectionist method for refining algorithms represented as generalized finitestate automata. The method translates the rule-like knowledge in an automaton into a corresponding artificial neural network, and then refines the reformulated automaton by applying backpropagation to a set of examples. This technique for translating an automaton into a network extends thekbann algorithm, a system that translates a set of propositional rules into a corresponding neural network. The extended system,FSkbann, allows one to refine the large class of algorithms that can be represented as state-based processes. As a test,FSkbann is used to improve the Chou-Fasman algorithm, a method for predicting how globular proteins fold. Empirical evidence shows that the multistrategy approach ofFSkbann leads to a statistically-significantly, more accurate solution than both the original Chou-Fasman algorithm and a neural network trained using the standard approach. Extensive statistics report the types of errors made by the Chou-Fasman algorithm, the standard neural network, and theFSkbann network.	artificial neural network;automaton;backpropagation;connectionism;dijkstra's algorithm	Richard Maclin;Jude W. Shavlik	1993	Machine Learning	10.1007/BF00993077	protein folding;stochastic neural network;feedforward neural network;probabilistic neural network;empirical evidence;computer science;artificial intelligence;backpropagation;machine learning;time delay neural network;artificial neural network;algorithm	ML	17.821961127027382	-26.468205043950473	152932
b43a497213aefa4798d5c7e4ca0ebe8f5d54b6ad	minimax-optimal bounds for detectors based on estimated prior probabilities	detectors;convergence;probability;prior probability;statistical machine learning;maximum likelihood estimate mle;detector;signal detection;maximum likelihood estimation;upper bound;training data;statistical learning;statistical learning theory detector maximum likelihood estimate mle minimax optimality prior probability;maximum likelihood estimate;statistical learning theory;detectors convergence maximum likelihood estimation training data probability upper bound statistical learning;minimax optimality;information theory	"""In many signal detection and classification problems, we have knowledge of the distribution under each hypothesis, but not the prior probabilities. This paper is aimed at providing theory to quantify the performance of detection via estimating prior probabilities from either labeled or unlabeled training data. The error or risk is considered as a function of the prior probabilities. We show that the risk function is locally Lipschitz in the vicinity of the true prior probabilities, and the error of detectors based on estimated prior probabilities depends on the behavior of the risk function in this locality. In general, we show that the error of detectors based on the maximum likelihood estimate (MLE) of the prior probabilities converges to the Bayes error at a rate of <formula formulatype=""""inline""""><tex Notation=""""TeX"""">$n^{-1/2}$</tex></formula>, where <formula formulatype=""""inline""""> <tex Notation=""""TeX"""">$n$</tex></formula> is the number of training data. If the behavior of the risk function is more favorable, then detectors based on the MLE have errors converging to the corresponding Bayes errors at optimal rates of the form <formula formulatype=""""inline""""><tex Notation=""""TeX"""">$n^{-(1+\alpha)/2}$</tex> </formula>, where <formula formulatype=""""inline""""><tex Notation=""""TeX"""">$\alpha > 0$</tex></formula> is a parameter governing the behavior of the risk function with a typical value <formula formulatype=""""inline""""><tex Notation=""""TeX"""">$\alpha = 1$</tex></formula>. The limit <formula formulatype=""""inline""""><tex Notation=""""TeX"""">$\alpha \rightarrow{} \infty$</tex></formula> corresponds to a situation where the risk function is flat near the true probabilities, and thus insensitive to small errors in the MLE; in this case, the error of the detector based on the MLE converges to the Bayes error exponentially fast with <formula formulatype=""""inline""""> <tex Notation=""""TeX"""">$n$</tex></formula>. We show that the bounds are achievable no matter given labeled or unlabeled training data and are minimax-optimal in the labeled case."""	detection theory;locality of reference;loss function;minimax;sensor	Jiantao Jiao;Lin Zhang;Robert D. Nowak	2012	IEEE Transactions on Information Theory	10.1109/TIT.2012.2201914	econometrics;detector;information theory;pattern recognition;mathematics;maximum likelihood;statistics	ML	22.365352219956353	-31.177034323892748	153145
32ea5ee2154940a32f2579df8b270b57be86e36d	the computational theory of intelligence: information entropy	machine learning;artificial intelligence;entropy;computer science;intelligence	This paper presents an information theoretic approach to the concept of intelligence in the computational sense. We introduce a probabilistic framework from which computation alintelligence is shown to be an entropy minimizing process at the local level. Using this new scheme, we develop a simple data driven clustering example and discuss its applications.	aggregate data;cluster analysis;computation;computational intelligence;consciousness;entropy (information theory);image noise;information theory;relevance;self-awareness;sparse matrix;test set	Daniel Kovach	2014	CoRR	10.4236/ijmnta.2014.34020	entropy;intelligence;artificial architecture;marketing and artificial intelligence;computer science;artificial intelligence;data science;machine learning;computational intelligence;ai-complete;hyper-heuristic	NLP	10.12489707332602	-27.536812430244375	153250
4dd22c01add4ef967e543063abca50b2476de1fb	on the efficient minimization of classification calibrated surrogates	supervised learning;convergence rate;satisfiability;maximum likelihood estimate;data dependence;zero sum game	Bartlett et al (2006) recently proved that a ground condition for convex surrogates, classification calibration, ties up the minimization of the surrogates and classification risks, and left as an important problem the algorithmic questions about the minimization of these surrogates. In this paper, we propose an algorithm which provably minimizes any classification calibrated surrogate strictly convex and differentiable — a set whose losses span the exponential, logistic and squared losses —, with boosting-type guaranteed convergence rates under a weak learning assumption. A particular subclass of these surrogates, that we call balanced convex surrogates, has a key rationale that ties it to maximum likelihood estimation, zerosum games and the set of losses that satisfy some of the most common requirements for losses in supervised learning. We report experiments on more than 50 readily available domains of 11 flavors of the algorithm, that shed light on new surrogates, and the potential of data dependent strategies to tune surrogates.	algorithm;bartlett's bisection theorem;convex function;design rationale;experiment;primer;requirement;supervised learning;surrogates;time complexity	Richard Nock;Frank Nielsen	2008			mathematical optimization;combinatorics;computer science;machine learning;mathematics;maximum likelihood;zero-sum game;supervised learning;rate of convergence;statistics;satisfiability	ML	21.319767950760895	-33.643026214828815	153457
2bbf820629e765e6b09db32470b99283bbc5dbbc	analysis of associative reinforcement learning in neural networks using iterated function systems	learning process;fractals;iterated function system;metric space;probability;learning;neural nets;proceso markov;reinforcement learning;intelligent networks neural networks learning automata stochastic processes extraterrestrial measurements fractals markov processes weight measurement supervised learning feedback;association mapping;aprendizaje;iterative methods;apprentissage;weighted space;processus markov;markov process;automata theory;markov processes;probability fractals iterative methods learning artificial intelligence markov processes neural nets;learning artificial intelligence;reseau neuronal;stochastic automata theory associative reinforcement learning neural networks iterated function systems stochastic search associative mapping markov process invariant probability measure fractal like structure;probability measure;red neuronal;random mapping;stochastic search;neural network	A mathematical theory of associative reinforcement learning in neural networks is developed in terms of random iterated function systems (IFSs), which are finite sets of random maps on metric spaces. In particular, the stochastic search for an associative mapping that maximizes the expected pay-off arising from reinforcement is formulated as a random IFS on weight-space. The dynamical evolution of the weights is described by a Markov process. If this process is ergodic then the limiting behavior of the system is described by an invariant probability measure on weight space that can have a fractal-like structure. A class of associative reinforcement learning algorithms is constructed that is an extension of the nonassociative schemes used in stochastic automata theory. The issue of generalization is discussed within the IFS framework and related to the stochastic and possibly fractal nature of the learning process. >	artificial neural network;iterated function system;iteration;reinforcement learning	Paul C. Bressloff;Jaroslav Stark	1992	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.199461	discrete mathematics;computer science;artificial intelligence;machine learning;mathematics;markov process;artificial neural network;statistics	Robotics	18.755131446589346	-27.736727969696407	153787
8511105a7c7cec80cf144984838cf5ba333bdd37	discriminant parallel perceptrons	multilayer perceptrons;metodo formal;methode formelle;intelligence artificielle;linear discriminate analysis;multilayer perceptron;classification;formal method;perceptron multicouche;discriminant analysis;analyse discriminante;analisis discriminante;conferenceobject;artificial intelligence;inteligencia artificial;reseau neuronal;bookpart;clasificacion;red neuronal;neural network	Parallel perceptrons (PPs), a novel approach to committee machine training requiring minimal communication between outputs and hidden units, allows the construction of efficient and stable nonlinear classifiers. In this work we shall explore how to improve their performance allowing their output weights to have real values, computed by applying Fisher’s linear discriminant analysis to the committee machine’s perceptron outputs. We shall see that the final performance of the resulting classifiers is comparable to that of the more complex and costlier to train multilayer perceptrons.	committee machine;linear discriminant analysis;multilayer perceptron;nonlinear system	Ana M. González;Iván Cantador;José R. Dorronsoro	2005		10.1007/11550907_3	speech recognition;formal methods;biological classification;computer science;artificial intelligence;machine learning;linear discriminant analysis;multilayer perceptron;artificial neural network	ML	10.144652022350042	-31.67707484949601	153809
50c8bfb994753de01f3d5bf60df38a39651b82fb	boosting trust region policy optimization by normalizing flows policy		We propose to improve trust region policy search with normalizing flows policy. We illustrate that when the trust region is constructed by KL divergence constraint, normalizing flows policy can generate samples far from the ’center’ of the previous policy iterate, which potentially enables better exploration and helps avoid bad local optima. We show that normalizing flows policy significantly improves upon factorized Gaussian policy baseline, with both TRPO and ACKTR, especially on tasks with complex dynamics such as Humanoid.	baseline (configuration management);complex dynamics;humanoid robot;iteration;kullback–leibler divergence;local optimum;program optimization;trust region	Yunhao Tang;Shipra Agrawal	2018	CoRR		machine learning;artificial intelligence;computer science;kullback–leibler divergence;boosting (machine learning);local optimum;complex dynamics;trust region;gaussian	ML	24.035734144003566	-32.58569320186914	153944
ad019ee83206d1e67e74056c04196ed1b6112b7c	a fast classification algorithm based on local models	algorithme rapide;feedforward neural network;iterative method;cluster algorithm;ajustamiento modelo;theorie locale;analyse amas;classification algorithm;local theory;red local;layer model;modelo capa;clasificador;intelligence artificielle;grupo puntual;classification;metodo iterativo;groupe ponctuel;ajustement modele;local network;classifier;cluster analysis;reseau neuronal non boucle;point group;methode iterative;fast algorithm;model matching;modele couche;comparative study;classificateur;artificial intelligence;analisis cluster;feedforward neural nets;inteligencia artificial;teoria local;reseau neuronal;reseau local;algoritmo rapido;clasificacion;red neuronal;neural network	This work presents a new classification method based on the iterative combination of two steps: a clustering technique and a set of one-layer neural networks. First, the clustering algorithm divides the input space in several regions (local models). Subsequently, a one-layer neural network, for each local region, is used to fit the model (classifier) for a specific group of data points. Experimental results on three different data sets are showed to verify the validity of the proposed method. Besides, a comparative study with a feedforward neural network is included. This study exhibits that the presented algorithm is a fast procedure that obtains, in many cases, better results than the other technique.	algorithm	Sabela Platero-Santos;Oscar Fontenla-Romero;Amparo Alonso-Betanzos	2006		10.1007/11875581_30	local area network;feedforward neural network;classifier;biological classification;computer science;artificial intelligence;machine learning;comparative research;mathematics;iterative method;point group;cluster analysis;artificial neural network;algorithm	Vision	10.763265885766195	-32.0788277253304	154065
e4d99599cf4b9d715e461fb2481a0a4c7494af8d	predicting the generalization ability of neural networks resembling the nearest-neighbor algorithm	probability;neural networks;neural nets;boolean functions;complementation generalization ability nearest neighbor algorithm nearest neighbor probability classification problems binary inputs hamming distance;nearest neighbor probability;testing;reliability theory;generalization ability;classification problems;upper bound;computer architecture;nearest neighbor algorithm;hamming distance;vector quantization;nearest neighbor;pattern classification;neural networks hamming distance testing boolean functions circuits reliability theory parallel processing computer architecture neurons vector quantization;circuits;neurons;generalisation artificial intelligence;complementation;parallel processing;generalisation artificial intelligence probability neural nets pattern classification;neural network;binary inputs	The definition of nearest-neighbor probability p(C) is introduced to characterize classification problems with binary inputs. It measures the likelihood that two patterns, which are close according to the Hamming distance, are assigned to the same class. It is shown that the generalization ability gNN (C) of neural networks that resemble the nearestneighbor algorithm can be expressed as a function of p(C) and is upper bounded by p(C) when p(C) > 0.5. In the opposite case a proper operator, called complementation, is proposed to improve the classification process in the test phase.	hamming distance;k-nearest neighbors algorithm;neural networks	Marco Muselli	2000		10.1109/IJCNN.2000.857809	computer science;theoretical computer science;machine learning;pattern recognition;mathematics;k-nearest neighbors algorithm;artificial neural network	ML	17.476726407797173	-29.565841739811034	154100
8bbc274222b5497c7ce1672e8e32f829119f6ed1	a novel learning algorithm of single-hidden-layer feedforward neural networks		Single-hidden-layer feedforward neural network (SLFN) is an effective model for data classification and regression. However, it has a very important defect that it is rather time-consuming to explore the training algorithm of SLFN. In order to shorten the learning time, a special non-iterative learning algorithm was proposed, named as extreme learning machine (ELM). The main idea is that the input weights and bias are chosen randomly and the output weights are calculated by a pseudo-inverse matrix. However, ELM also has a very important drawback that it cannot achieve stable solution for different runs because of randomness. In this paper, we propose a stabilized learning algorithm based on iteration correction. The convergence analysis shows that the proposed algorithm can finish the learning process in fewer steps than the number of neurons. Three theorems and their proofs can prove that the proposed algorithm is stable. Several data sets are selected from UCI databases, and the experimental results demonstrate that the proposed algorithm is effective.	algorithm;artificial neural network;database;discrepancy function;elm;experiment;feedforward neural network;iteration;randomness;software bug	Dong-Mei Pu;Da-Qi Gao;Tong Ruan;Yubo Yuan	2016	Neural Computing and Applications	10.1007/s00521-016-2372-y	wake-sleep algorithm;weighted majority algorithm;computer science;artificial intelligence;machine learning;mathematics;stability;active learning;algorithm;statistics;population-based incremental learning;generalization error	ML	15.815991754760224	-30.16940939478063	154253
75a07866847e52ab3473f9146dc886577bba0447	improving optimal linear associative memory using data partitioning	associative memory computational complexity iterative algorithms partitioning algorithms information retrieval encoding costs cybernetics fault tolerance neurons;content addressable storage computational complexity;data partitioning;facial images optimal linear associative memory data partitioning computational complexity pseudo inverse operation auto associative recall;computational complexity;associative memory;auto associative recall;pseudo inverse operation;content addressable storage;facial images;optimal linear associative memory	Linear associative memory (LAM) has two serious problems to be practical. One is a large space of memory. The other is a high computational complexity. In this paper, we propose partitioning of the input data to alleviate these problems. The optimal linear associative memory (OLAM) minimizes the error of recall employing a pseudo-inverse operation. The proposed algorithm was applied to auto-associative recall of facial images. We show that the proposed algorithm can both reduce the memory space and computational complexity over the conventional optimal linear associative memory.	algorithm;bidirectional associative memory;computational complexity theory;content-addressable memory;dspace	Doo San Baek;Se-Young Oh	2006	2006 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2006.385196	computer science;theoretical computer science;machine learning;computational complexity theory;algorithm	Robotics	13.820534702940526	-30.780816207344188	154359
f05454503ed0d9948162eb8d9da7421c3a40a403	stability evaluation of combined neural networks		In the industrial field, the artificial neural network classifiers are currently used and they are generally integrated of technologic systems which need efficient classifier. However, the lack of control over its mathematical formulation explains the instability of its classification results. In order to improve the prediction accuracy, most of researchers refer to the classifiers combination approach. This paper tries to illustrate the capability of an example of combined neural networks to improve the stability criterion of the single neural classifier. The stability comparison is performed by the error rate probability densities function estimated by a new variant of the kernel-diffeomorphism semi-bounded Plug-in algorithm.	algorithm;decision tree learning;emoticon;instability;kernel (operating system);neural networks;semiconductor industry;statistical classification;support vector machine	Ibtissem Ben Othman;Faouzi Ghorbel	2014		10.5220/0005077402030209	word error rate;artificial neural network;machine learning;stability criterion;instability;artificial intelligence;pattern recognition;mathematics	ML	10.732707536304625	-37.12386768017504	154365
c9f0577861d05d125b6732a0d0eb7fbd50b4195a	decreasing the size of the restricted boltzmann machine		In this paper, we propose a method to decrease the number of hidden units of the restricted Boltzmann machine while avoiding a decrease in the performance quantified by the Kullback-Leibler divergence. Our algorithm is then demonstrated by numerical simulations.		Yohei Saito;Takuya Kato	2018	CoRR		mathematical optimization;divergence;mathematics;restricted boltzmann machine	ML	24.21164197930605	-30.864242751421646	154511
eb5f8a2cb5126d7f343a3a02e336eef0c70752dc	consolidating a heuristic for incremental decision tree learning through asymptotic analysis	heuristic;decision tree learning;asymptotic analysis;approximation;decision trees;incremental induction	This paper addresses stability issues in incremental induction of decision trees. Stability problems arise when an induction algorithm must revise a decision tree very often and oscillations between similar concepts decrease learning speed. We review a heuristic that solves this problem and subsequently employ asymptotic analysis to approximate the basic parameters related to the estimation of computational effort in incremental learning of decision trees. We then use these approximations to simplify the heuristic, we deliver insight into its amortizing behavior and argue how they can also speed-up its execution and enhance its applicability, also providing experimental evidence to support these claims.	decision tree learning;heuristic;incremental decision tree	Dimitrios Kalles;Athanassios Papagelis;Yannis C. Stamatiou	2011	International Journal on Artificial Intelligence Tools	10.1142/S0218213011000024	mathematical optimization;asymptotic analysis;heuristic;decision tree learning;computer science;machine learning;approximation;decision tree;incremental decision tree;incremental heuristic search;id3 algorithm;algorithm	Robotics	17.42498860815206	-32.436556744738894	154531
46ac47d751ffb4708e46bfa6cd5eb056006c4d2a	a novel learning method for anfis using em algorithm and emotional learning	machine learning algorithms;decision tree;capacity planning;real time;traffic control;p2p;telecommunication traffic;machine learning;monitoring;computational complexity;traffic classification;classification algorithms;clustering algorithms;service differentiation;payloads;feature selection;decision trees;telecommunication traffic payloads decision trees machine learning monitoring computational complexity machine learning algorithms traffic control classification algorithms clustering algorithms	It is very difficult for the adaptive neuro-fuzzy interference system (ANFIS) using conventional training methods to converge while the samples space distribution is more complex, the desired results for that couldn't be achieved. To change the situation and improve the learning behavior of ANFIS, in this paper we propose a new self-adaptive learning algorithm for ANFIS differently from conventional training methods. The method firstly adopts the EM algorithm to learning fuzzy parameters of the ANFIS, and then applies emotion learning to learn the Takagi-Sugeno-Kang (TSK) parameters of the linear TSK functions of the ANFIS. The relevant researches indicate that the proposed learning method possesses faster training speed and better adaptability, and is more ubiquitous. In the end, a simulation example shows the availability of the proposed method.	adaptive neuro fuzzy inference system;converge;expectation–maximization algorithm;interference (communication);neuro-fuzzy;simulation	Hongsheng Su	2007	2007 International Conference on Computational Intelligence and Security (CIS 2007)	10.1109/CIS.2007.178	simulation;computer science;artificial intelligence;machine learning;decision tree;data mining;feature selection;computer security	Robotics	13.49977307988938	-31.530815866098248	154837
39ea9527c77f5b680dcb0a00230bcb755fbb2111	model-based recurrent neural network for modeling nonlinear dynamic systems	transfer functions;activation function;nonlinear dynamical systems;dynamic system;recurrent neural networks power system modeling artificial neural networks industrial training network topology multilayer perceptrons neural networks gallium nitride uncertainty nonlinear systems;radial basis function;recurrent network;nonlinear dynamical systems recurrent neural nets transfer functions;training recurrent neural network nonlinear dynamic systems mbrnn state space model radial basis functions;recurrent neural nets;recurrent neural network;state space model;nonlinear dynamic system	A model-based recurrent neural network (MBRNN) is introduced for modeling dynamic systems. This network has a fixed structure that is defined according to the linearized state-space model of the plant. Therefore, the MBRNN has the ability to incorporate the analytical knowledge of the plant in its formulation. With its original topology intact, the MBRNN can then be trained to represent the plant nonlinearities through modifying its nodes' activation functions, which consist of contours of Gaussian radial basis functions (RBFs). Training in MBRNN involves adjusting the weights of the RBF's so as to modify the contours representing the activation functions. The performance of the MBRNN is demonstrated via several examples. The results indicate that it requires much shorter training than needed by ordinary recurrent networks. This efficiency in training is attributed to the MBRNN's fixed topology which is independent of training.	activation function;anatomy, regional;artificial neural network;dynamical system;neural network simulation;nonlinear dynamics;nonlinear system;normal statistical distribution;radial (radio);radial basis function;recurrent neural network;state space;weight	Chengyu Gan;K. Danai	2000	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/3477.836382	feedforward neural network;radial basis function;types of artificial neural networks;computer science;artificial intelligence;state-space representation;recurrent neural network;dynamical system;machine learning;physical neural network;control theory;time delay neural network;transfer function;activation function;radial basis function network	Vision	14.854721131036092	-28.053852387466147	154889
0506867f14f1e2bd08178a6e323c5fb4b0bbb9dc	machine learning approaches for contact maps prediction in casp9 experiment			casp;machine learning	Giuseppe Tradigo;Pierangelo Veltri;Gianluca Pollastri	2011			machine learning;artificial intelligence;computer science	NLP	10.711944423965356	-26.688947234820034	155146
29cfcfa60dbc09473c1a59adc9bcb77e4436a68c	fugue: slow-worker-agnostic distributed learning for big models on big data		We present a scheme for fast, distributed learning on big (i.e. high-dimensional) models applied to big datasets. Unlike algorithms that focus on distributed learning in either the big data or big model setting (but not both), our scheme partitions both the data and model variables simultaneously. This not only leads to faster learning on distributed clusters, but also enables machine learning applications where both data and model are too large to fit within the memory of a single machine. Furthermore, our scheme allows worker machines to perform additional updates while waiting for slow workers to finish, which provides users with a tunable synchronization strategy that can be set based on learning needs and cluster conditions. We prove the correctness of such strategies, as well as provide bounds on the variance of the model variables under our scheme. Finally, we present empirical results for latent space models such as topic models, which demonstrate that our method scales well with large data and model sizes, while beating learning strategies that fail to take both data and model partitioning into account.	algorithm;big data;correctness (computer science);machine learning;topic model	Abhimanu Kumar;Alex Beutel;Qirong Ho;Eric P. Xing	2014			semi-supervised learning;computer science;theoretical computer science;online machine learning;machine learning;data mining	ML	18.899035952517035	-37.488409453554	155154
8707d0cd7bfc15055b2cb5d2011924dde41d5912	combined effects of class imbalance and class overlap on instance-based classification	chevauchement;instance based learning;minority;prior probability;dissimilarity measure;probabilite a priori;class imbalance;clasificador;intelligence artificielle;overlap;classification;minorite;imbricacion;regime desequilibre;classifier;real world application;probabilidad a priori;regimen desequilibrado;classificateur;artificial intelligence;inteligencia artificial;unbalanced conditions;clasificacion;minoria	In real-world applications, it has been often observed that class imbalance (significant differences in class prior probabilities) may produce an important deterioration of the classifier performance, in particular with patterns belonging to the less represented classes. This effect becomes especially significant on instance-based learning due to the use of some dissimilarity measure. We analyze the effects of class imbalance on the classifier performance and how the overlap has influence on such an effect, as well as on several techniques proposed in the literature to tackle the class imbalance. Besides, we study how these methods affect to the performance on both classes, not only on the minority class as usual.	instance-based learning;statistical classification	Vicente García;Roberto Alejo;José Salvador Sánchez;José Martínez Sotoca;Ramón Alberto Mollineda	2006		10.1007/11875581_45	instance-based learning;prior probability;classifier;biological classification;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;statistics	Metrics	10.447978091391782	-34.90099715457935	155334
bbc9e8220f3061fb483ca00518637fe296ad872a	reordering sparsification of kernel machines in approximate policy iteration	learning control;approximation error;reinforcement learning;least squares policy iteration;sparsification;feature vector;kernel machine;approximate policy iteration;inverted pendulum;policy iteration	Approximate policy iteration (API), which includes least-squares policy iteration (LSPI) and its kernelized version (KLSPI), has received increasing attention due to their good convergence and generalization abilities in solving difficult reinforcement learning problems. However, the sparsification of feature vectors, especially the kernel-based features, greatly influences the performance of API methods. In this paper, a novel reordering sparsification method is proposed for sparsifiying kernel machines in API. In this method, a greedy strategy is adopted, which adds the sample with the maximal squared approximation error to the kernel dictionary, so that the samples are reordered to improve the performance of kernel sparsification. Experimental results on the learning control of an inverted pendulum verify that by using the proposed algorithm, the size of the kernel dictionary is smaller than that of the previous sequential sparsification algorithm with the same level of sparsity, and the performance of the control policies learned by KLSPI can also be improved.	iteration;kernel method;markov decision process	Chunming Liu;Jinze Song;Xin Xu;Pengcheng Zhang	2009		10.1007/978-3-642-01510-6_46	inverted pendulum;kernel method;mathematical optimization;approximation error;feature vector;radial basis function kernel;computer science;theoretical computer science;machine learning;mathematics;reinforcement learning;polynomial kernel	ML	24.020381877856	-35.2396280847469	155470
fe103cf1b2bde692594afb1eddec8dda06ca1d6b	learning kernel classifiers: theory and algorithms (herbrich, r.; 2002) [book reviews]	machine learning algorithms;kernel;learning algorithm;support vector machines;bayesian methods;learning systems;statistical learning;machine learning;stochastic processes;classification algorithms;virtual colonoscopy;support vector machine classification;book reviews;learning theory	Focusing on classification learning, this book covers learning algorithms and learning theory. The book concludes with appendices covering some of the technical aspects involved. The book is a good reference for scientists and engineers interested in learning about kernel classifiers. It is not very suitable as a primary student text, but is recommended as secondary reading for students requiring an in-depth insight into this area.	algorithm;kernel (operating system)	Cecilio Angulo	2008	IEEE Trans. Neural Networks	10.1109/TNN.2008.2008390	semi-supervised learning;statistical classification;unsupervised learning;stochastic process;support vector machine;multi-task learning;instance-based learning;algorithmic learning theory;kernel;bayesian probability;computer science;data science;online machine learning;machine learning;learning theory;pattern recognition;inductive transfer;mathematics;ensemble learning;learning classifier system;stability;computational learning theory;active learning;generalization error	ML	18.512402437180626	-35.107283563786275	155480
82cfca8b203b2bc64168c5a7b6ca7473c03d03cd	on overfitting, generalization, and randomly expanded training sets	gaussian mixture;probability;probability density function;generalization artificial intelligence backpropagation multilayer perceptrons probability gaussian distribution;multilayer perceptrons;multilayer perceptron;backpropagation;input output;number of clusters;generalization artificial intelligence;cross validation;global cross validated shaping overfitting randomly expanded training sets algorithmic procedure random expansion backpropagation trained multilayer perceptrons k means clustering entropic colored gaussian joint input output probability density function estimates minimum differential entropy;synthetic data;k means clustering;gaussian distribution;stochastic processes testing neural networks backpropagation algorithms multilayer perceptrons entropy minimization methods clustering algorithms probability density function clustering methods	An algorithmic procedure is developed for the random expansion of a given training set to combat overfitting and improve the generalization ability of backpropagation trained multilayer perceptrons (MLPs). The training set is K-means clustered and locally most entropic colored Gaussian joint input-output probability density function (pdf) estimates are formed per cluster. The number of clusters is chosen such that the resulting overall colored Gaussian mixture exhibits minimum differential entropy upon global cross-validated shaping. Numerical studies on real data and synthetic data examples drawn from the literature illustrate and support these theoretical developments.	backpropagation;differential entropy;estimated;exhibits as topic;generalization (psychology);k-means clustering;multilayer perceptron;noise shaping;normal statistical distribution;numerical integration;numerical method;overfitting;portable document format;randomness;synthetic data;test set	George N. Karystinos;Dimitris A. Pados	2000	IEEE transactions on neural networks	10.1109/72.870038	normal distribution;input/output;probability density function;computer science;backpropagation;machine learning;pattern recognition;probability;mathematics;multilayer perceptron;cross-validation;statistics;k-means clustering;synthetic data	ML	21.65249230854668	-29.45818109195054	155723
9c81b74af12a4a0a756f73299d23325134410c6f	reverse neuron level decomposition for cooperative neuro-evolution of feedforward networks for time series prediction	problem decomposition;feedforward networks;cooperative coevolution;time series prediction	A major challenge in cooperative neuro-evolution is to find an efficient problem decomposition that takes into account architectural properties of the neural network and the training problem. In the past, neuron and synapse Level decomposition methods have shown promising results for time series problems, howsoever, the search for the optimal method remains. In this paper, a problem decomposition method, that is based on neuron level decomposition is proposed that features a reverse encoding scheme. It is used for training feedforward networks for time series prediction. The results show that the proposed method has improved performance when compared to related problem decomposition methods and shows competitive results when compared to related methods in the literature.	feed forward (control);feedforward neural network;neuron;time series	Ravneil Nand;Rohitash Chandra	2016		10.1007/978-3-319-28270-1_15	simulation;computer science;artificial intelligence;machine learning	ML	15.121000094908803	-24.410309407608857	155899
6d838f3628dd3e8cdbc7da0b1b472c8c71eb0124	multiple neural networks and bayesian belief revision for a never-ending unsupervised learning	unsupervised learning;mouth;reliability;probability;bayes rule;expert systems;never ending unsupervised learning;bayes methods;unsupervised learning bayes methods belief maintenance expert systems face recognition probability;continuous learning;bayesian methods;reliability face recognition face artificial neural networks mouth bayesian methods intelligent systems;artificial neural networks;face recognition;belief revision;intelligent systems;expert network;face;belief maintenance;multiple neural network;reliability factor;face recognition problem;continuous learning multiple neural network bayesian belief revision never ending unsupervised learning face recognition problem expert network reliability factor probability bayes rule;bayesian belief revision;neural network	A system of Multiple Neural Networks has been proposed to solve the face recognition problem. Our idea is that a set of expert networks specialized to recognize specific parts of face are better than a single network. This is because a single network could no longer be able to correctly recognize the subject when some characteristics partially change. For this purpose we assume that each network has a reliability factor defined as the probability that the network is giving the desired output. In case of conflicts between the outputs of the networks the reliability factor can be dynamically re-evaluated on the base of the Bayes Rrule. The new reliabilities will be used to establish who is the subject. Moreover the network disagreed with the group and specialized to recognize the changed characteristic of the subject will be retrained and then forced to correctly recognize the subject. Then the system is subjected to continuous learning.	belief revision;facial recognition system;neural networks;unsupervised learning	Aldo Franco Dragoni;Germano Vallesi;Paola Baldassarri	2010	2010 10th International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2010.5687229	face;bayesian probability;computer science;artificial intelligence;machine learning;pattern recognition;probability;reliability;bayes' theorem;belief revision;artificial neural network;statistics;r-factor	ML	17.367111457551466	-31.1206395994255	155919
976c38269eb3db577d851bc3dfeb8bb2c6297c44	regularization techniques for learning with matrices	learning algorithm;statistical machine learning;regularization method;multiple kernel learning;prior knowledge;regularization;statistical properties;science learning;multi task learning;learning problems;multi class learning;strong convexity;regret bounds;generalization bounds;conjugate function	There is growing body of learning problems for which it is natural to organize the parameters into matrix, so as to appropriately regularize the parameters under some matrix norm (in order to impose some more sophisticated prior knowledge). This work describes and analyzes a systematic method for constructing such matrix-based, regularization methods. In particular, we focus on how the underlying statistical properties of a given problem can help us decide which regularization function is appropriate. Our methodology is based on the known duality fact: that a function is strongly convex with respect to some norm if and only if its conjugate function is strongly smooth with respect to the dual norm. This result has already been found to be a key component in deriving and analyzing several learning algorithms. We demonstrate the potential of this framework by deriving novel generalization and regret bounds for multi-task learning, multi-class learning, and kernel learning.	algorithm;computer multitasking;dual norm;machine learning;matrix regularization;multi-task learning;norm (social);regret (decision theory)	Sham M. Kakade;Shai Shalev-Shwartz;Ambuj Tewari	2012	Journal of Machine Learning Research		semi-supervised learning;unsupervised learning;regularization perspectives on support vector machines;feature learning;multi-task learning;regularization;instance-based learning;mathematical optimization;proximal gradient methods for learning;algorithmic learning theory;empirical risk minimization;wake-sleep algorithm;early stopping;computer science;online machine learning;machine learning;pattern recognition;mathematics;stability;computational learning theory;active learning;generalization error	ML	21.65516489815897	-34.35031192062643	155951
0884d96bf86bbea46179cd55b0b52686b4712437	on the optimality of naïve bayes with dependent binary features	dependent binary features;optimality of nb;statistical pattern recognition;bayes classifier;naive bayes classifier nb	While Naı̈ve Bayes classifier (NB) is Bayes-optimal for independent features, we prove that it is also optimal for two equiprobable classes and two features with equal class-conditional covariances. Although strict optimality does not extend for three features, equal covariances are expected to be beneficial in higher-dimensional spaces. 2005 Elsevier B.V. All rights reserved.	naive bayes classifier	Ludmila I. Kuncheva	2006	Pattern Recognition Letters	10.1016/j.patrec.2005.12.001	bayes classifier;naive bayes classifier;computer science;machine learning;pattern recognition;bayes error rate	AI	19.62580685334449	-35.61556576496376	155960
dea8658ee4750ec6bb408a2281cf922cbb300a0a	asymptotic properties of nearest neighbor rules using edited data	nearest neighbor searches;convergence;decoding;nearest neighbor searches random variables convergence character recognition decoding pattern recognition;random variables;decision procedure;nearest neighbor;pattern recognition;asymptotic properties;character recognition	The convergence properties of a nearest neighbor rule that uses an editing procedure to reduce the number of preclassified samples and to improve the performance of the rule are developed. Editing of the preclassified samples using the three-nearest neighbor rule followed by classification using the single-nearest neighbor rule with the remaining preclassified samples appears to produce a decision procedure whose risk approaches the Bayes' risk quite closely in many problems with only a few preclassified samples. The asymptotic risk of the nearest neighbor rules and the nearest neighbor rules using edited preclassified samples is calculated for several problems.	decision problem	Dennis L. Wilson	1972	IEEE Trans. Systems, Man, and Cybernetics	10.1109/TSMC.1972.4309137	nearest-neighbor chain algorithm;large margin nearest neighbor;random variable;nearest neighbor graph;best bin first;convergence;computer science;machine learning;nearest neighbor search;fixed-radius near neighbors;k-nearest neighbors algorithm;statistics	ML	15.281882663433505	-35.28647275190718	156107
128ac699a40877fd42b9006b4792c06309bc95ff	novel data classification method based on radial basis function networks	belief networks;probability;prior probability;bayesian decision rule;k nearest neighbor estimation;class conditional probability density function;radial basis function networks;machine learning data set;support vector machine data classification radial basis function network prior probability vector projection boundary vector k nearest neighbor estimation class conditional probability density function network center minimum error rate bayesian decision rule machine learning data set;machine learning;radial basis function network;boundary vector;vector projection;pattern classification;error rate;k nearest neighbor;radial basis function networks belief networks learning artificial intelligence pattern classification probability;support vector machine;learning artificial intelligence;data classification;conditional probability;network center;minimum error rate;density functional;decision rule;radial basis function networks probability density function training data error analysis bayesian methods computational modeling machine learning machine learning algorithms support vector machines support vector machine classification	A new data classification method was prompted for the classify problem about samples with known prior probabilities. Vectors near the boundaries were pre-extracted from the training samples based on vector projection, the values of the class-conditional probability density of the boundary vectors were approximately computed by k-nearest-neighbors estimation. To approximate the class-conditional probability density function of each class of the objects in the training data set, radial basis function networks were constructed using the boundary vectors as the network centers. The classification was realized by the minimum error rate Bayesian decision rule. Simulation results for machine learning data sets show that the proposed algorithm can deliver the same level of accuracy as the support vector machines in data classification applications, and can effectively carry out data classification with more than two classes of objects	approximation algorithm;benchmark (computing);database;machine learning;pattern recognition;radial (radio);radial basis function network;simulation;support vector machine;test set;time complexity	Xiaorun Li;Guangzhou Zhao;Liaoying Zhao	2006	Sixth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2006.208	support vector machine;prior probability;conditional probability;word error rate;computer science;machine learning;vector projection;pattern recognition;probability;data mining;decision rule;k-nearest neighbors algorithm;radial basis function network;one-class classification;statistics	ML	14.98780773913145	-35.3076780339835	156159
59f4a3a8e4ce56dc2ece5d060f1390df0ce9032b	adaptive neuro-fuzzy modeling applied to policy gradient reinforcement learning.	reinforcement learning;neuro fuzzy	1. Auto-structure of presynaptic activity de nes postsynaptic ring statistics and can modulate STDPbased structure formation and learning Gordon Pipa, Ra ul Vicente, Alexander Tikhonov 2. Decision Making Logic of Visual Brain Andrzej W. Przybyszewski 3. A Computational Model of Saliency Map Read-Out During Visual Search Mia Seti c, Dra zen Domijan 4. A Corpus-based Computational Model of Metaphor Understanding Incorporating Dynamic Interaction Asuka Terai, Masanori Nakagawa	computation;computational model;gradient;neuro-fuzzy;reinforcement learning;search for extraterrestrial intelligence	Konstantinos C. Zikidis;Spyros G. Tzafestas	2001			computer science;artificial intelligence;neuro-fuzzy;machine learning;pattern recognition;learning classifier system;reinforcement learning	ML	12.16026556356123	-27.857169218353395	156363
d6ab64de70516f568476f3a40fc19aedb5145c84	beerbf: a bee-inspired data clustering approach to design rbf neural network classifiers	bee inspired algorithms;rbf;optimal data clustering;data classification;neural network	Different methods have been used to train radial basis function (RBF) neural networks. This paper proposes the use of a bee-inspired algorithm, named cOptBees, plus a heuristic to automatically select the number, location and dispersions of basis functions to be used in RBF networks. cOptBees was originally designed to solve data clustering problems and the prototypes determined by the algorithm will be selected as the centers for the RBF network. The presented approach, named BeeRBF, is used to solve classification problems and is evaluated both in terms of the decision boundaries generated and classification accuracy. The performance of BeeRBF was compared with that of k-means, random center selection and some other proposals from the literature. The results show that BeeRBF is competitive and has the advantage of automatically determining the number of centers to be used in the RBF network. & 2015 Elsevier B.V. All rights reserved.	algorithm;artificial neural network;cluster analysis;computation;decision boundary;display resolution;feedforward neural network;graphical user interface;heuristic;k-means clustering;layer (electronics);machine learning;maximum parsimony (phylogenetics);multilayer perceptron;norm (social);occam's razor;radial (radio);radial basis function network;resultant;turing machine	Dávila Patrícia Ferreira Cruz;Renato Dourado Maia;Leandro Augusto da Silva;Leandro Nunes de Castro	2016	Neurocomputing	10.1016/j.neucom.2015.03.106	hierarchical rbf;computer science;machine learning;pattern recognition;data mining;artificial neural network	AI	13.740407802196081	-25.190605856361785	156653
cdddfbd094fc9099f9af3bdd5e287df0a2ae49cf	a bayesian network approach to explaining time series with changing structure	bayesian network;time series;multivariate time series;research paper;dynamic bayesian network;dependence structure	Many examples exist of multivariate time series where dependencies between variables change over time. If these changing dependencies are not taken into account, any model that is learnt from the data will average over the different dependency structures. Paradigms that try to explain underlying processes and observed events in multivariate time series must explicitly model these changes in order to allow non-experts to analyse and understand such data. In this paper we have developed a method for generating explanations in multivariate time series that takes into account changing dependency structure. We make use of a dynamic Bayesian network model with hidden nodes. We introduce a representation and search technique for learning such models from data and test it on synthetic time series and real-world data from an oil refinery, both of which contain changing underlying structure. We compare our method to an existing EM-based method for learning structure. Results are very promising for our method and we include sample explanations, generated from models learnt from the refinery dataset.	control engineering;dependency grammar;deterministic algorithm;dynamic bayesian network;markov chain;network model;simulated annealing;smoothing;swift (programming language);synthetic intelligence;time series	Allan Tucker;Xiaohui Liu	2004	Intell. Data Anal.		econometrics;computer science;machine learning;time series;bayesian network;data mining;dynamic bayesian network;statistics	AI	22.31313050542911	-24.180229972485698	156749
ee86cb4949e380b8dad96fb66070702a6bbaf712	minimizing the effects of parameter deviations on cellular neural networks	cellular neural networks;cellular neural network	The sensitivity of cellular neural networks (CNN) against random parameter deviations is discussed in detail. For different CNN with erroneous parameters the probability is estimated that all cell outputs converge to the same stable fixpoint of the corresponding error free CNN. These results are compared with approximations based on a statistical independence assumption. The influence of deviated parameters is demonstrated for different image processing templates. We propose a new parameter learning method for minimizing the effect of template and bias deviations. In all treated cases a significant improvement can be observed by using this method. Copyright © 1999 John Wiley u0026 Sons, Ltd.	artificial neural network	Ronald Tetzlaff;Ronald Kunz;Dietrich Wolf	1999	I. J. Circuit Theory and Applications	10.1002/(SICI)1097-007X(199901/02)27:1%3C77::AID-CTA41%3E3.0.CO;2-0	cellular neural network;image processing;computer science;artificial intelligence;machine learning;calculus;mathematics;artificial neural network;algorithm	ML	18.68753338712622	-28.92092979142587	156784
b74b9b3d6f336e7b66240173d3700bb53794575f	feature selection for a nonlinear classifier	detection forme;algorithme glouton;analisis forma;legendre polynomial;shape detection;deteccion forma;pattern classification;pattern recognition;greedy algorithm;algoritmo gloton;feature selection;pattern analysis;reconnaissance forme;reconocimiento patron;analyse forme;classification forme	The nonlinear classiier is eeective for many practical problems. We have already proposed a method for constructing a nonlinear classiier using Legendre polynomials and have obtained good results on many actual data. In this approach, a set of original features is rst extended to a large number of new features in a nonlinear fashion and then some substantial features are chosen for the nonlinear classiier. In this study, we have improved the selection process in the second stage by using some conventional feature selection algorithms. In addition, important features were selected from the original features in the preprocessing stage. The reduction in the number of the original features permits the nonlinear classiier to use a higher degree of polynomials.	algorithm;feature selection;legendre polynomials;nonlinear programming;nonlinear system;polynomial;preprocessor	Maiko Sato;Mineichi Kudo;Jun Toyama;Masaru Shimbo	1998		10.1007/BFb0033279	margin classifier;greedy algorithm;legendre polynomials;quadratic classifier;computer science;machine learning;pattern recognition;mathematics;feature selection;algorithm	Vision	11.280410114311517	-34.25843179302329	156854
f1da9214d7164717b1ec967c0b9182d4d5a3a790	temporal data encoding and sequencelearning with spiking neural networks	intervalo tiempo;occupation time;proceso llegada;arrival time;musica;base donnee temporelle;temporal data;time interval;arrival process;sequence learning;processus arrivee;learning system;spiking neural network;musique;temps occupation;recurrent network;inter spike interval;tiempo llegada;tiempo ocupacion;temporal data processing;temporal databases;reseau neuronal recurrent;melodia;recurrent neural nets;reseau neuronal;temps arrivee;music;red neuronal;melody;artificial neural network;neural network;melodie;intervalle temps	Sequence Learning using a Spiking Neural Network (SNN) was performed. An SNN is a type of Artificial Neural Network (ANN) that uses input signal arrival time information to process temporal data. An SNN can learn not only combinational inputs but also sequential inputs over some limited amount of time without using a recurrent network. Music melodies were encoded using unit amplitude spikes having various inter-spike interval times. These spikes were then fed into an SNN learning system. The SNN learning system was able to recognize various melodies after learning. The SNN could identify the original and noise-added melody versions properly in most cases.	codi;neural networks;spiking neural network	Robert H. Fujii;Kenjyu Oozeki	2006		10.1007/11840817_81	speech recognition;computer science;artificial intelligence;machine learning;temporal database;artificial neural network	ML	18.317639818359567	-26.411670700626402	157089
f08d23b2c4b381b3172e9b279c9299ef321d159c	performance analysis of lvq algorithms: a statistical physics approach	metodo adaptativo;evaluation performance;lvqi;condition initiale;teleenseignement;algorithmique;performance evaluation;algorithm analysis;data compression;cost function;learning;classification non supervisee;stabilite asymptotique;evaluacion prestacion;heuristic method;metodo heuristico;inicializacion;methode adaptative;intelligence artificielle;order parameters;online learning;fisica estadistica;lvq;asymptotic stability;cost analysis;funcion coste;analisis costo;kohonen algorithm;aprendizaje;prototipo;statistical physics;algoritmo kohonen;analyse cout;apprentissage;lfm;cuantificacion vectorial;condicion inicial;vq;vector quantization;algorithme kohonen;algorithmics;algoritmica;robustesse;clasificacion no supervisada;adaptive method;signal classification;initial condition;economic aspect;performance analysis;physique statistique;classification signal;unsupervised classification;fonction cout;lvq2 1;artificial intelligence;robustness;order parameter;analyse algorithme;aspect economique;teleensenanza;vector quantizer;methode heuristique;compresion dato;inteligencia artificial;estabilidad asintotica;remote teaching;prototype;thermodynamic limit;lvq1;aspecto economico;initialization;analisis algoritmo;initialisation;compression donnee;on line learning;learning vector quantization;robustez;quantification vectorielle	Learning vector quantization (LVQ) constitutes a powerful and intuitive method for adaptive nearest prototype classification. However, original LVQ has been introduced based on heuristics and numerous modifications exist to achieve better convergence and stability. Recently, a mathematical foundation by means of a cost function has been proposed which, as a limiting case, yields a learning rule similar to classical LVQ2.1. It also motivates a modification which shows better stability. However, the exact dynamics as well as the generalization ability of many LVQ algorithms have not been thoroughly investigated so far. Using concepts from statistical physics and the theory of on-line learning, we present a mathematical framework to analyse the performance of different LVQ algorithms in a typical scenario in terms of their dynamics, sensitivity to initial conditions, and generalization ability. Significant differences in the algorithmic stability and generalization ability can be found already for slightly different variants of LVQ. We study five LVQ algorithms in detail: Kohonen's original LVQ1, unsupervised vector quantization (VQ), a mixture of VQ and LVQ, LVQ2.1, and a variant of LVQ which is based on a cost function. Surprisingly, basic LVQ1 shows very good performance in terms of stability, asymptotic generalization ability, and robustness to initializations and model parameters which, in many cases, is superior to recent alternative proposals.	algorithm;convergence (action);generalization (psychology);heuristics;initial condition;learning rule;learning vector quantization;loss function;mathematics;online and offline;online machine learning;profiling (computer programming);prototype;stability (learning theory);teuvo kohonen	Anarta Ghosh;Michael Biehl;Barbara Hammer	2006	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2006.05.010	learning vector quantization;computer science;artificial intelligence;machine learning;mathematics;algorithmics;algorithm	ML	19.719948804989812	-28.662244534520507	157102
8a0bba4c3b6ea3a0db9b4aa15271f92dc2b99097	a model for learned bloom filters and optimizing by sandwiching		Recent work has suggested enhancing Bloom filters by using a pre-filter, based on applying machine learning to determine a function that models the data set the Bloom filter is meant to represent. Here we model such learned Bloom filters, with the following outcomes: (1) we clarify what guarantees can and cannot be associated with such a structure; (2) we show how to estimate what size the learning function must obtain in order to obtain improved performance; (3) we provide a simple method, sandwiching, for optimizing learned Bloom filters; and (4) we propose a design and analysis approach for a learned Bloomier filter, based on our modeling approach.	attempt;bloom filter;generalization (psychology);machine learning;mathematical optimization;optimizing compiler;question (inquiry)	Michael Mitzenmacher	2018			artificial intelligence;machine learning;computer science;bloom filter	ML	18.265240369962168	-35.94455481643452	157301
ddd7af603b9ce2d1c7f73f3a3725bcfa3df87863	pairwise classifier combination using belief functions	classifier fusion;evaluation performance;classifier combination;belief function;performance evaluation;evaluacion prestacion;evidence theory;probabilistic approach;classification;theorie evidence;combining classifier;teoria dempster shafer;enfoque probabilista;approche probabiliste;dempster shafer theory;signal classification;classification signal;polychotomous classification;classification automatique;automatic classification;clasificacion automatica;theorie dempster shafer	In the so-called pairwise approach to polychotomous classification, a multi-class problem is solved by combining classifiers trained to discriminate between each pair of classes. In this paper, this approach is revisited in the framework of the Dempster-Shafer theory of belief functions, a non-probabilistic framework for quantifying and manipulating partial knowledge. It is proposed to interpret the output of each pairwise classifiers by a conditional belief function. The problem of classifier combination then amounts to computing the non-conditional belief function which is the most consistent, according to some criterion, with the conditional belief functions provided by the classifiers. Experiments with various datasets demonstrate the good performances of this method as compared to previous approaches to the same problem.	binary classification;error detection and correction;experiment;learning classifier system;multiclass classification;naive bayes classifier;performance	Benjamin Quost;Thierry Denoeux;Marie-Hélène Masson	2007	Pattern Recognition Letters	10.1016/j.patrec.2006.11.002	dempster–shafer theory;biological classification;machine learning;pattern recognition;data mining;mathematics;statistics	ML	10.10269882710773	-34.355016462099414	157331
e97891bbf4cd8720553e3d76553aafc90e824d6c	multi-objective evolutionary algorithm for radial basis function neural network design	optimal solution;network design;multi objective evolutionary algorithm;chaotic time series;evolving neural networks;multiobjective evolutionary algorithm;radial basis function neural network;genetic algorithm;high performance;neural network	In this chapter, we present a multiobjective evolutionary algorithm based design procedure for radial-basis function neural  networks. A Hierarchical Rank Density Genetic Algorithm (HRDGA) is proposed to evolve the neural network’s topology and parameters  simultaneously. Compared with traditional genetic algorithm based designs for neural networks, the hierarchical approach addresses  several deficiencies highlighted in literature. In addition, the rank-density based fitness assignment technique is used to  optimize the performance and topology of the evolved neural network to tradeoff between the training performance and network  complexity. Instead of producing a single optimal solution, HRDGA provides a set of near-optimal neural networks to the designers so that they can have more flexibility for  the final decision-making based on certain preferences. In terms of searching for a near-complete set of candidate networks  with high performances, the networks designed by the proposed algorithm prove to be competitive, or even superior, to three  state-of-the-art designs for radial-basis function neural networks to predict Mackey-Glass chaotic time series.  	artificial neural network;evolutionary algorithm;radial (radio);radial basis function	Gary G. Yen	2006		10.1007/3-540-33019-4_10	evolutionary programming;stochastic neural network;feedforward neural network;mathematical optimization;probabilistic neural network;types of artificial neural networks;recurrent neural network;machine learning;evolutionary acquisition of neural topologies;time delay neural network;radial basis function network	ML	14.183356456570497	-24.33441417112327	157479
c6c1d8b18d19a6017e749a8e3d06615ff85942f9	negative learning rates and p-learning		We present a method of training a differentiable function approximator for a regression task using negative examples. We effect this training using negative learning rates. We also show how this method can be used to perform direct policy learning in a reinforcement learning setting. 1 Regression and Learning Rates The goal of regression analyses is to find a regression function, a function that models the relationship between the independent variables (the inputs) and the dependent variables (the outputs). When a complex relationship between these variables, an exact regression function is not sought. Instead an approximate regression function is used to model the relationship. Function approximators have been shown to be a sound method for finding approximate regression functions. Function approximates are generally trained using example input-output pairs from the function that is to be approximated. Given the input from the pair, the output of the function approximator is compared to the actual output from the example. The function approximator is then modified –possibly through gradient descent– so that its output matches the output in the example. This is one training step. The function approximator is not usually modified so vigorously that the output matches the example output perfectly for each training. Extreme modification of the approximator tends to result in the loss or forgetting of the previous examples, that is, the previous training is overwritten by too strong of an update. Also, updates that are too vigorous tend to negatively affect the approximator’s ability to generalize to unseen examples. Another issue occures when a function approximator is updated, the parameters of the model, it are changed. If these parameters are changed too quickly, they can overrun a computer’s ability to represent these numbers. This is sometimes known as model explosion and it prevents the use of the function approximator. To solve these and other problems, the updates to a function approximator are attenuated by a fractional amount, conceptualized as the learning rate. This allows the approximator to be pushed in the desired direction by a small, tunable amount. All approximators trained by gradient descent use a learning rate. Numerous methods have been developed to automatically compute learning rates. Many use the second derivative of the parameter change (where the first derivative is the raw magnitude and direction of the update. This basic method is used from the familiar Newton’s Method, to esoteric concave optimization methods. Other methods use previous update amounts to tune the learning rate. However, the most common method for setting a learning rate is to start with 0.1 and hope for the best. 1 ar X iv :1 60 3. 08 25 3v 2 [ cs .A I] 2 9 M ar 2 01 6 2 Learning Rates as a Learning Channel In regression, the learning rate does not contain information about what the approximator should output for any given input. This information is contained in the input-output example pairs. This is why the learning rate is always positive; a positive learning rate means that the approximator should match this example more closely. Still, there are many situations where we do not have access to good input-output pairs. The pairs we have access to might not be from the actual function we are trying to model, but from any other function. The pairs we have might be totally random. However, we might have access to a measure of how closely the output we have matches up with hypothetical output, given some input, from the function we are trying to approximate. For example, take input-output pair e = (x, z) where x is some input vector and z is an output vector. We would like our function approximator nn(x) to give us the correct output from our target function nn∗(x) = y, but we do not have access to any example nn∗(x) = y for any x. However, if we have a distance to desired output function function dist∗(x, z) → R that gives a similarity measure between z and nn∗(x) = y, we can still train nn(·) We would like to use dist∗(·, ·) as a training signal to train n. Learning rate is useful as a channel for this distance to desired output function training signal. To use the learning rate as a learning channel we can take each example in the training set and use it to assign a custom learning rate for each example. We should still have a global learning rate μ. Now, when we train on example i, the learning rate ri for example ei is μ× dist(xi, zi). Now we train a simple 2-layer artificial neural network to reproduce the sine function on the interval [−5, 5] with 40 example points. The network uses tanh activation function for the 128 hidden units. Each example is of the form ei = (xi, zi, ri) where xi = −5 + i × 0.25 and zi is drawn from a uniform distribution on the interval [−1, 1]. The value ri is the learning rate factor for example i calculated by the distance to desired output function dist(xi) = ri = |sin(xi)− zi|. Let’s see how this works in figure 1. Figure 1: Output of network trained with per example learning rates ri = dist(xi, zi).	activation function;approximation algorithm;artificial neural network;binary prefix;computable function;concave function;gradient descent;mathematical optimization;newton;newton's method;reinforcement learning;similarity measure;test set	Devon Merrill	2016	CoRR		semi-supervised learning;unsupervised learning;multi-task learning;artificial intelligence;machine learning;supervised learning;stability;generalization error	ML	17.800576565926345	-30.82483000352339	157483
5b2172e68d67df93be867700e745a81b86b63a71	shrinking the tube: a new support vector regression algorithm	support vector regression	A new algorithm for Support Vector regression is described. For a priori chosen , it automatically adjusts a flexible tube of minimal radius to the data such that at most a fraction of the data points lie outside. Moreover, it is shown how to use parametric tube shapes with non-constant radius. The algorithm is analysed theoretically and experimentally.	algorithm;data point;experiment;flexible-fuel vehicle;support vector machine;williams tube	Bernhard Schölkopf;Peter L. Bartlett;Alexander J. Smola;Robert C. Williamson	1998			support vector machine;mathematical optimization;computer science;machine learning;mathematics;statistics	ML	12.599488814394144	-30.554842356258725	157732
98ba4c2037c6e81380bae76add1fcb34cf3ecf41	deep recurrent neural network for multiple time slot frequency spectrum predictions of cognitive radio			cognitive radio;recurrent neural network	Zhi-Ling Tang;Si-Min Li	2017	TIIS	10.3837/tiis.2017.06.013	distributed computing;cognitive radio;computer science;artificial intelligence;machine learning;frequency spectrum;recurrent neural network	HCI	12.322085301061465	-26.918429946185647	157890
62a2bb0fccb8a61047d1e30813f27dab7bffd386	hierarchical growing cell structures: treegcs	unsupervised learning;hierarchical clustering;topology;hierarchical structure;pattern clustering;cluster;hierarchical;neural nets;unsupervised;tree data structures;trees mathematics;parameter settings hierarchical growing cell structures treegcs hierarchical clustering algorithm growing cell structure gcs neural network gcs algorithm network topology input vectors hierarchical clustering neural network innate hierarchical structure vector based data gcs foundation ascendant hierarchical clustering dendogram;network topology;learning by example;growing;neural;unsupervised learning neural nets learning by example trees mathematics tree data structures pattern clustering;clustering algorithms neural networks humans network topology stability information retrieval probability distribution helium hierarchical systems frequency;network;neural network	We propose a hierarchical clustering algorithm (TreeGCS) based upon the Growing Cell Structure (GCS) neural network of B. Fritzke (1993). Our algorithm refines and builds upon the GCS base, overcoming an inconsistency in the original GCS algorithm, where the network topology is susceptible to the ordering of the input vectors. Our algorithm is unsupervised, flexible, and dynamic and we have imposed no additional parameters on the underlying GCS algorithm. Our ultimate aim is a hierarchical clustering neural network that is both consistent and stable and identifies the innate hierarchical structure present in vector-based data. We demonstrate improved stability of the GCS foundation and evaluate our algorithm against the hierarchy generated by an ascendant hierarchical clustering dendogram. Our approach emulates the hierarchical clustering of the dendogram. It demonstrates the importance of the parameter settings for GCS and how they affect the stability of the clustering.		Victoria J. Hodge;Jim Austin	2001	IEEE Trans. Knowl. Data Eng.	10.1109/69.917561	computer science;machine learning;pattern recognition;cure data clustering algorithm;data mining;hierarchical clustering;tree;artificial neural network;network topology;hierarchy;hierarchical clustering of networks;cluster	DB	12.899248442103943	-32.30307274505501	157941
74a0cf32ea66ab35ee86bdc086c226565435bb8b	adapting to non-stationarity with growing expert ensembles	statistical machine learning;time series;online learning;data analysis;science learning;stationary process;evolutionary system	When dealing with time series with complex non-stationarities, low retrospective regret on individual realizations is a more appropriate goal than low prospective risk in expectation. Online learning algorithms provide powerful guarantees of this form, and have often been proposed for use with non-stationary processes because of their ability to switch between different forecasters or “experts”. However, existing methods assume that the set of experts whose forecasts are to be combined are all given at the start, which is not plausible when dealing with a genuinely historical or evolutionary system. We show how to modify the “fixed shares” algorithm for tracking the best expert to cope with a steadily growing set of experts, obtained by fitting new models to new data as it becomes available, and obtain regret bounds for the growing ensemble.	algorithm;approximation;complex systems;epoch (reference date);extrapolation;generative model;machine learning;prospective search;regret (decision theory);stationary process;time series	Cosma Rohilla Shalizi;Abigail Z. Jacobs;Aaron Clauset	2011	CoRR		stationary process;computer science;artificial intelligence;machine learning;time series;data mining;mathematics;data analysis;statistics	ML	23.102329584004973	-26.711888151229786	157977
2c7fcc7868350ef1f879021d5d952e676ed042d4	adaptive importance sampling for value function approximation in off-policy reinforcement learning	metodo adaptativo;fonction valeur;validacion cruzada;reutilizacion;reinforcement learning;error sistematico;methode adaptative;funcion valor;reuse;off policy reinforcement learning;importance weighted cross validation;adaptive importance sampling;apprentissage renforce;function approximation;bias;approximation d une fonction;adaptive method;echantillonnage importance;validation croisee;value function approximation;value function;policy iteration;cross validation;reseau neuronal;importance sampling;aprendizaje reforzado;efficient sample reuse;aproximacion de funciones;red neuronal;reutilisation;erreur systematique;variance;neural network;variancia	Off-policy reinforcement learning is aimed at efficiently using data samples gathered from a policy that is different from the currently optimized policy. A common approach is to use importance sampling techniques for compensating for the bias of value function estimators caused by the difference between the data-sampling policy and the target policy. However, existing off-policy methods often do not take the variance of the value function estimators explicitly into account and therefore their performance tends to be unstable. To cope with this problem, we propose using an adaptive importance sampling technique which allows us to actively control the trade-off between bias and variance. We further provide a method for optimally determining the trade-off parameter based on a variant of cross-validation. We demonstrate the usefulness of the proposed approach through simulations.	approximation;bellman equation;control theory;cross reactions;cross-validation (statistics);importance sampling;population parameter;reinforcement learning;sample variance;sampling (signal processing);sampling - surgical action;simulation;unstable medical device problem	Hirotaka Hachiya;Takayuki Akiyama;Masashi Sugiyama;Jan Peters	2009	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2009.01.002	econometrics;function approximation;importance sampling;computer science;artificial intelligence;machine learning;bias;reuse;mathematics;variance;bellman equation;reinforcement learning;artificial neural network;cross-validation;statistics	ML	11.621683289142823	-32.79394615036555	158014
2e1434eb5fb1832c8709ccda34222b36e2941b80	bayesian deep reinforcement learning via deep kernel learning				Junyu Xuan;Jie Lu;Zheng Yan;Guangquan Zhang	2018	Int. J. Comput. Intell. Syst.			ML	11.068983503645054	-26.835091232589814	158149
