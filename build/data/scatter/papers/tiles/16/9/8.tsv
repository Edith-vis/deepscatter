id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
ff9d8e52546cc961f16eaaa41e70b16ed9a8be57	finding stable models via quantum computation	search algorithm;quantum computer;programming language;quantum algorithm;answer set programming	Quantum computers have the potential to out-perform classical computers—certain quantum algorithms run much faster than any known alternative classical algorithm. For example, Grover showed that a quantum computer can search an unordered list ofN items in timeO( √ N), providing a quadratic speed-up over the classical algorithm. In this paper, we show that we can modify Grover’s search algorithm to give an algorithm that finds stable models of an Answer Set Program with a similar quadratic improvement over the classical algorithm. Marek and Remmel showed that Answer Set Programming (ASP) programs can uniformly solve all NP-search problems, so our quantum algorithm to find stable models of ASP programs also solves all NP-search problems. It follows that Answer Set Programming could provide a programming language for quantum computation.	apl;answer set programming;computation;computer;html element;programming language;quantum algorithm;quantum computing;quantum cryptography;search algorithm;stable model semantics	David A. Meyer;James Pommersheim;Jeffrey B. Remmel	2004			algorithm;theoretical computer science;computer science;quadratic equation;quantum algorithm;answer set programming;quantum computer;stable model semantics;search algorithm	Theory	10.750836072253326	17.76320107894817	48578
85ac21026d3fb83c70fea657c958ac9313480ee7	strong lower bounds for the prize collecting steiner problem in graphs	steiner problem;optimal solution;solution optimale;programacion entera;cutting plane;combinatorial algorithm;steiner problem in graphs;cutting;algorithme combinatoire;programmation en nombres entiers;decoupage;probleme steiner;upper bound;programacion lineal;integer programming;computer experiment;informatique theorique;solucion optima;68r10;borne inferieure;linear programming relaxation;linear programming;graph algorithm;programmation lineaire;prize collecting steiner problem in graphs;troquelado;algorithme graphe;integer program;lower bound;cota inferior;computer theory;informatica teorica	Given an undirected graph G with nonnegative edges costs and nonnegative vertex penalties, the prize collecting Steiner problem in graphs (PCSPG) seeks a tree of G with minimum weight. The weight of a tree is the sum of its edge costs plus the sum of the penalties of those vertices not spanned by the tree. In this paper, we present an integer programming formulation of the PCSPG and describe an algorithm to obtain lower bounds for the problem. The algorithm is based on polyhedral cutting planes and is initiated with tests that attempt to reduce the size of the input graph. Computational experiments were carried out to evaluate the strength of the formulation through its linear programming relaxation. The algorithm found optimal solutions for 99 out of the 114 instances tested. On 96 instances, integer solutions were found (thus generating optimal PCSPG solutions). On all but seven instances, lower bounds were equal to best known upper bounds (thus proving optimality of the upper bounds). Of these seven instances, four lower bounds were off by 1 of the best known upper bound. Nine new best known upper bounds were produced for the test set.	algorithm;computation;experiment;graph (discrete mathematics);integer programming;linear programming relaxation;minimum weight;off-by-one error;polyhedron;steiner tree problem;test set	Abilio Lucena;Mauricio G. C. Resende	2004	Discrete Applied Mathematics	10.1016/S0166-218X(03)00380-9	mathematical optimization;combinatorics;integer programming;steiner tree problem;linear programming;mathematics;upper and lower bounds;algorithm	Theory	22.374546742897923	13.26358028089058	48678
697ca84544ee8791d0a81a0dac915ad3a3cff72d	a composite algorithm for a concave-cost network flow problem	modelizacion;graph theory;teoria grafo;limite inferior;layer model;modelo capa;flujo optimo;heuristic method;metodo heuristico;reseau;theorie graphe;red;algorithme;modelisation;algorithm;minimizacion costo;minimisation cout;cost minimization;modele couche;flot optimal;methode heuristique;network flow;modeling;optimal flow;limite inferieure;lower bound;network;algoritmo	Le cout total de chaque arc est une fonction lineaire par morceaux, concave du flux total sur l'arc. On formule le probleme en programmation entiere mixte; on developpe un algorithme composite pour produire a la fois de bonnes limites inferieures et des solutions heuristiques	algorithm;concave function;flow network	Anantharam Balakrishnan;Stephen C. Graves	1989	Networks	10.1002/net.3230190202	combinatorics;flow network;systems modeling;graph theory;calculus;mathematics;upper and lower bounds;algorithm	ML	21.668577274181946	12.263978504233968	48753
a2729ac0a3d47786773666638ebaef95d5e2babb	rescheduling for machine disruption to minimize makespan and maximum lateness	dynamic programming;machine disruption;deterministic scheduling;rescheduling	We consider a scheduling problem where a set of jobs has already been scheduled to minimize some cost objective on a single machine when the machine becomes unavailable for a period of time. The decision-maker needs to reschedule the jobs without excessively disrupting the original schedule. The disruption is measured as the maximum time deviation, for any given job, between the original and new schedules. We examine a general model where the maximum time disruption appears both as a constraint and as part of the cost objective. For a scheduling cost modeled as the makespan or maximum lateness, we provide a pseudopolynomial time optimal algorithm, a constant factor approximation algorithm, and a fully polynomial time approximation scheme. The approximation algorithm has an asymptotically achievable worst-case performance ratio of 2 and has average performance close to optimal. Managerial insights are given on how scheduling costs are affected by machine disruption and the approximation algorithm.	apx;approximation algorithm;best, worst and average case;denial-of-service attack;dynamic programming;job stream;makespan;polynomial;polynomial-time approximation scheme;pseudo-polynomial time;schedule (computer science);scheduling (computing);time complexity;time deviation;unavailability	Zhixin Liu;Young K. Ro	2014	J. Scheduling	10.1007/s10951-014-0372-2	mathematical optimization;real-time computing;computer science;dynamic programming;mathematics	Theory	15.22531112891005	9.727471187320083	48783
5d187033ecc0759460c51057c9069bf091cd1283	g12 - towards the separation of problem modelling and problem solving	software platform;search;large scale;constraint programming;optimization;modeling;problem solving	This paper presents the G12 large scale optimisation software platform, and discusses aspects of its architecture.	problem solving	Mark Wallace	2009		10.1007/978-3-642-01929-6_2	mathematical optimization;constraint programming;systems modeling;computer science;theoretical computer science;machine learning	AI	20.144950126488695	7.790534585637682	48804
16a2513acc6a2ff78b9d2f7664c10b6eae62a8a4	maximum bipartite flow in networks with adaptive channel width	wireless network;polynomial time algorithm;base station;network model;network optimization;network theory	Traditionally, network optimization problems assume that each link in the network has a fixed capacity. Recent research in wireless networking has shown that it is possible to design networks where the capacity of the links can be changed adaptively to suit the needs of specific applications. In particular, one gets a choice of having a few high capacity outgoing links ormany low capacity ones at any node of the network. This motivates us to have a re-look at classical network optimization problems and design algorithms to solve them in this new framework. In particular, we consider the problem of maximum bipartite flow, which has been studied extensively in the fixed-capacity network model. One of the motivations for studying this problem arises from the need to maximize the throughput of an infrastructure wireless network comprising base-stations (one set of vertices in the bipartition) and clients (the other set of vertices in the bipartition). We show that this problem has a significantly different combinatorial structure in this new network model from the fixed-capacity one. While there are several polynomial time algorithms for the maximum bipartite flow problem in traditional networks, we show that the problem is NP-hard in the new model. In fact, our proof extends to showing that the problem is APXhard. We complement our lower bound by giving two algorithms for solving the problem approximately. The first algorithm is deterministic and achieves an approximation factor of O(logN), where N is the number of nodes in the network, while the second algorithm is randomized and achieves an approximation factor of e e−1 . © 2010 Elsevier B.V. All rights reserved.	antimatroid;approximation;approximation algorithm;chandra–toueg consensus algorithm;edge coloring;entropy maximization;flow network;graph coloring;ibm notes;mathematical optimization;maximum flow problem;np-hardness;network model;optimization problem;point of view (computer hardware company);randomized algorithm;rounding;scheduling (computing);submodular set function;throughput;time complexity;vertex (geometry)	Yossi Azar;Aleksander Madry;Thomas Moscibroda;Debmalya Panigrahi;Aravind Srinivasan	2009		10.1007/978-3-642-02930-1_29	network theory;optimization problem;maximum flow problem;mathematical optimization;combinatorics;flow network;minimum-cost flow problem;multi-commodity flow problem;computer science;artificial intelligence;base station;theoretical computer science;wireless network;network model;mathematics;assignment problem;algorithm	Theory	18.49240509376247	16.25660029588517	49005
c91b54f63c052baf7b6d7893044d03b4fe41d1cb	the composition of semi-finished inventories at a solid board plant	interval graph;bipartite matching;satisfiability;production process;decision support system;maximum clique;interval graphs;setup time;computer experiment;heuristics;set covering;covering problem;cardboard production;set cover	A solid board factory produces rectangular sheets of cardboard in two different formats, namely large formats and small formats. The production process consists of two stages separated by an inventory point. In the first stage a cardboard machine produces the large formats. In the second stage a part of the large formats is cut into small formats by a separate rotary cut machine. Due to very large setup times, technical restrictions, and trim losses, the cardboard machine is not able to produce these small formats. The company follows two policies to satisfy customer demands for rotary cut format orders. When the company applies the first policy, then for each customer order an ‘optimal’ large format (with respect to trim loss) is determined and produced on the cardboard machine. In case of the second policy, a stock of a restricted number of large formats is determined in such a way that the expected trim loss is minimal. The rotary cut format order then uses the most suitable standard large format from the stock. Currently, the dimensions of the standard large formats in the semi finished inventory are based on intuitive motives, with an accent on minimizing trim losses. From the trim loss perspective it is most efficient to produce each rotary cut format from a Faculty of Management and Organization, Product Systems Design, University of Groningen, PO Box 800, NL-9700 AV GRONINGEN y Faculty of Management and Organization, Product Systems Design, University of Groningen, PO Box 800, NL-9700 AV GRONINGEN, The Netherlands z Faculty of Economic Sciences, University of Groningen, PO Box 800, NL-9700 AV GRONINGEN, E-mail: g.sierksma@eco.rug.nl	inventory;rotary system;rotary woofer;semiconductor industry;systems design	Henrico L. T. Wanders;Gerard J. C. Gaalman;Gerard Sierksma	2004	European Journal of Operational Research	10.1016/S0377-2217(02)00853-6	mathematical optimization;simulation;interval graph;computer experiment;decision support system;bipartite graph;computer science;marketing;operations management;heuristics;mathematics;scheduling;set cover problem;satisfiability	ML	15.292204599957094	5.469442233706325	49016
6bd5162400b8f19abcffa2342266653d0fa01382	complexity of the min-max (regret) versions of cut problems	metodo minimax;minimax method;problema np duro;complexity;interval data;np hard problem;min max regret;s t min cut;probleme np difficile;methode minimax;min cut;min max	This paper investigates the complexity of the min-max and min-max regret versions of the s− t min cut and min cut problems. Even if the underlying problems are closely related and both polynomial, we show that the complexity of their min-max and min-max regret versions, for a constant number of scenarios, are quite contrasted since they are respectively strongly NP-hard and polynomial. Thus, we exhibit the first polynomial problem, s− t min cut, whose min-max (regret) versions are strongly NP-hard. Also, min cut is one of the few polynomial problems whose min-max (regret) versions remain polynomial. However, these versions become strongly NP-hard for a non constant number of scenarios. In the interval data case, min-max versions are trivially polynomial. Moreover, for min-max regret versions, we obtain the same contrasted result as for a constant number of scenarios: min-max regret s− t cut is strongly NP-hard whereas min-max regret cut is polynomial.	maxima and minima;minimum cut;np-hardness;polynomial;regret (decision theory);strong np-completeness	Hassene Aissi;Cristina Bazgan;Daniel Vanderpooten	2005		10.1007/11602613_79	mathematical optimization;combinatorics;discrete mathematics;complexity;max-flow min-cut theorem;computer science;np-hard;mathematics;algorithm	Theory	21.528682703960794	17.064157784036016	49445
10cebbe856dea7273c2332ce77a2e4257e325cab	load rebalancing games in dynamic systems with migration costs		We consider the following dynamic load balancing game: Given an initial assignment of jobs to identical parallel machines, the system is modified; specifically, some machines are added or removed. Each job’s cost is the load on the machine it is assigned to; thus, when machines are added, jobs have an incentive to migrate to the new unloaded machines. When machines are removed, the jobs assigned to them must be reassigned. Consequently, other jobs might also benefit from migrations. In our job-extension penalty model, for a given extension parameter δ ≥ 0, if the machine on which a job is assigned to in the modified schedule is different from its initial machine, then the job’s processing time is extended by δ. We provide answers to the basic questions arising in this model. Namely, the existence and calculation of a Nash Equilibrium and a Strong Nash Equilibrium, and their inefficiency compared to an optimal schedule. Our results show that the existence of job-migration penalties might lead to poor stable schedules; however, if the modification is a result of a sequence of improvement steps or, better, if the sequence of improvement steps can be supervised in some way (by forcing the jobs to play in a specific order) then any stable modified schedule approximates well an optimal one. Our work adds two realistic considerations to the study of job scheduling games: the analysis of the common situation in which systems are upgraded or suffer from failures, and the practical fact according to which job migrations are associated with a cost.	dynamical system;job scheduler;job stream;load balancing (computing);nash equilibrium;scheduling (computing)	Sofia Belikovetsky;Tami Tamir	2013		10.1007/978-3-642-41392-6_7	simulation;computer science;dynamical system;mathematics;operations research;algorithm;nash equilibrium	Theory	13.523304190586472	7.5297580861911255	49446
2ecb98b072d403d4e8687c7373bfe5b47793bbf7	checkcol: improved local search for graph coloring	graph coloring;settore mat 09 ricerca operativa;combinatorial optimization;local search	In this paper we present a novel coloring algorithm based on local search. We analyze its performance, and report several experimental results on DIMACS benchmark graphs. From our experiments, this algorithm looks robust, and yields a substantial speed up on previous algorithms for coloring. Our algorithm improves the best known coloring for four different DIMACS benchmark graphs: namely, Le450-25c, Le450-25d and Flat300_28_0 and Flat1000_76_0. Furthermore, we have run experiments on a simulator to get insights on its cache consciousness: from these experiments, it appears that the algorithm performs substantially less cache misses than other existing algorithms. © 2005 Elsevier B.V. All rights reserved.	algorithm;application checkpointing;benchmark (computing);cpu cache;combinatorial optimization;consciousness;experiment;graph coloring;local search (optimization);mathematical optimization;robustness (computer science);search algorithm;simulation;tabu search;timeline;vertex (graph theory)	Massimiliano Caramia;Paolo Dell'Olmo;Giuseppe F. Italiano	2006	J. Discrete Algorithms	10.1016/j.jda.2005.03.006	mathematical optimization;combinatorics;combinatorial optimization;local search;theoretical computer science;graph coloring;mathematics;greedy coloring	AI	24.205220044356427	4.269829332386713	49522
5072eff49936dbfe1166d54ead5e67d56cd8ef04	a note on tight lower bound for mnl-bandit assortment selection models		In this note we prove a tight lower bound for the MNL-bandit assortment selection model that matches the upper bound given in (Agrawal et al., 2016a,b) for all parameters, up to logarithmic factors.	multi-armed bandit	Xi Chen;Yining Wang	2017	CoRR		combinatorics;mathematical optimization;mathematics;logarithm;upper and lower bounds	ECom	17.652028798524945	17.313193680110995	49732
652c645776ccaa13fa976ac2d2ca82ec8d9493a7	the traveling salesman problem, edited by e. l. lawler, j. k. lenstra, a.h.g. rinnooy kan, and d.b. shmoys, john wiley & sons, chichester, 1985, 463 pp	traveling salesman problem		arjen lenstra;john d. wiley;travelling salesman problem	R. Johnson;M. G. Pilcher	1989	Networks	10.1002/net.3230190511		Theory	23.04419925510504	8.451426637170787	49819
5d762d337979b8b51769c68aced810f3c1c7d75f	technical note - a polynomial algorithm for the equal capacity p-center problem on trees	location theory;location problem;probleme localisation;transportes;temps polynomial;equipement collectif;structure arborescente;algorithme;equipamiento colectivo;transports;algorithm;estructura arborescente;polynomial algorithm;facility;tree structure;transportation;polynomial time;problema localizacion;algoritmo;tiempo polinomial	The uncapacitated p -center problem has been shown to be NP-Hard for the case of a general network, yet polynomial algorithms exist for the case of a tree network. We extend the results for trees to include the case where each center can serve a limited number of customers and show that the capacitated p -center problem on trees can be solved in polynomial time when the capacities are identical. The algorithm consists of solving a capacitated covering problem and then using search routines to find the optimal domination radius. We show that the addition of center capacities to either the vertex center problem or the absolute center problem requires a multiplicative factor of O ( n ) more work, relative to that required for the uncapacitated problems, to solve the related covering problems ( n is the number of vertices in the tree).	algorithm;polynomial	Mordechai Jaeger;Jeff Goldberg	1994	Transportation Science	10.1287/trsc.28.2.167	time complexity;transport;mathematical optimization;combinatorics;discrete mathematics;location theory;computer science;mathematics;tree structure;algorithm	Theory	21.221441191562842	13.6613392363463	50087
f6c245b52ca2d5c676c3783b8b7c325a2b9efb6c	counting popular matchings in house allocation problems		We study the problem of counting the number of popular matchings in a given instance. McDermid and Irving gave a poly-time algorithm for counting the number of popular matchings when the preference lists are strictly ordered. We first consider the case of ties in preference lists. Nasre proved that the problem of counting the number of popular matching is #P-hard when there are ties. We give an FPRAS for this problem. We then consider the popular matching problem where preference lists are strictly ordered but each house has a capacity associated with it. We give a switching graph characterization of popular matchings in this case. Such characterizations were studied earlier for the case of strictly ordered preference lists (McDermid and Irving) and for preference lists with ties (Nasre). We use our characterization to prove that counting popular matchings in capacitated case is #P-hard.	algorithm;matching (graph theory);p (complexity);polynomial-time approximation scheme;sharp-p;sharp-p-complete;wish list	Rupam Acharyya;Sourav Chakraborty;Nitesh Jha	2014		10.1007/978-3-319-06686-8_4	combinatorics;discrete mathematics;mathematics	Theory	17.86228737339862	17.26825787827427	50448
7227b81d1b95b903645df9c6c96563b44a672e13	an efficient algorithm for reverse 2-median problem on a cycle	network improvement;median;polynomial algorithm;combinatorial optimization	Location problems exist extensively in the real world and they mainly deal with finding optimal locations for facilities. However, the reverse location problem is also often met in practice, in which the facilities may already exist in a network and cannot be moved to a new place, the task is to improve the network within a given budget such that the improved network works as efficient as possible. This paper is dedicated to the problem of how to use a limited budget to modify the lengths of the edges on a cycle such that the overall sum of the weighted distances of the vertices to the respective closest facility of two prespecified vertices becomes as small as possible (shortly, R2MC problem). It has already been shown that the reverse 2median problem with edge length modification on general graphs is strongly NP-hard. In this paper, we transform the R2MC problem to a reverse 3-median problem on a path and show that this problem can be solved efficiently by strongly polynomial algorithm.	algorithm;mathematical optimization;np-hardness;optimization problem;polynomial;strong np-completeness;time complexity;vertex (geometry)	Qin Wang;Yanqin Bai	2010	JNW	10.4304/jnw.5.10.1169-1176	mathematical optimization;minimum-cost flow problem;combinatorial optimization;cutting stock problem;median;1-center problem;algorithm	Theory	21.8142237493075	15.168561020377078	50470
19fa577172c2192ba741c83efb50417640636b0d	minimizing node expansions in bidirectional search with consistent heuristics		A* is optimally effective with regard to node expansions among unidirectional admissible algorithms—those that only assume that the heuristic used is admissible. Among bidirectional algorithms the Fractional MM algorithm is optimally effective (given the correct parameters) among admissible algorithms. This paper generalizes the bidirectional result to more complex settings where more information on the problem domain can be exploited: (1) When the cost of the minimal edge is known. (2) When the algorithm knows that the heuristics are consistent. This characterization uses a novel algorithm called MT. MT is similar to Fractional MM and is also optimally effective, but simpler to analyze.	admissible heuristic;bidirectional search;heuristic (computer science);mm algorithm;problem domain	Eshed Shaham;Ariel Felner;Nathan R. Sturtevant;Jeffrey S. Rosenschein	2018			bidirectional search;mathematical optimization;heuristics;heuristic;mm algorithm;problem domain;mathematics	AI	24.56323823720525	7.890332560268174	50742
a5c398bf8b6aaf6c4d1fe1956392755b6a2d0496	a fast algorithm for generalized arc consistency of the alldifferent constraint			algorithm;local consistency	Xizhe Zhang;Qian Li;Weixiong Zhang	2018		10.24963/ijcai.2018/194	machine learning;artificial intelligence;local consistency;computer science	AI	11.204462186084276	15.628705086543471	50909
8301ff420fd11dd7c9d55b5ef11825ae7ae18417	an analysis of the alias method for discrete random-variate generation	simulation;analysis of algorithms;random variate generation;computational complexity;random variable generation;optimization	T paper introduces and studies an optimization problem related to the alias method for discrete randomvariate generation. The alias method is an efficient method to generate random variates from a discrete probability distribution. The efficiency of the alias method can be improved by designing the alias table such that the expected number of computations that must be performed per value generated is minimized. The problem of optimizing the construction of the alias table is proven to be strongly NP-hard, even if either of two variations of the alias method relaxing the alias-table-generation restrictions are used. Integer-programming formulations describing these three optimization problems are presented, and insights regarding necessary optimality criteria and relationships among their optimal solutions are discussed.	alias method;computation;integer programming;mathematical optimization;optimization problem;strong np-completeness	Jonathan Cole Smith;Sheldon H. Jacobson	2005	INFORMS Journal on Computing	10.1287/ijoc.1030.0063	mathematical optimization;computer science;analysis of algorithms;theoretical computer science;mathematics;computational complexity theory;algorithm;statistics	AI	22.51755169295593	14.495324420990515	50994
3574677e9fa63f4924fca07b72a449e37d2a4a48	espn: efficient server placement in probabilistic networks with budget constraint	radio networks;silicon;radio networks computational complexity network servers;multihop model;optimal solution;wireless channels;approximate algorithm;service provider;approximation algorithms;approximation method;wireless communication network0;computer model;wireless network;network service provider;unstable network;environmental effect;artificial intelligent;marketing strategy;wireless communication;servers;network servers;computational modeling;social science;machine learning;computational complexity;servers approximation algorithms computational modeling probabilistic logic algorithm design and analysis approximation methods silicon;efficient server placement;approximation methods;espn;heuristic algorithm espn efficient server placement probabilistic network budget constraint wireless communication network0 unstable network single hop model multihop model computational complexity np hard optimal algorithm;probabilistic logic;np hard;quality of service;experimental measurement;optimal algorithm;budget constraint;algorithm design;algorithm design and analysis;service quality;heuristic algorithm;single hop model;probabilistic network	The notion of probabilistic network has been used to characterize the unpredictable environment in wireless communication networks or other unstable networks. In this paper, we are interested in the problem of placing servers in probabilistic networks subject to budget constraint, so as to maximize the expected number of servable clients that can successfully connect to a server. We study this problem in both the single-hop model and the multi-hop model. We discuss the computational complexity of this problem and show that it is NP-hard under both models.We then develop efficient approximation algorithms, which produce solutions provably close to optimal. If the costs of candidate locations are uniform, when extra budget is available in the future, the progressive feature of our algorithms allows for placing additional servers instead of relocating all the servers, while retaining the guaranteed performance. Results of extensive experiments on different topologies confirm the performance of our algorithms compared to the optimal algorithm and other heuristic algorithms.	apollonian network;approximation algorithm;computational complexity theory;control theory;experiment;heuristic;np-hardness;server (computing);telecommunications network	Dejun Yang;Xi Fang;Guoliang Xue	2011	2011 Proceedings IEEE INFOCOM	10.1109/INFCOM.2011.5934908	algorithm design;probabilistic analysis of algorithms;computer science;theoretical computer science;distributed computing;approximation algorithm;computer network	DB	12.952710082292944	14.342659667151814	51001
841b85a280c6d998216ab07f2555cacc1f8afaad	grid brokering for batch allocation using indexes	computational grid;routing policies;fast algorithm;indexation;value of information;numerical simulation	In this paper we show how dynamic brokering for batch allocation in grids based on bi-dimensional indices can be used in practice in computational grids, with or without knowing the sizes of the jobs. We provide a fast algorithm (with a quadratic complexity) which can be used off-line or even on-line to compute the index tables. We also report numerous simulations providing numerical evidence of the great efficiency of our index routing policy as well as its robustness with respect to parameter changes. The value of information is also assessed by comparing the performance of indexes when the sizes of the jobs are known and when they are not known.	algorithm;numerical analysis;online and offline;routing;simulation	Vandy Berten;Bruno Gaujal	2007		10.1007/978-3-540-72709-5_23	computer simulation;mathematical optimization;computer science;theoretical computer science;value of information;data mining	HPC	18.143063206205237	10.217054985757532	51036
8571536088c0a795abe9b13a52a41b3c518ec116	bin-packing with fragile objects and frequency allocation in cellular networks	bin packing problem;bin packing;approximate algorithm;approximation;optimization problem;wireless communication;frequency allocation;cellular network;lower bound	We consider two related optimization problems: bin-packin g with fragile objects and frequency allocation in cellular networks. The former is a generaliza tion of the classical bin packing problem and is motivated by the latter. The problem is as follows: Eac h object has two attributes, weight and fragility. The goal is to pack objects into bins such that, fo r every bin, the sum of weights of objects in that bin is no more than the fragility of any object in that bin . We consider approximation algorithms for this problem. We p rovide a 2-approximation to the problem of minimizing the number of bins. We also show a lower boun d of 3/2 on the approximation ratio. Unlike for the classical bin packing problem, this lower bou nd holds in the asymptotic case. We then consider the approximation with respect to fragility and pr ovide a 2-approximation algorithm (i.e., our algorithm uses the same number of bins as the optimum but the w eight of objects in a bin can exceed the fragility by a factor of 2). We also give improved approximation algorithms for frequen cy allocation problem (which is a special case of bin-packing with fragile objects). Finally, we consider a probabilistic setting and show that our algorithm for frequency allocation approaches optimal ity s the number of users increases.	approximation algorithm;bin packing problem;cylinder-head-sector;frequency allocation;mathematical optimization;set packing	Nikhil Bansal;Zhen Liu;Arvind Sankar	2009	Wireless Networks	10.1007/s11276-007-0081-2	mathematical optimization;bin packing problem;telecommunications;computer science;bin	Theory	19.750278008723523	14.940557311687574	51039
b75f0a95de78b98e7dda7ff66a8bd9a23e82a83c	a general-purpose hill-climbing method for order independent minimum grouping problems: a case study in graph colouring and bin packing	bin packing problem;coloracion grafo;bin packing;metaheuristics;grouping;algorithme glouton;qa mathematics;heuristic method;packing;problema relleno;metodo heuristico;algoritmo genetico;optimisation combinatoire;resolucion problema;hill climbing method;coloration graphe;metamodel;general methods;metamodele;metamodelo;metodo escalada;algorithme genetique;greedy algorithm;probleme remplissage;algoritmo gloton;genetic algorithm;hill climbing;methode heuristique;agrupamiento;methode escalade;grouping genetic algorithm;combinatorial optimization;grouping problems;groupage;problem solving;resolution probleme;graph colouring;optimizacion combinatoria	A class of problems referred to as Order Independent Minimum Grouping Problems is examined and an intuitive hill-climbing method for solving such problems is proposed. Example applications of this generic method are made to two well-known problems belonging to this class: graph colouring and bin packing. Using a wide variety of different problem instance-types, these algorithms are compared to two other generic methods for this problem type: the iterated greedy algorithm and the grouping genetic algorithm. The results of these comparisons indicate that the presented applications of the hill-climbing approach are able to significantly outperform these algorithms in many cases. A number of reasons for these characteristics are given in the presented analyses.	benchmark (computing);bin packing problem;computation;density functional theory;emoticon;experiment;general-purpose modeling;genetic algorithm;graph coloring;greedy algorithm;heuristic (computer science);hill climbing;iteration;set packing;triplet state;whole earth 'lectronic link	Rhyd Lewis	2009	Computers & OR	10.1016/j.cor.2008.09.004	mathematical optimization;combinatorics;bin packing problem;combinatorial optimization;computer science;mathematics;algorithm	AI	21.90318790917667	6.310674456874524	51074
14f6fb2a77ec8c8ddeaed2174b0e64f218edd69d	a heuristic job scheduling decision support system a case study	decision support system application;relational database problem;production system;software systems;relational database;decision support system;scheduling problem;production systems;scheduling methodology;heuristic methodology;job scheduling;microcomputer application	Abstract   The daily activity of establishing a job assignment schedule for each individual employee in a manufacturing setting can be quite a complex management task. Work rules, special work load requirements and absenteeism all act to compound the scheduling activity. Many organizations have tried to solve their scheduling problems by developing software systems to handle their daily scheduling decision making. The purpose of this paper is to describe the development of a unique heuristic-based scheduling software system. The scheduling system is presented in the context of a real world case study for a major US manufacturer who sponsored the scheduling system's development.	ccir system a;decision support system;heuristic;job scheduler;scheduling (computing)	Marc J. Schniederjans;Donald A. Carpenter	1996	Decision Support Systems	10.1016/0167-9236(96)00024-3	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;real-time computing;flow shop scheduling;decision support system;dynamic priority scheduling;computer science;rate-monotonic scheduling;artificial intelligence;operations management;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;scheduling;production system;instruction scheduling;lottery scheduling	ECom	11.380918798581398	4.499449755488636	51183
73b00df4563607c8bcb4a018eaea8daa1c5821e2	an approximation algorithm for interval data minmax regret combinatorial optimization problems	approximate algorithm;procesamiento informacion;algorithm performance;temps polynomial;algorithm analysis;regret minimax;approximation algorithms;optimisation robuste;approximation algorithm;combinatorial optimization problem;problema np duro;robust optimization;interval data;optimisation combinatoire;np hard problem;aproximacion polinomial;probleme np difficile;resultado algoritmo;informatique theorique;information processing;approximation polynomiale;algoritmo aproximacion;polynomial time;performance algorithme;maximal regret;analyse algorithme;algorithme approximation;performance ratio;traitement information;combinatorial optimization;analisis algoritmo;polynomial approximation;optimizacion combinatoria;computer theory;tiempo polinomial;informatica teorica	The general problem of minimizing the maximal regret in combinatorial optimization problems with interval data is cons In many cases, the minmax regret versions of the classical, polynomially solvable, combinatorial optimization problems NP-hard and no approximation algorithms for them have been known. Our main result is a polynomial time approximati rithm with a performance ratio of 2 for this class of problems.  2005 Elsevier B.V. All rights reserved.	approximation algorithm;combinatorial optimization;decision problem;mathematical optimization;maximal set;minimax;np-hardness;polynomial;regret (decision theory);time complexity	Adam Kasperski;Pawel Zielinski	2006	Inf. Process. Lett.	10.1016/j.ipl.2005.11.001	time complexity;optimization problem;mathematical optimization;combinatorics;computer science;np-hard;mathematics;l-reduction;approximation algorithm;algorithm	Theory	20.872734879353665	13.89085464585965	51224
f41b62bb8eba7993db9bcdbf2219ec95b512a253	bounding the optimum of constraint optimization problems	algoritmo busqueda;local search algorithm;algorithme recherche;search algorithm;logical programming;constraint satisfaction;optimisation combinatoire;upper bound;constraint optimization problem;resolucion problema;satisfaction contrainte;programmation logique;constraint satisfaction problem;satisfaccion restriccion;combinatorial optimization;programacion logica;problem solving;resolution probleme;optimizacion combinatoria	Solving constraint optimization problems is computationa lly so expensive that it is often impossible to provide a guaranteed o ptimal solution, either when the problem is too large, or when time is bounded. In thes e cases, local search algorithms usually provide goodsolutions. However, and even if an optimality proof is unreachable, it is often desirable to have so me guarantee on the quality of the solution found, in order to decide if it is wort hwile to spend more time on the problem. This paper is dedicated to the production of intervals, that bound as precisely as possible the optimum of Valued Constraint Satisfaction Problems (VCSP). Such intervals provide an upper bound on the distance of the best a vailable solution to the optimumi.e., on the quality of the optimization performed. Experimenta l results on randomVCSPsand real problems are given.	backtrack;constrained optimization;constraint satisfaction;local search (optimization);mathematical optimization;optimization problem;program optimization;search algorithm;unreachable memory;value (ethics)	Simon de Givry;Gérard Verfaillie;Thomas Schiex	1997		10.1007/BFb0017456	mathematical optimization;combinatorics;constraint satisfaction;combinatorial optimization;computer science;local search;mathematics;upper and lower bounds;constraint satisfaction problem;algorithm;search algorithm	AI	18.428865653342974	11.174761407818698	51411
b79ab72c0b66b1277d21679c1a4c12a12af7c5f9	on time-sensitive revenue management and energy scheduling in green data centers		In this paper, we design an analytically and experimentally better online energy and job scheduling algorithm with the objective of maximizing net profit for a service provider in green data centers. We first study the previously known algorithms and conclude that these online algorithms have provable poor performance against their worst-case scenarios. To guarantee an online algorithm’s performance in hindsight, we design a randomized algorithm to schedule energy and jobs in the data centers and prove the algorithm’s expected competitive ratio in various settings. Our algorithm is theoretical-sound and it outperforms the previously known algorithms in many settings using both real traces and simulated data. An optimal offline algorithm is also implemented as an empirical benchmark.	benchmark (computing);best, worst and average case;competitive analysis (online algorithm);data center;experiment;job scheduler;job stream;online algorithm;online and offline;provable security;randomized algorithm;schedule (project management);scheduling (computing);tracing (software)	Huangxin Wang;Jean X. Zhang;Fei Li	2014	CoRR		competitive analysis;real-time computing;simulation;computer science;distributed computing	Theory	14.037090638502313	11.670498508962956	51413
cfc3e2a12cffe45819e7bb15fc02e7cb140946ee	a grasp algorithm based new heuristic for the capacitated location routing problem		AbstractIn this paper, the capacitated location-routing problem (CLRP) is studied. CLRP is composed of two hard optimisation problems: the facility location problem and the vehicle routing problem. The objective of CLRP is to determine the best location of multiple depots with their vehicle routes such that the total cost of the solution is minimal. To solve this problem, we propose a greedy randomised adaptive search procedure. The proposed method is based on a new heuristic to construct a feasible CLRP solution, and then a local search-based simulated annealing is used as improvement phase. We have used a new technique to construct the clusters around the depots. To prove the effectiveness of our algorithm, several LRP instances are used. The results found are very encouraging.	algorithm;grasp;heuristic;routing	Imene Ferdi;Abdesslem Layeb	2018	J. Exp. Theor. Artif. Intell.	10.1080/0952813X.2017.1421268	artificial intelligence;vehicle routing problem;machine learning;computer science;local search (optimization);facility location problem;simulated annealing;total cost;grasp;algorithm;heuristic	Robotics	23.77647959250775	5.236490823214388	51425
8c33c0e6ca782812b63cf5a6cd27749f00c7b74f	max ones generalized to larger domains	informatica;computadora;assignment;asignacion;optimisation;language class;nombre entier;groupoide;machine a apprendre;maximo;optimizacion;ordinateur;algebra universal;technology;calcul formel;65kxx;assignation;restriction;optimization method;maximum;teknikvetenskap;computer;constraint satisfaction;classification;metodo optimizacion;apprentissage machine;68t05;recherche;calculo formal;permutation;49xx;integer;satisfaction contrainte;engineering and technology;68q17;teknik och teknologier;08a70;machine learning;groupoid;grupoide;90c27;conexion;classe langage;entero;raccordement;permutacion;68xx;methode optimisation;68q25;informatique;optimization;satisfaccion restriccion;contrainte ensemble;computer science;cardinalite;combinatorial optimization;algebre universelle;universal algebra;computer algebra;investigacion;connection;clasificacion;combinatorial optimisation;approximability;20l05;clase lenguaje	We study a family of problems, called Maximum Solution, where the objective is to maximize a linear goal function over the feasible integer assignments to a set of variables subject to a set of constraints. When the domain is Boolean (i.e., restricted to $\{0,1\}$), the maximum solution problem is identical to the well-studied Max Ones problem, and the approximability is completely understood for all restrictions on the underlying constraints [S. Khanna, M. Sudan, L. Trevisan, and D. P. Williamson, SIAM J. Comput., 30 (2001), pp. 1863-1920]. We continue this line of research by considering domains containing more than two elements. We present two main results: a complete classification for the approximability of all maximal constraint languages over domains of cardinality at most $4$, and a complete classification of the approximability of the problem when the set of allowed constraints contains all permutation constraints. Under the assumption that a conjecture due to Szczepara [Minimal Clones Generated by Groupoids, Ph.D. thesis, Universite de Montreal, Montreal, QC, 1996] holds, we give a complete classification for all maximal constraint languages. These classes of languages are well studied in universal algebra and computer science; they have, for instance, been considered in connection with machine learning and constraint satisfaction. Our results are proved by using algebraic results from clone theory, and the results indicate that this approach is very powerful for classifying the approximability of certain optimization problems.	max	Peter Jonsson;Fredrik Kuivinen;Gustav Nordh	2008	SIAM J. Comput.	10.1137/060669231	integer;universal algebra;mathematical optimization;combinatorics;constraint satisfaction;connection;combinatorial optimization;assignment;mathematics;permutation;constraint;groupoid;algorithm;algebra;technology	Theory	22.94134058343529	14.014491335393584	51863
96cc902487e5eec452a5405919f4345e4107874d	valid inequalities for non-unit demand capacitated spanning tree problems with flow costs	multicommodity flow;optimal solution;subset sum problems;subset sum problem;capacitated trees;valid inequalities;operations research;ciencia;model validation;low voltage;projetos;investigacao;publicacoes;single and multicommodity flow models;spanning tree;electricity distribution;capacitated minimum spanning tree;iscte iul;lower bound	We discuss valid inequalities for a variation of the capacitated minimum spanning tree problem which considers variable  ̄ow costs. This variation with  ̄ow costs arises in the design of low voltage electricity distribution networks (see Bousba, C., Wolsey, L., 1991. Annals of Operations Research 33, 285±303) or in the design of telephone networks (see Balakrishnan, A., Magnanti, T., Wong, R., 1995. Operations Research, 43, 58±76). We start by pointing out that most of the ideas discussed in the past for the unit-demand versions of the problem are hardly applied to versions with general demands on the nodes. Then, in the context of a  ̄ow-based model we propose some valid inequalities for the problem which are based on the optimal solution of an adequate subset sum problem and which ``make sense'' only when the node demands are dierent. We also consider a multicommodity reformulation of the original model and adapt for this model the inequalities proposed for the single-commodity  ̄ow models. We present an exponentially sized set of lower bounding constraints which are valid for the original  ̄ow-based model and which are implied by the compact multicommodity reformulation. Finally, computational results are presented. Ó 2000 Elsevier Science B.V. All rights reserved. Keywords: Capacitated trees; Single and multicommodity  ̄ow models; Valid inequalities; Subset sum problems 1. Introduction Consider a directed graph G (V, A) with V  f0; 1; . . . ; ng and 0 is the root node, qj is the nonnegative integer demand associated with terminal node j, j  1; . . . ; n, Q is the nonnegative integer capacity on the arcs, dij is the cost of a unit  ̄ow on arc (i, j) and cij is the ®xed cost associated with a positive  ̄ow on arc (i, j). We want to ®nd a minimum cost (®xed cost plus variable cost) arborescence rooted at node 0 such that the demand at each node and the capacity constraints are satis®ed. The variation of this capacitated minimum spanning tree problem where  ̄ow costs are ignored has been extensively studied in the literature European Journal of Operational Research 121 (2000) 394±411 www.elsevier.com/locate/orms * Corresponding author. E-mail addresses: lgouveia@fc.ul.pt (L. Gouveia), Maria. Joao.Lopes@iscte.pt (M.J. Lopes). 0377-2217/00/$ see front matter Ó 2000 Elsevier Science B.V. All rights reserved. PII: S 0 3 7 7 2 2 1 7 ( 9 9 ) 0 0 0 4 3 0 (see, for instance, Hall, 1996; Amberg et al., 1996; Gouveia and Martins, 1996). On the other hand, the variation including  ̄ow costs (which is the problem studied in this paper) has been almost neglected in the literature and, as far as we know, Bousba and Wolsey (1991) is the only work addressing capacitated trees with  ̄ow costs. They use this problem as a model for the design of low voltage electricity distribution networks. Flow costs model energy losses on the links of the network. The problem can be used also as a model for the design of telephone networks, where ®xed arc costs model link installation costs and  ̄ow costs model cable installation and usage costs (see Balakrishnan et al. (1995) for a related and more complicated version of this problem). To present a mixed-integer linear programming model for the problem, let xij denote the binary variable indicating whether the directed arc (i, j) is included in the solution and let yij be a nonnegative variable indicating the amount of  ̄ow on arc (i, j). We have then a single-commodity  ̄ow formulation for the problem which is similar to the one given in Bousba and Wolsey (1991) (see also Gavish, 1982 for the case without  ̄ow costs): Formulation SCF0: min Xn i0 Xn j1 cij xij  Xn i0 Xn j1 dij yij 1 s.t. Xn i0 xij  1; j  1; . . . ; n; 2 Xn i0 yij ÿ Xn i1 yji  qj; j  1; . . . ; n; 3 yij6Q xij; i  0; . . . ; n; j  1; . . . ; n; 4 yij P 0; i  0; . . . ; n; j  1; . . . ; n; 5 xij 2 f0; 1g; i  0; . . . ; n; j  1; . . . ; n: 6 Variables xij and yij with i j are ignored from the model. Because no trac  ̄ows back into the root node, we can also assume that xi0  yi0  0 for all i  1; . . . ; n, or equivalently, that these variables do not exist. For simplicity, all the models presented in this work are de®ned in a complete graph and we consider xij 0 and yij 0 for all the arcs (i, j) not in A. Constraints (2) guarantee that one and only one arc converges into each terminal node. Constraints (3) are  ̄ow conservation constraints guaranteeing the demand at each terminal node ( ̄ow conservation constraints on node 0 are implied by constraints (3) and the equalities yi0  0 i  1; . . . ; n and thus, are omitted). Constraints (4) together with constraints (3) guarantee that the solution is connected. Constraints (3), (4) and (2) guarantee that the xij variables de®ne a directed spanning tree rooted at node 0. The coecient Q in constraints (4) guarantees that the  ̄ow in each arc is not greater than Q. It is easy to see that the  ̄ow on arc (i, j) gives the sum of the demands of the nodes that are disconnected from the root if that arc is removed from the solution. Thus, the sum of the demands on any subtree o of the root node cannot be greater than Q because the maximum ̄ow in any arc leaving the root is equal to Q. The linear programming (LP) relaxation of the formulation SCF0 is in general rather weak. Different ways of tightening its LP relaxation are discussed next. Let us consider, ®rst, the case of the upper bounding inequalities (4). Notice that qi units of demand have to be satis®ed at node i. Then, the  ̄ow on arc (i, j) cannot be greater than (Q ÿ qi), otherwise the  ̄ow on the arc incoming into node i will be greater than Q which is unfeasible. This yields the following inequality (see Gavish, 1982): yij6 Qÿ qixij; i; j  1; . . . ; n: 7 Later, Gavish (1983) has also suggested a simple way of tightening constraints (5): yij P qj xij; i  0; . . . ; n; j  1; . . . ; n: 8 The validity of (8) follows from the condition that if xij 1 then the  ̄ow on arc (i, j) must be enough to satisfy the demand at node j. The model SCF0 with (4) for i; j  1; . . . ; n, replaced by (7) and (5) replaced by (8) will be denoted by SCF1. The formulations SCF0 and SCF1 are directed formulations because for each feasible link it considers two arcs corresponding to the two L. Gouveia, M.J. Lopes / European Journal of Operational Research 121 (2000) 394±411 395	binary data;directed graph;emoticon;file spanning;integer programming;lagrangian relaxation;linear inequality;linear programming relaxation;maxima and minima;minimum spanning tree;operations research;personally identifiable information;programming model;stm32;social inequality;subset sum problem;tree (data structure)	Luís Gouveia;Maria João Lopes	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00043-0	mathematical optimization;combinatorics;multi-commodity flow problem;spanning tree;mathematics;regression model validation;mathematical economics;upper and lower bounds;low voltage;subset sum problem	Theory	23.202080325557805	18.061798066563057	51881
16c93a803bb8af8dc59abac4e9a7a226aab5396e	a heuristic algorithm for cube packing with time schedule	optimal solution;time complexity;space distance;simulated annealing algorithm;birth order;three dimensional;np hard problem;packing level;time schedule;theoretical analysis;greedy algorithm;genetic algorithm;average neighbor birth order;cube packing problem;heuristic algorithm	Packing problem has been proved to be an NP-hard problem. Many algorithms such as simulation annealing algorithm, genetic algorithm and other heuristic algorithms have been proposed to solve two-dimensional and three-dimensional packing problem. To solve the cube packing problem with time schedule, this paper first introduces some concepts such as packing level, space distance and average neighbor birth order and then proposes a greedy algorithm. The algorithm tries every feasible corner greedily to calculate the space utilization, packing level, space distance, average neighbor birth order of this placement, and chooses the best placement according to these criteria. Theoretical analysis indicates that the time complexity of this algorithm is O(A 2 B 2 C 2 T 2 n 5). The experiments show that the average space utilization of non-guillotine cutting test cases is 98.81%, and the average space utilization of guillotine cutting test cases achieves 99.87%. Furthermore, optimal solutions of more than half cases are achieved by this algorithm. The experimental results show that this algorithm can solve the problem of cube packing with time schedule effectively and efficiently.	bin packing problem;computational complexity theory;deterministic algorithm;entity–relationship model;experiment;feasible region;genetic algorithm;greedy algorithm;heuristic (computer science);mathematical optimization;np-hardness;olap cube;rev;set packing;simulated annealing;simulation;traverse;test case;time complexity	Wei Li;Wenqi Huang;Dongchen Jiang;Xianglong Liu	2010	Science in China Series F: Information Sciences	10.1007/s11432-010-0022-z	heuristic;time complexity;three-dimensional space;mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;bin packing problem;set packing;genetic algorithm;simulated annealing;computer science;np-hard;klee–minty cube;mathematics;algorithmics;algorithm	DB	23.588675622042583	5.672146402077103	52069
ed9d14073b7ab26ab612adc90755e3fe2876f1dc	sparse monge matrices arising from scheduling problems	transportation problem;monge matrices;scheduling;air traffic management	Recently Ball, Hoffman and Mukherjee showed that a certain stochastic scheduling problem arising in air traffic flow management could be solved by a simple greedy algorithm. In this paper we relate this result to Monge matrices and Monge sequences.	scheduling (computing);sparse	Charles N. Glover;Michael O. Ball	2013	Oper. Res. Lett.	10.1016/j.orl.2013.01.011	transportation theory;mathematical optimization;theoretical computer science;mathematics;distributed computing;scheduling	Theory	22.14101789829977	8.994827466845601	52109
4ad84da0266a09aff82f0b4f63a8f51117ed48c1	asymptotic optimality of bestfit for stochastic bin packing	fat trees;reliability;data center networks;random graphs;hypergrids;capacity	In the static bin packing problem, items of diffierent sizes must be packed into bins or servers with unit capacity in a way that minimizes the number of bins used, and it is well-known to be a hard combinatorial problem. Best-Fit is among the simplest online heuristics for this problem. Motivated by the problem of packing virtual machines in servers in the cloud, we consider the dynamic version of this problem, when jobs arrive randomly over time and leave the system after completion of their service. We analyze the uid limits of the system under an asymptotic Best-Fit algorithm and show that it asymptotically minimizes the number of servers used in steady state (on the uid scale). The significance of the result is due to the fact that Best-Fit seems to achieve the best performance in practice.	asymptotically optimal algorithm;best practice;bin packing problem;cloud computing;heuristic (computer science);job stream;randomness;set packing;steady state;virtual machine	Javad Ghaderi;Yuan Zhong;R. Srikant	2014	SIGMETRICS Performance Evaluation Review	10.1145/2667522.2667543	random graph;mathematical optimization;combinatorics;bin packing problem;reliability;mathematics;statistics	Theory	15.654824544836297	12.432113795021973	52192
59aca4c677942c792ed8d0bd388877dead850f4d	majorization theory in sensor scheduling	sensors scheduling;objective function upper bound minimization majorization theory single normal sensor scheduling distributed pattern communication time scheduling local computation capability general order system;job shop scheduling;majorization theory networked control systems sensor scheduling;processor scheduling;optimal scheduling;schedules;linear programming;optimal scheduling job shop scheduling processor scheduling intelligent sensors schedules linear programming;intelligent sensors	This paper presents that the majorization theory plays an essential role in a class of sensor scheduling problems, whose solutions all have periodic or uniformly distributed patterns. This paper revisits the problem of communication time scheduling for a single sensor with local computation capability, and strengthens its original result by the majorization theory. The scheduling for a single normal sensor in a general-order system is also studied, and the optimal schedules for minimizing the upper bound of the objective function is provided. Examples are provided at the end.	chao (sonic);computation;denial-of-service attack;ibm notes;loss function;optimization problem;schedule (computer science);scheduling (computing);sensor;smart transducer;yang	Chao Yang;Wen Yang;Hongbo Shi	2015	2015 54th IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2015.7402679	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;job shop scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;schedule;computer science;linear programming;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;stride scheduling;mathematics;distributed computing;scheduling;gain scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling;i/o scheduling;intelligent sensor	Robotics	13.996207524917255	12.512244361951105	52223
52d40a6751f356ec70548c341c7476ee436c515a	the joint distribution of elastic buckets in multiway search trees	arbre recherche;random graph;analyse multivariable;multivariate analysis;05c05;loi conjointe;grafo aleatorio;60f05;graphe aleatoire;searching;search trees;arbol investigacion;68p05;ley conjunta;analisis multivariable;multivariate statistics;search tree;joint distribution;random trees	Random search trees are studied when they grow under a general computer memory management scheme. In a general scheme, the space is released in buckets of certain predesignated sizes. For a search tree with branch factor $m$, the nodes may hold up to $m-1$ keys. Suppose the buckets of the memory management scheme that can hold less than $m$ keys have key capacities $c_1, \ldots,c_p$. The search tree must then be implemented with multitype nodes of these capacities. After $n$ insertions, let $X_n^{(i)}$ be the number of buckets of type $i$ (i.e., of capacity $c_i$, $1{\leq}i{\leq}p$). The multivariate structure of the tree is investigated. For the vector {\bf X}$_n = (X_n^{(1)}, \ldots, X_n^{(p)})^T$, the asymptotic mean and covariance matrix are determined. Under practical memory management schemes, all variances and covariances experience a phase transition: For $3 \leq m \leq 26$, all variances and covariances are asymptotically linear in $n$; for higher branch factors the variances and covariances become a superlinear (but subquadratic) function of $n$. The joint distribution of {\bf X}$_n$ is shown to be multivariate normal in a range of $m$. While the tree is growing, conversions between types are necessary. A multivariate problem concerning these conversions with an asymptotic multivariate normal distribution is also studied. The fixed bucket, exact fit, and buddy system allocation schemes will serve as illustrating examples.		William Lew;Hosam M. Mahmoud	1994	SIAM J. Comput.	10.1137/S009753979223023X	random graph;multivariate statistics;mathematical optimization;combinatorics;discrete mathematics;mathematics;multivariate analysis;search tree;joint probability distribution;algorithm;statistics	Theory	15.488193457312603	15.093603752375719	52305
4e009cf5735fb9c69a1929a844814f1f3af2926b	an improved branch - and - cut algorithm for the capacitated vehicle routing problem	vehicle fleets;capacite charge;graph theory;evaluation performance;teoria grafo;performance evaluation;trafico mercaderia;routing;vehicle routing problem;implementation;road traffic;estudio comparativo;evaluacion prestacion;capacitated vehicle routing problem;simulacion numerica;probleme tournee vehicule;goods traffic;problema ruta vehiculo;theorie graphe;customer service;delivery vehicles;algorithme;etude comparative;algorithm;ejecucion;temps calcul;trafic routier;capacidad carga;mathematical models;simulation numerique;comparative study;algorithms;load capacity;branch and cut algorithms;trafico carretera;trip length;vehicle capacity;tiempo computacion;computation time;branch and cut;trafic marchandise;delivery service;numerical simulation;algoritmo	The capacitated vehicle routing problem (CVRP) deals with the distribution of a single commodity from a centralized depot to a number of specified customer locations with known demands. The CVRP considered in this paper assumes common vehicle capacity, fixed or variable number of vehicles, and an objective to minimize the total distance traveled by all the vehicles. This paper develops several new cutting planes for this problem, and uses them in an exact branch-and-cut algorithm. Two of the new cutting planes are based on a specified structure of an optimal solution and its existence. Computational results are reported for 1,650 simulated Euclidean problems as well as 24 standard literature test problems; solved problems range in size from 15--100 customers. A comparative analysis demonstrates the significant computational benefit of the proposed method.	algorithm;branch and cut;vehicle routing problem	N. R. Achuthan;Lou Caccetta;Stephen P. Hill	2003	Transportation Science	10.1287/trsc.37.2.153.15243	mathematical optimization;routing;simulation;computer science;engineering;graph theory;operations management;vehicle routing problem;comparative research;mathematical model;mathematics;transport engineering;implementation;algorithm;branch and cut	Theory	17.72660337648816	5.498785100589729	52340
a923d074c68c14d72149c2babed74f8eecf8151e	fixed-charge transportation problem: facets of the projection polyhedron	transportation problem;grupo de excelencia;integer programming;ciencias basicas y experimentales;matematicas;branch and cut;grupo a;fixed charge	In this paper we consider the well-known fixed-charge transportation problem. To send any flow from source si to destination tj, we incur a unit variable shipping cost of cij and a fixed cost fij. Here we study the structure of the projection polyhedron of this problem, in the space of 0-1 variables associated with fixed charges, and we develop several classes of valid inequalities and derive conditions under which they are facet defining. In some cases, if the conditions are not satisfied, we show how they can be lifted to define facets. Several heuristics for generating and adding these facets are presented. Using these results, we develop a computationally effective algorithm for solving the problem. The computational results clearly indicate the usefulness of this approach.	polyhedron	Yogesh Agarwal;Yash P. Aneja	2012	Operations Research	10.1287/opre.1120.1041	transportation theory;mathematical optimization;combinatorics;integer programming;mathematics;geometry;branch and cut	Theory	21.785207681218417	10.789421300057446	52526
957e173926d30e072e4dcbd281bbef7548dc0af8	roof duality, complementation and persistency in quadratic 0-1 optimization	optimal solution;discrete optimization;maximum flow;polynomial time;pseudo boolean	The paper is concerned with the ‘primal’ problem of maximizing a given quadratic pseudo-boolean function. Four equivalent problems are discussed—the primal, the ‘complementation’, the ‘discrete Rhys LP’ and the ‘weighted stability problem of a SAM graph’. Each of them has a relaxation—the ‘roof dual’, the ‘quadratic complementation,’ the ‘continuous Rhys LP’ and the ‘fractional weighted stability problem of a SAM graph’. The main result is that the four gaps associated with the four relaxations are equal. Furthermore, a solution to any of these problems leads at once to solutions of the other three equivalent ones. The four relaxations can be solved in polynomial time by transforming them to a bipartite maximum flow problem. The optimal solutions of the ‘roof-dual’ define ‘best’ linear majorantsp(x) off, having the following persistency property: if theith coefficient inp is positive (negative) thenxi=1 (0) in every optimum of the primal problem. Several characterizations are given for the case where these persistency results cannot be used to fix any variable of the primal. On the other hand, a class of gap-free functions (properly including the supermodular ones) is exhibited.	duality gap;mathematical optimization;pseudo-boolean function	Peter L. Hammer;Pierre Hansen;Bruno Simeone	1984	Math. Program.	10.1007/BF02612354	time complexity;discrete optimization;maximum flow problem;mathematical optimization;combinatorics;discrete mathematics;mathematics	Vision	23.59197702462828	15.467052660766647	52634
ab4a75d6fa3de8da38b730fb7588458a2ec6fb5e	illustrating constraint programming systems in logistic planning	optimal solution;constraint logic programs;model system;hd 30 w66 v 95 85 1995;mathematical programming;constraint programming;facility location problem;logic programs	Logistic systems analysts use a wide array of modeling systems such as algebraic and logic programs. Two simple examples show how they mesh as Constraint Logic programs, emphasizing the visual style of formulation. A facility location problem is solved in Prolog. Its standard mathematical programming formulation is then represented in CLP(9~) to reach an optimal solution faster. The examples are chosen to raise systemic issues such as model re-use and adaptability that are at the heart of logistic analysis and planning.	automated planning and scheduling;clp(r);constraint programming;facility location problem;logic programming;mathematical optimization;prolog	Jean-Michel Thizy	1994		10.1007/3-540-61478-8_93	constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;binary constraint;constraint satisfaction;programming domain;reactive programming;functional reactive programming;computer science;constraint graph;facility location problem;machine learning;procedural programming;inductive programming;fifth-generation programming language;prolog;algorithm;hybrid algorithm	AI	20.066175722528655	7.8705733882897695	52636
ead4672da64400161cf0ff034ab0b546a7b18cc0	a heuristic local search algorithm for unsatisfiable cores extraction	unsatisfiable core;local search algorithm;backtrack search;equality reduction;binary clause resolution;sat solver;local search;unit clause propagation	Explaining the causes of infeasibility of Boolean formulas has many practical applications in various fields. We are generally interested in a small explanation of unsatisfiability that excludes irrelevant information. A small unsatisfiable core provides a succinct explanation of infeasibility and is valuable for applications. In recent years the problem of finding unsatisfiable subformulas has been addressed frequently by research works, which are mostly based on the SAT solvers with DPLL backtrack-search algorithm. However little attention has been concentrated on extraction of unsatisfiable cores using incomplete methods. In this paper, we propose a heuristic-based local search algorithm to derive unsatisfiable cores. This approach directly constructs the resolution sequence for proving unsatisfiability with a local search procedure, and then extracts small unsatisfiable cores from the sequence. We report and analyze the experimental results on benchmarks.	artificial intelligence;backtracking;benchmark (computing);boolean expression;boolean satisfiability problem;conjunctive normal form;dpll algorithm;electronic design automation;formal verification;genetic algorithm;greedy algorithm;heuristic (computer science);local search (optimization);relevance;search algorithm;software propagation;unit propagation	Jianmin Zhang;ShengYu Shen;Sikun Li	2007		10.1007/978-3-540-74484-9_56	mathematical optimization;discrete mathematics;computer science;local search;mathematics;algorithm	AI	12.558806725605935	16.930734135580312	52684
0b37e691c81aa523faed604ed8a3a9a8f6655fdd	scheduling on parallel machines with preemption and transportation delays	np completeness;dynamic program;transportation delays;fptas;scheduling;preemption;parallel machines	This paper deals with an identical parallel machines scheduling problem, where independent jobs can be preempted and transported from one machine to another. The transportation of a preempted job requires a time called the transportation delay. The goal is to find a solution that minimizes the total completion time (makespan). We first study the case of equal-size jobs where new complexity results are given. Then, to solve the problem with two identical machines, we present a dynamic programming algorithm and a fully polynomial time approximation scheme (FPTAS). Experimental results show the efficiency of the FPTAS compared to a previously published heuristic.	preemption (computing);schedule (project management)	Amina Haned;Ameur Soukhal;Mourad Boudhar;Nguyen Huynh Tuong	2012	Computers & OR	10.1016/j.cor.2011.04.013	mathematical optimization;real-time computing;np-complete;computer science;distributed computing;preemption;scheduling	NLP	15.648743068879094	9.479708753188111	53096
dd03008f2d0cc047b0419f529d117cdf26f47e21	solving weighted max-sat via global equilibrium search	probleme satisfiabilite;global equilibrium search;weighted maximum satisfiability;maximum satisfiability;heuristic method;metodo heuristico;satisfiability;satisfiabilite maximum;satisfactibilidad maxima;problema satisfactibilidad;heuristics;methode heuristique;high efficiency;satisfiability problem	In this note we investigate the performance of global equilibrium search based heuristics on the weighted MAX-SAT problem. Three variants of the approach are implemented and compared with other existing algorithms on publicly available benchmark instances. The reported computational results indicate high efficiency of the method considered. c © 2008 Elsevier B.V. All rights reserved.	algorithm;benchmark (computing);computation;heuristic (computer science);max;maximum satisfiability problem	Oleg V. Shylo;Oleg A. Prokopyev;Vladimir Shylo	2008	Oper. Res. Lett.	10.1016/j.orl.2007.11.007	mathematical optimization;combinatorics;computer science;maximum satisfiability problem;heuristics;mathematics;boolean satisfiability problem;algorithm;satisfiability	AI	21.968663375875014	6.3302397803075845	53691
5c5dcfe37b960e241feda1a845bc9fa2bb2170c3	new algorithms for approximate nash equilibria in bimatrix games	approximate algorithm;approximation error;nash equilibria;polynomial time algorithm;noncooperative games;additive approximation;zero sum game;linear pro gramming;bimatrix game	We consider the problem of computing additively approximate Nash equilibria in non-cooperative two-player games. We provide a new polynomial time algorithm that achieves an approximation guarantee of 0.36392. Our work improves the previously best known (0.38197 + )-approximation algorithm of Daskalakis, Mehta and Papadimitriou [6]. First, we provide a simpler algorithm, which also achieves 0.38197. This algorithm is then tuned, improving the approximation error to 0.36392. Our method is relatively fast, as it requires solving only one linear program and it is based on using the solution of an auxiliary zerosum game as a starting point.	approximation algorithm;approximation error;linear programming;nash equilibrium;p (complexity);polynomial	Hartwig Bosse;Jaroslaw Byrka;Evangelos Markakis	2007		10.1007/978-3-540-77105-0_6	mathematical optimization;approximation error;combinatorics;best response;economics;lemke–howson algorithm;mathematics;normal-form game;zero-sum game;mathematical economics;nash equilibrium	ECom	17.958174752374667	16.299944813337376	53765
48070ae5e511108c8610eb9ea216503a22813d26	a constraint logic programming algorithm for modeling dynamic pricing	constraint logic programs;revenue management;hd28 management industrial management;simulation;qa76 electronic computers computer science computer software;analysis of algorithms;dynamic pricing;artificial intelligence;constraint logic programming	We extend Lemke's algorithm to solve a dynamic pricing problem. We identify an instance in which Lemke's algorithm fails to converge to an optimal solution (when an optimum does exist) and propose a constraint logic programming solution to this problem. We analyze the complexity of the extended Lemke's algorithm. Our analysis shows that, in the short term, dynamic pricing can be used to improve resource management efficiency. It is also shown that dynamic pricing can be used to manage the long-term behavior of demand.	algorithm;constraint logic programming	Fernando S. Oliveira	2008	INFORMS Journal on Computing	10.1287/ijoc.1060.0218	constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;simulation;constraint satisfaction;computer science;analysis of algorithms;theoretical computer science;algorithm	EDA	20.18153835267491	5.01639960104034	53934
d5f7a9b6c6fdc2d9c5185f7cdaf61fa422deee30	optimal algorithms for sensitivity analysis in associative multiplication problems	mathematics;sensitivity analysis;optimal algorithm	AbstraeL We consider efficient ways of determining the sensitivity of a product to changes in individual factors. The task is motivated by several interesting combinatorial and numeric problems which can be given a unified formulation as the problem of findi.n~ the (associative) product of N objects. Both deterministic and probabilistic changes to the factors are considered. Algorithms for two kinds of deterministic variation schemes are considered. No atrivial lower bounds are obtained which demonstrate the algorithms to be optimal. For prob~bilistic choice of the parameter' to be varied, it is shown that optimal ordere6 binary search t~ees or Huffman trees determine the optimal strategies. A number of unsolved problems are posed.	binary search algorithm;huffman coding	Arnon Rosenthal	1981	Theor. Comput. Sci.	10.1016/0304-3975(81)90006-2	mathematical optimization;combinatorics;discrete mathematics;probabilistic analysis of algorithms;computer science;mathematics;sensitivity analysis;algorithm;algebra	Theory	19.859966566616436	13.258473827440811	53947
adaa9232d47ac045bc48fb2a272dbad201f11a10	improved online algorithms for 1-space bounded 2-dimensional bin packing	bin packing problem;online algorithm;bin packing;conference_paper;packing algorithms;lower bounds;2 dimensional;on line algorithms;lower bound;competitive ratio	In this paper, we study 1-space bounded 2-dimensional bin packing and square packing. A sequence of rectangular items (square items, respectively) arrive over time, which must be packed into square bins of size 1×1. 90-rotation of an item is allowed. When an item arrives, we must pack it into an active bin immediately without any knowledge of the future items. The objective is to minimize the total number of bins used for packing all the items in the sequence. In the 1-space bounded variant, there is only one active bin for packing the current item. If the active bin does not have enough space to pack the item, it must be closed and a new active bin is opened. Our contributions are as follows: For 1-space bounded 2-dimensional bin packing, we propose an online packing strategy with competitive ratio 5.155, surpassing the previous 8.84-competitive bound. The lower bound of competitive ratio is also improved from 2.5 to 3. Furthermore, we study 1-space bounded square packing, which is a special case of the bin packing problem. We give a 4.5-competitive packing algorithm, and prove that the lower bound of competitive ratio is at least 8/3.	bin packing problem;competitive analysis (online algorithm);online algorithm;set packing	Yong Zhang;Jing-Chi Chen;Francis Y. L. Chin;Xin Han;Hing-Fung Ting;Yung H. Tsin	2010		10.1007/978-3-642-17514-5_21	mathematical optimization;combinatorics;bin packing problem;apx;computer science;mathematics;bin;square packing in a square	Theory	17.068287881016147	15.027606459066577	54227
2cea5c9af34f97a0785fc17ee7e0b9955b142814	an evaluation of the temporal coherence heuristic in partial-order planning	heuristic;metric;heuristic problem solving;intelligence artificielle;resolucion problema;planificacion;artificial intelligence;metrico;planning;inteligencia artificial;temporal coherence;planification;ai planning;metrique;problem solving;resolution probleme;partial order	This paper presents an evaluation of a heuristic for partial order planning known as temporal coherence The temporal coherence heuristic was proposed by Drummond and Currie as a method to improve the e ciency of partial order planning without losing the ability to nd a solution i e completeness It works by using a set of domain constraints to prune away plans that do not make sense or temporally inco herent Our analysis shows that while intuitively appealing temporal coherence can only be applied to a very speci c implementation of a partial order planner and still maintain completeness Furthermore the heuristic does not always improve planning e ciency in some cases its application can actually degrade the e ciency of planning dramatically To understand when the heuristic will work well we conducted complex ity analysis and empirical tests Our results show that temporal coherence works well when strong domain constraints exist that signi cantly reduce the search space when the number of subgoals is small when the plan size is not too large and when it is inexpensive to check each domain constraint	coherence (physics);data domain;heuristic;partial-order planning	Qiang Yang;Cheryl Murray	1994	Computational Intelligence	10.1111/j.1467-8640.1994.tb00165.x	partially ordered set;planning;mathematical optimization;heuristic;metric;computer science;artificial intelligence;machine learning;algorithm	AI	12.235388935171894	15.482054967230493	54472
79dcf0f2be74a3f74ee8c386c9829198cfc17c00	c-sets-based sequential heuristic procedure for the one-dimensional cutting stock problem with pattern reduction	cutting stock;look ahead;cutting stock problem;one dimensional cutting;pattern reduction;look ahead strategy	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	algorithm;autocatalytic set;computation;cutting stock problem;francis;fuzzy set;heuristic;mathematical optimization;primary source;shapefile;time complexity	Yaodong Cui;Zhiyong Liu	2011	Optimization Methods and Software	10.1080/10556780903420531	mathematical optimization;cutting stock problem;mathematics	Robotics	11.968736466689455	10.160322664684514	54494
a4ef55254e5c56fc607e909cca4a614471081e40	complexity of single machine scheduling problems under scenario-based uncertainty	modelizacion;maximal cost;absolute robustness;algorithmique;single machine scheduling;machine unique;complexite calcul;donnees incertaines;scenario based uncertainty;scenario;modelisation;robustesse absolue;systeme incertain;complejidad computacion;single machine;maquina unica;argumento;algorithmics;algoritmica;computational complexity;scheduling;robustesse;script;robust deviation;optimal schedule;robustness;sistema incierto;scheduling problems;scenarios;modeling;uncertain system;uncertain processing;ordonnancement;reglamento;robustez;chapitre d ouvrage	We consider scheduling environments where some job characteristics are uncertain. This uncertainty is modeled through a finite set of well-defined scenarios. In such a context, we search for a solution that is acceptable for any considered scenario. For this purpose, several criteria can be applied to select among solutions. We use here the so-called absolute robustness criterion. We present algorithmic and computational complexity results for several single machine scheduling problems.	computational complexity theory;robustness (computer science);scheduling (computing);single-machine scheduling	Mohamed Ali Aloulou;Federico Della Croce	2008	Oper. Res. Lett.	10.1016/j.orl.2007.11.005	mathematical optimization;real-time computing;simulation;systems modeling;computer science;scenario;computational complexity theory;algorithmics;scheduling;robustness	HPC	17.32330377837312	10.27186456132489	54616
9700c83abc4cd901329e1cbfddd55568d99daf54	applying self-organizing agents to university class scheduling	multiagent system;agent systems;scheduling problem;self organization	We propose a self-organizing agent system to solve a sched- uling problem. The proposed application takes into account various re- strictions relative to Japanese university class scheduling in particular. A multiagent system of agents representing requirements of professors and departments are introduced. Scheduling is solved using a black- board model and negotiation between these agents. Through a software simulation, we were able to show that our proposed method success- fully applies the self-organizing nature of agents to solve the schedul- ing problem.	scheduling (computing)	Eiji Nunohiro;Kenneth J. Mackin	2003		10.1007/978-3-540-45226-3_192	fair-share scheduling;simulation;dynamic priority scheduling;computer science;artificial intelligence;operations management	AI	12.085352650942047	6.778039774260508	54747
7fed5e7a7fe5800ce403c75b7320fcf27d9de053	dynamic learning optimization algorithm for p2p-vod systems		Nowadays Video-on-Demand are widely used and number of customers increases, consequently, many network problems must be solved to ensure the quality of service. One of the solutions that has proved its efficiency consists in using Peer-to Peers architecture. However, they raise challenges such as peers resource allocation. Most literature on tackle the problem with optimal static rules found at off-line study of the system. In this paper, we propose to formulate this problem as a dynamic optimization problem, then, solve it using a dynamic learning based optimization algorithm. The obtained results show that using a dynamic resource allocation reduces the rejection rate while enhancing the entropy of the system, in the face of a dynamically changing title demand.	algorithm;application release automation;dynamic programming;evolution strategy;kernel density estimation;mathematical optimization;network switch;online and offline;optimization problem;peer-to-peer;performance;quality of service;rejection sampling	Amir Nakib;Thibaud Rohmer;El-Ghazali Talbi;Abdelhamid Nafaa	2017	2017 IEEE 19th International Conference on High Performance Computing and Communications; IEEE 15th International Conference on Smart City; IEEE 3rd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)	10.1109/HPCC-SmartCity-DSS.2017.51	rejection rate;distributed computing;real-time computing;quality of service;architecture;computer science;algorithm;resource allocation;optimization problem	Robotics	11.959011482802117	9.358424975172671	55239
325157db08e387f1464700000c94d547c4a6fbf8	on algebraic and graph structural properties of assembly petri net - searching by linear programming	optimization problem;assembly planning;assembly sequence assembly petri net linear programming assembly planning state shift equation optimization problem;mathematical model;robotic assembly linear programming equations robotics and automation;linear program;petri nets;petri net;structural properties	---t&y usin.g th.e Petri I L C ~ convent i .a1 AND/OR n,et. S con.dEg, the state shift equation off?%; n.ett which is '8,,,,,$$~&t+ that t h e w 6 a.sis so1ution)of a state shift matr ix is iden,tical to the set of a solution which corres on.ds to a.n. a.ctu.a,l a,ssem.bly se uenxe. Th.is 6 th,a,tA&cond%$n optim,ization problem which m.in,imizes a s u m m a t i o n of a weight value of induded in th,e assembly sequen -+HA is a.n.alyzed. Prw+i%is analyszsh	linear algebra;linear programming;petri net	Takahide Kanehara;Tatsuya Suzuki;Akio Inaba;Shigeru Okuma	1993		10.1109/IROS.1993.583945	mathematical optimization;combinatorics;discrete mathematics;stochastic petri net;computer science;linear programming;petri net	Vision	20.083299819891263	12.325461897631087	55286
54886891ade3f84833ac7747fe6ace614b62c4bb	tabu search vs. random walk	intelligence artificielle;operations research;satisfiability;constraint satisfaction;optimisation combinatoire;satisfaction contrainte;guided local search;recherche operationnelle;random walk;artificial intelligence;tabu search;constraint satisfaction problem;inteligencia artificial;satisfaccion restriccion;combinatorial optimization;investigacion operacional;busqueda tabu;recherche tabou;optimizacion combinatoria	We investigate the beneet of Tabu Search for satissability (SAT) and constraint satisfaction problems (CSP) and compare it to the more frequently used random walk heuristic. We argue, that a more deterministic direction of search as done with Tabu Search is worth considering also for SAT and CSP. We give experimental evidence that Tabu Search can be used to eeciently guide local search procedures like GSAT and WSAT for SAT and the min connicts heuristic for CSP. The algorithms are tested on randomly generated problems and hard graph coloring instances from the DIMACS benchmark test set. Additionally, we give some explanation on the value of Tabu Search.	algorithm;benchmark (computing);constraint satisfaction problem;graph coloring;heuristic;local search (optimization);maxima and minima;procedural generation;randomness;tabu search;test set	Olaf Steinmann;Antje Strohmaier;Thomas Stützle	1997		10.1007/3540634932_27	beam search;mathematical optimization;constraint satisfaction;combinatorial optimization;tabu search;computer science;artificial intelligence;machine learning;mathematics;incremental heuristic search;constraint satisfaction problem;random walk;guided local search;satisfiability	AI	21.932334003943488	6.2613193731722605	55311
3ab90217dd8b6ba22323ca255af9fea420cb7a87	a kind of adaptive negotiation mechanism for flexible job shop scheduling	technology;computer science artificial intelligence;lagrangean relaxation;science technology;auction;computer science;framework	Agent-based production scheduling is a promising approach to solve production scheduling problem, especially in a dynamic, uncertain environment. In the system, agents are connected through a network and negotiate with each other to fulfill scheduling. The negotiation mechanism specifies the way in which negotiation should take place. This paper proposes an adaptive negotiation framework and two kinds of negotiation policies to fulfill scheduling and rescheduling in the flexible job shop. The mechanism makes the system more adaptive in dynamic production environments. The computational experiments are given to demonstrate the feasibility and performance of the mechanism.	job shop scheduling;scheduling (computing)	Cixing Lv;Zhongqi Sheng;Sufen Li;Chaowan Yin;Yunlong Zhu	2006		10.1007/11816171_42	fair-share scheduling;job shop scheduling;simulation;flow shop scheduling;dynamic priority scheduling;engineering;artificial intelligence;operations management;two-level scheduling	AI	12.389695658068588	6.251446404766754	55341
ea45ca312f4a93ccc5d194f5c718f3b824e13a18	single machine scheduling with assignable due dates	assignment;asignacion;temps polynomial;single machine scheduling;gestion labor;machine unique;complexite calcul;assignment of release times;probleme np complet;assignment of due dates;assignation;date echeance;fonction objectif;objective function;polynomial time algorithm;complejidad computacion;single machine;maquina unica;gestion tâche;computational complexity;scheduling;due date;polynomial time;fecha vencimiento;funcion objetivo;np complete;ordonamiento;machine scheduling;problema np completo;task scheduling;generalized due dates;ordonnancement;np complete problem;tiempo polinomial	This paper introduces a new subclass of machine scheduling problems in which due dates are treated as variables and must be assigned to the individual jobs. A solution then is a sequence of jobs along with due date assignments. In contrast to existing due date assignment models, solutions to the proposed problems do not depend on predetermined rules or the requirement that due dates be assigned in the same order as the sequence. The single machine case is investigated in detail Complexity results are presented for all common objective functions and processing restrictions. The analysis shows that in a number of instances polynomial time algorithms are available though most problems that are intractable under traditional due date definitions remain so.	scheduling (computing);single-machine scheduling	Xiangtong Qi;Gang Yu;Jonathan F. Bard	2002	Discrete Applied Mathematics	10.1016/S0166-218X(01)00316-X	mathematical optimization;np-complete;computer science;algorithm	Theory	16.767518031652337	10.08789100207207	55467
d21111a8ce5e1c790e22a76fae4c5bebedd27419	a survey of the generalized assignment problem and its applications	generalized assignment problem;applications;knapsack	Given n items and m knapsacks, the Generalized Assignment Problem (GAP) is to find the optimum assignment of each item to exactly one knapsack, without exceeding the capacity of any knapsack. This problem can also be described as the optimal assignment of n jobs to m capacitated agents. During the last three decades, many papers have been published on the GAP. In this survey we mainly concentrate on its real-life applications in scheduling, timetabling, telecommunication, facility location, transportation, production planning, etc. We also mention some of the most recent solution approaches: from state-of-the-art metaheuristics to variable neighborhood search algorithms and from exact solution procedures to simple heuristic algorithms.	generalized assignment problem;heuristic;metaheuristic;real life;scheduling (computing);search algorithm;timeline;variable neighborhood search	Temel Öncan	2007	INFOR	10.3138/infor.45.3.123	continuous knapsack problem;mathematical optimization;combinatorics;linear bottleneck assignment problem;computer science;generalized assignment problem;operations management;mathematics;weapon target assignment problem;knapsack problem;information technology	AI	17.617031081310586	4.256789070670301	55482
df873998cf973ab22bb2138df056607ca25b1970	a 0/1 integer programming model for the office space allocation problem	soft constraints;satisfiability;integer program;combinatorial optimisation	We propose a 0/1 integer programming model to tackle the office space allocatio n (OSA) problem which refers to assigning room space to a set of entities (people, machines, roles, etc.), with the goal of optimising the space utilisation while satisfying a set of additio nal requirements. In the proposed approach, these requirements can be mode lled as constraints (hard constraints) or as objectives (soft constraints). Then, we con du t some experiments on benchmark instances and observe that setting certain constraints as ha rd (actual constraints) or soft (objectives) has a significant impact on the computational difficulty on this combinatorial optimisation problem.	benchmark (computing);combinatorial optimization;computation;entity;experiment;integer programming;mathematical optimization;naruto shippuden: clash of ninja revolution 3;programming model;requirement;space allocation problem	Özgür Ülker;Dario Landa Silva	2010	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2010.05.073	mathematical optimization;combinatorics;mathematics;constraint;algorithm;satisfiability	ML	19.733974786424398	5.199212723635844	55586
01f0351a8b3bb80a595eebbee9cf1d380f5439e7	linear sum assignment with edition		We consider the problem of transforming a set of elements into another by a sequence of elementary edit operations, namely substitutions, removals and insertions of elements. Each possible edit operation is penalized by a non-negative cost and the cost of a transformation is measured by summing the costs of its operations. A solution to this problem consists in defining a transformation having a minimal cost, among all possible transformations. To compute such a solution, the classical approach consists in representing removal and insertion operations by augmenting the two sets so that they get the same size. This allows to express the problem as a linear sum assignment problem (LSAP), which thus finds an optimal bijection (or permutation, perfect matching) between the two augmented sets. While the LSAP is known to be efficiently solvable in polynomial time complexity, for instance with the Hungarian algorithm, useless time and memory are spent to treat the elements which have been added to the initial sets. In this report, we show that the problem can be formalized as an extension of the LSAP which considers only one additional element in each set to represent removal and insertion operations. A solution to the problem is no longer represented as a bijection between the two augmented sets. We show that the considered problem is a binary linear program (BLP) very close to the LSAP. While it can be solved by any BLP solver, we propose an adaptation of the Hungarian algorithm which improves the time and memory complexities previously obtained by the approach based on the LSAP. The importance of the improvement increases as the size of the two sets and their absolute difference increase. Based on the analysis of the problem presented in this report, other classical algorithms can be adapted.	assignment problem;decision problem;event loop;hungarian algorithm;ibm systems network architecture;iteration;linear programming;matching (graph theory);one-class classification;paging;polynomial;rough set;solver;superuser;time complexity;xfig	Sébastien Bougleux;Luc Brun	2016	CoRR		mathematical optimization;combinatorics;computer science;mathematics;algorithm;statistics	Theory	23.84068315832512	13.961399539820563	55829
a23400862e55ca600b784357ed2afd94291941b7	using algorithm configuration tools to generate hard sat benchmarks.		Algorithm configuration tools have been successfully used to speed up local search satisfiability (SAT) solvers and other search algorithms by orders of magnitude. In this paper, we show that such tools are also very useful for generating hard SAT formulas with a planted solution, which is useful for benchmarking SAT solving algorithms and also has cryptographic applications. Our experiments with state-of-the-art local search SAT solvers show that by using this approach we can randomly generate satisfiable formulas that are considerably harder than uniform random formulas of the same size from the phase-transition region or formulas generated by state-of-the-art approaches. Additionally, we show how to generate small satisfiable formulas that are hard to solve by CDCL solvers.	benchmark (computing);boolean satisfiability problem;conflict-driven clause learning;cryptography;experiment;extensibility;hard coding;local search (optimization);randomness;search algorithm;solver	Tomás Balyo;Lukás Chrpa	2018			theoretical computer science;computer science	AI	11.665054447092729	16.918454453089897	55926
9661d5561005dd6069731e0c3d53e13e545eb4d8	a soft-decision based two-layered scheduling approach for uncertain steelmaking-continuous casting process	uncertainty;continuous casting;steelmaking;scheduling;soft decision	Strong uncertainties is a key challenge for the application of scheduling algorithms in real-world production environments, since the optimized schedule at a time often turns to be deteriorated or even infeasible during its execution due to a large majority of unexpected events. This paper studies the uncertain scheduling problem arising from the steelmaking-continuous casting (SCC) process and develops a soft-decision based two-layered approach (SDA) to cope with the challenge. In our approach, traditional scheduling decisions, i.e. the beginning time and assigned machine for each job at each stage, are replaced with soft scheduling decisions in order to provide more flexibility towards unexpected events. Furthermore, all unexpected events are classified into two categories in terms of the impact degree on scheduling: critical events and non-critical events. In the two-layered solution framework, the upper layer is the offline optimization layer for handling critical events, in which a particle swarm optimization algorithm is proposed for generating soft scheduling decisions; while the lower layer is the online dispatching layer for handling non-critical events, where a dispatching heuristic is designed to decide in real time which charge and when to process after a machine becomes available, with the guidance of the soft schedule given by the upper layer. Computational experiments on randomly generated SCC scheduling instances and practical production data demonstrate that the proposed soft-decision based approach can obtain significantly better solutions compared to other methods under strongly uncertain SCC production environments. Keywords—steelmaking, continuous casting, uncertainty, scheduling, soft decision	algorithm;computation;decision theory;defense in depth (computing);experiment;heuristic;mathematical optimization;online and offline;optimization problem;particle swarm optimization;procedural generation;real life;real-time clock;risk management;schedule;scheduling (computing);smart environment;soft-decision decoder;type conversion	Jinghua Hao;Min Liu;Shenglong Jiang;Cheng Wu	2015	European Journal of Operational Research	10.1016/j.ejor.2015.02.026	fair-share scheduling;fixed-priority pre-emptive scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;simulation;uncertainty;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operations management;two-level scheduling;mathematics;scheduling;steelmaking;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling;statistics	AI	13.482939865145024	7.1868335532988725	56054
640f76f4a290a4f3cfdff20559eec77fd4c3077e	np-hardness of the single-variable-resource scheduling problem to minimize the total weighted completion time	workload;resource scheduling;completion time;sequencage;total weighted completion time;logistique;gestion labor;availability;disponibilidad;temps achevement;problema np duro;fonction objectif;objective function;np hard problem;sequencing;np hardness;gestion tâche;logistics;probleme np difficile;scheduling;charge travail;funcion objetivo;task scheduling;carga trabajo;tiempo acabado;single variable resource;disponibilite;journal magazine article;ordonnancement;reglamento;logistica	Baker and Nuttle [1] studied the following single-variable-resource scheduling problem: sequencing n jobs for processing by a single resource to minimize a function of job completion times, when the availability of the resource varies over time. When the objective function to be minimized is the total weighted completion time, Baker and Nuttle conjectured that the problem is NP-hard. We show in this note that the conjecture is true.	job stream;loss function;np-hardness;optimization problem;scheduling (computing)	J. J. Yuan;T. C. Edwin Cheng;Cai Tong Ng	2007	European Journal of Operational Research	10.1016/j.ejor.2006.02.014	logistics;availability;mathematical optimization;computer science;marketing;operations management;sequencing;np-hard;operations research;scheduling;algorithm	Theory	17.066192632926732	10.061444609864571	56098
092a7b38f97013fee0b08ebfa861bfa7c841ad5d	scheduling parallel machines with inclusive processing set restrictions and job release times	metodo caso peor;tiempo total acabamiento;temps polynomial;efficient algorithm;approximation algorithm;machine parallele;temps total achevement;maquina paralelas;worst case analysis;aproximacion polinomial;makespan;scheduling;indexation;approximation polynomiale;algoritmo aproximacion;polynomial time;methode cas pire;release times;parallel machines;fully polynomial time approximation scheme;scheduling parallel machines release times worst case analysis polynomial time approximation scheme;algorithme approximation;performance ratio;processing speed;worst case method;journal magazine article;polynomial time approximation scheme;ordonnancement;reglamento;polynomial approximation;tiempo polinomial	We consider the problem of scheduling a set of jobs with different release times on parallel machines so as to minimize the makespan of the schedule. The machines have the same processing speed, but each job is compatible with only a subset of those machines. The machines can be linearly ordered such that a higher-indexed machine can process all those jobs that a lower-indexed machine can process. We present an efficient algorithm for this problem with a worst-case performance ratio of 2. We also develop a polynomial time approximation scheme (PTAS) for the problem, as well as a fully polynomial time approximation scheme (FPTAS) for the case in which the number of machines is fixed.	algorithm;best, worst and average case;job stream;makespan;ptas reduction;parallel computing;polynomial;polynomial-time approximation scheme;scheduling (computing);time complexity	Chung-Lun Li;Xiuli Wang	2010	European Journal of Operational Research	10.1016/j.ejor.2009.02.011	mathematical optimization;combinatorics;polynomial-time approximation scheme;computer science;mathematics;approximation algorithm;algorithm	Theory	16.68210978213796	11.005567443278151	56190
6d7cf2a6833425d4477880e99010de2fd482d86f	convexification of queueing formulas by mixed-integer second-order cone programming: an application to a discrete location problem with congestion		Mixed-Integer Second-Order Cone Programs (MISOCPs) form a nice class of mixedinter convex programs, which can be solved very efficiently due to the recent advances in optimization solvers. Our paper bridges the gap between modeling a class of optimization problems and using MISOCP solvers. It is shown how various performance metrics of M/G/1 queues can be molded by different MISOCPs. To motivate our method practically, it is first applied to a challenging stochastic location problem with congestion, which is broadly used to design socially optimal service networks. Four different MISOCPs are developed and compared on sets of benchmark test problems. The new formulations efficiently solve large-size test problems, which cannot be solved by the best existing method. Then, the general applicability of our method is shown for similar optimization problems that use queue-theoretic performance measures to address customer satisfaction and service quality.	benchmark (computing);convex hull;convex optimization;mathematical optimization;network congestion;optimization problem;second-order cone programming;theory	Amir Ahmadi-Javid;Pooya Hoseinpour	2017	CoRR		mathematical optimization;nice;discrete mathematics;mathematics;second-order cone programming;customer satisfaction;service quality;queueing theory;integer;optimization problem;queue	AI	22.79578758879175	10.897206365244015	56439
11658ae8542e13f7f0da74cd5d3c64c9f481e282	a local genetic algorithm for binary-coded problems	modelizacion;algoritmo paralelo;replacement;parallel algorithm;algoritmo busqueda;remplacement;algorithme recherche;heuristic method;search algorithm;metodo heuristico;algoritmo genetico;algorithme parallele;busca local;modelisation;steady state genetic algorithm;algorithme genetique;code binaire;genetic algorithm;codigo binario;regime permanent;reemplazo;methode heuristique;regimen permanente;modeling;local search;binary code;recherche locale;steady state	Local Genetic Algorithms are search procedures designed in order to provide an effective local search. Several Genetic Algorithm models have recently been presented with this aim. In this paper we present a new Binary-coded Local Genetic Algorithm based on a Steady-State Genetic Algorithm with a crowding replacement method. We have compared a Multi-Start Local Search based on the Binary-Coded Local Genetic Algorithm with other instances of this metaheuristic based on Local Search Procedures presented in the literature. The results show that, for a wide range of problems, our proposal consistently outperforms the other local	crowding;experiment;genetic algorithm;local search (constraint satisfaction);local search (optimization);metaheuristic;serial digital video out;test suite	Carlos García-Martínez;Manuel Lozano;Daniel Molina	2006		10.1007/11844297_20	mathematical optimization;binary code;systems modeling;genetic algorithm;cultural algorithm;tabu search;computer science;artificial intelligence;local search;genetic operator;genetic representation;iterated local search;mathematics;parallel algorithm;best-first search;steady state;algorithm;guided local search;search algorithm;population-based incremental learning	AI	20.719474351930327	6.328382329631009	56792
7a484ec2c36ef8430f4d6217443818e3b908b3c1	a dynamically turbo-charged greedy heuristic for graph coloring		We introduce a dynamic version of the graph coloring problem and prove its fixed-parameter tractability with respect to the edit-parameter. This is used to present a {\em turbo-charged} heuristic for the problem that works by combining the turbo-charging technique with other standard heuristic tools, including greedy coloring. The recently introduced turbo-charging idea is further enhanced in this paper by introducing a dynamic version of the so called {\em moment of regret} and {\em rollback points}. Experiments comparing our turbo-charging algorithm to other heuristics demonstrate its effectiveness. Our algorithm often produced results that were either exact or better than all the other available heuristics.		Faisal N. Abu-Khzam;Bachir M. Chahine	2018	CoRR			AI	15.872405787381282	12.213536598233897	56883
6625fb89c614955b2188a7769ed2054ce28119e0	an integer linear programming model for binary knapsack problem with dependent item values		Binary Knapsack Problem (BKP) is to select a subset of items with the highest value while keeping the size within the capacity of the knapsack. This paper presents an Integer Linear Programming (ILP) model for a variation of BKP where the value of an item may depend on presence or absence of other items in the knapsack. Strengths of such Value-Related Dependencies are assumed to be imprecise and hard to specify. To capture this imprecision, we have proposed modeling value-related dependencies using fuzzy graphs and their algebraic structure. We have demonstrated through simulations that our proposed ILP model is scalable to large number of items.	integer programming;knapsack problem;linear programming;programming model	Davoud Mougouei;David M. W. Powers;Asghar Moeini	2017		10.1007/978-3-319-63004-5_12	discrete mathematics;fuzzy logic;change-making problem;branch and price;continuous knapsack problem;cutting stock problem;generalized assignment problem;knapsack problem;integer programming;mathematical optimization;mathematics	Theory	19.35552779436038	9.501524956006454	57113
092557be104e6da0ee63223823ef134695890710	job-shop scheduling: an investigation in constraint-directed reasoning	job shop scheduling	1. Introduction I___-This paper describes ISIS-II*, a constraint-directed reasoning system for the scheduling of factory job-shops. ISIS-II takes a heuristic search approach to generating schedules. The key features of ISIS-II's approach is that it can represent and use a variety of different types of constraints to guide the search, and is able to selectively relax conflicting constraints.	heuristic;job shop scheduling;relax ng;reasoning system;schedule (computer science);scheduling (computing)	Mark S. Fox;Bradley P. Allen;Gary Strohm	1982			fair-share scheduling;job shop scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;deadline-monotonic scheduling;scheduling;lottery scheduling	AI	14.369607569321902	7.21278964242759	57152
910983e3f066e381929006bb41e66ac9d58b4953	dell uses a new production-scheduling algorithm to accommodate increased product variety	heuristic;parallel lines;scheduling algorithm;assemble to order history this paper was refereed;assemble to order;optimization;product variety;production scheduling;product families;new products	Early in 2003, with continually increasing product variety and production volumes, Dell, Inc. had reached the designed capacity limits of one of its main production facilities, the Morton L. Topfer Manufacturing Center (TMC). In 2004, TMC was facing a doubling of the number of product families it produced, with an anticipated degradation in production rates of nearly 20 percent. To help assuage this problem, we developed a new production-scheduling algorithm, which contains both optimization and heuristic components. The algorithm schedules product families on parallel, identical kitting lines to minimize the number of setups required and to reduce downtime and slow time during setups. Because of our work, Dell was able to accommodate the twofold increase in product variety, as well as an effective production-volume increase of over 35 percent. Furthermore, Dell realized a conservative cost avoidance of more than {$}1 million annually, primarily because it saved overtime costs that it would have required, in the absence of our solution, to handle the increases in production volume and product variety. This solution has been in operation at TMC since June 2004.	algorithm;scheduling (computing)	Jennifer L. Loveland;Susan K. Monkman;Douglas J. Morrice	2007	Interfaces	10.1287/inte.1060.0264	mathematical optimization;heuristic;computer science;engineering;operations management;parallel;mathematics;scheduling;operations research;scheduling;engineering drawing	HCI	14.79027470777089	8.112998860250684	57410
abb1cb2f77f75522bf634ccf99e0158c67cdea10	scheduling with time-dependent execution times	processeur unique;single processor;time dependent;temps polynomial;execution time;dependance temps;gestion labor;complexite calcul;combinatorial problems;complejidad computacion;gestion tâche;time dependence;computational complexity;scheduling;polynomial time;temps execution;task scheduling;tiempo ejecucion;tiempo polinomial	We consider systems of tasks where the task execution times are time-dependent and where all tasks have some common deadline. We describe how to compute in polynomial time a schedule that minimizes the number of late tasks. ‘Ibis answers a question raised in a recent paper by Ho, Leung and Wei.	schedule (computer science);time complexity	Gerhard J. Woeginger	1995	Inf. Process. Lett.	10.1016/0020-0190(95)00011-Z	time complexity;parallel computing;real-time computing;computer science;computational complexity theory;scheduling;algorithm	Embedded	16.78154041552585	10.861736652221108	57539
6c63f271b07bc8545699c524509982bdd7b33dfd	design of a fully automated robotic spot-welding line		The mixed model assembly line design problem includes allocating operations to the stations in the robotic cell and satisfying the demand and cycle time within a desired interval for each model to be produced. We also ensure that assignability, precedence and tool life constraints are met. Each pair of spot welding tools can process a certain number of welds and must be replaced at the end of tool life. Tool replacement decisions not only affect the tooling cost, but also the production rate. Therefore, we determine the number of stations and allocate the operations into the stations in such a way that tool change periods coincide with the unavailability periods to eliminate tool change related line stoppages in a mixed model fully automated robotic assembly line. We provide a mathematical formulation of the problem, and propose a heuristic algorithm.	algorithm;assembly language;cplex;central processing unit;computation;heuristic (computer science);mixed model;robot;unavailability	M. Selim Akturk;Adnan Tula;Hakan Gultekin	2011			engineering;control engineering;spot welding	Robotics	11.242882714107317	4.389101626958826	57548
886da58cbaf4eb2d680f4358c7a7303e674f2581	an exterior simplex type algorithm for the minimum cost network flow problem	empirical study;methode empirique;metodo simplejo;metodo empirico;empirical method;simplex algorithm;simplex method;optimisation combinatoire;90c49;65k05;flujo red;exterior point algorithm;91a90;90c27;90c35;proof of correctness;network flow;minimum cost network flow problem;combinatorial optimization;methode simplexe;flot reseau;optimizacion combinatoria	In this paper a new Network Exterior Point Simplex Algorithm (NEPSA) for the Minimum Cost Network Flow Problem (MCNFP) is analytically presented. NEPSA belongs to a special simplex type category and is a modification of the classical network simplex algorithm. The main idea of the algorithm is to compute two flows. One flow is basic but not always feasible and the other is feasible but not always basic. A complete proof of correctness for the proposed algorithm is also presented. Moreover, the computational behavior of NEPSA is shown by an empirical study carried out for randomly generated sparse instances created by the well-known GRIDGEN network problem generator.	algorithm;flow network	Konstantinos Paparrizos;Nikolaos Samaras;Angelo Sifaleras	2009	Computers & OR	10.1016/j.cor.2008.01.001	out-of-kilter algorithm;mathematical optimization;suurballe's algorithm;minimum-cost flow problem;multi-commodity flow problem;combinatorial optimization;calculus;mathematics;empirical research;simplex algorithm;algorithm	Theory	22.271774365837132	11.78983922434016	57730
a4ff9892463305c23cfc001c42842c7c6632ce5f	implementation and experiments with an algorithm for parallel scheduling of complex dags under uncertainty	project management;application of perfect hashing;combinatorial optimization;grid computing;parallel scheduling;algorithm implementation	Our earlier paper introduced a parallel scheduling problem where a directed acyclic graph modeling t tasks and their dependencies needs to be executed on n unreliable workers. Worker i executes task j correctly with probability pi,j . The goal is to find a regimen Σ, that dictates how workers get assigned to tasks (possibly in parallel and redundantly) throughout execution, to minimize the expected completion time. The paper provided a polynomial time algorithm for the problem restricted to the case when dag width and the number of workers are at most a constant, and showed necessity of these restrictions, unless P=NP. The current paper describes algorithm engineering approaches used to produce an efficient implementation of the algorithm, and experiments demonstrating how the algorithm scales.	algorithm engineering;directed acyclic graph;experiment;p (complexity);p versus np problem;parallel computing;scheduling (computing)	Grzegorz Malewicz	2006		10.1137/1.9781611972863.7	project management;mathematical optimization;combinatorics;real-time computing;combinatorial optimization;computer science;theoretical computer science;distributed computing;parallel algorithm;algorithm;grid computing	ML	15.975527417220958	11.232883274890613	57841
dd1870e89ccbea534f6f0d2ce59f5f04a1d2f254	a modified tabu search algorithm for cost-based job shop problem	juste a temps;modelizacion;neighbourhood structure;in process inventory;forecasting;deposito en curso;backorder;reliability;project management;information systems;algoritmo busqueda;probleme livraison;maintenance;algorithme recherche;soft or;information technology;search algorithm;packing;operations research;location;investment;journal;journal of the operational research society;encargo en retardo;inventory;administracion deposito;purchasing;modelisation;atelier multigamme;history of or;logistics;marketing;filter;tabu search algorithm;scheduling;coste;dispatching problem;gestion stock;job shop problem;filtre;production;communications technology;job shop;just in time;tabu search;justo en tiempo;encours de fabrication;computer science;memory structure;operational research;commande en retard;modeling;cost based problem;inventory control;filtro;ordonnancement;applications of operational research;or society;busqueda tabu;reglamento;problema reparto;filter structure;recherche tabou;jors;management science;infrastructure;cout	In this paper, a cost-based job shop problem (JIT-JSP) is proposed to model the multi-order processing procedure in a just-in-time (JIT) environment. The objective of JIT-JSP is to minimize three costs: workin-process holding cost of half-finished orders, inventory holding cost of finished orders and backorder cost of unfulfilled orders. A modified tabu search (MTS) method is developed to improve the schedule quality by searching the neighbourhood of a feasible schedule iteratively. The MTS method is comprised of three components that help to ensure a more effective searching procedure: neighbourhood structure, memory structure and filter structure. Computational results show that the MTS method significantly improves the initial schedule generated by an arbitrarily selected dispatching rule. Journal of the Operational Research Society (2010) 61, 611–619. doi:10.1057/jors.2009.9 Published online 18 March 2009	3-opt;computation;feasible region;flip-flop (electronics);javaserver pages;job shop scheduling;just-in-time compilation;machine-dependent software;scheduling (computing);search algorithm;tabu search	Zhangqian Zhu;Kien Ming Ng;H. L. Ong	2010	JORS	10.1057/jors.2009.9	inventory control;project management;logistics;simulation;inventory;economics;forecasting;tabu search;filter;investment;computer science;marketing;operations management;reliability;location;operations research;information technology;scheduling;search algorithm	AI	18.52951193357194	6.079190198560138	57855
e2c5546b04e06813f1ac3117cd7bfd172852e79e	uniform parallel-machine scheduling for minimizing total resource consumption with a bounded makespan		This paper examines the uniform parallel-machine scheduling problem in which the objective aims to minimize the total resource consumption (TRC) with a bounded makespan. A matheuristic is proposed to deal with this strongly NP-hard problem. The performance of the proposed matheuristic is compared with that of the state-of-the-art particle swarm optimization (PSO) meta-heuristic and the lower bound (LB) of TRC on a set of benchmark instances. Computational results show that the proposed matheuristic significantly outperforms the PSO meta-heuristic and its solution is very close to the tight LB. Given the critical need for environmental protection, this paper provides an effective and efficient algorithm for diminishing the gap between the theoretical progress of scheduling and the practical need for environmental protection.	algorithm;benchmark (computing);computation;heuristic;lattice boltzmann methods;makespan;mathematical optimization;metaheuristic;np-hardness;parallel computing;particle swarm optimization;scheduling (computing)	Shih-Wei Lin;Kuo-Ching Ying	2017	IEEE Access	10.1109/ACCESS.2017.2735538	distributed computing;lottery scheduling;job shop scheduling;genetic algorithm scheduling;computer science;deadline-monotonic scheduling;dynamic priority scheduling;fair-share scheduling;two-level scheduling;fixed-priority pre-emptive scheduling;mathematical optimization	AI	15.858081737960715	8.96080452136109	57948
0e3cef17fcfadbff9a0684bebedbffebcbc93505	new variations of the reverse facility location problem	distance measure;natural extension;space complexity;facility location problem	In this paper we consider a natural extension of the socalled reverse facility location problem which was introduced by Cabello et al. [3]. Given a set of n users and a set of m facilities, where a user takes service from its nearest facility, the objective is to place two new facilities such that the total number of users served by these two new facilities is maximized. We refer to this problem as the 2-MaxCov problem. In the L1 and L∞ metrics, the worst case time and space complexities of our proposed algorithm for solving this problem are both O(n log n). In the L2 metric, if m = 1, the 2-MaxCov problem can be solved easily in O(n) time. We have also considered the obnoxious version of this problem, referred to as the 2-Farthest-MaxCov problem, where a user is served by its farthest facility. Our proposed algorithm for this problem runs in O(n log n) time for all the considered distance measures.	algorithm;best, worst and average case;facility location problem	Bhaswar B. Bhattacharya;Subhas C. Nandy	2010			mathematical optimization;combinatorics;facility location problem;mathematics;dspace;1-center problem;algorithm	Theory	21.739020998310007	15.151695923812852	57975
6cde761ca655a596dfcf31164129a771522abed8	total completion time minimization on multiple machines subject to machine availability and makespan constraints	limited machine availability;polynomial time algorithm;scheduling;bi criteria;parallel machine	This paper studies preemptive bi-criteria scheduling on m parallel machines with machine unavailable intervals. The goal is to minimize the total completion time subject to the constraint that the makespan is at most a constant T . We study the unavailability model such that the number of available machines can not go down by 2 within any period of pmax where pmax is the maximum processing time among all jobs. We show that there is an optimal polynomial time algorithm.	algorithm;decstation;decision problem;makespan;mean time between failures;p (complexity);scheduling (computing);time complexity;unavailability	Yumei Huo;Hairong Zhao	2015	European Journal of Operational Research	10.1016/j.ejor.2014.12.012	mathematical optimization;real-time computing;computer science;distributed computing;scheduling	Theory	15.684416832712325	10.106118251451237	58178
849d5ed2421c704a5326520a934089ca907e79f5	balancing assembly lines with variable parallel workplaces: problem definition and effective solution procedure	workload;time average;cycle time;equilibrado;industrie automobile;completion time;sequencage;programacion entera;automovil;gestion production;linea montaje;heuristic method;assembly line balancing;temps achevement;metodo heuristico;promedio temporal;mass production;programmation en nombres entiers;production management;lorry;optimisation combinatoire;assembly;sequencing;branch and bound method;programacion lineal;integer programming;metodo branch and bound;computer experiment;automobile;industria automovil;gestion produccion;motor car;balancing;charge travail;linear programming;assembly line;programmation lineaire;montage;methode heuristique;methode separation et evaluation;montaje;camion;carga trabajo;combinatorial optimization;tiempo acabado;produccion en masa;branch and bound;production masse;equilibrage;automobile industry;integer linear program;chaine montage;assembly line balancing mass production combinatorial optimization sequencing;moyenne temporelle;optimizacion combinatoria	Assembly line balancing problems (ALBP) arise whenever an assembly line is configured, redesigned or adjusted. An ALBP consists of distributing the total workload for manufacturing any unit of the products to be assembled among the work stations along the line subject to a strict or average cycle time. Traditionally, stations are considered to be manned by one operator, respectively, or duplicated in form of identical parallel stations, each also manned by a single operator. In practice, this assumption is usually too restrictive. This is particularly true for large products like cars, trucks, busses and machines, which can be handled by several operators performing different tasks at the same time. Only restricted research has been done on such parallel workplaces within the same station though they have significant relevance in real-world assembly line settings. In this paper, we consider an extension of the basic ALBP to the case of flexible parallel workplaces (VWALBP) as they typically occur in the automobile and other industries assembling large products. The problem is defined and modelled as an integer linear program. As a solution approach a branchand-bound procedure is proposed which also can be applied as a heuristic. Finally, computational experiments documenting the solution capabilities of the procedure are reported. 2008 Elsevier B.V. All rights reserved.	computation;experiment;heuristic;linear programming;relevance;software documentation	Christian Becker;Armin Scholl	2009	European Journal of Operational Research	10.1016/j.ejor.2008.11.051	mathematical optimization;mass production;computer experiment;integer programming;combinatorial optimization;computer science;automotive industry;linear programming;operations management;sequencing;mathematics;assembly;branch and bound;algorithm	AI	17.98658962113665	7.383362050923183	58396
4a2bb9fc1c677fcbb04f126bed96f0a24b8da1b6	on-line seat reservations via off-line seating arrangements	seat reservation problem;fairness;on line algorithms;channel assignment problem;optimal algorithm;on line algorithm	When reservations are made to for instance a train, it is an on-line problem to accept or reject, i.e., decide if a person can be fitted in given all earlier reservations. However, determining a seating arrangement, implying that it is safe to accept, is an off-line problem with the earlier reservations and the current one as input. We develop algorithms with optimal running time to handle problems of this nature.	algorithm;online and offline;time complexity	Jens S. Kohrt;Kim S. Larsen	2005	Int. J. Found. Comput. Sci.	10.1142/S0129054105003042	simulation;operations research	Theory	17.623681501462134	11.482343441469357	58433
17f2c4d0a6941c393b053e62ff2d3d882800d479	deriving the upper bound of the number of sensors required to know all link flows in a traffic network	optimal sensor location link flow estimation;sensors road traffic;sensors;road traffic;traffic flow;location;road networks;sensors vectors equations upper bound mathematical model estimation observability;cuenca networks sensors traffic network link flows path information link path incidence matrix linearly independent path vectors parallel network ciudad real;algorithms;optimization;methodology	It is demonstrated that the minimum number of sensors required to know all link flows in a traffic network can be determined only if path information is available. However, not all paths need to be enumerated but, at most, a small subset defining the rank rw of the link-path incidence matrix W. If this rank for a reduced subset of paths is already m - n, where m and n are the number of links and noncentroid nodes, respectively, we can conclude that m - n sensors are sufficient. It is also shown that the formulas providing the dependent link flows in terms of the independent link flows can be obtained by the node-based or path-based approaches with the same results only when rw = m - n. Finally, an algorithm to obtain the small subsets of linearly independent path vectors is given. The methods are shown by a parallel network example and the Ciudad Real and Cuenca networks, for which the savings in link counts with respect to the m - n bound are larger than 16%. The corresponding savings in path enumeration are larger than 80%.	algorithm;incidence matrix;sensor	Enrique F. Castillo;Aida Calvino;José María Menéndez;Pilar Jiménez;Ana Rivas	2013	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2012.2233474	mathematical optimization;combinatorics;discrete mathematics;sensor;traffic flow;methodology;mathematics;location	Metrics	23.160063452599136	17.658979475756283	58449
005d4638b0edab831bd92a15c6ab875e6da561ad	gap inequalities for the max-cut problem: a cutting-plane algorithm	computational result;heuristic separation algorithm;special case;max-cut problem;known inequality;valid inequality;separation heuristics;gap inequality;lp-based cutting-plane algorithm;good upper bound	Laurent & Poljak introduced a class of valid inequalities for the max-cut problem, called gap inequalities, which include many other known inequalities as special cases. The gap inequalities have received little attention and are poorly understood. This paper presents the first ever computational results. In particular, we describe heuristic separation algorithms for gap inequalities and their special cases, and show that an LP-based cutting-plane algorithm based on these separation heuristics can yield very good upper bounds in practice.	algorithm;cutting-plane method;gap theorem;heuristic (computer science);integer programming;linear programming;maximum cut	Laura Galli;Konstantinos Kaparis;Adam N. Letchford	2012		10.1007/978-3-642-32147-4_17	mathematical optimization;calculus;mathematics	Theory	22.884636262073215	15.125189674412535	58514
53bb3514e2bc1bfeb51caf0e1160aad515fe41a8	min-max-min robust combinatorial optimization	robuste optimierung;min max min;robust optimization;komplexitat;combinatorial optimization	In this thesis we introduce a robust optimization approach which is based on a binary min-max-min problem. The so called Min-max-min Robust Optimization extends the classical min-max approach by calculating k different solutions instead of one. Usually in robust optimization we consider problems whose problem parameters can be uncertain. The basic idea is to define an uncertainty set U which contains all relevant problem parameters, called scenarios. The objective is then to calculate a solution which is feasible for every scenario in U and which optimizes the worst objective value over all scenarios in U . As a special case of the K-adaptability approach for robust two-stage problems, the min-max-min robust optimization approach aims to calculate k different solutions for the underlying combinatorial problem, such that, considering the best of these solutions in each scenario, the worst objective value over all scenarios is optimized. This idea can be modeled as a min-max-min problem. In this thesis we analyze the complexity of the afore mentioned problem for convex and for discrete uncertainty sets U . We will show that under further assumptions the problem is as easy as the underlying combinatorial problem for convex uncertainty sets if the number of calculated solutions is greater than the dimension of the problem. Additionally we present a practical exact algorithm to solve the min-max-min problem for any combinatorial problem, given by a deterministic oracle. On the other hand we prove that if we fix the number of solutions k, then the problem is NP -hard even for polyhedral uncertainty sets and the unconstrained binary problem. For the case when the number of calculated solutions is lower or equal to the dimension we present a heuristic algorithm which is based on the exact algorithm above. Both algorithms are tested and analyzed on random instances of the knapsack problem, the vehicle routing problem and the shortest path problem. For discrete uncertainty sets we show that the min-max-min problem is NP hard for a selection of combinatorial problems. Nevertheless we prove that it can be solved in pseudopolynomial time or admits an FPTAS if the min-max problem can be solved in pseudopolynomial or admits an FPTAS respectively.	as-easy-as;best, worst and average case;cobham's thesis;combinatorial optimization;convex function;convex optimization;defensive programming;exact algorithm;experiment;file spanning;heuristic (computer science);knapsack problem;linear function;mathematical optimization;maxima and minima;minimum cut;minimum spanning tree;np-hardness;optimization problem;point of view (computer hardware company);polynomial;polynomial-time approximation scheme;robust optimization;shortest path problem;time complexity	Christoph Buchheim;Jannis Kurtz	2017	Math. Program.	10.1007/s10107-016-1053-z	optimization problem;mathematical optimization;combinatorics;robust optimization;combinatorial optimization;mathematics;algorithm;quadratic assignment problem	Theory	21.049500445833438	10.273775724191163	58712
4a5c0b56cc700cd3158537d290318ef8e4884ee0	microcode compaction with timing constraints	problem complexity;success rate;heuristic algorithm;time constraint	At present, microcode compaction with timing constraints (abbreviated as MCTC) is still an open problem. Complex timing relation between microoperations greatly affects the optimization result of microcode. This paper begins with a survey of MCTC problems, then presents a formal description of MCTC and, on the basis of a systematic study of the characteristics of MCTC, presents a generally-oriented heuristic algorithm— CAS, which has a high success rate of scheduling and promises good optimization result. Preliminary experiments indicate that CAS is better than other existing MCTC algorithms.	algorithm;data compaction;experiment;heuristic (computer science);mathematical optimization;micro-operation;microcode;scheduling (computing)	Bogong Su;Shiyuan Ding;Jian Wang;Jinshi Xia	1987		10.1145/255305.255314	heuristic;real-time computing;computer science;theoretical computer science;algorithm	EDA	14.52517625565543	7.931205182625316	58832
7edf993ba7b030635f16de1acf3f4b1578ace4df	network flows in optimisation problems and their extensions		Network flow problems are among the most important ones in graph theory. Since there are many well-known polynomial algorithms for solving the classical Maximum Flow Problem, we, instead of summarising them, focus on special formulations and their transformation into the basic one, and because other graph theory problems may be formulated with the help of network flow tools, we show how to formulate the Minimum Steiner Tree Problem using the maximum network flow terminology and derive its mathematical model. Finally, we discuss the Integer Maximal Multicommodity Flow Problem. Since this network flow version belongs to the class of NP-hard combinatorial problems, for large scale instances, it must be solved by approximation or heuristic techniques. We present a stochastic heuristic approach based on a simulated annealing algorithm.	algorithm;approximation;flow network;graph theory;heuristic;mathematical model;mathematical optimization;maximal set;maximum flow problem;np-hardness;polynomial;simulated annealing;steiner tree problem;stochastic gradient descent	Milos Seda	2010		10.7148/2010-0271-0276	graph theory;flow network;maximum flow problem;mathematical optimization;polynomial;simulated annealing;steiner tree problem;multi-commodity flow problem;heuristic;mathematics	Theory	23.100835555268922	10.040814465965237	58958
85ecab93a0caf8f53018679feaeb5973df3ef3ed	an exact approach for solving integer problems under probabilistic constraints with random technology matrix	discrete distribution;probabilistic constraints;set covering problem;large scale;branch and bound method;stochastic integer programming;numerical experiment;integer program;branch and bound	This paper addresses integer programming problems under probabilistic constraints involving discrete distributions. Such problems can be reformulated as large scale integer problems with knapsack constraints. For their solution we propose a specialized Branch and Bound approach where the feasible solutions of the knapsack constraint are used as partitioning rules of the feasible domain. The numerical experience carried out on a set covering problem with random covering matrix shows the validity of the solution approach and the efficiency of the implemented algorithm.		Patrizia Beraldi;Maria Elena Bruni	2010	Annals OR	10.1007/s10479-009-0670-9	probability distribution;mathematical optimization;combinatorics;discrete mathematics;integer programming;special ordered set;covering problems;branch and price;change-making problem;mathematics;set cover problem;constraint;branch and bound;branch and cut	Theory	24.20927714136395	10.819061418337176	58971
d21895aebeea1b6a888370b83d7eff6c164d2640	an improved algorithm for finding optimal lot sizing policies for finite production rate assembly systems	multistage;operations research;inventory production heuristics;lot sizing;production rate;technical report;industrial engineering	We show that an O(n3 log n) algorithm can find optimal power-of-two lot size policies for finite production rate assembly systems. This Improves an O(n5) algorithm proposed in D. Atkins, M. Queyranne and D. Sun's 1992 paper.	algorithm	Robin Roundy;Daning Sun	1994	Operations Research	10.1287/opre.42.3.562	mathematical optimization;computer science;technical report;operations management	Robotics	15.552256119534286	8.628787258075757	59305
cb218af5f5812aa933ded212770c96908fd8bd8b	a computational approach to unbiased districting	calcul scientifique;computer aided analysis;gerrymandering;mathematics;matematicas aplicadas;analyse assistee;modele mathematique;mathematiques appliquees;probleme np complet;implementation;np complete problems;modelo matematico;computacion cientifica;mathematical model;analisis asistido;problema np completo;econometrics;scientific computation;implementacion;applied mathematics;np complete problem;redistricting	In the context of discrete districting problems with geographical constraints, we demonstrate that determining an (ex post) unbiased districting, which requires that the number of representatives of a party should be proportional to its share of votes, turns out to be a computationally intractable (NP-complete) problem. This raises doubts as to whether an independent jury will be able to come up with a “fair” redistricting plan in case of a large population, that is, there is no guarantee for finding an unbiased districting (even if such exists). We also show that, in the absence of geographical constraints, an unbiased districting can be implemented by a simple alternating-move game among the two parties.	computational complexity theory;np-completeness;plan 9 from bell labs;population;ritz dakota digital;unbiased rendering	Clemens Puppe;Attila Tasnádi	2008	Mathematical and Computer Modelling	10.1016/j.mcm.2008.05.024	np-complete;artificial intelligence;mathematics;operations research;algorithm;statistics	AI	17.363872363760503	6.546928778250655	59317
89f7fd2c87616abd787e8953ec14fdfd398198ba	on the approximability of the minimum congestion unsplittable shortest path routing problem	camino mas corto;graphe non oriente;shortest path;non directed graph;approximate algorithm;programacion entera;capacite;trajectoire optimale;routing;approximation algorithm;flujo optimo;routage;telecommunication network;plus court chemin;problema np duro;capacidad;programmation en nombres entiers;approximation;optimisation combinatoire;unsplittable flow;shortest path routing;np hard problem;planificacion;flujo red;multi path routing;integer programming;probleme np difficile;computational complexity;optimal trajectory;grafo no orientado;red telecomunicacion;cycle graphe;trayectoria optima;algoritmo aproximacion;reseau telecommunication;invariante;planning;flot optimal;cycle graph;planification;network flow;algorithme approximation;capacity;combinatorial optimization;optimal flow;flot reseau;invariant;telecommunication networks;optimizacion combinatoria;ciclo diagrama;enrutamiento	We are given an undirected simple graph G = (V, E) with edge capacities ce ∈ ZZ+, e ∈ E, and a set K ⊆ V 2 of commodities with demand values d(s,t) ∈ ZZ+, (s, t) ∈ K. An unsplittable shortest path routing (USPR) of the commodities K is a set of flow paths Φ(s,t), (s, t) ∈ K, such that each Φ(s,t) is the unique shortest (s, t)-path for commodity (s, t) with respect to a common edge length function λ = (λe) ∈ ZZ+. The minimum congestion unsplittable shortest path routing problem (Min-Con-USPR) is to find an USPR that minimizes the maximum congestion (i.e., the flow to capacity ratio) over all edges. We show that it is NP-hard to approximate Min-Con-USPR within a factor of O(|V |1− ) for any > 0. We also present a simple approximation algorithm that achieves an approximation guarantee of O(|E|) in the general case and of 2 in the special case where the underlying graph G is a cycle. Finally, we construct examples where the minimum congestion that can be obtained with an USPR is a factor of Ω(|V |2) larger than the congestion of an optimal unsplittable flow routing or an optimal shortest multi-path routing, and a factor of Ω(|V |) larger than the congestion of an optimal unsplittable source-invariant routing. This indicates that unsplittable shortest path routing problems are indeed harder than their corresponding unsplittable flow, shortest multi-path, and unsplittable source-invariant routing problems. The Min-Con-USPR problem is of great practical interest in the planning of telecommunication networks that are based on shortest path routing protocols.		Andreas Bley	2005		10.1007/11496915_8	planning;mathematical optimization;routing;combinatorics;flow network;integer programming;combinatorial optimization;computer science;approximation;invariant;cycle graph;mathematics;approximation algorithm;algorithm	Theory	23.06444370226129	17.286451657124704	59339
765af9860aabe590b0be895d0105f466d91ab647	a generalized model and a heuristic algorithm for the large-scale covering tour problem		The covering tour problem (CTP) is defined on a graph, where there exist two types of vertices. One is called visited vertex , which can be visited. The other is called covered vertex , which must be covered but cannot be visited. Each visited vertex covers a subset of covered vertices, and the costs of edges between visited vertices are given. The objective of the CTP is to obtain a minimum cost tour on a subset of visited vertices while covering all covered vertices. In this paper, we deal with the large-scale CTPs, which are composed of tens of thousands of vertices; in the previous studies, the scales of the instances in the experiments are at most a few hundred vertices. We propose a heuristic algorithm using local search techniques for the large-scale CTP. With computational experiments, we show that our algorithm outperforms the existing methods.	algorithm;heuristic (computer science)	Keisuke Murakami	2018	RAIRO - Operations Research	10.1051/ro/2017090	combinatorics;mathematical optimization;travelling salesman problem;local search (optimization);vertex (geometry);set cover problem;mathematics;heuristic (computer science);graph	Robotics	24.04388837908793	6.5681881229128996	59403
0d3dc56989ae1cd4d74d2e79632c12e3010609a3	computing approximate solutions of the maximum covering problem with grasp	heuristic;maximum covering problem;linear programming bound;linear program ming;combinatorial optimization problem;upper bound;greedy randomized adaptive search procedure;approximate solution;facility location problem;linear program;grasp;covering problem;facility location	We consider the maximum covering problem, a combinatorial optimization problem that arises in many facility location problems. In this problem, a potential facility site covers a set of demand points. With each demand point, we associate a nonnegative weight. The task is to select a subset of p> 0 sites from the set of potential facility sites, such that the sum of weights of the covered demand points is maximized. We describe a greedy randomized adaptive search procedure (GRASP) for the maximum covering problem that finds good, though not necessarily optimum, placement configurations. We describe a well-known upper bound on the maximum coverage which can be computed by solving a linear program and show that on large instances, the GRASP can produce facility placements that are nearly optimal.	combinatorial optimization;covering problems;grasp;greedy algorithm;greedy randomized adaptive search procedure;linear programming;mathematical optimization;optimization problem;randomized algorithm	Mauricio G. C. Resende	1998	J. Heuristics	10.1023/A:1009677613792	greedy randomized adaptive search procedure;mathematical optimization;combinatorics;heuristic;computer science;facility location problem;machine learning;mathematics;1-center problem	Theory	21.777798381602818	14.00425936643305	59564
39f4c7b7456745491b8189fb1dc3fb0e6e92a486	facility layout problems: a survey	optimal method;system performance;literature review;facility layout;manufacturing system	Layout problems are found in several types of manufacturing systems. Typically, layout problems are related to the location of facilities (e.g., machines, departments) in a plant. They are known to greatly impact the system performance. Most of these problems are NP hard. Numerous research works related to facility layout have been published. A few literature reviews exist, but they are not recent or are restricted to certain specific aspects of these problems. The literature analysis given here is recent and not restricted to specific considerations about layout design. We suggest a general framework to analyze the literature and present existing works using such criteria as: the manufacturing system features, static/dynamic considerations, continual/discrete representation, problem formulation, and resolution approach. Several research directions are pointed out and discussed in our conclusion. # 2007 Elsevier Ltd. All rights reserved. www.elsevier.com/locate/arcontrol Annual Reviews in Control 31 (2007) 255–267	np (complexity);np-hardness;resolution (logic)	Amine Drira;Henri Pierreval;Sonia Hajri-Gabouj	2007	Annual Reviews in Control	10.1016/j.arcontrol.2007.04.001	computer science;engineering;computer performance;operations research;engineering drawing	Theory	22.232497697216097	9.978647764434525	59573
0919af5cdd10b34e8cd7c79ffc7d1b036e1f3bd5	a computational evaluation of constructive and improvement heuristics for the blocking flow shop to minimise total flowtime	computational evaluation;flowshop;blocking;scheduling;beam search;total flowtime;heuristics;pfsp	We address the blocking flow shop to minimise total flowtime.We conduct a comprehensive evaluation of a total of 35 heuristics.We propose an efficient constructive heuristic using a beam-search-based approach.We compare the proposal with the best-so-far algorithms for the problem. This paper focuses on the blocking flow shop scheduling problem with the objective of total flowtime minimisation. This problem assumes that there are no buffers between machines and, due to its application to many manufacturing sectors, it is receiving a growing attention by researchers during the last years. Since the problem is NP-hard, a large number of heuristics have been proposed to provide good solutions with reasonable computational times. In this paper, we conduct a comprehensive evaluation of the available heuristics for the problem and for related problems, resulting in the implementation and testing of a total of 35 heuristics. Furthermore, we propose an efficient constructive heuristic which successfully combines a pool of partial sequences in parallel, using a beam-search-based approach. The computational experiments show the excellent performance of the proposed heuristic as compared to the best-so-far algorithms for the problem, both in terms of quality of the solutions and of computational requirements. In fact, despite being a relative fast constructive heuristic, new best upper bounds have been found for more than 27% of Taillard's instances.	dinic's algorithm;heuristic (computer science)	Victor Fernandez-Viagas;Rainer Leisten;Jose M. Framiñan	2016	Expert Syst. Appl.	10.1016/j.eswa.2016.05.040	beam search;mathematical optimization;computer science;heuristics;mathematics;scheduling;blocking;algorithm;statistics	AI	15.987804080645153	7.473457283328836	59587
0ab2be9309b84c457a3ba88abf20276bfa2951c5	additive heuristic for four-connected gridworlds	heuristic;single agent search;pattern databases;pathfinding	Memory-based heuristic techniques have been used to effectively reduce search times in implicit graphs. Recently, these techniques have been applied to improving search times in explicit graphs. This paper presents a new memory-based, additive heuristic that can be used on a type of explicit graph: the four-connected gridworld. The heuristic reduces the number of expanded nodes by up to five times, reduces execution time by up to 29 times, and can efficiently accommodate graph changes.	ap computer science a;additive model;algorithm;heuristic;motion planning;run time (program lifecycle phase);taxicab geometry;utility functions on indivisible goods	Kenneth Anderson	2010			consistent heuristic;beam search;null-move heuristic;combinatorics;theoretical computer science;machine learning;mathematics;incremental heuristic search	HPC	23.558984382743137	4.508881897404792	59764
a528a6b3703a99cf98dd2eafca18f229e421c090	modelling transfer line design problem via a set partitioning problem	parallel operations;line balancing;transfer line design;set partitioning problem	The design of a transfer line is considered. This line is used for a repetitive execution of a given set of operations to produce identical items. The line is composed of a sequence of workstations equipped with processing modules (blocks). Each block performs specific operations. The machined items move along the workstations in the same direction. There is the same cost associated with each workstation and different costs associated with diverse blocks. The problem is to determine the number of workstations, select a set of blocks and assign the selected blocks to the workstations so that, for each item, each operation is performed exactly once with total line cost to be minimized. The specificity of the problem is that all operations of the same workstation are performed in parallel. There are inclusion, exclusion, and precedence relations that restrict the assignment of blocks and operations to the same workstation and constrain the processing order of the operations on the transfer line. We suggest a reduction of this transfer line design problem to a simple set partitioning problem. This reduction is based on the concept of a locally feasible workstation.	experiment;heuristic;integer programming;linear programming;partition problem;preprocessor;sensitivity and specificity;simple set;solver;workstation	Pavel A. Borisovsky;Alexandre Dolgui;Sergey Kovalev	2012	Optimization Letters	10.1007/s11590-011-0317-z	parallel computing;real-time computing;computer science;distributed computing	EDA	14.4745558605412	5.509508815457971	59868
bc7705cf9805fdf707cabf39fc5c99b5c7f6a578	solving the response time variability problem by means of the cross-entropy method	cross entropy;metaheuristics;mixed model assembly lines;response time variability;production lines;fair sequences;rtvp;scheduling;just in time;jit production;cross entropy method	The response time variability problem (RTVP) is an NP-hard combinatorial scheduling problem that has recently appeared in the literature. The RTVP has a wide range of production line systems applications such as sequencing the models to be produced on a mixed-model assembly line in a just-in-time context. This problem occurs whenever several units of different models need to be sequenced so as to minimise the variability of the distance between any two consecutive units of the same model. A mathematical mixed integer linear programming (MILP) model has been presented by another study, but the practical limit for obtaining optimal solutions is around 40 units to be scheduled. Another study has developed five heuristic algorithms to solve non-small RTVP instances. We propose to solve the RTVP by means of the metaheuristic cross-entropy (CE) method, which has been developed recently. We report on the computational experiments in which the CE method is compared with the five heuristic algorithms proposed in the literature.	cross entropy;cross-entropy method;heart rate variability;response time (technology)	Alberto García-Villoria;Albert Corominas;Rafael Pastor	2010	IJMTM	10.1504/IJMTM.2010.032904	mathematical optimization;real-time computing;cross-entropy method;production line;computer science;operations management;cross entropy;scheduling;metaheuristic	SE	15.510332129992863	7.26950999944665	59984
3ea817bc3ce9615d7dfe387ac6a86cf68687d238	optimizing over the subtour polytope of the travelling salesman problem	optimisation;optimizacion;travelling salesman problem;camino hamiltoniano;graph clique;graphe fini;finite graph;fonction economique;relajacion;grafo finito;problema viajante comercio;objective function;politope;probleme combinatoire;problema combinatorio;probleme commis voyageur;funcion economica;chemin hamiltonien;relaxation;optimization;combinatory problem;clique graphe;hamiltonian path;polytope	A commonly studied relaxation of the travelling salesman problem is obtained by adding subtour elimination constraints to the constraints of a 2-factor problem and removing the integrality requirement. We investigate the problem of solving this relaxation for a special type of objective function. We also discuss some ways in which this relates to the concept of rank introduced by Chvatal.	optimizing compiler;travelling salesman problem	Sylvia C. Boyd;William R. Pulleyblank	1991	Math. Program.	10.1007/BF01588786	hamiltonian path;clique;polytope;mathematical optimization;combinatorics;discrete mathematics;relaxation;mathematics;travelling salesman problem;3-opt	Theory	22.64369522086152	12.670501880144602	59991
323fb2475d1776fcb547d703ea82956072d09de6	formal languages for integer programming modeling of shift scheduling problems	optimisation sous contrainte;modelizacion;constrained optimization;lenguaje programacion;probleme confection horaire;programacion entera;problema concepcion horario;programming language;reformulations;metodo formal;methode formelle;formal languages;automaton;global constraint;constraint satisfaction;programmation en nombres entiers;formal method;optimizacion con restriccion;optimization problem;modelisation;grammaire cf;automata;satisfaction contrainte;mixed integer program;programacion mixta entera;integer programming;mathematical programming;context free grammar;scheduling;automate;gramatica independiente;constraint programming;langage programmation;programmation partiellement en nombres entiers;scheduling problem;mixed integer programming;satisfaccion restriccion;integer program;timetabling problem;modeling;programmation mathematique;programacion matematica;lenguaje formal;ordonnancement;formal language;reglamento;langage formel	This paper approaches the problem of modeling optimization problems containing substructures involving constraints on sequences of decision variables. Such constraints can be very complex to express with Mixed Integer Programming (MIP). We suggest an approach inspired by global constraints used in Constraint Programming (CP) to exploit formal languages for the modeling of such substructures with MIP. More precisely, we first suggest a way to use automata, as the CP regular constraint does, to express allowed patterns for the values taken by the constrained sequence of variables. Secondly, we present how context-free grammars can contribute to formulate constraints on sequences of variables in a MIP model. Experimental results on both approaches show that they facilitate the modeling, but also give models easier to solve by MIP solvers compared to compact assignment MIP formulations.	automata theory;automaton;column generation;computation;constraint programming;context-free grammar;context-free language;decision theory;flow network;formal language;integer programming;linear algebra;linear programming;mathematical optimization;parse tree;parsing;regular constraint;scheduling (computing);solver	Marie-Claude Côté;Bernard Gendron;Claude-Guy Quimper;Louis-Martin Rousseau	2009	Constraints	10.1007/s10601-009-9083-2	mathematical optimization;combinatorics;formal language;integer programming;computer science;mathematics;automaton;algorithm	AI	19.746051309680666	8.113808828370962	60046
3104646cba66370a6e87266934b4f16442bdba60	mixed integer linear programming and constraint logic programming: towards a unified modeling framework		xvii 1 CLP–MILP: Introduction 1 1.1 Preliminary Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Thesis’ Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 2 CLP–MILP: Overview of Main Characteristics 7 2.	constraint logic programming;integer programming;linear programming	Leandro Magatão	2010				Theory	22.89657404125206	9.806657386421398	60064
6bb9aeaa9e6f3674d19e97061ed85e13965b96c6	almost 20 years of combinatorial optimization for railway planning: from lagrangian relaxation to column generation	004;railway planning integer multicommodity flow integer linear programming formulations lagrangian relaxation column generation;combinatorial optimization;column generation;lagrangian relaxation	We summarize our experience in solving combinatorial optimization problems arising in railway planning, illustrating all of these problems as integer multicommodity flow ones and discussing the main features of the mathematical programming models that were successfully used in the 1990s and in recent years to solve them. 1998 ACM Subject Classification G.2.2 Graph Theory, Network problems; G.2.2 Graph Theory, Path and circuit problems; G.2.3 Applications	column generation;combinatorial optimization;graph theory;lagrangian relaxation;mathematical optimization;relaxation (approximation)	Alberto Caprara	2010		10.4230/OASIcs.ATMOS.2010.1	column generation;mathematical optimization;combinatorics;discrete mathematics;lagrangian relaxation;combinatorial optimization;branch and price;mathematics	Theory	22.937037128787832	10.035914986244684	60204
08734a58992bad78f388c8480ce468924f7a59f4	a composite rule combining due date control and wip balance in a wafer fab	composite rule;wafer fab;lwnq rule;wip balance;odd rule;due date;mod rule;basic single rule;operation due date;advanced rule;new composite rule;due date control;supply chain management;cycle time;process control;indexation;simulation;semiconductor device modeling;indexes;design of experiment;production	Different single dispatching rules aim at different objectives, for instance, SPT (shortest processing time) rule is good at minimizing cycle time and ODD (operation due date) rule intends to minimize deviation between lateness and target due date to achieve better on-time delivery. While some advanced rules called composite rules combine the characteristics of those basic single rules into one composite dispatching rule such as MOD (modified operation due date) which is a combination of SPT and ODD rule. In this paper, a new composite rule which combines ODD, SPT and LWNQ rules (least work at next queue) is developed with the objective of due date control and workload balance. A design of experiment is used to determine the appropriate scaling parameter for this composite rule. The simulation results show significant improvement versus the use of MOD rule.	design of experiments;hall-effect thruster;image scaling;semiconductor fabrication plant;simpson's rule;simulation;wafer (electronics)	Zhugen Zhou;Oliver Rose	2011	Proceedings of the 2011 Winter Simulation Conference (WSC)		database index;semiconductor device modeling;real-time computing;supply chain management;simulation;cycle time variation;computer science;engineering;process control;design of experiments;statistics	DB	11.342265205517531	5.252863281469209	60285
991bcb51d291dc37b76f5a3eccea519c12471c18	matching medical students to pairs of hospitals: a new variation on a well-known theme	algorithm performance;algorithm analysis;national resident matching program;stable matching;operations research;optimisation combinatoire;flujo red;recherche operationnelle;resultado algoritmo;seasonality;united kingdom;performance algorithme;analyse algorithme;network flow;combinatorial optimization;investigacion operacional;flot reseau;analisis algoritmo;optimizacion combinatoria;medical students	The National Resident Matching Program in the U.S. provides one of the most successful applications of an algorithmic matching process. Under this scheme, graduating medical students are allocated to hospitals, taking into account the ordered preferences of both students and hospitals, so that the resulting matching is stable in a precise technical sense. Variants of this problem arise elsewhere. For example, in the United Kingdom, the students/hospitals problem is more complicated, primarily because students must take on two positions in their pre-registration year, namely a medical post and a surgical post. Hence there is a need for a matching process that assigns each student to one medical and one surgical unit, taking into account varying numbers of posts in the two half years, and students’ seasonal preferences, as well as the basic preferences of students and hospital units for each other. This paper describes an algorithmic solution to this new variation on an old theme that uses network flow and graph theoretic methods as well as the traditional stable matching algorithm. The approach described has been implemented and will soon come into use as a centralised matching	algorithm;c++;centralisation;computation;flow network;graph theory;matching (graph theory);national resident matching program;realms of the haunting;requirement;stable marriage problem;test data	Robert W. Irving	1998		10.1007/3-540-68530-8_32	mathematical optimization;flow network;simulation;stable marriage problem;combinatorial optimization;artificial intelligence;mathematics;operations research;algorithm;seasonality	Web+IR	19.038729805004138	10.228591063962424	60606
d12732ce6d3f7af0b9807f735ad297117bc8aa8c	makespan minimization scheduling with ready times, group technology and shortening job processing times			makespan;scheduling (computing)	Ji-Bo Wang;Lu Liu;Jianjun Wang;Lin Li	2018	Comput. J.	10.1093/comjnl/bxy007	minification;scheduling (computing);job shop scheduling;distributed computing;computer science;group technology	Embedded	14.632366671435845	8.37271652057728	60848
ef1071b29c53a28a64f159f5734adfbed1445a25	decision fusion of combinatorial optimization algorithms for solving the graph coloring problem	graph coloring problem;combinatorial optimization	The graph coloring problem is a practical method of representing many real world problems including time scheduling, frequency assignment, register allocation, and circuit board testing. The most important fact that makes graph coloring exciting is that finding the minimum number of colors for an arbitrary graph is NP-hard. This project implements combinatorial optimization algorithms (genetic algorithm (GA), simulated annealing algorithm (SA)) and sequential/greedy algorithms (highest order algorithm (HSO) and the sequential algorithm (SQ)) to find a solution for the graph coloring problem. Decision Fusion is then applied on the implemented algorithms to find an optimized solution. Applying decision fusion on the algorithms signifies the importance given to the factors such as the time of execution and availability of processing resources. Extensive testing and evaluations has been performed to determine important parameters and the efficiency of the simulator. The simulator has always produced better results than the SA, GA, SQ and HSO implemented independently.	color;combinatorial optimization;genetic algorithm;graph coloring;greedy algorithm;mathematical optimization;np-hardness;printed circuit board;register allocation;scheduling (computing);sequential algorithm;simulation;software release life cycle;sound quality;tridiagonal matrix algorithm	Praveen Nuthulapati;Ajay K. Katangur	2007			assignment problem;quadratic assignment problem;greedy coloring;combinatorial optimization;bottleneck traveling salesman problem;topology;mathematical optimization;graph bandwidth;graph coloring;optimization problem;computer science	Theory	24.225255019728532	4.667098177912945	60971
1a8c926370703327ed3cf3a889d6d7dbf1c86ab4	new models for two variants of popular matching		We study the problem of matching a set of applicants to a set of posts, where each applicant has an ordinal preference list, which may contain ties, ranking a subset of posts. A matching M is popular if there exists no matching M' where more applicants prefer M' to M . Several notions of optimality are studied in the literature for the case of strictly ordered preference lists. In this paper we address the case involving ties and propose novel algorithmic and complexity results for this variant. Next, we focus on the NP-hard case where additional copies of posts can be added in the preference lists, called Popular Matching with Copies. We define new dominance rules for this problem and present several novel graph properties characterising the posts that should be copied with priority. We present a comprehensive set of experiments for the popular matching problem with copies to evaluate our dominance rules as well as the different branching strategies. Our experimental study emphasizes the importance of the dominance rules and characterises the key aspects of a good branching strategy.		Danuta Sorina Chisca;Mohamed Siala;Gilles Simonin;Barry O'Sullivan	2017	2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)	10.1109/ICTAI.2017.00119	artificial intelligence;machine learning;graph property;branching (version control);ordinal number;bipartite graph;ranking;existential quantification;pattern recognition;computer science;computer programming	DB	17.860984149548507	16.991221026053985	61009
9d32fc39bb0aec7ed5ac976d60be912f1f447e34	milp-based approaches for medium-term planning of single-stage continuous multiproduct plants with parallel units	traveling salesman problem;mixed integer linear program;continuous time;ucl;hybrid time representation;discovery;theses;conference proceedings;rolling horizon;digital web resources;mixed integer linear programming;ucl discovery;scheduling;open access;parallel machines;ucl library;book chapters;open access repository;ucl research	In this paper, we address the problem of medium-term planning of single-stage continuous multiproduct plants with multiple processing units in parallel. Sequence-dependent changeover times and costs occur when switching from one type of product to another. A traveling salesman problem (TSP)-based mixed-integer linear programming (MILP) model is proposed based on a hybrid discrete/continuous time representation. We develop additional constraints and variables to ensure that subtours do not occur in the solution. The model is successfully applied to an example of a polymer processing plant to illustrate its applicability. In order to solve larger model instances and planning horizons, a rolling horizon approach is developed to reduce the computational expense. Finally, the proposed model is compared to a recently published approach through literature examples, and the results show that the computational performance of the proposed model is superior.		Songsong Liu;José M. Pinto;Lazaros G. Papageorgiou	2010	Comput. Manag. Science	10.1007/s10287-009-0096-5	mathematical optimization;computer science;artificial intelligence;operations management;machine learning;mathematics;travelling salesman problem;operations research;scheduling	Logic	13.730682468663527	4.191379956528759	61128
76e6053020e235e79bbec90b1ea8e2176aec4962	random k-gd-sat model and its phase transition	random sat problems;phase transition;np- complete problems;propositional satisfiability	We present a new type of sat problem called the k-gd-sat, which generalizes k-sat and gd-sat. In k-gd-sat, clause lengths have geometric distribution, controlled by a probability parameter p; for p = 1, a k-gd-sat problem is a k-sat problem. We report on the phase transition between satisfiability and unsatisfiability for randomly generated instances of k-gd-sat. We provide theoretical analysis and experimental results suggesting that there is an intriguing relationship (linear in the parameter 1/p) between crossover points for different parameters of k-gd-sat. We also consider a relationship between crossover points for k-sat and k-gd-sat and provide links between these values.	approximation;boolean satisfiability problem;computational complexity theory;experiment;image scaling;procedural generation	Milena Vujosevic-Janicic;Jelena Tomasevic;Predrag Janicic	2007	J. UCS	10.3217/jucs-013-04-0572	phase transition;np-complete;data mining;discrete mathematics;crossover;computer science;algorithm;geometric distribution;satisfiability	AI	11.688002546213953	17.747397880556335	61373
35f5157a5a336e954437e754d65dbe4f473d7a06	continuous replica placement schemes in distributed systems	distributed system;content distribution network;video allocation;allocation;grid;scheduling;replica placement;content distribution networks;optimality criteria;scheduling problem;heuristics;greedy method	The Replica Placement Problem (RPP) aims at creating a set of duplicated data objects across the nodes of a distributed system in order to optimize certain criteria. Typically, RPP formulations fall into two categories: static and dynamic. The first assumes that access statistics are estimated in advance and remain static, and, therefore, a one-time replica distribution is sufficient (IRPP). In contrast, dynamic methods change the replicas in the network potentially upon every request. This paper proposes an alternative technique, named Continuous Replica Placement Problem (CRPP), which falls between the two extreme approaches. CRPP can be defined as: Given an already implemented replication scheme and estimated access statistics for the next time period, define a new replication scheme, subject to optimization criteria and constraints. As we show in the problem formulation, CRPP is different in that the existing heuristics in the literature cannot be used either statically or dynamically to solve the problem. In fact, even with the most careful design, their performance will be inferior since CRPP embeds a scheduling problem to facilitate the proposed mechanism. We provide insight on the intricacies of CRPP and propose various heuristics.	distributed computing;heuristic (computer science);mathematical optimization;scheduling (computing)	Thanasis Loukopoulos;Petros Lampsas;Ishfaq Ahmad	2005		10.1145/1088149.1088187	job shop scheduling;greedy algorithm;parallel computing;real-time computing;computer science;theoretical computer science;operating system;heuristics;distributed computing;grid;scheduling	HPC	14.270351649770218	9.199438919086685	61417
1335ba5fb1071d2d0c87a3a221755879efc65dfd	the price of bounded preemption		In this paper we provide a tight bound for the price of preemption for scheduling jobs on a single machine (or multiple machines). The input consists of a set of jobs to be scheduled and of an integer parameter $k \ge 1$. Each job has a release time, deadline, length (also called processing time) and value associated with it. The goal is to feasibly schedule a subset of the jobs so that their total value is maximal; while preemption of a job is permitted, a job may be preempted no more than k times. The price of preemption is the worst possible (i.e., largest) ratio of the optimal non-bounded-preemptive scheduling to the optimal k-bounded-preemptive scheduling. Our results show that allowing at most k preemptions suffices to guarantee a Θ(\min\łog_k+1 n, łog_k+1 P\ )$ fraction of the total value achieved when the number of preemptions is unrestricted (where n is the number of the jobs and P the ratio of the maximal length to the minimal length), giving us an upper bound for the price; a specific scenario serves to prove the tightness of this bound. We further show that when no preemptions are permitted at all (i.e., k=0), the price is Θ(\min\n, łog P\ )$. As part of the proof, we introduce the notion of the Bounded-Degree Ancestor-Free Sub-Forest (BAS). We investigate the problem of computing the maximal-value BAS of a given forest and give a tight bound for the loss factor, which is Θ(łog_k+1 n)$ as well, where n is the size of the original forest and k is the bound on the degree of the sub-forest.	broadcast auxiliary service;job stream;maximal set;preemption (computing);scheduling (computing)	Noga Alon;Yossi Azar;Mark Berlin	2018		10.1145/3210377.3210407	parallel computing;computer science;scheduling (computing);mathematical optimization;bounded function;upper and lower bounds;integer;preemption	Theory	14.82615271887465	11.814254157564836	61454
c2400b7b2b07a8b5224f39e857db080e3d7196b4	a possibilistic approach to bottleneck combinatorial optimization problems with ill-known weights	combinatorial optimization problem;possibility theory;solution concept;combinatorial optimization;fuzzy optimization	In this paper a general bottleneck combinatorial optimization problem with uncertain element weights modeled by fuzzy intervals is considered. A rigorous possibilistic formalization of the problem and solution concepts in this setting that lead to finding robust solutions under fuzzy weights are given. Some algorithms for finding a solution according to the introduced concepts and evaluating optimality of solutions and elements are provided. Keywords— Bottleneck combinatorial optimization, Interval, Fuzzy interval, Fuzzy optimization and design, Possibility theory.	algorithm;combinatorial optimization;decision problem;mathematical optimization;minimax;optimization problem;possibility theory;regret (decision theory);time complexity	Adam Kasperski;Pawel Zielinski	2009			optimization problem;mathematical optimization;combinatorics;linear bottleneck assignment problem;fuzzy transportation;combinatorial optimization;mathematics;algorithm;bottleneck traveling salesman problem;quadratic assignment problem	ML	21.134818748105225	9.374695409784277	61557
9d574d60c13ddc0eb3546e985d7e223bae14d97f	the two-stage assembly flow shop scheduling with an availability constraint: worst case analysis		In this paper, we are interested in handling the limited availability of machines in the two-stage assembly flow shop scheduling problems. Emphasis is put on the semiresumable case with respect to the minimization of the makespan. We provide, when possible, heuristics with a tight worst-case ratio bound of 2.	best, worst and average case;flow shop scheduling;heuristic (computer science);limited availability;makespan;scheduling (computing)	Hatem Hadda;Najoua Dridi;Sonia Hajri-Gabouj	2014	J. Math. Model. Algorithms in OR	10.1007/s10852-013-9235-7	mathematical optimization;real-time computing;flow shop scheduling;computer science	Robotics	15.392509785980018	9.025680018038923	61789
f020547a18d201ec48e9b87e05d59b976b881cc5	makespan distribution of permutation flowshop schedules	permutation flowshop scheduling problem pfsp;scheduling problem;makespan distribution;asymptotic normal;job dominated and machine dominated pfsps	The makespan distribution of permutation flowshop schedules has been a topic of debate for almost fifty years. Many researchers have confirmed or doubted the famous claim that the makespan distribution of permutation flowshop schedules is asymptotically normal if the number of jobs is sufficiently large. This paper theoretically and empirically investigates the makespan distribution of permutation flowshop schedules and shows that the normality claim is not valid for the job-dominated and machine-dominated flowshops. Errors in the proof of normality of the makespan distribution of permutation flowshop schedules are pointed out. It is shown that the makespan distribution of a permutation flowshop scheduling problem depends on the number of jobs as well as the number of machines.	makespan	Feng Jin;Jatinder N. D. Gupta;Shiji Song;Cheng Wu	2008	J. Scheduling	10.1007/s10951-008-0071-y	job shop scheduling;mathematical optimization;combinatorics;discrete mathematics;johnson's rule;computer science;mathematics	Theory	15.681745570031493	12.715777371975323	61804
8386a28cfede6cec1951184c1b90bc6ec9de3a8e	setting due dates to minimize the total weighted possibilistic mean value of the weighted earliness-tardiness costs on a single machine	earliness tardiness costs;customer service;journal;polynomial time algorithm;due date assignment;single machine;the weighted possibilistic mean value and variance;optimal scheduling;scheduling;customer service level;precedence constraint;scheduling problem;numerical experiment	In this paper, it is investigated how to sequence jobs with fuzzy processing times and predict their due dates on a single machine such that the total weighted possibilistic mean value of the weighted earliness–tardiness costs is minimized. First, an optimal polynomial time algorithm is put forward for the scheduling problem when there are no precedence constraints among jobs. Moreover, it is shown that if general precedence constraints are involved, the problem is NP-hard. Then, four reduction rules are proposed to simplify the constraints without changing the optimal schedule. Based on these rules, an optimal polynomial time algorithm is proposed when the precedence constraint is a tree or a collection of trees. Finally, a numerical experiment is given. © 2011 Elsevier Ltd. All rights reserved.	algorithm;experiment;job stream;np-hardness;numerical analysis;p (complexity);polynomial;schedule (computer science);scheduling (computing)	Jinquan Li;Xuehai Yuan;E. S. Lee;Dehua Xu	2011	Computers & Mathematics with Applications	10.1016/j.camwa.2011.09.063	job shop scheduling;mathematical optimization;real-time computing;mathematics;scheduling	AI	15.43380525650767	9.49292564554041	61839
26699b7fac11ecbf4bdebccb2ab5282c016cb8a0	the k-cardinality tree problem: reformulations and lagrangian relaxation	k cardinality tree problem;heuristique;k;lagrangien;multicommodity flow;optimisation;programacion entera;combinatorics;digraph;tree;optimizacion;heuristica;05c05;combinatoria;implementation;branch and bound algorithm;arbol;coaccion;combinatoire;contrainte;digrafo;05c20;68wxx;programmation en nombres entiers;relajacion;algorithme;upper bound;algorithm;graph connectivity;constraint;programacion lineal;integer programming;multiflot;informatique theorique;directed graph;timing optimization;68r10;graphe oriente;conectividad grafo;linear programming relaxation;linear programming;arbre;programmation lineaire;relaxation;lagrangiano;grafo orientado;optimization;heuristics;cardinalite;integer program;implementacion;borne superieure;connectivite graphe;lagrangian;lagrangian relaxation;cota superior;computer theory;algoritmo;informatica teorica;digraphe	Given an undirected defining graph for the k-Cardinality Tree Problem (KCTP), an associated directed graph involving two additional vertices is introduced in this paper and gives rise to two compact reformulations of the problem. For the first one, connectivity of feasible solutions is enforced through multicommodity flows while, for the other, lifted Miller-Tucker-Zemlin constraints are used. Comparing the two reformulations, much stronger Linear Programming relaxation bounds are obtained from the first one, albeit at much higher CPU times. However, a Branch-and-Bound algorithm based on the second reformulation proved much more effective and managed to obtain, for the first time, optimality certificates for a large number of KCTP instances from the literature. Additionally, for some instances where optimality could not be proven within the given pre-specified CPU time limit, new best upper bounds were generated. Finally, a Lagrangian heuristic based on the first reformulation was also implemented and proved capable of generating feasible KCTP solutions comparable in quality with the best overall results obtained by metaheuristic based heuristics found in the literature. For our test cases, Lagrangian upper bounds are no more than 3.8% away from the best upper bounds known. Additionally, several new best upper bounds and optimality certificates were obtained by the heuristic. Corresponding Lagrangian heuristic CPU times, however, are typically higher than those associated with their competitors.	lagrangian relaxation;linear programming relaxation	Frederico Paiva Quintão;Alexandre Salles da Cunha;Geraldo Robson Mateus;Abilio Lucena	2010	Discrete Applied Mathematics	10.1016/j.dam.2009.01.017	mathematical optimization;combinatorics;discrete mathematics;directed graph;integer programming;linear programming;mathematics;algorithm	NLP	22.438951437564935	12.689501288626827	61962
0805ff911cb252b2b7fc3290b0ae72a0d8dc92a1	an fptas for sm-cels problem with monotone cost functions	optimal solution;cybernetics;approximate algorithm;cost function;best approximation;dynamic program;inventory costs;np hard problem;time series analysis;approximate solution;lot sizing;fully polynomial time approximation scheme;lot size;programming;design methodology	Purpose – The purpose of this paper is to find the best approximation algorithm for solving the more general case of single‐supplier multi‐retailer capacitated economic lot‐sizing (SM‐CELS) problem in deterministic inventory theory, which is the non‐deterministic polynomial (NP)‐hard problem.Design/methodology/approach – Since few theoretical results have been published on polynomial time approximation algorithms for SM‐CELS problems, this paper develops a fully polynomial time approximation scheme (FPTAS) for the problem with monotone production and holding‐backlogging cost functions. First the optimal solution of a rounded problem is presented as the approximate solution and its straightforward dynamic‐programming (DP) algorithm. Then the straightforward DP algorithm is converted into an FPTAS by exploiting combinatorial properties of the recursive function.Findings – An FPTAS is designed for the SM‐CELS problem with monotone cost functions, which is the strongest polynomial time approximation result.Re...	polynomial-time approximation scheme;monotone	Jianteng Xu;Qingpu Zhang;Qingguo Bai	2009	Kybernetes	10.1108/03684920910994105	programming;mathematical optimization;combinatorics;discrete mathematics;polynomial-time approximation scheme;cybernetics;design methods;computer science;artificial intelligence;time series;np-hard;mathematics	Theory	23.731221121854702	11.771535588082964	62216
d16bf61c789ca48e8754b91e633da072a82ecbf8	scheduling optional tasks with explanation		Many scheduling problems involve reasoning about tasks which may or may not actually occur, so called optional tasks. The state-ofthe-art approach to modelling and solving such problems makes use of interval variables which allow a start time of ⊥ indicating the task does not run. In this paper we show we can model interval variables in a lazy clause generation solver, and create explaining propagators for scheduling constraints using these interval variables. Given the success of lazy clause generation on many scheduling problems, this combination appears to give a powerful new solving approach to scheduling problems with optional tasks. We demonstrate the new solving technology on wellstudied flexible job-shop scheduling problems where we are able to close 36 open problems.	experiment;interval arithmetic;job shop scheduling;lazy evaluation;microsoft outlook for mac;propagator;scheduling (computing);solver;the australian	Andreas Schutt;Thibaut Feydy;Peter J. Stuckey	2013		10.1007/978-3-642-40627-0_47	fair-share scheduling;mathematical optimization;real-time computing;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing;algorithm	AI	15.472953527187313	6.971335310197864	62220
651c899b59d317e2a5b04113a60b71701f190801	on the complexity of learning lexicographic strategies	optimal solution;take the best;pac learning;bounded rationality;polynomial time algorithm;fast and frugal heuristic;computational complexity;greedy algorithm;upper and lower bounds;performance ratio;hardness of approximation;sample complexity;probably approximately correct	Fast and frugal heuristics are well studied models of bounded rationality. Psychological research has proposed the take-the-best heuristic as a successful strategy in decision making with limited resources. Take-the-best searches for a sufficiently good ordering of cues (or features) in a task where objects are to be compared lexicographically. We investigate the computational complexity of finding optimal cue permutations for lexicographic strategies and prove that the problem is NP-complete. It follows that no efficient (that is, polynomial-time) algorithm computes optimal solutions, unless P=NP. We further analyze the complexity of approximating optimal cue permutations for lexicographic strategies. We show that there is no efficient algorithm that approximates the optimum to within any constant factor, unless P=NP.#R##N##R##N#The results have implications for the complexity of learning lexicographic strategies from examples. They show that learning them in polynomial time within the model of agnostic probably approximately correct (PAC) learning is impossible, unless RP=NP. We further consider greedy approaches for building lexicographic strategies and determine upper and lower bounds for the performance ratio of simple algorithms. Moreover, we present a greedy algorithm that performs provably better than take-the-best. Tight bounds on the sample complexity for learning lexicographic strategies are also given in this article.	lexicographical order	Michael Schmitt;Laura Martignon	2006	Journal of Machine Learning Research		mathematical optimization;combinatorics;discrete mathematics;computer science;machine learning;mathematics;probably approximately correct learning	ML	14.605174537333259	16.217469659953434	62470
40e0e6382dd41e9d9f5977e65f0fde3f2dc5ba2f	sequential constraint augmentation with variable neighbourhood search for the multidimensional assignment problem	search problem;assignment problem;probleme affectation;temps polynomial;recherche voisinage;problema np duro;multidimensional assignment problem;problema investigacion;neighbourhood search;quartier voisinage;permutation;optimisation combinatoire;upper bound;sequential constraint augmentation;temps calcul;np hard problem;computational results;probleme np difficile;permutacion;polynomial time;problema asignacion;tiempo computacion;computation time;borne superieure;combinatorial optimization;probleme recherche;neighborhood search;barrio vecindad;combinatorial optimisation;busqueda de cercania;cota superior;optimizacion combinatoria;residential neighborhoods;tiempo polinomial	This work proposes the Sequential Constraint Augmentation (SCA) procedure for the Multidimensional Assignment Problem (MAP). Although the two-dimensional assignment problem has been shown to be solvable in polynomial time, the problem becomes NP-hard when it is extended to three dimensions. We investigate the benefits of implementing an intra-permutation 2 exchange and variable neighbourhood search for the SCA. The variable neighbourhood approach utilises the intra-permutation 2 and n-exchanges and the inter permutation 2-exchange. All three κ-exchange neighbourhoods are motivated by the permutation formulation of the MAP. Computational results show that the SCA procedure provides a tight upper bound with little computational effort. Exploring our variable neighbourhood significantly improves the SCA solution within a relatively short amount of computation time.	assignment problem;variable neighborhood search	Eduardo L. Pasiliao;Panos M. Pardalos	2007	IJCSE	10.1504/IJCSE.2007.017824	time complexity;combinatorics;search problem;combinatorial optimization;computer science;calculus;np-hard;mathematics;permutation;assignment problem;upper and lower bounds;algorithm	AI	21.34792015163312	11.163479464300098	62499
f7a28718f257a6e565f07619224e83f974b6d45d	multimode project scheduling based on particle swarm optimization	optimisation;construccion arquitectura tecnologia ambiental;project management;computacion informatica;optimizacion;optimizacion pso;resource allocation;estudio comparativo;construction industry;grupo de excelencia;construction scheduling;etude comparative;particle swarm optimizer;ciencias basicas y experimentales;scheduling;particle swarm optimization;comparative study;optimisation pso;gestion projet;optimization;project scheduling;tecnologias;methodology;experimentation;ordonnancement;gestion proyecto;reglamento;experimentacion	The multimode resource-constrained project scheduling problem (MRCPSP) considers both renewable and nonrenewable resources that have not been addressed efficiently in the construction field. This article introduces a methodology for solving the MRCPSP based on particle swarm optimization (PSO) that has not been utilized for this and other construction-related problems. The framework of the PSO-based methodology is developed. A particle representation formulation is proposed to represent the potential solution to the MRCPSP in terms of priority combination and mode combination for activities. Each particle-represented solution should be checked against the nonrenewable resource infeasibility and will be handled by adjusting the mode combination. The feasible particle-represented solution is transformed to a schedule through a serial generation scheme. Experimental analyses are presented to investigate the performance of the proposed methodology.	experiment;mathematical optimization;particle swarm optimization;phase-shift oscillator;scheduling (computing);stochastic process	Hong Zhang;C. M. Tam;Heng Li	2006	Comp.-Aided Civil and Infrastruct. Engineering	10.1111/j.1467-8667.2005.00420.x	project management;simulation;resource allocation;computer science;engineering;artificial intelligence;comparative research;methodology;particle swarm optimization;management;scheduling;schedule	AI	19.19357244893403	5.1405735867597775	62548
6e986bdbe6f48220382bed1ac3ff25be5eb95ef2	solving a truck dispatching scheduling problem using branch-and-cut	graph theory;zero one programming;teoria grafo;programacion entera;probleme livraison;heuristic method;graph clique;vehicle routing;branch and cut method;programmation zero un;metodo heuristico;theorie graphe;methode branchement et coupe;programmation en nombres entiers;compania petrolera;lorry;algorithme;algorithm;integer;programacion lineal;integer programming;scheduling;cutting plane facet generation;transportation;oil company;dispatching problem;linear programming;compagnie petroliere;programmation lineaire;scheduling problem;algorithms;ordonamiento;programming integer;methode heuristique;branch and cut algorithm for a structured 0 1 problem;clique graphe;camion;dispatching of trucks for an oil company;branch and cut;programming;ordonnancement;problema reparto;algoritmo	"""A branch-and-cut IP solver is developed for a class of structured 0/1 integer programs arising from a truck dispatching scheduling problem. This problem involves a special class of knapsack equality constraints. Families of facets for the polytopes associated with individual knapsack constraints are identified. In addition, a notion of """"conflict graph"""" is utilized to obtain an approximating node-packing polytope for the convex hull of all 0/1 solutions. The branch-and-cut solver generates cuts based on both the knapsack equality constraints and the approximating node-packing polytope, and incorporates these cuts into a tree-search algorithm that uses problem reformulation and linear programming-based heuristics at each node in the search tree to assist in the solution process. Numerical experiments are performed on large-scale real instances supplied by Texaco Trading & Transportation, Inc. The optimal schedules correspond to cost savings for the company and greater job satisfaction for drivers due to more balanced work schedules and income distribution."""	branch and cut;scheduling (computing)	Robert E. Bixby;Eva K. Lee	1998	Operations Research	10.1287/opre.46.3.355	integer;clique;continuous knapsack problem;programming;transport;mathematical optimization;combinatorics;truck;integer programming;linear programming;graph theory;mathematics;knapsack problem;scheduling;algorithm;branch and cut	Robotics	18.059863388086118	6.6751095907808375	62561
63a7f8aa8747865438867d1ac5add446282bb49a	on semi-online machine scheduling and generalized bin covering		In this thesis we study algorithms for scheduling problems. We investigate semi-online minimum makespan scheduling and generalized bin covering. In online minimum makespan scheduling we are given a set of m machines and n jobs, where each job Jt is specified by a processing time. The jobs arrive one by one and we have to assign them to the machines without any knowledge about future incoming jobs. The load of a machine is defined to be total processing time of the assigned jobs. The goal is to place the jobs on the machines such that the maximum load of a machine is minimized. In semi-online minimum makespan scheduling this strict setting is softened. We investigate three different models. In the first setting an algorithm is given an advice on the total processing time of the jobs. We present a simple 1.75-competitive algorithm and a lower bound of ≈ 1.585. In the second setting we may reassign jobs upto a limited amount. In this model we present an algorithm that has a competitive ratio of ρm ≈ 1.4659 form→∞ and uses no more than φm ·m job migrations, where φm is a constant between 7 and 10, depending onm. The result is complemented by two lower bounds. Firstly, no algorithm can attain a competitive ratio smaller than ρm using o(n) migrations. Secondly, every algorithm that has competitiveness smaller than 1 + 1/ √ 2 must use Ω(m) job migrations. We finally trade performance for migrations and obtain a family of algorithms with competitiveness ρ̂, for every 5/3 ≤ ρ̂ ≤ 1.75, that uses between 4m and 2.5m job migrations. The third semi-online setting we study is minimum makespan scheduling with parallel schedules. In this problem an algorithm may maintain several schedules, the best of which is output after the arrival of the entire job sequence. We provide a reduction to the special case, where the optimum solution value is known. We design an algorithm that maintains O(1) schedules and is (4/3 + ε)-competitive, for any ε > 0. We furthermore give an algorithm that is (1 + ε)-competitive, for any ε > 0, using mO(1/ε) schedules. Our results are complemented by a lower bound stating that mΩ(1/ε) schedules have to be maintained in order to achieve a competitiveness of less than 1 + ε, for every ε ≤ 1/3. In generalized bin covering we are given m bin types and n items. Each bin type Mj is specified by a demand dj and a revenue rj . Each item Jt has a size pj . A bin of typeMj is said to be covered if the total size of the assigned items is at least the demand dj . Then the revenue rj is earned. The goal is to find an assignment of items to bins maximizing the total obtained revenue. We study two models of bin supply. In the unit supply model there is only one bin of each type available. By contrast in the infinite supply model each bin type is available arbitrarily often, and hence the former is a generalization of the latter. We give a 5-approximation for the unit supply model. In the special case that we have dj = rj , for all bin typesMj , we can give a 9/4-approximation for the unit supply model. We show a lower bound on the approximation factor of 2, unless P = NP, that holds for the unit supply model. The result remains valid even asymptotically. For the infinite supply model we give an AFPTAS in the special case that dj = rj , for all bin types Mj .	algorithm;approximation;competitive analysis (online algorithm);jt (visualization format);job stream;makespan;maxima and minima;p versus np problem;schedule (computer science);scheduling (computing);semiconductor industry	Matthias Hellwig	2013			bin;scheduling (computing);distributed computing;mathematics	Theory	15.172796890494142	11.46200814311898	62657
949c33c51098988bb7acd3f2f48c2cad7b7ef038	vehicle routing and staffing for sedan service	optimisation;urban transportation;programacion entera;driver staffing;optimizacion;systeme aide decision;transporte urbano;routing;vehicle routing problem;approche heuristique;vehicle routing;columna;formulacion;probleme tournee vehicule;colonne;sistema ayuda decision;problema ruta vehiculo;columns;programmation en nombres entiers;busca local;qa75 electronic computers computer science;he transportation and communications;decision support system;integer programming;heuristic methods;transport urbain;enfoque heuristico;urban transportation services;drivers;optimization;fleet management;heuristic approach;local search;formulation;vehicle passenger service;recherche locale;column generation	We present the optimization component of a decision support system developed for a sedan service provider. The system assists supervisors and dispatchers in scheduling driver shifts and routing the fleet throughout the day to satisfy customer demands within tight time windows. We periodically take a snapshot of the dynamic data and formulate an integer program, which we solve to near-optimality using column generation. Although the data snapshot is stale by the time a solution is computed, we are able to solve the integer program quickly enough that the solution can be adopted after minor modifications are made by a fast local-search heuristic. The system described in this paper is currently in use and has improved the provider’s productivity significantly.	column generation;decision support system;dynamic data;heuristic;integer programming;mathematical optimization;microsoft windows;scheduling (computing);snapshot (computer storage);vehicle routing problem	Oktay Günlük;Tracy Kimbrel;Laszlo Ladányi;Baruch Schieber;Gregory B. Sorkin	2006	Transportation Science	10.1287/trsc.1050.0122	column generation;mathematical optimization;routing;simulation;computer science;engineering;local search;operations management;vehicle routing problem;formulation;mathematics;transport engineering	Arch	16.89404741168289	5.244598614982461	62877
3033926910f0cd3ace2372632c6632c7a70c7596	several 2-facility location problems on networks with equity objectives	efficient algorithms;network location;finite dominating sets;equity measures	We consider 2-facility location problems with equity measures, defined on networks. The models discussed are, the variance, the mean of absolute weighted deviations, the maximum weighted absolute deviation, the sum of absolute weighted differences, and the range. We give new algorithmic results for these models in the 2-facility case. © 2014 Wiley Periodicals, Inc. NETWORKS, Vol. 000(00), 000–00	ackermann function;algorithm;computation;facility location problem;john d. wiley;linear programming;subdivision surface;time complexity	Jörg Kalcsics;Stefan Nickel;Justo Puerto;Antonio M. Rodríguez-Chía	2015	Networks	10.1002/net.21568	mathematical optimization;mathematics;mathematical economics;statistics	Theory	24.495406450106717	17.152050171578363	62942
4c68b8b33aac51b7f7f182f2f5a46a45c99b2f4b	the match fit algorithm: a testbed for the computational motivation of attention	bin packing problem;evaluation performance;bin packing;performance evaluation;evaluacion prestacion;heuristic method;multigrille;problema relleno;metodo heuristico;memoire travail;memoria trabajo;multigrid;parameter space;multigrilla;working memory;probleme remplissage;methode heuristique;on line algorithm;time constraint	We present an assessment of the performance of a new on-line bin packing algorithm, which can interpolate smoothly from the Next Fit to Best Fit algorithms, as well as encompassing a new class of heuristic which packs multiple blocks at once. The performance of this novel O(n) on-line algorithm can be better than that of the Best Fit algorithm. The new algorithm runs about an order of magnitude slower than Next Fit, and about two orders of magnitude faster than Best Fit, on large sample problems. It can be tuned for optimality in performance by adjusting parameters which set its working memory usage, and exhibits a sharp threshold in this optimal parameter space as time constraint is varied. These optimality concerns provide a testbed for the investigation of the value of memory and attention-like properties to algorithms.	best practice;bin packing problem;computation;heuristic;interpolation;online algorithm;online and offline;set packing;smoothing;testbed	Joseph G. Billock;Demetri Psaltis;Christof Koch	2001		10.1007/3-540-45718-6_23	bin packing problem;simulation;computer science;artificial intelligence;algorithm;statistics	Comp.	17.39973813438437	12.300881969527245	63338
7ef3a1352435ce896316810236f6cd219ca87061	the knapsack sharing problem: an exact algorithm	dynamic programming;programacion dinamica;probleme sac a dos;algorithm performance;dynamic program;problema mochila;optimisation combinatoire;knapsack problem;resultado algoritmo;exact algorithm;programmation dynamique;performance algorithme;combinatorial optimization;algoritme sequentiel;optimizacion combinatoria	In this paper, we propose an exact algorithm for the knapsack sharing problem. The proposed algorithm seems quite efficient in the sense that it solves quickly some large problem instances. The problem is decomposed into a series of single constraint knapsack problems; and by applying the dynamic programming and another strategy, we solve optimally the original problem. The performance of the exact algorithm is evaluated on a set of medium and large problem instances (a total of 240 problem instances). This algorithm is parallelizable and this is one of its important feature.	bell test experiments;dynamic programming;exact algorithm;experiment;knapsack problem	Mhand Hifi;Slim Sadfi	2002	J. Comb. Optim.	10.1023/A:1013385216761	continuous knapsack problem;mathematical optimization;combinatorics;combinatorial optimization;generalized assignment problem;cutting stock problem;change-making problem;dynamic programming;mathematics;knapsack problem;algorithm	AI	17.559805846616555	9.250420283303276	63515
812f68792ccd4d3bb88e32c62137065a7a370b04	number balancing is as hard as minkowski's theorem and shortest vector		The number balancing (NBP) problem is the following: given real numbers a1, . . . , an ∈ [0, 1], find two disjoint subsets I1, I2 ⊆ [n] so that the difference | ∑ i∈I1 ai − ∑ i∈I2 ai| of their sums is minimized. An application of the pigeonhole principle shows that there is always a solution where the difference is at most O( √ n 2n ). Finding the minimum, however, is NP-hard. In polynomial time, the differencing algorithm by Karmarkar and Karp from 1982 can produce a solution with difference at most n−Θ(log , but no further improvement has been made since then. In this paper, we show a relationship between NBP and Minkowski’s Theorem. First we show that an approximate oracle for Minkowski’s Theorem gives an approximate NBP oracle. Perhaps more surprisingly, we show that an approximate NBP oracle gives an approximate Minkowski oracle. In particular, we prove that any polynomial time algorithm that guarantees a solution of difference at most 2 √ /2 would give a polynomial approximation for Minkowski as well as a polynomial factor approximation algorithm for the Shortest Vector Problem.	appletalk;approximation algorithm;autoregressive integrated moving average;lattice problem;minkowski's theorem;np-hardness;neutral body posture;oracle nosql db;p (complexity);pigeonhole sort;polynomial;time complexity	Rebecca Hoberg;Harishchandra Ramadas;Thomas Rothvoss;Xin Yang	2017		10.1007/978-3-319-59250-3_21	combinatorics;mathematical analysis;discrete mathematics;mathematics;algorithm	Theory	19.33974942087058	15.673267386843792	63625
ca3f16c8ce491f2377e6e1976dff533432359346	multilevel graph partitioning: an evolutionary approach	graphe non oriente;forecasting;graph theory;reliability;teoria grafo;project management;non directed graph;descomposicion grafo;information systems;maintenance;soft or;information technology;packing;operations research;location;algoritmo genetico;theorie graphe;investment;journal;journal of the operational research society;inventory;purchasing;history of or;graph partitioning;logistics;marketing;grafo no orientado;scheduling;graph partitioning problem;algorithme genetique;production;multilevel graph partitioning;communications technology;algorithme evolutionniste;genetic algorithm;genetic algorithms;algoritmo evolucionista;computer science;operational research;evolutionary algorithm;partitionnement graphe;applications of operational research;or society;jors;management science;graph decomposition;infrastructure;decomposition graphe	The graph partitioning problem is defined as that of dividing the vertices of an undirected graph into a set of balanced parts through the removal of a set of edges, whose size is to be minimized. A number of researchers have investigated multilevel schemes, which coarsen the graph by collapsing vertices and edges, partition the smaller graph, and then uncoarsen it to construct a partitioning of the original graph. In this paper, a genetic algorithm for the coarsening phase of a multilevel scheme for graph partitioning is presented. The proposed approach has been demonstrated to improve the solution quality at the expense of running time. Journal of the Operational Research Society (2005) 56, 549–562. doi:10.1057/palgrave.jors.2601837 Published online 6 October 2004	experiment;genetic algorithm;graph (discrete mathematics);graph partition;iterative and incremental development;metis;partition problem;software release life cycle;time complexity;vertex (geometry)	S. Küçükpetek;F. Polat;Halit Oguztüzün	2005	JORS	10.1057/palgrave.jors.2601837	project management;graph power;combinatorics;genetic algorithm;directed graph;multiple edges;graph bandwidth;level structure;economics;null graph;graph labeling;computer science;graph partition;graph theory;marketing;theoretical computer science;simplex graph;mixed graph;evolutionary algorithm;hypercube graph;cycle graph;mathematics;voltage graph;graph;butterfly graph;operations research;information technology;quartic graph;complement graph;semi-symmetric graph;line graph;algorithm;strength of a graph	AI	18.600548639436838	5.698843902573329	63651
d330d67945aa4e7ece1ca57b51fa7db052add1e1	a note: minmax due-date assignment problem with lead-time cost	lead time;due date assignment;single machine;scheduling;minmax	All three major classes of due-date assignment models (CON, SLK and DIF) have been solved in the literature for a minsum setting, and only two of them (CON and SLK) have been solved for a minmax setting. In this note we introduce a solution for the missing minmax model of DIF. Specifically, we study a single-machine scheduling and due-date assignment problem, in which job-dependent lead-times are considered. Three cost components for each job are assumed: earliness cost, tardiness cost, and the cost for delaying the due-date (beyond its lead-time). The goal is to schedule the jobs and to assign due-dates, such that the maximum cost among all the jobs is minimized. We introduce an O(nlog^2n) solution algorithm (where n is the number of jobs).	assignment problem;minimax	Baruch Mor;Gur Mosheiov;Dvir Shabtay	2013	Computers & OR	10.1016/j.cor.2013.03.004	minimax;mathematical optimization;real-time computing;computer science;scheduling	ECom	15.248956489624772	9.400755426833088	63686
045be05d56a685cc828c274d497776767984ebe2	harmonic algorithm for online bin packing			algorithm;bin packing problem;set packing	Leah Epstein	2016		10.1007/978-1-4939-2864-4_490	bin packing problem	Theory	23.081075476821507	8.84120110296807	63791
746cf315b49fb25f7fe0fdc2d8058a1dbdb0cbf2	balancing of simple assembly lines under variations of task processing times	assembly line balancing problems;uncertainty;stability sensitivity analysis	One of the simple assembly line balancing problems (SALBPs), known as SALBP-E, is considered. It consists in assigning a given set V = {1,2, . . . , n} of elementary tasks to linearly ordered workstations with respect to precedence and capacity restrictions while minimizing the following product: number of used workstations × working time on the most loaded one. The stability of feasible and optimal solutions for this problem with regard to possible variations of the processing time of certain tasks is investigated. Two heuristic procedures finding a compromise between the efficiency and the considered stability measure of studied solutions are suggested and evaluated on known benchmarks.	approximation algorithm;benchmark (computing);computational complexity theory;experiment;heart rate variability;heuristic;loss function;numerical analysis;optimization problem;p (complexity);pareto efficiency;perturbation theory;stability radius;workstation	Evgeny Gurevsky;Olga Battaïa;Alexandre Dolgui	2012	Annals OR	10.1007/s10479-012-1203-5	mathematical optimization;uncertainty;computer science;operations management;mathematics;algorithm;statistics	AI	15.253561981474446	4.524606028451395	63842
2da2236cd92fbca3a83e38eaace2bcf448730ba0	online removable square packing	online algorithm;upper bound;knapsack problem;competitive ratio	The online removable square packing problem is a two-dimen-sional version of the online removable Knapsack problem. For a sequence of squares with side length at most 1, we are requested to pack a subset of them into a unit square bin in an online fashion where the online player can decide whether to take the current square or not and which squares currently in the unit square to remove. The goal is to maximize the total packed area. Our results include: (i) No online algorithm can achieve a better competitive ratio than $(\sqrt{5}+3)/2\approx 2.618$ . (ii) The matching upper bound is achieved by a relatively simple online algorithm if repacking is allowed. (iii) Without repacking, we can achieve an upper bound of 3 by using the concept of bricks of Januszewski and Lassak. (iv) The offline version of the problem admits a PTAS.	competitive analysis (online algorithm);knapsack problem;online algorithm;online and offline;ptas reduction;removable media;set packing;spectrum reallocation	Xin Han;Kazuo Iwama;Guochuan Zhang	2007	Theory of Computing Systems	10.1007/s00224-007-9039-0	competitive analysis;online algorithm;mathematical optimization;combinatorics;computer science;mathematics;upper and lower bounds;knapsack problem;square packing in a square	Theory	17.148167220523206	14.901711463014957	64000
c98ace63c1cca80542f25d9adff1b1e8d02578ae	refining the complexity of the sports elimination problem	parameterized complexity;sports elimination problem;multivariate complexity analysis;graph labelling	The sports elimination problem asks whether a team participating in a competition still has a chance to win, given the current standings and the remaining matches to be played among the teams. This problem can be viewed as a graph labelling problem, where arcs receive labels that contribute to the score of both endpoints of the arc, and the aim is to label the arcs in a way that each vertex obtains a score not exceeding its capacity. We investigate the complexity of this problem in detail, using a multivariate approach to examine how various parameters of the input graph (such as the maximum degree, the feedback vertex/edge number, and different width parameters) influence the computational tractability. We obtain several efficient algorithms, as well as certain hardness results.	algorithm;cobham's thesis;computation;computational complexity theory;feedback arc set;graph (discrete mathematics);parameterized complexity	Katarína Cechlárová;Eva Potpinková;Ildikó Schlotter	2016	Discrete Applied Mathematics	10.1016/j.dam.2015.01.021	parameterized complexity;mathematical optimization;combinatorics;discrete mathematics;feedback vertex set;vertex cover;machine learning;mathematics;algorithm	AI	18.73507457799125	18.032260672613518	64148
a1f5a6566e43143f3250ff58e2fc6b42350e08f6	a heuristic two-phase solution approach for the multi-objective dial-a-ride problem	heuristic two-phase solution procedure;additional efficient solution;wiley periodicals;inc. networks;search-based heuristic;multi-objective dial-a-ride problem;minimum cost objective;heuristic two-phase solution approach;constraint method;approximate weighted sum solution;exact efficient set;proposed two-phase method	In this article, we develop a heuristic two-phase solution procedure for the dial-a-ride problem with two objectives. Besides the minimum cost objective a client centered objective has been defined. Phase one consists of an iterated variable neighborhood search-based heuristic, generating approximate weighted sum solutions; phase two is a path relinking module, computing additional efficient solutions. Results for two sets of benchmark instances are reported. For the smaller instances, exact efficient sets are generated by means of the -constraint method. Comparison shows that the proposed two-phase method is able to generate high-quality approximations of the true Pareto frontier. © 2009 Wiley Periodicals, Inc. NETWORKS, Vol. 54(4), 227–242 2009	approximation algorithm;benchmark (computing);branch and cut;heuristic;horner's method;in-phase and quadrature components;iteration;john d. wiley;local search (optimization);mathematical optimization;multi-objective optimization;pareto efficiency;two-phase commit protocol;two-phase locking;variable neighborhood search;weight function	Sophie N. Parragh;Karl F. Doerner;Richard F. Hartl;Xavier Gandibleux	2009	Networks	10.1002/net.20335	mathematical optimization;input/output;mathematics;efficiency;algorithm	AI	23.762384508343718	5.03187138932816	64198
e493e791c5ee69bc4f2a94e6a65570d905254220	scheduling trucks in a cross-dock with mixed service mode dock doors	cross docking;scheduling;flexible capacity;warehouse management	Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2015, INFORMS	algorithm;analysis of algorithms;computation;direction finding;dock connector;docking (molecular);download;emoticon;fo (complexity);gurobi;heuristic (computer science);institute for operations research and the management sciences;nl (complexity);robot;scheduling (computing);solver;stochastic process;time complexity	Péter Bodnár;René M. B. M. de Koster;Kaveh Azadeh	2017	Transportation Science	10.1287/trsc.2015.0612	real-time computing;simulation;computer science;engineering;operations management;scheduling	Logic	13.342821483387269	5.087805211614352	64527
e117da3d6abb2ca86bfe75830e381d14915a7cef	minimization of half-products	minimisation;minimization;fonction booleenne;optimisation;completion time;completion time variance minimization;quadratic function;funcion cuadratica;fonction quadratique;temps polynomial;numerical solution;variance minimale;optimizacion;probleme np complet;efficiency;methode approchee;variancia minima;boolean function;temps achevement;metodo aproximado;minimizacion;approximate method;quadratic binary minimization;matrices;funcion booliana;indexation;polynomial time;algorithms;minimal variance;problema np completo;optimization;fully polynomial approximation scheme;variational methods;np complete problem;tiempo polinomial;mathematics computers information science management law miscellaneous	Since Å xi for binary variables, aiiÅ 0 could be assumed without any loss of generality. 2 x i It is well known that finding the minimum of f is an NP-hard problem (Garey and Johnson 1979); it contains, as special cases, the vertex cover, maximum cut, signed-graph balancing and MAX-2SAT problems. Moreover, for the general minimization problem there exists a constant c ú 0 such that the existence of a (1 0 c)-approximation algorithm would imply P Å NP ; see Arora et al. (1992). This result amplifies the importance of special classes of quadratic pseudo-Boolean functions, for which the minimization problem can be either solved, or at least approximated efficiently. In this paper we introduce a special class, for which the problem of minimization over the set of binary vectors is still difficult, but for which there exists a polynomial time approximation algorithm. The interested reader can find more about related problems, polynomially solvable special cases, algorithms and approximations, e.g., in Boros and Hammer (1991), Deza and Laurent (1992), Padberg (1989) and Palubeckis (1990). Let p Å (p1 , . . . , pn) , q Å (q1 , . . . , qn) ¢ 0 and r Å (r1 , . . . , rn) ¢ 0 be integer vectors, and let us consider the function	2-satisfiability;approximation algorithm;decision problem;maximum cut;michael garey;np-hardness;polynomial;signed graph;time complexity;vertex cover	Tamás Badics;Endre Boros	1998	Math. Oper. Res.	10.1287/moor.23.3.649	time complexity;minimisation;mathematical optimization;combinatorics;np-complete;quadratic function;calculus;mathematics;efficiency;boolean function;algorithm;matrix	Theory	23.698945174701826	13.903184076498789	64686
d5d5b11bbc5789cab1e8314a77d5fc079fa70db1	on-line algorithms for 2-space bounded 2-dimensional bin packing	on line algorithms	In 2-space bounded model of on-line bin packing, there are 2 active bins, and each item can be packed only into one of the active bins. If it is impossible to pack an item into any active bin, we close one of the current active bins and open a new active bin to pack that item. In 2-space bounded 2-dimensional bin packing problem, each item is a rectangle of side lengths not greater than 1. The items are packed on-line into square bins of size 1x1 and 90^o-rotations are allowed. In this paper a 4-competitive 2-space bounded 2-dimensional on-line packing algorithm is presented. Furthermore, an on-line strategy with competitive ratio 3.8 is given for 2-space bounded square packing.	algorithm;bin packing problem;set packing	Janusz Januszewski	2012	Inf. Process. Lett.	10.1016/j.ipl.2012.06.016	mathematical optimization;combinatorics;bin packing problem;computer science;mathematics;bin;square packing in a square	DB	17.044524496703726	14.917144928438633	65016
98bdd7d00f495b0dad689c5863fe7015353b4ff9	integer programming methods for special college admissions problems	qa75 electronic computers computer science szamitastechnika;lb2300 higher education felsőoktatas;szamitogeptudomany;college admissions problem;lower quotas;integer programming;stable score limits;paired applications;common quotas	We develop Integer Programming (IP) solutions for some special college admission problems arising from the Hungarian higher education admission scheme. We focus on four special features, namely the solution concept of stable score-limits, the presence of lower and common quotas, and paired applications. We note that each of the latter three special feature makes the college admissions problem NP-hard to solve. Currently, a heuristic based on the Gale-Shapley algorithm is being used in the application. The IP methods that we propose are not only interesting theoretically, but may also serve as an alternative solution concept for this practical application, and also for other ones.	algorithm;heuristic;integer programming;np-hardness	Péter Biró;Iain McBride	2016	J. Comb. Optim.	10.1007/s10878-016-0085-x	mathematics education;mathematical optimization;combinatorics;simulation;integer programming;computer science;mathematics;algorithm	ML	19.54891437797248	10.965297327505453	65051
3fc3d9a04ffccb7e3ab7356ca97258213d688699	lagrangian decomposition, metaheuristics, and hybrid approaches for the design of the last mile in fiber optic networks	network design;fiber optic;greedy randomized adaptive search procedure;hybrid approach;redundancy;community networks;variable neighborhood search;survivable network design;steiner tree problem;integer linear program;lower bound;lagrangian relaxation	We consider a generalization of the (Price Collecting) Steiner Tree Problem on a graph with special redundancy requirements for customer nodes. The problem occurs in the design of the last mile of real-world communication networks. We formulate it as an abstract integer linear program and apply Lagrangian Decomposition to obtain relatively tight lower bounds as well as feasible solutions. Furthermore, a Variable Neighborhood Search and a GRASP approach are described, utilizing a new construction heuristic and special neighborhoods. In particular, hybrids of these methods are also studied and turn out to often perform superior. By comparison to previously published exact methods we show that our approaches are applicable to larger problem instances, while providing high quality solutions together with good lower bounds.	branch and price;computation;display resolution;grasp;heuristic;lagrangian relaxation;last mile;linear programming;linear programming relaxation;local search (optimization);meta content framework;metaheuristic;multi-commodity flow problem;passive optical network;requirement;steiner tree problem;telecommunications network;variable neighborhood search	Markus Leitner;Günther R. Raidl	2008		10.1007/978-3-540-88439-2_12	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	24.50833696462709	8.741997996150454	65246
5a2151e0fe0dd1924ee590746d1651090279d770	a continuous-time unit-based milp formulation for the resource-constrained project scheduling problem		In the basic resource-constrained project scheduling problem RCPSP, one aims at selecting starting times for the tasks of a project such that the project makespan is minimized and the project schedule is precedence- and resource-feasible. There is a considerable body of literature about problem-specific solution methods; recently, mixed-integer linear programming (MILP) formulations for the RCPSP have received increasing attention. We suggest a new MILP formulation that utilizes a set of continuous variables indicating the starting times of the project tasks, and three sets of binary variables indicating the assignment of resource units to the project tasks, the potential overlapping of the project tasks, and the sequencing of the project tasks. In a comparison with ten reference formulations from the literature, it is found that the advantages of this new formulation are its simple structure, enhanced flexibility, and superior or comparable performance, particularly when the range of the tasks’ durations is relatively high.		Mario Gnagi;Adrian Zimmermann;Norbert Trautmann	2018	2018 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2018.8607337		Robotics	14.725137851781344	5.263112270674786	65294
17683a931e9ba8f80d07d941e9bcc95451f30fe0	airline crew scheduling with potts neurons	tecnologia electronica telecomunicaciones;learning algorithm;computacion informatica;algorithm performance;neurone potts;time complexity;resource allocation;logique floue;grupo de excelencia;logica difusa;algorithme apprentissage;fuzzy logic;potts neuron;complexite temps;retroaccion;retroaction;resultado algoritmo;high energy physics;ciencias basicas y experimentales;scheduling;performance algorithme;feedback regulation;scheduling problem;ordonamiento;asignacion recurso;reseau neuronal;tecnologias;allocation ressource;complejidad tiempo;grupo a;algoritmo aprendizaje;red neuronal;ordonnancement;neural network	A Potts feedback neural network approach for finding good solutions to resource allocation problems with a nonfixed topology is presented. As a target application, the airline crew scheduling problem is chosen. The topological complication is handled by means of a propagator defined in terms of Potts neurons. The approach is tested on artificial random problems tuned to resemble real-world conditions. Very good results are obtained for a variety of problem sizes. The computer time demand for the approach only grows like (number of flights)3. A realistic problem typically is solved within minutes, partly due to a prior reduction of the problem size, based on an analysis of the local arrival and departure structure at the single airports.	analysis of algorithms;artificial neural network;artificial neuron;cluster analysis;crew scheduling;entity;feasible region;fragmentation (computing);fuzzy mathematics;image scaling;potts model;propagator;routing;scheduling (computing);semantics (computer science)	Martin Lagerholm;Carsten Peterson;Bo Söderberg	1997	Neural Computation	10.1162/neco.1997.9.7.1589	fuzzy logic;time complexity;job shop scheduling;simulation;resource allocation;computer science;artificial intelligence;machine learning;scheduling;artificial neural network	ML	18.75980611853408	9.00625793301396	65388
032b6d5c0bd73a08076bde15e644c86f2dfd7bbb	dynamic routing problems with fruitful regions: models and evolutionary computation	modelizacion;parallelisme;adaptability;adaptabilite;algoritmo adaptativo;routing;real time;routage;dynamic routing;algoritmo genetico;adaptabilidad;resolucion problema;modelisation;adaptive algorithm;parallelism;algorithme adaptatif;paralelismo;biomimetique;temps reel;algorithme genetique;tiempo real;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;evolutionary algorithm;modeling;problem solving;resolution probleme;biomimetics;evolutionary computing;enrutamiento;time constraint	We introduce the concept of fruitful regions in a dynamic routing context: regions that have a high potential of generating loads to be transported. The objective is to maximise the number of loads transported, while keeping to capacity and time constraints. Loads arrive while the problem is being solved, which makes it a real-time routing problem. The solver is a self-adaptive evolutionary algorithm that ensures feasible solutions at all times. We investigate under what conditions the exploration of fruitful regions improves the effectiveness of the evolutionary algorithm.	computer;evolutionary algorithm;evolutionary computation;mathematical optimization;real-time clock;real-time transcription;solver;vehicle routing problem	Jano I. van Hemert;Han La Poutré	2004		10.1007/978-3-540-30217-9_70	biomimetics;mathematical optimization;routing;adaptability;systems modeling;genetic algorithm;adaptive routing;computer science;artificial intelligence;evolutionary algorithm;mathematics;algorithm	PL	20.124647260685897	6.190281100346599	65399
2f3eeaad11c925b6587552ab76fd0cb010b6a28b	the 0-1 knapsack problem with a single continuous variable	institutional repositories;mixed programming;ritidoplastia;zero one programming;continuous 0 1 knapsacks;probleme sac a dos;rhytidoplastie;fedora;lower and upper bound;desigualdad;inequality;continuous variable;modele mixte;inegalite;programmation zero un;restriction;valid inequalities;problema mochila;programmation mixte;polyhedral structure;vital;knapsack problem;programacion mixta;mixed model;lifting and projection;flow model;vtls;modelo mixto;ils;lifting	Constraints arising in practice often contain many 0-1 variables and one or a small number of continuous variables. Existing knapsack separation routines cannot be used on such constraints. Here we study such constraint sets, and derive valid inequalities that can be used as cuts for such sets, as well for more general mixed 0-1 constraints. Specifically we investigate the polyhedral structure of the knapsack problem with a single continuous variable, called the continuous 0-1 knapsack problem. First different classes of facet-defining inequalities are derived based on projection and lifting. The order of lifting, particularly of the continuous variable, plays an important role. Secondly we show that the flow cover inequalities derived for the single node flow set, consisting of arc flows into and out of a single node with binary variable lower and upper bounds on each arc, can be obtained from valid inequalities for the continuous 0-1 knapsack problem. Thus the separation heuristic we derive for continuous knapsack sets can also be used to derive cuts for more general mixed 0-1 constraints. Initial computational results on a variety of problems are presented.	binary data;computation;heuristic;knapsack problem;lambda lifting;polyhedron;separation kernel	Hugues Marchand;Laurence A. Wolsey	1999	Math. Program.	10.1007/s101070050044	mixed model;continuous knapsack problem;mathematical optimization;combinatorics;discrete mathematics;change-making problem;inequality;mathematics;knapsack problem	AI	24.276607745291212	12.649686884838827	65637
952f5c00fcde608a4d733c35567c031e523fcd34	some startling inconsistencies when electing committees		We generalize the idea of a Condorcet winner to committee elections to select a Condorcet committee of size m. As in the case of a Condorcet winner, the Condorcet committee need not exist. We adapt two methods to measure how far a set of m candidates is from being the Condorcet committee. In particular, we generalize a procedure proposed by Lewis Carroll for selecting the candidate that is closest to being the Condorcet winner to allow the selection of a committee. We also generalize Kemeny’s method, which gives a complete transitive ranking, to the selection of committees and show that it is closely related to the first method.We show that these methods lead to some surprising inconsistencies. For example, the committee of size k may be disjoint from the committee of size j or they may overlap in any manner, the committee arising fromCarroll’smethodmay appear at any locations in theKemeny ranking, and except for two highly restrictive cases, the members of the committee arising from Kemeny’s method may appear at any location in the Kemeny ranking.	carroll morgan (computer scientist);transitive closure	Thomas C. Ratliff	2003	Social Choice and Welfare	10.1007/s00355-003-0209-y	dodgson's method;voting paradox;approval voting;data mining;operations research;condorcet method;kemeny–young method	ML	16.077334530820817	17.43185305343198	65643
eb7d45971670165a739fa5cf15589348f8b74492	workload balancing in identical parallel machine scheduling using a mathematical programming method	mathematical programming;scheduling;workload balancing;parallel machine	AbstractThis paper addresses the workload balancing problem in identical parallel machines context. The problem consists of assigning n different jobs to m identical parallel machines in order to minimize the workload imbalance among the different machines. This problem is formulated as a linear mixed integer program to minimize the difference between the greatest and smallest workload assigned to each machine. Based on some numerical examples reported in the literature, we establish that the classical formulation which consists of minimizing the greatest machine completion time does not provide the optimal workload repartition. That is why we consider a new mathematical formulation based on the minimization of the difference between the workload of the bottleneck machine and the workload of the fastest machine. The proposed programming method is also used to provide optimal solutions in reasonable computational times for different test problems presented in the literature by Raghavendra and Murthy 10 to ...	mathematical optimization;parallel computing;scheduling (computing)	Yassine Ouazene;Farouk Yalaoui;Hicham Chehade;Alice Yalaoui	2014	Int. J. Comput. Intell. Syst.	10.1080/18756891.2013.853932	real-time computing;computer science;theoretical computer science;distributed computing;scheduling	HPC	14.966903259796485	9.937876830673533	65644
83bb6d55d43d636a24ecf411ace3ec7b2e2a6f5b	scheduling shared continuous resources on many-cores	approximation algorithms;resources;scheduling	We consider the problem of scheduling a number of jobs on m identical processors sharing a continuously divisible resource. Each job j comes with a resource requirement rj∈[0,1]. The job can be processed at full speed if granted its full resource requirement. If receiving only an x-portion of r_j, it is processed at an x-fraction of the full speed. Our goal is to find a resource assignment that minimizes the makespan (i.e., the latest completion time). Variants of such problems, relating the resource assignment of jobs to their processing speeds, have been studied under the term discrete-continuous scheduling. Known results are either very pessimistic or heuristic in nature.  In this paper, we suggest and analyze a slightly simplified model. It focuses on the assignment of shared continuous resources to the processors. The job assignment to processors and the ordering of the jobs have already been fixed. It is shown that, even for unit size jobs, finding an optimal solution is NP-hard if the number of processors is part of the input. Positive results for unit size jobs include an efficient optimal algorithm for 2 processors. Moreover, we prove that balanced schedules yield a 2-1/m-approximation for a fixed number of processors. Such schedules are computed by our GreedyBalance algorithm, for which the bound is tight.	approximation algorithm;best, worst and average case;central processing unit;emoticon;heuristic;image scaling;job stream;makespan;microsoft outlook for mac;multiprocessing;np-hardness;schedule (computer science);scheduling (computing);worst-case complexity;yao graph	André Brinkmann;Peter Kling;Friedhelm Meyer auf der Heide;Lars Nagel;Sören Riechers;Tim Süß	2014		10.1145/2612669.2612698	real-time computing;computer science;operating system;distributed computing;scheduling;multiprocessor scheduling;approximation algorithm;resource	Theory	15.62553011587186	11.141534052230424	65777
1f7a30ae35d4ccd027c5d43747a65e92fb53b9e4	multiprocessor speed scaling for jobs with arbitrary sizes and deadlines	liverpool;multiprocessor scheduling;dynamic speed scaling;repository;competitive analysis;university;online algorithms;article;deadline scheduling	In this paper we study energy efficient deadline scheduling on multiprocessors in which the processors consumes power at a rate of s when running at speed s, where α ≥ 2. The problem is to dispatch jobs to processors and determine the speed and jobs to run for each processor so as to complete all jobs by their deadlines using the minimum energy. The problem has been well studied for the single processor case. For the multiprocessor setting, constant competitive online algorithms for special cases of unit size jobs or arbitrary size jobs with agreeable deadlines have been proposed by Albers et al. [6]. A randomized algorithm has been proposed for jobs of arbitrary sizes and arbitrary deadlines by Greiner et al. [22]. We propose a deterministic online algorithm for the general setting and show that it is O(log P )-competitive, where P is the ratio of the maximum and minimum job size.	atmel avr;central processing unit;deterministic algorithm;dynamic dispatch;earliest deadline first scheduling;image scaling;job stream;logp machine;maxima and minima;multiprocessing;online algorithm;openarena;randomized algorithm;scheduling (computing);throughput	Paul Bell;Prudence W. H. Wong	2015	J. Comb. Optim.	10.1007/s10878-013-9618-8	competitive analysis;online algorithm;mathematical optimization;parallel computing;real-time computing;computer science;mathematics;distributed computing;multiprocessor scheduling	Theory	15.76723054859467	11.579699553092459	66021
d3567c715e37871a6532e6c7052802b2e97a2f8f	an analysis of consecutively bounded depth-first search with applications in automated deduction	automated deduction;search strategy;depth first search;logic programs;breadth first search	Consecutively bounded depth-first search involves repeatedly performing exhaustive depth-first search with increasing depth bounds of 1, 2, 3, and so on. The effect is similar to that of breadth-first search, but, instead of retaining the results at level n-1 for use in computing level n, earlier results are recom-puted. Consecutively bounded depth-first search is useful whenever a complete search strategy is needed and either it is desirable to minimize memory requirements or depth-first search can be implemented particularly efficiently. It is notably applicable to automated deduction, especially in logic-programming systems, such as PROLOG and EQLOG, and their extensions. Consecutively bounded depth-first search, unlike unbounded breadth-first search, can perform cutoffs by using heuristic estimates of the minimum number of steps remaining on a solution path. Even if the possibility of such cutoffs is disregarded, an analysis shows that, in general, consecutively bounded depth-first search requires only b/b-1 times as many operations as breadth-first search, where 6 is the branching factor. 1 1 Introduction In this paper, we investigate the properties of consecutively bounded depth-first search. In this method, exhaustive depth-first search is repeatedly performed with increasing depth bounds of 1, 2, 3, and so on. The effect is similar to that of breadth-first search, but, instead of retaining the results at level n — 1 for use in computing level n, earlier results are recomputed. 2 Although this may appear to be a naive and costly search method, it is not necessarily so. It is sometimes advantageous to perform consecutively bounded depth-first search instead of the breadth-first search it imitates. One reason for this is that depth-first search requires much less memory. Consecutively bounded depth-first search can also make use of heuristic information, in contrast to unbounded breadth-and depth-first search—the latter are uninformed search strategies that do not take into account heuristic estimates of the remaining distance to a solution. Informed search strategies such as the A* algorithm use such heuristic information to order the ' The vi ews and concl usi ons contained i n this document are those of the authors and shoul d not be interpreted as representative of the official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the United States government. Approved for public rel ease. Distribution unlimited. 2 We assume a basi c familiarity with standard breadth-first, depth-first, and A* search strategies (e.g., see Ni l sson [4]). search space. …	a* search algorithm;automated theorem proving;branching factor;breadth-first search;brute-force search;depth-first search;heuristic;logic programming;natural deduction;prolog;requirement	Mark E. Stickel;Mabry Tyson	1985			beam search;discrete mathematics;breadth-first search;computer science;theoretical computer science;mathematics;algorithm	AI	10.08974343743444	17.014034163308516	66024
c2addeed7c7995f07acd65bcd3a8d74b9721743d	a branch-and-cut-and-price approach for the capacitated m-ring-star problem	ring star;integer programming;branch and cut and price;combinatorial optimization	The Capacitated m-ring-star Problem is a variant of the classical one-depot capacitated vehicle routing problem in which a customer is either on a route or is connected to another customer or to some Steiner point present in a route. We develop a new exact algorithm for this problem using a branch-and-cut-and-price approach and compare its performance with that of a branch-and-cut algorithm proposed earlier in the literature. Computational results show that the new algorithm outperforms the branch-and-cut one in many instance classes.	branch and cut;branch and price;bulk copy program;computation;exact algorithm;heuristic (computer science);preprocessor;speedup;steiner tree problem;vehicle routing problem	Edna Ayako Hoshino;Cid C. de Souza	2012	Discrete Applied Mathematics	10.1016/j.dam.2011.11.029	mathematical optimization;combinatorics;integer programming;combinatorial optimization;mathematics;algorithm	ML	22.505191517498897	8.05189514491073	66056
1fff5725c84756c74bceb4655337ac81cc50e9a0	single machine scheduling with a time-dependent learning effect and deteriorating jobs	minimisation;forecasting;minimization;time dependent;tiempo total acabamiento;reliability;completion time;learning effectiveness;project management;information systems;single machine scheduling;execution time;machine unique;maintenance;soft or;information technology;packing;temps total achevement;temps achevement;minimizacion;operations research;location;investment;journal;journal of the operational research society;processing time;inventory;purchasing;history of or;single machine;maquina unica;dependance du temps;makespan;logistics;time dependence;marketing;scheduling;production;communications technology;temps traitement;temps execution;deteriorating jobs;computer science;operational research;tiempo ejecucion;tiempo acabado;dependencia del tiempo;tiempo proceso;ordonnancement;applications of operational research;or society;reglamento;jors;learning effect;management science;infrastructure	The paper deals with the single machine scheduling problems with a time-dependent learning effect and deteriorating jobs. By the effects of time-dependent learning and deterioration, we mean that the processing time of a job is defined by function of its starting time and total normal processing time of jobs in front of it in the sequence. It is shown that even with the introduction of a time-dependent learning effect and deteriorating jobs to job processing times, the single machine makespan minimization problem remain polynomially solvable. But for the total completion time minimization problem, the classical shortest processing time first rule or largest processing time first rule cannot give an optimal solution.	job stream;scheduling (computing);single-machine scheduling	J.-B. Wang	2009	JORS	10.1057/palgrave.jors.2602607	project management;logistics;minimisation;simulation;inventory;economics;forecasting;investment;marketing;operations management;reliability;learning effect;location;operations research;information technology;scheduling;statistics	ECom	16.70867019729658	9.26218692229445	66360
89415a7628d115a46bf73912c273c4a56dd61cc3	heuristics for the minimum rectilinear steiner tree problem: new algorithms and a computational study	steiner problem;minimum rectilinear steiner tree problem;steiner trees;heuristics;steiner tree problem	De Souza, CC. and C.C. Ribeiro, Heuristics for the minimum rectilinear Steiner tree problem: new algorithms and a computational study, Discrete Applied Mathematics 45 (1993) 2055220. We propose in this paper new approximate algorithms for the minimum rectilinear Steiner tree problem, based on a two-point-connection strategy. We also present extensive computational experiments involving the new algorithms and several existing heuristics, more consistent than the other experiments reported in the literature. We conclude from these experiments that one of these new heuristics obtains slightly better solutions in the average when compared with the previously known heuristics.	approximation algorithm;computation;experiment;feature selection;first draft of a report on the edvac;heterogeneous system architecture;heuristic (computer science);inferring horizontal gene transfer;iteration;norm (social);rectilinear steiner tree;regular grid;steiner tree problem	Cid C. de Souza;Celso C. Ribeiro	1993	Discrete Applied Mathematics	10.1016/0166-218X(93)90010-L	mathematical optimization;combinatorics;discrete mathematics;steiner tree problem;mathematics;algorithm	AI	23.582424383198706	7.288257078231972	66410
77a6211387601a9ba50a3d75903a99e3ff0f4e92	a computational study of several heuristics for the drpp	optimal solution;cutting plane;lower bounds;exact solution;arc routing;postman problems;heuristics;connected component;lower bound;heuristic algorithm	The problem of designing a route of minimum length for a postman that starts and finishes at his office and has to deliver the mail along a set of streets in a city is known as the Rural Postman Problem. When the postman has to obey the directions of the streets, we have the directed version of this problem. Finding an exact solution, in the general case, is intractably difficult. Hence, we have implemented three heuristic algorithms for approximately solving this problem and a procedure for obtaining a lower bound to the optimal length. Also, we present numerical experimentations based on a collection of random instances with up to 30 connected components, 240 vertices and 801 arcs. A lower bound for the optimal DRPP value is obtained by using cutting plane techniques, producing an optimal solution in 21 out of 60 instances. The main purpose of this work is to compare these three algorithms. We also give guidelines concerning the performance of the algorithms depending on the characteristics of the problem to solve.	heuristic (computer science)	V. Campos;J. V. Savall	1995	Comp. Opt. and Appl.	10.1007/BF01299159	heuristic;mathematical optimization;combinatorics;connected component;heuristics;mathematics;upper and lower bounds;algorithm;cutting-plane method	Logic	22.95606656324191	7.232968068518883	66502
aa4f39c5a0420decbacbbf9b2daee7801afcd29e	a runtime-restricted strategy for highly parallel scheduling human resource in change management	bdim;change management;itil;change workflow runtime restricted strategy parallel scheduling human resource scheduling change management it management environment information technology runtime impact business impact heuristic based strategy human operator ordering individual skill mining change activity ordering critical path method business constraint workflow splitting regrouping;data mining;runtime;scheduling;human resource;management of change;runtime bdim itil change management human resource;dp management;scheduling data mining dp management human resource management management of change parallel processing;human resource management;parallel processing;humans runtime scheduling planning uncertainty processor scheduling	The uncertainty of change and low-utilization of human resource make change management more difficult to implement in today's competitive IT management environment. To fill this gap, in this paper a novel strategy is proposed for scheduling human resource to change activities concerning both runtime and business impact. Strategy is heuristic-based to obtain (1) ordering of human operators by mining potential individual skills, and (2) ordering of change activities based on improved critical path method, and then scheduling humans to activities with business constraints. Note that, before the activities are ordered, the splitting-regrouping of the complicated change workflow should be considered first by the concepts of computable dependency and cluster. The approach has been validated by a small but realistic case. Results showed that, compared to previous studies, our novel strategy is more suitable for highly parallel time-critical scenarios.	automated planning and scheduling;change management (engineering);computable function;critical path method;heuristic;online and offline;scheduling (computing);window of opportunity	Wei Dong;Zhiqiang Zhan;Xue-song Qiu	2012	2012 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2012.6249389	fair-share scheduling;information technology infrastructure library;resource allocation;computer science;knowledge management;change management;scheduling;human resource management system	AI	12.777787176127374	7.88124805917053	66526
5a15ebc1d79251a755a292d6f64789b92b4a7976	fixed-charge transportation on a path: linear programming formulations	institutional repositories;fedora;vital;extended formulation;transportation;lot sizing;mixed integer programming;vtls;convex hull;ils	The fixed-charge transportation problem is a fixed-charge network flow problem on a bipartite graph. This problem appears as a subproblem in many hard transportation problems, and is also both a special case and a strong relaxation of the challenging bigbucket multi-item lot-sizing problem. In this paper, we provide a polyhedral analysis of the polynomially solvable special case in which the associated bipartite graph is a path. We describe a new class of inequalities that we call ”path-modular” inequalities. We give two distinct proofs of their validity. The first one is direct and crucially relies on suband super-modularity of an associated set function, thereby providing an interesting link with flow-cover type inequalities. The second proof is by showing that the projection of an O(n)-size extended linear programming formulation onto the original variable space yields exactly the polyhedron described by the path-modular inequalities. Thus we also show that these inequalities suffice to describe the convex hull of the feasible solutions to this problem. We finally show how to solve the separation problem associated to the path-modular inequalities in O(n) time.	algorithm;combinatorial optimization;convex hull;decision problem;flow network;international symposium on fundamentals of computation theory;l.a. noire;linear programming formulation;linear programming relaxation;mathematical optimization;polyhedron;transportation theory (mathematics)	Mathieu Van Vyve	2011		10.1007/978-3-642-20807-2_33	transport;mathematical optimization;combinatorics;discrete mathematics;integer programming;convex hull;mathematics;algorithm	Theory	23.709263381072844	14.835508031237834	66698
682c16c5f3d5fb4bbfc76f0070f6a6df1576727b	optimization of resource location in hierarchical computer networks	hierarchical system;topology;programacion entera;concepcion sistema;aproximacion;reseau ordinateur;systeme hierarchise;topologie;programmation entiere;topologia;computer network;approximation;algorithme;algorithm;sistema jerarquizado;integer programming;system design;red ordenador;conception systeme;algoritmo	In the future, complex computer networks will be controlled and managed using hierarchical structures. We provide an integer pro~mming formulation of the problem, and present two approximate a~go~thms to solve it. One involves a simulated ann~ing-liner programing hybrid algorithm, and the other is a greedy second best heuristic. Computational results show that these approximate algorithms perform better than a Lagrangian relaxation of the problem.	approximation algorithm;computation;greedy algorithm;heuristic;hybrid algorithm;lagrangian relaxation;linear programming relaxation	Ashok Vernekar;G. Anandalingam;C. N. Dorny	1990	Computers & OR	10.1016/0305-0548(90)90016-Z	mathematical optimization;integer programming;lagrangian relaxation;computer science;artificial intelligence;approximation;mathematics;hierarchical control system;algorithm;systems design	ECom	20.70595908815182	7.812384748599562	66765
60bd41fff7381a37105f6a87a28c83668648ff25	a generic domain pruning technique for gdl-based dcop algorithms in cooperative multi-agent systems		Generalized Distributive Law (GDL) based message passing algorithms, such as Max-Sum and Bounded Max-Sum, are often used to solve distributed constraint optimization problems in cooperative multi-agent systems (MAS). However, scalability becomes a challenge when these algorithms have to deal with constraint functions with high arity or variables with a large domain size. In either case, the ensuing exponential growth of search space can make such algorithms computationally infeasible in practice. To address this issue, we develop a generic domain pruning technique that enables these algorithms to be effectively applied to larger and more complex problems. We theoretically prove that the pruned search space obtained by our approach does not affect the outcome of the algorithms. Moreover, our empirical evaluation illustrates a significant reduction of the search space, ranging from 33% to 81%, without affecting the solution quality of the algorithms, compared to the state-of-the-art.	algorithm;algorithmic efficiency;application domain;approximation algorithm;computation;computational complexity theory;constrained optimization;dcop;distributed constraint optimization;entropy maximization;expectation–maximization algorithm;generalized distributive law;mathematical optimization;message passing;multi-agent system;preprocessor;scalability;time complexity	Md. Mosaddek Khan;Long Tran-Thanh;Nicholas R. Jennings	2018			message passing;distributed computing;scalability;computer science;bounded function;ranging;algorithm;arity;generalized distributive law;multi-agent system;distributed constraint optimization	AI	22.236951216313862	4.513091726255006	66960
8603c2cc7dcb9056aa8560988972cc9a2ec7a32a	high-level modelling and reformulation of constraint satisfaction problems	lenguaje programacion;programacion entera;programming language;constraint satisfaction;programmation en nombres entiers;optimisation combinatoire;satisfaction contrainte;integer programming;langage programmation;constraint satisfaction problem;satisfaccion restriccion;combinatorial optimization;optimizacion combinatoria	 IntroductionThe modelling process of constraint satisfaction problems (CSPs) as constraintprograms requires sophisticated reasoning skills and involves crucial decisionson which variable and value representations to choose, on which constraint formulation to state, and on which solution methods to employ. Furthermore, thetight interaction between representation, constraint formulation, and solutionmethods adds another degree of complexity to the modelling task. For instance,the choice... 	constraint satisfaction problem	Brahim Hnich	2001		10.1007/3-540-45578-7_67	mathematical optimization;combinatorics;integer programming;constraint satisfaction;combinatorial optimization;computer science;mathematics;constraint satisfaction problem;algorithm	AI	19.84572654755823	8.025846065515905	67141
9fba922c459551a398808bff416f31898c2a318f	technical note - an improved combinatorial algorithm for the flowshop-scheduling problem	combinatorial algorithm;scheduling problem	This paper examines the combinatorial approach to the solution of the n-job, M-machine flowshop scheduling problem under the assumptions outlined by Dudek and Teuton [Opns. Res. 12, 471–497 (1964)] and proposes an improved combinatorial algorithm that, according to our computational experience, is more efficient than the Smith-Dudek algorithm [Opns. Res. 15, 71–82 (1967), and 17, 756 (1969)].	algorithm;combinatorial optimization;scheduling (computing)	Jatinder N. D. Gupta	1971	Operations Research	10.1287/opre.19.7.1753	job shop scheduling;mathematical optimization;combinatorics;mathematics;algorithm	Theory	19.295928417524426	10.928846792526613	67224
479ef673af4c5f774be8c7d22312f59631e99a99	interior-point methods: worst case and average case analysis of a phase-i algorithm and a termination procedure	interior point methods;interior point;simplex method;average case analysis;upper bound;probabilistic model;probabilistic analysis;polynomial time;linear programming;linear program;interior point method	We are interested in the average behavior of interior-point methods (IPMs) for linear programming problems (LPs). We use the rotation-symmetry-model as the probabilistic model for the average case analysis. This model had been used by Borgwardt in his average case analysis of the simplex-method. IPMs solve LPs in three phases. First, one has to find an appropriate starting point, then a sequence of interior points is generated, which converges to the optimal face. Finally, the optimum has to be calculated, as it is not an interior point. We present upper bounds on the average number of iterations in the first and the third phase by looking at random figures of the underlying polyhedron. These bounds show, that IPMs solve LPs in strongly polynomial time in the average case, so only the dimension parameters and not the encoding length of the problem determine the average behavior of IPMs.	algorithm;best, worst and average case	Petra Huhn;Karl Heinz Borgwardt	2002	J. Complexity	10.1006/jcom.2002.0640	mathematical optimization;combinatorics;algebraic interior;linear programming;interior point method;calculus;mathematics	Theory	23.67636312009196	14.875598143661172	67454
fac62a28423e495df5fb92df3a2437c675e1d759	a novel optimization of profile hmm by a hybrid genetic algorithm	modelizacion;algoritmo aleatorizado;modelo markov oculto;optimisation;alignement sequence;algoritmo busqueda;proteine;modelo markov;optimizacion;modele markov cache;hidden markov model;algorithme recherche;protein sequence;heuristic method;search algorithm;biologia molecular;programmation stochastique;metodo heuristico;intelligence artificielle;algorithme randomise;alineacion secuencia;algoritmo genetico;baum welch;busca local;modelisation;markov model;biomimetique;molecular biology;randomized algorithm;algorithme genetique;artificial intelligence;genetic algorithm;optimization;proteina;sequence alignment;multiple sequence alignment;methode heuristique;inteligencia artificial;modele markov;stochastic programming;protein;modeling;local search;programacion estocastica;recherche locale;heuristic algorithm;stochastic search;multiple alignment;hybrid genetic algorithm;biomimetics;biologie moleculaire	Profile Hidden Markov Models (Profile HMM) are well suited to modelling multiple alignment and are widely used in molecular biology. Usually, heuristic algorithms such as Baum-Welch are used to estimate the model parameters. However, Baum-Welch has a tendency to stagnate on local optima. A more involved approach is to use some form of stochastic search algorithm that ‘bumps' Baum-Welch off from local maxima. In this paper, a hybrid genetic algorithm is presented for training profile HMM (hybrid GA-HMM training) and producing multiple sequence alignment from groups of unaligned protein sequences. The quality of the alignments produced by hybrid GA-HMM training is compared to that by the other Profile HMM training methods. The experimental results prove very competitive with and even better than the other tested profile HMM training methods. Analysis of the behavior of the algorithm sheds light on possible improvement.	genetic algorithm;hidden markov model;mathematical optimization;memetic algorithm	Lifang Liu;Hongwei Huo;Bao-Shu Wang	2005		10.1007/11494669_90	multiple sequence alignment;computer science;artificial intelligence;machine learning;algorithm;hidden markov model	AI	20.8896741245982	6.014996036012115	67547
89e437f702fd1caefc5e9780311bd5494b12efed	production and distribution scheduling of supply chain structure using intelligent particle swarm optimisation algorithm	modelizacion;metodo adaptativo;distribution scheduling;evaluation performance;business to business;swarm intelligence;performance evaluation;intelligence en essaim;logistique;optimizacion pso;gestion production;relation client fournisseur;evaluacion prestacion;mercado internacional;intelligent pso;methode adaptative;pso;marche international;probabilistic approach;production management;production process;distributed scheduling;modelisation;logistics;international market;scm;scheduling;enfoque probabilista;approche probabiliste;particle swarm optimization;gestion produccion;adaptive method;processus fabrication;programacion produccion;probabilistic demand;optimisation pso;relacion cliente proveedor;production planning;algorithme evolutionniste;supply chain;algoritmo evolucionista;production scheduling;evolutionary algorithm;reseau neuronal;planification production;modeling;inteligencia de enjambre;particle swarm optimisation;red neuronal;empresa hacia empresa b2b;ordonnancement;supply chain management;proceso fabricacion;reglamento;neural network;logistica;entreprise a entreprise;supplier customer relationship	In today's global market, managing the entire Supply Chain (SC) becomes a key factor for the successful business and businesses have to be more adaptive to change. World class organisations now realise that non-integrated manufacturing processes, non-integrated distribution processes and poor relationship with suppliers and customers are inadequate for their success. Recently, however, there has been increasing attention placed on the performance, design and analysis of the SC as a whole. This paper specifically deals with the modelling and optimisation of a four-stage SC using the Particle Swarm Optimisation (PSO) algorithm and the problem was solved for optimal distribution of components and products made by them using PSO algorithm. And it was found that the PSO algorithm has been successfully applied to solve problems in SC network optimisation and gives quality results.	algorithm;mathematical optimization;particle swarm optimization;scheduling (computing)	Rajeshwar S. Kadadevaramath;K. M. Mohanasundaram;K. Rameshkumar;B. Chandrashekhar	2009	IJISTA	10.1504/IJISTA.2009.024262	supply chain management;simulation;computer science;engineering;scheduling;operations research	Robotics	19.233928370088794	5.7773297007033255	67647
d6a7d688390076cf211ac5aeb28e6eb586cf946c	esprit-project 2457-flexplan: integrated process planning and workshop scheduling	workshop scheduling;integrated process planning;esprit-project 2457-flexplan	Abstract The conventional approaches to PPC are being reconsidered with respect to the shift in production goals from maximum output at minimum cost to high flexibility, quality, reduced throughput-time and high schedule observance. On the level of workshop control the implementation of a generated schedule in the shop is impeded by unavoidable disruptions. Since process planning is usually performed a long time before manufacturing, the load situation and the availability machines in the shop is not taken into account. Investigations have shown that in many small and medium-sized metal-working companies, 20 to 30% of the total load has to be redirected to other resources and that only a small amount of workshop orders actually complies with the original short-term schedule. This situation can be improved significantly by using flexible process plans that comprise manufacturing alternatives. These flexible or non-linear process plans allow to reconsider the final manufacturing route only shortly before or during the workshop scheduling process, when the actual situation in the workshop is known. On the other hand it facilitates to reschedule orders to other manufacturing resources in case of unforeseen disruptions. This paper describes developments achieved within the ESPRIT Project 2457 FLEXPLAN. FLEXPLAN develops an integrated process planning and scheduling system based on ‘non-linear’ process plans (NLPPs). These process plans are represented as Petri nets that resemble a net of feasible operation sequences. The system comprises knowledge-based automatic process planning functions for a limited spectrum of workpieces, a graphical editor for non-linear process plans and an hierarchical workshop scheduling system that utilises the NLPPs to increase flexibility in the workshop. The workshop scheduling system comprises a load-oriented module for medium range scheduling, a finite scheduling module with graphical user interface and schedule evaluation functions. The optimisation algorithm used in the finite scheduling is based on a rule-based execution of petri-nets.	scheduling (computing)	Bernd C. Schmidt;Jochen Kreutzfeldt	1992			fair-share scheduling;simulation;flow shop scheduling;dynamic priority scheduling;engineering;operations management;two-level scheduling;scheduling;engineering drawing	Robotics	11.962317721990852	4.426478783792374	67804
f792937a354c9e789c623fed01f42b906a5fc9ff	probabilistic bounds on the performance of list scheduling	list;graph theory;test kolmogorov smirnov;statistique;teoria grafo;lista;algorithm analysis;g 2 1;gestion labor;approximation algorithms;f 2 2;probleme np complet;68c;kolmogorov smirnov test;kolmogorov smirnov statistics;05b;np complete problems;theorie graphe;makespan scheduling;68q;gestion tâche;repartition liste;statistics;liste;probabilistic algorithm analysis;list scheduling;problema np completo;analyse algorithme;task scheduling;analisis algoritmo;np complete problem;estadistica	The problem of scheduling tasks on m processors to minimize the schedule length (makespan) is NP-complete. Here we study the behavior of list schedules under the assumptions that there are no task precedence constraints and that task times are chosen from a uniform distribution.We show that, given a desired degree of confidence $1 - \varepsilon $, we can find a minimum sample size N such that if $n \geqq N$ and the n task times $\bar X = (X_1 , \cdots ,X_n )$ are chosen from any uniform distribution, then \[ {\bf P}\left[ {\frac{{L(\bar X)}}{{{\operatorname{OPT}}(\bar X)}}   1 - \varepsilon \] where $L(\bar X)$ is the length of any list schedule and ${\operatorname{OPT}}(\bar X)$ is the length of the optimal schedule. Thus for n sufficiently large, the performance of any list schedule can be made arbitrarily close to that of the optimal policy with any desired degree of confidence. For example, for $m = 2$ and $\varepsilon = 0.01$, the ratio is bounded by 1.11 when $n =...	list scheduling;schedule (project management)	John L. Bruno;Peter J. Downey	1986	SIAM J. Comput.	10.1137/0215028	mathematical optimization;combinatorics;np-complete;computer science;graph theory;mathematics;approximation algorithm;algorithm;statistics	Theory	15.949653017419742	12.483044743548286	67841
26385749054955441cb28d31ee89f579910b7059	the steiner tree problem with hop constraints	network measurement;mathematical programming;steiner tree problem;telecommunication networks	The Steiner tree problem in graphs is to determine a minimum cost subgraph of a given graph spanning a set of specified vertices. In certain telecommunication networks, additional constraints such as, e.g., reliability constraints, have to be observed. Assume that a certain reliability is associated with each arc of the network, measuring the probability that the respective arc is operational. In case there has to be a guarantee that each message sent from a root vertex to a specified vertex reaches its destination with a certain probability, so-called hop constraints may be used to model the respective generalization. In this paper, we discuss the Steiner tree problem with hop constraints, i.e., a generalization of Steiner’s problem in graphs where the number of arcs (hops) between a root node and any of the specified vertices is limited. A mathematical programming formulation is provided and extended to handle problem instances of moderate size. As the Steiner tree problem with hop constraints is NPhard, a simple heuristic is developed and an exchange procedure based on the tabu search metastrategy is applied to improve given solutions. Numerical results are discussed for a number of problem instances derived from, e.g., well-known benchmark instances of Steiner’s problem in graphs.	algorithm;benchmark (computing);bridging (networking);dynamic programming;file spanning;graph (discrete mathematics);heuristic;heuristic (computer science);mathematical optimization;network planning and design;numerical method;reachability;recursion;smoothed-particle hydrodynamics;steiner tree problem;tabu search;tree (data structure);vertex (geometry)	S. Voß	1999	Annals OR	10.1023/A:1018967121276	mathematical optimization;combinatorics;discrete mathematics;steiner tree problem;mathematics	Theory	23.19298867304131	17.49304594267999	68020
a3c58a5a4dc392463bcf52780504bdae60c0850f	a comparison of solution procedures for two-machine flow shop scheduling with late work criterion	dynamic programming;tecnologia industrial tecnologia mecanica;computacion informatica;flow shop scheduling;dynamic program;enumerative method;late work;computer experiment;ciencias basicas y experimentales;common due date;list scheduling;tecnologias;grupo a;flow shop	In this paper we analyze different solution procedures for the two-machine flow shop scheduling problem with a common due date and weighted late work criterion, i.e. for problem F2jdj ZdjYw , which is known to be binary NP-hard. In computational experiments we compare the practical efficiency of a dynamic programming approach, an enumerative method and a heuristic list scheduling procedure. Test results show that each solution method has its advantages and none of them can be rejected from consideration a priori. q 2005 Elsevier Ltd. All rights reserved.	computation;dynamic programming;experiment;flow shop scheduling;heuristic;list scheduling;np-hardness;scheduling (computing)	Jacek Blazewicz;Erwin Pesch;Malgorzata Sterna;Frank Werner	2005	Computers & Industrial Engineering	10.1016/j.cie.2005.09.001	fair-share scheduling;job shop scheduling;mathematical optimization;flow shop scheduling;computer science;operations management;mathematics;algorithm	AI	16.41819256524937	8.297798538294233	68089
7ab72a14e39af54ddb4d683e58310c05572e3c3f	approximate circle packing in a rectangular container: integer programming formulations and valid inequalities		A problem of packing a limited number of unequal circles in a fixed size rectangular container is considered. The aim is to maximize the (weighted) number of circles placed into the container or minimize the waste. Frequently, the problem is formulated as a nonconvex continuous optimization problem which is solved by heuristic techniques combined with local search procedures. A new formulation is proposed using a regular grid approximating the container and considering the nodes of the grid as potential positions for assigning centers of the circles. The packing problem is then stated as a large scale linear 0-1 optimization problem. The binary variables represent the assignment of centers to the nodes of the grid. The resulting binary problem is then solved by commercial software. Two families of valid inequalities are proposed to strengthen the formulation. Numerical results are presented to demonstrate the efficiency of the proposed approach.	approximation algorithm;commercial software;continuous optimization;heuristic;integer programming;lagrangian relaxation;linear programming relaxation;local search (optimization);mathematical optimization;numerical method;optimization problem;regular grid;set packing;turing completeness	Igor S. Litvinchev;Luis Infante;Edith Lucero Ozuna Espinosa	2014		10.1007/978-3-319-11421-7_4	mathematical optimization	Robotics	23.25770515822243	6.539802616351827	68102
a5572a9fe7adedca1340282a5ab3ceeb9ccfd659	on finding the exact solution of a zero-one knapsack problem	optimal solution;exact solution;digital disk;polynomial time algorithm;algorithm;knapsack problem;digital region;probability distribution;random variable;upper and lower bounds;compactness;digital convexity	Given a 0-1 knapsack problem with input drawn from a certain probability distribution, we show that for every ε > 0, there is a self-checking polynomial-time algorithm that finds an optimal solution with probability at least 1 -ε. We also prove some upper and lower bounds on random variables related to the problem.	algorithm;knapsack problem;polynomial;time complexity	Andrew V. Goldberg;Alberto Marchetti-Spaccamela	1984		10.1145/800057.808701	probability distribution;continuous knapsack problem;random variable;mathematical optimization;combinatorics;discrete mathematics;cutting stock problem;change-making problem;mathematics;compact space;upper and lower bounds;knapsack problem;statistics	Theory	20.324503482926964	13.61243956834947	68449
d192fce0b32ecd43d96474ed6b4e17d9af6a697f	two ant-colony algorithms for minimizing total flowtime in permutation flowshops	tecnologia industrial tecnologia mecanica;computacion informatica;ant algorithm;soft computing;benchmark problem;flowshop;operations research;ant colony algorithm;ciencias basicas y experimentales;scheduling;scheduling problem;total flowtime;tecnologias;grupo a	The problem of scheduling in flowshops with the objective of minimizing total flowtime is studied. For solving the problem two ant-colony algorithms are proposed and analyzed. The first algorithm refers to some extent to ideas by Stuetzle [Stuetzle, T. (1998). An ant approach for the flow shop problem. In: Proceedings of the sixth European Congress on intelligent techniques and soft computing (EUFIT '98) (Vol. 3) (pp. 1560-1564). Aachen: Verlag Mainz] and Merkle and Middendorf [Merkle, D., & Middendorf, M. (2000). An ant algorithm with a new pheromone evaluation rule for total tardiness problems. In: Proceedings of the EvoWorkshops 2000, lecture notes in computer science 1803 (pp. 287-296). Berlin: Springer]. The second algorithm is newly developed. The proposed ant-colony algorithms have been applied to 90 benchmark problems taken from Taillard [Taillard, E. (1993). Benchmarks for basic scheduling problems. European Journal of Operational Research, 64, 278-285]. A comparison of the solutions yielded by the ant-colony algorithms with the best heuristic solutions known for the benchmark problems up to now, as published in extensive studies by Liu and Reeves [Liu, J., & Reeves, C.R. (2001). Constructive and composite heuristic solutions to the P//ΣCi scheduling problem. European Journal of Operational Research, 132,439-452, and Rajendran and Ziegler [Rajendran, C., & Ziegler, H. (2004). Ant-colony algorithms for permutation flowshop scheduling to minimize makespan/total flowtime of jobs. European Journal of Operational Research, 155, 426-438], shows that the presented ant-colony algorithms are better, on an average, than the heuristics analyzed by Liu and Reeves and Rajendran and Ziegler.	algorithm	Chandrasekharan Rajendran;Hans Ziegler	2005	Computers & Industrial Engineering	10.1016/j.cie.2004.12.009	job shop scheduling;mathematical optimization;ant colony optimization algorithms;computer science;artificial intelligence;operations management;soft computing;operations research;scheduling	Theory	16.94464255080636	7.860396959371861	68543
d0c12a28e7f5704ba6dc0115b455b5bcd5858304	test scheduling for core-based socs using genetic algorithm based heuristic approach	bin packing;test access mechanism;wrapper design;soc testing;genetic algorithm;test scheduling	This paper presents a Genetic algorithm (GA) based solution to co-optimize test scheduling and wrapper design for core based SOCs. Core testing solutions are generated as a set of wrapper configurations, represented as rectangles with width equal to the number of TAM (Test Access Mechanism) channels and height equal to the corresponding testing time. A locally optimal best-fit heuristic based bin packing algorithm has been used to determine placement of rectangles minimizing the overall test times, whereas, GA has been utilized to generate the sequence of rectangles to be considered for placement. Experimental result on ITC'02 benchmark SOCs shows that the proposed method provides better solutions compared to the recent works reported in the literature.		Chandan Giri;Soumojit Sarkar;Santanu Chattopadhyay	2007		10.1007/978-3-540-74205-0_107	bin packing problem;real-time computing;genetic algorithm;computer science;artificial intelligence;machine learning;algorithm	Robotics	20.04364831368057	4.349966548484308	68663
8c63984dee0d6eab6f5563f2e5b6a911033306ef	3-sat in rtime(o(1.32793n)) - improving randomized local search by initializing strings of 3-clauses	local search	This paper establishes a randomized algorithm that finds a satisfying assignment for a satisfiable formula F in 3-CNF in O(1.32793n) expected running time. The algorithms is based on the analysis of socalled strings, which are sequences of 3-clauses where non-succeeding clauses do not share a variable and succeeding clauses share one or two variables. One the one hand, if there are not many independent strings, we can solve F with a decent success probability, but on the other hand, if there are many strings, we use them to improve the running time of Schöning’s 3-SAT algorithm. Within a string, propagation of unit clauses is used to find successors.	boolean satisfiability problem;conjunctive normal form;local search (optimization);randomized algorithm;software propagation;time complexity	Daniel Rolf	2003	Electronic Colloquium on Computational Complexity (ECCC)			Theory	10.75169488829043	17.7986841672437	68794
af42ad1d18e235231636757cf8aba118a4984048	a 5/4-approximation algorithm for scheduling identical malleable tasks	constant factor;phase-by-phase schedule;minimal completion time;optimal schedule;execution time exponential;4-approximation algorithm;p identical processor;constant time;approximation algorithm;n-independent identical malleable task;execution time decrease	  We consider the problem of finding a schedule for n identical malleable tasks on p identical processors with minimal completion time. This problem arises while using the branch & bound or the divide & conquer  strategy to solve a problem on a parallel system. If nothing is known about the sub-problems, then they are assumed to be  identical. We assume that the execution time decreases with the number of processors while the computational work increases.  We give an algorithm with running time exponential in p which computes an optimal schedule. In order to approximate an optimal schedule, we use the concept of phase-by-phase schedules.  Here schedules consist of phases in which every job uses the same number of processors. We prove that one can approximate  an optimal schedule up to a factor       \frac54\frac{5}{4} using constant time, and we show that this is optimal. Furthermore, we give an ε-approximation algorithm if the speed-up is optimal up to a constant factor.    	algorithm	Thomas Decker;Thomas Lücking;Burkhard Monien	2003		10.1007/978-3-540-24592-6_8	mathematical optimization;divide and conquer algorithms;completion;numero sign;completeness;computer science;mathematics;distributed computing;time constant;scheduling;schedule;grammatical number;branch and bound;approximation algorithm;algorithm	Embedded	16.245435781928542	10.827771661930521	68861
e5ec28df25e7d678ad8a68ec33ccbb7b52759155	a decomposition algorithm for local access telecommunications network expansion planning	dynamic programming;networks graphs;programacion dinamica;routing;structure arborescente;algorithms expanding local access telephone networks;telecommunication network;algorithme;algorithm;integer;hd28 m414 no 3496 92;planificacion;estructura arborescente;decomposition algorithm;red telecomunicacion;tree structure;programmation dynamique;reseau telecommunication;planning;communications integer programming for local access expansion;encaminamiento;planification;92;programming;applications capacity expansion of local access telephone systems;telecommunication networks;hd28 m414 no 3496;acheminement;expansion;algoritmo	Growing demand, increasing diversity of services, and advances in transmission and switching technologies are prompting telecommunication companies to rapidly expand and modernize their networks. This paper develops and tests a decomposition methodology to generate cost-effective expansion plans, with performance guarantees, for one major component of the network hierarchy-the local access network connecting customers to the local switching center. The model captures economies of scale in facility costs, and addresses the central tradeoff between installing concentrators and expanding cables to accommodate demand growth. By exploiting the special tree and routing structure of the expansion planning problem, our solution method integrates two major algorithmic strategies from mathematical programming-the use of valid inequalities, obtained by studying a problem's polyhedral structure, and dynamic programming, which can be used to solve an uncapacitated version of the local access network expansion planning problem. The computational results for three actual test networks demonstrate that this enhanced dynamic programming algorithm, when embedded in a Lagrangian relaxation scheme (with problem preprocessing and local improvement), is very effective in generating good upper and lower bounds: implemented on a personal computer, the method was able to generate solutions that are within 1.2 to 7.0% of optimality. In addition to developing a successful solution methodology for a practical problem, this paper illustrates the possibility of effectively combining decomposition methods and polyhedral approaches.	access network;algorithm;computation;dynamic programming;embedded system;lagrangian relaxation;linear programming relaxation;mathematical optimization;personal computer;polyhedron;preprocessor;routing;telecommunications network;telephone exchange	Anantaram Balakrishnan;Thomas L. Magnanti;Richard T. Wong	1995	Operations Research	10.1287/opre.43.1.58	integer;planning;programming;mathematical optimization;routing;simulation;computer science;operations management;dynamic programming;mathematics;tree structure;management;algorithm;telecommunications network	AI	21.242375523435957	11.98023035373747	68884
9b947da7ffbe2a85ba6fd9977b53ef892744dd1a	online bin covering: expectations vs. guarantees	bin covering;performance measures;competitive analysis;online algorithms	Bin covering is a dual version of classic bin packing. Thus, the goal is to cover as many bins as possible, where covering a bin means packing items of total size at least one in the bin. For online bin covering, competitive analysis fails to distinguish between most algorithms of interest; all “reasonable” algorithms have a competitive ratio of 1 2 . Thus, in order to get a better understanding of the combinatorial difficulties in solving this problem, we turn to other performance measures, namely relative worst order, random order, and max/max analysis, as well as analyzing input with restricted or uniformly distributed item sizes. In this way, our study also supplements the ongoing systematic studies of the relative strengths of various performance measures. Two classic algorithms for online bin packing that have natural dual versions are Harmonick and Next-Fit. Even though the algorithms are quite different in nature, the dual versions are not separated by competitive analysis. We make the case that when guarantees are needed, even under restricted input sequences, dual Harmonick is preferable. In addition, we establish quite robust theoretical results showing that if items come from a uniform distribution or even if just the ordering of items is uniformly random, then dual Next-Fit is the right choice. ∗A preliminary version of this paper appeared in the proceedings of the Seventh Annual International Conference on Combinatorial Optimization and Applications, 2013. Supported in part by the Danish Council for Independent Research and the Villum Foundation.	algorithm;bin packing problem;combinatorial optimization;competitive analysis (online algorithm);set packing	Marie G. Christ;Lene M. Favrholdt;Kim S. Larsen	2014	Theor. Comput. Sci.	10.1016/j.tcs.2014.06.029	competitive analysis;online algorithm;mathematical optimization;combinatorics;bin packing problem;computer science;mathematics;algorithm	Theory	16.7228691916515	16.208678358636366	68898
0f96909088aa81e8f6f1392c7f1dc64eb87fb727	algorithm based on simulated annealing for land-use allocation	computadora;tratamiento datos;computers;iberian peninsula;europa;europa sur;distribucion espacial;optimisation;mapa utilizacion suelo;optimizacion;ordinateur;espana;europe sud;carte occupation sol;data processing;traitement donnee;simulated annealing;land cover maps;peninsule iberique;algorithme;objective function;peninsula iberica;land use;ideal point analysis;spatial distribution;galicia;hierarchical optimization;algorithms;carte utilisation terrain;optimization;espagne;distribution spatiale;europe;southern europe;mola;land uses;galice;utilisation terrain;galicia spain;multicriterion land allocation;land use map;utilizacion terreno;algoritmo;spain	This article describes the use of simulated annealing for allocation of land units to a set of possible uses on, the basis of their suitability for those uses, and the compactness of the total areas allotted to the same use or kind of use, which are fixed a priori. The results obtained for the Terra Cha district of Galicia (N.W. Spain) using different objective weighting schemes are compared with each other and with those obtained for this district under the same area constraints, using hierarchical optimization, ideal point analysis, and multi-objective land allocation (MOLA) to maximize average use suitability. Inclusion of compactness in the simulated annealing objective function avoids the highly disperse allocations typical of optimizations that ignore this sub-objective.	algorithm;simulated annealing	Inés Santé-Riveira;Marcos Boullón-Magán;Rafael Crecente-Maseda;David Miranda-Barrós	2008	Computers & Geosciences	10.1016/j.cageo.2007.03.014	land use;data processing;computer science	Robotics	18.663494894198397	5.11640638513172	68914
90811ceaef7fcdabe8f5c7aa3214306b6c08e43c	resource-dependent scheduling with deteriorating jobs and learning effects on unrelated parallel machine	resource allocation;scheduling;deteriorating jobs;parallel machine;learning effect	The focus of this paper is to analyze unrelated parallel-machine resource allocation scheduling problem with learning effect and deteriorating jobs. The goal is to find the optimal sequence of jobs and the optimal resource allocation separately for minimizing the cost function including the total load, the total completion time, the total absolute deviation of completion time and the total resource cost. We show that the problem is polynomial time solvable if the number of machines is a given constant.	decision problem;job stream;loss function;optimization problem;parallel computing;polynomial;scheduling (computing);time complexity	Yuan-Yuan Lu;Jian Jin;Ping Ji;Ji-Bo Wang	2015	Neural Computing and Applications	10.1007/s00521-015-1993-x	mathematical optimization;real-time computing;resource allocation;computer science;operating system;learning effect;scheduling	Theory	15.53851525320171	10.00406024673389	69033
27bddc00ec405e8ea4aa43663a5a727758696189	a technique for speeding up the solution of the lagrangian dual	traveling salesman problem;lagrangien;multicommodity flow;optimal solution;location problem;probleme localisation;temps polynomial;probleme livraison;equipement collectif;solutions general;routing;vehicle routing problem;travelling salesman problem;combinatorial optimization problem;probleme arbre steiner;programmation stochastique;reseau;polynomials;acceleration;red;relajacion;algorithme;optimisation combinatoire;problema viajante comercio;equipamiento colectivo;algorithm;lagrangean relaxation;programacion lineal;tamano lote;91;probleme commis voyageur;taille lot;hd28 m414 no 3278;polynomial algorithm;facility;polynomial time;linear programming relaxation;dispatching problem;hd28 m414 no 3278 91;linear programming;programmation lineaire;lot sizing;facility location problem;algorithms;relaxation;lagrangiano;optimization;encaminamiento;problema localizacion;steiner tree problem;network flow;combinatorial optimization;stochastic programming;lp relaxation;lagrangian;programacion estocastica;lagrangian functions;flot reseau;problema reparto;problem solving;network;acheminement;combinatorial analysis;optimizacion combinatoria;algoritmo;tiempo polinomial	We propose new techniques for the solution of the LP relaxation and the Lagrangean dual in combinatorial optimization problems. Our techniques find the optimal solution value and the optimal dual multipliers of the LP relaxation and the Lagrangean dual in polynomial time using as a subroutine either the Ellipsoid algorithm or the recent algorithm of Vaidya. Moreover, in problems of a certain structure our techniques find not only the optimal solution value, but the solution as well. Our techniques lead to significant improvements in running time compared with previously known methods (interior point methods, Ellipsoid algorithm, Vaidya's algorithm). We apply our method to the solution of the LP relaxation and the Lagrangean dual of several classical combinatorial problems, like the traveling salesman problem, the vehicle routing problem, the Steiner tree problem, the k-connected problem, multicommodity flows, network design problems, network flow problems with side constraints, facility location problems, K-polymatroid intersection, multiple item capacitated lot sizing problem, etc. In all these applications our techniques significantly improve the running time and yield the fastest way to solve them.	algorithm;combinatorial optimization;duality (optimization);ellipsoid method;fastest;flow network;interior point method;lagrange multiplier;lagrangian relaxation;linear programming relaxation;mathematical optimization;network planning and design;polymatroid;polynomial;steiner tree problem;subroutine;time complexity;travelling salesman problem;vehicle routing problem	Dimitris Bertsimas;James B. Orlin	1992	Math. Program.	10.1007/BF01582057	mathematical optimization;combinatorics;covering problems;combinatorial optimization;linear programming;linear programming relaxation;vehicle routing problem;calculus;mathematics;travelling salesman problem	Theory	22.05667164033917	12.025861767746074	69127
5bcad16efe4a3c5cc4a7a2922bd7a751e9ab41f5	receding horizon control for airport capacity management	predictive control air traffic control airports planning;file attente;airports traffic control air traffic control weather forecasting delay vehicle dynamics aerodynamics environmental management capacity planning robustness;predictive control;optimisation;air traffic control;capacite production;capacity management;optimizacion;receding horizon control rhc;trafico aereo;real time;gestion trafic;airports;adjustment;queue;airport capacity management;receding horizon control rhc airport capacity management acm delay optimization queue;traffic management;reglage;receding horizon control;airport;dynamic environment;systeme incertain;commande ecoulement;airport capacity management real time allocation real time planning air traffic management receding horizon control;robustesse;temps reel;flot commande;control flow;real time planning;gestion trafico;tiempo real;robustness;planning;optimization;horizon fuyant;capacidad produccion;trafic aerien;flujo control;reglaje;aeropuerto;flow control;airport capacity management acm;sistema incierto;computational efficiency;real time allocation;open ended horizon;article;fila espera;uncertain system;air traffic;production capacity;horizonte huidizo;aeroport;robustez;air traffic management	A major goal of air traffic management is to strategically control the flow of traffic so that the demand at an airport meets but does not exceed the operational capacity in a dynamic environment. This paper uses the concept of receding horizon control (RHC) to conduct real-time planning for airport capacity management (ACM). It is shown that RHC provides a generic and flexible framework for developing real-time allocation algorithms for airport capacity in a dynamic and uncertain environment, and existing approaches such as the one step ahead adjustment can be considered as special cases of this approach. Robustness against the change of the environment and demands and computational efficiency are two advantages when applying RHC to the ACM problem, which are illustrated by a case study.	algorithm;computation;memory management;network congestion;real-time clock;real-time transcription;recueil des historiens des croisades	Wen-Hua Chen;Xiao-Bing Hu	2007	IEEE Transactions on Control Systems Technology	10.1109/TCST.2006.890295	simulation;computer science;engineering;air traffic control;operations research	Embedded	16.458512073273006	5.702153232714856	69160
8a1984704cb4747df1c31ae42e929e7161c32684	proactive vehicular traffic rerouting for lower travel time	graph theory;road traffic;vehicular congestion avoidance;vehicles roads heuristic algorithms vehicle dynamics real time systems digital signal processing computational modeling;vehicular networks proactive driver guidance traffic load balancing vehicularcongestion avoidance;traffic engineering computing graph theory random processes road traffic;proactive driver guidance;proactive vehicular traffic rerouting dta algorithm dynamic traffic assignment flow balanced ksp ebksp entropy balanced ksp random k shortest path shortest path with repulsion dynamic shortest path vehicular traffic guidance system fuel consumption traffic congestion travel time;random processes;traffic engineering computing;traffic load balancing;vehicular networks	Traffic congestion causes driver frustration and costs billions of dollars annually in lost time and fuel consumption. This paper presents five traffic rerouting strategies designed to be incorporated in a cost-effective and easily deployable vehicular traffic guidance system that reduces travel time. The proposed strategies proactively compute individually tailored rerouting guidance to be pushed to vehicles when signs of congestion are observed on their route. The five proposed strategies are the dynamic shortest path (DSP), the A* shortest path with repulsion (AR*), the random k shortest path (RkSP), the entropy-balanced kSP (EBkSP), and the flow-balanced kSP (FBkSP). Extensive simulation results show that the proposed strategies are capable of reducing the travel time as much as a state-of-the-art dynamic traffic assignment (DTA) algorithm while avoiding the issues that make DTA impractical, such as the lack of scalability and robustness, and high computation time. Furthermore, the variety of proposed strategies allows tuning the system to different levels of tradeoffs between rerouting effectiveness and computational efficiency. In addition, the proposed traffic guidance system can significantly improve the traffic even if many drivers ignore the guidance or if the system adoption rate is relatively low.	a* search algorithm;computation;digital television adapter;guidance system;network congestion;proactive parallel suite;scalability;shortest path problem;simulation;time complexity;traffic exchange	Susan Juan Pan;Iulian Sandu Popa;Karine Zeitouni;Cristian Borcea	2013	IEEE Transactions on Vehicular Technology	10.1109/TVT.2013.2260422	vehicular ad hoc network;simulation;floating car data;engineering;graph theory;traffic congestion reconstruction with kerner's three-phase theory;traffic flow;mathematics;transport engineering;traffic bottleneck;statistics;computer network;traffic optimization	Mobile	12.507011063851163	13.93715632567133	69702
a4c5220847f64d203094e68aa7c2cbc5d863cce2	extended ant colony optimization for non-convex mixed integer nonlinear programming	optimisation sous contrainte;constrained optimization;swarm intelligence;non convex programming;programacion entera;ant colony optimization;intelligence en essaim;hybrid metaheuristics;convex programming;articulo;benchmark problem;heuristic method;oracle penaltymethod;metodo penalidad;optimum global;metodo heuristico;programmation non convexe;programmation convexe;global optimum;programmation en nombres entiers;oracle penalty method;optimizacion con restriccion;programacion no convexa;penalty method;methode penalite;real world application;metamodel;programacion mixta entera;metamodele;integer programming;metamodelo;analyse non convexe;programmation partiellement en nombres entiers;mixed integer programming;global optimization;minlp;methode heuristique;mixed integer nonlinear programming;non convex analysis;inteligencia de enjambre;optimo global;oracle;analisis no convexo;programacion convexa	Two novel extensions for the well known Ant Colony Optimization (ACO) framework are introduced here, which allow the solution of Mixed Integer Nonlinear Programs (MINLP). Furthermore, a hybrid implementation (ACOmi) based on this extended ACO framework, specially developed for complex non-convex MINLPs, is presented together with numerical results. These extensions on the ACO framework have been developed to serve the needs of practitioners who face highly non-convex and computationally costly MINLPs. The performance of this new method is evaluated considering several non-convex MINLP benchmark problems and one real-world application. The results obtained by our implementation substantiate the success of this new approach.	ant colony optimization algorithms;benchmark (computing);convex function;engineering design process;mathematical optimization;metaheuristic;micro instrumentation and telemetry systems;nonlinear programming;nonlinear system;numerical analysis;numerical method;penalty method;solver;whole earth 'lectronic link	Martin Schlüter;Jose A. Egea;Julio R. Banga	2009	Computers & OR	10.1016/j.cor.2008.08.015	oracle;metamodeling;mathematical optimization;combinatorics;ant colony optimization algorithms;integer programming;penalty method;mathematics;global optimum;algorithm	AI	24.587402004676555	9.060990327068808	69775
f3eee209e26c7553f53084b05f80c2c5c9abd900	dca for minimizing the cost and tardiness of preventive maintenance tasks under real-time allocation constraint	preventive maintenance;real time;maintenance cost;release date;flow time;convex function;dc programming;dca;mixed integer linear problem;tardiness	In this paper, we introduce a new approach based on DC (Difference of Convex functions) Programming and DCA (DC Algorithm) for minimizing the maintenance cost involving flow-time and tardiness penalties. The main idea is to divide the horizon considered into H intervals and the problem is first formulated as a mixed integer linear problem (MILP). It is afterward reformulated in the form of a DC program by an exact penalty technique. Solution method based on DCA is investigated to solve the resulting problem. The efficiency of DCA is compared with the algorithm based on the new flow-time and tardiness rule (FTR) given in [8]. The computational results on several test problems show that the solutions provided by DCA are better.	real-time transcription	Tran Duc Quynh;Le Thi Hoai An;Kondo Hloindo Adjallah	2010		10.1007/978-3-642-12101-2_42	convex function;preventive maintenance;mathematical optimization;real-time computing;computer science	AI	14.884153981301873	6.917704423007978	69781
b62266806f2113a0db93d29f1b55123e7d7f70a6	petri net representation for 0-1 integer programming problems	optimal firing sequence problem;traveling salesman problem;vehicle routing problems petri net representation 0 1 integer programming problem discrete event systems final marking initial marking optimal firing sequence problem optimal transition sequence objective function minimization petri net theory traveling salesman problem;0 1 integer programming problem;vehicle routing problems;vehicle routing problems discrete event systems petri nets 0 1 integer programming problem optimal firing sequence problem traveling salesman problem;linear programming firing vehicles vehicle routing traveling salesman problems optimization fires;discrete event systems;petri nets;vehicle routing integer programming petri nets sequences travelling salesman problems	Petri net is a mathematical modeling tool that represents wide variety of discrete event systems. Given an initial marking and final marking for a Petri net, an optimal firing sequence problem is defined as the problem to And an optimal transition sequence to minimize the objective function. For the purpose of analysis of 0-1 integer programming problems, we propose a general algorithm to convert general 0-1 integer programming problem into an optimal firing sequence problem of Petri net. By utilizing the proposed algorithm, general 0-1 integer programming problems can be visualized and analyzed by Petri net theory. The property of solutions derived by solving the original 0-1 integer programming and the optimal firing sequence problem is discussed. The solution of 0-1 integer programming problem and that of the optimal firing sequence problem of Petri net are compared. The results show that the solutions for both problems are identical for traveling salesman problem and vehicle routing problems.	algorithm;integer programming;item unique identification;linear programming;loss function;mathematical model;optimization problem;petri net;travelling salesman problem;vehicle routing problem	Akito Kodama;Tatsushi Nishi	2014	2014 IEEE International Conference on Industrial Engineering and Engineering Management	10.1109/IEEM.2014.7058734	2-opt;mathematical optimization;combinatorics;discrete mathematics;integer programming;stochastic petri net;covering problems;computer science;cutting stock problem;vehicle routing problem;mathematics;travelling salesman problem;petri net;bottleneck traveling salesman problem	Robotics	16.602229779592943	6.488710703512993	69782
1f23b28f9b41c735b5ccb3600b0e2d83846aed3a	the bilinear assignment problem: complexity and polynomially solvable special cases		In this paper we study the bilinear assignment problem (BAP) with size parameters m and n, \(m\le n\). BAP is a generalization of the well known quadratic assignment problem and the three dimensional assignment problem and hence NP-hard. We show that BAP cannot be approximated within a constant factor unless P = NP even if the associated quadratic cost matrix Q is diagonal. Further, we show that BAP remains NP-hard if \(m = O(\root r \of {n})\), for some fixed r, but is solvable in polynomial time if \(m = O\left( \frac{\log n}{\log \log n}\right) \). When the rank of Q is fixed, BAP is observed to admit FPTAS and when this rank is one, it is solvable in polynomial time under some additional restrictions. We then provide a necessary and sufficient condition for BAP to be equivalent to two linear assignment problems. A closed form expression to compute the average of the objective function values of all solutions is presented, whereas the median of the solution values cannot be identified in polynomial time, unless P = NP. We then provide polynomial time heuristic algorithms that find a solution with objective function value no worse than that of \((m-1)!(n-1)!\) solutions. However, computing a solution whose objective function value is no worse than that of \(m!n!-\lceil \frac{m}{\beta }\rceil !\lceil \frac{n}{\beta }\rceil !\) solutions is NP-hard for any fixed rational number \(\beta >1\).	assignment problem;bilinear filtering;decision problem	Ante Custic;Vladyslav Sokol;Abraham P. Punnen;Binay K. Bhattacharya	2017	Math. Program.	10.1007/s10107-017-1111-1	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	22.545124382676242	15.104017944783372	69852
9760c64f9fc020694918f520f1b3a5b62486ce43	optimization models of discrete-event system dynamics	sistema fila espera;modelo dinamico;modelizacion;systeme attente;programacion discreta;optimisation;queueing network;systeme evenement discret;programacion entera;simulation methodology;optimizacion;event graph;system dynamics;generacion automatica;teoria sistema;simulation;dynamic model;gradiente;grupo de excelencia;programmation stochastique;gradient;red cola espera;programmation en nombres entiers;automatic generation;dynamical system;sistema acontecimiento discreto;modelisation;systeme dynamique;discrete event system;generation automatique;programacion mixta entera;programmation discrete;integer programming;systems theory;reseau file attente;ciencias basicas y experimentales;algebre max plus;scheduling;theorie systeme;matematicas;modele dynamique;queueing system;graphe evenement;programmation partiellement en nombres entiers;algebra max plus;mixed integer programming;optimization;grafo aconticimiento;max plus algebra;sistema dinamico;methodology;grupo a;stochastic programming;modeling;programacion estocastica;ordonnancement;optimization model;reglamento;discrete programming	A methodology is given for modeling the dynamics of discrete-event stochastic systems as optimization problems. The intent is to provide a means to utilize the rich mathematical theory and algorithms of optimization in the study of this important class of systems. A procedure for mapping a simulation event relationship graph into a mixed-integer program is presented, along with examples of queueing networks and manufacturing systems that illustrate the approach. Several potential applications are examined, including automatic constraint generation for optimal resource scheduling, representations of max-plus algebra models for queueing system dynamics, response gradient estimation, and an unconventional technique for simulating queueing systems using virtual resources that are identified from the optimization models for these systems.	algorithm;causality;constraint (mathematics);fo (complexity);like button;longest path problem;loss function;markov property;mathematical induction;mathematical optimization;maxima and minima;nl (complexity);optimization problem;petri net;program optimization;scheduling (computing);semiconductor industry;simulation;social inequality;stochastic process;system dynamics;tree (data structure)	Wai Kin Chan;Lee W. Schruben	2008	Operations Research	10.1287/opre.1080.0559	stochastic programming;mathematical optimization;combinatorics;systems modeling;integer programming;artificial intelligence;dynamical system;methodology;mathematics;system dynamics;gradient;scheduling;systems theory;algorithm	Robotics	19.53234257194859	8.228826706855946	69921
b3aeebb3f5e169814fb042d0cadd59d62c80a044	parametrized relocation of low-mobility resources	limited knowledge;dynamic location;min sum algebra;competitive ratio;dynamic optimization	Relocation of service-providers in response to changing real-time needs is suboptimal due to limited foreknowledge of client requests. Simple cost schedules for relocation and remote-service provision have been investigated both for the possibility of complete optimizability and the degree of inefficiency introduced by imperfect future knowledge. This work further explores a parametrization developed for reflecting limitations in the mobility of some resources. The optimizability response to this parameter exhibits two significant thresholds. Below the first threshold, optimization is trivial, but many real-world resource-location problems correspond to parameter values past the second threshold. This work explores both the value of the second threshold and the behavior of optimal limited-lookahead responses for resources whose immobility places them past this threshold. It is determined that, for resources of sufficiently high immobility α, it is possible with finite lookahead to achieve a relocation schedule which is within a ratio of (1 + α) of the optimal omniscient schedule. © 2013 Wiley Periodicals, Inc. NETWORKS, Vol. 62(1), 48–55 2013	john d. wiley;mathematical optimization;parsing;real-time transcription;relocation (computing)	D. Jacob Wildstrom	2013	Networks	10.1002/net.21492	competitive analysis;mathematical optimization;simulation;computer science;algorithm	AI	13.555868315029834	10.556654498893849	69937
22f61555fcc6f15a57a6ef2261ded2d85407cad1	optimal stationary behavior for a class of timed continuous petri nets	control optimo;routage optimal;red petri;modelo determinista;stationary behavior;continuous petri nets;modele deterministe;linear functionals;optimal control;programacion lineal;optimal routing;commande optimale;stationary firing rate;linear programming;programmation lineaire;linear program;petri net;deterministic model;reseau petri	In this paper, we consider a deterministic timed continuous Petri net model where conflicts at places are solved by using stationary routing parameters. We show how to compute the stationary firing rate for all transitions via linear programming, so as to determine the optimal routing parameters that maximize user-defined linear functions of the firing rates. Finally, we discuss the relations with discrete Petri nets.	petri net;stationary process	Bruno Gaujal;Alessandro Giua	2004	Automatica	10.1016/j.automatica.2004.04.018	control engineering;stochastic petri net;optimal control;linear programming;deterministic system;control theory;mathematics;petri net;algorithm	Robotics	10.307138847775422	7.86780690820668	70184
424cdbbd19a2b24c29a424e6f0ef4d32b629f7d9	scheduling selfish jobs on multidimensional parallel machines	scheduling games;parallel machines;multidimensional scheduling	We study the multidimensional vector scheduling problem with selfish jobs, both in non-cooperative and in cooperative versions. We show existence of assignments that are Nash, strong Nash, weakly and strictly Pareto optimal Nash equilibria in these settings. We improve upon the previous bounds on the price of anarchy for the non-cooperative case, and find tight bounds for every number of machines and dimension. For the cooperative case we provide tight bounds on the strong prices of anarchy and stability, as well as tight bounds on weakly and strictly Pareto optimal prices of anarchy and stability, for every number of machines and dimension.	anarchy;direction finding;job stream;nash equilibrium;pareto efficiency;schedule (project management);scheduling (computing)	Leah Epstein;Elena Kleiman	2014	Theor. Comput. Sci.	10.1145/2612669.2612683	price of stability;mathematical optimization;mathematics;distributed computing;mathematical economics;price of anarchy	Theory	14.592284330846702	11.810660384132696	70284
6272b874d18d2c01c71dbd26afd2546b8bc18d29	approximation schemes for parallel machine scheduling with availability constraints	total weighted completion time;approximate algorithm;ptas;parallel machine scheduling;single machine;approximation scheme;parallel machines;fully polynomial time approximation scheme;inapproximability;parallel machine;polynomial time approximation scheme	"""We investigate the problems of scheduling n weighted jobs to m parallel machines with availability constraints. We consider two different models of availability constraints: the preventive model, in which the unavailability is due to preventive machine maintenance, and the fixed job model, in which the unavailability is due to a priori assignment of some of the n jobs to certain machines at certain times. Both models have applications such as turnaround scheduling or overlay computing. In both models, the objective is to minimize the total weighted completion time. We assume that m is a constant, and that the jobs are non-resumable. For the preventive model, it has been shown that there is no approximation algorithm if all machines have unavailable intervals even if w""""i=p""""i for all jobs. In this paper, we assume that there is one machine that is permanently available and that the processing time of each job is equal to its weight for all jobs. We develop the first polynomial-time approximation scheme (PTAS) when there is a constant number of unavailable intervals. One main feature of our algorithm is that the classification of large and small jobs is with respect to each individual interval, and thus not fixed. This classification allows us (1) to enumerate the assignments of large jobs efficiently; and (2) to move small jobs around without increasing the objective value too much, and thus derive our PTAS. Next, we show that there is no fully polynomial-time approximation scheme (FPTAS) in this case unless P=NP. For the fixed job model, it has been shown that if job weights are arbitrary then there is no constant approximation for a single machine with 2 fixed jobs or for two machines with one fixed job on each machine, unless P=NP. In this paper, we assume that the weight of a job is the same as its processing time for all jobs. We show that the PTAS for the preventive model can be extended to solve this problem when the number of fixed jobs and the number of machines are both constants."""	approximation;parallel computing;scheduling (computing)	Bin Fu;Yumei Huo;Hairong Zhao	2011	Discrete Applied Mathematics	10.1016/j.dam.2011.06.007	mathematical optimization;combinatorics;discrete mathematics;polynomial-time approximation scheme;mathematics;algorithm	HPC	15.5643944562043	10.550447110183967	70605
d22adfc4db5fa1cd1784396632aaac87d79daa21	the discrete lot-sizing and scheduling problem: complexity and modification for batch availability	mixed integer linear program;complexity;simulated annealing;satisfiability;dlsp;single machine;computational complexity;scheduling;manufacturing;scheduling problem;lot sizing;production scheduling;batch availability	The discrete lot-sizing and scheduling problem (DLSP) has been suggested for the simultaneous choice of lot sizes and production schedules. In the context of computational complexity, it turns out that literature results for the DLSP are incorrect. Therefore, we prove that the decision version of the DLSP is NP-hard in the strong sense. The common assumption of instantaneous availability of the manufactured units is not satis®ed in practice if the units arrive in inventory only in one batch after the whole lot has been completed. Therefore, additional constraints are presented for this case of batch availability on a single machine. The resulting modi®ed DLSP is formulated as a mixed-integer linear program. This problem can be shown to be NP-hard again using ideas similar to the item-availability case. Hence, a two-phase simulated-annealing (SA) heuristic is suggested for solving the DLSP in the case of batch availability. Numerical results are presented for dierent problem classes. Ó 2000 Elsevier Science B.V. All rights reserved.	analysis of algorithms;computation;computational complexity theory;computer cooling;context of computational complexity;decision problem;dirk helbing;general-purpose modeling;heuristic;in-phase and quadrature components;inventory;linear programming;mathematical optimization;np-hardness;numerical analysis;schedule (computer science);scheduling (computing);simulated annealing;two-phase commit protocol;two-phase locking	Wolfgang Brüggemann;Hermann Jahnke	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00190-3	job shop scheduling;mathematical optimization;complexity;simulated annealing;computer science;operations management;mathematics;distributed computing;scheduling;manufacturing;computational complexity theory;scheduling;satisfiability	AI	15.584197337765215	8.702007461869814	70617
0d782140bb6733203df636da91f4522b0dbe0064	a faster polynomial algorithm for 2-cyclic robotic scheduling	hoist scheduling;complexity;product line;polynomial algorithm;cyclic scheduling;no wait flowshop	This paper addresses the 2-cyclic identical part scheduling in a no-wait robotic flowshop where exactly two parts enter and two parts leave the production line during each cycle. This problem was previously proved to be polynomially solvable in O(N 8 log N ) time, where N is the number of tanks in the production line. This paper proposes an improved algorithm with reduced complexity O(N 5 log N ).	algorithm;decision problem;polynomial;robot;scheduling (computing);subroutine	Chengbin Chu	2006	J. Scheduling	10.1007/s10951-006-8501-1	fair-share scheduling;mathematical optimization;complexity;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;mathematics;algorithm;i/o scheduling	Robotics	15.639151813278117	9.487017244258265	70758
1b2d6f2897d584dc235f041256efaeac651207f2	dynamic programming and lower-bound approaches to the minimum binding problem	dynamic programming algorithm;dynamic program;computer experiment;binding problem;lower bound	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	binding problem;dynamic programming;francis;primary source	Shotaro Kataoka;M. Kajiya	2004	Int. J. Systems Science	10.1080/00207720412331297901	binding problem;mathematical optimization;partition problem;computer experiment;cutting stock problem;machine learning;dynamic programming;mathematics;upper and lower bounds;algorithm	Robotics	12.067428665666876	10.232589075447104	70906
37b525dc744833f105cbe79bf0a8aca516b9d54e	local search for distributed sat with complex local problems	multi agent system;distributed constraint satisfaction problem;distributed constraint satisfaction;local search;propositional satisfiability	A distributed constraint satisfaction problem(DisCSP) is a general framework that can formalize various application problems in Multi-Agent Systems. The authors have developed a series of algorithms for solving DisCSPs, including an iterative improvement algorithm called the distributed breakout (DB) algorithm. This algorithm, however, deals only with DisCSPs where each agent has exactly one local variable and the relevant constraints to the variable. In this paper, we propose a new algorithm called Multi-DB for solving distributed SAT (DisSAT) where each agent has multiple local variables and the relevant clauses to the variables. We conduct an experiment to compare Multi-DB with the previous algorithm called Multi-AWC on well-known (Dis)3-SAT benchmarks. The results are very impressive since Multi-DB has much less average communication and computation costs for almost all cases (at least an order of magnitude less for larger problems). We also identify a trade-off between communication and computation costs of algorithms when we vary the degree of decentralization.	algorithm;boolean satisfiability problem;breakout box;computation;constraint satisfaction problem;distributed constraint optimization;iterative method;local search (constraint satisfaction);local search (optimization);local variable	Katsutoshi Hirayama;Makoto Yokoo	2002		10.1145/545056.545099	distributed algorithm;mathematical optimization;computer science;artificial intelligence;local search;theoretical computer science;multi-agent system;algorithm;difference-map algorithm;hybrid algorithm	AI	22.128827873064374	4.619573444111201	70923
9bbe5a4f31616fd2f1fc0447c63f3a6e1737a792	efficient filtering for the resource-cost alldifferent constraint	alldifferent;assignment cost;filtering;scalability;scheduling;energy;resource;product matrix travelling salesman problem	This paper studies a family of optimization problems where a set of items, each requiring a possibly different amount of resource, must be assigned to different slots for which the price of the resource can vary. The objective is then to assign items such that the overall resource cost is minimized. Such problems arise commonly in domains such as production scheduling in the presence of fluctuating renewable energy costs or variants of the Travelling Salesman Problem. In Constraint Programming, this can be naturally modeled in two ways: (a) with a sum of element constraints; (b) with a MinimumAssignment constraint. Unfortunately the sum of element constraints obtains a weak filtering and the MinimumAssignment constraint does not scale well on large instances. This work proposes a third approach by introducing the ResourceCostAllDifferent constraint and an associated incremental and scalable filtering algorithm, running in O ( n ⋅ m ) $\mathcal {O}(n \cdot m)$ , where n is the number of unbound variables and m is the maximum domain size of unbound variables. Its goal is to compute the total cost in a scalable manner by dealing with the fact that all assignments must be different. We first evaluate the efficiency of the new filtering on a real industrial problem and then on the Product Matrix Travelling Salesman Problem, a special case of the Asymmetric Travelling Salesman Problem. The study shows experimentally that our approach generally outperforms the decomposition and the MinimumAssignment ones for the problems we considered.	algorithm;backtracking;constraint programming;emoticon;experiment;fastest;free variables and bound variables;linear algebra;mathematical optimization;optimization problem;performance;robustness (computer science);scalability;scheduling (computing);solver;travelling salesman problem	Sascha Van Cauwelaert;Pierre Schaus	2017	Constraints	10.1007/s10601-017-9269-y	discrete mathematics;constraint programming;filter (signal processing);total cost;mathematical optimization;travelling salesman problem;scalability;scheduling (production processes);special case;mathematics;optimization problem	AI	20.148649312108198	9.355919945394195	71072
f0cc1f57a9ac93adfdc9c0afca75c78315d26b16	min sum edge coloring in multigraphs via configuration lp	edge coloring;randomized rounding;approximate algorithm;approximation algorithms;configuration lp;fractional derivative;scheduling problem;min sum;edge scheduling;bipartite graph	We consider the scheduling of biprocessor jobs under sum objective (BPSMS). Given a collection of unit-length jobs where each job requires the use of two processors, find a schedule such that no two jobs involving the same processor run concurrently. The objective is to minimize the sum of the completion times of the jobs. Equivalently, we would like to find a sum edge coloring of the given multigraphs, i.e. a partition of its edge set into matchings M1, ..., Mt minimizing Σi=1 t i|Mi|.#R##N##R##N#This problem is APX-hard even in the case of bipartite graphs [M04]. This special case is closely related to the classic open shop scheduling problem. We give a 1.829-approximation algorithm for BPSMS that combines a configuration LP with greedy methods improving the previously best known ratio of 2 [BBH+98]. The algorithm uses the fractions derived from the configuration LP and a non-standard randomized rounding. We also give a purely combinatorial and practical algorithm for the case of simple graphs, with a 1.8861-approximation ratio.	edge coloring;graph coloring;multigraph	Magnús M. Halldórsson;Guy Kortsarz;Maxim Sviridenko	2008		10.1007/978-3-540-68891-4_25	job shop scheduling;open-shop scheduling;mathematical optimization;randomized rounding;combinatorics;discrete mathematics;fractional calculus;bipartite graph;edge coloring;mathematics;approximation algorithm	Theory	15.666126629267737	11.108268281280159	71306
03147e48de0ff0a56e2ff4a7d85f2db63dc50567	finding endogenously formed communities	algorithms;design;stochastic processes;graph algorithms;theory;network problems	A central problem in data mining and social network analysis is determining overlapping communities (clusters) among individuals or objects in the absence of external identification or tagging. We address this problem by introducing a framework that captures the notion of communities or clusters determined by the relative affinities among their members. To this end we define what we call an affinity system, which is a set of elements, each with a vector characterizing its preference for all other elements in the set. We define a natural notion of (potentially overlapping) communities in an affinity system, in which the members of a given community collectively prefer each other to anyone else outside the community. Thus these communities are endogenously formed in the affinity system and are “self-determined” or “self-certified” by its members. We provide a tight polynomial bound on the number of selfdetermined communities as a function of the robustness of the community. We present a polynomial-time algorithm for enumerating these communities. Moreover, we obtain a local algorithm with a strong stochastic performance guarantee that can find a community in time nearly linear in the of size the community (as opposed to the size of the network). Social networks and social interactions fit particularly naturally within the affinity system framework – if we can appropriately extract the affinities from the relatively sparse yet rich information from social networks and social interactions, our analysis then yields a set of efficient algorithms for enumerating self-determined communities in social networks. In the context of social networks we also connect our analysis with results about (α, β)-clusters introduced by Mishra, Schreiber, Stanton, and Tarjan [22, 23]. In contrast with the polynomial bound we prove on the number of communities in the affinity system model, we show that there exists a family of networks with superpolynomial number of (α, β)-clusters. ∗School of Computer Science, College of Computing, Georgia Institute of Technology, Atlanta, Georgia. †Microsoft Research, New England, Cambridge, MA. ‡Princeton University §Microsoft Research, New England, Cambridge, MA. ¶Computer Science Department, University of Southern California.	affinity analysis;computer science;data mining;interaction;local algorithm;microsoft research;norm (social);polynomial;processor affinity;social network analysis;sparse matrix;stochastic gradient descent;tag (metadata);time complexity	Maria-Florina Balcan;Christian Borgs;Mark Braverman;Jennifer T. Chayes;Shang-Hua Teng	2013		10.1137/1.9781611973105.55	bioinformatics;data mining;mathematics	Theory	15.756814381661385	17.65137524311762	71315
c3e8c2d1594ff61d9f27b9370bb5ee780068411e	precedence knowledge acquisition for generating robot assembly sequences	algorithm analysis;question answer pattern precedence knowledge acquisition robot assembly sequences mechanical object;pattern matching;knowledge acquisition;assembling;industrial robots;robotic assembly knowledge acquisition machine intelligence knowledge engineering design engineering assembly systems algorithm design and analysis manufacturing industries computer science logic design;logical form;knowledge acquisition assembling industrial robots;question answering	An approach for obtaining precedence knowledge of n parts for generating all the feasible assembly sequences to construct a mechanical object is presented. Generally, to generate all the assembly sequences, the precedence-logical forms are obtained from the answers regarding the relation between pairs of parts consecutively asked about a design engineer, and the assembly sequences are deduced by logic induction. Previous work has shown that the question-answer pattern requires 2l operations (where l is total number of the liaisons and bound between n-l and (n/sup 2/-n)/2). The author proposes an efficient method and pattern-matching operation to obtain precedence relationships of parts. This approach results in only l questions to be answered to obtain such knowledge. For a special case with one-fixture assembly system, the question-answer format only requires n questions to be answered, resulting in a reduction of order of complexity. Detailed algorithms, analysis, and examples are presented to show the effectiveness of the proposed scheme. >	knowledge acquisition;robot	C. L. Philip Chen	1989		10.1109/ICSMC.1989.71255	question answering;logical form;computer science;artificial intelligence;machine learning;pattern matching;algorithm	Robotics	12.677533882519297	13.300120817852223	71328
8e67c139786c146af6ecaff49279d075666ed76a	dynamic scheduling via polymatroid optimization	dynamic programming;matroid;queueing network;programacion dinamica;red cola espera;matroide;polymatroide;optimization problem;politope;control problem;mathematical programming;reseau file attente;optimal scheduling;scheduling;queueing system;conservation law;programmation dynamique;linear program;polymatroid;ordonamiento;loi conservation;programmation mathematique;programacion matematica;ordonnancement;ley conservacion;dynamic scheduling;optimal control problem;polytope	Dynamic scheduling of multi-class jobs in queueing systems has wide ranging applications, but in general is a very difficult control problem. Here we focus on a class of systems for which conservation laws hold. Consequently, the performance space becomes a polymatroid - a polytope witha matroid-like structure, withall the vertices corresponding to the performance under priority rules, and all the vertices are easily identified. This structure translates the optimal control problem to an optimization problem, which, under a linear objective, becomes a special linear program; and the optimal schedule is a priority rule. In a more general setting, conservation laws extend to so-called generalized conservation laws, under which the performance space becomes more involved; however, the basic structure that ensures the optimality of priority rules remains intact. This tutorial provides an overview to the subject, focusing on the main ideas, basic mathematical facts, and computational implications.	polymatroid;program optimization;scheduling (computing)	David D. Yao	2002		10.1007/3-540-45798-4_5	matroid;optimization problem;polytope;mathematical optimization;combinatorics;discrete mathematics;dynamic priority scheduling;computer science;linear programming;artificial intelligence;dynamic programming;mathematics;distributed computing;scheduling;conservation law;algorithm	EDA	23.224255054843464	11.61594465934746	71476
c93e3c82cd4bb21816fedceafb1c9536ad011094	a note on optimal order of m machines in tandem with blocking	optimisation;production control operations research optimisation;operations research;production control;random variables throughput production stochastic processes buffer storage optimal scheduling automation shape hazards delay effects;stochastic ordering production control machine flowshop scheduling optimisation;stochastic order	The author considers a flowshop of machines with no intermediated storage between two successive machines. The problem is to find the permutation of machines which will maximize the throughput. Based on the method of branching, it is shown that for the case of four machines the optimal order is to arrange the two slowest machines in the first and last positions and the two fastest machines in the middle positions and the fastest one next to the slowest one, provided the processing times on the machines are comparable in the sense of stochastic ordering. >	blocking (computing)	Yi-Min Xie	1992		10.1109/ROBOT.1992.220086	mathematical optimization;real-time computing;stochastic ordering;computer science	Theory	10.546964335568163	5.54021535244861	71555
795813d54279cd389bbb536a533858945b5be04e	parallel approximation algorithms	approximate algorithm	Many problems of great practical importance are hard to solve computationally, at least if exact solutions are required. We survey a number of (NPor P-complete) problems for which fast parallel approximation algorithms are known: The O-l knapsack problem, binpacking, the minimal makeshift problem, the list scheduling problem, greedy scheduling, and the high density subgraph problem. Algorithms for these problems are presented highlighting the underlying techniques and principles, and several types of parallel approximation schemes axe exhibited. *The author was partly supported by NSF grant DCR-8351757.	approximation algorithm;greedy algorithm;ibm notes;knapsack problem;list scheduling;p-complete;scheduling (computing)	Ernst W. Mayr	1988			probabilistic analysis of algorithms;polynomial-time approximation scheme;computer science;parallel algorithm;minimax approximation algorithm;approximation algorithm;cost efficiency	Theory	15.568066113898666	14.267031351510937	71741
25ac09cfd0fc2b3bfd9beb211f22a3be4195410a	the complexity of machine scheduling for stability with a single disrupted job	complexite;duree job;disruption tâche unique;incertidumbre;uncertainty;complejidad;complexity;stability;flow time;robust stability;precedence constraints;scheduling;robustesse;robustness;machine scheduling;incertitude;subject;tasks;breakdowns;ordonnancement;reglamento;robustez	A stable schedule is a robust schedule that will change little when uncertain events occur. The purpose of this paper is to investigate the complexity status of a number of machine scheduling problems with stability objective, when the duration of a single job is anticipated to be disrupted. c © 2004 Elsevier B.V. All rights reserved.	scheduling (computing)	Roel Leus;Willy Herroelen	2005	Oper. Res. Lett.	10.1016/j.orl.2004.04.008	complexity;real-time computing;uncertainty;stability;computer science;rate-monotonic scheduling;mathematics;distributed computing;scheduling;statistics;robustness	AI	17.31043561946726	9.986614975423336	72030
3d4bce800354fbc099ab09417eeca915b7456c29	designing hybrid cooperations with a component language for solving optimisation problems	optimisation;optimizacion;cooperation;algorithme hybride;cooperation hybride;coordination language;constraint satisfaction;cooperacion;resolucion problema;langage coordination;satisfaction contrainte;optimization;satisfaccion restriccion;problem solving;resolution probleme	In this paper, we use a simple asynchronous coordination language to design some complex hybrid cooperation schemes for solving optimisation problems. The language allows us to specify the interaction between complete and incomplete constraint solvers in a clear and uniform way. Experimental results show the benefits of such hybrid cooperations in terms of efficiency.	mathematical optimization	Carlos Castro;Eric Monfroy	2004		10.1007/978-3-540-30106-6_46	simulation;constraint satisfaction;computer science;artificial intelligence;mathematics;cooperation;algorithm	AI	20.028281402583392	7.99196701134717	72341
543ea6d9a0497dd0e9c2bb872b6c584c5c281ae0	real time management of a metro rail terminus	minimisation;workload;spacing;modelizacion;espacement;regularite;minimization;optimisation;controleur trafic;traffic controller;blocage;optimizacion;gestion labor;espaciamiento;regularidad;job shop scheduling;routing;metropolitano;metropolitain;real time;gestion trafic;heuristic method;regularity;routage;traffic control;bloqueo;metodo heuristico;date echeance;minimizacion;traffic management;blocking;fonction objectif;train;objective function;modelisation;atelier multigamme;gestion tâche;scheduling;temps reel;due date;charge travail;lexicographic order;gestion trafico;scheduling problem;tiempo real;fecha vencimiento;funcion objetivo;job shop;optimization;supervisor trafico;methode heuristique;task scheduling;carga trabajo;job shop scheduling problem;modeling;ordonnancement;reglamento;subways;enrutamiento	This paper addresses a scheduling problem arising in the real time management of a metro rail terminus. It mainly consists in routing incoming trains through the station and scheduling their departures with the objective of optimizing punctuality and regularity of train service. The purpose of this work is to develop an automated train traffic control system, able to directly implement most traffic control actions, without the authorization of the local area manager. The scheduling problem is modeled as a bicriteria job shop scheduling problem with additional constraints. The two objective functions, in lexicographical order, are the minimization of tardiness/earliness and the headway optimization. The problem is solved in two steps. At first a heuristic builds a feasible solution by considering the first objective function. Then the regularity is optimized without deteriorating the first objective function. Computational results show that the system is able to manage the terminus very efficiently. 2006 Elsevier B.V. All rights reserved.	authorization;computation;control system;heuristic;job shop scheduling;lexicographical order;lexicography;loss function;mathematical optimization;optimization problem;routing;scheduling (computing)	Marta Flamini;Dario Pacciarelli	2008	European Journal of Operational Research	10.1016/j.ejor.2006.09.098	job shop scheduling;minimisation;mathematical optimization;routing;active traffic management;real-time computing;simulation;systems modeling;computer science;operations management;lexicographical order;train;mathematics;scheduling;blocking	AI	17.95231884759778	6.814725335180735	72648
89e7628dd920b6bd3bd28deda88f68825247774f	the two headed disk: stochastic dominance of the greedy policy	algorithm analysis;stochastic dominance;algorithme glouton;dominancia estocastica;analysis of algorithm;algorithme;analysis of algorithms;seek time;condicion optimalidad;stochastic optimization;condition optimalite;two headed disk;greedy algorithm;algorithms;dominance stochastique;analyse algorithme;stochastic optimality;working paper;analisis algoritmo;optimality condition	"""In his paper """"Should the two-headed disk be greedy? Yes, it should"""" Hofri defined a """"greedy policy"""" as follows. Assuming that the range of disk addresses is [0,1], a request at location x is served by the closest arm while the other arm jockeys to a new position, z , where z = (1/3)x or z = 2/3 +x/3 depending on whether x is larger or smaller than 1/2. Hofri proved that this policy minimizes the expected seek distance for uniform request probabilities and conjectured that it stochastically dominates every other policy. Stochastic dominance is of practical importance in this context as it guarantees that a policy that optimizes expected seek distance also guarantees optimal seek time. The main result of this paper is a proof of Hofri's conjecture. The paper contains two proofs, the first establishes the conjecture, and the second shows that if the seek distance is stochastically minimized under a repositioning policy, then the policy must be Hofri's greedy policy and the request distribution must be uniform."""	greedy algorithm;hard disk drive performance characteristics	Sridhar Seshadri;Doron Rotem	1996	Inf. Process. Lett.	10.1016/0020-0190(95)00210-3	mathematical optimization;hard disk drive performance characteristics;combinatorics;greedy algorithm;computer science;stochastic dominance;analysis of algorithms;stochastic optimization;mathematics;mathematical economics;algorithm	DB	17.3339352955663	13.352356970947792	72689
e88616d0856aaaf707d407e9801a9dd84098dbe1	system parameter, lot-size, and work-in-process optimization in manufacturing processes: an approach based on the application of timed event graphs	modelizacion;optimisation;optimizacion;red petri;production process;modelisation;grafo;mathematical programming;graph;graphe;work in process;processus fabrication;lot sizing;optimization;timed event graph;petri net;modeling;programmation mathematique;programacion matematica;reseau petri;proceso fabricacion	Timed Event Graphs are a class of Petri nets which can model some kinds of manufac tur ing processes. In this paper , a manufac tur ing system which includes the repeti t ive product ion of different products is r epresen ted by a T imed Event Graph , so as to apply the re levant pe r fo rmance analysis techniques. The objectives of the re la ted opt imizat ion problems take into account the maximizat ion of the th roughpu t of the system and the cost of the plant. The re levant decision variables are re la ted to the machine execution speeds, the d imensions of the lot-sizes for products, and the work-in-progress in the plant. It is shown that the overall opt imizat ion problem can bc decomposed into two subsequen t mathemat ica l p rogramming problems. The first one is a nonl inear , cont inuous mathemat ica l p rogramming problem, whereas the second one is an in teger l inear p rogramming one. Some special cases in which the s t ructure of the first p roblem is relatively simple are discussed.	decision theory;linear algebra;mathematical optimization;petri net;process optimization	Angela Di Febbraro;Riccardo Minciardi	1994	Robotics and Autonomous Systems	10.1016/0921-8890(94)90035-3	stochastic programming;optimization problem;simulation;systems modeling;computer science;work in process;scheduling;graph;petri net;algorithm	AI	19.084919460084627	8.1937381400275	72696
01f9033cdf521c0e784c2875746135b99de4ef89	a new heuristic formulation for a competitive maximal covering location problem		Authors are encouraged to submit new papers to INFORMS journals by means of a style file template, which includes the journal title. However, use of a template does not certify that the paper has been accepted for publication in the named journal. INFORMS journal templates are for the exclusive purpose of submitting to an INFORMS journal and should not be used to distribute the papers in print or online or to submit the papers to another publication.	analysis of algorithms;bilevel optimization;cobham's thesis;computation;covering problems;embedded system;greedy algorithm;heuristic;institute for operations research and the management sciences;mathematical model;mathematical optimization;maximal set;multi-level cell;numerical analysis;optimization problem;proxy server	Korosh Torabi;Lawrence V. Snyder	2018	Transportation Science	10.1287/trsc.2017.0769	mathematics;mathematical optimization;facility location problem;programming paradigm;stackelberg competition;heuristic	Theory	22.09379467466639	8.979799856613228	72791
6a4324ddee54df2500e8afd82f35b655f9868c0f	robot task sequencing for a flexible assembly system with 3d printers		We examine a robot task sequencing problem for a flexible assembly system which consists of multiple 3D printers, two post-processing machines, multiple assembly machines, an inspection machine, and one material handling robot. The flexible assembly systems, which have been built in many large cities in Korea, are designed to produce customized products for start-up companies and individuals. In this paper, we develop a robot task sequence in order to operate the system efficiently. We consider cyclic scheduling, a process for a system in which the robot repeats a specified sequence in a cycle to produce identical items. The system behavior is then modeled with a timed event graph (TEG) and the optimality of the robot task sequence is proved by analyzing the workloads of resources and the circuit ratios of the TEG.	3d printing;decision problem;material handling;robot;scheduling (computing);stack machine;video post-processing	Hyun-Jung Kim;Jun-Ho Lee	2017	2017 4th International Conference on Control, Decision and Information Technologies (CoDIT)	10.1109/CoDIT.2017.8102557	scheduling (computing);robot;real-time computing;engineering;graph	Robotics	11.219402110947465	4.660382202660749	72879
28c924f3572e69d7cf543a3d342cc1e0b4649d61	scheduling at villa vigoni		This issue contains a selection of the papers presented at the Workshop on “Models and Algorithms for Planning and Scheduling Problems” which was held in Loveno di Menaggio, on the Lake of Como, 14-18 June 1993. The workshop was put up in the Oberwolfach style, i.e., a limited number of participants (45) and lectures (35), surveys of experts in the field, ample time for discussion, the right mixture of senior researchers and young promising talents, and an inspiring scientific and social atmosphere. This atmosphere was more than achieved by the splendid location in Villa Vigoni, a beautiful 19th century villa in neoclassical style on the hills of the Lake of Como. The Villa Vigoni is famous for its valuable interiors, its beautiful park and surroundings, and its excellent cuisine and hospitality. The topics presented spanned the whole field of planning and scheduling. The major topics were: machine scheduling project analysis and scheduling vehicle scheduling and routing graph-theoretic models complexity of scheduling problems approximation algorithms on-line algorithms computational methods and software A number of prominent people in the area were invited to give selected contributions: J. Blazewicz, G. Gallo, C.R. Glassey, D.S. Hochbaum, E.L. Lawler, J.K. Lenstra, M. Lucertini, F. MafRoli, M. Queyranne, D.B. Shmoys, P. Toth, G. Weiss, and D. de Werra. Moreover, in order to have a high quality standard, the 24 contributed papers had to pass a strong selection process. This issue includes 9 papers which cover several aspects of the research activities on scheduling problems: modelling techniques, &Y-hardness results, polynomial algorithms, approximate algorithms and heuristics. The modelling issue is dealt with in the paper of Bampis, Guinand and Trystram who present and analyse scheduling problems that arise in the context of parallel programming. The relevance of communication delays in different parallel architectures implies the need for the extension of known models. _ Orman and Potts give an extensive and detailed complexity analysis of the problem to sequence jobs consisting of two operations on a single machine in order to minimize the makespan.	analysis of algorithms;approximation algorithm;arjen lenstra;automated planning and scheduling;display resolution;graph theory;heuristic (computer science);job stream;makespan;online and offline;parallel computing;polynomial;potts model;relevance;routing;schedule (project management);scheduling (computing)	Rolf H. Möhring;Franz Josef Radermacher;Maria Grazia Speranza	1997	Discrete Applied Mathematics	10.1016/S0166-218X(96)00033-9	discrete mathematics;combinatorics;scheduling (computing);mathematics	Theory	15.057579869871683	14.461669159947919	73075
c578ecef16b326a2c48974fefafdee1a0ee2e4f6	a note on optimality conditions for the euclidean. multifacility location problem	graph theory;location problem;probleme localisation;teoria grafo;linear least square;theorie graphe;incidence matrix;probleme combinatoire;condition optimalite;problema combinatorio;probleme localisation multicentre;condicion estado optimo;problema localizacion;combinatory problem;optimality condition	The key problem of the Euclidean multifacility location (EMFL) problem is to decide whether a given dead point is optimal. If it is not optimal, we wish to compute a descent direction. This paper extends the optimality conditions of Calamai and Conn and Overton to the case when the rows of the active constraints matrix are linearly dependent. We show that linear dependence occurs whenever (3, the graph of the coinciding facilities, has a cycle. In this case the key problem is formulated as a linear least squares problem with bounds on the Euclidean norms of certain subvectors.	active set method;conn;descent direction;iscb overton prize;linear least squares (mathematics)	Achiya Dax	1986	Math. Program.	10.1007/BF02591990	mathematical optimization;combinatorics;graph theory;calculus;mathematics;incidence matrix	ML	23.998126233088655	13.988299649464192	73169
6be6e108ab8e0f30157e3f34df6c63bd8a600e85	schedulers for larger classes of pinwheel instances	satellite communication;pinwheel;real time;scheduling;scheduling problem;article;hard real time	The pinwheel is a hard-real-time scheduling problem for scheduling satellite ground stations to service a number of satellites without data loss. Given a multiset of positive integers (instance)A={a1,..., an}, the problem is to find an infinite sequence (schedule) of symbols from {1,2,...,n} such that there is at least one symboli within any interval of ai symbols (slots). Not all instancesA can be scheduled; for example, no “successful” schedule exists for instances whose density,ρ(A)=∑ i i (l/ai), is larger than 1. It has been shown that all instances whose densities are less than a 0.5 density threshold can always be scheduled. If a schedule exists, another concern is the design of a fast on-line scheduler (FOLS) which can generate each symbol of the schedule in constant time. Based on the idea of “integer reduction,” two new FOLSs which can schedule different classes of pinwheel instances, are proposed in this paper. One uses “single-integer reduction” and the other uses “double-integer” reduction. They both improve the previous 0.5 result and have density thresholds of 13/20 and2/3, respectively. In particular, if the elements inA are large, the density thresholds will asymptotically approach In 2 and 1/R2, respectively.	online and offline;pinwheel (cryptography);real-time clock;schedule (computer science);scheduling (computing);time complexity	Mee Yee Chan;Francis Y. L. Chin	1993	Algorithmica	10.1007/BF01187034	job shop scheduling;combinatorics;real-time computing;computer science;mathematics;distributed computing;scheduling;communications satellite;algorithm	Theory	14.670750846419756	12.560245712723724	73227
b8b0fa7451b5a51e9a3d1a0d389a0223c8df6450	how hard is it to tell which is a condorcet committee?☆	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	This paper establishes the computational complexity status for a problem of deciding on the quality of a committee. Starting with individual preferences over alternatives, we analyse when it can be determined efficiently if a given committee [Formula: see text] satisfies a weak (resp. strong) Condorcet criterion-i.e., if [Formula: see text] is at least as good as (resp. better than) every other committee in a pairwise majority comparison. Scoring functions used in classic voting rules are adapted for these comparisons. In particular, we draw the sharp separation line between computationally tractable and intractable instances with respect to different voting rules. Finally, we show that deciding if there exists a committee which satisfies the weak (resp. strong) Condorcet criterion is computationally hard.		Andreas Darmann	2013		10.1016/j.mathsocsci.2013.06.004	text mining;social science;medical research;voting paradox;data mining;mathematics;mathematical economics;ranked pairs;law;condorcet method;kemeny–young method	AI	16.144493631280866	17.284272968984205	73367
1b6d6c123ddd97070753a439e9af5f660393b792	keyword-aware optimal route search	computer science engineering;journal article	Identifying a preferable route is an important problem that finds applications in map services. When a user plans a trip within a city, the user may want to find “a most popular route such that it passes by shopping mall, restaurant, and pub, and the travel time to and from his hotel is within 4 hours.” However, none of the algorithms in the existing work on route planning can be used to answer such queries. Motivated by this, we define the problem of keywordaware optimal route query, denoted by KOR, which is to find an optimal route such that it covers a set of user-specified keywords, a specified budget constraint is satisfied, and an objective score of the route is optimal. The problem of answering KOR queries is NP-hard. We devise an approximation algorithm OSScaling with provable approximation bounds. Based on this algorithm, another more efficient approximation algorithm BucketBound is proposed. We also design a greedy approximation algorithm. Results of empirical studies show that all the proposed algorithms are capable of answering KOR queries efficiently, while the BucketBound and Greedy algorithms run faster. The empirical studies also offer insight into the accuracy of the proposed algorithms.	approximation algorithm;graph partition;greedy algorithm;moe;multitier architecture;np-hardness;planning;preprocessor;provable security;tier 1 network	Xin Cao;Lisi Chen;Gao Cong;Xiaokui Xiao	2012	PVLDB	10.14778/2350229.2350234	computer science;theoretical computer science;machine learning;data mining;database;approximation algorithm	DB	23.591839569888233	7.279478135088195	73505
19e00a474129bf51d11b63a699c95e7e3b5913b2	a solvable case of quadratic 0-1 programming	quadratic programming;programmation quadratique;programmation entiere;algorithme;algorithm;algorritmo;integer programming;mathematical programming;programmation mathematique	where Q is a symmetric matrix with null elements in the diagonal. We do not loose generality with this last assumption because x 2 = xi for 1 _< i_< n. Finding the minimum o f f is an NP-hard problem [6], it contains as special case the maximum stable set problem. This problem is polynomially solvable when all the elements of Q are non-positive [10]. For the general case, a branch-and-bound algorithm has been proposed in [3], and polynomial algorithms for computing lower bounds of f have been given in [8]. We define the graph G(Q)= (V,E), associated to Q = [q/j] as follows:	algorithm;branch and bound;decision problem;np-hardness;polynomial	Francisco Barahona	1986	Discrete Applied Mathematics	10.1016/0166-218X(86)90065-X	mathematical optimization;combinatorics;integer programming;mathematics;quadratic programming;algorithm	Theory	23.808686574060555	13.906929916566368	73702
d5ec6819f49cb57e3355b80121ac071b99384d25	non-clairvoyant scheduling to minimize the average flow time on single and parallel machines	cpu scheduling;time sharing;single machine;operating system;parallel machines;lower bound;competitive ratio	Scheduling a sequence of jobs released over time when the processing time of a job is only known at its completion is a classical problem in CPU scheduling in time sharing operating systems. A widely used measure for the responsiveness of the system is the average flow time of the jobs, i.e. the average time spent by jobs in the system between release and completion. The Windows NT and the Unix operating system scheduling policies are based on the Multi-level Feedback algorithm [12, 1]. In this paper we prove that a randomized version of the Multi-level Feedback algorithm is competitive for single and parallel machine systems, in our opinion providing one theoretical validation of the goodness of an idea that has been very effective in practice along the last two decades. The randomized Multi-level Feedback algorithm (RMLF) was first proposed by Kalyanasundaram and Pruhs [7] for a single machine achieving an O(\log n \log\log n) competitive ratio to minimize the average flow time against the on-line adaptive adversary, where n is the number of jobs that are released. We present a version of RMLF working for any numberm of parallel machines. We show for RMLF a first O(\log n\log \frac{n}{m}) competitiveness result against the oblivious adversary on parallel machines. We also show that the same RMLF algorithm surprisingly achieves a tight O(\log n) competitive ratio against the oblivious adversary on a single machine, therefore matching the lower bound of [10].	adversary (cryptography);adversary model;central processing unit;competitive analysis (online algorithm);computationally bounded adversary;job stream;online and offline;operating system;parallel computing;randomized algorithm;responsiveness;scheduling (computing);time-sharing;unix;windows nt	Luca Becchetti;Stefano Leonardi	2001		10.1145/380752.380782	competitive analysis;mathematical optimization;real-time computing;computer science;theoretical computer science;distributed computing;upper and lower bounds;scheduling;time-sharing	Theory	15.314753176704563	11.81953091566847	73827
f293f713308622e6b95c35731994b45edc86d75d	the flexible blocking job shop with transfer and set-up times	workload;insertion;job shop schduling;tiempo total acabamiento;blocage;gestion labor;gestion production;job shop scheduling;availability;disponibilidad;flexibilidad;flexible machines;heuristic method;atelier flexible;temps total achevement;bloqueo;metodo heuristico;forme disjonctive;buffer system;blocking;production management;sistema amortiguador;busca local;atelier multigamme;gestion tâche;makespan;insercion;flexible manufacturing system;scheduling;gestion produccion;disjunctive form;charge travail;job shop;sistema flexible produccion;tabu search;flexibilite;forma disyuntiva;methode heuristique;task scheduling;disjunctive graph;carga trabajo;systeme tampon;disponibilite;local search;ordonnancement;recherche locale;busqueda tabu;flexibility;reglamento;recherche tabou;setup	The Flexible Blocking Job Shop (FBJS) considered here is a job shop scheduling problem characterized by the availability of alternative machines for each operation and the absence of buffers. The latter implies that a job, after completing an operation, has to remain on the machine until its next operation starts. Additional features are sequence-dependent transfer and set-up times, the first for passing a job from a machine to the next, the second for change-over on a machine from an operation to the next. The objective is to assign machines and schedule the operations in order to minimize the makespan. We give a problem formulation in a disjunctive graph and develop a heuristic local search approach. A feasible neighborhood is constructed, where typically a critical operation is moved (keeping or changing its machine) together with some other operations whose moves are “implied”. For this purpose, we develop the theoretical framework of job insertion with local flexibility, based on earlier work of Gröflin and Klinkert on insertion. A tabu search that consistently generates feasible neighbor solutions is then proposed and tested on a larger test set. Numerical results support the validity of our approach and establish first benchmarks for the FBJS.	blocking (computing);disjunctive normal form;heuristic;job shop scheduling;makespan;numerical method;scheduling (computing);tabu search;test set	Heinz Gröflin;Dinh-Nguyen Pham;Reinhard Bürgy	2011	J. Comb. Optim.	10.1007/s10878-009-9278-x	insertion;job shop scheduling;availability;mathematical optimization;simulation;flow shop scheduling;tabu search;computer science;bicarbonate buffering system;local search;job stream;mathematics;scheduling;blocking	AI	18.489603098904446	7.825455466998965	74161
e33909864e3106dedf221fdb16e71554fcee7ea1	exact resolution of the one-machine sequencing problem with no machine idle time	no idle constraint;branch and bound algorithm;one machine sequencing problem;satisfiability;branch and bound method;makespan;delivery times;polynomial time;release dates;time use	0360-8352/$ see front matter 2010 Elsevier Ltd. A doi:10.1016/j.cie.2010.03.007 q This manuscript was processed by Area Editor Im * Corresponding author. E-mail addresses: jacques.carlier@utc.fr (J. Carli (F. Hermès), aziz.moukrim@utc.fr (A. Moukrim (K. Ghédira). This paper investigates the one-machine sequencing problem in a workshop where the machine has to satisfy the no-idle constraint, that is, the machine must process jobs without interruption. The objective is to minimize the makespan. Each job has a release date for which it is available for processing on the machine and a delivery time during which it must remain in the system after being processed by the machine. This problem has been studied without adding the no-idle constraint. It is solved in polynomial time, when the preemption of jobs is allowed, applying Jackson’s rule. But, when the preemption of jobs is not allowed, it becomes strongly NP-hard. Although, it can be solved in a very short time using Carlier’s branch and bound algorithm. Below, we propose to adapt Carlier’s branch and bound method in order to calculate an optimal nonpreemptive schedule for the problem when adding the no-idle constraint. 2010 Elsevier Ltd. All rights reserved.	algorithm;branch and bound;computation;interrupt;jackson;job stream;makespan;np-hardness;polynomial;preemption (computing);software release life cycle;time complexity	Jacques Carlier;Fatma Hermès;Aziz Moukrim;Khaled Ghédira	2010	Computers & Industrial Engineering	10.1016/j.cie.2010.03.007	time complexity;job shop scheduling;mathematical optimization;real-time computing;computer science;operations management;mathematics;branch and bound;satisfiability	AI	16.164991439525124	9.374581433888126	74174
5595e048acb746fc055b95c6765eb72f07047782	unidirectional loop layout problem with balanced flow	estacion trabajo;routing;probleme np complet;station travail;plan equilibre;localization;heuristic method;layout problem;probleme agencement;routage;plant layout;metodo heuristico;intelligence artificielle;localizacion;algoritmo genetico;planning installation;artificial intelligent;workstation;localisation;materials handling;plan equilibrado;material flow;algorithme genetique;problema disposicion;artificial intelligence;genetic algorithm;problema np completo;methode heuristique;inteligencia artificial;flux matiere;proyecto instalacion;np complete problem;hybrid genetic algorithm;balanced design;manutention materiau;enrutamiento;flujo materia	The unidirectional loop is an economical and flexible materials handling system transporting materials around a loop network in one direction only. There are n candidate locations around the loop to allocate n machines. This configuration is easily adaptable to changes in product mix and routing requirements. The challenge here is to find an assignment for machines to available sites to minimize the handling cost. If the material flow is conserved at each workstation, that is, if total inflow is equal to total outflow then such a loop is called as a balanced loop. This work addresses the unidirectional loop layout design problem with balanced flow. The problem is known to be NP-complete, and thus heuristic methods and artificial intelligence techniques are appropriate to solve such difficult problems in reasonable time. A hybrid Genetic Algorithm (GA) based on a move heuristic is developed to solve the problem. The performance of the GA is tested by using well known data sets from literature and considerable improvements are obtained.	artificial intelligence;assignment (computer science);circular layout;genetic algorithm;heuristic;heuristic (computer science);lp-type problem;linear programming relaxation;local search (optimization);material flow;np-completeness;phase-locked loop;requirement;routing;software release life cycle;unbalanced circuit;workstation	Feristah Ozcelik;A. Attila Islier	2006		10.1007/11779568_80	loop tiling;routing;genetic algorithm;np-complete;internationalization and localization;workstation;loop fission;loop interchange;computer science;artificial intelligence;material flow;algorithm	Robotics	19.225939813718274	6.699288100337463	74199
1315dacf78ac57b6f9e5b59fb9c5e270c1b2995f	office systems research at ibm, arc		Ph.D University of California at Berkeley, Dec 2004. Industrial Engineering and Operations Research  Minors: Statistics, Computer Science. Designing capacitated survivable networks: Polyhedral analysis and algorithms. A network is said to be survivable if all demands on the network can be met under the failure of any one of its edges. We present new models, study relevant pricing problems and develop cutting planes that are incorporated in a computationally efficient algorithm. We also study various mixed-integer sets and their polyhedra in to develop strong valid inequalities for the mixed-integer knapsack set. [PDF] Dissertation Committee : Alper Atamtürk, Ilan Adler, Dorit Hochbaum, Thomas Henzinger.	algorithm;algorithmic efficiency;computer science;industrial engineering;operations research;polyhedral;portable document format	R. Williams	1987		10.1007/978-3-662-01110-2_1	industrial engineering	Theory	19.672684818177785	14.354389345937507	74297
079d5247d7c758073e2bffa29ccc8c3f8be364c1	from enterprise models to scheduling models: bridging the gap	constraint programming;scheduling problem;enterprise modeling;optimization;automatic scheduling	Enterprise models cover all aspects of modern enterprises, from accounting, through management of custom orders and invoicing, to operational data such as records on machines and workers. In other words, all data necessary for running the company are available in enterprise models. The problem is that these data are not in the proper format for some tasks such as scheduling and optimization. This paper deals with the automated translation of data from the enterprise model to a scheduling model and back. In particular, we describe how to extract data from the enterprise model for solving the scheduling problem using constraint-based solvers.	bridging (networking);enterprise modelling;machine translation;mathematical optimization;media redundancy protocol;preprocessor;schedule (computer science);scheduling (computing);user experience	Roman Barták;James Little;Oscar Manzano;Con Sheahan	2010	J. Intelligent Manufacturing	10.1007/s10845-008-0166-5	functional software architecture;fair-share scheduling;nurse scheduling problem;job shop scheduling;mathematical optimization;constraint programming;enterprise system;real-time computing;enterprise software;flow shop scheduling;enterprise modelling;dynamic priority scheduling;computer science;rate-monotonic scheduling;integrated enterprise modeling;two-level scheduling;enterprise architecture management;database;scheduling;enterprise architecture;enterprise information system	OS	12.059608284513102	4.901767338575535	74299
d5325052cac72955717e0f53cb20c7d5b4222a09	searching over metapositions in kriegspiel	aplicacion militar;sistema experto;application militaire;algoritmo busqueda;guerra;chess game;algorithme recherche;metodo arborescente;branching;search algorithm;base connaissance;probabilistic approach;jeu 2 personnes;systeme ordre reduit;ajedrez;war;juego 2 personas;enfoque probabilista;approche probabiliste;ramificacion;two person game;military application;ramification;base conocimiento;tree structured method;jeu echecs;methode arborescente;jeu ordinateur;systeme expert;computer games;endgame;terminacion juego;fin jeu;reduced order systems;guerre;knowledge base;expert system	Kriegspiel is a Chess variant similar to wargames, in which players have to deal with uncertainty. Kriegspiel increases the difficulty typical of Chess by hiding from each player his opponent’s moves. Although it is a two person game it needs a referee, whose task consists in accepting the legal moves and rejecting the illegal ones, with respect to the real situation. Neither player knows the whole history of moves and each player has to guess the state of the game on the basis of messages received from the referee. A player’s try may result legal or illegal, and a legal move may prove to be a capture or a check. The paper describes the rationale of a program to play basic endgames of Kriegspiel, where a player has left only the King. These endings have been theoretically studied with rule-based mechanisms, whereas few researches exist on a gametree-based approach. We show how the branch of game tree can be reduced in order to employ an evaluation function and a search algorithm. Then we deal with game situations dependent on stochastic element and we show how we resolve them during the tree visit.	artificial intelligence;computer chess;computer programming;design rationale;endgame tablebase;evaluation function;icga journal;international computer games association;logic programming;p (complexity);pc game;search algorithm;theoretical computer science;theory;transposition table;wargames	Andrea Bolognesi;Paolo Ciancarini	2004		10.1007/11674399_17	bayesian game;knowledge base;simulation;branching;extensive-form game;computer science;artificial intelligence;strategy;ramification;war;expert system;algorithm;search algorithm	AI	11.007650309598416	16.69821023209748	74495
6f068bac93750394796dce20451a9fa2aea5384d	new results on web caching with request reordering	modelizacion;dynamic programming;documento electronico;metodo polinomial;online algorithm;web documents;programacion dinamica;approximate algorithm;temps polynomial;caching;batch production;best approximation;approximation algorithms;competitividad;on line;en linea;approximation algorithm;procede discontinu;problema np duro;cache memory;dynamic program;algorithme deterministe;general techniques;antememoria;optimisation combinatoire;document electronique;polynomial time algorithm;modelisation;np hard problem;deterministic algorithms;antememoire;produccion por lote;probleme np difficile;polynomial method;production par lot;programmation dynamique;algoritmo aproximacion;batch process;polynomial time;competitiveness;mejor aproximacion;procedimiento discontinuo;en ligne;online algorithms;algorithme approximation;fault model;combinatorial optimization;methode polynomiale;competitivite;modeling;web caching;cost model;electronic document;competitive ratio;optimizacion combinatoria;tiempo polinomial;meilleure approximation	We study web caching with request reordering. The goal is to maintain a cache of web documents so that a sequence of requests can be served at low cost. To improve cache hit rates, a limited reordering of requests is allowed. Feder et al. (Proceedings of the 13th ACM–SIAM Symposium on Discrete Algorithms, pp. 104–105, 2002), who recently introduced this problem, considered caches of size 1, i.e. a cache can store one document. They presented an offline algorithm based on dynamic programming as well as online algorithms that achieve constant factor competitive ratios. For arbitrary cache sizes, Feder et al. (Theor. Comput. Sci. 324:201–218, 2004) gave online strategies that have nearly optimal competitive ratios in several cost models. In this paper we first present a deterministic online algorithm that achieves an optimal competitiveness, for the most general cost model and all cache sizes. We then investigate the offline problem, which is NP-hard in general. We develop the first polynomial time algorithms that can manage arbitrary cache sizes. Our strategies achieve small constant factor approximation ratios. The algorithms are based on a general technique that reduces web caching with request reordering to a problem of computing batched service schedules. Our approximation result for the Fault Model also improves upon the best previous approximation guarantee known for web caching without request reordering. We remark that, unlike Feder et al., we assume that bypassing is allowed, i.e. referenced documents do not necessarily have to be brought into cache to serve their requests.	analysis of algorithms;approximation algorithm;cpu cache;cache (computing);competitive analysis (online algorithm);deterministic algorithm;dynamic programming;fault model;mathematical optimization;mechwarrior: living legends;np-hardness;olami–feder–christensen model;online algorithm;online and offline;optimization problem;schedule (computer science);symposium on discrete algorithms;time complexity;web cache;web page	Susanne Albers	2008	Algorithmica	10.1007/s00453-008-9276-x	online algorithm;mathematical optimization;cache;computer science;theoretical computer science;cache invalidation;mathematics;distributed computing;smart cache;cache algorithms;approximation algorithm;algorithm	Theory	17.196892364693674	10.656444225483016	74564
50eb91368e314a3b2dbb3cf2bc1aa920ac36c69c	cutting planes in constraint programming: a hybrid approach	optimisation sous contrainte;constrained optimization;programacion entera;cutting plane;travelling salesman problem;global constraint;operations research;programmation en nombres entiers;problema viajante comercio;optimizacion con restriccion;hybrid approach;integer programming;mathematical programming;probleme commis voyageur;computational complexity;metodo plano secante;constraint programming;methode plan secant;programmation mathematique;programacion matematica;cutting plane method	In recent years, a growing number of attempts have been performed in order to integrate well known Operations Research( OR) techniques in Constraint Programming (CP) tools. The aim of the integration is to maintain the modelling facilities of the CP paradigm, while improving its performances by exploiting effective OR techniques. In our previous work, we proposed the use of optimization constraints [9], embedding a linear relaxation of the constraint itself and performing pruning on the basis of costs. In particular, domain values can be removed whenever it can be shown that their assignment will necessarily lead to solutions worse than the best solution found. In this setting, the use of cutting planes in global constraints allows to tighten the relaxation so as to infer more accurate bounds on the problem. We propose different ways of using cutting-planes in optimization constraints achieving different levels of tightness of the integration and pruning power. Even if the proposed technique is general, we use as testing application the Travelling Salesman Problem (TSPs) and its time constrained variant. Computational results compare different relaxations in terms of pruning achieved and computational complexity.	constraint programming	Filippo Focacci;Andrea Lodi;Michela Milano	2000		10.1007/3-540-45349-0_15	mathematical optimization;constrained optimization;combinatorics;integer programming;computer science;mathematics;algorithm;cutting-plane method	AI	20.435810726805553	4.910313873746968	74765
9811988eeea67fc7998e5e907c94efd12c9f1b84	spectral bounds for unconstrained (-1, 1)-quadratic optimization problems	quadratic programming;quadratic program;programmation semi definie;semidefinite programming;programmation quadratique;maximum cut problem;relaxation semidefinie;computer experiment;unconstrained quadratic programming;unconstrained quadratic programming semidefinite programming maximum cut problem;borne inferieure;quadratic optimization;unconstrained optimization;programacion cuadratica;optimizacion sin restriccion;programacion semi definida;relajacion semidefinida;optimisation sans contrainte;semidefinite relaxation;lower bound;cota inferior;semidefinite program;semi definite programming	Given an unconstrained quadratic optimization problem in the following form:with , we present different methods for computing bounds on its optimal objective value. Some of the lower bounds introduced are shown to generally improve over the one given by a classical semidefinite relaxation. We report on theoretical results on these new bounds and provide preliminary computational experiments on small instances of the maximum cut problem illustrating their performance.	mathematical optimization	Walid Ben-Ameur;José Neto	2010	European Journal of Operational Research	10.1016/j.ejor.2010.02.042	quadratic unconstrained binary optimization;mathematical optimization;combinatorics;discrete mathematics;computer experiment;mathematics;upper and lower bounds;quadratic programming	Theory	22.768115436776668	13.356470433756705	74886
c35d6cc2e5e1458f0e06e6a4dc0d91afed15a749	a genetic algorithm for the steel continuous casting with inter-sequence dependent setups and dedicated machines				Abdelkader Sbihi;Makram Chemangui	2018	RAIRO - Operations Research	10.1051/ro/2018023		DB	11.320489178365744	4.922558185066787	74940
d1c21bbfba4f81081ee05a9e875e78583be15912	an approximation algorithm for network design problems with downwards-monotone demand functions	network design;approximate algorithm;network design problems;approximation algorithms;integer programs;integer program;spanning forests	Building on an existing 2-approximate algorithm for the class of network design problems with downwards-monotone demand functions, many of which are NP-hard, we present an algorithm that produces solutions that are at least as good as and typically better than solutions produced by the existing algorithm.	approximation algorithm;np-hardness;network planning and design;monotone	Michael J. Laszlo;Sumitra Mukherjee	2008	Optimization Letters	10.1007/s11590-007-0051-8	algorithm design;mathematical optimization;network planning and design;combinatorics;discrete mathematics;mathematics;approximation algorithm	Theory	22.38068584734656	14.325520680926983	75047
fb302450c8856af012c72cca87c339fbecae50e5	hardware configuration selection through discretizing a continuous variable solution	discretization error;previous model;throughput subject;cpu speed;continuous variable solution;continuous variable;device capacity;discrete problem;hardware configuration selection;fixed cost constraint;computer system configuration;appropriate discretization;benchmark;real time;distributed processing;modeling;calibration;simulation;fixed cost	This paper extends a previous model for computer system configuration planning developed by the authors. The problem is to optimally select the CPU speed, the device capacities, and file assignments so as to maximize throughput subject to a fixed cost constraint. We advocate solving this essentially discrete problem in continuous variables followed by an appropriate discretization. The discretization error thus committed is analyzed in detail.	discretization	Robert A. Wagner;Kishor S. Trivedi	1980	SIGMETRICS Performance Evaluation Review	10.1145/1009375.806156	discretization error;mathematical optimization;real-time computing;calibration;simulation;systems modeling;benchmark;computer science;operating system;discretization;discretization of continuous features;fixed cost	HPC	12.830758780822933	9.277661106932355	75153
23645e253bee559185d3cd216f440b4f28248519	faster approximate lossy generalized flow via interior point algorithms	interior point algorithms;approximate algorithm;approximation algorithms;linear time algorithm;linear system;network flows;linear time;linear programming;linear program;network flow;linear equations;interior point algorithm	We present asymptotically faster approximation algorithms for the generalized flow problems in which multipliers on edges are at most 1. For this lossy version of the maximum generalized flow problem, we obtain an additive ε approximation of the maximum flow in time O{m3/2 log (U/ε)2}, where m is the number of edges in the graph, all capacities are integers in the range {1, ... , U}, and all loss multipliers are ratios of integers in this range. For minimum cost lossy generalized flow with costs in the range {1,... ,U}, we obtain a flow that has value within an additive ε of the maximum value and cost at most the optimal cost. In many parameter ranges, these algorithms improve over the previously fastest algorithms for the generalized maximum flow problem by a factor of m1/2 and for the minimum cost generalized flow problem by a factor of approximately m1/2/ ε2. The algorithms work by accelerating traditional interior point algorithms by quickly solving the system of linear equations that arises in each step. The contributions of this paper are twofold. First, we analyze the performance of interior point algorithms with approximate linear system solvers. This analysis alone provides an algorithm for the standard minimum cost flow problem that runs in time Om3/2 log U}--an improvement of roughly O{n / m1/2} over previous algorithms. Second, we examine the linear equations that arise when using an interior point algorithm to solve generalized flow problems. We observe that these belong to the family of symmetric M-matrices, and we then develop Om-time algorithms for solving linear systems in these matrices. These algorithms reduce the problem of solving a linear system in a symmetric M-matrix to that of solving O{log n} linear systems in symmetric diagonally-dominant matrices, which we can do in time Om using the algorithm of Spielman and Teng. All of our algorithms operate on numbers of bit length at most O{log n U / ε}.	approximation algorithm;bit-length;diagonally dominant matrix;fastest;flow network;linear equation;linear system;loss function;lossy compression;maximum flow problem;minimum-cost flow problem;system of linear equations;utility functions on indivisible goods	Samuel I. Daitch;Daniel A. Spielman	2008		10.1145/1374376.1374441	mathematical optimization;combinatorics;discrete mathematics;flow network;linear programming;mathematics	Theory	21.83133245446207	17.830991830963278	75277
fdffdea112f0aff0e87308240c7840e2645243fc	on combinatorial design spaces for the configuration design of product families	configuration design;engineering design problem;design space modeling methodology;configuration design space;design space;defining design space;design requirement;combinatorial design space;configuration design problem;engineering design;product family;defining configuration design space;combinatorial design;combinatorics	For typical optimization problems, the design space of interest is well defined: It is a subset of Rn, where n is the number of (continuous) variables. Constraints are often introduced to eliminate infeasible regions of this space from consideration. Many engineering design problems can be formulated as search in such a design space. For configuration design problems, however, the design space is much more difficult to define precisely, particularly when constraints are present. Configuration design spaces are discrete and combinatorial in nature, but not necessarily purely combinatorial, as certain combinations represent infeasible designs. One of our primary design objectives is to drastically reduce the effort to explore large combinatorial design spaces. We believe it is imperative to develop methods for mathematically defining design spaces for configuration design. The purpose of this paper is to outline our approach to defining configuration design spaces for engineering design, with an emphasis on the mathematics of the spaces and their combinations into larger spaces that more completely capture design requirements. Specifically, we introduce design spaces that model physical connectivity, functionality, and assemblability considerations for a representative product family, a class of coffeemakers. Then, we show how these spaces can be combined into a “common” product variety design space. We demonstrate how constraints can be defined and applied to these spaces so that feasible design regions can be directly modeled. Additionally, we explore the topological and combinatorial properties of these spaces. The application of this design space modeling methodology is illustrated using the coffeemaker product family.		Zahed Siddique;David W. Rosen	2001	AI EDAM		mathematical optimization;combinatorial design;probabilistic design;configuration design;high-level design;generative design	EDA	12.008829740081111	13.139736497334699	75532
28ebd6b4258975cf2845050eda5db3b7c54e2774	an exact algorithm for the capacitated shortest spanning arborescence	network design;cutting plane;routing;branch and bound algorithm;network analysis planning;upper bound;exact algorithm;transportation;branch and bound;lower bound;heuristic algorithm;lagrangian relaxation	We are given a complete and loop-free digraphG=(V, A), whereV={1,...,n} is the vertex set,A={(i, j) :i, j ∈V} the arc set, andr ∈V is a distinguishedroot vertex. For each arc (i, j) ∈A, letcij be the associatedcost, and for each vertexi, letqi≥0 be the associateddemand (withqr=0). Moreover, a nonnegativebranch capacity, Q, is defined.A Capacitated Shortest Spanning Arborescence rooted at r (CSSAr) is a minimum cost partial digraph such that: (i) each vertexj ≠r has exactly one entering arc; (ii) for each vertexj ≠r, a path fromr toj exists; (iii) for each branch leaving vertexr, the total demand of the vertices does not exceed the branch capacity,Q. A variant of theCSSAr problem (calledD-CSSAr) arises when the out-degree of the root vertex is constrained to be equal to a given valueD. These problems are strongly NP-hard, and find practical applications in routing and network design. We describe a new Lagrangian lower bound forCSSAr andD-CSSAr problems, strengthened in a cutting plane fashion by iteratively adding violated constraints to the Lagrangian problem. We also present a new lower bound based on projection leading to the solution of min-cost flow problems. The two lower bounds are then combined so as to obtain an overall additive lower bounding procedure. The additive procedure is then imbedded in a branch-and-bound algorithm whose performance is enhanced by means of reduction procedures, dominance criteria, feasibility checks and upper bounding. Computational tests on asymmetric and symmetric instances from the literature, involving up to 200 vertices, are given, showing the effectiveness of the proposed approach.		Paolo Toth;Daniele Vigo	1995	Annals OR	10.1007/BF02098285	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;upper and lower bounds;branch and bound	Theory	23.108379947271942	16.80607871453108	75592
fdda4952625071ccbc48dd0d455c07007016b0be	optimal positioning of a mobile service unit on a line	location;patrolling;facilities planning and design;optimization problem;mobile service;linear time;random variable;probability measure;stochastic location	In this paper we address the problem of locating a mobile response unit when demand is distributed according to a random variable on a line. Properties are proven which reduce the problem to locating a non-mobile facility, transforming the original optimization problem into an one-dimensional convex program. In the special case of a discrete demand (a simple probability measure), an algorithm which runs in expected linear time is proposed.	algorithm;convex optimization;global positioning system;mathematical optimization;optimization problem;time complexity	Emilio Carrizosa;Manuel Muñoz-Márquez;Justo Puerto	2002	Annals OR	10.1023/A:1020993417646	time complexity;random variable;optimization problem;mathematical optimization;patrolling;simulation;probability measure;operations management;mathematics;location;1-center problem;statistics	Robotics	16.54908061816928	4.461910123057517	75638
16366dfb8741c41933ed7ed45096627736c7b974	a logarithmic method for reducing binary variables and inequality constraints in solving task assignment problems	mixed integer programming problem;binary variables;task assignment problem;article	This paper studies the classical task assignment problem TAP in which M unbreakable tasks are assigned to N agents with the objective to minimize the communication and process costs subject to each agent's capacity constraint. Because a large-size TAP involves many binary variables, most, if not all, traditional methods experience the difficulty in solving the problem within a reasonable time period. Recent works present a logarithmic approach to reduce the number of binary variables in problems with mixed-integer variables. This study proposes a new logarithmic method that significantly reduces the numbers of binary variables and inequality constraints in solving task assignment problems. Our numerical experiments demonstrate that the proposed method is superior to other known methods of this kind for solving large-size TAPs.	social inequality	Han-Lin Li;Yao-Huei Huang;Shu-Cherng Fang	2013	INFORMS Journal on Computing	10.1287/ijoc.1120.0527	mathematical optimization;combinatorics;generalized assignment problem;mathematics;algorithm	HPC	16.684964555516697	7.683733872194525	76152
c3b47833fd2cc77569903afed15c75a19c00213a	a dynamic approach to multi-stage job shop scheduling in an industry 4.0-based flexible assembly system		Industry 4.0 technology is based on the concepts of flexibility and dynamic assembly system design. This enables new production strategies and creates new challenges for job shop scheduling. In particular, manufacturing processes for different customer orders may have individual machine structures whereas the flexible stations are able to execute different functions subject to individual sets of operations within the jobs. This study develops a control approach to job shop scheduling in a customized manufacturing process and job sequencing of operations within the jobs. The developed approach presents a contribution to flexible distributed scheduling in the emerging field of Industry 4.0-based innovative production systems.	algorithm;control theory;industry 4.0;job scheduler;job shop scheduling;job stream;optimal control;scheduling (computing);stationary process;systems design;type system	Dmitry A. Ivanov;Alexandre Dolgui;Boris V. Sokolov	2017		10.1007/978-3-319-66923-6_56	operations management;job shop scheduling;systems design;scheduling (computing);industry 4.0;new production;computer science;flow shop scheduling	Robotics	10.67726780150894	4.7174232164962335	76277
0cc5ff6fe380899fb1c1451f2e30ec0e42ab2c52	an extension to the single bottleneck transportation problem	optimal solution;solution optimale;problema transporte;transportation problem;gollete estrangulamiento;probleme transport;heuristic method;algoritmo recursivo;metodo heuristico;goulot etranglement;algorithme recursif;solucion optima;recursive algorithm;methode heuristique;bottleneck	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source;transportation theory (mathematics)	Jianshe Dai;Dawei Li;Yi Liao;Fei Zhu	1996	Int. J. Systems Science	10.1080/00207729608929252	transportation theory;mathematical optimization;computer science;mathematics;operations research;algorithm;recursion	Robotics	12.041158143546097	10.20985191575208	76332
eee6f94e7c36edb42418205d44420729862f7182	a fully polynomial approximation scheme for a scheduling problem with intree-type precedence delays	tiempo total acabamiento;temps polynomial;single machine scheduling;methode approchee;temps total achevement;metodo aproximado;temps minimal;approximate method;constrenimiento precedencia;makespan;precedence constraints;minimum delays;scheduling;polynomial algorithm;retard;polynomial time;precedence constraint;minimum time;contrainte precedence;scheduling problem;ordonamiento;retraso;tiempo minimo;ordonnancement;polynomial approximation;tiempo polinomial	We investigate a single-machine scheduling problem with precedence delays that have a simple structure: the corresponding tree has k leaves and only k + 2 nodes. The objective is to minimize the makespan. We present a pseudo-polynomial algorithm for this problem, and we also give a fully polynomial approximation scheme. c © 1998 Elsevier Science B.V. All rights reserved.	algorithm;makespan;polynomial;polynomial-time approximation scheme;scheduling (computing);single-machine scheduling	Petra Schuurman	1998	Oper. Res. Lett.	10.1016/S0167-6377(98)00012-1	time complexity;job shop scheduling;mathematical optimization;discrete mathematics;computer science;mathematics;scheduling;algorithm	AI	17.30438506810633	10.460191940955552	76600
77de6ccd8e7a9e395a2aaef5c5dc494b10fc1810	propagating the bin packing constraint using linear programming	bin packing problem;bin packing;global constraint;linear program	The state-of-the-art global constraint for bin packing is due to Shaw. We compare two linear continuous relaxations of the bin packing problem, based on the DP-flow and Arc-flow models, with the filtering of the bin packing constraint. Our experiments show that we often obtain significant improvements in runtime. The DP-flow model is a novel formulation of the problem.	bin packing problem;constraint programming;continuous knapsack problem;experiment;graph reduction;image scaling;linear programming;run time (program lifecycle phase);set packing;software propagation;time complexity	Hadrien Cambazard;Barry O'Sullivan	2010		10.1007/978-3-642-15396-9_13	mathematical optimization;combinatorics;discrete mathematics;bin packing problem;set packing;computer science;linear programming;mathematics;bin	AI	20.22508526900924	9.365721865526627	76808
324ed467fef7d235ac0c3c7209b11bb31b863bc9	solving simple planning problems with more inference and no search	temps polynomial;planification optimale;planning artificial intelligence;constraint satisfaction;planification intelligence artificielle;resolucion problema;satisfaction contrainte;polynomial time;optimal planning;satisfaccion restriccion;planificacion optima;ai planning;problem solving;resolution probleme;tiempo polinomial	Many problems used in AI planning including Blocks, Logistics, Gripper, Satellite, and others lack the interactions that characterize puzzles and can be solved nonoptimally in low polynomial time. They are indeed easy problems for people, although as with many other problems in AI, not always easy for machines. In this work, we study the type of inferences that are required in a domain-independent planner for solving simple problems such as these in a backtrack-free manner by performing polynomial node operations. For this, we make use of the optimal temporal planner CPT which combines a POCL branching scheme with strong inference mechanisms, and show that a few simple and general additional inference mechanisms suffice to render the search over various domains backtrack free. This is an interesting empirical finding, we believe, that may contribute to the development of more robust automated planners, and to a better understanding of human planning. Significant performance gains in relation to CPT are also reported.	automated planning and scheduling;backtrack;backtracking;cpt (file format);interaction;logistics;polynomial;robot end effector;time complexity	Vincent Vidal;Hector Geffner	2005		10.1007/11564751_50	automated planning and scheduling;time complexity;mathematical optimization;constraint satisfaction;computer science;artificial intelligence;machine learning;mathematics;algorithm	AI	12.689349081727	15.527597070215288	76995
fde2911502592e259e6d4e303856b48c04fb8dc0	genetic algorithms for a two-agent single-machine problem with release time	two agent;single machine;scheduling;total tardiness;release time;maximum tardiness;article	Scheduling with two competing agents has drawn a lot of attention lately. However, it is assumed that all the jobs are available in the beginning in most of the research. In this paper, we study a single-machine problem in which jobs have different release times. The objective is to minimize the total tardiness of jobs from the first agent given that the maximum tardiness of jobs from the second agent does not exceed an upper bound. Three genetic algorithms are proposed to obtain the near-optimal solutions. Computational results show that the branch-and-bound algorithm could solve most of the problems with 16 jobs within a eywords: cheduling otal tardiness wo-agent ingle-machine elease time reasonable amount of time. In addition, it shows that the performance of the combined genetic algorithm is very good with mean error percentages of less than 0.2% for all the cases. © 2012 Elsevier B.V. All rights reserved.	branch and bound;computation;genetic algorithm;in the beginning... was the command line;job stream;scheduling (computing)	Wen-Chiung Lee;Yu-Hsiang Chung;Mei-Chia Hu	2012	Appl. Soft Comput.	10.1016/j.asoc.2012.06.015	mathematical optimization;real-time computing;computer science;scheduling	AI	15.190995229389387	8.3946682140025	76998
94b8de0f1c1e148e5cd59605908db6a88f18fce9	the rectilinear steiner tree problem with given topology and length restrictions		We consider the problem of embedding the Steiner points of a Steiner tree with given topology into the rectilinear plane. Thereby, the length of the path between a distinguished terminal and each other terminal must not exceed given length restrictions. We want to minimize the total length of the tree. The problem can be formulated as a linear program and therefore it is solvable in polynomial time. In this paper we analyze the structure of feasible embeddings and give a combinatorial polynomial time algorithm for the problem. Our algorithm combines a dynamic programming approach and binary search and relies on the total unimodularity of a matrix appearing in a sub-problem.	binary search algorithm;computer terminal;decision problem;dynamic programming;linear programming;p (complexity);rectilinear steiner tree;regular grid;steiner tree problem;time complexity	Jens Maßberg	2015		10.1007/978-3-319-21398-9_35	mathematical optimization;combinatorics;discrete mathematics;steiner tree problem;mathematics	Theory	23.234723831076774	14.125015538573921	77185
13abc3797a81426c4f6232a7a1b01ce798b46f6f	mini-bucket elimination with bucket propagation	optimisation sous contrainte;constrained optimization;constrenimiento flexible;valor elevado;bucket elimination;eliminacion;execution time;best approximation;approximation method;metodo combinatorio;combinatorial optimization problem;optimization method;methode combinatoire;soft constraints;valeur elevee;space time;constraint satisfaction;espacio tiempo;metodo optimizacion;optimisation combinatoire;optimizacion con restriccion;combinatorial problem;satisfaction contrainte;temps calcul;probleme combinatoire;soft constraint;problema combinatorio;methode approximation;mathematical programming;scheduling;subasta;borne inferieure;delai d execution;methode optimisation;bidding;mejor aproximacion;high value;temps execution;combinatorial method;plazo ejecucion;contrainte souple;constraint satisfaction problem;enchere;satisfaccion restriccion;elimination;tiempo computacion;computation time;tiempo ejecucion;combinatorial optimization;programmation mathematique;programacion matematica;ordonnancement;espace temps;lower bound;time allowed;reglamento;cota inferior;optimizacion combinatoria;meilleure approximation;combinatorial auction	Many important combinatorial optimization problems can be expressed as constraint satisfaction problems with soft constraints. When problems are too difficult to be solved exactly, approximation methods become the best option. Mini-bucket Elimination (MBE) is a well known approximation method for combinatorial optimization problems. It has a control parameter z that allow us to trade time and space for accuracy. In practice, it is the space and not the time that limits the execution with high values of z. In this paper we introduce a new propagation phase that MBE should execute at each bucket. The purpose of this propagation is to jointly process as much information as possible. As a consequence, the undesirable lose of accuracy caused by MBE when splitting functions into different mini-buckets is minimized. We demonstrate our approach in scheduling, combinatorial auction and max-clique problems, where the resulting algorithm MBE gives important percentage increments of the lower bound (typically 50% and up to 1566%) with only doubling the cpu time.	approximation algorithm;asymptote;central processing unit;clique problem;combinatorial optimization;computation tree;constraint satisfaction problem;dspace;depth-first search;interval propagation;local consistency;mathematical optimization;period-doubling bifurcation;scheduling (computing);software propagation	Emma Rollon;Javier Larrosa	2006		10.1007/11889205_35	mathematical optimization;constrained optimization;combinatorial auction;bidding;constraint satisfaction;combinatorial optimization;computer science;artificial intelligence;space time;mathematics;upper and lower bounds;scheduling;constraint satisfaction problem;algorithm;elimination	Theory	18.030833180912484	9.315586975304202	77266
7c820cd1906439c369cf21325556043e55fb6c4d	applying max-sum to asymmetric distributed constraint optimization		We study the adjustment and use of the Max-sum algorithm for solving Asymmetric Distributed Constraint Optimization Problems (ADCOPs). First, we formalize asymmetric factor-graphs and apply the different versions of Max-sum to them. Apparently, in contrast to local search algorithms, most Max-sum versions perform similarly when solving symmetric and asymmetric problems and some even perform better on asymmetric problems. Second, we prove that the convergence properties of Max-sum ADVP (an algorithm that was previously found to outperform other Max-sum versions) and the quality of the solutions it produces are dependent on the order between nodes involved in each constraint, i.e., the inner constraint order (ICO). A standard ICO allows to reproduce the properties achieved for symmetric problems, and outperform previously proposed local search ADCOP algorithms. Third, we demonstrate that a non-standard ICO can be used to balance exploration and exploitation, resulting in the best performing Maxsum version on both symmetric and asymmetric standard benchmarks.	benchmark (computing);breadth-first search;constraint logic programming;converge;distributed constraint optimization;factor graph;ico;local search (optimization);search algorithm;software propagation	Roie Zivan;Tomer Parash;Yarden Naveh	2015			mathematical optimization;theoretical computer science;mathematics;algorithm	AI	22.306679266021856	4.557744389744407	77453
d2097a85d556471f3cfdc9528d79e040f7063abc	a computer-based nurse scheduling system		Abstract   This paper describes a computer-based system for scheduling nurses in a St. Louis hospital. List processing and problem oriented data structures provided a flexible framework for the development of a heuristic which considers a complicated set of constraints when generating monthly shift schedules. The scheduling system covers several staff categories (supervisors, RN's, LPN's, AIDES, secretaries), considers individual preferences for shifts and days off, includes part-time employees, accommodates special requests for days off or particular shift assignments, and provides a convenient interface for the scheduling clerks who make final adjustments to the computer-generated schedules.	nurse scheduling problem;scheduling (computing)	L. Douglas Smith;A. Wiggins	1977	Computers & OR	10.1016/0305-0548(77)90015-6	nurse scheduling problem;real-time computing;simulation;computer science	Robotics	14.204984185493583	8.797709771493707	77515
2dcc70d0ec71f0f8355f6f0a6e7affc15e4435c7	optimal fuzzy counterparts of scheduling rules	fuzzy dominance;ranking of fuzzy numbers;fuzzy scheduling;earliest fuzzy due date;numero difuso;incertidumbre;uncertainty;fuzzy number;rangement;logique floue;nombre flou;logica difusa;date echeance;dominance flou;processing time;fuzzy logic;shortest processing time;ranking;mathematical programming;optimal scheduling;scheduling;ordonnancement flou;probability theory;due date;temps traitement;fecha vencimiento;earliest due date;ordonamiento;incertitude;ordenamiento;optimalite flou;fuzzy rule;regle floue;tiempo proceso;fuzzy optimization;shortest fuzzy processing time;ordonnancement	The optimality of a fuzzy logic alternative to the usual treatment of uncertainties in a scheduling system using probability theory is examined formally. Fuzzy scheduling techniques proposed in the literature either fuzzify directly the existing scheduling rules, or solve mathematical programming problems to determine the optimal schedules. In the former method, the fuzzy optimality for the optimal scheduling rules is usually not justi®ed but still assumed. In this paper, the necessary conditions for fuzzy optimality are de®ned, and fuzzy counterparts of some of the well-known scheduling rules such as shortest processing time (SPT) and earliest due date (EDD) are developed. Ó 1999 Elsevier Science B.V. All rights reserved.	fuzzy logic;hall-effect thruster;mathematical optimization;schedule (computer science);scheduling (computing);single-machine scheduling;whole earth 'lectronic link	Ertunga C. Özelkan;Lucien Duckstein	1999	European Journal of Operational Research	10.1016/S0377-2217(97)00445-1	fuzzy logic;fair-share scheduling;probability theory;mathematical optimization;uncertainty;defuzzification;dynamic priority scheduling;adaptive neuro fuzzy inference system;ranking;type-2 fuzzy sets and systems;computer science;rate-monotonic scheduling;fuzzy number;machine learning;mathematics;fuzzy associative matrix;lottery scheduling;round-robin scheduling;scheduling;fuzzy set operations;algorithm;statistics	AI	17.988140455802796	9.361723690613786	77588
2d95dbb75987827b974b9aadb2611ca93b692c4d	online scheduling with rejection and reordering: exact algorithms for unit size jobs	unit job;scheduling with rejection;reordering buffers	We study an online scheduling problem with rejection on $$m\ge 2$$ identical machines, in which we deal with unit size jobs. Each arriving job has a rejection value (a rejection cost or penalty for minimization problems, and a rejection profit for maximization problems) associated with it. A buffer of size $$K$$ is available to store $$K$$ jobs. A job which is not stored in the buffer must be either assigned to a machine or rejected. Upon the arrival of a new job, the job can be stored in the buffer if there is a free slot (possibly created by evicting other jobs and assigning or rejecting every evicted job). At termination, the buffer must be emptied. We study four variants of the problem, as follows. We study the makespan minimization problem, where the goal is to minimize the sum of the makespan and the penalty of rejected jobs, and the $$\ell _p$$ norm minimization problem, where the goal is to minimize the sum of the $$\ell _p$$ norm of the vector of machine completion times and the penalty of rejected jobs. We also study two maximization problems, where the goal in the first version is to maximize the sum of the minimum machine load (the cover value of the machines) and the total rejection profit, and in the second version the goal is to maximize a function of the machine completion times (which measures the balance of machine loads) and the total rejection profit. We show that an optimal solution (an exact solution for the offline problem) can always be obtained in this environment, and determine the required buffer size. Specifically, for all four variants we present optimal algorithms with $$K=m-1$$ and prove that in each case, using a buffer of size at most $$m-2$$ does not allow the design of an optimal algorithm, which makes our algorithms optimal in this respect as well. The lower bounds hold even for the special case where the rejection value is equal for all input jobs.	algorithm;job stream;rejection sampling;scheduling (computing)	Leah Epstein;Hanan Zebedat-Haider	2014	J. Comb. Optim.	10.1007/s10878-012-9593-5	mathematical optimization;real-time computing;computer science	Theory	14.928177852030704	11.06183261368438	77737
6afcb3ec2ad215b031f7b71bf1040965de00c556	2-medians in trees with pos/neg weights	arbre graphe;optimal solution;location theory;location problem;theorie localisation;solution optimale;probleme localisation;tree graph;temps lineaire;tiempo lineal;algorithme;objective function;algorithm;combinatorial problem;probleme combinatoire;problema combinatorio;minimum distance;mathematical programming;teoria localizacion;solucion optima;linear time;median problem;facility location problem;probleme mediane;location problems;problema localizacion;p median problem;arbol grafo;obnoxious facilities;programmation mathematique;programacion matematica;algoritmo	This paper deals with facility location problems with pos=neg weights in trees. We consider two di erent objective functions which model two di erent ways to handle obnoxious facilities. If we minimize the overall sum of the minimum weighted distances of the vertices from the facilities, the optimal solution has nice combinatorial properties, e.g., vertex optimality. For the pos=neg 2-median problem on a network with n vertices, these properties can be exploited to derive an O(n) algorithm for trees, an O(n log n) algorithm for stars and a linear algorithm for paths. For the p-median problem with pos=neg weights on a path we give an O(pn) algorithm. If we minimize the overall sum of the weighted minimum distances of the vertices from the facilities, we can show that there exists a nite set of O(n) points in the tree which contains the locations of facilities in an optimal solution. This leads to an O(n) algorithm for nding the optimum 2-medians in a tree. The complexity can be reduced to O(n), if the medians are restricted to vertices or if the tree is a path. ? 2000 Elsevier Science B.V. All rights reserved.	algorithm;point of sale;vertex (geometry);vertex (graph theory)	Rainer E. Burkard;Eranda Çela;Helidon Dollani	2000	Discrete Applied Mathematics	10.1016/S0166-218X(00)00177-3	time complexity;mathematical optimization;combinatorics;location theory;facility location problem;mathematics;tree;algorithm	Theory	22.56399386510895	13.912910343014383	77796
547ea0bcc1e99f2709a1aa6ac82fbe50d1d56236	"""a note on """"the capacitated lot-sizing and scheduling problem with sequence-dependent setup costs and setup times"""	modelizacion;tiempo iniciacion;disjunctive programming;lotsizing and scheduling;sequence dependent;machine unique;programmation disjonctive;temps mise en route;operations research;modelisation;set constraint;single machine;maquina unica;setup time;clsp;tamano lote;recherche operationnelle;taille lot;scheduling;constrenimiento conjunto;scheduling problem;lot sizing;contrainte ensembliste;setup carryover;modeling;programacion disyuntiva;investigacion operacional;ordonnancement;reglamento	Gupta and Magnusson [The capacitated lot-sizing and scheduling problem with sequence-dependent setup costs and setup times. Computers and Operations Research 2005;32(4):727-47] develop a model for the single machine capacitated lot-sizing and scheduling problem (CLSP) with sequence dependent setup times and setup costs, incorporating all the usual features of setup carryovers. In this note we show that this model does not avoid disconnected subtours. A new set of constraints is added to the model to provide an exact formulation for this problem.	scheduling (computing)	Bernardo Almada-Lobo;José Fernando Oliveira;Maria Antónia Carravilla	2008	Computers & OR	10.1016/j.cor.2006.08.019	job shop scheduling;mathematical optimization;real-time computing;systems modeling;computer science;mathematics;scheduling	Crypto	17.522564231896816	8.954808619689045	77960
76d285b43fd84f3e91437e3218f37240b353215d	on solving maximum and quickest interval-valued flows over time		Network flows over time (also called Dynamic Network Flows) are considered as generalized form of standard (static) networks by adding an element of time. The factor of transit time on the arcs which specify the amount of time it takes for one unit of the flows to pass through a particular arc, make these networks different to traditional form of networks. While in most of network flow problems, transit times and capacities are given constant, stochastic or Fuzzy numbers, in this paper we suppose that transit times, capacities and consequently flows on arcs fall within specific ranges expressed as compact intervals. This vagueness in transit times, capacities and flows could arise in a number of ways: 1) when determining the exact capacity or transit time quantities is hard and there may happen errors in determining them which intervals reflect the measurement errors; 2) when it is impossible or even it is not needed to produce neither a distribution nor fuzzy functions but transit times, capacities and flows lie within specific ranges, or vary in time within these ranges. While determining the exact time for traveling in specific path in network transportation system is extremely difficult or almost impossible, determination of interval which can describe the range of required time for travelling in the network would be easy and fully operational. Our contribution in this paper is producing maximum flow and quickest s − t flow algorithms, first to network flows over time with interval-valued capacities and then to T-length bounded network flows over time with interval-valued transit times and capacities.		Reza Rostami;Ali Ebrahimnejad	2016	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-151760	mathematical optimization;simulation;mathematics	Robotics	10.937048119287951	8.466184411927824	78042
0766b772910a3a84b566e7bd9d34be4f0196011e	efficient and effective practical algorithms for the set-covering problem	approximation solutions;np-hard;greedy algorithm;set-covering problem.;meta search engine;greedy heuristic;computational complexity;data structure;time complexity;search engine;set covering problem	The set-covering problem is an interesting problem in computational complexity theory. In [CLR91], the set-covering problem has been proved to be NP hard and a greedy heuristic algorithm is presented to solve the problem. In [DYWM06], the set-covering problem is found to be equivalent to the problem of identifying redundant search engines on the Web, and finding efficient and effective practical algorithms to the problem becomes a key issue in building a vary large-scale Web metasearch engine. A new algorithm Check-And-Remove (CAR) is proposed in [DYWM06] with a better time complexity than the greedy algorithm presented in [CLR91]. However, in some cases the cover set produced by the new algorithm is too large to be acceptable. We propose some changes to the data structure that improve the performance of both algorithms. We also present a new greedy algorithm whose time complexity is the same as that of the CAR algorithm. The experimental results show that our final greedy algorithm runs faster than the CAR algorithm and produces better results in all test cases.	computational complexity theory;covering problems;data structure;greedy algorithm;heuristic (computer science);np-hardness;set cover problem;test case;time complexity;web search engine;world wide web	Qi Yang;Jamie McPeek;Adam Nofsinger	2008			time complexity;computational problem;computer science;maximum coverage problem;computational complexity theory;greedy randomized adaptive search procedure;artificial intelligence;best-first search;algorithm;counting problem;mathematical optimization;machine learning;greedy algorithm	ML	23.771047655187555	4.34204453642364	78094
b0122e7432b10048c97ceb00fe47656a44961dc3	a generalized implicit enumeration algorithm for graph coloring	optimal solution;enumeration;metodologia;algorithm analysis;generic algorithm;complexite calcul;graph coloring;computing complexity;methodologie;coloration graphe;backtracking;analyse algorithme;methodology;graph coloration	A generalized algorithm for graph coloring by implicit enumeration is formulated. A number of backtracking sequential methods are discussed in terms of the generalized algorithm. Some are revealed to be partially correct and inexact. A few corrections to the invalid algorithms, which cause these algorithms to guarantee optimal solutions, are proposed. Finally, some computational results and remarks on the practical relevance of improved implicit enumeration algorithms are given.	algorithm;backtracking;computation;graph coloring;relevance	Marek Kubale;Boguslaw Jackowski	1985	Commun. ACM	10.1145/3341.3350	algebraic enumeration;combinatorics;discrete mathematics;graph enumeration;genetic algorithm;computer science;edge coloring;graph coloring;methodology;mathematics;voltage graph;enumeration;algorithm;backtracking	Graphics	14.021354197971677	17.915541447121836	78119
f0a373b7bff05eebeef6f148d9f42385d74a9604	arc-consistency for non-binary dynamic csps	arc consistency;artificial intelligent;dynamic environment;constraint satisfaction problem;incremental algorithm	Constraint satisfaction problems (CSPs) provide a model often used in Artificial Intelligence. Since the problem of the existence of a solution in a CSP is an NP-complete task, many filtering techniques have been developed for CSPs. The most used filtering techniques are those achieving arc-consistency. Nevertheless, many reasoning problems in AI need to be expressed in a dynamic environment and almost all the techniques already developed to solve CSPs deal only with static CSPs. So, in this paper, we first recall what we name a dynamic CSP, and then, generalize the incremental algorithm achieving arc-consistency on binary dynamic CSPs to general dynamic CSPs. Like for the binary version of this algorithm, there is an advantage to use our specific algorithm for dynamic CSPs instead of the best static one, GAC4.	algorithm;artificial intelligence;catherine;constraint satisfaction;local consistency;mycoplasma laboratorium	Christian Bessiere	1992			mathematical optimization;computer science;artificial intelligence;machine learning;constraint satisfaction problem;algorithm;hybrid algorithm;local consistency	AI	11.367730646487171	15.612855793931013	78184
6d277e43784fac5f9f35692995f916d9306bd403	car-sharing between two locations: online scheduling with two servers		In this paper, we consider an on-line scheduling problem that is motivated by applications such as car sharing, in which users submit ride requests, and the scheduler aims to accept requests of maximum total profit using two servers (cars). Each ride request specifies the pick-up time and the pick-up location (among two locations, with the other location being the destination). The length of the time interval between the submission of a request (booking time) and the pick-up time is fixed. The scheduler has to decide whether or not to accept a request immediately at the time when the request is submitted. We present lower bounds on the competitive ratio for this problem and propose a smart greedy algorithm that achieves the best possible competitive ratio. 2012 ACM Subject Classification Theory of computation → Online algorithms	competitive analysis (online algorithm);greedy algorithm;online and offline;scheduling (computing);theory of computation;uptime	Kelin Luo;Thomas Erlebach;Yin-Feng Xu	2018		10.4230/LIPIcs.MFCS.2018.50	discrete mathematics;competitive analysis;scheduling (computing);computer science;job shop scheduling;computer network;server;greedy algorithm	Theory	13.958452612948491	10.543217597074817	78238
d032bc89fc7d05a3fb687f986517bdb7771401fc	new results about lcgp, a least committed graphplan		"""Planners from the family of Graphplan (Graphplan, IPP, STAN...) are presently considered as the most efficient ones on numerous planning domains. Their partially ordered plans can be represented as sequences of sets of simultaneous actions. Using this representation and the criterion of independence, Graphplan constrains the choice of actions in such sets. We demonstrate that this criterion can be partially relaxed in order to produce valid plans in the sense of Graphplan. Our planner LCGP needs fewer levels than Graphplan to generate these plans (the same number in the worst cases). Then we present an experimental study which demonstrates that, in classical planning domains, LCGP """"practically"""" solves more problems than planners from the family of Graphplan (Graphplan, IPP, STAN...). In most cases, these tests demonstrate the best performances of LCGP. Then, we present a domain-independent heuristic for variable and domain ordering. LCGP is thus improved using this heuristic, and compared with HSP-R, a very efficient non-optimal sequential planner, based on an heuristic backward state space search."""	experiment;global serializability;graphplan;heuristic;hosted service provider;performance;state space search	Michel Cayrol;Pierre Régnier;Vincent Vidal	2000			state space search;graphplan;heuristic;mathematical optimization;mathematics	AI	21.30436463128608	4.544203772695639	78411
f07f7926bf544f4b90f7c432f3b16d3a9407f9b7	the inapproximability of non np-hard optimization problems	vertex cover;dominating set;optimization problem;np hard problem;polynomial time	The inapproximability of non NP-hard optimization problems is investigated. Techniques are given to show that problems Log Dominating Set and Log Hypergraph Vertex Cover cannot be approximated to a constant ratio in polynomial time unless the corresponding NP-hard versions are also approximable in deterministic subexponential time. A direct connection is established between non NP-hard problems and a PCP characterization of NP. Reductions from the PCP characterization show that Log Clique is not approximable in polynomial time and Max Sparse SAT does not have a PTAS under the assumption that SAT cannot be solved in deterministic 2 O(logn p n) time and that NP 6 6 DTIME(2 o(n)). A number of non-trivial approximation-preserving reductions are also presented, making it possible to extend inapproximability results to more natural non NP-hard problems such as Tournament Dominating Set and Rich Hypergraph Vertex Cover.	approximation algorithm;dominating set;hardness of approximation;mathematical optimization;np (complexity);np-hardness;pcp theorem;ptas reduction;polynomial;program optimization;sparse;time complexity;vertex cover	Liming Cai;David W. Juedes;Iyad A. Kanj	1998		10.1007/3-540-49381-6_46	time complexity;optimization problem;mathematical optimization;combinatorics;discrete mathematics;dominating set;vertex cover;computer science;np-hard;mathematics;algorithm	Theory	21.21386773710937	17.23781368255092	78489
00f0ca121a677446b683a1a3db5504754ea08089	optimal stochastic single-machine-tardiness scheduling by stochastic branch-and-bound	optimal solution;optimisation;estimacion;solution optimale;stochastic process;optimizacion;lower and upper bound;machine unique;branch and bound method;single machine;maquina unica;estimation;metodo branch and bound;scheduling;solucion optima;scheduling theory;processus stochastique;borne inferieure;single machine tardiness problem;ordonamiento;optimization;methode separation et evaluation;stochastic scheduling;proceso estocastico;branch and bound;ordonnancement;lower bound;cota inferior	"""A stochastic branch{and{bound technique for the solution of stochastic single{machine tardiness problems with job weights is presented. The technique relies on partitioning the solution space and estimating lower and upper bounds by sampling. For the lower bound estimation, two diierent types of sampling (\within"""" and \without"""" the minimization) are combined. Convergence to the optimal solution (with probability one) can be demonstrated. The approach is generalizable to other discrete stochastic optimization problems. In computational experiments with the single{ machine tardiness problem, the technique worked well for problem instances with a relatively small number of jobs; due to the enormous complexity of the problem, only approximate solutions can be expected for a larger number of jobs. Furthermore, a general precedence rule for the single{machine scheduling of jobs with uncertain processing times has been derived, essentially saying that \safe"""" jobs are to be scheduled before \unsafe"""" jobs."""	approximation algorithm;branch and bound;central processing unit;complexity;computation;experiment;feasible region;heuristic;job stream;mathematical optimization;np-hardness;order of operations;sampling (signal processing);scheduling (computing);single-machine scheduling;stochastic optimization	Walter J. Gutjahr;A. Hellmayr;Georg Ch. Pflug	1999	European Journal of Operational Research	10.1016/S0377-2217(98)00279-3	stochastic process;mathematical optimization;estimation;operations management;mathematics;upper and lower bounds;scheduling;branch and bound;algorithm;statistics	ML	17.319542856219364	9.943342641306018	78564
cfb0960687ba0e250c8dd3665243b49b2112488a	approximating the single source unsplittable min-cost flow problem	graph theory;teoria grafo;approximate algorithm;routing;probleme np complet;approximation algorithm;05c38;virtual circuit;routage;theorie graphe;optimisation combinatoire;unsplittable flow;multi commodity flow;flujo red;article multiple;mathematical programming;90b10;05c85;algoritmo aproximacion;90c35;multiple item;problema np completo;partitionnement;load balance;network flow;key words approximation algorithm multi commodity flow network flow routing unsplittable flow mathematics subject classification 1991 90c27;algorithme approximation;combinatorial optimization;hardness of approximation;programmation mathematique;programacion matematica;flot reseau;np complete problem;optimizacion combinatoria;enrutamiento	In the single source unsplittable min-cost flow problem, commodities must be routed simultaneously from a common source vertex to certain destination vertices in a given graph with edge capacities and costs; the demand of each commodity must be routed along a single path so that the total flow through any edge is at most its capacity. Moreover, the total cost must not exceed a given budget. This problem has been introduced by Kleinberg [7] and generalizes several NP-complete problems from various areas in combinatorial optimization such as packing, partitioning, scheduling, load balancing, and virtual-circuit routing. Kolliopoulos and Stein [9] and Dinitz, Garg, and Goemans [4] developed algorithms improving the first approximation results of Kleinberg for the problem of minimizing the violation of edge capacities and for other variants. However, known techniques do not seem to be capable of providing solutions without also violating the cost constraint. We give the first approximation results with hard cost constraints. Moreover, all our results dominate the best known bicriteria approximations. Finally, we provide results on the hardness of approximation for several variants of the problem.	algorithm;combinatorial optimization;flow network;hardness of approximation;karp's 21 np-complete problems;load balancing (computing);mathematical optimization;maxima and minima;minimum-cost flow problem;order of approximation;routing;scheduling (computing);set packing;virtual circuit	Martin Skutella	2002	Math. Program.	10.1007/s101070100260	mathematical optimization;routing;combinatorics;flow network;np-complete;combinatorial optimization;graph theory;load balancing;mathematics;virtual circuit;hardness of approximation;approximation algorithm;algorithm	Theory	21.22929255908109	12.937246499620278	78802
19c26bb21c0ca9b1c4bc30d12192131494c70f00	finding optimal bayesian networks using precedence constraints	structure learning;control engineering;reglerteknik;exact algorithm;parallelization;datavetenskap datalogi;space time tradeoff;computer science;partial order	We consider the problem of finding a directed acyclic graph (DAG) that optimizes a decomposable Bayesian network score. While in a favorable case an optimal DAG can be found in polynomial time, in the worst case the fastest known algorithms rely on dynamic programming across the node subsets, taking time and space 2n, to within a factor polynomial in the number of nodes n. In practice, these algorithms are feasible to networks of at most around 30 nodes, mainly due to the large space requirement. Here, we generalize the dynamic programming approach to enhance its feasibility in three dimensions: first, the user may trade space against time; second, the proposed algorithms easily and efficiently parallelize onto thousands of processors; third, the algorithms can exploit any prior knowledge about the precedence relation on the nodes. Underlying all these results is the key observation that, given a partial order P on the nodes, an optimal DAG compatible with P can be found in time and space roughly proportional to the number of ideals of P , which can be significantly less than 2n. Considering sufficiently many carefully chosen partial orders guarantees that a globally optimal DAG will be found. Aside from the generic scheme, we present and analyze concrete tradeoff schemes based on parallel bucket orders.	algorithm;bayesian network;best, worst and average case;central processing unit;directed acyclic graph;dynamic programming;fastest;maxima and minima;polynomial;time complexity	Pekka Parviainen;Mikko Koivisto	2013	Journal of Machine Learning Research		partially ordered set;mathematical optimization;combinatorics;discrete mathematics;computer science;machine learning;mathematics;space–time tradeoff	ML	17.870346466171316	15.931008339917202	78818
97553157746a9ae4718cb84ad8a391c96fe51ae8	a branch-and-bound algorithm for concave network flow problems	dynamic programming;optimal solution;branch and bound algorithm;state space relaxation;dynamic program;state space;global optimization;network flow;branch and bound;concave network flows;lower bound	In this paper a Branch-and-Bound (BB) algorithm is developed to obtain an optimal solution to the single source uncapacitated minimum cost Network Flow Problem (NFP) with general concave costs. Concave NFPs are NP-Hard, even for the simplest version therefore, there is a scarcity of exact methods to address them in their full generality. The BB algorithm presented here can be used to solve optimally single source uncapacitated minimum cost NFPs with any kind of concave arc costs. The bounding is based on the computation of lower bounds derived from state space relaxations of a dynamic programming formulation. The relaxations, which are the subject of the paper (Fontes et al., 2005b) and also briefly discussed here, involve the use of non-injective mapping functions, which guarantee a reduction on the cardinality of the state space. Branching is performed by either fixing an arc as part of the final solution or by removing it from the final solution. Computational results are reported and compared to available alternative methods for addressing the same type of problems. It could be concluded that our BB algorithm has better performance and the results have also shown evidence that it has a sub-exponential time growth.	algorithm;branch and bound;concave function;flow network	Dalila B. M. M. Fontes;Eleni Hadjiconstantinou;Nicos Christofides	2006	J. Global Optimization	10.1007/s10898-005-1658-x	mathematical optimization;combinatorics;mathematics;branch and bound;algorithm;global optimization	Theory	21.857568874349194	10.44007068386381	78912
4ac575c4a88c521f4a35e81666802f07ee6d1d2f	handling critical jobs online: deadline scheduling and convex-body chasing		Completing possibly unforeseen tasks in a timely manner is vital for many real-world problems: For instance, in hospitals, emergency patients may come in and require to be treated, or self-driving cars need to avoid obstacles appearing on the street. Under the hard constraint of timely fulfilling these tasks, one still usually wishes to use resources conscientiously. We consider the above applications in the form of two fundamental mathematical problems. First, in online deadline scheduling, jobs arrive over time and need to scheduled on a machine until their deadline. Second, in convex-body chasing, an agent needs to immediately serve tasks located within convex regions and minimize the total travelled distance. In this paper we review the main results we obtained in the thesis of the same title: We present various novel online algorithms and techniques for analyzing them. Thereby we improve upon previously known bounds.	scheduling (computing)	Kevin Schewior	2016		10.1007/978-3-319-89920-6_4	mathematical problem;competitive analysis;online algorithm;mathematics;mathematical optimization;real-time computing;scheduling (computing);convex body;online optimization	Theory	13.576358334137463	10.037239809773608	79003
1210eb646783e5c9586e4a0bbbc6e69af303e5e4	an improved pseudo-polynomial upper bound for the value problem and optimal strategy synthesis in mean payoff games		In this work we offer an O(|V |2|E|W ) pseudo-polynomial time deterministic algorithm for solving the Value Problem and Optimal Strategy Synthesis in Mean Payoff Games. This improves by a factor log(|V |W ) the best previously known pseudo-polynomial time upper bound due to Brim, et al. The improvement hinges on a suitable characterization of values, and a description of optimal positional strategies, in terms of reweighted Energy Games and Small Energy-Progress Measures.	computation;computational mathematics;computer science;deterministic algorithm;linear algebra;polynomial;pseudo-polynomial time;time complexity	Carlo Comin;Romeo Rizzi	2015	CoRR			Logic	17.553806839506617	17.106039018167685	79065
6a1297c080f8d1eddc868d0acf0d18bcb6b8ee2e	local search for hamiltonian path with applications to clustering visitation paths	site web;forecasting;reliability;base donnee repartie;project management;distributed database;information systems;red www;2 opt;maintenance;probleme np complet;camino hamiltoniano;institute for integrated and intelligent systems;soft or;information technology;heuristic method;formation cellule;reseau web;packing;base repartida dato;metodo heuristico;bond energy algorithm bea;operations research;location;investment;journal;journal of the operational research society;inventory;busca local;purchasing;history of or;logistics;marketing;faculty of engineering and information technology;cell formation;scheduling;formacion celula;chemin hamiltonien;280213;production;communications technology;world wide web;problema np completo;cell formation problems;methode heuristique;computer science;operational research;sitio web;clustering a matrix of attributes;local search;recherche locale;web site;applications of operational research;or society;other artificial intelligence;np complete problem;jors;management science;infrastructure;hamiltonian path	Clustering a data array has been found useful in the design of web-sites and distributed database system. We show that a critical step during this clustering process is related to solving the Longest Hamiltonian Path Problem, a well known NP-complete problem. Using the grouping of visitation paths of web-users as a case study, we test several heuristic algorithms. As a result of our experiments, we identify a successful method for dealing with this problem. Our algorithm spends less CPU time and provides better quality solutions than the most recent approach.	cluster analysis;hamiltonian path;local search (optimization)	Rodolfo Torres-Velázquez;Vladimir Estivill-Castro	2004	JORS	10.1057/palgrave.jors.2601770	hamiltonian path;project management;correlation clustering;logistics;simulation;inventory;economics;forecasting;investment;computer science;local search;marketing;operations management;operating system;reliability;mathematics;cluster analysis;location;management;operations research;information technology;scheduling;distributed database	ML	18.155328077646974	5.533349365989275	79215
03d7ac4c4ecbe1dfea7ee9b3b1dda8190d0325f8	a refined view of causal graphs and component sizes: sp-closed graph classes and beyond	engineering and technology;teknik och teknologier	The causal graph of a planning instance is an important tool for planning both in practice and in theory. The theoretical studies of causal graphs have largely analysed the computational complexity of planning for instances where the causal graph has a certain structure, often in combination with other parameters like the domain size of the variables. Chen and Giménez ignored even the structure and considered only the size of the weakly connected components. They proved that planning is tractable if the components are bounded by a constant and otherwise intractable. Their intractability result was, however, conditioned by an assumption from parameterised complexity theory that has no known useful relationship with the standard complexity classes. We approach the same problem from the perspective of standard complexity classes, and prove that planning is NP-hard for classes with unbounded components under an additional restriction we refer to as SPclosed. We then argue that most NP-hardness theorems for causal graphs are difficult to apply and, thus, prove a more general result; even if the component sizes grow slowly and the class is not densely populated with graphs, planning still cannot be tractable unless the polynomial hierachy collapses. Both these results still hold when restricted to the class of acyclic causal graphs. We finally give a partial characterization of the borderline between NP-hard and NP-intermediate classes, giving further insight into the problem.	causal filter;causal graph;cobham's thesis;complexity class;computational complexity theory;connected component (graph theory);connectivity (graph theory);directed acyclic graph;entity–relationship model;np-hardness;np-intermediate;parameterized complexity;polynomial;population	Christer Bäckström;Peter Jonsson	2013	J. Artif. Intell. Res.	10.1613/jair.3968	combinatorics;discrete mathematics;computer science;artificial intelligence;machine learning;mathematics	ML	14.43467260028825	17.310392522096738	79240
35fe1bd9279f49cbebcd090c02db90e73014a003	robust airline crew pairing: move-up crews	modelizacion;flight crews;optimisation;decomposition;optimizacion;airline crew scheduling;pairing;air transportation;robust optimization;modelisation;transport aerien;transporte aereo;large scale;scheduling;robustesse;personal de navegacion;personnel navigant;robustness;crew;optimization;schedules and scheduling;economics;emparejamiento;descomposicion;escala grande;economies of scale;appariement;modeling;ordonnancement;reglamento;large scale optimization;robustez;echelle grande	Due to irregular operations, the crew cost at the end of a month is typically substantially higher than the projected crew cost in planning. We assume that the fleeting and the aircraft routing decisions have already been made. We present a model and a solution methodology that produces robust crew schedules in planning. Besides the objective of minimizing the crew cost, we introduce the objective of maximizing the number of move-up crews, i.e. the crews that can potentially be swapped in operations. To solve the resulting large-scale integer program, we use a combination of delayed column generation and Lagrangian relaxation. The restricted master problem is solved by means of Lagrangian relaxation and the “duals” of the restricted master problem, which are used in delayed column generation, correspond to the Lagrangian multipliers. We report computational experiments, which demonstrate benefits of using the robust crew schedule instead of the traditional one. We evaluate various crew schedules by generating random disruptions and then running a crew recovery module. We compare solutions with respect to the direct crew cost and indirect costs such uncovered legs, reserved crews, and deadheading. The main conclusion is that robustness leads to reduced operational crew cost, however, in planning the trade-off between the inflated direct crew cost and robustness needs to be exploited judicially.	cplex;column generation;edmund m. clarke;experiment;ibm notes;ilog;integer programming;lagrange multiplier;lagrangian relaxation;linear programming relaxation;paging;robustness (computer science);routing;schedule (computer science);software release life cycle	Sergey Shebalov;Diego Klabjan	2006	Transportation Science	10.1287/trsc.1050.0131	mathematical optimization;robust optimization;simulation;systems modeling;computer science;engineering;economies of scale;operations management;pairing;mathematics;decomposition;operations research;scheduling;robustness;aviation	AI	16.994031599830812	5.450758405392716	79366
c23f4e66dfbfc90a5c56331230ad907fd8afe862	a new heuristic branching scheme for the crew pairing problem with base constraints		Airline crew scheduling is typically performed in two steps : crew pairing followed by crew assignment. The crew pairing problem (CPP) finds a set of pairings (sequences of flights separated by connections or rests starting and ending at the same crew base) that covers a set of flights at minimum cost. The crew assignment problem consists of assigning the crew members to these pairings to create their individual schedules. The main downside of this sequential approach is that the pairings generated in the first step are not all suitable for the crew assignment step, yielding poor-quality solutions. This paper studies an extension of the CPP that includes additional constraints limiting the total worked time at each crew base. This problem, called the CPP with base constraints (CPPBC), is designed to improve the coupling of the two scheduling steps. To solve the CPPBC, we develop four branch-and-price heuristics: three of them rely on known heuristic branching schemes, the other introduces a new branching method, called retrospective branching. This branching scheme is designed to detect and revise poor branching decisions made earlier in the search tree, without backtracking. We tested and compared these four heuristics on real-world datasets. Our results show that the algorithm with retrospective branching yields, most of the times, better-quality solutions than the other tested methods.	heuristic	Frédéric Quesnel;Guy Desaulniers;François Soumis	2017	Computers & OR	10.1016/j.cor.2016.11.020	real-time computing;mathematics;algorithm	Crypto	15.876278818876333	4.598234428247812	79463
aacccc87b529ad0eaa7349b93c8efd882b0006a7	on the location of supply points to minimize transportation costs	transport costs	of locating supply points optimally with respect to transportation costs i s given. Although the algorithm may fail to converge to an optimal solution, repeated application with judicious selections of alternative starting values will assure a good, i f not optimal, solution. The algorithm has been tested and some sample results are included. The location of factories, warehouses-and supply points in general, to serve customers distributed over a network of cities-is often influenced by transportation costs. If transportation costs are uniform and linear with respect to distance, the total transportation cost is proportional to the sum of the distances from the supply points to the cities served, each weighted by the volume of shipments. To illustrate notation and terminology, a network is shown in Figure 1. The cities in a network will be labelled with subscripted ~i~~~~ 1 p's and referred to as points or nodes. The set of p's will be denoted by P. The distance along a path from a node pi to pi not passing through intervening nodes will be denoted by d i , and, of course d i. j = d. 1. I. and di. = 0. The shortest path from one node to another may pass through one or more intervening nodes-as in Figure 1 where the shortest path from p l to p3 passes through p,. If a direct path exists between a pair of nodes, it will be assumed to be unique, but there may be no direct path between nodes, and in such cases we will put d i , i = m for computational purposes. However, it will be a.ssumed that some path exists connecting every pair of nodes in the network. The demand or volume of shipments to be made to node pi ~ will be denoted by an associated weight wi. A node a t which a supply point is located will be called a source; a node having a demand to be satisfied will be referred to as a sink. We may wish .I to consider locating a source a t a city having no demand, and it will be convenient to assign a weight of zero to such cities in order that they may be treated formally as sinks rather than on an exception basis. Thus, in mathematical terms, we have the following problem. where D,.i is the minimal path length from p i to pi. …	algorithm;converge;reduction strategy (lambda calculus);shortest path problem	Francesco E. Maranzana	1963	IBM Systems Journal	10.1147/sj.22.0129	variable cost;mathematical optimization;computer science	AI	21.56369542341641	10.923677940510215	79531
5f4e95cdb5f868581b2f10c80cae78c579cff49b	a comparison of evolutionary approaches to the shortest common supersequence problem	circuit decodeur;prension;combinatorial optimization problem;chaine caractere;intelligence artificielle;gripping;circuito desciframiento;optimisation combinatoire;combinatorial problem;decoding circuit;probleme combinatoire;problema combinatorio;funcion penalidad;mathematical programming;biomimetique;cadena caracter;reparation;artificial intelligence;algorithme evolutionniste;prehension;algoritmo evolucionista;inteligencia artificial;evolutionary algorithm;fonction penalite;combinatorial optimization;reparacion;programmation mathematique;programacion matematica;repair;shortest common supersequence;character string;biomimetics;optimizacion combinatoria;penalty function	The Shortest Common Supersequence problem is a hard combinatorial optimization problem with numerous practical applications. Several evolutionary approaches are proposed for this problem, considering the utilization of penalty functions, GRASP-based decoders, or repairing mechanisms. An empirical comparison is conducted, using an extensive benchmark comprising problem instances of different size and structure. The empirical results indicate that there is no single best approach, and that the size of the alphabet, and the structure of strings are crucial factors for determining performance. Nevertheless, the repairbased EA seems to provide the best performance tradeoff.	adversary (cryptography);benchmark (computing);combinatorial optimization;grasp;heuristic (computer science);mathematical optimization;optimization problem;shortest common supersequence problem;string (computer science)	Carlos Cotta	2005		10.1007/11494669_7	biomimetics;shortest common supersequence;string;combinatorial optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;penalty method;mathematics;algorithm	AI	20.98825336229105	6.038366380631099	79618
0b709f312f1729ac77fae6a9cc89be8e1743f378	a combinatorial arc tolerance analysis for network flow problems	tolerance analysis;network flow	For the separable convex cost flow problem, we consider the problem of determining tolerance set for each arc cost function. For a given optimal flow x, a valid perturbation of ci j(x) is a convex function that can be substituted for ci j(x) in the total cost function without violating the optimality of x. Tolerance set for an arc(i, j) is the collection of all valid perturbations of ci j(x). We characterize the tolerance set for each arc(i, j) in terms of nonsingleton shortest distances between nodes i and j. We also give an efficient algorithm to compute the nonsingleton shortest distances between all pairs of nodes in O(n3) time where n denotes the number of nodes in the given graph.	algorithm;convex function;flow network;loss function	P. T. Sokkalingam;Prabha Sharma	2005	JAMDS	10.1155/JAMDS.2005.83	mathematical optimization;combinatorics;discrete mathematics;flow network;mathematics	Theory	23.380930526235975	16.949606966705815	79675
91de8e5037e2988862a294d8e6a3e3fe7261b435	linear programming, by ronald i. rothenberg, elsevier north holland, new york, 1979, 359pp. price: $24.95	linear program		linear programming	C. B. Millham	1983	Networks	10.1002/net.3230130222	mathematical optimization;computer science;linear programming;mathematics	Theory	23.51816638086094	9.153280316445361	79691
419412ad6ab22fd249bfc1af3d873cb6089de654	simulated annealing heuristics for the dynamic facility layout problem	costo materia;dynamic facility layout problem;heuristic method;layout problem;probleme agencement;look ahead;plant layout;metodo heuristico;simulated annealing;planning installation;recuit simule;material costs;materials handling;material flow;problema disposicion;facility layout;recocido simulado;heuristics;methode heuristique;look ahead back strategy;flux matiere;proyecto instalacion;cout matiere;manutention materiau;flujo materia	FOR THE DYNAMIC FACILITY LAYOUT PROBLEM Alan R. McKendall, Jr.* and Jin Shang Department of Industrial & Management Systems Engineering West Virginia University 325A Mineral Resources Building Morgantown, WV 26506, USA Saravanan Kuppusamy Schneider Logistics, Inc 3101 South Packerland Drive Greenbay, WI 54306-2666, USA Submitted 22 March 2004 Accepted 20 June 2004 Abstract In today’s economy, manufacturing plants must be able to operate efficiently and respond quickly to changes in product mix and demand. Therefore, this paper considers the problem of arranging and rearranging (when there are changes between the flows of materials between departments) manufacturing facilities such that sum of the material handling and rearrangement costs are minimized. This problem is known as the dynamic facility layout problem (DFLP). In this paper, two simulated annealing (SA) heuristics are developed for the DFLP. The first SA heuristic (called SA I) is a direct adaptation of SA to the DFLP. The second SA heuristic (called SA II) is the same as SA I with a look-ahead/look-back strategy added. To test the performance of the heuristics, a data set taken from the literature is used in the analysis. The results obtained show that the proposed heuristics are very effective for the dynamic facility layout problem.	heuristic (computer science);logistics;management system;material handling;simulated annealing;systems engineering	Alan R. McKendall;Jin Shang;Saravanan Kuppusamy	2006	Computers & OR	10.1016/j.cor.2005.02.021	mathematical optimization;simulation;simulated annealing;computer science;heuristics;mathematics;material flow	AI	18.481565043261586	5.2641514642873295	79793
4ed60d097a524f55a6d15003c1d0d568333a5f37	computational complexity of a cost allocation approach to a fixed cost spanning forest problem	fixed cost;graph theory;optimisation;teoria grafo;foret graphe;game theory;cost allocation;costo fijo;optimizacion;complexite calcul;complejidad calculo;game core;juego cooperativo;cout fixe;arbre maximal;noyau jeu;teoria juego;computing complexity;theorie jeu;theorie graphe;cooperative game;cooperative game approach;programacion lineal;arbol maximo;jeu cooperatif;computational complexity;linear programming;programmation lineaire;bosque grafo;optimization;nucleo juego;spanning tree;spanning forest;forest graph;graph optimization	We present a computational analysis of a game theoretic approach to a cost allocation problem arising from a graph optimization problem, referred to as the fixed cost spanning forest FCSF problem. The customers in the FCSF problem, represented by nodes in a graph G, are in need of service that can be produced at some facilities yet to be constructed. The cost allocation problem is concerned with the fair distribution of the cost of providing the service among customers. We formulate this cost allocation problem as a cooperative game, referred to as the FCSF game. In general, the core of a FCSF game may be empty. However, for the case when G is a tree, it is shown that the core is not empty. Moreover, we prove that in this case core points can be generated in strongly polynomial time. We further provide a nonredundant characterization of the core of the FCSF game defined over a tree in the special case when all nodes are communities. This is shown to lead, in some instances, to a strongly polynomial algorithm for computing the nucleolus.	computational complexity theory;spanning tree	Daniel Granot;Frieda Granot	1992	Math. Oper. Res.	10.1287/moor.17.4.765	game theory;mathematical optimization;combinatorics;spanning tree;linear programming;graph theory;mathematics;mathematical economics;computational complexity theory;algorithm;fixed cost	Theory	21.841946616350015	16.881356265005174	79842
7119ef1062dca2320a4d0b6689bc30778ef35f42	a new heuristic for the period traveling salesman problem	simulation ordinateur;traveling salesman problem;period;travelling salesman problem;heuristic method;periodo;metodo heuristico;algorithme;optimisation combinatoire;problema viajante comercio;algorithm;periode;probleme commis voyageur;simulacion computadora;methode heuristique;combinatorial optimization;computer simulation;optimizacion combinatoria;algoritmo	In this paper, a new heuristic for the period traveling salesman problem is presented. Our heuristic is fast and simple and has improved upon previous best-known solutions. In addition, we have generated a variety of challenging, new test problems. Our new heuristic is shown to perform well on these new problems.	heuristic;travelling salesman problem	I-Ming Chao;Bruce L. Golden;Edward A. Wasil	1995	Computers & OR	10.1016/0305-0548(94)00031-3	consistent heuristic;computer simulation;heuristic;traveling purchaser problem;null-move heuristic;2-opt;mathematical optimization;greedy algorithm;combinatorial optimization;computer science;lin–kernighan heuristic;artificial intelligence;mathematics;travelling salesman problem;algorithm;3-opt;bottleneck traveling salesman problem	EDA	20.47386702198519	6.554683416862917	79884
21a178ac80316dfea75b8de7e505a3fef60d3777	analysis of upper bounds for the pallet loading problem	pallet loading;packing;hb economic theory;upper bound;mathematical programming;linear programming relaxation;partial order	This paper is concerned with upper bounds for the well-known Pallet Loading Problem (PLP), which is the problem of packing identical boxes into a rectangular pallet so as to maximize the number of boxes ®tted. After giving a comprehensive review of the known upper bounds in the literature, we conduct a detailed analysis to determine which bounds dominate which others. The result is a ranking of the bounds in a partial order. It turns out that two of the bounds dominate all others: a bound due to Nelissen and a bound obtained from the linear programming relaxation of a set packing formulation. Experiments show that the latter is almost always optimal and can be computed quickly.	column generation;cutting stock problem;experiment;linear programming relaxation;pl/p;rounding;set packing;whole earth 'lectronic link	Adam N. Letchford;André R. S. Amaral	2001	European Journal of Operational Research	10.1016/S0377-2217(00)00163-6	partially ordered set;mathematical optimization;linear programming relaxation;operations management;mathematics;mathematical economics;upper and lower bounds	Theory	18.552469333494177	11.54626201080187	79890
b93def6b4c12fe40166274dd8a79dba493d5e8f2	decomposition-based classified ant colony optimization algorithm for scheduling semiconductor wafer fabrication system	decomposition;ant colony optimization;scheduling;semiconductor wafer fabrication system swfs;decomposition based classified aco d caco	Due to its typical features, such as large-scale, multiple re-entrant flows, and hybrid machine types, the semiconductor wafer fabrication system (SWFS) is extremely difficult to schedule. In order to cope with this difficulty, the decomposition-based classified ant colony optimization (D-CACO) method is proposed and analyzed in this paper. The D-CACO method comprises decomposition procedure and classified ant colony optimization algorithm. In the decomposition procedure, a large and complicate scheduling problem is decomposed into several subproblems and these subproblems are scheduled in sequence. The classified ACO algorithm then groups all of the operations of the subproblems and schedules them according to machine type. To test the effect of the method, a set of simulations are conducted on a virtual fab simulation platform. The test results show that the proposed D-CACO algorithm works efficiently in sched-	algorithm;ant colony optimization algorithms;mathematical optimization;scheduling (computing);semiconductor fabrication plant;simulation;wafer (electronics);wafer fabrication	Chengtao Guo;Zhibin Jiang;Huai Zhang;Na Li	2012	Computers & Industrial Engineering	10.1016/j.cie.2011.09.002	mathematical optimization;ant colony optimization algorithms;computer science;engineering;operations management;operating system;decomposition;scheduling;engineering drawing	EDA	12.663405375832127	5.127205489381158	80066
38d0291e9361e24583ce57ddd108d4eac5157e08	applications of graph algorithms in gis	shortest path;geographic information system;road network;shortest path algorithm;routing;turn penalties;k shortest paths;graphs;road networks;technology and engineering;alternative paths;graph algorithm;heuristics;experimental evaluation;shortest path problem	This paper describes ongoing PhD research on applications of graph algorithms in Geographical Information Systems. Many GIS problems can be translated into a graph problem, especially in the domain of routing in road networks. Our research aims to evaluate and develop efficient methods for different variants of the routing problem.  Standard existing shortest path algorithms are not always suited for use in road networks, e.g. in a realistic situation forbidden turns and turn penalties need to be taken into account. An experimental evaluation of different methods for this purpose is presented.  Another interesting problem is the generation of alternative routes. This can be modelled as a k shortest paths problem, where a ranking of k paths is desired rather than only the shortest path itself. A new heuristic approach for generating alternative routes is presented and evaluated.	algorithm;geographic information system;graph theory;heuristic;list of algorithms;routing;shortest path problem	Stéphanie Vanhove;Veerle Fack	2010	SIGSPATIAL Special	10.1145/1953102.1953108	private network-to-network interface;mathematical optimization;combinatorics;canadian traveller problem;widest path problem;constrained shortest path first;any-angle path planning;longest path problem;floyd–warshall algorithm;equal-cost multi-path routing;average path length;computer science;pathfinding;euclidean shortest path;machine learning;yen's algorithm;mathematics;geographic information system;link-state routing protocol;shortest path problem;k shortest path routing;shortest path faster algorithm	DB	23.204216943949948	7.220515665382823	80077
deec27180816e29086a40e026fe2ebfc3564bb7f	optimal load balancing on sonet bidirectional rings	networks graphs;reseau communication;programacion entera;communications;complexite calcul;routing;equilibrio de carga;aproximacion;equilibrage charge;load balancing of rings;programmation en nombres entiers;approximation;algorithme;algorithm;complejidad computacion;exact solution to a ring loading problem;programacion lineal;integer programming;computational complexity;ring structure;estructura anular;load balancing;linear programming;structure annulaire;programmation lineaire;design of self healing rings;algorithms;load balance;encaminamiento;linear;red de comunicacion;programming;communication network;applications;reseau optique synchrone;acheminement;algoritmo	In this paper we consider the Ring Loading Problem, which arises in the design of SONET bidirectional rings. The issue of demand splitting divides the ring loading problem into the two kinds. One allows a demand to be split and routed in two different directions and the other does not. The former kind becomes a relaxation of the latter. We present an efficient exact solution procedure for the case with demand splitting, and a two-approximation algorithm for the case without demand splitting. Computational results are also shown to prove the efficiency of the proposed procedures.	load balancing (computing)	Young-Soo Myung;Hu-gon Kim;Dong-wan Tcha	1997	Operations Research	10.1287/opre.45.1.148	mathematical optimization;combinatorics;integer programming;computer science;linear programming;load balancing;calculus;mathematics;algorithm	Theory	20.849686507674985	11.436261537584647	80386
acd53239593399b44d6fb15f6b6ed8bd1fa8ca39	minimal cost reconfiguration of data placement in a storage area network	reconfiguration;approximation algorithms;video on demand;data placement	Video-on-Demand (VoD) services require frequent updates in file configuration on the storage subsystem, so as to keep up with the frequent changes in movie popularity. This defines a natural reconfiguration problem in which the goal is to minimize the cost of moving from one file configuration to another. The cost is incurred by file replications performed throughout the transition. The problem shows up also in production planning, preemptive scheduling with set-up costs, and dynamic placement of Web applications. We show that the reconfiguration problem is NP-hard already on very restricted instances. We then develop algorithms which achieve the optimal cost by using servers whose load capacities are increased by O(1), in particular, by factor 1+@d for any small 0<@d<1 when the number of servers is fixed, and by factor of 2+@e for arbitrary number of servers, for some @e@?[0,1). To the best of our knowledge, this particular variant of the data migration problem is studied here for the first time.	storage area network	Hadas Shachnai;Gal Tamir;Tami Tamir	2012	Theor. Comput. Sci.	10.1016/j.tcs.2012.06.018	parallel computing;real-time computing;computer science;control reconfiguration;mathematics;distributed computing;approximation algorithm	Theory	14.573471939604707	10.022547378175823	80402
535ec13c3c8d01ff15708588f8ab2921cdf938b2	a fast asymptotic approximation scheme for bin packing with rejection	bin packing;time complexity;multiple knapsack problem;knapsack problem;polynomial time;approximation scheme;asymptotic approximation;polynomial time approximation scheme	Bin packing with rejection” is the following problem: Given a list of items with associated sizes and rejection costs, find a packing into unit bins of a subset of the list such that the number of bins used plus the sum of rejection costs of unpacked items is minimized. We show that bin packing with rejection can be reduced to n multiple knapsack problems and, based on techniques for the multiple knapsack problem, we give a fast asymptotic polynomial time approximation scheme,“Reject&Pack”, with time complexity O(n −2)). This improves a recent approximation scheme given by Epstein, which has time complexity O(n ) −1 ). We also show that Reject&Pack can be extended to variable-sized bin packing with rejection and give an asymptotic polynomial time approximation scheme.	asymptote;bin packing problem;knapsack problem;polynomial;polynomial-time approximation scheme;rejection sampling;set packing;time complexity	Wolfgang W. Bein;José R. Correa;Xin Han	2008	Theor. Comput. Sci.	10.1016/j.tcs.2007.10.042	continuous knapsack problem;mathematical optimization;combinatorics;discrete mathematics;bin packing problem;polynomial-time approximation scheme;apx;cutting stock problem;mathematics;bin;knapsack problem	Theory	17.633947960333472	13.893721925204765	80568
85c7c23e94594e86522ccac3a15ce788adda3f60	new algorithms for minimizing the weighted number of tardy jobs on a single machine		In this paper we study the classical single machine scheduling problem where the objective is to minimize the weighted number of tardy jobs. Our analysis focuses on the case where one or more of three natural parameters is either constant or is taken as a parameter in the sense of parameterized complexity. These three parameters are the number of different due dates, processing times, and weights in our set of input jobs. We show that the problem belongs to the class of fixed parameter tractable (FPT) problems when combining any two of these three parameters. We also show that the problem is polynomial-time solvable when the latter two parameters are constant, complementing Karp’s result who showed that the problem is NP-hard already for a single due date.	arjen lenstra;bellman equation;branch and bound;cobham's thesis;computation;decision problem;integer programming;j.w. graham medal;job shop scheduling;job stream;journal of the acm;lawler's algorithm;makespan;management science;mathematics of operations research;np-hardness;parallel computing;parameterized complexity;schedule (project management);scheduling (computing);single-machine scheduling;thatcher effect;time complexity	Danny Hermelin;Shlomo Karhi;Mike Pinedo;Dvir Shabtay	2017	CoRR		mathematics;discrete mathematics;mathematical optimization;parameterized complexity;single-machine scheduling	Theory	16.114810544116104	10.537456780251189	80734
bffc07604f9bb847faf95e03a997c215dd0b6838	rationalization of production order execution with use of the greedy and tabu search algorithms		In the paper, rationalization of production order execution in a large manufacturing company is suggested. Till now, the decision-making process was based on the human factor, which resulted in irregular utilization of manufacturing resources. The presented work was aimed at developing new order selection system. That would make it possible to utilize the admitted resources possibly best and thus to meet the deadlines and to adapt to specific production requirements. In the work, the greedy and Tabu Search algorithms were used. As a basis for the research employing, historical data were accepted. Each order were given a priority, production time, profit and penalty for failure. Additionally, the machine failure risk was calculated based on empirical measurements. Simulations of several subsequent working weeks were performed in order to analyse the results obtained thanks to the suggested methods and to compare them with the results presently reached by the company.	greedy algorithm;tabu search	Kamil Musial;Joanna Kochanska;Anna Burduk	2018		10.1007/978-3-319-94120-2_24	rationalization (psychology);machine learning;artificial intelligence;tabu search;manufacturing;algorithm;empirical measure;computer science;metaheuristic;greedy algorithm	OS	13.505954298088099	7.157743953963193	80764
c8eebcefc4847a329077193f579124847e3435bc	a polynomial time algorithm for minimax-regret evacuation on a dynamic path		A dynamic path network is an undirected path with evacuees situated at each vertex. To evacuate the path, evacuees travel towards a designated sink (doorway) to exit. Each edge has a capacity, the number of evacuees that can enter the edge in unit time. Congestion occurs if an evacuee has to wait at a vertex for other evacuees to leave first. The basic problem is to place k sinks on the line, with an associated evacuation strategy, so as to minimize the total time needed to evacuate everyone. The minmax-regret version introduces uncertainty into the input, with the number of evacuees at vertices only being specified to within a range. The problem is to find a universal solution whose regret (difference from optimal for a given input) is minimized over all legal inputs. The previously best known algorithms for the minmax-regret version problem ran in time exponential in k. In this paper, we derive new properties of solutions that yield the first polynomial time algorithms for solving the problem.	algorithm;graph (discrete mathematics);minimax;network congestion;path (graph theory);regret (decision theory);situated;time complexity	Guru Prakash Arumugam;John Augustine;Mordecai J. Golin;Prashanth Srikanthan	2014	CoRR		mathematical optimization;discrete mathematics;simulation;longest path problem	Theory	24.410017043545825	17.76324365630455	80798
2a56e1ad2b2627338c9ea3fc610cb5c315d8b40a	on the single machine scheduling problem with sequence-dependent setup times and periodic maintenance		This paper tackles the single machine scheduling problem with sequence-dependent setup times and periodic maintenance. The objective function to be minimized here is the weighted sum of completion times using mixed integer programming approaches. We propose and analyze herein two mixed-integer linear programming (MILP) formulations. The performance of these MILPs is tested on randomly generated data sets.	algorithm;bin packing problem;computation;dummy variable (statistics);experiment;heuristic (computer science);integer programming;job stream;linear programming;loss function;metaheuristic;optimization problem;procedural generation;scheduling (computing);set packing;single-machine scheduling;weight function	Hanane Krim;Rachid Benmansour;David Duvivier	2018	2018 5th International Conference on Control, Decision and Information Technologies (CoDIT)	10.1109/CoDIT.2018.8394827	periodic graph (geometry);job shop scheduling;single-machine scheduling;linear programming;integer programming;sequence-dependent setup;mathematical optimization;computer science;data set	Robotics	15.94128609437295	7.81185146775421	80812
275589976eebf99d6821c5dd423794f8b6acc0d0	on the primer selection problem in polymerase chain reaction experiments	branch and bound algorithm;polymerase chain reaction;approximate solution;timing optimization	"""In this paper we address the problem of primer selection in polymerase chain reaction (PCR) experiments. We prove that the problem of minimizing the number of primers required to amplify a set of DNA sequences is NP-complete. Moreover, we show that it is also intractable to approximate solutions to this problem to within a constant times optimal. On the practical side, we give a simple branch-and-bound algorithm that solves the primers minimization problem within reasonable time for typical instances. Moreover, we present an eecient approximation scheme for this problem, and prove that our heuristic always produces solutions with cost no worse than a logarithmic factor times optimal. Finally, we analyze a weighted variant, where both the number of primers as well as the sum of their \costs"""" is optimized simultaneously. We conclude by addressing the empirical performance of our methods on biological data."""	approximation algorithm;branch and bound;experiment;heuristic;np-completeness;primer;selection algorithm	William R. Pearson;Gabriel Robins;Dallas E. Wrege;Tongtong Zhang	1996	Discrete Applied Mathematics	10.1016/S0166-218X(96)00066-2	mathematical optimization;combinatorics;polymerase chain reaction;mathematics;branch and bound;algorithm	ML	19.306585044621134	10.939323119823573	80875
452194178dcfbc684ea610763590a5530095a79c	greedy randomized adaptive search procedure with path-relinking for the vertex p-center problem		The p-center problem consists of choosing a subset of vertices in an undirected graph as facilities in order to minimize the maximum distance between a client and its closest facility. This paper presents a greedy randomized adaptive search procedure with path-relinking (GRASP/PR) algorithm for the p-center problem, which combines both GRASP and path-relinking. Each iteration of GRASP/PR consists of the construction of a randomized greedy solution, followed by a tabu search procedure. The resulting solution is combined with one of the elite solutions by path-relinking, which consists in exploring trajectories that connect high-quality solutions. Experiments show that GRASP/PR is competitive with the state-of-the-art algorithms in the literature in terms of both solution quality and computational efficiency. Specifically, it virtually improves the previous best known results for 10 out of 40 large instances while matching the best known results for others.	computation;grasp;graph (discrete mathematics);greedy algorithm;greedy randomized adaptive search procedure;iteration;randomized algorithm;tabu search;vertex (graph theory)	Ai-Hua Yin;Taoqing Zhou;Junwen Ding;Qing-Jie Zhao;Zhi-Peng Lv	2017	Journal of Computer Science and Technology	10.1007/s11390-017-1802-3	mathematical optimization;distributed computing;computer science;facility location problem;greedy randomized adaptive search procedure;vertex (geometry);tabu search;closest facility;grasp;graph	AI	23.970690892357908	6.143963183193078	81282
c9c67af2001e4be72feb40feb879b887b8f4333b	heuristic algorithms for job‐shop scheduling problemswith stochastic precedence constraints	job shop scheduling;flow shop scheduling;approximate solution;precedence constraint;job shop;stochastic scheduling;heuristic algorithm	This paper deals with job‐shop scheduling with stochastic precedenceconstraints given by so‐called OR networks. At first, a job‐shop problem withstochastic OR network precedence constraints is described, where the expected makespan isto be minimized. Next, the concept of an aggregate schedule is discussed, which represents a deterministic staticscheduling policy for our stochastic problem. The construction of an appropriate aggregatedisjunctive graph permits us to adapt the shifting bottleneck heuristic. After that,a priority‐rulemethod is proposed for finding an approximate aggregate schedule. An experimentalperformance analysis shows that both heuristics provide good approximate solutions. Finally,we briefly discuss a flow‐shop problem with OR network precedence constraints and thecase of cyclic OR networks. Copyright Kluwer Academic Publishers 1999	algorithm;heuristic;job shop scheduling;scheduling (computing)	Klaus Neumann;Welf G. Schneider	1999	Annals OR	10.1023/A:1018955319343	heuristic;job shop scheduling;mathematical optimization;flow shop scheduling;computer science;operations management;mathematics;distributed computing;precedence diagram method	AI	15.493608805687975	8.978313862754673	81571
3240886506d601239bbc28f21b3eb9a3d142feba	searching for a counterfeit coin with b-balance	pire cas;worst case;optimisation;b balance;combinatorics;optimizacion;combinatoria;counterfeit coin;combinatoire;fausse monnaie;search;cas moyen;informatique theorique;optimization;average case;recherche modele;search model;algoritmo optimo;algorithme optimal;optimal algorithm;computer theory;algorithme sequentiel;informatica teorica	We consider the classical problem of searching for a heavier coin in a set of n coins, n − 1 of which have the same weight. The weighing device is b-balance which is the generalization of two-arms balance. The minimum numbers of weighings are determined exactly for worst-case sequential algorithm, average-case sequential algorithm, worst-case predetermined algorithm, average-case predetermined algorithm. We also investigate the above search model with additional constraint: each weighing is only allowed to use the coins that are still in doubt. We present a worst-case optimal sequential algorithm and an average-case optimal sequential algorithm requiring the minimum numbers of weighings. © 2006 Elsevier B.V. All rights reserved.	best, worst and average case;coat of arms;sequential algorithm;whole earth 'lectronic link	Wen An Liu;Huan Huan Cui;Bing Qing Ma	2006	Discrete Applied Mathematics	10.1016/j.dam.2006.03.010	combinatorics;group testing;artificial intelligence;mathematics;algorithm	AI	17.610176621927852	12.178326886982669	81683
2a30b8baeb38ab800c51579e1f8f7ce2ba7ff726	knowledge state algorithms	online algorithm;algoritmo aleatorizado;bookmark;competitividad;transition probability;on line;en linea;signet;radiobusqueda;competitive algorithms;armonica;cache memory;plan randomise;harmonic;algorithme randomise;travail sortie;antememoria;algorithme competitif;aleatorizacion;paging;antememoire;plan aleatorizado;marcador;harmonique;randomized design;task systems;work function;probabilidad transicion;competitiveness;randomized algorithm;randomisation;competitive analysis;en ligne;online algorithms;randomization;algoritmo competitivo;competitivite;server problem;radiomessagerie;probabilite transition;funcion de trabajo;harmonic number	We introduce the novel concept of knowledge states. The knowledge state approach can be used to construct competitive randomized online algorithms and study the trade-off between competitiveness and memory. Many well-known algorithms can be viewed as knowledge state algorithms. A knowledge state consists of a distribution of states for the algorithm, together with a work function which approximates the conditional obligations of the adversary. When a knowledge state algorithm receives a request, it then calculates one or more “subsequent” knowledge states, together with a probability of transition to each. The algorithm uses randomization to select one of those subsequents to be the new knowledge state. We apply this method to randomized k-paging. The optimal minimum competitiveness of any randomized online algorithm for the k-paging problem is the kth harmonic number, $H_{k}=\sum^{k}_{i=1}\frac{1}{i}$ . Existing algorithms which achieve that optimal competitiveness must keep bookmarks, i.e., memory of the names of pages not in the cache. An H k -competitive randomized algorithm for that problem which uses O(k) bookmarks is presented, settling an open question by Borodin and El-Yaniv. In the special cases where k=2 and k=3, solutions are given using only one and two bookmarks, respectively.	adversary (cryptography);adversary model;bookmark (world wide web);cpu cache;central processing unit;competitive analysis (online algorithm);computationally bounded adversary;concurrency (computer science);data item;emoticon;k-server problem;multiprocessing;online algorithm;page replacement algorithm;paging;randomized algorithm;server (computing);shared memory;spaces;uniform data access	Wolfgang W. Bein;Lawrence L. Larmore;John Noga;Rüdiger Reischuk	2009	Algorithmica	10.1007/s00453-009-9366-4	online algorithm;combinatorics;simulation;computer science;artificial intelligence;mathematics;algorithm;statistics	Theory	16.43932869202174	13.202962342373752	81821
cd25eb9d7bcf91d9c3ccc6641366516d8378c838	optimization - based analysis of collaborative airport arrival planning	ecoulement trafic;optimisation;air traffic control;optimizacion;systeme aide decision;proceso llegada;cooperation;u s national aeronautics and space administration;gestion trafic;simulacion numerica;air transportation;traffic flow;sistema ayuda decision;traffic management;arrival process;volume trafic;processus arrivee;transport aerien;transporte aereo;sequencing;volumen trafico;planificacion;decision support system;integer programming;scheduling;arrivals and departures;simulation numerique;decision support systems;economic aspect;gestion trafico;planning;optimization;aspect economique;temps retard;approach control;benefits;delay time;airlines;capacity of traffic;planification;airport operations;tiempo retardo;flujo trafico;aspecto economico;ordonnancement;reglamento;numerical simulation	This paper describes, a novel optimization-based approach to benefits analysis that allows us to analyze new collaborative air traffic management tools. We apply this method to analysis of the Collaborative Arrival Planner (CAP), a concept under development by NASA as part of a suite of decision-support tools for improved air traffic management. Central to our benefits analysis is an integer program, the Arrival Sequencing Model (ASM), which minimizes cost through adjustments to the arrival sequence. We use the ASM to evaluate whether CAP-enabled airline control over and/or visibility into the airport arrival sequencing process could improve overall performance of the air transportation system.		Kari Andersson;William Hall;Stephen Atkins;Eric Feron	2003	Transportation Science	10.1287/trsc.37.4.422.23274	planning;mathematical optimization;active traffic management;simulation;decision support system;computer science;engineering;operations management;air traffic control;traffic flow;sequencing;operations research;scheduling;cooperation;aviation	ML	16.927645287227744	5.574161272412072	82034
d82508edc0f980c83d22b53510d7b09d0bea80b9	a polynomial approximation scheme for a constrained flow-shop scheduling problem	polynomial approximation schemes;approximation algorithms;aproximacion;coaccion;production system;contrainte;systeme production;flow shop scheduling;sistema produccion;approximation;algorithme;algorithm;constraint;flow shops;scheduling;release dates;ordonamiento;ordonnancement;flow shop;polynomial approximation;algoritmo;shop scheduling	We present a polynomial approximation scheme for a two-machine flow shop scheduling problem with the additional constraint that each job has a release date, when it first becomes available for processing. This is one of the first such results for multiple-task scheduling problems; previously, the best approximation result for this problem was an algorithm guaranteed to deliver a schedule of length at most 5/3 times the optimal length. Our 1 + e-approximation algorithm is intuitively appealing because it is based on Johnson's algorithm, an optimization algorithm for the problem without release dates.	flow shop scheduling;polynomial;polynomial-time approximation scheme;scheduling (computing)	Leslie A. Hall	1994	Math. Oper. Res.	10.1287/moor.19.1.68	fair-share scheduling;job shop scheduling;mathematical optimization;combinatorics;polynomial-time approximation scheme;flow shop scheduling;dynamic priority scheduling;rate-monotonic scheduling;mathematics;approximation algorithm;algorithm	Theory	17.195673389874674	10.381155705550949	82077
9b0ba55db11cbf18576e07c4b3feb0ebe9758641	mathematical optimization approaches for facility layout problems: the state-of-the-art and future research directions	facilities planning and design;unequal areas facility layout;mixed integer linear optimization;semidefinite optimization;row layout	Facility layout problems are an important class of operations research problems that has been studied for several decades. Most variants of facility layout are NP-hard, therefore global optimal solutions are difficult or impossible to compute in reasonable time. Mathematical optimization approaches that guarantee global optimality of solutions or tight bounds on the global optimal value have nevertheless been successfully applied to several variants of facility layout. This review covers three classes of layout problems, namely row layout, unequal-areas layout, and multifloor layout. We summarize the main contributions to the area made using mathematical optimization, mostly mixed integer linear optimization and conic optimization. For each class of problems, we also briefly discuss directions that remain open for future research.	mathematical optimization	Miguel F. Anjos;Manuel V. C. Vieira	2017	European Journal of Operational Research	10.1016/j.ejor.2017.01.049	operations management;mathematical optimization;conic optimization;linear programming;topology optimization;computer science;integer	Theory	22.52759483245274	10.134639086803885	82083
2e374da305c068276e644580fcd0d228e4f7fdfe	minimizing weighted number of early and tardy jobs with a common due window involving location penalty	dynamic programming;single machine scheduling;due window;np completeness;dynamic program;polynomial time algorithm;computer experiment;polynomial algorithm;dynamic program ming;early tardy job	This paper studies a single machine scheduling problem to minimize the weighted number of early and tardy jobs with a common due window. There are n non-preemptive and simultaneously available jobs. Each job will incur an early (tardy) penalty if it is early (tardy) with respect to the common due window under a given schedule. The window size is a given parameter but the window location is a decision variable. The objective of the problem is to find a schedule that minimizes the weighted number of early and tardy jobs and the location penalty. We show that the problem is NP-complete in the ordinary sense and develop a dynamic programming based pseudo-polynomial algorithm. We conduct computational experiments, the results of which show that the performance of the dynamic algorithm is very good in terms of memory requirement and CPU time. We also provide polynomial time algorithms for two special cases.		Wing-Kwan Yeung;Ceyda Oguz;T. C. Edwin Cheng	2001	Annals OR	10.1023/A:1016094508744	mathematical optimization;real-time computing;np-complete;computer experiment;computer science;dynamic programming;mathematics;algorithm	Theory	15.524778568415728	9.16567725844679	82109
07d5536194c8d779a67768ba21aa98cdd8e34082	scheduling non-unit jobs to minimize calibrations	integrated stockpile evaluation;approximation algorithms;resource allocation;scheduling;calibration	The recently proposed Integrated Stockpile Evaluation (ISE) problem extends a classic offline scheduling problem where n jobs, each with arrival times and deadlines, must be scheduled nonpreemptively on m machines. The additional constraint in the ISE problem is that a machine may only be used if it has been calibrated recently. The goal is to minimize the number of calibrations necessary to complete all the jobs before their deadlines.  This paper presents a good polynomial-time approximation algorithm for the ISE problem general case where each job may have a different processing time. (Prior work was restricted to unit processing times.) The ISE problem generalizes a classic interval-scheduling problem where the goal is to minimize the number of machines. We show constructively that the other direction is also true, i.e., that the interval-scheduling bounds are also achievable. Specifically, suppose we have a black-box interval scheduling algorithm that finds an s-speed α m-machine solution to the interval scheduling problem. Then our ISE algorithm finds an O(α-approximation for number of calibrations using O(α m) machines with s-speed augmentation.	american and british english spelling differences;approximation algorithm;asymptotically optimal algorithm;black box;interval arithmetic;interval scheduling;job stream;microsoft windows;online and offline;overhead (computing);polynomial;reduction (complexity);scheduling (computing);time complexity	Jeremy T. Fineman;Brendan Sheridan	2015		10.1145/2755573.2755605	mathematical optimization;real-time computing;calibration;resource allocation;computer science;operating system;scheduling;approximation algorithm	Theory	14.77434528077745	10.701164369514382	82172
b96a8d884c403eb46ed8cac8c2da173a87925b04	due-window assignment for a single machine scheduling with both deterioration and positional effects	scheduling;positional effect;deteriorating jobs;due window assignment	This paper considers a single machine scheduling with both deterioration and positional effects and due-window assignment problem. The job-dependent due-windows are obtained by the common flow allowance criterion. The objective is to schedule the jobs, and the due-windows so as to minimize the sum of earliness, tardiness, and due-window starting time and due-window size costs. We introduce a polynomial solution for the problem. Furthermore, we show how the solutions can be extended to the setting with job rejection.	schedule (project management);single-machine scheduling	Chuanli Zhao;Hengyong Tang	2015	APJOR	10.1142/S0217595915500141	mathematical optimization;real-time computing;computer science;operations management;deadline-monotonic scheduling;scheduling	Arch	15.157964102513063	9.319850573437865	82213
816bb24dcc0d3d28bb671f3d42dfb7094deee0d0	a computational study of the permutation flow shop problem based on a tight lower bound	workload;optimal solution;solution optimale;tiempo total acabamiento;gestion labor;benchmark;branch and bound algorithm;benchmark problem;temps total achevement;problema np duro;delai livraison;permutation;np hard problem;large scale;branch and bound method;gestion tâche;makespan;metodo branch and bound;probleme np difficile;scheduling;solucion optima;permutacion;permutation flow shop;time lag;benchmarks;charge travail;plazo entrega;methode separation et evaluation;task scheduling;carga trabajo;atelier monogamme;delivery lead time;ordonnancement;flow shop;lower bound;reglamento	We consider the classical permutation &ow shop problem which requires scheduling n jobs through m machines which are placed in series so as to minimize the makespan. This problem is known to be NP-hard. We describe a branch-and-bound algorithm with a lower bounding procedure based on the so-called two-machine &ow shop problem with time lags, ready times, and delivery times. We present extensive computational results on both random instances, with up to 8000 operations, and well-known benchmarks, with up to 2000 operations, which show that the proposed algorithm solves large-scale instances in moderate CPU time. In particular, we report proven optimal solutions for benchmark problems which have been open for some time. ? 2003 Elsevier Ltd. All rights reserved.	algorithm;benchmark (computing);branch and bound;central processing unit;computation;flow shop scheduling;makespan;np-hardness;scheduling (computing);series and parallel circuits	Talel Ladhari;Mohamed Haouari	2005	Computers & OR	10.1016/j.cor.2003.12.001	job shop scheduling;mathematical optimization;benchmark;flow shop scheduling;computer science;np-hard;mathematics;permutation;upper and lower bounds;scheduling;branch and bound;algorithm	Theory	16.976448560019186	9.617572204852605	82235
584a182935a0f91e99291cb72b9bab03605612b7	a sat-based approach to cost-sensitive temporally expressive planning	temporal expressiveness;satisfiability;numerical cost constraint;planning	Complex features, such as temporal dependencies and numerical cost constraints, are hallmarks of real-world planning problems. In this article, we consider the challenging problem of cost-sensitive temporally expressive (CSTE) planning, which requires concurrency of durative actions and optimization of action costs. We first propose a scheme to translate a CSTE planning problem to a minimum cost (MinCost) satisfiability (SAT) problem and to integrate with a relaxed parallel planning semantics for handling true temporal expressiveness. Our scheme finds solution plans that optimize temporal makespan, and also minimize total action costs at the optimal makespan. We propose two approaches for solving MinCost SAT. The first is based on a transformation of a MinCost SAT problem to a weighted partial Max-SAT (WPMax-SAT), and the second, called BB-CDCL, is an integration of the branch-and-bound technique and the conflict driven clause learning (CDCL) method. We also develop a CSTE customized variable branching scheme for BB-CDCL which can significantly improve the search efficiency. Our experiments on the existing CSTE benchmark domains show that our planner compares favorably to the state-of-the-art temporally expressive planners in both efficiency and quality.	automated planning and scheduling;benchmark (computing);boolean satisfiability problem;branch and bound;certified senior broadcast television engineer;concurrency (computer science);conflict-driven clause learning;constraint learning;experiment;makespan;mathematical optimization;maximum satisfiability problem;numerical analysis;temporal logic	Qiang Lu;Ruoyun Huang;Yixin Chen;You Xu;Weixiong Zhang;Guoliang Chen	2013	ACM TIST	10.1145/2542182.2542200	planning;mathematical optimization;artificial intelligence;theoretical computer science;machine learning;algorithm;satisfiability	AI	21.1847716560121	4.214870524979612	82422
cc152fdf6bdd7729ca69b46c8eea4e6de4256537	optimal operation of parallel distillation systems with multiple product grades: an industrial case study		Abstract In the fine chemical industry, customers often demand different grades with different purity specifications. To achieve the best performance, the production tasks should be assigned to different distillation columns at the most suitable operating conditions and time periods. In this paper, an optimal scheduling method is presented through an industrial case study with multiple products and parallel distillation columns. Rigorous nonlinear models are built for each distillation column and validated with plant data, based on which, a reduced-order model is obtained with data of optimal operating points at various conditions. The reduced-order model is then incorporated into a mode-based discrete-time mixed integer linear program (MILP) scheduling model, where transitions between different operating modes are specified based on plant data. The MILP-based scheduling is applied to a real-word industrial case study to demonstrate its computational efficiency and effectiveness in improving economic performance with comparison to two heuristic scheduling methods.		Yingyan Luo;Qi Zhang;Lingyu Zhu;Xi Chen	2018	Computers & Chemical Engineering	10.1016/j.compchemeng.2018.01.009	control engineering;mathematical optimization;fractionating column;scheduling (computing);mathematics;distillation;linear programming;heuristic;nonlinear system	SE	11.441024848669487	5.307382153092947	82427
26c20a9b6aa285562d401008f2a0b0e2dcbf3eb5	egonet: a genetic algorithm model for the optimisation of telephone networks	use;genetique;cross connection;optimisation;networks layout design;reseau communication;world;implantation topometrie;optimizacion;genetica;telephone networks;telephone;heuristic method;coaccion;contrainte;conception;metodo heuristico;reseau;red telefonica;layout;test;algoritmo genetico;genetics;red;windows;ensayo;algorithme;minimo;algorithm;utilisation;essai;modelo;constraint;minimum;heuristic algorithms;fenetre;connexion croisee;uso;coste;diseno;algorithme genetique;ventana;design;genetic algorithm;genetic algorithms;optimization;modele;monde;methode heuristique;mundo;telephone network;reseau telephonique;telefono;institutional repository research archive oaister;red de comunicacion;communication network;models;heuristic algorithm;network;cout;algoritmo;implantacion topometria	The aim of this paper is to study the use of genetic algorithms for the optimisation of telephone networks layout design. The genetic algorithms are used to design the network in a geographical sense with minimum costs depending on a set of real-world rules (constraints). A genetic algorithm tool (EGONET) is described. EGONET is written in ANSI-C and thus can be used on a wide range of platforms. EGONET was tested under Unix/Linux, OS/2 and Windows 98.	genetic algorithm;mathematical optimization	Kifah R. Tout;Eberhard von Goldammer;David J. Evans	2003	Int. J. Comput. Math.	10.1080/0020716021000059124	mathematical optimization;genetic algorithm;telephone network;telecommunications;artificial intelligence	AI	20.200557874253487	6.9303010047913345	82575
114e3ee758e86e5d0e55c06625342018f84dc869	on-line manipulation planning for two robot arms in a dynamic environment	dynamic change;dynamic environment;robot arm;continuous flow;robot motion planning;machine tool;simulation environment	In a constantly changing and partially unpredictable environment, robot motion planning must be on-line. The planner receives a continuous ow of information about occurring events and generates new plans, while previously planned motions are being executed. This paper describes an on-line planner for two cooperating arms whose task is to grab parts of various types on a conveyor belt and transfer them to their respective goals while avoiding collision with obstacles. Parts arrive on the belt in random order, at any time. Both goals and obstacles may be dynamically changed. This scenario is typical of manufacturing cells serving machine-tools, assembling products, or packaging objects. The proposed approach breaks the overall planning problem into subproblems, each involving a low-dimensional con guration or con guration time space, and orchestrates very fast primitives solving these subproblems. The resulting planner has been implemented and extensively tested in a simulated environment, as well as with a real dual-arm system. Its competitiveness has been evaluated against an oracle making (almost) the best decision at any one time; the results show that the planner compares extremely well.		Tsai-Yen Li;Jean-Claude Latombe	1997	I. J. Robotics Res.	10.1177/027836499701600202	simulation;robotic arm;computer science;engineering;artificial intelligence;machine tool;mechanical engineering	Robotics	10.890137236989771	4.930060437830631	82893
dd0d4407032f43b4e7564131f87a3294b9df440c	improved rounding procedures for the discrete version of the capacitated eoq problem	constante tiempo;metodo caso peor;optimal solution;solution optimale;time constant;indice produccion;problema transporte;transportation problem;probleme transport;temps minimal;worst case analysis;inventory;administracion deposito;horizonte infinito;horizon infini;economic order quantity;cout moyen;average cost;solucion optima;taux production;coste medio;transportation;methode cas pire;gestion stock;minimum time;production rate;quantite economique a commander;infinite horizon;frequency based policies;cantidad economica pedida;performance ratio;tiempo minimo;worst case method;inventory control;constante temps	We consider a transportation problem where different products have to be shipped from an origin to a destination by means of vehicles with given capacity. The production rate at the origin and the demand rate at the destination are constant over time and identical for each product. The problem consists in deciding when to make the shipments and how to fill the vehicles, with the objective of minimizing the sum of the average transportation and inventory costs at the origin and at the destination over an infinite horizon. This problem is the well known capacitated EOQ (economic order quantity) problem and has an optimal solution in closed form. In this paper we study a discrete version of this problem in which shipments are performed only at multiples of a given minimum time. It is known that rounding-off the optimal solution of the capacitated EOQ problem to the closest lower or upper integer value gives a tight worst-case ratio of 2, while the best among the possible single frequency policies has a performance ratio of 5/3. We show that the 5/3 bound can be obtained by a single frequency policy based on a rounding procedure which considers classes of instances and, for each class, identifies a shipping frequency by rounding-off in a different way the optimal solution of the capacitated EOQ problem. Moreover, we show that the bound can be reduced to 3/2 by using two shipping frequencies, obtained by a rounding procedure, in one class of instances only.	economic order quantity;rounding	Luca Bertazzi;Maria Grazia Speranza	2005	European Journal of Operational Research	10.1016/j.ejor.2003.10.056	inventory control;transportation theory;transport;economic order quantity;inventory;economics;marketing;operations management;time constant;mathematical economics;operations research	Theory	15.366449881928991	4.219442138980332	83288
2d605a0d6957974449910ddee9619117c2e37ca8	distributed task rescheduling with time constraints for the optimization of total task allocations in a multirobot system		This paper considers the problem of maximizing the number of task allocations in a distributed multirobot system under strict time constraints, where other optimization objectives need also be considered. It builds upon existing distributed task allocation algorithms, extending them with a novel method for maximizing the number of task assignments. The fundamental idea is that a task assignment to a robot has a high cost if its reassignment to another robot creates a feasible time slot for unallocated tasks. Multiple reassignments among networked robots may be required to create a feasible time slot and an upper limit to this number of reassignments can be adjusted according to performance requirements. A simulated rescue scenario with task deadlines and fuel limits is used to demonstrate the performance of the proposed method compared with existing methods, the consensus-based bundle algorithm and the performance impact (PI) algorithm. Starting from existing (PI-generated) solutions, results show up to a 20% increase in task allocations using the proposed method.		Joanna Turner;Qinggang Meng;Gerald Schaefer;Amanda Whitbrook;Andrea Soltoggio	2018	IEEE Transactions on Cybernetics	10.1109/TCYB.2017.2743164	vehicle routing problem;pi;bundle;resource management;real-time computing;computer science;distributed computing;multi-agent system	Robotics	12.770647478778653	5.960273832896452	83349
973657ce78120aa873f6e7d554ea79d19f9a5141	solving large steiner triple covering problems	matrice incidence;optimal solution;problema arbol steiner;matriz incidencia;steiner triple systems;programacion entera;orbite;branch and bound algorithm;branching;probleme arbre steiner;set covering problem;incidence matrix;programmation en nombres entiers;steiner system;symetrie;symmetry;branch and bound method;probleme recouvrement;couverture;sistema steiner;branch and bound algorithms;problema recubrimiento;integer programming;metodo branch and bound;systeme steiner;ramificacion;recouvrement ensemble;ramification;coverage;set covering;methode separation et evaluation;steiner tree problem;cubierta conjunto;covering problem;simetria;integer program;orbit;steiner triple system;orbita;cobertura	Computing the 1-width of the incidence matrix of a Steiner Triple System gives rise to small set covering instances that provide a computational challenge for integer programming techniques. One major source of difficulty for instances of this family is their highly symmetric structure, which impairs the performance of most branch-and-bound algorithms. The largest instance in the family that has been solved corresponds to a Steiner Tripe System of order 81. We present optimal solutions to the set covering problems associated with systems of orders 135 and 243. The solutions are obtained by a tailored implementation of constraint orbital branching, a method for branching on general disjunctions designed to exploit symmetry in integer programs.	algorithm;branch and bound;computation;covering problems;embedded system;incidence matrix;integer programming;linear programming;molecular orbital;parallel computing;steiner tree problem	James Ostrowski;Jeff T. Linderoth;Fabrizio Rossi;Stefano Smriglio	2011	Oper. Res. Lett.	10.1016/j.orl.2011.02.001	mathematical optimization;combinatorics;discrete mathematics;integer programming;steiner tree problem;mathematics;geometry;steiner system	Theory	23.04149878524076	12.696184616674136	83440
7a78756fd5b8feb810ee2553de176c4ba83af772	project scheduling in decision-theoretic competitive bidding	costing;bidding strategies;job shop scheduling contracts cost function processor scheduling availability delay pervasive computing manufacturing industries production facilities human resource management;computational complexity;scheduling;tabu search metaheuristic decision theoretic competitive bidding cost estimation optimal bidding model resource constrained project scheduling problem weighted tardiness penalty cost np completeness;decision theory;decision theoretic;tabu search;project scheduling;search problems;cost estimation;resource constrained project scheduling problem;search problems computational complexity costing decision theory scheduling	Accurate cost estimates for an incoming order are critical in formulating the optimal bidding strategy. When a firm is approaching its resource capacity in the short-run, adding a new job into the system may cause violations of the due date requirements, thus penalty costs arise. In this study we propose a two-stage scheduling-based optimal bidding model. Stage-I considers a resource-constrained project scheduling problem (RCPSP) minimizing the weighted tardiness (penalty costs). Due to the NP-completeness of the stage-I model, we propose a tabu search metaheuristic to obtain a high quality solution with reasonable computational time. The obtained cost estimates are then fed into the stage-II decision-theoretic competitive bidding model to find the optimal bidding price. Advantages and extensions of the proposed model are discussed.	computation;display resolution;metaheuristic;np-completeness;procurement;requirement;schedule (project management);scheduling (computing);tabu search;theory;time complexity	Haitao Li;Keith Womer	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688693	fair-share scheduling;mathematical optimization;flow shop scheduling;decision theory;dynamic priority scheduling;tabu search;computer science;rate-monotonic scheduling;two-level scheduling;computational complexity theory;round-robin scheduling;scheduling;schedule;activity-based costing;cost estimate;statistics	Robotics	14.04716913226877	7.229275892694311	83539
b00be373188e572fb82520c4346892ee693a6452	an approach to predictive-reactive scheduling of parallel machines subject to disruptions	fuzzy set;parallel machine scheduling;scheduling problem;parallel machines	In this paper, a new predictive-reactive approach to a parallel machine scheduling problem in the presence of uncertain disruptions is presented. The approach developed is based on generating a predictive parallel machine scheduling in such a way as to absorb the effects of possible uncertain disruptions through adding idle times to the job processing times. The uncertain disruption considered is material shortage and it is described using two parameters: number of disruption occurrences and disruption repair period. These parameters are specified imprecisely based on managerial subjective judgement and they are modelled and combined using fuzzy sets. If the impact of a disruption is too high to be absorbed by the predictive schedule, a rescheduling action is needed. In this new approach two rescheduling methods are applied, namely Left shift rescheduling and Building new schedules. The approach developed has been applied to solving a real-life scheduling problem of a pottery company. The results obtained have been satisfactory and showed the flexibility of the predictive-reactive approach.	cpu cache;denial-of-service attack;deployment environment;display resolution;fuzzy set;google reader;job shop scheduling;job stream;makespan;parallel computing;real life;requirement;schedule (computer science);scheduling (computing);simulation;uncertain inference	Alejandra Duenas;Dobrila Petrovic	2008	Annals OR	10.1007/s10479-007-0280-3	fair-share scheduling;job shop scheduling;mathematical optimization;real-time computing;dynamic priority scheduling;computer science;operations management;two-level scheduling;mathematics;distributed computing;fuzzy set	AI	12.947859665990922	6.933567793378387	83607
b7015cdce6d9d6516eaa1a3f7c7c57936b3d6236	a genetic scheduler for electric vehicle charging	performance measure;genetic operator;task model;satisfiability;smart grid;genetics;peak load reduction;genetic algorithm;initial population;electric vehicle;electric vehicle charging;task allocation;time constraint	This paper presents a design and evaluates the performance of a genetic scheduler for electric vehicles, aiming at reducing the peak load of a fast charging station while meeting the time constraint of all charging requests. Upon the preemptive task model consisting of actuation time, operation length, deadline, and a consumption profile, the proposed scheduler fills the allocation table, by which charging tasks can be started, suspended, and resume at each time slot. To obtain a better initial population, our heuristic approach selects time slots having the lowest power load until the previous task allocation. Then, the regular genetic operations further improve the schedule, additionally creating new chromosomes capable of satisfying all time constraints. The performance measurement result obtained from a prototype implementation shows that our scheme can reduce the peak load for the given charging task sets by up to 11.0 %, compared with a conventional scheme.	heuristic;load profile;preemption (computing);prototype;scheduling (computing)	Junghoon Lee;Hye-Jin Kim;Gyung-Leen Park	2012		10.1145/2245276.2232076	real-time computing;simulation;genetic algorithm;computer science;artificial intelligence;operating system;genetic operator;machine learning;smart grid;satisfiability	Embedded	12.135732971806855	5.390555392201398	83638
d3932bc0dcc18f2c76c9e599897aebd9198f2556	an effective branch-and-bound algorithm for convex quadratic integer programming	branch and bound algorithm;objective function;linear time;integer program;lower bound	We present a branch-and-bound algorithm for minimizing a convex quadratic objective function over integer variables subject to convex constraints. In a given node of the enumeration tree, corresponding to the fixing of a subset of the variables, a lower bound is given by the continuous minimum of the restricted objective function. We improve this bound by exploiting the integrality of the variables using suitably-defined lattice-free ellipsoids. Experiments show that our approach is very fast on both unconstrained problems and problems with box constraints. The main reason is that all expensive calculations can be done in a preprocessing phase, while a single node in the enumeration tree can be processed in linear time in the problem dimension.	algorithm;branch and bound;integer programming	Christoph Buchheim;Alberto Caprara;Andrea Lodi	2010		10.1007/978-3-642-13036-6_22	time complexity;mathematical optimization;combinatorics;discrete mathematics;integer programming;nonlinear programming;linear programming relaxation;branch and price;mathematics;upper and lower bounds;branch and bound;branch and cut	ML	24.109124410584787	12.136091881360802	83847
fcf35ce6e2c3e131bfb934c886418dbcce90625e	monotone optimal multipartitions using schur convexity with respect to partial orders	optimisation;fiabilidad;reliability;relation ordre partiel;schur convexity;optimizacion;90b25;monotonie;particion;optimal partitions;26a51;partial ordering;convexite schur;assembling;fiabilite;monotonicity;partitions;partition;montage;optimization;relacion orden parcial;monotonia;montaje;partial order	In a (t, n, m)-multipartitioning problem, lists of nm ordered numbers are partitioned into n sets, where each set contains m numbers from each list. The goal is to maximize some objective function that depends on the sum ofthe elements in each set and is called the partitionfunction. The authors use the recently developed theory of majorization and Schur convexity with respect to partially ordered sets to study optimal multipartitions for the above problem. In particular, they apply the results to construct a class ofcounterexamples to a recent conjecture ofDu and Hwang, which asserts that (classic) Schur convex functions can be characterized as the partition functions for l, n, m)-multipartitioning problems having monotone optimal solutions. Key words, partitions, monotonicity, optimal partitions, Schur convexity, partial order AMS subject classifications. 90B25, 26A51	convex function;loss function;optimization problem;vhdl-ams;monotone	Frank K. Hwang;Uriel G. Rothblum;Larry A. Shepp	1993	SIAM J. Discrete Math.	10.1137/0406042	partially ordered set;mathematical optimization;combinatorics;discrete mathematics;schur's theorem;mathematics;geometry;algebra	Theory	24.338288311863494	14.209161927979942	84014
94a85ab21cc52bbb3d503d6eb2db87302e2a17c5	dynamic mean value cross decomposition algorithm for capacitated facility location problems	mean value cross decomposition;cross decomposition;primal recovery strategies;capacitated facility location problems;lagrangian relaxation	In this article, we propose a practical algorithm for capacitated facility location problems (CFLP). There are some approaches which can obtain primal solutions while simultaneously exploiting the primal structure and the dual structure. One of these approaches is the mean value cross decomposition (MVCD) method that ensures convergence without solving master problems. However, MVCD has been previously applied only to uncapacitated facility location problems (UFLP), due to the fact that the performance is highly dependent on the structure of the problem. The proposed algorithm, named the dynamic mean value cross decomposition algorithm (DMVCD), is effectively integrated with MVCD and cutting plane methods in order to tighten the bounds by reducing the duality gap. Computational results of various instances are also reported to verify the effectiveness and efficiency of DMVCD.	approximation algorithm;branch and bound;computation;criss-cross algorithm;cutting-plane method;duality gap;experiment;facility location problem;heuristic;lagrangian relaxation;linear programming relaxation;management science;mathematical optimization;operations research;polyhedron;rate of convergence;submodular set function	Chulyeon Kim;Gyunghyun Choi;Sung-Seok Ko	2013	Informatica, Lith. Acad. Sci.		mathematical optimization;lagrangian relaxation;mathematics;mathematical economics	Theory	21.20835793244334	9.550873229745594	84128
190736342eb7f0dc4f5389744d8a6ffe4402df07	approximation algorithms for the test cover problem	performance guarantee;approximate algorithm;algorithm performance;complexite calcul;algorithme glouton;approximation algorithm;packing;problema np duro;polynomial time algorithm;np hard problem;complejidad computacion;path packing;probleme np difficile;test cover;computational complexity;resultado algoritmo;recouvrement essai;algoritmo aproximacion;performance algorithme;recouvrement ensemble;greedy algorithm;algoritmo gloton;set covering;cubierta conjunto;covering problem;algorithme approximation;performance ratio;local search;set cover;recherche locale;garnissage;relleno;garantie performance	"""In the test cover problem a set of m items is given together with a collection of subsets, called tests. A smallest sub collection of tests is to be selected such that for each pair of items there is a test in the selection that contains exactly one of the two items. It is known that the problem is NP-hard and that the greedy algorithm has a performance ratio O(logm). We show that, unless P :;;: NP, no polynomial-time algorithm can do essentially better. For the case that each test contains at most k items, we give an O(log k )-approximation algorithm. We pay special attention to the case that each test contains at most two items. A strong relation """",ith a problem of packing paths in a graph is established, which implies that even this special case is NP-hard. We prove APX-hardness of both problems, and derive performance guarantees for greedy algorithms and for a series of local improvement heuristics. 'Institute of Information and Computing Sciences, Utrecht University, The Netherlands; koendb@cs.uu.nl. Partially supported by the Future and Emerging Technologies Programme of the EU under contract number IST-1999-14186 (ALCOM-FT). tCelera Genomics, Rockville, MD, U.S.A.; bjarnLhalldorsson@celera.com. Partially supported by a Merck Computational Biology and Chemistry Program Graduate Fellowship from the Merck Company Foundation. t Department of Computer Science, University of Iceland, Iceland; mmh@hLis. Also Iceland Genomics Corporation, mmh@uvs.is §Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, The Netherlands; {wscor Jkl,leen }@win.tue.nl. '-School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA, U.S.A. IIGraduate School of Industrial Administration, Carnegie Mellon University, Pittsburgh, PA, U.S.A.; ravi@cmu.edu. Partially supported by subcontract No. 16082-RFP-OO-2C in the area of """"Combinatorial Optimization in Biology (XAXE),"""" Los Alamos National Laboratories, and NSF grant CCR-OI05548. """"CWI, Amsterdam, The Netherlands; stougie@cwLnL"""	apx;approximation algorithm;combinatorial optimization;computation;computational biology and chemistry;computational genomics;computer science;greedy algorithm;heuristic (computer science);ibm notes;merck index;np (complexity);np-hardness;set packing;software release life cycle;systems engineering;time complexity	Koen M. J. De Bontridder;Bjarni V. Halldórsson;Magnús M. Halldórsson;Cor A. J. Hurkens;Jan Karel Lenstra;R. Ravi;Leen Stougie	2003	Math. Program.	10.1007/s10107-003-0414-6	mathematical optimization;combinatorics;greedy algorithm;local search;np-hard;mathematics;set cover problem;computational complexity theory;approximation algorithm;algorithm	Theory	20.93172029265993	15.054635732802145	84518
e076cc9989b878c9dedae9fdd61d9f2df2815bcc	two-stage assembly-type flowshop batch scheduling problem subject to a fixed job sequence	dynamic programming;forecasting;reliability;project management;information systems;maintenance;soft or;information technology;packing;dynamic program;operations research;location;journal article;investment;assembly flowshop;journal;journal of the operational research society;inventory;performance metric;purchasing;history of or;logistics;marketing;scheduling;batch scheduling;scheduling problem;production;communications technology;fixed sequence;computer science;operational research;article;applications of operational research;or society;jors;management science;infrastructure	This paper discusses a two-stage assembly-type flowshop scheduling problem with batching considerations subject to a fixed job sequence. The two-stage assembly flowshop consists of m stage-1 parallel dedicated machines and a stage-2 assembly machine which processes the jobs in batches. Four regular performance metrics, namely, the total completion time, maximum lateness, total tardiness, and number of tardy jobs, are considered. The goal is to obtain an optimal batching decision for the predetermined job sequence at stage 2. This study presents a two-phase algorithm, which is developed by coupling a problemtransformation procedure with a dynamic program. The running time of the proposed algorithm is O(mnþ n), where n is the number of jobs. Journal of the Operational Research Society (2012) 63, 839–845. doi:10.1057/jors.2011.90 Published online 21 September 2011	algorithm;job scheduler;open-shop scheduling;scheduling (computing);time complexity;two-phase commit protocol	Feng-Jang Hwang;Bertrand M. T. Lin	2012	JORS	10.1057/jors.2011.90	project management;logistics;real-time computing;inventory;economics;forecasting;investment;computer science;marketing;operations management;dynamic programming;reliability;mathematics;location;operations research;information technology;scheduling	Theory	15.441899117988333	8.229913420544314	84798
7d93585a3659726b2afddb4e8bd32d039088147d	efficient heuristics for the minimum labeling global cut problem		Abstract Let G = ( V , E , L ) be an edge-labeled graph. Let V be the set of vertices of G , E the set of edges, L the set of labels (colors) such that each edge e ∈ E has an associated label L ( e ) . The goal of the minimum labeling global cut problem (MLGCP) is to find a subset L ′ ⊆ L of labels such that G ′ = ( V , E ′ , L  L ′ ) is not connected and | L ′ | is minimized. In this work, we generate random instances for the MLGCP to perform empirical tests. Also propose a set of heuristics using concepts of Genetic Algorithm and metaheuristic VNS, including some of their procedures, like two local search moves, and an auxiliary data structure to speed up the local search. Computational experiments show that the metaheuristic VNS outperforms other methods with respect to solution quality.	heuristic (computer science)	Thiago Gouveia da Silva;Gilberto Farias de Sousa Filho;Igor A. M. Barbosa;Nenad Mladenovic;Lucídio dos Anjos Formiga Cabral;Luiz Satoru Ochi;Daniel Aloise	2018	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2018.03.004	genetic algorithm;combinatorics;local search (optimization);vertex (geometry);metaheuristic;speedup;mathematics;data structure;heuristics;graph	Theory	24.11811682534596	6.140533036015179	84864
424b20ff8bf88312dd130a59d762f663b7e4da65	on computing backbones of propositional theories	computational problem;model enumeration;large propositional theory;propositional theory;modern sat solvers;computing backbones;optimization problem;prime implicant computation;large backbone;minimal model computation;propositional theories	Backbones of propositional theories are literals that are true in every model. Backbones have been used for characterizing the hardness of decision and optimization problems. Moreover, backbones find other applications. For example, backbones are often identified during product configuration. Backbones can also improve the efficiency of solving computational problems related with propositional theories. These include model enumeration, minimal model computation and prime implicant computation. This paper investigates algorithms for computing backbones of propositional theories, emphasizing the integration of these algorithms with modern SAT solvers. Experimental results, obtained on representative problem instances, indicate that the proposed algorithms are effective in practice and can be used for computing the backbones of large propositional theories. In addition, the experimental results indicate that propositional theories can have large backbones, often representing a significant percentage of the total number of variables.	algorithm;best, worst and average case;boolean satisfiability problem;computation;computational problem;id-wsf;knowledge-based configuration;literal (mathematical logic);mathematical optimization;propositional calculus;solver;theory;user-centered design	Joao Marques-Silva;Mikolás Janota;Inês Lynce	2010			algorithm	AI	13.262877974469877	17.323811426487087	84933
df2f3be906ad6359376eafd9373c1dcc7f29b4c0	a genetic algorithm for scheduling dual flow shops	dual flow shop;setup time;scheduling;due date;article;genetic algorithm ga	0957-4174/$ see front matter 2011 Elsevier Ltd. A doi:10.1016/j.eswa.2011.08.008 ⇑ Corresponding author. E-mail address: cw_chiou@yahoo.com.tw (C.-W. C This study examines a dual-flow shop-scheduling problem that allows cross-shop processing. The scheduling objective is to minimize the coefficient of variation of slack time (lateness), where the slack time (ST) of a job denotes the difference between its due date and total completion time. This scheduling problem involves two decisions: job route assignment (assigning jobs to shops) and job sequencing. This study develops a genetic algorithm (GA) embedded with the earliest due date (EDD) dispatching rule for making these decisions. Numerical experiments with the GA algorithm indicate that the performance of adopting a cross-shop production policy may significantly outperform that of adopting a single-shop production policy. This is particularly true when the two flow shops are asymmetrically designed. This study develops a grouping heuristic algorithm to reduce setup time and due-date-based demand simultaneously. This study uses the proposed genetic algorithm (GA) to prove that the grouping heuristic algorithm performs well. Obtaining an approximate optimal solution makes it possible to decide the route assignment of jobs and the job sequencing of machines. 2011 Elsevier Ltd. All rights reserved.	approximation algorithm;coefficient;embedded system;experiment;flip-flop (electronics);flow shop scheduling;genetic algorithm;heuristic (computer science);job shop scheduling;job stream;scheduling (computing);single-machine scheduling;slack variable;software release life cycle	Chie-Wun Chiou;Wen-Min Chen;Chin-Min Liu;Muh-Cherng Wu	2012	Expert Syst. Appl.	10.1016/j.eswa.2011.08.008	mathematical optimization;real-time computing;flow shop scheduling;computer science;least slack time scheduling;scheduling	AI	15.386325272112671	6.786813591331	85035
a45b474dd8d00d19960b840a52b20ee1f797160a	a tutorial on amortized local competitiveness in online scheduling	online scheduling	Recently the use of potential functions to analyze online scheduling algorithms has become popular [19, 7, 29, 13, 31, 4, 30, 3, 21, 15, 14, 28, 12, 2, 5, 6, 9, 11, 23, 33, 24, 8, 17, 16, 25, 1, 20, 26, 22, 18]. These potential functions are used to show that a particular online algorithm is locally competitive in an amortized sense. Algorithm analyses using potential functions are sometimes criticized as seeming to be black magic as the formal proofs do not require, and commonly do not contain, any discussion of the intuition behind the design of the potential function. Sometimes, as in the case for the first couple uses of potential functions in the online scheduling literature, this is because the authors arrived at the potential function by trial and error, and there was not a cohesive underlying intuition guiding the development. However, now that tens of online scheduling papers have used potential functions, one can see that a “standard” potential function has emerged that seems to be applicable to a wide range of problems. The use of this standard potential function to prove amortized local competitiveness can no longer be considered to be magical, and is a learnable technique. Our main goal here is to give a tutorial teaching this technique to readers with some modest prior knowledge of scheduling, online problems, and the concept of worst-case performance ratios.	amortized analysis;best, worst and average case;online algorithm;potential method;scheduling (computing)	Sungjin Im;Benjamin Moseley;Kirk Pruhs	2011	SIGACT News	10.1145/1998037.1998058	mathematical optimization;combinatorics;real-time computing;dynamic priority scheduling;computer science;theoretical computer science;mathematics;distributed computing;algorithm	Theory	15.497339733150515	12.827043667631417	85114
6c74591aaaf076ccbfdd47ee24d112d29629c61a	characterization and modelling of guillotine constraints	modelizacion;metodo polinomial;cutting stock;condition necessaire suffisante;cutting stock problem;modelisation;saber hacer;mixed integer program;programacion mixta entera;probleme decoupe;know how;polynomial method;polynomial algorithm;necessary and sufficient condition;savoir faire;programmation partiellement en nombres entiers;mixed integer programming;problema troquelado;methode polynomiale;guillotine pattern;modeling;condicion necesaria suficiente	This paper focuses on guillotine cuts which often arise in real-life cutting stock problems. In order to construct a solution verifying guillotine constraints, the first step is to know how to determine whether a given cutting pattern is a guillotine pattern. For this purpose, we first characterize guillotine patterns by proving a necessary and sufficient condition. Then, we propose a polynomial algorithm to check this condition. Based on this mathematical characterization of guillotine patterns, we then show that guillotine constraints can be formulated into linear inequalities. The performance of the algorithm to check guillotine cutting patterns is evaluated by means of computational results.		Said Ben Messaoud;Chengbin Chu;Marie-Laure Espinouse	2008	European Journal of Operational Research	10.1016/j.ejor.2007.08.029	mathematical optimization;combinatorics;systems modeling;integer programming;operations management;cutting stock problem;mathematics;algorithm	Vision	18.917189618021133	7.921509056596424	85152
73df05cabd70b3cc772d1009b819eb6d3350068f	bounds for the quadratic assignment problem using the bundle method	arbre graphe;assignment problem;quadratic programming;90c06;afectacion cuadratica;probleme affectation;programmation semi definie;tree graph;programmation quadratique;branching;bundle method;methode faisceau;llamada;problema np duro;methode point interieur;90c57;np hard problem;branch and bound method;relaxation semidefinie;metodo punto interior;90c51;metodo branch and bound;probleme np difficile;mathematical programming;90c27;ramificacion;recall;metodo haz;problema asignacion;ramification;programacion cuadratica;quadratic assignment problem;methode separation et evaluation;programacion semi definida;relajacion semidefinida;interior point method 90c22 90c27 90c57 90c51 90c06;arbol grafo;interior point method;semidefinite programming relaxation;branch and bound;rappel;programmation mathematique;programacion matematica;semidefinite relaxation;semidefinite program;semi definite programming;quadratic assignment;affectation quadratique	Semidefinite programming (SDP) has recently turned out to be a very powerful tool for approximating some NP-hard problems. The nature of the quadratic assignment problem (QAP) suggests SDP as a way to derive tractable relaxations. We recall some SDP relaxations of QAP and solve them approximately using a dynamic version of the bundle method. The computational results demonstrate the efficiency of the approach. Our bounds are currently among the strongest ones available for QAP. We investigate their potential for branch and bound settings by looking also at the bounds in the first levels of the branching tree.	approximation algorithm;branch and bound;cobham's thesis;np-hardness;quadratic assignment problem;semidefinite programming;subgradient method	Franz Rendl;Renata Sotirov	2007	Math. Program.	10.1007/s10107-006-0038-8	mathematical optimization;combinatorics;branching;interior point method;calculus;np-hard;recall;mathematics;assignment problem;ramification;quadratic programming;branch and bound;tree;quadratic assignment problem	ML	22.588103286046394	13.305940216690972	85248
50ddd4b26932fc4574107e4b005782eb4cc636be	satisfiability-based algorithms for boolean optimization	non chronological backtracking;branch and bound algorithm;boolean function;automated reasoning;satisfiability;backtrack search;boolean satisfiability;artificial intelligent;binate covering problem;non monotonic reasoning;covering problem;branch and bound;propositional satisfiability;modeling tool;electronic design automation	This paper proposes new algorithms for the Binate Covering Problem (BCP), a well-known restriction of Boolean Optimization. Binate Covering finds application in many areas of Computer Science and Engineering. In Artificial Intelligence, BCP can be used for computing minimum-size prime implicants of Boolean functions, of interest in Automated Reasoning and Non-Monotonic Reasoning. Moreover, Binate Covering is an essential modeling tool in Electronic Design Automation. The objectives of the paper are to briefly review branch-and-bound algorithms for BCP, to describe how to apply backtrack search pruning techniques from the Boolean Satisfiability (SAT) domain to BCP, and to illustrate how to strengthen those pruning techniques by exploiting the actual formulation of BCP. Experimental results, obtained on representative instances indicate that the proposed techniques provide significant performance gains for a large number of problem instances.	algorithm;approximation;artificial intelligence;automated reasoning;backtracking;boolean satisfiability problem;branch and bound;bulk copy program;computer engineering;covering problems;electronic design automation;linear programming;mathematical optimization;non-monotonic logic;text simplification	Vasco M. Manquinho;Joao Marques-Silva	2004	Annals of Mathematics and Artificial Intelligence	10.1023/B:AMAI.0000012872.46214.11	mathematical optimization;discrete mathematics;boolean expression;electronic design automation;computer science;artificial intelligence;maximum satisfiability problem;theoretical computer science;machine learning;mathematics;branch and bound;algorithm	AI	12.548262366144625	16.825804753174875	85299
e16223f68fa38c3bacadb7a494e317a48f5e8980	minimizing the number of tardy jobs in single machine sequencing	minimisation;minimization;ordered set;machine unique;minimizacion;ensemble ordonne;combinatorial problem;probleme combinatoire;single machine;problema combinatorio;scheduling;retard;precedence constraint;contrainte precedence;ordonamiento;retraso;ordonnancement;conjunto ordenado	Abstract Sharary, A.H. and N. Zaguia, Minimizing the number of tardy jobs in single machine sequencing, Discrete Mathematics 117 (1993) 215-223. A set P of n jobs has to be processed without preemption, one job at a time, on a single machine. The weight and processing time of each job is one. Furthermore, the jobs are subject to precedence constraints represented by a given ordered set (P, <). In a feasible schedule a job is called a tardy job if its completion time is strictly bigger than its due time. The problem is to find a feasible schedule that minimizes the number of tardy jobs. Clearly each job cannot be completed before 1 D(x) I= 1 {y in P: y < x} 1 units of time. So we fix a nonnegative integer k and we allow a tardiness of k units of time for each job. This problem seems to be hard even when the structure of the order on P is quite simple. In this paper we present an effective procedure for constructing an optimal schedule in some special cases. Moreover, we show that the problem of minimizing the number of tardy jobs for interval orders is related to an interesting combinatorial problem of ordered sets.		Ahmad Sharary;Nejib Zaguia	1993	Discrete Mathematics	10.1016/0012-365X(93)90336-R	minimisation;mathematical optimization;mathematics;scheduling;algorithm	Theory	16.42337130403758	10.141346591127961	85498
3c4f18a19bbe66a5be0cbd5dd65ce24c1414fe4b	approximating min-max (regret) versions of some polynomial problems	camino mas corto;shortest path;temps polynomial;metodo minimax;approximation algorithm;arbre maximal;minimax method;combinatorial optimization problem;plus court chemin;approximation;optimisation combinatoire;scenario;min max regret;aproximacion polinomial;argumento;arbol maximo;fptas;versions;script;methode minimax;approximation polynomiale;minimum spanning tree;algoritmo aproximacion;polynomial time;fully polynomial time approximation scheme;spanning tree;algorithme approximation;combinatorial optimization;min max;regret;polynomial approximation;optimizacion combinatoria;tiempo polinomial	While the complexity of min-max and min-max regret versions of most classical combinatorial optimization problems has been thoroughly investigated, there are very few studies about their approximation. For a bounded number of scenarios, we establish a general approximation scheme which can be used for min-max and min-max regret versions of some polynomial problems. Applying this scheme to shortest path and minimum spanning tree, we obtain fully polynomial-time approximation schemes with much better running times than the ones previously presented in the literature.	approximation;combinatorial optimization;file spanning;mathematical optimization;maxima and minima;minimum spanning tree;polynomial;regret (decision theory);shortest path problem;time complexity	Hassene Aissi;Cristina Bazgan;Daniel Vanderpooten	2006		10.1007/11809678_45	time complexity;mathematical optimization;combinatorics;discrete mathematics;polynomial-time approximation scheme;spanning tree;combinatorial optimization;scenario;minimum spanning tree;approximation;mathematics;shortest path problem;approximation algorithm;algorithm;regret	Theory	21.321706693066833	13.95130993434599	85644
0fd8aa4a24cc8e53613ebf030c36f55a529c583a	the price of anarchy in network creation games is (mostly) constant	price of anarchy	We study the price of anarchy and the structure of equilibria in network creation games. A network creation game (first defined and studied by Fabrikant et al. [4]) is played by n players {1, 2, . . . , n}, each identified with a vertex of a graph (network), where the strategy of player i, i = 1, . . . , n, is to build some edges adjacent to i. The cost of building an edge is α > 0, a fixed parameter of the game. The goal of every player is to minimize its creation cost plus its usage cost. The creation cost of player i is α times the number of built edges. In the SUMGAME (the original variant of Fabrikant et al. [4]) the usage cost of player i is the sum of distances from i to every node of the resulting graph. In the MAXGAME (variant defined and studied by Demaine et al. [3]) the usage cost is the eccentricity of i in the resulting graph of the game. In this paper we improve previously known bounds on the price of anarchy of the game (of both variants) for various ranges of α, and give new insights into the structure of equilibria for various values of α. The two main results of the paper show that for α > 273 ċ n all equilibria in SUMGAME are trees and thus the price of anarchy is constant, and that for α > 129 all equilibria in MAXGAME are trees and the price of anarchy is constant. For SUMGAME this (almost) answers one of the basic open problems in the field - is price of anarchy of the network creation game constant for all values of α? - in an affirmative way, up to a tiny range of α.	anarchy	Matús Mihalák;Jan Christoph Schlegel	2010		10.1007/978-3-642-16170-4_24	price of stability;simulation;economics;public economics;microeconomics;mathematical economics;price of anarchy	Theory	20.139386646411456	18.063839106585927	85766
d4c60cb8c70806b3776d033df0d35720a77495c4	competitive ratio of list scheduling on uniform machines and randomized heuristics	online algorithm;randomized scheduling;online scheduling;analysis of algorithm;analysis of algorithms;algorithm;randomized algorithm;list scheduling;online algorithms;competitive ratio	We study online scheduling on m uniform machines, where m − 1 of them have a reference speed 1 and the last one a speed s with 0 ≤ s ≤ 1. The competitive ratio of the well-known List Scheduling (LS) algorithm is determined. For some values of s and m = 3, LS is proven to be the best deterministic algorithm. We describe a randomized heuristic for m machines. Finally, for the case m = 3, we develop and analyze the competitive ratio of a randomized algorithm which outperforms LS for any s.		Antoine Musitelli;Jean-Marc Nicoletti	2011	J. Scheduling	10.1007/s10951-010-0177-x	fair-share scheduling;competitive analysis;online algorithm;mathematical optimization;flow shop scheduling;computer science;rate-monotonic scheduling;machine learning;distributed computing;algorithm	Theory	15.853968442186387	11.480312133286315	86161
a5e831030aafedc69cdf60b2c5cedb6bbd497349	fast cube tests for lia constraint solving	linear arithmetic;integer arithmetic;constraint solving;smt	We present two tests that solve linear integer arithmetic constraints. These tests are sound and efficiently find solutions for a large number of problems. While many complete methods search along the problem surface for a solution, these tests use cubes to explore the interior of the problems. The tests are especially efficient for constraints with a large number of integer solutions, e.g., those with infinite lattice width. Inside the SMT-LIB benchmarks, we have found almost one thousand problem instances with infinite lattice width, and we have shown the advantage of our cube tests on these instances by comparing our implementation of the cube test with several state-of-the-art SMT solvers. Our implementation is not only several orders of magnitudes faster, but it also solves all instances, which most SMT solvers do not. Finally, we discovered an additional application for our cube tests: the extraction of equalities implied by a system of linear arithmetic inequalities. This extraction is useful both as a preprocessing step for linear integer constraint solving as well as for the combination of theories by the Nelson-Oppen	constraint satisfaction problem;expect;experiment;heuristic;iso/iec 10967;integer programming;lambda cube;olap cube;polyhedron;preprocessor;simultaneous multithreading	Martin Bromberger;Christoph Weidenbach	2016		10.1007/978-3-319-40229-1_9	mathematical optimization;combinatorics;discrete mathematics;mathematics;algorithm	AI	24.383089643788875	13.826570889863197	86433
e588fcba3aba0d3efddafd0eb9188c5e58b760bc	algorithms and approximation schemes for minimum lateness/tardiness scheduling with rejection	dynamic programming;metodo polinomial;programacion dinamica;fonction valeur;approximate algorithm;probleme np complet;approximation algorithm;date echeance;dynamic program;funcion valor;objective function;polynomial time algorithm;aproximacion polinomial;rejection;polynomial method;scheduling;retard;approximation polynomiale;programmation dynamique;algoritmo aproximacion;due date;polynomial time;coste;approximation scheme;fecha vencimiento;earliest due date;fully polynomial time approximation scheme;problema np completo;value function;algorithme approximation;methode polynomiale;retraso;rechazo;rejet;ordonnancement;reglamento;np complete problem;polynomial approximation;cout	We consider the problem of minimum lateness/tardiness scheduling with rejection for which the objective function is the sum of the maximum lateness/tardiness of the scheduled jobs and the total rejection penalty (sum of rejection costs) of the rejected jobs. If rejection is not considered, the problems are solvable in polynomial time using the Earliest Due Date (EDD) rule. We show that adding the option of rejection makes the problems NP-complete. We give pseudo-polynomial time algorithms, based on dynamic programming, for these problems. We also develop a fully polynomial time approximation scheme (FPTAS) for minimum tardiness scheduling with rejection using a geometric rounding technique on the total rejection penalty. Observe that the usual notion of an approximation algorithm (guaranteed factor bound relative to optimal objective function value) is inappropriate when the optimal objective function value could be negative, as is the case with minimum lateness scheduling with rejection. An alternative notion of approximation, called ∈-optimization approximation [7], is suitable for designing approximation algorithms for such problems. We give a polynomial time e-optimization approximation scheme (PTEOS) for minimum lateness scheduling with rejection and a fully polynomial time ∈-optimization approximation scheme (FPTEOS) for a modified problem where the total rejection penalty is the product (and not the sum) of the rejection costs of the rejected jobs.	algorithm;approximation;rejection sampling	Sudipta Sengupta	2003		10.1007/978-3-540-45078-8_8	time complexity;mathematical optimization;polynomial-time approximation scheme;np-complete;input/output;computer science;dynamic programming;calculus;mathematics;bellman equation;scheduling;approximation algorithm;algorithm	Robotics	17.216880251031803	10.445906658946496	86497
c17cdccf6088d37a34bc21a53150068dda5f931f	a worst case analysis of a dynamic programming-based heuristic algorithm for 2d unconstrained guillotine cutting	dynamic programming;metodo caso peor;optimal solution;heuristic;methode recursive;2d cutting;programacion dinamica;mathematics;algorithm analysis;complexite calcul;qa mathematics;heuristic method;metodo recursivo;recursive method;heuristic dynamic programming;metodo heuristico;dynamic method;dynamic program;worst case analysis;qa75 electronic computers computer science;complejidad computacion;methode dynamique;computational complexity;programmation dynamique;methode cas pire;metodo dinamico;analyse algorithme;methode heuristique;worst case method;heuristic dynamic programming 2d cutting;analisis algoritmo;heuristic algorithm	In this paper, a dynamic programming-based recursive method is proposed for solving an unconstrained 2D rectangular cutting problem. The algorithm is an incomplete method, in which some intricate cutting patterns may not be obtained. The worst case performance of the algorithm is evaluated and some theoretical analyses for the algorithm are performed. Compared to traditional dynamic programming, this algorithm gives a high percentage of optimal solutions (94.84%, 86.67% and 77.83% for small, medium and large sized unweighted instances, 99.67%, 99.50% and 97.00% for small, medium and large sized weighted instances) but features a far lower computational complexity. Computational results are also presented for some known benchmarks. Crown Copyright 2009 Published by Elsevier B.V. All rights reserved.	approximation algorithm;benchmark (computing);best, worst and average case;computation;computational complexity theory;crown group;cutting stock problem;cutting-plane method;dynamic programming;exact algorithm;heuristic (computer science);procedural generation;randomness;recursion (computer science);time complexity	Xiang Song;C. B. Chu;Rhyd Lewis;Y. Y. Nie;Jonathan M. Thompson	2010	European Journal of Operational Research	10.1016/j.ejor.2009.05.047	heuristic;mathematical optimization;heuristic;computer science;artificial intelligence;dynamic programming;mathematics;computational complexity theory;algorithm	AI	19.07627391110766	10.491526018039421	86799
f724e623a529a8e90ae6c5b0aaa105deeaab3c6e	cdcl solver additions: local look-ahead, all-unit-uip learning and on-the-fly probing		Many applications can be tackled with modern CDCL SAT solvers. However, most of todays CDCL solvers guide their search with a simple, but very fast to compute decision heuristic. In contrast to CDCL solvers, SAT solvers that are based on look-ahead procedures spend more time for decisions and with their local reasoning. This paper proposes three light-weight additions to the CDCL algorithm, local look-ahead, all-unit-UIP learning and on-the-fly-probing which allow the search to find unit clauses that are hard to find by unit propagation and clause learning alone. With the additional reasoning steps of these techniques the resulting algorithm is able to solve SAT formulas that cannot be solved by the	algorithm;conflict-driven clause learning;constraint learning;heuristic;software propagation;solver;unit propagation;uip	Norbert Manthey	2014		10.1007/978-3-319-11206-0_11	mathematical optimization;theoretical computer science;machine learning	AI	22.665432741189807	4.282626767371419	86849
4f42e5945e935af37ada15cf4e6e4781c263280a	a bicriteria approach to scheduling a single machine with job rejection and positional penalties	positional penalties;bicriteria optimization;scheduling with job rejection;fptas;pseudo polynomial time algorithm;mathcal np hard	Single machine scheduling problems have been extensively studied in the literature under the assumption that all jobs have to be processed. However, in many practical cases, one may wish to reject the processing of some jobs in the shop, thus resulting in a rejection cost. In such a framework, the scheduler has to decide rst which jobs will be rejected and which will be accepted. Then he has to schedule the accepted jobs e¢ ciently. Scheduling with job rejection is essentially a problem with two criteria. The rst is a scheduling criterion, which is dependent on the completion times of the accepted jobs, and the second is the total rejection cost. Problems of scheduling with rejection have been previously studied, but usually in a narrow framework  focusing on one scheduling criterion at a time. This paper provides a unied bicriteria analysis of a large set of single machine problems sharing a common property: all problems can be represented by or reduced to a scheduling problem with a scheduling criterion which includes positional penalties. Among these scheduling criteria are the minimization of the makespan, the sum of completion times, the sum and variation of completion times, and the total earliness plus tardiness costs where the due dates are assignable. Four di¤erent problem variations for dealing with the two criteria are studied. The variation of minimizing the total integrated cost is shown to be solvable in polynomial time, while all other three variations are shown to be NP-hard. For those hard problems, we provide a pseudo polynomial time algorithm. An FPTAS for obtaining an approximate e¢ cient schedule is provided as well. In addition, we present an interesting special case which is solvable in polynomial time. This research was supported by THE ISRAEL SCIENCE FOUNDATION (grant No. 633/08). Partial support by the Paul Ivanier Center for Robotics and Production Management, Ben-Gurion University of the Negev is also gratefully acknowledged. ye-mails: dvirs@bgu.ac.il and nufarg@bgu.ac.il ze-mails: lirony@ie.technion.ac.il	approximation algorithm;decision problem;job stream;makespan;np-hardness;p (complexity);polynomial-time approximation scheme;rejection sampling;robotics;schedule (project management);scheduling (computing);single-machine scheduling;time complexity	Dvir Shabtay;Nufar Gasper;Liron Yedidsion	2012	J. Comb. Optim.	10.1007/s10878-010-9350-6	fair-share scheduling;open-shop scheduling;mathematical optimization;flow shop scheduling;dynamic priority scheduling;rate-monotonic scheduling;mathematics;distributed computing;round-robin scheduling;multiprocessor scheduling	Theory	15.619876225659546	10.421065776462934	87096
da40fa4867af75f1144df5846d10dd4cf1e194a7	scheduling of single-arm cluster tools with multi-type wafers and shared pms		As the wafer size increases and consumption demand changes, wafer fabrication mode tends to be multi-type and small-batch production. However, most of existing scheduling methods focus on the control problems of single wafer type, which is not suitable for the scheduling of multiple wafer types. With wafer residency time constraints considered, this paper concentrates on the scheduling and control problems of single-armed cluster tools with multi-type wafers and shared PMs. To balance workloads among processing steps, a virtual processing modules technology is adopted. According to the modified backward scheduling strategy, analytic expressions for testing schedulabilities are derived. Finally, a periodic scheduling algorithm for steady-state is presented. Meanwhile, illustrative examples are given to verify the feasibility and availability of the proposed algorithm.	algorithm;scheduling (computing);steady state;virtual machine;wafer (electronics);wafer fabrication	Jipeng Wang;Chunrong Pan;Hesuan Hu;Yuan Zhou	2017	2017 13th IEEE Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2017.8256242	wafer fabrication;periodic graph (geometry);steady state;scheduling (computing);wafer;real-time computing;job shop scheduling;expression (mathematics);computer science	HPC	11.870260761809062	5.63482348258519	87327
0e6bd1ec7ba259aa5ac151110e03583213f7417c	randomized search heuristics as an alternative to exact optimization	programacion discreta;optimisation;discrete optimization;complexity theory;optimizacion;004;e;computational intelligence;heuristic method;simplex algorithm;metodo heuristico;satisfiability;analisis programa;aleatorizacion;programmation discrete;mathematical programming;randomisation;linear program;timing analysis;optimization;program analysis;methode heuristique;collaborative research;network flow;analyse programme;randomization;heuristique recherche randomisee;programmation mathematique;random search;programacion matematica;theorie complexite;large scale problem;discrete programming	There are many alternatives to handle discrete optimization problems in applications. Problem-specific algorithms vs. heuristics, exact optimization vs. approximation vs. heuristic solutions, guaranteed run time vs. expected run time vs. experimental run time analysis. Here, a framework for a theory of randomized search heuristics is presented. After a brief history of discrete optimization, scenarios are discussed where randomized search heuristics are appropriate. Different randomized search heuristics are presented and it is argued why the expected optimization time of heuristics should be analyzed. Afterwards, the tools for such an analysis are described and applied to some well-known discrete optimization problems. Finally, a complexity theory of so-called blackbox problems is presented and it is shown how the limits of randomized search heuristics can be proved without assumptions like NP = P. This survey article does not contain proofs but hints where to find them.	approximation;computational complexity theory;discrete optimization;heuristic (computer science);mathematical optimization;np (complexity);randomized algorithm;run time (program lifecycle phase);search engine optimization	Ingo Wegener	2004		10.1007/978-3-540-25967-1_10	program analysis;randomization;discrete optimization;mathematical optimization;e;combinatorics;flow network;random search;computer science;artificial intelligence;heuristics;machine learning;computational intelligence;mathematics;simplex algorithm;static timing analysis;algorithm;satisfiability	Theory	13.23209539669365	17.19473258625694	87707
70bbb8e1612ec0ce13691ff5773f4141b7a5655f	how heavy-tailed distributions affect simulation-generated time averages	heavy tail;generation time;size distribution;lomax distribution;m g 1 queue;network model;sample path average;m g queue;statistical inference;heavy tailed distribution;covariance function;conditional distribution;telecommunication networks;discrete event simulation;network modeling	For statistical inference based on telecommunications network simulation, we examine the effect of a heavy-tailed file-size distribution whose corresponding density follows an inverse power law with exponent α + 1, where the shape parameter α is strictly between 1 and 2. Representing the session-initiation and file-transmission processes as an infinite-server queueing system with Poisson arrivals, we derive the transient conditional mean and covariance function that describes the number of active sessions as well as the steady-state counterparts of these moments. Assuming the file size (service time) for each session follows the Lomax distribution, we show that the variance of the sample mean for the time-averaged number of active sessions tends to zero as the power of 1 − α of the simulation run length. Therefore, impractically large sample-path lengths are required to achieve point estimators with acceptable levels of statistical accuracy. This study compares the accuracy of point estimators based on the Lomax distribution with those for lognormal and Weibull file-size distributions whose parameters are determined by matching their means and a selected extreme quantile with those of the Lomax. Both alternatives require shorter run lengths than the Lomax to achieve a given level of accuracy. Although the lognormal requires longer sample paths than the Weibull, it better approximates the Lomax and leads to practicable run lengths in almost all scenarios.	queueing theory;run-length encoding;server (computing);simulation;steady state;telecommunications network	George S. Fishman;Ivo J. B. F. Adan	2006	ACM Trans. Model. Comput. Simul.	10.1145/1138464.1138467	econometrics;mathematical optimization;heavy-tailed distribution;network model;mathematics;lomax distribution;statistics	Metrics	10.546236053964861	12.050306378605688	87773
cd79eff0d14f1e155929b34a5f399ecdf672b4ba	tractability properties of the weighted star discrepancy	weighted star discrepancy;quasi monte carlo;large classes;strong tractability;lower bound	Tractability properties of various notions of discrepancy have been intensively studied in the last decade. In this paper we consider the so-called weighted star discrepancy which was introduced by Sloan and Woźniakowski. We show that under a very mild condition on the weights one can obtain tractability with s-exponent zero (s is the dimension of the point set). In the case of product weights we give a condition such that the weighted star discrepancy is even strongly tractable. Furthermore, we give a lower bound for the weighted star discrepancy for a large class of weights. This bound shows that for such weights one cannot obtain strong tractability.	cobham's thesis;discrepancy function;low-discrepancy sequence	Aicke Hinrichs;Friedrich Pillichshammer;Wolfgang Ch. Schmid	2008	J. Complexity	10.1016/j.jco.2007.08.002	discrepancy function;quasi-monte carlo method;mathematical optimization;combinatorics;discrete mathematics;mathematics;upper and lower bounds	Theory	22.577031913665987	16.25073394939506	87787
7edb59307f1e1867c3e2a063de32b9fc8b417806	applications of genetic algorithm and simulation to dispatching rule-based fms scheduling	performance measure;dispatching rules;flexible manufacturing systems;dispatching rule based fms scheduling;raw materials;processor scheduling;simulation;buffer storage;computational modeling;production control;material storage;four level simultaneous decision making problem genetic algorithm simulation dispatching rule based fms scheduling production scheduling;decision theory;production;artificial intelligence flexible manufacturing systems production control genetic algorithms decision theory;artificial intelligence;genetic algorithm;genetic algorithms;production scheduling;four level simultaneous decision making problem;robotics and automation;dispatching;genetic algorithms dispatching flexible manufacturing systems computational modeling buffer storage material storage production processor scheduling robotics and automation raw materials	This paper presents a hybrid intelligent approach to a production scheduling problem in FMS. An FMS scheduling system is modelled as a four-level simultaneous decision-making problem. The genetic algorithm and simulation approaches are integrated to seek efficiently the best combination of dispatching rules in order to obtain an appropriate production schedule under specific performance measures.	genetic algorithm;scheduling (computing);simulation	Hideo Fujimoto;Kazuhiko Yasuda;Yuao Tanigawa;Kazuhiko Iwahashi	1995		10.1109/ROBOT.1995.525284	fair-share scheduling;real-time computing;simulation;genetic algorithm;dynamic priority scheduling;computer science;engineering;artificial intelligence	Embedded	10.951863983591572	5.815493353591282	87819
f0fbb53604a8f6aba117853bd358756bcb381840	parallel combinatorial algorithms for multi-sets and their applications	parallel algorithm;iterative combination;multi set;iterative permutation	In this paper we extend some well-known notions of combinatorics on multi-sets such as iterative permutation, multi-subset, iterative combination and then construct new efficient algorithms for generating all iterative permutations, multi-subsets and iterative combinations of a multi-set. Applying the parallelizing method based on output decomposition we parallelize the algorithms. Furthermore, we use these algorithms to solve an optimal problem of work arrangement and an extended knapsack one.	algorithm	Hoang Chi Thanh	2013	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194013400068	mathematical optimization;computer science;theoretical computer science;parallel algorithm;iterative method	SE	20.227304682871658	11.847878340083358	87954
6b67111bf02b7888cda0665b076b9ee93b7fe29d	an efficient algorithm for the multiperiod capacity expansion of one location in telecommunications	camino mas corto;dynamic programming;shortest path;programacion dinamica;probleme sac a dos;time complexity;efficient algorithm;telecommunication network;problema mochila;costo;knapsack problem;planificacion;complexite temps;red telecomunicacion;programmation dynamique;capacity expansion exact solution via shortest paths;reseau telecommunication;chemin plus court;planning;facilities equipment planning;planification;complejidad tiempo;cout;deterministic solution to time dependent knapsack problems	The minimum cost multiperiod capacity expansion of one location in telecommunications network planning can be formulated as a time-dependent knapsack problem. The problem consists of meeting integral demands at distinct time periods at minimum total discounted cost through a selection of items with integral costs and capacities from a collection of N distinct types of objects. This note presents an efficient pseudopolynomial time solution to this time-dependent knapsack problem. The technique involves an initial dynamic programming run with time complexity OND + C followed by a shortest path algorithm with worst-case time complexity OC2T through a suitably defined network, where D and C are the maxima of the values of the demands and capacities, and T is the number of time periods to be considered. The application of this technique to the problem of optimal capacity expansion of one location in telecommunications network planning is described and computational results are reported.	algorithm	Iraj Saniee	1995	Operations Research	10.1287/opre.43.1.187	planning;time complexity;continuous knapsack problem;mathematical optimization;input/output;computer science;operations management;dynamic programming;mathematics;shortest path problem;knapsack problem;algorithm;telecommunications network	Crypto	16.57775511124597	4.849411339117586	88180
f54dd2180e2e80c9fd9002aa7b46a5a85546a2d6	an integer program and a hybrid genetic algorithm for the university timetabling problem	university timetabling problem;mixed integer linear program;consecutiveness constraint;integer program;periodicity constraint;heuristic algorithm;hybrid genetic algorithm	An integer program and a hybrid genetic algorithm for the university timetabling problem Xuehao Feng, Yuna Lee & Ilkyeong Moon To cite this article: Xuehao Feng, Yuna Lee & Ilkyeong Moon (2017) An integer program and a hybrid genetic algorithm for the university timetabling problem, Optimization Methods and Software, 32:3, 625-649, DOI: 10.1080/10556788.2016.1233970 To link to this article: http://dx.doi.org/10.1080/10556788.2016.1233970	experiment;genetic algorithm;hercules graphics card;integer programming;local search (optimization);memetic algorithm;quasiperiodicity;search algorithm;tabu search;twisted pair	Xuehao Feng;Yuna Lee;Ilkyeong Moon	2017	Optimization Methods and Software	10.1080/10556788.2016.1233970	heuristic;mathematical optimization;artificial intelligence;mathematics;algorithm	AI	22.799823063541073	8.445582915414715	88219
789afea7bec53f538253f4d120e7b0b514e33538	sorting permutations by reversals through branch-and-price	networks graphs;matchings;analysis of algorithms;integer;molecular biology;exact algorithm;linear program;algorithms;programming;applications;integer linear program;branch and price	We describe an exact algorithm for the problem of sorting a permutation by the minimum number of reversals, originating from evolutionary studies in molecular biology. Our approach is based on an integer linear programming formulation of a graph-theoretic relaxation of the problem, calling for a decomposition of the edge set of a bicolored graph into the maximum number of alternating cycles. The formulation has one variable for each alternating cycle, and the associated linear programming relaxation is solved by column generation. A major advantage with respect to previous approaches is that the subproblem to face in the column generation phase no longer requires the solution of min-cost general matching problems, but of min-cost bipartite matching problems. Experiments show that there is a tremendous speed-up in going from general matching to bipartite matching, although the best-known algorithms for the two problems have the same theoretical worst-case complexity. We also show the worst-case ratio between the lower bound value obtained by our new method and previous ones. We illustrate the effectiveness of our approach through extensive computational experiments. In particular, we can solve to proven optimality the largest real-world instances from the literature in a few seconds, and the other (smaller) real-world instances within a few milliseconds on a workstation. Moreover, we can solve to optimality random instances with n = 100 within 3 seconds, and with n = 200 within 15 minutes, where n is the size of the permutation, whereas the size of the instances solvable by previous approaches was at most 100. We also describe a polynomial-time heuristic algorithm which consistently finds solutions within 2% of the optimum for random instances with n up to 1000. (Sorting By Reversals; Branch-and-Price; Alternating-Cycle Decomposition; Column Generation; Matching)	best, worst and average case;branch and price;column generation;computation;decision problem;exact algorithm;experiment;graph theory;heuristic (computer science);integer programming;linear programming formulation;linear programming relaxation;matching (graph theory);maxima and minima;regular expression;sorting;time complexity;workstation;worst-case complexity	Alberto Caprara;Giuseppe Lancia;See-Kiong Ng	2001	INFORMS Journal on Computing	10.1287/ijoc.13.3.224.12631	integer;programming;mathematical optimization;combinatorics;discrete mathematics;linear programming;branch and price;3-dimensional matching;analysis of algorithms;mathematics;information technology;algorithm	Theory	20.648123251160648	11.241012503612346	88310
0824937e919eeafe82e76d49c4dcd4d89f7180d4	performance guarantees of local search for multiprocessor scheduling	metodo caso peor;maastricht university;performance guarantee;multiprocessor scheduling;tiempo total acabamiento;algoritmo busqueda;algorithm performance;local search algorithm;algorithme recherche;search algorithm;machine parallele;temps total achevement;digital archive;analysis of algorithm;operations research and management science;makespan;mathematical programming;resultado algoritmo;scheduling;open access;local optimum;performance algorithme;methode cas pire;parallel machines;ordonamiento;production scheduling;publication;scientific;worst case method;programmation mathematique;local search;parallel machine;programacion matematica;institutional repository;ordonnancement;optimum local	This paper deals with the worst-case performance of local search algorithms for makespan minimization on parallel machines. We analyze the quality of the local optima obtained by iterative improvements over the jump, the swap, and the newly defined push neighborhood.	local search (optimization);multiprocessing;multiprocessor scheduling;scheduling (computing)	Petra Schuurman;Tjark Vredeveld	2001		10.1007/3-540-45535-3_29	job shop scheduling;mathematical optimization;simulation;computer science;local search;mathematics;algorithm	Embedded	17.72326634121156	9.198684067773696	88723
44bc5436b150c7d0509337c56998725f371be112	approximating the joint replenishment problem with deadlines	approximation algorithms;lp rounding;inventory theory;joint replenishment problem jrp	The objective of the classical Joint Replenishment Problem (JRP) is to minimize ordering costs by combining orders in two stages, first at some retailers, and then at a warehouse. These orders are needed to satisfy demands that appear over time at the retailers. We investigate the natural special case that each demand has a deadline until when it needs to be satisfied. For this case, we present a randomized 5/3-approximation algorithm. We moreover prove that JRP with deadlines is APX-hard. Finally, we extend the known hardness results by showing that JRP with linear delay cost functions is NP-hard, even if each retailer has to satisfy only three demands.	apx;randomized algorithm	Tim Nonner;Alexander Souza	2009	Discrete Math., Alg. and Appl.	10.1142/S1793830909000130	mathematical optimization;inventory theory;real-time computing;mathematics;approximation algorithm	Theory	15.5178068994488	10.355575772223258	88761
c435996f37da5b229fe5816c63610f30f170b7e7	an exact algorithm for the type-constrained and variable sized bin packing problem	type constrained bin packing problem;bin packing problem;combinatorial problems;algorithm;combinatorial problem;branch and bound method;exact algorithm	In this paper, we introduce an additional constraint to the one-dimensional variable sized bin packing problem. Practically, some of items have to be packed separately in different bins due to their specific requirement. Therefore, these items are labelled as different types. The bins can be used to pack either any type of items if they are empty originally or the same type of items as what they already have. We model the problem as a type-constrained and variable sized bin packing problem (TVSBPP), and solve it via a branch and bound method. An efficient backtracking procedure is proposed to improve the efficiency of the algorithm.	bin packing problem;exact algorithm;set packing	Chunyang Zhou;Chongfeng Wu;Yun Feng	2009	Annals OR	10.1007/s10479-009-0557-9	mathematical optimization;combinatorics;discrete mathematics;bin packing problem;best bin first;set packing;computer science;cutting stock problem;mathematics;bin;knapsack problem	Robotics	21.733423091784346	10.017099395946053	88794
be4121480b742c3d996dcee687e93f686bf0dfab	genetic search and the dynamic facility layout problem	equipement collectif;layout problem;coaccion;contrainte;probleme agencement;algoritmo genetico;genetics;equipamiento colectivo;combinatorial problem;probleme combinatoire;problema combinatorio;constraint;facility;algorithme genetique;problema disposicion;facility layout;genetic algorithm	This research examines the suitability of genetic algorithms to the problem of facility layout over time. Genetic algorithms use the principles of genetics to evolve an initial population of solutions into a population of superior solutions. One advantage of this approach is its ability to include multiple constraints as well as non-linear and non-convex objective functions. We present a genetic procedure for the multi-period facility layout problem and report results for two test problems.	genetic algorithm;nonlinear system	Daniel G. Conway;Munirpallam A. Venkataramanan	1994	Computers & OR	10.1016/0305-0548(94)90023-X	mathematical optimization;genetic algorithm;computer science;genetic representation;mathematics;constraint;operations research;algorithm	AI	20.07700063664253	4.995530930530851	89055
e5ec9b006c30224e15560d1ed2b19c608a7fbeb4	k-center problems with minimum coverage	workload;location problem;probleme localisation;localisation installation;approximate algorithm;k center problem;approximation algorithm;problema np duro;68wxx;np hard problem;probleme np difficile;informatique theorique;probleme k centre;algoritmo aproximacion;borne inferieure;charge travail;facility location problem;problema localizacion;minimum coverage;information system;operations management;algorithme approximation;carga trabajo;couverture minimum;68w25;lower bound;facility location;cota inferior;computer theory;informatica teorica	In this work, we study an extension of the k-center facility location problem, where centers are required to service a minimum of clients. This problem is motivated by requirements to balance the workloadof centerswhile allowing each center to cater to a spreadof clients.Westudy three variants of this problem, all of which are shown to be NP-hard. In-approximation hardness and approximation algorithmswith factorsequal or close to thebest lowerboundsareprovided.Generalizations, including vertex costs and vertex weights, are also studied. © 2004 Elsevier B.V. All rights reserved.	approximation algorithm;dummy variable (statistics);emoticon;facility location problem;metric k-center;np-hardness;requirement;social inequality;time complexity;universal quantification;verification and validation;vertex cover	Andrew Lim;Brian Rodrigues;Fan Wang;Zhou Xu	2005	Theor. Comput. Sci.	10.1016/j.tcs.2004.08.010	computer science;facility location problem;calculus;mathematics;approximation algorithm;algorithm	ECom	20.801070443757084	14.284457286520162	89162
0534b4ee67a3fe1f46685eecf4ee427295f51c24	the online knapsack problem: advice and randomization	resource augmentation;knapsack problem;advice complexity;online computation;randomization	We study the advice complexity and the random bit complexity of the online knapsack problem. Given a knapsack of unit capacity, and n items that arrive in successive time steps, an online algorithm has to decide for every item whether it gets packed into the knapsack or not. The goal is to maximize the value of the items in the knapsack without exceeding its capacity. In the model of advice complexity of online problems, one asks how many bits of advice about the unknown parts of the input are both necessary and sufficient to achieve a specific competitive ratio. It is well-known that even the unweighted online knapsack problem does not admit any competitive deterministic online algorithm. For this problem, we show that a single bit of advice helps a deterministic online algorithm to become 2-competitive, but that Ω(log n) advice bits are necessary to further improve the deterministic competitive ratio. This is the first time that such a phase transition for the number of advice bits has been observed for any problem. Additionally, we show that, surprisingly, instead of an advice bit, a single random bit allows for a competitive ratio of 2, and any further amount of randomness does not improve this. Moreover, we prove that, in a resource augmentation model, i. e., when allowing the online algorithm to overpack the knapsack by some small amount, a constant number of advice bits suffices to achieve a near-optimal competitive ratio. We also study the weighted version of the problem proving that, with O(log n) bits of advice, we can get arbitrarily close to an optimal solution and, using asymptotically fewer bits, we are not competitive. Furthermore, we show that an arbitrary number of random bits does not permit a constant competitive ratio.	competitive analysis (online algorithm);context of computational complexity;knapsack problem;online algorithm;randomized algorithm;randomness	Hans-Joachim Böckenhauer;Dennis Komm;Richard Královic;Peter Rossmanith	2014	Theor. Comput. Sci.	10.1016/j.tcs.2014.01.027	randomization;continuous knapsack problem;mathematical optimization;combinatorics;mathematics;knapsack problem;algorithm	Theory	17.299653051111783	15.402596084023507	89203
5bda8e3eb77af7ce80e8bca2dbb118b41855cb76	tips: mining top-k locations to minimize user-inconvenience for trajectory-aware services		Facility location problems aim to identify the best locations to set up new services. Majority of the existing works typically assume that the users of the service are static. However, there exists a wide array of services such as fuel stations, ATMs, food joints, etc., that are widely accessed by mobile users, besides the static ones. Such trajectory-aware services should, therefore, factor in the trajectories of its users rather than simply their static locations. In this work, we introduce the problem of optimal placement of facility locations for such trajectory-aware services that minimize the user inconvenience. The inconvenience of a user is defined as the extra distance traveled by her from her regular path to avail a service. We call this as the TIPS problem (Trajectory-aware Inconvenience-minimizing Placement of Services) and consider two variants of it. While the goal of the first variant (called MAX-TIPS) is to minimize the maximum inconvenience faced by any user, that of the second variant (called AVG-TIPS) is to minimize the average inconvenience. As both these problems are NP-hard, we propose multiple efficient heuristics to solve them. Empirical evaluation on real urban scale road networks validate the efficiency and effectiveness of the proposed heuristics.	avg;algorithm;facility location problem;heuristic (computer science);max;np-hardness;synthetic intelligence;time complexity	Shubhadip Mitra;Priya Saraf;Arnab Bhattacharya	2017	CoRR		data mining;heuristics;computer science;facility location problem;trajectory	DB	23.658897086808093	7.2641399661350645	89278
84757e15c69be887ec2f0162e90e0e981feedce7	a heuristics-based advanced planning and scheduling system with bottleneck scheduling algorithm	planning dispatching job shop scheduling manufacturing industries;forward backward;make to order;resource utilization;cycle time;scheduling algorithm job shop scheduling production systems heuristic algorithms engines manufacturing industries resource management algorithm design and analysis dispatching machinery production industries;semiconductor backend assembly companies advanced planning and scheduling system bottleneck scheduling algorithm production scheduling problems discrete manufacturing industry make to stock environment make to order environment bottleneck driven shop floor environment forward scheduling backward scheduling resource utilization work in process heuristic algorithms job prioritization rules machine selection rules dispatching list generation scheduling engine;design and development;job shop scheduling;manufacturing industries;advanced planning and scheduling;scheduling algorithm;work in process;planning;manufacturing industry;production scheduling;make to stock;dispatching;heuristic algorithm	This paper presents a heuristics-based advanced planning and scheduling (APS) system with bottleneck scheduling algorithm. It has been designed to solve production scheduling problems in discrete manufacturing industry. The proposed APS system can be configured to be deployed in different production environments, including make-to-stock, make-to-order, bottleneck-driven shop floor, through its forward, backward and bottleneck scheduling algorithms. It allows users to specify heuristic rules at each operation based on the scheduling policy of the operation. The embedded scheduling techniques facilitates the generation of feasible and practical schedule to achieve a fine balance among the conflicting production goals of maximizing resource utilization, minimizing work-in-process (WIP), and reduction of cycle time. In addition, the system can be easily reconfigured to address them various requirements imposed by the physical and operational constraints of the production environment. The APS system deploys two layers of heuristic algorithms intertwined within the scheduling engine. The two layers of heuristic algorithms are job prioritization (JP) rules and machine selection (MS) rules. JP heuristics rules are designed to prioritize orders at each operation, while machine selection (MS) algorithm selects the best-fit machines and other optional resources to generate the dispatching list. The modular and configurable approach adopted in the design and development of the scheduling engine allows the reconfiguration of basic core JP and MS modules for different industry-specific requirements. The proposed APS system has been successfully implemented to fulfil the daily production scheduling needs of a few semiconductor backend assembly companies.	algorithm;automated planning and scheduling;cognitive dimensions of notations;curve fitting;deployment environment;discrete manufacturing;embedded system;heuristic (computer science);open-shop scheduling;requirement;risk management;scheduling (computing);semiconductor	Tay Jin Chua;F. Y. Wang;Tian Xiang Cai;Xiao-Feng Yin	2006	2006 IEEE Conference on Emerging Technologies and Factory Automation	10.1109/ETFA.2006.355437	fair-share scheduling;fixed-priority pre-emptive scheduling;job shop scheduling;real-time computing;earliest deadline first scheduling;simulation;flow shop scheduling;dynamic priority scheduling;computer science;engineering;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;stride scheduling;scheduling;least slack time scheduling;lottery scheduling;manufacturing;round-robin scheduling	Robotics	11.843933651013382	4.818175770675378	89348
09a730aebf97cdef9bd20c2408aed8d67a726e26	graph balancing: a special case of scheduling unrelated parallel machines	approximate algorithm;s renyi random graphs;gibbs samplers;glauber dynamics;mixing time;ising model;erd odblac;parallel machines;lower bound	We design a 1.75-approximation algorithm for a special case of scheduling parallel machines to minimize the makespan, namely the case where each job can be assigned to at most two machines with the same processing time on either machine. (This is a special case of so-called restricted assignment, where the set of eligible machines can be arbitrary for each job.) We also show that even for this special case it is NP-hart to compute better than 1.5 approximation.  This is the first improvement of the approximation ratio 2 of Lenstra, Shmoys, and Tardos [Approximation algorithms for scheduling unrelated parallel machines, Math. Program. 46:259--271, 1990], for any special case with unbounded number of machines. Our lower bound yields the same ratio as their bound which works for restricted assignment, and which is still the state-of-the-art lower bound even for the most general case.	approximation algorithm;arjen lenstra;makespan;scheduling (computing)	Tomás Ebenlendr;Marek Krcál;Jirí Sgall	2008	Algorithmica	10.1007/s00453-012-9668-9	ising model;mathematical optimization;combinatorics;discrete mathematics;mathematics;upper and lower bounds;algorithm	Theory	15.675217612330151	12.093573425669241	89448
59452358bef3cca032e9eb80af3e63eb0188d491	improving the performance of enumerative search methods-i. exploiting structure and intelligence	methode branch and bound;enumeration;produccion;enumeracion;branch and bound algorithm;heuristic method;performance;search method;search strategy;metodo heuristico;intelligence artificielle;optimisation combinatoire;domain knowledge;local knowledge;branch and bound method;statistical analysis;metodo branch and bound;scheduling;production;artificial intelligence;ordonamiento;methode heuristique;inteligencia artificial;rendimiento;combinatorial optimization;ordonnancement;optimizacion combinatoria	"""Generally, branch and bound algorithms typically use mechanistic search strategies and generally do not fully exploit """"local"""" information inherent in problem structures; i.e. specific problem-domain knowledge. Incorporating intelligence in branch and bound algorithms has been suggested by Glover, but not studied in a rigorous experimental framework. We use the mean tardiness job sequencing problem to explore these issues. This paper is divided into two Parts. In Part I, we provide the intuitive motivation for this investigation and an experimental framework. In Part II, we present detailed computational results and statistical analysis. The results indicate that branch and bound algorithms can be enhanced significantly by exploiting local knowledge of problem structure and more judicious search strategies. Note: This is Part I of a two part article. The second part will appear i , Volume 22 No. 9. I N T R O D U C T I O N We focus on combinatorial optimization problems--problems involving discrete variables and in which the underlying solution space grows combinatorially with the problem size. Enumerative search methods such as branch and bound and heuristic search are common approaches to solving these problems. Each has inherent disadvantages. While branch and bound methods can guarantee an optimal solution, they require, in the worst case, exponential time. Heuristic search methods, on the other hand, need less computational resources, but generally terminate at a local optimum. Attempts to overcome the shortcomings of each of these approaches have been made by various researchers. For example, target analysis 1-1,5-1 is an integration of artificial intelligence with operations research that uses a learning model patterned after classification problems. The idea behind target analysis is to use a set of """"training problems"""" to determine optimal algorithm parameter settings in conventional search strategies such as implicit enumeration. Avoiding local optimality in local search heuristics underlies the concept of tabu search introduced +Adam Fadlalla holds an M.B.A. from Miami University (Ohio), an M.Sc. in computer science, and Ph.D. in Information Systems from the University of Cincinnati. He is currently an Assistant Professor of Computer and Information Systems at Cleveland State University. His research interests include optimization and applications of artificial intelligence. He is an active business consultant in the Middle East. ++James R. Evans holds a Ph.D. ih Industrial and Systems Engineering from Georgia Tech and is Professor of Quantitative Analysis and Director of the Total Quality Management Center in the College of Business Administration at the University of Cincinnati. His interests have included networks, mathematical programming, and creative thinking in MS/OR. 605 606 Adam Fadlalla and James R. Evans by Glover [6]. Tabu search is a meta-procedure that organizes and directs the operations of a subordinate method. Instead of terminating when reaching a point of local optimality, tabu search structures the operation of its embedded heuristic in a manner that permits it to continue, thus avoiding local optimality traps. This is accomplished by forbidding moves with certain attributes (making them tabu), and choosing moves from those remaining for which the embedded heuristic assigns the highest evaluation. The tabu status, however, can be overruled if certain aspiration level conditions are met, or by short term or long term forgetting. The effectiveness of simple local search heuristics depends on the structure, and not solely on the size, of the neighborhood. A study by Evans [7] tested the ability of local search heuristics to find the global optimum solution for the mean tardiness job sequencing problem. Evans investigated the probability of obtaining a global optimum through the analysis of the structure of the state space of solutions and showed that a neighborhood of smaller size can outperform one of larger size if it judiciously searches within the state space. This is reflected in the ability of a smaller neighborhood to cover a wide area of the search space, thus increasing the chances of stumbling upon good solutions. Conventionally, improvements in branch and bound algorithms have been realized through better bounding and heuristic functions. Our primary goal is to investigate the performance of branch and bound methods by incorporating effective search strategies from heuristics as well as intelligent information gleaned from the structure of the problem. Like target analysis, this may be viewed as an attempt to merge artificial intelligence within the branch and bound approach. This leads to hybrid algorithms that draw upon the strengths of both branch and bound as well as intelligent search while avoiding their weaknesses. This work is motivated by Glover [1] who suggests that intelligent learning within branch and bound may draw on several sources of information, such as: (1) alternative means of evaluating mutually exclusive branches, (2) easily specified logical interdependencies, (3) historical data of the search, (4) various methods for generating trial completions of the current solution. While some of these ideas have been used sporadically in various contexts, they have not been studied in an experimental framework, particularly with a view of understanding interactions. In Part I of this paper we develop the motivation and foundation for improving branch and bound performance through heuristic search and problem domain intelligence. In Part II we report on an experimental design and statistical analysis of computational results. We use the minimum tardiness job sequencing problem as a basis for these experiments. BRANCH AND BOUND ALGORITHMS FOR THE MEAN TARDINESS SEQUENCING PROBLEM As a basis for our discussion, we focus on the single machine mean tardiness job sequencing problem, which has been studied extensively in the literature [8-14]. We emphasize that our objective is neither to develop new algorithms nor to compare them with previous research for this particular problem, but to study the effects of generic strategies that incorporate artificial intelligence with the branch and bound concept. The mean tardiness problem is defined as follows: A set of n jobs is available for processing on a single processor at time 0. Each job j has a processing time tj and a due date dj. We will assume that dr> t;, jobs cannot be preempted, and only one job can be processed at a time. The tardiness for job j is T i = max(0, Cj-dr} , where C; is the completion time of job j. Total tardiness, T, is the sum of the tardiness of all jobs. The objective is to find a sequence which minimizes the total tardiness. An example that we will be using for illustrative purposes throughout this paper is given in Table 1. Branch and bound algorithms consist of three fundamental components: (l) a branching strategy, (2) a bounding function, and (3) an initial upper bound. Improving enumerative search methods 607 Table 1. An instance of the job sequencing problem with n = 4"""	analysis of algorithms;applications of artificial intelligence;best, worst and average case;branch and bound;combinatorial optimization;computation;computational resource;computer science;design of experiments;embedded system;experiment;feasible region;global optimization;heuristic (computer science);information systems;information system;interaction;interdependence;job shop scheduling;job stream;local optimum;local search (optimization);mathematical optimization;newman's lemma;operations research;preemption (computing);problem domain;state space;stumbleupon;systems engineering;tabu search;terminate (software);time complexity	Adam Fadlalla;James R. Evans	1995	Computers & OR	10.1016/0305-0548(94)00056-E	mathematical optimization;performance;combinatorial optimization;computer science;artificial intelligence;machine learning;mathematics;enumeration;scheduling;branch and bound;domain knowledge;algorithm	AI	17.79411462344192	8.625252369492374	89492
a03ac02d809e2803b7fec35aa09749a2c4a50c4e	using constraint logic programming for industrial scheduling problems	scheduling problem		constraint logic programming;scheduling (computing)	Silvia Breitinger;Hendrik C. R. Lock	1995			real-time computing;hybrid algorithm (constraint satisfaction);constraint logic programming;constraint programming;scheduling (production processes);fair-share scheduling;computer science;mathematical optimization;concurrent constraint logic programming;two-level scheduling;constraint satisfaction	Robotics	13.91571805815468	6.60493352884239	89724
a3fdc2352ae8e7b1ba64ce5f5b4f1561b424c8fe	optimal arrival flight sequencing and scheduling using discrete airborne delays	discrete airborne delays;spacing;lagrangian dual decomposition;file attente;espacement;mixed integer linear program;desigualdad matricial lineal;occupation time;programacion discreta;air traffic control;sequencage;decision support tool;controleur trafic;tiempo diferido;traffic controller;espaciamiento;optimisation sousgradient;systeme aide decision;processor scheduling;trafico aereo;metodo descomposicion;gestion trafic;branch and bound algorithm;methode decomposition;duality;queue;terminal;discrete time;flight;aeronef;optimal arrival flight sequencing;sistema ayuda decision;traffic management;aeronave;optimisation combinatoire;scenario;optimization problem;airport;vol;temps calcul;decomposition method;sequencing;set constraint;dualite;scheduling algorithm;decision support system;branch and bound method;linear matrix inequality;programacion lineal;programacion mixta entera;delayed time;temps occupation;programmation discrete;maximum position shift constraints;argumento;metodo branch and bound;delay lagrangian functions aircraft linear programming processor scheduling linear matrix inequalities costs scheduling algorithm computational efficiency algorithm design and analysis;methode lagrange;scheduling;subgradient optimization;airplane;constrenimiento conjunto;script;metodo lagrange;tiempo ocupacion;borne inferieure;avion;coste;linear programming;gestion trafico;programmation lineaire;programmation partiellement en nombres entiers;scheduling problem;linear program;contrainte ensembliste;mixed integer programming;lagrangian method;dualidad;inegalite matricielle lineaire;difference set;supervisor trafico;temps retard;optimizacion subgradiente;delay time;methode separation et evaluation;trafic aerien;branch and bound algorithm optimal arrival flight sequencing flight scheculing discrete airborne delays air traffic control maximum position shift constraints linear programming lagrangian dual decomposition linear matrix inequalities;tiempo computacion;tree searching	An algorithm for optimal arrival flight sequencing and spacing in a near-terminal area is proposed. The optimization problem and algorithm proposed in this paper are developed for a decision-support tool for air-traffic control, which uses discrete delay times as optimization variables. The algorithm is applicable to various scenarios with situational and operational constraints such as maximum position shift (MPS) constraints or different sets of discrete delay times, depending on aircraft types or approaching routes. The proposed algorithm is based on a branch-and-bound algorithm with linear programming (LP) and Lagrangian dual decomposition. We formulate the sequencing and scheduling problem as LP with linear matrix inequalities (LMIs), which allows computing the lower bound of the cost for the best first search in the branch-and-bound algorithm and propose Lagrangian dual decomposition for computational efficiency. The proposed algorithm is analyzed and validated through illustrative air-traffic scenarios with various operational constraints, and the simulation results show that the computation time can be significantly reduced using the proposed Lagrangian dual-decomposition method.	airborne ranger;algorithm;best-first search;branch and bound;computation;lagrange multiplier;lagrangian and eulerian specification of the flow field;lagrangian relaxation;linear matrix inequality;linear programming;mathematical optimization;optimization problem;scheduling (computing);simulation;time complexity	Yeonju Eun;Inseok Hwang;Hyochoong Bang	2010	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2010.2044791	mathematical optimization;combinatorics;simulation;computer science;linear programming;air traffic control;mathematics;scheduling	EDA	16.76746701888544	5.692236987019857	89939
0d1c316905b10f2e2d993fe67137827c8f350bd7	minimizing setup and beam-on times in radiation therapy	radioterapia;radiotherapy;discretisation;cancerology;cabeza;malade;tiempo iniciacion;approximate algorithm;patient;tumor maligno;beam mechanics;approximation algorithm;temps lineaire;customization;discretization;linear time algorithm;personnalisation;hombre;temps minimal;discretizacion;temps mise en route;tiempo lineal;radiotherapie;binary number;viga;optimisation combinatoire;accord frequence;setup time;numero binario;tuning;cancer therapy;cancerologie;linear time;human;algoritmo aproximacion;personalizacion;minimum time;sintonizacion frecuencia;radiation therapy;tumeur maligne;head;cancerologia;poutre;tete;algorithme approximation;combinatorial optimization;tiempo minimo;enfermo;malignant tumor;homme;optimizacion combinatoria;nombre binaire	Radiation therapy is one of the commonly used cancer therapies. The radiation treatment poses a tuning problem: it needs to be effective enough to destroy the tumor, but it should maintain the functionality of the organs close to the tumor. Towards this goal the design of a radiation treatment has to be customized for each patient. Part of this design are intensity matrices that define the radiation dosage in a discretization of the beam head. To minimize the treatment time of a patient the beam-on time and the setup time need to be minimized. For a given row of the intensity matrix, the minimum beam-on time is equivalent to the minimum number of binary vectors with the consecutive “1”s property that sum to this row, and the minimum setup time is equivalent to the minimum number of distinct vectors in a set of binary vectors with the consecutive “1”s property that sum to this row. We give a simple linear time algorithm to compute the minimum beam-on time. We prove that the minimum setup time problem is APX-hard and give approximation algorithms for it using a duality property. For the general case, we give a 24 13 approximation algorithm. For unimodal rows, we give a 9 7 approximation algorithm. We also consider other variants for which better approximation ratios exist. ∗IBM T.J. Watson Research Center, P.O. Box 218, Yorktown Heights, NY 10598, {nikhil,sbar}@us.ibm.com †IDA Center for Communications Research, 805 Bunn Drive, Princeton, NJ 08540, don.coppersmith@idaccr.org. This work was done while at IBM T.J. Watson Research Center.	apx;approximation algorithm;discretization;flip-flop (electronics);performance tuning;thomas j. watson research center;time complexity	Nikhil Bansal;Don Coppersmith;Baruch Schieber	2006		10.1007/11830924_5	radiation therapy;combinatorial optimization;calculus;discretization;mathematics;geometry;approximation algorithm;algorithm	Theory	20.18616007450071	15.72871938774311	89982
55d90f5b93bc6734757e764ae20ce3e0c64df448	how hard is it for a party to nominate an election winner?		We consider a Plurality-voting scenario, where the candidates are split between parties, and each party nominates exactly one candidate for the final election. We study the computational complexity of deciding if there is a set of nominees such that a candidate from a given party wins in the final election. In our second problem, the goal is to decide if a candidate from a given party always wins, irrespective who is nominated. We show that these problems are computationally hard, but are polynomial-time solvable for restricted settings.	commitment ordering;computational complexity theory;decision problem;polynomial-time reduction;time complexity	Piotr Faliszewski;Laurent Gourvès;Jérôme Lang;Julien Lesca;Jérôme Monnot	2016				AI	18.377500014962934	17.482663341226722	90055
533e88bc0fc2a5890a7537ea686fb2b378c211fa	maximizing the total profit of rectangles packed into a rectangle	bin packing problem;chevauchement;rentabilidad;metodo caso peor;approximate algorithm;approximation algorithms;approximation algorithm;layout problem;packing;probleme agencement;problema relleno;problema np duro;overlap;imbricacion;journal;profit;np hard problem;beneficio;probleme np difficile;algoritmo aproximacion;methode cas pire;benefice;problema disposicion;probleme remplissage;rentabilite;profitability;rotacion;algorithme approximation;rotation;worst case method;garnissage;rectangle packing;relleno	We consider the following rectangle packing problem. Given a set of rectangles, each of which is associated with a profit, we are requested to pack a subset of the rectangles into a bigger rectangle so that the total profit of rectangles packed is maximized. The rectangles may not overlap. This problem is strongly NP-hard even for packing squares with identical profits. We first present a simple (3 + ε)-approximation algorithm. Then we consider a restricted version of the problem and show a (2 + ε)-approximation algorithm. This restricted problem includes the case where rotation by 90° is allowed (and is possible), and the case of packing squares. We apply a similar technique to the general problem, and get an improved algorithm with a worst-case ratio of at most 5/2 + ε. Finally, we devise a (2 + ε)-approximation algorithm for the general problem.	best, worst and average case;dijkstra's algorithm;np-hardness;set packing	Klaus Jansen;Guochuan Zhang	2006	Algorithmica	10.1007/s00453-006-0194-5	mathematical optimization;combinatorics;bin packing problem;profit;rotation;computer science;np-hard;mathematics;rectangle method;approximation algorithm;algorithm;profitability index	Theory	18.35794242846847	11.896798557154966	90200
f5dad748a7b02a444e275f1bb560a73156f31998	maximizing expected number of transplants in kidney exchange programs		Abstract   In this paper we address the problem of maximizing the  expected  number of transplants in a kidney exchange program. We propose an integer programming model with an exponential number of decision variables which are associated with cycles. By introducing the concept of  type of cycle , we avoid the complete cycle enumeration and develop a branch-and-price approach.		Filipe Alvelos;Xenia Klimentova;Abdur Rais;Ana Viana	2016	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2016.03.036	mathematics;operations research;algorithm	Theory	15.481021504455137	5.396005793674422	90405
1aa4bd4f4d56bb4ccf164acbc4f1a49130bf594f	an agent cloning approach for process design of discrete plants	multi agent system;inherently safer processes;process design	This paper describes an agent cloning methodology for designing discrete processes. The objective is to find the best mix of technologies that meet raw material and product requirements. Process alternatives are evaluated based on manufacturing cost, throughput time, and toxicity. In the proposed methodology, agents design equipment and initiate process design tasks according to a recursive algorithm based on dynamic programming and the branch and bound method.		Tatan Firmansyah;Rafael Batres	2011		10.1007/978-3-642-23854-3_42	control engineering;systems engineering;engineering;operations management	EDA	10.657027860841389	4.389461549391115	90417
8f66b25b058a9ded2a20d96d23a7d2128fe2ce91	using patterns to form homogeneous teams	k anonymity;kernelization;parameterized complexity;matrix modification problems;fixed parameter tractability;np hardness;team formation;team selection	Homogeneous team formation is the task of grouping individuals into teams, each of which consists of members who fulfill the same set of prespecified properties. In this theoretical work, we propose, motivate, and analyze a combinatorial model where, given a matrix over a finite alphabet whose rows correspond to individuals and columns correspond to attributes of individuals, the user specifies lower and upper bounds on team sizes as well as combinations of attributes that have to be homogeneous (that is, identical) for all members of the corresponding teams. Furthermore, the user can define a cost for assigning any individual to a certain team. We show that some special cases of our new model lead to NP-hard problems while others allow for (fixed-parameter) tractability results. For example, the problem is already NP-hard even if (i) there are no lower and upper bounds on the team sizes, (ii) all costs are zero, and (iii) the matrix has only two columns. In contrast, the problem becomes fixed-parameter tractable for the combined parameter “number of possible teams” and “number of different individuals”, the latter being upper-bounded by the number of rows.	algorithm;algorithmica;best, worst and average case;cobham's thesis;column (database);combinatorial optimization;heuristic (computer science);np-hardness;parameterized complexity;polynomial;polynomial-time approximation scheme;the matrix;time complexity	Robert Bredereck;Thomas Köhler;André Nichterlein;Rolf Niedermeier;Geevarghese Philip	2013	Algorithmica	10.1007/s00453-013-9821-0	parameterized complexity;mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;kernelization;algorithm	ML	18.018584059622885	15.527392027309043	90419
d513cc6d469f3dcd858fde136a68fd4fea7b756c	approximation algorithms for data placement problems	assignment;objet;optimal solution;68w40;asignacion;solution optimale;approximate algorithm;storage access;arbre steiner;90b80;49j30;approximation algorithms;05c05;approximation algorithm;nudo;aproximacion;coaccion;multidestinatario;contrainte;assignation;90c59;object;reseau;mediane;median;68wxx;consistencia;red;relajacion;approximation;moyenne;cout moyen;constraint;programacion lineal;average cost;solucion optima;replicated data;almacenamiento;promedio;coste medio;consistance;acces memoire;algoritmo aproximacion;stockage;data access;linear programming;acceso memoria;programmation lineaire;relaxation;average;total length;mediana;noeud;algorithme approximation;49k30;capacity constraint;68w25;lp relaxation;node;steiner tree;storage;objeto;multidestinataire;data placement;consistency;multicast;network;facility location	We develop approximation algorithms for the problem of plac ing replicated data in arbitrary networks, where the nodes may both issue requests for data objec ts and have capacity for storing data objects, so as to minimize the average data-access cost. We i ntroduce thedata placement problemto model this problem. We have a set of caches F , a set of clientsD, and a set of data objects O. Each cachei can store at most ui data objects. Each client j ∈ D has demandj for a specific data object o(j) ∈ O and has to be assigned to a cache that stores that object. Stor ing an objecto in cachei incurs a storage cost of o i , and assigning client j to cachei incurs an access cost of djcij . The goal is to find a placement of the data objects to caches respecting the capac ity constraints, and an assignment of clients to caches, so as to minimize the total storage and client acce ss costs. We present a 10-approximation algorithm for this problem. O ur algorithm is based on rounding an optimal solution to a natural LP-relaxation of the proble m. One of the main technical challenges encountered during rounding is to preserve the cache capaci ties while incurring only a constant-factor increase in the solution cost. We also introduce theconnected data placement problem , to capture settings where write-requests are also issued for data objects, so that one requires a mecha nism to maintain consistency of data. We model this by requiring that all caches containing a given ob ject be connected by a Steiner tree to a root for that object, which issues a multicast-message upon a wri te to (any copy of) that object. The total cost now includes the cost of these Steiner trees. We devise a 14-a pproximation algorithm for this problem. We show that our algorithms can be adapted to handle two varia nts of the problem: (a) ak-median variant, where there is a specified bound on the number of cach es that may contain a given object; (b) a generalization where objects have lengths and the total le ngth of the objects stored in any cache must not exceed its capacity. This work is a combined version of two papers: an extended abs tract by Baev and Rajaraman [3] that appeared in the Proceedings of the 12th Annual ACM-SIAM Symposium on Discrete Algor ithms, 2001, and an unpublished manuscript by Swamy [38]. ivan.baev@hp.com. Java, Compilers, and Tools Laboratory, Hewlett-Packard C ompany, 11000 Wolfe Road, Cupertino, CA 95014. rraj@ccs.neu.edu. College of Computer Science, Northeastern University, Bo ston, MA 02115. Supported by NSF CAREER award NSF CCR-9983901. cswamy@math.uwaterloo.ca. Combinatorics and Optimization, University of Waterloo, Waterloo, ON N2L 3G1. Supported in part by NSERC grant 32760-06. Part of this work was d one while the author was a student at Cornell University, NY 14853.	approximation algorithm;cpu cache;call of duty: black ops;computer science;emoticon;ibm notes;java;lagrangian relaxation;linear programming relaxation;multicast;rounding;steiner tree problem;tract (literature)	Ivan D. Baev;Rajmohan Rajaraman;Chaitanya Swamy	2008	SIAM J. Comput.	10.1137/080715421	data access;mathematical optimization;combinatorics;multicast;steiner tree problem;computer science;linear programming relaxation;object;theoretical computer science;facility location problem;approximation;relaxation;assignment;mathematics;distributed computing;constraint;node;consistency;median;approximation algorithm;algorithm	Theory	20.365648456255737	15.197297437539683	90493
d33b91341875c50a31ef35af452e65aa3260b9da	an almost time optimal route planning method for complex manufacturing topologies		This paper focuses on time and distance optimal route planning for complex manufacturing topologies. The main idea of the proposed algorithm is to transform the manufacturing process into an undirected weighted graph, which can be treated as the well-known Traveling Salesman Problem (TSP). The optimal solution for the TSP is found with the help of Linear Integer Programming, which yields to Non-deterministic Polynomial-time (NP-hard). In order to overcome unpractical computation times for more complex tasks the optimal solution is approximated with the help of the Minimum Spanning Tree (MST) algorithm and alternatively with the Christofides algorithm. Simulation results and a comparison of the denoted methods are shown.		Matthias Jörgl;Hubert Gattringer;Andreas Müller	2015		10.1007/978-3-319-27340-2_83	mathematical optimization	Robotics	24.25094980139605	7.650267095753319	90913
2ca0ad2dcb61811eff3981a2c04ccb2ecf48d2ce	the design or multipoint linkages in a teleprocessing tree network	optimal solution;networks;optimal systems;teleprocessing;integer programming networks optimal systems teleprocessing;approximation method;data processing;integer programming;network optimization;tree network;integer program;optimal algorithm	The problem of designing a minimum cost network with multipoint linkages which connects several remote terminals to a data processing center is studied. The important aspects of a teleprocessing network are queue behavior at the terminals and the cost and reliability of the entire system. In this paper it is assumed that the rate and manner in which information is requested at the terminals is known and that acceptable line loadings are given. An algorithm that determines (in principle) the optimum minimum cost network subject to reliability constraints is developed. A heuristic based on Vogel's approximation method (VAM) and two other heuristics presented by Martin and Esau-Williams were compared with each other and with the optimal algorithm. The Esau-Williams heuristic seems to be the one that gives the best solution and Martin's requires the least processing time. It is shown experimentally that Martin's and Esau-Williams heuristics are, in fact, near-optimal heurstics in the sense that the solutions provided by these heuristics are generally very near the optimal solution. In this paper we make the assumption that all lines of the network have the same capacity.	algorithm;approximation;experiment;heuristic (computer science);multipoint ground;transaction processing;tree network	K. Mani Chandy;Robert A. Russell	1972	IEEE Transactions on Computers	10.1109/T-C.1972.223452	mathematical optimization;combinatorics;integer programming;data processing;computer science;theoretical computer science;algorithm;computer network	Theory	20.572546038055876	13.090267774772464	90927
bb4f831812256153487f874d4d790bcf234593c5	probabilistic analysis of a network design problem heuristic	mixed programming;network design;transportation problem;probleme transport;heuristic method;programmation entiere;reseau;programmation mixte;integer programming;conception reseau;methode heuristique;network	Abstract#R##N##R##N#Previous work has shown the budget network design problem (selecting a subset of arcs, subject to a budget constraint, so that the total weighted sum of the shortest paths in the network is minimized) to be a very difficult optimization problem. This article gives an efficient heuristic procedure for solving budget network design problems embedded in a circle on the euclidean plane where the nodes are independently and randomly distributed over the circle. With mild conditions on the budget constraint, we prove that as the number of nodes increases, the probability that the heuristic solution value exceeds any fixed percentage of the optimal solution value goes to zero. Computational results for the heuristic arc given.	heuristic;network planning and design;probabilistic analysis of algorithms	Richard T. Wong	1985	Networks	10.1002/net.3230150306	transportation theory;mathematical optimization;network planning and design;combinatorics;integer programming;computer science;mathematics;algorithm	Logic	21.736766519602952	11.75365554816745	91008
49902175dd29edbbf2e0f08cf13d675a56efb47c	minimizing worst-case and average-case makespan over scenarios	job scheduling;approximation algorithm;makespan;scenarios	We consider scheduling problems over scenarios where the goal is to find a single assignment of the jobs to the machines which performs well over all scenarios in an explicitly given set. Each scenario is a subset of jobs that must be executed in that scenario. The two objectives that we consider are minimizing the maximum makespan over all scenarios and minimizing the sum of the makespans of all scenarios. For both versions, we give several approximation algorithms and lower bounds on their approximability. We also consider some (easier) special cases. Combinatorial optimization problems under scenarios in general, and scheduling problems under scenarios in particular, have seen only limited research attention so far. With this paper, we make a step in this interesting research direction.	approximation algorithm;assignment (computer science);best, worst and average case;combinatorial optimization;job stream;makespan;mathematical optimization;scheduling (computing)	Esteban Feuerstein;Alberto Marchetti-Spaccamela;Frans Schalekamp;René Sitters;Suzanne van der Ster;Leen Stougie;Anke van Zuylen	2017	J. Scheduling	10.1007/s10951-016-0484-y	scheduling (computing);mathematical optimization;approximation algorithm;job shop scheduling;real-time computing;computer science;job scheduler;combinatorial optimization;distributed computing	Theory	15.523698993152841	10.502819747546813	91130
185a9ffeafdaca03219948309a02c3fac450feea	incremental building in peptide computing to solve hamiltonian path problem	time complexity;combinatorial problems;proof of concept;hamiltonian path problem;molecular computing	To solve intractable problems using biomolecules the model requires exponential number of the same. As a proof of concept this model is acceptable, but when it comes to realization of the model the number of biomolecules needed should be drastically reduced by some techniques. In this work we address this issue for peptide computing – we propose a method called incremental building to reduce the number of peptides needed to work with for solving large combinatorial problems. We explain this model for solving the Hamiltonian path problem, analyze the space and time complexity for the same, and also discuss this method from the perspective of molecular computing as a whole and study its implications.	hamiltonian path problem;peptide computing	Sakthi Balan Muthiah;Parameswaran Seshan	2010		10.1007/978-3-642-13089-2_46	time complexity;mathematical optimization;combinatorics;discrete mathematics;peptide computing;computer science;mathematics;hamiltonian path problem;proof of concept;algorithm	Theory	13.44150670351972	17.562324249180108	91185
aa23a42796bbfbdb1f086d45652e36fafaeab6c3	scheduling in reentrant robotic cells: algorithms and complexity	cycle time;complexity;polynomial time algorithm;makespan;reentrant robotic cell;cell cycle	We study the scheduling of m-machine reentrant robotic cells, in which parts need to reenter machines several times before they are finished. The problem is to find the sequence of 1-unit robot move cycles and the part processing sequence which jointly minimize the cycle time or the makespan. When m = 2, we show that both the cycle time and the makespan minimization problems are polynomially solvable. When m = 3, we examine a special class of reentrant robotic cells with the cycle time objective. We show that in a three-machine loopreentrant robotic cell, the part sequencing problem under three out of the four possible robot move cycles for producing one unit is strongly NP-hard. The part sequencing problem under the remaining robot move cycle can be solved easily. Finally, we prove that the general problem, without restriction to any robot move cycle, is also intractable.	complexity;decision problem;makespan;reentrancy (computing);robot;scheduling (computing)	George Steiner;Zhihui Xue	2005	J. Scheduling	10.1007/s10951-005-5314-6	job shop scheduling;mathematical optimization;complexity;real-time computing;cycle time variation;computer science;cell cycle;mathematics;algorithm	Robotics	15.669031145768209	9.375333336459919	91602
e8dde5eddb3831db9465d1a36bc2827006a514ae	on multi-objective optimization aided visualization of graphs related to business process diagrams		A problem of the drawing of aesthetically looking graphs, related to business process diagrams, is considered. We model a situation where sites of flow objects of the diagram are fixed, and the sequence flow is defined. The edges of a graph, which represent the sequence flow, should be drawn aiming at an aesthetical image. The latter problem is reformulated as a multi-objective combinatorial optimization problem. The generally recognized criteria of aesthetical presentation, such as general length of lines, number of crossings, and number of bends, are considered the objectives to be minimized. Two algorithms are developed for the stated problem taking into account its specifics. The efficiency of the developed algorithms is evaluated experimentally using randomized test problems of different	ant colony optimization algorithms;business process;combinatorial optimization;crossing number (graph theory);diagram;experiment;mathematical optimization;multi-objective optimization;optimization problem;randomized algorithm;routing	Vytautas Jancauskas;Giedrius Kaukas;Antanas Zilinskas;Julius Zilinskas	2012			business process;diagram;visualization;multi-objective optimization;combinatorial optimization;theoretical computer science;graph;computer science	AI	24.029655955443605	6.767700261716224	91629
ce43a022d782237e03042d59232baf98a7a47749	alternative configurations for cutting machines in a tube cutting mill	cutting stock problem with setup;programacion entera;continuous stock cutting problem;cutting;cutting stock problem;programmation en nombres entiers;binary number;linear functionals;numero binario;probleme decoupe;integer programming;problema troquelado;integer program;production efficiency;nombre binaire	In a steel tube mill where an endless stream of steel tube is supplied from a manufacturing facility, trim waste is never made regardless of cutting patterns used and the standard cutting stock problem seems meaningless. Therefore, the continuous stock cutting problem with setup is introduced to minimize the sum of cutting time and pattern changing time to meet the given demand. We propose a new configuration of cutting machines to achieve higher production efficiency, namely the open-ended configuration as opposed to the traditional closed-ended configuration, thereby two variants of the problem are defined. We propose linear formulations for both problems using binary expansion of the number of pieces of different types in a pattern. Furthermore, we define the time for pattern change as a linear function of the number of knives used in the pattern to be more realistic. Computational studies suggest that the open-ended cutting machine may improve the production time by up to 44% and that our linear formulations are more efficient than the existing ones.	binary number;computation;cutting stock problem;linear function;nonlinear gameplay;numerical analysis;numerical method;simultaneous multithreading;williams tube	Iman Hajizadeh;Chi-Guhn Lee	2007	European Journal of Operational Research	10.1016/j.ejor.2005.12.049	mathematical optimization;integer programming;binary number;productive efficiency;operations management;cutting stock problem;mathematics;cutting	ML	17.186812799773108	7.037528561341017	91775
8278c140304bb4863cdd2fe1825ec4b001d7ccfc	a genetic algorithm-based approach for solving the resource-sharing and scheduling problem	mixed integer linear program;continuous time;branch and bound algorithm;mixed integer linear programming;resource sharing and scheduling problem;resource sharing;scheduling problem;genetic algorithm;branch and bound;single mode	0360-8352/$ see front matter 2009 Elsevier Ltd. A doi:10.1016/j.cie.2009.05.003 * Corresponding author. Tel.: +972 8 6472199; fax: E-mail addresses: pintog@bgu.ac.il (G. Pinto), ines rgadi@bgu.ac.il (G. Rabinowitz). We introduce a heuristic that is based on a unique genetic algorithm (GA) to solve the resource-sharing and scheduling problem (RSSP). This problem was previously formulated as a continuous-time mixed integer linear programming model and was solved optimally using a branch-and-bound (B&B) algorithm. The RSSP considers the use of a set of resources for the production of several products. Producing each product requires a set of operations with precedence relationships among them. Each operation can be performed using alternative modes which define the subset of the resources needed, and an operation may share different resources simultaneously. The problem is to select a single mode for each operation and accordingly to schedule the resources, while minimizing the makespan time. The GA we propose is based on a new encoding schema that adopts the structure of a DNA in nature. In our experiments we compared the effectiveness and runtime of our GA versus a B&B algorithm and two truncated B&B algorithms that we developed on a set of 118 problem instances. The results demonstrate that the GA solved all the problems (10 runs each), and reaches optimality in 75% of the runs, had an average deviation of less than 1% from the optimal makespan, and a runtime that was much less sensitive to the size of the problem instance. 2009 Elsevier Ltd. All rights reserved.	branch and bound;experiment;fax;genetic algorithm;heuristic;integer programming;linear programming;makespan;programming model;scheduling (computing);serializability;software release life cycle	Gaby Pinto;Inessa Ainbinder;Gad Rabinowitz	2009	Computers & Industrial Engineering	10.1016/j.cie.2009.05.003	job shop scheduling;mathematical optimization;computer science;mathematics;distributed computing;branch and bound;algorithm	AI	15.418715575561324	6.6195754597349925	91792
0e1872063e775175fe507dc168288fe097892d09	flow-based formulation for the maximum leaf spanning tree problem		Abstract   The maximum leaf spanning tree problem consists in finding a spanning tree of a given graph  G  with the maximum number of leaves. In this work we propose a flow-based mixed-integer linear programming model for this problem. Computational experiments are executed in two sets of instances from the literature. The results show that the model is competitive with alternative exact approaches.	connected dominating set;file spanning;minimum spanning tree	Marcio Felix Reis;Orlando Lee;Fabio Luiz Usberti	2015	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2015.07.035	euclidean minimum spanning tree;mathematical optimization;combinatorics;discrete mathematics;kruskal's algorithm;minimum degree spanning tree;spanning tree;minimum spanning tree;k-ary tree;connected dominating set;k-minimum spanning tree;mathematics;distributed minimum spanning tree;shortest-path tree	Theory	23.33126095224342	17.29248927650159	91823
22d75c6d27171c76aff1b4c6a953a657c5ce67d4	the static stochastic knapsack problem with normally distributed item sizes		This paper develops exact and heuristic algorithms for a stochastic knapsack problem where items with random sizes may be assigned to a knapsack. An item’s value is given by the realization of the product of a random unit revenue and the random item size. When the realization of the sum of selected item sizes exceeds the knapsack capacity, a penalty cost is incurred for each unit of overflow, while our model allows for a salvage value for each unit of capacity that remains unused. We seek to maximize the expected net profit resulting from the assignment of items to the knapsack. Although the capacity is fixed in our core model, we show that problems with random capacity, as well as problems in which capacity is a decision variable subject to unit costs, fall within this class of problems as well. We focus on the case where item sizes are independent and normally distributed random variables, and provide an exact solution method for a continuous relaxation of the problem. We show that an optimal solution to this relaxation exists containing no more than two fractionally selected items, and develop a customized branch-and-bound algorithm for This work was supported by the National Science Foundation under grant no. DMI-0355533. Y. Merzifonluoğlu Middle East Technical University, Northern Cyprus Campus, Kalkanlı, Güzelyurt, KKTC, Mersin 10, Turkey e-mail: myasemin@metu.edu.tr J. Geunes (B) Department of Industrial and Systems Engineering, University of Florida, Gainesville, FL, USA e-mail: geunes@ise.ufl.edu H. E. Romeijn Department of Industrial and Operations Engineering, University of Michigan, Ann Arbor, MI, USA e-mail: romeijn@umich.edu	algorithm;branch and bound;data recovery;email;heuristic;job stream;knapsack problem;linear programming relaxation;logistics;network planning and design;operations engineering;systems engineering	Yasemin Merzifonluoglu;Joseph Geunes;H. Edwin Romeijn	2012	Math. Program.	10.1007/s10107-011-0443-5	continuous knapsack problem;mathematical optimization;mathematics;mathematical economics;knapsack problem	ML	13.261152637030895	8.562453862896442	91838
1af7fee1bfe097320351c65890bd6495e244c755	primal–dual algorithms for connected facility location problems	problema arbol steiner;k median problem;location problem;probleme k median;probleme localisation;localisation installation;approximate algorithm;best approximation;steiner trees;approximation algorithms;primal dual algorithms;approximation algorithm;primal dual method;probleme arbre steiner;methode primale duale;programacion lineal;metodo primal dual;algoritmo aproximacion;linear programming;programmation lineaire;mejor aproximacion;facility location problem;primal dual algorithm;problema localizacion;steiner tree problem;algorithme approximation;problema k medio;steiner tree;connected facility location;facility location;meilleure approximation	We consider the Connected Facility Location problem. We are given a graph $G = (V,E)$ with costs $\{c_e\}$ on the edges, a set of facilities $\F \subseteq V$, and a set of clients $\D \subseteq V$. Facility $i$ has a facility opening cost $f_i$ and client $j$ has $d_j$ units of demand. We are also given a parameter $M\geq 1$. A solution opens some facilities, say $F$, assigns each client $j$ to an open facility $i(j)$, and connects the open facilities by a Steiner tree $T$. The total cost incurred is ${\sum}_{i\in F} f_i+ sum_{j\in\D} d_jc_{i(j)j}+M\sum_{e\in T}c_e$. We want a solution of minimum cost. A special case of this problem is when all opening costs are 0 and facilities may be opened anywhere, i.e., $\F=V$. If we know a facility $v$ that is open, then the problem becomes a special case of the single-sink buy-at-bulk problem with two cable types, also known as the rent-or-buy problem. We give the first primal–dual algorithms for these problems and achieve the best known approximation guarantees. We give an 8.55-approximation algorithm for the connected facility location problem and a 4.55-approximation algorithm for the rent-or-buy problem. Previously the best approximation factors for these problems were 10.66 and 9.001, respectively. Further, these results were not combinatorial—they were obtained by solving an exponential size linear rogramming relaxation. Our algorithm integrates the primal–dual approaches for the facility location problem and the Steiner tree problem. We also consider the connected $k$-median problem and give a constant-factor approximation by using our primal–dual algorithm for connected facility location. We generalize our results to an edge capacitated variant of these problems and give a constant-factor approximation for these variants.	approximation algorithm;diffusing update algorithm;facility location problem;linear programming relaxation;steiner tree problem;time complexity	Chaitanya Swamy;Amit Kumar	2004	Algorithmica	10.1007/s00453-004-1112-3	mathematical optimization;combinatorics;steiner tree problem;computer science;mathematics;approximation algorithm;algorithm	Theory	21.343007207394606	14.302052731230233	91947
fdd30d3caea0b09647f5160ae381bd249e28bb49	bi-criteria minimization for the permutation flowshop scheduling problem with machine-based learning effects	total completion time;flowshop;makespan;scheduling;article;learning effect	In traditional scheduling problems, the processing time for the given job is assumed to be a constant regardless of whether the job is scheduled earlier or later. However, the phenomenon named ‘‘learning effect’’ has extensively been studied recently, in which job processing times decline as workers gain more experience. This paper discusses a bi-criteria scheduling problem in an m-machine permutation flowshop environment with varied learning effects on different machines. The objective of this paper is to minimize the weighted sum of the total completion time and the makespan. A dominance criterion and a lower bound are proposed to accelerate the branch-and-bound algorithm for deriving the optimal solution. In addition, the near-optimal solutions are derived by adapting two well-known heuristic algorithms. The computational experiments reveal that the proposed branch-and-bound algorithm can effectively deal with problems with up to 16 jobs, and the proposed heuristic algorithms can yield accurate nearoptimal solutions. 2012 Elsevier Ltd. All rights reserved.	algorithm;branch and bound;computation;experiment;heuristic;makespan;scheduling (computing);weight function	Yu-Hsiang Chung;Lee-Ing Tong	2012	Computers & Industrial Engineering	10.1016/j.cie.2012.03.009	job shop scheduling;mathematical optimization;computer science;operations management;operating system;distributed computing;learning effect;scheduling	AI	15.711708238895012	7.721855376121336	92429
33d3f006f0fa5ddefa60cf4cc0ec02aa8018b60c	no, coreset, no cry	approximate algorithm;approximation algorithm;temps lineaire;linear time algorithm;tiempo lineal;resolucion problema;probleme recouvrement;couverture;problema recubrimiento;informatique theorique;linear time;algoritmo aproximacion;recouvrement ensemble;coverage;set covering;cubierta conjunto;covering problem;algorithme approximation;problem solving;resolution probleme;computer theory;cobertura;informatica teorica	We show that coresets do not exist for the problem of 2-slabs in IR, thus demonstrating that the natural approach for solving approximately this problem efficiently is infeasible. On the positive side, for a point set P in IR, we describe a near linear time algorithm for computing a (1+ε)-approximation to the minimum width 2-slab cover of P . This is a first step in providing an efficient approximation algorithm for the problem of covering a point set with k-slabs.	apx;approximation algorithm;coreset;maxima and minima;slab allocation;time complexity	Sariel Har-Peled	2004		10.1007/978-3-540-30538-5_27	time complexity;computer science;calculus;mathematics;approximation algorithm;algorithm	Theory	20.4284913524831	16.04873027141094	92561
b6ac24536042cb45237102ad488daab91cd7b83c	a scheme of independent calculations in a precedence constrained routing problem		We consider a routing problem with constraints. To solve this problem, we employ a variant of the dynamic programming method, where the significant part (that is, the part that matters in view of precedence constraints) of the Bellman function is calculated by means of an independent calculations scheme. We propose a parallel implementation of the algorithm for a supercomputer, where the construction of position space layers for the hypothetical processors is conducted with use of discrete dynamic systems’ apparatus.	routing	Alexander G. Chentsov;Alexey M. Grigoryev	2016		10.1007/978-3-319-44914-2_10	destination-sequenced distance vector routing	Theory	12.162102656289742	8.016918025205866	92763
0985b6b34dd24ec6de8fa8801bb755ef56d4baf9	solving the traveling circus problem by branch & cut		In this study, we present a Branch and Cut (B&C) algorithm to solve the Traveling Circus Problem (TCP) using extensions of the theoretical results from [6]. The TCP, a problem that combines the location aspects of the p–median problem with the routing aspects of the Traveling Salesman Problem, asks for a tour visiting p of the n nodes of a directed network which minimizes the length of the tour and the total cost of satisfying the demand of all customers from nodes on the tour.	algorithm;branch and cut;routing;travelling salesman problem	Mark E. Hartmann;Özgür Özlük	1999	Electronic Notes in Discrete Mathematics	10.1016/S1571-0653(05)80027-7	mathematical optimization;algorithm	Theory	22.17406565543	8.122569026439157	93061
b8ceb6bc7c4f7573f353862c667339af69ba41a6	another approach for the traveling salesman problem	optimisation sous contrainte;traveling salesman problem;constrained optimization;circuito hamiltoniano;circuit hamiltonien;travelling salesman problem;hamiltonian circuit;algorithme;problema viajante comercio;upper bound;optimizacion con restriccion;algorithm;mathematical programming;probleme commis voyageur;programmation mathematique;programacion matematica;algoritmo	In this paper a simple algorithm for finding upper bounds of the solution of the traveling salesman problem is discussed.	travelling salesman problem	Vites Longani	2000	Applied Mathematics and Computation	10.1016/S0096-3003(99)00116-2	nearest neighbour algorithm;traveling purchaser problem;2-opt;mathematical optimization;constrained optimization;greedy algorithm;christofides algorithm;cross-entropy method;combinatorial optimization;calculus;mathematics;travelling salesman problem;algorithm;3-opt;bottleneck traveling salesman problem	Theory	21.556570176728545	7.126941014262879	93079
856d43f68c715cc49f68d33b8ce7a66ab7817351	online packing and covering framework with convex objectives		We consider online fractional covering problems with a convex objective, where the covering constraints arrive over time. Formally, we want to solve min {f(x) | Ax ≥ 1, x ≥ 0}, where the objective function f : R → R is convex, and the constraint matrix Am×n is nonnegative. The rows of A arrive online over time, and we wish to maintain a feasible solution x at all times while only increasing coordinates of x. We also consider packing problems of the form max {cy − g(μ) | Ay ≤ μ, y ≥ 0}, where g is a convex function. In the online setting, variables y and columns of A arrive over time, and we wish to maintain a non-decreasing solution (y, μ). These problems are dual to each other when g = f the Fenchel dual of f . We provide an online primal-dual framework for both classes of problems with competitive ratio depending on certain “monotonicity” and “smoothness” parameters of f ; our results match or improve on guarantees for some special classes of functions f considered previously. Using this fractional solver with problem-dependent randomized rounding procedures, we obtain competitive algorithms for the following problems: online covering LPs minimizing lp-norms of arbitrary packing constraints, set cover with multiple cost functions, capacity constrained facility location, capacitated multicast problem, set cover with set requests, and profit maximization with non-separable production costs. Some of these results are new and others provide a unified view of previous results, with matching or slightly worse competitive ratios. Statistics and Operations Research Dept., Tel Aviv University, Research supported in part by ISF grant 954/11 and by BSF grant 2010426. Technion Israel Institute of Technology, Haifa, Israel. Work supported by ISF grant 954/11 and BSF grant 2010426. Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213, USA. Research partly supported by NSF awards CCF-1016799 and CCF-1319811. Department of Industrial and Operations Engineering, University of Michigan, Ann Arbor, MI 48109.	bean scripting framework;column (database);competitive analysis (online algorithm);computer science;convex function;covering problems;cylinder-head-sector;entropy maximization;fenchel's duality theorem;ibm notes;ink serialized format;lp-type problem;loss function;maxima and minima;multicast;operations engineering;operations research;optimization problem;randomized algorithm;randomized rounding;set cover problem;set packing;solver	Niv Buchbinder;Shahar Chen;Anupam Gupta;Viswanath Nagarajan;Joseph Naor	2014	CoRR		mathematical optimization;combinatorics;mathematics	Theory	19.71632469770279	14.535325381813823	93141
248834558eca6d15013be0180b08a4870f3ef198	a super-fast distributed algorithm for bipartite metric facility location		The facility location problem consists of a set of facilities F , a set of clients C, an opening cost fi associated with each facility xi, and a connection cost D(xi, yj) between each facility xi and client yj . The goal is to find a subset of facilities to open, and to connect each client to an open facility, so as to minimize the total facility opening costs plus connection costs. This paper presents the first expectedsub-logarithmic-round distributed O(1)-approximation algorithm in the CONGEST model for the metric facility location problem on the complete bipartite network with parts F and C. Our algorithm has an expected running time of O((log logn)) rounds, where n = |F|+ |C|. This result can be viewed as a continuation of our recent work (ICALP 2012) in which we presented the first sub-logarithmic-round distributed O(1)approximation algorithm for metric facility location on a clique network. The bipartite setting presents several new challenges not present in the problem on a clique network. We present two new techniques to overcome	approximation algorithm;continuation;distributed algorithm;facility location problem;icalp;time complexity	James Hegeman;Sriram V. Pemmaraju	2013		10.1007/978-3-642-41527-2_36	mathematical optimization;distributed computing	Theory	21.0659608121644	14.76859812880564	93158
d61ed927c2d6372903ef913edcd562e10fcd2a41	time-cost trade-off analysis of project networks in fuzzy environments	crush;parametric programming;aplastamiento;project management;fuzzy set;lower and upper bound;programmation parametrique;project manager;logique floue;conjunto difuso;logica difusa;temps minimal;ensemble flou;fuzzy sets;fuzzy logic;upper bound;fuzzy sets project management time cost trade off crash parametric programming;programacion parametrica;mathematical programming;time cost trade off;fonction appartenance;borne inferieure;membership function;coste;minimum time;crash;gestion projet;programacion binivel;extension principle;funcion pertenencia;bilevel programming;borne superieure;ecrasement;programmation biniveau;tiempo minimo;lower bound;gestion proyecto;cota superior;cota inferior;cout	Article history: Received 3 February 2010 Accepted 1 February 2011 Available online 26 February 2011	approximation algorithm;dr. web;experiment;fuzzy number;fuzzy set;genetic algorithm;heuristic (computer science);linear programming formulation;mathematical model;nonlinear system;numerical analysis;polynomial;powera;project network;project networks;r-type;time complexity	Shih-Pin Chen;Ming-Jiun Tsai	2011	European Journal of Operational Research	10.1016/j.ejor.2011.02.002	fuzzy logic;project management;mathematical optimization;membership function;defuzzification;fuzzy transportation;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;operations management;mathematics;fuzzy set;upper and lower bounds;fuzzy set operations;algorithm;statistics	Vision	18.81108688997538	8.587532451551175	93174
307fa0be7ad65d12695c90f168f7544ce983f5ae	what about wednesday? approximation algorithms for multistage stochastic optimization	algoritmo aleatorizado;vertex cover;multistage;approximate algorithm;decision making under uncertainty;cost function;approximation algorithm;echantillonnage;programmation stochastique;multietage;algorithme randomise;natural extension;satisfiability;funcion coste;sampling;optimisation combinatoire;optimization problem;appareil etage;aleatorizacion;stochastic optimization;sharing;particion;approximate solution;poliescalonado;stochastic approximation;approximation stochastique;algoritmo aproximacion;randomized algorithm;randomisation;fonction cout;multistage apparatus;aproximacion estocastica;partage;algorithme approximation;muestreo;randomization;combinatorial optimization;stochastic programming;steiner tree;aparato poliescalonado;programacion estocastica;facility location;optimizacion combinatoria	The field of stochastic optimization studies decision making under uncertainty, when only probabilistic information about the future is available. Finding approximate solutions to well-studied optimization problems (such as Steiner tree, Vertex Cover, and Facility Location, to name but a few) presents new challenges when investigated in this framework, which has promoted much research in approximation algorithms. There has been much interest in optimization problems in the setting of two-stage stochastic optimization with recourse, which can be paraphrased as follows: On the first day (Monday), we know a probability distribution π from which client demands will be drawn on Tuesday, and are allowed to make preliminary investments (e.g., installing links, opening facilities) towards meeting this future demand. On Tuesday, the actual requirements are revealed (drawn from the same distribution π) and we must purchase enough additional equipment to satisfy these demands; however, these purchases are now made at an inflated cost. In a recent paper [8], we proposed the Boosted Sampling framework which converted an approximation algorithm A for an optimization problem Π into one for the stochastic version of Π (provided A satisfied certain technical conditions). In this paper, we give two generalizations of this Boosted Sampling framework: Firstly, we show that a natural extension of the framework works in a general k-stage setting, where information about the future is gradually revealed in several stages and we are allowed to take (increasingly expensive) corrective actions in each stage. We use these to give approximation algorithms for k-stage Steiner Tree, Facility Location and Vertex Cover. ⋆ Supported in part by NSF CAREER award CCF-0448095 and an Alfred P. Sloan Fellowship. ⋆⋆ Supported by NSF grant EIA 02-05116. ⋆ ⋆ ⋆ Supported in part by NSF grant CCR-0105548 and ITR grant CCR-0122581. Furthermore, the Boosted Sampling framework of [8] requires the inflation parameter specifying the increase in cost of future actions be independent of the distribution π. In this paper, we show how to extend the framework to the case where this inflation parameter is arbitrarily correlated with the client set S.	approximation algorithm;boson sampling;decision theory;gibbs sampling;ibm notes;mathematical optimization;multistage amplifier;optimization problem;optimizing compiler;purchasing;requirement;scart;sampling (signal processing);steiner tree problem;stochastic optimization;vertex cover	Anupam Gupta;Martin Pál;R. Ravi;Amitabh Sinha	2005		10.1007/11538462_8	randomization;stochastic programming;optimization problem;stochastic approximation;sampling;mathematical optimization;combinatorics;vertex cover;steiner tree problem;combinatorial optimization;computer science;facility location problem;stochastic optimization;mathematics;randomized algorithm;approximation algorithm;algorithm;satisfiability	Theory	20.911226438636884	14.131620721421383	93360
26636f60cece420ddc20f6f3b2e867ba5def9339	time-indexed formulations for machine scheduling problems: column generation	approximate algorithm;general techniques;dantiz wolfe decompositon;scheduling;indexation;linear programming relaxation;machine scheduling;lower bound;column generation;time indexed formulation	Time-indexed formulations for machine scheduling problems have received a great deal of attention; not only do the linear programming relaxations provide strong lower bounds, but they are good guides for approximation algorithms as well. Unfortunately, time-indexed formulations have one major disadvantage: their size. Even for relatively small instances the number of constraints and the number of variables can be large. In this paper, we discuss how Dantzig-Wolfe decomposition techniques can be applied to alleviate, at least partly, the difficulties associated with the size of time-indexed formulations. In addition we show that the application of these techniques still allows the use of cut generation techniques.	approximation algorithm;column generation;dantzig–wolfe decomposition;linear programming;scheduling (computing)	J. M. van den Akker;Cor A. J. Hurkens;Martin W. P. Savelsbergh	2000	INFORMS Journal on Computing	10.1287/ijoc.12.2.111.11896	column generation;mathematical optimization;computer science;linear programming relaxation;mathematics;upper and lower bounds;scheduling;algorithm	Theory	18.898042322999046	11.258205927103836	93394
0636d34020fa928dcd2f674cea612ef8475d7011	minimizing mean weighted execution time loss on identical and uniform processors	metodo polinomial;complexite;planificacion integral;gestion labor;multiprocessor;real time;integrated planning;complejidad;complexity;systeme deterministe;algorithme;algorithm;algorritmo;gestion tâche;sistema determinista;polynomial method;scheduling;temps reel;tiempo real;task scheduling;multiprocesador;methode polynomiale;ordonnancement;deterministic system;multiprocesseur	Abstract   The problem of minimizing mean weighted execution time loss was formulated by the present author in 1984; there the preemptive case for identical as well as for a fixed number of uniform processors was solved via a linear programming approach. In this paper, we propose a strongly polynomial algorithm based on a network flow technique, which minimizes the above criterion for an arbitrary number of identical as well as uniform processors. The upper bounds on the number of preemptions in both cases are also given.		Jacek Blazewicz;Gerd Finke	1987	Inf. Process. Lett.	10.1016/0020-0190(87)90145-1	complexity;real-time computing;multiprocessing;computer science;deterministic system;mathematics;distributed computing;integrated business planning;scheduling;algorithm	OS	17.02723480930885	10.807996804343246	93615
f00fb0ddee42aa65dceddff4ff1b56154c9c379d	a note on the hardness of skolem-type sequences	optimisation;simplification;combinatorics;np completude;optimizacion;gestion labor;combinatoria;np completeness;combinatoire;upper bound;gestion tâche;informatique theorique;coupled task scheduling;simplificacion;datavetenskap datalogi;optimization;computer science;task scheduling;borne superieure;skolem sequence;cota superior;computer theory;informatica teorica	The purpose of this note is to give upper bounds (assuming P different from NP) on how far the generalizations of Skolem sequences can be taken while still hoping to resolve the existence question. We prove that the existence questions for both multi Skolem sequences and generalized Skolem sequences are strongly NP-complete. These results are significant strengthenings and simplifications of the recent NP-completeness result for generalized multi Skolem sequences.	strong np-completeness	Gustav Nordh	2010	Discrete Applied Mathematics	10.1016/j.dam.2010.01.006	mathematical optimization;combinatorics;discrete mathematics;np-complete;mathematics;upper and lower bounds;simplification;algorithm	Theory	14.389574932923505	18.05727042017662	93843
fb02d47e8d7a5c9fc3deac01e349d321f3abafc9	a tabu search approach for the flow shop scheduling problem	simulated annealing algorithm;heuristic method;production system;systeme production;flow shop scheduling;metodo heuristico;sistema produccion;permutation;algorithme;algorithm;scheduling;permutacion;ordonamiento;tabu search;methode heuristique;ordonnancement;flow shop;busqueda tabu;recherche tabou;algoritmo	In this paper, we propose a tabu search approach for solving the permutation flow shop scheduling problem. The proposed implementation of the tabu search approach suggests simple techniques for generating neighborhoods of a given sequence and a combined scheme for intensification and diversification that has not been considered before. These new features result in an implementation that improves upon previous tabu search implementations that use mechanisms of comparable simplicity. Also, better results were obtained than those produced by a simulated annealing algorithm from the literature. @ 1998 Elsevier Science B.V.	algorithm;diversification (finance);flow shop scheduling;scheduling (computing);simulated annealing;tabu search	Mohamed Ben-Daya;Mohammad A. Al-Fawzan	1998	European Journal of Operational Research	10.1016/S0377-2217(97)00136-7	mathematical optimization;flow shop scheduling;tabu search;computer science;operations management;hill climbing;mathematics;algorithm;guided local search	Embedded	19.7509467915362	6.176254529881746	93864
8fcddb06db7b9d91ced047b41fac33c20485cf95	matrix method for the multi salesmen problem (tsp) with several vehicles	data structure	Despite the considerable progress made in a transport logistics research, an actual problem today is an optimization of time spends on search for optimal solution [1]. This article describes a method that can be used to simplify and solve the cargo routing problem with several vehicles. The method offers easier and faster solution compare to other known methods. The cargo routing problems are based on the classic traveling salesman problem (TSP). TSP is an NP-hard problem [2]. The task is to find a shortest possible route that visits each travel point exactly once with a return to the starting point given a list of points and their pairwise distances. Modern computer technology is widely used to solve this type of problems. However, practical matters require a more complex undertaking [3]. One of the variations of routing problem is a routing with several vehicles and various cargo limitations [4]. Linear and integer programming methods are often incompatible for this type of problems due to the complexity and vast volume of data processing. Approaches that can be used include an introduction of heuristic methods (hypotheses) [5], [6]. This technique leads to a decomposition of the problem [7]. This article discusses a procedure of division of the routing problem with several vehicles to a problem with one vehicle with matrix approach.	computer;heuristic;integer programming;logistics;mathematical optimization;matrix method;np-hardness;routing;travelling salesman problem	Sergey Ishkov;Elena Ishkova	2011	CoRR		mathematical optimization;data structure;computer science;programming language;operations research	Theory	17.660220735415475	4.240935562876051	93966
50c0354e82ed79dfdae9c1bb035c8dfdc7d81348	robust crew pairing for managing extra flights	modelizacion;gestion personnel;overhead line;comptage;staff management;temps retablissement;recuperacion;reglamentacion;t technology general;ligne aerienne;flight;pairing;q science general;air transportation;recovery;recovery time;contaje;gestion personal;feasibility;modelisation;vol;transport aerien;transporte aereo;charters;planificacion;computational study;mathematical models;mathematical programming;robustesse;personal de navegacion;personnel navigant;counting;mathematical model;crew pairing;regulation;robustness;crew;planning;recuperation;linea aerea;emparejamiento;planification;reglementation;appariement;modeling;vuelo;programmation mathematique;extra flights;programacion matematica;practicabilidad;faisabilite;robustnesss;tiempo restablecimiento;robustez	A: This paper discusses a modeling approach to robust crew pairing when a set of extra flights is likely to be added to the regular flight schedule. The set of these possible extra flights is known at the planning stage. We demonstrate that these extra flights may be incorporated into the schedule if necessary by modifying the planned crew pairings appropriately and without delaying or canceling existing flights. To this end, we either identify a pair of crews whose schedules may be (partially) swapped while adding an extra flight into the schedule or show that an extra flight may be inserted into the schedule of a crew without affecting others. We note that deadheading may be necessary in either case. For these two types of solutions, we define the appropriate feasibility rules with respect to the common airline regulations. We then propose two robust mathematical programming models that consider incorporating such solutions into the set of selected pairings while keeping the increase in the crew cost at an acceptable level. The baseline solution for comparison is found by a conventional crew pairing model in the literature which ignores robustness at the planning stage and relies on recovery procedures at the time of operation. We also propose the variations of the two models, where the double counting of the possible solutions across extra flights is prevented. Finally, we conduct computational experiments on a set of data generated from the actual data of an airline company. We solve the crew pairing problem both with the proposed robust models and the conventional model. Our results demonstrate the benefits of the proposed modeling approach and indicate that the proposed robust models provide natural options to recovery without disrupting the existing flights at a relatively small incremental cost, which is visible at the planning stage.	baseline (configuration management);computation;experiment;mathematical optimization;norm (social);robustness (computer science);schedule (computer science)	Hatice Tekiner;S. Ilker Birbil;Kerem Bülbül	2009	Computers & OR	10.1016/j.cor.2008.07.005	feasibility study;simulation;mathematical model;mathematics;operations research	ML	16.93372741218073	5.513260959073693	94144
6c8c9af3b8a532badf366620016d44fb9c649d0e	a scheduling model with a more general function of learning effects	scheduling;single criterion;multi criteria;learning effect	The proposed model is more general.Both the normal processing case and the actual processing case are considered.The proof technique is simpler and easier to use. This study develops a more general model for scheduling problems with learning effects. Compared with the existent general models, the proposed time- and position-dependent model simultaneously covers the normal and actual processing cases. Moreover, the model has many new properties that the previous work did not study. In this paper, a distinctive proof technique is developed based on the adding-and-subtracting-terms operation and the Lagrange Mean Value Theorem. The proof technique is easier to use than the method based on multiple identical or similar lemmas employed in a large number of literatures.	scheduling (computing)	Kaiping Luo	2015	Computers & Industrial Engineering	10.1016/j.cie.2015.01.025	mathematical optimization;simulation;computer science;artificial intelligence;machine learning;mathematics;learning effect;scheduling;algorithm	ML	14.716544302838088	8.763312232622422	94185
6be40991d7c6ca17c64485530852d5e4b3ec78a6	a two stage scheduling with transportation and batching	scheduling;transportation;fully polynomial time approximation scheme;np hard	We investigate a two stage scheduling problem with transportation and batching, in which jobs are transported from holding area to the batching machine by m vehicles in the first stage. Each vehicle can transport only one job at a time. As the job is big and heavy in the steel industry, it is reasonable to assume that the vehicle capacity is unit. In the second stage, the batching machine can process up to a fixed number of jobs as a batch simultaneously. Each bath to be processed occurs a processing cost. Our objective is to minimize the makespan and processing cost. For m=1, we present a polynomial time algorithm. For the general problem we prove that it is NP-hard in ordinary sense. Then we provide a pseudo-polynomial time algorithm and obtain a fully polynomial time approximation scheme.	scheduling (computing)	Hongli Zhu	2012	Inf. Process. Lett.	10.1016/j.ipl.2012.06.013	transport;mathematical optimization;real-time computing;polynomial-time approximation scheme;computer science;np-hard;scheduling;algorithm	DB	15.382764843541555	8.983406619024972	94340
908b72f08560b012a5b7cdc11d203ed39ed1fc7f	unit cost buyback problem		In this paper, we study the unit cost buyback problem, i.e., the buyback problemwith a fixed cancellation cost for each canceled element. The input of the problem is a sequence of elements e1, e2, . . . , en where each element ei has a weight w(ei). We assume that the weights are in a known range [l, u], i.e., l ≤ w(ei) ≤ u for any i. Given the ith element ei , we either accept ei or reject it with no cost, where we can keep a set of elements that satisfies a certain constraint. In order to accept a new element ei , we can cancel some previously selected elements at a cost which is proportional to the number of elements canceled. Our goal is to maximize the profit, i.e., the total weights of elements accepted (and not canceled) minus the total cancellation cost occurred. We construct optimal online algorithms and prove that they are the best possible when the constraint is a matroid constraint or the unweighted knapsack constraint.	matroid;online algorithm;weight	Yasushi Kawase;Xin Han;Kazuhisa Makino	2013		10.1007/978-3-642-45030-3_41	online algorithm;computer science;competitive analysis;discrete mathematics;unit cost;knapsack problem;matroid;upper and lower bounds	DB	17.803109566451326	14.483378383114829	94371
11e4d7af7660c1adb2e0c15b31cf20047b8cd010	idle times analysis in two-sided assembly line balancing problem		This paper considers idle times in two-sided assembly line structure. In the last two decades a large variety of heuristics and exact solutions procedures have been proposed to balance two-sided assembly line. Some measures of solution quality have appeared in line balancing literature: balance delay (BD), line efficiency (LE), line time (LT) and smoothness index (SI). These measures are very important for estimation the balance solution quality. Author of this paper modified and discussed the line time and smoothness index for two-sided assembly line. Special attention was given to idle times in discussed problem. A new measure of delay times is considered and at the end final remarks are presented.	blu-ray;heuristic (computer science);production leveling	Waldemar Grzechca	2013		10.3182/20130619-3-RU-3018.00520	engineering;operations management;industrial engineering;operations research	EDA	14.657255935161766	5.875479405874638	94486
0e487356257c59cb42b90cd9ddf68766584acfca	fast algorithms for generating discrete random variates with changing distributions	randomized algorithms;queueing network;discrete event dynamic system;simulation;queueing networks;discrete event system;random variate generation;fast algorithm;random variable;randomized algorithm;queuing networks	One of the most fundamental operations when simulating a stochastic discrete-event dynamic system is the generation of a nonuniform discrete random variate. The simplest form of this operation can be stated as follows: Generate a random variable X that is distributed over the integers 1,2,…,<italic>n</italic> such that P(X=<italic>i</italic>) = <italic>a<subscrpt>i</subscrpt></italic>/(<italic>a</italic><subscrpt>1</subscrpt> +…+<italic>a<subscrpt>n</subscrpt></italic>), where <italic>a<subscrpt>i</subscrpt></italic>'s are fixed nonnegative numbers. The well-known “alias algorithm” is available to accomplish this task in O(1) time. A more difficult problem is to generate variates for X when the <italic>a<subscrpt>i</subscrpt></italic>'s are changing with time. We  present three rejection-based algorithms for this task, and for each algorithm we characterize the performance in terms of acceptance probability and the expected effort to generate a variate. We show that, under fairly unrestrictive conditions, the long-run expected effort is O(1). Applications to Markovian queuing networks are discussed. We also compare the three algorithms with competing schemes appearing in the literature.	algorithm;competitive analysis (online algorithm);computer simulation;dynamical system;existential quantification;rejection sampling;run time (program lifecycle phase);whole earth 'lectronic link	Sanguthevar Rajasekaran;Keith W. Ross	1993	ACM Trans. Model. Comput. Simul.	10.1145/151527.151529	random variate;mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;randomized algorithm;statistics	Theory	10.694509510699795	11.813447879026977	94513
c407d9310843fa5f89a11016ed91462cfaee9b5f	a dynamical communication system on a network	computacion informatica;synchronization of parallel computing processes;mathematical theory;dynamical system;ciencias basicas y experimentales;matematicas;grupo a;communication;markov chains	A dynamical system is introduced and investigated. The system contains N vertices. The vertices send messages at discrete time instants according to a given rule. A conflict of two vertices takes place if the vertices try to send messages to each other at the same instant. Each vertex sends a message to another vertex at every step if no conflict takes place. In case of a conflict, only one of the two competing vertices sends a message. Deterministic and stochastic conflict resolution rules are considered. We investigate the average number of messages sent by a vertex per a time unit, called the productivity of this vertex, the total productivity of the system and other characteristics. The productivity of vertices depends on the initial state of the system, and the criterion of efficiency is the expected average productivity of vertices provided all possible initial states of the system are equiprobable. An ergodic version of the system is also considered in which any particle moves with approximately equal to 1 probability provided there is no conflict. © 2014 Elsevier B.V. All rights reserved. 1. Model of a network Consider a network, which contains N vertices. Each vertex can send a message to another vertex during a discrete time. The vertices are connected in accordance with a symmetrical communication matrix C =  cij  . Each element equals 0 if no message is sent from the vertex i to the vertex j, cij = 1 if such transmission is possible at a discrete time period. Suppose cij = cji, i ≠ j, i = 1, . . . ,N, j = 1, . . . ,N. 2. Dynamical communication system	approximation;dynamical system;ergodicity;open road tolling;simulation;synergy;vertex (geometry);vertex (graph theory)	Valery V. Kozlov;Alexander P. Buslaev;Alexander G. Tatashev	2015	J. Computational Applied Mathematics	10.1016/j.cam.2014.07.026	markov chain;mathematical optimization;combinatorics;discrete mathematics;graph center;theoretical computer science;dynamical system;mathematics;algorithm	Theory	10.339130672024764	11.14213521809666	94604
059e27d1839ca3b790437c0b2abcdc838624549d	similarity caching	caching;buffer management;nearest neighbor;competitive analysis	We introduce the similarity caching problem, a variant of classical caching in which an algorithm can return an element from the cache that is similar, but not necessarily identical, to the query element. We are motivated by buffer management questions in approximate nearest-neighbor applications, especially in the context of caching targeted advertisements on the web. Formally, we assume the queries lie in a metric space, with distance function d(.,.). A query p is considered a cache hit if there is a point q in the cache that is sufficiently close to p, i.e., for a threshold radius r, we have d(p,q) ≤ r. The goal is then to minimize the number of cache misses, vis-à-vis the optimal algorithm. As with classical caching, we use the competitive ratio to measure the performance of different algorithms.  While similarity caching is a strict generalization of classical caching, we show that unless the algorithm is allowed extra power (either in the size of the cache or the threshold r) over the optimal offline algorithm, the problem is intractable. We then proceed to quantify the hardness as a function of the complexity of the underlying metric space. We show that the problem becomes easier as we proceed from general metric spaces to those of bounded doubling dimension, and to Euclidean metrics. Finally, we investigate several extensions of the problem: dependence of the threshold r on the query and a smoother trade-off between the cache-miss cost and the query-query similarity.	approximation algorithm;cpu cache;cache (computing);competitive analysis (online algorithm);online algorithm;online and offline;period-doubling bifurcation;visual instruction set	Flavio Chierichetti;Ravi Kumar;Sergei Vassilvitskii	2009		10.1145/1559795.1559815	competitive analysis;computer science;theoretical computer science;database;mathematics;distributed computing;k-nearest neighbors algorithm	Theory	15.995243998779221	14.78925456281077	94636
1d6ece5b90ec144ace89e309cd8aaf96d1155298	a heuristic rule for relocating blocks	apilamiento;relocation;heuristic rule;localization;branch and bound algorithm;heuristic method;metodo heuristico;localizacion;regle decision;branch and bound method;localisation;stacking;metodo branch and bound;almacenamiento;stockage;conteneur;methode heuristique;regla decision;methode separation et evaluation;contenedor;branch and bound;storage;decision rule;block stacking;empilement;container	One of the most important objectives of the storage and pickup operations in block stacking systems is to minimize the number of relocations during the pickup operation.This study suggests two methods for determining the locations of relocated blocks. First, a branch-and-bound (B&B) algorithm is suggested. Next, a decision rule is proposed by using an estimator for an expected number of additional relocations for a stack. The performance of the decision rule was compared with that of the B&B algorithm. 2004 Elsevier Ltd. All rights reserved.	algorithm;branch and bound;heuristic;stacking	Kap Hwan Kim;Gyu-Pyo Hong	2006	Computers & OR	10.1016/j.cor.2004.08.005	mathematical optimization;computer science;mathematics;branch and bound;algorithm	AI	18.833103583949374	6.423524931467566	94653
5f12d5f839360c000c9a935d8b28c1cc72c8d98b	computing nash equilibria for scheduling on restricted parallel links	algorithmic game theory;nash equilibrium;scheduling restricted machines;nash equilibria;unsplittable flow;polynomial time algorithm;polynomial time;scheduling problem;parallel machines;computation of nash equilibria	We consider the problem of routing n users on m parallel links, under the restriction that each user may only be routed on a link from a certain set of allowed links for the user. Thus, the problem is equivalent to the correspondingly restricted problem of assigning n jobs to m parallel machines. In a pure Nash equilibrium, no user may improve its own individual cost (delay) by unilaterally switching to another link from its set of allowed links. As our main result, we introduce a polynomial time algorithm to compute from any given assignment a pure Nash equilibrium with non-increased makespan. The algorithm gradually changes a given assignment by pushing unsplittable user traffics through a network that is defined by the users and the links. Here, we use ideas from blocking flows. Furthermore, we use similar techniques as in the generic Preflow-Push algorithm to approximate a schedule with minimum makespan, gaining an improved approximation factor of 2 - 1/w1 for identical links, where w1 is the largest user traffic. We extend this result to related links, gaining an approximation factor of 2. Our approximation algorithms run in polynomial time. We close with tight upper bounds on the coordination ratio for pure Nash equilibria.	approximation algorithm;blocking (computing);job stream;makespan;nash equilibrium;p (complexity);polynomial;push–relabel maximum flow algorithm;routing;scheduling (computing);time complexity	Martin Gairing;Thomas Lücking;Marios Mavronicolas;Burkhard Monien	2004	Theory of Computing Systems	10.1007/s00224-009-9191-9	job shop scheduling;mathematical optimization;combinatorics;computer science;mathematics;distributed computing;algorithm;nash equilibrium	Theory	17.819657570112728	15.231315246431729	94660
514ce15a754d8b3da481334ab1a3cb2ef37defe2	an implicit optimization approach for survivable network design	survivable network design;exponential number;network operator attempt;implicit optimization approach;exponential increase;network operator;disruption scenario;feasible flow;disruption budget;residual network;benders cut;network operator design;security;benders decomposition;power systems;satisfiability;algorithm design;optimization;power system;decomposition;reliability;algorithm design and analysis;stochastic programming	We consider the problem of designing a network of minimum cost while satisfying a prescribed survivability criterion. The survivability criterion requires that a feasible flow must still exists (i.e. all demands can be satisfied without violating arc capacities) even after the disruption of a subset of the network's arcs. Specifically, we consider the case in which a disruption (random or malicious) can destroy a subset of the arcs, with the cost of the disruption not to exceed a disruption budget. This problem takes the form of a tri-level, two-player game, in which the network operator designs (or augments) the network, then the attacker launches a disruption that destroys a subset of arcs, and then the network operator attempts to find a feasible flow over the residual network. We first show how this can be modeled as a two-stage stochastic program from the network operator's perspective, with each of the exponential number of potential attacks considered as a disruption scenario. We then reformulate this problem, via a Benders decomposition, to consider the recourse decisions implicitly, greatly reducing the number of variables but at the expense of an exponential increase in the number of constraints. We next develop a cut-generation based algorithm. Rather than explicitly considering each disruption scenario to identify these Benders cuts, however, we develop a bi-level program and corresponding separation algorithm that enables us to implicitly evaluate the exponential set of disruption scenarios. Our computational results demonstrate the efficacy of this approach.	algorithm;benders decomposition;black and burst;cobham's thesis;computer multitasking;denial-of-service attack;embedded system;flow network;iteration;jean;linear programming;malware;mathematical optimization;network planning and design;network security;nonlinear system;optimization problem;run time (program lifecycle phase);stochastic programming;time complexity;triangular function;vulnerability (computing)	Richard Li-Yang Chen;Amy Mainville Cohn;Ali Pinar	2011	2011 IEEE Network Science Workshop		algorithm design;mathematical optimization;computer science;information security;theoretical computer science;machine learning;mathematics;electric power system;algorithm	AI	11.712146127705662	8.393027128505214	94724
67ef8f511c45e74eb13b2c56fbb6d3fd01068ebf	an improved multi-agent approach for solving large traveling salesman problem	traveling salesman problem;distributed system;optimisation;multiagent system;systeme reparti;optimizacion;optimization technique;fonction generatrice;travelling salesman problem;conformation;problema np duro;intelligence artificielle;operations research;problema viajante comercio;optimization problem;np hard problem;hybrid approach;conformacion;sistema repartido;probleme np difficile;mathematical programming;probleme commis voyageur;recherche operationnelle;funcion generatriz;artificial intelligence;generating function;optimization;inteligencia artificial;sistema multiagente;programmation mathematique;programacion matematica;investigacion operacional;systeme multiagent	The traveling salesman problem (TSP) is a very hard optimization problem in the field of operations research. It has been shown to be NP-hard, and is an often-used benchmark for new optimization techniques. This paper proposes an improved multi-agent approach for solving large TSP. This proposed approach mainly includes three kinds of agents with different function. The first kind of agent is conformation agent and its function is generating the new solution continuously. The second kind of agent is optimization agent and its function is optimizing the current solutions group. The third kind of agent is refining agent and its function is refining the best solution from the beginning of the trial. At same time, there are many sub-agents in each kind of agent. These sub-agents accomplish the task of its superior agent cooperatively. At the end of this paper, the experimental results have shown that the proposed hybrid approach has good performance with respect to the quality of solution and the speed of computation.	agent architecture;computation;mathematical optimization;multi-agent system;np-hardness;operations research;optimization problem	Yu-an Tan;Xinhua Zhang;Li-Ning Xing;Xue-lan Zhang;Shu-Wu Wang	2006		10.1007/11802372_34	2-opt;computer science;artificial intelligence;mathematics;travelling salesman problem;operations research;algorithm	AI	20.561974815095496	5.7817073635509635	94733
2b0008e17d7360866d53331ce1be996e646fec97	scheduling alternative activities	scheduling problem;process planning	In realistic scheduling problems, there may be choices among resources or among process plans. We formulate a constraint-based representation of alternative activities to model problems containing such choices. We extend existing constraint-directed scheduling heuristic commitment techniques and propagators to reason directly about the fact that an activity does not necessarily have to exist in a final schedule. Experimental results show that an algorithm using a novel texture-based heuristic commitment technique together with extended edge-finding propagators achieves the best overall performance of the techniques tested.	algorithm;heuristic;propagator;scheduling (computing)	J. Christopher Beck;Mark S. Fox	1999			fair-share scheduling;mathematical optimization;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;scheduling;round-robin scheduling	AI	14.733532071175745	7.373223732904709	94781
3125ecac75f4a38bb9291ccda414e7402209bbc4	a note on heuristic approach based on ubqp formulation of the maximum diversity problem	unconstrained binary quadratic programming;r flip local search;maximum diversity problem;combinatorial optimization problem;diversification strategy	Abstract The maximum diversity problem (MDP) is a challenging NP-hard problem with a wide range of real applications. Several researchers have pointed out close relationship between the MDP and unconstrained binary quadratic program (UBQP). In this paper, we provide procedures to solve MDP ideas from the UBQP formulation of the problem. We first give some local optimality results for r-flip improvement procedures on MDP. Then, a set of highly effective diversification approaches based on sequential improvement steps for MDP are presented. Four versions of the approaches are used within a simple tabu search and applied to 140 benchmark MDP problems available on the Internet. The procedures solve all 80 small- to medium-sized problems instantly to the best known solutions. For 22 of the 60 large problems, the procedures improved by significant amounts the best known solutions in reasonably short CPU time.		Bahram Alidaee;Haibo Wang	2017	JORS	10.1057/s41274-016-0031-4	diversification;mathematical optimization;combinatorics;mathematics;mathematical economics	Robotics	21.466789346889012	10.13577217856912	95075
afd307f2be0d07d418bb7fcadca4f5d4fafdeaa9	performance guarantees of jump neighborhoods on restricted related parallel machines	approximation algorithms	Abstract   We study the performance of two popular jump neighborhoods on the classical scheduling problem of minimizing the makespan on related parallel machines under the additional restriction that jobs are only allowed to be scheduled on a subset of machines. In particular, we analyze the performance guarantee of local optima with respect to the jump and the lexicographical jump neighborhood.		Cyriel Rutten;Diego Recalde;Petra Schuurman;Tjark Vredeveld	2012	Oper. Res. Lett.	10.1016/j.orl.2012.04.002	mathematical optimization;real-time computing;mathematics;distributed computing	ML	15.854266211866404	10.306490431517362	95098
02ec4385230274441f0512f6f8683061ad428b07	fms scheduling based on timed petri net model and rta* algorithm	minimisation;flexible manufacturing systems;resource allocation;rule based;search algorithm;reverse model timed petri net model rta algorithm reactive fast search algorithm maximum completion time total deadline over time rule based supervisor reactive scheduling;flexible manufacturing systems scheduling algorithm job shop scheduling manufacturing systems production systems manufacturing processes resource management mathematical programming queueing analysis vehicles;time petri net;production control;search problems;minimisation petri nets flexible manufacturing systems production control search problems graph colouring resource allocation;petri nets;petri net;manufacturing system;graph colouring	This paper presents a new scheduling method for manufacturing system based on a Timed Petri net model and a reactive fast search algorithm. The following two typical problems are addressed in this paper. (1) Minimize the maximum completion time. (2) Minimize the total deadline over-time. As for problem (1), a search algorithm which combines RTA* and rule-based supervisor is proposed. Since both RTA* and rule-based supervisor can be executed in a reactive manner, machines and AGVs allocations can be scheduled reactively, and simultaneously. As for problem (2), original petri net model is converted to its reverse model and the algorithm developed in problem (1) is applied with regarding the due time as a starting time in the reverse model.	logic programming;petri net;scheduling (computing);search algorithm	YoungWoo Kim;Akio Inaba;Tatsuya Suzuki;Shigeru Okuma	2001		10.1109/ROBOT.2001.932656	rule-based system;real-time computing;stochastic petri net;computer science;artificial intelligence;distributed computing;petri net	Robotics	11.202003581913404	6.668670074697815	95402
e3c7594da86fdc563fe9ba0a7a39ab82017761c3	capacitated single allocation hub location problem - a bi-criteria approach	minimisation;modelizacion;location problem;minimization;probleme localisation;programacion entera;logistique;temps service;decision aid;cost function;systeme aide decision;minimizacion;interactive method;tiempo servicio;sistema ayuda decision;service time;funcion coste;programmation en nombres entiers;fonction objectif;interactive methods;objective function;modelisation;bi criteria problems;decision support system;programacion lineal;logistics;cost minimization;integer programming;mathematical programming;hub location;linear programming;programmation lineaire;coaccion capacidad;fonction cout;funcion objetivo;contrainte capacite;problema localizacion;capacity constraint;modeling;programmation mathematique;article;programacion matematica;location model;integer linear program;logistica	A different approach to the capacitated single allocation hub location problem is presented. Instead of using capacity constraints to limit the amount of flow that can be received by the hubs, we introduce a second objective function to the model (besides the traditional cost minimizing function), that tries to minimize the time to process the flow entering the hubs. Two bi-criteria single allocation hub location problems are presented: in a first model, total time is considered as the second criteria and, in a second model, the maximum service time for the hubs is minimized. To generate non-dominated solutions an interactive decision-aid approach developed for bi-criteria integer linear programming problems is used. Both bi-criteria models are tested on a set of instances, analyzing the corresponding non-dominated solutions set and studying the reasonableness of the hubs flow charge for these nondominated solutions. The increased information provided by the non-dominated solutions of the bi-criteria model when compared to the unique solution given by the capacitated hub location model is highlighted. 2007 Elsevier Ltd. All rights reserved.	integer programming;linear programming;loss function;optimization problem;usb hub	Maria da Graça Costa;M. Eugénia V. Captivo;João C. N. Clímaco	2008	Computers & OR	10.1016/j.cor.2007.04.005	logistics;minimisation;mathematical optimization;systems modeling;integer programming;decision support system;computer science;linear programming;mathematics;operations research;algorithm	AI	17.26255477964062	5.36229031514621	95452
4dd63e63a0ac2357b2233ca87b3a22590965b426	bounding search space size via (hyper)tree decompositions	search space;search algorithm;tree decomposition	This paper develops a measure for bounding the performance of AND/OR search algorithms for solving a variety of queries over graphical models. We show how drawing a connection to the recent notion of hypertree decompositions allows to exploit determinism in the problem specification and produce tighter bounds. We demonstrate on a variety of practical problem instances that we are often able to improve upon existing bounds by several orders of magnitude.	approximation algorithm;automatic parallelization;bayesian network;branch and bound;directed graph;graphical model;indeterminacy in concurrent computation;loss function;mathematical optimization;sampling (signal processing);search algorithm;software propagation;time complexity;tree decomposition	Lars Otten;Rina Dechter	2008			mathematical optimization;combinatorics;discrete mathematics;computer science;artificial intelligence;machine learning;mathematics;tree decomposition;search algorithm	AI	13.830687083729593	16.558656010091116	95535
c02bb1e3171af52a8d6734dda7b79f70be09750a	maximizing monotone submodular functions over the integer lattice	submodular functions;integer lattice;dr-submodular functions;90c27 combinatorial optimization	The problem of maximizing non-negative monotone submodular functions under a certain constraint has been intensively studied in the last decade. In this paper, we address the problem for functions defined over the integer lattice.rnrnSuppose that a non-negative monotone submodular function $$f:mathbb {Z}_+^n rightarrow mathbb {R}_+$$ is given via an evaluation oracle. Assume further that f satisfies the diminishing return property, which is not an immediate consequence of the submodularity when the domain is the integer lattice. Then, we show polynomial-time $$1-1/e-epsilon $$-approximation algorithm for cardinality constraints, polymatroid constraints, and knapsack constraints. For a cardinality constraint, we also show a $$1-1/e-epsilon $$-approximation algorithm with slightly worse time complexity that does not rely on the diminishing return property.rnrnOur algorithms for a polymatroid constraint and a knapsack constraint first extend the domain of the objective function to the Euclidean space and then run the continuous greedy algorithm. We give two different kinds of continuous extensions, one is for polymatroid constraints and the other is for knapsack constraints, which might be of independent interest.	submodular set function;monotone	Tasuku Soma;Yuichi Yoshida	2018	Math. Program.	10.1007/s10107-018-1324-y	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	22.03981159132289	15.860786770982774	95650
5b30e6885c6db25ac9b0c594f0c3de52a442151d	width-based algorithms for classical planning: new results		We have recently shown that classical planning problems can be characterized in terms of a width measure that is bounded and small for most planning benchmark domains when goals are restricted to single atoms. Two simple algorithms have been devised for exploiting this structure: Iterated Width (IW) for achieving atomic goals, that runs in time exponential in the problem width by performing a sequence of pruned breadth first searches, and Serialized IW (SIW) that uses IW in a greedy search for achieving conjunctive goals one goal at a time. While SIW does not use heuristic estimators of any sort, it manages to solve more problems than a Greedy BFS using a heuristic like hadd. Yet, it does not approach the performance of more recent planners like LAMA. In this short paper, we introduce two simple extension to IW and SIW that narrow the performance gap with state-of-the-art planners. The first involves changing the greedy search for achieving the goals one at a time, by a depthfirst search that is able to backtrack. The second involves computing a relaxed plan once before going to the next subgoal for making the pruning in the breadth-first procedure less agressive, while keeping IW exponential in the width parameter. The empirical results are interesting as they follow from ideas that are very different from those used in current planners.	automated planning and scheduling;backtrack;benchmark (computing);breadth-first search;greedy algorithm;heuristic;iw engine;iterated function;post-wall waveguide;time complexity	Nir Lipovetzky;Hector Geffner	2014		10.3233/978-1-61499-419-0-1059	mathematical optimization;artificial intelligence;machine learning;algorithm	AI	22.641982508384682	4.3051824732456785	95801
744ad97de844b95157f8665133d80d3cf5f2fd06	a new weighted spearman's footrule as a measure of distance between rankings		Many applications motivate the distance measure between rankings, such as comparing top-k lists and rank aggregation for voting, and intrigue great interest to researchers. For example, for a search engine, the use of different ranking algorithms may return different ranking lists. The effect of a ranking algorithm can be estimated by computing the distance (similarity) between the result ranking it returns and the appropriate ranking people expect. People may be interested in only the first few items of result ranking, therefore the metric for measuring the distance should emphasize on the items in higher positions. Besides, in an extreme case, if a result ranking is the total reverse of the expected ranking, then it is considered to be the worst ranking with the maximum distance. Therefore, a metric is called for, which can satisfy both of the two intuitions. To address this problem, we present a weighted metric based on the classical Spearman's footrule metric to measure the distance between two permutations of n objects. This metric can be applied in rank aggregation problem with a polynomial time algorithm, and produces a 2-approximation for adopting the weighted Kendall's tau distance proposed by Farnoud et al.	algorithm;bures metric;kendall tau distance;low-rank approximation;p (complexity);polynomial;review aggregator;web search engine	Jianwen Chen;Yiping Li;Ling Feng	2012	CoRR		combinatorics;discrete mathematics;ranking;ranking;kendall tau distance;mathematics;ranking svm;statistics	Web+IR	17.832032737360553	17.198306179650427	95819
106debec896ac05fe109d7a0aa99ce1779630418	cosats, x-cosats: two multi-agent systems cooperating simulated annealing, tabu search and x-over operator for the k-graph partitioning problem	modelizacion;graph theory;intercambio informacion;decomposition domaine;multiagent system;teoria grafo;descomposicion grafo;domain decomposition;multi agent system;analisis estadistico;search space;heuristic method;descomposicion dominio;metodo heuristico;intelligence artificielle;simulated annealing;theorie graphe;busca local;modelisation;recuit simule;graph partitioning;statistical analysis;reseau collecte;echange information;agent intelligent;information exchange;analyse statistique;intelligent agent;artificial intelligence;recocido simulado;tabu search;agente inteligente;methode heuristique;inteligencia artificial;sistema multiagente;modeling;local search;red recoleccion;recherche locale;busqueda tabu;recherche tabou;graph decomposition;systeme multiagent;decomposition graphe;gathering system	In this paper we propose two multi-agent systems gathering several metaheuristics for the K-Graph Partitioning Problem(K-GPP). In the first model COSATS, two metaheuristic agents, namely Tabu Search and Simulated Annealing run simultaneously to solve the K-GPP. These agents are mutually guided during their search process by means of a new mechanism of information exchange based on statistical analysis of search space. In the second model X-COSATS, a crossover agent is added to the model in order to make a crossover between the local optima found by simulated annealing and tabu agents. COSATS and X-COSATS are tested on several large graph benchmarks. The experiments demonstrated that our models achieve partitions with significantly higher quality than those generated by simulated annealing and tabu search operating separately.	graph partition;simulated annealing;tabu search	Moez Hammami;Khaled Ghédira	2005		10.1007/11554028_90	systems modeling;information exchange;simulated annealing;tabu search;computer science;graph partition;artificial intelligence;local search;graph theory;hill climbing;machine learning;mathematics;domain decomposition methods;intelligent agent;adaptive simulated annealing;algorithm;metaheuristic;guided local search	AI	20.910211572470445	5.781464682616664	96061
1bc3af921461fe741ce84df8d5d765469835a779	computing the nxm shortest paths efficiently	shortest path;n m shortest paths;road network;vehicle routing problem;traveling salesperson problem;a algorithm;gis;algorithms;experimentation	Computation of all the shortest paths between multiple sources and multiple destinations on various networks is required in many problems, such as the traveling salesperson problem (TSP) and the vehicle routing problem (VRP). This paper proposes new algorithms that compute the set of shortest paths efficiently by using the A<sup>*</sup> algorithm. The efficiency and properties of these algorithms are examined by using the results of experiments on an actual road network.	algorithm;computation;experiment;shortest path problem;travelling salesman problem;vehicle routing problem	Tetsuo Shibuya	2000	ACM Journal of Experimental Algorithmics	10.1145/351827.384251	private network-to-network interface;mathematical optimization;constrained shortest path first;a* search algorithm;floyd–warshall algorithm;average path length;computer science;euclidean shortest path;vehicle routing problem;machine learning;yen's algorithm;mathematics;distributed computing;link-state routing protocol;shortest path problem;travelling salesman problem;k shortest path routing;shortest path faster algorithm;algorithm	Theory	22.84031984213943	7.375203036203201	96075
23697f088c487dac42142c8bcfafc1e0efcd0d5b	adaptive lexicographic optimization in multi-class m/gi/1 queues	file attente;metodo adaptativo;optimisation;optimizacion;cost function;file m gi 1;adaptive control;queue;lexicographic optimization;methode adaptative;optimisation lexicographique;scheduling;stochastic approximation;adaptive method;approximation stochastique;ordonamiento;optimization;aproximacion estocastica;stochastic model;stochastic scheduling;modelo estocastico;fila espera;modele stochastique;ordonnancement	We consider a multi-class M/GI/1 system, in which an average response time objective is associated with each class. The performance of each class is measured by the ratio of the average response time over the corresponding value of the objective. To achieve fairness in service allocation it is required to Þnd a policy that lexicographically minimizes the vector of performance ratios arranged in non-increasing order. We provide such a policy that is adaptive, uses only knowledge of arrival and departure instants and is thus easy to implement. We also consider a variant of this policy which adapts faster to changes in the statistical parameters of the model. Both policies are analyzed via associated stochastic recursions using techniques of stochastic approximation.	fairness measure;goal programming;lexicographical order;recursion;response time (technology);stochastic approximation;stochastic gradient descent	Partha P. Bhattacharya;Leonidas Georgiadis;Pantelis Tsoucas;Yannis Viniotis	1993	Math. Oper. Res.	10.1287/moor.18.3.705	stochastic approximation;mathematical optimization;real-time computing;simulation;adaptive control;stochastic modelling;mathematics;scheduling;queue	Metrics	10.283882602414787	9.501320687523394	96331
21ed008be10a6d22e519938998641df7b55715d0	a heuristic for inserting randomly arriving jobs into an existing hoist schedule		Hoist scheduling in automated electroplating lines has been extensively studied in a static environment. However, practical electroplating lines are subject to diversified unforeseen disruptions that require frequent rescheduling to maintain or optimize system performance. This paper addresses a hoist scheduling problem, where randomly arriving jobs need to be inserted into an existing schedule without changing the sequence of hoist moves already scheduled. The objective is to minimize the total completion time of all the jobs in the existing schedule and a newly inserted job. We develop a polynomial-time heuristic that adjusts the starting times of the existing hoist moves to a limited extent but does not bring about a severe disturbance of the existing hoist moves. We compare our algorithm with two existing approaches with different rescheduling policies (i.e., partial and zero adjustment of the existing schedule). We empirically analyze the productivity and the stability of the schedules generated by the three approaches. Computational results demonstrate that our algorithm can generate more productive and stable schedules than the two existing approaches. Note to Practitioners—Electroplating and chemical surface treatment lines with automated material handling hoists are commonplace in electronics, semiconductor, and many other manufacturing industries. In an uncertain environment, hoist rescheduling plays an important role in improving the productivity and reducing the impact of disruptions. This paper presents a hoist scheduling algorithm to deal with dynamic job arrivals by considering the impact of the disturbance incurred by rescheduling. Our algorithm can generate a better schedule with smaller total completion time and slighter disturbance than the existing algorithms. The proposed algorithm runs in polynomial time and can be used to control hoist operations in practical electroplating lines. A comparative analysis provides useful insights on the implementation of rescheduling approaches and policies to industry practitioners.	algorithm;best, worst and average case;computation;crew scheduling;heuristic (computer science);javascript syntax;job stream;material handling;polynomial;qualitative comparative analysis;randomness;schedule (computer science);scheduling (computing);semiconductor;time complexity;vehicle rescheduling problem	Pengyu Yan;Ada Che;Eugene Levner;Shi Qiang Liu	2018	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2017.2749429	real-time computing;time complexity;control engineering;computer science;job shop scheduling;algorithm design;hoist (device);simulation;scheduling (computing);schedule;heuristic		15.340269443631717	8.241725002067435	96782
e84bf3e4d658915cdb9a90acbf0d67758f71e50d	bbph: using progressive hedging within branch and bound to solve multi-stage stochastic mixed integer programs	progressive hedging;stochastic programming;branch and bound	Progressive hedging, though an effective heuristic for solving stochastic mixed integer programs (SMIPs), is not guaranteed to converge in this case. Here, we describe BBPH, a branch and bound algorithm that uses PH at each node in the search tree such that, given sufficient time, it will always converge to a globally optimal solution. In addition to providing a theoretically convergent “wrapper” for PH applied to SMIPs, computational results demonstrate that for some difficult problem instances branch and bound can find improved solutions after exploring only a few nodes.	algorithm;branch and bound;converge;heuristic;linear programming;maxima and minima;progressive scan;search tree	Jason Barnett;Jean-Paul Watson;David L. Woodruff	2017	Oper. Res. Lett.	10.1016/j.orl.2016.11.006	stochastic programming;mathematical optimization;combinatorics;branch and price;mathematics;mathematical economics;branch and bound;branch and cut	AI	21.04908281407829	9.765061415343059	96802
c41378273d1d0eb956221b7fb35f977b467da8f2	evolutionary driver scheduling with relief chains	public transport hybrid genetic algorithms learning property combinatorial traits driver scheduling set covering;pedestrian safety;poison control;injury prevention;public transport;hybrid genetic algorithms;driver scheduling;safety literature;traffic safety;injury control;home safety;hybrid approach;injury research;safety abstracts;human factors;occupational safety;safety;combinatorial traits;scheduling problem;safety research;genetic algorithm;accident prevention;violence prevention;bicycle safety;set covering;poisoning prevention;falls;ergonomics;set cover;suicide prevention;integer linear program;hybrid genetic algorithm;learning property	Public transport driver scheduling problems are well known to be NP-hard. Although some mathematically based methods are being used in the transport industry, there is room for improvement. A hybrid approach incorporating a genetic algorithm (GA) is presented. The role of the GA is to derive a small selection of good shifts to seed a greedy schedule construction heuristic. A group of shifts called a relief chain is identi-fied and recorded. The relief chain is then inherited by the offspring and used by the GA for schedule construction. The new approach has been tested using real-life data sets, some of which represent very large problem instances. The results are generally better than those compiled by experienced schedulers and are comparable to solutions found by integer linear programming (ILP). In some cases, solutions were obtained when the ILP failed within practical computational limits.	auto-tune;biologic preservation;cargo cult programming;chromosome (genetic algorithm);clinical act of insertion;compiler;computation;genetic algorithm;greedy algorithm;hl7publishingsubsection <operations>;heuristic;heuristic (computer science);integer (number);integer programming;linear iga bullous dermatosis;linear programming;local search (optimization);np-hardness;random number generation;random seed;real life;relaxation;rule (guideline);s/pdif;scheduling (computing);scheduling - hl7 publishing domain;software release life cycle;solutions;the offspring;trait;word lists by frequency;xiap gene;xiap wt allele	Raymond S. K. Kwan;Ann S. K. Kwan;Anthony Wren	2001	Evolutionary Computation	10.1162/10636560152642869	mathematical optimization;simulation;genetic algorithm;computer science;suicide prevention;artificial intelligence;human factors and ergonomics;operations management;injury prevention;machine learning;public transport;set cover problem;algorithm	AI	15.647898423709965	4.271849210305882	96876
6a5ca8c29f46f33e969d4ada24e2505f7d95afb8	complexity and approximation of an area packing problem		Motivated by an application in mobile telecommunication systems, we investigate a packing problem in which items are specified in terms of area constraints. We establish strong NP-hardness of this problem, provide a linear time 3-approximation algorithm, and discuss the combinatorics of a special case.	approximation algorithm;best, worst and average case;discrete optimization;mathematical optimization;np-hardness;optimization problem;set packing;time complexity	Cor A. J. Hurkens;Andrea Lodi;Silvano Martello;Michele Monaci;Gerhard J. Woeginger	2012	Optimization Letters	10.1007/s11590-010-0246-2	mathematical optimization;combinatorics;discrete mathematics;set packing;mathematics	AI	22.138399878959838	14.85256514989497	96998
e027120fcaf4760cac9340ffbe4c593220551925	optimization of occupancy rate in dial-a-ride problems via linear fractional column generation	transporte colectivo segun demanda;fonction rationnelle;programacion fraccionaria;generation colonne;optimisation;dial a ride;logistique;optimizacion;set partitions;generacion columna;on demand transportation;vehicle routing problem;linear fractional program;vehicle routing;probleme tournee vehicule;problema ruta vehiculo;programmation fractionnaire;fractional programming;transport system;fonction objectif;set partitioning;dial a ride problem;objective function;programacion lineal;logistics;timing optimization;partitionnement ensemble;transport collectif a la demande;coste;linear programming;programmation lineaire;funcion objetivo;optimization;funcion racional;particion conjunto;rational function;column generation;logistica;cout	In this paper, we consider a dial-a-ride problem where the objective is to maximize the passenger occupancy rate. The problem arises from an on-demand transportation system developed in a rural zone in France, where the objective of encouraging people meeting is pursued. We address the solution of the problem with a column generation approach, applied to a set partitioning formulation where the objective function is fractional. Based on the literature on linear fractional programming, two methods are developed to deal with this fractional objective. Experiments permit to compare these two approaches and to evaluate the impact of the new objective compared to a standard min-cost or min-time optimization.	column generation	Thierry Garaix;Christian Artigues;Dominique Feillet;Didier Josselin	2011	Computers & OR	10.1016/j.cor.2010.12.014	column generation;fractional programming;logistics;rational function;mathematical optimization;simulation;input/output;vehicle routing problem;mathematics	Theory	18.14722959961002	5.566016284223632	97046
738071b41ac37656311906850d4c305d40fbe518	a search space pruning method for test pattern generation using search state dominance		In this paper, we present a new technique that can prune search space in test-pattern generation for combinational circuits. We extend the concept of search state equivalence derived by Giraldi and Bushnell, to that of search state dominance, and propose a new extended method, DST (Dominant STate hashing) algorithm, based on the search state dominance. The DST algorithm can prune the search space more effectively than the EST (Equivalent STate hashing) algorithm of Giraldi and Bushnell. Experimental results on benchmark circuits are reported.		Takayuki Fujino;Hideo Fujiwara	1993	Journal of Circuits, Systems, and Computers	10.1142/S0218126693000496	beam search;mathematical optimization;machine learning;jump search;mathematics;best-first search;algorithm;search algorithm	ML	10.106823356297033	15.811078750939435	97156
a8cc94586a4e027ec46f42a6597e7bb5454b412f	online scheduling of mixed cpu-gpu jobs	cpu gpu cluster;online scheduling;unrelated machine scheduling;competitive ratio	We consider the online scheduling problem in a CPU-GPU cluster. In this problem there are two sets of processors, the CPU processors and the GPU processors. Each job has two distinct processing times, one for the CPU processor and the other for the GPU processor. Once a job is released, a decision should be made immediately about which processor it should be assigned to. The goal is to minimize the makespan, i.e., the largest completion time among all the processors. Such a problem could be seen as an intermediate model between the scheduling problem on identical machines and unrelated machines. We provide a 3.85-competitive online algorithm for this problem and show that no online algorithm exists with competitive ratio strictly less than 2. We also consider two special cases of this problem, the balanced case where the number of CPU processors equals to that of GPU processors, and the one-sided case where there is only one CPU or GPU processor. For the balanced case, we first provide a simple 3-competitive algorithm, and then a better algorithm with competitive ratio of 2.732 is derived. For the one-sided case, a 3-competitive algorithm is given.	central processing unit;competitive analysis (online algorithm);gpu cluster;graphics processing unit;job stream;makespan;nl (complexity);nl-complete;numerical aperture;online algorithm;scheduling (computing)	Lin Chen;Deshi Ye;Guochuan Zhang	2014	Int. J. Found. Comput. Sci.	10.1142/S0129054114500312	fair-share scheduling;competitive analysis;parallel computing;real-time computing;computer science;rate-monotonic scheduling;distributed computing;multiprocessor scheduling	Theory	15.47960718332697	11.470715439069394	97171
0e315f7ac2f82ca8b94cec65f3e1c5dfd467948c	two metaheuristics for multiobjective stochastic combinatorial optimization	multiobjective programming;algoritmo aleatorizado;optimum pareto;programmation multiobjectif;swarm intelligence;ant colony optimization;temps service;travelling salesman problem;heuristic method;combinatorial optimization problem;time window;calculo estocastico;programmation stochastique;metodo heuristico;tiempo servicio;algorithme randomise;probabilistic approach;service time;simulated annealing;decision analysis;stochastic calculus;optimisation combinatoire;problema viajante comercio;combinatorial problem;stochastic optimization;probleme combinatoire;recuit simule;problema combinatorio;optimizacion enjambre particula;mathematical programming;probleme commis voyageur;enfoque probabilista;approche probabiliste;multiobjective decision analysis;randomized algorithm;optimisation essaim particule;fenetre temporelle;recocido simulado;calcul stochastique;methode heuristique;ventana temporal;combinatorial optimization;stochastic programming;pareto optimum;programmation mathematique;optimo pareto;programacion estocastica;programacion matematica;optimizacion combinatoria;programacion multiobjetivo	Two general-purpose metaheuristic algorithms for solving multiobjective stochastic combinatorial optimization problems are introduced: SP-ACO (based on the Ant Colony Optimization paradigm) which combines the previously developed algorithms S-ACO and P-ACO, and SPSA, which extends Pareto Simulated Annealing to the stochastic case. Both approaches are tested on random instances of a TSP with time windows and stochastic service times.	algorithm;ant colony optimization algorithms;combinatorial optimization;general-purpose modeling;mathematical optimization;metaheuristic;microsoft windows;pareto efficiency;programming paradigm;random search;simulated annealing;simultaneous perturbation stochastic approximation	Walter J. Gutjahr	2005		10.1007/11571155_12	stochastic programming;stochastic calculus;mathematical optimization;ant colony optimization algorithms;parallel metaheuristic;simulated annealing;decision analysis;combinatorial optimization;swarm intelligence;computer science;artificial intelligence;stochastic optimization;mathematics;randomized algorithm;travelling salesman problem;algorithm;metaheuristic	Theory	20.565924512581248	6.135231599011041	97299
0b9e72257da33b4330a2b30adb7fd1dda70e52d6	on the effectiveness of synchronous parallel branch-and-bound algorithms	algoritmo paralelo;methode branch and bound;probleme sac a dos;parallel algorithm;shared memory;decomposition;memoria compartida;efficiency;branch and bound algorithm;paralelisacion;problema mochila;algorithme parallele;optimisation combinatoire;knapsack problem;eficacia;branch and bound method;metodo branch and bound;parallelisation;parallelization;efficacite;parallel branch and bound;descomposicion;parallel efficiency;combinatorial optimization;memoire partagee;optimizacion combinatoria	We theoretically compare the efficiency of two versions, sequential and parallel (synchronous), of the method called branch-and-bound used for searching for an optimal solution in the scope of combinatorial optimization. The sequential version consists of successive decompositions of the original problem in smaller disjoint subproblems and its parallel version consists of a high level parallelization that assumes a shared memory model of parallel computation. Its principle consists of decomposing several subproblems in parallel at each iteration in a synchronous way, and its efficiency is usually defined with respect to its sequential counterpart. In this paper, we redefine the notion of efficiency in such a way that the usefulness of the work done by each processor will be taken into account. The knapsack problem is used as an application and some simulation results are presented to validate and illustrate the use of the new efficiency measures.	algorithm;branch and bound	Ricardo C. Corrêa;Afonso Ferreira	1995	Parallel Processing Letters	10.1142/S0129626495000357	shared memory;mathematical optimization;combinatorics;parallel computing;combinatorial optimization;computer science;mathematics;parallel algorithm;efficiency;decomposition;knapsack problem;branch and bound;algorithm;cost efficiency	Robotics	20.232147076551367	11.306560054219277	97357
ea571b505de8f7f37ea5e64764dd3830755c2c39	exact and heuristic algorithms for parallel-machine scheduling with dejong's learning effect	heuristic scheduling algorithms;learning effectiveness;learning curve;branch and bound algorithm;greedy heuristic;np hard problem;parallel machine scheduling;scheduling algorithm;branch and bound algorithms;exact algorithm;experimental evaluation;heuristic algorithm;learning effect	We consider a parallel-machine scheduling problem with a learning effect and the makespan objective. The impact of the learning effect on job processing times is modelled by the general DeJong's learning curve. For this NP-hard problem we propose two exact algorithms: a sequential branch-and-bound algorithm and a parallel branch-and-bound algorithm. We also present the results of experimental evaluation of these algorithms on a computational cluster. Finally, we use the exact algorithms to estimate the performance of two greedy heuristic scheduling algorithms for the problem.	algorithm;heuristic;parallel computing;scheduling (computing)	Dariusz Okolowski;Stanislaw Gawiejnowicz	2010	Computers & Industrial Engineering	10.1016/j.cie.2010.04.008	heuristic;fair-share scheduling;mathematical optimization;greedy algorithm;flow shop scheduling;weighted majority algorithm;dynamic priority scheduling;computer science;rate-monotonic scheduling;theoretical computer science;machine learning;np-hard;learning effect;learning curve;scheduling;branch and bound;generalization error	AI	16.24543489834354	9.975945153986167	97545
36ce1725915804e9ad810dd5a1688fc8208a70d4	set covering, packing and partitioning problems	set cover	where A is a mxn matrix of zeroes and ones, e = (1,...,1) is a vector of m ones and c is a vector of n (arbitrary) rational components. This pure 0-1 linear programming problem is called the set covering problem. When the inequalities are replaced by equations the problem is called the set partitioning problem, and when all of the ≥ constraints are replaced by ≤ constraints, the problem is called the set packing problem.	covering problems;linear programming;partition problem;set cover problem;set packing	Karla L. Hoffman;Manfred W. Padberg	2009		10.1007/978-0-387-74759-0_599	structural engineering;wall stud;computer science	Theory	24.155679543411267	13.116474882080764	97671
80632b11afb8b61a49c5169ec7505c4bc5ef63af	to fill or not to fill: the gas station problem	traveling salesman problem;graph theory;shortest path;shortest paths;approximate algorithm;generic model;approximation algorithms;vehicle routing;polynomial time	In this article we study several routing problems that generalize shortest paths and the traveling salesman problem. We consider a more general model that incorporates the actual cost in terms of gas prices. We have a vehicle with a given tank capacity. We assume that at each vertex gas may be purchased at a certain price. The objective is to find the cheapest route to go from s to t, or the cheapest tour visiting a given set of locations. We show that the problem of finding a cheapest plan to go from s to t can be solved in polynomial time. For most other versions, however, the problem is NP-complete and we develop polynomial-time approximation algorithms for these versions.	approximation algorithm;np-completeness;planar graph;polynomial;routing;shortest path problem;time complexity;travelling salesman problem	Samir Khuller;Azarakhsh Malekian;Julián Mestre	2011	ACM Trans. Algorithms	10.1145/1978782.1978791	time complexity;traveling purchaser problem;2-opt;mathematical optimization;combinatorics;computer science;graph theory;mathematics;shortest path problem;travelling salesman problem;approximation algorithm;k shortest path routing;algorithm	Theory	22.624438933029523	7.920550830740962	97823
741c5215698321c36ce6de93e4759ca1643e4fb7	the minimum cost flow problem: a unifying approach to dual algorithms and a new tree-search algorithm	generic algorithm;search algorithm;primal dual algorithm;network flow	This paper is concerned with the minimum cost flow problem. It is shown that the class of dual algorithms which solve this problem consists of different variants of a common general algorithm. We develop a new variant which is, in fact, a new form of the ‘primal-dual algorithm’ and which has several interesting properties. It uses, explicitly only dual variables. The slope of the change in the (dual) objective is monotone. The bound on the maximum number of iterations to solve a problem with integral bounds on the flow is better than bounds for other algorithms.	flow network;minimum-cost flow problem;search algorithm;tree traversal	Refael Hassin	1983	Math. Program.	10.1007/BF02591772	out-of-kilter algorithm;mathematical optimization;suurballe's algorithm;combinatorics;flow network;genetic algorithm;ramer–douglas–peucker algorithm;minimum-cost flow problem;push–relabel maximum flow algorithm;multi-commodity flow problem;constraint satisfaction dual problem;mathematics;dinic's algorithm;algorithmics;algorithm;search algorithm	Theory	23.87515728967757	12.414296292385561	97834
c7a39b541bceaa1dd55b7ec909c9ecd78bc11b80	a translational approach to constraint answer set solving	answer sets;decomposition;constraint processing;answer set programming;finite domain;constraint satisfaction problem;logic programs	We present a new approach to enhancing Answer Set Programming (ASP) with Constraint Processing techniques which allows for solving interesting Constraint Satisfaction Problems in ASP. We show how constraints on finite domains can be decomposed into logic programs such that unit-propagation achieves arc, bound or range consistency. Experiments with our encodings demonstrate their computational impact.	answer set programming;benchmark (computing);constraint satisfaction problem;curve fitting;interdependence;programmer;software propagation;stable model semantics;unit propagation	Christian Drescher;Toby Walsh	2010	TPLP	10.1017/S1471068410000220	constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;binary constraint;decomposition method;constraint satisfaction;constraint learning;computer science;constraint graph;artificial intelligence;answer set programming;constraint satisfaction dual problem;complexity of constraint satisfaction;constraint;decomposition;satisfiability modulo theories;constraint satisfaction problem;algorithm;hybrid algorithm;local consistency;backtracking	AI	11.854961147356681	15.87605417659303	97990
bb37d999d6a73dee4bee017218fb731e12b28dfd	minimization of makespan through jointly scheduling strategy in production system with mould maintenance consideration		Job shop scheduling problem with machine maintenance has attracted the attention of many scholars over the past decades. However, only a limited number of studies investigate the availability of injection mould which is important to guarantee the regular production of plastic industry. Furthermore, most researchers only consider the situation that the maintenance duration and interval are fixed. But in reality, maintenance duration and interval may vary based on the resource age. This paper solves the job shop scheduling with mould maintenance problem (JSS-MMP) aiming at minimizing the overall makespan through a jointly schedule strategy. Particle Swarm Optimization Algorithm (PSO) and Genetic Algorithm (GA) are used to solve this optimization problem. The simulation results show that under the condition that the convergence time of two algorithms are similar, PSO is more efficient than GA in terms of convergence rate and solution quality.	makespan;production system (computer science);scheduling (computing)	Xiaoyue Fu;Felix T. S. Chan;Ben Niu;Sai Ho Chung;Ying Bi	2017		10.1007/978-3-319-63309-1_51	rate of convergence;job shop scheduling;genetic algorithm;computer science;scheduling (computing);minification;mathematical optimization;particle swarm optimization;convergence (routing);optimization problem	AI	15.35058262762173	7.293306923193338	98052
6599896025e98dad53a3b3537f4dd590ba1bd213	automated analysis of real-time scheduling using graph games	game theory;real time scheduling;competitive analysis	In this paper, we introduce the powerful framework of graph games for the analysis of real-time scheduling with firm deadlines. We introduce a novel instance of a partial-observation game that is suitable for this purpose, and prove decidability of all the involved decision problems. We derive a graph game that allows the automated computation of the competitive ratio (along with an optimal witness algorithm for the competitive ratio) and establish an NP-completeness proof for the graph game problem. For a given on-line algorithm, we present polynomial time solution for computing (i) the worst-case utility; (ii) the worst-case utility ratio w.r.t. a clairvoyant off-line algorithm; and (iii) the competitive ratio. A major strength of the proposed approach lies in its flexibility w.r.t. incorporating additional constraints on the adversary and/or the algorithm, including limited maximum or average load, finiteness of periods of overload, etc., which are easily added by means of additional instances of standard objective functions for graph games.	adversary (cryptography);best, worst and average case;competitive analysis (online algorithm);computation;computational complexity theory;decision problem;exptime;heuristic (computer science);np-completeness;online algorithm;online and offline;polynomial;real-time clock;real-time computing;scheduling (computing);state space;systems theory;time complexity;undecidable problem	Krishnendu Chatterjee;Alexander Kößler;Ulrich Schmid	2013		10.1145/2461328.2461356	mathematical optimization;discrete mathematics;graph bandwidth;mathematics;distributed computing	AI	13.871857641497627	13.428961526095348	98310
cdb214c69d8aff5cc8c455864eb552501a3f0262	a population-based fast algorithm for a billion-dimensional resource allocation problem with integer variables		Among various complexities affecting the performance of an optimization algorithm, the search space dimension is a major factor. Another key complexity is the discreteness of the search space. When these two complexities are present in a single problem, optimization algorithms have been demonstrated to be inefficient, even in linear programming (LP) problems. In this paper, we consider a specific resource allocation problem constituting to an integer linear programming (ILP) problem which, although comes from a specific industry, is similar to other practical resource allocation and assignment problems. Based on a population based optimization approach, we present a computationally fast method to arrive at a near-optimal solution. Compared to two popular softwares (glpk,Makhorin, 2012 and CPLEX,Gay, 2015), which are not able to handle around 300 and 2000 integer variables while continuing to run for hours, respectively, our proposed method is able to find a near-optimal solution in less than second on the same computer. Moreover, the main highlight of this study is to propose a customized population based optimization algorithm that scales in almost a linear computational complexity in handling 50,000 to one billion (109) variables. We believe that this is the first time such a large-sized real-world constrained problem is ever handled using any optimization algorithm. We perform sensitivity studies of our method for different problem parameters and these studies clearly demonstrate the reasons for such a fast and scale-up application of the proposed method.	algorithm;assignment (computer science);assignment problem;cplex;combinatorial optimization;computational complexity theory;gnu linear programming kit;integer programming;knapsack problem;mathematical optimization;np-hardness;polynomial;scheduling (computing);subset sum problem	Kalyanmoy Deb;Christie Myburgh	2017	European Journal of Operational Research	10.1016/j.ejor.2017.02.015	mathematical optimization;computational complexity theory;combinatorial optimization;cutting stock problem;theoretical computer science;algorithm;population;linear programming;integer programming;resource allocation;computer science;optimization problem	AI	22.948581120785157	5.205618037438122	98349
84e96e8a5a6b8ee4a32442058764ba050e0f84b0	capturing structure with satisfiability	regularite;satisfactoriabilidad;regularidad;regularity;satisfiability;constraint satisfaction;boolean satisfiability;resolucion problema;combinatorial problem;satisfaction contrainte;probleme combinatoire;problema combinatorio;performance analysis;satisfaisabilite;satisfaccion restriccion;sat solver;article;problem solving;resolution probleme	We present Regular-SAT, an extension of Boolean Satisfiability based on a class of many-valued CNF formulas. Regular-SAT shares many properties with Boolean SAT, which allows us to generalize some of the best known SAT results and apply them to Regular-SAT. In addition, Regular-SAT has a number of advantages over Boolean SAT. Most importantly, it produces more compact encodings that capture problem structure more naturally. Furthermore, its simplicity allows us to develop Regular-SAT solvers that are competitive with SAT and CSP procedures. We present a detailed performance analysis of Regular-SAT on several benchmark domains. These results show a clear computational advantage of using a Regular-SAT approach over a pure Boolean SAT or CSP approach, at least on the domains under consideration. We therefore believe that an approach based on Regular-SAT provides a compelling intermediate approach between SAT and CSPs, bringing together some of the best features of each paradigm.	algorithm;algorithmic efficiency;bart selman;benchmark (computing);bibliothèque de l'école des chartes;boolean satisfiability problem;computation;conjunctive normal form;data structure;heuristic (computer science);internet backbone;overhead (computing);programming paradigm	Ramón Béjar;Alba Cabiscol;Cèsar Fernández;Felip Manyà;Carla P. Gomes	2001		10.1007/3-540-45578-7_10	mathematical optimization;combinatorics;discrete mathematics;#sat;computer science;maximum satisfiability problem;mathematics;boolean satisfiability problem;algorithm	AI	12.946615811584284	16.27680706221874	98485
40da36e855a520e84106942d397cc38e57fe3bf2	application of the out-of-kilter algorithm to the asymmetric traveling salesman problem	forecasting;hamiltonian cycle;optimisation;reliability;project management;information systems;algoritmo busqueda;optimizacion;asymmetry;maintenance;travelling salesman problem;cycle hamiltonien;algorithme recherche;soft or;information technology;heuristic method;search algorithm;packing;metodo heuristico;asymetrie;operations research;location;investment;journal;journal of the operational research society;traveling salesman;inventory;problema viajante comercio;purchasing;history of or;logistics;ciclo hamiltoniano;probleme commis voyageur;marketing;scheduling;production;asimetria;communications technology;optimization;heuristics;methode heuristique;computer science;operational research;networks and graphs;applications of operational research;or society;jors;management science;infrastructure;asymmetric traveling salesman problem	This paper presents a heuristic method that finds optimum or near-optimum solutions to the asymmetric traveling salesman problem. The method uses the out-of-kilter algorithm to search for a neighbourhood. When subtours are produced by a flow-augmenting path of the out-of-kilter algorithm, it patches them into a Hamiltonian cycle. It extends the neighbourhood space by exchanging an even number of arcs, and it also exchanges arcs by a non-sequential primary change. Instances from real applications were used to test the algorithm, along with randomly generated problems. The new heuristic algorithm produced optimum solutions for 16 out of 28 real-world instances from TSPLIB and other sources. Also, compared with four efficient heuristics, it produced the best solutions for all except six instances. It also produced relatively good solutions in reasonable times for 216 randomly generated instances from nine instance generators. Journal of the Operational Research Society (2003) 54, 1085–1092. doi:10.1057/palgrave.jors.2601614	flow network;hamiltonian path;heuristic (computer science);out-of-kilter algorithm;procedural generation;travelling salesman problem	Sang-Ho Kwon;G Young-Gun;Maing-Kyu Kang	2003	JORS	10.1057/palgrave.jors.2601614	project management;mathematical optimization;economics;computer science;marketing;operations management;mathematics;travelling salesman problem;operations research;information technology	EDA	18.28230351538676	5.639954661476105	98699
a301e84603414ed583a07d33866ebecba729c874	a column generation approach for large-scale aircrew rostering problems	modelizacion;europa;generation colonne;systeme grande taille;strategie controle;transportation airline application;probleme tableau service;large scale system;air transportation;horario;france;set partitioning;modelisation;integer;transport aerien;transporte aereo;large scale;airline application;personnel;scheduling;francia;transportation;partitionnement ensemble;personal de navegacion;personnel navigant;schedule;airline crew members;crew;europe;scheduling personnel;rostering;modeling;programming;column generation;horaire;sistema gran escala;large scale systems	This article describes a method for solving the crew rostering problem in air transportation. This problem consists of constructing personalized schedules that assign pairings, days off, and other activities to airline crew members. A generalized set partitioning model and a method using column generation have been used. This method has been adapted in a number of ways to take advantage of the nature of the problem and to accelerate solution. Numerical tests on problems from Air France have demonstrated that this method is capable of solving very large scale problems with thousands of constraints and hundreds of subproblems. The tests have also shown that these adaptations are capable of reducing solution time by a factor of about a thousand. Finally, results from this method are compared with those obtained with the method currently used at Air France.	arcs (computing);approximation;branch and bound;column (database);column generation;control theory;crew scheduling;harwell cadet;heuristic;horner's method;nurse scheduling problem;point of view (computer hardware company);upwind scheme	Michel Gamache;François Soumis;Gérald Marquis;Jacques Desrosiers	1999	Operations Research	10.1287/opre.47.2.247	column generation;integer;programming;transport;mathematical optimization;simulation;systems modeling;operations management;mathematics;management;operations research;scheduling;schedule;aviation	Robotics	17.861029493791012	6.469386058152701	98715
7f18e3f22c0c60bf677ec047d35f5e0ea67e31b2	more on the magnus-derek game	05xx;nombre entier;combinatorics;combinatoria;combinatoire;jeu 2 personnes;integer;juego 2 personas;informatique theorique;additive combinatorics;entero;two person game;58a25;68r05;game playing;article;computer theory;informatica teorica	We consider the so called Magnus–Derek game, which is a two-person game played on a round table with n positions. The two players are called Magnus and Derek. Initially there is a token placed at position 0. In each roundMagnus chooses a positive integerm ≤ n/2 as the distance of the targeted position from his current position for the token to move, and Derek decides a direction, clockwise or counterclockwise, to move the token. The goal of Magnus is to maximize the total number of positions visited, while Derek’s is to minimize this number. If both players play optimally, we prove that Magnus, the maximizer, can achieve his goal in O(n) rounds, which improves a previous result with O(n log n) rounds. Then we consider a modified version of the Magnus–Derek game, where one of the players reveals his moves in advance and the other player plays optimally. In this case we prove that it is NP-hard for Derek to achieve his goal if Magnus reveals his moves in advance. On the other hand, Magnus has an advantage to occupy all positions. We also consider the circumstance that both players play randomly, andwe show that the expected time to visit all positions is O(n log n). © 2010 Elsevier B.V. All rights reserved.	average-case complexity;np-hardness;randomness	Li-Jui Chen;Jinn-Jy Lin;Min-Zheng Shieh;Shi-Chun Tsai	2011	Theor. Comput. Sci.	10.1016/j.tcs.2010.09.031	integer;combinatorics;simulation;computer science;artificial intelligence;mathematics;algorithm	ECom	19.726224050681743	17.03978460499854	98764
b31555c74236e4993e8ab1dcd7dd5d0a11cc5606	approximating interval selection on unrelated machines with unit-length intervals and cores		We consider a scheduling problem with machine dependent intervals, where each job consists of m fixed intervals, one on each of the m machines. To schedule a job, exactly one of the m intervals needs to be selected, making the corresponding machine busy for the time period equal to the selected interval. The objective is to schedule a maximum number of jobs such that no two selected intervals from the same machine overlap. This problem is NP-hard and admits a deterministic 1 / 2-approximation. The problem remains NP-hard even if all intervals have unit length, and all m intervals of any job have a common intersection. We study this special case and show that it is APX-hard, and design a 501 / 1000-approximation algorithm.		Katerina Böhmová;Enrico Kravina;Matús Mihalák	2016		10.1007/978-3-319-45587-7_30	mathematical optimization;job shop scheduling;approximation algorithm;computational complexity theory;mathematics;special case	NLP	15.630496644683715	10.37134744448508	98839
542fe386b0b0b4c0b5492e992a37ae04e7f2c9eb	adaptive scheduling for high-volume shops	performance measure;metodo adaptativo;optimisation;convergence;temps polynomial;algorithm analysis;optimizacion;performance measure production control complexity convergence high volume shops conceptual algorithm np hard scheduling heuristic algorithm classical dispatch scheduling embedded optimization beam search periodic production pattern;implementation;production system;systeme production;probleme np dur;problema np duro;methode adaptative;sistema produccion;rolling horizon;algorithme;high volume;algorithm;ejecucion;np hard problem;production control;computational complexity;scheduling;adaptive method;polynomial time;scheduling problem;ordonamiento;optimization;analyse algorithme;search problems;adaptive scheduling job shop scheduling scheduling algorithm heuristic algorithms processor scheduling production performance analysis algorithm design and analysis time measurement polynomials;search problems computational complexity convergence optimisation production control scheduling;analisis algoritmo;ordonnancement;lower bound;heuristic algorithm;algoritmo;tiempo polinomial	A conceptual algorithm for NP-hard scheduling problems that gives accurate reactive scheduling for high-volume shops is presented. The heuristic algorithm provides classical dispatch scheduling with an embedded optimization procedure. It delivers successive updates of the initially generated schedule by extending in an unconventional way the horizon of applicability. An adaptive mechanism is implemented. The successive schedule updates are generated using beam search. The conceptual algorithm is applied to problems where a periodic production pattern is assumed. Analysis of the algorithm's behavior reveals that the performance measure converges to the calculated lower bounds and that the computational time can be polynomial, for each problem, in the number of parts to process. >	scheduling (computing)	Carlos F. G. Bispo;João Sentieiro;Roger D. Hibberd	1992	IEEE Trans. Robotics and Automation	10.1109/70.182670	heuristic;fair-share scheduling;time complexity;job shop scheduling;mathematical optimization;real-time computing;convergence;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;np-hard;mathematics;production system;upper and lower bounds;computational complexity theory;implementation;scheduling;algorithm	Robotics	16.972421324104463	9.488059841276614	99049
8fe2b2e0de8d0d178321d319ee2171330ec4acba	improved competitive analysis of online scheduling deadline-sensitive jobs		We consider the following scheduling problem. There is a single machine and the jobs will arrive for completion online. Each job j is preemptive and, upon its arrival at time aj , its other characteristics are immediately revealed to the machine: the deadline dj , the workload Dj and the value vj . The objective is to maximize the aggregate value of jobs completed by their deadlines. Using the minimum of dj−aj Dj over all jobs as the slackness s, a non-committed and a committed online scheduling algorithm A and AC is proposed in [Lucier et al., SPAA’13; Azar et al., EC’15], achieving competitive ratios of crA(s) = 2 + O( 1 ( 3 √ s−1)2 ) and crAC (s) = crA(s·ω(1−ω)) ω(1−ω) respectively, where ω ∈ (0, 1) and s ≥ 1 ω(1−ω) . In this paper, without recourse to the dual fitting technique used in the above works, we propose a simpler and more intuitive analytical framework for A and AC , improving crA(s) to 1 +O( 1 ( 3 √ s−1)2 ) and therefore improving crAC (s) by 1 ω(1−ω) . As stated in [Lucier et al., SPAA’13; Azar et al. EC’15], it is justifiable in scenarios like the online batch processing for cloud computing that s is large, hence the item O( 1 ( 3 √ s−1)2 ) in crA(s) can be ignored. Under the above assumption, our analysis brings very significant improvements: from 2 to 1 and from 2 ω(1−ω) to 1 ω(1−ω) for crA(s) and crAC (s) respectively.	aggregate data;algorithm;batch processing;cloud computing;competitive analysis (online algorithm);job stream;preemption (computing);scheduling (computing);word lists by frequency	Patrick Loiseau;Xiaohu Wu	2015	CoRR		mathematical optimization;real-time computing;simulation;computer science;algorithm	AI	14.271416465671008	11.278571316966902	99103
25c9800089442923cac27a5a6422d8addcf7082d	a branch and price solution approach for order acceptance and capacity planning in make-to-order operations	prix vente;arbre graphe;modelizacion;lagrangien;make to order;mixed integer linear program;optimal solution;generation colonne;optimisation;capacite production;order acceptance branch and price capacity planning make to order operations large scale optimization;resource constraint;model combination;approximate algorithm;programacion entera;ordered set;capacity planning;optimizacion;execution time;tree graph;mass customization;generacion columna;gestion production;produccion flujo tirado;preparacion pedido;resource allocation;branching;decomposition techniques;date echeance;ensemble ordonne;long terme;operations research;production a la commande;programmation en nombres entiers;production management;long term;processing time;modelisation;atelier multigamme;profit;large scale;decision support system;flujo red;branch and bound method;single machine;programacion lineal;largo plazo;programacion mixta entera;integer programming;beneficio;constrenimiento recurso;metodo branch and bound;ramificacion;block diagonalization;gestion produccion;due date;linear programming;benefice;programmation lineaire;programmation partiellement en nombres entiers;ramification;mixed integer programming;temps traitement;fecha vencimiento;temps execution;job shop;lagrangiano;supply chain;optimization;profitability;capacidad produccion;asignacion recurso;preparation commande;computer analysis;information system;methode separation et evaluation;operations management;network flow;escala grande;allocation ressource;tiempo ejecucion;arbol grafo;order acceptance;order picking;branch and bound;modeling;selling price;make to order operations;lagrangian;tiempo proceso;contrainte ressource;flot reseau;production capacity;column generation;large scale optimization;precio venta;conjunto ordenado;branch and price;echelle grande	"""Make-to-order (MTO) operations have to effectively manage their capacity to make long-term sustainable profits. This objective can be met by selectively accepting available customer orders and simultaneously planning for capacity. We model a MTO operation of a job-shop with multiple resources having regular and non-regular capacity. The MTO firm has a set of customer orders at time zero with fixed due-dates. The process route, processing times, and sales price for each order are all given. Since orders compete for limited resources, the firm can only accept some orders. In this paper we formulate a Mixed-Integer Linear Program (MILP) to aid an operational manager to decide which orders to accept and how to allocate resources such that the overall profit is maximized. A branch-and-price algorithm is devised to solve the MILP effectively. The MILP is first decomposed into a master problem and several sub-problems using Dantzig-Wolfe decomposition. Each sub-problem is represented as a network flow problem and an exact procedure is proposed to solve the sub-problems efficiently. We also propose an approximate branch-and-price scheme, Lagrangian bounds, and approximations to fathom nodes in the branch-and-bound tree. Computational analysis shows that the proposed branchand-price algorithm can solve large problem instances with relatively short time. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 (815) 753‐6748 pdamodaran@niu.edu November 2, 2009 Dear Editor, We are submitting our manuscript entitled """"A Branch and Price Solution Approach for Order Acceptance and Capacity Planning in Make‐to‐Order Operations"""" for review and publication in European Journal of Operational Research. The problem under study can be observed at several manufacturing facilities. The co‐authors have personally interacted with several make‐to‐order firms.  The model and the solution proposed in this paper can benefit industry and stimulate academic research to consider several extensions of this problem. We hope you will find this paper and its contribution worthy to publish in your journal. If you need additional information with regards to the manuscript, please write to me.  I look forward to hearing your comments and the reviewers’ comments/suggestions on our manuscript. Sincerely, Purushothaman Damodaran Department of Industrial and Systems Engineering Northern Illinois University De Kalb, IL 60115 Cover Letter Click here to view linked References"""	approximation algorithm;branch and bound;branch and price;computation;dantzig–wolfe decomposition;fathom;flow network;linear programming;operations research;systems engineering	Siddharth Mestry;Purushothaman Damodaran;Chin-Sheng Chen	2011	European Journal of Operational Research	10.1016/j.ejor.2011.01.002	column generation;mathematical optimization;build to order;flow network;profit;systems modeling;integer programming;economics;branching;resource allocation;mass customization;branch and price;operations management;lagrangian;mathematics;supply chain;ramification;productive capacity;operations research;branch and bound;tree;information system;algorithm;profitability index	AI	17.517772640735387	6.8257795397380105	99214
111a92b71a4adb8ace1cb1ac4b2f2ab5f5811c99	solution methods for the p-median problem: an annotated bibliography	facility location	The p-median problem is a graph theory problem that was originally designed for, and has been extensively applied to, facility location. In this bibliography, we summarize the literature on solution methods for the uncapacitated and capacitated p-median problem on a graph or network.	graph theory	J. Reese	2006	Networks	10.1002/net.20128	mathematical optimization;computer science;artificial intelligence;facility location problem;mathematics;bibliography;operations research	Theory	23.02979122648021	9.558929265821414	99268
ba86f165bad96d8f9a842ad40e2c9243e293883a	optimizing strategic safety stock placement in supply chains with clusters of commonality	safety stock;dynamic programming;optimisation;programacion dinamica;logistique;optimizacion;cost function;stock securite;arbre maximal;dynamic program;funcion coste;administracion deposito;network topology;networks with clusters of commonality;logistics;arbol maximo;component commonality;computational complexity;programmation dynamique;multiechelon inventory system;gestion stock;hewlett packard;fonction cout;supply chain;optimization;spanning tree;safety stock optimization;stock seguridad;inventory control;large classes;system safety;logistica;dynamic programming application	Multiechelon inventory optimization is increasingly being applied by business users as new tools expand the class of network topologies that can be optimized. In this paper, we formalize a topology that we call networks with clusters of commonality (CoC), which captures a large class of real-world supply chains that contain component commonality. Viewed as a modified network, a CoC network is a spanning tree where the nodes in the modified network are themselves maximal bipartite subgraphs in the original network. We first present algorithms to identify these networks and then present a singlestate-variable dynamic program for optimizing safety stock levels and locations. We next present two reformulations of the dynamic program that significantly reduce computational complexity while preserving the optimality of the resulting solution. This work both incorporates arbitrary safety stock cost functions and makes possible optimizing a large class of practically useful but previously intractable networks. It has been successfully applied at several Fortune 500 companies, including the recent Edelman finalist project at Hewlett Packard described in detail in Billington et al. (2004).	algorithm;computational complexity theory;file spanning;mathematical optimization;maximal set;network topology;optimizing compiler;safety stock;spanning tree	Salal Humair;Sean P. Willems	2006	Operations Research	10.1287/opre.1060.0313	inventory control;logistics;mathematical optimization;simulation;spanning tree;computer science;marketing;operations management;dynamic programming;mathematics;supply chain;computational complexity theory;management;operations research;system safety;network topology;algorithm	ML	22.018964900212108	12.379447312729573	99584
9aaa7843a862831e673999785eaa0214ffdc8a55	minimizing task completion time with the execution set method	duracion;networks graphs applications;completion time;relation ordre partiel;ordered set;execution time;tarea completamente;temps achevement;ensemble ordonne;robotics;reseau;linear programming optimization;duration;red;completion task;assembly;partially ordered set;programacion lineal;partial ordering;linear programming;robotica;programmation lineaire;linear program;temps execution;montage;robotique;relacion orden parcial;tâche completement;montaje;tiempo ejecucion;tiempo acabado;robot;network;duree;conjunto ordenado	We consider a partial ordered set (POSET) of assembling operations, with known execution durations, that must be accomplished. The assembling operations can be executed on an acyclic network with an identical set of robots on each conveyer (arc). The number of depots (nodes) is a known integer. Between each pair of depots we can locate only one conveyer. We seek an arrangement of the network and a plan that divides the task operations among the conveyers, minimizing the overall task completion time. We use linear programming optimization, subject to reasonably general rules for distributing the operation-fragments among the conveyers.		Zohar Laslo;Baruch Keren;Hagai Ilani	2008	European Journal of Operational Research	10.1016/j.ejor.2006.09.030	partially ordered set;mathematical optimization;real-time computing;computer science;linear programming;artificial intelligence;mathematics;algorithm	Robotics	18.189918144349345	8.556881884424003	99644
35ee4d724d4bcb3e475cbbe14edd9d641fc53941	an approximation algorithm for the bipartite traveling tournament problem	approximation algorithms;traveling salesman;scheduling;traveling tournament problem	The bipartite traveling tournament problem BTTP is an NP-complete scheduling problem whose solution is a double round-robin inter-league tournament with minimum total travel distance. The 2n-team BTTP is a variant of the well-known traveling salesman problem TSP, albeit much harder as it involves the simultaneous coordination of 2n teams playing a sequence of home and away games under fixed constraints, rather than a single entity passing through the locations corresponding to the teams' home venues. As the BTTP requires a distance-optimal schedule linking venues in close proximity, we provide an approximation algorithm for the BTTP based on an approximate solution to the corresponding TSP.#R##N##R##N#We prove that our polynomial-time algorithm generates a 2n-team inter-league tournament schedule whose total distance is at most 1 + 2c/3 + 3-c/3n times the total distance of the optimal BTTP solution, where c is the approximation factor of the TSP. In practice, the actual approximation factor is far better; we provide a specific example by generating a nearly-optimal inter-league tournament for the 30-team National Basketball Association, with total travel distance just 1.06 times the trivial theoretical lower bound.	approximation algorithm;hamiltonian (quantum mechanics);polynomial;time complexity;traveling tournament problem;trusted third party	Richard Hoshino;Ken-ichi Kawarabayashi	2013	Math. Oper. Res.	10.1287/moor.2013.0597	mathematical optimization;combinatorics;simulation;mathematics;travelling salesman problem;scheduling;approximation algorithm	Theory	19.938665863306344	16.66745182708282	99885
a16345272908f9c28d87b800f60312167478dca9	algorithms for mixed-model sequencing with due date restrictions	sequencing;multiple objectives;mixed model;problem complexity;heuristics;combinatorial optimization;local search	In a Mixed-Model Sequencing (MMS) environment, customer demands with respect to timeliness of delivery conflict with the production-centered goal of smooth component utilization. This research is designed to be an initial step in the process of dealing with both balance and lateness objectives. The results show that a slight decrease in on-time production leads to substantial gains in smoothing component utilization. The fundamental task in addressing the multiple-objective environment is to distinguish those problem models in a sequence, whose due dates cause the schedule to be unbalanced with respect to part usage.#R##N##R##N#This paper also presents some insights into the behavior of the multi-objective MMS problem. Inherent characteristics of the MMS are revealed and explained, primarily with respect to demand patterns and lateness restrictions.#R##N##R##N#Because of the problem complexity it is necessary to employ a heuristic to produce quality solutions for large problems. This study evaluates a set of heuristics, focusing on the tradeoffs between lateness measures, smooth component utilization, and computation time. This research involves the first application of local search heuristics to this problem. One heuristic, the Border Swap, proves to be an extremely effective mechanism for recognizing problem models, and solving the multi-objective problem.	algorithm;mixed model	Robin Lovgren;Michael Racer	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00091-0	mixed model;mathematical optimization;simulation;combinatorial optimization;local search;operations management;heuristics;sequencing;mathematics	Robotics	14.953543391877819	4.359677473149986	99886
0205bceae42d0b6f6a3ae3b5d513eb2123bc9e7d	two meta-heuristic algorithms for flexible flow shop scheduling problem with robotic transportation and release time	ant colony optimization;robotic transportation;flexible flow shop;eligible machine;genetic algorithm;unrelated parallel machine	In this research, flexible flow shop scheduling with unrelated parallel machines at each stage are considered. The number of stages and machines vary at each stage and each machine can process specific operations. In other words, machines have eligibility and parts have different release times. In addition, the blocking restriction is considered for the problem. Parts should pass each stage and process on only one machine at each stage. In the proposed problem, transportation of parts, loading and unloading parts are done by robots and the objective function is finding an optimal sequence of processing parts and robots movements to minimize the makespan and finding the closest number to the optimal number of robots. The main contribution of this study is to present the mixed integer linear programming model for the problem which considers release times for parts in scheduling area, loading and unloading times of parts which transferred by robots. New methodologies are investigated for solving the proposed model. Ant Colony Optimization (ACO) with double pheromone and genetic algorithm (GA) are proposed. Finally, two meta-heuristic algorithms are compared to each other, computational results show that the GA performs better than ACO and the near optimal numbers of robots are determined. © 2015 Elsevier B.V. All rights reserved.	ant colony optimization algorithms;blocking (computing);computation;flow shop scheduling;genetic algorithm;heuristic;integer programming;linear programming;loss function;makespan;optimization problem;programming model;robot;scheduling (computing);software release life cycle	Seyedeh Sarah Zabihzadeh;Javad Rezaeian	2016	Appl. Soft Comput.	10.1016/j.asoc.2015.11.008	mathematical optimization;ant colony optimization algorithms;genetic algorithm;flow shop scheduling;computer science;machine learning	AI	14.401567985713614	5.148318710498451	99930
998f6356bcc7c45d71a6bdf145e2014966e8d9c0	batching identical jobs	workload;constante tiempo;dynamic programming;complex dynamics;programacion dinamica;time constant;temps polynomial;batch production;procede discontinu;dynamic program;complexity;fonction objectif;key words scheduling theory;processing time;objective function;setup time;produccion por lote;scheduling;scheduling theory;production par lot;retard;programmation dynamique;batch process;polynomial time;charge travail;temps traitement;funcion objetivo;procedimiento discontinuo;ordonamiento;carga trabajo;retraso;tiempo proceso;large classes;ordonnancement;constante temps;tiempo polinomial	We study the problems of scheduling jobs, with different release dates and equal processing times, on two types of batching machines. All jobs of the same batch start and are completed simultaneously. On a serial batching machine, the length of a batch equals the sum of the processing times of its jobs and, when a new batch starts, a constant setup time s occurs. On a parallel batching machine, there are at most b jobs per batch and the length of a batch is the largest processing time of its jobs. We show that in both environments, for a large class of so called “ordered” objective functions, the problems are polynomially solvable by dynamic programming. This allows us to derive that the problems where the objective is to minimize the weighted number of late jobs, or the weighted flow time, or the total tardiness, or the maximal tardiness are polynomial. In other words, we show that 1|p-batch, b < n, ri, pi = p|F and 1|s-batch, ri, pi = p|F , are polynomial for F ∈ { ∑	algorithm;batch processing;decision problem;dichotomic search;dynamic programming;flip-flop (electronics);job stream;loss function;maximal set;np-hardness;optimization problem;polynomial;scheduling (computing);time complexity	Philippe Baptiste	2000	Math. Meth. of OR	10.1007/s001860000088	time complexity;mathematical optimization;complexity;real-time computing;complex dynamics;dynamic programming;mathematics;time constant;scheduling;algorithm;batch processing	Theory	16.709866363266823	10.40557346255162	100078
b9635274e3b63634ca132f501c5494d59339999d	double resource optimization for a robust computer network subject to a transmission budget	critical analysis;double resource assignment;robustness;transmission budget;network reliability;structural analysis	To maintain a reliable computer network is now a challenge in our daily business operations especially when the transmission budget is limited. A computer network usually consists of transmission lines and transmission facilities, both of which may suffer failure, partial failure, or be in maintenance. Such a computer network is called a stochastic-flow network, since both kinds of resources are stochastic in nature. The problem of double resource optimization for a robust computer network subject to a transmission budget (DROCNTB) is to search for the exact minimum double-resource assignments under transmission-budget constraint such that the computer network keeps survived even under both kinds of failures. This paper develops an efficient algorithm to search for the exact optimal assignment for the DROCNTB problem. Several benchmark examples are explored and compared. The results show that the proposed algorithm is very efficient.	arcs (computing);algorithm;benchmark (computing);evolutionary algorithm;experiment;flow network;mathematical optimization;maxima and minima;optimization problem;stochastic process;transmission line	Yi-Kuei Lin;Shin-Guang Chen	2016	Annals OR	10.1007/s10479-014-1742-z	mathematical optimization;simulation;computer science;operations management;network simulation;structural analysis;reliability;operations research;robustness	Metrics	11.959781262033365	8.516132167588651	100083
52045fcce2c62f86eed1d71ec8deffb9b66f562e	approximating call-scheduling makespan in all-optical networks	optical network;settore inf 01 informatica;approximate algorithm;all optical network;scheduling algorithm	We study the problem of routing and scheduling requests of limited durations in all-optical net- #R##N#works with restrictions on the number of available wavelengths on each link. The task is servicing the #R##N#requests, assigning each of them a route from source to destination, a starting time and a wavelength #R##N#with the goal of minimizing the overall time needed to serve all requests. We study the relationship #R##N#between this problem and minimum path coloring and we show how to exploit known results on #R##N#path coloring to derive approximation scheduling algorithms for meshes, trees and nearly-Eulerian, #R##N#uniformly high-diameter graphs. We also propose different approximation algorithms for stars, trees #R##N#and in trees of rings.	makespan;scheduling (computing)	Luca Becchetti;Miriam Di Ianni;Alberto Marchetti-Spaccamela	2004	J. Discrete Algorithms	10.1016/j.jda.2004.04.008	mathematical optimization;computer science;theoretical computer science;distributed computing;scheduling	Theory	22.5470159687848	18.239111737318968	100184
a8a74c2c16f3fdc04c6319e3847fd445d079bdae	the inverse {0, 1}{0, 1}-knapsack problem: theory, algorithms and computational experiments	inverse optimization;knapsack problem	The inverse   {0,1}      {  0  ,  1  }        -knapsack problem consists of finding a minimal adjustment of the profit vector such that a given feasible set of items becomes an optimal solution. In this paper, two models are considered. In the first, the adjustment is measured by the Chebyshev norm. A pseudo-polynomial time algorithm is proposed to solve it. In the second, the adjustment is based on the Manhattan norm. This model is reduced to solve a linear integer program. While the first problem is proved to be  co-NP -Complete, the second is  co-NP -Hard and strong arguments are against its  co-NP -Completeness. For both models, a bilevel linear integer programming formulation is also presented. Numerical results from computational experiments to assessing the feasibility of these approaches are reported.	algorithm;computation;experiment	Julien Roland;José Rui Figueira;Yves De Smet	2013	Discrete Optimization	10.1016/j.disopt.2013.03.001	continuous knapsack problem;mathematical optimization;combinatorics;discrete mathematics;cutting stock problem;change-making problem;mathematics;knapsack problem;subset sum problem	Theory	23.25644715545993	11.26482178742168	100212
e617ab839ce30e1c74be53a89e5a5baa85b7d5b2	a load balancing method for dedicated photolithography machine constraint		The dedicated photolithography machine constraint in semiconductor manufacturing is one of the new issues of photolithography machinery due to natural bias. In this paper, we propose the heuristic Load Balancing (LB) scheduling approach based on a Resource Schedule and Execution Matrix (RSEM) to tackle this constraint. The LB method is to schedule each wafer lot at the first photolithography stage to a suitable machine, according to the load balancing factors among machines. We describe the proposed LB scheduling method and present an example to demonstrate the proposed method and the result of the simulations to validate the approach.	heuristic;lattice boltzmann methods;load balancing (computing);schedule;scheduling (computing);semiconductor device fabrication;simulation	Arthur M. D. Shr;Alan Liu;Peter P. Chen	2006		10.1007/978-0-387-36594-7_36	real-time computing;computer science;distributed computing;engineering drawing	AI	12.780742810997403	5.271086241438845	100310
8fa400601e96fc46fcea8b1e03505fc52625dc93	single machine scheduling with time-dependent linear deterioration and rate-modifying maintenance	qa mathematics;journal of the operational research society	We study single machine scheduling problems with linear time-dependent deterioration effects and maintenance activities. Maintenance periods (MPs) are included into the schedule, so that the machine, that gets worse during the processing, can be restored to a better state. We deal with a job-independent version of the deterioration effects, i.e., all jobs share a common deterioration rate. However, we introduce a novel extension to such models and allow the deterioration rates to change after every MP. We study several versions of this generalized problem and design a range of polynomial-time solution algorithms that enable the decision-maker to determine possible sequences of jobs and MPs in the schedule, so that the makespan objective can be minimized. We show that all problems reduce to a linear assignment problem with a product matrix and can be solved by methods very similar to those used for solving problems with positional effects.	algorithm;assignment problem;job stream;makespan;parallel port;polynomial;relevance;scheduling (computing);single-machine scheduling;software maintenance;time complexity	Kabir Rustogi;Vitaly A. Strusevich	2015	JORS	10.1057/jors.2014.18	economics;computer science;operations management;operations research	AI	15.375003317342758	8.648426277509516	100617
f40823984cefcac582380af0c658ea6a661b28b9	time complexity of single- and identical parallel-machine scheduling with gert network precedence constraints	reseau gert;stochastic process;single machine scheduling;time complexity;machine unique;gert networks;machine parallele identique;processing time;constrenimiento precedencia;parallel machine scheduling;complexite temps;single machine;maquina unica;identical parallel machines;scheduling;processus stochastique;precedence constraint;contrainte precedence;scheduling problem;temps traitement;parallel machines;ordonamiento;machine scheduling;key words stochastic scheduling;stochastic scheduling;proceso estocastico;complejidad tiempo;tiempo proceso;ordonnancement	In this paper we deal with the time complexity of single- and identical parallel-machine scheduling problems in which the durations and precedence constraints of the activities are stochastic. The stochastic precedence constraints are given by GERT networks. First, we sketch the basic concepts of GERT networks and machine scheduling with GERT network precedence constraints. Second, we discuss the time complexity of some open single-machine scheduling problems with GERT network precedence constraints. Third, we investigate the time complexity of identical parallel-machine scheduling problems with GERT network precedence constraints. Finally, we present an efficient reduction algorithm for the problem of computing the expected makespan for the latter type of scheduling problem.	parallel computing;scheduling (computing);time complexity	Jürgen Zimmermann	1999	Math. Meth. of OR	10.1007/PL00020914	time complexity;stochastic process;mathematical optimization;real-time computing;computer science;mathematics;distributed computing;scheduling;precedence diagram method;statistics	Theory	16.91609202061482	10.9087772684664	101011
db5577c845e023bee8f72d678599efd0c6a9ed13	a simulated annealing algorithm with the random compound move for the sequential partitioning problem of directed acyclic graphs	directed acyclic graph;neighbourhood structure;grafo aciclico;structure voisinage;compound move;simulated annealing algorithm;graphe acyclique;simulated annealing;satisfiability;acyclic graph;set partitioning;algorithme;algorithm;recuit simule;graph partitioning;directed graph;graphe oriente;partitionnement ensemble;recocido simulado;tabu search;grafo orientado;busqueda tabu;recherche tabou;algoritmo	In this paper, we present an approach for finding a minimum cost partition of the nodes of a directed acyclic graph into subsets of a given size, subject to the constraint that the precedence relationships among the elements are satisfied, based on the concept of simulated annealing. Simulated annealing is generally applicable, and can be used to obtain solutions arbitrarily close to an optimum. However, the standard simulated annealing approach with a conventional neighbourhood structure does not yield good solutions for this problem, since this is a multiple partitioning problem and the number of subsets is not fixed. For this problem, we develop an effective neighbourhood structure and a new acceptance criterion. We also assess the effectiveness of the developed algorithm. The results show that this proposed algorithm outperforms, in terms of solution quality, any other algorithm using tabu search. The computational time of the procedure is proportional to the number of nodes in the graph.	algorithm;directed acyclic graph;partition problem;simulated annealing	Taichi Kaji;Azuma Ohuchi	1999	European Journal of Operational Research	10.1016/S0377-2217(97)00381-0	mathematical optimization;combinatorics;discrete mathematics;simulated annealing;computer science;mathematics;directed acyclic graph;adaptive simulated annealing	Theory	20.42751953586264	15.991087586807879	101022
af5ae6ab320ff3695cf957b796d847de67934af0	decomposition algorithms for synchronous flow shop problems with additional resources and setup times	resources;setup times;scheduling;synchronous movement;flow shop	In this paper, we present decomposition algorithms for synchronous flow shop problems with additional resources and setup times. In such an environment, jobs are moved from one machine to the next by an unpaced synchronous transportation system, which implies that the processing is organized in synchronized cycles. In each cycle the current jobs start at the same time on the corresponding machines and after processing have to wait until the last job is finished. Afterwards, all jobs are moved to the next machine simultaneously. During processing, each job needs one additional resource and setup times have to be taken into account when changing from one resource to another. The goal is to find a production sequence of the jobs as well as a feasible assignment of resources to the jobs such that the total production time (makespan) is minimized. We propose two decomposition strategies dealing with the two subproblems of job sequencing and resource assignment hierarchically. Both approaches are computationally evaluated and compared. As a by-product, we also present efficient heuristics for the makespan minimization problem in synchronous flow shops without setup times.	algorithm	Stefan Waldherr;Sigrid Knust	2017	European Journal of Operational Research	10.1016/j.ejor.2016.11.015	job shop scheduling;real-time computing;flow shop scheduling;computer science;operations management;distributed computing;scheduling;resource	Networks	14.072096776943319	5.385239816496839	101345
0095d9e332d7c35370d43916ac1ee5f85c6ce188	a branch-and-bound algorithm for single machine scheduling with quadratic earliness and tardiness penalties	single machine;scheduling;branch and bound;quadratic earliness and tardiness	This paper considers the problem of scheduling a single machine, in which the objective function is to minimize the weighted quadratic earliness and tardiness penalties and no machine idle time is allowed. We develop a branch and bound algorithm involving the implementation of lower and upper bounding procedures as well as some dominance rules. The lower bound is designed based on a lagrangian relaxation method and the upper bound includes two phases, one for constructing initial schedules and the other for improving them. Computational experiments on a set of randomly generated instances show that one of the proposed heuristics, used as an upper bound, has an average gap less than 1.3% for instances optimally solved. The results indicate that both the lower and upper bounds are very tight and the branch-and-bound algorithm is the first algorithm that is able to optimally solve problems with up to 30 jobs in a reasonable amount of time.	algorithm;branch and bound;computation;computational complexity theory;experiment;heuristic (computer science);job stream;lagrangian relaxation;linear programming relaxation;loss function;optimization problem;procedural generation;relaxation (approximation);scheduling (computing);single-machine scheduling	Kamran Kianfar;Ghasem Moslehi	2012	Computers & OR	10.1016/j.cor.2012.03.004	mathematical optimization;computer science;mathematics;scheduling;branch and bound;algorithm	AI	16.52530891990587	8.771387357736511	101447
26d7312f2beaca8cb5fb932374a60be7b758d285	multi-criteria shortest path for rough graph		Shortest path problem in real life applications has to deal with multiple criteria. This article intends to solve a proposed multi-criteria shortest path problem of a weighted connected directed network whose associated edge weights are represented as rough variables in order to tackle the imprecision. We have exhibited two different approaches to determine the optimum path(s) of the proposed problem. The first approach is the proposed modified rough Dijkstra’s labelling algorithm. The second approach considers the rough chance constrained programming technique to formulate the proposed multi-criteria shortest path problem which is eventually solved by two different methods: the goal attainment method and the nondominated sorting genetic algorithm II. These methodologies are numerically illustrated for a multi-criteria weighted connected directed network. Moreover, the simulated results on similar networks of large order and size are analyzed to show the efficiency of the algorithms.	shortest path problem	Saibal Majumder;Samarjit Kar	2018	J. Ambient Intelligence and Humanized Computing	10.1007/s12652-017-0601-6	computer science;machine learning;euclidean shortest path;canadian traveller problem;artificial intelligence;yen's algorithm;widest path problem;k shortest path routing;shortest path faster algorithm;mathematical optimization;shortest path problem;constrained shortest path first	AI	24.22578916803575	7.773230416219887	101528
9274919722bc3b476176a867585db9b2c0894e17	an optimization algorithm for the clearing of interbank payments	sistema compensacion;programacion discreta;banking;discrete optimization;approximation algorithm;heuristic method;metodo heuristico;secteur bancaire;complexity;paiement interbanque;systeme compensation;optimisation combinatoire;resolucion problema;programmation discrete;computer experiment;clearing system;algoritmo aproximacion;heuristics;methode heuristique;complexite probleme;algorithme approximation;combinatorial optimization;optimal algorithm;or in banking;problem solving;resolution probleme;discrete programming;optimizacion combinatoria	We consider the clearing of interbank payments under limited amount of money used by banks for the maintenance of the clearing process. We show that the corresponding discrete optimization problem is non-approximable and propose a fast heuristic for solving the problem. The results of computational experiments demonstrate the high quality of solutions.	algorithm;mathematical optimization	Yakov M. Shafransky;Alexander A. Doudkin	2006	European Journal of Operational Research	10.1016/j.ejor.2004.09.003	discrete optimization;mathematical optimization;complexity;computer experiment;combinatorial optimization;computer science;operations management;heuristics;mathematics;mathematical economics;approximation algorithm	ECom	18.700177915520783	6.464258163637702	101550
4a9de0c139de9b710532143506dbc49b798522c9	towards the integration of power-indexed formulations in multi-architecture connected facility location problems for the optimal design of hybrid fiber-wireless access networks	telecommunications access networks connected facility location mixed integer linear programming power indexed formulations mip heuristics;004	Urban access networks are the external part of worldwide networks that make telecommunication services accessible to end users and represent a critical part of the infrastructures of modern cities. An important recent trend in urban access networks is the integration of fiber and wireless networks, leading to so-called fiber-wireless (Fi-Wi) networks. Fi-Wi networks get the best of both technologies, namely the high capacity offered by optical fiber networks and the mobility and ubiquity offered by wireless networks. The optimal design of fiber and wireless networks has been separately extensively studied. However, there is still a lack of mathematical models and algorithms for the integrated design problem. In this work, we propose a new Power-Indexed optimization model for the 3-architecture Connected Facility Location Problem arising in the design of urban telecommunication access networks. The new model includes additional power-indexed variables and constraints to represent the signal-to-interference formulas expressing wireless signal coverage. To solve the problem, which can prove very hard even for a state-of-the art optimization solver, we propose a new heuristic that combines a probabilistic variable fixing procedure, guided by (tight) linear relaxations, with an MIP heuristic, corresponding to an exact very large neighborhood search. Computational experiments on realistic instances show that our heuristic can find solutions of much higher quality than a state-of-the-art solver. 1998 ACM Subject Classification G.1.6 Optimization ∗ The work of Fabio D’Andreagiovanni and Jonad Pulaj was partially supported by the Einstein Center for Mathematics Berlin (ECMath) through Project MI4 (ROUAN) and by the German Federal Ministry of Education and Research (BMBF) through Project VINO (Grant 05M13ZAC) and Project ROBUKOM (Grant 05M10ZAA). © Fabio D’Andreagiovanni, Fabian Mett, and Jonad Pulaj; licensed under Creative Commons License CC-BY 5th Student Conference on Operational Research (SCOR’16). Editors: Bradley Hardy, Abroon Qazi, and Stefan Ravizza; Article No. 8; pp. 8:1–8:11 Open Access Series in Informatics Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany 8:2 Power-Indexed Formulations for Hybrid Fiber-Wireless Access Networks	access network;algorithm;computation;experiment;facility location problem;heuristic;informatics;interference (communication);mathematical model;mathematical optimization;operations research;optical fiber;optimal design;signal-to-noise ratio;solver	Fabio D'Andreagiovanni;Fabian Mett;Jonad Pulaj	2016		10.4230/OASIcs.SCOR.2016.8	mathematical optimization;computer science;operations management;distributed computing	ECom	22.820817327581704	10.186763371149778	101629
ca96c8038585d276ffa6baedea6dd7efc39d81f6	scheduling for stability in single-machine production systems	manufacturing systems;single machine scheduling;project;uncertain processing times;uncertainty;efficiency;branch and bound algorithm;production system;single machine;uncertainty robustness;robustness;branch and bound;breakdowns;shop;job	Robust scheduling aims at the construction of a schedule that is protected against uncertain events. A stable schedule is a robust schedule that changes only little when variations in the input parameters arise. This paper presents a model for single-machine scheduling with stability objective and a common deadline. We propose a branch-andbound algorithm for solving an approximate formulation of the model. The algorithm is exact when exactly one job is disrupted during schedule execution.	approximation algorithm;baseline (configuration management);branch and bound;central processing unit;combinatorial optimization;computation;convex function;decision problem;denial-of-service attack;interaction;job shop scheduling;job stream;lindo;mathematical optimization;programming model;schedule (computer science);scheduling (computing);single-machine scheduling;solver;spatial variability;time complexity;word lists by frequency	Roel Leus;Willy Herroelen	2007	J. Scheduling	10.1007/s10951-007-0014-z	fair-share scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;branch and bound	AI	15.357729973445998	9.138766352385334	101699
adebc255ccb6e408c19e60ff6a1b7a4097789df4	a two-phase backbone-based search heuristic for partial max-sat - an initial investigation	probleme satisfiabilite;eje troncal;algoritmo busqueda;formule cnf;maximum satisfiability;stochastic method;algorithme recherche;heuristic method;search algorithm;programmation stochastique;metodo heuristico;logique propositionnelle;intelligence artificielle;satisfiability;constraint satisfaction;satisfiabilite maximum;reseau federateur;busca local;satisfaction contrainte;formula cnf;propositional logic;problema satisfactibilidad;methode stochastique;artificial intelligence;stochastic local search;methode heuristique;inteligencia artificial;satisfaccion restriccion;conjunctive normal form;logica proposicional;backbone;satisfiabilidad maxima;stochastic programming;local search;satisfiability problem;programacion estocastica;recherche locale;metodo estocastico	The Partial MAX-SAT Problem (PMSAT) is a variant of the MAX-SAT problem that consists of two CNF formulas defined over the same variable set. Its solution must satisfy all clauses of the first formula and as many clauses in the second formula as possible. This study is concerned with the PMSAT solution in setting a two-phase stochastic local search method that takes advantage of an estimated backbone variables of the problem. First experiments conducted on PMSAT instances derived from SAT instances indicate that this new method offers significant performance benefits over state-of-the-art PMSAT techniques.	heuristic;max;maximum satisfiability problem;two-phase locking	Mohamed El Bachir Menai	2005		10.1007/11504894_94	stochastic programming;conjunctive normal form;constraint satisfaction;computer science;artificial intelligence;local search;mathematics;propositional calculus;boolean satisfiability problem;algorithm;satisfiability;search algorithm	AI	21.724468749824727	6.415814852103347	101811
c6a86893947639334e6c20c3efa1457fa55f9ba7	combining speed-up techniques for shortest-path computations	camino mas corto;random graph;shortest path;public transport;grafo aleatorio;plus court chemin;graphe aleatoire;route;dijkstra s algorithm;directed graph;graphe oriente;carretera;grafo orientado;highway;direct search	Computing a shortest path from one node to another in a directed graph is a very common task in practice. This problem is classically solved by Dijkstra's algorithm. Many techniques are known to speed up this algorithm heuristically, while optimality of the solution can still be guaranteed. In most studies, such techniques are considered individually. The focus of our work is the combination of speed-up techniques for Dijkstra's algorithm. We consider all possible combinations of four known techniques, namely goal-directed search, bi-directed search, multilevel approach, and shortest-path bounding boxes, and show how these can be implemented. In an extensive experimental study we compare the performance of different combinations and analyze how the techniques harmonize when applied jointly. Several real-world graphs from road maps and public transport and two types of generated random graphs are taken into account.	computation;shortest path problem	Martin Holzer;Frank Schulz;Thomas Willhalm	2004		10.1007/978-3-540-24838-5_20	random graph;route;suurballe's algorithm;combinatorics;bidirectional search;directed graph;dijkstra's algorithm;a* search algorithm;computer science;pathfinding;artificial intelligence;theoretical computer science;machine learning;yen's algorithm;mathematics;distributed computing;public transport;path;shortest path problem;shortest path faster algorithm;algorithm	Logic	23.16508507576511	7.050655783644735	102029
c18a1c272ab7b23365ed56a84e75a41112e258d7	on-line optimal control of two-stage discrete event systems with real-time constraints	real time constraint;cost function;real time;optimal control;discrete event system;global optimization;structural properties	We consider a two-stage Discrete Event System (DES) involving tasks with real-time constraints and seek to control processing times so as to minimize a cost function subject to each task meeting its own constraint. It has been shown that the off-line version of this problem can be efficiently solved by the Virtual Deadline Algorithm (VDA) [8]. In this report, an algorithm is developed to handle an online version with unknown task characteristics in advance. By utilizing the concept of “best solution in probability” introduced in [7] and extend the algorithm to a two-stage system, the algorithm makes uses of probability distributions and results in a less conservative solution compared with worst-case analysis. Numerical examples are included to illustrate our results.	algorithm;best, worst and average case;loss function;numerical method;online and offline;optimal control;real-time clock;real-time computing;real-time locating system;row echelon form	Jianfeng Mao;Christos G. Cassandras	2006	2006 8th International Workshop on Discrete Event Systems	10.1007/s10626-007-0019-y	mathematical optimization;real-time computing;optimal control;computer science;control theory;mathematics;global optimization	Embedded	13.251429802453771	7.850792639727392	102055
e841a58a6264658c94f0b205d6034018ef48d7d4	simulated annealing for finding tsp lower bound		Held and Karp’s theory has been proposed in the early 1970s in order to estimate an optimal tour length for the Travelling Salesman Problem. The ascent method, which is based on this theory, makes it possible to obtain a graph, which contains a large number of edges common with the optimal solution. In this article, we presents a new algorithm of simulated annealing for the same purpose. Our approach improves the quality of obtained results and makes it possible to receive a greater number of edges common with the optimal solution. The ascent method, suggested by Helsgaun, was applied for comparison since it is well documented, achieves good results and has an available implementation.	simulated annealing	Lukasz Strak;Wojciech Wieczorek;Arkadiusz Nowakowski	2017		10.1007/978-3-319-67077-5_5	mathematical optimization;computer science;artificial intelligence;machine learning;travelling salesman problem;simulated annealing;upper and lower bounds;graph	Theory	24.3107770138989	5.580183914897735	102125
5a0643d860b2427bfd3f2b0eceb50f7481206a66	optimal scheduling of two-component products on a single facility	group technology;branch and bound algorithm;simulation experiment;optimal scheduling;scheduling problem;production scheduling	We apply group technology on a single-facility scheduling problem of products assembled from common and unique components. Our model assumes that common components are classified into multiple families, whose set-up times are sequence-independent but not identical. This extension from one type of common components to multiple types distinguishes this study from those in the literature. After identifying properties for dominant schedules, a branch-and-bound algorithm is constructed to determine a production schedule with the minimum total completion time of products. A series of simulation experiments are made with respect to the number of families and the number of products. The outcome may provide a foundation for future research on this topic.	scheduling (computing)	Wen-Hua Yang	2004	Int. J. Systems Science	10.1080/00207720310001657072	fair-share scheduling;fixed-priority pre-emptive scheduling;job shop scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;mathematics;scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;branch and bound;multiprocessor scheduling	Theory	15.09518128896226	8.899518147348026	102165
14f2356855febc5805738ad079c9242f467b652d	relax and fix heuristics to solve one-stage one-machine lot-scheduling models for small-scale soft drink plants	modelizacion;chaine fabrication;ciencias exatas e da terra;embotellamiento;tiempo iniciacion;zero one programming;optimisation;soft drinks;planificacion regional;bebida refrescante;planification regionale;escala pequena;petite moyenne entreprise;boisson rafraichissante;optimizacion;regional planning;gestion production;ciencia da computacao;echelle petite;gollete estrangulamiento;heuristic method;modele mixte;programmation zero un;metodo heuristico;temps mise en route;product line;soft drink;small scale;production management;production process;production line;resolucion problema;modelisation;programmacion cero uno;goulot etranglement;mixed integer program;setup time;programacion mixta entera;mixed model;tamano lote;soft drink industry;taille lot;scheduling;gestion produccion;small medium sized firm;processus fabrication;programacion produccion;coste;programmation partiellement en nombres entiers;lot sizing;coaccion capacidad;mixed integer programming;artigo;production planning;optimization;linea fabricacion;contrainte capacite;bottling;methode heuristique;production lot scheduling models;modelo mixto;planification production;capacity constraint;modeling;relax and fix heuristics;bottleneck;pequenas y medianas empresas;ordonnancement;proceso fabricacion;reglamento;problem solving;resolution probleme;embouteillage;cout	The production planning of regional small-scale soft drink plants can be modeled by mixed integer models that integrate lot sizing and scheduling decisions and consider sequence-dependent setup times and costs. These plants produce soft drinks in different flavors and sizes and they have typically only one production line. The production process is carried out basically in two main stages: liquid preparation (stage I) and bottling (stage II). However, since the production bottleneck of these plants is often in stage II, in this study we represent the problem as a one-stage one-machine lot-scheduling model that considers stage II as the bottleneck but also takes into account a capacity constraint of stage I. To solve the problem, we propose relax and fix heuristics exploring the model structure and we evaluate their computational performances solving different problem instances based on real data of a Brazilian small-scale soft drink company. The solutions obtained are compared to the company solutions and the solutions of a general-purpose optimization software.	heuristic (computer science);linear programming relaxation;scheduling (computing)	Deisemara Ferreira;Reinaldo Morabito;Socorro Rangel	2010	Computers & OR	10.1016/j.cor.2009.06.007	mixed model;mathematical optimization;systems modeling;integer programming;input/output;regional planning;production line;computer science;bottling line;mathematics;scheduling;operations research;scheduling	AI	17.588264727753796	6.8803715568423724	102192
0be60412525d81158be79d59e3d3b213938e206c	exact algorithms for procurement problems under a total quantity discount structure	metodo polinomial;maastricht university;remise quantitative;approximate algorithm;corresponding author;temps polynomial;compra;market share;procurement;approximation algorithm;reverse auction;branch and cut method;problema np duro;rebaja cuantitativa;methode separation et coupe;contrato;companies;digital archive;temps calcul;np hard problem;minimizacion costo;aproximacion polinomial;branch and bound method;programacion lineal;minimisation cout;cost minimization;metodo branch and bound;marche contrat;probleme np difficile;polynomial method;exact algorithm;rebajas;open access;approximation polynomiale;subasta;algoritmo aproximacion;polynomial time;bidding;linear programming;min cost flow;programmation lineaire;linear program;achat;enchere;methode separation et evaluation;tiempo computacion;business volume discount;computation time;publication;scientific;algorithme approximation;branch and cut;business and economics;metodo branch and cut;auctions bidding;discount;methode polynomiale;rabais;branch and bound;institutional repository;purchases;polynomial approximation;tiempo polinomial;quantity discount	In this paper, we study the procurement problem faced by a buyer who needs to purchase a variety of goods from suppliers applying a so-called total quantity discount policy. This policy implies that every supplier announces a number of volume intervals and that the volume interval in which the total amount ordered lies determines the discount. Moreover, the discounted prices apply to all goods bought from the supplier, not only to those goods exceeding the volume threshold. We refer to this cost-minimization problem as the total quantity discount (TQD) problem. We give a mathematical formulation for this problem and argue that not only it is NP-hard, but also that there exists no polynomial-time approximation algorithm with a constant ratio (unless P = NP). Apart from the basic form of the TQD problem, we describe four variants. In a first variant, the market share that one or more suppliers can obtain is constrained. Another variant allows the buyer to procure more goods than strictly needed, in order to reach a lower total cost. We also consider a setting where the buyer needs to pay a disposal cost for the extra goods bought. In a third variant, the number of winning suppliers is limited, both in general and per product. Finally, we investigate a multi-period variant, where the buyer not only needs to decide what goods to buy from what supplier, but also when to do this, while considering the inventory costs. We show that the TQD problem and its variants can be solved by solving a series of min-cost flow problems. Finally, we investigate the performance of three exact algorithms (min-cost flow based branch-and-bound, linear programming based branch-and-bound, and branch-and-cut) on randomly generated instances involving 50 suppliers and 100 goods. It turns out that even the large instances of the basic problem are solved to optimality within a limited amount of time. However, we find that different algorithms perform best in terms of computation time for different variants. 2006 Elsevier B.V. All rights reserved.	approximation algorithm;branch and bound;branch and cut;computation;linear programming;maxima and minima;minimum-cost flow problem;np-hardness;p versus np problem;polynomial;procedural generation;procurement;time complexity	Dries R. Goossens;A. J. T. Maas;Frits C. R. Spieksma;Joris van de Klundert	2007	European Journal of Operational Research	10.1016/j.ejor.2006.03.010	time complexity;market share;mathematical optimization;economics;bidding;minimum-cost flow problem;procurement;computer science;linear programming;marketing;reverse auction;operations management;publication;np-hard;mathematics;mathematical economics;branch and bound;branch and cut;statistics	Theory	15.787864741132251	5.207542617508469	102230
c4f25bbba41566ff67eb2de66d36a3083410a0cf	a note on heuristics for the traveling salesman problem	traveling salesman problem	We introduce subclasses of the traveling salesman problem (TSP) and analyze the behaviour of heuristics on them. We derive bounds for the performance of the algorithms.	heuristic (computer science);travelling salesman problem	Gianfranco d'Atri	1980	Math. Program.	10.1007/BF01581633	traveling purchaser problem;2-opt;mathematical optimization;lin–kernighan heuristic;mathematics;travelling salesman problem;3-opt;bottleneck traveling salesman problem	EDA	22.718941749300818	7.307624478925633	102408
85295c45f9578aad5a83f6e7b2c8190d31784575	an efficient optimal solution to the coil sequencing problem in electro-galvanizing line	modelizacion;dynamic programming;optimal solution;electro galvanizing line;metodo polinomial;switching;programacion dinamica;sequencage;efficiency;dynamic programming algorithm;dynamic program;satisfiability;modelisation;industrie metallurgique;sequencing;eficacia;computer experiment;polinomio matricial;mathematical programming;polynomial method;polynomial algorithm;steel industry;conmutacion;programmation dynamique;coste;property a;efficacite;industria metalurgica;matrix polynomial;methode polynomiale;polynome matriciel;modeling;programmation mathematique;steel production;programacion matematica;commutation;metallurgical industry;switching cost;cout	This paper studies a coil sequencing problem that arises from electro-galvanizing line in steel industry. The problem is to find a processing sequence of steel coils such that the switching costs between consecutive coils are minimized while satisfying technical restrictions. The problem can be decomposed into several independent sub-problems, each corresponding to a turn which is a sequence of continuously processed coils with the same post-processing requirement. The coils in each turn can be further divided into several families each consisting of the coils with the same width. Based on analysis of the problem properties, a two-phase polynomial algorithm is developed to obtain an optimal turn. The sequence of coils in a family with given boundary coils (first and last coils) is determined in the first phase using a polynomial dynamic programming algorithm. In the second phase, the optimal turn is formed by another polynomial dynamic programming algorithm which takes the boundary coils for each family as state variables. The efficiency of the proposed algorithm is demonstrated through computational experiments.		Lixin Tang;Yang Yang;Jiyin Liu	2010	Computers & OR	10.1016/j.cor.2010.01.009	mathematical optimization;computer science;dynamic programming;mathematics;algorithm	ECom	17.686316003366578	7.333375899344889	102553
00d35b08cff47ae0ff01e9543fbe0ad1f843254a	a note on graham's bound		Abstract   In [2], Graham establishes an upper bound for the makespan of a set of tasks whose executions are governed by given precedence constraints. In this paper we provide a similar upper bound for the makespan of such parallel processing systems when the interprocessor communication delays are taken into account. Our result is a slight generalization of that of Graham's.	comparison of relational database management systems;graham scan	Zhen Liu	1990	Inf. Process. Lett.	10.1016/0020-0190(90)90177-Y	combinatorics;mathematics;distributed computing;algorithm	DB	16.132809324182936	11.312662901705476	102706
73089e0cc12b4a59672bfe8681a92ccca28f4867	optimally relaxing partial-order plans with maxsat	automated planning;reordering;deordering;partial order planning;maxsat	Partial-order plans (POPs) are attractive because of their least commitment nature, providing enhanced plan flexibility at execution time relative to sequential plans. Despite the appeal of POPs, most of the recent research on automated plan generation has focused on sequential plans. In this paper we examine the task of POP generation by relaxing or modifying the action orderings of a plan to optimize for plan criteria that promotes flexibility in the POP. Our approach relies on a novel partial weighted MaxSAT encoding of a plan that supports the minimization of deordering or reordering of actions. We further extend the classical least commitment criterion for a POP to consider the number of actions in a solution, and provide an encoding to achieve least commitment plans with respect to this criterion. We compare the effectiveness of our approach to a previous approach for POP generation via sequential-plan relaxation. Our results show that while the previous approach is proficient at heuristically finding the optimaldeorderingof a plan, our approach gains greater flexibility with the optimalreordering.	algorithm;heuristic;linear programming relaxation;maximum satisfiability problem;polynomial;run time (program lifecycle phase);solver	Christian J. Muise;Sheila A. McIlraith;J. Christopher Beck	2012			mathematical optimization;computer science;artificial intelligence;maximum satisfiability problem	AI	22.482108765460126	4.300225546575351	102879
a26cf9015ac218776e4b20fb205c7bac3243cbf2	online bin packing with (1, 1) and (2, r) bins	bin packing;linear programming;article;competitive ratio	We study a variant of online bin packing problem, in which there are two types of bins: $$(1,1)$$(1,1) and $$(2,R)$$(2,R), i.e., unit size bin with cost 1 and size 2 bin with cost $$R > 1$$R>1, the objective is to minimize the total cost occurred when all the items are packed into the two types of bins. When $$R > 3$$R>3, the offline version of this problem is equivalent to the classical bin packing problem. In this paper, we focus on the case $$ R \le 3$$R≤3, and propose online algorithms and obtain lower bounds for the problem.	bin packing problem;set packing	Jing Chen;Xin Han;Kazuo Iwama;Hing-Fung Ting	2015	J. Comb. Optim.	10.1007/s10878-014-9749-6	competitive analysis;mathematical optimization;combinatorics;bin packing problem;computer science;linear programming;mathematics;bin	Theory	16.378192572933855	11.329547175356137	103181
076485b4027920b89db488ad193caf7385b5d989	decremental state space relaxation strategies and initialization heuristics for solving the orienteering problem with time windows with dynamic programming	camino mas corto;traveling salesman problem;dynamic programming;shortest path;dominance;programacion dinamica;travelling salesman problem;vertex;heuristic method;espace etat;time window;plus court chemin;metodo heuristico;dynamic program;optimisation combinatoire;problema viajante comercio;resolucion problema;state space method;dominancia;methode espace etat;probleme commis voyageur;state space;programmation dynamique;fenetre temporelle;vertice;methode heuristique;ventana temporal;espacio estado;combinatorial optimization;optimal algorithm;problem solving;resolution probleme;metodo espacio estado;shortest path problem;optimizacion combinatoria	We present an exact optimization algorithm for the Orienteering Problem with Time Windows (OPTW). The algorithm is based on bi-directional and bounded dynamic programming with decremental state space relaxation. We compare different strategies proposed in the literature to guide decremental state space relaxation: our experiments on instances derived from the literature show that there is no dominance between these strategies. We also propose a new heuristic technique to initialize the critical vertex set and we provide experimental evidence of its effectiveness.	dynamic programming;heuristic (computer science);linear programming relaxation;microsoft windows;state space	Giovanni Righini;Matteo Salani	2009	Computers & OR	10.1016/j.cor.2008.01.003	mathematical optimization;combinatorial optimization;computer science;calculus;mathematics;shortest path problem;travelling salesman problem;algorithm	ML	21.043916658598533	6.595171084293461	103523
bf4282282c9ac898ffa985a2e8f6958b7c59ad9c	finding a best traveling salesman 4-opt move in the same time as a best 2-opt move	traveling salesman problem;shortest path;ejection chain;traveling salesman	A special class of 4-opt moves plays a key role in several leading heuristics for the traveling salesman problem (TSP). However, the number of such moves is quite large—O(n4) for a graph of n nodes, on the order of the square of the number of 2-opt moves. Consequently, classical TSP heuristics have not attempted to seek best (and often not even improving) instances of these moves. We show that a best move from the collection that consists of these moves, together with an additional class of 4-opt moves and certain related 3-opt moves, can nevertheless be found in the same order of time required to find a best 2-opt move. Our method employs an acyclic shortest path model based on ideas introduced with ejection chain procedures and generates a sequence that can include improving moves at earlier stages. Joined with candidate list strategies that limit the tour edges available to be dropped, the method can also be structured to find best members from the set of implied surviving moves in O(n) time, making available TSP strategies for incorporating 4-opt moves that were previously beyond practical consideration.	2-opt	Fred Glover	1996	J. Heuristics	10.1007/BF00247211	mathematical optimization;combinatorics;computer science;mathematics;travelling salesman problem;algorithm	Theory	23.846416544304255	5.9322714529755896	103601
952993e5f695c891bf2277e77ca7554454405ec0	remark on algorithm 815: fortran subroutines for computing approximate solutions of feedback set problems using grasp	optimisation;reliability;programacion entera;mathematiques discretes;optimizacion;matematicas discretas;performance;prension;discrete mathematics;mathematiques combinatoires;gripping;g 2 1 discrete mathematics combinatorics combinatorial algorithms;programmation en nombres entiers;combinatorial problem;probleme combinatoire;problema combinatorio;integer programming;approximate solution;robustesse;g 1 6 numerical analysis optimization integer programming;subroutine;fortran subroutines;feedback set problems;robustness;prehension;sous programme;optimization;source code;fortran;grasp;fiabilite logiciel;fiabilidad logicial;software reliability;g 4 mathematics of computing mathematical software reliability and robustness;combinatorial mathematics;languages;subprograma;robustez	We show that the Fortran source code for Algorithm 815 contains an error and we propose a correction. The error may cause the algorithm to generate incorrect results. We also show that the performance of the corrected algorithm can be improved by a minor adjustment in the code.	approximation algorithm;fortran;grasp;subroutine	Berend Hasselman	2006	ACM Trans. Math. Softw.	10.1145/1132973.1132982	algorithm design;mathematical optimization;combinatorics;mathematical analysis;integer programming;ramer–douglas–peucker algorithm;performance;computer science;theoretical computer science;subroutine;reliability;grasp;mathematics;programming language;algorithm;software quality;robustness;algebra;source code	Graphics	23.595967123390672	13.251344213858061	103970
493054b0f89a78448664307162100df49d3876e4	fast optimal alignment		We show how to speed up sequence alignment algorithms of the type introduced by Needleman and Wunsch (and generalized by Sellers and others). Faster alignment algorithms have been introduced, but always at the cost of possibly getting sub-optimal alignments. Our modification results in the optimal alignment still being found, often in 1/10 the usual time. What we do is reorder the computation of the usual alignment matrix so that the optimal alignment is ordinarily found when only a small fraction of the matrix is filled. The number of matrix elements which have to be computed is related to the distance between the sequences being aligned; the better the optimal alignment, the faster the algorithm runs.	computation;fill;needleman–wunsch algorithm;sequence alignment;the matrix	James W. Fickett	1984	Nucleic acids research	10.1093/nar/12.1Part1.175	needleman–wunsch algorithm	Comp.	14.69920261410383	15.355189050240508	104236
ba5d4ccf7089a44a737178ee738a5682e639d5fb	mean value analysis of re-entrant line with batch machines and multi-class jobs	performance measure;cycle time;queueing network;approximation method;queue length;re entrant shop;mean value analysis;relative error;batch machine;numerical experiment;multi class jobs;semiconductor manufacturing;steady state	We propose an approximate approach for estimating the performance measures of the re-entrant line with single-jobmachines and batch machines based on the mean value analysis (MVA) technique.Multi-class jobs are assumed to be processed in predetermined routings, in which some processes may utilize the same machines in the re-entrant fashion. The performance measures of interest are the steady-state averages of the cycle time of each job class, the queue length of each bu!er, and the throughput of the system. The system may not be modeled by a product form queueing network due to the inclusion of the batch machines and the multi-class jobs with di!erent processing times. Thus, we present a methodology for approximately analyzing such a re-entrant line using the iterative procedures based upon the MVA and some heuristic adjustments. Numerical experiments show that the relative errors of the proposed method are within 5% as compared against the simulation results.	approximation algorithm;approximation error;complex systems;computation;experiment;heuristic;iterative method;job stream;model–view–adapter;numerical method;queueing theory;semiconductor fabrication plant;simulation;steady state;throughput	Youngshin Park;Sooyoung Kim;Chi-Hyuck Jun	2002	Computers & OR	10.1016/S0305-0548(00)00099-X	mean value analysis;approximation error;real-time computing;cycle time variation;computer science;mathematics;distributed computing;steady state;semiconductor device fabrication;statistics	Metrics	11.12134634472899	5.942316053919847	104376
866d6ec99660647303c10acc1b6dbbc5029ab5cc	solving ocst problems with problem-specific guided local search	dynamic change;optimal solution;objective function;problem specific adaptation;guided local search;optimal communications spanning tree;spanning tree;evolutionary algorithm	This paper considers the Euclidean variant of the optimal communication spanning tree (OCST) problem. Previous work analyzed features of high-quality solutions and found that edges in optimal solutions have low weight and point towards the center of a tree. Consequently, integrating this problem-specific knowledge into a metaheuristic increases its performance. In this paper, we present an approach to dynamically change the objective function to guide the search process into promising areas. Our approach is based on guided local search. The resulting problem-specific guided local search method considering weight and orientation of edges outperforms standard variants considering only edge weights as well as state-of-the-art evolutionary algorithms using edge-sets for larger problems.	evolutionary algorithm;file spanning;guided local search;local search (optimization);loss function;optimization problem;spanning tree;tree (data structure)	Wolfgang Steitz;Franz Rothlauf	2010		10.1145/1830483.1830541	optimal binary search tree;mathematical optimization;combinatorics;spanning tree;computer science;local search;machine learning;evolutionary algorithm;mathematics;guided local search	AI	24.539553436723306	5.334280971575321	104401
a2263c07ff9bee249ab5d41704c4baf0a5515199	combinatorial optimization in opl studio	modelizacion;lenguaje programacion;programmation logique avec contrainte;programming language;combinatorial optimization problem;programacion logica con restriccion;code generation;modeling language;optimisation combinatoire;modelisation;mathematical programming;scheduling;constraint programming;langage programmation;ordonamiento;constraint logic programming;combinatorial optimization;modeling;programmation mathematique;programacion matematica;ordonnancement;column generation;scripting language;optimizacion combinatoria	OPL is a modeling language for mathematical programming and combinatorial optimization problems. It is the first modeling language to combine high-level algebraic and set notations from modeling languages with a rich constraint language and the ability to specify search procedures and strategies that are the essence of constraint programming. In addition, OPL models can be controlled and composed using OPLScript, a script language that simplifies the development of applications that solve sequences of models, several instances of the same model, or a combination of both as in column-generation applications. Finally, OPL models can be embedded in larger application through C++ code generation. This paper presents an overview of these functionalities on a scheduling application.	c++;code generation (compiler);column generation;combinatorial optimization;constraint programming;embedded system;high- and low-level;mathematical optimization;modeling language;open programming language (opl);scheduling (computing);scripting language	Pascal Van Hentenryck;Laurent D. Michel;Philippe Laborie;Wim Nuijten;Jerome Rogerie	1999		10.1007/3-540-48159-1_1	constraint logic programming;column generation;constraint programming;systems modeling;combinatorial optimization;computer science;artificial intelligence;theoretical computer science;machine learning;scripting language;modeling language;programming language;scheduling;algorithm;code generation	PL	19.845338993364308	8.040658441880032	104559
b581a86dfef45235da89bbf937ba5ae395e9c14b	the complexity of rational synthesis	non zero sum games reactive synthesis omega regular objectives;004	We study the computational complexity of the cooperative and non-cooperative rational synthesis problems, as introduced by Kupferman, Vardi and co-authors. We provide tight results for most of the classical omega-regular objectives, and show how to solve those problems optimally. 1998 ACM Subject Classification B.6.3 Automatic Synthesis, F.2 Analysis of algorithms and problem complexity, F.1.1 Automata	algorithm;analysis of algorithms;automaton;chaitin's constant;computational complexity theory	Rodica Condurache;Emmanuel Filiot;Raffaella Gentilini;Jean-François Raskin	2016		10.4230/LIPIcs.ICALP.2016.121	mathematical optimization;combinatorics;computer science;mathematics	Logic	16.383876436534166	17.80699553156536	104600
06db351aaff8409148acc7e4ac4e2bd279ad3051	incremental algorithms for local search from existential second-order logic	second order;algoritmo busqueda;algorithme incrementiel;algorithme recherche;search algorithm;combinatorial problems;user support;busca local;resolucion problema;combinatorial problem;second order logic;logica orden 2;probleme combinatoire;logique ordre 2;problema combinatorio;portfolio management;datavetenskap datalogi;gestion cartera;incremental algorithm;computer science;gestion portefeuille;local search;recherche locale;problem solving;resolution probleme	Local search is a powerful and well-established method for solving hard combinatorial problems. Yet, until recently, it has provided very little user support, leading to time-consuming and error-prone implementation tasks. We introduce a scheme that, from a high-level description of a constraint in existential second-order logic with counting, automatically synthesises incremental penalty calculation algorithms. The performance of the scheme is demonstrated by solving real-life instances of a financial portfolio design problem that seem unsolvable in reasonable time by complete search.	algorithm;automatic control;cognitive dimensions of notations;computation;dynamic problem (algorithms);experiment;high- and low-level;linear temporal logic to büchi automaton;local search (constraint satisfaction);local search (optimization);real life;search algorithm	Magnus Ågren;Pierre Flener;Justin Pearson	2005		10.1007/11564751_7	mathematical optimization;computer science;artificial intelligence;mathematics;incremental heuristic search;second-order logic;algorithm;project portfolio management	AI	21.525551630845015	6.1705555245131825	104722
0652e922205456fdec603666fdba569eec7563bb	set covering with our eyes closed	68w40;approximation algorithms;settore ing inf 05 sistemi di elaborazione delle informazioni;universal algorithms;online algorithms;68w25;set cover;68w05;facility location;68w27	Given a universe U of n elements and a weighted collection l of m subsets of U, the universal set cover problem is to a-priori map each element u epsi U to a set S(u) epsi l containing u, so that X sube U is covered by S(X)=UuepsiXS(u). The aim is finding a mapping such that the cost of S(X) is as close as possible to the optimal set-cover cost for X. (Such problems are also called oblivious or a-priori optimization problems.) Unfortunately, for every universal mapping, the cost of S(X) can be Omega(radicn) times larger than optimal if the set X is adversarially chosen. In this paper we study the performance on average, when X is a set of randomly chosen elements from the universe: we show how to efficiently find a universal map whose expected cost is O(log mn) times the expected optimal cost. In fact, we give a slightly improved analysis and show that this is the best possible. We generalize these ideas to weighted set cover and show similar guarantees to (non-metric) facility location, where we have to balance the facility opening cost with the cost of connecting clients to the facilities. We show applications of our results to universal multi-cut and disc-covering problems, and show how all these universal mappings give us stochastic online algorithms with the same competitive factors.	covering problems;mathematical optimization;online algorithm;randomness;sube card;set cover problem	Fabrizio Grandoni;Anupam Gupta;Stefano Leonardi;Pauli Miettinen;Piotr Sankowski;Mohit Singh	2008	2008 49th Annual IEEE Symposium on Foundations of Computer Science	10.1137/100802888	online algorithm;mathematical optimization;combinatorics;computer science;facility location problem;mathematics;set cover problem;approximation algorithm;algorithm	Theory	20.584028540425685	14.83941515081908	104865
43d3fc340ff5e6e96c2b889c4d9f15f0415987f7	scheduling cutting process for large paper rolls	stock cutting problem heuristic approaches scheduling;buyuk rulo kesimi sezgisel yaklasimlar cizelgeleme	Paper cutting is a simple process of slicing large rolls of paper, jumbo-reels, into various sub-rolls with variable widths based on demands risen by customers. Since the variability is high due to collected various orders into a pool, the process turns to be production scheduling problem, which requires optimisation so as to minimise the final remaining amount of paper wasted. The problem holds characteristics similar one-dimensional bin-packing problem to some extends and differs with some respects. This paper introduces a modelling attempt as a scheduling problem with an integer programming approach for optimisation purposes. Then, a constructive heuristic algorithm revising one of well-known approaches, called Best-fit algorithm, is introduced to solve the problem. The illustrative examples provided shows the near optimum solution provided with very low complexity.	algorithm;best practice;bin packing problem;constructive heuristic;cutting stock problem;global optimization;heart rate variability;heuristic (computer science);integer programming;jumbo frame;mathematical optimization;metaheuristic;scheduling (computing);set packing	Mehmet Emin Aydin;Osman Taylan	2013	CoRR	10.5505/apjes.2013.83997	mathematical optimization;computer science;engineering;cutting stock problem;engineering drawing	AI	14.544261104585946	5.339787260252942	104999
82c8cde9415ac34a820e357809c51c3fc0d3523d	resource allocation in networks using abstraction and constraint satisfaction techniques	programmation logique avec contrainte;reseau communication;programacion logica con restriccion;complejidad programa;intelligence artificielle;constraint satisfaction;satisfaction contrainte;informatique theorique;artificial intelligence;constraint logic programming;inteligencia artificial;satisfaccion restriccion;program complexity;red de comunicacion;communication network;complexite programme;computer theory;informatica teorica	Most work on constraint satisfaction problems (CSP) starts with a standard problem definition and focuses on algorithms for finding solutions. However, formulating a CSP so that it can be solved by such methods is often a difficult problem in itself. In this paper, we consider the problem of routing in networks, an important problem in communication networks. It is as an example of a problem where a CSP formulation would lead to unmanageable solution complexity. We show how an abstraction technique results in tractable formulations and makes the machinery of CSP applicable to this problem.		Christian Frei;Boi Faltings	1999		10.1007/978-3-540-48085-3_15	constraint logic programming;constraint satisfaction;computer science;artificial intelligence;programming language;operations research;algorithm;telecommunications network	AI	19.939090753228474	8.123320486806138	105034
33c0241e8dfd14de2fa9bbec59f1e0292e7ce8ab	push and swap: fast cooperative path-finding with completeness guarantees	completeness guarantee;hard instance;cooperative path-finding;simulated experiment;alternative method;fast algorithm;goal location;general class;high level;proposed algorithm	Cooperative path-finding can be abstracted as computing non-colliding paths for multiple agents between their start and goal locations on a graph. This paper proposes a fast algorithm that can provide completeness guarantees for a general class of problems without any assumptions about the graph’s topology. Specifically, the approach can address any solvable instance where there are at most n-2 agents in a graph of size n. The algorithm employs two primitives: a “push” operation where agents move towards their goals up to the point that no progress can be made, and a “swap” operation that allows two agents to swap positions without altering the configuration of other agents. Simulated experiments are provided on hard instances of cooperative path-finding, including comparisons against alternative methods. The results are favorable for the proposed algorithm and show that the technique scales to problems that require high levels of coordination, involving hundreds of agents.	algorithm;decision problem;experiment;graph (discrete mathematics);paging	Ryan Luna;Kostas E. Bekris	2011		10.5591/978-1-57735-516-8/IJCAI11-059	mathematical optimization;artificial intelligence;theoretical computer science;machine learning;mathematics;distributed computing	AI	22.09020933378253	4.897493653254283	105119
78da87749061c49eb2d14999623ccff703ecf9be	a constraint-based operation sequencing for a knowledge-based process planning	information acquisition;difference operator;feature recognition;decision making process;optimality criteria;process planning;heuristic algorithm;knowledge base	Process planning is a decision-making process. Decisions on machining operations for a particular feature have to be made on various independent conditions such as which operation should be performed with which tools and under what cutting parameters. An integrated knowledge-based CAPP system called ProPlanner has been developed. The system has five modules namely information acquisition, feature recognition, machining operation planning and tool selection, set-up planning, and operation sequencing. Most process-planning systems do not produce alternative process plans. Usually, a fixed sequence created by a process plan is not necessarily the best possible sequence. Therefore, the aim should be to generate all possible operation sequences and use some optimality criteria to obtain the best sequence for the given operating environment. This paper presents an efficient heuristic algorithm, belongs to the system's operation sequencing module, for finding near-optimal operation sequences from all available process plans in a machining set-up. The costs of the various machining schemes are calculated and the machining scheme with the lowest cost is chosen. All feasible cutting tools are identified for each particular feature and the corresponding machining operations. This process is repeated for all the features in the machining set-up. All possible feature sequence combinations allowed by the current feature constraints are then generated. Appropriate cutting tools are identified and assigned to different operations. The feature sequence with the smallest number of tool changes is adopted.		Cevdet Göloglu	2004	J. Intelligent Manufacturing	10.1023/B:JIMS.0000034109.17959.90	heuristic;feature recognition;decision-making;mathematical optimization;knowledge base;computer science;engineering;artificial intelligence;machine learning;engineering drawing	Robotics	12.13068349449175	4.216960748515533	105644
1728c6d7f3553ede75bdc3afbf21e9f404571174	a skyline-based heuristic for the 2d rectangular strip packing problem	packing;tabu search;heuristics	In this paper, we propose a greedy heuristic for the 2D rectangular packing problem that represents packings using a skyline. To solve the 2D rectangular strip packing problem, we make use of this heuristic as a subroutine in an iterative deepening binary search on the maximum height of the packing that incorporates a tabu search mechanic. Our approach outperforms all existing approaches on several sets of standard benchmark test cases for the 2D strip packing problem.	heuristic;set packing	Lijun Wei;Andrew Lim;Wenbin Zhu	2011		10.1007/978-3-642-21827-9_29	mathematical optimization;set packing;tabu search;computer science;artificial intelligence;heuristics	Robotics	23.247236646727252	5.666188626710216	105780
cbba03af18bb844bacea27e619799277176637f4	cheating strategies for the gale-shapley algorithm with complete preference lists	cheating;mariage;modelizacion;graph theory;metodo polinomial;mujer;woman;sex;temps polynomial;probleme np complet;stable marriage;hombre;sexe;pairing;marriage;permutation;polynomial time algorithm;modelisation;femme;polynomial method;tricherie;matrimonio;permutacion;human;polynomial time;preferencia;completitud;np complete;problema np completo;preference;emparejamiento;completeness;methode polynomiale;appariement;completude;modeling;sexo;np complete problem;trampa;homme;tiempo polinomial	This paper deals with a strategic issue in the stable marriage model with complete preference lists (i.e., a preference list of an agent is a permutation of all the members of the opposite sex). Given complete preference lists of all the men, a partial marriage, and complete preference lists of unmatched women, we consider the problem of finding preference lists of matched women such that the men-proposing Gale-Shapley algorithm applied to the lists produces a (perfect) marriage which is an extension of a given partial marriage. We propose a polynomial time algorithm for finding a desired set of preference lists, if these exist. We also deal with the case that complete preference lists of all the men and a partial marriage are given. In this case, we consider a problem of the existence of preference lists of all the women such that the men-proposing Gale-Shapley algorithm produces a marriage including a given partial marriage. We show NP-completeness of this problem.	algorithm;bookmark (world wide web);decision problem;file spanning;limewire;marginal model;np-completeness;one-to-many (data model);p (complexity);spanning tree;stable marriage problem	Hirotatsu Kobayashi;Tomomi Matsui	2009	Algorithmica	10.1007/s00453-009-9359-3	mathematical optimization;combinatorics;np-complete;graph theory;mathematics;geometry;algorithm;statistics	ECom	18.260301194779284	17.88849428845603	105863
2fefd017965a9a0303a4bab73d8282d1b49a897f	on dynamic bin packing: an improved lower bound and resource augmentation analysis	bin packing problem;multiplier;bin packing;competitividad;aumentacion;competitive algorithms;problema relleno;temps minimal;augmentation;optimisation combinatoire;algorithme competitif;multiplicateur;increase;borne inferieure;competitiveness;minimum time;probleme remplissage;combinatorial optimization;algoritmo optimo;algorithme optimal;optimal algorithm;competitivite;tiempo minimo;on line algorithm;lower bound;multiplicador;competitive ratio;cota inferior;optimizacion combinatoria	We study the dynamic bin packing problem introduced by Coffman, Garey and Johnson. This problem is a generalization of the bin packing problem in which items may arrive and depart from the packing dynamically. The main result in this paper is a lower bound of 2.5 on the achievable competitive ratio, improving the best known 2.428 lower bound, and revealing that packing items of restricted form like unit fractions (i.e., of size 1/k for some integer k), for which a 2.4985-competitive algorithm is known, is indeed easier. We also investigate the resource augmentation version of the problem where the on-line algorithm can use bins of size b (>1) times that of the optimal off-line algorithm. An interesting result is that we prove b=2 is both necessary and sufficient for the on-line algorithm to match the performance of the optimal off-line algorithm, i.e., achieve 1-competitiveness. Further analysis gives a trade-off between the bin size multiplier 1<b≤2 and the achievable competitive ratio.	bin packing problem;competitive analysis (online algorithm);michael garey;online algorithm;online and offline;set packing	Wun-Tat Chan;Prudence W. H. Wong;Fencol C. C. Yung	2008	Algorithmica	10.1007/s00453-008-9185-z	mathematical optimization;bin packing problem;best bin first;combinatorial optimization;computer science;mathematics;algorithm;square packing in a square	Theory	17.40901281234778	11.960514090326	105892
d978da707d5f09e6b7c9007fdadc0c0d8419724e	an extension principle based solution approach for shortest path problem with fuzzy arc lengths		A shortest path problem on a network in the presence of fuzzy arc lengths is focused in this paper. The aim is to introduce the shortest path connecting the first and last vertices of the network which has minimum fuzzy sum of arc lengths among all possible paths. In this study a solution algorithm based on the extension principle of Zadeh is developed to solve the problem. The algorithm decomposes the fuzzy shortest path problem into two lower bound and upper bound sub-problems. Each sub-problem is solved individually in different a levels to obtain the shortest path, its fuzzy length and its associated membership function value. The proposed method contains no fuzzy ranking function and also for each acut, it gives a unique lower and upper bound for the fuzzy length of the shortest path. The algorithm is examined over some well-known networks from the literature and its performance is superior to the existent methods.	algorithm;ranking (information retrieval);shortest path problem	Sadegh Niroomand;Ali Mahmoodirad;Ahmad Heydari;Fatemeh Kardani;Abdollah Hadi-Vencheh	2017	Operational Research	10.1007/s12351-016-0230-4	mathematical optimization;combinatorics;discrete mathematics;canadian traveller problem;constrained shortest path first;longest path problem;average path length;fuzzy number;euclidean shortest path;yen's algorithm;mathematics;shortest path problem;distance;k shortest path routing;shortest path faster algorithm	AI	23.9251228331217	17.02707330881332	105924
c79e78ad9c71014d5804bfb2b64f943865784642	a note on submodular function minimization with covering type linear constraints	submodular function minimization;primal-dual approximation algorithm	In this paper, we consider the non-negative submodular function minimization problem with covering type linear constraints. Assume that there exist m linear constraints, and we denote by $$\varDelta _i$$ Δi the number of non-zero coefficients in the ith constraints. Furthermore, we assume that $$\varDelta _1 \ge \varDelta _2 \ge \cdots \ge \varDelta _m$$ Δ1≥Δ2≥⋯≥Δm . For this problem, Koufogiannakis and Young proposed a polynomial-time $$\varDelta _1$$ Δ1 -approximation algorithm. In this paper, we propose a new polynomial-time primal-dual approximation algorithm based on the approximation algorithm of Takazawa and Mizuno for the covering integer program with $$\{0,1\}$$ {0,1} -variables and the approximation algorithm of Iwata and Nagano for the submodular function minimization problem with set covering constraints. The approximation ratio of our algorithm is $$\max \{\varDelta _2, \min \{\varDelta _1, 1 + \varPi \}\}$$ max{Δ2,min{Δ1,1+Π}} , where $$\varPi $$ Π is the maximum size of a connected component of the input submodular function.	approximation algorithm;coefficient;connected component (graph theory);existential quantification;integer programming;loss function;polynomial;submodular set function;time complexity	Naoyuki Kamiyama	2017	Algorithmica	10.1007/s00453-017-0363-8	submodular set function;mathematics;discrete mathematics;combinatorics;approximation algorithm;mathematical optimization;integer;connected component	ML	23.111039431548484	16.490362121791456	106306
a99dcd5c06a1549f5d4b6c7d1a0aa263664c7169	a tabu search heuristic for solving the clsp with backlogging and set-up carry-over	forecasting;backlogging;optimisation;backorder;reliability;computadora personal;ordinateur personnel;project management;information systems;optimizacion;langage c;personal computer;maintenance;soft or;information technology;heuristic method;packing;metodo heuristico;operations research;location;investment;journal;journal of the operational research society;encargo en retardo;inventory;feasibility;purchasing;c language;history of or;flujo red;logistics;programacion mixta entera;tamano lote;marketing;taille lot;network flows;scheduling;set up carry over;programmation partiellement en nombres entiers;lot sizing;production;mixed integer programming;communications technology;tabu search;optimization;methode heuristique;computer science;operational research;network flow;commande en retard;capacitated lot sizing;practicabilidad;flot reseau;faisabilite;applications of operational research;or society;busqueda tabu;recherche tabou;jors;management science;infrastructure;lenguaje c	In this paper, the multi-item, single-level, capacitated, dynamic lot sizing problem with set-up carry-over and backlogging, abbreviated to CLSP+, is considered. The problem is formulated as a mixed integer programming problem. A heuristic method consisting of four elements: (1) a demand shifting rule, (2) lot size determination rules, (3) checking feasibility conditions and (4) set-up carry-over determination, provides us with an initial feasible solution. The resulting feasible solution is improved by adopting the corresponding set-up and set-up carry-over schedule and re-optimizing it by solving a minimum-cost network flow problem. Then the improved solution is used as a starting solution for a tabu search procedure, with the value of moves assessed using the same minimum-cost network problem. Computational results on randomly generated problems show that the algorithm, which is coded in C++, is able to provide optimal solutions or solutions extremely close to optimal. The computational efficiency makes it possible to solve reasonably large problem instances routinely on a personal computer.	heuristic;tabu search	Behrooz Karimi;Seyyed M. T. Fatemi Ghomi;John M. Wilson	2006	JORS	10.1057/palgrave.jors.2601968	project management;mathematical optimization;flow network;economics;computer science;marketing;operations management;mathematics;operations research;information technology	AI	17.64038733020394	5.83771170054222	106332
07c9d9cb735c7cc445fd796d253b37cf318c7a28	efficient factor graph fusion for multi-robot mapping and beyond		This work presents a novel method to efficiently factorize the combination of multiple factor graphs having common variables of estimation. Variable ordering, a well-known variable elimination technique in linear algebra is employed to efficiently solve a factor graph. Our primary contribution in this work is to reuse the variable ordering of the graphs being combined to find the ordering of the fused graph called fusion ordering. By reusing the variable ordering of the parent graphs we were able to produce an order-of-magnitude difference in the time required for solving the fused graph. A formal verification is provided to show that the proposed strategy does not violate any of the relevant standards. The fusion ordering is experimented on the standard dataset used in the sparse linear algebra community called SuiteSparse [1]. Recent factor graph formulation for Simultaneous Localization and Mapping (SLAM) like Incremental Smoothing and Mapping (ISAM) using the Bayes tree has been very successful and garnered much attention. In the case of mapping, multi-robot system has a great advantage over a single robot that provides faster map coverage and better estimation quality. We also demonstrate the improvement of our ordering scheme on a real-world multi-robot AP Hill dataset [2].		Ramkumar Natarajan;Michael A. Gennert	2018	2018 21st International Conference on Information Fusion (FUSION)	10.23919/ICIF.2018.8455502	computer science;machine learning;variable elimination;artificial intelligence;linear algebra;factor graph;smoothing;simultaneous localization and mapping;factorization;formal verification;bayes' theorem	Robotics	13.903691037985878	16.08869814528487	106416
3b04f136471e4889c0286165c450dfe5275fdafc	stochastic flow shop scheduling model for the panama canal	forecasting;graph theory;trafic maritime;analisis componente principal;tiempo total acabamiento;queueing network;reliability;teoria grafo;metaheuristics;project management;information systems;transporte maritimo;logistique;maintenance;maritime transportation;trafico maritimo;industrial and manufacturing systems engineering;soft or;information technology;heuristic method;simulation;packing;temps total achevement;programmation stochastique;metodo heuristico;sea traffic;operations research;location;flow models;theorie graphe;red cola espera;canal;investment;journal;journal of the operational research society;inventory;purchasing;modele ecoulement;estrategia empresa;history of or;metamodel;transit time;makespan;particion;logistics;metamodele;marketing;metamodelo;reseau file attente;scheduling;principal component analysis;partition;analyse composante principale;temps parcours;production;coaccion capacidad;communications technology;contrainte capacite;methode heuristique;computer science;stochastic model;operational research;capacity constraint;stochastic programming;firm strategy;atelier monogamme;tiempo recorrido;strategie entreprise;modelo estocastico;programacion estocastica;modele stochastique;ordonnancement;flow shop;applications of operational research;industrial engineering;or society;reglamento;jors;management science;infrastructure;stochastic flows;logistica;transport maritime	Reducing transit time is becoming increasingly important in maritime shipping of manufactured goods and commodities. Traversing the Panama Canal is a principal component of many global companies’ strategies to reduce shipping time in their supply chain. Operations in the Panama Canal can be described by a capacitated queueing network. In this study we used a metaheuristic approach based on Nested Partitions to find near optimal schedules for daily vessel traffic consisting of large vessels that want to pass through the Panama Canal. Results indicate that the metaheuristic technique consistently reduced the makespan of a set of vessels as compared to historical schedules used in canal operations. We also found distinct patterns in the schedules in which certain vessels consistently appeared at a certain position in the schedule.	flow shop scheduling;scheduling (computing)	J. Jackman;Z. Guerra de Castillo;S. Ólafsson	2011	JORS	10.1057/jors.2009.188	partition;stochastic programming;project management;logistics;simulation;inventory;economics;forecasting;investment;computer science;graph theory;marketing;operations management;reliability;mathematics;location;operations research;information technology;scheduling;principal component analysis	EDA	17.510344330534615	5.5650644240782094	106500
5a982ba6fe8f0e78f7cd7bc37de7b5576f8514f8	fully polynomial approximation schemes for locating a tree-shaped facility: a generalization of the knapsack problem	graph theory;probleme sac a dos;teoria grafo;knapsack problems;complexite calcul;optimization method;problema mochila;theorie graphe;metodo optimizacion;knapsack problem;complejidad computacion;aproximacion polinomial;computational complexity;tree shaped facility;approximation polynomiale;methode optimisation;polynomial approximation;facility location	Abstract   Given an  n -node tree  T  = ( V , E ), we are concerned with the problem of selecting a subtree of a given length which optimizes the sum of weighted distances of the nodes from the selected subtree. This problem is NP-hard for both the minimization and the maximization versions since it generalizes the knapsack problem. We present fully polynomial approximation schemes which generate a (1 +  e )-approximation and a (1 −  e )-approximation for the minimization and maximization versions respectively, in   O  (  n     2   g3  )   time.	approximation;knapsack problem;polynomial	Arie Tamir	1998	Discrete Applied Mathematics	10.1016/S0166-218X(98)00059-6	continuous knapsack problem;mathematical optimization;combinatorics;discrete mathematics;graph theory;facility location problem;mathematics;computational complexity theory;knapsack problem;algorithm	Theory	22.341869563393978	14.14412234726449	106533
d446619e42f2f43ae31755e410bf5de3cb5e54c0	job shop schedules analysis in the context of industry 4.0		Industry 4.0 is announced as a fourth industrial revolution. The next level of evolution will comprehend the wide spread inclusion of machines sensors and big data analytics. Enterprise Resource Planning and Manufacturing Execution Systems will be the information management tools for the revolution. Different forms of optimization will be in the brink of development to answer this revolution needs. In this paper is proposed a model for solving a classical job shop scheduling problem, which is NP-hard in the strong sense. For accomplishing this, a test problem is run to evaluate the difference between the performance of Shifting Bottleneck Heuristic (SBH) and some dispatching rules, such as First Come First Served (FCFS), Earliest due Date (EDD), and Shortest Processing Time (SPT). The evaluation criteria used were the makespan (Cmax) and the total weighted tardiness (TWT). The results did show that the SBH outperforms the dispatching rules, although the computation time turns out to be considerable higher.	big data;computation;enterprise resource planning;hall-effect thruster;heuristic;industry 4.0;information management;job shop scheduling;makespan;manufacturing execution system;mathematical optimization;scheduling (computing);sensor;single-machine scheduling;time complexity	R. A. Sousa;Maria Leonilde R. Varela;C. Alves;J. Machado	2017	2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)	10.1109/ICE.2017.8279955	shifting bottleneck heuristic;operations management;manufacturing execution system;job shop scheduling;job shop;big data;enterprise resource planning;industry 4.0;schedule;computer science	Robotics	14.520642419762634	8.762443850662233	106591
07030be38396ed8b7dbe44ab306b188c975761ba	a linear programming based satisfiability solver using a new horn-driven search tree design	satisfiability;search trees;binary search tree;constraint programming;linear program;integer program	We will present an algorithm for the satisfiability problem, which finds its origin in the Integer Programming area, and therefore will also generalize to more general constraint programming problems. This algorithm is based on single-lookahead unit resolution ([2]), linear programming and a new search tree design based on a tree design by ([1]). The special aspect of the tree is that it is not a binary search tree. The advantage of our algorithm over a standard integer programming approach, is that we need to solve a linear program only in a very limited number of nodes in the search tree. In every node in the search tree we first apply single-lookahead unit resolution. The unit propagation algorithm we used in our implementation is based on the watched literal strategy. Only in case the unit resolution does not lead to the conclusion that the formula in the node is unsatisfiable or has a satisfying assignment, we solve a linear program. The solution of the linear program is used to split the part of the search into subparts. This splitting aims for getting a formula close to a Horn formula.	boolean satisfiability problem;linear programming;search tree;solver	Linda van Norden;Hans van Maaren	2002		10.1007/3-540-46135-3_71	optimal binary search tree;cartesian tree;mathematical optimization;constraint programming;discrete mathematics;binary search tree;integer programming;constraint satisfaction;linear-fractional programming;binary tree;computer science;linear programming;order statistic tree;self-balancing binary search tree;k-d tree;mathematics;ternary search tree;programming language;tree traversal;algorithm;dichotomic search;satisfiability;search algorithm	AI	24.202374471506474	12.771157463728972	107024
f1501e081929089615e522580539ba40f54ee9c4	rescheduling for multiple new orders	deterministic scheduling;branch and bound algorithm;rescheduling for new job disruptions;heuristic worst case analysis	Aset of original jobs has been scheduled on a single machine, but not processed, when a set of new jobs arrives. The decision maker needs to insert the new jobs into the existing schedule without excessively changing it. The objective is minimization of the maximum lateness of the jobs, subject to a customer service requirement modeled by a limit on the maximum time change of the original jobs. Because the schedule of the original jobs can be arbitrary, this problem models multiple disruptions from repeated new job arrivals. We show that this scheduling problem is intractable, even if no new jobs arrive. We describe several approximation algorithms and analyze their worst-case performance. Next, we develop a branch and bound algorithm that uses a variable neighborhood descent algorithm to obtain an initial upper bound, several dominance properties that we establish, and a lower bounding scheme based on a preemptive relaxation of the problem. The branch and bound algorithm solves 99.9% of randomly generated instances with up to 1,000 jobs within 60 CPU seconds. Our work demonstrates for the first time that optimization of large scale, intractable rescheduling problems is possible. More generally, it refocuses the literature on scheduling problems towards rescheduling issues.		Nicholas G. Hall;Zhixin Liu;Chris N. Potts	2007	INFORMS Journal on Computing	10.1287/ijoc.1060.0209	mathematical optimization;computer science;mathematics;distributed computing;branch and bound	Theory	15.585659360984025	8.786762543557353	107120
0fe1eea7ff1d5d142e95e9bf6787d0cbfedf4f66	preemptive job-shop scheduling problems with a fixed number of jobs	complexite;complejidad;problema np duro;reducibility;complexity;reductibilidad;algorithme pseudopolynomial;fonction objectif;objective function;np hard problem;key words job shop problem;ordonancement prehentif;probleme np difficile;scheduling;funcion objetivo;job shop;ordonamiento;np hard;job shop scheduling problem;probleme n travaux sur m machines;ordonnancement;reductibilite	It is shown that the two machine preemptive job-shop problem with mean  ̄ow-time or makespan objective function and three jobs is NP-hard. This contrasts the fact that the nonpreemptive versions of these problems are polynomially solvable if the number of jobs is arbitrary but ®xed. It is also shown that the preemptive problems can be solved pseudopolynomially if both the number of machines and the number of jobs is ®xed.	decision problem;job stream;loss function;makespan;optimization problem;scheduling (computing)	Peter Brucker;Svetlana A. Kravchenko;Yuri N. Sotskov	1999	Math. Meth. of OR	10.1007/PL00020906	mathematical optimization;np-hard;mathematics;algorithm	Theory	17.146161473515694	10.405290457698424	107175
6a2270fd8302b6a847253a0f5d8ab6bbf928cdc0	a variable neighbourhood search algorithm for the constrained task allocation problem	forecasting;fixed cost;reliability;project management;information systems;algoritmo busqueda;costo fijo;heuristica;maintenance;jornada anualizada;algorithme recherche;qa mathematics;cout fixe;soft or;information technology;search algorithm;packing;recherche voisinage;operations research;location;investment;journal;journal of the operational research society;quartier voisinage;inventory;optimisation combinatoire;busca local;purchasing;busqueda local;history of or;task allocation problem;assignacio de tasques;logistics;busqueda en entornos variables;marketing;scheduling;cerca en entorns variables;production;coaccion capacidad;communications technology;variable neighbourhood search;contrainte capacite;heuristics;cerca local;computer science;operational research;external research report;combinatorial optimization;capacity constraint;neighborhood search;local search;article;barrio vecindad;jornada anualitzada;recherche locale;applications of operational research;or society;busqueda de cercania;jors;management science;infrastructure;task allocation;optimizacion combinatoria;residential neighborhoods;asignacion de tareas	A Variable Neighbourhood Search algorithm is proposed for solving a task allocation problem whose main characteristics are: (i) each task requires a certain amount of resources and each processor has a finite capacity to be shared between the tasks it is assigned; (ii) the cost of solution includes fixed costs when using processors, assigning costs and communication costs between tasks assigned to different processors. A computational experiment shows that the algorithm is satisfactory in terms of time and solution quality.	central processing unit;computation;search algorithm;variable neighborhood search	Amaia Lusa;C. N. Potts	2008	JORS	10.1057/palgrave.jors.2602413	project management;logistics;simulation;inventory;economics;forecasting;combinatorial optimization;investment;computer science;local search;marketing;operations management;heuristics;reliability;mathematics;location;operations research;information technology;scheduling;fixed cost;search algorithm	AI	17.88848214600127	5.360851813328396	107178
cd0671eb79075918225bf3cd23e66d12b805c89f	memory management optimization problems for integrated circuit simulators	minimisation;arbre graphe;directed acyclic graph;graph ordering;grafo aciclico;cycle time;complexite;memoire;minimization;optimisation;temps cycle;combinatorics;memory management;comportement;digraph;modele mathematique;temps polynomial;51e24;optimizacion;cost function;integrated circuit;gestion;tree graph;procedimiento;05bxx;05c05;probleme np complet;combinatoria;relacion orden;simulation;complejidad;combinatoire;65kxx;digrafo;ordering;conception;graphe acyclique;simulacion;optimization method;tiempo acceso;circuito integrado;correspondence problem;minimizacion;05c20;modelo matematico;complexity;metodo optimizacion;funcion coste;acyclic graph;49xx;optimization problem;memory access;relation ordre;memoria;integrated circuit simulation;conducta;informatique theorique;directed graph;68r10;graphe oriente;polynomial time;methode optimisation;diseno;mathematical model;fonction cout;hardware design;temps acces;design;grafo orientado;problema np completo;optimization;code;behavior;arbol grafo;management;performance optimization;codigo;circuit integre;memory;np complete problem;access time;procedure;computer theory;tiempo polinomial;informatica teorica;digraphe	In hardware design, it is necessary to simulate the anticipated behavior of the integrated circuit before it is actually cast in silicon. As simulation procedures are long due to the great number of tests to be performed, optimization of the simulation code is of prime importance. This paper describes two mathematical models for the minimization of the memory access times for a cycle-based simulator. An integrated circuit being viewed as a directed acyclic graph, the problem consists in building a graph order on the vertices, compatible with the relation order induced by the graph, in order to minimize a cost function that represents the memory access time. For the two proposed cost functions, we show that the two corresponding problems are NP-complete. However, we show that the special cases where the graphs are in-trees or out-trees can be solved in polynomial time.	access time;cas latency;combinatorial optimization;directed acyclic graph;evaluation function;heuristic (computer science);integrated circuit;karp's 21 np-complete problems;loss function;mathematical model;mathematical optimization;memory management;operating system;polynomial;randomized algorithm;simulation;time complexity	Timothée Bossart;Alix Munier Kordon;Francis Sourd	2007	Discrete Applied Mathematics	10.1016/j.dam.2007.03.019	combinatorics;directed graph;artificial intelligence;mathematics;directed acyclic graph;algorithm;closure problem	EDA	20.820280780676885	12.690170353429824	107216
fb001769dff33bfd8376aced5a222d68c05c807c	a note on solutions to the maximal expected covering location problem	location problem;travel time;covering location problems;objective function;hypercube queueing model;queueing model;maximal expected coverage	The maximal expected covering location problem (MEXCLP) and its adjusted counterpart (AMEXCLP) compute expected coverage arising only from unqueued calls, whereas the interactive use of the hypercube queueing model (HQM) considers both unqueued and queued calls in this computation. In this note we show that the three models are not strictly comparable because of the structural di=erences in their objective functions and that, when using HQM, it is important to state clearly the factor being used to express traveling time in terms of service time units.	computation;linear programming relaxation;maximal set;queueing theory;server (computing);terms of service	Fernando Y. Chiyoshi;Roberto D. Galvão;Reinaldo Morabito	2003	Computers & OR	10.1016/S0305-0548(01)00083-1	mathematical optimization;combinatorics;mathematics	Theory	21.309386561403805	15.485192036514018	107271
70c1d0a558c2dec26e809db81359579d15e8d191	on the power of advice and randomization for online bipartite matching	n line algorithms;004;bipartite matching;randomization;on line algorithms bipartite matching randomization	While randomized online algorithms have access to a sequence of uniform random bits, deterministic online algorithms with advice have access to a sequence of advice bits, i.e., bits that are set by an all-powerful oracle prior to the processing of the request sequence. Advice bits are at least as helpful as random bits, but how helpful are they? In this work, we investigate the power of advice bits and random bits for online maximum bipartite matching (MBM). The well-known Karp-Vazirani-Vazirani algorithm [24] is an optimal randomized (1− 1 e )-competitive algorithm for MBM that requires access to Θ(n logn) uniform random bits. We show that Ω(log( 1 )n) advice bits are necessary and O( 1 5 n) sufficient in order to obtain a (1 − )-competitive deterministic advice algorithm. Furthermore, for a large natural class of deterministic advice algorithms, we prove that Ω(log log logn) advice bits are required in order to improve on the 1 2 -competitiveness of the best deterministic online algorithm, while it is known that O(logn) bits are sufficient [9]. Last, we give a randomized online algorithm that uses cn random bits, for integers c ≥ 1, and a competitive ratio that approaches 1 − 1 e very quickly as c is increasing. For example if c = 10, then the difference between 1 − 1 e and the achieved competitive ratio is less than 0.0002.	carrier-to-noise ratio;competitive analysis (online algorithm);mbm (file format);matching (graph theory);online algorithm;randomized algorithm;whole earth 'lectronic link	Christoph Dürr;Christian Konrad;Marc P. Renault	2016		10.4230/LIPIcs.ESA.2016.37	randomization;combinatorics;bipartite graph;theoretical computer science;mathematics;algorithm;statistics	Theory	17.28835543109583	15.377396807520476	107379
677edfe39dba84b48ae53f48959e7ca29fa2f4fa	the over-constrained airport gate assignment problem	assignment problem;transportes;probleme affectation;algorithme glouton;heuristic method;metodo heuristico;air transportation;simulated annealing;transports;transport aerien;transporte aereo;recuit simule;transportation;greedy algorithm;problema asignacion;algoritmo gloton;recocido simulado;tabu search;methode heuristique;airlines;busqueda tabu;recherche tabou	In this paper, we study the over-constrained airport gate assignment problem where the objectives are to minimize the number of ungated 4ights and total walking distances or connection times. We 7rst use a greedy algorithm to minimize ungated 4ights. Exchange moves are employed to facilitate the use of heuristics. Simulated annealing and a hybrid of simulated annealing and tabu search are used. Experimental results are good and exceed those previously obtained. ? 2003 Elsevier Ltd. All rights reserved.	assignment problem;greedy algorithm;heuristic (computer science);simulated annealing;tabu search	Hang Ding;Andrew Lim;Brian Rodrigues;Yi Zhu	2005	Computers & OR	10.1016/j.cor.2003.12.003	transport;mathematical optimization;greedy algorithm;simulated annealing;tabu search;computer science;mathematics;assignment problem;operations research;aviation	AI	19.425954713222723	6.418536675391155	107528
1593077022a87b59efed4ea3b1f5a23d1b61dc5b	multiobjective optimization models and solution methods for planning land development using minimum spanning trees, lagrangian relaxation and decomposition techniques	dissertation	Title: MULTIOBJECTIVE OPTIMIZATION MODELS AND SOLUTION METHODS FOR PLANNING LAND DEVELOPMENT USING MINIMUM SPANNING TREES, LAGRANGIAN RELAXATION AND DECOMPOSITION TECHNIQUES José Alberto Faria, Doctor of Philosophy, 2005 Directed By: Professor Steven A. Gabriel Department of Civil and Environmental Engineering and Applied Mathematics and Scientific Computation Program University of Maryland The land development problem is presented as the optimization of a weighted average of the objectives of three or more stakeholders, subject to develop within bounds residential, industrial and commercial areas that meet governmental goals. The work is broken into three main sections. First, a mixed integer formulation of the problem is presented along with an algorithm based on decomposition techniques that numerically has proven to outperform other solution methods. Second, a quadratic mixed integer programming formulation is presented including a compactness measure as applied to land development. Finally, to prevent the proliferation of sprawl a new measure of compactness that involves the use of the minimum spanning tree is embedded into a mixed integer programming formulation. Despite the exponential number of variables and constraints required to define the minimum spanning tree, this problem was solved using a hybrid algorithm developed in this research. MULTIOBJECTIVE OPTIMIZATION MODELS AND SOLUTION METHODS FOR PLANNING LAND DEVELOPMENT USING MINIMUM SPANNING TREES, LAGRANGIAN RELAXATION AND DECOMPOSITION TECHNIQUES	computation;computational science;embedded system;file spanning;hybrid algorithm;integer programming;land;lagrangian relaxation;linear programming;mathematical optimization;minimum spanning tree;multi-objective optimization;numerical analysis;relaxation (approximation);time complexity	Jose Alberto Faria	2005			mathematical optimization;simulation;machine learning	ML	19.057598215208806	4.210354269837149	107638
3423249ee953882f412137c31f53e6549131cdc3	a tabu search algorithm for parallel machine total tardiness problem	parallel machine scheduling;setup time;tabu search algorithm;scheduling;total tardiness problem;parallel machines;tabu search;sequence dependent setup times	In this study, a Tabu Search (TS) approach to the parallel machine scheduling problem is presented. The problem considered consists of a set of independent jobs to be scheduled on a number of parallel processors to minimize total tardiness. Several surveys on parallel machine scheduling with due date related objectives [1, 2, 3] reveal that the NP-hard nature of the problem renders it a challenging area for many researchers who studied various versions. However, most of these studies have the assumption that jobs are available at the beginning of the scheduling period, which is an important deviation form reality. Here, as well as distinct due dates and ready times, features such as sequence dependent setup times and different processing rates for machines are incorporated into the classical model. These enhancements approach the model to the actual practice at the expense of complicating the problem further. The motivation of this study has been to explore the ability of Tabu Search to overcome these difficulties superimposed on the traditional parallel machine scheduling problem. In order to obtain a robust search mechanism, several key components of TS such as candidate list strategies, tabu classifications, tabu tenure and intensification/diversification strategies are investigated. Alternative approaches to each of these issues are developed and extensively tested on a set of problems obtained from the literature. Considerably better results are obtained and the success of the totally deterministic TS algorithm implemented is thereby demonstrated.	central processing unit;diversification (finance);job stream;np-hardness;parallel computing;rendering (computer graphics);scheduling (computing);search algorithm;tabu search	Ümit Bilge;Furkan Kiraç;Müjde Kurtulan;Pelin Pekgün	2004	Computers & OR	10.1016/S0305-0548(02)00198-3	mathematical optimization;real-time computing;tabu search;computer science;mathematics;scheduling;guided local search	AI	15.839196342417848	7.610136282574592	107707
de0320dd7413e77b941f8a4089a906f0a25cdb2d	semidefinite relaxation bounds for bi-quadratic optimization problems with quadratic constraints	bi quadratic optimization;approximate algorithm;random polynomials;90c26;90c59;15a69;bi quadratic optimizationsemidefinite programming relaxationapproximation solutionprobabilistic solution15a6990c2290c2690c5;journal;approximation solution;approximate solution;quadratic optimization;90c22;semidefinite programming relaxation;semidefinite relaxation;probabilistic solution;semidefinite program	This paper studies the relationship between the so-called bi-quadratic optimization problem and its semidefinite programming (SDP) relaxation. It is shown that each r -bound approximation solution of the relaxed bi-linear SDP can be used to generate in randomized polynomial time an O(r)-approximation solution of the original bi-quadratic optimization problem, where the constant in O(r) does not involve the dimension of variables and the data of problems. For special cases of maximization model, we provide an approximation algorithm for the considered problems.	approximation algorithm;expectation–maximization algorithm;lagrangian relaxation;linear programming relaxation;mathematical optimization;optimization problem;polynomial;quadratic programming;rp (complexity);randomized algorithm;semidefinite programming;time complexity	Xinzhen Zhang;Chen Ling;Liqun Qi	2011	J. Global Optimization	10.1007/s10898-010-9545-5	mathematical optimization;combinatorics;discrete mathematics;mathematics;quadratic programming	Theory	22.923066588242627	14.997328589023564	107719
2d9afb91113f64370594916169f89598bafcd226	an efficient polynomial-time approximation scheme for the joint replenishment problem	similar technique;constant size capacity;joint replenishment problem;efficient polynomial-time approximation scheme;non-stationary demand;capacitated jrp;stationary demand	We give an efficient polynomial-time approximation scheme (EPTAS) for the Joint Replenishment Problem (JRP) with stationary demand. Moreover, using a similar technique, we give a PTAS for the capacitated JRP with non-stationary demand but constant size capacities.	ptas reduction;polynomial;polynomial-time approximation scheme;stationary process;time complexity	Tim Nonner;Maxim Sviridenko	2013		10.1007/978-3-642-36694-9_27	mathematical optimization;real-time computing;mathematical economics	Theory	17.563016725923962	12.8104844040081	107724
b397761b0242a5d77a0ac19178856be9b6dbc1f1	robust optimization for the connected facility location problem	heuristic;robust optimization	Abstract In this paper we present a robust optimization (RO) model for the Connected Facility Location (ConFL) problem within the framework introduced by Bertsimas and Sim [Bertsimas, D. and M. Sim, Robust discrete optimization and network flows , Mathematical Programming 98 (2003), pp. 49–71], and show how to use a heuristic in conjunction with a lower bounding mechanism to rapidly find high-quality solutions. The use of a heuristic and a lower bound mechanism within this RO approach decreases significantly its computational time and broadens its applicability to other NP-hard problems. Here we present some of our computational results that attest to the efficiency of the approach, particularly on the Robust ConFL problem.	facility location problem;robust optimization	M. Gisela Bardossy;S. Raghavan	2013	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2013.10.023	mathematical optimization;machine learning;mathematics;mathematical economics	Theory	21.5149399708894	10.174926276674892	107753
406444d33ed4f728d9d8b7c3ddd32b1908487eab	many hard examples in exact phase transitions	hamiltonian cycle;complexite;comportement;probleme np complet;cycle hamiltonien;complejidad;complexity;constraint satisfaction;cnf;algorithme;sat;algorithm;satisfaction contrainte;random problem;phase transition;ciclo hamiltoniano;conducta;constraint satisfaction problem csp;modele comparaison;transition phase;probleme satisfaction contrainte;phase transitions;resolution complexity;transicion fase;problema np completo;csp;constraint satisfaction problem;experimental evaluation;satisfaccion restriccion;behavior;existence;random problems;probleme aleatoire;np complete problem;algoritmo	This paper analyzes the resolution complexity of two random CSP models (i.e. Model RB/RD) for which we can establish the existence of phase transitions and identify the threshold points exactly. By encoding CSPs into CNF formulas, it is proved that almost all instances of Model RB/RD have no tree-like resolution proofs of less than exponential size. Thus, we not only introduce new families of CSPs and CNF formulas hard to solve, which can be useful in the experimental evaluation of CSP and SAT algorithms, but also propose models with both many hard instances and exact phase transitions. Finally, conclusions are presented, as well as a detailed comparison of Model RB/RD with the Hamiltonian cycle problem and random 3-SAT, which, respectively, exhibit three different kinds of phase transition behavior in NP-complete problems.	algorithm;boolean satisfiability problem;conjunctive normal form;cryptographic service provider;hamiltonian path problem;karp's 21 np-complete problems;ruby document format;time complexity	Ke Xu;Wei Li	2006	Theor. Comput. Sci.	10.1016/j.tcs.2006.01.001	phase transition;combinatorics;computer science;calculus;mathematics;algorithm	AI	11.482628216361286	18.223439243384473	107958
c5a3ef38061d89c357957c9aafc5c756e9570f09	updating paths in time-varying networks given arc weight changes	camino mas corto;transportation network;shortest path;shortest paths;stochastic networks;optimisation;time varying;advanced driver information systems;systeme intelligent;red transporte;transportes;reoptimization;travel time;optimizacion;routing;intelligent transportation systems;sistema inteligente;routage;plus court chemin;real time information;methode calcul;shortest path algorithms;dynamical system;stochastic system;algorithme;metodo calculo;resolucion problema;systeme dynamique;transports;algorithm;optimal routing;transportation;advanced traffic management systems;intelligent system;optimization;sistema dinamico;sistema estocastico;weight change;experimentation;computing method;systeme stochastique;dynamic networks;problem solving;resolution probleme;experimentacion;reseau transport;algoritmo;enrutamiento	Many transportation applications, including applications in intelligent transportation systems, require the solution of a series of shortest path problems in which only the travel time along a set of arcs of the network change from one problem instance to the next. One could use an existing path algorithm to solve each problem instance independently as it arises. However, significant savings in computation time can often be achieved through the use of a reoptimization algorithm that would begin from the prior solution in determining the updated optimal solution for the given arc travel-time changes. Such quick solution is critical for providing routing instructions to travelers in real time as travel-time information is retrieved from the traffic network. Numerous works have presented reoptimization techniques for use in updating shortest path trees in deterministic and static networks; however, it appears that no reoptimization technique exists in the literature for updating paths where future travel times in time-varying networks change. In this paper, such procedures are proposed. The proposed techniques can provide updated solutions given simultaneous and arbitrary changes (increasing and decreasing in value) in any number of network arcs. Further, this technique can be extended for use in stochastic networks.	time-varying network	Elise Miller-Hooks;Baiyu Yang	2005	Transportation Science	10.1287/trsc.1040.0112	mathematical optimization;simulation;computer science;artificial intelligence;mathematics;shortest path problem;algorithm	Theory	20.766185986125905	7.928206448258137	108047
0c8941493fb6106aab7464f017d69194df0371cd	two machine preemptive scheduling problem with release dates, equal processing times and precedence constraints	preemptive scheduling;machine parallele;processing time;constrenimiento precedencia;open shop;identical parallel machines;scheduling;scheduling theory;precedence constraint;contrainte precedence;scheduling problem;temps traitement;parallel machines;tiempo proceso;ordonnancement;reglamento	We consider a scheduling problem with two identical parallel machines and n jobs. For each job we are given its release date when job becomes available for processing. All jobs have equal processing times. Preemptions are allowed. There are precedence constraints between jobs which are given by a (di)graph consisting of a set of outtrees and a number of isolated vertices. The objective is to find a schedule minimizing mean flow time. We suggest an O(n) algorithm to solve this problem. The suggested algorithm also can be used to solve the related two-machine open shop problem with integer release dates, unit processing times and analogous precedence constraints. 2004 Elsevier B.V. All rights reserved.	algorithm;job stream;open-shop scheduling;preemption (computing);scheduling (computing);software release life cycle	Irene N. Lushchakova	2006	European Journal of Operational Research	10.1016/j.ejor.2004.08.037	job shop scheduling;real-time computing;flow shop scheduling;computer science;operations management;distributed computing;preemption;scheduling	Theory	16.240758756578035	9.98894441122217	108126
deddcfea5f0a1a03ca1e8c39af1fa26bfd63969d	solution of the liu-layland problem via bottleneck just-in-time sequencing	periodic scheduling;apportionment problem;the liu layland problem;hard real time system;just in time sequencing;scheduling problem;just in time;hard real time systems	This paper proposes a new approach to the well known LiuLayland periodic scheduling problem. This approach proves that any justin-time sequence with maximum absolute deviation being less than one is in fact a periodic schedule. Consequently, periodic schedules can be obtained by any algorithm capable of generating just-in-time sequences with maximum absolute deviation being less than one, for instance, any algorithm minimizing maximum deviation or the quota methods of apportionment.	algorithm;just-in-time compilation;justin (robot);schedule (computer science);scheduling (computing);time series;whole earth 'lectronic link	Wieslaw Kubiak	2005	J. Scheduling	10.1007/s10951-005-1638-5	job shop scheduling;mathematical optimization;real-time computing;computer science;mathematics	AI	15.911459693023279	9.148465010565547	108141
47f17346f727dd8976c961e67060667ecb3781e4	solving 0/1 integer programs with enumeration cutting planes	cutting plane;numbers;cutting;computations;real world application;integer programming;linear programming relaxation;linear programming;communications networks;relaxation;integer program;branch and bound	A cutting plane technique with applicability to the solution of integer programs is presented. The computational value of this technique is demonstrated by applying it to a collection of seven difficult integer programs arising from real-world applications. Four of the seven problems are solved to optimality without the aid of branch and bound, and six of the seven problems have the gap between the value of the integer program and its linear programming relaxation closed by over 98%.	linear programming	E. Andrew Boyd	1994	Annals OR	10.1007/BF02085635	mathematical optimization;combinatorics;discrete mathematics;integer overflow;integer programming;nearest integer function;linear programming;linear programming relaxation;branch and price;computation;relaxation;integer points in convex polyhedra;mathematics;cutting;branch and bound;branch and cut;cutting-plane method	Logic	24.18902410113332	11.620267837513326	108406
1692ea6d224b48f15201e8ad19027aab4144464f	study on optimization potential influencing factors in simulation studies focused on parallel batch machine scheduling using variable neighbourhood search	batch processing (industrial);job shop scheduling;optimisation;search problems;semiconductor device manufacture;simulation;vns;critical time bound;industrial application;job families;minimal batch size constraint;model characteristics;model constraint;operational lot scheduling;optimization potential influencing factor;parallel batch machine scheduling problem;process dedication scheme;queuing time;semiconductor manufacturing;simulation;tardiness;time window decomposition;variable neighbourhood search	Studies on operational lot scheduling in semiconductor manufacturing show significantly varying optimization potentials, depending on a multitude of factors relating to methods and models in simulation. We present experiments examining Variable Neighbourhood Search (VNS) used to improve the objectives queuing time and tardiness for the parallel batch machine scheduling problem. The discussed results incorporate the effects of specific model characteristics and constraints, namely incompatible job families, process dedication schemes, critical time bounds, and minimal batch size constraints among others. With regard to methodical factors, we examine the effect of time window decomposition on simulation results, and we discuss fundamental VNS settings, respectively their influence on improvements measured for problem instances of size relevant for industrial applications. This study intends to identify important factors in scheduling studies and evaluates their influence on optimization potentials based on extensive experiments.	experiment;mathematical optimization;scheduling (computing);semiconductor device fabrication;simulation;window function	Robert Kohn;Oliver Rose	2012	Proceedings Title: Proceedings of the 2012 Winter Simulation Conference (WSC)		fair-share scheduling;job shop scheduling;mathematical optimization;real-time computing;simulation;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;job scheduler;two-level scheduling;scheduling;round-robin scheduling	HPC	15.514252497506028	8.109929218314784	108909
be112b530a1d85df6e9f526f5944a2dbf6b800a9	scheduling the professional ecuadorian football league by integer programming	torneo;modelizacion;programacion entera;methode empirique;tournament;economic sciences;metodo empirico;heuristic method;empirical method;metodo heuristico;programmation en nombres entiers;deporte equipo;modelisation;sport equipe;ciencias economicas;integer programming;mathematical programming;scheduling;football;tournoi;sports scheduling;sciences economiques;methode heuristique;integer programming models;modeling;programmation mathematique;programacion matematica;team sport;ordonnancement;reglamento	A sports schedule sets the dates and venues of games among teams in a sports league. Constructing a sports schedule is a highly restrictive problem. The schedule must meet constraints due to regulations of a particular sports league federation and it must guarantee the participation of all teams on equal terms. Moreover, economic benefits of the teams and other agents involved in this activity are expected. Until 2011, the Ecuadorian football federation (FEF) had developed schedules for their professional football championship manually. In early 2011, the authors presented to the FEF authorities evidence that the use of mathematical programming to create feasible sports schedules could easily exceed the benefits obtained by the empirical method. Under this premise, this work presents an integer programming formulation, solved to optimality, for scheduling the professional football league in Ecuador, and also a heuristic approach based on three-phases for its solution. The schedules obtained met the expectations of the FEF and one of them was adopted as the official schedule for the 2012 edition of the Ecuadorian professional football championship.		Diego Recalde;Ramiro Torres;Polo Vaca	2013	Computers & OR	10.1016/j.cor.2012.12.017	mathematical optimization;simulation;systems modeling;integer programming;computer science;mathematics;empirical research;operations research;scheduling;tournament	NLP	17.44379116865679	6.474463797795723	108949
3bbfa107f75a382b4eb7b6d5be9a6b05f45214b8	a heuristic to determine equipment setup changes based on estimated lot arrivals in a semiconductor fab	heuristic programming;production equipment;production management;semiconductor device manufacture;semiconductor devices;equipment setup changes;equipment utilization;estimated arrival times;estimated lot arrivals;heuristic algorithm;low volume products;product queue times;semiconductor fab;semiconductor industry	Certain classes of tools used in the semiconductor industry require the tools to be setup differently in order to process different types of products. In cases of large setup times, it is important to minimize the number of setup changes in order to improve the overall equipment utilization. Minimizing the number of setup changes needs to be balanced with the restriction on the product queue times. Further, it is important that the cycle time of low volume products is not penalized in order to improve equipment utilization. This article presents a heuristic algorithm to determine the setup for each tool in a workstation based on the estimated arrival times of different products at the workstation. The approach described here takes into account the number of tools, their capability, and the expected workload for each setup over a predetermined horizon. The heuristic is independent of the product mix released into the line.	algorithm;heuristic (computer science);semiconductor fabrication plant;semiconductor industry;workstation	Raja Sunkara;Ramesh R. Rao	2004	Proceedings of the 2004 Winter Simulation Conference, 2004.		heuristic;real-time computing;simulation;semiconductor device;cycle time variation;engineering	HPC	10.577975724271932	4.382645887804955	109225
110561e0a5554b67b60c93093f58564708a810a4	a stochastic programming approach to scheduling in tac scm	optimal solution;combinatorial optimization problem;look ahead;online optimization;probabilistic model;expected value;optimal scheduling;trading agent competition;optimization;sample average approximation;stochastic programming;supply chain management	In this paper, we combine two approaches to handling uncertainty: we use techniques for finding optimal solutions in the expected sense to solve combinatorial optimization problems in an online setting. The problem we address is the scheduling component of the Trading Agent Competition in Supply Chain Management (TAC SCM) problem, a combinatorial optimization problem with inherent uncertainty (see www.sics.se/tac/). This problem is formulated as a stochastic program, and is solved using the sample average approximation (SAA) method in an online setting to find today's optimal schedule, given probabilistic models of the future. This optimization procedure forms the heart of Botticelli, one of the finalists in the TAC SCM 2003 competition. Two sets of experiments are described, using one and two days' worth of information about the future. In the two day experiments (using one day's worth of information about the future), it is shown that SAA outperforms the expected value method, which solves a deterministic variant of the problem assuming all stochastic inputs have deterministic values equal to their expected values. In the three day experiments (using two days' worth of information about the future), it is shown that SAA with look ahead outperforms greedy SAA. This approach generalizes to N days of lookahead, and since the problem setting is one of online optimization, the benefits of two day lookahead accrue rapidly.	approximation;combinatorial optimization;experiment;greedy algorithm;mathematical optimization;online optimization;optimization problem;parsing;scheduling (computing);stochastic programming	Michael Benisch;Amy Greenwald;Victor Naroditskiy;Michael Carl Tschantz	2004		10.1145/988772.988796	stochastic programming;optimization problem;statistical model;mathematical optimization;supply chain management;simulation;computer science;artificial intelligence;operations management;machine learning;mathematics;mathematical economics;algorithm;expected value;statistics	ECom	13.717653130773433	7.85512889622959	109304
359f723a82100a87a83130f20e29caf7e85d9216	on different approximation criteria for subset product problems	optimisation;algorithm analysis;optimizacion;complexite calcul;computing complexity;approximation;probleme combinatoire;optimization;analyse algorithme;combinatory problem	The aim of this paper is to study the approximation properties of a class of optimization problems whose feasible solutions are sets of objects that verify a property testable in polynomial time. This class contains many combinatorial problems with different characteristics of complexity. For example, the minimum spanning tree problem consists in finding in a weighted graph the set of arcs that connects all the nodes and has minimum weight. The approximation properties of the NPhard problems belonging to this class have been extensively studied by many authors [1,2,5,6]. In this paper we study necessary and sufficient conditions for different approximation criteria applied to subset problems with product objective function.	approximation theory;file spanning;mathematical optimization;minimum spanning tree;minimum weight;optimization problem;polynomial;time complexity	Alberto Marchetti-Spaccamela;G. Romano	1985	Inf. Process. Lett.	10.1016/0020-0190(85)90061-4	mathematical optimization;combinatorics;approximation;mathematics;l-reduction;algorithm	Theory	23.012376476227555	14.420899324469191	109574
2ceffce786ea48072a3731840e8a4b1a2884934e	a new algorithm approach to the general lovász local lemma with applications to scheduling and satisfiability problems (extended abstract)	satisfiability;njit	"""The LovAsz Local Lemma (LLL) is a powerful tool tha t is increasingly playing a valuable role in computer science. It has led to solutions for numerous problems in many different areas, reaching from problems in pure combinatorics to problems in routing, scheduling and approximation theory. However, since the original lemma is non-constructive, many of these solutions were first purely existential. A breakthrough result by Beck and its generalizations have led to polynomial t ime algorithms for many ~f these problems. However, these methods can only be applied to a simple, symmetric form of the LLL. In this paper we provide a novel approach to design polynomialt ime algorithms for problems tha t require the LLL in its general form. We apply our techniques to find good approximate solutions to a large class of NP-hard problems called minimax integer programs (MIPs). Our method finds approximate solutions tha t are especially for problems of non-uniform character significantly bet ter than all methods presented before. To demonstrate the applicability of our approach, we apply it to transform important results in the area of job shop scheduling tha t have so far been only existential (due to the fact tha t the general LLL was used) into algorithms tha t find the predicted solutions (with only a small loss) in polynomial time. Fhrthermore, ¢Work par t ly done while the author was with Heinz Nixdorf Inst i tute and Depar tment of Mathematics and Computer Science at the Paderborn University, Germany. *Research part ial ly suppor ted by DFG-Sonderforschungsbereich 376 """"Massive Parallelit/it: Algorithmen, Entwurfsmethoden, Anwendungen."""" tSee w~w.upb, d e / c s / c h r s c h . h t r a l for a full version of this paper. Permission to make digital or hard copies ofali or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the lull citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. STOC 2000 Portland Oregon USA Copyright ACM 2000 1-58113-184-4/00/5...$5.00 we demonstrate how our results can be used to solve satisfiability problems."""	approximation algorithm;approximation theory;computer science;heinz rutishauser;job shop scheduling;lenstra–lenstra–lovász lattice basis reduction algorithm;linear programming;minimax;np-hardness;polynomial;routing;scheduling (computing);symposium on theory of computing;time complexity	Artur Czumaj;Christian Scheideler	2000		10.1145/335305.335310	mathematical optimization;combinatorics;discrete mathematics;algorithmic lovász local lemma;mathematics;satisfiability	Theory	21.066516361867563	16.863889175320242	109852
53bd3ad296e20dcb090bb34f792777cba7f2ad9e	constraint satisfaction problems: algorithms and applications	hd28 management industrial management;combinatorial optimization problem;combinatorial problems;operations research;simulated annealing;satisfiability;constraint satisfaction;artificial intelligent;finite domain;computer experiment;constraint satisfaction problem;integer program;combinatorial optimization;branch and bound;programming;local search	A constraint satisfaction problem (CSP) requires a value, selected from a given ®nite domain, to be assigned to each variable in the problem, so that all constraints relating the variables are satis®ed. Many combinatorial problems in operational research, such as scheduling and timetabling, can be formulated as CSPs. Researchers in arti®cial intelligence (AI) usually adopt a constraint satisfaction approach as their preferred method when tackling such problems. However, constraint satisfaction approaches are not widely known amongst operational researchers. The aim of this paper is to introduce constraint satisfaction to the operational researcher. We start by de®ning CSPs, and describing the basic techniques for solving them. We then show how various combinatorial optimization problems are solved using a constraint satisfaction approach. Based on computational experience in the literature, constraint satisfaction approaches are compared with well-known operational research (OR) techniques such as integer programming, branch and bound, and simulated annealing. Ó 1999 Elsevier Science B.V. All rights reserved.	algorithm;branch and bound;combinatorial optimization;constraint satisfaction problem;cryptographic service provider;integer programming;mathematical optimization;operations research;scheduling (computing);simulated annealing	Sally C. Brailsford;Chris N. Potts;Barbara M. Smith	1999	European Journal of Operational Research	10.1016/S0377-2217(98)00364-6	constraint logic programming;concurrent constraint logic programming;programming;mathematical optimization;constraint programming;combinatorics;binary constraint;computer experiment;decomposition method;ac-3 algorithm;simulated annealing;constraint satisfaction;combinatorial optimization;constraint learning;computer science;constraint graph;local search;constraint satisfaction dual problem;mathematics;complexity of constraint satisfaction;constraint;constraint satisfaction problem;branch and bound;algorithm;hybrid algorithm;local consistency;backtracking;satisfiability	AI	20.09424091887902	5.187843550086621	109897
675033db3b12168556e57fb62e33c6696adadc3e	local search approaches in stable matching problems	stable matching;ties and incomplete preference lists;sampling;local search	The stable marriage (SM) problem has a wide variety of practical applications, ranging from matching resident doctors to hospitals, to matching students to schools or, more generally, to any two-sided market. In the classical formulation, n men and n women express their preferences (via a strict total order) over the members of the other sex. Solving an SM problem means finding a stable marriage where stability is an envy-free notion: no man and woman who are not married to each other would both prefer each other to their partners or to being single. We consider both the classical stable marriage problem and one of its useful variations (denoted SMTI (Stable Marriage with Ties and Incomplete lists)) where the men and women express their preferences in the form of an incomplete preference list with ties over a subset of the members of the other sex. Matchings are permitted only with people who appear in these preference lists, and we try to find a stable matching that marries as many people as possible. Whilst the SM problem is polynomial to solve, the SMTI problem is NP-hard. We propose to tackle both problems via a local search approach, which exploits properties of the problems to reduce the size of the neighborhood and to make local moves efficiently. We empirically evaluate our algorithm for SM problems by measuring its runtime behavior and its ability to sample the lattice of all possible stable marriages. We evaluate our algorithm for SMTI problems in terms of both its runtime behavior and its ability to find a maximum cardinality stable marriage. Experimental results suggest that for SM problems, the number of steps of our algorithm grows only as O(n log(n)), and that it samples very well the set of all stable marriages. It is thus a fair and efficient approach to generate stable marriages. Furthermore, our Algorithms 2013, 6 592 approach for SMTI problems is able to solve large problems, quickly returning stable matchings of large and often optimal size, despite the NP-hardness of this problem.	image scaling;local search (optimization);markov chain;moving target indication;np-hardness;polynomial;simplex algorithm;stable marriage problem;while	Mirco Gelain;Maria Silvia Pini;Francesca Rossi;Kristen Brent Venable;Toby Walsh	2013	Algorithms	10.3390/a6040591	sampling;mathematical optimization;combinatorics;stable marriage problem;local search;mathematics;stable roommates problem;algorithm	AI	18.387354496469698	18.075503094053214	110145
6ddf537732f638019d1657f668de4197c83cdd99	approximation algorithms for combinatorial optimization under uncertainty	approximate algorithm;electrical engineering and computer science;thesis;combinatorial optimization	"""Combinatorial optimization problems arise in many fields of industry and technology, where they are frequently used in production planning, transportation, and communication network design. Whereas in the context of classical discrete optimization it is usually assumed that the problem inputs are known, in many real-world applications some of the data may be subject to an uncertainty, often because it represents information about the future. In the field of stochastic optimization uncertain parameters are usually represented as random variables that have known probability distributions. In this thesis we study a number of different scenarios of planning under uncertainty motivated by applications from robotics, communication network design and other areas. We develop approximation algorithms for several KP-hard stochastic combinatorial optimization problems in which the input is uncertain modeled by probability distribution and the goal is to design a solution in advance so as to minimize expected future costs or maximize expected future profits. We develop techniques for dealing with certain probabilistic cost functions making it possible to derive combinatorial properties of an optimum solution. This enables us to make connections with already well-studied combinatorial optimization problems and apply some of the tools developed for them. The first problem we consider is motivated by an application from Al, in which a mobile robot delivers packages to various locations. The goal is to design a route for robot to follow so as to maximize the value of packages successfully delivered subject to an uncertainty in the robot's lifetime. We model this problem as an extension of the well-studied Prize-Collecting Traveling Salesman problem, and develop a constant factor approximation algorithm for it, solving an open question along the way. Next we examine several classical combinatorial optimization problems such as binpacking, vertex cover, and shortest path in the context of a """"preplanning"""" framework, in which one can """"plan ahead"""" based on limited information about the problem input, or """"wait and see"""" until the entire input becomes known, albeit incurring additional expense. We study this time-information tradeoff, and show how to approximately optimize the choice of what to purchase in advance and what to defer. The last problem studied, called maybecast is concerned with designing a routing network under a probabilistic distribution of clients using locally availabel information. This problem can be modeled as a stochastic version of the Steiner tree problem. However probabilistic objective function turns it into an instance of a challenging optimization problem with concave costs. Thesis Supervisor: David R. Karger Title: Associate Professor"""	apx;approximation algorithm;combinatorial optimization;concave function;discrete optimization;mathematical optimization;mobile robot;network planning and design;optimization problem;pixel;robotics;routing;shortest path problem;steiner tree problem;stochastic optimization;telecommunications network;travelling salesman problem;vertex cover;whole earth 'lectronic link	Maria Minkoff	2003			stochastic programming;probabilistic-based design optimization;optimization problem;mathematical optimization;cross-entropy method;fuzzy transportation;combinatorial optimization;computer science;artificial intelligence;vehicle routing problem;machine learning;3-opt;quadratic assignment problem	Theory	21.585144127563595	15.846415152807452	110164
91eb629c737d6403739e749dceefb60710554ebc	energy optimal schedules for jobs with multiple active intervals	workload;intervalo tiempo;energy;workload characterization;temps polynomial;energia;dynamic voltage scaling;min energy schedule;horario;time interval;68wxx;polynomial time algorithm;energie;energy optimization;energy consumption;optimal scheduling;informatique theorique;scheduling;polynomial time;charge travail;schedule;65f35;multiple interval jobs;algorithme polynomial;scheduling problem;carga trabajo;job scheduling;ordonnancement;horaire;reglamento;computer theory;68m20;intervalle temps;tiempo polinomial;informatica teorica	In this paper, we study the scheduling problem of jobs with multiple active intervals. Each job in the problem instance has n (n > 1) disjoint active time intervals where it can be executed and a workload characterized by the required number of CPU cycles. Previously, people studied multiple interval job scheduling problem where each job must be assigned enoughCPU cycles in one of its active intervals.We study a different practical versionwhere the partial work done by the end of an interval remains valid and each job is considered finished if total CPU cycles assigned to it in all its active intervals reach the requirement. The goal is to find a feasible schedule that minimizes energy consumption. By adapting the algorithm for single interval jobs proposed in Yao, Demers and Shenker (1995) [1], one can still obtain an optimal schedule. However, the two phases in that algorithm (critical interval finding and scheduling the critical interval) can no longer be carried out directly. We present polynomial time algorithms to solve the two phases for jobs with multiple active intervals and therefore can still compute the optimal schedule in polynomial time. © 2009 Elsevier B.V. All rights reserved.	algorithm;central processing unit;decision problem;instruction cycle;job scheduler;job stream;multistage interconnection networks;polynomial;schedule (computer science);scheduling (computing);time complexity;yao graph	Wanyong Tian;Minming Li;Enhong Chen	2010	Theor. Comput. Sci.	10.1016/j.tcs.2009.11.002	time complexity;job shop scheduling;mathematical optimization;real-time computing;energy;computer science;job scheduler;mathematics;scheduling;schedule	ECom	16.44740523946387	10.696921654865136	110175
7aeda99a5a9d336e1ce2bd80882cfed96f420ed1	efficient algorithms for the round-trip 1-center and 1-median problems	location theory;location routing;collection depots;centers;medians;algorithms	This paper presents improved algorithms for the round-trip single-facility location problem on a general graph, in which a set A of collection depots is given and the service distance of a customer is defined to be the distance from the server, to the customer, then to a depot, and back to the server. Each customer i is associated with a subset A i ? A of depots that i can potentially select from and use. When A i = A for each customer i, the problem is unrestricted; otherwise it is restricted. For the restricted round-trip 1-center problem, we give an O ( m n lg ? n ) -time algorithm. For the restricted 1-median problem, we give an O ( m n lg ? ( | A | / m ) + n 2 lg ? n ) -time algorithm. For the unrestricted 1-median problem, we give an O ( m n + n 2 lg ? lg ? n ) -time algorithm. An improved algorithm for the restricted round-trip 1-center problem.An improved algorithm for the restricted 1-median problem.An improved algorithm for the unrestricted 1-median problem.	1-center problem;algorithm;geometric median;round-trip engineering	Biing-Feng Wang;Jhih-Hong Ye;Pei-Jung Chen	2016	J. Comput. Syst. Sci.	10.1016/j.jcss.2016.01.002	mathematical optimization;location theory;computer science;mathematics;median;algorithm	Theory	21.401373164237697	14.41295649717014	110190
b8480358fcd2e8eaecad1c51c35773a00bbe8d25	scheduling a music rehearsal problem with unequal music piece length	unequal piece length;cell formation;scheduling;mixed integer programming;music rehearsal	This paper studies a music rehearsal scheduling where music pieces require different sets of players and different rehearsal durations. The rehearsal is arranged in multiple days. The players need to show up only on the day that the pieces they play are scheduled. They must show up before the first piece they involve starts and leave after the last one ends. The objectives are to assign music pieces to the rehearsal days to minimize the total number of days that all players have to show up and sequence the music pieces within each day to minimize the total waiting time of the players. We propose a 2-stage methodology to schedule music pieces, which is a combination of a cell formation technique and an integer-programming model. From 77 test problems, the solutions from the proposed method are as good as the optimal solutions from MIP models and are better than the best founds in all the test problems. The computational time is also significantly less.		Noppadon Sakulsom;Wipawee Tharmmaphornphilas	2014	Computers & Industrial Engineering	10.1016/j.cie.2013.12.017	real-time computing;simulation;speech recognition;integer programming;computer science;engineering;operating system;scheduling	DB	13.992678441064413	6.102380389151074	110455
17892f700bf0835a21120075f76d08154ee80319	probabilistic heuristics for disseminating information in networks	node degree distributions probabilistic heuristics network information dissemination structural knowledge cost effective improvement time complexity random graph framework;graph theory;random graph;heuristic flooding;node degree distributions;cluster computing;peer to peer computing floods algorithm design and analysis bandwidth analytical models bidirectional control distributed computing delay effects systems engineering and theory computer science;probabilistic flooding;time complexity;probabilistic algorithm;random networks;internet architecture;degree distribution;probabilistic heuristics;network information dissemination;random graph framework;computational complexity;random networks heuristic flooding probabilistic flooding;information dissemination;cost effectiveness;cost effective improvement;information dissemination computational complexity graph theory;structural knowledge	We study the problem of disseminating a piece of information through all the nodes of a network, given that it is known originally only to a single node. In the absence of any structural knowledge on the network, other than the nodes' neighborhoods, this problem is traditionally solved by flooding all the network's edges. We analyze a recently introduced probabilistic algorithm for flooding and give an alternative probabilistic heuristic that can lead to some cost-effective improvements, like better trade-offs between the message and time complexities involved. We analyze the two algorithms, both mathematically and by means of simulations, always within a random-graph framework and considering relevant node-degree distributions.	heuristic (computer science);random graph;randomized algorithm;simulation	Alexandre O. Stauffer;Valmir Carneiro Barbosa	2007	IEEE/ACM Transactions on Networking	10.1109/TNET.2007.892877	time complexity;random graph;degree distribution;cost-effectiveness analysis;computer cluster;computer science;graph theory;theoretical computer science;machine learning;distributed computing;randomized algorithm;computational complexity theory;computer network	Metrics	12.86396587226851	14.249682221787548	110548
129c8122ebc7e623656c1905173deed59e17f6c6	using multi-agent system for dynamic job shop scheduling	u10 methodes mathematiques et statistiques;multi agent system;agent based;job shop scheduling;simulated annealing;production process;e12 travail et emploi;job shop;dynamic scheduling;new products	Today's industries need more flexible scheduling systems able to produce new valid schedule in response to the modifications concerning orders, production processes and deliveries of materials. This paper introduces a multi-agent system applied to a job shop dynamic scheduling problem in which new production orders or deliveries arrive continuously and affect the already scheduled plan. We have solved the problem by: i) coupling reactive and pro-active agent behavior; and ii) implementing a stochastic method - simulated annealing - into agent's behavior. The job shop scheduling system is implemented using various types of agents whose interactions make the global state of the system move from a solution to another by continuously adapting to the changes from the environment. In this perspective, the interactions between the agents representing the client job orders, the production centers and the material stocks result in the assignment of operations and the plan for stock movements. Our experimental results show that, by modifying the classical agent-based message scheme, the integration of stochastic approach and multi-agent based technology could improve dynamic scheduling problems for a small to medium size problem space. (Resume d'auteur)	job shop scheduling;multi-agent system;scheduling (computing)	Min-Jung Yoo;Jean-Pierre Müller	2002			fair-share scheduling;job shop scheduling;real-time computing;simulation;flow shop scheduling;simulated annealing;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;scheduling;lottery scheduling	AI	12.432342947545711	6.03097834637384	110618
338d4d229dbb9ae88b8c5372980b0cbc85968c0b	polynomial algorithms for a class of minimum rank-two cost path problems	optimal solution;shortest path;cost function;minimum rank;polynomial algorithm	In this paper, we develop two algorithms for finding a directed path of minimum ranktwo monotonic cost between two specified nodes in a network with n nodes andm arcs. Under the condition that one of the vectors characterizing the cost function f is binary, one yields an optimal solution inO(n3) or O(nm log n) time if f is quasiconcave; the other solves any problem in O(nm+ n2 log n) time.	algorithm;loss function;path (graph theory);polynomial;quasiconvex function	Takahito Kuno	1999	J. Global Optimization	10.1023/A:1008372614175	mathematical optimization;combinatorics;discrete mathematics;mathematics;shortest path problem	Theory	23.520903667148254	17.19157034367954	110853
095ded6c5e0e2e39347da4f905a5ec9132c35394	an approximation algorithm for the traveling salesman problem with backhauls	traveling salesman problem;graph theory;teoria grafo;approximate algorithm;travelling salesman problem;aproximacion;arbre maximal;combinatorial problems;network analysis planning;theorie graphe;approximation;algorithme;problema viajante comercio;analysis of algorithms;algorithm;combinatorial problem;probleme combinatoire;problema combinatorio;arbol maximo;probleme commis voyageur;spanning tree;trucks;algoritmo	The Traveling Salesman Problem with Backhauls (TSPB) is defined on a graph G = (V, E). The vertex set is partitioned into V = ({v1}, L, B), where v1 is a depot, L is a set of linehaul customers, and B is a set of backhaul customers. A cost matrix satisfying the triangle inequality is defined on the edge set E. The TSPB consists of determining a least-cost Hamiltonian cycle on G such that all vertices of L are visited contiguously after v1, followed by all vertices of B. Following a result by Christofides for the Traveling Salesman Problem, we propose an approximation algorithm with worst-case performance ratio of 3/2 for the TSPB.	approximation algorithm;backhaul (telecommunications);travelling salesman problem	Michel Gendreau;Gilbert Laporte;Alain Hertz	1997	Operations Research	10.1287/opre.45.4.639	mathematical optimization;combinatorics;christofides algorithm;graph theory;mathematics;travelling salesman problem;algorithm;bottleneck traveling salesman problem	EDA	21.270785749796747	12.969469216239338	110942
9a70868fa0582a100e1140d90c7d2f8575db166e	the research on dispatching rule for improving on-time delivery for semiconductor wafer fab	dispatching rules;cycle time;dispatching throughput chromium semiconductor device modeling workstations computer integrated manufacturing cities and towns uncertainty manufacturing processes time factors;cycle time dispatching rule on time delivery semiconductor wafer fab dynamic dispatching;large scale;manufacturing processes;dynamic scheduling dispatching semiconductor device manufacture manufacturing processes;semiconductor device manufacture;dispatching;dynamic scheduling	Semiconductor wafer fab cries for really dynamic dispatching approach, due to its high uncertainty, re-entrance and large-scale. A dispatching rule for improving on-time delivery for semiconductor wafer fab (ODDR) is proposed, which considers the dispatching of bottleneck machines, not-bottleneck machines, batching machines and hot lots. As a result, it can distinctly improve on-time delivery without decreasing the throughput and increasing the cycle time. Finally, a simplistic model, but with essential characteristics of semiconductor wafer fab, is used to compare ODDR with FIFO, EDD and CR. It can be seen from the experimental results that ODDR is prior to FIFO, EDD and CR on throughput, cycle time and on-time delivery with better performance, especially for on-time delivery.	dynamic dispatch;fifo (computing and electronics);semiconductor fabrication plant;throughput;wafer (electronics)	Li Li;Fei Qiao;Hua Jiang;Qidi Wu	2004	ICARCV 2004 8th Control, Automation, Robotics and Vision Conference, 2004.	10.1109/ICARCV.2004.1468875	real-time computing;dynamic priority scheduling;cycle time variation;computer science;engineering;manufacturing engineering	Robotics	10.418135960487286	5.6331839283068055	111041
97814ed42a31f57e66d2b98cf6bbf35efb0a2f28	data reductions, fixed parameter tractability, and random weighted d-cnf satisfiability	reduccion sistema;probleme satisfiabilite;modelizacion;algoritmo aleatorizado;algorithmique;formule cnf;temps polynomial;weighted cnf satisfiability;complexite calcul;transition probability;probleme np complet;pruning tree;fixed parameter tractable;heuristic method;system reduction;satisfiabilite;metodo heuristico;fixed parameter tractability;intelligence artificielle;algorithme randomise;probabilistic approach;satisfiability;poda;reduction donnee;modelisation;complejidad computacion;phase transition;formula cnf;reduction systeme;algorithmics;algoritmica;computational complexity;probabilistic analysis;enfoque probabilista;approche probabiliste;problema satisfactibilidad;probabilidad transicion;polynomial time;transition phase;randomized algorithm;phase transitions;resolution complexity;artificial intelligence;reduccion datos;transicion fase;problema np completo;data reduction;methode heuristique;inteligencia artificial;conjunctive normal form;elagage;modeling;satisfiability problem;probabilite transition;random instances;np complete problem;satisfactibilidad;tiempo polinomial	Data reduction is a key technique in the study of fixed parameter algorithms. In the AI literature, pruning techniques based on simple and efficient-to-implement reduction rules also play a crucial role in the success of many industrial-strength solvers. Understanding the effectiveness and the applicability of data reduction as a technique for designing heuristics for intractable problems has been one of the main motivations in studying the phase transition of randomly-generated instances of NP-complete problems. In this paper, we take the initiative to study the power of data reductions in the context of random instances of a generic intractable parameterized problem, the weighted d-CNF satisfiability problem. We propose a non-trivial random model for the problem and study the probabilistic behavior of the random instances from the model. We design an algorithm based on data reduction and other algorithmic techniques and prove that the algorithm solves the random instances with high probability and in fixed-parameter polynomial time O(dnm) where n is the number of variables, m is the number of clauses, and k is the fixed parameter. We establish the exact threshold of the phase transition of the solution probability and show that in some region of the problem space, unsatisfiable random instances of the problem have parametric resolution proof of fixed-parameter polynomial size. Also discussed is a more general random model and the generalization of the results to the model. To the best knowledge of the author, this work is the first in the literature on the fixed-parameter tractability of random instances of intractable parameterized problems.	algorithm;boolean satisfiability problem;conjunctive normal form;heuristic (computer science);karp's 21 np-complete problems;parameterized complexity;polynomial;problem domain;randomness;time complexity;with high probability	Yong Gao	2009	Artif. Intell.	10.1016/j.artint.2009.06.005	phase transition;random graph;combinatorics;random element;computer science;random function;mathematics;algorithmics;algorithm	Theory	11.16718817148441	18.23381739246727	111161
60ec4930771940360bb575c1454e21c638660409	benders-and-cut algorithm for fixed-charge capacitated network design problem	network design;telecommunication network design;branch and bound algorithm;benders decomposition;integer programming;telecommunication;heavy traffic;integer program;branch and bound	We develop a Benders-and-cut algorithm for fixed-charge capacitated network design problem which incorporates both Benders cuts and polyhedral cuts into an implicit branch-and-bound algorithm. The algorithm is tested over a wide range of problem instances with varying sizes and traffic conditions. It is shown that this new algorithm’s performance is competitive compared with existing algorithms, and that Benders cuts are more effective under heavy traffic load, while cut set inequalities are more effective under light traffic load.	algorithm;network planning and design	Varadharajan Sridhar;June Sung Park	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00272-6	mathematical optimization;combinatorics;integer programming;computer science;mathematics;branch and bound;algorithm;branch and cut	Theory	21.883186788438266	11.365318064251767	111526
ec7baa57f9bbd578b695e400ad0ee9e0f1449ab5	the stochastic trim-loss problem	trim loss problem;recommandation;programmation stochastique;cutting stock problem;operations research;satisfiability;analyse convexe;scenario;profit;systeme incertain;branch and bound method;probleme decoupe;argumento;beneficio;metodo branch and bound;mathematical programming;recherche operationnelle;problema caida;script;probleme chute;benefice;analyse non convexe;recomendacion;recommendation;problema troquelado;profitability;methode separation et evaluation;non convex analysis;convex analysis;stochastic programming;sistema incierto;branch and bound;programmation mathematique;uncertain system;programacion estocastica;programacion matematica;investigacion operacional;analisis convexo;stochastic programming trim loss problem branch and bound;analisis no convexo	The cutting stock problem (CSP) is one of the most fascinating problems in operations research. The problem aims at determining the optimal plan to cut a number of parts of various length from an inventory of standard-size material so to satisfy the customers demands. The deterministic CSP ignores the uncertain nature of the demands thus typically providing recommendations that may result in overproduction or in profit loss. This paper proposes a stochastic version of the CSP which explicitly takes into account uncertainty. Using a scenario-based approach, we develop a two-stage stochastic programming formulation. The highly non-convex nature of the model together with its huge size prevent the application of standard software. We use a solution approach designed to exploit the specific problem structure. Encouraging preliminary computational results are provided.		Patrizia Beraldi;Maria Elena Bruni;Domenico Conforti	2009	European Journal of Operational Research	10.1016/j.ejor.2008.04.042	stochastic programming;convex analysis;mathematical optimization;profit;scenario;operations management;cutting stock problem;mathematics;mathematical economics;branch and bound;profitability index;satisfiability	Theory	18.387398267972994	6.12612973359193	111672
b86c8c81268b3f1b6010abc76efd8b58f8c9be37	speeding up of genetic algorithm for network topology optimization with use of cumulative updating of network reliability	random graph;node cut;network topolog optimization;genetic algorithms;network reliability;diameter constraint	Network optimization problems in conditions of constraints are NP-hard problems mostly. Genetic Algorithms are applicable solution for network structure optimization and for obtaining good results within acceptable periods of time. In this study we consider the problem of network topology optimization with unreliable communication channels and perfectly reliable nodes in order to obtain the most reliable structure. The problem of reliability computing for such networks is NP-hard so exact algorithm demands enormous computational effort. However, the method based on cumulative updating of lower and upper bounds of network reliability allows to decide the feasibility of a given network without performing exhaustive calculation of reliability. Relying on this technique we propose a new method which speed up network optimization process by the genetic algorithm.	computation;exact algorithm;flow network;genetic algorithm;mathematical optimization;np-hardness;network topology;topology optimization	Kseniya A. Nechunaeva;Denis A. Migov	2015		10.1145/2701126.2701163	random graph;probabilistic-based design optimization;mathematical optimization;meta-optimization;genetic algorithm;computer science;theoretical computer science;machine learning;network simulation;reliability	Metrics	11.974015278010983	8.64547707702632	111729
d7da19f4fb8aebe9eae0b01ece28e3e81b2f86f8	finding fixed satellite service orbital allotments with a k-permutation algorithm	satellite location problem;mixed programming;location problem;satellite communication;satellite geostationnaire;probleme localisation;synchronous satellites;nonlinear programming;satelite geoestacionario;interchannel interference;heuristic method;fixed satellite service;k permutation algorithm;metodo heuristico;telecomunicacion via satelite;programmation mixte;small samples;telecommunication par satellite;permutation;algorithme;satellite broadcasting;algorithm;modelo;mixed integer program;programacion mixta;integer programming;satellite orbits;heuristic methods;special purpose heuristic procedure;mathematical programming;aggregates;satellite relay systems integer programming linear programming;orbital allotments;permutacion;satellite relay systems;geostationary satellites;linear programming;linear mixed integer programming model;mathematical model;algorithms;orbital calculations;geostationnary satellite;modele;problema localizacion;methode heuristique;satellite telecommunication;interference constraints;satellite broadcasting linear programming frequency selective surfaces interference constraints aggregates orbital calculations interchannel interference mathematical programming mathematical model satellite communication;models;service fixe par satellite;algoritmo;special purpose heuristic procedure orbital allotments k permutation algorithm satellite location problem geostationary satellites fixed satellite service linear mixed integer programming model;frequency selective surfaces	A satellite system synthesis problem, the satellite location problem (SLP), is addressed. In SLP, orbital locations (longitudes) are allotted to geostationary satellites in the fixed satellite service. A linear mixed-integer programming model is presented that views SLP as a combination of two problems: the problem of ordering the satellites and the problem of locating the satellites given some ordering. A special-purpose heuristic procedure, a k-permutation algorithm, that has been developed to find solutions to SLPs formulated in the manner suggested is described. Solutions to small example problems are presented and analyzed on the basis of calculated interferences. >	algorithm;fixed-satellite service;molecular orbital	Charles H. Reilly;David J. A. Gonsalvez;Clark A. Mount-Campbell	1990	IEEE Trans. Communications	10.1109/26.58758	mathematical optimization;geostationary orbit;simulation;integer programming;telecommunications;nonlinear programming;computer science;linear programming;mathematical model;mathematics;permutation;communications satellite;fixed satellite service	Embedded	18.345898115791798	6.0022733075887675	111830
d98a6fc413a6f0fc636d18e13e8d9673a5a12586	finding the k shortest paths in a time-schedule network with constraints on arcs	constrained shortest paths;time constrained network;time schedule network;k shortest paths	We study a new variant of the time-constrained shortest path problem (TCSPP), that is, the K shortest paths problem in a time-schedule network with constraints on arcs. In such networks, each arc has a list of pre-specified departure times, and traversal along the arc can only take place at one of those departure times. We develop a solution algorithm that finds the K shortest looping paths in O(mlog(nr)+Kmr^2@h) time, where n is the number of nodes, m is the number of arcs, r is the maximum number of departure times on an arc, and @h is the maximum in-degree of a node. Computational experiments show that our algorithm outperforms existing ones adapted to solve the same problem.	shortest path problem	Wen Jin;Shuiping Chen;Hai Jiang	2013	Computers & OR	10.1016/j.cor.2013.07.005	mathematical optimization;combinatorics;constrained shortest path first;shortest job next;floyd–warshall algorithm;average path length;machine learning;yen's algorithm;mathematics;k shortest path routing;shortest path faster algorithm	Theory	23.61474999776491	17.946559042018723	111855
9fad5ff81b8aa5b7ee04fc44c9bac4d3f8665056	a framework for stochastic scheduling of two-machine robotic rework cells with in-process inspection system	robotic cell;performance;scheduling;rework	This study is focused on the domain of a two-machine robotic cell scheduling problem for three various kinds of pickup scenarios: free, interval, and no-wait pickup scenarios. Particularly, we propose the first analytical method for minimizing the partial cycle time of such a cell with a PCbased automatic inspection system to make the problem more realistic. It is assumed that parts must be inspected in one of the production machines, and this may result in a rework process. The stochastic nature of the rework process prevents us from applying existing deterministic solution methods for the scheduling problem. This study aims to develop an in-line inspection of identical parts using multiple contact/non-contact sensors. Initially, we convert a multiple-sensor inspection system into a single-sensor inspection system. Then, the expected sequence times of two different cycles are derived based on a geometric distribution, and finally the maximum expected throughput is pursued for each individual case with free pickup scenario. Results are also extended for the interval and no-wait pick up scenarios as two well-solved classes of the scheduling problem. The waiting time of the part at each machine after finishing its operation is bounded within a fixed time interval in cells with interval pickup scenario, whereas the part is processed from the input conveyor to the output conveyor without any interruption on machines in cells with no-wait pickup scenario. We show a simple approach for solving these two scenarios of the problem which are common in practice.	cell (microprocessor);interrupt;interval arithmetic;rework (electronics);robot;scheduling (computing);sensor;throughput	Mehdi Foumani;Kate Smith-Miles;Indra Gunawan;Asghar Moeini	2017	Computers & Industrial Engineering	10.1016/j.cie.2017.02.009	real-time computing;simulation;performance;computer science;engineering;operations management;scheduling	Robotics	10.677832323406475	4.985956045426814	111956
858cbf00f81a1768d958edd901984d06540784b8	heuristics for the combined cut order planning two-dimensional layout problem in the apparel industry	make to order;cut scheduling;cut order planning;two dimensional layout;simulated annealing;fashion industry;genetic annealing;apparel manufacturing;irregular packing and cutting;genetic algorithms	Cut order planning (COP) is an NP-hard nonlinear optimization problem. Managers of apparel manufacturing units face this problem during the planning of the first stage of the manufacturing process. It affects the fluidity of the work flow and use of fabric. It consists in dividing every garment’s order into sections, assigning the sizes to them, and determining their lengths and numbers of layers such that the total fabric length is minimized. Current industrial practice assumes that the length of the layout of a section is known a priori, and it does not depend on its combination of sizes. That is, the industry solves COP independently of the two-dimensional layout (TDL) that is the second stage of the manufacturing process. By relying on the length estimates in lieu of determining the actual length of a section, the industry is obtaining erroneous estimates of the true length used. Herein, COP and TDL are combined into a single problem CT (CT = COP + TDL) whose objective is to minimize fabric length. CT is solved using constructive heuristics, and three metaheuristics: a stochastic local improvement method, global improvement method, and hybrid approach. The approaches are tested on existing benchmark instances and new industrial cases. Their results provide computational proof of the benefits that industry can ripe by combining COP and TDL. The comparison of the performance of the approaches highlights their respective academic and practical utilities.	benchmark (computing);computation;heuristic (computer science);hyper-heuristic;international federation of operational research societies;local search (optimization);mathematical optimization;maxima and minima;maximal set;metaheuristic;nonlinear programming;nonlinear system;optimization problem;real life;set packing;tab stop;time complexity	Rym M'Hallah;Ahlem Bouziri	2016	ITOR	10.1111/itor.12104	mathematical optimization;build to order;genetic algorithm;simulated annealing;computer science;operations management	Robotics	14.760369834901388	4.950439248412162	112016
ec5ad2ee0a71499d0181014c85e03dc19ec3ea8f	a hybrid grasp-path relinking algorithm for the capacitated p-hub median problem	location problem;probleme localisation;scatter search;localization;heuristic method;prension;problema np duro;metodo heuristico;localizacion;gripping;optimisation combinatoire;resolucion problema;optimization problem;np hard problem;aleatorizacion;localisation;probleme np difficile;mathematical programming;path relinking;randomisation;algorithme evolutionniste;prehension;algoritmo evolucionista;problema localizacion;methode heuristique;evolutionary algorithm;randomization;combinatorial optimization;programmation mathematique;programacion matematica;problem solving;resolution probleme;optimizacion combinatoria	The p – hub median problem is an NP hard location – allocation problem, that consists of finding p points to establish facilities and the assignment of the users to these points. In the capacitated version of this problem, each hub has got a maximum capacity limiting the traffic to be assigned. A new evolutionary approach that has been very effective for solving optimization problems is Path Relinking, an extension of Scatter Search that links solutions over neighborhood spaces. GRASP is a well-known randomized multistart metaheuristic. In this paper, we present a hybrid GRASP-Path Relinking for the capacitated p – hub median problem where the GRASP is used to construct the population of the Path Relinking. Computational results demonstrate that the hybrid GRASP-Path Relinking provides better solutions, in terms of both running times and solution quality.	algorithm;grasp;usb hub	Melquíades Pérez Pérez;Francisco Almeida;J. Marcos Moreno-Vega	2005		10.1007/11546245_13	mathematical optimization;combinatorics;mathematics;algorithm	Theory	20.963940998238428	6.458006313054972	112098
84533afe50fa68a44aa76b22918a4eb5bbac7cbf	identifying conflicts in overconstrained temporal problems	temporal constraint satisfaction problem;constraint system;constraint density;overconstrained temporal problem;two-phase algorithm;identifying conflict;conflicting set;disjunctive temporal problem;algorithm scale;powerful constraint satisfaction technique;infeasible constraint system;constraint satisfaction;satisfiability	We describe a strong connection between maximally satisfiable and minimally unsatisfiable subsets of constraint systems. Using this relationship, we develop a two-phase algorithm, employing powerful constraint satisfaction techniques, for the identification of conflicting sets of constraints in infeasible constraint systems. We apply this technique to overconstrained instances of the Disjunctive Temporal Problem (DTP), an expressive form of temporal constraint satisfaction problems. Using randomly-generated benchmarks, we provide experimental results that demonstrate how the algorithm scales with problem size and constraint density.	algorithm;analysis of algorithms;benchmark (computing);constraint programming;constraint satisfaction problem;disjunctive normal form;randomness;two-phase locking	Mark H. Liffiton;Michael D. Moffitt;Martha E. Pollack;Karem A. Sakallah	2005			constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;discrete mathematics;binary constraint;decomposition method;ac-3 algorithm;constraint satisfaction;constraint learning;computer science;constraint graph;constraint satisfaction dual problem;mathematics;complexity of constraint satisfaction;constraint;constraint satisfaction problem;algorithm;difference-map algorithm;hybrid algorithm;local consistency;backtracking;satisfiability	AI	11.589419198375385	15.807780059405196	112219
1be0bdc58aad52776d2be373bf5069b6091de0ab	teaching note - implementing line balancing heuristics in spreadsheets	heuristic;excel;priority rule;array formula;balancing;assembly line;scenarios	Two previous papers in INFORMS Transactions on Education demonstrated an innovative Excel array formula approach that can be used for the handling of precedences in project management and assembly line balancing models. In this paper I combine the array formula approach with a clever but simple precedence coding system to present an efficient spreadsheet for performing assembly line balancing using the heuristic method that is common in operations management textbooks. In addition, I demonstrate to students a perturbation method to handle ties in algorithms in Excel and also demonstrate the application of Excel's Scenario Manager to line balancing.	heuristic;spreadsheet	Howard J. Weiss	2013	INFORMS Trans. Education	10.1287/ited.1120.0096	simulation;heuristic;computer science;operations management;operations research;algorithm	HCI	18.025861011809734	7.7997598210244306	112248
14f364c250cf403dc54aa6521f55c794f9bdac97	a robust ptas for the parallel machine covering problem	004;stability approximation schemes online algorithms	Problem definition. We consider the classical scheduling problem of maximizing the minimum machine load on parallel machines. In this setting we are given a set of jobs J , a set of machines M to process the jobs and a processing time pj for each job j ∈ J . For a given assignment of jobs to machines, the load of a machine i is defined as the sum of the processing of jobs assigned to i. Our objective is to maximize the minimum load of the machines. This problem is usually called the machine covering problem, and referred as P ||Cmin in the three-field notation (see Lawler et al. [1]).	covering problems;job stream;ptas reduction;parallel computing;scheduling (computing)	Martin Skutella;José Verschae	2009			mathematical optimization;combinatorics;machine learning;mathematics	Theory	15.630086952028055	10.631115133186482	112256
4cba99d17752a1b1cd8c30b91b6873faffc35d48	computational aspects of reordering plans	artificial intelligent;polynomial time	This article studies the problem of modifying the action ordering of a plan in order to optimise the plan according to various criteria. One of these criteria is to make a plan less constrained and the other is to minimize its parallel execution time. Three candidate de nitions are proposed for the rst of these criteria, constituting a sequence of increasing optimality guarantees. Two of these are based on deordering plans, which means that ordering relations may only be removed, not added, while the third one uses reordering, where arbitrary modi cations to the ordering are allowed. It is shown that only the weakest one of the three criteria is tractable to achieve, the other two being NP-hard and even di cult to approximate. Similarly, optimising the parallel execution time of a plan is studied both for deordering and reordering of plans. In the general case, both of these computations are NP-hard. However, it is shown that optimal deorderings can be computed in polynomial time for a class of planning languages based on the notions of producers, consumers and threats, which includes most of the commonly used planning languages. Computing optimal reorderings can potentially lead to even faster parallel executions, but this problem remains NP-hard and di cult to approximate even under quite severe restrictions.	approximation algorithm;automated planning and scheduling;cobham's thesis;computation;np-hardness;run time (program lifecycle phase);time complexity	Christer Bäckström	1998	J. Artif. Intell. Res.	10.1613/jair.477	time complexity;mathematical optimization;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;algorithm	AI	22.36409259006694	4.584179627789455	113250
a2573d095033f959caa917d75cc0642fe5ae06e5	processing games with restricted capacities	modelizacion;completion time;markets;temps polynomial;mercado;coalicion;cooperation;juego cooperativo;temps achevement;allocation;cooperacion;cooperative game;allocation noyau;modelisation;minimizacion costo;flujo red;minimisation cout;cost minimization;coalition;jeu cooperatif;scheduling;games;core allocation;marche;polynomial time;coste;scheduling individual capacity cooperation core allocation;network flow;external research report;capacity;tiempo acabado;process scheduling;modeling;asignacion nucleo;individual capacity;flot reseau;ordonnancement;reglamento;cout;tiempo polinomial	This paper analyzes processing problems and related cooperative games. In a processing problem there is a finite set of jobs, each requiring a specific amount of effort to be completed, whose costs depend linearly on their completion times. The main feature of the model is a capacity restriction, i.e., there is a maximum amount of effort per time unit available for handling jobs. There are no other restrictions whatsoever on the processing schedule. Assigning to each job a player and letting each player have an individual capacity for handling jobs, each coalition of cooperating players in fact faces a processing problem with the coalitional capacity being the sum of the individual capacities of the members. The corresponding processing game summarizes the minimal joint costs for every coalition. It turns out that processing games are totally balanced. The proof of this statement is constructive and provides a core element in polynomial time. 2009 Elsevier B.V. All rights reserved.	job stream;time complexity	Hans Reijnierse;Peter Borm;Marieke Quant;Marc Meertens	2010	European Journal of Operational Research	10.1016/j.ejor.2009.06.014	mathematical optimization;simulation;computer science;operations management;operations research;scheduling	Theory	17.12987655866384	9.045411512943224	113320
20a348ab2e8f9482d8d88e9afc9df15079560697	facility location optimization methods based on aggregate and disperse moves	polynomial time approximation algorithm;optimal solution;optimisation;hierarchical facility costs;approximate algorithm;hierarchy tree;trees mathematics approximation theory facility location optimisation;facility location optimization methods;modular function;optimal method;trees mathematics;approximation theory;constant factor approximation algorithm;optimization methods aggregates cost function polynomials computer science economies of scale application software memory file servers search methods;polynomial time;facility location problem;economies of scale;polynomial time approximation algorithm facility location optimization methods hierarchical facility costs hierarchy tree constant factor approximation algorithm;facility location	The hierarchical facility costs are a special case of the setting in which the facility cost is a more complex function of the set of clients assigned to a single facility, and the algorithm for the problem independent of the number of levels in the hierarchy tree, for the case of identical costs on all facilities does not simply depend on their number. We use the aggregate and disperse moves to show that a constant factor approximation algorithm for the facility location problem with hierarchical facility costs, which a locally optimal solution is a 5-approximation for the problem. Using scaling we improve the bound to 4.236, and accepting only sufficiently large improvements, we can turn this into a polynomial time (4.236+epsiv)-approximation algorithm for the hierarchical facility location problem. A more general class of such problems be defined by using a facility cost that is an arbitrary sub-modular function cost(S) of the set of clients S assigned to the facility. Sub-modularity represents a natural economy of scale in handling extra clients at an existing facility.		Hong-Zhen Zheng;Jun-Heng Huang;De-chen Zhan	2007		10.1109/FSKD.2007.287	mathematical optimization;combinatorics;discrete mathematics;facility location problem;mathematics;1-center problem	EDA	20.410736245911966	14.760646110126329	113393
6e7574c067c82196a6908771ce57fd6ba7afce90	technical note - rationalizing discrete programs		In this paper we show that a bounded integer programming problem, with real data, can be replaced with another problem of the same dimension, with rational data, in such a way that the feasible solutions and optimal feasible solutions to the new problem are identical with those to the original problem.		F. J. Gould;D. S. Rubin	1973	Operations Research	10.1287/opre.21.1.343	optimization problem;mathematical optimization;combinatorics;discrete mathematics;cutting stock problem;mathematics	Theory	23.780349257029833	12.015736773436103	113641
f588958cc2edbc91b0a05a30c2f8c44d87a6b2b7	multiprocessor scheduling with machine allotment and parallelism constraints	workload;parallelisme;multiprocessor scheduling;tiempo total acabamiento;machine allotment;approximate algorithm;temps polynomial;gestion labor;multiprocessor;machine unique;sistema informatico;temps total achevement;distributed computing;problema np duro;ejecucion programa;computer system;program execution;polynomial time algorithm;np hard problem;parallelism;single machine;maquina unica;gestion tâche;paralelismo;makespan;probleme np difficile;scheduling;execution programme;polynomial time;charge travail;communication cost;scheduling problem;calculo repartido;completitud;ordonamiento;systeme informatique;completeness;task scheduling;multiprocesador;carga trabajo;algoritmo optimo;algorithme optimal;completude;optimal algorithm;modem;calcul reparti;polynomial time approximation scheme;ordonnancement;tiempo polinomial;multiprocesseur	Abstract. Modern computer systems distribute computation among several machines to speed up the execution of programs. Yet, setup and communication costs, as well as parallelism constraints, bound the number of machines that can share the execution of a given application, and the number of machines by which it can be processed simultaneously . We study the resulting scheduling problem, stated as follows. Given a set of n jobs and m uniform machines, assign the jobs to the machines subject to parallelism and machine allotment constraints, such that the overall completion time of the schedule (or makespan ) is minimized. Indeed, the multiprocessor scheduling problem (where each job can be processed by a single machine) is a special case of our problem; thus, our problem is strongly NP-hard. We present a (1+ α) -approximation algorithm for this problem, where α ∈ (0,1] depends on the minimal number of machine allotments and the minimal parallelism allowed for any job. Also, we show that when the maximal number of machines that can share the execution of a job is some fixed constant, our problem has a polynomial time approximation scheme ; for other special cases we give optimal polynomial time algorithms. Finally, through the relation of our problem to the classic preemptive scheduling problem on multiple machines, we shed some fresh light on what is known in scheduling folklore as the power of preemption.	approximation algorithm;computation;job stream;makespan;maximal set;multiprocessing;multiprocessor scheduling;np-hardness;parallel computing;polynomial;polynomial-time approximation scheme;preemption (computing);scheduling (computing);strong np-completeness;time complexity	Hadas Shachnai;Tami Tamir	2001	Algorithmica	10.1007/s00453-001-0098-3	time complexity;job shop scheduling;mathematical optimization;parallel computing;real-time computing;multiprocessing;polynomial-time approximation scheme;completeness;computer science;np-hard;mathematics;scheduling;multiprocessor scheduling;algorithm	Theory	16.605365965375306	11.27602999404022	113976
467a9244c7660f51b61f3596edb16c45f96e8241	block approach to the cyclic flow shop scheduling	block properties;cyclic flow shop problem;scheduling	Keywords: Scheduling Cyclic flow shop problem Block properties a b s t r a c t The cyclic flow show problem with machine setups is considered in this paper. It relies in producing of a set of certain elements in fixed intervals of time (cycle time). Process optimization is reduced to minimization of cycle time, i.e., the time after which the next batch of the same elements may be produced. Since the problem is strongly NP-hard, in order to solve it an approximate algorithm was used. There is presented a graph model of a problem and the so called block eliminating properties capable of reducing, in a significant way, neighborhood used in the tabu search algorithm. Conducted computational experiments confirm high efficiency of the proposed technique. For many years, one could observe an increasing market demand for diversity (multiassortment) of production. This may be provided, among many other issues, by means of cyclic production. In fixed intervals of time (cycle time) a certain 'batch' of assortment (a mix of kit, a set) is produced. Process optimization is typically reduced to minimization of cycle time. Proper selection of mix and cycle time enables not only to meet demand, but also to improve efficacy and effectiveness of machinery use. Thus, recently, one can observe a significant increase of interest in the problems of cyclic tasks scheduling theory. For they are usually important and difficult, (mostly NP-hard) problems, from the standpoint of not only theory, but also practice. A comprehensive overview of the state of knowledge concerning the cyclic task scheduling problem can be found in the work of Levner, Kats, Lopez, and Cheng (2010) analyzing the issues of computational complexity of algorithms for solving various types of cycle scheduling problem. Here, in particular NP-difficult problems of various cyclic types including a variety of criterion functions and additional constraints (no wait, no buffer, etc.) are considered. In the scientific work by Panwalkar, Dudek, and Smith (1973) on task scheduling it was found that 75% of problems occurring in practice requires at least one setup dependent on the order of tasks execution. However, in 15% of the problems a setup of all tasks should be taken into consideration. Nevertheless, in the vast majority of works, in the field of scheduling setups are not taken into account at all. This applies both to single and multi-machine problems and to different goal functions. Cyclic problems belong …	approximation algorithm;computation;computational complexity theory;experiment;flow shop scheduling;magnetic-core memory;mathematical optimization;np-hardness;process optimization;scheduling (computing);scientific literature;search algorithm;strong np-completeness;tabu search	Wojciech Bozejko;Mariusz Uchronski;Mieczyslaw Wodecki	2015	Computers & Industrial Engineering	10.1016/j.cie.2015.01.004	mathematical optimization;combinatorics;flow shop scheduling;computer science;mathematics;scheduling;algorithm	AI	15.679790455257809	7.878399834046596	113986
cb7444d69bf9d881e1c226feb84410e2c9cc8e2e	on the power of lookahead in on-line vehicle routing problems	modelizacion;traveling salesman problem;lower and upper bound;vehicle routing problem;travelling salesman problem;probleme tournee vehicule;problema ruta vehiculo;problema viajante comercio;upper bound;modelisation;combinatorial problem;probleme combinatoire;problema combinatorio;probleme commis voyageur;borne inferieure;delai d execution;plazo ejecucion;borne superieure;modeling;on line algorithm;lower bound;time allowed;cota superior;competitive ratio;cota inferior	Vehicle Routing Problems are generalizations of the well known Traveling Salesman Problem; we focus on the on-line version of these problems, where requests are not known in advance and arrive over time. We introduce two models of lookeahead for this class of problems, the time lookahead ∆, which allows an on-line algorithm to foresee all the requests that will be released during next ∆ time units, and the request lookahead, which allows an on-line algorithm to foresee the next k requests that will be released. We present lower and upper bounds on the competitive ratio of known and studied variants of the OlTsp; we compare these results with the ones from the literature. Our results show that the effectiveness of lookahead varies significantly as we consider different problems, from the point of view of competitive analysis. Even when it does not yield better competitive ratios, lookahead can be used to improve the empirical performance of algorithms: we present the results of an experimental study on algorithms endowed with time lookahead.	adversary (cryptography);competitive analysis (online algorithm);heuristic (computer science);lookahead carry unit;maximum flow problem;online algorithm;online and offline;parsing;simulation;travelling salesman problem;vehicle routing problem;whole earth 'lectronic link	Luca Allulli;Giorgio Ausiello;Luigi Laura	2005		10.1007/11533719_74	mathematical optimization;computer science;artificial intelligence;vehicle routing problem;mathematics;upper and lower bounds;travelling salesman problem;algorithm	Theory	17.304064424750376	11.586798611533712	114023
0354522460ed3c5da7c8dd733e3fe8250748abd7	ten times eighteen	dynamic programming;expected score maximization;computational complexity;dice rolling game	We consider the following simple game: We are given a table with ten slots indexed one to ten. In each of the ten rounds of the game, three dice are rolled and the numbers are added. We then put this number into any free slot. For each slot, we multiply the slot index with the number in this slot, and add up the products. The goal of the game is to maximize this score. In more detail, we play the game many times, and try to maximize the sum of scores or, equivalently, the expected score. We present a strategy to optimally play this game with respect to the expected score. We then modify our strategy so that we need only polynomial time and space. Finally, we show that knowing all ten rolls in advance, results in a relatively small increase in score. Although the game has a random component and requires a non-trivial strategy to be solved optimally, this strategy needs only polynomial time and space.	game theory;polynomial;realms;state space;time complexity	Sebastian Böcker	2015	JIP	10.2197/ipsjjip.23.258	mathematical optimization;example of a game without a value;simulation;computer science;dynamic programming;computational complexity theory;sequential game;algorithm	AI	15.706525649677147	15.862473445334178	114169
b11320d0e8a5be956cc21222bf2a3b068753b688	two-machine flowshop scheduling with truncated learning to minimize the total completion time	simulated annealing;truncated learning function;scheduling;two machine flowshop	Scheduling with learning effects has received a lot of research attention lately. However, the flowshop setting is relatively unexplored. On the other hand, the actual processing time of a job under an uncontrolled learning effect will drop to zero precipitously as the number of jobs increases. This is rather absurd in reality. Motivated by these observations, we consider a two-machine flowshop scheduling problem in which the actual processing time of a job in a schedule is a function of the job's position in the schedule and a control parameter of the learning function. The objective is to minimize the total completion time. We develop a branch-and-bound and three simulated annealing algorithms to solve the problem. Computational results show that the proposed algorithms are efficient in producing near-optimal solutions.	scheduling (computing)	Der-Chiang Li;Peng-Hsiang Hsu;Chin-Chia Wu;T. C. Edwin Cheng	2011	Computers & Industrial Engineering	10.1016/j.cie.2011.04.021	mathematical optimization;real-time computing;simulated annealing;computer science;operations management;scheduling	AI	15.468490362000724	7.514925836633017	114313
260dd719cfe3645b50d8e91f522ee830699fc059	delivery itineraries and distribution capacity of a freight network with time slots	street;transportation network;transportation networks;carga dinamica;red transporte;entrega;parking;stationnement;heuristic method;time window;estacionamiento;metodo heuristico;fente;charge dynamique;dynamic load;delai livraison;volume trafic;distribution cost;slot;dechargement;scenario;livraison;volumen trafico;branch and bound method;cout moyen;cout distribution;argumento;metodo branch and bound;mathematical programming;average cost;unloading;descargo;coste medio;script;plazo entrega;settore mat 09 ricerca operativa;fenetre temporelle;coordinacion;methode heuristique;traffic engineered;delivery good;methode separation et evaluation;capacity of traffic;point of view;ventana temporal;calle;branch and bound;programmation mathematique;rue;programacion matematica;ranura;delivery lead time;central business district;coordination;reseau transport	"""The paper focuses on the distribution problem of delivering goods to medium size stores in a Central Business District (CBD) having limited off-street parking which can accommodate only restricted space and time for parking, loading/unloading operations. In this scenario, freight distribution can be addressed from two perspectives: (i) from the viewpoint of delivery/pick-up firms, delivery itineraries need to be coordinated with consideration of the delivery capacities and times at store sites for parking, and loading/unloading operations; (ii) from the viewpoint of transportation and city planners, the """"distribution capacity"""" in the CBD must be determined, including the average cost of distribution routes, the maximum number of routes that can be simultaneously coordinated, the total number of stores that can be served, etc., much in the way traffic engineers are interested in the """"traffic capacity"""" of a transportation network under which the vehicles move efficiently. Both the above viewpoints are addressed in this paper by solving the following problem: what delivery itineraries are available so that parking loading/unloading capacities and associated time windows are respected and the itineraries are """"balanced"""" in a way that costs and number of deliveries fall in given ranges. This problem is studied and a mathematical programming formulation is developed. To evaluate exactly the freight distribution capacity, a branch-and-bound approach is developed, where the relaxation of the formulation provides good bounds. Subsequently, a heuristic is presented that is useful from an operational point of view. In fact, the latter algorithm exploits the results provided by the exact approach and maximizes the efficiency of the system."""		Massimiliano Caramia;Paolo Dell'Olmo;Monica Gentili;Pitu B. Mirchandani	2007	Computers & OR	10.1016/j.cor.2005.07.013	mathematical optimization;simulation;dynamic load testing;computer science;scenario;mathematics;branch and bound	Metrics	16.84902101389135	4.949254498269614	114467
65f9fd24ea03e8030604c65199046c8454e4b871	dynamic agent ordering in distributed constraint satisfaction problems	proceso secuencial comunicante;distributed system;empirical study;multiagent system;systeme reparti;multi agent system;autonomous system;institute for integrated and intelligent systems;relacion orden;communicating process;heuristic method;communicating sequential process;simultaneidad informatica;ordering;metodo heuristico;constraint satisfaction;sistema autonomo;proceso comunicante;satisfaction contrainte;relation ordre;concurrency;sistema repartido;processus sequentiel communicant;autonomous agent;faculty of engineering and information technology;distributed constraint satisfaction problem;processus communicant;systeme autonome;intelligent agent;backtracking;280213;methode heuristique;satisfaccion restriccion;sistema multiagente;simultaneite informatique;other artificial intelligence;systeme multiagent	The distributed constraint satisfaction problem (CSP) is a general formalisation used to represent problems in distributed multiagent systems. To deal with realistic problems, multiple local variables may be required within each autonomous agent. A number of heuristics have been developed for solving such multiple local variable problems. However, these approaches do not always guarantee agent independence and the size of problem that can be solved is fairly limited. In this paper, we are interested in increasing search e ciency for distributed CSPs. To this end we present a new algorithm using unsatis ed constraint densities to dynamically determine agent ordering during the search. The independence of agents is guaranteed and agents without neighbouring relationships can run concurrently and asynchronously. As a result of using a backtracking technique to solve the local problem, we have been able to reduce the number of nogoods stored during the search, leading to further e ciency gains. In an empirical study, we show our new approach outperforms an equivalent static ordering algorithm and a current state-of-the-art technique both in terms of execution time and memory usage.	agent-based model;algorithm;autonomous agent;autonomous robot;backtracking;computation;concurrency (computer science);constraint satisfaction problem;cryptographic service provider;data access object;distributed constraint optimization;heuristic (computer science);local variable;multi-agent system;real-time clock;run time (program lifecycle phase)	Lingzhong Zhou;John Thornton;Abdul Sattar	2003		10.1007/978-3-540-24581-0_36	concurrency;constraint satisfaction;order theory;computer science;autonomous system;artificial intelligence;autonomous agent;empirical research;constraint satisfaction problem;intelligent agent;algorithm;backtracking	AI	21.68453883581978	5.003950582306112	114522
4907adfcd5a7885dcc5fae4fe85b1c90098fc263	the simulated greedy algorithm for several submodular matroid secretary problems	matroid;submodular function;secretary problem	We study the matroid secretary problems with submodular valuation functions. In these problems, the elements arrive in random order. When one element arrives, we have to make an immediate and irrevocable decision on whether to accept it or not. The set of accepted elements must form an independent set in a predefined matroid. Our objective is to maximize the value of the accepted elements. In this paper, we focus on the case that the valuation function is a non-negative and monotonically non-decreasing submodular function. We introduce a general algorithm for such submodular matroid secretary problems. In particular, we obtain constant competitive algorithms for the cases of laminar matroids and transversal matroids. Our algorithms can be further applied to any independent set system defined by the intersection of a constant number of laminar matroids, while still achieving constant competitive ratios. Notice that laminar matroids generalize uniform matroids and partition matroids. On the other hand, when the underlying valuation function is linear, our algorithm achieves a competitive ratio of 9.6 for laminar matroids, which significantly improves the previous result.	competitive analysis (online algorithm);greedy algorithm;independent set (graph theory);partition matroid;secretary problem;submodular set function;value (ethics)	Tengyu Ma;Bo Tang;Yajun Wang	2015	Theory of Computing Systems	10.1007/s00224-015-9642-4	matroid;mathematical optimization;combinatorics;discrete mathematics;graphic matroid;submodular set function;mathematics;secretary problem;weighted matroid;matroid partitioning	Theory	17.80907446585148	15.293711010534025	114809
ec01ee193d2e4b033eed31c471ef9ae3a85bca06	competitiveness and response time in on-line algorithms	online algorithm;search trees;high performance;on line algorithm;competitive ratio	The study of competitive algorithms has concentrated on competitiveness — comparing online algorithms to optimal off-line algorithms on sequences of operations. Published algorithms proven (or suggested) to be competitive invariably have pessimal response time i.e. their worst-case single operation time is as bad as possible. We consider whether or not such algorithms can be adapted to improve the response time without sacrificing competitiveness. We consider lists, off-line static search trees, dynamic search trees, and the k-server problem on a line segment of length L. For lists, pessimal response time is unavoidable. For off-line static search trees our algorithm is 2-competitive and has response time 2 log n. For dynamic search trees our algorithm has logarithmic amortized time and is statically optimal (like splay trees), but the response time is O(n log n) and (log2 n). For the k-server problem we prove that any algorithm with O(optimal) response time has a competitive ratio of at least (L/k). This is achieved by a simple on-line algorithm. We also show that even a weak limit on response time for the k-server problem (e.g. response time less than half pessimal) yields an (L/k) separation between on-line and off-line algorithms. Our results apply to high-performance multi-head disk drives where response time is critical.	algorithm;responsiveness	Vladimir Estivill-Castro;Murray Sherk	1991		10.1007/3-540-54945-5_73	competitive analysis;online algorithm;mathematical optimization;simulation;computer science;machine learning;fsa-red algorithm	Theory	16.32075534969134	12.103572271311133	114911
0c9a13a34cbd0a49f2f2d5c7dae36bd768eb3770	solving packing and covering lps in õ(1/ε2) distributed iterations with a single algorithm and simpler analysis		Packing and covering linear programs belong to the narrow class of linear programs that are efficiently solvable in parallel and distributed models of computation, yet are a powerful modeling tool for a wide range of fundamental problems in theoretical computer science, operations research, and many other areas. Following recent progress in obtaining faster distributed and parallel algorithms for packing and covering linear programs, we present a simple algorithm whose iteration count matches the best known Õ( 1 ǫ 2 ) for this class of problems. The algorithm is similar to the algorithm of Allen-Zhu and Orecchia [2], it can be interpreted as Nesterov’s dual averaging, and it constructs approximate solutions to both primal (packing) and dual (covering) problems. However, the analysis relies on the construction of an approximate optimality gap and a primal-dual view, leading to a more intuitive interpretation. Moreover, our analysis suggests that all existing algorithms for solving packing and covering linear programs in parallel/distributed models of computation are, in fact, unaccelerated, and raises the question of designing accelerated algorithms for this class of problems.	approximation algorithm;decision problem;iteration;linear programming;model of computation;operations research;parallel algorithm;set packing;theoretical computer science	Jelena Diakonikolas;Lorenzo Orecchia	2017	CoRR			Theory	24.291494270236367	11.587517962444732	114944
1c653574e1ef7430516fcb45d6c129166d96c5e8	experiences with backward simulation based approach for lot release planning	semiconductor device testing;job shop scheduling;assembly;manufacturing processes;job shop scheduling production planning semiconductor device manufacture semiconductor device testing electronics industry throughput assembly manufacturing processes system testing process planning;electronics industry;semiconductor device manufacture;system testing;production planning;technical report;process planning;throughput;semiconductor manufacturing	Bottleneck based scheduling approach suggests planning the release of lots based on the capacity of the bottleneck machines in the manufacturing process. Many scheduling systems determine the start of the first operation of the lot based on backward scheduling from its operation on the bottleneck machine. An approach was developed for determining the lot release times based on backward simulation. While conceptually appealing and successful with simple problems, the approach did not lead to expected improvements in a highly complex semiconductor manufacturing scenario. This paper describes the approach, its implementation and the limitations realized in the complex scenario.	confidentiality;heuristic (computer science);scheduling (computing);semiconductor device fabrication;semiconductor industry;simulation	Sanjay Jain;Stephen Chan	1997		10.1145/268437.268622	job shop scheduling;throughput;computer science;engineering;technical report;industrial engineering;assembly;scheduling;semiconductor device fabrication;system testing;world wide web;manufacturing engineering	AI	10.531839469075571	4.6038993494595815	114981
9e7f57f3accca60433d6382dec7099a443e41d85	preprocessing in stochastic programming: the case of capacitated networks	frame;preprocessing;modeling;convex hull;feasibility;stochastic programming;programming	Preprocessing can speed up the solution procedures for two-stage stochastic programming. We consider the case when the second-stage problem is a pure, uncapacitated network. We describe a number of procedures to reduce the size of the recourse problem. We describe a procedure for generating efficiently the (induced) feasibility cuts, and show that further reductions are possible if more information about the node-types is taken into account. We also investigate network collapsing techniques that would simplify the work required to find both optimality cuts and feasibility cuts, if we had not yet reduced the problem to one with relatively complete recourse. Computational results confirm that substantial savings are possible. INFORMS Journal on Computing, ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499.	preprocessor;stochastic programming	Stein W. Wallace;Roger J.-B. Wets	1995	INFORMS Journal on Computing	10.1287/ijoc.7.1.44	stochastic programming;frame;feasibility study;programming;mathematical optimization;combinatorics;systems modeling;computer science;convex hull;machine learning;mathematics;preprocessor;algorithm	ECom	17.66330550766937	4.501784713758971	115082
8e29750d57a33cb50ec22d1bb2b79370a779e753	on the relation between concavity cuts and the surrogate dual for convex maximization problems	surrogate dual;convex maximization;concavity cut	In this note we establish a relation between two bounds for convex maximization problems, the one based on a concavity cut, and the surrogate dual bound. Both bounds have been known in the literature for a few decades but, to the authors’ knowledge, the relation between them has not been previously observed in the literature.	concave function;entropy maximization;loss function;optimization problem	Marco Locatelli;Fabio Schoen	2012	J. Global Optimization	10.1007/s10898-011-9748-4	mathematical optimization;combinatorics;discrete mathematics;entropy maximization;mathematics	ML	22.79223432009291	15.098519178929369	115229
0f855c4247bdc6ea35b9ecf9da7a1a5203a18297	using quadratic programming to solve high multiplicity scheduling problems on parallel machines	distributed system;quadratic programming;systeme reparti;quadratic program;systeme multiprocesseur memoire repartie;cost function;complexite calcul;funcion coste;algorithme;algorithm;minimizacion costo;complejidad computacion;sistema repartido;minimisation cout;cost minimization;computational complexity;scheduling;polynomial algorithm;sistema multiprocesador memoria distribuida;polynomial time;scheduling problem;fonction cout;parallel machines;ordonamiento;systeme parallele;distributed memory multiprocessor system;parallel system;ordonnancement;sistema paralelo;algoritmo	We introduce and analyze several models of schedulingn different types (groups) of jobs onm parallel machines, where in each group all jobs are identical. Our main goal is to exhibit the usefulness of quadratic programming approaches to solve these classes of high multiplicity scheduling problems, with the total weighted completion time as the minimization criterion. We develop polynomial algorithms for some models, and strongly polynomial algorithms for certain special cases. In particular, the model in which the weights are job independent, as well as the generally weighted model in which processing requirements are job independent, can be formulated as an integer convex separable quadratic cost flow problem, and therefore solved in polynomial time. When we specialize further, strongly polynomial bounds are achievable. Specifically, for the weighted model with job-independent processing requirements if we restrict the weights to be machine independent (while still assuming different machine speeds), anO(mn+n logn) algorithm is developed. If it is also assumed that all the machines have the same speed, the complexity of the algorithm can be improved toO(m logm+n logn). These results can be extended to related unweighted models with variable processing requirements in which all the machines are available at time zero.	algorithm;eisenstein's criterion;flow network;job stream;p (complexity);polynomial;quadratic programming;requirement;scheduling (computing);time complexity	Frieda Granot;Jadranka Skorin-Kapov;Amir Tamir	1997	Algorithmica	10.1007/BF02522821	time complexity;mathematical optimization;combinatorics;computer science;mathematics;computational complexity theory;scheduling;quadratic programming;algorithm	Theory	17.08384537426135	10.855431878832583	115674
b5f69b81f978ba0ebe70b8efa14948e7e7b62e8d	contribution to the optimization of unequal area rectangular facility layout problem. (contribution à l'optimisation de problème d'agencement d'espaces rectangulaires inégaux)			mathematical optimization	Ranjan Kumar Hasda	2017				Theory	23.076778744337954	8.903900744361865	115839
6c52c295fa8ab0d9ccc949796ded00cdc71d8864	batched bin packing revisited	graph bin packing;tight bound;batched bin packing	We revisit the batched bin packing problem. In this model, items come in K consecutive batches, and the items of the earlier batches must be packed without any knowledge of later batches. We give the first approximation algorithm for the case K = 2, with tight asymptotic approximation ratio of 1.5833, while the known lower bound of the model is 1.378. With the application of this result, we are also able to provide an improved algorithm for the recently defined graph-bin packing problem in a special case, where we improve the upper bound from 3 to 2.5833.	approximation algorithm;bin packing problem;order of approximation;set packing	György Dósa	2017	J. Scheduling	10.1007/s10951-015-0431-3	mathematical optimization;combinatorics;bin packing problem;mathematics	Theory	16.927127932027954	14.834325666457211	116045
250f0a61ec22ba94dfd15b80289d2b5c178f512c	tabu search for the planar three-index assignment problem	assignment problem;combinatorial problems;latin square;indexation;tabu search;difference set;combinatorial optimization	Tabu Search is a very effective method for approximately solving hard combinatorial problems. In the current work we implement Tabu Search for solving the Planar Three-Index Assignment Problem. The problem deals with finding the minimum cost assignment between elements of three distinct sets demanding that every pair of elements, each representing a different set, appears in the same solution exactly once. The solutions of the problems correspond to Latin squares. These structures form the basis of the move generation mechanism employed by the Tabu Search procedures. Standard Tabu Search ideas such as candidate move list, variable tabu list size, and frequency-based memory are tested. Computational results for a range of problems of varying dimensions are presented.	assignment problem;candidate move;computation;effective method;tabu search	D. Magos	1996	J. Global Optimization	10.1007/BF00229300	mathematical optimization;combinatorics;combinatorial optimization;tabu search;generalized assignment problem;latin square;mathematics;assignment problem;weapon target assignment problem;algorithm;difference set;guided local search	AI	24.189918417826025	6.189162307138759	116197
0fb0b6dbf2a5271b60f7eb837797617b13438801	an empirical study of algorithms for point-feature label placement	label placement;empirical study;time complexity;stochastic method;heuristic method;combinatorial optimization problem;complexity analysis;simulated annealing;journal article;heuristic search;gradient descent;automated cartography;stochastic methods	A major factor affecting the clarity of graphical displays that include text labels is the degree to which labels obscure display features (including other labels) as a result of spatial overlap. Point-feature label placement (PFLP) is the problem of placing text labels adjacent to point features on a map or diagram so as to maximize legibility. This problem occurs frequently in the production of many types of informational graphics, though it arises most often in automated cartography. In this paper we present a comprehensive treatment of the PFLP problem, viewed as a type of combinatorial optimization problem. Complexity analysis reveals that the basic PFLP problem and most interesting variants of it are NP-hard. These negative results help inform a survey of previously reported algorithms for PFLP; not surprisingly, all such algorithms either have exponential time complexity or are incomplete. To solve the PFLP problem in practice, then, we must rely on good heuristic methods. We propose two new methods, one based on a discrete form of gradient descent, the other on simulated annealing, and report on a series of empirical tests comparing these and the other known algorithms for the problem. Based on this study, the first to be conducted, we identify the best approaches as a function of available computation time.	algorithm;automatic label placement;cartography;combinatorial optimization;computation;diagram;gradient descent;graphical user interface;graphics;heuristic;infographic;mathematical optimization;np-hardness;optimization problem;simulated annealing;time complexity	Jon Christensen;Joe Marks;Stuart M. Shieber	1995	ACM Trans. Graph.	10.1145/212332.212334	gradient descent;time complexity;mathematical optimization;automatic label placement;heuristic;simulated annealing;computer science;artificial intelligence;machine learning;empirical research;algorithm;statistics	Graphics	24.55646832194191	6.992673187391258	116397
168d39517b90e843ccb594bcf8d9f68ec9a66bdd	discrete newton's algorithm for parametric submodular function minimization		We consider the line search problem in a submodular polytope P (f) ⊆ R: Given an arbitrary a ∈ R and x0 ∈ P (f), compute max{δ : x0 + δa ∈ P (f)}. The use of the discrete Newton’s algorithm for this line search problem is very natural, but no strongly polynomial bound on its number of iterations was known [Iwata, 2008]. We solve this open problem by providing a quadratic bound of n + O(n log n) on its number of iterations. Our result considerably improves upon the only other known strongly polynomial time algorithm, which is based on Megiddo’s parametric search framework and which requires Õ(n) submodular function minimizations [Nagano, 2007]. As a by-product of our study, we prove (tight) bounds on the length of chains of ring families and geometrically increasing sequences of sets, which might be of independent interest.	algorithm;iteration;line search;newton;p (complexity);parametric search;polynomial;search problem;submodular set function;time complexity	Michel X. Goemans;Swati Gupta;Patrick Jaillet	2017		10.1007/978-3-319-59250-3_18	mathematical optimization;combinatorics;discrete mathematics;submodular set function;mathematics	Theory	23.953974589573747	15.809569292961024	116628
64a3c5c330e91fe15dee84b9ff118fa3c3c1b06b	a reinforcement learning approach to interval constraint propagation	modelizacion;embedding;prestation service;moyenne ponderee;constraint propagation;weighted averaging;search space;reinforcement learning;prestacion servicio;heuristic method;weighting;estimacion promedio;metodo heuristico;contrato;ponderacion;constraint satisfaction;contracting service;interval propagation;numerical constraints;modelisation;satisfaction contrainte;apprentissage renforce;contract;weighted average;plongement;systeme non lineaire;promedio pondero;aritmetica intervalo;methode heuristique;ponderation;inmersion;contrat;satisfaccion restriccion;mean estimation;interval arithmetic;arithmetique intervalle;estimation moyenne;aprendizaje reforzado;sistema no lineal;modeling;systems of nonlinear equations;non linear system	When solving systems of nonlinear equations with interval constraint methods, it has often been observed that many calls to contracting operators do not participate actively to the reduction of the search space. Attempts to statically select a subset of efficient contracting operators fail to offer reliable performance speed-ups. By embedding the recency-weighted average Reinforcement Learning method into a constraint propagation algorithm to dynamically learn the best operators, we show that it is possible to obtain robust algorithms with reliable performances on a range of sparse problems. Using a simple heuristic to compute initial weights, we also achieve significant performance speed-ups for dense problems.	algorithm;amelioration pattern;condition number;constraint satisfaction problem;embedded system;heuristic;interval arithmetic;local consistency;newton's method;nonlinear system;numerical analysis;overhead (computing);performance;reinforcement learning;software propagation;sparse matrix;unary operation	Frédéric Goualard;Christophe Jermann	2007	Constraints	10.1007/s10601-007-9027-7	contract;mathematical optimization;combinatorics;discrete mathematics;constraint satisfaction;computer science;embedding;weighting;mathematics;interval arithmetic;reinforcement learning	AI	21.863646816024463	6.153258801590185	116677
f56957af4cf592884a0e8d0e339e6d87495de34e	complexity results for storage loading problems with stacking constraints	complexity;stacking;stacking constraints;storage loading	In this paper, we present complexity results for storage loading problems where the storage area is organized in fixed stacks with a limited common height. Such problems appear in several practical applications, e.g., in the context of container terminals, container ships or warehouses. Incoming items arriving at a storage area have to be assigned to stacks so that certain constraints are respected (e.g., not every item may be stacked on top of every other item). We study structural properties of the general model and special cases where at most two or three items can be stored in each stack. Besides providing polynomial time algorithms for some of these problems, we establish the boundary to NP-hardness. © 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).	algorithm;np-hardness;stacking;time complexity	Florian Bruns;Sigrid Knust;Natalia V. Shakhlevich	2016	European Journal of Operational Research	10.1016/j.ejor.2015.09.036	mathematical optimization;complexity;theoretical computer science;stacking;mathematics	Theory	18.337079483395108	13.553385145077131	116724
1e7e910e977aacf9129fed1806426c4899dbd697	the complexity of integer bound propagation	constraint propagation;time complexity;search space;linear constraint;artificial intelligent;search trees;numerical range;polynomial algorithm;constraint programming;branch and prune	Bound propagation is an important Artificial Intelligence technique used in Constraint Programming tools to deal with numerical constraints. It is typically embedded within a search procedure (”branch and prune”) and used at every node of the search tree to narrow down the search space, so it is critical that it be fast. The procedure invokes constraint propagators until a common fixpoint is reached, but the known algorithms for this have a pseudo-polynomial worst-case time complexity: they are fast indeed when the variables have a small numerical range, but they have the well-known problem of being prohibitively slow when these ranges are large. An important question is therefore whether stronglypolynomial algorithms exist that compute the common bound consistent fixpoint of a set of constraints. This paper answers this question. In particular we show that this fixpoint computation is in fact NP-complete, even when restricted to binary linear constraints.	algorithm;artificial intelligence;best, worst and average case;computation;constraint programming;embedded system;fixed point (mathematics);karp's 21 np-complete problems;numerical analysis;polynomial;search tree;software propagation;time complexity;whole earth 'lectronic link	Lucas Bordeaux;George Katsirelos;Nina Narodytska;Moshe Y. Vardi	2011	J. Artif. Intell. Res.	10.1613/jair.3248	constraint logic programming;time complexity;mathematical optimization;constraint programming;numerical range;combinatorics;discrete mathematics;binary constraint;constraint satisfaction;constraint learning;computer science;machine learning;mathematics;constraint satisfaction problem;algorithm;local consistency	AI	10.909300272514114	17.36486923416585	117055
d7c305fcf6f3e99314697c54e0dcd14095db8e7a	algorithms for the shortest path improvement problems under unit hamming distance		In a shortest path improvement problem under unit Hamming distance (denoted by SPIUH), an edge weighted graph with a set of source-terminal pairs is given; we need to modify the lengths of edges by a minimum cost under unit Hamming distance such that the modified distances of the shortest paths are upper bounded by given values. The SPIUH problem on arborescent network is formulated as a 0-1 integer programming model. Some strongly polynomial time algorithms are designed for the problems on some special arborescent networks. Firstly, two greedy algorithms are proposed for problems on chain networks and special startree networks, respectively. Secondly, a strongly polynomial time algorithm is presented for the problem with a single source and constrained paths. Finally, a heuristic algorithm and its computational experiments are given for the SPIUH problem on general graphs.	computation;experiment;greedy algorithm;hamming distance;heuristic (computer science);integer programming;linear programming;p (complexity);programming model;shortest path problem;time complexity	Bingwu Zhang;Xiucui Guan;Chunyuan He;Shuguo Wang	2013	J. Applied Mathematics	10.1155/2013/847317	mathematical optimization;combinatorics;discrete mathematics;hamming distance;hamming graph;mathematics;shortest path problem;k shortest path routing;shortest path faster algorithm	Theory	23.434569494887228	17.378564895977057	117205
2767b19373c5dbb5d93c5b909f9752d99fc83c26	the strength of dantzig-wolfe reformulations for the stable set and related problems		Dantzig-Wolfe reformulation of an integer program convexifies a subset of the constraints, which yields an extended formulation with a potentially stronger linear programming (LP) relaxation. We would like to better understand the strength of such reformulations in general. As a first step we investigate the classical edge formulation for the stable set problem. We characterize weakest possible Dantzig-Wolfe reformulations (with LP relaxations not stronger than the edge formulation) and strongest possible reformulations (yielding the integer hull). We (partially) extend our findings to related problems such as the matching problem and the set packing problem. These are the first non-trivial general results about the strength of relaxations obtained from decomposition methods, after Geoffrion’s seminal 1974 paper about Lagrangian relaxation.	integer (number);integer programming;lagrangian relaxation;linear programming relaxation;set packing;subgroup	Marco E. Lübbecke;Jonas T. Witt	2018	Discrete Optimization	10.1016/j.disopt.2018.07.001		Theory	23.744529321132315	15.202632446182106	117553
3ceb41421d8771f0f71b66a1359a3f7a5f027701	lagrangian relaxation	maximization problem;optimal solution;column generation;lagrangian relaxation;lagrangian relaxation;upper bound;numerical aspect	Lagrangian relaxation is a tool to find upper bounds on a given (arbitrary) maximization problem. Sometimes, the bound is exact and an optimal solution is found. Our aim in this paper is to review this technique, the theory behind it, its numerical aspects, its relation with other techniques such as column generation.	column generation;expectation–maximization algorithm;lagrangian relaxation;linear programming relaxation;numerical analysis;relaxation (approximation)	Claude Lemaréchal	2001		10.1007/3-540-45586-8_4	mathematical optimization;combinatorics;discrete mathematics;lagrangian relaxation;mathematics	Logic	22.954994844344483	14.883024140798408	117843
5885939c4eacbf9911511a119027e24c466cdb07	multiprocessor jobs, preemptive schedules, and one-competitive online algorithms		We study online preemptive makespan minimization on m parallel machines, where the (multiprocessor) jobs arrive over time and have widths from some fixed set W ⊆ {1, 2, . . . ,m}. For every number m of machines we concisely characterize all the sets W for which there is a 1-competitive fully online algorithm and all the sets W for which there is a 1-competitive nearly online algorithm.	makespan;multiprocessing;online algorithm	Jirí Sgall;Gerhard J. Woeginger	2014		10.1007/978-3-319-18263-6_20	multiprocessor scheduling	Theory	15.836130897755854	11.331042596555944	117848
f023f4b2fd47dd6c7608eda7776ec6fb8786e4f5	identifying large robust network clusters via new compact formulations of maximum k-club problems	graph theory;robust network clusters;compact 0 1 formulations;k clubs;combinatorial optimization;r robust k clubs	Network robustness issues are crucial in a variety of application areas. In many situations, one of the key robustness requirements is the connectivity between each pair of nodes through a path that is short enough, which makes a network cluster more robust with respect to potential network component disruptions. A k-club, which by definition is a subgraph of a diameter of at most k, is a structure that addresses this requirement (assuming that k is small enough with respect to the size of the original network). We develop a new compact linear 0–1 programming formulation for finding maximum k-clubs that has substantially fewer entities compared to the previously known formulation (O(kn2) instead of O(nk+1), which is important in the general case of ku003e2) and is rather tight despite its compactness. Moreover, we introduce a new related concept referred to as an R-robust k-club (or, (k,R)-club), which naturally arises from the developed k-club formulations and extends the standard definition of a k-club by explicitly requiring that there must be at least R distinct paths of length at most k between all pairs of nodes. A compact formulation for the maximum R-robust k-club problem is also developed, and error and attack tolerance properties of the important special case of R-robust 2-clubs are investigated. Computational results are presented for multiple types of random graph instances.	algorithm;attack tolerance;computation;entity;experiment	Alexander Veremyev;Vladimir Boginski	2012	European Journal of Operational Research	10.1016/j.ejor.2011.10.027	mathematical optimization;combinatorics;discrete mathematics;combinatorial optimization;graph theory;mathematics	Vision	23.95309992989679	16.777952495536784	118015
2b22dd0ea5f231777860750ee5aa7948a88469c1	an efficient bounds consistency algorithm for the global cardinality constraint	constraint propagation;constraint programming	Previous studies have demonstrated that designing special purpose constraint propagators can signiflcantly improve the e-ciency of a constraint programming approach. In this paper we present an ef- flcient algorithm for bounds consistency propagation of the generalized cardinality constraint (gcc). Using a variety of benchmark and random problems, we show that our bounds consistency algorithm is competi- tive with and can dramatically outperform existing state-of-the-art com- mercial implementations of constraint propagators for the gcc. We also present a new algorithm for domain consistency propagation of the gcc which improves on the worst-case performance of the best previous al- gorithm for problems that occur often in applications.	algorithm;cardinality (data modeling)	Claude-Guy Quimper;Peter van Beek;Alejandro López-Ortiz;Alexander Golynski;Sayyed Bashir Sadjad	2003		10.1007/978-3-540-45193-8_41	constraint logic programming;cardinal number;mathematical optimization;constraint programming;ac-3 algorithm;benchmark;constraint satisfaction;computer science;calculus;mathematics;programming language;implementation;algorithm;hybrid algorithm;local consistency	ML	11.965356989877295	16.08865495346957	118256
de447a472fb20e20c8b9140c71474c81cf05bf7f	performance evaluation of proposed differential evolution and particle swarm optimization algorithms for scheduling m-machine flow shops with lot streaming	scheduling;particle swarm optimization algorithm;flow shop;differential evolution algorithm;lot streaming	We consider n-job, m-machine lot streaming problem in a flow shop with equal size sub lots where the objective is to minimize the makespan and total flow time. Lot streaming (Lot sizing) is a technique that splits a production lot consisting of identical items into sub lots to improve the performance of a multi stage production system by over lapping the sub lots on successive machines. There is a scope for efficient algorithms for scheduling problems in m-machine flow shop with lot streaming. In recent years, much attention is given to heuristics and search techniques. To solve this problem, we propose a Differential Evolution Algorithm (DEA) and Particle Swarm Optimization (PSO) to evolve best sequence for makespan/total flow time criterion for m-machine flow shop involved with lot streaming and set up time. In this research, we propose the DEA and PSO algorithms for discrete lot streaming with equal sub lots. The proposed methods are tested and the performances were evaluated. The computational results show that the proposed algorithms are very competitive for the lot streaming flow shop scheduling problem. G. Vijay chakaravarthy (B) Department of Mechanical Engineering, Fathima Michael College of Engineering & Technology, Madurai 625 020, India e-mail: vijay_vanitha123@yahoo.com S. Marimuthu Department of Mechanical Engineering, Latha Mathavan Engineering College, Madurai 625 301, India e-mail: marimuthushree@yahoo.co.in A. Naveen Sait Department of Mechanical Engineering, Chendhuran College of Engineering & Technology, Pudukkottai 622 507, India e-mail: naveensait@yahoo.co.in	algorithm;computation;differential evolution;email;flow shop scheduling;heuristic (computer science);makespan;particle swarm optimization;performance evaluation;production system (computer science);scheduling (computing);uptime	G. Vijay Chakaravarthy;Senthilarasi Marimuthu;A. Naveen Sait	2013	J. Intelligent Manufacturing	10.1007/s10845-011-0552-2	mathematical optimization;real-time computing;flow shop scheduling;computer science;scheduling	AI	15.985186170397949	8.011379964623147	118671
b7aac0c29c3078eff085bd1b1dc839203853766a	reconstruction of polycrystalline structures: a new application of combinatorial optimization	graph theory;teoria grafo;reconstruction graphe;polycristal;simulated annealing;theorie graphe;polycrystal;grafico planario;graph reconstruction;reconstruccion grafico;graphe planaire;modele simulation;policristal;modelo simulacion;geometric probability;combinatorial optimization;simulation model;planar graph	Many known materials possess polycrystalline structure. The images produced by plane cuts through such structures are polygonal complexes. The problem of finding the edges, when only the vertices of a given polygonal complex are known, is considered. A combinatorial optimization model is proposed whose solution yields an approximation of the complex. The problem itself is solved using simulated annealing. Encouraging first experiments are presented. Viele bekannte Werkstoffe besitzen Polykristallstruktur. Derartige Strukturen können an Hand ebener Schnitte durch die Werkstoffe als Polygon-Komplexe beobachtet werden. Es wird hier die Aufgabe der Auffindung der Kanten, wenn nur die Ecken der genannten Polygon-Komplexe gegeben sind, betrachtet. Es wird eine Aufgabe der kombinatorischen Optimierung vorgeschlagen, dessen Lösung eine Approximation des Komplexes darstellt. Die Aufgabe selber wird mit der “simulierten Abkühlung” behandelt. Ermutigende erste Ergebnisse liegen vor.	approximation;combinatorial optimization;eine and zwei;experiment;mathematical optimization;simulated annealing;vhf omnidirectional range	Hubert Telley;Thomas M. Liebling;Alain Mocellin	1987	Computing	10.1007/BF02253739	mathematical optimization;combinatorics;simulated annealing;combinatorial optimization;graph theory;simulation modeling;mathematics;geometry;planar graph;geometric probability	Theory	21.377567573380965	12.256325874062977	118768
956777e3f5d13b3006080616dcaf089473d147f1	walcom: algorithms and computation		In this talk we will look at the classical prediction game where the adversary (or nature) is producing a sequence of bits and a prediction algorithm is trying to predict the future bit(s) from the past bits. This is like gambling on the future bits which involves the risk of making mistakes while shooting for profit from right predictions. Say the algorithm gets a payoff of 1 on a right prediction and −1 on wrong predictions (and is also make fractional bets c ≤ 1 in which case its payoff is +c or −c). We will see an algorithm [1] that has a good performance while almost never taking a risk of having a net loss where loss is said to happen when the number of wrong predictions exceeds the number of right predictions. Our algorithm gets no more than an exponentially small loss e−Ω( T ) over T bits on any sequence (where is a constant parameter). Further as compared to the payoff that would have been achieved by predicting the majority bit (in hindsight) our algorithms payoff is not lower by more than O( T ) (which is commonly known as regret). We will also see experimental results on how these algorithms perform on stock data. Our algorithms build upon several classical works on the experts problem [2–4] We will also see what kind of sequences are best from the adversary’s perspective. We will show that under a certain formulation of predictive payoff it is best for the adversary to generate a “fractal like” sequence [5].	adversary (cryptography);algorithm;computation;fractal;regret (decision theory)	Sophia Rex;Christiane Schmidt	2013		10.1007/978-3-642-36065-7	model of computation;probabilistic analysis of algorithms;analysis of algorithms	ML	13.112156123544125	18.11697983585505	119071
6f30d9f1e8b21a9d3d9f94521f46550927c4ed7f	an integrated approach for requirement selection and scheduling in software release planning	release planning;integrated approach;model combination;requirement dependency;simulation;scrum;development process;integer linear programming ilp;precedence constraint;requirement scheduling;project scheduling;requirement selection;dynamic adaptation;integer linear program;project planning	It is essential for product software companies to decide which requirements should be included in the next release and to make an appropriate time plan of the development project. Compared to the extensive research done on requirement selection, very little research has been performed on time scheduling. In this paper, we introduce two integer linear programming models that integrate time scheduling into software release planning. Given the resource and precedence constraints, our first model provides a schedule for developing the requirements such that the project duration is minimized. Our second model combines requirement selection and scheduling, so that it not only maximizes revenues but also simultaneously calculates an on-time-delivery project schedule. Since requirement dependencies are essential for scheduling the development process, we present a more detailed analysis of these dependencies. Furthermore, we present two mechanisms that facilitate dynamic adaptation for over-estimation or under-estimation of revenues or processing time, one of which includes the Scrum methodology. Finally, several simulations based on real-life data are performed. The results of these simulations indicate that requirement dependency can significantly influence the requirement selection and the corresponding project plan. Moreover, the model for combined requirement selection and scheduling outperforms the sequential selection and scheduling approach in terms of efficiency and on-time delivery.	integer programming;linear programming;real life;requirement;scheduling (computing);scrum (software development);simulation;software release life cycle	Chen Li;J. M. van den Akker;Sjaak Brinkkemper;Guido Diepen	2010	Requirements Engineering	10.1007/s00766-010-0104-x	fair-share scheduling;real-time computing;dynamic priority scheduling;computer science;systems engineering;engineering;rate-monotonic scheduling;operations management;two-level scheduling;scrum;scheduling;round-robin scheduling;management;schedule;functional requirement;non-functional requirement;software development process;project planning;precedence diagram method	SE	12.52385682485681	4.935805608626445	119077
722356a0aac38f0df824092a5fcd73ae1a0c7622	lot-sizing two-echelon assembly systems with random yields and rigid demand	cout variable;multiple lot sizing;parallelisme;variable cost;numerical method;efficient algorithm;heuristic method;metodo heuristico;satisfiability;high precision;rigid demand;assembly;parallelism;paralelismo;metodo numerico;tamano lote;taille lot;precision elevee;precision elevada;lot sizing;assembly system;cout production;montage;methode heuristique;production cost;linear equations;montaje;methode numerique;random yield;coste produccion	We consider a two-echelon assembly system producing a single final product for which the demand is known. The first echelon consists of several parallel stages while the second echelon consists of a single assembly stage. We assume that the yield at each stage is random and that demand needs to be satisfied in its entirety; thus, several production runs may be required. A production policy should specify, for each possible configuration of intermediate inventories, on which stage to produce next and the lot-size to be processed. The objective is to minimize the expected total of setup and variable production costs. We prove that the expected cost of any given production policy can be calculated by solving a finite set of linear equations whose solution is unique. The result is general in that it applies to any yield distribution. We also develop efficient algorithms leading to heuristic solutions with high precision and provide numerical results for binomial yields.	algorithm;group policy;heuristic;inventory;linear equation;numerical analysis;row echelon form	Abraham Grosfeld-Nir;Shoshana Anily;Tal Ben-Zvi	2006	European Journal of Operational Research	10.1016/j.ejor.2005.01.033	variable cost;mathematical optimization;numerical analysis;operations management;mathematics;assembly;linear equation;satisfiability	Theory	13.907671136318799	5.586108387068533	119107
fc00ddaada86efac5894b1efb6c43bfab425f8bd	minimizing the mean weighted absolute deviation from due dates in lot-streaming flow shop scheduling	optimal solution;mean weighted absolute deviation;production system;computer experiment;scheduling;linear program;pairwise interchange method;stream flow;neighborhood search;flow shop;heuristic algorithm;lot streaming	"""Lot-streaming is the process of splitting a job (lot) into a number of smaller sublots so that successive operations can be overlapped in a multi-stage production system. This paper presents a procedure for minimizing the mean weighted absolute deviation from due dates when jobs are scheduled in a lot-streaming #ow shop. This performance criterion has been shown to be non-regular and requires a search among schedules with inserted idle times to """"nd an optimal solution. For a given job sequence, we present linear programming formulations to obtain optimal sublot completion times for cases where bu!ers between successive machines have limited or in""""nite capacities, and sublots have equal-size or are consistent. A no-wait #ow shop problem is also considered. Sixteen pairwise interchange methods are considered to generate the best sequences. These algorithms are obtained by combining four rules to generate initial sequences with four neighborhood search mechanisms. Computational experiments are conducted on 140 test problems. The results show that the best solutions are obtained by the heuristic algorithm with a non-adjacent pairwise interchange method and the smallest overall slack time rule to generate the initial sequence."""	algorithm;application programming interface;computation;experiment;feasible region;flow shop scheduling;graph (discrete mathematics);heuristic (computer science);job stream;linear programming;local search (optimization);material handling;open shading language;procedural generation;production system (computer science);scheduling (computing);single-machine scheduling;slack variable;streaming media	Suk-Hun Yoon;Jose A. Ventura	2002	Computers & OR	10.1016/S0305-0548(01)00032-6	heuristic;mathematical optimization;computer experiment;flow shop scheduling;computer science;linear programming;mathematics;production system;streamflow;scheduling	AI	16.049685124100478	7.045617109332641	119301
3a00544880f5bb998416a3853a351a0c32c83c49	dynamic programming driven memetic search for the steiner tree problem with revenues, budget, and hop constraints	dynamic programming;evolutionary computation;constrained steiner trees;content distribution networks;heuristics	Authors are encouraged to submit new papers to INFORMS journals by means of a style file template, which includes the journal title. However, use of a template does not certify that the paper has been accepted for publication in the named journal. INFORMS journal templates are for the exclusive purpose of submitting to an INFORMS journal and should not be used to distribute the papers in print or online or to submit the papers to another publication.	benchmark (computing);computation;crossover (genetic algorithm);dynamic programming;heuristic (computer science);hop;institute for operations research and the management sciences;internet backbone;iterated local search;iteration;local search (optimization);mathematical optimization;memetic algorithm;memetics;network planning and design;real life;steiner tree problem;subroutine	Zhang-Hua Fu;Jin-Kao Hao	2015	INFORMS Journal on Computing	10.1287/ijoc.2014.0622	mathematical optimization;combinatorics;computer science;heuristics;machine learning;dynamic programming;mathematics;evolutionary computation	DB	22.04121455297339	8.744573806116607	119322
cbcc2b1012658daacd353f09a30a2589ec8a1b20	the two-processor scheduling problem is in r-nc	efficient algorithm;scheduling theory;algebraic method;scheduling problem;technical report;computer science	The two-processor scheduling problem is perhaps the most basic problem in scheduling theory, and several efficient algorithms have been discovered for it. However, these algorithms are inherently sequential in nature. We give a fast parallel (R-NC) algorithm for this problem. Interestingly enough, our algorithm for this purely combinatoric-looking problem draws on some powerful algebraic methods.	algorithm;linear algebra;scheduling (computing);windows nt processor scheduling	Umesh V. Vazirani;Vijay V. Vazirani	1985		10.1145/22145.22147	computational problem;fair-share scheduling;nurse scheduling problem;job shop scheduling;open-shop scheduling;mathematical optimization;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;technical report;theoretical computer science;genetic algorithm scheduling;two-level scheduling;distributed computing;multiprocessor scheduling;memetic algorithm	Theory	14.891777363689954	13.67104523750464	119511
8fafe4ad84c5dabb03d01ed08fe8c28202872e4f	the multi-layered network design problem	internet protocol;distributed system;optimal solution;variable metric method;virtual networks;virtual network;global solution;solution optimale;network design;reseau communication;systeme reparti;reseau optique;protocolo internet;optical transport network;numerical method;protocole internet;optimum global;global optimisation;global optimum;red fibra optica;optimisation combinatoire;telecomunicacion optica;telecommunication optique;sistema repartido;red multinivel;optical arrays;metodo numerico;solucion optima;metodo metrico variable;reseau fibre optique;optical telecommunication;optical fiber network;solution globale;multilayer network;methode metrique variable;reseau multicouche;point of view;combinatorial optimization;red de comunicacion;optimo global;solucion global;communication network;methode numerique;red virtual;reseau virtuel;optimizacion combinatoria	We address the problem of designing a network built on several layers. This problem occurs in practical applications but has not been studied extensively from the point of view of global optimisation, since the problem of designing a single-layered network is complex. An example of an application is the design of a virtual network (Internet Protocol) built on a sparse optical transport network.#R##N##R##N#We suggest a mathematical formulation without any flow variables or path variables, based on metric inequalities. We give numerical results for two-layered network instances obtained with a global method giving optimal solutions and we compare them with approximate results obtained by solving the problem in two steps.	network planning and design	Arnaud Knippel;Benoit Lardeux	2007	European Journal of Operational Research	10.1016/j.ejor.2006.07.046	internet protocol;optical transport network;mathematical optimization;network planning and design;minimum-cost flow problem;multi-commodity flow problem;telecommunications;numerical analysis;combinatorial optimization;computer science;artificial intelligence;mathematics;network simulation;global optimum;telecommunications network	Theory	22.09848514313842	11.597627953420783	119514
b02aba65fb2792cee4fb0cbae12858195f383764	turboiso: towards ultrafast and robust subgraph isomorphism search in large graph databases	candidate region exploration;combine and permute strategy;neighborhood equivalence class;subgraph isomorphism	Given a query graph q and a data graph g, the subgraph isomorphism search finds all occurrences of q in g and is considered one of the most fundamental query types for many real applications. While this problem belongs to NP-hard, many algorithms have been proposed to solve it in a reasonable time for real datasets. However, a recent study has shown, through an extensive benchmark with various real datasets, that all existing algorithms have serious problems in their matching order selection. Furthermore, all algorithms blindly permutate all possible mappings for query vertices, often leading to useless computations. In this paper, we present an efficient and robust subgraph search solution, called TurboISO, which is turbo-charged with two novel concepts, candidate region exploration and the combine and permute strategy (in short, Comb/Perm). The candidate region exploration identifies on-the-fly candidate subgraphs (i.e, candidate regions), which contain embeddings, and computes a robust matching order for each candidate region explored. The Comb/Perm strategy exploits the novel concept of the neighborhood equivalence class (NEC). Each query vertex in the same NEC has identically matching data vertices. During subgraph isomorphism search, Comb/Perm generates only combinations for each NEC instead of permutating all possible enumerations. Thus, if a chosen combination is determined to not contribute to a complete solution, all possible permutations for that combination will be safely pruned. Extensive experiments with many real datasets show that TurboISO consistently and significantly outperforms all competitors by up to several orders of magnitude.	algorithm;approximation algorithm;benchmark (computing);biological network;chen–ho encoding;computation;entity–relationship model;experiment;graph database;han unification;holographic principle;lu decomposition;matching (graph theory);mathematical optimization;microsoft research;np-hardness;query optimization;subgraph isomorphism problem;trinity;turing completeness;vldb;vertex (geometry);yang	Wook-Shin Han;Jinsoo Lee;Jeong-Hoon Lee	2013		10.1145/2463676.2465300	computer science;data mining;subgraph isomorphism problem;database;induced subgraph isomorphism problem;algorithm	DB	14.210625502309444	16.278334808931486	119520
701de83308e80ea5b59eca6c8e570cd95aa987ff	solving multiple scenarios in a combinatorial auction	modelizacion;optimal solution;sector privado;politique sociale;programacion entera;politica publica;programmation en nombres entiers;politique gouvernementale;politica social;optimisation combinatoire;scenario;modelisation;social policy;secteur prive;argumento;integer programming;script;government policies;subasta;bidding;difference set;public policy;private sector;enchere;economies of scale;economy of scale;integer program;combinatorial optimization;modeling;economie d echelle;politique publique;optimizacion combinatoria;combinatorial auction	As part of its social policy, the government of Chile provides more than 1.8 million meals daily to public schoolchildren under the authority of Junta Nacional de Auxilio Escolar y Becas (JUNAEB), the state agency responsible for the program, at an annual cost of 360 million dollars. The service is provided by private firms chosen through an annual public auction. In order to capture economies of scale, a combinatorial auction design is implemented, allowing suppliers to bid on different sets of geographical units within the country. The bid evaluation process must solve multiple scenarios of a difficult combinatorial optimization model. To date, more than 2 billion dollars have been awarded under this methodology. In this paper, we describe the 2006 auction process and report that solution times can be significantly improved if the scenarios are solved in an appropriate order and the optimal solution to one scenario is employed as the initial solution of another. Results reflecting these improvements are given for real instances of the 2006 auction.	certificate authority;computation;mathematical optimization;procurement;time complexity	Jaime Catalán;Rafael Epstein;Mario Guajardo;Daniel Yung;Cristian Martinez	2009	Computers & OR	10.1016/j.cor.2008.12.006	spectrum auction;public policy;auction algorithm;mathematical optimization;combinatorial auction;generalized second-price auction;unique bid auction;economies of scale;revenue equivalence;mathematics;auction theory	ECom	17.443211471241106	5.80226658746613	119668
07b0056bf51eb1476221f00444c8a570a5c600e4	a new model for single machine scheduling with uncertain processing time		Uncertain single machine scheduling problem for batches of jobs is an important issue for manufacturing systems. In this paper, we use uncertainty theory to study the single machine scheduling problem with deadlines where the processing times are described by uncertain variables with known uncertainty distributions. A new model for this problem is built to maximize expected total weight of batches of jobs. Then the model is transformed into a deterministic integer programming model by using the operational law for inverse uncertainty distributions. In addition, a property of the transformed model is provided and an algorithm is designed to solve this problem. Finally, a numerical example is given to illustrate the effectiveness of the model and the proposed algorithm.		Kai Hu;Xingfang Zhang;Mitsuo Gen;Jungbok Jo	2017	J. Intelligent Manufacturing	10.1007/s10845-015-1033-9	mathematical optimization;real-time computing;computer science	AI	12.961386410554663	7.339023570382992	119692
1e71a41cf9a3e5a2a193b747b4aac8442f9f7aaf	design of a generalized job shop control system and pm packages	control system;job shop	Batch manufacture occurs where the demand for individual items is insufficient to justify the installation of dedicated resources and other mass manufacturing techniques for the production of each item. The batch manufacturing environment, or job shop, consists of general-purpose machine tools capable of being fitted with various tools and fixtures to perform a wide variety of jobs. Individual items are grouped in batches, and their production proceeds in a series of discontinuous steps.	control system	Harinder Jagdev	1988		10.1007/978-3-642-73318-5_15	real-time computing;flow shop scheduling;automotive engineering;manufacturing engineering	Robotics	10.604905006785344	4.333634327691208	119837
aac4a7284de41d9406dfab61a9a5e52eb63d20f1	cutting planes in combinatorics		In Chapter 26 of his book [2], George Dantzig presented side by side (i) a number of difficult mathematical problems reducible to integer linear programming problems, and (ii) Gornory's cutting-plane method for solving integer linear programming problems. In the same spirit, we are going to illustrate the use of cutting-plane arguments in the solution of combinatorial problems. To approach the subject gently, let us first consider the following problem from recreational mathematics [8]:	cutting-plane method;integer programming;linear programming	Vasek Chvátal	1985	Eur. J. Comb.	10.1016/S0195-6698(85)80031-7	mathematical optimization;combinatorics;integer programming;criss-cross algorithm;covering problems;branch and price;mathematics;branch and cut;cutting-plane method	Theory	24.606935976995597	11.993617589727402	119890
77e1dd200470d717b1ca3440cce4f2c1bf31e7c1	improving online algorithms via ml predictions		In this work we study the problem of using machine learned predictions to improve performance of online algorithms. We consider two classical problems, ski rental and non-clairvoyant job scheduling, and obtain new online algorithms that use predictions to make their decisions. These algorithms are oblivious to the performance of the predictor, improve with better predictions, but do not degrade much if the predictions are poor.		Manish Purohit;Zoya Svitkina;Ravi Kumar	2018			artificial intelligence;machine learning;job scheduler;online algorithm;computer science	Theory	14.508719081794974	11.733542951600459	120056
9a9b44e193fe8f3dbd8f6afbb5105d99885c1ca8	a primal-dual interpretation of two 2-approximation algorithms for the feedback vertex set problem in undirected graphs	minimisation;institutional repositories;graphe non oriente;graph theory;minimization;network design;teoria grafo;non directed graph;approximate algorithm;programacion entera;fedora;feedback vertex set;approximation algorithms;methode approchee;primal dual method;metodo aproximado;minimizacion;approximate method;methode primale duale;theorie graphe;programmation en nombres entiers;vital;algorithme;optimisation combinatoire;algorithm;metodo primal dual;integer programming;grafo no orientado;vtls;integer program;combinatorial optimization;ils;optimizacion combinatoria;algoritmo	Recently, Becker and Geiger and Bafna, Berman and Fujito gave 2-approximation algorithms for the feedback vertex set problem in undirected graphs. We show how their algorithms can be explained in terms of the primal–dual method for approximation algorithms, which has been used to derive approximation algorithms for network design problems. In the process, we give a new integer programming formulation for the feedback vertex set problem whose integrality gap is at worst a factor of two; the well-known cycle formulation has an integrality gap of (log n), as shown by Even, Naor, Schieber and Zosin. We also give a new 2-approximation algorithm for the problem which is a simpli cation of the Bafna et al. algorithm. c © 1998 Elsevier Science B.V. All rights reserved.	approximation algorithm;donald becker;feedback vertex set;graph (discrete mathematics);integer programming;linear programming relaxation;network planning and design;whole earth 'lectronic link	Fabián A. Chudak;Michel X. Goemans;Dorit S. Hochbaum;David P. Williamson	1998	Oper. Res. Lett.	10.1016/S0167-6377(98)00021-2	minimisation;mathematical optimization;network planning and design;combinatorics;integer programming;feedback vertex set;vertex cover;combinatorial optimization;graph theory;mathematics;approximation algorithm;algorithm	Theory	22.25806836341562	12.974539801249309	120095
1b00a7ea3ea2a581cb4fd3b3fead69b497a6cbb2	iems for large scale charging of electric vehicles: architecture and optimal online scheduling	charging service provider energy management system iems large scale charging electric vehicles optimal online scheduling network switched charging renewable source deterministic model arbitrary arrivals charging requests service deadlines multiprocessor deadline scheduling threshold admission and greedy scheduling tags purchasing price optimal charging price;pricing;energy management systems;greedy algorithms;battery chargers;scheduling;power system economics;electric vehicles;electricity optimal scheduling admission control scheduling algorithms pricing renewable energy sources computer architecture;scheduling battery chargers electric vehicles energy management systems greedy algorithms power system economics pricing	The problem of large scale charging of electric vehicles (EVs) is considered. An architecture for the energy management system (EMS) is proposed based on the concept of network switched charging where chargers are controlled by a scheduler that optimizes the overall operating profit of the service provider. It is assumed that the EMS has access to collocated renewable sources (e.g. solar power) and can supplement the renewable with purchased electricity from the grid. The renewable source may vary arbitrarily, and requests of all EVs accepted for service must be completed by their respective deadlines. Under a deterministic model for arbitrary arrivals, charging requests, and service deadlines, online scheduling of EV charging is formulated as a multi-processor deadline scheduling problem for which the optimal scheduler maximizes the competitive ratio against the best offline scheduler. An online scheduling algorithm, referred to as TAGS, is proposed based on the principle of threshold admission and greedy scheduling. TAGS has the complexity of O(n log n) where n is the number of EVs in the facility. It is shown that, when the price offered to the EV customers is higher than the purchasing price of electricity from the grid, TAGS achieves the competitive ratio of 1. Otherwise, TAGS achieves the maximum competitive ratio given by the inverse of a real root of a certain polynomial. Simulations are used to evaluate the performance of TAGS against standard benchmarks and for the setting of optimal charging price.	best, worst and average case;competitive analysis (online algorithm);computation;computer simulation;extended validation certificate;greedy algorithm;multiprocessing;online and offline;polynomial;procurement;purchasing;scheduling (computing);thread-local storage;variable pricing	Shiyao Chen;Lang Tong	2012	2012 IEEE Third International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2012.6486056	fair-share scheduling;fixed-priority pre-emptive scheduling;embedded system;real-time computing;dynamic priority scheduling;engineering;rate-monotonic scheduling;operations management	Embedded	13.853431817555855	10.7412543923873	120229
054a05782040c052bf9cf0be078492930afa887e	scheduling parallel jobs on heterogeneous platforms		We consider the problem of scheduling parallel jobs on heterogeneous platforms. Given a set J of n jobs where each job j∈J is described by a pair (pj, qj) with a processing time pj and number qj of processors required and a set of N heterogeneous platforms Pi with mi processors, the goal is to find a schedule for all jobs on the platforms minimizing the maximum completion time. The problem is directly related to a two-dimensional multi strip packing problem. Unless P=NP there is no approximation algorithm with absolute ratio better than 2 for the problem. We propose an approximation algorithm with absolute ratio 2 improving the previously best known approximation algorithms. This closes the gap between the lower bound of <2 and the best approximation ratio.	scheduling (computing)	Klaus Jansen;Denis Trystram	2016	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2016.10.003	mathematical optimization;real-time computing;mathematics;distributed computing;multiprocessor scheduling	Theory	15.544160317215614	11.264022377335792	120462
f9deeb8c9418b28ed6b015095fa1da24facde7ac	computational experience with a polynomial-time dual simplex algorithm for the transportation problem	transportation problem;probleme transport;simplex algorithm;simplex method;reseau;operations research;red;computer experiment;algorithme simplexe dual;polynomial time;technical report;methode simplexe;industrial engineering;network	This paper reports on the implementation of dual network simplex methods for solving the transportation problem. The implementation is based on an algorithm developed by Ikura and Nemhauser [6], which employs a special column selection rule to guarantee that the total number of dual simplex pivots is bounded by a polynomial in the number of sources and sinks and the sum of supplies and demands. By incorporating a scaling technique developed by Edmonds and Karp [3], the bound on the number of pivots becomes a polynomial in the input length. Recently dual simplex type algorithms [6], [10] have been shown to be theoretically efficient. These results motivated us to investigate if our polynomial-time dual simplex algorithm for the transportation problem is practically efficient as well. Our most interesting empirical finding is that scaling of supplies and demands is computationally very effective and reduces computation time by 30-50 percent. This conclusion is also supported by recent results (see [2], [5]) on network flow problems. These results refute the claim that scaling is merely a theoretical device for achieving polynomiality (e.g. [9,p. 158]). Our computational results also show that	computation;duplex (telecommunications);edmonds' algorithm;edmonds–karp algorithm;flow network;image scaling;polynomial;selection (user interface);selection rule;simplex algorithm;time complexity;transportation theory (mathematics)	Yoshiro Ikura;George L. Nemhauser	1986	Discrete Applied Mathematics	10.1016/0166-218X(86)90085-5	mathematical optimization;computer science;mathematics;simplex algorithm;operations research;algorithm	ML	21.743403191310446	13.292890876126169	120544
b8e72ec2ba6b97f51e5a5755cb1439d6f0e97306	some reverse location problems	location problem;polynomial algorithm;minmax criterion;tree network;minimum cut;facility location	The general location problem in a network is to ®nd locations of facilities in a given network such that the total cost is minimum. It is very often to have its reverse case, in which the facilities have already been located on the network, and the problem is how to improve the network within a given budget so that the improved network is as ecient as possible. In this paper we present a strongly polynomial algorithm for a reverse location problem in tree networks. The method can be extended to solve reverse twoor more-location problems. Ó 2000 Elsevier Science B.V. All rights reserved.	algorithm;linear programming;mathematical optimization;maxima and minima;minimum cut;misuse case;optimization problem;polynomial;regular expression;subroutine;time complexity;tree network	Jianzhong Zhang;Zhenhong Liu;Zhongfan Ma	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00122-8	mathematical optimization;combinatorics;minimum cut;minimum-cost flow problem;facility location problem;machine learning;mathematics;1-center problem	Theory	22.024298168477493	13.86249132872738	120778
ab00c1bfe35e21a2edb7287234af03f74a3ee3ae	solving rummikub problems by integer linear programming	integer linear programming;rummikub;game;integer linear program	The Rummikub problem of finding the maximal number or value of the tiles that can be placed from your rack onto the table is very difficult, since the number of possible combinations are enormous. We show that this problem can be modeled as an integer linear programming problem. In this way solutions can be found in 1 s. We extend the model such that unnecessary changes of the existing sets on the table are minimized.	integer programming;linear programming;maximal set	Dick den Hertog;P. B. Hulshof	2006	Comput. J.	10.1093/comjnl/bxl033	trial division;games;mathematical optimization;combinatorics;discrete mathematics;integer programming;linear-fractional programming;nearest integer function;computer science;linear programming relaxation;branch and price;cutting stock problem;change-making problem;highly cototient number;integer points in convex polyhedra;mathematics;branch and cut	Theory	23.904347109089244	13.285206832792317	120893
339b3a5d272020e224aaa2b896a06b91887b9e18	greed is good: near-optimal submodular maximization via greedy optimization		It is known that greedy methods perform well for maximizing monotone submodular functions. At the same time, such methods perform poorly in the face of non-monotonicity. In this paper, we show—arguably, surprisingly—that invoking the classical greedy algorithm O( √ k)-times leads to the (currently) fastest deterministic algorithm, called REPEATEDGREEDY, for maximizing a general submodular function subject to k-independent system constraints. REPEATEDGREEDY achieves (1 + O(1/ √ k))k approximation using O(nr √ k) function evaluations (here, n and r denote the size of the ground set and the maximum size of a feasible solution, respectively). We then show that by a careful sampling procedure, we can run the greedy algorithm only once and obtain the (currently) fastest randomized algorithm, called SAMPLEGREEDY, for maximizing a submodular function subject to k-extendible system constraints (a subclass of k-independent system constrains). SAMPLEGREEDY achieves (k + 3)-approximation with only O(nr/k) function evaluations. Finally, we derive an almost matching lower bound, and show that no polynomial time algorithm can have an approximation ratio smaller than k + 1/2 − ε. To further support our theoretical results, we compare the performance of REPEATEDGREEDY and SAMPLEGREEDY with prior art in a concrete application (movie recommendation). We consistently observe that while SAMPLEGREEDY achieves practically the same utility as the best baseline, it performs at least two orders of magnitude faster.	approximation algorithm;baseline (configuration management);deterministic algorithm;expectation–maximization algorithm;extensibility;fastest;greedy algorithm;p (complexity);polynomial;randomized algorithm;sampling (signal processing);submodular set function;monotone	Moran Feldman;Christopher Harshaw;Amin Karbasi	2017			mathematical optimization;entropy maximization;mathematical economics;welfare economics	ML	19.211065999193345	16.233200489473305	121041
ceb3ebc3f578035929650c23e9e8d9160f3211a7	clique partitioning with value-monotone submodular cost	max coloring;batch scheduling with compatibilities;partition into cliques;cardinality constraint;submodular functions;cost coloring	We consider the problem of partitioning a graph into cliques of bounded cardinality. The goal is to find a partition that minimizes the sum of clique costs where the cost of a clique is given by a set function on the nodes. We present a general algorithmic solution based on solving the problem variant without the cardinality constraint. We obtain constant factor approximations depending on the solvability of this relaxation for a large class of submodular cost functions which we call value-monotone submodular functions. For special graph classes we give optimal algorithms. © 2014 Elsevier B.V. All rights reserved.	algorithm;approximation;binary space partitioning;cardinality (data modeling);linear programming relaxation;submodular set function;monotone	José R. Correa;Nicole Megow	2015	Discrete Optimization	10.1016/j.disopt.2014.11.001	mathematical optimization;combinatorics;clique graph;discrete mathematics;submodular set function;mathematics	Theory	23.124094574793393	16.12836816120536	121529
70791069717885ed148095369ae5467b01dec59d	a hybrid relaxed planning graph-lp heuristic for numeric planning domains	quality metric;linear program ming;mixed integer program;linear program;static analysis;lp relaxation	Effective search control for numeric planning domains, in which appropriate numeric resource usage is critical to solving the problem, remains an open challenge in domainindependent planning. Most real-world problems rely on metric resources such as energy, money, fuel or materials. Despite the importance of numbers, few heuristics have been proposed to guide search in such domains. Hoffmann’s extended relaxation, implemented in Metric-FF, is one of the best general heuristics. We examine the behaviour of the Relaxed Planning Graph (RPG) heuristic, used by Metric-FF, in numeric problems. While effective in problems with simple numeric interactions, it has two weaknesses when numeric reasoning is a fundamental part of solving the problem. We present a new heuristic for use in strongly numeric domains, using a Linear Program to capture numeric constraints as an adjunct to a relaxed planning graph. We demonstrate that an intelligent combination of these two techniques offers greatly improved heuristic guidance.	heuristic (computer science);interaction;linear programming relaxation;rpg;state space search	Andrew Coles;Maria Fox;Derek Long;Amanda Jane Coles	2008			mathematical optimization;combinatorics;computer science;linear programming;linear programming relaxation;artificial intelligence;machine learning;symbolic-numeric computation;mathematics;static analysis;algorithm	AI	20.600399350829065	4.544112221654046	121584
458dc144ce57a39f5e160a93d8315c30ee924779	on-line k-truck problem and its competitive algorithms	competitive algorithm;pms;on line k truck problem;greedy algorithm;on line algorithm;structural properties;competitive ratio	In this paper, based on the Position Maintaining Strategy (PMS for short), on-line scheduling of k-truck problem, which is a generalization of the famous k-server problem, is originally presented by our team. We proposed several competitive algorithms applicable under different conditions for solving the on-line k-truck problem. First, a competitive algorithm with competitive ratio 2k + 1/θ is given for any θ ≥ 1. Following that, if θ ≥ (c + 1)/(c − 1) holds, then there must exist a (2k − 1)-competitive algorithm for k-truck problem, where c is the competitive ratio of the on-line algorithm about the relevant k-server problem. And then a greedy algorithm with competitive ratio 1 + λ/θ , where lambda is a parameter related to the structure property of a given graph, is given. Finally, competitive algorithms with ratios 1 + 1/θ are given for two special families of graphs.	approximation algorithm;competitive analysis (online algorithm);greedy algorithm;k-server problem;online algorithm;online and offline;scheduling (computing);server (computing)	Weimin Ma;Yin-Feng Xu;Kanliang Wang	2001	J. Global Optimization	10.1023/A:1017982528216	competitive analysis;mathematical optimization;combinatorics;greedy algorithm;machine learning;mathematics	Theory	16.4300387706699	10.402400285418718	122110
cfe75aaaecd882f18d92154939d3eaf2535de23e	network flow models for electronic barter exchanges	network flow	Electronic barter exchange sites are starting to appear on the Internet. In this article, I present three models for direct bartering of items without the use of barter units. The first model allows bartering of items with single instances. The second model barters items with multiple instances. Finally, the third model allows bartering collection of single instance items for other collection of items. In these models, my main objective is to maximize the number of items that are bartered. I also discuss other objectives. I develop a minimum cost network flow based algorithm for the problems described by the first and the second models. I make use of directed hypergraphs and integer programming to solve NP-hard Model 3 problems. I believe that the first model can be suitable for Internet domain name bartering. The second model, on the other hand, can be useful for music or book bartering. Efficient software is readily available for the minimum cost network flow problem and hence can be used for the soluti...	flow network	Can C. Özturan	2004	J. Org. Computing and E. Commerce	10.1207/s15327744joce1403_02	flow network;computer science;artificial intelligence;operations management;data mining	Logic	16.71227293901192	4.675967820620046	122485
4f58df2bfc0b50cb64c986d1b4c1c41f556cbe94	partitioning a street network into compact, balanced, and visually appealing routes		In practice, it is often desirable for the routes of vehicles to be compact and separate. A set of routes is compact if the streets serviced by each route are geographically clustered, and separated if the routes overlap minimally. We consider the Min-Max K Windy Rural Postman Problem MMKWRPP, in which the objective is to route a homogeneous fleet of K vehicles such that the cost of the longest route is minimized. We develop a heuristic that is algorithmically simple, produces solutions that are comparable in quality to those produced by an existing approach, and performs well with respect to metrics that quantify compactness and separation. Our heuristic uses a partitioning scheme in which the weight of a vertex includes contributions from both incident streets requiring service and the distance needed to travel to a vertex. We present computational results for a set of instances that we generate from real-world street networks and for a set of artificial instances. Our code is part of the Open-source Arc Routing Library OAR Lib at https://github.com/Olibear/ArcRoutingLibrary. © 2017 Wiley Periodicals, Inc. NETWORKS, Vol. 693, 290-303 2017		Oliver Lum;Carmine Cerrone;Bruce L. Golden;Edward A. Wasil	2017	Networks	10.1002/net.21730	street network;mathematical optimization;combinatorics;arc routing;vehicle routing problem;vertex (geometry);compact space;metaheuristic;heuristic;homogeneous;computer science	ML	23.59433682768847	7.450071599041676	122523
6be18acdd37c6f78f2849e6d59bc49f5f7e00af0	supply chain scheduling: sequence coordination	fabrication;optimisation;fabricacion;temps polynomial;optimizacion;gestion;chaine approvisionnement;efficient algorithm;cooperation;supply chain scheduling;prise decision;minimizacion funcion;decision maker;cooperacion;fonction objectif;objective function;polynomial time algorithm;minimizacion costo;minimisation cout;cost minimization;function minimization;optimal scheduling;informatique theorique;scheduling;manufacturing;polynomial time;algorithme polynomial;scheduling problem;funcion objetivo;supply chain;optimization;toma decision;management;ordonnancement;supply chain management;reglamento;minimisation fonction;computer theory;tiempo polinomial;informatica teorica	A critical issue in supply chain management is coordinating the decisions made by decision makers at different stages, for example a supplier and one or several manufacturers. We model this issue by assuming that both the supplier and each manufacturer have an ideal schedule, determined by their own costs and constraints. An interchange cost is incurred by the supplier or a manufacturer whenever the relative order of two jobs in its actual schedule is different from that in its ideal schedule. An intermediate storage buffer is available to resequence the jobs between the two stages. We consider the problems of finding an optimal supplier’s schedule, an optimal manufacturer’s schedule, and optimal schedules for both. The objective functions we consider are the minimization of total interchange cost, and of total interchange plus buffer storage cost. We describe efficient algorithms for all the supplier’s and manufacturers’ problems, as well as for a special case of the joint scheduling problem. The running time of these algorithms is polynomial in both the number of jobs and the number of manufacturers. Finally, we identify conditions under which cooperation between the supplier and a manufacturer reduces their total cost. © 2006 Elsevier B.V. All rights reserved.	algorithm;job stream;polynomial;schedule (computer science);scheduling (computing);supply chain attack;time complexity	Alessandro Agnetis;Nicholas G. Hall;Dario Pacciarelli	2006	Discrete Applied Mathematics	10.1016/j.dam.2005.04.019	time complexity;decision-making;supply chain management;mathematics;supply chain;manufacturing;fabrication;operations research;scheduling;cooperation	Theory	16.73305413408504	8.970238431040201	122609
60fbdb448aa9b9bdf4a4af0f2d41222e517d4a4d	a tight characterization of the performance of static solutions in two-stage adjustable robust linear optimization	49k35;90c47;90c46	In this paper, we study the performance of static solutions for twostage adjustable robust linear optimization problems with uncertain constraint and objective coefficients and give a tight characterization of the adaptivity gap. Computing an optimal adjustable robust optimization problem is often intractable since it requires to compute a solution for all possible realizations of uncertain parameters [16]. On the other hand, a static solution is a single (here and now) solution that is feasible for all possible realizations of the uncertain parameters and can be computed efficiently for most dynamic optimization problems. We show that for a fairly general class of uncertainty sets, a static solution is optimal for the twostage adjustable robust linear packing problems. This is highly surprising in view of the usual perception about the conservativeness of static solutions. Furthermore, when a static solution is not optimal for the adjustable robust problem, we give a tight approximation bound on the performance of the static solution that is related to a measure of non-convexity of a transformation of the uncertainty set. We also show that our bound is at least as good (and in many case significantly better) as the bound given by the symmetry of the uncertainty set [9,8]. V. Goyal is supported by NSF Grant CMMI-1201116, DOE Grant DE-AR0000235 and Google Research Award. B. Lu is supported by NSF Grant CMMI-1201116. Dimitris Bertsimas Sloan School of Management and Operations Research Center, Massachusetts Institute of Technology, Cambridge MA 02139. dbertsim@mit.edu Vineet Goyal Dept. of Industrial Engineering and Operations Research, Columbia University, New York NY 10027. vg2277@columbia.edu Brian Y. Lu Dept. of Industrial Engineering and Operations Research, Columbia University, New York NY 10027. yl2662@columbia.edu 2 D. Bertsimas, V. Goyal, and B. Lu	approximation;brian;coefficient;columbia (supercomputer);dynamic programming;ibm notes;industrial engineering;lu decomposition;linear programming;mathematical optimization;operations research;optimization problem;robust optimization;set packing	Dimitris Bertsimas;Vineet Goyal;Brian Y. Lu	2015	Math. Program.	10.1007/s10107-014-0768-y	mathematical optimization;control theory;mathematics	Theory	19.621329328004734	14.496312826656554	123115
8142be2ae2aaab88b56481912eed9901a529a451	a class of min-cut placement algorithms	assignment problem;distance measure;objective function;electrical circuit;lower bound	"""Summa r y In this paper we present a class of rain-cut placement algorithms for solving some assignment problems related to the physical implementation of electrical circuits. We discuss the need for abandoning classical objective functions based upon distance, and introduce new objective functions based upon """"signals-cut. """" The number of signals cut by a line c is a lower bound on the number of routing tracks which must cross c in routing the circuit. Three specific objective functions are introduced and the relationship between one of these and a classical distance measure based upon half-perimeter is presented. Two rain-cut placement algorithms are presented. They are referred to as C)uadrature and Slice/Bisec-tion. The concepts of a block and cut line are introduced. These two entitiesare the major constructs in developing any new min-cut placement algorithm. Mostofthe concepts presented have been implemented , and some experimental results are given."""	algorithm;assignment problem;dudebro: my shit is fucked up so i got to shoot/slice you ii: it's straight-up dawg time;minimum cut;perimeter;routing	Melvin A. Breuer	1977		10.1145/62882.62896	electrical network;mathematical optimization;combinatorics;mathematics;assignment problem;upper and lower bounds;algorithm;placement	EDA	24.138150585084173	16.705687636896197	123176
40c5660cc7e680d3ed3fcbe6f016ab8cc9aa9054	the complexity of cover inequality separation	binary integer programming;integer programming;linear time;linear program;integer program;separation problem;cover inequalities	Crowder et al. (Oper. Res. 31 (1983) 803-834) conjectured that the separation problem for cover inequalities for binary integer programs is polynomially solvable. We show that the general problem is NP-hard but a special case is solvable in linear time.	social inequality	Diego Klabjan;George L. Nemhauser;Craig A. Tovey	1998	Oper. Res. Lett.	10.1016/S0167-6377(98)00025-X	time complexity;mathematical optimization;combinatorics;discrete mathematics;integer programming;linear programming;branch and price;mathematics;algorithm	Graphics	24.294884636616107	14.208283548441694	123471
2b42de507a347740b041c6f26eb90957f2953be1	lower bounds on the performance of polynomial-time algorithms for sparse linear regression		Under a standard assumption in complexity theory (NP 6⊂ P/poly), we demonstrate a gap between the minimax prediction risk for sparse linear regression that can be achieved by polynomial-time algorithms, and that achieved by optimal algorithms. In particular, when the design matrix is ill-conditioned, the minimax prediction loss achievable by polynomial-time algorithms can be substantially greater than that of an optimal algorithm. This result is the first known gap between polynomial and optimal algorithms for sparse linear regression, and does not depend on conjectures in average-case complexity.	algorithm;average-case complexity;best, worst and average case;computational complexity theory;condition number;minimax;p/poly;polynomial;sparse matrix;time complexity	Yuchen Zhang;Martin J. Wainwright;Michael I. Jordan	2014			randomized algorithms as zero-sum games;mathematical optimization;combinatorics;probabilistic analysis of algorithms;mathematics	ML	16.827038836378662	18.067918395056523	123634
a9d4942d70a0c45cbe6b4f451e586f8aa443dba5	optimal sequencing of double-gripper gantry robot moves in tightly-coupled serial production systems	cycle time;stochastic process;production system;deterministic processing time optimal sequencing double gripper gantry robot moves tightly coupled serial production systems double gripper gantry robot scheduling tightly coupled automated serial production line scheduling;systeme production;product line;robots production systems optimal scheduling job shop scheduling manufacturing systems processor scheduling robotics and automation grippers flexible manufacturing systems manufacturing automation;sistema produccion;robot industriel;optimal control;production control;optimal scheduling;scheduling;industrial robots;robots;robot industrial;processus stochastique;portique;portal frame;scheduling problem;ordonamiento;optimal control industrial robots robots production control;proceso estocastico;manufacturing system;ordonnancement;portico;industrial robot	This study addresses the problem of scheduling double-gripper gantry robots and provides a structure for analyzing scheduling problems in a tightly-coupled automated serial production line with deterministic processing time. Literature to date indicates that there has been no documented effort dealing with the scheduling problem of double-gripper gantry robots. This paper presents an optimal schedule by analyzing the cycle time formula for two-station (m=2) tightly-coupled production lines served by a double-gripper gantry robot. The result is then generalized to the problem of scheduling a gantry robot in a production line with m (where m>2) workstations, and finally an optimal schedule for the m-station case is developed. The effectiveness of using double-gripper gantry robots is discussed and some analytical insights into the employment of double-gripper gantry robot are provided for manufacturing system designers.	cartesian coordinate robot	Qi Su;F. Frank Chen	1996	IEEE Trans. Robotics and Automation	10.1109/70.481748	robot;stochastic process;real-time computing;simulation;optimal control;cycle time variation;computer science;engineering;artificial intelligence;production system;scheduling;portal frame;portico	Robotics	10.510816127318094	5.471559930050857	123684
0005ad143a7ca7d60265447df8fb7e8e5d43ee2b	average-case analysis of the modified marmonic algorithm	multinomial distribution;bin packing;average case analysis;random variable;performance ratio	In this paper we analyze the average-case performance of the Modified Harmonic algorithm for on-line bin packing. We first analyze the average-case performance for arbitrary distribution of item sizes over (0,1]. This analysis is based on the following result. Letf1 andf2 be two linear combinations of random variables {Ni}i=1k where theNi's have a joint multinomial distribution for eachn=σi=1k,Ni. LetE(f1) ≠ O andE(f2)≠ 0. Then limn→∞E(max(f1,f2))/n = limn→∞ max(E(f1),E(f2))/n. We then consider the special case when the item sizes are uniformly distributed over (0,1]. For specific values of the parameters, the Modified Harmonic algorithm turns out to be better than the other two linear-time on-line algorithms—Next Fit and Harmonic—in both the worst case as well as the average case. We also obtain optimal values for the parameters of the algorithm from the average-case standpoint. For these values of the parameters, the average-case performance ratio is less than 1.19. This compares well with the performance ratios 1.333. and 1.2865. of the Next Fit algorithm and the Harmonic algorithm, respectively.	algorithm;best, worst and average case	Prakash V. Ramanan;Kazuhiro Tsuga	1986		10.1007/3-540-17179-7_11	random variable;mathematical optimization;combinatorics;bin packing problem;mathematics;multinomial distribution;statistics	EDA	15.987146254143141	12.672179931794586	123696
0a3478f9e1a58d2b2dc94817101ff7e057311c13	approximating carathéodory's theorem and nash equilibria		In this talk I will present an approximate version of Caratheodory’s theorem and its algorithmic applications. In particular, I will show that for every vector in the convex hull of a set of vectors X there exists a nearby (under p-norm distance, for p at least 2) vector that can be expressed as a convex combination of at most b vectors of X, where the bound b is independent of the dimension of the vectors. Given the significance of Caratheodory’s theorem, this approximate version is interesting in its own right. It also has notable algorithmic applications. Specifically, I will describe how this approximate version of Caratheodory’s theorem leads to a new algorithm for computing approximate Nash equilibria in two-player games. This algorithm, in particular, provides a polynomial-time approximation scheme for Nash equilibrium in games where the sum of the payoff matrices is sparse. Moreover, for arbitrary two-player games the running time of the algorithm matches the best-known upper bound, which is obtained in (Lipton, Markakis, and Mehta 2003). Arxiv preprint: http://arxiv.org/abs/1406.2296	approximation algorithm;convex hull;nash equilibrium;polynomial;polynomial-time approximation scheme;sparse matrix;time complexity	Siddharth Barman	2014	CoRR		convex hull;mathematical optimization;existential quantification;upper and lower bounds;nash equilibrium;matrix (mathematics);stochastic game;preprint;mathematics;convex combination	Theory	22.204579115740923	16.159078541062463	123833
f23c9783724b575cf1f178644c8f7b6e04ff376e	online set packing	online set packing;multipacket frames;randomized algorithm;competitive analysis;packet fragmentation;68w20;68w27	In online set packing (osp), elements arrive online, announcing which sets they belong to, and the algorithm needs to assign each element, upon arrival, to one of its sets. The goal is to maximize the number of sets that are assigned all their elements: a set that misses even a single element is deemed worthless. This is a natural online optimization problem that abstracts allocation of scarce compound resources, e.g., multi-packet data frames in communication networks. We present a randomized competitive online algorithm for the weighted case with general capacity (namely, where sets may have different values, and elements arrive with different multiplicities). We prove a matching lower bound on the competitive ratio for any randomized online algorithm. Our bounds are expressed in terms of the maximum set size and the maximum number of sets an element belongs to. We also present refined bounds that depend on the uniformity of these parameters.	circuit complexity;competitive analysis (online algorithm);data buffer;mathematical optimization;network packet;online algorithm;online optimization;optimization problem;randomized algorithm;set packing;telecommunications network;the matrix	Yuval Emek;Magnús M. Halldórsson;Yishay Mansour;Boaz Patt-Shamir;Jaikumar Radhakrishnan;Dror Rawitz	2012	SIAM J. Comput.	10.1137/110820774	competitive analysis;mathematical optimization;combinatorics;computer science;mathematics;randomized algorithm;ip fragmentation;algorithm	Theory	17.705984153379084	15.035805693888532	124103
57da10cbfdb9ec07ac95dbe86eaf1f21e2930ef4	scheduling logistic activities to improve hospital supply systems	workload;equilibrado;hospital;logistique;employe;adquisicion por suscripcion;compra;logistic;procurement;heuristic method;metodo heuristico;contrato;purchasing;hopital;soin;logistics;marche contrat;scheduling;care;balancing;charge travail;workload balancing;achat;coordinacion;supply chain;tabu search;employee;methode heuristique;carga trabajo;cuidado;empleado;equilibrage;ordonnancement;busqueda tabu;purchases;reglamento;recherche tabou;coordination;logistica;acquisition titre onereux	This paper presents an innovative approach for improving hospital logistics by coordinating the procurement and distribution operations while respecting inventory capacities. Instead of focusing on multi-echelon inventory decisions, our approach put the emphasis on the scheduling decisions: when to buy a product, when to deliver to each care unit, when each employee should work and what task should he do, etc. This promising strategy requires the elaboration of coordinated schedules that balance the activities through the purchasing cycle. We introduce two modelling approaches that can account for the numerous scheduling decisions in such environment. We present a tabu search metaheuristic that explores four different neighborhoods and which accommodates the two modelling approaches. We tested our models and algorithms on a real case extracted from a hospital based in Montreal, Canada. The supply schedules generated by our algorithm were considered by the hospital managers as efficient and well balanced. The approach may help hospitals to improve their logistics by better coordinating purchasing and procurement.	schedule (project management)	Sophie D. Lapierre;Angel B. Ruiz	2007	Computers & OR	10.1016/j.cor.2005.03.017	logistics;simulation;computer science;operations research	HCI	17.46731911672057	6.003295801936887	124185
05705aaaae9c68aaba233eebb36911b3d8081600	filtering bounded knapsack constraints in expected sublinear time	filtering;bounded knapsack	We present a highly efficient incremental algorithm for propagating bounded knapsack constraints. Our algorithm is based on the sublinear filtering algorithm for binary knapsack constraints by Katriel et al. and achieves similar speed-ups of one to two orders of magnitude when compared with its lineartime counterpart. We also show that the representation of bounded knapsacks as binary knapsacks leads to ineffective filtering behavior. Experiments on standard knapsack benchmarks show that the new algorithm significantly outperforms existing methods for handling bounded knapsack constraints.	binary number;continuous knapsack problem;dijkstra's algorithm;experiment;heuristic;jacop (solver);numerical method;solver;time complexity	Yuri Malitsky;Meinolf Sellmann;Radoslaw Szymanek	2010			filter;continuous knapsack problem;mathematical optimization;computer science;knapsack problem	AI	22.875510148187136	5.424916874382641	124504
468589d17617d661e42bde12c55569bcf9012691	graph domination, tabu search and the football pool problem	minimum dominating set;upper bound;tabu search algorithm;football;tabu search	"""We describe the use of a tabu search algorithm for generating near minimum dominating sets in graphs. We demonstrate the eeectiveness of this algorithm by considering a previously studied class of graphs, the so-called \football pool"""" graphs, and improving many of the known upper bounds for this class."""	covering code;dominating set;search algorithm;tabu search	Rowan Davies;Gordon F. Royle	1997	Discrete Applied Mathematics	10.1016/S0166-218X(96)00049-2	mathematical optimization;combinatorics;tabu search;machine learning;mathematics;upper and lower bounds;guided local search	Theory	23.291262423299052	12.813206489598402	124717
d5c0bc90144430794651f045313f36fe83cd3755	a note on the lower bound for the price of anarchy of scheduling games on unrelated machines	scheduling game;price of anarchy;worst case ratio;coordination mechanism	This note presents a lower bound for the Strong Price of Anarchy (SPoA) of coordination mechanisms for unrelated parallel machine scheduling games with social cost of minimizing the makespan. The SPoA of any set of non-preemptive strongly local policies satisfying the IIA property is at least m , the number of machines. Combining with the upper bound of the worst-case ratio of Shortest First algorithm for unrelated parallel machine scheduling problem with objective of minimizing the makespan (Ibarra and Kim, 1977), the SPoA of S P T policy, as well as the worst-case ratio of Shortest First algorithm, is exactly m .	anarchy;scheduling (computing)	Yujie Yan;Zhihao Ding;Zhiyi Tan	2015	Discrete Applied Mathematics	10.1016/j.dam.2015.01.013	mathematical optimization;mathematics;mathematical economics;price of anarchy	Theory	14.837709329924127	11.56677215779182	124897
4c1d67dd94454780f34596c688754727537ce678	new policies for the dynamic traveling salesman problem	traveling salesman problem;asymptotic optimality;dynamic fleet management;routing policies;waiting time;heavy traffic;stochastic and dynamic vehicle routing;dynamic vehicle routing	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	asymptotically optimal algorithm;circa;emoticon;francis;nl (complexity);primary source;travelling salesman problem	Gianpaolo Ghiani;Antonella Quaranta;Chefi Triki	2007	Optimization Methods and Software	10.1080/10556780701550026	traveling purchaser problem;2-opt;mathematical optimization;static routing;simulation;mathematics;travelling salesman problem;3-opt;bottleneck traveling salesman problem	Robotics	11.95165022492921	10.133953345138872	124947
742a7fd433be08f7c93a7d3140fb27d0a17eb974	polynomiality for bin packing with a constant number of item types	article	We consider the bin packing problem with d different item sizes si and item multiplicities ai, where all numbers are given in binary encoding. This problem formulation is also known as the 1-dimensional cutting stock problem. In this work, we provide an algorithm which, for constant d, solves bin packing in polynomial time. This was an open problem for all d ≥ 3. In fact, for constant d our algorithm solves the following problem in polynomial time: given two ddimensional polytopes P and Q, find the smallest number of integer points in P whose sum lies in Q. Our approach also applies to high multiplicity scheduling problems in which the number of copies of each job type is given in binary encoding and each type comes with certain parameters such as release dates, processing times and deadlines. We show that a variety of high multiplicity scheduling problems can be solved in polynomial time if the number of job types is constant.	algorithm;bin packing problem;binary file;cutting stock problem;polynomial;scheduling (computing);set packing;time complexity	Michel X. Goemans;Thomas Rothvoß	2014		10.1137/1.9781611973402.61	combinatorics;discrete mathematics;mathematics	Theory	15.986469795423087	11.381720234608983	125026
e3da899a231afe996d733860d6d3cc9953da39bc	scheduling file transfers in a distributed network	performance guarantee;approximate algorithm;distributed networks;role;script;polynomial time;performance bounds;enrollment	We consider a problem of scheduling file transfers in a network so as to minimize overall finishing time, which we formalize as a problem of scheduling the edges of a weighted multigraph. Although the general problem is NP-complete, we identify polynomial time solvable special eases and derive good performance bounds for several natural approximation algorithms. The above results assume the existence of a central controller, but we also show how the approximation algorithms, along with their performance guarantees, can be adapted to a distributed regime.	approximation algorithm;decision problem;multigraph;np-completeness;polynomial;scheduling (computing);time complexity	Edward G. Coffman;M. R. Garey;David S. Johnson;Andrea S. LaPaugh	1983		10.1145/800221.806726	time complexity;real-time computing;computer science;theoretical computer science;role;distributed computing;algorithm	Theory	14.386044969307706	11.9839485863306	125067
f0492a8eb608334d52b3a789eeabfe2bf8b2af94	kernelization as heuristic structure for the vertex cover problem	recouvrement graphe;invertebrata;cubierta grafo;vertex cover;swarm intelligence;parameterized complexity;intelligence en essaim;arthropoda;insecto social;methode noyau;metodo combinatorio;heuristic method;metodo heuristico;methode combinatoire;optimisation combinatoire;combinatorial problem;probleme combinatoire;graph covering;problema combinatorio;ant colony system;aculeata;insecta;metodo nucleo;kernel method;combinatorial method;hymenoptera;methode heuristique;insecte social;social insect;formicoidea;combinatorial optimization;inteligencia de enjambre;combinatorial optimisation;large scale problem;optimizacion combinatoria	For solving combinatorial optimisation problems, exact methods accurately exploit the structure of the problem but are tractable only up to a certain size; approximation or heuristic methods are tractable for very large problems but may possibly be led into a bad solution. A question that arises is, From where can we obtain knowledge of the problem structure via exact methods that can be exploited on large-scale problems by heuristic methods? We present a framework that allows the exploitation of existing techniques and resources to integrate such structural knowledge into the Ant Colony System metaheuristic, where the structure is determined through the notion of kernelization from the field of parameterized complexity. We give experimental results using vertex cover as the problem instance, and show that knowledge of this type of structure improves performance beyond previously defined ACS algorithms.	algorithm;ant colony;approximation;benchmark (computing);central processing unit;cobham's thesis;combinatorial optimization;heuristic;iteration;kernelization;mathematical optimization;metaheuristic;parameterized complexity;random graph;selection rule;vertex cover	Stephen Gilmour;Mark Dras	2006		10.1007/11839088_45	parameterized complexity;kernel method;mathematical optimization;combinatorics;vertex cover;combinatorial optimization;swarm intelligence;computer science;artificial intelligence;machine learning;mathematics;kernelization;algorithm	AI	22.35798685446292	6.2624137793283206	125206
bbb20debd036abff2d6a1b2eac109f1564364515	on a simple optimal stopping problem	optimal stopping problem	L.A. Shepp has posed aild analyzed the problem of optimal random drawinp with Jut replacement from an urn containing predetermined numbers of plus and minus balls. ;Here Shepp’s results are extended by improving the bounds on value; of penturbeu urns, deriving an exact algorithm for the urn values and computing the stopping boundary for urns of u-, tn 200 balls.	exact algorithm;optimal stopping	William M. Boyce	1973	Discrete Mathematics	10.1016/0012-365X(73)90123-4	mathematical optimization;combinatorics;optimal stopping;mathematics;mathematical economics	Theory	17.46911574132084	13.899787333666977	125213
48054e932d7cff0a879559ae41fc9cd8b2db5176	combinatorial prophet inequalities		We introduce a novel framework of Prophet Inequalities for combinatorial valuation functions. For a (non-monotone) submodular objective function over an arbitrary matroid feasibility constraint, we give an O(1)-competitive algorithm. For a monotone subadditive objective function over an arbitrary downward-closed feasibility constraint, we give an O(log n log r)-competitive algorithm (where r is the cardinality of the largest feasible subset). Inspired by the proof of our subadditive prophet inequality, we also obtain an O(log n · log r)-competitive algorithm for the Secretary Problem with a monotone subadditive objective function subject to an arbitrary downward-closed feasibility constraint. Even for the special case of a cardinality feasibility constraint, our algorithm circumvents an Ω( √ n) lower bound by Bateni, Hajiaghayi, and Zadimoghaddam [BHZ13] in a restricted query model. En route to our submodular prophet inequality, we prove a technical result of independent interest: we show a variant of the Correlation Gap Lemma [CCPV07, ADSY12] for non-monotone submodular functions.	algorithm;correlation gap;farkas' lemma;loss function;matroid;optimization problem;secretary problem;social inequality;submodular set function;value (ethics);monotone	Aviad Rubinstein;Sahil Singla	2017			competitive analysis;online algorithm;mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;algorithm	Theory	22.016748858609805	15.770789705876279	125300
a3a299f35d12ce74c152ee24730cee2302f3eb37	bandwidth allocation algorithms for weighted maximum rate constrained link sharing policy	pire cas;weighted scheduling;procesamiento informacion;algorithm analysis;time complexity;bandwidth allocation;algorithme;algorithm;temps calcul;cas moyen;complexite temps;sharing;particion;allocation largeur bande;informatique theorique;scheduling;information processing;gestion reseau;maximum rate constraint;analyse algorithme;contrainte taux maximim;network management;tiempo computacion;partage;computation time;complejidad tiempo;traitement information;analisis algoritmo;ordonnancement;reglamento;computer theory;algoritmo;informatica teorica	This paper addresses the problem of bandwidth allocation under the weighted maximum rate constrained link shari and proves a key theory in the condition of allocation termination. We propose several algorithms with various worst-c average-case time complexities, and evaluate their computation elapse times.  2005 Elsevier B.V. All rights reserved.	algorithm;average-case complexity;best, worst and average case;computation;memory management;saturation arithmetic;time complexity	Jeng-Farn Lee;Meng Chang Chen;Ming-Tat Ko;Wanjiun Liao	2006	Inf. Process. Lett.	10.1016/j.ipl.2005.11.006	network management;time complexity;information processing;computer science;artificial intelligence;operations research;scheduling;algorithm;dynamic bandwidth allocation;bandwidth allocation	AI	17.446283701682766	10.461446562102568	125540
20ebb09358a45a281352a03d9e81418d058ac844	new bounds for online packing lps	qa mathematics;qa76 electronic computers computer science computer software	Solving linear programs online has been an active area of research in recent years and was used with great success to develop new online algorithms for a variety of problems. We study the setting introduced by Ochel et al. as an abstraction of lifetime optimization of wireless sensor networks. In this setting, the online algorithm is given a packing LP and has to monotonically increase LP variables in order to maximize the objective function. However, at any point in time, the adversary only provides an α-approximation of the remaining slack for each constraint. This is designed to model scenarios in which only estimates of remaining capacities (e.g. of batteries) are known, and they get more and more accurate as the remaining capacities approach 0. Ochel et al. (ICALP’12) gave a Θ(lnα/α)-competitive online algorithm for this online packing LP problem and showed an upper bound on the competitive ratio of any online algorithm, even randomized, of O(1/ √ α). We significantly improve the upper bound and show that any deterministic online algorithm for LPs with d variables is at most O(dα/α)competitive. For randomized online algorithms we show an upper bound of O(mα/α) for LPs with m lnα variables. For LPs with sufficiently many variables, these bounds are O(ln α/α), nearly matching the known lower bound. On the other hand, we also show that the known lower bound can be significantly improved if the number of variables in the LP is small. Specifically, we give a deterministic Θ(1/ √ α)-competitive online algorithm for packing LPs with two variables. This is tight, since the previously known upper bound of O(1/ √ α) still holds for 2-dimensional LPs.	adversary (cryptography);competitive analysis (online algorithm);deterministic algorithm;linear programming;loss function;mathematical optimization;online algorithm;optimization problem;randomized algorithm;set packing;slack variable	Matthias Englert;Nicolaos Matsakis;Marcin Mucha	2014		10.1007/978-3-642-54423-1_28	mathematical optimization;combinatorics;computer science;mathematics;algorithm	Theory	19.971691594574573	16.433221973295954	125581
93567943d70842e1e7c1e9abc05cd2ddc362e8ab	linear programming based time lag identification in event sequences		Abstract Many technical systems like manufacturing plants or software applications generate large event sequences. Knowing the temporal relationship between events is important for gaining insights into the status and behavior of the system. This paper proposes a novel approach for identifying the time lag between different event types. This identification task is formulated as a binary integer optimization problem that can be solved efficiently and close to optimality by means of a linear programming approximation. The performance of the proposed approach is demonstrated on synthetic and real-world event sequences.		Marco F. Huber;Marc-Andre Zoller;Marcus Baum	2018	Automatica	10.1016/j.automatica.2018.08.025	binary integer decimal;mathematical optimization;software;linear programming;lag;mathematics;optimization problem	AI	14.473794253917296	7.526131787320283	125595
89eb7fe97a13bc6df09b3d37f32fa933512b636e	reoptimizing the 0-1 knapsack problem	heuristique;pire cas;optimal solution;optimisation;solution optimale;probleme sac a dos;reoptimization;approximate algorithm;combinatorics;algorithm performance;optimizacion;generic algorithm;heuristica;49j30;algorithme glouton;combinatoria;approximation algorithm;combinatoire;problema mochila;worst case analysis;68wxx;0 1 knapsack problem;knapsack problem;conception algorithme;resultado algoritmo;informatique theorique;solucion optima;algoritmo aproximacion;performance algorithme;greedy algorithm;algoritmo gloton;performance bounds;optimization;heuristics;algorithme approximation;49k30;68w25;analyse cas pire;computer theory;informatica teorica	In this paper we study the problem where an optimal solution of a knapsack problem on n items is known and a very small number k of new items arrive. The objective is to find an optimal solution of the knapsack problem with n + k items, given an optimal solution on the n items (reoptimization of the knapsack problem). We show that this problem, even in the case k = 1, is NP-hard and that, in order to have effective heuristics, it is necessary to consider not only the items included in the previously optimal solution and the new items, but also the discarded items. Then, we design a general algorithm that makes use, for the solution of a subproblem, of an α-approximation algorithm known for the knapsack problem. We prove that this algorithm has a worst-case performance bound of 1 2−α , which is always greater than α, and therefore that this algorithm always outperforms the corresponding α-approximation algorithm applied from scratch on the n+k items.We show that this bound is tight when the classical Ext-Greedy algorithm and the G 3 4 algorithm are used to solve the subproblem. We also show that there exist classes of instances on which the running time of the reoptimization algorithm is smaller than the running time of an equivalent PTAS and FPTAS. © 2010 Elsevier B.V. All rights reserved.	approximation algorithm;best, worst and average case;computational complexity theory;effective method;existential quantification;ext js javascript framework;greedy algorithm;heuristic (computer science);knapsack problem;np-hardness;ptas reduction;polynomial-time approximation scheme;relevance;time complexity;william m. ulrich	Claudia Archetti;Luca Bertazzi;Maria Grazia Speranza	2010	Discrete Applied Mathematics	10.1016/j.dam.2010.08.003	continuous knapsack problem;mathematical optimization;combinatorics;greedy algorithm;genetic algorithm;cutting stock problem;change-making problem;heuristics;mathematics;knapsack problem;approximation algorithm;algorithm	AI	18.656149044082817	10.659079050364099	125611
cde44bba5671fc581baa6fe52f2e7c553c07e081	semi-online machine covering for two uniform machines	assignment;online algorithm;asignacion;algorithme glouton;05bxx;algorithme en ligne;performance;assignation;algoritmo en linea;algorithm en ligne;68wxx;conception algorithme;probleme recouvrement;problema recubrimiento;informatique theorique;scheduling;complecion;greedy algorithm;competitive analysis;algoritmo gloton;machine scheduling;rendimiento;covering problem;semi online algorithms;05b40;completion;ordonnancement;analyse competitive;reglamento;competitive ratio;two machine scheduling;computer theory;68m20;informatica teorica	The machine covering problem deals with partitioning a sequence of jobs among a set of machines, so as to maximize the completion time of the least loaded machine. We study a semi-online variant, where jobs arrive one by one, sorted by non-increasing size. The jobs are to be processed by two uniformly related machines, with a speed ratio of q ≥ 1. Each job has to be processed continuously, in a time slot dedicated to it on one of the machines. This assignment needs to be performed upon the arrival of the job. The length of the time slot, which is required for a specific job to run on a given machine, is equal to the size of the job divided by the speed of the machine. We give a complete competitive analysis of this problem by providing an algorithm of the best possible competitive ratio for every q ≥ 1. We first give a tight analysis of the performance of a natural greedy algorithm LPT for the problem. To achieve the best possible performance for the semi-online problem, we use a combination of LPT , together with two alternative algorithms which we design. The new algorithms attain the best possible competitive ratios in the two intervalsq ∈ (1,√1.5) andq ∈ (2.4856, 1 +√3), respectively, whereas the greedy algorithm has the best possible competitive ratio for any other q ≥ 1.	competitive analysis (online algorithm);covering problems;greedy algorithm;job stream;online algorithm;parallel port;semiconductor industry	Xingyu Chen;Leah Epstein;Zhiyi Tan	2009	Theor. Comput. Sci.	10.1016/j.tcs.2009.08.001	competitive analysis;computer science;mathematics;algorithm	Theory	16.649653084806083	11.019874010187138	125929
6d51d5958b9e0c7b8ac58601f38ad9c41e2605b3	a linear approximation method for the shapley value	approximation lineaire;game theory;approximation error;coalitional game theory;time complexity;complexite calcul;approximation method;approximation algorithm;coalitional games;temps lineaire;linear approximation;teoria juego;voting game;complejidad lineal;intelligence artificielle;theorie jeu;tiempo lineal;linear complexity;error aproximacion;upper bound;qa75 electronic computers computer science;aleatorizacion;complejidad computacion;complexite temps;shapley value;computational complexity;voting;linear time;aproximacion lineal;comparative study;algoritmo aproximacion;randomisation;artificial intelligence;voto;inteligencia artificial;solution concept;vote;majority voting;algorithme approximation;complejidad tiempo;randomization;borne superieure;empirical evaluation;complexite lineaire;linear extension;erreur approximation;cota superior	The Shapley value is a key solution concept for coalitional games in general and voting games in particular. Its main advantage is that it provides a unique and fair solution, but its main drawback is the complexity of computing it (e.g for voting games this complexity is #P-complete). However, given the importance of the Shapley value and voting games, a number of approximation methods have been developed to overcome this complexity. Among these, Owen’s multi-linear extension method is the most time efficient, being linear in the number of players. Now, in addition to speed, the other key criterion for an approximation algorithm is its approximation error. On this dimension, the multi-linear extension method is less impressive. Against this background, this paper presents a new approximation algorithm, based on randomization, for computing the Shapley value of voting games. This method has time complexity linear in the number of players, but has an approximation error that is, on average, lower than Owen’s. In addition to this comparative study, we empirically evaluate the error for our method and show how the different parameters of the voting game affect it. Specifically, we show the following effects. First, as the number of players in a voting game increases, the average percentage error decreases. Second, as the quota increases, the average percentage error decreases. Third, the error is different for players with different weights; players with weight closer to the mean weight have a lower error than those with weight further away. We then extend our approximation to the more general k-majority voting games and show that, for n players, the method has time complexity O(k2n) and the upper bound on its approximation error is O(k2/√n).	approximation algorithm;approximation error;extension method;linear approximation;p-complete;sharp-p-complete;stable marriage problem;time complexity	S. Shaheen Fatima;Michael Wooldridge;Nicholas R. Jennings	2008	Artif. Intell.	10.1016/j.artint.2008.05.003	time complexity;game theory;computer science;artificial intelligence;mathematics;mathematical economics;approximation algorithm;algorithm	ECom	15.141815502075769	17.966812920747916	126081
efb74b4ee833906f643d42a394d25d95a3176ca7	minimum-cost multicast routing for multi-layered multimedia distribution	metodo relajacion;modelizacion;distributed system;largeur bande;systeme reparti;multimedia;formal model;routing;heuristic method;subgradient method;multidestinatario;routage;problema np duro;metodo heuristico;probabilistic approach;scale free network;random networks;methode relaxation;multicast tree;optimization problem;modelisation;network topology;np hard problem;sistema repartido;lagrangean relaxation;computer experiment;probleme np difficile;mathematical programming;enfoque probabilista;approche probabiliste;relaxation method;anchura banda;bandwidth;methode heuristique;modeling;programmation mathematique;topologie circuit;multicast routing;programacion matematica;multidestinataire;multicast;enrutamiento	In this paper, we attempt to solve the problem of min-cost multicast routing for multi-layered multimedia distribution. More specifically, for (i) a given network topology (ii) the destinations of a multicast group and (iii) the bandwidth requirement of each destination, we attempt to find a feasible routing solution to minimize the cost of a multicast tree for multi-layered multimedia distribution. This problem has been proved to be NP-hard. We propose two adjustment procedures, namely: the tie breaking procedure and the drop-and-add procedure to enhance the solution quality of the modified TM heuristic. We also formally model this problem as an optimization problem and apply the Lagrangean relaxation method and the subgradient method to solve the problem. Computational experiments are performed on regular networks, random networks, and scale-free networks. According to the experiment results, the Lagrangean based heuristic can achieve up to 23.23% improvement compared to the M-T-M heuristic.	algorithm;analysis of algorithms;computation;computational linguistics;experiment;flow network;heuristic (computer science);lagrangian relaxation;linear programming relaxation;mathematical optimization;maxima and minima;multicast;np-hardness;network topology;optimization problem;relaxation (approximation);relaxation (iterative method);routing;subgradient method	Hsu-Chen Cheng;Frank Yeong-Sung Lin	2004		10.1007/978-3-540-30189-9_9	optimization problem;mathematical optimization;routing;multicast;systems modeling;computer experiment;protocol independent multicast;computer science;subgradient method;scale-free network;np-hard;mathematics;distributed computing;distance vector multicast routing protocol;source-specific multicast;relaxation;network topology;bandwidth;algorithm;xcast	HPC	20.765661539793026	8.063509524866008	126097
09407ddea83446b6b70a9ce62a5672691562cf65	extensions of labeling algorithms for multi-objective uncertain shortest path problems			algorithm;shortest path problem	Andrea Raith;Marie Schmidt;Anita Schöbel;Lisa Thom	2018	Networks	10.1002/net.21815	mathematics;mathematical optimization;multi-objective optimization;robust optimization;shortest path problem	Theory	24.109461353152035	7.883827807116741	126125
b093214280c289f50667af00a870c866a25eedd5	algorithms for the generalized weighted frequency assignment problem	cross entropy;simulated annealing;frequency assignment;genetic algorithm;tabu search;heuristics	We report the performance of 15 construction heuristics to find initial solutions, and 4 search algorithms to solve a frequency assignment problem where the value of an assigned frequency is determined by the site where it is assigned. The algorithms were tested on 3 sets of problems, the first one corresponds to the well-known Philadelphia problems, and the last two correspond to situations frequently encountered when FM frequencies are assigned in Mexico. Our experimental results show that the construction heuristics that consider the weights of the sites perform well. Among the 4 search algorithms tested, the one based on cross entropy performed better than the others in small problems, whereas in large problems the algorithm based on simulated annealing performed the best.	algorithm;assignment problem	David F. Muñoz;Diego F. Muñoz	2012	Computers & OR	10.1016/j.cor.2012.04.015	mathematical optimization;combinatorics;genetic algorithm;simulated annealing;tabu search;computer science;heuristics;machine learning;mathematics;cross entropy	ECom	24.14571576823026	4.688045895243837	126136
10d39439af76b861945ed35ab28aea2e3b377a9c	the prize-collecting generalized steiner tree problem via a new approach of primal-dual schema	notorious densest k-subgraph problem;generalized steiner tree problem;combinatorial approach;approximation factor;general combinatorial technique;various problem;k-forest problem;prize-collecting version;prize-collecting generalized steiner tree;new approach;primal-dual schema;combinatorial algorithm;general combinatorial approach;nucleolus;lagrangian relaxation;np hard;steiner tree;steiner tree problem	In this paper we study the prize-collecting version of the Generalized Steiner Tree problem. To the best of our knowledge, there is no general combinatorial technique in approximation algorithms developed to study the prize-collecting versions of various problems. These problems are studied on a case by case basis by Bienstock et al. [5] by applying an LP-rounding technique which is not a combinatorial approach. The main contribution of this paper is to introduce a general combinatorial approach towards solving these problems through novel primal-dual schema (without any need to solve an LP). We fuse the primal-dual schema with Farkas lemma to obtain a combinatorial 3-approximation algorithm for the Prize-Collecting Generalized Steiner Tree problem. Our work also inspires a combinatorial algorithm [19] for solving a special case of Kelly's problem [22] of pricing edges.We also consider the k-forest problem, a generalization of k-MST and k-Steiner tree, and we show that in spite of these problems for which there are constant factor approximation algorithms, the k-forest problem is much harder to approximate. In particular, obtaining an approximation factor better than O(n1/6-ε) for k-forest requires substantially new ideas including improving the approximation factor O(n1/3-ε) for the notorious densest k-subgraph problem. We note that k-forest and prize-collecting version of Generalized Steiner Tree are closely related to each other, since the latter is the Lagrangian relaxation of the former.	approximation algorithm;combinatorial optimization;farkas' lemma;kelly criterion;lagrangian relaxation;linear programming relaxation;rounding;steiner tree problem	Mohammad Taghi Hajiaghayi;Kamal Jain	2006			mathematical optimization;combinatorics;discrete mathematics;steiner tree problem;k-ary tree;mathematics;algorithm	Theory	22.82068267530007	15.395364458725279	126176
165cce3a5e008b9675d4243b2f938a5b9fc335a9	a simpler proof for o(congestion + dilation) packet routing		In the store-and-forward routing problem, packets have to be routed along given paths such that the arrival time of the latest packet is minimized. A groundbreaking result of Leighton, Maggs and Rao says that this can always be done in time O(congestion + dilation), where the congestion is the maximum number of paths using an edge and the dilation is the maximum length of a path. However, the analysis is quite arcane and complicated and works by iteratively improving an infeasible schedule. Here, we provide a more accessible analysis which is based on conditional expectations. Like [LMR94], our easier analysis also guarantees that constant size edge buffers suffice. Moreover, it was an open problem stated e.g. by Wiese [Wie11], whether there is any instance where all schedules need at least (1 + ε) · (congestion + dilation) steps, for a constant ε > 0. We answer this question affirmatively by making use of a probabilistic construction.	dilation (morphology);network congestion;network packet;router (computing);routing;schedule (computer science);store and forward;time of arrival	Thomas Rothvoß	2012	CoRR			Theory	24.42558350483831	17.7904421734661	126269
a4bebd282e1ec68979251ed30f2e877f6a432a31	on competitive online read-many parallel disks scheduling	parallel disk model;online algorithm;disk scheduling;lower and upper bound;natural extension;upper bound;online algorithms;lower bound;competitive ratio	We consider the natural extension of the single disk caching problem to parallel disk I/O model. We close the existing gap between lower and upper bounds and achieve optimal competitive ratio of O(√D) when lookahead is more than the memory size M. When lookahead is smaller, we derive various upper bounds and lower bounds on the competitive ratio under various adversarial models.	competitive analysis (online algorithm);input/output;parsing;scheduling (computing)	Rahul Shah;Peter J. Varman;Jeffrey Scott Vitter	2005		10.1145/1073970.1074006	online algorithm;mathematical optimization;combinatorics;computer science;distributed computing;upper and lower bounds	Theory	16.093158773279406	12.453065546946208	126552
1821556c06912717ad8f798167082a2d0c2d79da	the progressive party problem: integer linear programming and constraint programming compared	discrete optimization;constraint programming;constraint satisfaction problem;combinatorial optimization;integer linear program	Many discrete optimization problems can be formulated as either integer linear programming problems or constraint satisfaction problems. Although ILP methods appear to be more powerful, sometimes constraint programming can solve these problems more quickly. This paper describes a problem in which the difference in performance between the two approaches was particularly marked, since a solution could not be found using ILP. The problem arose in the context of organizing a “progressive party” at a yachting rally. Some yachts were to be designated hosts; the crews of the remaining yachts would then visit the hosts for six successive half-hour periods. A guest crew could not revisit the same host, and two guest crews could not meet more than once. Additional constraints were imposed by the capacities of the host yachts and the crew sizes of the guests. Integer linear programming formulations which included all the constraints resulted in very large models, and despite trying several different strategies, all attempts to find a solution failed. Constraint programming was tried instead and solved the problem very quickly, with a little manual assistance. Reasons for the success of constraint programming in this problem are identified and discussed.	combinatorial optimization;computation;constraint programming;constraint satisfaction problem;discrete optimization;experiment;heuristic (computer science);integer programming;linear programming;mathematical optimization;organizing (structure);software propagation	Barbara M. Smith;Sally C. Brailsford;Peter M. Hubbard;H. Paul Williams	1996	Constraints	10.1007/BF00143880	constraint logic programming;concurrent constraint logic programming;discrete optimization;optimization problem;mathematical optimization;constraint programming;combinatorics;discrete mathematics;binary constraint;integer programming;constraint satisfaction;second-order cone programming;linear-fractional programming;combinatorial optimization;nonlinear programming;computer science;constraint graph;linear programming relaxation;branch and price;constraint satisfaction dual problem;mathematics;constraint;constraint satisfaction problem;hybrid algorithm;branch and cut;backtracking	AI	15.974340519521848	4.796543860095391	126656
fbed1792c082e9654520add6962051add1f007b3	optimal design of steel structures according to the eurocodes using mixed-integer linear programming methods,, ; optimaal ontwerp van stalen structuren volgens de eurocodes aan de hand van gemengd-discrete lineaire optimalisatiemethodes			linear programming;optimal design	Roxane Van Mellaert	2017				EDA	23.175994521124704	9.125659013157902	126702
99079294cf5f39524b315f8914f8927667f1739d	managing spatio-temporal complexity in hopfield neural network simulations for large-scale static optimization	simulation ordinateur;traveling salesman problem;hopfield model;complejidad espacio;modele hopfield;optimisation;systeme grande taille;optimizacion;time complexity;complexite calcul;modelo hopfield;point equilibre;travelling salesman problem;implementation;simulation;combinatorial optimization problem;optimization method;large scale system;weight matrix;huge data array;metodo optimizacion;equilibrium point;relajacion;hopfield neural network;algorithme;optimisation combinatoire;problema viajante comercio;optimization problem;algorithm;punto equilibrio;combinatorial problem;large scale;complejidad computacion;probleme combinatoire;complexite temps;large scale simulation;problema combinatorio;probleme commis voyageur;computational complexity;estructura datos;methode optimisation;coste;space complexity;simulation study;relaxation;optimization;structure donnee;simulacion computadora;complexite espace;reseau neuronal;complejidad tiempo;implementacion;combinatorial optimization;data structure;computer simulation;red neuronal;sistema gran escala;artificial neural network;large scale optimization;neural network;optimizacion combinatoria;cout;algoritmo	8 A simulation methodology, which trades space complexity with time complexity, to create the Hopfield neu9 ral network weight matrix, the costliest data structure for simulation of Hopfield neural network algorithm for 10 large-scale optimization problems, is proposed. Modular composition of a weight term of the Hopfield neural net11 work weight matrix for a generic static optimization problem, which facilitates construction and reconstruction of 12 the weights on demand during a simulation, is exposed. Proposed methodology is demonstrated on a static com13 binatorial optimization problem, namely the Traveling Salesman Problem (TSP), through the algebraic procedure 14 for temporal (versus spatial) weight matrix construction, pseudo code and C/C ++ code implementation, and an 15 associated simulation study. The proposed methodology is successfully tested through simulation on a general pur16 pose Windows TM-AMDTM platform for up to 1000 city Traveling Salesman Problem instance, which would require 17 approximately no less than 1TB of memory to be allocated simply to instantiate the weight matrix in the memory 18 space of the simulation process. 19 © 2003 Published by Elsevier B.V. on behalf of IMACS. 20	algorithm;artificial neural network;dspace;data structure;hopfield network;mathematical optimization;microsoft windows;optimization problem;pseudocode;simulation;terabyte;time complexity;travelling salesman problem	Gürsel Serpen	2004	Mathematics and Computers in Simulation	10.1016/j.matcom.2003.09.023	mathematical optimization;artificial intelligence;mathematics;travelling salesman problem;hopfield network;artificial neural network;algorithm;3-opt	ML	20.980447988411303	7.424898582748789	126723
7b23863585c25a2449f5a7946029e767d15eda9a	an improved approximation algorithm for the single machine total completion time scheduling problem with availability constraints	metodo caso peor;total completion time;tiempo total acabamiento;completion time;borne erreur;approximate algorithm;single machine scheduling;machine unique;approximation algorithm;heuristic method;temps total achevement;temps achevement;metodo heuristico;worst case analysis;availability constraints;single machine;maquina unica;makespan;computer experiment;scheduling;algoritmo aproximacion;methode cas pire;scheduling problem;methode heuristique;error bound;algorithme approximation;tiempo acabado;worst case method;ordonnancement;reglamento;limite error	In this paper, we study the single machine total completion scheduling problem subject to a period of maintenance. We propose an approximation algorithm to solve the problem with a worst case error bound of 3/17. Furthermore, an example is provided to show that the bound is tight. Computational experiments and an analysis are given afterwards.	approximation algorithm;scheduling (computing)	Cherif Sadfi;Bernard Penz;Christophe Rapine;Jacek Blazewicz;Piotr Formanowicz	2005	European Journal of Operational Research	10.1016/j.ejor.2003.08.026	job shop scheduling;mathematical optimization;computer experiment;computer science;operations management;mathematics;scheduling;algorithm	Theory	17.11949997274972	10.199452345443392	126778
687ff216ae8237d1f4d5251eb2a9a05e4d38c03c	the ring tree facility location problem		In this work we discuss a facility location variant of the capacitated ring tree problem. The new model generalizes vehicle routing problems and Steiner tree problems, yielding applicability in telecommunication and transportation networks. In this ring tree facility location problem (RTFLP) two layers of networks have to be designed to connect two different types of customers to a central depot. The first, or inner layer, consists of cycles that intersect in the depot and collect all type 2 customers, and some of the type 1 customers. An outer layer is represented by a forest that contains the remaining type 1 customers such that each tree shares exactly one vertex with the inner layer. Capacity bounds apply to the number of connected substructures emanating from the depot, the number of customers in each of these so-called ring trees, and in each tree of the forest. Additional optional Steiner vertices can be used to reduce the overall costs, which are layer-dependent edge costs and facility location costs at the vertices in which the two layers coincide. Our contribution is the introduction of the RTFLP, the development of two mathematical formulations, and preliminary computational results for the first RTFLP test set derived from instances from the literature.	cycles and fixed points;facility location problem;integer programming;nsa product types;steiner tree problem;test set;the forest;tree (data structure);vehicle routing problem;vertex (geometry)	Fabio Henrique N. Abe;Edna Ayako Hoshino;Alessandro Hill	2015	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2015.07.055	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	21.7659457080392	14.5705945562866	126895
644db272933d3a662a204bd68cf45841b62169a0	fundamentals of computation theory	computability theory;formal language;discrete mathematics	Aggregation problems arise when an expensive resource is shared by multiple agents. Shared access to this resource may result in agents incurring additional expenses, for example due to excessive wait time. This leads to a tradeoff between the frequency of access to the shared resource and the overhead costs for individual agents. Some participants of FCT may face this dilemma when heading to the airport after the conference. Sharing a cab saves overall cost, but it may create some inconvenience, or even additional expenses, if it results in an early or late arrival at the airport. Aggregation problems of this nature are ubiquitous. For example, in the TCP Acknowledgment Problem in networks, control acknowledgement packets can be aggregated and transmitted together. This reduces network traffic, but it can also result in undesirable delays and complicate congestion control. In the Joint Replenishment Problem, extensively studied in the operations research area, retailers place orders for a commodity at the supplier. To satisfy these orders, the supplier sends shipments of the commodity to a shared warehouse, which then redistributes them to the suppliers. The objective is to minimize the total shipment cost and the retailers’ cost of waiting for their shipments. This talk will survey the existing work on efficient algorithms for such aggregation problems, attempting to provide a unified perspective and emphasizing connections between different variants. We will discuss both offline and online algorithms, focussing mostly on recent results on approximation algorithms for these problems and on the remaining open problems. L. G ↪ asieniec and F. Wolter (Eds.): FCT 2013, LNCS 8070, p. 1, 2013. c © Springer-Verlag Berlin Heidelberg 2013	acknowledgment index;approximation algorithm;course (navigation);international symposium on fundamentals of computation theory;lecture notes in computer science;network congestion;network packet;online algorithm;online and offline;operations research;overhead (computing);social network aggregation;springer (tank)	Yuichi Asahiro;Hiroshi Eto;Takehiro Ito;Eiji Miyano	2013		10.1007/978-3-642-40164-0	model of computation;combinatorics;discrete mathematics;counting problem;computability theory;effective method;theory of computation;search problem;computability logic;theoretical computer science;decision problem;mathematics;computability;computable function;undecidable problem;reduction	Theory	13.105248372880299	10.122137749490516	126977
c1625e3db777ac3ec324377e081ae608662ce54c	shifting bottleneck scheduling for total weighted tardiness minimization - a computational evaluation of subproblem and re-optimization heuristics	total weighted tardiness;dominance rule;decomposition;shifting bottleneck procedure;job shop scheduling;iterated local search	Machine-based decomposition of total weighted tardiness job shops is known to be considerably more complicated than in the makespan case, mainly due to the structure of the underlying graph model and thus the arising one-machine subproblems. In fact, the effectiveness of a shifting bottleneck approach crucially depends on the employed subproblem solver. Although a sophisticated exact algorithm exists, problem instances involving more than 30 jobs are still challenging. In this paper, new heuristic approaches to subproblems of this kind are devised which rely on advanced problem-specific concepts like local optimality and dominance principles. The proposed subproblem solvers are combined with an iterated local search method for re-optimizing already scheduled machines. Computational experiments show that the final enhanced shifting bottleneck algorithms are not only applicable to job shops involving up to 100 jobs and 20 machines, but also able to improve existing results for benchmark instances. & 2015 Elsevier Ltd. All rights reserved.	benchmark (computing);best practice;computation;directed graph;embedded system;exact algorithm;experiment;generalized least squares;heuristic (computer science);iterated local search;iteration;job stream;list scheduling;local optimum;local search (optimization);makespan;mathematical optimization;minimum description length;scheduling (computing);solver	Roland Braune;Günther Zäpfel	2016	Computers & OR	10.1016/j.cor.2015.07.012	job shop scheduling;mathematical optimization;computer science;iterated local search;mathematics;decomposition;algorithm	AI	19.748727447314007	4.294704773152835	127137
7fe882da8a54df457bff275ce6719b38f3770ef9	informational braess' paradox: the effect of information on traffic congestion		To systematically study the implications of additional information about routes provided to certain users e.g., via GPS-based route guidance systems, we introduce a new class of congestion games in which users have differing information sets about the available edges and can only use routes consisting of edges in their information set. After defining the notion of an information-constrained wardrop equilibrium ICWE for this class of congestion games and studying its basic properties, we turn to our main focus: whether additional information can be harmful in the sense of generating greater equilibrium costs/delays. We formulate this question in the form of an informational Braessu0027 paradox IBP, which extends the classic Braessu0027 paradox in traffic equilibria and asks whether users receiving additional information can become worse off. We provide a comprehensive answer to this question showing that in any network in the series of linearly independent SLI class, which is a strict subset of series-parallel networks, the IBP cannot occur, and in any network that is not in the SLI class, there exists a configuration of edge-specific cost functions for which the IBP will occur. In the process, we establish several properties of the SLI class of networks, which include the characterization of the complement of the SLI class in terms of embedding a specific set of networks, and also an algorithm that determines whether a graph is SLI in linear time. We further prove that the worst-case inefficiency performance of ICWE is no worse than the standard Wardrop equilibrium.	algorithm;best, worst and average case;global positioning system;guidance system;moravec's paradox;network congestion;paradox (database);series-parallel graph;time complexity	Daron Acemoglu;Ali Makhdoumi;Azarakhsh Malekian;Asuman E. Ozdaglar	2018	Operations Research	10.1287/opre.2017.1712	linear independence;guidance system;time complexity;operations management;mathematical optimization;inefficiency;existential quantification;information set;embedding;traffic congestion;computer science	ECom	22.90837993659584	17.793441944879792	127183
89868a591212ca29766d7a56dfbfb93e10c1fe1e	provisional agreement protocol for global transportation scheduling	swinburne	The global transportation scheduling problem is complex, decentralised, open and dynamic. It typically requires the services of many transport organizations to transport partial quantities along partial routes to fulfill a transportation task. We have applied agents to address this problem. The Provisional Agreement Protocol (PAP) was developed to facilitate the planning required in our transportation problem. A greedy PAP approach has been implemented for the complex global transportation problem, allowing partial quantity and route bids, and backtracking if an infeasible solution is encountered. In this paper, we present the PAP, together with some improvements over that which has been previously presented. Further implementation details and formal evaluation are provided. Our implementation allows a wider range of transportation problems to be solved than previous approaches.	scheduling (computing)	Don Perugini;Dale Lambert;Leon Sterling;Adrian R. Pearce	2005		10.1007/3-7643-7363-6_2	computer science;scheduling (computing);distributed computing	Theory	21.072270296425206	4.486095535756888	127394
739bd2ae1107a679bf5c7ba5ec017c1a6f3c180a	a pso approach for software project planning	two phase;software project;pso;ebs;scheduling;sclpso;planning;staffing	Search-based software project management is a hot research point in software engineering. Based on the event-based scheduler (EBS) we have proposed in previous work [1], this paper intends to further propose a two-phase particle swarm optimization approach which uses a set-based representation for task scheduling and an integer representation for workload assignment scheduling to improve planning performance. Experimental results on 83 instances demonstrate the effectiveness of the proposed approach.	automated planning and scheduling;mathematical optimization;particle swarm optimization;scheduling (computing);software engineering;software project management;two-phase locking	Ya-Hui Jia;Wei-neng Chen;Xiaomin Hu	2014		10.1145/2598394.2598422	real-time computing;computer science;operations management;database	SE	13.574467910907765	6.4343884182204265	127510
bed794da6322a615eb6d8acbd733b8869b950383	on-line multi-threaded paging	appel unilateral;algorithm performance;lower and upper bound;proceso ligero;on line;en linea;equite;equidad;paging;analyse competition;equity;processus leger;resultado algoritmo;systeme multitache;smoothing;performance algorithme;alisamiento;llamada unilateral;competitive analysis;multithread;en ligne;multitâche;thread;on line algorithm;multitarea;lissage;multitask system;steady state	In this paper we introduce a generalization of Paging to the case where there are many threads of requests. This models situations in which the requests come from more than one independent source. Hence, apart from deciding how to serve a request, at each stage it is necessary to decide which request to serve among several possibilities. Four different on-line problems arise depending on whether we consider fairness restrictions or not, with finite or infinite input sequences. We study all of them, proving lower and upper bounds for the competitiveness of on-line algorithms. The main competitiveness results presented in this paper state that when no fairness restrictions are imposed it is possible to obtain competitive algorithms for finite and infinite inputs. On the other hand, for the fair case in general there exist no competitive algorithms. In addition, we consider three definitions of competitiveness for infinite inputs. One of them forces algorithms to behave efficiently at every finite stage, while the other two aim at comparing the algorithms' steady-state performances. A priori, the three definitions seem different. We study them and find, however, that they are essentially equivalent. This suggests that the competitiveness results that we obtain reflect the intrinsic difficulty of the problem and are not a consequence of a too strict definition of competitiveness.	competitive analysis (online algorithm);existential quantification;fairness measure;metrical task system;online algorithm;online and offline;paging;performance;randomized algorithm;steady state;thread (computing);unfair contract terms act 1977	Esteban Feuerstein;Alejandro Strejilevich de Loma	2001	Algorithmica	10.1007/s00453-001-0073-z	competitive analysis;thread;simulation;computer science;steady state;equity;algorithm;smoothing;paging	Theory	15.926048355991453	12.568849716854116	127752
aa0315545eadfee39e21c910ade559c51bbb1828	dynamic programming for the minimum tour duration problem	traveling salesman problem;dynamic programming;state space relaxation;tour duration;time windows	The minimum tour duration problem (MTDP) is the variant of the traveling salesman problem with time windows, which consists of finding a time window-feasible Hamiltonian path minimizing the tour duration. We present a new effective dynamic programming (DP)-based approach for the MTDP. When solving the traveling salesman problem with time windows with DP, two independent resources are propagated along partial paths, one for costs and one for earliest arrival times. For dealing with tour duration minimization, we provide a new DP formulation with three resources for which effective dominance and bounding procedures are applicable. This is a non-trivial task because in the MTDP at least two resources depend on each other in a non-additive and non-linear way. In particular, we define consistent resource extension functions (REF) so that dominance is straightforward using componentwise comparison for the respective resource vectors. Moreover, one of the main advantages of the new REF definition is that the DP can be reversed consistently such that the forward DP or any of its relaxations provides bounds for the backward DP, and vice versa. Computational test confirm the effectiveness of the proposed approach.	algorithm design;benchmark (computing);coefficient;column (database);column generation;computation;davis–putnam algorithm;duality (optimization);dynamic programming;hamiltonian path;lagrangian relaxation;lattice boltzmann methods;linear programming relaxation;maximal set;microsoft windows;moore neighborhood;nonlinear system;penalty method;subgradient method;theory;travelling salesman problem;undefined behavior;utility functions on indivisible goods;vehicle routing problem;von neumann neighborhood	Christian Tilk;Stefan Irnich	2017	Transportation Science	10.1287/trsc.2015.0626	mathematical optimization;computer science;operations management;dynamic programming;mathematics;travelling salesman problem;algorithm	ML	18.29428944120848	8.11157379303135	127843
b3694b31f87680207b20559441cc494d1e5feca9	an approximation scheme for two-machine flowshop scheduling with setup times and an availability constraint	machine papier;tiempo iniciacion;tiempo total acabamiento;paper machine;temps polynomial;availability;disponibilidad;temps total achevement;temps mise en route;permutation;aproximacion polinomial;setup time;makespan;scheduling;availability constraint;permutacion;approximation polynomiale;polynomial time;approximation scheme;scheduling problem;flowshop scheduling;atelier monogamme;maquina papel;disponibilite;journal magazine article;polynomial time approximation scheme;ordonnancement;flow shop;reglamento;polynomial approximation;tiempo polinomial	This paper studies the two-machine permutation flowshop scheduling problem with anticipatory setup times and an availability constraint imposed only on the first machine. The objective is to minimize the makespan. Under the assumption that interrupted jobs can resume their operations, we present a polynomial-time approximation scheme (PTAS) for this problem.	interrupt;job stream;makespan;ptas reduction;polynomial;polynomial-time approximation scheme;scheduling (computing);time complexity	Xiuli Wang;T. C. Edwin Cheng	2007	Computers & OR	10.1016/j.cor.2005.11.019	time complexity;job shop scheduling;availability;mathematical optimization;combinatorics;real-time computing;polynomial-time approximation scheme;flow shop scheduling;computer science;mathematics;permutation;scheduling	ECom	17.01953746534298	10.245344901236283	127931
7cc137c213e0f4fb1e1a6a3df499d8dc044ea114	fast fully polynomial approximation schemes for minimizing completion time variance	polynomial approximation	We present fully polynomial approximation schemes for the problem of minimizing completion time variance of a set of n jobs on a single machine. The fastest of these schemes runs in time O(n/ ) and thus improves on all fully polynomial approximation schemes presented in the literature.	approximation algorithm;combinatorial optimization;dynamic programming;experiment;fastest;mathematical optimization;polynomial;polynomial-time approximation scheme;time deviation	Wieslaw Kubiak;Jinliang Cheng;Mikhail Y. Kovalyov	2002	European Journal of Operational Research	10.1016/S0377-2217(01)00211-9	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;square-free polynomial	Theory	17.612357375443903	10.286807789775814	128152
357d377c36781791e974ce00a2b1b9964467eb05	parallel machine scheduling with machine availability and eligibility constraints	workload;metodo polinomial;infeasibility;tiempo total acabamiento;tiempo busqueda;maximum flow;temps polynomial;gestion labor;availability;disponibilidad;machine parallele;temps total achevement;temps recherche;parallel machine scheduling;flujo red;gestion tâche;makespan;polynomial method;inpractibilidad;network flows;scheduling;availability constraint;polynomial time;charge travail;infaisabilite;scheduling problem;binary search;parallel machines;task scheduling;network flow;carga trabajo;methode polynomiale;search time;disponibilite;flot reseau;ordonnancement;reglamento;eligibility constraint;tiempo polinomial	In this paper we consider the problem of scheduling n independent jobs on m identical machines incorporating machine availability and eligibility constraints while minimizing the makespan. Each machine is not continuously available at all times and each job can only be processed on specified machines. A network flow approach is used to formulate this scheduling problem into a series of maximum flow problems. We propose a polynomial time binary search algorithm to either verify the infeasibility of the problem or solve it optimally if a feasible schedule exists. 2006 Elsevier B.V. All rights reserved.	binary search algorithm;flow network;makespan;maximum flow problem;mean time between failures;parallel computing;polynomial;scheduling (computing);time complexity	Lu-Wen Liao;Gwo-Ji Sheen	2008	European Journal of Operational Research	10.1016/j.ejor.2006.11.027	job shop scheduling;open-shop scheduling;mathematical optimization;real-time computing;flow network;computer science;operations management;mathematics;distributed computing	AI	17.05764608401192	9.817534184890535	128495
02fc63e4d10f9816cb7892e4342bcba123a21a61	job-shop scheduling based on multiagent evolutionary algorithm	workload;multiagent system;gestion labor;job shop scheduling;intelligence artificielle;algoritmo genetico;atelier multigamme;gestion tâche;scheduling;charge travail;algorithme genetique;artificial intelligence;algorithme evolutionniste;genetic algorithm;job shop;algoritmo evolucionista;inteligencia artificial;evolutionary algorithm;task scheduling;carga trabajo;job shop scheduling problem;sistema multiagente;ordonnancement;reglamento;systeme multiagent	With the intrinsic properties of job-shop scheduling problems (JSPs) in mind, we integrate the multiagent systems and evolutionary algorithms to form a new algorithm, Multiagent Evolutionary Algorithm for JSPs (MAEAJSPs). In MAEA-JSPs, all agents live in a latticelike environment. Making use of the designed behaviors, MAEA-JSPs realizes the ability of agents to sense and act on the environment in which they live. During the process of interacting with the environment and the other agents, each agent increases energy as much as possible, so that MAEA-JSPs can find the optima. In the experiments, 59 benchmark JSPs are used, and good performance is obtained.	agent-based model;benchmark (computing);evolutionary algorithm;experiment;interaction;javaserver pages;job shop scheduling;multi-agent system;scheduling (computing)	Weicai Zhong;Jing Liu;Licheng Jiao	2005		10.1007/11539902_114	job shop scheduling;simulation;genetic algorithm;computer science;artificial intelligence;evolutionary algorithm;scheduling	AI	20.188084810860964	5.730428151701705	128716
232b6eef169591df4bf296dada130b74e3d80cc8	performance of evolutionary algorithms on random decomposable problems	bayes estimation;algoritmo paralelo;optimisation;parallel algorithm;optimizacion;heuristic method;multiplicite;metodo heuristico;probabilistic approach;algorithme parallele;estimacion bayes;enfoque probabilista;approche probabiliste;multiplicidad;algorithme evolutionniste;algoritmo evolucionista;optimization;methode heuristique;evolutionary algorithm;hierarchical bayesian optimization algorithm;optimal algorithm;multiplicity;estimation bayes	Martin Pelikan Missouri Estimation of Distribution Algorithms Lab (MEDAL) University of Missouri-St. Louis E-mail: pelikan@cs.umsl.edu Kumara Sastry Illinois Genetic Algorithms Lab (IlliGAL) University of Illinois at Urbana-Champaign E-mail: ksastry@uiuc.edu Martin V. Butz Department of Cognitive Psychology University of Wuerzburg, Germany E-mail: mbutz@psychologie.uni-wuerzburg.de David E. Goldberg Illinois Genetic Algorithms Lab (IlliGAL) University of Illinois at Urbana-Champaign E-mail: ksastry@uiuc.edu	estimation of distribution algorithm;evolutionary algorithm;genetic algorithm	Martin Pelikan;Kumara Sastry;Martin V. Butz;David E. Goldberg	2006		10.1007/11844297_80	mathematical optimization;computer science;machine learning;evolutionary algorithm;mathematics;parallel algorithm;multiplicity;algorithm	Theory	22.200578888720926	6.5815367274699605	128732
baeb09331c7d5daed215a02e930837c55f53c72e	two-sided truncations of inhomogeneous birth-death processes		We consider a class of inhomogeneous birth-death queueing models and obtain uniform approximation bounds of two-sided truncations. Some examples are considered. Our approach to truncations of the state space can be used in modeling information flows related to high-performance computing. INTRODUCTION It is well known that explicit expressions for the probability characteristics of stochastic birth-death queueing models can be found only in a few special cases. Therefore, the study of the rate of convergence as time t → ∞ to the steady state of a process is one of two main problems for obtaining the limiting behavior of the process. If the model is Markovian and stationary in time, then, as a rule, the stationary limiting characteristics provide sufficient or almost sufficient information about the model. On the other hand, if one deals with inhomogeneous Markovian model then, in addition, the limiting probability characteristics of the process must be approximately calculated. The problem of existence and construction of limiting characteristics for time-inhomogeneous birth and death processes is important for queueing and some other applications, see for instance, [1], [3], [5], [8], [15], [16]. General approach and related bounds for the rate of convergence was considered in [13]. Calculation of the limiting characteristics for the process via truncations was firstly mentioned in [14] and was considered in details in [15], uniform in time bounds have been obtained in [17]. As a rule, the authors dealt with the so-called northwest truncations (see also [9]), namely they studied the truncated processes with the same first states 0, 1, . . . , N In the present paper we consider a more general approach and deal with truncated processes on state space N1, N1 + 1, . . . , N2 for some natural N1, N2 > N1. Let X = X(t), t ≥ 0 be a birth and death process (BDP) with birth and death rates λn(t), μn(t) respectively. Let pij(s, t) = Pr {X(t) = j |X(s) = i} for i, j ≥ 0, 0 ≤ s ≤ t be the transition probability functions of the process X = X(t) and pi(t) = Pr {X(t) = i} be the state probabilities. Throughout the paper we assume that P (X (t+ h) = j|X (t) = i) = = qij (t)h+ αij (t, h) if j ̸= i, 1− ∑ k ̸=i qik (t)h+ αi (t, h) if j = i, (1) where all αi(t, h) are o(h) uniformly in i, i. e. supi |αi(t, h)| = o(h). Here all qi,i+1 (t) = λi(t), i ≥ 0, qi,i−1 (t) = μi(t) i ≥ 1, and all other qij(t) ≡ 0. The probabilistic dynamics of the process is represented by the forward Kolmogorov system of differential equations:  dp0 dt = −λ0(t)p0 + μ1(t)p1, dpk dt = λk−1(t)pk−1 − (λk(t) + μk(t)) pk+ +μk+1(t)pk+1, k ≥ 1. (2) By p(t) = (p0(t), p1(t), . . . ) , t ≥ 0, we denote the column vector of state probabilities and by A(t) = (aij(t)) , t ≥ 0 the matrix related to (2). One can see that A (t) = Q⊤ (t), where Q(t) is the intensity (or infinitesimal) matrix for X(t). We assume that all birth and death intensity functions λi(t) and μi(t) are linear combinations of a finite number of functions which are locally integrable on [0,∞). Moreover, we suppose that λn(t) ≤ Λn ≤ L < ∞, μn(t) ≤ ∆n ≤ L < ∞, (3) Proceedings 30th European Conference on Modelling and Simulation ©ECMS Thorsten Claus, Frank Herrmann, Michael Manitz, Oliver Rose (Editors) ISBN: 978-0-9932440-2-5 / ISBN: 978-0-9932440-3-2 (CD) for almost all t ≥ 0. Throughout the paper by ∥ · ∥ we denote the l1-norm, i. e. ∥x∥ = ∑ |xi|, and ∥B∥ = supj ∑ i |bij | for B = (bij)i,j=0. Let Ω be a set all stochastic vectors, i. e. l1 vectors with nonnegative coordinates and unit norm. Then we have ∥A(t)∥ ≤ 2 sup(λk(t) + μk(t)) ≤ 4L, for almost all t ≥ 0. Hence the operator function A(t) from l1 into itself is bounded for almost all t ≥ 0 and locally integrable on [0;∞). Therefore we can consider the system (2) as a differential equation dp dt = A (t)p, p = p(t), t ≥ 0, (4) in the space l1 with bounded operator function A(t). It is well known (see, for instance, [2]) that the Cauchy problem for differential equation (1) has unique solutions for arbitrary initial condition, and moreover p(s) ∈ Ω implies p(t) ∈ Ω for t ≥ s ≥ 0. Therefore, we can apply the general approach to employ the logarithmic norm of a matrix for the study of the problem of stability of Kolmogorov system of differential equations associated with nonhomogeneous Markov chains. The method is based on the following two components: the logarithmic norm of a linear operator and a special similarity transformation of the matrix of intensities of the Markov chain considered, see the corresponding definitions, bounds, references and other details in [4], [5], [13], [15], [17]. Definition. A Markov chain X(t) is called weakly ergodic, if ∥p∗(t) − p∗∗(t)∥ → 0 as t → ∞ for any initial conditions p∗(0),p∗∗(0). Here p∗(t) and p∗∗(t) are the corresponding solutions of (4). Put Ek(t) = E {X(t) |X(0) = k } ( then the corresponding initial condition of system (4) is the k − th unit vector ek). Definition. Let X(t) be a Markov chain. Then φ(t) is called the limiting mean of X(t) if lim t→∞ (φ(t)− Ek(t)) = 0	approximation;bandwidth-delay product;c date and time functions;enterprise content management;ergodic theory;ergodicity;expanded memory;initial condition;international standard book number;kolmogorov automorphism;markov chain;queueing theory;rate of convergence;simulation;state space;stationary process;steady state;supercomputer;taxicab geometry;the matrix;truncation	Yacov Satin;Anna Korotysheva;Ksenia Kiseleva;Galina Shilova;Elena Fokicheva;Alexander I. Zeifman;Victor Korolev	2016		10.7148/2016-0663	mathematical analysis;mathematics	ML	10.114798118966501	11.287272369142183	128787
48dd9c122bd67a070a33dacbb424cdac6134e81b	on the biobjective adjacent only quadratic spanning tree problem	multiobjective optimization;branch and bound	The adjacent only quadratic minimum spanning tree problem is an NP-hard version of the minimum spanning tree where the costs of interaction effects between every pair of adjacent edges are included in the objective function. This paper addresses the biobjective version of this problem. A Pareto local search algorithm is proposed. The algorithm is applied to a set of 108 benchmark instances. The results are compared to the optimal Pareto front generated by a branch and bound algorithm, which is a multiobjective adaptation of a well known algorithm for the mono-objective case.	approximation;benchmark (computing);branch and bound;exact algorithm;file spanning;local search (optimization);loss function;minimum spanning tree;optimization problem;pareto efficiency;search algorithm	Sílvia M. D. M. Maia;Elizabeth Ferreira Gouvea Goldbarg;Marco César Goldbarg	2013	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2013.05.135	euclidean minimum spanning tree;mathematical optimization;combinatorics;kruskal's algorithm;minimum degree spanning tree;spanning tree;prim's algorithm;minimum spanning tree;machine learning;mathematics;reverse-delete algorithm;distributed minimum spanning tree	Theory	24.195198802966527	5.5929349252883105	128901
9edb0ab8e09f2e738b990e04baa2de74ba204ff6	task schedulable problem and maximum scheduling problem in a multi-agent system	flow network;mas;maximum task scheduling problem;np complete;task schedulable problem;task scheduling	Tasks scheduling is a key problem in multi-agent system, traditional tasks scheduling methods can’t be applied to new application areas of the MAS such as emergency system. In order to apply the Agent method to these new areas, a multi-agent system model is built in this paper, and corresponding task schedulable problem and maximum scheduling problem are defined based on this multi-agent system model. Task schedulable problem is modeled using flow network, and it is proved that maximum flow algorithm can be used to solve such problem, which means the problem can be solved in polynomial time. Furthermore, by analyzing the flow network model, a necessary and sufficient condition which can be used to determine whether tasks can be scheduled is gained and proved. Three approximation algorithms have been proposed to solve the maximum scheduling problem. The experiment results show that all above algorithms can get pretty solutions in solving maximum scheduling problem, and the approximation ratio for optimal solution of these approximation algorithms are all larger than or equal to 0.5 even though the resource ratio is very low.	approximation algorithm;flow network;maximum flow problem;multi-agent system;network model;polynomial;principle of maximum entropy;scheduling (computing);time complexity	Bin Li;Xiaowei Zhang;Jun Wu;Junwu Zhu	2011	JSW		fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;open-shop scheduling;mathematical optimization;real-time computing;flow network;np-complete;minimum-cost flow problem;multi-commodity flow problem;dynamic priority scheduling;computer science;generalized assignment problem;rate-monotonic scheduling;two-level scheduling;distributed computing;round-robin scheduling;multiprocessor scheduling	AI	16.293925815364595	9.248451983433563	129110
572c903c708fa1d9922904b0701c8b999efbbfea	migration plans with minimum overall migration time	optimized production technology;optimized production technology hardware;hardware	In this paper we concentrate on finding the best migration plan, that is, a partial ordering of live migrations that realizes a move from the current to the desired placement, takes the minimal possible time, and maintains the placement constrains throughout the process. This is not an easy task since additional resources and intermediate migrations may be needed in order to maintain feasibility; in fact, we show that even for a simple model, capturing only the critical aspects of the problem, computing the optimal migration plan is NP hard. We develop algorithms that find feasible migration plans and prove that their overall migration time is within an adaptive constant factor from the optimal possible time. Then, using data from real cloud placements, we evaluate the expected performance of these algorithms in realistic scenarios. Our results indicate that the algorithms perform very well under these realistic conditions.	algorithm;np (complexity);np-hardness	Alexander Nus;Danny Raz	2014	2014 IEEE Network Operations and Management Symposium (NOMS)	10.1109/NOMS.2014.6838358	real-time computing;simulation;computer science	Theory	14.012519347067915	9.592869910396079	129164
4c4347f1492f4589ad37ba8a708757ea12d95af0	using cutting planes to solve the symmetric travelling salesman problem	hamiltonian cycle;cutting plane;travelling salesman problem;branch and bound	Two algorithms using cutting planes are developed for solving the Travelling Salesman Problem. In both algorithms the problem is started with a subset of the set of constraints that define the problem (apart from integrality requirements).	travelling salesman problem	P. Miliotis	1978	Math. Program.	10.1007/BF01609016	hamiltonian path;2-opt;mathematical optimization;combinatorics;discrete mathematics;lin–kernighan heuristic;cutting stock problem;mathematics;travelling salesman problem;branch and bound;3-opt;bottleneck traveling salesman problem;cutting-plane method	Theory	23.29719841859428	12.676390656280406	129254
068a56ac3ec358e5a1b74abf7ce36f847965b458	on scheduling a photolithography area containing cluster tools		Photolithography is typically the bottleneck process in semiconductor manufacturing. In this paper, we present a model for optimizing the scheduling of the photolithography process in the presence of both individual and cluster tools. The combination of these individual and cluster tools that process various layers (stages) of the semiconductor manufacturing process flow is a special type of flexible flowshop. We seek separately to minimize total weighted completion time and maximize on-time delivery performance. Experimental results suggest that our solution algorithms show promise for real world implementation as they can help to improve resource utilization, reduce job completion times, and decrease unnecessary delays in a wafer fab.	algorithm;downtime;heuristic;integer programming;job scheduler;job stream;linear programming;loss function;optimization problem;scheduling (computing);semiconductor device fabrication;semiconductor fabrication plant;software release life cycle	Sreenath Chalil Madathil;Siddhartha Nambiar;Scott J. Mason;Mary E. Kurz	2018	Computers & Industrial Engineering	10.1016/j.cie.2018.05.036	photolithography;engineering;wafer fabrication;delivery performance;real-time computing;scheduling (computing);semiconductor device fabrication;bottleneck	Robotics	12.804252408407873	5.196645882756333	129352
82176d2009cc720d3899fc5cd82d862f7349a8de	a fast algorithm for the two-variable integer programming problem	greatest common divisor;word length;fast algorithm;integer program	An algorithm that solves any two-variable integer programming problem is presented. A constant word-length model for the data is assumed. The complexity for a problem with m constraints and word length of L digits iS bounded by the maximum of two values. The first, which is O(mlogm) steps, is a bound on the complexity of finding the convex region bounded by the constraints, each step being an arithmetic orperation or a compare. The second, which Is O(mL) steps, is the complexity of solving m greatest-common-divisor problems. The algorithm finds a minimal binding set of constraints for any given problem, in addition to finding the soluuon set. A new method of solving three constraint problems is introduced.	algorithm;convex set;integer programming	Sidnie Dresher Feit	1984	J. ACM	10.1145/2422.322417	mathematical optimization;combinatorics;discrete mathematics;integer programming;nearest integer function;computer science;branch and price;change-making problem;integer square root;mathematics;pohlig–hellman algorithm;divisor;prime factor;greatest common divisor;algorithm;integer relation algorithm;multiple	Theory	24.233854955139197	13.98673555683458	129562
005a0f844a4d1b8391f45a7ef8078ef29b40bb2c	a sequence-pair and mixed integer programming based methodology for the facility layout problem	facility layout problem;sequence pair representation;dissertation;mixed integer programming		integer programming;linear programming	Qi Liu	2004			mathematical optimization;combinatorics;integer programming;branch and price;theoretical computer science;mathematics	Theory	22.689389181921268	9.042061067051312	129597
c149b61511397e066df99def884158a32c34aa4a	the simulated greedy algorithm for several submodular matroid secretary problems	004;secretary problem submodular function matroid online algorithm	We study the matroid secretary problems with submodular valuation functions. In these problems, the elements arrive in random order. When one element arrives, we have to make an immediate and irrevocable decision on whether to accept it or not. The set of accepted elements must form an independent set in a predefined matroid. Our objective is to maximize the value of the accepted elements. In this paper, we focus on the case that the valuation function is a non-negative and monotonically non-decreasing submodular function. #R##N##R##N#We introduce a general algorithm for such submodular matroid secretary problems. In particular, we obtain constant competitive algorithms for the cases of laminar matroids and transversal#R##N#matroids. Our algorithms can be further applied to any independent set system defined by the intersection of a constant number of laminar matroids, while still achieving constant competitive ratios. Notice that laminar matroids generalize uniform matroids and partition matroids. #R##N##R##N#On the other hand, when the underlying valuation function is linear, our algorithm achieves a competitive ratio of 9.6 for laminar matroids, which significantly improves the previous#R##N#result.	greedy algorithm;matroid;secretary problem;submodular set function	Tengyu Ma;Bo Tang;Yajun Wang	2013		10.4230/LIPIcs.STACS.2013.478	matroid;mathematical optimization;combinatorics;discrete mathematics;graphic matroid;computer science;submodular set function;mathematics;weighted matroid;matroid partitioning;algorithm	Theory	17.74334988240512	15.31929075073508	129706
f88c2bae33d0abbb098c6439c90ccb5b7e768bce	average case analysis of blocks relocation heuristics		We consider the Blocks Relocation Problem (BRP) where some blocks stored in stacks have to be removed and where the order in which the blocks are to be removed is given in advance. We are only allowed to remove a block on top of a stack or to relocate a block from the top of a stack to the top of another stack. The objective is to remove the blocks using a minimum number of relocations. We present a simple BRP heuristic similar to a heuristic presented by Caserta and Vos. Under certain assumptions on the stack capacity and the initial stack height, we formally show that the heuristic produces high quality solutions with high probability for large BRP instances. For any positive numbers e 1 and e 2 we show how the heuristic – under the assumptions mentioned above – can be used to construct a polynomial time algorithm that for any n solves a fraction of 1 − e 1 of all BRP instances of size n using no more than 1 + e 2 times the optimal number of relocations.	best, worst and average case;heuristic (computer science);relocation (computing)	Martin Olsen;Allan Gross	2014		10.1007/978-3-319-11421-7_6	time complexity;computer science;theoretical computer science;mathematical optimization;stack (abstract data type);relocation;heuristic;case analysis;heuristics	AI	18.897015520671978	17.089224985655203	129819
ce48fe1cc65631df6719968d730657f7f09499ee	an efficient algorithm for computing the i th letter of 4 n a	approximation algorithm;worst case analysis;setup time;scheduling;approximation scheme			Jeffrey Shallit;David Swart	1999			mathematical optimization;combinatorics;polynomial-time approximation scheme;computer science;theoretical computer science;scheduling;minimax approximation algorithm;approximation algorithm	NLP	17.970188963369353	11.800024173167637	130186
ebd93612ce2d84c46c21f740485969216745a111	a genetic algorithm for job sequencing problems with distinct due dates and general early-tardy penalty weights	organigramme;job management;flowchart;cost function;machine unique;gestion production;heuristic method;simulacion numerica;cost reduction;formulacion;etude methode;date echeance;estudio metodo;algoritmo genetico;production management;single machine;funcion penalidad;scheduling;gestion produccion;exact algorithm;simulation numerique;due date;algorithme genetique;fecha vencimiento;genetic algorithm;ordonamiento;gestion trabajos;method study;fonction penalite;gestion travaux;job scheduling;organigrama;formulation;ordonnancement;penalty function;numerical simulation	A job scheduling problem with distinct due dates in a single machine is considered. General penalty weights which are not necessarily proportional to the processing times are applied to jobs either early or tardy. An optimal timing algorithm is presented which decides the optimal starting time of each job in a given job sequence. Idle times are inserted between blocks of jobs such that the cost function of each newly created job block is minimized. Prominent near optimal sequences are generated via a genetic algorithm N best reproduction without duplicates, uniform order-based crossover and intra-block mutation operators are employed. The proposed genetic algorithm is proved to outperform existing heuristic methods. On average, 12-33% cost reduction effect is obtained by the evolution algorithm compared to the solution by an excellent heuristic procedure. The near optimality of the solutions by the GA is also illustrated by the comparison with an exact algorithm.	exact algorithm;genetic algorithm;heuristic;job scheduler;job shop scheduling;job stream;loss function;scheduling (computing);software release life cycle	Chae-Young Lee;Jae Young Choi	1995	Computers & OR	10.1016/0305-0548(94)00073-H	computer simulation;genetic algorithm;flowchart;computer science;job scheduler;penalty method;formulation;operations research;scheduling;algorithm	HPC	17.30385208116512	8.401544301738765	130196
70c19de550bec0a38df5bd61fdb0ee1d2cb29322	incremental algorithms for facility location and k-median	optimal solution;location problem;online algorithm;configuracion;solution optimale;probleme localisation;equipement collectif;algorithme en ligne;performance;incremental clustering;algoritmo en linea;equipamiento colectivo;clustering;informatique theorique;solucion optima;facility;problema localizacion;incremental algorithm;online algorithms;rendimiento;performance ratio;configuration;algorithme incremental;facility location;computer theory;informatica teorica	In the incremental versions of Facility Location and k-Median, the demand points arrive one at a time and the algorithm maintains a good solution by either adding each new demand to an existing cluster or placing it in a new singleton cluster. The algorithm can also merge some of the existing clusters at any point in time. For Facility Location, we consider the case of uniform facility costs, where the cost of opening a facility is the same for all points, and present the first incremental algorithm which achieves a constant performance ratio. Using this algorithm as a building block, we obtain the first incremental algorithm for k-Median which achieves a constant performance ratio using O(k) medians. The algorithm is based on a novel merge rule which ensures that the algorithm’s configuration monotonically converges to the optimal facility locations according to a certain notion of distance. Using this property, we reduce the general case to the special case when the optimal solution consists of a single facility.	dijkstra's algorithm;dynamic problem (algorithms);facility location problem;k-medians clustering	Dimitris Fotakis	2006	Theor. Comput. Sci.	10.1016/j.tcs.2006.05.015	online algorithm;mathematical optimization;simulation;computer science;mathematics;1-center problem;algorithm	Theory	20.528702039121363	13.99035960215048	130420
e4cce0d14e0fcb014f465fb68e14c8dee75f30a0	approximation algorithms for a bi-level knapsack problem	bilevel knapsack problem;approximation algorithms	In this paper, we consider a variant of the knapsack problem. There are two knapsacks with probably different capacities, owned by two agents respectively. Given a set of items, each with a fixed size and a profit. The two agents select items and pack them into their own knapsacks under the capacity constraint. Same items can be packed simultaneously to different knapsacks. However, in this case the profit of such items may vary. One agent packs items into his knapsack to maximize the total profit, while another agent can only pack items into his knapsack as well but he cares about the total profits of items packed into two knapsacks. The latter agent is a leader while the former is a follower. We aim at designing an approximation algorithm for the leader assuming that the follower is selfish. For different settings we provide approximation results.	approximation algorithm;black and burst;knapsack problem	Lin Chen;Guochuan Zhang	2013	Theor. Comput. Sci.	10.1016/j.tcs.2012.08.008	continuous knapsack problem;mathematical optimization;computer science;mathematics;mathematical economics;knapsack problem;approximation algorithm;algorithm	ECom	17.160955055653066	7.77847113039843	130531
3fd1efe12d410b7f73e6c75e1bf7e9acb74c116f	branch and bound search for automatic linking process of seismogram	branch and bound		branch and bound	Kou-Yuan Huang;King-Sun Fu;Z. S. Lin	1985			seismogram;mathematical optimization;branch and bound;algorithm;mathematics	Vision	22.922687677576118	8.99322667581319	130825
2141707665aab09d092f8a528bc8252569358de4	large neighborhood search for the most strings with few bad columns problem		In this work we consider the following NP -hard combinatorial optimization problem from computational biology. Given a set of input strings of equal length, the goal is to identify a maximum cardinality subset of strings that di er maximally in a pre-de ned number of positions. First of all we introduce an integer linear programming model for this problem. Second, two variants of a rather simple greedy strategy are proposed. Finally, a large neighborhood search algorithm is presented. A comprehensive experimental comparison among the proposed techniques shows, rst, that larger neighborhood search generally outperforms both greedy strategies. Second, while large neighborhood search shows to be competitive with the stand-alone application of CPLEX for small and medium sized problem instances, it outperforms CPLEX in the context of larger instances.	cplex;column (database);combinatorial optimization;computation;computational biology;greedy algorithm;integer programming;linear programming;local search (optimization);mathematical optimization;optimization problem;programming model;search algorithm	Evelia Lizárraga;Maria J. Blesa;Christian Blum;Günther R. Raidl	2017	Soft Comput.	10.1007/s00500-016-2379-4	mathematical optimization;theoretical computer science;machine learning;artificial intelligence;cardinality;combinatorial optimization;computer science;integer programming;search algorithm	ML	23.875988624209104	4.4290840249998595	130838
dacc78435f167ce881755ac68af01b8571f1c670	fast optimal clearing of capped-chain barter exchanges		Kidney exchange is a type of barter market where patients exchange willing but incompatible donors. These exchanges are conducted via cycles—where each incompatible patient-donor pair in the cycle both gives and receives a kidney—and chains, which are started by an altruist donor who does not need a kidney in return. Finding the best combination of cycles and chains is hard. The leading algorithms for this optimization problem use either branch and price—a combination of branch and bound and column generation—or constraint generation. We show a correctness error in the leading prior branch-and-price-based approach [Glorie et al. 2014]. We develop a provably correct fix to it, which also necessarily changes the algorithm’s complexity, as well as other improvements to the search algorithm. Next, we compare our solver to the leading constraint-generation-based solver and to the best prior correct branch-and-price solver. We focus on the setting where chains have a length cap. A cap is desirable in practice since if even one edge in the chain fails, the rest of the chain fails: the cap precludes very long chains that are extremely unlikely to execute and instead causes the solution to have more parallel chains and cycles that are more likely to succeed. We work with the UNOS nationwide kidney exchange, which uses a chain cap. Algorithms from our group autonomously make the transplant plans for that exchange. On that real data and demographically-accurate generated data, our new solver scales significantly better than the prior leading	branch and bound;branch and price;column generation;complexity;correctness (computer science);cycle (graph theory);mathematical optimization;optimization problem;search algorithm;solver;traffic exchange;unos	Benjamin Plaut;John P. Dickerson;Tuomas Sandholm	2016			simulation;computer science;algorithm	AI	16.042140116693936	4.944368655366409	131028
1ebc56b3533cfb1f8fb5266d3d9168af7a9148db	local strategy improvement for parity game solving	local algorithm;game theory;program synthesis;satisfiability;model checking;computational complexity;on the fly;logic in computer science;data structure	The problem of solving a parity game is at the core of many problems in model checking, satisfiability checking and program synthesis. Some of the best algorithms for solving parity game are strategy improvement algorithms. These are global in nature since they require the entire parity game to be present at the beginning. This is a distinct disadvantage because in many applications one only needs to know which winning region a particular node belongs to, and a witnessing winning strategy may cover only a fractional part of the entire game graph. We present a local strategy improvement algorithm which explores the game graph on-the-fly whilst performing the improvement steps. We also compare it empirically with existing global strategy improvement algorithms and the currently only other local algorithm for solving parity games. It turns out that local strategy improvement can outperform these others by several orders of magnitude.	algorithm;exptime;model checking;program synthesis;while	Oliver Friedmann;Martin Lange	2010		10.4204/EPTCS.25.13	combinatorial game theory;model checking;game theory;combinatorics;discrete mathematics;data structure;game tree;computer science;mathematics;simulations and games in economics education;algorithmic game theory;programming language;computational complexity theory;sequential game;algorithm;satisfiability	Logic	10.107837196971241	17.235812508174437	131376
b8a078f1797f8b8eb22894b18e8cdc7ef7b3a778	elicitation strategies for soft constraint problems with missing preferences: properties, algorithms and experimental studies	elicitation;modelizacion;optimal solution;constrenimiento flexible;solution optimale;multiagent system;confidencialidad;algoritmo busqueda;dato que falta;algorithme recherche;informacion incompleta;logique floue;search algorithm;incompleteness;logica difusa;soft constraints;intelligence artificielle;constraint satisfaction;confidentiality;fuzzy logic;donnee manquante;modelisation;vida privada;incomplete information;confidentialite;satisfaction contrainte;soft constraint;private life;preference elicitation;solucion optima;comportement utilisateur;information incomplete;preferencia;artificial intelligence;vie privee;contrainte souple;preference;missing data;inteligencia artificial;user behavior;satisfaccion restriccion;sistema multiagente;modeling;comportamiento usuario;preferences;systeme multiagent	We consider soft constraint problems where some of the preferences may be unspecified. This models, for example, settings where agents are distributed and have privacy issues, or where there is an ongoing preference elicitation process. In this context, we study how to find an optimal solution without having to wait for all the preferences. In particular, we define algorithms, that interleave search and preference elicitation, to find a solution which is necessarily optimal, that is, optimal no matter what the missing data will be, with the aim to ask the user to reveal as few preferences as possible. We define a combined solving and preference elicitation scheme with a large number of different instantiations, each corresponding to a concrete algorithm, which we compare experimentally. We compute both the number of elicited preferences and the user effort, which may be larger, as it contains all the preference values the user has to compute to be able to respond to the elicitation requests. While the number of elicited preferences is important when the concern is to communicate as little information as possible, the user effort measures also the hidden work the user has to do to be able to communicate the elicited preferences. Our experimental results on classical, fuzzy, weighted and temporal incomplete CSPs show that some of our algorithms are very good at finding a necessarily optimal solution while asking the user for only a very small fraction of the missing preferences. The user effort is also very small for the best algorithms.	anytime algorithm;branch and bound;constrained optimization;constraint (mathematics);control theory;cryptographic service provider;experiment;local search (optimization);missing data;perturbation theory;preference elicitation;privacy;procedural generation;requirements elicitation;semantics (computer science);solver;variable elimination	Mirco Gelain;Maria Silvia Pini;Francesca Rossi;Kristen Brent Venable;Toby Walsh	2010	Artif. Intell.	10.1016/j.artint.2009.11.015	fuzzy logic;systems modeling;confidentiality;constraint satisfaction;missing data;computer science;artificial intelligence;requirements elicitation;data mining;mathematics;complete information;search algorithm	AI	12.444909117045114	12.47181052786948	131530
07695c0a92dbe5dda3f30320af631347127eebe9	the summed start-up costs in a unit commitment problem	valid inequalities;integrality gap;summed start up costs;mixed integer programming;start up cost epigraph;unit commitment	We consider the sum of the incurred start-up costs of a single unit in a Unit Commitment problem. Our major result is a correspondence between the facets of its epigraph and some binary trees for concave start-up cost functions CU, which is bijective if CU is strictly concave. We derive an exponential \({\mathcal{H}}\)-representation of this epigraph, and provide an exact linear separation algorithm. These results significantly reduce the integrality gap of the Mixed Integer formulation of a Unit Commitment Problem compared to current literature.		René Brandenberg;Matthias Huber;Matthias Silbernagl	2017	EURO J. Computational Optimization	10.1007/s13675-016-0062-2	mathematical optimization;combinatorics;discrete mathematics;integer programming;power system simulation;mathematics	NLP	23.680503268852995	13.244054146200632	131610
fadb72a624a9ccae591e8445b48fc0b619ff9d1a	non-clairvoyant scheduling to minimize max flow time on a machine with setup times		Consider a problem in which n jobs that are classified into k types arrive over time at their release times and are to be scheduled on a single machine so as to minimize the maximum flow time. The machine requires a setup taking s time units whenever it switches from processing jobs of one type to jobs of a different type. We consider the problem as an online problem where each job is only known to the scheduler as soon as it arrives and where the processing time of a job only becomes known upon its completion (non-clairvoyance). We are interested in the potential of simple “greedy-like” algorithms. We analyze a modification of the FIFO strategy and show its competitiveness to be Θ( √ n), which is optimal for the considered class of algorithms. For k = 2 types it achieves a constant competitiveness. Our main insight is obtained by an analysis of the smoothed competitiveness. If processing times pj are independently perturbed to p̂j = (1 + Xj)pj , we obtain a competitiveness of O(σ−2 log n) when Xj is drawn from a uniform or a (truncated) normal distribution with standard deviation σ. The result proves that bad instances are fragile and “practically” one might expect a much better performance than given by the Ω( √ n)-bound.		Alexander Mäcker;Manuel Malatyali;Friedhelm Meyer auf der Heide;Sören Riechers	2017		10.1007/978-3-319-89441-6_16	computer science;mathematical optimization;maximum flow problem;scheduling (computing);smoothed analysis	Theory	15.263383658615268	10.654106447912131	131640
05789838fb8f22240c528bdeb7e3eefff1bd8c94	exploiting parallelism in constraint satisfaction for qualitative simulation	constraint satisfaction problem;constraint satisfaction;parallel algorithm;artificial intelligent	Constraint satisfaction is very common in many arti cial intelligence applications. This paper presents results from parallelizing constraint satisfaction in a special application | the algorithm for qualitative simulation QSim [Kuipers 94]. A parallel-agent based strategy (PAB) is used to solve the constraint satisfaction problem (CSP). Two essential steps of PAB are studied in more detail to achieve a good performance of the parallel algorithm. Partitioning heuristics to generate independent parts of the overall search space are investigated. Sequential CSP algorithms are compared in order to reveal the most e cient one for QSim. The evaluation of these heuristics and algorithms is based on runtime measurements using CSPs traced from QSim. These runtimes allow a bestand worst-case estimation of the expected speedup of the parallel algorithms. The comparison of sequential CSP algorithms leads to following strategy for solving partitioned problems. Less complex problems are solved with simple backtracking, and more complex models are solved with graph-directed backjumping (GBJ).	agent-based model;automatic parallelization;backjumping;backtracking;best, worst and average case;constraint satisfaction problem;cryptographic service provider;experiment;heuristic (computer science);multiprocessing;parallel algorithm;simulation;speedup;visual basic	Marco Platzner;Bernhard Rinner;Reinhold Weiss	1995	J. UCS	10.3217/jucs-001-12-0811	constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;decomposition method;constraint satisfaction;constraint learning;computer science;constraint graph;theoretical computer science;machine learning;constraint satisfaction dual problem;parallel algorithm;complexity of constraint satisfaction;constraint;constraint satisfaction problem;hybrid algorithm;local consistency;backtracking	AI	21.904716382908965	4.673221515631622	131719
ffc75ac8c42c00ffcfda6b68a07fa47f5a6eb28f	resource constrained project scheduling with general precedence relations optimized with sat	sat;project scheduling	This paper presents an approach, based on propositional satisfiability (SAT), for the resource constrained project scheduling problem with general precedence relations. This approach combines propositional satisfiability formulations with a bisection method, in order to achieve an optimal solution. The empirical results suggest that when the optimal schedule is significantly affected by the availability of resources, this strategy outperforms the typical integer linear programming approach.	schedule (project management)	Rui Alves;Filipe Alvelos;Sérgio Dinis Sousa	2013		10.1007/978-3-642-40669-0_18	parallel computing;computer science;artificial intelligence;distributed computing;schedule	AI	15.117289398438146	7.866560789385187	131778
3423c994289f89bae4803df668416f88ecd4bef8	curriculum based course timetabling: new solutions to udine benchmark instances	university course timetabling;decomposition;integer programming	We present an integer programming approach to the university course timetabling problem, in which weekly lectures have to be scheduled and assigned to rooms. Students’ curricula impose restrictions as to which courses may not be scheduled in parallel. Besides some hard constraints (no two courses in the same room at the same time, etc.), there are several soft constraints in practice which give a convenient structure to timetables; these should be met as well as possible. We report on solving benchmark instances from the literature and the 2nd International Timetabling Competition which are based on real data from the university of Udine. The first set is solved to proven optimality; for the second set we give solutions which on average compete well with or beat the previously best known solutions. Our algorithm is not an overall winner, but it is very robust in the sense that it deterministically gives satisfactory lower and upper bounds in reasonable computation time without particular tuning. For slightly larger instances from the literature our approach shows significant potential as it considerably beats previous benchmarks. We further present solutions of proven quality to a few much larger instances with more elaborate hard constraints.	benchmark (computing);computation;deterministic algorithm;integer programming;schedule;time complexity;timeline	Gerald Lach;Marco E. Lübbecke	2012	Annals OR	10.1007/s10479-010-0700-7	mathematical optimization;simulation;integer programming;computer science;artificial intelligence;mathematics;decomposition;algorithm	Logic	19.0659371083638	10.141070500714301	131855
6590b45357839465a64748176c6e1528fd3f11cf	improved bounds for online routing and packing via a primal-dual approach	computational complexity competitive algorithms;offline packing;online algorithm;routing bandwidth algorithm design and analysis throughput upper bound computer science design methodology polynomials joining processes;online routing;generic algorithm;lower and upper bound;routing;primal dual method;competitive algorithms;polynomial time algorithm online routing online packing primal dual approach offline routing offline packing;polynomials;upper bound;polynomial time algorithm;computational complexity;online packing;routing algorithm;joining processes;bandwidth;computer science;potential function;offline routing;algorithm design and analysis;lower bound;primal dual approach;throughput;design methodology	In this work we study a wide range of online and offline routing and packing problems with various objectives. We provide a unified approach, based on a clean primal-dual method, for the design of online algorithms for these problems, as well as improved bounds on the competitive factor. In particular, our analysis uses weak duality rather than a tailor made (i.e., problem specific) potential function. We demonstrate our ideas and results in the context of routing problems. Using our primal-dual approach, we develop a new generic online routing algorithm that outperforms previous algorithms suggested earlier by Y. Azar et al. (1993, 1997). We then show the applicability of our generic algorithm to various models and provide improved algorithms for achieving coordinate-wise competitiveness, maximizing throughput, and minimizing maximum load. In particular, we improve the results obtained by A. Goel et al. (2001) by an O(log n) factor for the problem of achieving coordinate-wise competitiveness, and by an O(log log n) factor for the problem of maximizing the throughput. For some of the settings we also prove improved lower bounds. We believe our results further our understanding of the applicability of the primal-dual method to online algorithms, and we are confident that the method will prove useful to other online scenarios. Finally, we revisit the notions of coordinate-wise and prefix competitiveness in an offline setting. We design the first polynomial time algorithm that computes an almost optimal coordinate-wise routing for several routing models. We also revisit previously studied routing models by A. Kumar and J.M. Kleinberg (2000) and A. Goel and A. Meyerson (2005) and prove tight lower and upper bounds of Theta(log n) on prefix competitiveness for these models	competitive analysis (online algorithm);generic programming;online algorithm;online and offline;p (complexity);polynomial;routing;set packing;throughput;weak duality	Niv Buchbinder;Joseph Naor	2006	2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06)	10.1109/FOCS.2006.39	mathematical optimization;combinatorics;computer science;theoretical computer science;mathematics;distributed computing;upper and lower bounds;algorithm	Theory	20.491936326520364	16.437431875463652	131928
55acec44c90ab78ba2f7ed236e0cc8ef94ee5083	competitive analysis for sum stretch on single and identical parallel machines			competitive analysis (online algorithm)	Abhinav Srivastav;Denis Trystram	2014	CoRR		distributed computing	HPC	15.831664004121246	11.785322122865196	131946
3a43a347d026c8ee0d20a085f1e13bdfd0deb2b7	linear relaxation techniques for task management in uncertain settings	simple temporal problem;task management;management information system;time constraint	In this paper, we consider the problem of assisting a busy user in managing her workload of pending tasks. We assume that our user is typically oversubscribed, and is invariably juggling multiple concurrent streams of tasks (or work flows) of varying importance and urgency. There is uncertainty with respect to the duration of a pending task as well as the amount of follow-on work that may be generated as a result of executing the task. The user’s goal is to be as productive as possible; i.e., to execute tasks that realize the maximum cumulative payoff. This is achieved by enabling the assistant to provide advice about where and how to shed load when all tasks cannot be done. A simple temporal problem with uncertainty and preferences (called an STPPU) provides a natural framework for representing the user’s current set of tasks. However, current STPPU solution techniques are inadequate as a basis for generating advice in this context, since they are applicable only in the restrictive case where all pending tasks can be accomplished within time constraints and our principal concern is support in oversubscribed circumstances. We present two techniques that are based on linear relaxation for solving the this oversubscribed problem. Given an ordering of tasks, these algorithms identify which tasks to ignore, which to compress and by how much, to maximize quality. We show experimentally that our approaches perform significantly better than techniques adapted from prior research in oversubscribed scheduling.	algorithm;experiment;heuristic;linear programming relaxation;online and offline;overselling;relaxation (approximation);scheduling (computing);slack variable	Pradeep Varakantham;Stephen F. Smith	2008			mathematical optimization;real-time computing;simulation;computer science;artificial intelligence;machine learning;management information systems	AI	13.87780600776291	9.606656456160888	132461
206c2bcd94eb52fcfb59a7fad452698144e1923a	priority algorithms for makespan minimization in the subset model	optimisation;tiempo total acabamiento;approximate algorithm;optimizacion;approximation numerique;algorithme glouton;approximation algorithms;approximation algorithm;temps total achevement;aproximacion numerica;optimization problem;makespan;scheduling;algoritmo aproximacion;greedy algorithm;algoritmo gloton;ordonamiento;optimization;numerical approximation;algorithme approximation;ordonnancement	"""We continue the recent study of priority algorithms initiated by Borodin et al. [Proc. 13th ACM-SIAM Symp. on Discrete Algorithms, 2002, pp. 752-761]. The definition of a priority algorithm nicely captures the idea of a """"greedy-like"""" type algorithm. While priority algorithms are applicable to many optimization problems, in this paper we consider the problem of makespan minimization in scheduling in the subset model. We show that by using a fixed priority algorithm one cannot achieve a considerable improvement over the approximation ratio given by the online greedy algorithm. Namely, we present an Ω(log m/log log m) lower bound on the approximation ratio of any fixed priority algorithm where m is the number of machines."""	algorithm;makespan	Oded Regev	2002	Inf. Process. Lett.	10.1016/S0020-0190(02)00264-8	optimization problem;mathematical optimization;combinatorics;greedy algorithm;computer science;mathematics;scheduling;priority queue;approximation algorithm;algorithm	DB	17.449841876489664	10.516398634086794	132475
f420ef5c1307cd763be007b9986d44b723208891	online removable knapsack with limited cuts	minimisation;online algorithm;minimization;probleme sac a dos;maximization;algorithme en ligne;competitive algorithms;ressource;minimizacion;algoritmo en linea;problema mochila;unit;algorithme competitif;knapsack problem;informatique theorique;delai d execution;decision;plazo ejecucion;online algorithms;58a25;algoritmo optimo;algorithme optimal;optimal algorithm;maximizacion;recurso;time allowed;unite;maximisation;competitive ratio;unidad;computer theory;resource;informatica teorica	In this paper, we study online maximization and minimization knapsack problems with limited cuts, in which (1) items are given one by one over time, i.e., after a decision is made on the current item, the next one is given, (2) items are allowed to be cut at most k(>=1) times, and (3) items are allowed to be removed from the knapsack. We obtain the following three results. (i)For the maximization knapsack problem, we propose a (k+1)/k-competitive online algorithm, and show that it is the best possible, i.e., no online algorithm can have a competitive ratio less than (k+1)/k. (ii)For the minimization knapsack problem, we show that no online algorithm can have a constant competitive ratio. (iii)We extend the result in (i) to the resource augmentation model, where an online algorithm is allowed to use a knapsack of capacity m (>1), while the optimal algorithm uses a unit capacity knapsack.	removable media	Xin Han;Kazuhisa Makino	2010	Theor. Comput. Sci.	10.1016/j.tcs.2010.08.009	continuous knapsack problem;online algorithm;mathematical optimization;polynomial-time approximation scheme;computer science;artificial intelligence;change-making problem;mathematics;knapsack problem;algorithm	ECom	17.898073941057028	10.481224461912278	132616
f9584d6a0c458254bdabc6677fc436c4cc122cfc	generating efficient schedules for identical parallel machines involving flow-time and tardy jobs	optimum pareto;gestion production;heuristic method;evaluation method;machine parallele;problema np duro;metodo heuristico;production management;dominating set;flow time;np hard problem;parallel machine scheduling;evaluation methodology;probleme np difficile;scheduling;heuristic algorithms;gestion produccion;bi criteria;job flows;empirical results;parallel machines;tardy jobs;methode heuristique;pareto optima;pareto optimum;optimo pareto;ordonnancement;non dominated efficient schedules;heuristic algorithm;reglamento	This paper considers the problem of generating a set of efficient (non-dominated) schedules on identical parallel machines involving total flow-time and total number of tardy jobs. In view of the NP-hard nature of this problem, heuristic algorithms are proposed for its solution. Two evaluation methods that provide a scheme by which multiple nondominated sets can be compared are described and used to compare the performance of the proposed algorithms. Results of several experiments demonstrate the capability of the proposed algorithms and evaluation methodologies to address the problem at hand. 2004 Elsevier B.V. All rights reserved.	algorithm;computation;experiment;genetic algorithm;heuristic;heuristic (computer science);job shop scheduling;job stream;makespan;np-hardness;population;rough set;schedule (project management);scheduling (computing);simulated annealing;tabu search;usability	Jatinder N. D. Gupta;Alex J. Ruiz-Torres	2005	European Journal of Operational Research	10.1016/j.ejor.2004.07.015	heuristic;mathematical optimization;dominating set;computer science;operations management;np-hard;mathematics;scheduling;algorithm	AI	17.153069326041045	8.538047867212665	132706
1577986622155fa4901e04cba34509bc87440060	a note on a greedy heuristic for flow-shop makespan minimization with no machine idle-time	minimisation;minimization;tiempo total acabamiento;algorithme glouton;heuristic method;flowshop;temps total achevement;metodo heuristico;minimizacion;greedy heuristic;makespan;scheduling;delai d execution;greedy algorithm;algoritmo gloton;plazo ejecucion;heuristics;methode heuristique;atelier monogamme;ordonnancement;flow shop;time allowed;reglamento	We study makespan minimization on an  m  machine flowshop. No idle time is allowed between consecutive operations on each machine. We introduce an efficient (O( n  2 )) greedy algorithm, which is shown numerically to perform better than a recently published heuristic.	greedy algorithm;heuristic;makespan	Daniel Baraz;Gur Mosheiov	2008	European Journal of Operational Research	10.1016/j.ejor.2006.11.025	job shop scheduling;mathematical optimization;greedy algorithm;johnson's rule;computer science;operations management;mathematics;algorithm	Robotics	17.257279983581352	9.651211516032948	132925
696f94c13b58c8c60423a5340c7f3ead6aa8a1c9	minimizing the bicriteria of makespan and maximum tardiness with an upper bound on maximum tardiness	algorithme rapide;multiobjective programming;programmation multiobjectif;dominance;tiempo total acabamiento;metaheuristics;fonction potentiel;complex function;analisis estadistico;heuristic method;flowshop;temps total achevement;metodo heuristico;algoritmo genetico;fonction seuil;fonction objectif;multiobjective;upper bound;scenario;objective function;metamodel;makespan;statistical analysis;extreme value;metamodele;argumento;dominancia;metamodelo;funcion umbral;weighted sums;scheduling;fast algorithm;valeur extreme;script;analyse statistique;retard;funcion potencial;algorithme genetique;scheduling problem;funcion objetivo;funcion compleja;genetic algorithm;fonction complexe;genetic algorithms;bicriteria;heuristics;threshold function;methode heuristique;borne superieure;potential function;retraso;atelier monogamme;algoritmo rapido;ordonnancement;flow shop;valor extremo;reglamento;cota superior;programacion multiobjetivo	This paper studies the flowshop scheduling problem with a complex bicriteria objective function. A weighted sum of makespan and maximum tardiness subject to a maximum tardiness threshold value is to be optimized. This problem, with interesting potential applications in practice, has been sparsely studied in the literature. We propose global and local dominance relationships for the three machine problem and a fast and effective genetic algorithm (GA) for the more general m-machine case. The proposed GA incorporates a novel three-phase fitness assignment mechanism specially targeted at dealing with populations in which both feasible as well as infeasible solutions might coexist. Comprehensive computational and statistical experiments show that the proposed GA outperforms the two most effective existing heuristics by a considerable margin in all scenarios. Furthermore, the proposed GA is also faster and able to find more feasible solutions. It should be noted that when the weight assigned to maximum tardiness is zero, then the problem is reduced to minimizing makespan subject to a maximum tardiness threshold value. Heuristics for both problems have been provided in the literature recently but they have not been compared. Another contribution of this paper is to compare these recent heuristics with each other. 1 Corresponding author. Telephone number: +34 96 387 70 07, ext. 74946. Fax number: +34 96 387 74 99	central processing unit;coexist (image);computation;experiment;ext js javascript framework;fax;genetic algorithm;heuristic (computer science);loss function;makespan;optimization problem;population;scheduling (computing);software release life cycle;telephone number;weight function;yet another	Rubén Ruiz;Ali Allahverdi	2009	Computers & OR	10.1016/j.cor.2007.12.013	job shop scheduling;mathematical optimization;genetic algorithm;computer science;artificial intelligence;mathematics;algorithm	AI	20.20341417200243	6.408042639760433	132949
5fd6d0db08f9ade451f66bdd4d9fa664383a340d	the dominance flow shop scheduling problem		Abstract We introduce a new line of analysis of Flow Shop scheduling problems, for the case of two jobs and assuming that processing times are unknown. The goal is to determine the domination relations between permutation and non-permutation schedules. We analyze the structural and dominance properties that ensue in this setting, based on the critical paths of schedules.	flow shop scheduling;scheduling (computing)	Daniel A. Rossit;Óscar C. Vásquez;Fernando A. Tohmé;Mariano Frutos;Martín D. Safe	2018	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2018.07.004	permutation;discrete mathematics;schedule;mathematics;flow shop scheduling	Theory	15.641040513528749	9.133257262436253	132976
21204aa6624f59dcdaaf8c0eb9b6795ff9b3b990	fuzzy-based methodology for multi-objective scheduling in a robot-centered flexible manufacturing cell	dispatching rules;flexible manufacturing cell;fuzzy logic;shortest processing time;batch process;earliest due date	A fuzzy logic based methodology for generating the sequence of part movements in a multi-product batch processing through a computerized machine cell is presented in this paper. A number of production objectives are taken into account. Two fuzzy based strategies: fuzzy-job and fuzzy-machine are proposed and their performance is compared to two well known dispatching rules such as SPT (Shortest Processing Time) and WEED (Weighted Earliest Due Date). The sequencing algorithm was implemented on a standard personnel computer and the scheduler was interfaced to a robot controller for implementing loading and unloading strategy within the cell. The proposed fuzzy-based methodologies especially fuzzy-job shows a superior performance compared to the traditional dispatching rules considered.	robot;scheduling (computing)	Indira Molina Restrepo;S. Balakrishnan	2008	J. Intelligent Manufacturing	10.1007/s10845-008-0093-5	fuzzy logic;fuzzy electronics;real-time computing;computer science;engineering;artificial intelligence;engineering drawing;fuzzy set operations;batch processing	Robotics	11.816153712912307	5.389360356764329	133009
1e507c9ef9ff3bae2b84aaae89330a05c949d4df	modeling languages and condor: metacomputing for optimization	modelizacion;mixed programming;selection problem;optimisation;problema seleccion;programacion entera;modele mathematique;optimizacion;learning;resource manager;intelligence artificielle;modelo matematico;calculo automatico;programmation mixte;programmation en nombres entiers;modeling language;computing;aprendizaje;calcul automatique;optimization problem;modelisation;apprentissage;mixed integer program;programacion lineal;programacion mixta entera;programacion mixta;machine learning;integer programming;mathematical programming;linear programming;mathematical model;programmation lineaire;programmation partiellement en nombres entiers;mixed integer programming;artificial intelligence;feature selection;optimization;inteligencia artificial;modeling;performance optimization;probleme selection	A generic framework is postulated for utilizing the computational resources provided by a metacomputer to concurrently solve a large number of optimization problems generated by a modeling language. An example of the framework using the Condor resource manager and the AMPL and GAMS modeling languages is provided. A mixed integer programming formulation of a feature selection problem from machine learning is used to test the mechanism developed. Due to this application’s computational requirements, the ability to perform optimizations in parallel is necessary in order to obtain results within a reasonable amount of time. Details about the simple and easy to use tool and implementation are presented so that other modelers with applications generating many independent mathematical programs can take advantage of it to significantly reduce solution times.	ampl;add-ons for firefox;computational resource;computer cluster;data mining;feature selection;gams;integer programming;linear programming;machine learning;mathematical optimization;metacomputing;modeling language;remote computer;requirement;selection algorithm;spawn (computing);supercomputer;throughput;workstation	Michael C. Ferris;Todd S. Munson	2000	Math. Program.	10.1007/PL00011382	optimization problem;mathematical optimization;computing;integer programming;algebraic modeling language;computer science;artificial intelligence;machine learning;mathematical model;mathematics;modeling language;algorithm	HPC	20.480715036063273	7.289326679536133	133018
4586c6e6324963f23df804fe4a52edba1bc21ea4	parallel random search and tabu search for the minimal consistent subset selection problem	optimisation;discrete optimization;sistema experto;algoritmo busqueda;algorithm performance;optimizacion;algorithme recherche;aproximacion;heuristic method;search algorithm;metodo heuristico;intelligence artificielle;prise decision;parallel computation;approximation;aleatorizacion;vecino mas cercano;large scale;calculo paralelo;resultado algoritmo;performance algorithme;subset selection;parallel computer;randomisation;plus proche voisin;artificial intelligence;nearest neighbour;tabu search;optimization;methode heuristique;inteligencia artificial;systeme expert;randomization;toma decision;calcul parallele;random search;expert system	The Minimal Consistent Subset Selection (MCSS) problem is a discrete optimization problem whose resolution for large scale instances requires a prohibitive processing time. Prior algorithms addressing this problem are presented. Randomization and approximation techniques are suitable to face the problem, then random search and meta-heuristics are proposed and consequently Tabu Search strategies are applied and evaluated. Parallel computing helps to reduce processing time and/or produce better results; different approaches for designing parallel tabu search are analyzed.	random search;selection algorithm;tabu search	Vicente Cerverón;Ariadna Fuertes	1998		10.1007/3-540-49543-6_20	randomization;discrete optimization;mathematical optimization;random search;tabu search;computer science;artificial intelligence;hill climbing;machine learning;approximation;mathematics;expert system;algorithm;guided local search;search algorithm	Crypto	21.236836620321668	5.533183270149574	133551
04b85cc57408f70584598d348fd951aaa6fa61fd	conditions for on-line scheduling of hard real-time tasks on multiprocessors	simulation ordinateur;systeme temps reel;distributed system;systeme reparti;algorithm performance;systeme multiprocesseur memoire repartie;heuristic method;metodo heuristico;satisfiability;algorithme;algorithm;sistema repartido;resultado algoritmo;scheduling;sistema multiprocesador memoria distribuida;performance algorithme;scheduling problem;ordonamiento;real time system;sistema tiempo real;distributed memory multiprocessor system;simulacion computadora;methode heuristique;computer simulation;ordonnancement;hard real time;algoritmo	In this paper we consider the problem ofon-linescheduling ofhard real-timetasks onmultipleprocessors. For a given set of ready tasks, one can propose many schedules. These schedules, however, may not necessarily be suitable for on-line scheduling. A suitable on-line schedule is one which can accommodate any future task set when it arrives. The traditional approach to solve the on-line scheduling problem is to propose a heuristic, and then to prove its effectiveness by comparing it with existing heuristics using simulation. No attempt has, however, been made to obtain a condition on the current schedule which when satisfied will permit one to schedule an arbitrary future task. In this paper, we aim at developing such a condition on the current schedule for the set of ready tasks which when satisfied can guarantee an on-line schedule for any futurefeasibletask set.		M. Dominic;Bijendra N. Jain	1998	J. Parallel Distrib. Comput.	10.1006/jpdc.1998.1484	computer simulation;parallel computing;real-time computing;computer science;operating system;scheduling;algorithm;satisfiability	Embedded	17.357736162628825	10.23077378393243	133559
0ec514e22986861dbaffc0b5635eafa396d02109	rounding-based moves for semi-metric labeling	semi metric labeling;multiplicative bounds;linear programming relaxation;move making algorithms	Semi-metric labeling is a special case of energy minimization for pairwise Markov random fields. The energy function consists of arbitrary unary potentials, and pairwise potentials that are proportional to a given semi-metric distance function over the label set. Popular methods for solving semi-metric labeling include (i) move-making algorithms, which iteratively solve a minimum st-cut problem; and (ii) the linear programming (LP) relaxation based approach. In order to convert the fractional solution of the LP relaxation to an integer solution, several randomized rounding procedures have been developed in the literature. We consider a large class of parallel rounding procedures, and design move-making algorithms that closely mimic them. We prove that the multiplicative bound of a move-making algorithm exactly matches the approximation factor of the corresponding rounding procedure for any arbitrary distance function. Our analysis includes all known results for move-making algorithms as special cases.	algorithm;approximation;energy minimization;lagrangian relaxation;linear programming relaxation;markov chain;markov random field;mathematical optimization;randomized rounding;semiconductor industry;unary operation	M. Pawan Kumar;Puneet Kumar Dokania	2016	Journal of Machine Learning Research		mathematical optimization;randomized rounding;combinatorics;discrete mathematics;computer science;linear programming relaxation;mathematics	ML	24.010586003300606	15.796822211434007	133786
edb4a2d4321e0de55524ad2e3944f1e9106cdafa	"""letter to the editor - comments on a paper by romesh saigal: """"a constrained shortest route problem"""""""		Romesh Saigal presents a zero-one linear program and a dynamic programming algorithm for finding the shortest route containing exactly q arcs from node 1 to node n in a network N, A with distances ci,j. This note shows that the linear programming formulation and his extension based on it are defective, and that the dynamic programming algorithm can lead to suboptimal solutions, but a minor change in the dynamic programming formulation relieves the difficulty.		Marc Rosseel	1968	Operations Research	10.1287/opre.16.6.1232	mathematical optimization;combinatorics;mathematics;algorithm	Robotics	23.474776473320496	14.044923194185836	133841
4c8fa353cb87536d6c171ede1dab00810a44207a	extending dantzig's bound to the bounded multiple-class binary knapsack problem	generation colonne;probleme sac a dos;programacion entera;cutting stock problem;problema mochila;programmation en nombres entiers;optimisation combinatoire;upper bound;knapsack problem;programacion lineal;probleme decoupe;integer programming;mathematical programming;exact algorithm;linear time;linear programming relaxation;linear programming;programmation lineaire;greedy algorithm;problema troquelado;profitability;integer program;borne superieure;combinatorial optimization;programmation mathematique;lp relaxation;programacion matematica;column generation;cota superior;optimizacion combinatoria	The bounded multiple-class binary knapsack problem is a variant of the knapsack problem where the items are partitioned into classes and the item weights in each class are a multiple of a class weight. Thus, each item has an associated multiplicity. The constraints consists of an upper bound on the total item weight that can be selected and upper bounds on the total multiplicity of items that can be selected in each class. The objective is to maximize the sum of the profits associated with the selected items. This problem arises as a sub-problem in a column generation approach to the cutting stock problem. A special case of this model, where item profits are restricted to be multiples of a class profit, corresponds to the problem obtained by transforming an integer knapsack problem into a 0-1 form. However, the transformation proposed here does not involve a duplication of solutions as the standard transformation typically does. The paper shows that the LP-relaxation of this model can be solved by a greedy algorithm in linear time, a result that extends those of Dantzig (1957) and Balas and Zemel (1980) for the 0-1 knapsack problem. Hence, one can derive exact algorithms for the multi-class binary knapsack problem by adapting existing algorithms for the 0-1 knapsack problem. Computational results are reported that compare solving a bounded integer knapsack problem by transforming it into a standard binary knapsack problem versus using the multiple-class model as a 0-1 form.	column generation;computation;cutting stock problem;greedy algorithm;knapsack problem;lp-type problem;linear programming relaxation;time complexity	François Vanderbeck	2002	Math. Program.	10.1007/s10107-002-0300-7	continuous knapsack problem;mathematical optimization;combinatorics;discrete mathematics;integer programming;combinatorial optimization;generalized assignment problem;linear programming;linear programming relaxation;cutting stock problem;change-making problem;mathematics;knapsack problem	AI	20.640065769767823	12.298448531437172	134269
4089bd9f3c04884bd9163f84dce8f3346d18b814	reactive local search techniques for the maximum k-conjunctive constraint satisfaction problem (max-k-ccsp)	approximate algorithm;satisfiability;constraint satisfaction;heuristic algorithms;reactive tabu search;history sensitive heuristics;constraint satisfaction problem;local search;heuristic algorithm;reactive search	In this paper the performance of the Hamming-based Reactive Tabu Search algorithm (H-RTS) previously proposed for the Maximum Satissability problem is studied for the diierent Conjunctive Constraint Satisfaction problem. In addition, the use of non-oblivious functions recently proposed in the framework of approximation algorithms is investigated. In particular, two relevant special cases of the k-Conjunctive Constraint Satisfaction problem are considered: Maximum Directed Cut and Maximum Independent Set in cubic graphs. The preliminary diversiication{bias analysis of the basic components shows a remarkable diierence between the two problems, and the derived predictions are then validated by extensive experiments with the complete H-RTS algorithm. The performance of H-RTS is compared with that of Simulated Annealing and simple repeated local search.	approximation algorithm;constraint satisfaction problem;cubic function;experiment;independent set (graph theory);local search (constraint satisfaction);local search (optimization);max;regular expression;search algorithm;simulated annealing;tabu search	Roberto Battiti;Marco Protasi	1999	Discrete Applied Mathematics	10.1016/S0166-218X(99)00030-X	constraint logic programming;heuristic;mathematical optimization;combinatorics;constraint satisfaction;tabu search;constraint learning;constraint graph;local search;hill climbing;constraint satisfaction dual problem;mathematics;complexity of constraint satisfaction;constraint satisfaction problem;algorithm;difference-map algorithm;hybrid algorithm;local consistency;backtracking;guided local search;satisfiability;search algorithm	AI	11.86262302478238	16.31002279171012	134348
0638fa6cdbaf42d9e65583638f79e5a7657155c2	multiplying pessimistic estimators: deterministic approximation of max tsp and maximum triangle packing	traveling salesman problem;approximate algorithm;approximation algorithms;derandomization;maximum triangle packing;pessimistic estimators;randomized algorithm;maximum traveling salesman problem	We give a generalization of the method of pessimistic estimators [14], in which we compose estimators by multiplying them. We give conditions on the pessimistic estimators of two expectations, under which the product of the pessimistic estimators is a pessimistic estimator of the product of the two expectations. This approach can be useful when derandomizing algorithms for which one needs to bound a certain probability, which can be expressed as an intersection of multiple events; using our method, one can define pessimistic estimators for the probabilities of the individual events, and then multiply them to obtain a pessimistic estimator for the probability of the intersection of the events. We apply this method to give derandomizations of all known approximation algorithms for the maximum traveling salesman problem and the maximum triangle packing problem: we define simple pessimistic estimators based on the analysis of known randomized algorithms and show that we can multiply them to obtain pessimistic estimators for the expected weight of the solution. This gives deterministic algorithms with better approximation guarantees than what was previously known.	approximation algorithm;averaged one-dependence estimators;method of conditional probabilities;randomized algorithm;set packing;travelling salesman problem	Anke van Zuylen	2010		10.1007/978-3-642-14031-0_9	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;randomized algorithm;travelling salesman problem;approximation algorithm;algorithm	Theory	19.693134062027383	17.644168973740193	134641
595f857f21400406b2e54c1be82774cbfb8a707d	combining contemporary and traditional project management tools to resolve a project scheduling problem	tool management;modelizacion;project management;project manager;temps lineaire;tiempo lineal;modelisation;programacion lineal;precedence diagrams;gestion herramienta;scheduling;time cost tradeoff;gestion outil;linear time;coste;linear programming;programmation lineaire;linear program;gestion projet;project scheduling;modeling;ordonnancement;gestion proyecto;reglamento;cout	In this paper we examine a construction project involving the building of large concrete slabs for three buildings in an office park complex. There are finish-to-start (FS) as well as start-to-start (SS) and finish-to-finish (FF) precedence relationships among the project activities. We prepare an initial project schedule using Microsoft Project and manually validate the results using the precedence diagramming method (PDM) procedure. When the client informs us that the schedule must be shortened we find that Microsoft Project does not have the capability for resolving our particular time/cost tradeoff issues. So we revert to the traditional approach for resolving time/cost tradeoffs in projects and develop an original linear programming formulation for the time/cost tradeoff problem when a project is modeled as a precedence diagram. By combining contemporary (Microsoft Project) and traditional (a linear programming time/cost tradeoff model) project management tools we are able to successfully resolve the scheduling issues associated with the slab construction project. Further, we demonstrate the anomalous effects of start-to-start (SS) and finish-to-finish (FF) relationships via our construction project example in which the solution to the time/cost tradeoff problem requires that certain activities be lengthened in order to shorten the project duration.	comparison of project management software;scheduling (computing)	John E. Hebert;Richard F. Deckro	2011	Computers & OR	10.1016/j.cor.2009.12.004	time complexity;mathematical optimization;simulation;systems modeling;work breakdown structure;input/output;computer science;linear programming;mathematics;project management triangle;operations research;scheduling;schedule;project planning;precedence diagram method	Theory	17.327602318581633	7.039525624069726	134709
f326de6a43086a864e0d3932eb25bee923be722f	technical note-three-stage flow-shops with recessive second stage		Several papers have described special structural properties for which the minimum makespan flow-shop problem can be efficiently solved. We describe a new special case of the 3 × n problem with small second-stage processing times relative to the first and third stages for which Johnson's algorithm gives an optimal schedule.		Fennell Burns;John Rooker	1978	Operations Research	10.1287/opre.26.1.207	mathematical optimization;computer science;operations management;operations research;algorithm	NLP	15.735891913659596	7.945481443804702	135404
50c9fbd142813a2a5004758d09b88408d7c21992	heuristics and meta-heuristics for lot sizing and scheduling in the soft drinks industry: a comparison study	soft drinks;two level production planning;raw materials;production process;memetic algorithm;scheduling;scheduling problem;lot sizing;artigo;production planning;soft drinks industry;genetic algorithm;parallel machines;capacity constraint	1 Departamento de Engenharia de Produção, Universidade Federal de Sao Carlos, C.P. 676, 13565-905, Sao Carlos, SP, Brazil degafernandes@hotmail.com; morabito@power.ufscar.br 2 Departamento de Matemática, Estat́ıstica e Computação, Universidade Estadual Paulista, C.P. 1234, 19060-400, Presidente Prudente, SP, Brazil paulo.morelato@gmail.com 3 Dept. of Technology and Operations Management, University of Duisburg-Essen, 47048, Duisburg, Germany alf.kimms@uni-duisburg-essen.de 4 Departamento de Ciência da Computação e Estat́ıstica, Universidade Estadual Paulista, Rua Cristóvão Colombo, 2265, 15054-000, S. J. do Rio Preto, SP, Brazil socorro@ibilce.unesp.br 5 Departamento de Ciência da Computação, Universidade Federal de Lavras, C.P. 3037, 37200-000, Lavras, MG, Brazil claudio@dcc.ufla.br	heuristic (computer science);mg (editor);scheduling (computing);winsock	Deisemara Ferreira;Paulo Morelato França;Alf Kimms;Reinaldo Morabito;Socorro Rangel;Claudio Fabiano Motta Toledo	2008		10.1007/978-3-540-78985-7_8	mathematical optimization;engineering;operations management;operations research	Security	18.753961616553593	4.791946262598941	135844
a39f1e03698df7602c0727a6acfc1bcece43aaf8	proving graph un-colorability with a consistency check of csp	graph theory;large scale integration stochastic processes constraint theory microstructure artificial intelligence;graph uncolorability;graph colouring constraint theory;constraint satisfaction problem graph uncolorability csp consistency check;consistency checking;constraint theory;constraint satisfaction problem;csp consistency check;graph colouring	In this paper, we approach a derivation of the fifth challenge presented on IJCAI 1997 (Selman et al., 1997), that is to detect inconsistency by means of incomplete methods. Whereas this problem is of considerable interest, no significant contribution has emerged since 1997. In order to treat this matter, we review Gaur et al. (1997) that showed how to detect unsatisfiable CSP instances by coloring a graph. We observe that this approach doesn't seem to offer the expected prospects. Anyway, we exploit a similar process that permits to prove graph uncolorability by a CSP consistency check	graph coloring;international joint conference on artificial intelligence	Jean-Nicolas Bès;Philippe Jégou	2005	17th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'05)	10.1109/ICTAI.2005.102	mathematical optimization;combinatorics;discrete mathematics;null graph;graph property;constraint graph;clique-width;graph theory;mathematics;complexity of constraint satisfaction;graph;critical graph;constraint satisfaction problem;local consistency	Robotics	12.636069919130811	17.078630075241275	135912
9677dc1af9bf4661fe4c0613f82836e6464b6c6e	a branch, price and remember algorithm for the u shaped assembly line balancing problem		In this paper we propose a branch, price and remember algorithm to solve the U shaped assembly line balancing problem. Our proposed algorithm uses a column generation approach to obtain tight lower bounds for this problem. It also stores generated columns in memory to enhance the speed of column generation approach. We also develop a modification of Hoffman algorithm to obtain high quality upper bounds. Our computational results show that our proposed algorithm is able to optimally solve 255 of Scholl’s well-known 269 benchmark problems. Previous best known exact algorithm, ULINO, is able to solve 233 of the 269 benchmark problems. We also examined our algorithm on a new data set and the results show that our algorithm is able to solve 96.48 percent of all available benchmark problems.	benchmark (computing);branch and price;column (database);column generation;computation;display resolution;exact algorithm;production leveling;scheduling (computing);search tree	Abdolmajid Yolmeh;Najmeh Salehi	2017	CoRR		column generation;exact algorithm;algorithm;computer science	EDA	16.411163127024682	6.664804900787832	136009
6980415e5ca3e591ac76298f67fef22fc9c09222	partial inverse assignment problems under l1 norm	metodo polinomial;assignment problem;probleme affectation;polynomially solvable problems;combinatorial optimization problem;problema inverso;optimisation combinatoire;combinatorial problem;probleme combinatoire;problema combinatorio;inverse problem;polynomial method;polynomial algorithm;problema asignacion;partial inverse optimization;combinatorial optimization;methode polynomiale;probleme inverse;optimizacion combinatoria	In this paper, we consider the partial inverse assignment problem under l1 norm without bound constraints. We show that the partial inverse problem can be solved by a strongly polynomial algorithm. The technique for solving this problem can be extended to handle a special type of partial inverse 0.1 combinatorial optimization problems. © 2006 Elsevier B.V. All rights reserved.	algorithm;assignment problem;combinatorial optimization;mathematical optimization;polynomial;taxicab geometry;time complexity	Xiaoguang Yang;Jianzhong Zhang	2007	Oper. Res. Lett.	10.1016/j.orl.2005.12.003	mathematical optimization;combinatorics;combinatorial optimization;inverse problem;generalized assignment problem;calculus;mathematics;assignment problem;weapon target assignment problem;quadratic assignment problem	AI	23.352778946001703	12.710442477868378	136048
b89d2eb649aa33bb5519487b9dfcc4d0d828d6b6	group shops scheduling with makespan criterion subject to random release dates and processing times	modelizacion;swarm intelligence;tiempo total acabamiento;systeme evenement discret;intelligence en essaim;execution time;optimizacion pso;variable aleatoire;random processing times;group shop scheduling problem;heuristic method;simulation;temps total achevement;simulation optimization;variable aleatoria;programmation stochastique;metodo heuristico;random release dates;systeme ouvert;processing time;sistema acontecimiento discreto;modelisation;atelier multigamme;discrete event system;makespan;random process;ant colony algorithm;scheduling;particle swarm optimization;random variable;borne inferieure;scheduling problem;optimisation pso;temps traitement;temps execution;job shop;methode heuristique;tiempo ejecucion;stochastic programming;open systems;atelier monogamme;sistema abierto;modeling;inteligencia de enjambre;job scheduling;tiempo proceso;programacion estocastica;ordonnancement;flow shop;lower bound;ant colony optimization algorithm;heuristic algorithm;reglamento;cota inferior;discrete event simulation	This paper deals with a stochastic group shop scheduling problem. The group shop scheduling problem is a general formulation that includes the other shop scheduling problems such as the flow shop, the job shop and the open shop scheduling problems. Both the release date of each job and the processing time of each job on each machine are random variables with known distributions. The objective is to find a job schedule which minimizes the expected makespan. First, the problem is formulated in a form of stochastic programming and then a lower bound on the expected makespan is proposed which may be used as a measure for evaluating the performance of a solution without simulating. To solve the stochastic problem efficiently, a simulation optimization approach is developed that is a hybrid of an ant colony optimization algorithm and a heuristic algorithm to generate good solutions and a discrete event simulation model to evaluate the expected makespan. The proposed approach is tested on instances where the random variables are normally, exponentially or uniformly distributed and gives promising results.	makespan;scheduling (computing)	Fardin Ahmadizar;Mehdi Ghazanfari;Seyyed M. T. Fatemi Ghomi	2010	Computers & OR	10.1016/j.cor.2009.04.002	stochastic programming;heuristic;random variable;job shop scheduling;mathematical optimization;ant colony optimization algorithms;systems modeling;flow shop scheduling;computer science;artificial intelligence;discrete event simulation;job scheduler;mathematics;open system;upper and lower bounds;particle swarm optimization;scheduling	Metrics	17.53382701770537	9.04985781834027	136134
5ba7db8b4eb98c8adca1d7c359320aa8b1d9d608	technical note - extension of the elzinga-hearn algorithm to the weighted case	648 unconstrained optimization;185 facilities location	The problem considered in this note is that of locating a single new facility among m existing facilities with the objective of minimizing the maximum weighted Euclidean distance of the new facility from the existing facilities, without making the assumption that all the weights are equal. The new algorithm takes into consideration the structure of the problem, and it will terminate in a finite number of iterations if exact arithmetic is used.	algorithm	Christakis Charalambous	1982	Operations Research	10.1287/opre.30.3.591	mathematical optimization;combinatorics;discrete mathematics;mathematics;1-center problem	NLP	22.414921544912932	14.176497892493664	136171
7862f7667e267981eed3db1f6ba16cf6d07956a6	towards bin packing (preliminary problem survey, models with multiset estimates)		The paper described a generalized integrated glance to bin packing problems including a brief literature survey and some new problem formulations for the cases of multiset estimates of items. A new systemic viewpoint to bin packing problems is suggested: (a) basic element sets (item set, bin set, item subset assigned to bin), (b) binary relation over the sets: relation over item set as compatibility, precedence, dominance; relation over items and bins (i.e., correspondence of items to bins). A special attention is targeted to the following versions of bin packing problems: (a) problem with multiset estimates of items, (b) problem with colored items (and some close problems). Applied examples of bin packing problems are considered: (i) planning in paper industry (framework of combinatorial problems), (ii) selection of information messages, (iii) packing of messages/information packages in WiMAX communication system (brief description).	bin packing problem;cluster analysis;combinatorial optimization;computer science;emoticon;experiment;graph coloring;mathematical optimization;ordinal data;scheduling (computing);set packing	Mark Sh. Levin	2016	CoRR		mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	19.94602995351067	11.678975024515145	136475
d808e3d3d1627562f6cb6c741445952c8b81e911	arc crossing minimization in hierarchical digraphs with tabu search	minimisation;graph theory;hierarchical system;minimization;teoria grafo;graph drawing;project manager;systeme hierarchise;minimizacion;theorie graphe;optimisation combinatoire;temps calcul;sistema jerarquizado;red multinivel;computer experiment;tabu search;production scheduling;multilayer network;tiempo computacion;reseau multicouche;computation time;combinatorial optimization;business process reengineering;busqueda tabu;recherche tabou;modeling tool;optimizacion combinatoria;software visualization	Graphs are commonly used as a basic modeling tool in areas such as project management, production scheduling, line balancing, business process reengineering, and software visualization. An important problem in the area of graph drawing is to minimize arc crossings in a multi-layer hierarchical digraph. Existing solution methods for this problem are based on simple ordering rules for single layers that may lead to inferior drawings. This paper first introduces an extensive review of relevant work previously published in this area. Then a tabu search implementation is presented that seeks high-quality drawings by means of an intensification phase that finds a local optimum according to an insertion mechanism and two levels of diversification. Computational experiments with 200 graphs with up to 30 nodes per layer and up to 30 layers are presented to assess the merit of the method. * Research was supported by the Modeling Group of U S WEST Advanced Technologies, 4001 Discovery Drive, Boulder, CO 80303. ** Research was supported by the Conselleria de Educación y Ciencia de la Generalitat Valenciana. Spain. *** Research was supported by the Dirección General de Investigación Cientifica y Tecnica (DGICYT). Spain. 2 / LAGUNA, MARTÍ, and VALLS	business process;code refactoring;computation;crossing number (graph theory);directed graph;diversification (finance);experiment;graph drawing;layer (electronics);linear algebra;local optimum;nor gate;scheduling (computing);software visualization;tabu search	Manuel Laguna;Rafael Martí;Vicente Valls Verdejo	1997	Computers & OR	10.1016/S0305-0548(96)00083-4	software visualization;minimisation;mathematical optimization;computer experiment;combinatorial optimization;tabu search;business process reengineering;computer science;artificial intelligence;graph theory;mathematics;scheduling;hierarchical control system;graph drawing	ML	21.80029833347152	12.38716143267119	136710
033b2a2984ac3fc8a07afc0ed800079195019918	bivariate best first searches to process category based queries in a graph for trip planning applications in transportation		With the technological advancement in computer science, Geographic Information Science (GIScience), and transportation, more and more complex path finding queries including category based queries are proposed and studied across diverse disciplines. A category based query, such as Optimal Sequenced Routing (OSR) queries and Trip Planning Queries (TPQ), asks for a minimum-cost path that traverses a set of categories with or without a predefined order in a graph. Due to the extensive computing time required to process these complex queries in a large scale environment, efficient algorithms are highly desirable whenever processing time is a consideration. In Artificial Intelligence (AI), a best first search is an informed heuristic path finding algorithm that uses domain knowledge as heuristics to expedite the search process. Traditional best first searches are single-variate in terms of the number of variables to describe a state, and thus not appropriate to process these queries in a graph. In this dissertation, 1) two new types of category based queries, Category Sequence Traversal Query (CSTQ) and Optimal Sequence Traversal Query (OSTQ), are proposed; 2) the existing single-variate best first searches are extended to multivariate best first searches in terms of the state specified, and a class of new concepts--state graph, sub state graph, sub state graph space, local heuristic, local admissibility, local consistency, global heuristic, global admissibility, and global consistency--is	algorithm;artificial intelligence;best-first search;bivariate data;computer science;geographic information science;global serializability;heuristic (computer science);local consistency;open-source religion;pathfinding;routing;tree traversal	Qifeng Lu	2012			combinatorics;discrete mathematics;machine learning;mathematics	AI	23.061013989498196	7.4681204482301204	136963
04cd726db89981385c5e85871f897b7952f14630	minimizing makespan on identical parallel machines using neural networks	simulation ordinateur;distributed system;hopfield model;modele hopfield;condition initiale;longest processing time;tiempo total acabamiento;systeme reparti;fonction energie;execution time;modelo hopfield;machine parallele;temps total achevement;hopfield neural nets;problema np duro;inicializacion;energy function;processing time;dynamical system;systeme dynamique;simulation experiment;np hard problem;sistema repartido;condicion inicial;makespan;funcion penalidad;probleme np difficile;reseau neuronal hopfield;scheduling;initial condition;funcion energia;scheduling problem;dynamic neural network;temps traitement;temps execution;parallel machines;simulacion computadora;sistema dinamico;reseau neuronal;fonction penalite;tiempo ejecucion;computer simulation;tiempo proceso;red neuronal;initialization;ordonnancement;initialisation;reglamento;neural network;penalty function	This paper deals with the problem of minimizing the maximum completion time (makespan) of jobs on identical parallel machines. A Hopfield type dynamical neural network is proposed for solving the problem which is known to be NP-hard even for the case of two machines. A penalty function approach is employed to construct the energy function of the network and time evolving penalty coefficients are proposed to be used during simulation experiments to overcome the tradeoff problem. The results of proposed approach tested on a scheduling problem across 3 different datasets for 5 different initial conditions show that the proposed network converges to feasible solutions for all initialization schemes and outperforms the LPT (longest processing time) rule.	artificial neural network;coefficient;computation;experiment;heuristic;hopfield network;initial condition;makespan;mathematical optimization;np-hardness;parallel computing;parallel port;penalty method;scheduling (computing);simulation;whole earth 'lectronic link	Derya Eren Akyol;Gunhan Mirac Bayhan	2006		10.1007/11893295_61	job shop scheduling;initialization;simulation;computer science;artificial intelligence;dynamical system;penalty method;np-hard;scheduling;initial value problem;algorithm	AI	18.655963713247104	9.017594347775061	137477
14762bba189782c444677a44b0f9d22b9e732e76	average-case analysis of the double description method and the beneath-beyond algorithm	simplex method;average case analysis;dual problem;degeneration;correspondence analysis;linear program;incremental algorithm;point of view;convex hull	This paper deals with the average computational effort for calculating all vertices of a polyhedron described by m inequalities in an n-dimensional space, when we apply the so-called “Double Description Method” (from a dual point of view, i.e. for finding all facets of the convex hull of m given points, this is equivalent to application of the “BeneathBeyond Algorithm”). Both are incremental algorithms, i.e. they develop the information about the polyhedron stepwise by taking the inequalities/points successively into regard. The average-case analysis is done with respect to the Rotation-Symmetry Model, which is well known from the corresponding analysis of the Simplex Method for linear programming. In this model degenerate problems occur with probability 0. So the (finite) effort to solve those problems has no impact on the expected effort in our model. All the derived results and complexities apply equivalently to both algorithms and to the corresponding primal and dual problems.	best, worst and average case;computation;convex hull;linear programming;polyhedron;probabilistic analysis of algorithms;simplex algorithm;stepwise regression	Karl Heinz Borgwardt	2007	Discrete & Computational Geometry	10.1007/s00454-006-1257-8	big m method;mathematical optimization;combinatorics;discrete mathematics;duality;convex polytope;topology;linear programming;convex hull;mathematics;geometry;correspondence analysis;simplex algorithm	Theory	23.971960406044513	14.537943202820967	137753
0cd0eddf66888de02bc6d16fe49f1f4c04836cb8	a new formulation of the capacitated discrete ordered median problems with 0, 1-assignment				Justo Puerto	2007		10.1007/978-3-540-77903-2_26	mathematical optimization;combinatorics	Theory	22.877123743128426	8.511673710003398	137983
4f963cc779ac8af11cc25928865ff290fc1ccc2e	robust point correspondence by concave minimization	efficient algorithm;objective function;optimization problem;general methods;global optimization;feature selection;convex hull	We propose a new methodology for reliably solving the correspondence problem between points of two or more images. This is a key step in most problems of Computer Vision and, so far, no general method exists to solve it. Our methodology is able to handle most of the commonly used assumptions in a unique formulation, independent of the domain of application and type of features. It performs correspondence and outlier rejection in a single step, and achieves global optimality with feasible computation. Feature selection and correspondence are first formulated as an integer optimization problem. This is a brute force formulation, which considers the whole combinatorial space of possible point selections and correspondences. To find its global optimal solution we build a concave objective function and relax the search domain into its convex-hull. The special structure of this extended problem assures its equivalence to the original one, but it can be optimally solved by efficient algorithms that avoid combinatorial search. q 2002 Elsevier Science B.V. All rights reserved.	algorithm;brute-force search;combinatorial search;computational complexity theory;computer vision;concave function;convex hull;correspondence problem;feature selection;international symposium on fundamentals of computation theory;mathematical optimization;nvidia quadro;optimization problem;polynomial;rejection sampling;turing completeness	João Maciel;João Paulo Costeira	2000		10.5244/C.14.63	convex analysis;optimization problem;mathematical optimization;conic optimization;combinatorics;convex optimization;linear matrix inequality;nonlinear programming;computer science;convex hull;machine learning;mathematics;continuous optimization;vector optimization;feature selection;proper convex function;global optimization	Vision	21.93954661044318	10.426603719408558	138113
eebf4b9a015ab01c3922cca8ea34b45390892219	budgeted online assignment in crowdsourcing markets: theory and practice		We consider the following budgeted online assignment (BOA) problem motivated by crowdsourcing. We are given a set of offline tasks that need to be assigned to workers who come online from the pool of types {1, 2, ..., n}. For a given time horizon {1, 2, ..., T}, at each instant of time t, a worker j arrives from the pool in accordance with a known probability distribution [pjt] such that ∑j pjt ≤ 1; j has a known subset N(j) of the tasks that it can complete, and an assignment of one task i to j (if we choose to do so) should be done before task iu0027s deadline. The assignment e = (i,j) (of task i ∈ N(j) to worker j) yields a profit we to the crowdsourcing provider and requires different quantities of K distinct resources, as specified by a cost vector ae ∈ [0, 1]K; these resources could be client-centric (such as their budget) or worker-centric (e.g., a driveru0027s limitation on the total distance traveled or number of hours worked in a period). The goal is to design an online-assignment policy such that the total expected profit is maximized subject to the budget and deadline constraints.rnrnWe propose and analyze two simple linear programming (LP)-based algorithms and achieve a competitive ratio of nearly 1/(l + 1), where l is an upper bound on the number of non-zero elements in any ae. This is nearly optimal among all LP-based approaches.	crowdsourcing	Pan Xu;Aravind Srinivasan;Kanthi K. Sarpatwar;Kun-Lung Wu	2017			distributed computing;computer science;online algorithm;mathematical optimization;competitive analysis;probability distribution;time horizon;data mining;approximation algorithm;linear programming;upper and lower bounds;crowdsourcing	ECom	14.365911741202083	10.63691532278842	138223
3ca6899365ff3f842a2bdc32e53a3656a71f35ce	dynamically partitioning for solving qbf	quantified boolean formula;sat solver	In this paper we present a new technique to solve Quantified Boolean Formulas (QBF). Our technique applies the idea of dynamic partitioning to QBF solvers. Dynamic partitioning has previously been utilized in #SAT solvers that count the number of models of a propositional formula. One of the main differences with the #SAT case comes from the solution learning techniques employed in search based QBF solvers. Extending solution learning to a partitioning solver involves some considerable complexities which we show how to resolve. We have implemented our ideas in a new QBF solver, and demonstrate that dynamic partitioning is able to increase the performance of search based solvers, sometimes significantly. Empirically our new solver offers performance that is superior to other search based solvers and in many cases superior to non-search based solvers.	heuristic (computer science);olap cube;partial cube;sharp-sat;solver;true quantified boolean formula	Horst Samulowitz;Fahiem Bacchus	2007		10.1007/978-3-540-72788-0_22	mathematical optimization;discrete mathematics;computer science;theoretical computer science;mathematics;boolean satisfiability problem;algorithm	AI	13.549129382058375	16.323595195828823	138361
6559a562276131d85200e734baa95ff245cd242f	deriving compact extended formulations via lp-based separation techniques		The best formulations for some combinatorial optimization problems are integer linear programming models with an exponential number of rows and/or columns, which are solved incrementally by generating missing rows and columns only when needed. As an alternative to row generation, some exponential formulations can be rewritten in a compact extended form, which have only a polynomial number of constraints and a polynomial, although larger, number of variables. As an alternative to column generation, there are compact extended formulations for the dual problems, which lead to compact equivalent primal formulations, again with only a polynomial number of constraints and variables. In this this paper we introduce a tool to derive compact extended formulations and survey many combinatorial optimization problems for which it can be applied. The tool is based on the possibility of formulating the separation procedure by an LP model. It can be seen as one further method to generate compact extended formulations besides other tools of geometric and combinatorial nature present in the literature.	column (database);column generation;combinatorial optimization;integer programming;linear programming;mathematical optimization;net neutrality;polynomial;time complexity	Giuseppe Lancia;Paolo Serafini	2014	4OR	10.1007/s10288-014-0262-7	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	24.521146089906726	11.4094768320257	138581
5015a95ee6d8ee05d1b345429a4100b5d27b648a	an adaptive multi-parameter based dispatching strategy for single-loop interbay material handling systems	simulation ordinateur;tiempo espera;cycle time;multicriteria analysis;metodo adaptativo;microelectronic fabrication;multiagent system;completion time;fabricacion microelectrica;probleme livraison;interbay material handling system;logique floue;temps achevement;automatisation;logica difusa;date echeance;methode adaptative;intelligence artificielle;sistema complejo;probabilistic approach;automatizacion;buffer system;temps attente;semiconductor wafer fabrication;sistema amortiguador;fuzzy logic;origin destination;simulation experiment;adaptive;systeme complexe;complex system;manejo de materiales;enfoque probabilista;approche probabiliste;waiting time;materials handling;adaptive method;due date;dispatching problem;deadlock;interbloqueo;fecha vencimiento;artificial intelligence;multi parameter;analisis multicriterio;simulacion computadora;inteligencia artificial;analyse multicritere;interblocage;systeme tampon;sistema multiagente;tiempo acabado;mass transport;computer simulation;problema reparto;systeme multiagent;vehicle dispatching;fabrication microelectronique;manutention materiau;automation	The automation of interbay systems in 300mm semiconductor wafer fabrication systems (SWFSs) is complex due to the dynamic, stochastic and mass transportation demands, transportation deadlocks, and vehicle blockages. An adaptive multi-parameter based (AMP) dispatching policy is proposed to obtain better performance of the interbay material handling systems and SWFSs. The system parameters, including vehicle's distance, lot's due date, lot's waiting time, and lot's origin-destination buffer status parameters are simultaneously considered, and the multi-parameter's weight coefficients are adjusted adaptively by Takagi-Sugeno fuzzy logic method. With experimental data from an interbay system of 300mm SWFSs and running simulation experiments, it is demonstrated that the proposed approach has better performance in terms of cycle time, throughput, due-date satisfaction rate, and vehicle utilization compared to conventional single- and multi-attribute dispatching methodologies.	material handling	L. H. Wu;P. Y. Mok;J. Zhang	2011	Computers in Industry	10.1016/j.compind.2010.10.010	computer simulation;fuzzy logic;simulation;cycle time variation;computer science;engineering;bicarbonate buffering system;artificial intelligence;operations management;deadlock;automation;adaptive behavior;operations research;mass transfer	Robotics	19.14252967243533	6.361203610488999	138623
7c4a8caeecc0cb1a2219f100e0cd93c9e0e96cdb	rolling partial rescheduling with efficiency and stability based on local search algorithm	local effect;machine papier;critere stabilite;algoritmo busqueda;systeme grande taille;paper machine;local search algorithm;laminado;machine unique;algorithme recherche;effet local;gestion evenement;search algorithm;terminal;criterio estabilidad;large scale system;intelligence artificielle;rolling;sistema reactivo;optimisation combinatoire;busca local;large scale;single machine;maquina unica;scheduling;event management;reactive system;systeme reactif;artificial intelligence;stability criterion;inteligencia artificial;gestion aconticimiento;combinatorial optimization;laminage;maquina papel;local search;ordonnancement;recherche locale;reglamento;sistema gran escala;efecto local;optimizacion combinatoria	This paper discusses the single-machine large-scale rescheduling problem with efficiency and stability as criteria, where more disruptions arise during the execution of schedule. A rolling strategy is driven by disruption events and the reactive partial rescheduling (PR) is adopted at each disruption. Two types of PR sub-problem are designed respectively for the procedural and the terminal PR-horizons. A local search algorithm is used to solve the PR sub-problems. Computational results show that the rolling PR can greatly improve the schedule stability with little sacrifice in schedule efficiency and consistently outperforms the rolling RSR.		Bing Wang;Tao Liu	2006		10.1007/11816157_114	mathematical optimization;combinatorial optimization;computer science;artificial intelligence;local search	AI	19.85851153401795	6.463822189609622	138630
207c989fca14ab6037b84df8fe8fbad89eb1b65b	a scenario decomposition algorithm for 0-1 stochastic programs	parallel computation;scenario dual decomposition;0 1 stochastic programs	Section 3 of the paper “A scenario decomposition algorithm for 0-1 stochastic programs,” Operations Research Letters, 41(6):565-569, 2013, contains some errors. The result in Proposition 2 had to be stated with respect to epsilon optimality as opposed to optimality. In this errata the entire Section 3 is reproduced with the errors corrected. The portions highlighted in red indicate the changes with respect to the original paper.	algorithm;operations research	Shabbir Ahmed	2013	Oper. Res. Lett.	10.1016/j.orl.2013.07.009	mathematical optimization;discrete mathematics;theoretical computer science;mathematics	Robotics	19.14801357554031	11.727923657398575	138769
67e5ad8cfad7d0f8dc9b5cc52c670f73861ea56d	complexity and tractability islands for combinatorial auctions on discrete intervals with gaps		Combinatorial auctions are mechanisms for allocating bundles of goods to agents who each have preferences over these goods. Finding an economically efficient allocation, the so-called winner determination problem, is computationally intractable in the general case, which is why it is important to identify special cases that are tractable but also sufficiently expressive for applications. We introduce a family of auction problems in which the goods on auction can be rearranged into a sequence, and each bid submitted concerns a bundle of goods corresponding to an interval on this sequence, possibly with multiple gaps of bounded length. We investigate the computational complexity of the winner determination problem for such auctions and explore the frontier between tractability and intractability in detail, identifying tractable, intractable, and fixed-parameter tractable cases.	algorithm;analysis of algorithms;cobham's thesis;computation;computational complexity theory;decision problem;directed acyclic graph;dynamic programming;exception handling;longest path problem;mathematical optimization;np-completeness;parameterized complexity;polynomial;radio frequency;time complexity	Janosch Döcker;Britta Dorn;Ulrich Endriss;Dominikus Krüger	2016		10.3233/978-1-61499-672-9-802	common value auction;mathematical optimization;computer science;computational complexity theory;bundle;bounded function;combinatorial auction	AI	15.205787490550914	16.911108872085716	138935
06029adc17a59951e4dbf5cf7129de30805f722f	an a-team based architecture for constraint programming	optimisation sous contrainte;constrained optimization;distributed system;fiabilidad;reliability;multiagent system;architecture systeme;systeme reparti;agent based;automatisation;intelligence artificielle;automatizacion;constraint satisfaction;optimisation combinatoire;optimizacion con restriccion;combinatorial problem;satisfaction contrainte;probleme combinatoire;problema combinatorio;sistema repartido;fiabilite;constraint programming;artificial intelligence;arquitectura sistema;inteligencia artificial;satisfaccion restriccion;system architecture;combinatorial optimization;sistema multiagente;problem solving;systeme multiagent;optimizacion combinatoria;automation	The paper proposes an agent-based constraint programming architecture that we have successfully applied to solve large, particularly combinatorial, operations problems. The architecture is based on the asynchronous team (A-Team) in which multiple problem solving agents cooperate with each other by exchanging results to produce a set of nondominated solutions. We extend the A-Team by introducing CSP-specific agents, explicitly defining solution states, and enabling solution decomposition/composition, and thereby improve the performance, reliability, and automation of constraint programming significantly.	agent-based model;constraint programming;problem solving	Yujun Zheng;Lianlai Wang;Jinyun Xue	2006		10.1007/11802372_58	constraint logic programming;concurrent constraint logic programming;constraint programming;constrained optimization;simulation;constraint satisfaction;combinatorial optimization;computer science;artificial intelligence;automation;reliability;inductive programming;algorithm	AI	20.07208477481152	7.191758662195623	138949
d9cc1b928aa8a7bed648a86d4fc746d934437e2a	a genetic algorithm approach to manage ion implantation processes in wafer fabrication	ion implantation;scheduling;genetic algorithm;sequence dependent set ups	The management of ion implantation processes is one of several challenging problems in scheduling wafer fabrication facilities. A complicating factor is the fact that there are sequence dependent set-ups (e.g. species changes). Because of the set-ups, it is sometimes desirable to leave an implanter idle (if another lot requiring this species will arrive soon) rather than to change the set-up. We study the use of a genetic algorithm (GA) to assign the jobs to machines where the First In First Out (FIFO) dispatching rule is used to schedule the individual machines. This approach is compared to the use of a commonly used dispatching policy-set-up avoidance. The parameters of the genetic algorithm (population size, crossover probability, and mutation probability) are analysed using response surface techniques to find combinations that allow the algorithm to determine a relatively good solution in a short CPU time.	central processing unit;fifo (computing and electronics);genetic algorithm;ion implantation;response surface methodology;scheduling (computing);software release life cycle;wafer (electronics);wafer fabrication	Shwu-Min Horng;John W. Fowler;Jeffery K. Cochran	2000	IJMTM	10.1504/IJMTM.2000.001339	real-time computing;simulation;genetic algorithm;computer science;engineering;operations management;ion implantation;scheduling	Theory	13.778713269296963	6.083221978734695	138969
908cda3ae77297886b21df36c62982472770ab14	on minimizing average weighted completion time of multiprocessor tasks with release dates	time average;preemptive scheduling;temps polynomial;multiprocessor;processor scheduling;promedio temporal;processing time;polynomial time;approximation scheme;scheduling problem;temps traitement;ordonnancement processeur;multiprocesador;tiempo proceso;polynomial time approximation scheme;moyenne temporelle;tiempo polinomial;multiprocesseur	We consider the problem of scheduling n independent multiprocessor tasks with release dates on a fixed number of processors, where the objective is to compute a non-preemptive schedule minimizing the average weighted completion time. For each task, in addition to its processing time and release date, there is given a prespecified, dedicated subset of processors which are required to process the task simultaneously. We propose here a polynomial-time approximation scheme for the problem, making substantial improvement on previous results and following the recent developments [1, 2, 15] on approximation schemes for scheduling problems with the average weighted completion time objective.	multiprocessing	Aleksei V. Fishkin;Klaus Jansen;Lorant Porkolab	2001		10.1007/3-540-48224-5_71	time complexity;job shop scheduling;mathematical optimization;real-time computing;multiprocessing;polynomial-time approximation scheme;computer science;operating system;mathematics;preemption;multiprocessor scheduling;algorithm	Theory	16.435117054792578	10.899832855894514	139321
4e98aa7d5d15a8a1b6a7ae2345ccb4d9f2ebf527	optimizing over consecutive 1's and circular 1's constraints	consecutive 1 s constraints;shortest path;interval graph;parametric shortest path;satisfiability;optimization problem;circular scheduling problems;90c27;polynomial algorithm;scheduling problem;linear program;68q25;parametric optimization	We consider packing and covering optimization problems over constraints in consecutive and circular 1’s. Such problems arise in the context of shift scheduling, and in problems related to interval graphs. Previous approaches to this problem depended on solving several minimum cost network flow problems. We devise here substantially more efficient and strongly polynomial algorithms based on parametric shortest paths approaches. The objective function in the covering and packing problems is to either minimize or maximize the number of sets that satisfy the constraints. The various problems studied are classified according to whether the constraints are all consecutive 1’s or if there are also circular 1’s constraints, and according to whether the constraints are all of covering type; all of packing type, or mixed. The running time of our algorithm for a pure covering all consecutive 1’s constraints problem on n variables and m constraints is O(m + n). For the pure packing problem with consecutive 1’s constraints we present an O(m + n log n) time algorithm. For the “mixed” case with both covering and packing consecutive 1’s constraints we present an O(mn) time algorithm. An O(mn + n log n)-time algorithm is presented for the case where the constraints are circular (consecutive 1’s constraint is also circular) of pure type – either all covering constraints or all packing constraints. Finally, we show an O(n min{mn,n2 log n + m log n}) time algorithm for the most general problem of mixed covering and packing case where the constraints are circular. All our algorithms are strongly polynomial and improve on the non-strongly polynomial parametric minimum cost network flow or the (strongly polynomial) linear programming known approaches.	algorithm;binary logarithm;binary search algorithm;carrier-to-noise ratio;coefficient;convex function;cylinder-head-sector;dijkstra's algorithm;flow network;linear programming;mathematical optimization;maxima and minima;maximum flow problem;ncover;optimization problem;optimizing compiler;p (complexity);polynomial;problem solving;scheduling (computing);set packing;shift jis;shortest path problem;time complexity	Dorit S. Hochbaum;Asaf Levin	2006	SIAM Journal on Optimization	10.1137/040603048	optimization problem;job shop scheduling;mathematical optimization;combinatorics;discrete mathematics;interval graph;linear programming;mathematics;shortest path problem;satisfiability	Theory	22.911581793234667	13.876073136228229	139360
2e92d57d9dc8c43bc7c6ddf8d9cb793535a52656	advice complexity and barely random algorithms	medida informacion;online algorithm;algorithm complexity;gestion labor;algorithme en ligne;complejidad algoritmo;mesure information;68q87;radiobusqueda;barely random algorithms;algoritmo en linea;random number;information content;68wxx;input;upper bound;unit;aleatorizacion;online problems;paging;gestion tâche;complexite algorithme;information measure;informatique theorique;scheduling;algorithme aleatoire;advice complexity;entree ordinateur;borne inferieure;randomized algorithm;randomisation;nombre aleatoire;68q30;job shop;68q25;task scheduling;entrada ordenador;randomization;borne superieure;algoritmo optimo;algorithme optimal;optimal algorithm;numero aleatorio;68w20;radiomessagerie;ordonnancement;lower bound;reglamento;unite;cota superior;unidad;cota inferior;computer theory;68m20;informatica teorica	Recently, a new measurement – the advice complexity – was introduced for measuring the information content of online problems. The aim is to measure the bitwise information that online algorithms lack, causing them to perform worse than offline algorithms. Among a large number of problems, a well-known scheduling problem, job shop scheduling with unit length tasks, and the paging problem were analyzed within this model. We observe some connections between advice complexity and randomization. Our special focus goes to barely random algorithms, i. e., randomized algorithms that use only a constant number of random bits, regardless of the input size. We apply the results on advice complexity to obtain efficient barely random algorithms for both the job shop scheduling and the paging problem. Furthermore, so far, it has not yet been investigated for job shop scheduling how good an online algorithm may perform when only using a very small (e. g., constant) number of advice bits. In this paper, we answer this question by giving both lower and upper bounds, and also improve the best known upper bound for optimal algorithms.	bitwise operation;information;job shop scheduling;online algorithm;online and offline;page replacement algorithm;paging;randomized algorithm;scheduling (computing);self-information	Dennis Komm;Richard Královic	2011	RAIRO - Theor. Inf. and Applic.	10.1051/ita/2011105	job shop scheduling;simulation;flow shop scheduling;computer science;artificial intelligence;mathematics;upper and lower bounds;algorithm	Theory	16.908359744131836	11.85461147965705	139372
3f29eded55ea93c8811eaf40d892922caaeb80d1	on the use of intersection cuts for bilevel optimization	90c11 mixed integer programming;90c57 polyhedral combinatorics;branch-and-bound;branch-and-cut;65k05 mathematical programming methods	We address a generic Mixed-Integer Bilevel Linear Program (MIBLP), i.e., a bilevel optimization problem where all objective functions and constraints are linear, and some/all variables are required to take integer values. We first propose necessary modifications needed to turn a standard branch-and-bound MILP solver into an exact and finitely-convergent MIBLP solver, also addressing MIBLP unboundedness and infeasibility. As in other approaches from the literature, our scheme is finitely-convergent in case both the leader and the follower problems are pure integer. In addition, it is capable of dealing with continuous variables both in the leader and in follower problems—provided that the leader variables influencing follower’s decisions are integer and bounded. We then introduce new classes of linear inequalities to be embedded in this branch-and-cut framework, some of which are intersection cuts based on feasible-free convex sets. We present a computational study on various classes of benchmark instances available from the literature, in which we demonstrate that our approach outperforms alternative state-ofthe-art MIBLP methods.	add-ons for firefox;benchmark (computing);bilevel optimization;branch and bound;branch and cut;computation;convex set;embedded system;heuristic (computer science);linear inequality;linear programming;mathematical optimization;optimization problem;polyhedron;solver;turned a	Matteo Fischetti;Ivana Ljubic;Michele Monaci;Markus Sinnl	2018	Math. Program.	10.1007/s10107-017-1189-5	mathematics;discrete mathematics;mathematical optimization;linear inequality;bilevel optimization;bounded function;linear programming;integer;solver	Logic	23.643342936478962	10.83924665241205	139394
ceb861b5420e8cb95d7ac2dad0fed08d0efd73dd	a stabilized column generation scheme for the traveling salesman subtour problem	heuristique;optimisation sous contrainte;graphe non oriente;traveling salesman problem;constrained optimization;mathematics;experimental analysis;non directed graph;travelling salesman problem;prize collecting traveling salesman problem;stabilized column generation;generation colonne stabilisee;optimization method;satisfiability;metodo optimizacion;traveling salesman;problema viajante comercio;upper bound;optimizacion con restriccion;traveling salesman subtour problem;programacion lineal;probleme commis voyageur;grafo no orientado;90c27;90b10;informatique theorique;edge graph;methode optimisation;linear programming relaxation;linear programming;programmation lineaire;linear program;arete graphe;borne superieure;matematik;1 tree problem with one degree constraint;column generation;arista grafico;cota superior;computer theory;informatica teorica	Given an undirected graph with edge costs and both revenues and weights on the vertices, the traveling salesman subtour problem is to find a subtour that includes a depot vertex, satisfies a knapsack constraint on the vertex weights, and that minimizes edge costs minus vertex revenues along the subtour. We propose a decomposition scheme for this problem. It is inspired by the classic side-constrained 1-tree formulation of the traveling salesman problem, and uses stabilized column generation for the solution of the linear programming relaxation. Further, this decomposition procedure is combined with the addition of variable upper bound (VUB) constraints, which improves the linear programming bound. Furthermore, we present a heuristic procedure for finding feasible subtours from solutions to the column generation problems. An extensive experimental analysis of the behavior of the computational scheme is presented. © 2006 Elsevier B.V. All rights reserved.	column generation;graph (discrete mathematics);heuristic;linear programming relaxation;pseudoforest;travelling salesman problem	Andreas Westerlund;Maud Göthe-Lundgren;Torbjörn Larsson	2006	Discrete Applied Mathematics	10.1016/j.dam.2005.04.012	2-opt;mathematical optimization;combinatorics;linear programming;mathematics;travelling salesman problem;algorithm;bottleneck traveling salesman problem	AI	22.37847705036372	12.714903022439678	139937
4315baed930e06dac39875eba9e289e95d964309	approximation algorithms for combinatorial problems	approximate algorithm;combinatorial problems;set covering problem;satisfiability;optimization problem;knapsack problem;maximum clique;approximate solution;polynomial time;heuristic algorithm	Simple, polynomial-time, heuristic algorithms for finding approximate solutions to various polynomial complete optimization problems are analyzed with respect to their worst case behavior, measured by the ratio of the worst solution value that can be chosen by the algorithm to the optimal value. For certain problems, such as a simple form of the kanpsack problem and an optimization problem based on satisfiability testing, there are algorithms for which this ratio is bounded by a constant, independent of the problem size. For a number of set covering problems, simple algorithms yield worst case ratios which can grow with the log of the problem size. And for the problem of finding the maximum clique in a graph, no algorithm has been found for which the ratio does not grow at least as fast as n^@e, where n is the problem size and @e>0 depends on the algorithm.	approximation algorithm	David S. Johnson	1974	J. Comput. Syst. Sci.	10.1016/S0022-0000(74)80044-9	heuristic;time complexity;continuous knapsack problem;optimization problem;mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;set packing;vertex cover;covering problems;combinatorial optimization;computer science;generalized assignment problem;cutting stock problem;p versus np problem;mathematics;assignment problem;set cover problem;maximum common subgraph isomorphism problem;co-np-complete;knapsack problem;approximation algorithm;satisfiability	Theory	21.446050267785736	17.62062426942535	139984
fb80eedf118a78fb6d84fcd4995c4899b5bfa8cf	a column generation heuristic for the two-dimensional two-staged guillotine cutting stock problem with multiple stock size	mixed integer linear program;cutting;packing;cutting stock problem;knapsack problem;combinatorial optimization;column generation;heuristic algorithm	We consider a Two-Dimensional Cutting Stock Problem where stock of different sizes is available, and a set of rectangular items has to be obtained through two-staged guillotine cuts. We propose a heuristic algorithm, based on column generation, which requires as subproblem the solution of a Two-Dimensional Knapsack Problem with two-staged guillotines cuts. A further contribution of the paper consists in the definition of a Mixed Integer Linear Programming Model for the solution of this Knapsack Problem, as well as a heuristic procedure based on dynamic programming. Computational experiments show the effectiveness of the proposed approach, which obtains very small optimality gaps and outperforms the heuristic algorithm proposed by Cintra et al. [3].	algorithm;column generation;computation;cutting stock problem;dynamic programming;experiment;heuristic (computer science);knapsack problem;linear programming;np-hardness;programming model	Fabio Furini;Enrico Malaguti;Rosa Medina Durán;Alfredo Persiani;Paolo Toth	2012	European Journal of Operational Research	10.1016/j.ejor.2011.10.018	column generation;heuristic;continuous knapsack problem;mathematical optimization;combinatorics;combinatorial optimization;operations management;cutting stock problem;change-making problem;mathematics;cutting;knapsack problem	AI	16.567025059088742	6.531529937093502	140149
e1dc2ec5276560694891c281dcef0b54acb0a7b1	scheduling on-demand broadcast with timing constraints	systeme temps reel;modelizacion;distributed system;optimal solution;timing constraints;database system;solution optimale;systeme reparti;aggregated critical requests;sistema temporizado;recompense;modelo markov;proceso markov;complejidad polinomial;real time;timed system;database;base dato;decision markov;polynomial complexity;deadline;modelisation;dynamic environment;recompensa;complexite polynomial;reward;markov model;sistema repartido;scheduling;waiting time;processus markov;solucion optima;temps reel;diffusion donnee;on demand broadcasting;markov process;difusion dato;base de donnees;systeme temporise;tiempo real;markov decision;real time system;sistema tiempo real;markov decision process;data broadcast;modele markov;date limite;fechas ultimas;modeling;ordonnancement;reglamento;real time systems;pspace;time constraint	Broadcast delivery has been acknowledged as an effective way to dispense data in certain highly dynamic environments. While there are several well-known on-line broadcast scheduling strategies that minimize wait time, there has been little research that considers on-demand broadcasting with timing constraints. Scheduling strategies are needed that identify which data item to broadcast next in order to minimize missed deadlines. In this work, we present the mathematical formulation of a realtime broadcast system and an analysis of the system as a Markov Decision Process (MDP). The MDP model indicates finding an optimal solution is a hard problem in PSPACE. We propose two scheduling heuristics, called Aggregated Critical Requests-ω (ACR-ω) and Aggregated Critical Requests-β (ACR-β), which are based on the MDP formulation. These scheduling algorithms are designed for timely delivery of data to clients in order to maximize the reward by minimizing the deadlines missed. Results from trace-driven experiments indicate the ACR approach provides a flexible strategy that can outperform existing strategies under a variety of factors.	algorithm;content delivery network;crew scheduling;data item;experiment;heuristic (computer science);markov chain;markov decision process;online and offline;pspace;schedule (project management);scheduling (computing)	Qiu Fang;Susan V. Vrbsky;Ming Lei;Richard Borie	2009	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2009.04.009	markov decision process;real-time computing;simulation;real-time operating system;systems modeling;pspace;computer science;operating system;markov process;markov model;scheduling	AI	17.337465812475685	10.122888631825981	140268
dde8150341bc459b3ade2b8c26407e5a28f1d82d	approximation strategy based on data merging for static data management in networks	hierarchical structure;optimized production technology;approximate algorithm;approximation strategy facility location data management data merging;data merging;approximation algorithms;data management;greedy algorithms;linear programming approximation theory data handling greedy algorithms;data mining;service installation cost;constant ratio approximation algorithm;approximation strategy;approximation theory;computational modeling;merging costs approximation algorithms clustering algorithms tree graphs computer network management conference management technology management frequency polynomials;linear programming data merging static data management greedy method lp dual method constant ratio approximation algorithm facility location service installation cost;merging;linear programming;static data management;clustering algorithms;approximation methods;data handling;lp dual method;facility location;greedy method	we studied static data management problem based on data merging in general networks with object to minimize the total costs. By using greedy and LP-dual method, an initial placement is acquired. Given network \emph{G=(V, E)} and data set \emph{X}, we can achieve a constant ratio approximation algorithm.The key of our method is to construct some clusters based on hierarchical structure for requests. In order to get the initial placement, we preciously discuss an approximation strategy for a variance of facility location with service installation cost.	apx;approximation algorithm;greedy algorithm	Dongmei Xing;Hong Zhu	2009	2009 Fifth International Joint Conference on INC, IMS and IDC	10.1109/NCM.2009.64	mathematical optimization;greedy algorithm;data management;computer science;linear programming;theoretical computer science;data mining	DB	20.227617641912538	14.769379450502075	140458
40e7750fecf39b42a8d1a29bb0980f4abf48fbf6	heuristic algorithms for hadamard matrices with two circulant cores	heuristique;metodologia;heuristica;05bxx;geometry;combinatorial problems;05b20;geometrie;methodologie;68wxx;fonction objectif;hadamard matrix;objective function;combinatorial problem;terme;conception algorithme;probleme combinatoire;problema combinatorio;hadamard matrices;matrices;informatique theorique;heuristic algorithms;addition;funcion objetivo;tabu search;geometria;difference set;heuristics;methodology;05b10;matrice;algorithme heuristique;busqueda tabu;heuristic algorithm;recherche tabou;computer theory;adiccion;informatica teorica	We design heuristic algorithms to construct Hadamard matrices with two circulant cores. This hard combinatorial problem can be formulated in terms of objective functions of several binary variables, so that heuristic methodologies can be used. Our algorithms are based on local and tabu search and they use information on the geometry of the objective function landscapes. In addition, we use the supplementary difference sets formalism to detect when solutions of a special structure exist. Using these algorithms we have computed at least one Hadamard matrix with two circulant cores of the sixteen orders 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116. In particular, the Hadamard matrix with two circulant cores of order 116 is constructed here for the first time, indeed it was accidentally reported as known in an earlier paper. © 2008 Elsevier B.V. All rights reserved.	algorithm;circulant matrix;hadamard transform;heuristic;loss function;optimization problem;semantics (computer science);tabu search	Marco Chiarandini;Ilias S. Kotsireas;Christos Koukouvinos;Luís Paquete	2008	Theor. Comput. Sci.	10.1016/j.tcs.2008.06.002	heuristic;mathematical optimization;combinatorics;hadamard transform;tabu search;heuristics;methodology;mathematics;complex hadamard matrix;hadamard matrix;addition;algorithm;matrix;difference set	AI	22.500160262615946	11.837305198544398	140576
1c2521b0ce8562fd8fc213e94622f7e258dad7d3	the selective fixing algorithm for the closest string problem	closest string problem;continuous relaxation;heuristics	A hybrid heuristic algorithm based on integer linear programming is proposed for the closest string problem (CSP). The algorithm takes a rough feasible solution in input and iteratively selects variables to be fixed at their initial value until the number of free variables is small enough for the remaining problem to be solved to optimality by an ILP solver. The new solution can then be used as input for another iteration of the algorithm and this approach is repeated a predefined number of times. The procedure is denoted as Selective Fixing Algorithm (SFA). SFA has first been tested on standard instances available from the literature, which is denoted as rectangular having string length larger than the number of strings. Then, this approach has also been tested on the so-called square instances (having string length equal to the number of strings) and rectangular inverse instances (having string length smaller than the number of strings). Computational experiments indicate that SFA globally outperforms the state-of-the-art heuristics.	algorithm;closest string	Federico Della Croce;Michele Garraffa	2014	Computers & OR	10.1016/j.cor.2013.07.017	mathematical optimization;combinatorics;discrete mathematics;commentz-walter algorithm;heuristics;boyer–moore string search algorithm;mathematics;string metric;string searching algorithm	NLP	23.52888079102648	5.737831567539092	140966
3efc523700c87b40ab9e51b0a53b819736a11a68	soft scheduling		Classical notions of disjunctive and cumulative scheduling are studied from the point of view of soft constraint satisfaction. Soft disjunctive scheduling is introduced as an instance of soft CSP and preferences included in this problem are applied to generate a lower bound based on existing discrete capacity resource. Timetabling problems at Purdue University and Faculty of Informatics at Masaryk University considering individual course requirements of students demonstrate practical problems which are solved via proposed methods. Implementation of general preference constraint solver is discussed and first computational results for timetabling problem are presented.	constrained optimization;constraint programming;constraint satisfaction;disjunctive normal form;informatics;requirement;scheduling (computing);solver;timeline	Hana Rudová	2001	CoRR			AI	19.801490625610786	10.381103673710816	141069
a5dc8a7844825ea41a6298c69b7de1df9106669d	practical methods of optimization volume 1 : unconstrained optimization, by r. flet-cher, wiley, new york, 1980, 120 pp. price: $24.50	unconstrained optimization		john d. wiley;mathematical optimization	Trond Steihaug	1982	Networks	10.1002/net.3230120417	constrained optimization;computer science;mathematics	ML	23.569462678490833	9.16413331153873	141220
d18a807ad1c87e881829f84c153e5ee2c42b5ba5	multiple sequence alignment using saga: investigating the effects of operator scheduling, population seeding, and crossover operators	alignement sequence;score function;biologia molecular;inicializacion;alineacion secuencia;algoritmo genetico;scheduling;molecular biology;determinante;algorithme genetique;determinant;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;sequence alignment;multiple sequence alignment;evolutionary algorithm;initialization;ordonnancement;initialisation;reglamento;biologie moleculaire	Multiple sequence alignment (MSA) is a fundamental problem of great importance in molecular biology. In this study, we investigated several aspects of SAGA, a well-known evolutionary algorithm (EA) for solving MSA problems. The SAGA algorithm is important because it represents a successful attempt at applying EAs to MSA and since it is the first EA to use operator scheduling on this problem. However, it is largely undocumented which elements of SAGA are vital to its performance. An important finding in this study is that operator scheduling does not improve the performance of SAGA compared to a uniform selection of operators. Furthermore, the experiments show that seeding SAGA with a ClustalW-derived alignment allows the algorithm to discover alignments of higher quality compared to the traditional initialization scheme with randomly generated alignments. Finally, the experimental results indicate that SAGA’s performance is largely unaffected when the crossover operators are disabled. Thus, the major determinant of SAGA’s success seems to be the mutation operators and the scoring functions used.	clustalw/clustalx;evolutionary algorithm;experiment;multiple sequence alignment;procedural generation;randomness;scheduling (computing);scoring functions for docking;undocumented feature	René Thomsen;Wouter Boomsma	2004		10.1007/978-3-540-24653-4_12	initialization;determinant;genetic algorithm;multiple sequence alignment;computer science;bioinformatics;artificial intelligence;evolutionary algorithm;sequence alignment;score;programming language;scheduling;algorithm	AI	20.956422590411314	5.795242293729882	141338
13dd1eda7c6820c8d1fbf08cf35493430ec25508	online scheduling of simple linear deteriorating jobs to minimize the total general completion time	liverpool;repository;university	Traditional scheduling assumes that the processing time of a job is fixed. Yet there are numerous situations in which the processing time increases (deteriorates) as the start time increases. In particular, lots of work has been devoted to jobs with simple linear deterioration. The processing time pj of job Jj is a simple linear function of its start time sj, precisely, pj = bjsj, where bj is the deteriorating rate. In this paper, we study the problem of online non-preemptive scheduling of jobs with arbitrary release times and simple linear deteriorating rates on a single machine to minimize the total general completion time. We present an algorithmDSDR (Delayed Smallest Deteriorating Rate) andprove that it achieves the best-possible competitive ratio (1 + bmax) for all deterministic online algorithms, where α is the general index of completion time and α > 0. © 2013 Elsevier B.V. All rights reserved.	competitive analysis (online algorithm);index (publishing);job shop scheduling;job stream;linear function;loss function;makespan;nonlinear system;online algorithm;online and offline;optimization problem;scheduling (computing);throughput	Sheng Yu;Prudence W. H. Wong	2013	Theor. Comput. Sci.	10.1016/j.tcs.2013.02.024	real-time computing;computer science;operations research	Theory	15.759756171864566	10.350758445364827	141634
899b66f46cf65d356095c59f1d66dde2a54ec75b	randomized approximation algorithm for minimum submodular cost partial multi-cover problem		This paper studies randomized approximation algorithm for a variant of the set cover problem called minimum submodular cost partial multi-cover (SCPMC). In a partial set cover problem, the goal is to find a minimum cost subcollection of sets covering at least a required fraction of elements. In a multi-cover problem, each element e has a covering requirement re, and the goal is to find a minimum cost subcollection of sets S ′ which fully covers all elements, where an element e is fully covered by S ′ if e belongs to at least re sets of S ′. In a minimum submodular cost set cover problem (SCSC), the objective function is submodular and the constraint is a set cover. The SCPMC problem studied in this paper is a combination of the above three problems. Previous work shows that such a combination enormously increases the difficulty of studies. In this paper, assuming that the maximum covering requirement rmax = maxe re is a constant and the objection function is nonnegative, monotone increasing, and submodular, we give the first randomized algorithm for SCPMC achieving performance ratio O(b) with a high probability, where b = maxe ( f re ) and f is the maximum number of sets containing a common element. The algorithm is based on a novel non-linear program. Furthermore, in the case when the covering requirement r ≡ 1, an O(f)-approximation can be achieved even when monotonicity requirement is dropped off from the objective function.	approximation algorithm;linear programming;loss function;nonlinear system;optimization problem;randomized algorithm;set cover problem;submodular set function;monotone	Yishuo Shi;Zhao Zhang;Dingzhu Du	2017	CoRR		discrete mathematics;monotone polygon;submodular set function;combinatorics;monotonic function;set cover problem;approximation algorithm;mathematics;mathematical optimization;randomized algorithm	Theory	21.242796909058168	16.74317878985093	141725
922b96b2377ce67c539a4635a38dd2f166c6f245	scheduling identical jobs with chain precedence constraints on two uniform machines	tiempo total acabamiento;machine uniforme;temps lineaire;temps total achevement;tiempo lineal;identical jobs;algorithme;constrenimiento precedencia;algorithm;makespan;uniform machines;scheduling;job identique;linear time;precedence constraint;contrainte precedence;ordonamiento;key words scheduling;ordonnancement;chain precedence constraints;algoritmo	The problem of scheduling identical jobs with chain precedence constraints on two uniform machines is considered. It is shown that the corresponding makespan problem can be solved in linear time.	scheduling (computing)	Peter Brucker;Johann Hurink;Wieslaw Kubiak	1999	Math. Meth. of OR	10.1007/PL00020913	time complexity;job shop scheduling;real-time computing;mathematics;distributed computing;scheduling	Theory	16.881080493059542	10.816461169250822	141849
6ce4cec6cd241d45b7c7b87e2dcf28bb7bb76c39	branch-and-bound parallelization strategies applied to a depot location and container fleet management problem	complex objects;location problem;network design;distributed networks;branch and bound algorithm;search trees;multicommodity location with balancing requirements;network flow;branch and bound;parallel optimization	This paper presents branch-and-bound parallelization strategies applied to the location/allocation problem with balancing requirements. This formulation is representative of a larger class of discrete network design and location problems arising in many transportation logistics and telecommunications applications: it displays a multicommodity network flow structure and a complex objective function comprising fixed and variable flow costs. As for many problems of this class, the bounding procedure embedded in the branch-and-bound algorithm is complex and time-consuming. The parallelization strategies that we describe are designed to exploit this feature. Parallelism is obtained by dividing the search tree among processors and performing operations on several subproblems simultaneously. The strategies differ in the way they manage the list of subproblems and control the search. We report and analyze experimental results, on a distributed network of workstations, which aim to compare different implementations of these strategies.	branch and bound;parallel computing	Benoît Bourbeau;Teodor Gabriel Crainic;Bernard Gendron	2000	Parallel Computing	10.1016/S0167-8191(99)00094-0	mathematical optimization;parallel computing;computer science;theoretical computer science;distributed computing;branch and bound	PL	17.4296223514617	4.657532670118844	141912
965136b5b3cdaca74c0947e93a39778b1bb710ba	on the generalised stock–cutting problem	optimal solution;mathematical morphology;morphological operation;simulated annealing;key words stock cutting mathematical morphology optimisation simulated annealing mathematical programming;mathematical programming	In this paper, we formulate the two-stage stock-cutting problem, according to which a set of rectangular pieces of prespecified dimensions are to be cut from an arbitrarily shaped object with arbitrarily shaped holes or defective regions. We show how mathematical morphological operators can be used in order to determine the optimal shifting for a given cutting pattern. It is then proved that the problem of obtaining the optimal cutting pattern is ${\cal NP}$ -hard and a solution to the unconstrained problem using mathematical programming is proposed. However, for the general problem, good sub-optimal solutions can be obtained using the technique of simulated annealing. Experimental results are also included.	analysis of algorithms;coefficient;emoticon;heuristic (computer science);integer programming;mathematical morphology;mathematical optimization;programming model;set packing;simplex algorithm;simulated annealing;workstation	Nikos Georgis;Maria Petrou;Josef Kittler	2000	Machine Vision and Applications	10.1007/s001380050106	mathematical optimization;mathematical morphology;simulated annealing;computer science;cutting stock problem;machine learning;mathematics	Vision	16.607373398910827	6.613571287617481	142094
2a04c0b0ce18fdf58869afb610c5766f7fbc0a33	further results on the exploration of combinatorial tree in multi-parametric quadratic programming		A combinatorial approach has been recently proposed for multi-parametric quadratic programming and has shown to be more effective in finding the complete solution than existing geometric methods for higher-order systems. In this paper, we propose a method for exploring the combinatorial tree which exploits some of the underlying geometric properties of adjacent critical regions as the supplementary information in combinatorial approach to exclude a noticeable number of feasible candidate active sets from combinatorial tree. This method is particularly well-suited for cases where many combinations of active constraints are feasible but not optimal. Results indicate that this method can find all critical regions corresponding to non-degenerate multi-parametric programming. A postprocessing algorithm can be applied to complete the proposed method in the cases in which some critical regions might not be enumerated due to degeneracies in the problem.	active set method;algorithm;degenerate energy levels;parametric programming;quadratic programming;video post-processing	Parisa Ahmadi-Moshkenani;Sorin Olaru;Tor Arne Johansen	2016	2016 European Control Conference (ECC)	10.1109/ECC.2016.7810273	mathematical optimization;combinatorics;discrete mathematics;combinatorial optimization;combinatorial principles;mathematics	Robotics	23.81005121116162	15.355564013395275	142149
84b37584bc14720679fd195adbf3ed34a7297e7f	min-domain retroactive ordering for asynchronous backtracking	search algorithm;artificial intelligent;search;distributed constraints satisfaction;distributed constraint satisfaction;ordering heuristics	Ordering heuristics are a powerful tool in CSP search algorithms. Among the most successful ordering heuristics are heuristics which enforce a fail first strategy by using the Min-domain property (Haralick and Elliott, Artif Intel 14:263–313, 1980; Bessiere and Regin, Mac and combined heuristics: two reasons to forsake FC (and CBJ?) on hard problems. In Proc. CP 96, pp. 61–75, Cambridge, MA, 1996; Smith and Grant, Trying harder to fail first. In European Conference on Artificial Intelligence, pp. 249–253, 1998; Dechter, Constraint Processing. Morgan Kaufman, 2003). Ordering heuristics have been introduced recently to asynchronous backtracking (ABT), for distributed constraints satisfaction (DisCSP) (Zivan and Meisels, Dynamic ordering for asynchronous backtracking on discsps. In CP-2005, pp. 32–46, Sigtes (Barcelona), Spain, 2005). However, the pioneering study of dynamically ordered ABT, ABT_DO, has shown that a straightforward implementation of the Min-domain heuristic does not produce the expected improvement over a static ordering. The present paper proposes an asynchronous dynamic ordering which does not follow the standard restrictions on the position of reordered agents in ABT_DO. Agents can be moved to a position that is higher than that of the target of the backtrack. Combining the Nogood-triggered heuristic and the Min-domain property in this new class of heuristics results in the best performing version of ABT_DO. The new version of retroactively ordered ABT is faster by a large factor than the best form of ABT.	analytical base table;backtrack;backtracking;communicating sequential processes;distributed constraint optimization;european conference on artificial intelligence;experiment;heuristic (computer science);maxima and minima;morgan;robert haralick;search algorithm;time complexity	Roie Zivan;Moshe Zazone;Amnon Meisels	2008	Constraints	10.1007/s10601-008-9046-z	mathematical optimization;computer science;artificial intelligence;algorithm;search algorithm	AI	22.12588006728452	4.764030030282857	142260
6e75640477ab417eff650109ba28c4ed7bbf3604	soc test scheduling algorithm using aco-based rectangle packing	bin packing problem;optimal solution;plan masse;invertebrata;solution optimale;swarm intelligence;arthropoda;insecto social;ant algorithm;problema relleno;intelligence artificielle;system on a chip;layout plan;scheduling algorithm;espace probabilite;sistema sobre pastilla;optimizacion enjambre particula;aculeata;insecta;scheduling;solucion optima;optimisation essaim particule;espacio probabilidad;probleme remplissage;artificial intelligence;systeme sur puce;hymenoptera;inteligencia artificial;insecte social;test scheduling;social insect;formicoidea;probability space;plano masa;ordonnancement;reglamento	This paper presents a new SoC test scheduling method based on an ant algorithm. The proposed scheduling algorithm formulates the SoC test scheduling problem as a rectangle bin packing problem and uses ACO to cover more solution space to increase the probability of finding optimal solutions. The experimental results conducted using ITC '02 SoC benchmarks show that the proposed idea gives the test application time comparable to earlier researches in less calculation time.	algorithm;scheduling (computing);set packing	Jin-Ho Ahn;Sungho Kang	2006		10.1007/11816171_82	swarm intelligence;computer science;artificial intelligence;operating system;scheduling;algorithm	EDA	19.757962904978363	6.438333310348094	142286
2d9be64d5c8fcb0a8f8c53a8db0f59ac7da1a7fd	fuzzy admission control and scheduling of production systems	optimisation;queueing theory;fuzzy control;production system;optimisation fuzzy admission control scheduling production systems fuzzy logic holding cost parallel machines queueing theory poisson streams resource demand;fuzzy logic;production control;average cost;optimisation production control fuzzy control fuzzy logic queueing theory;parallel machines;infinite horizon;fuzzy control fuzzy systems admission control production systems costs workstations fuzzy logic infinite horizon parallel machines context modeling;fuzzy model;admission control	Two outstanding problems of admission control and scheduling in networks with three and two workstations respectively are solved using fuzzy logic. In the first case we have one workstation with two parallel ones. A reward is earned whenever the first stage accepts a customer and a holding cost is incurred by a customer in the queue in the second stage. The class of customer to be served next by the first stage is dynamically selected so as to maximize an average benefit over an infinite horizon. In the second case there are two parallel machines and three arrival processes generated by independent Poisson streams. Each machine has its own queue and receives parts from its own arrival stream. The third arrival stream consists of parts with resource demand on both machines. Each customer pays a holding cost per unit time in the system. Again, the scheduling policy is specified which minimizes the average cost. The fuzzy models are new in this context and tackle problems that cannot be solved by analysis.	schedule (project management)	Runtong Zhang;Yannis A. Phillis	1999		10.1109/ROBOT.1999.772573	fuzzy logic;control engineering;real-time computing;fuzzy transportation;computer science;artificial intelligence;fuzzy number;production system;queueing theory;fuzzy set operations;fuzzy control system	Robotics	10.200690626069939	7.0197504746103165	142477
b7ebd6b12bc066737687a2d951be0713e009fec9	some two-agent single-machine scheduling problems to minimize minmax and minsum of completion times		In this study we address several two-agent problems in which the measure criterion is to minimize the maximum cost or total weighted completion of all the jobs, while subject to an upper bound on the maximum cost of agent A. In term of minimizing the maximum cost of all the jobs subject to an upper bound on the maximum cost of agent A, we discuss some optimal properties and propose polynomial time solution algorithm to solve it. In term of minimizing the total weighted completion of all the jobs subject to an upper bound on the maximum cost of agent A, we analyze the complexity, show that this problem is NP-hard, and discuss it under special cases. In addition, for minimizing the total weighted completion of all the jobs subject to an upper bound on the makespan of agent A, we derive some dominance rules to be used in a branch-and-bound method and propose a heuristic for finding the optimal and near-optimal solution, respectively. A computational simulation is also provided to determine the performance of the proposed algorithms.	minimax;scheduling (computing);single-machine scheduling	Xiaoling Cao;Wen-Hsing Wu;Wen-Hung Wu;Chin-Chia Wu	2018	Operational Research	10.1007/s12351-016-0265-6	mathematical optimization;operations management;mathematics;algorithm	AI	15.561376542501824	10.081376958440565	142494
a0a7399fd7712502daf042f391b3e5d8ae0cfee6	the hierarchical mixed rural postman problem: polyhedral analysis and a branch-and-cut algorithm	hierarchical routing problems;polyhedral analysis;branch and cut;mixed rural postman problem	The Hierarchical Mixed Rural Postman Problem is defined on a mixed graph where arcs and edges that require a service are divided into clusters that have to be serviced in a hierarchical order. The problem generalizes the Mixed Rural Postman Problem and thus is NP-hard. In this paper, we provide a polyhedral analysis of the problem and propose a branch-and-cut algorithm for its solution based on the introduced classes of valid inequalities. Extensive computational experiments are reported on benchmark instances. The exact approach allows to find the optimal solutions in less than 1 hour for instances with up to 999 vertices, 2678 links, and five clusters.	algorithm;branch and cut;polyhedral;route inspection problem	Marco Colombi;Ángel Corberán;Renata Mansini;Isaac Plana;José María Sanchis	2017	European Journal of Operational Research	10.1016/j.ejor.2016.07.026	mathematical optimization;combinatorics;discrete mathematics;mathematics;branch and cut	Robotics	22.6774635364416	8.37164631926816	142593
3214cd82471a7673272c009e27c64e17f40f5e7a	roll cutting in the curtain industry, or: a well-solvable allocation problem	metodo polinomial;temps polynomial;cutting;cutting stock problem;polynomial time algorithm;probleme decoupe;polynomial method;allocation problem;polynomial time;future orders;problema troquelado;methode polynomiale;tiempo polinomial	We study the problem of cutting a number of pieces of the same length from  n  rolls of different lengths so that the remaining part of each utilized roll is either sufficiently short or sufficiently long. A piece is ‘sufficiently short’, if it is shorter than a pre-specified threshold value  δ  min , so that it can be thrown away as it cannot be used again for cutting future orders. And a piece is ‘sufficiently long’, if it is longer than a pre-specified threshold value  δ  max  (with  δ  max  >  δ  min ), so that it can reasonably be expected to be usable for cutting future orders of almost any length. We show that this problem, faced by a curtaining wholesaler, is solvable in  O ( n log n ) time by analyzing a non-trivial class of allocation problems.	decision problem	Arianna Alfieri;Steef L. van de Velde;Gerhard J. Woeginger	2007	European Journal of Operational Research	10.1016/j.ejor.2005.11.065	time complexity;mathematical optimization;operations management;cutting stock problem;mathematics;cutting;algorithm	Theory	17.991732222867324	11.362662505945012	142658
2aaf49ecbbbab03e12593d681712573d771a3af8	genetic algorithms in integrated process planning and scheduling	process capability;multi objective genetic algorithm;cost of production;weighted sums;genetic algorithm;process planning;pareto optimality	Process planning and scheduling are actually interrelated and should be solved simultaneously. Most integrated process planning and scheduling methods only consider the time aspects of the alternative machines when constructing schedules. The initial part of this paper describes a genetic algorithm (GA) based algorithm that only considers the time aspect of the alternative machines. The scope of consideration is then further extended to include the processing capabilities of alternative machines, with different tolerance limits and processing costs. In the proposed method based on GAs, the processing capabilities of the machines, including processing costs as well as number of rejects produced in alternative machine are considered simultaneously with the scheduling of jobs. The formulation is based on multi-objective weighted-sums optimization, which are to minimize makespan, to minimize total rejects produced and to minimize the total cost of production. A comparison is done w ith the traditional sequential method and the multi-objective genetic algorithm (MOGA) approach, based on the Pareto optimal concept.	automated planning and scheduling;genetic algorithm;scheduling (computing)	Norhashimah Morad;Ams Zalzala	1999	J. Intelligent Manufacturing	10.1023/A:1008976720878	mathematical optimization;genetic algorithm;process capability;computer science;genetic algorithm scheduling;engineering drawing	Robotics	12.288196777501105	4.304213329732469	142734
0e9695a8d7254cf6e5802509f29f64a9b706de8e	on handling cutting planes in interior-point methods for solving semi-definite relaxations of binary quadratic optimization problems	maximum cut;interior point algorithms;cutting plane;interior point;combinatorial optimization problem;cutting plane methods;semi definite program;warm starts;quadratic optimization;facility layout;combinatorial optimization;interior point method;interior point algorithm;cutting plane method;semi definite programming	On handling cutting planes in interiorpoint methods for solving semidefinite relaxations of binary quadratic optimization problems Alexander Engau a , Miguel F. Anjos b c & Anthony Vannelli d a Department of Mathematical and Statistical Sciences , University of Colorado Denver , Campus Box 170, PO Box 173364, Denver , CO , 80217-3364 , USA b Département de Mathématiques et Génie Industriel , École Polytechnique de Montréal , Montréal , Québec , Canada c GERAD , École Polytechnique de Montréal , Montréal , Québec , Canada d College of Engineering and Physical Science , University of Guelph , 50 East Stone Road, Guelph , Ontario , Canada , N1G 2W1 Published online: 21 Oct 2011.	algorithm;branch and bound;combinatorial optimization;computation;cutting-plane method;interior point method;iteration;mathematical optimization;maximum cut;nl-complete;newton;quadratic programming;semiconductor industry;slack variable;solver;time complexity	Alexander Engau;Miguel F. Anjos;Anthony Vannelli	2012	Optimization Methods and Software	10.1080/10556788.2010.544308	mathematical optimization;combinatorics;combinatorial optimization;interior point method;mathematics;geometry;cutting-plane method	ML	23.38133376153497	9.343763160401725	142767
7c500b0e4971b55ad7527464a99796acf0018c77	an interactive gramps algorithm for the heterogeneous fixed fleet vehicle routing problem with and without backhauls	cout variable;flotte;metodo adaptativo;variable cost;gramps;metaheuristics;backhauls;algoritmo busqueda;systeme aide decision;routing;vehicle routing problem;algorithme recherche;adaptive memory programming;heuristic method;visual interaction;search algorithm;routage;metodo heuristico;methode adaptative;probleme tournee vehicule;sistema ayuda decision;routing metaheuristics gramps heterogeneous fixed fleet backhauls;problema ruta vehiculo;satisfiability;flota;decision support system;metamodel;heterogeneous fixed fleet;metamodele;metamodelo;adaptive method;fleet;programmation interactive;aparato visual;appareil visuel;difference set;methode heuristique;visual system;interactive programming;enrutamiento	In this article, a visual interactive approach based on a new greedy randomised adaptive memory programming search (GRAMPS) algorithm is proposed to solve the heterogeneous fixed fleet vehicle routing problem (HFFVRP) and a new extension of the HFFVRP, which is called heterogeneous fixed fleet vehicle routing problem with backhauls (HFFVRPB). This problem involves two different sets of customers. Backhaul customers are pickup points and linehaul customers are delivery points that are to be serviced from a single depot by a heterogeneous fixed fleet of vehicles, each of which is restricted in the capacity it can carry, with different variable travelling costs. The proposed approach is implemented within a visual decision support system, which was developed to allow users to produce and judge alternative decisions by using their knowledge and experience about the requirements of the HFFVRP. The computational results are provided on classical problem instances for HFFVRP and a new best-known solution has been reported. A new set of problem instances for HFFVRPB is proposed. The results show that the proposed approach can find high quality solutions in very short time and the system is able to create alternative solutions in order to satisfy the user's expectations.	algorithm;backhaul (telecommunications);gramps;vehicle routing problem	G. Yazgi Tütüncü	2010	European Journal of Operational Research	10.1016/j.ejor.2009.03.044	metamodeling;variable cost;mathematical optimization;routing;simulation;visual system;decision support system;computer science;operations management;vehicle routing problem;mathematics;difference set;satisfiability;search algorithm	Theory	19.05889675527443	5.590649579921602	142809
a4da3054d7d81d4396a1983b34650cd36d1c5211	a mathematical programming model for scheduling steelmaking-continuous casting production	iron and steel industries;continuous casting;machine conflict;iron;non linear model;mathematical programming;steelmaking continuous casting;steel industry;software package;linear programming;mathematical model;linear program;just in time;production scheduling;computer integrated manufacturing	This paper presents a mathematical model, based on the just-in-time (JIT) idea, for solving machine con ̄icts in steelmaking-continuous casting (SCC) production scheduling in the computer integrated manufacturing system (CIMS) environment. The model is developed as a non-linear model based on actual production situations, considering both punctual delivery and production operation continuity. It is then converted into a linear programming model which can be solved using standard software packages. An example demonstrating the application of the proposed method is given. The paper also describes the implementation of an SCC production scheduling system in which the proposed model is used as an eective method to optimize production continuity and product delivery while eliminating machine con ̄icts. Ó 2000 Elsevier Science B.V. All rights reserved.	computer-integrated manufacturing;just-in-time compilation;linear model;linear programming;mathematical model;mathematical optimization;naruto shippuden: clash of ninja revolution 3;nonlinear system;programming model;scheduling (computing);scott continuity	Lixin Tang;Jiyin Liu;Aiying Rong;Zihou Yang	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00041-7	mathematical optimization;linear programming;operations management;mathematical model;mathematics;scheduling;iron	Robotics	13.486859358592813	4.255217714881642	143222
dd13e2c8ba3f8e18730cf887eded4ffddbe8d146	a hypergraph separator based variable ordering heuristic for solving real world sat	boolean constraint propagation;look ahead;internal structure;backtrack search;search trees;tree decomposition;sat solver;binary tree	  Problem structure has been used to guide the variable ordering heuristic in backtracking search since [1]. Recent experimental  results show that guiding the variable ordering heuristic using tree decompositions can improve the performance of SAT and  CSP solvers. Huang and Darwiche’s [2] variable ordering heuristic uses a Dtree, a static binary tree decomposition, to compute  the variable group ordering. Since the Dtree has to be constructed before search, the pre-established variable groupings never  change during the execution of the solving. Boolean Constraint Propagation (BCP) is the look-ahead strategy for all of the  cutting-edge SAT solvers. Because long implication chains exist in real world instances and a large number of variables on  the implication chains can be instantiated after making a relatively small number of decisions, the internal structure of  real world instances often changes dramatically in different parts of the search tree.    	heuristic	Wei Li	2004		10.1007/978-3-540-30201-8_79	optimal binary search tree;red–black tree;mathematical optimization;combinatorics;discrete mathematics;binary tree;computer science;interval tree;mathematics;boolean satisfiability problem;ternary search tree;tree traversal;algorithm;tree decomposition	AI	13.781243393734142	16.246516456343397	143480
a35da4b524750f3b22b07635fc0397731bf5f7d6	adaptive lot/equipment matching strategy and ga based approach for optimized dispatching and scheduling in a wafer probe center	semiconductor device testing;optimal solution;genetic algorithm adaptive lot equipment matching strategy ga optimized dispatching optimized scheduling wafer probe center lot based selection scheme equipment based selection scheme pair generation mechanism auction algorithm;game theory;flow shop scheduling semiconductor device manufacture semiconductor device testing adaptive scheduling genetic algorithms petri nets optimised production technology dispatching lot sizing game theory dynamic scheduling;efficient algorithm;flow shop scheduling;dispatching probes job shop scheduling semiconductor device modeling petri nets genetic algorithms processor scheduling mathematical model testing scheduling algorithm;production process;time petri net;semiconductor device manufacture;mathematical model;adaptive scheduling;scheduling problem;lot sizing;genetic algorithm;genetic algorithms;petri nets;optimised production technology;dispatching;dynamic scheduling	In this paper, we use a graphical and mathematical modeling tool colored-timed Petri nets (CTPN) to model the testing flow in the wafer probe center. With this CTPN model, we can simulate the production processes, and keep track of the equipment status and the lot conditions efficiently and precisely. In the dispatching phase, we present the lot-based and the equipment-based selection schemes. Each of these two schemes has its own advantages, but also some drawbacks. Therefore, we propose a new approach pair generation mechanism and adaptive lot/equipment matching strategy, which can promise a dispatching strategy that can be more optimal in the sense that both lot-based and equipment-based viewpoints are taken into account simultaneously. In this paper, we further adopt an efficient algorithm auction algorithm to help us to find out the optimal solution to the internally generated lot/equipment matching problem. Besides, some adaptive factors are also applied. Lastly in the scheduling phase, we apply the genetic algorithm (GA) based approach to obtain a near-optimal solution to our scheduling problem. From our experiment results, the developed CTPN based genetic algorithm yields a more efficient solution than several other schedulers.	auction algorithm;embedded system;experiment;feasible region;genetic algorithm;heuristic;job shop scheduling;makespan;mathematical model;petri net;scheduling (computing);simulation;software release life cycle;the algorithm auction;wafer (electronics);xfig	Tsung-Che Chiang;Yi-Shiuan Shen;Li-Chen Fu	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307543	game theory;mathematical optimization;real-time computing;genetic algorithm;computer science	Robotics	12.043556694820834	5.424794590067411	143494
ef6ca6bec9a97c04fd259152ae9f5d548bd12be0	qos-aware multicommodity flows and transportation planning	transportation planning;multicommodity flow	We consider the QoS-aware Multicommodity Flow problem, a natural generalization of the weighted multicommodity flow problem where the demands and commodity values are elastic to the Quality-ofService characteristics of the underlying network. The problem is fundamental in transportation planning and also has important applications beyond the transportation domain. We provide a FPTAS for the QoSaware Multicommodity Flow problem by building upon a Lagrangian relaxation method and a recent FPTAS for the non-additive shortest path problem.	flow network;lagrangian relaxation;linear programming relaxation;polynomial-time approximation scheme;quality of service;relaxation (approximation);shortest path problem;utility functions on indivisible goods	George Tsaggouris;Christos D. Zaroliagis	2006				Theory	22.256529864317763	11.334688267246582	143510
6fdeb4517c4afa91aa04c23b6a38020b37fe044e	bi-criteria scheduling problems: number of tardy jobs and maximum weighted tardiness	optimal solution;metodo polinomial;empirical study;methode empirique;temps polynomial;machine unique;gestion production;metodo empirico;heuristic method;empirical method;problema np duro;metodo heuristico;date echeance;production management;processing time;polynomial time algorithm;np hard problem;single machine;maquina unica;probleme np difficile;polynomial method;scheduling;gestion produccion;retard;due date;polynomial time;scheduling problem;temps traitement;fecha vencimiento;maximum weighted tardiness;number of tardy jobs;heuristics;methode heuristique;np hard;methode polynomiale;retraso;tiempo proceso;ordonnancement;reglamento;tiempo polinomial	Consider a single machine and a set of jobs that are available for processing at time 0. Job has a processing time , a due date and a weight . We consider bi-criteria scheduling problems involving the maximum weighted tardiness and the number of tardy jobs. We give NPhardness proofs for the scheduling problems when either one of the two criteria is the primary criterion and the other one is the secondary criterion. These results answer two open questions posed by Lee and Vairaktarakis in 1993. We consider complexity relationships between the various problems, give polynomial-time algorithms for some special cases, and propose fast heuristics for the general case. The effectiveness of the heuristics is measured by empirical study. Our results show that one heuristic performs extremely well compared to optimal solutions.	algorithm;best, worst and average case;eisenstein's criterion;futures studies;heuristic (computer science);job stream;np-hardness;p (complexity);polynomial;pseudo-polynomial time;regular expression;scheduling (computing);single-machine scheduling;time complexity;trusted computer system evaluation criteria	Yumei Huo;Joseph Y.-T. Leung;Hairong Zhao	2007	European Journal of Operational Research	10.1016/j.ejor.2005.06.067	job shop scheduling;mathematical optimization;computer science;operations management;np-hard;mathematics;empirical research;algorithm	Theory	17.157424670934013	10.13996514536516	143512
68b679e632b85eaee58fd899764ee2d5811ec76d	optimal resource allocation for network protection against spreading processes	air transportation network optimal resource allocation network protection arbitrary directed network protection resource distribution network nodes preventive resources node defense vaccine viral infection process corrective resource spreading neutralization antidotes cost optimal resource distribution viral spreading process containment polynomial time geometric programming arbitrary directed graph nonidentical node cost function optimal protection strategy design epidemic outbreak;directed graphs;transportation computational complexity directed graphs epidemics geometric programming network theory graphs resource allocation;resource allocation;resource management cost function control systems vaccines eigenvalues and eigenfunctions linear approximation;computational complexity;transportation;network analysis and control biomedical systems markov processes;network theory graphs;epidemics;geometric programming	We study the problem of containing spreading processes in arbitrary directed networks by distributing protection resources throughout the nodes of the network. We consider that two types of protection resources are available: 1) preventive resources able to defend nodes against the spreading (such as vaccines in a viral infection process) and 2) corrective resources able to neutralize the spreading after it has reached a node (such as antidotes). We assume that both preventive and corrective resources have an associated cost and study the problem of finding the cost-optimal distribution of resources throughout the nodes of the network. We analyze these questions in the context of viral spreading processes in directed networks. We study the following two problems: 1) given a fixed budget, find the optimal allocation of preventive and corrective resources in the network to achieve the highest level of containment and 2) when a budget is not specified, find the minimum budget required to control the spreading process. We show that both the resource allocation problems can be solved in polynomial time using geometric programming (GP) for arbitrary directed graphs of nonidentical nodes and a wide class of cost functions. We illustrate our approach by designing optimal protection strategies to contain an epidemic outbreak that propagates through an air transportation network.	cost efficiency;directed graph;geometric programming;mathematical optimization;regular expression;time complexity	Victor M. Preciado;Michael Zargham;Chinwendu Enyioha;Ali Jadbabaie;George J. Pappas	2014	IEEE Transactions on Control of Network Systems	10.1109/TCNS.2014.2310911	transport;mathematical optimization;simulation;geometric programming;directed graph;resource allocation;computer science;mathematics;computational complexity theory;algorithm	Metrics	11.57555499605595	8.509934525906498	143680
8bd4b275ec5e9f277a2c300343586d1c6b75efa0	simulation-based scheduling for parcel consolidation terminals: a comparison of iterative improvement and simulated annealing	postal services;scheduling;simulated annealing;feeder trailers;iterative improvement;parcel consolidation terminals;simulated annealing;simulation-based scheduling;unload scheduling	This research explores the application of a simulation-based scheduling algorithm to generate unload schedules for processing feeder trailers in a parcel consolidation terminal. The study compares the performance of iterative improvement and simulated annealing to produce quality schedules. The paper reports the results from a number of experimental test problems.	algorithm;iterative method;schedule (computer science);scheduling (computing);semiconductor consolidation;simulated annealing;simulation;turing test	Douglas L. McWilliams	2005	Proceedings of the Winter Simulation Conference, 2005.		fair-share scheduling;real-time computing;simulation;flow shop scheduling;computer science;engineering;scheduling	HPC	13.984347529583804	4.55269388700871	143832
00c33f2b4e79d5ace20c98683a8dfda7d81f9e96	algorithms for a realistic variant of flowshop scheduling	minimisation;dispatching rules;minimization;tiempo iniciacion;optimisation;tiempo total acabamiento;analisis estadistico;probleme livraison;optimizacion;dynamic dispatching rule heuristic;machine unique;iterated local search;heuristic method;atelier flexible;machine parallele;competitive algorithms;temps total achevement;metodo heuristico;minimizacion;maquina paralelas;temps mise en route;busca local;algorithme competitif;single machine;maquina unica;setup time;metamodel;makespan;statistical analysis;iterated local search metaheuristic;metamodele;flexible manufacturing system;metamodelo;scheduling;hybrid flexible flowshops;analyse statistique;dispatching problem;parallel machines;sistema flexible produccion;optimization;methode heuristique;sequence dependent setup times;atelier monogamme;high performance;local search;ordonnancement;recherche locale;flow shop;reglamento;problema reparto	This paper deals with a realistic variant of flowshop scheduling, namely the hybrid flexible flowshop. A hybrid flowshop mixes the characteristics of regular flowshops and parallel machine problems by considering stages with parallel machines instead of having one single machine per stage. We also investigate the flexible version where stage skipping might occur, i.e., not all stages must be visited by all jobs. Lastly, we also consider job sequence dependent setup times per stage. The optimization criterion considered is makespan minimization. The literature is plenty with approaches for hybrid flowshops. However, hybrid flexible flowshops have been seldom studied. The situation is even worse with the addition of sequence dependent setups. In this study, we propose two advanced algorithms that specifically deal with the flexible and setup characteristics of this problem. The first algorithm is a dynamic dispatching rule heuristic, and the second is an iterated local search metaheuristic. The proposed algorithms are evaluated by comparison against seven other high performing existing algorithms. The statistically sound results support the idea that the proposed algorithms are very competitive for the studied problem.	algorithm;analysis of algorithms;convex optimization;heuristic;heuristic (computer science);iterated local search;iteration;job stream;line code;local search (optimization);makespan;mathematical optimization;metaheuristic;parallel computing;scheduling (computing)	B. Naderi;Rubén Ruiz;Mostafa Zandieh	2010	Computers & OR	10.1016/j.cor.2009.04.017	metamodeling;job shop scheduling;minimisation;mathematical optimization;flow shop scheduling;computer science;local search;iterated local search;mathematics;scheduling	AI	19.65101937603277	6.417884436482322	143999
8c410d5d68c4b0b2fc2d32186c64932b634907ae	two-stage flow-open shop scheduling problem to minimize makespan		This paper investigates a novel shop scheduling model, in which each job is processed first in a flow shop and then in an open shop. The objective is to optimize the maximum completion time, i.e. makespan. For large-scale problems, the asymptotic optimality of the dense scheduling (DS) algorithm is proven in the sense of probability limit. Furthermore, a DS-based heuristic algorithm is presented to obtain approximate solution. For moderate-scale problems, a discrete differential evolution algorithm is provided to achieve high-quality solutions. A series of random simulations are executed to demonstrate the effectiveness of the proposed algorithms.	makespan;open-shop scheduling;scheduling (computing)	Tao Ren;Bingqian Liu;Peng Zhao;Huawei Yuan;Haiyan Li;Danyu Bai	2016		10.1007/978-3-319-42291-6_53	job shop scheduling;johnson's rule;flow shop scheduling;dynamic priority scheduling	AI	15.645466573468394	8.889159480070383	144028
8ab45a6620e0b1b9945a232cb9bad11e019ed61e	tight lower bounds on envy-free makespan approximation	makespan approximation;locally efficient;scheduling;mechanism design;envy freeness	In this work we give a tight lower bound on makespan approximations for envy-free allocation mechanism dedicated to scheduling tasks on unrelated machines. Specifically, we show that no mechanism exists that can guarantee an envy-free allocation of jobs to m machines with a makespan of less than a factor of O(logm) of the minimal makespan. Combined with previous results, this paper definitively proves that the optimal algorithm for obtaining a minimal makespan for any envy-free division can at best approximate the makespan to a factor of O(logm).	approximation algorithm;makespan;scheduling (computing)	Amos Fiat;Ariel Levavi	2012		10.1007/978-3-642-35311-6_46	mechanism design;mathematical optimization;johnson's rule;economics;computer science;mathematics;distributed computing;mathematical economics;scheduling	ECom	14.919453839856702	11.599052347626705	144225
697c386326366317e5eb285845972c005bc789e4	an exact solution search for the max-min multiple knapsack problem	cplex solver exact solution search max min multiple knapsack problem knapsack profit aggressive fixation optimality surrogate relaxation;surrogate knapsack optimality optimization reduction;minimax techniques knapsack problems;runtime upper bound search problems indexes optimization generators electronic mail	In this paper, we propose to solve the max-min multiple knapsack problem by using an exact solution search. An instance of the problem is defined by a set of n items to be packed into m knapsacks as to maximize the minimum of the knapsacks' profits. The proposed method uses a series of interval searches, where each interval is bounded with a target value (considered as a lower bound) and an estimated upper bound. The target lower bound is computed by applying some aggressive fixation of some items to optimality whereas the upper bound is computed by using a surrogate relaxation. The performance of the proposed method is evaluated on a set of instances containing a variety of sizes. Computational results showed the superiority of the proposed method when comparing its provided results to those obtained by the Cplex solver and one of the best exact method available in the literature.	cplex;computation;exact algorithm;interval arithmetic;knapsack problem;lagrangian relaxation;linear programming relaxation;maxima and minima;solver;successive over-relaxation	Ferhan Al-Maliky;Mhand Hifi;Hedi M'Halla	2014	2014 International Conference on Control, Decision and Information Technologies (CoDIT)	10.1109/CoDIT.2014.6996879	continuous knapsack problem;mathematical optimization;combinatorics;discrete mathematics;polynomial-time approximation scheme;cutting stock problem;change-making problem;mathematics;knapsack problem	Robotics	20.150861226099998	10.026602871407713	144347
5e16e98074048f73a0db2b25669a8fbdb69048ba	how do you know your search algorithm and code are correct?	debugging;testing;correctness	Algorithm design and implementation are notoriously error-prone. As researchers, it is incumbent upon us to maximize the probability that our algorithms, their implementations, and the results we report are correct. In this position paper, I argue that the main technique for doing this is confirmation of results from multiple independent sources, and provide a number of concrete suggestions for how to achieve this in the context of combinatorial search algorithms. Introduction and Overview Combinatorial search results can be theoretical or experimental. Theoretical results often consist of correctness, completeness, the quality of solutions returned, and asymptotic time and space complexities. Experimental results typically consist of the number and quality of the solutions returned, the number of nodes generated, and the running time of the algorithm. In the remainder of this paper, we first consider the role of proofs in verifying results, then the issues of solution correctness, both optimal and sub-optimal solution quality, nodes generated, and finally running time.	algorithm design;cognitive dimensions of notations;combinatorial search;correctness (computer science);optimization problem;search algorithm;time complexity;verification and validation	Richard E. Korf	2014				AI	10.550960286664255	18.129160684311657	144445
e92c95fa5d35895bfaa2b48b8ad629a4dec0a584	comparative analysis of scheduling rules through arena for parallel machines	dispatching rules scheduling set of parallel processors queue makespan arena simulation;scheduling knowledge based systems production engineering computing resource allocation;optimization;program processors;program processors optimization dispatching;dispatching;production scheduling rules arena dynamic system complex system real production system environment weighted sum longest processing time rule shortest processing time rule shortest queue rule parallel processors utilization level makespan value parallel machine scheduling	This study aims to determinate which scheduling rule should be applied, for minimizing the makespan value, and maximizing the utilization level of a production system, which includes a set of three parallel processors, each one integrating five machines, by using a simulation approach based on Arena. A first simulation was done under random conditions, not attending to any kind of rule, and after some dispatching rules were applied, namely the shortest queue rule; the shortest processing time rule; the longest processing time rule; and combination of rules through a weighted sum about completion times and the work in process. A comparative analysis about the application of these rules is carried out in this paper. The rules that have been applied to achieve the goals were selected taking into account not only the problem to be studied, but also different conditions present in a real production system environment. The problem consists on a complex and dynamic system, where each job has the same priority and different processing times, without preemption.	central processing unit;dynamical system;environment variable;expectation–maximization algorithm;makespan;preemption (computing);production system (computer science);programming tool;property (philosophy);qualitative comparative analysis;scheduling (computing);simulation;weight function	Filipa de Oliveira Teixeira;Lara Oliveira;Leonilde R. Varela	2014	2014 Sixth World Congress on Nature and Biologically Inspired Computing (NaBIC 2014)	10.1109/NaBIC.2014.6921873	mathematical optimization;parallel computing;real-time computing;computer science;distributed computing	DB	12.250796341666172	6.694079316621279	144475
137cfb92fd4a9376396d4457d68d06675900ee57	an iterated greedy heuristic for no-wait flow shops with sequence dependent setup times, learning and forgetting effects		Abstract This paper addresses a sequence dependent setup times no-wait flowshop with learning and forgetting effects to minimize total flowtime. This problem is NP-hard and has never been considered before. A position-based learning and forgetting effects model is constructed. Processing times of operations change with the positions of corresponding jobs in a schedule. Objective increment properties are deduced and based on them three accelerated neighbourhood construction heuristics are presented. Because of the simplicity and excellent performance shown in flowshop scheduling problems, an iterated greedy heuristic is proposed. The proposed iterated greedy algorithm is compared with some existing algorithms for related problems on benchmark instances. Comprehensive computational and statistical tests show that the presented method obtains the best performance among the compared methods.	greedy algorithm;heuristic;iteration	Xiaoping Li;Zhi Yang;Rubén Ruiz;Tian Chen;Shaochun Sui	2018	Inf. Sci.	10.1016/j.ins.2018.04.038	machine learning;artificial intelligence;iterated function;statistical hypothesis testing;algorithm;flow (psychology);scheduling (computing);mathematics;sequence-dependent setup;forgetting;heuristics;greedy algorithm	AI	16.237959322774813	7.71078753368621	144638
00873f2a678261f370d1b1681144b47d92bbdb92	a list based threshold accepting metaheuristic for the heterogeneous fixed fleet vehicle routing problem	distribution;flotte;forecasting;reliability;threshold accepting;project management;information systems;logistique;maintenance;vehicle routing problem;soft or;information technology;heuristic method;packing;vehicle routing;metodo heuristico;probleme tournee vehicule;problema ruta vehiculo;operations research;location;investment;journal;journal of the operational research society;inventory;purchasing;history of or;logistics;mathematical programming;heterogeneidad;marketing;scheduling;fleet;production;communications technology;heuristics;methode heuristique;computer science;operational research;programmation mathematique;programacion matematica;applications of operational research;or society;heterogeneity;jors;management science;heterogeneite;infrastructure;logistica	In real life situations most companies that deliver or collect goods own a heterogeneous fleet of vehicles. Their goal is to find a set of vehicle routes, each starting and ending at a depot, making the best possible use of the given vehicle fleet such that total cost is minimized. The specific problem can be formulated as the Heterogeneous Fixed Fleet Vehicle Routing Problem (HFFVRP), which is a variant of the classical Vehicle Routing Problem. This paper describes a variant of the threshold accepting heuristic for the HFFVRP. The proposed metaheuristic has a remarkably simple structure, it is lean and parsimonious and it produces high quality solutions over a set of published benchmark instances. Improvement over several of previous best solutions also demonstrates the capabilities of the method and is encouraging for further research. Journal of the Operational Research Society (2003) 54, 65–71. doi:10.1057=palgrave.jors.2601443	benchmark (computing);display resolution;heuristic;metaheuristic;occam's razor;real life;vehicle routing problem	Christos D. Tarantilis;Chris T. Kiranoudis;Vassilios S. Vassiliadis	2003	JORS	10.1057/palgrave.jors.2601443	distribution;logistics;simulation;inventory;economics;forecasting;investment;marketing;operations management;heterogeneity;heuristics;vehicle routing problem;reliability;mathematics;location;management;operations research;scheduling	Robotics	18.163843262907804	5.165790580932458	144994
f64d35f0fe7ba2725a4e1c866c68b7e2cf008f9b	constraint satisfaction over generalized staircase constraints		One of the key research interests in the area of Constraint Satisfaction Problem (CSP) is to identify tractable classes of constraints and develop efficient solutions for them. In this paper, we introduce generalized staircase (GS) constraints which is an important generalization of one such tractable class found in the literature, namely, staircase constraints. GS constraints are of two kinds, down staircase (DS) and up staircase (US). We first examine several properties of GS constraints, and then show that arc consistency is sufficient to determine a solution to a CSP over DS constraints. Further, we propose an optimal O(cd) time and space algorithm to compute arc consistency for GS constraints where c is the number of constraints and d is the size of the largest domain. Next, observing that arc consistency is not necessary for solving a DSCSP, we propose a more efficient algorithm for solving it. With regard to US constraints, arc consistency is not known to be sufficient to determine a solution, and therefore, methods such as path consistency or variable elimination are required. Since arc consistency acts as a subroutine for these existing methods, replacing it by our optimal O(cd) arc consistency algorithm produces a more efficient method for solving a USCSP.	algorithm;cobham's thesis;constraint logic programming;constraint satisfaction problem;cyclic redundancy check;local consistency;picross ds;real life;roland gs;solver;subroutine;variable elimination	Shubhadip Mitra;Partha Dutta;Arnab Bhattacharya	2013	CoRR		mathematical optimization;combinatorics;discrete mathematics;mathematics;constraint;local consistency	AI	24.350473677595293	11.149774255400892	144995
5a40f7998924144a47c87651ffa7cab12ed63809	lower-bounded facility location	optimal solution;location problem;approximate algorithm;approximation algorithm;real time;capacitated facility location problem;suffix tree;objective function;quasi real time;pattern matching;facility location problem;uncapacitated facility location problem;lower bound;facility location	We study the lower-bounded facility location problem which generalizes the classical uncapacitated facility location problem in that it comes with lower bound constraints for the number of clients assigned to a facility in the case that this facility is opened. This problem was introduced independently in the papers by Karger and Minkoff [2000] and by Guha et al. [2000], both of which give bicriteria approximation algorithms for it. These bicriteria algorithms come within a constant factor of the optimal solution cost, but they also violate the lower bound constraints by a constant factor. Our result in this article is the first true approximation algorithm for the lower-bounded facility location problem which respects the lower bound constraints and achieves a constant approximation ratio for the objective function. The main technical idea for the design of the algorithm is a reduction to the capacitated facility location problem, which has known constant-factor approximation algorithms.	apx;approximation algorithm;facility location problem;loss function;optimization problem	Zoya Svitkina	2010	ACM Trans. Algorithms	10.1145/1824777.1824789	mathematical optimization;combinatorics;computer science;facility location problem;mathematics;1-center problem;approximation algorithm	Theory	21.42773409659925	14.248954979867742	145146
3c3bb3e4d1f97ad810181ae98944aeac5df67b70	fuzzy flexible-flow shops at two machine centers	johnson algorithm;fuzzy set;flexible flow shop;scheduling;lpt;membership function			Tzung-Pei Hong;Wei-Chou Chen	1998	JACIII	10.20965/jaciii.1998.p0142	mathematical optimization;flow shop scheduling;membership function;computer science;artificial intelligence;machine learning;parallel port;fuzzy set;scheduling;fuzzy set operations	NLP	13.063915161333185	6.213970289284808	145218
3e4c1edbb5fa53a5ec159ada914a3ca8e63df5b2	an optimization approach for communal home meal delivery service: a case study	analisis numerico;computacion informatica;matematicas aplicadas;mathematiques appliquees;routing;travelling salesman problem;65kxx;time window;routage;vehicle routing;optimization method;metodo optimizacion;analyse numerique;experimental result;problema viajante comercio;49xx;numerical analysis;home delivery;estudio caso;mathematical programming;probleme commis voyageur;ciencias basicas y experimentales;vehicle routing problem with time windows;matematicas;transportation;methode optimisation;resultado experimental;etude cas;heuristics;58a25;resultat experimental;grupo a;applied mathematics;programmation mathematique;off the shelf;programacion matematica;enrutamiento	This paper is the first to discuss the communal home meal delivery problem. The problem can be modelled as a multiple travelling salesman problem with time windows, that is closely related to the well-studied vehicle routing problem with time windows. Experimental results are reported for a real-life case study from Central Finland over several alternative scenarios using the SPIDER commercial solver. The comparison with current practice reveals that a significant savings potential can be obtained using off-theshelf optimization tools. As such, the potential for supporting real-life communal routing problems can be considered to be important for VRP practitioners. © 2008 Elsevier B.V. All rights reserved.	decision support system;heuristic;mathematical optimization;microsoft windows;optimization problem;outsourcing;real life;solver;travelling salesman problem;vehicle routing problem;whole earth 'lectronic link	Olli Bräysy;Pentti Nakari;Wout Dullaert;Pekka Neittaanmäki	2009	J. Computational Applied Mathematics	10.1016/j.cam.2008.10.038	transport;mathematical optimization;routing;numerical analysis;heuristics;vehicle routing problem;mathematics;travelling salesman problem	AI	18.285709055679625	5.363212754358722	145238
c8360bb9a26cace30975d914554c1a814aebf7cd	exact algorithms for the clustered vehicle routing problem	clusters;vehicle routing;grupo de excelencia;qa75 electronic computers computer science;ciencias basicas y experimentales;matematicas;branch and cut;grupo a	Authors are encouraged to submit new papers to INFORMS journals by means of a style file template, which includes the journal title. However, use of a template does not certify that the paper has been accepted for publication in the named journal. INFORMS journal templates are for the exclusive purpose of submitting to an INFORMS journal and should not be used to distribute the papers in print or online or to submit the papers to another publication.	algorithm;computation;garbage collection (computer science);graph reduction;heuristic (computer science);institute for operations research and the management sciences;integer programming;metaheuristic;preprocessor;vehicle routing problem	Maria Battarra;Günes Erdogan;Daniele Vigo	2014	Operations Research	10.1287/opre.2013.1227	mathematical optimization;simulation;computer science;operations management;vehicle routing problem;mathematics;algorithm;branch and cut	Theory	22.061259878711187	8.930255651994123	145432
bf08763dc7912adb248cb103de519844bf17d7ab	online primal-dual algorithms with configuration linear programs		In this paper, we present primal-dual approaches based on configuration linear programs to design competitive online algorithms for problems with arbitrarily-grown objective. Non-linear, especially convex, objective functions have been extensively studied in recent years in which approaches relies crucially on the convexity property of cost functions. Besides, configuration linear programs have been considered typically in offline setting and the main approaches are rounding schemes. In our framework, we consider configuration linear programs coupled with a primal-dual approach. This approach is particularly appropriate for non-linear (non-convex) objectives in online setting. By the approach, we first present a simple greedy algorithm for a general cost-minimization problem. The competitive ratio of the algorithm is characterized by the mean of a notion, called smoothness, which is inspired by a similar concept in the context of algorithmic game theory. The algorithm gives optimal (up to a constant factor) competitive ratios while applying to different contexts such as network routing, vector scheduling, energyefficient scheduling and non-convex facility location. Next, we consider the online 0 − 1 covering problems with non-convex objective. Building upon the resilient ideas from the primal-dual framework with configuration LPs, we derive a competitive algorithm for these problems. Our result generalizes the online primal-dual algorithm developed recently by Azar et al. [8] for convex objectives with monotone gradients to non-convex objectives. The competitive ratio is now characterized by a new concept, called local smoothness — a notion inspired by the smoothness. Our algorithm yields tight competitive ratio for the objectives such as the sum of lk-norms and gives competitive solutions for online problems of submodular minimization and some natural non-convex minimization under covering constraints. ∗Research supported by the ANR project OATA n ANR-15-CE40-0015-01	algorithmic game theory;ambiguous name resolution;competitive analysis (online algorithm);convex function;convex optimization;covering problems;diffusing update algorithm;gradient;greedy algorithm;linear programming;nonlinear gameplay;nonlinear system;online algorithm;online and offline;rounding;routing;scheduling (computing);submodular set function;monotone	Nguyen Kim Thang	2017	CoRR		algorithmic game theory;combinatorics;mathematics;discrete mathematics;competitive analysis;online algorithm;submodular set function;covering problems;smoothness;algorithm;mathematical optimization;facility location problem;greedy algorithm	Theory	20.79250873961058	16.32696851914274	145434
4d83babd61009b8c93ef3f0c90eafd48d39f9b7c	design of dynamic algorithms via primal-dual method	settore ing inf 05 sistemi di elaborazione delle informazioni	In this paper, we develop a dynamic version of the primaldual method for optimization problems, and apply it to obtain the following results. (1) For the dynamic set-cover problem, we maintain an O(f)-approximately optimal solution in O(f · log(m + n)) amortized update time, where f is the maximum “frequency” of an element, n is the number of sets, and m is the maximum number of elements in the universe at any point in time. (2) For the dynamic b-matching problem, we maintain an O(1)-approximately optimal solution in O(log n) amortized update time, where n is the number of nodes in the graph.	algorithm;amortized analysis;dynamic problem (algorithms);mathematical optimization;set cover problem	Sayan Bhattacharya;Monika Henzinger;Giuseppe F. Italiano	2015		10.1007/978-3-662-47672-7_17	mathematical optimization;computer science;calculus;mathematics;algorithm	Theory	19.001412613122245	13.648925674227664	145632
922c1d2ca911bd161eefa2bdf4171b3f7233e1ae	fms jobshop scheduling using lagrangian relaxation method	optimisation;flexible manufacturing systems;operations research;operations research flexible manufacturing systems production control relaxation theory optimisation;objective function;production control fms jobshop scheduling lagrangian relaxation objective function minimum weighted flow time one machine multi operation problems flexible manufacturing system;production control;flexible manufacturing systems lagrangian functions relaxation methods optimal scheduling job shop scheduling processor scheduling routing cost function gaussian processes testing;precedence constraint;scheduling problem;lagrangian method;relaxation theory;lagrangian relaxation	This paper tackles a FMS jobshop scheduling problem with alternative routings. The objective function is to minimize the weighted flow time of jobs. We use Lagrangian relaxation method to relax the precedence constraints and propose a two-stage approach to solve the decomposed one-machine multi-operation problems. Three examples are tested and the computational results are compared to the Lagrangian relaxation method proposed by Hoitomt (1993). The comparison studies show that with the minimum weighted flow time of jobs as the objective of the scheduling problem the method proposed in this paper yields better solution with less computational time than the existing Lagrangian method.	lagrangian relaxation;relaxation (approximation);relaxation (iterative method);scheduling (computing)	Jinyan Meng;Yeng Chai Soh;Youyi Wang	1995		10.1109/ROBOT.1995.525331	fair-share scheduling;job shop scheduling;mathematical optimization;real-time computing;flow shop scheduling;lagrangian relaxation;dynamic priority scheduling;computer science;mathematics	NLP	16.311834434347873	8.180478532796675	145682
abb8d9e2826d48846596614d2522236a7cb19e5d	an efficient partition based method for exact set similarity joins		We study the exact set similarity join problem, which, given two collections of sets, finds out all the similar set pairs from the collections. Existing methods generally utilize the prefix filter based framework. They generate a prefix for each set and prune all the pairs whose prefixes are disjoint. However the pruning power is limited, because if two dissimilar sets share a common element in their prefixes, they cannot be pruned. To address this problem, we propose a partitionbased framework. We design a partition scheme to partition the sets into several subsets and guarantee that two sets are similar only if they share a common subset. To improve the pruning power, we propose a mixture of the subsets and their 1-deletion neighborhoods (the subset of a set by eliminating one element). As there are multiple allocation strategies to generate the mixture, we evaluate different allocations and design a dynamic-programming algorithm to select the optimal one. However the time complexity of generating the optimal one is O(s) for a set with size s. To speed up the allocation selection, we develop a greedy algorithm with an approximation ratio of 2. To further reduce the complexity, we design an adaptive grouping mechanism, and the two techniques can reduce the complexity to O(s log s). Experimental results on three real-world datasets show our method achieves high performance and outperforms stateof-the-art methods by 2-5 times.	approximation algorithm;dynamic programming;experiment;greedy algorithm;inverted index;netbsd gzip / freebsd gzip;scheme;speedup;time complexity;work breakdown structure	Dong Deng;Guoliang Li;He Wen;Jianhua Feng	2015	PVLDB	10.14778/2856318.2856330	combinatorics;discrete mathematics;partition refinement;theoretical computer science;mathematics	DB	20.34249059694442	9.379924789054956	145716
002fbbc1edd8673b890a6cdb68e0bb5c0323b117	a (2+epsilon)-approximation algorithm for the generalized preemptive open shop problem with minsum objective	problem;approximate algorithm;peso;temps polynomial;approximation numerique;approximation algorithm;objective minsum;time;result;probleme;fonction objectif;aproximacion numerica;objective function;atelier multigamme;open shop;programacion lineal;weight;temps;scheduling;poids;complecion;algoritmo aproximacion;polynomial time;linear programming;programmation lineaire;resultado;funcion objetivo;job shop;ordonamiento;resultat;numerical approximation;problema;algorithme approximation;completion;minsum objective;ordonnancement;tiempo;tiempo polinomial	In this paper we consider a generalized version of the classical preemptive open shop problem with sum of weighted job completion times objective. The main result is a (2 + e)- approximation algorithm for this problem. In the last section we also discuss the possibility of improving our algorithm.	algorithm;open-shop scheduling	Maurice Queyranne;Maxim Sviridenko	2002	J. Algorithms	10.1016/S0196-6774(02)00251-1	time complexity;mathematical optimization;completion;linear programming;calculus;mathematics;scheduling;weight;approximation algorithm;algorithm	Theory	17.394241884119584	10.390564314573133	145911
7eac97245a0f0496a22a42c45464ed2657215f3c	a branch and bound algorithm of the single machine schedule with sequence dependent setup times for minimizing total tardiness	matematicas aplicadas;algorithm performance;single machine scheduling;mathematiques appliquees;lower and upper bound;machine unique;methode comparaison;branch and bound algorithm;competitive algorithms;sequence dependent setup;problema np duro;single machine schedule;operations research;journal;permutation;np hard problem;algorithme competitif;branch and bound method;single machine;maquina unica;setup time;metodo branch and bound;computer experiment;probleme np difficile;recherche operationnelle;resultado algoritmo;scheduling;permutacion;performance algorithme;total tardiness;methode separation et evaluation;applied mathematics;branch and bound;investigacion operacional;ordonnancement;reglamento	This paper addresses the NP-hard problem of scheduling N jobs on a single machine with due dates, sequence-dependent setup times, and no preemption where the objective is to minimize the total tardiness. This problem has previously been treated by Rubin and Ragatz [P.A. Rubin, G.L. Ragatz, Scheduling in a sequence dependent setup environment with generic search, Computers and Operations Research 22 (1) (1995) 85-99], Ragatz [G.L. Ragatz, A branch-and-bound method for minimum tardiness sequencing on a single processor with sequence dependent setup times, in: Proceedings: twenty-fourth annual meeting of the Decision Sciences Institute, 1993, pp. 1375-1377] and Tan et al. [K.C. Tan, R. Narasinmhan, P.A. Rubin, G.L. Ragatz, A comparison of four methods for minimizing total tardiness on a single processor with sequence dependent setup times, Omega 28 (2000) 313-326]. An algorithm based on branch-and-bound permutation schemes is developed including the implementation of lower and upper bounding procedures, and dominance rules. Computational experiments demonstrate the effectiveness of the algorithm. A comparison with Ragatz's B&B approaches indicates that the algorithm that we describe is competitive and has a certain advantage for larger problems.	algorithm;branch and bound	Xiaochuan Luo;Feng Chu	2006	Applied Mathematics and Computation	10.1016/j.amc.2006.05.127	mathematical optimization;computer science;mathematics;branch and bound;algorithm	Theory	16.917591385622394	9.176761175994065	145980
1dfd1bfdd5f14e5283f3d6748ebf98ec6b1f2a65	efficient represenation of discrete sets for constraint programming	optimisation sous contrainte;constrained optimization;programacion discreta;constraint satisfaction;optimizacion con restriccion;satisfaction contrainte;set constraint;finite domain;programmation discrete;crane;arbre avl;mathematical programming;grua socorro;constraint programming;contrainte ensembliste;constraint solving;satisfaccion restriccion;programmation mathematique;avl tree;programacion matematica;discrete programming;grue levage	In constraint solving for finite domains, efficient set representation is an important issue. In this paper we propose an enhancement of Erwig's diet representation called the enhanced diet, which represents a finite domain as an AVL tree of intervals. In addition to element insertion and deletion, we show that the domain splitting used for constraints such as X < Y can be done in O(log m) steps by adopting Crane's Algorithm, where m is the number of intervals, not the number of elements.	constraint programming	Shuji Ohnishi;Hiroaki Tasaka;Naoyuki Tamura	2003		10.1007/978-3-540-45193-8_79	mathematical optimization;constraint programming;constrained optimization;combinatorics;constraint satisfaction;computer science;mathematics;algorithm;avl tree	Robotics	22.930846506209733	11.942298141864827	146005
3bd1d5173105060bce0df47842003ee10c1faafb	a mazing 2+&epsiv; approximation for unsplittable flow on a path		We study the problem of unsplittable flow on a path (UFP), which arises naturally in many applications such as bandwidth allocation, job scheduling, and caching. Here we are given a path with nonnegative edge capacities and a set of tasks, which are characterized by a subpath, a demand, and a profit. The goal is to find the most profitable subset of tasks whose total demand does not violate the edge capacities. Not surprisingly, this problem has received a lot of attention in the research community.   If the demand of each task is at most a small-enough fraction Δ of the capacity along its subpath (Δ-small tasks), then it has been known for a long time [Chekuri et al., ICALP 2003] how to compute a solution of value arbitrarily close to the optimum via LP rounding. However, much remains unknown for the complementary case, that is, when the demand of each task is at least some fraction Δ > 0 of the smallest capacity of its subpath (Δ-large tasks). For this setting, a constant factor approximation is known, improving on an earlier logarithmic approximation [Bonsma et al., FOCS 2011].   In this article, we present a polynomial-time approximation scheme (PTAS) for Δ-large tasks, for any constant Δ > 0. Key to this result is a complex geometrically inspired dynamic program. Each task is represented as a segment underneath the capacity curve, and we identify a proper maze-like structure so that each corridor of the maze is crossed by only O(1) tasks in the optimal solution. The maze has a tree topology, which guides our dynamic program. Our result implies a 2+ϵ approximation for UFP, for any constant ϵ > 0, improving on the previously best 7+ϵ approximation by Bonsma et al. We remark that our improved approximation algorithm matches the best known approximation ratio for the considerably easier special case of uniform edge capacities.	approximation algorithm;icalp;job scheduler;ptas reduction;polynomial;polynomial-time approximation scheme;rounding;scheduling (computing);symposium on foundations of computer science;time complexity;tree network;word lists by frequency	Aris Anagnostopoulos;Fabrizio Grandoni;Stefano Leonardi;Andreas Wiese	2018	ACM Trans. Algorithms	10.1145/3242769		Theory	18.51366493532526	15.57863166008286	146162
be7e2393fe15dff6640474f385c605e68d5aeb99	an acyclic days-off scheduling problem	maximum flow;discrete tomography;polynomial time algorithm;scheduling problem	This paper studies the days off scheduling problem when the demand for staffing fluctuates from day to another and when the number of total workdays is fixed in advance for each employee. The scheduling problem is then to allocate rests to employees with different days off policies: (1) two or three consecutive days off for each employee per week and (2) at least three consecutive days off for each employee per month. For each one, we propose a polynomial time algorithm to construct a solution if it exists.	algorithm;directed acyclic graph;discrete tomography;maximum flow problem;p (complexity);polynomial;scheduling (computing);time complexity	Marie-Christine Costa;Fethi Jarray;Christophe Picouleau	2006	4OR	10.1007/s10288-005-0086-6	maximum flow problem;job shop scheduling;mathematical optimization;real-time computing;computer science;mathematics	ECom	14.764569312855738	9.337480567792337	146300
e358fec7d9894a0e87585dcb31c8f9c01de15d3e	an algorithm for project (job) sequencing with resource constraints	resource constraint	This paper treats the problem of project (or machine) scheduling with resource constraints to achieve minimum total duration time as a disjunctive graph. The prospective advantage of this approach is the elimination of the need to consider individual time periods over the program horizon; a feasibility check determines whether the resource constraints can be met by any particular network representation of the project. The paper gives an algorithm that uses partial enumeration for what is essentially a mixed integer program. The algorithm employs a maximum-flow computation as a check for feasibility with respect to available resources.	algorithm;job shop scheduling	Samuel Corenstein	1972	Operations Research	10.1287/opre.20.4.835	mathematical optimization;real-time computing;computer science;operations management;mathematics	HPC	14.838703362822397	7.013914977888984	146520
67effa8136b1b3aad7365e6a617cc2632e2bd0c7	the local-global conjecture for scheduling with non-linear cost	non linear cost function;single machine;pruning rules;scheduling;algorithm a	We consider the classical scheduling problem on a single machine, on which we need to schedule sequentially n given jobs. Every job j has a processing time pj and a priority weight wj , and for a given schedule a completion time Cj . In this paper we consider the problem of minimizing the objective value ∑ j wjC β j for some fixed constant β > 0. This non-linearity is motivated for example by the learning effect of a machine improving its efficiency over time, or by the speed scaling model. For β = 1, the well-known Smith’s rule that orders job in the non-increasing order of wj/pj give the optimum schedule. However, for β 6= 1, the complexity status of this problem is open. Among other things, a key issue here is that the ordering between a pair of jobs is not well-defined, and might depend on where the jobs lie in the schedule and also on the jobs between them. We investigate this question systematically and substantially generalize the previously known results in this direction. These results lead to interesting new dominance properties among schedules which lead to huge speed up in exact algorithms for the problem. An experimental study evaluates the impact of these properties on the exact algorithm A*.	a* search algorithm;exact algorithm;experiment;image scaling;job stream;nonlinear system;scheduling (computing);single-machine scheduling;time complexity;whole earth 'lectronic link	Nikhil Bansal;Christoph Dürr;Nguyen Kim Thang;Óscar C. Vásquez	2017	J. Scheduling	10.1007/s10951-015-0466-5	mathematical optimization;computer science;operating system;mathematics;scheduling;algorithm	Theory	15.407337127957515	11.038039952991422	146625
25b97af230c4d76f9a4bdb84ff6b27d03dbb3dc1	on solving multi-type railway line planning problems	railway transportation;rail traffic;trafic ferroviaire;programacion entera;rail transportation;on line;en linea;gestion trafic;traffic management;trafico ferroviario;programmation en nombres entiers;strategic planning;optimisation combinatoire;transporte ferroviaro;integer programming;gestion trafico;planification strategique;en ligne;integer program;combinatorial optimization;transport ferroviaire;combinatorial optimisation;planificacion estrategica;optimizacion combinatoria	An important strategic element in the planning process of a railway operator is the development of a line plan, i.e., a set of routes (paths) on the network of tracks, operated at a given hourly frequency. The models described in the literature have thus far considered only lines that halt at all stations along their route. In this paper we introduce several models for solving line planning problems in which lines can have different halting patterns. Correctness and equivalence proofs for these models are given, as well as an evaluation using several real-life instances.	branch and cut;computation;correctness (computer science);halting problem;integer programming;internetwork packet exchange;multi-commodity flow problem;polynomial;real life;time complexity;turing completeness	Jan-Willem Goossens;Stan P. M. van Hoesel;Leo G. Kroon	2006	European Journal of Operational Research	10.1016/j.ejor.2004.04.036	mathematical optimization;active traffic management;simulation;integer programming;strategic planning;combinatorial optimization;operations management;mathematics	AI	17.917265282670055	5.7676632230632645	146696
87ba27ded7ff899ea40930c9b16ef27aaf3b92f2	a note on the optimal makespan of a parallel machine scheduling problem	parallel machine scheduling;theoretical analysis;scheduling problem;parallel machines;correctness proof	For the parallel machine scheduling problem under consideration, the authors in two literatures of 1961 and 2002 respectively gave the proofs for the optimal makespan under Level Algorithm. But, some errors in their proofs are found by us with three counterexamples, and no one has given the correct proof until now. In this paper, a new algorithm is proposed. And the new algorithm is more convenient and easier for theoretical analysis than Level Algorithm does. Then, it is showed that the result schedule obtained by using the new algorithm is consistent with that by Level Algorithm in the sense that they can give the same result schedule. Finally, by using the proposed new algorithm, the proof for the optimal makespan is accomplished.	algorithm;clozure cl;combinatorial optimization;computational complexity theory;cyclic redundancy check;general instrument ay-3-8910;holographic principle;makespan;mathematics of operations research;michael garey;parallel computing;scheduling (computing);schmidt decomposition;shadow volume;springer (tank);time complexity	Yumei Li;Yundong Gu;Kaibiao Sun;Hongxing Li	2007		10.1007/978-3-540-71441-5_53	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;job shop scheduling;open-shop scheduling;mathematical optimization;parallel computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;theoretical computer science;two-level scheduling;distributed computing;lottery scheduling;round-robin scheduling;multiprocessor scheduling	Theory	18.576365850752648	11.250222594662777	146698
fbb580569c11c8f0800375d3d0190df9454ad743	sequence-dependent scheduling with order deliveries	total weighted completion time;meta heuristics;sequence dependent setup;satellite imaging scheduling;order delivery;article	This paper studies a sequence-dependent scheduling problem incorporating order delivery, motivated by satellite imaging scheduling. A set of jobs is to be processed on a single machine and each job belongs to a specific group. The completion time of a group is the moment when all jobs belonging to this group are completed. The problem is to determine a processing sequence of the jobs such that the sum of weighted completion times over all groups is minimized. We present a binary integer program to formulate the studied problem and then develop an O(n2) dynamic programming algorithm for determining optimal solutions. To produce approximate solutions within an acceptable time, we design a tabu search algorithm, an iterated local search algorithm and a genetic algorithm. Computational experiments are conducted to study the performance of the integer program and the solution algorithms. Numerical statistics suggest that the binary integer program can reach optimal solutions faster than the integer program existing in the literature, and the iterated local search algorithm outperforms other approaches when the number of jobs increases. 2013 Elsevier Inc. All rights reserved.	approximation algorithm;computation;dynamic programming;experiment;genetic algorithm;integer programming;iterated local search;iteration;job stream;linear programming;local search (optimization);scheduling (computing);search algorithm;tabu search	Bertrand M. T. Lin;Peng-Yeng Yin;Y. S. Liu	2013	Applied Mathematics and Computation	10.1016/j.amc.2013.06.087	mathematical optimization;mathematics;algorithm;metaheuristic	AI	16.67153656795477	8.184390792180606	146748
fa99499939cda53aac8b7e9007ddba82384d9759	optimal location of dwell points in a single loop agv system with time restrictions on vehicle availability	intervalo tiempo;tiempo respuesta;dynamic programming;metodo polinomial;optimisation;duracion trayecto;programacion dinamica;posicionamiento;sobrecarga;handling equipment;vehiculo guiado;matrice intervalle;travel time;temps polynomial;optimizacion;gestion production;operating problem;availability;disponibilidad;dynamic programming algorithm;localization;response time;temps minimal;shutdown;optimal location;dynamic program;localizacion;time interval;production management;temps reponse;polynomial time algorithm;control problem;parada;positioning;chariot sans conducteur;matriz intervalo;localisation;response function;transit time;guided vehicle;polynomial method;surcharge;materials handling;vehiculo automatizado;gestion produccion;vehicule guide;interval matrix;programmation dynamique;polynomial time;temps parcours;minimum time;problema explotacion;dwell points;optimization;materiel manutention;automated guided vehicle;funcion respuesta;algoritmo optimo;overload;methode polynomiale;instalaciones manipulacion;algorithme optimal;optimal algorithm;arret;tiempo recorrido;tiempo minimo;manufacturing system;disponibilite;dynamic programming automated guided vehicles dwell points;probleme exploitation;fonction reponse;positionnement;intervalle temps;tiempo polinomial;manutention materiau;duree trajet;automated guided vehicles	Since the workload of a manufacturing system changes over time, the material handling equipment used in the facility will be idle at certain time intervals to avoid system overload. In this context, a relevant control problem in operating an automated guided vehicle (AGV) system is where to locate idle vehicles. These locations, called dwell points, establish the response times for AVG requests. In this article, a dynamic programming algorithm to solve idle vehicle positioning problems in unidirectional single loop systems is developed to minimize the maximum response time considering restrictions on vehicle time available to travel and load/unload requests. This polynomial time algorithm finds optimal dwell points when all requests from a given pick-up station are handled by a single AGV. The proposed algorithm is used to study the change in maximum response time as a function of the number of vehicles in the system. 2007 Published by Elsevier B.V.	avg;algorithm;dynamic programming;material handling;p (complexity);polynomial;response time (technology)	José A. Ventura;Brian Q. Rieksts	2009	European Journal of Operational Research	10.1016/j.ejor.2007.09.014	mathematical optimization;real-time computing;simulation;computer science;operations management;dynamic programming;mathematics	Robotics	18.338945038869586	7.518779302624257	146780
0d6bd8302617e2af3d8b74b32c79e6462ae0007b	driving frequency selection for frequency domain simulation experiments	algorithme rapide;mixed programming;optimisation;factor screening;programacion entera;optimizacion;heuristic method;simulation;programmation entiere;simulacion;metodo heuristico;programmation mixte;operations research;simulation experiment;frequency domain methods;design of experiments;programacion lineal;programacion mixta;integer programming;methode domaine frequence;frequency domain method;fast algorithm;linear programming;programmation lineaire;optimization;technical report;methode heuristique;metodo dominio frecuencia;simulation design of experiments;frequency domain;algoritmo rapido;industrial engineering	Frequency domain methodology has been applied to discrete-event simulations to identify terms in a polynomial model of the simulation output. In this paper, the problem of optimally selecting input frequencies is studied. A fast algorithm is presented that closely approximates the optimal solution. The results obtained from the algorithm are compared to known optimal solutions. Tables of input frequencies for various experiments are presented in an appendix.	experiment;simulation	Sheldon H. Jacobson;Arnold H. Buss;Lee W. Schruben	1991	Operations Research	10.1287/opre.39.6.917	mathematical optimization;integer programming;computer science;linear programming;artificial intelligence;technical report;mathematics;design of experiments;frequency domain;algorithm	Robotics	19.027708235352154	7.307602988283878	146847
35f63d016f339e161aab2420f7a94d2eb03e1ff3	an enhanced tabu search algorithm to minimize a bi-criteria objective in batching and scheduling problems on unrelated-parallel machines with desired lower bounds on batch sizes	group scheduling;bi criteria;sequence and machine dependent setup time;batch scheduling;tabu search;unrelated parallel machines	This paper addresses a sequence- and machine-dependent batch scheduling problem on a set of unrelated-parallel machines where the objective is to minimize a linear combination of total weighted completion time and total weighted tardiness. In particular, batch scheduling disregards the group technology assumptions by allowing for the possibility of splitting pre-determined groups of jobs into batches with respect to desired lower bounds on batch sizes. With regard to bounds on batch sizes, the MILP model is developed as two integrated batching and scheduling phases to present the problem. A benchmark of small-size instances on group scheduling shows the superior performance of batch scheduling up to 37% reduction in the objective function value. An efficient meta-heuristic algorithm based on tabu search with multi-level diversification and multi-tabu structure is developed at three levels, which moves back and forth between batching and scheduling phases. To eliminate searching in ineffective neighborhoods and thus enhance computational efficiency of search algorithms, several lemmas are proposed and proven. The results of applying lemmas reflect up to 40% reduction in computational times. Comparing the optimal solutions found by CPLEX and tabu search shows that the tabu search algorithm could find solutions, at least as good as CPLEX but in incredibly shorter computational time. In order to trigger the search algorithm, two different initial solution finding mechanisms have been developed and implemented. Also, due to lack of a qualified benchmark for unrelated-parallel machines, a comprehensive data generation mechanism has been developed in a way that it fairly reflects the real world situations encountered in practice. The machine availability times and job release times are considered to be dynamic and the run time of each job differs on different machines based upon the capability of the machines.	scheduling (computing);search algorithm;tabu search	Omid Shahvari;Rasaratnam Logendran	2017	Computers & OR	10.1016/j.cor.2016.07.021	fair-share scheduling;mathematical optimization;real-time computing;flow shop scheduling;dynamic priority scheduling;tabu search;computer science;rate-monotonic scheduling;job scheduler	AI	15.714263962678883	7.425202195371083	147073
8e35680903457b55000aac2700d2c42e21c35411	improved algorithms for two single machine scheduling problems	metodo caso peor;tiempo total acabamiento;entrega;approximate algorithm;algorithmique;temps polynomial;single machine scheduling;machine unique;best approximation;maintenance;approximation algorithm;temps total achevement;worst case ratio;livraison;aproximacion polinomial;single machine;maquina unica;makespan;algorithmics;mathematical programming;algoritmica;informatique theorique;scheduling;approximation polynomiale;delivery;algoritmo aproximacion;polynomial time;methode cas pire;mantenimiento;mejor aproximacion;scheduling problem;delivery good;algorithme approximation;worst case method;programmation mathematique;programacion matematica;analyse cas pire;polynomial time approximation scheme;ordonnancement;reglamento;polynomial approximation;computer theory;tiempo polinomial;meilleure approximation;informatica teorica	In this paper, we investigate two single machine scheduling problems. The first problem addresses a class of the two-stage scheduling problems in which the first stage is job production and the second stage is job delivery. For the case that jobs are processed on a single machine and delivered by a single vehicle to one customer area, with the objective of minimizing the time when all jobs are completed and delivered to the customer area and the vehicle returns to the machine, an approximation algorithm with a worst-case ratio of 5/3 is known and no approximation can have a worst-case of 3/2 unless P = NP. We present an improved approximation algorithm with a worst-case ratio of 53/35, which only leaves a gap of 1/70. The second problem is a single machine scheduling problem subject to a period of maintenance. The objective is to minimize the total completion time. The best known approximation algorithm has a worst-case ratio of 20/17 We present a polynomial time approximation scheme.	algorithm;scheduling (computing);single-machine scheduling	Yong Jun He;Weiya Zhong;Huikun Gu	2006	Theor. Comput. Sci.	10.1016/j.tcs.2006.04.014	fair-share scheduling;time complexity;job shop scheduling;mathematical optimization;polynomial-time approximation scheme;dynamic priority scheduling;computer science;rate-monotonic scheduling;calculus;mathematics;scheduling;approximation algorithm;algorithm	Theory	17.10682009062264	10.26645342573281	147124
e60f6123562e5f9864e5567fc2af127d65700d5f	solving a multiobjective location routing problem with a metaheuristic based on tabu search. application to a real case in andalusia	starting;location problem;multiobjective programming;programmation multiobjectif;dechet solide;probleme localisation;solid waste;metaheuristics;routing;localization;heuristic method;elimination dechet;routage;maintenance cost;metodo heuristico;eliminacion residuo;waste disposal;localizacion;animal waste;lorry;equite;optimisation combinatoire;equidad;demarrage;ciencias economicas;multiple objectives;rejection;equity;localisation;location routing problem;location routing problems;arranque;multiobjective combinatorial optimization;costo manutencion;tabu search;residuos solidos;sciences economiques;problema localizacion;transport costs;methode heuristique;economics;camion;combinatorial optimization;rechazo;rejet;busqueda tabu;recherche tabou;cout entretien;optimizacion combinatoria;programacion multiobjetivo;enrutamiento	In this work we present a multiobjective location routing problem and solve it with a multiobjective metaheuristic procedure. In this type of problem, we have to locate some plants within a set of possible locations to meet the demands of a number of clients with multiple objectives. This type of model is used to solve a problem with real data in the region of Andalusia (Spain). Thus, we study the location of two incineration plants for the disposal of solid animal waste from some preestablished locations in Andalusia, and design the routes to serve the different slaughterhouses in this region. This must be done while taking into account certain economic objectives (start-up, maintenance, and transport costs) and social objectives (social rejection by towns on the truck routes, maximum risk as an equity criterion, and the negative implications for towns close to the plant).	metaheuristic;routing;tabu search	Rafael Caballero;Mercedes González;Flor M. Guerrero;Julián Molina Luque;Concepción Paralera	2007	European Journal of Operational Research	10.1016/j.ejor.2005.10.017	mathematical optimization;routing;truck;municipal solid waste;internationalization and localization;combinatorial optimization;tabu search;computer science;operations management;operations research;equity	Robotics	18.411672416997188	5.555900701272911	147217
ab8e8ad1373188487557e5c08db35099be02cfdc	multi-objective decision analysis for competence-oriented project portfolio selection	modelizacion;gestion personnel;multiple criteria analysis;project portfolios;commerce electronique;approximation asymptotique;multicriteria analysis;staff management;multiobjective programming;optimum pareto;programmation multiobjectif;model selection;optimisation;metaheuristics;project management;comercio electronico;optimizacion;employe;economic sciences;e commerce;efficiency;portfolio selection;heuristic method;exact solution;multi objective optimization;prise de decision;metodo heuristico;selection modele;solucion exacta;gestion personal;decision analysis;modelisation;ciencias economicas;eficacia;saber hacer;selection projet;metamodel;staff scheduling;seleccion modelo;metamodele;know how;metamodelo;scheduling;multiple criteria analysis competence development metaheuristics project portfolios staff scheduling;savoir faire;efficacite;gestion projet;employee;optimization;sciences economiques;analisis multicriterio;methode heuristique;asymptotic approximation;analyse multicritere;solution exacte;toma decision;pareto optimal solution;competence development;pareto optimum;modeling;seleccion proyecto;empleado;optimo pareto;project selection;ordonnancement;electronic trade;gestion proyecto;reglamento;aproximacion asintotica;programacion multiobjetivo	0377-2217/$ see front matter 2010 Elsevier B.V. A doi:10.1016/j.ejor.2010.01.041 * Corresponding author. Tel.: +43 1 4277 38632; fa E-mail address: walter.gutjahr@univie.ac.at (W.J. G This paper develops a multi-objective optimization model for project portfolio selection taking employee competencies and their evolution into account. The objectives can include economic gains as well as gains expressed in terms of aggregated competence increments according to pre-defined profiles. In order to determine Pareto-optimal solutions, the overall problem is decomposed into a master problem addressing the portfolio selection itself, and a slave problem dealing with a suitable assignment of personnel to the work packages of the selected projects over time. We provide an asymptotic approximation of the problem by a linearized formulation, which allows an efficient and exact solution of the slave problem. For the solution of the master problem, we compare the multi-objective metaheuristics NSGA-II and P-ACO. Experimental results both for synthetically generated test instances and for real-world test instances, based on an application case from the E-Commerce Competence Center Austria, are presented. 2010 Elsevier B.V. All rights reserved.	approximation;decision analysis;e-commerce;master/slave (technology);mathematical optimization;metaheuristic;multi-objective optimization;pareto efficiency	Walter J. Gutjahr;Stefan Katzensteiner;Peter Reiter;Christian Stummer;Michaela Denk	2010	European Journal of Operational Research	10.1016/j.ejor.2010.01.041	metamodeling;project management;mathematical optimization;simulation;systems modeling;economics;decision analysis;computer science;operations management;multi-objective optimization;mathematics;efficiency;operations research;scheduling;model selection	AI	17.74987104099923	6.371436530080443	147218
b04e6975c5ca7e17e89d47c8de56a0e4a35eeb23	an o(n4) algorithm for preemptive scheduling of a single machine to minimize the number of late jobs	dynamic programming;complejidad espacio;programacion dinamica;preemptive scheduling;single machine scheduling;time complexity;machine unique;dynamic program;algorithme;algorithm;complexite temps;single machine;maquina unica;scheduling;programmation dynamique;space complexity;ordonamiento;complexite espace;complejidad tiempo;ordonnancement;algoritmo	Sevaux for many enlightening discussions on the topic of this paper. The author gratefully acknowledges the useful comments from the reviewer. Abstract: We study the problem of minimizing, in the preemptive case, the number of late jobs on a single machine (1 | pmtn, r j | Σ U j). This problem can be solved by Lawler's algorithm [8] whose time and space complexities are respectively O(n 5) and O(n 3). We propose a new dynamic programming algorithm whose complexities are respectively O(n 4) and O(n 2).	dynamic programming;job stream;lawler's algorithm;preemption (computing);scheduling (computing)	Philippe Baptiste	1999	Oper. Res. Lett.	10.1016/S0167-6377(98)00045-5	time complexity;real-time computing;computer science;dynamic programming;distributed computing;preemption;dspace;scheduling;algorithm	Theory	17.067221803323317	10.777697236408706	147243
1e2d293115160a6b71365ac88656260bf999819b	towards scalable network delay minimization	social network services;minimization;complexity theory;approximation algorithms;airports;computational modeling;delays	Reduction of end-to-end network delays is an optimization task with applications in multiple domains. Low delays enable improved information flow in social networks, quick spread of ideas in collaboration networks, low travel times for vehicles on road networks and increased rate of packets in communication networks. Delay reduction can be achieved by both improving the propagation capabilities of individual nodes and adding additional edges in the network. One of the main challenges in such design problems is that the effects of local changes are not independent, and as a consequence, there is a combinatorial search space of possible improvements. Thus, minimizing the cumulative propagation delay requires novel scalable and data-driven approaches. In this paper, we consider the problem of network delay minimization via node upgrades. Although the problem is NP-hard, we show that probabilistic approximation for a restricted version can be obtained. We design scalable and high-quality techniques for the general setting based on sampling that are targeted to different models of delay distribution. Our methods scale almost linearly with the graph size and consistently outperform competitors in quality.	approximation algorithm;combinatorial search;end-to-end principle;mathematical optimization;np-hardness;propagation delay;sampling (signal processing);scalability;social network;software propagation;telecommunications network	Sourav Medya;Petko Bogdanov;Ambuj K. Singh	2016	2016 IEEE 16th International Conference on Data Mining (ICDM)	10.1109/ICDM.2016.0140	mathematical optimization;computer science;theoretical computer science;distributed computing;computational model;network delay;approximation algorithm	DB	12.596509909266452	14.022186695223729	147499
aaad78535c2bd33909d58712e5054b572ca00401	the linear extension polytope of a poset		Abstract   Let  P  be a finite poset. By definition, the linear extension polytope of  P  has as vertices the characteristic vectors of all linear extensions of  P . In case  P  is an antichain, it is the linear ordering polytope. The linear extension polytope appears in combinatorial optimization in the context of scheduling with precedence constraints, see e.g. [A. Schulz, Polytopes and Scheduling, Phd Thesis, TU Berlin, 1996]. It seems also relevant to order theory, being similar in spirit to other constructions such as the linear extension graph, see e.g. [M. Massow, Linear extension graphs and linear extension diameter, PhD thesis, TU Berlin, 2009]. In this work, we relate the combinatorial properties of the poset  P  to the polyhedral structure of its linear extension polytope. Of particular interest is a natural relaxation of the linear extension polytope. We prove that the relaxation is exact in case  P  is a width-2 poset, and formulate a conjecture stating exactly when the relaxation is exact.		Jean-Paul Doignon;Samuel Fiorini;Selim Rexhep	2016	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2016.10.021	mathematical optimization;combinatorics;uniform k 21 polytope;discrete mathematics;convex polytope;linear programming;birkhoff polytope;mathematics;vertex enumeration problem;algorithm	Theory	24.319229400472693	14.717757095343934	147522
8cd365360ecf33a96baf489f7482fdd1b72a0510	a swift heuristic method for work order scheduling under the skilled-workforce constraint		The considered problem is how to optimally allocate a set of jobs to technicians of different skills such that the number of technicians of each skill does not exceed the number of persons with that skill designation. The key motivation is the quick sensitivity analysis in terms of the workforce size which is quite necessary in many industries in the presence of unexpected work orders. A time-indexed mathematical model is proposed to minimize the total weighted completion time of the jobs. The proposed model is decomposed into a number of single-skill sub-problems so that each one is a combination of a series of nested binary Knapsack problems. A heuristic procedure is proposed to solve the problem. Our experimental results, based on a real-world case study, reveal that the proposed method quickly produces a schedule statistically close to the optimal one while the classical optimal procedure is very timeconsuming.	heuristic;job stream;mathematical model;scheduling (computing);statistically close;swift (programming language)	Nima Safaei;Corey Kiassat	2018	CoRR		swift;computer science;artificial intelligence;machine learning;knapsack problem;scheduling (computing);binary number;workforce;work order;heuristic	AI	14.677505711031102	6.383041151773191	147548
2acc7f11fac801b6fcd0833ced3d77c96f28bed3	a relax-and-cut algorithm for the prize-collecting steiner problem in graphs	heuristique;lagrangien;optimisation;combinatorics;arbre steiner;optimizacion;heuristica;05c05;steiner problem in graphs;combinatoria;vertex;combinatoire;duality;metodo penalidad;68wxx;probleme steiner;relajacion;effective lagrangian;algorithme;algorithm;dualite;penalty method;methode penalite;programacion lineal;informatique theorique;68r10;modificacion;retard;borne inferieure;non delayed relax and cut;linear programming relaxation;coste;linear programming;programmation lineaire;relaxation;prize collecting steiner problem in graphs;lagrangiano;dualidad;optimization;vertice;heuristics;retraso;lagrangian;lower bound;lagrangian relaxation;cota inferior;computer theory;modification;cout;algoritmo;informatica teorica	Given an undirected graph G with penalties associated with its vertices and costs associated with its edges, a Prize Collecting Steiner (PCS) tree is either an isolated vertex of G or else any tree of G, be it spanning or not. The weight of a PCS tree equals the sum of the costs for its edges plus the sum of the penalties for the vertices of G not spanned by the PCS tree. Accordingly, the Prize Collecting Steiner Problem in Graphs (PCSPG) is to find a PCS tree with the lowest weight. In this paper, after reformulating and re-interpreting a given PCSPG formulation, we use a Lagrangian Non Delayed Relax and Cut (NDRC) algorithm to generate primal and dual bounds to the problem. The algorithm was capable of adequately dealing with the exponentially many candidate inequalities to dualize. It incorporates ingredients such as a new PCSPG reduction test, an effective Lagrangian heuristic and a modification in the NDRC framework that allowed duality gaps to be further reduced. The Lagrangian heuristic suggested here dominates their PCSPG counterparts in the literature. The NDRC PCSPG lower bounds, most of the time, nearly matched corresponding Linear Programming relaxation bounds.	algorithm;augmented lagrangian method;booting;branch and cut;central processing unit;degree-constrained spanning tree;file spanning;graph (discrete mathematics);heuristic;information;linear programming relaxation;steiner tree problem;test set;vertex (graph theory)	Alexandre Salles da Cunha;Abilio Lucena;Nelson Maculan;Mauricio G. C. Resende	2009	Discrete Applied Mathematics	10.1016/j.dam.2008.02.014	vertex;mathematical optimization;combinatorics;discrete mathematics;duality;lagrangian relaxation;input/output;steiner tree problem;linear programming;linear programming relaxation;heuristics;penalty method;relaxation;lagrangian;mathematics;upper and lower bounds;algorithm	Theory	22.347462689692716	12.92067672444828	147659
bbc35d39942dd5e1a12c8cf5eba031e90c55f4e9	integer programming and combinatorial optimization, 13th international conference, ipco 2008, bertinoro, italy, may 26-28, 2008, proceedings	institutional repositories;fedora;vital;vtls;innovative;ils		combinatorial optimization;integer programming		2008		10.1007/978-3-540-68891-4	mathematical optimization;theoretical computer science;machine learning	Robotics	23.06287819119377	9.105184137173131	147797
f64c34d285ded9fb1a57cf030b5c7926cdfa6439	complementary replacement: a meta scheduling principle	dispatching rules;time sharing	A principle of scheduling is presented that includes a wide class of time and space allocation problems met in time sharing and virtual systems. Its essence is a method, based on symmetry, to use any of several rules for admission-to-service in a single server system to derive a space-replacement rule. This method, called complementary replacement includes several known job dispatching rules as well as some page-replacement algorithms such as the MIN and LRU (last-recently-used). A fundamental but unsolved problem with the principle is its range of applicability and the conditions under which it guarantees an optimum.	page replacement algorithm;scheduling (computing);server (computing);time-sharing	H. Hellerman	1969		10.1145/961053.961070	mathematical optimization;computer science;operating system;time-sharing;algorithm	Theory	13.059996812005407	11.740355148988439	147877
54bf7b3e1c67a73a794671112150b302c099933d	upper bounds and exact algorithms for p-dispersion problems	location problem;probleme localisation;distance minimale;programmation semi definie;relaxation lagrange;localization;branch and bound algorithm;upper bounds;probleme somme p dispersion;localizacion;minimal distance;upper bound;branch and bound method;relaxation semidefinie;localisation;metodo branch and bound;computer experiment;minimum distance;exact algorithm;problema localizacion;locational analysis;methode separation et evaluation;programacion semi definida;relajacion semidefinida;borne superieure;branch and bound;semidefinite relaxation;distancia minima;lagrange relaxation;lagrangian relaxation;cota superior;semidefinite program;semi definite programming	The p-dispersion-sum problem is the problem of locating p facilities at some of n predefined locations, such that the distance sum between the p facilities is maximized. The problem has applications in telecommunication (where it is desirable to disperse the transceivers in order to minimize interference problems), and in location of shops and service-stations (where the mutual competition should be minimized).A number of fast upper bounds are presented based on Lagrangian relaxation, semidefinite programming and reformulation techniques. A branch-and-bound algorithm is then derived, which at each branching node is able to compute the reformulation-based upper bound in O(n) time. Computational experiments show that the algorithm may solve geometric problems of size up to n = 90, and weighted geometric problems of size n = 250.The related p-dispersion problem is the problem of locating p facilities such that the minimum distance between two facilities is as large as possible. New formulations and fast upper bounds are presented, and it is discussed whether a similar framework as for the p-dispersion sum problem can be used to tighten the upper bounds. A solution algorithm based on transformation of the p-dispersion problem to the p-dispersion-sum problem is finally presented, and its performance is evaluated through several computational experiments.	algorithm	David Pisinger	2006	Computers & OR	10.1016/j.cor.2004.09.033	mathematical optimization;combinatorics;computer science;calculus;mathematics;branch and bound;semidefinite programming	Theory	22.880939003440975	13.646954430403097	147886
82da3d5faaae342f6068ac9afdda028ebfd85275	minimizing total weighted completion time in a two-machine flow shop scheduling under simple linear deterioration	total weighted completion time;simple linear deterioration;branch and bound algorithm;flow shop scheduling;linear functionals;scheduling;timing optimization;computer analysis;flow shop;lower bound;heuristic algorithm	In this paper, we address a two-machine flow shop scheduling problem under simple linear deterioration. By a simple linear deterioration function, we mean that the processing time of a job is a simple linear function of its execution start time. The objective is to find a sequence that minimizes total weighted completion time. Optimal schedules are obtained for some special cases. For the general case, several dominance properties and two lower bounds are derived to speed up the elimination process of a branch-and-bound algorithm. A heuristic algorithm is also proposed to overcome the inefficiency of the branch-and-bound algorithm. Computational analysis on randomly generated problems is conducted to evaluate the branch-and-bound algorithm and heuristic algorithm.	flow shop scheduling;scheduling (computing)	Shu-Hui Yang;Ji-Bo Wang	2011	Applied Mathematics and Computation	10.1016/j.amc.2010.11.037	job shop scheduling;mathematical optimization;flow shop scheduling;mathematics;algorithm	Theory	16.163395794619696	8.620766448319529	147923
ef4a1a912a9df01a0b8e098e676f6cb9e946e1d6	a branch-and-bound algorithm for the time-dependent travelling salesman problem			algorithm;branch and bound;travelling salesman problem	Anna Arigliano;Tobia Calogiuri;Gianpaolo Ghiani;Emanuela Guerriero	2018	Networks	10.1002/net.21830	mathematical optimization;combinatorics;mathematics;vehicle routing problem;branch and bound;travelling salesman problem;upper and lower bounds	ML	22.58207686955757	7.573074114916427	147976
7497966c3d87489ac4b8ec764de72b5ffce212e8	focused topological value iteration	strongly connected component;value iteration;heuristic search;markov decision process;connected component	Topological value iteration (TVI) is an effective algorithm for solving Markov decision processes (MDPs) optimally, which 1) divides an MDP into strongly-connected components, and 2) solves these components sequentially. Yet, TVI’s usefulness tends to degrade if an MDP has large components, because the cost of the division process isn’t offset by gains during solution. This paper presents a new algorithm to solve MDPs optimally, focused topological value iteration (FTVI). FTVI addresses TVI’s limitations by restricting its attention to connected components that are relevant for solving the MDP. Specifically, FTVI uses a small amount of heuristic search to eliminate provably sub-optimal actions; this pruning allows FTVI to find smaller connected components, thus running faster. We demonstrate that our new algorithm outperforms TVI by an order of magnitude, averaged across several domains. Surprisingly, FTVI also significantly outperforms popular ‘heuristically-informed’ MDP algorithms such as LAO*, LRTDP, and BRTDP in many domains, sometimes by as much as two orders of magnitude. Finally, we characterize the type of domains where FTVI excels — suggesting a way to an informed choice of solver.	connected component (graph theory);graphical user interface;heuristic;information;iteration;iterative method;markov chain;markov decision process;media dispatch protocol;relevance;search algorithm;solver;strongly connected component;televideo	Peng Dai;Mausam;Daniel S. Weld	2009			markov decision process;mathematical optimization;combinatorics;discrete mathematics;heuristic;computer science;artificial intelligence;machine learning;mathematics;algorithm	AI	23.154627687853996	4.327619104634231	148184
7e7ad58a862c59cf6eefd624df390f465f3b26c4	graph partitioning using linear and semidefinite programming	reseau communication;descomposicion grafo;programmation semi definie;semidefinite programming;graph partitioning;programacion lineal;mathematical programming;linear programming;programmation lineaire;relaxation lineaire;partitionnement;programacion semi definida;programmation mathematique;red de comunicacion;communication network;programacion matematica;semidefinite relaxation;graph decomposition;semidefinite program;semi definite programming;decomposition graphe	Graph partition is used in the telecommunication industry to subdivide a transmission network into small clusters. We consider both linear and semidefinite relaxations for the equipartition problem and present numerical results on real data from France Telecom networks with up 900 nodes, and also on randomly generated problems.	graph partition;semidefinite programming	Abdel Lisser;Franz Rendl	2003	Math. Program.	10.1007/s10107-002-0342-x	mathematical optimization;combinatorics;discrete mathematics;graph partition;mathematics;semidefinite embedding;telecommunications network;semidefinite programming	Theory	22.04840321074458	12.670757800541152	148515
cc4c272ffe1e7212858a28abcb218369538151d3	minmax regret 1-facility location on uncertain path networks	facility location;uncertainty;algorithms	Let P be an undirected path graph of n vertices. Each edge of P has a positive length and a constant capacity. Every vertex has a nonnegative supply, which is an unknown value but is known to be in a given interval. The goal is to find a point on P to build a facility and move all vertex supplies to the facility such that the maximum regret is minimized. The previous best algorithm solves the problem in O(nlog2n) time and O(nlogn) space. In this paper, we present an O(nlogn) time and O(n) space algorithm, and our approach is based on new observations and algorithmic techniques.	minimax;regret (decision theory)	Haitao Wang	2013		10.1007/978-3-642-45030-3_68	mathematical optimization	ML	24.039670822204823	17.577928947363482	148890
f12a34d9f68e553a770f3a24809d4b10993716de	a test problem generator for the steiner problem in graphs	steiner problem;optimal solution;numerical algorithmics;steiner problem in graphs;efficiency;performance;testing;test;probleme steiner;algorithme;algorithm;eficacia;test problems;algorithmique numerique;integer programming;mathematical programming;efficacite;rendimiento;integer program;experimentation;constrained optimization problem;programmation mathematique;programacion matematica;algoritmico numerico;optimality condition;experimentacion;algoritmo	In this paper we present a new binary-programming formulation for the Steiner problem in graphs (SPG), which is well known to be NP-hard. We use this formulation to generate test problems with known optimal solutions. The technique uses the KKT optimality conditions on the corresponding quadratically constrained optimization problem.	constrained optimization;constraint (mathematics);karush–kuhn–tucker conditions;mathematical optimization;np-hardness;optimization problem;steiner tree problem	B. N. Khoury;Panos M. Pardalos;Dingzhu Du	1993	ACM Trans. Math. Softw.	10.1145/168173.168420	mathematical optimization;combinatorics;integer programming;steiner tree problem;mathematics;software testing;algorithm	Theory	22.55721235942811	12.40176528414923	148898
77ef233bbec239d68b0c97045da8a3ef048d033c	on optimal k -iinear scheduling of tree-like task graphs for logp-machines	gestion labor;structure programme;programacion paralela;sistema informatico;complejidad programa;parallel programming;computer system;program optimization;gestion tâche;estructura programa;systeme informatique;optimisation programme;program complexity;task scheduling;program structure;complexite programme;programmation parallele;optimizacion programa	Abs t rac t . A k-linear schedule may map up to k directed paths of a task graph onto one processor. We consider k-linear scheduling algorithms for the communication cost model of the LogP-machine, i.e. without assumption on processor bounds. The main result of this paper is that optimal k-linear schedules of trees and tree-like task graphs G with n tasks can be computed in time O(n k+~ log n) and O(n k+3 log n), respectively, if o > g. These schedules satisfy a capacity constraint, i.e., there are at most [L/g] messages in transit from any or to any processor at any time.	analysis of algorithms;graph - visual representation;linear scheduling method;logp machine;schedule (document type);scheduling (computing);scheduling - hl7 publishing domain;trees (plant);algorithm;message	Wolf Zimmermann;Martin Middendorf;Welf Löwe	1998		10.1007/BFb0057870	parallel computing;real-time computing;simulation;computer science;program optimization;programming language;algorithm	Theory	17.276548226221507	11.53852287825728	149050
a08c773ee6868487108654156b0e79f6dd5b0656	an ilp for the metro-line crossing problem	optimal solution;public transport;embedded graph;polynomial time;integer linear program	In this paper we consider a problem that occurs when drawing public transportation networks. Given an embedded graph G = (V,E) (e.g. the railroad network) and a set H of paths in G (e.g. the train lines), we want to draw the paths along the edges of G such that they cross each other as few times as possible. For aesthetic reasons we insist that the relative order of the paths that traverse a vertex does not change within the area occupied by the vertex. We prove that the problem, which is known to be NP-hard, can be rewritten as an integer linear program that finds the optimal solution for the problem. In the case when the order of the endpoints of the paths is fixed we prove that the problem can be solved in polynomial time. This improves a recent result by Bekos et al. (2007).	embedded system;linear programming;np-hardness;traverse;time complexity	Matthew Asquith;Joachim Gudmundsson;Damian Merrick	2008			time complexity;mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;public transport;algorithm	Theory	24.458608358955317	17.944735867554936	149067
eac6bad58b60970f359d3237ef9b5797438e5b50	possibilistic bottleneck combinatorial optimization problems with ill-known weights	bottleneck combinatorial optimization;fuzzy interval;combinatorial optimization problem;robust optimization;interval;possibility theory;solution concept;combinatorial optimization	In this paper a general bottleneck combinatorial optimization problem with uncertain element weights modeled by fuzzy intervals is considered. A possibilistic formalization of the problem and solution concepts in this setting, which lead to compute robust solutions under fuzzy weights are given. Some algorithms for finding a solution according to the introduced concepts and evaluating optimality of solutions and elements are provided. These algorithms are polynomial for bottleneck combinatorial optimization problems with uncertain element weights, if their deterministic counterparts are polynomially solvable.	algorithm;combinatorial optimization;decision problem;mathematical optimization;optimization problem;polynomial	Adam Kasperski;Pawel Zielinski	2011	Int. J. Approx. Reasoning	10.1016/j.ijar.2011.01.003	interval;optimization problem;extremal optimization;possibility theory;mathematical optimization;combinatorics;discrete mathematics;robust optimization;linear bottleneck assignment problem;fuzzy transportation;combinatorial optimization;computer science;combinatorial explosion;mathematics;solution concept;bottleneck traveling salesman problem;quadratic assignment problem	Theory	21.127278615163167	9.40309702508532	149161
abf7b35b19879a90e28a90cd5575c2b6ce3a36bc	scheduling algorithms for data redistribution and load-balancing on master-slave platforms	modelizacion;parallelisme;distributed memory;metodo polinomial;topology;algorithme glouton;equilibrio de carga;memoria compartida;topologie;one port model;equilibrage charge;relacion maestro esclavo;relation maitre esclave;topologia;modelisation;scheduling algorithm;parallelism;divisible load theory;paralelismo;polynomial method;scheduling;polynomial algorithm;master slave platform;load balancing;greedy algorithm;algoritmo gloton;completitud;load balance;completeness;memoire repartie;algoritmo optimo;master slave relationship;data redistribution;methode polynomiale;algorithme optimal;data consistency;completude;optimal algorithm;modeling;ordonnancement;independent tasks;reglamento	In this work we are interested in the problem of scheduling and redistributing data on master-slave platforms. We consider the case were the workers possess initial loads, some of which having to be redistributed in order to balance their completion times. We assume that the data consists of independent and identical tasks. We prove the NP completeness of the problem for fully heterogeneous platforms. Also, we present optimal polynomial algorithms for special important topologies: a simple greedy algorithm for homogeneous star-networks, and a more complicated algorithm for platforms with homogeneous communication links and heterogeneous workers.	acm/ieee supercomputing conference;alessandro vespignani;approximation algorithm;boinc;best, worst and average case;compiler;computation;computer cluster;computer science;computers and intractability: a guide to the theory of np-completeness;data parallelism;distributed computing;greedy algorithm;heuristic (computer science);interconnection;load balancing (computing);management science;michael garey;parallel computing;polynomial;seti@home;schedule (project management);scheduling (computing);search for extraterrestrial intelligence;set cover problem;simulation;springer (tank);workstation	Loris Marchal;Veronika Rehn-Sonigo;Yves Robert;Frédéric Vivien	2007	Parallel Processing Letters	10.1142/S0129626407002879	parallel computing;computer science;load balancing;operating system;mathematics;distributed computing;scheduling;algorithm	Theory	17.059743844211013	12.125184102830922	149201
d84fca2ebf8edfebf2381e13abf5162423ecdb9e	quantum adiabatic optimization without heuristics		Quantum adiabatic optimization (QAO) is performed using a time-dependent Hamiltonian H(s) with spectral gap γ(s). Assuming the existence of an oracle Γ such that γ(s) = Θ (Γ(s)), we provide an algorithm that reliably performs QAO in time O ( γ min log(γ min ) ) with O ( log(γ min ) ) oracle queries, where γmin = mins γ(s). Our strategy is not heuristic and does not require guessing time parameters or annealing paths. Rather, our algorithm naturally produces an annealing path such that dH/ds ≈ γ(s) and chooses its own runtime T to be as close as possible to optimal while promising convergence to the ground state. We then demonstrate the feasibility of this approach in practice by explicitly constructing a gap oracle Γ for the problem of finding a vertex m = argminu W (u) of the cost function W : V −→ [0, 1], restricting ourselves to computational basis measurements and driving Hamiltonian H(0) = I − V −1 u,v∈V |u〉〈v|, with V = |V|. Requiring only that W have a constant lower bound on its spectral gap and upper bound κ on its spectral ratio, our QAO algorithm returns m using Γ with probability (1 − ǫ)(1 − e) in time Õ(ǫ[ √ V + (κ − 1)V ]). This achieves a quantum advantage for all κ, and when κ ≈ 1, recovers Grover scaling up to logarithmic factors. We implement the algorithm as a subroutine in an optimization procedure that produces m with exponentially small failure probability and expected runtime Õ(ǫ[ √ V + (κ− 1)V ]), even when κ is not known beforehand.	algorithm;computation;ground state;hamiltonian (quantum mechanics);heuristic (computer science);loss function;mathematical optimization;maxima and minima;quantum;simulated annealing;subroutine	Michael Jarret;Brad Lackey;Aike Liu;Kianna Wan	2018	CoRR		discrete mathematics;hamiltonian (quantum mechanics);vertex (geometry);logarithm;spectral gap;adiabatic process;ground state;upper and lower bounds;quantum;mathematics	Theory	20.738905303076283	17.85478913521503	149359
f2edaab3a442760d6f29a282ee27de9ce2f6e12a	exact and heuristic algorithms for the just-in-time scheduling problem in a batch processing system		Batch processing systems are commonly used in many different environments such as chemical and semiconductor industries. In this research, a just-in-time scheduling problem in a batch processing system is investigated. Minimization of total earliness and tardiness of the jobs with respect to a common due date is considered as the objective function. First, the research problem is formulated as a mixed integer linear programming model. Then, to find the optimal schedule for a predetermined set of batches, a dynamic programming algorithm is proposed. Based on the proposed dynamic programming algorithm, several heuristics are also developed. A lower bounding method is presented, and then a branch and bound algorithm is proposed to solve the problem optimally. To demonstrate the performance of the proposed algorithms, several computational experiments are conducted.	algorithm;batch processing;branch and bound;computation;dynamic programming;experiment;heuristic (computer science);integer programming;job scheduler;job stream;just-in-time compilation;linear programming;loss function;optimization problem;parallel port;programming model;relevance;scheduling (computing);semiconductor	N. Rafiee Parsa;Behrooz Karimi;S. M. Moattar Husseini	2017	Computers & OR	10.1016/j.cor.2016.12.001	mathematical optimization;real-time computing;computer science;distributed computing	AI	13.538529694832272	5.5535732774914	149392
6e30b0532c5b485dfd9b6244c7fac02d3170f96a	strongly polynomial simplex algorithm for bipartite vertex packing	labeling scheme;bipartite vertex packing;strong spanning trees;simplex algorithm;simplex method;polynomial complexity;linear program;spanning tree;bipartite graph;node labeling	Abstract   This paper gives a new algorithm to solve the weighted vertex packing problem on a bipartite graph via strong spanning trees. The algorithm is a special implementation of the primal simplex algorithm applied to the linear programming statement of the problem. Using a simple node labeling scheme, the algorithm has a strongly polynomial complexity.	independent set (graph theory);polynomial;set packing;simplex algorithm;time complexity	Ronald D. Armstrong;Zhiying Jin	1996	Discrete Applied Mathematics	10.1016/0166-218X(94)00122-T	mathematical optimization;complete bipartite graph;combinatorics;discrete mathematics;kruskal's algorithm;bipartite graph;vertex cover;spanning tree;prim's algorithm;linear programming;3-dimensional matching;mathematics;blossom algorithm;assignment problem;reverse-delete algorithm;simplex algorithm;matching	Theory	23.3987437231597	17.53774342703456	149405
badd8653557b01e5c2326f8d594b71270000876d	a constraint programming approach for solving unrelated parallel machine scheduling problem		Abstract This paper addresses the non-preemptive unrelated parallel machine scheduling problem (PMSP) with job sequence and machine dependent setup times. This is a widely seen NP-hard (non-deterministic polynomial-time) problem with the objective to minimize the makespan. This study provides a noval constraint programming (CP) model with two customized branching strategies that utilize CP’s global constraints, interval decision variables, and domain filtering algorithms. The performance of the CP model is evaluated against the state-of-art algorithms. In addition, we compare the performance of the default branching method in the CP solver against the two customized variants. In terms of average solution quality, the computational results indicate that the CP model slightly outperforms all of the state-of-art algorithms in solving small problem instances, is able to prove the optimality of 283 currently best-known solutions. It is also effective in finding good quality feasible solutions for the larger problem instances.	constraint programming;parallel computing;scheduling (computing)	Ridvan Gedik;Darshan Kalathia;Gokhan Egilmez;Emre Kirac	2018	Computers & Industrial Engineering	10.1016/j.cie.2018.05.014	constraint programming;mathematical optimization;engineering;branching (version control);job shop scheduling;filter (signal processing);solver	AI	16.0153133812917	7.156915804167053	149477
7e9aa4133f56beded184c0a6ce5b621b6248c2da	harmonic buffer management policy for shared memory switches	file attente;memoria tampon;shared memory switches;shared memory;memoria compartida;buffer management;queue;informatique theorique;scheduling;borne inferieure;competitive analysis;non preemptive policies;high throughput;memoire tampon;fila espera;ordonnancement;lower bound;analyse competitive;reglamento;memoire partagee;competitive ratio;cota inferior;computer theory;buffer memory;informatica teorica	In this paper we consider shared-memory switches. We introduce a novel general nonpreemptive buffer management scheme, which considers the queues ordered by their size. We propose a new scheduling policy, based on our general scheme, which we call the Harmonic policy. We analyze the performance of the Harmonic policy by means of competitive analysis and demonstrate that its throughput competitive ratio is at most ln(N) + 2, where N is the number of output ports. We also present a lower bound of Ω(log N/log log N) on the performance of any online deterministic policy. Our simulations also show that the Harmonic policy achieves high throughput and easily adapts to changing load conditions.	network switch;shared memory	Alexander Kesselman;Yishay Mansour	2004	Theor. Comput. Sci.	10.1016/j.tcs.2004.05.014	competitive analysis;parallel computing;real-time computing;telecommunications;computer science;algorithm	Theory	16.509915922799856	12.000330816538783	149493
f93b4554d33520c704262823dbb69f3de526cfb8	fast protein structure alignment	protein structure alignment;worst case analysis;optimization problem;polynomial time algorithm;protein structure;molecular biology;linear transformation;3d structure;optimization model	We address the problem of aligning the 3D structures of two proteins. Our pairwise comparisons are based on a new optimization model that is succinctly expressed in terms of linear transformations and highlights the problem’s intrinsic geometry. The optimization problem is approximately solved with a new polynomial time algorithm. The worstcase analysis of the algorithm shows that the solution is bounded by a constant depending only on the data of the problem.	algorithm;align (company);assignment problem;graph theory;mathematical optimization;optimization problem;p (complexity);sequence alignment	Yosi Shibberu;Allen Holder;Kyla Lutz	2010		10.1007/978-3-642-13078-6_18	optimization problem;biology;protein structure;mathematical optimization;combinatorics;theoretical computer science;mathematics;linear map	Comp.	20.69251098374051	11.292732783920165	149519
8ce679907823a5d4fa1a309fb414b5fe27db0e96	the multiscenario lot size problem with concave costs	inventory;upper bound;objective function;lot sizing;production planning;branch and bound;multiple objective programming;scenarios;pareto optimality	The dynamic single-facility single-item lot size problem is addressed. The finite planning horizon is divided into several time periods. Although the total demand is assumed to be a fixed value, the distribution of this demand among the different periods is unknown. Therefore, for each period the demand can be chosen from a discrete set of values. For this reason, all the combinations of the demand vector yield a set of different scenarios. Moreover, we assume that the production/reorder and holding cost vectors can vary from one scenario to another. For each scenario, we consider as the objective function the sum of the production/reorder and the holding costs. The problem consists of determining all the Pareto-optimal or non-dominated production plans with respect to all scenarios. We propose a solution method based on a multiobjective branch and bound approach. Depending on whether shortages are considered or not, different upper bound sets are provided. Computational results on several randomly generated problems are reported.	concave function	Jose Gutiérrez;Justo Puerto;Joaquin Sicilia	2004	European Journal of Operational Research	10.1016/S0377-2217(03)00014-6	mathematical optimization;inventory;economics;operations management;mathematics;upper and lower bounds;welfare economics;branch and bound	Theory	14.860559255039718	4.189481746060921	149591
442b02078b04bed5a6958353b93570d39f763095	algorithmic aspects of the core of combinatorial optimization games	graph theory;cost allocation;combinatorial optimization game;core;combinatorial optimization	We discuss an integer programming formulation for a class of cooperative games. We focus on algorithmic aspects of the core, one of the most important solution concepts in cooperative game theory. Central to our study is a simple (but very useful) observation that the core for this class is nonempty if and only if an associated linear program has an integer optimal solution. Based on this, we study the computational complexity and algorithms to answer important questions about the cores of various games on graphs, such as maximum flow, connectivity, maximum matching, minimum vertex cover, minimum edge cover, maximum independent set, and minimum coloring.	combinatorial optimization	Xiaotie Deng;Toshihide Ibaraki;Hiroshi Nagamochi	1999	Math. Oper. Res.	10.1287/moor.24.3.751	core;mathematical optimization;combinatorics;discrete mathematics;vertex cover;combinatorial optimization;graph theory;edge cover;mathematics	Theory	22.112182517800274	17.18074884694583	149631
7dc80a5e5b3c661dea975401b63eceae55efc79c	a 3/2-approximation for the proportionate two-machine flow shop scheduling with minimum delays	flow shop scheduling;polynomial time algorithm;optimal scheduling;lower bound	We study the two-machine flow shop problem with minimum delays. The problem is known to be strongly NP-hard even in the case of unit processing times and to be approximable within a factor of 2 of the length of an optimal schedule in the general case. The question whether there exists a polynomial-time algorithm with a better approximation ratio has been posed by several researchers but still remains open. In this paper we improve the above bound to 3/2 for the special case of the problem when both operations of each job have equal processing times (this case of flow shop is known as the proportionate flow shop). Our analysis of the algorithm relies upon a nontrivial generalization of the lower bound established by Yu for the case of unit processing times.	flow shop scheduling;scheduling (computing)	Alexander A. Ageev	2007		10.1007/978-3-540-77918-6_5	job shop scheduling;mathematical optimization;flow shop scheduling;mathematics;upper and lower bounds;algorithm	EDA	15.667893296224896	10.716127276314452	149789
fa4ed649aaef86ac88efff9278d9db0b3d9e76c6	a best online algorithm for scheduling on two parallel batch machines	lettre alphabet;tratamiento paralelo;parallel batch machines;online algorithm;tiempo total acabamiento;traitement parallele;algorithme en ligne;online scheduling;machine parallele;competitive algorithms;temps total achevement;traitement par lot;algoritmo en linea;algorithm en ligne;operations research;procesamiento por lote;68wxx;algorithme competitif;makespan;recherche operationnelle;informatique theorique;scheduling;batch process;parallel machines;letra alfabeto;letter;batch processing;investigacion operacional;parallel processing;ordonnancement;reglamento;competitive ratio;computer theory;68m20;informatica teorica	We consider the online scheduling on two parallel batch machines with infinite batch size to minimize makespan, where jobs arrive over time. That is, all information of a job is not available until it is released. For this online scheduling problem, Nong et al. [Q.Q. Nong, T.C.E. Cheng, C.T. Ng, An improved online algorithm for scheduling on two unrestrictive parallel batch processing machines, Operations Research Letters, 36 (2008) 584–588] have provided an online algorithmwith competitive ratio no greater than √ 2.We show that this bound is tight for the problem. Furthermore we give a new best possible online algorithm with a tighter structure. © 2009 Elsevier B.V. All rights reserved.	batch processing;competitive analysis (online algorithm);makespan;online algorithm;operations research;scheduling (computing)	Ji Tian;Ruyan Fu;Jinjiang Yuan	2009	Theor. Comput. Sci.	10.1016/j.tcs.2009.02.011	fair-share scheduling;job shop scheduling;parallel processing;computer science;distributed computing;algorithm;batch processing	Theory	16.663791954917375	11.133634081989745	149959
e1e9a8aa196c3652ee25a7248cf171e6b23cf34e	integer programming in vlsi design	concepcion circuito;programacion entera;routing;circuit design;programmation entiere;circuit vlsi;vlsi design;algorithme;algorithm;vlsi circuit;integer programming;conception circuit;encaminamiento;circuito vlsi;integer program;acheminement;programmation combinatoire;algoritmo	Raghavan, P., Integer programming in VLSI design, Discrete Applied Mathematics 40 (1992) 2943. This paper surveys some recent developments in the application of combinatorial optimization to VLSI design. We focus on integer programs arising in wire routing and PLA partitioning. Typically, the integer programs we are interested in are computationally difficult. We present approaches to approximately solving them by rounding the solutions to the relaxed linear programs. The resulting algorithms run in polynomial time and have provable performance guarantees, We also introduce the notion of multiterminal multicommodity flows, and point out their relevance to VLSI routing.	algorithm;binary space partitioning;central processing unit;combinatorial optimization;discrete mathematics;experiment;gate array;ibm 3090;integer programming;linear programming;loss function;mathematical optimization;method of conditional probabilities;multiseat configuration;operations research;optimization problem;p (complexity);polynomial;programmable logic array;provable prime;relevance;rounding;routing (electronic design automation);slack variable;time complexity;tom;very-large-scale integration	Prabhakar Raghavan	1992	Discrete Applied Mathematics	10.1016/0166-218X(92)90020-B	mathematical optimization;routing;integer programming;theoretical computer science;circuit design;mathematics;very-large-scale integration;algorithm	Theory	21.735738532284227	12.62560309041959	150071
19e0b829cf327cb9e2058117646d26c29bcacb0b	a milp-based vnd for the min-max regret shortest path tree problem with interval costs		Abstract The min-max regret Shortest Path Tree problem (RSPT) is a NP-Hard Robust Optimization counterpart of the Shortest Path Tree problem, where arcs costs are modeled as intervals of possible values. This problem arises from the uncertainty in link quality the routing protocols for IPv6 Low Wireless Personal Area Networks have to handle. In this paper, we propose a Variable Neighborhood Descent (VND) heuristic based on a Mixed Integer Linear Programming formulation. An exact algorithm based on the same formulation is used to assess the quality of this heuristic. Computational experiments show that VND has an average optimality gap of 0.91%, being smaller that with the best heuristic in literature for RSPT.	maxima and minima	Iago Augusto Carvalho;Thiago F. Noronha;Chistophe Duhamel;Luiz Filipe M. Vieira	2018	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2018.03.006	discrete mathematics;robust optimization;shortest-path tree;regret;mathematics;integer programming;heuristic;routing protocol;exact algorithm	Theory	23.264101534201274	17.136367744656877	150268
3fa4d928420474f059617bbec2985b7cce1dd04e	black-box randomized reductions in algorithmic mechanism design	truthful approximation algorithms;optimisation;black box randomized reductions;approximate algorithm;algorithmic mechanism design;approximation algorithms;resource management;polynomials;packing problem;smoothed analysis mechanism design truthful approximation algorithms;smoothed analysis;objective function;optimization problem;approximation theory;linear perturbations;arbitrary approximation algorithms;polynomials approximation theory optimisation;multiparameter problems;optimization problem black box randomized reductions algorithmic mechanism design arbitrary approximation algorithms multiparameter problems packing problem smoothed analysis linear perturbations objective function;optimization;algorithm design and analysis approximation algorithms approximation methods polynomials resource management optimization computer science;approximation methods;computer science;mechanism design;algorithm design and analysis	We give the first black-box reduction from arbitrary approximation algorithms to truthful approximation mechanisms for a non-trivial class of multi-parameter problems. Specifically, we prove that every packing problem that admits an FPTAS also admits a truthful-in-expectation randomized mechanism that is an FPTAS. Our reduction makes novel use of smoothed analysis, by employing small perturbations as a tool in algorithmic mechanism design. We develop a “duality'' between linear perturbations of the objective function of an optimization problem and of its feasible set, and use the “primal'' and “dual'' viewpoints to prove the running time bound and the truthfulness guarantee, respectively, for our mechanism.	randomized algorithm	Shaddin Dughmi;Tim Roughgarden	2010		10.1109/FOCS.2010.79	algorithmic mechanism design;smoothed analysis;mechanism design;optimization problem;algorithm design;mathematical optimization;packing problems;combinatorics;discrete mathematics;computer science;resource management;mathematics;approximation algorithm;polynomial;approximation theory	Theory	20.850395758989606	16.38790846821541	150360
c4f57ad9f1fc8776763c2bd40017f502387db8f0	fully polynomial approximation schemes for single-item capacitated economic lot-sizing problems	research theory;maastricht university;cost function;generic model;approximation method;suboptimal algorithms;mathematical economics and econometrics;digital archive;polynomials;analysis of algorithms;approximation theory;numerical analysis;single item capacitated lot sizing;open access;approximation scheme;lot sizing;lot sizing model;industrial functions;production cost;publication;scientific;fully polynomial approximation schemes;fully polynomial approximation scheme;institutional repository;polynomial approximation;industrial costs;lot sizing models	NP{hard cases of the single{item capacitated lot{sizing problem have been the topic of extensive research and continue to receive considerable attention. However, surprisingly few theoretical results have been published on approximation methods for these problems. To the best of our knowledge, until now no polynomial approximation method is known which produces solutions with a relative deviation from optimality that is bounded by a constant. In this paper we show that such methods do exist, by presenting an even stronger result: the existence of fully polynomial approximation schemes. The approximation scheme is rst developed for a quite general model, which has concave backlogging and production cost functions and arbitrary (monotone) holding cost functions. Subsequently we discuss important special cases of the model and extensions of the approximation scheme to even more general models. Subject classi cation: Analysis of algorithms, suboptimal algorithms: fully polynomial approximation schemes. Dynamic programming/optimal control: lot{sizing models. Inventory/production: single{item capacitated lot{sizing. In the single{item capacitated economic lot{sizing problem we consider a production facility which manufactures a single product to satisfy known integer demands over a nite planning horizon of T periods. At each period, the production and holding{ backlogging cost functions are given, and the amount of production is subject to a Department of Quantitative Economics, Maastricht University, P.O. Box 616, 6200 MD Maastricht, The Netherlands; e{mail: s.vanhoesel@ke.unimaas.nl Econometric Institute, Erasmus University Rotterdam, P.O. Box 1738, 3000 DR Rotterdam, The Netherlands; e{mail: wagelmans@few.eur.nl	analysis of algorithms;approximation algorithm;concave function;dynamic programming;geforce 6 series;optimal control;polynomial;polynomial-time approximation scheme;monotone	Stan P. M. van Hoesel;Albert P. M. Wagelmans	2001	Math. Oper. Res.	10.1287/moor.26.2.339.10552	mathematical optimization;combinatorics;polynomial-time approximation scheme;numerical analysis;analysis of algorithms;publication;mathematics;mathematical economics;hardness of approximation;approximation algorithm;algorithm;polynomial;approximation theory	Theory	19.997165541978955	13.974638090104426	150385
ffd272510e1c79254ca6baf2235b7e052c5e3acb	heuristic for scheduling intrees on m machines with non-availability constraints		This paper considers the problem of scheduling n tasks subject to intree-precedence constraints on m identical machines under non-availability constraints. The objective is to minimize the makespan. This problem is known to be NP-hard. We propose and test several heuristic variants based on different selection and dispatching rules.	heuristic	Khaoula Ben Abdellafou;Hatem Hadda;Ouajdi Korbaa	2016		10.1007/978-3-319-53480-0_38	fair-share scheduling;flow shop scheduling;dynamic priority scheduling;rate-monotonic scheduling	Theory	15.455125994213978	8.833825984425358	150514
0fce6fafa7e1d86439a00462231b7f1a0857b21c	an efficient generalized network-simplex-based algorithm for manufacturing network flows	sistema lineal;modelizacion;metodo simplejo;materia prima;raw materials;matiere premiere;optimal method;manufacturing process;simplex method;entreprise etendue;flow models;linear system;generalized network simplex method;production process;optimisation combinatoire;modelisation;assembly;modele ecoulement;flujo red;manufacturing networks;procedimiento fabricacion;network flows;estructura datos;empresa extendida;processus fabrication;extended enterprise;montage;structure donnee;process model;network flow;linear equations;montaje;systeme lineaire;procede fabrication;combinatorial optimization;modeling;data structure;methode simplexe;flot reseau;proceso fabricacion;optimizacion combinatoria	Fang and Qi (Optim. Methods Softw. 18:143–165, 2003) introduced a new generalized network flow model called manufacturing network flow model for manufacturing process modeling. A key distinguishing feature of such models is the assembling of component raw-materials, in a given proportion, into an end-product. This assembling operation cannot be modeled using usual generalized networks (which allow gains and losses in flows), or using multi-commodity networks (which allow flows of multiple commodity types on a single arc). The authors developed a networksimplex-based algorithm to solve a minimum cost flow problem formulated on such a generalized network and indicated systems of linear equations that need to be solved during the course of the network-simplex-based solution procedure. In this paper, it is first shown how various steps of the network-simplex-based solution procedure can be performed efficiently using appropriate data structures. Further, it is also shown how the resulting system of linear equations can be solved directly on the generalized network.	algorithm;data structure;flow network;linear equation;minimum-cost flow problem;process modeling;system of linear equations	Prahalad Venkateshan;Kamlesh Mathur;Ronald H. Ballou	2008	J. Comb. Optim.	10.1007/s10878-007-9080-6	mathematical optimization;flow network;data structure;minimum-cost flow problem;combinatorial optimization;mathematics;algorithm	Robotics	18.654799721628866	7.694809897780629	150641
9a546f9f43508247be39ddaa039b49df6c057ac5	constraint satisfaction algorithms	search problem;arbre recherche;research tree;satisfaccion coaccion;marquage arriere;algorithmes de consistance d arc;probleme de satisfaction des contraintes;forward checking;intelligence artificielle;problema investigacion;constraint satisfaction;algorithme;resolucion problema;algorithmes de consistance de reseau;algorithm;satisfaction contrainte;network consistency algorithms;arbol investigacion;tree search algorithms;backjumping;backmarking;retour arriere;backtracking;artificial intelligence;arc consistency algorithms;constraint satisfaction problem;inteligencia artificial;probleme recherche;saut arriere;problem solving;resolution probleme;algoritmo;algorithmes de recherche arborescente;verification avant	Constraint satisfaction problems are ubiquitous in artificial intelligence and many algorithms have been developed for their solution. This paper provides a unified survey of some of these, in terms of three classes: ( i ) tree search, ( i i ) arc consistency (AC), and (iii) hybrid tree search/arc consistency algorithms. It is shown that several important algorithms, when slightly rearranged, are of the latter hybrid form, but with arc consistency components that d o not necessarily achieve full arc consistency at the tree nodes. Accordingly, we define several new partial AC procedures, ACYs, AC1/4, ACY3, and AC1/2, analogous to the well-knownfull AC algorithms which Mackworth has called ACI, AC2, and AC3. The fractional suffixes on our AC algorithms are roughly proportional to the degree of partial arc consistency they achieve. Unlike traditional versions, our AC algorithms (full and partial) are presented in a parameterized form to allow them to be embedded efficiently at the nodes of a tree search process. Algorithm complexities are compared empirically, using the n-queens problem and a new version called confused n-queens. Gaschnig’s Backmarking (a tree search algorithm) and Haralick’s Forward Checking (a hybrid algorithm) are found to be the most efficient. For the hybrid algorithms, we find that it pays to do little arc consistency processing at the nodes, incurring more nodes, but sufficiently reducing the work per node so as to obtain less work over the whole tree. The unified view taken here suggests several new algorithms. Preliminary results show one of these to be the best algorithm so far.	ac (complexity);artificial intelligence;backmarking;constraint satisfaction problem;embedded system;genetic algorithm;hybrid algorithm;local consistency;look-ahead (backtracking);robert haralick;search algorithm;tree traversal;whole earth 'lectronic link	Bernard A. Nadel	1989	Computational Intelligence	10.1111/j.1467-8640.1989.tb00328.x	constraint satisfaction;search problem;computer science;artificial intelligence;backjumping;look-ahead;constraint satisfaction problem;algorithm;backtracking	AI	11.261132481001237	16.819633780445322	150760
3145ddfa8c1bd937b1f8e7d229a2993950a49c89	sequencing of jobs in some production system	approximate algorithm;production system;flow shop scheduling;objective function;scheduling;tabu search;heuristics	We consider a real-life problem of scheduling clients orders in the production of concrete blocks in a factory of building industry. This problem can be modelled as a hybrid  ̄ow shop scheduling problem with mixed no-wait/no-store constraints and mixed bottleneck/non-bottleneck machines. The objective function is to minimize maximum completion time. To solve the problem, we propose an approximation algorithm based on the tabu search approach. Ó 2000 Elsevier Science B.V. All rights reserved.	approximation algorithm;loss function;optimization problem;production system (computer science);real life;scheduling (computing);tabu search	Józef Grabowski;Jaroslaw Pempera	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00224-6	fair-share scheduling;nurse scheduling problem;job shop scheduling;mathematical optimization;real-time computing;flow shop scheduling;dynamic priority scheduling;tabu search;computer science;rate-monotonic scheduling;operations management;genetic algorithm scheduling;heuristics;two-level scheduling;mathematics;scheduling;production system;scheduling;multiprocessor scheduling	AI	15.35157351164887	7.5472142261183714	150779
79644851c6df95521613d4d6a48a23f853a6a014	exact solution procedures for the balanced unidirectional cyclic layout problem	modelizacion;bucle cerrado;dynamic programming;optimisation;programacion dinamica;estacion trabajo;posicionamiento;vehiculo guiado;flexible manufacturing systems;optimizacion;probleme np complet;station travail;transportador;dynamic programming algorithm;localization;layout problem;exact solution;atelier flexible;propiedad material;probleme agencement;conveyor;dynamic program;localizacion;solucion exacta;modelisation;herramienta corte;outil coupe;positioning;workstation;chariot sans conducteur;branch and bound method;localisation;metodo branch and bound;guided vehicle;flexible manufacturing system;vehiculo automatizado;propriete materiau;vehicule guide;programmation dynamique;material flow;closed loop;properties of materials;problema disposicion;sistema flexible produccion;problema np completo;optimization;balanced unidirectional cyclic layout;boucle fermee;methode separation et evaluation;cutting tool;solution exacte;automated guided vehicle;flux matiere;branch and bound;transporteur;modeling;np complete problem;positionnement;flujo materia	In this paper, we consider the balanced unidirectional cyclic layout problem (BUCLP) arising in the determination of workstation locations around a closed loop conveyor system, in the allocation of cutting tools on the sites around a turret, in the positioning of stations around a unidirectional single loop AGV path. BUCLP is known to be NP-Complete. One important property of this problem is the balanced material flow assumption where the material flow is conserved at every workstation. We first develop a branch-and-bound procedure by using the special material flow property of the problem. Then, we propose a dynamic programming algorithm, which provides optimum solutions for instances with up to 20 workstations due to memory limitations. The branch and bound procedure can solve problems with up to 50 workstations.		Temel Öncan;I. Kuban Altinel	2008	European Journal of Operational Research	10.1016/j.ejor.2006.09.094	mathematical optimization;computer science;operations management;dynamic programming;mathematics;algorithm	Theory	18.567372713719173	7.194256631441551	151049
4875789c07f8ee86f1a25d307f1173b52cbc8218	a fuzzy rule for improving the performance of multiobjective job dispatching in a wafer fabrication factory		This paper proposes a fuzzy slack-diversifying fluctuation-smoothing rule to enhance the scheduling performance in a wafer fabrication factory. The proposed rule considers the uncertainty in the remaining cycle time and is aimed at simultaneous improvement of the average cycle time, cycle time standard deviation, the maximum lateness, and number of tardy jobs. Existing publications rarely discusse ways to optimize all of these at the same time. An important input to the proposed rule is the job remaining cycle time. To this end, this paper proposes a self-adjusted fuzzy back propagation network (SA-FBPN) approach to estimate the remaining cycle time of a job. In addition, a systematic procedure is also established, which can solve the problem of slack overlapping in a nonsubjective way and optimize the overall scheduling performance.The simulation study provides evidence that the proposed rule can improve the four performance measures simultaneously.	backpropagation;efx factory;fuzzy rule;quantum fluctuation;scheduling (computing);simulation;slack variable;smoothing;software factory;software propagation;wafer fabrication	Toly Chen;Yi-Chi Wang	2013	J. Applied Mathematics	10.1155/2013/986172	operations research	AI	12.12105759555667	5.84347263430229	151245
455e677075555898e45853f355c66aaa80ac727d	in search of the best constraint satisfaction search	empirical study;search algorithm;constraint satisfaction	We present the results of an empirical study of several constraint satisfaction search algorithms and heuristics. Using a random problem generator that allows us to create instances with given characteristics, we show how the relative performance of various search methods varies with the number of variables, the tightness of the constraints, and the sparseness of the constraint graph. A version of backjumping using a dynamic variable ordering heuristic is shown to be extremely e ective on a wide range of problems. We conducted our experiments with problem instances drawn from the 50% satis able range.	backjumping;backmarking;boolean satisfiability problem;constraint graph;constraint satisfaction;cryptographic service provider;experiment;http 404;heuristic (computer science);look-ahead (backtracking);neural coding;search algorithm	Daniel Frost;Rina Dechter	1994			constraint logic programming;beam search;mathematical optimization;constraint programming;decomposition method;constraint satisfaction;constraint learning;computer science;constraint graph;artificial intelligence;backjumping;machine learning;min-conflicts algorithm;brute-force search;constraint satisfaction dual problem;incremental heuristic search;complexity of constraint satisfaction;empirical research;constraint satisfaction problem;difference-map algorithm;hybrid algorithm;local consistency;backtracking;guided local search;search algorithm	AI	22.168773221067152	6.094131696622489	151325
e6cb6edd73364f98e5615d89ca22cfd5f69bc644	a note on finding one-variable patterns consistent with examples and counterexamples		We consider the problem of finding one-variable patterns consistent with given positive examples and negative examples. We try to give some evidence that the pattern finding problem is computationally difficult by finding an NP-complete graph problem (called MCP) such that the pattern finding problem is a subproblem of MCP. We also give sufficient conditions such that the pattern finding problem is polynomial-time computable and show that some of the conditions are related with solving word-equations in one variable.		Takeshi Koshiba;Kunihiko Hiraishi	2000			counterexample;combinatorics;mathematics	Logic	14.975005033963592	18.039932016348594	151926
2fcf9c6a58a41004447d82f403f41701748d09ca	computationally intelligent online dynamic vehicle routing by explicit load prediction in an evolutionary algorithm	modelizacion;dynamic programming;algoritmo paralelo;regularite;programacion dinamica;parallel algorithm;regularidad;distribucion carga;routing;vehicle routing problem;heuristic method;regularity;routage;metodo heuristico;probleme tournee vehicule;probabilistic approach;problema ruta vehiculo;algorithme parallele;modelisation;probabilistic model;planificacion;distribution temporelle;enfoque probabilista;approche probabiliste;programmation dynamique;distribution charge;algorithme evolutionniste;load distribution;planning;algoritmo evolucionista;methode heuristique;evolutionary algorithm;planification;modeling;distribucion temporal;dynamic optimization;time distribution;enrutamiento;dynamic vehicle routing	In this paper we describe a computationally intelligent approach to solving the dynamic vehicle routing problem where a fleet of vehicles needs to be routed to pick up loads at customers and drop them off at a depot. Loads are introduced online during the actual planning of the routes. The approach described in this paper uses an evolutionary algorithm (EA) as the basis of dynamic optimization. For enhanced performance, not only are currently known loads taken into consideration, also possible future loads are considered. To this end, a probabilistic model is built that describes the behavior of the load announcements. This allows the routing to make informed anticipated moves to customers where loads are expected to arrive shortly. Our approach outperforms not only an EA that only considers currently available loads, it also outperforms a recently proposed enhanced EA that performs anticipated moves but doesn’t employ explicit learning. Our final conclusion is that under the assumption that the load distribution over time shows sufficient regularity, this regularity can be learned and exploited explicitly to arrive at a substantial improvement in the final routing efficiency.	dynamic programming;evolutionary algorithm;evolutionary computation;load balancing (computing);mathematical optimization;statistical model;the times;vehicle routing problem	Peter A. N. Bosman;Han La Poutré	2006		10.1007/11844297_32	planning;statistical model;mathematical optimization;routing;simulation;systems modeling;computer science;artificial intelligence;weight distribution;vehicle routing problem;dynamic programming;evolutionary algorithm;mathematics;parallel algorithm	Robotics	20.0004088405179	6.2390895014683565	152017
406241e44a97d319f6e101b11d4ffd345d0a9975	the impact of fixed and variable costs in a multi-skill project scheduling problem: an empirical study	cost minimization;project scheduling;multi skilled resources	In this paper, we address a cost-oriented multi-skill project scheduling problem. The project consists on a set of activities such that, for some pairs, a start-to-start time dependency exists. The execution of each activity requires several skills. More than one resource of each skill may be required for processing an activity. A pull of multi-skilled resources is assumed. Costs are associated with resource usage and include fixed and variable costs. The former are incurred simply by using the resources; the latter depend on the final makespan of the project. For this problem, a mathematical programming modeling framework is proposed. The ‘natural’ model contains a non-linear objective function which, nonetheless, can be linearized at the expense of one additional set of continuous variables. The linearized model is enhanced using several sets of additional inequalities. The results of an extensive set of computational tests performed with the final model are reported. One major goal is to evaluate the possibility of using an off-the-shelf solver for tackling the problem. Another relevant goal is to understand the extent to which a cost-oriented objective influences the solutions obtained. Accordingly, we compare the solutions obtained using such objective with the solutions obtained using the traditional makespan minimization objective, often considered in project scheduling problems.	schedule (project management);scheduling (computing)	Isabel Correia;Francisco Saldanha-da-Gama	2014	Computers & Industrial Engineering	10.1016/j.cie.2014.03.020	mathematical optimization;simulation;computer science;operations management;schedule	SE	14.75028090228286	6.178876013543492	152224
28c019264f7d3ca9eef439125e6a413c718e7b02	an improved algorithm for module allocation in distributed computing systems	minimisation;distributed system;minimization;modulo;systeme reparti;algorithm performance;cost function;complexite calcul;etude experimentale;resource allocation;probleme np dur;problema np duro;minimizacion;funcion coste;algorithme;asignacion optima;algorithm;np hard problem;search trees;complejidad computacion;sistema repartido;distributed computing system;heterogeneidad;computational complexity;resultado algoritmo;state space;information processing;performance algorithme;allocation optimale;communication cost;fonction cout;asignacion recurso;allocation ressource;optimal allocation;communication;comunicacion;module;estudio experimental;heuristic algorithm;heterogeneity;heterogeneite;algoritmo	We consider the problem of finding an optimal and sub-optimal allocation of program modules onto processors of a distributed computing system. A module causes two types of cost to be incurred at the processor to which it is allocated?an execution cost for processing the module, and a communication cost if the module communicates with other modules which are not allocated to the same processor. The distributed computing system is heterogeneous, that is, both costs vary from processor to processor. Certain constraints, such as storage and load constraints, may be present at each processor. Our aim is to allocate the modules to the processors in an optimal manner, that is, the sum of execution and communication costs over all processors should be the minimum possible, without violating any of the constraints. It is an NP-hard problem and we use a state space search technique?theA* algorithm to obtain an optimal allocation. We propose a method to reduce the number of nodes generated in the search tree. The distributed computing system model that we have considered here is the same as that considered by Chernet al. (Inform. Process. Lett.32(2) (July 1989), 61?71). Through simulations over a wide range of parameters, we have compared our method with that of in Chernet al. We also present a heuristic algorithm which obtains sub-optimal allocations in a reasonable amount of computation time.		Tom P. Ajith;Chebiyyam Siva Ram Murthy	1997	J. Parallel Distrib. Comput.	10.1006/jpdc.1997.1302	heuristic;module;distributed algorithm;minimisation;information processing;resource allocation;computer science;state space;theoretical computer science;heterogeneity;np-hard;mathematics;distributed computing;computational complexity theory;algorithm;modulo	HPC	17.473188084014165	10.97830131996927	152254
177af7153b4fd2c4fc25ceb4eb99afefe16fda93	a competitive algorithm for minimizing weighted flow time on unrelatedmachines with speed augmentation	online algorithm;approximation algorithms;flow time;scheduling;parallel machines;competitive ratio	We consider the online problem of scheduling jobs on unrelated machines so as to minimize the total weighted flow time. This problem has an unbounded competitive ratio even for very restricted settings. In this paper we show that if we allow the machines of the online algorithm to have ε more speed than those of the offline algorithm then we can get an O((1+ε-1)2)-competitive algorithm. Our algorithm schedules jobs preemptively but without migration. However, we compare our solution to an offline algorithm which allows migration. Our analysis uses a potential function argument which can also be extended to give a simpler and better proof of the randomized immediate dispatch algorithm of Chekuri-Goel-Khanna-Kumar for minimizing average flow time on parallel machines.	competitive analysis (online algorithm);dynamic dispatch;online algorithm;online and offline;parameter (computer programming);randomized algorithm;scheduling (computing)	Jivitej S. Chadha;Naveen Garg;Amit Kumar;V. N. Muralidhara	2009		10.1145/1536414.1536506	competitive analysis;out-of-kilter algorithm;online algorithm;mathematical optimization;weighted majority algorithm;computer science;machine learning;distributed computing;parallel algorithm;scheduling;approximation algorithm	Theory	15.902931005023937	11.846941508542423	152392
cdc653d3bf61f40fffdf3e3a8c0c4f7fae3cb506	capacitated network design games with weighted players	game theory;nash equilibrium;computational complexity;price of stability;network design games;series parallel graphs	We consider network design games with weighted players and uniform edge capacities and study their Nash equilibria. In these games, each player has to choose a path from her source to her sink through a network subject to the constraint that the total weight of all players using an edge within their chosen path does not exceed the capacity of the edge. The fixed cost of each edge that is used by some player is shared among the players using the edge by charging each player a fraction of the edge's cost equal to the ratio of her weight to the total weight of all players using the edge. We show that there exist instances of capacitated network design games with weighted players and uniform capacities that do not admit a Nash equilibrium even in the case that all players share the same source and sink. Moreover, we show that it is strongly NP -hard to decide whether a given instance admits a Nash equilibrium even if a feasible solution for the underlying network design problem is guaranteed to exist. In contrast, we prove that, for series-parallel graphs, there always exists a Nash equilibrium whose total cost equals the cost of an optimal solution of the corresponding network design problem and provide an exponential-time algorithm to compute this equilibrium. © 2016 Wiley Periodicals, Inc. NETWORKS, Vol. 682, 141-158 2016	network planning and design	André B. Chassein;Sven Oliver Krumke;Clemens Thielen	2016	Networks	10.1002/net.21689	price of stability;combinatorial game theory;game theory;mathematical optimization;combinatorics;best response;repeated game;mathematical economics;computational complexity theory;sequential game;nash equilibrium	ECom	22.382501597263815	17.88007997426491	152613
1f4d27b0f2f2005350db3dfaf7838da8e5fcf76e	multi-agent a* for parallel and distributed systems	multi agent planning;distributed search;parallel search	Search is among the most fundamental techniques for problem solving, and A* is probably the best known heuristic search algorithm. In this paper we adapt A* to the multiagent setting, focusing on multi-agent planning problems. We provide a simple formulation of multi-agent A*, with a parallel and distributed variant. Our algorithms exploit the structure of multi-agent problems to not only distribute the work efficiently among different agents, but also to remove symmetries and reduce the overall workload. Given a multi-agent planning problem in which agents are not tightly coupled, our parallel version of A* leads to super-linear speedup, solving benchmark problems that have not been solved before. In its distributed version, the algorithm ensures that private information is not shared among agents, yet computation is still efficient – sometimes even more than centralized search – despite the fact that each agent has access to partial information only.	a* search algorithm;agent-based model;benchmark (computing);centralized computing;computation;distributed computing;heuristic;multi-agent system;personally identifiable information;problem solving;speedup	Raz Nissim;Ronen I. Brafman	2012			beam search;distributed algorithm;mathematical optimization;computer science;theoretical computer science;distributed computing;incremental heuristic search	AI	22.07241097631569	4.268946981701851	152722
ed894757dbda80e96527ef076592dc3738f40401	a travelling salesman approach to solve the f	travelling salesman problem;nearest insertion rule;no idle machines;scheduling;permutation flow shop	This paper investigates the F =no-idle=Cmax problem, where machines work continuously without idle time intervals. The idle characteristic is a very strong constraint and it affects seriously the value of Cmax criterion. We treat here only the permutation flow-shop configuration for machine no-idle problems with the objective to minimise the makespan. Based on the idea that this problem can be modelled as a travelling salesman problem, an adaptation of the well-known nearest insertion rule is proposed to solve it. A computational study shows the result quality. 2003 Elsevier B.V. All rights reserved.	akaike information criterion;experiment;heuristic;integer programming;job stream;linear programming;makespan;programming model;rule 184;solver;travelling salesman problem;whole earth 'lectronic link	Nour El Houda Saadani;Alain Guinet;Mohamed Moalla	2005	European Journal of Operational Research	10.1016/j.ejor.2003.08.030	nearest neighbour algorithm;mathematical optimization;computer science;machine learning;mathematics;travelling salesman problem;scheduling;algorithm;3-opt	AI	16.607367840794456	8.354707389645457	152820
0965ed489953c0a20adbecc63ec31c9f234a41ea	robust flows over time: models and complexity results	05c21 flows in graphs;90c05 linear programming;90c59 approximation methods and heuristics;90c46 optimality conditions;duality	We study dynamic network flows with uncertain input data under a robust optimization perspective. In the dynamic maximum flow problem, the goal is to maximize the flow reaching the sink within a given time horizon T , while flow requires a certain travel time to traverse an edge. In our setting, we account for uncertain travel times of flow. We investigate maximum flows over time under the assumption that at most Γ travel times may be prolonged simultaneously due to delay. We develop and study a mathematical model for this problem. As the dynamic robust flow problem generalizes the static version, it is NP-hard to compute an optimal flow. However, our dynamic version is considerably more complex than the static version. We show that it is NP-hard to verify feasibility of a given candidate solution. Furthermore, we investigate temporally repeated flows and show that in contrast to the non-robust case (that is, without uncertainties) they no longer provide optimal solutions for the robust problem, but rather yield a worst case optimality gap of at least T . We finally show that the optimality gap is at most O(ηk log T ), where η and k are newly introduced instance characteristics and provide a matching lower bound instance with optimality gap Ω(log T ) and η = k = 1. The results obtained in this paper yield a first step towards understanding robust dynamic flow problems with uncertain travel times.	best, worst and average case;duality gap;dynamic programming;flow network;mathematical model;mathematical optimization;maximum flow problem;np-hardness;robust optimization;traverse	Corinna Gottschalk;Arie M. C. A. Koster;Frauke Liers;Britta Peis;Daniel Schmand;Andreas Wierz	2018	Math. Program.	10.1007/s10107-017-1170-3	mathematical optimization;simulation;mathematics	Theory	20.0113756124035	10.595458130389439	153165
838082eeca30bc8a1c2e39574cc9299cd0258db4	tabu search algorithms for cyclic machine scheduling problems	cycle time;opt connectivity;block approach;tabu search algorithm;cyclic scheduling;job shop problem;job shop;machine scheduling;tabu search;large classes	Cyclic scheduling is concerned with the planning of activities that have to be identically repeated at regular intervals. Such types of scheduling problems arise in different application areas like compiler design, manufacturing, digital signal processing, railway scheduling, timetabling, etc. Despite the variety of applications, the subject has received modest attention in the scheduling literature. The main results can be found in a few papers that have been published during the last ten years.	compiler;digital signal processing;scheduling (computing);tabu search	Peter Brucker;Thomas Kampmeyer	2005	J. Scheduling	10.1007/s10951-005-1639-4	fair-share scheduling;nurse scheduling problem;mathematical optimization;flow shop scheduling;dynamic priority scheduling;tabu search;cycle time variation;computer science;rate-monotonic scheduling;machine learning;two-level scheduling;mathematics	AI	15.594498909301725	8.327782066343064	153221
73c0e673c83c853dd172e977e431aca5072e79f0	star routing: between vehicle routing and vertex cover		We consider an optimization problem posed by an actual newspaper company, which consists of computing a minimum length route for a delivery truck, such that the driver only stops at street crossings, each time delivering copies to all customers adjacent to the crossing. This can be modeled as an abstract problem that takes an unweighted simple graph (G = (V, E)) and a subset of edges X and asks for a shortest cycle, not necessarily simple, such that every edge of X has an endpoint in the cycle.		Diego Delle Donne;Guido Tagliavini	2018		10.1007/978-3-030-04651-4_35	combinatorics;discrete mathematics;approximation algorithm;vehicle routing problem;truck;computational complexity theory;vertex cover;computer science;graph;optimization problem	Theory	23.86452660235689	17.817198606648848	153349
bbcc349a804a093a28c8b43ce69f9f9188eb9fe1	approximate strong equilibria in job scheduling games with two uniformly related machines	scheduling;games;approximate strong nash equilibrium	We consider approximate strong equilibria (SE) in strategic job scheduling games with two uniformly related machines. Jobs are assigned to machines, and each job wishes to minimize its cost, given by the completion time of the machine it is assigned to. Finding a Nash equilibrium (NE) in this game is simple. However, NE-configurations are not stable against coordinated deviations of several jobs. Various measures can be used to evaluate how well an NE-configuration approximates SE. A schedule is said to be an α-SE if there is no coalitional deviation such that every member of the coalition reduces its cost by a factor greater than α. We show that any pure NE on two related machines of speed ratio s is a s 2 +s−1 s2 ≤ 5 4 -SE, and provide a matching lower bound. In addition, we show that the LPT (Longest Processing Time) algorithm provides a better approximation ratio than a general NE, in particular, any LPT schedule is a 1.1011-SE. This is in contrast to the LS (List Scheduling) greedy algorithm for which the improvement ratio of coalitional deviations can be arbitrarily large. In addition, we design a fully polynomial time approximation scheme (FPTAS), which computes an NE that is a (1 + ε)-SE. We also provide bounds for two other measures of approximate SE, considering the supremum possible improvement of a deviating job and the maximal increase in the cost of non-coalition members, and show that checking whether a specific schedule is an SE is co-NP-complete, which motivates the study of approximate strong equilibria. Finally, we consider multiple machines. We show that any pure NE on m related machines is a 2-SE. We give improved results for identical machines, and in particular, we show that any pure NE is a 1.32-SE. © 2013 Elsevier B.V. All rights reserved.	approximation algorithm;co-np;co-np-complete;greedy algorithm;job (computing);job scheduler;job shop scheduling;list scheduling;maximal set;np-completeness;nash equilibrium;parallel port;polynomial;polynomial-time approximation scheme;scheduling (computing);time complexity	Leah Epstein;Michal Feldman;Tami Tamir;Lukasz Witkowski;Marcin Witkowski	2013	Discrete Applied Mathematics	10.1016/j.dam.2013.02.035	games;mathematical optimization;combinatorics;mathematics;mathematical economics;scheduling;algorithm	Theory	14.99321740547268	11.768176254274813	153389
94b6ca355ce087dc40fe9e5e86d3c9551f5dc3a0	a general framework for handling commitment in online throughput maximization		We study a fundamental online job admission problem where jobs with deadlines arrive online over time at their release dates, and the task is to determine a preemptive single-server schedule which maximizes the number of jobs that complete on time. To circumvent known impossibility results, we make a standard slackness assumption by which the feasible time window for scheduling a job is at least 1+ ε times its processing time, for some ε > 0. We quantify the impact that different provider commitment requirements have on the performance of online algorithms. Our main contribution is one universal algorithmic framework for online job admission both with and without commitments. Without commitment, our algorithm with a competitive ratio of O(1/ε) is the best possible (deterministic) for this problem. For commitment models, we give the first non-trivial performance bounds. If the commitment decisions must be made before a job’s slack becomes less than a δ -fraction of its size, we prove a competitive ratio of O(ε/((ε − δ )δ )), for 0 < δ < ε . When a provider must commit upon starting a job, our bound is O(1/ε2). Finally, we observe that for scheduling with commitment the restriction to the “unweighted” throughput model is essential; if jobs have individual weights, we rule out competitive deterministic algorithms. Department of Computer Science, University of Houston, Texas, United States. Email: chenlin198662@gmail.com. Department for Mathematics and Computer Science, University of Bremen, Germany. Email: {feberle,nicole.megow}@uni-bremen.de. Supported by the German Science Foundation (DFG) under contract ME 3825/1. Fakultät für Informatik, Technische Universität München, München, Germany; Département d’Informatique, École Normale Supérieure, PSL University, Paris, France. Email: kschewior@gmail.com. Supported by Conicyt Grant PII 20150140 and DAAD PRIME program. Department of Industrial Engineering and Operations Research, Columbia University, New York, United States. Email: cliff@ieor.columbia.edu. Research supported in part by NSF grants CCF-1421161 and CCF-1714818.	columbia (supercomputer);competitive analysis (online algorithm);computer science;email;entropy maximization;gesellschaft für informatik;ibm notes;industrial engineering;job stream;online algorithm;operations research;personally identifiable information;requirement;scheduling (computing);server (computing);slack variable;throughput	Lin Chen;Franziska Carola Eberle;Nicole Megow;Kevin Schewior;Clifford Stein	2018	CoRR			Theory	14.439987848856989	11.53384523222012	153449
52b4ccc793114421e97c7501d77270b9963495a4	fuzzy grid scheduling using tabu search	grid scheduling;processor scheduling algorithm;fuzzy reasoning;processor scheduling;fuzzy grid scheduling;fuzzy job completion time;uncertainty handling fuzzy reasoning fuzzy set theory grid computing processor scheduling search problems;uncertainty handling;fuzzy job completion time fuzzy grid scheduling tabu search algorithm processor scheduling algorithm fuzzy sets uncertainty modelling;fuzzy set theory;fuzzy sets;tabu search algorithm;tabu search;search problems;grid computing;processor scheduling fuzzy sets grid computing genetic algorithms scheduling algorithm uncertainty simulated annealing instruments robustness shape;uncertainty modelling	This paper considers the problem of grid scheduling in which different jobs are assigned to different processors, and a scheduling algorithm is devised, using tabu search, to find optimal solutions in order to maximize the number of scheduled jobs. However, inherent in the nature of the application, the processing times of jobs are not precise but are estimates that vary between minimal values, in case of premature failure of jobs, to maximal values as specified 'a priori' by well-experienced users. Fuzzy methodology becomes instrumental in this application as it allows the use of fuzzy sets to represent the processing times of jobs, modelling their uncertainty. This work presents the implementation of a tabu search algorithm to create good schedules and explores the robustness of the schedule when processing times do vary by assessing its performance in both fuzzy and crisp modes. Finally, the impact of changing the shapes of fuzzy completion times and the average job length on the schedule performance is discussed.	central processing unit;fuzzy concept;fuzzy set;job stream;maximal set;scheduling (computing);search algorithm;tabu search	Carole Fayad;Jonathan M. Garibaldi;Djamila Ouelhadj	2007	2007 IEEE International Fuzzy Systems Conference	10.1109/FUZZY.2007.4295513	mathematical optimization;real-time computing;computer science;artificial intelligence;fuzzy number;machine learning;fuzzy set;fuzzy set operations	HPC	13.068241496279073	7.5921984708504535	153889
9ebfac1971d8f99cfb2d3329e56bde450063c705	minimizing the total completion time on-line on a single machine, using restarts	tiempo total acabamiento;completion time;machine unique;temps total achevement;randomised algorithms;temps achevement;algorithme deterministe;algorithme randomise;deterministic algorithms;single machine;maquina unica;makespan;randomized algorithm;competitive ratio	We give an algorithm to minimize the total completion time on-line on a single machine, using restarts, with a competitive ratio of 3/2. The optimal competitive ratio without using restarts is 2 for deterministic algorithms and e/(e - 1) ? 1.582 for randomized algorithms. This is the first restarting algorithm to minimize the total completion time that is proved to be better than an algorithm that does not restart.		Rob van Stee;Han La Poutré	2002		10.1007/3-540-45749-6_75	competitive analysis;job shop scheduling;mathematical optimization;computer science;randomized algorithm;algorithm	HCI	16.962592671564412	10.63677844011258	153964
432883cd1bc47cd4faffe76e81cabd1afb7c3f21	on splittable and unsplittable flow capacitated network design arc-set polyhedra	multicommodity flow;optimisation;network design;polyedre;optimizacion;poliedro;branching;temps lineaire;branch and cut method;problema np duro;polyhedron;valid inequalities;methode separation et coupe;tiempo lineal;optimization problem;np hard problem;flujo red;computer experiment;probleme np difficile;ramificacion;linear time;ramification;optimization;network flow;branch and cut;flot reseau;unsplittable flow problem	We study the polyhedra of splittable and unsplittable single arc–set relaxations of multicommodity flow capacitated network design problems. We investigate the optimization problems over these sets and the separation and lifting problems of valid inequalities for them. In particular, we give a linear–time separation algorithm for the residual capacity inequalities [19] and show that the separation problem of c–strong inequalities [7] isNP–hard, but can be solved over the subspace of fractional variables only. We introduce two classes of inequalities for the unsplittable flow problems. We present a summary of computational experiments with a branch-and-cut algorithm for multicommodity flow capacitated network design problems to test the effectiveness of the results presented here empirically.	algorithm;branch and cut;computation;experiment;lifting scheme;mathematical optimization;network planning and design;polyhedron;time complexity	Alper Atamtürk;Deepak Rajan	2002	Math. Program.	10.1007/s101070100269	time complexity;optimization problem;mathematical optimization;network planning and design;combinatorics;flow network;computer experiment;multi-commodity flow problem;branching;np-hard;mathematics;ramification;algorithm;branch and cut;polyhedron	Theory	22.318314189057222	12.500484239064424	154080
07e8055ea78cd970f28bb020864dc5c8996ee5e5	tight sum-of-squares lower bounds for binary polynomial optimization problems	sos lasserre hierarchy lift and project methods binary polynomial optimization;004	We give two results concerning the power of the Sum-Of-Squares(SoS)/Lasserre hierarchy. For binary polynomial optimization problems of degree 2d and an odd number of variables n, we prove that (n+ 2d− 1)/2 levels of the SoS/Lasserre hierarchy are necessary to provide the exact optimal value. This matches the recent upper bound result by Sakaue, Takeda, Kim and Ito. Additionally, we study a conjecture by Laurent, who considered the linear representation of a set with no integral points. She showed that the Sherali-Adams hierarchy requires n levels to detect the empty integer hull, and conjectured that the SoS/Lasserre rank for the same problem is n− 1. We disprove this conjecture and derive lower and upper bounds for the rank. 1998 ACM Subject Classification Optimization, Convex programming, Integer programming	apple sos;convex optimization;integer programming;mathematical optimization;optimization problem;polynomial;sum-of-squares optimization	Adam Kurpisz;Samuli Leppänen;Monaldo Mastrolilli	2016		10.4230/LIPIcs.ICALP.2016.78	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;algorithm	Theory	24.606571704120643	14.611143545361061	154225
8ca48813cb76240f5a7c57988f653718fd1aa9ef	weighted geometric set cover via quasi-uniform sampling	epsilon nets;set covering problem;approximation;sampling methods;set cover;large classes	There has been much progress on geometric set cover problems, but most known techniques only apply to the unweighted setting. For the weighted setting, very few results are known with approximation guarantees better than that for the combinatorial set cover problem. In this article, we employ the idea of quasi-uniform sampling to obtain improved approximation guarantees in the weighted setting for a large class of problems for which such guarantees were known in the unweighted case. As a consequence of this sampling method, we obtain new results on the fractional set cover packing problem.	approximation;sampling (signal processing);set cover problem;set packing	Kasturi R. Varadarajan	2010		10.1145/1806689.1806777	mathematical optimization;combinatorics;discrete mathematics;set packing;covering problems;computer science;mathematics;set cover problem;algorithm	Theory	21.903253255855574	16.805032958841814	154228
c4613abb26898ff9e9e2fbbaf163e428114b06b4	characterization of all ρ-approximated sequences for some scheduling problems	manufacturing systems;optimal solution;lattices job shop scheduling processor scheduling real time systems polynomials schedules;permutation lattice ρ approximated sequence characterization scheduling problems polynomial time solvability production manufacturing system;computer experiment;scheduling;polynomial time;scheduling problem;manufacturing system;scheduling manufacturing systems	Some scheduling problems present the peculiarity to be solvable in polynomial time and to have a huge number of optimal solutions. In the disturbed environment of a production manufacturing system, where the forecasted schedule is going to change because of unexpected events or uncertainties, it can be interesting not only to know one or several optimal sequences, but the characteristics of ‘good’ sequences. In this paper, we focus on the characterization of all the p-approximated sequences, which are solutions of a scheduling problem with a performance not worse than a given distance from the value of the optimal solution. With the support of the lattice of permutations, we define the characteristics of the optimal sequences for some particular scheduling problems. We present a method which is able, for some specific scheduling problems, to give the characteristics of all the p-approximated sequences. A computational experience is carried out to evaluate the performance of the proposed method.	ambiguous name resolution;approximation algorithm;branch and bound;computation;constraint programming;decision problem;discrete optimization;experiment;iteration;linear programming;mathematical optimization;np-hardness;natural deduction;optimization problem;risk management;scheduling (computing);time complexity	Jean-Charles Billaut;Pierre Lopez	2011	ETFA2011	10.1109/ETFA.2011.6059026	fair-share scheduling;nurse scheduling problem;time complexity;fixed-priority pre-emptive scheduling;job shop scheduling;open-shop scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;computer experiment;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;two-level scheduling;stride scheduling;gain scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling;multiprocessor scheduling;i/o scheduling	Theory	15.212202296101795	8.981273720407179	154695
f6f8c1caf81b26310caae5f16e1f4fb48c980969	heuristic algorithms for scheduling an automated wet-etch station	computacion informatica;grupo de excelencia;simulated annealing;ciencias basicas y experimentales;batch process;quimica;scheduling problem;tabu search;job scheduling;heuristic algorithm	Wet-etching is a key step in wafer fabrication. A wet-etch station is a chemical batch process involving a complex interplay of mixed intermediate storage (MIS) policies and a shared robot for wafer transfers. Its operation poses a challenging resource-constrained scheduling problem that is crucial for enhancing productivity, improving yield and minimizing contamination. In this paper, we develop three new algorithms for scheduling wafer jobs for a given sequence, which comfortably outperform a literature algorithm in terms of solution quality without requiring excessive effort. Furthermore, we propose a simulated annealing (SA) algorithm for sequencing the wafer jobs. Using this SA algorithm, an existing sequencing algorithm based on tabu search (TS), two job-scheduling algorithms and two algorithms for initial job sequence, we identify eight complete algorithms for scheduling operations in an automated wet-etch station (AWS). After a thorough numerical evaluation, we conclude that the TS sequencing strategy combined with two of our three job-scheduling algorithms is the best option that yields up to 25–30% lower makespans than a literature algorithm, and requires acceptable computing times for industrial-scale problems. © 2003 Elsevier Ltd. All rights reserved.	algorithm;amazon web services;batch processing;debian;etching (microfabrication);heuristic;isotropic etching;numerical analysis;scheduling (computing);simulated annealing;tabu search;wafer (electronics);wafer fabrication	Swarnendu Bhushan;Iftekhar A. Karimi	2004	Computers & Chemical Engineering	10.1016/S0098-1354(03)00192-3	heuristic;fair-share scheduling;job shop scheduling;mathematical optimization;real-time computing;flow shop scheduling;simulated annealing;dynamic priority scheduling;tabu search;computer science;rate-monotonic scheduling;job scheduler;batch processing	AI	13.34740845028343	5.340773332156431	155217
521b5a1c152e143a7beeafa6e9a306ef1ea76889	models and tabu search metaheuristics for service network design with asset-balance requirements	modelizacion;transportation network;service network design;network design;metaheuristics;red transporte;exigence;frameworks;asset management;asset;conception;requirement;result;transporte mercaderia;methode calcul;algorithme;metodo calculo;modelisation;algorithm;design conservation constraints;transport marchandise;mathematical models;actif;exigencia;diseno;activo;resultado;design;tabu search;services;resultat;freight transportation;modeling;constraints;computing method;busqueda tabu;recherche tabou;reseau transport;algoritmo	This paper focuses on a generic model for service network design, which includes asset positioning and utilization through constraints on asset availability at terminals. We denote these relations as “design-balance constraints” and focus on the design-balanced capacitated multi-commodity network design model, a generalization of the capacitated multi-commodity network design model generally used in service network design applications. Both arc and cycle-based formulations for the new model are presented. The paper also proposes a Tabu Search meta-heuristic framework for the arcbased formulation. Results on a wide range of network design problem instances from the literature indicate the proposed method behaves very well in terms of computational efficiency and solution quality.	algorithm;computation;diversification (finance);feasible region;heuristic;logistics;metaheuristic;network planning and design;requirement;solver;sparse matrix;tabu search	Michael Berliner Pedersen;Teodor Gabriel Crainic;Oli B. G. Madsen	2009	Transportation Science	10.1287/trsc.1080.0234	design;mathematical optimization;network planning and design;simulation;tabu search;computer science;engineering;operations management;requirement;operations research;asset;metaheuristic	EDA	18.231652427981256	5.50513712740797	155256
66b0a7c3f090e07f7b7da397ac4867da2b95d39c	a polynomial time algorithm for unloading boxes off a gravity conveyor	dynamic programming;unloading;boxes;gravity conveyor	In this paper, we study the problem introduced by Baptiste et al. (2011) [3] of minimizing the number of steps to unload a set of boxes off a gravity conveyor. We show that this problem can be solved in polynomial time with a dynamic programming algorithm that runs inO  n3A log F  time,where n is the number of boxes initially lined up on the conveyor, A is the size of the accessible zone, and F is the forklift capacity. © 2013 Elsevier B.V. All rights reserved.	color;dynamic programming;experiment;online algorithm;p (complexity);time complexity	Pierre Baptiste;Alain Hertz;André Linhares;Djamal Rebaine	2013	Discrete Optimization	10.1016/j.disopt.2013.07.004	mathematical optimization;simulation;dynamic programming;mathematics;algorithm	AI	18.576837548378432	12.350300255165502	155314
8c54f9b1a8e6428ed64ae8e730867ea6d4ec9c0c	computing exact and approximate nash equilibria in 2-player games	nash equilibrium;best approximation;nash equilibria;objective function;polynomial time algorithm;normal form;linear program;bimatrix game	The problem of computing a Nash equilibrium in a normal form 2-player game (or bimatrix games) is PPAD-complete in general, while it can be efficiently solved in a special subclass which we call regular bimatrix games. The current best approximation algorithm, proposed in [19], achieves a guarantee of 0.3393. In this paper we design a polynomial time algorithm for computing exact and approximate Nash equilibria for bimatrix games. The novelty of this contribution is twofold. For regular bimatrix games, it allows to compute equilibria whose payoffs optimize any objective function and meet any set of constraints which can be expressed through linear programming, while, in the general case, it computes α-approximate Nash equilibria, where α is the maximum difference between any two payoffs in the same strategy of any player. Hence, our algorithm improves the best know approximation guarantee for the bimatrices in which α < 0.3393.	nash equilibrium	Vittorio Bilò;Angelo Fanelli	2010		10.1007/978-3-642-14355-7_7	price of stability;epsilon-equilibrium;mathematical optimization;combinatorics;best response;linear programming;lemke–howson algorithm;mathematics;correlated equilibrium;risk dominance;normal-form game;mathematical economics;nash equilibrium	ECom	18.065016227731643	16.14071308699635	155443
b09660332c7bd4a67eddf6e0780eb6c89dc78672	a minimum cost multicast routing algorithm with the consideration of dynamic user membership	metodo relajacion;on line systems;optimisation;formal model;optimizacion;routing;heuristic method;subgradient method;multidestinatario;routage;metodo heuristico;lagrange multiplier;random networks;methode relaxation;multicast tree;tree algorithm;optimization problem;planificacion;lagrangean relaxation;computer experiment;methode lagrange;systeme en ligne;relaxation method;diffusion donnee;metodo lagrange;multiplicateur lagrange;difusion dato;multiplicador lagrange;algorithme en arbre;lagrangian method;planning;optimization;methode heuristique;algoritmo del arbol;data broadcast;planification;multicast routing;multidestinataire;multicast;enrutamiento	In this paper, we attempt to solve the problem of constructing a minimum cost multicast tree with the consideration of dynamic user membership. Unlike the other minimum cost multicast tree algorithms, this problem consists of one multicast group of fixed members and each destination member is dynamic and has a probability of being active as which was gathered by observation over some period of time. With the omission of node join/leave handling, this model is suitable for prediction and planning purpose than for online maintenance of multicast trees. We formally model this problem as an optimization problem and apply the Lagrangean relaxation method and the subgradient method to solve the problem. Computational experiments are performed on regular networks and random networks. According to the experiment results, the Lagrangean based heuristic can achieve up to 37.69% improvement compared to the simple heuristic.	algorithm;multicast	Frank Yeong-Sung Lin;Hsu-Chen Cheng;Yao-Jung Yeh	2005		10.1007/978-3-540-30582-8_27	planning;optimization problem;mathematical optimization;routing;combinatorics;multicast;computer experiment;computer science;subgradient method;mathematics;lagrange multiplier;relaxation;algorithm;xcast	EDA	20.74134552936989	8.01536783443357	155583
1f766a17d704250ddfdb1eba713c9176edefd574	logistics scheduling with batching and transportation	reglamento discontinuo;performance measure;metodo polinomial;performance guarantee;completion time;sequencage;approximate algorithm;problema transporte;transportation problem;logistique;batch production;probleme transport;batching;moyen transport;approximation algorithm;medio transporte;hd28 management industrial management;procede discontinu;temps achevement;en discontinuo;hf commerce;delai livraison;distribution cost;sequencing;produccion por lote;logistics;cout distribution;polynomial method;polynomial algorithm;transportation;production par lot;problem complexity;batch scheduling;algoritmo aproximacion;batch process;plazo entrega;scheduling problem;procedimiento discontinuo;transport costs;algorithme approximation;ordonnancement discontinu;methode polynomiale;tiempo acabado;transportation mode;delivery lead time;en discontinu;batchwise;logistica	We study a general two-stage scheduling problem, in which jobs of different importance are processed in the first stage on a processor and then, in the second stage, the completed jobs need to be batch delivered to various prespecified destinations in one of a number of available transportation modes. Our objective is to minimize the sum of weighted job delivery time and total transportation cost. The problem involves not only the traditional performance measurement, such as weighted completion time, but also transportation arrangement and cost, key factors in logistics management. We draw an overall picture of the problem complexity for various cases of problem parameters accompanied by efficient algorithms for solvable cases. On the other hand, we provide for the most general case an approximation algorithm of performance guarantee. Bio: Bo Chen is Professor of Operational Research, Warwick Business School, University of Warwick. He received his PhD in Operational Research from Erasmus University, The Netherlands, and since then has been faculty of the University of Warwick. He was ESRC Senior Management Research Fellow (UK) during 19972000, Visiting Professor of Stanford University (US) in 2003, and Chair Professor of Tsinghua University (China) in 2005. He has been Fellow of the UK Operational Research Society since 2002. His research interests include scheduling theory and applications, real-time optimization, combinatorial optimization and decision analysis.	approximation algorithm;chen–ho encoding;combinatorial optimization;decision analysis;decision problem;entity–relationship model;job stream;logistics;mathematical optimization;open-shop scheduling;operations research;real-time clock;scheduling (computing)	Bo Chen;Chung-Yee Lee	2008	European Journal of Operational Research	10.1016/j.ejor.2006.11.047	transportation theory;logistics;transport;mathematical optimization;simulation;computer science;operations management;job scheduler;sequencing;mathematics;operations research;approximation algorithm;batch processing	Theory	16.729129322645022	8.976118184435201	155592
14c16c6a814a3940a210a0e27dcb4b8d427d892b	stable marriage and roommates problems with restricted edges: complexity and approximability		In the Stable Marriage and Roommates problems, a set of agents is given, each of them having a strictly ordered preference list over some or all of the other agents. A matching is a set of disjoint pairs of mutually acceptable agents. If any two agents mutually prefer each other to their partner, then they block the matching, otherwise, the matching is said to be stable. We investigate the complexity of finding a solution satisfying additional constraints on restricted pairs of agents. Restricted pairs can be either forced or forbidden. A stable solution must contain all of the forced pairs, while it must contain none of the forbidden pairs. Dias et al. (2003) gave a polynomial-time algorithm to decide whether such a solution exists in the presence of restricted edges. If the answer is no, one might look for a solution close to optimal. Since optimality in this context means that the matching is stable and satisfies all constraints on restricted pairs, there are two ways of relaxing the constraints by permitting a solution to: (1) be blocked by as few as possible pairs, or (2) violate as few as possible constraints n restricted pairs. Our main theorems prove that for the (bipartite) Stable Marriage problem, case (1) leads to NP-hardness and inapproximability results, whilst case (2) can be solved in polynomial time. For non-bipartite Stable Roommates instances, case (2) yields an NP-hard but (under some cardinality assumptions) 2-approximable problem. In the case of NP-hard problems, we also discuss polynomially solvable special cases, arising from restrictions on the lengths of the preference lists, or upper bounds on the numbers of restricted pairs. © 2016 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/) ✩ A preliminary version of this paper appeared in the Proceedings of SAGT 2015: The 8th International Symposium on Algorithmic Game Theory. ∗ Correspondence to: School of Computer Science, Reykjavik University, Menntavegur 1, 101 Reykjavik, Iceland. E-mail addresses: cseh@math.tu-berlin.de (Á. Cseh), David.Manlove@glasgow.ac.uk (D.F. Manlove). http://dx.doi.org/10.1016/j.disopt.2016.03.002 1572-5286/© 2016 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/) Á. Cseh, D.F. Manlove / Discrete Optimization 20 (2016) 62–89 63	approximation algorithm;blocking (computing);decision problem;hardness of approximation;linear programming;list of macintosh software;maxima and minima;minimum-weight triangulation;np-hardness;olami–feder–christensen model;ordered pair;polynomial;stable marriage problem;time complexity;while	Ágnes Cseh;David Manlove	2015		10.1007/978-3-662-48433-3_2	mathematical optimization;combinatorics;discrete mathematics;stable marriage problem;mathematics;stable roommates problem	Theory	18.56290074522552	17.636187510508936	155620
3340d323aca8b001a6667364b541fbd6eddff837	constraint satisfaction - algorithms and complexity analysis	constraint propagation;algorithm analysis;complexite calcul;analysis and design;contrainte;combinatorial problems;complexity analysis;constraint satisfaction;combinatorial problem;coherence globale;probleme combinatoire;finite domain;problema combinatorio;computational complexity;probleme satisfaction contrainte;analysis and design of algorithms;analyse algorithme;constraint satisfaction problem;network structure;global consistency;analisis algoritmo;stresses	"""The constraint satisfaction problem (CSP) comprises n variables with associated nite domains (with a maximal cardinality d), and some combinations of value assignments (\constraints"""") to the variables; then, in order to get the globally consistent solution, we need to compute the set of all n-tuples consistent with the given constraints. There are a lot of papers which exploit speciic constraint network structures; others focus on local constraint propagation. However, nally, the global solution is wanted, and in this regard, I would like to introduce here a general framework which really yields this globally consistent solution. It is well-known that local consistency does not imply global consistency. Anyway, to start directly with a higher-level mechanism may not be a bad idea. The algorithms presented here may get consulted when nothing can be exploited regarding network topology or other features. Remark This report may supersede #14/90. The current issue (#17/94) is a slight update of the following work: On global constraint satisfaction."""	algorithm;analysis of algorithms;constraint satisfaction problem;local consistency;maximal set;network topology;software propagation	Walter Hower	1995	Inf. Process. Lett.	10.1016/0020-0190(95)00089-U	constraint logic programming;constraint programming;combinatorics;binary constraint;average-case complexity;constraint satisfaction;constraint learning;computer science;constraint graph;worst-case complexity;constraint satisfaction dual problem;mathematics;complexity of constraint satisfaction;constraint;computational complexity theory;asymptotic computational complexity;constraint satisfaction problem;algorithm;hybrid algorithm;local consistency	AI	19.70172347936878	12.471629571953576	155626
0d577c6cfdeead84a7cb05f8fa602b2317398234	branch-and-cut approaches for chance-constrained formulations of reliable network design problems		We study solution approaches for the design of reliably connected networks. Specifically, given a network with arcs that may fail at random, the goal is to select a minimum cost subset of arcs such the probability that a connectivity requirement is satisfied is at least 1− , where is a risk tolerance. We consider two types of connectivity requirements. We first study the problem of requiring an s-t path to exist with high probability in a directed graph. Then we consider undirected graphs, where we require the graph to be fully connected with high probability. We model each problem as a stochastic integer program with a joint chance constraint, and present two formulations that can be solved by a branch-and-cut algorithm. The first formulation uses binary variables to represent whether or not the connectivity requirement is satisfied in each scenario of arc failures and is based on inequalities derived from graph cuts in individual scenarios. We derive additional valid inequalities for this formulation and study their facetinducing properties. The second formulation is based on probabilistic graph cuts, an extension of graph cuts to graphs with random arc failures. Inequalities corresponding to probabilistic graph cuts are sufficient to define the set of feasible solutions and can be separated efficiently at integer solutions, allowing this formulation to be solved by a branch-and-cut algorithm. Computational results demonstrate that the approaches can effectively solve instances on large graphs with many failure scenarios. In addition, we demonstrate that, by varying the risk tolerance, our model yields a rich set of solutions on the efficient frontier of cost and reliability.	algorithm;branch and cut;computation;cut (graph theory);directed graph;graph (discrete mathematics);integer programming;network planning and design;random graph;requirement;risk aversion;with high probability	Yongjia Song;James R. Luedtke	2013	Math. Program. Comput.	10.1007/s12532-013-0058-3	mathematical optimization;combinatorics;discrete mathematics;connectivity;mathematics;voltage graph	Theory	23.25282021519299	16.819691529015707	155628
81deddb2326913f86ba786a0d8b97445c1fd02b4	on the complexity of minimizing the total calibration cost		Bender et al. (SPAA 2013) proposed a theoretical framework for testing in contexts where safety mistakes must be avoided. Testing in such a context is made by machines that need to be often calibrated. Since calibrations have non negligible cost, it is important to study policies minimizing the calibration cost while performing all the necessary tests. We focus on the single-machine setting and we study the complexity status of different variants of the problem. First, we extend the model by considering that the jobs have arbitrary processing times and that the preemption of jobs is allowed. For this case, we propose an optimal polynomial time algorithm. Then, we study the case where there is many types of calibrations with different lengths and costs. We prove that the problem becomes NP-hard for arbitrary processing times even when the preemption of the jobs is allowed. Finally, we focus on the case of unit-time jobs and we show that a more general problem, where the recalibration of the machine is not instantaneous, can be solved in polynomial time.		Eric Angel;Evripidis Bampis;Vincent Chau;Vassilis Zissimopoulos	2017		10.1007/978-3-319-59605-1_1	mathematical optimization;time complexity;calibration;mathematics;preemption	Theory	14.74997485602168	10.53903007224148	155639
a03d2bbf3b761b6fb78a25917265c7ae477b8ada	an evolutionary algorithm for sequencing production on a paced assembly line	and simulation;manufacturing;genetic algorithm;heuristics;operations and logistics management assembly systems;evolutionary algorithm	A new sequencing method for mixed-model assembly lines is developed and tested. This method, called the Evolutionary Production Sequencer (EPS) is designed to maximize production on an assembly line. The performance of EPS is evaluated using three measures: minimum cycle time necessary to achieve 100% completion without rework, percent of items completed without rework for a given cycle time, and sequence “smoothness.” The first two of these measures are based on a simulated production system. Characteristics of the system, such as assembly line station length, assembly time and cycle time, are varied to better gauge the performance of EPS. More fundamental variation is studied by modeling two production systems. In one set of tests, the system consists of an assembly line in isolation (i.e., a single-level system). In another set of tests, the production system consists of the assembly line and the fabrication system supplying components to the line (i.e., a two-level system). Sequence smoothness is measured by the mean absolute deviation (MAD) between actual component usage and the ideal usage at each point in the production sequence. The performance of EPS is compared to those of well-known assembly line sequencing techniques developed by Miltenburg (1 989), Okamura and Yamashina (1979), and Yano and Rachamadugu (1991). EPS performed very well under all test conditions when the criterion of success was either minimum cycle time necessary to achieve 100% production without rework or percent of items completed without rework for a given cycle time. When MAD was the criterion of success, EPS was found inferior to the Miltenburg heuristic but better than the other two production-oriented techniques. Subject Areas: Evolutionary Algorithm, Genetic Algorithm, Heuristics, Manufacturing, Operations and Logistics Management: Assembly Systems, and Simulation.	assembly language;evolutionary algorithm;genetic algorithm;heuristic (computer science);line level;mad;mixed model;multi-level cell;production system (computer science);rework (electronics);simulation	Robert T. Sumichrast;Keith A. Oxenrider;Edward R. Clayton	2000	Decision Sciences	10.1111/j.1540-5915.2000.tb00928.x	simulation;genetic algorithm;computer science;artificial intelligence;operations management;heuristics;evolutionary algorithm;manufacturing	Robotics	12.813532674424536	4.629055868323662	155859
da47449c4b653340accaebfe95c8f52621e6dbd4	interdicting a nuclear-weapons project	ciblage;modelizacion;defense;resource limitation;optimisation;aplicacion militar;completion time;interdiction;off the shelf equipment;government defense foreign policy;application militaire;project management;tiempo diferido;programacion entera;nuclear weapon;optimizacion;cascade structures;personal computer;economic sciences;cascade;project manager;foreign policy;weapons of mass destruction;government;grupo de excelencia;temps achevement;defense systems;weapon;maximin problem;programming integer linear;programmation en nombres entiers;politique gouvernementale;critical path method;enrichment;modelisation;integer;arma nuclear;nuclear weapons;ciencias economicas;probleme maximin;blancado;targeting;programacion lineal;delayed time;integer programming;estudio caso;ciencias basicas y experimentales;cpm;matematicas;enrichissement;cascada;government policies;project management cpm;etude cas;military application;problema maximin;linear programming;arma;armement nucleaire;programmation lineaire;gestion projet;military;optimization;metodo camino critico;software tools;temps retard;sciences economiques;military targeting;delay time;linear;arme;grupo a;tiempo acabado;modeling;tiempo retardo;programming;off the shelf;enriquecimiento;military government;temps differe;methode chemin critique;gestion proyecto	A “proliferator” seeks to complete a first small batch of fission weapons as quickly as possible, whereas an “interdictor” wishes to delay that completion for as long as possible. We develop and solve a max-min model that identifies resourcelimited interdiction actions that maximally delay completion time of the proliferator’s weapons project, given that the proliferator will observe any such actions and adjust his plans to minimize that time. The model incorporates a detailed project-management (critical path method) submodel, and standard optimization software solves the model in a few minutes on a personal computer. We exploit off-the-shelf project-management software to manage a database, control the optimization, and display results. Using a range of levels for interdiction effort, we analyze a published case study that models three alternate uranium-enrichment technologies. The task of “cascade loading” appears in all technologies and turns out to be an inherent fragility for the proliferator at all levels of interdiction effort. Such insights enable policy makers to quantify the effects of interdiction options at their disposal, be they diplomatic, economic, or military.	critical path method;database;gene ontology term enrichment;mathematical optimization;maxima and minima;personal computer;singlet fission	Gerald G. Brown;W. Matthew Carlyle;Robert C. Harney;Eric M. Skroch;R. Kevin Wood	2009	Operations Research	10.1287/opre.1080.0643	project management;mathematical optimization;simulation;integer programming;nuclear weapon;linear programming;operations management;critical path method;mathematics;foreign policy;management;operations research;algorithm	DB	17.408120292297045	5.844070017586647	155877
ffc1d29bd4c580532b2c496b787e2f01d7fc024f	scheduling two machines that require multiple types of maintenance, for a single operation	optimal solution;maintenance;heuristic method;operations research;objective function;schedule;heuristics;state transition	The problem explored was of using two machines, one at a time, to perform a continuous operation, where each machine is subject to different types and lengths of maintenance. The operation periods between maintenance periods can also vary in length. All the periods are deterministic in length. When the last period ends, the first period starts again. The objective is to maximize the portion of time with an operating machine. We conjecture this is an NP problem. This problem extends the study by J. Kreimer and A. Mehrez (European Journal of Operational Research 69 (1993) 50–54) on an  n -machine single type of maintenance scheduling (MS) problem. The no-interrupt policy, that was optimal for their problem is not optimal for ours. Properties of the optimal solution and identification of the state transition mechanism lead to a finite, but exponentially bounded, algorithm that constructs cyclic solutions. Heuristic methods are recommended and tested for small-sized problems. They achieve, on an average, more than 99% of the highest objective function value found by the algorithm, and equal that value in 55–80% of the random problems. The most efficient heuristic method consists of the SPT scheduling rule.	scheduling (computing)	Gad Rabinowitz;Shai Goren;Abraham Mehrez	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00338-0	mathematical optimization;operations management;heuristics;mathematics;schedule	HPC	15.309115152835686	8.785153920547764	156122
465cc5dc616f47842beab22c2bff01a02cc2714f	optimal university course timetables and the partial transversal polytope	university course timetabling;partial transversal polytope;soft constraints;valid inequalities;integer programming;integer program	University course timetabling is the conflict-free assignment of courses to weekly time slots and rooms subject to various hard and soft constraints. One goal is to meet as closely as possible professors’ preferences. Building on an intuitive integer program (IP), we develop an exact decomposition approach which schedules courses first, and matches courses/times to rooms in a second stage. The subset of constraints which ensures a feasible room assignment defines the well-known partial transversal polytope. We describe it as a polymatroid, and thereby obtain a complete characterization of its facets. This enables us to add only strong valid inequalities to the first stage IP. In fact, for all practical purposes the number of facets is small. We present encouraging computational results on real-world and simulated timetabling data. The sizes of our optimally solvable instances (respecting all hard constraints) are the largest reported in the literature by far.	computation;decision problem;integer programming;polymatroid;schedule;whole earth 'lectronic link	Gerald Lach;Marco E. Lübbecke	2008		10.1007/978-3-540-68552-4_18	mathematical optimization;combinatorics;mathematics;algorithm		19.24591445164204	10.493538133815338	156185
20af81fb08b853d53a47ca4b0972105e91a0ff6f	approximation schemes for scheduling	randomized algorithms;approximation algorithms;least median of squares regression;robust estimation;line fitting;load management;schedules;approximation scheme;algorithms;load balance;machinery;line arrangements;mathematics computers information science management law miscellaneous	We consider the classic scheduling/load balancing problems where there are m identical machines and n jobs, and each job should be assigned to some machine. Traditionally, the assignment of jobs to machines is measured by the makespan (maximum load) i.e., the L, norm of the assignment. An Eapproximation scheme was given by Hochbaum and Shmoys [lo] for minimizing the L, norm. In several applications, such as in storage allocation, a more appropriate measure is the sum of the squares of the loads (which is equivalent to the Lz norm). This problem was considered in [4, 5, 131 who showed how to approximate the optimum value by a factor of about 1.04. In fact, a more general measure, which is the L, norm (for any p 1 1) can also be approximated to some constant (see Chandra and Wong [4]) which may be as large as 3/2. We improve these results by providing an +approxim&ion scheme for the general L, norm (and in particular for the Lz norm). We also consider the case of restricted assignment of unit jobs where we show how to find in polynomial time, a solution which is optimal for all norms.	approximation algorithm;job stream;l (complexity);load balancing (computing);makespan;polynomial;scheduling (computing);t-norm;time complexity	Noga Alon;Yossi Azar;Gerhard J. Woeginger;Tal Yadid	1997			mathematical optimization;combinatorics;machine;discrete mathematics;schedule;computer science;load balancing;mathematics;randomized algorithm;approximation algorithm;algorithm	Theory	15.378749956416334	10.995763297008383	156190
3982df01df393e9245c79680a03352e67b6bd57f	extracting microstructure in binary constraint networks	constraint satisfaction problem;microstructures	We present algorithms that perform the extraction of partial assignments from binary Constraint Satisfaction Problems without introducing new constraints. They are based on a new perspective on domain values: we view a value not as a single, indivisible unit, but as a combination of value fragments. Applications include removing nogoods while maintaining constraint arity, learning nogoods in the constraint network, enforcing on neighborhood inverse consistency and removal of unsolvable sub-problems from the constraint network.	algorithm;binary constraint;constraint satisfaction problem;dynamic problem (algorithms);heuristic (computer science);indivisible	Chavalit Likitvivatanavong;Roland H. C. Yap	2006		10.1007/978-3-540-73817-6_8	constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;combinatorics;discrete mathematics;binary constraint;decomposition method;constraint satisfaction;constraint learning;constraint graph;constraint satisfaction dual problem;mathematics;complexity of constraint satisfaction;constraint;constraint satisfaction problem;hybrid algorithm;local consistency;backtracking	AI	11.588235131602481	15.581581652363427	156325
104fbbcba8042772680e3982f640539f0d5a389d	the application of actor-critic reinforcement learning for fab dispatching scheduling		This paper applies Actor-Critic reinforcement learning to control lot dispatching scheduling in reentrant line manufacture model. To minimize the Work-In-Process(WIP) and Cycle Time(CT), the lot dispatching policy is directly optimized through Actor-Critic algorithm. The results show that the optimized dispatching policy yields smaller average WIP and CT than traditional dispatching policy such as Shortest Processing Time, Latest-Step-First-Served, and Least-Work-Next-Queue.	algorithm;reentrancy (computing);reinforcement learning;scheduling (computing);semiconductor fabrication plant	Namyong Kim;Hayong Shin	2017	2017 Winter Simulation Conference (WSC)	10.1109/WSC.2017.8248209	real-time computing;simulation;reentrancy;computer science;scheduling (computing);reinforcement learning	HPC	11.755081211139467	5.575623414067873	156354
6a21d9cbfc2166bbceb67b8064ce58b4c6dd472d	solving graph coloring problems using cultural algorithms		In this paper, we combine a novel Sequential Graph Coloring Heuristic Algorithm (SGCHA) with a non-systematic method based on a cultural algorithm to solve the graph coloring problem (GCP). The GCP involves finding the minimum number of colors for coloring the graph vertices such that adjacent vertices have distinct colors. In our solving approach, we first use an estimator which is implemented with SGCHA to predict the minimum colors. Then, in the non-systematic part which has been designed using cultural algorithms, we improve the prediction. Various components of the cultural algorithm have been implemented to solve the GCP with a self adaptive behavior in an efficient manner. As a result of utilizing the SGCHA and a cultural algorithm, the proposed method is capable of finding the solution in a very efficient running time. The experimental results show that the proposed algorithm has a high performance in time and quality of the solution returned for solving graph coloring instances taken from DIMACS website. The quality of the solution is measured here by comparing the returned solution with the optimal one.	adaptive behavior;color;cultural algorithm;games computers play;graph coloring;heuristic (computer science);neighbourhood (graph theory);time complexity	Reza Abbasian;Malek Mouhoub;Amin Jula	2011			graph power;mathematical optimization;factor-critical graph;graph bandwidth;fractional coloring;theoretical computer science;complete coloring;edge coloring;graph coloring;voltage graph;list coloring;complement graph;greedy coloring;strength of a graph	AI	24.423983409795586	5.318388410648083	156485
4226974de1c99a0cf4f19c01e397983691fa8ac7	algoritmo aleatorizado basado en distribuciones deslizantes para el problema de planificación en sistemas grid	randomized algorithm;grid	In this paper we present a randomized algorithm for the online version of the Job Shop problem where jobs are composed of processes with precedence constraints and processors are organized in a Grid topology. The proposed randomized algorithm is based on a new technique that we have denominated as sliding distributions, which aims at combining the advantages of the deterministic approximation algorithms with those of the Montecarlo randomized algorithms. The objective is to provide an algorithm that delivers ρ-approximated solutions with high probability, but at the same time, is able to investigate an extended neighborhood of such solutions so that it can escape from local extrema. We formally characterize the temporal complexity of the proposed algorithm and show that it is correct. We also evaluate the performance of the proposed algorithm by means of a series of simulation-based experiments. The results show that the proposed algorithm outperforms the traditional state of the art algorithms for scheduling in Grid systems. The performance metrics are average delay, maximum delay, and Grid utilization.	approximation algorithm;central processing unit;experiment;job shop scheduling;job stream;maxima and minima;monte carlo;randomized algorithm;scheduling (computing);simulation;with high probability	Hector Julian Selley-Rojas;Jesus Garcia-Diaz;Manuel A. Soto-Ramos;Felipe R. Menchaca-Garcia;Rolando Menchaca-Méndez	2015	Computación y Sistemas		mathematical optimization;computer science;mathematics;distributed computing;randomized algorithm;grid;algorithm	EDA	16.115626649181294	11.540217395055395	156815
0e692fb3f49f71b5e9472fe7f1326abb01bcad40	a class of inverse dominant problems under weighted l ∞ norm and an improved complexity bound for radzik's algorithm	linear fractional combinatorial optimization;improvement problem;combinatorial optimization problem;dominating set;polynomial time algorithm;inverse problem;dominant set;polynomial time;combinatorial optimization;large classes	In this paper, we first discuss a class of inverse dominant problems under weighted l? norm, which is how to change the original weights of elements with bounds in a finite ground set so that a given set becomes a weakly dominant set with respect to a given collection of subsets under the new weights and the largest change of the weights is minimum. This model includes a large class of improvement problems in combinatorial optimization. We propose a Newton-type algorithm for the model. This algorithm can solve the model in strongly polynomial time if the subproblem involved is solvable in strongly polynomial time. In the second part of the paper, we improve the complexity bound for Radzik's Newton-type method which is designed to solve linear fractional combinatorial optimization problems. As Radzik's method is closely related to our algorithm, this bound also estimates the complexity of our algorithm.	algorithm	Qin Wang;Xiaoguang Yang;Jianzhong Zhang	2006	J. Global Optimization	10.1007/s10898-005-1649-y	time complexity;optimization problem;mathematical optimization;combinatorics;discrete mathematics;dominating set;combinatorial optimization;inverse problem;mathematics	Theory	23.37579384868213	15.070772123692675	156948
de095bd527cf8beaaa44886b4f9fa284138a55f8	extracting subgraphs by mixed integer programming for discrete design of truss structures	open source software subgraph extraction mixed integer programming truss structure discrete structure design potential bar mip glpk gnu linear programming kit;supports bars design engineering graph theory integer programming linear programming structural engineering	In this paper, we consider a discrete design problem of two-dimensional truss structures. We are given a set of potential nodes and a set of potential bars connecting these nodes, i.e., a ground structure. Then we only treat solutions which are combinations of accepted nodes and accepted bars in the ground structure. We present a linear inequality system with integrality constraints to extract a subgraph from the ground structure, which tries to model the subgraph on a simple truss. The linear inequality system delivers a MIP (Mixed Integer Programming) formulation of the discrete design problem. We also conduct numerical experiments to examine the solutions obtained by solving the MIP problem, and report some valid examples. The test problem instances are exactly solved by GLPK (GNU Linear Programming KIT), which is one of well-known open source softwares solving MIP and LP (Linear Programming) problems.	experiment;gnu linear programming kit;integer programming;linear inequality;numerical analysis;open-source software;social inequality	Atsushi Yamada;Yoshiyuki Karuno	2012	The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems	10.1109/SCIS-ISIS.2012.6505136	mathematical optimization;combinatorics;integer programming;computer science;branch and price;machine learning;mathematics;algorithm	EDA	24.3496623052593	9.403796280367402	156989
462045a0866158fc43f24546e32a41bb9f101149	on the separation in 2-period double round robin tournaments with minimum breaks	separation;breaks;sports scheduling;constraint programming;round robin tournament	This paper considers the separation in 2-period double round robin tournaments (2P-DRRTs) with minimum breaks. The separation is a lower bound on the number of slots between the two games with the same opponents. None of known schemes provides 2P-DRRTs with minimum breaks and a positive separation. We first propose a new scheme to generate 2-separation 2P-DRRTs with minimum breaks, based on single round robin tournaments (SRRTs) with minimum breaks which have the last break in the third slot from the end. Our experiment results show that such SRRTs exist for 8–68 teams. Secondly, we consider maximizing the separation in general 2P-DRRTs with minimum breaks by integer programming and constraint programming, respectively. The two approaches of direct formulation and ‘‘first-break, then-schedule’’ decomposition are presented and compared. We obtain the maximum separation for up to 14 teams. Furthermore, we consider the application with place constraints to show the flexibility and efficiency of scheduling 2P-DRRTs with minimum breaks and a positive separation. & 2011 Elsevier Ltd. All rights reserved.	constraint programming;integer programming;round-robin scheduling;scheduling (computing);single sign-on	Lishun Zeng;Shinji Mizuno	2012	Computers & OR	10.1016/j.cor.2011.10.004	mathematical optimization;constraint programming;simulation;computer science;mathematics	AI	16.91156750894908	7.648853784169719	157060
02fb78a581d77f17629e549f031b2886b3a12ae2	quality of move-optimal schedules for minimizing total weighted completion time	completion time;total weighted completion time;aproximacion optima;heuristic method;machine parallele;temps achevement;metodo heuristico;temps minimal;approximation;busca local;optimal approximation;approximation optimale;90b35;optimal scheduling;minimum time;parallel machines;methode heuristique;tiempo acabado;tiempo minimo;local search;recherche locale	We study the minimum total weighted completion time problem on identical machines. We analyze a simple local search heuristic, moving jobs from one machine to another. The local optima can be shown to be approximately optimal with approximation ratio 3 2 . In a special case, the approximation ratio is 3 2 − 1/ √ 6 ≈ 1.092. © 2005 Elsevier B.V. All rights reserved. MSC: 90B35	approximation algorithm;heuristic;local optimum;local search (optimization);schedule (computer science)	Tobias Brüggemann;Johann Hurink;Walter Kern	2006	Oper. Res. Lett.	10.1016/j.orl.2005.08.003	mathematical optimization;local search;approximation;calculus;mathematics;algorithm	AI	17.471895272701136	9.546542008377713	157262
d9bb827b881a3ed4a136dfe78f8dec2351fcf5b1	empirical investigations on parallelized linkage identification	parallelisme;analisis mecanismo;parallel algorithm;mechanism analysis;paralelisacion;resolucion problema;temps calcul;estimation of distribution algorithm;parallelism;analyse mecanisme;paralelismo;biomimetique;parallelisation;parallel computer;parallelization;tiempo computacion;computation time;problem solving;resolution probleme;biomimetics	To solve GA-difficult problems in which we cannot ensure tight linkage in their encoding, advanced methods such as linkage iden- tification techniques and estimation of distribution algorithms work ef- fectively although they need some additional computational cost. The computation time can be reduced by employing parallel computers and several approaches have been proposed for their parallelized algorithms. This paper presents empirical results on parallelization of the linkage identification compared to that of an estimation of distribution algo- rithm.	linkage (software);parallel computing	Masaharu Munetomo;Naoya Murao;Kiyoshi Akama	2004		10.1007/978-3-540-30217-9_33	biomimetics;estimation of distribution algorithm;computer science;artificial intelligence;theoretical computer science;parallel algorithm;algorithm	NLP	21.585684248318532	5.288456483390307	157282
4b0d99ad8f7f62b5df8b438722a9a4cb38de3677	tracking the frequency moments at all times		The traditional requirement for a randomized streaming alg orithm is justone-shot, i.e., algorithm should be correct (within the stated ε-error bound) at the end of the stream. In this paper, we study the tracking problem, where the output should be correct at all times. The standard approach for solving the tracking problem is to run O(logm) independent instances of the one-shot algorithm and apply the union bound to all m time instances. In this paper, we study if this standard appr oach can be improved, for the classical frequency moment problem . We show that for theFp problem for any1 < p ≤ 2, we actually only needO(log logm+logn) copies to achieve the tracking guarantee in the cash register model, where n is the universe size. Meanwhile, we present a lower bound of Ω(logm log logm) bits for all linear sketches achieving this guarantee. This s ows that our upper bound is tight whenn = (logm). We also present an Ω(log m) lower bound in the turnstile model, showing that the standard approach by using the union bou d is essentially optimal.	moment problem;randomized algorithm;streaming algorithm;turnstile	Zengfeng Huang;Wai Ming Tai;Ke Yi	2014	CoRR		mathematical optimization;combinatorics;mathematics;algorithm;statistics	Theory	16.714109566993553	15.346993258831962	157290
24e251a5d72fe33963a536e32f408bf2c8758185	scheduling-lps bear probabilities: randomized approximations for min-sum criteria	performance guarantee;completion time;preemptive scheduling;approximate algorithm;generic model;gestion labor;randomized approximation algorithm;temps achevement;optimisation combinatoire;gestion tâche;scheduling;indexation;scheduling problem;list scheduling;min sum;parallel machines;ordonamiento;task scheduling;combinatorial optimization;algoritmo optimo;algorithme optimal;optimal algorithm;ordonnancement;optimizacion combinatoria	In this paper, we provide a new class of randomized approximation algorithms for scheduling problems by directly interpreting solutions to so-called time-indexed LPs as probabilities. The most general model we consider is scheduling unrelated parallel machines with release dates (or even network scheduling) so as to minimize the average weighted completion time. The crucial idea for these multiple machine problems is not to use standard list scheduling but rather to assign jobs randomly to machines (with probabilities taken from an optimal LP solution) and to perform list scheduling on each of them. For the general model, we give a (2+ e)-approximation algorithm. The best previously known approximation algorithm has a performance guarantee of 16/3 [HSW96]. Moreover, our algorithm also improves upon the best previously known approximation algorithms for the special case of identical parallel machine scheduling (performance guarantee (2.89 + e) in general [CPS+96] and 2.85 for the average completion time [CMNS97], respectively). A perhaps surprising implication for identical parallel machines is that jobs are randomly assigned to machines, in which each machine is equally likely. In addition, in this case the algorithm has running time O(nlogn) and performance guarantee 2. The same algorithm also is a 2-approximation for the corresponding preemptive scheduling problem on identical parallel machines. Finally, the results for identical parallel machine scheduling apply to both the off-line and the on-line settings with no difference in performance guarantees. In the on-line setting, we are scheduling jobs that continually arrive to be processed and, for each time t, we must construct the schedule until time t without any knowledge of the jobs that will arrive afterwards.	approximation algorithm;job stream;list scheduling;machin-like formula;norm (social);online and offline;parallel computing;randomized algorithm;randomness;scheduling (computing);single-machine scheduling;time complexity	Andreas S. Schulz;Martin Skutella	1997		10.1007/3-540-63397-9_32	fair-share scheduling;fixed-priority pre-emptive scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;combinatorial optimization;computer science;rate-monotonic scheduling;operating system;distributed computing;preemption;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling;algorithm;i/o scheduling	Theory	16.00595434449722	11.255171555979244	157303
aa4eff16aa1e2b22b6a5026ab13a8286de34b47e	a dynamic programming algorithm for days-off scheduling with sequence dependent labor costs	dynamic programming;dynamic programming algorithm;dynamic program;satisfiability;labor scheduling;compressed workweek;state constraints;scheduling problem;optimization	This paper presents a dynamic programming (DP) algorithm for solving a labor scheduling problem with several realistic days-off scheduling constraints and a cost structure that depends on the work sequence for each employee. The days-off scheduling constraints include the following: (1) each employee is assigned no more than three workdays per week, (2) each employee is assigned at least two consecutive off days per week, and (3) any work stretch cannot exceed four consecutive workdays. The sequencedependent cost structure assumes that the daily wage of each employee depends on two factors: (1) whether the given workday is weekend or a regular workday, and (2) the sequence of work patterns assigned in previous days. A DP algorithm suited to instances of moderate size is used to determine the optimum work assignments that minimize the total labor cost, while satisfying the work demand under the stated constraints.	computation;davis–putnam algorithm;dynamic programming;experiment;integer programming;real life;requirement;scheduling (computing)	Moustafa Elshafei;Hesham K. Alfares	2008	J. Scheduling	10.1007/s10951-007-0040-x	fair-share scheduling;job shop scheduling;mathematical optimization;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;dynamic programming;mathematics	AI	14.700449711338024	9.210682819407596	157502
b3a207bdceffb41d7e1da6ca7c213e7b7c4eafd6	scheduling with release dates on a single machine to minimize total weighted completion time	methode branch and bound;optimisation;completion time;optimizacion;limite inferior;heuristic method;temps achevement;metodo heuristico;machine;experimental result;release date;algorithme;algorithm;maquina;branch and bound method;single machine;metodo branch and bound;scheduling;resultado experimental;ordonamiento;optimization;methode heuristique;resultat experimental;limite inferieure;ordonnancement;lower bound;algoritmo;job splitting	This paper considers the problem of scheduling jobs with release dates on a single machine to minimize the total weighted completion time. A branch and bound algorithm is proposed which incorporates three special features that contribute to its efficiency. Firstly, quickly computed lower bounds are obtained using a procedure which is based on job splitting. The job splitting methodology is shown to be applicable to a range of total weighted completion time scheduling problems. Secondly, the branching rule includes a release date adjustment mechanism which increases release dates at certain nodes of the tree with a view to tightening lotver bounds. Thirdly, the branch and bound algorithm includes a ne.< dominance rule for eliminating nodes of the search tree. Computational experience on problems 4th up to 50 jobs indicates that the proposed algorithm is superior to other known algorithms.	algorithm;branch and bound;computation;job stream;open-shop scheduling;scheduling (computing);search tree;software release life cycle	Hocine Belouadah;Marc E. Posner;Chris N. Potts	1992	Discrete Applied Mathematics	10.1016/0166-218X(92)90255-9	mathematical optimization;machine;mathematics;upper and lower bounds;scheduling;algorithm	Theory	17.293295158078504	9.547889241953623	157713
4ff7175ca7e7e0482442ec3660a9bb105d7804bf	branch-and-price and beam search algorithms for the variable cost and size bin packing problem with optional items	bin packing;beam search;column generation;branch and price	In the Variable Cost and Size Bin Packing Problem with optional items, a set of items characterized by volume and profit and a set of bins of different types characterized by volume and cost are given. The goal consists in selecting those items and bins which optimize an objective function which combines the cost of the used bins and the profit of the selected items. We propose two methods to tackle the problem: branch-and-price as an exact method and beam search as a heuristics, derived from the branch-and-price. Our branch-and-price method is characterized by a two level branching strategy. At the first level the branching is performed on the number of available bins for each bin type. At the second level it consists on pairs of items which can or cannot be loaded together. Exploiting the branch-and-price skeleton, we then present a variegated beam search heuristics, characterized by different beam sizes. We finally present extensive computational results which show a high accuracy of the exact method and a very good efficiency of the proposed heuristics.	beam search;bin packing problem;branch and cut;branch and price;column generation;computation;computer science;exact algorithm;heuristic (computer science);logistics;loss function;operations research;optimization problem;optimizing compiler;search algorithm;set packing	Mauro Maria Baldi;Teodor Gabriel Crainic;Guido Perboli;Roberto Tadei	2014	Annals OR	10.1007/s10479-012-1283-2	column generation;beam search;mathematical optimization;bin packing problem;computer science;branch and price;operations management;mathematics	AI	16.325674988224176	5.994241848853809	157912
1f44c448fcba1207cbc4d2e94c1269dd460cb508	minimizing the weighted number of tardy task units	imprecise computation;preemptive schedule;weighted number;feasible schedule;late task;on-time task;tardy task unit;tardy task units;single processor	The problem of minimizing the weighted number of tardy task units on a single processor is considered. We give an O(nlog n + kn)-time algorithm for a set of n tasks with k distinct weights. The relation of this problem with that of minimizing the total weighted error in the imprecise computation model is also discussed.	algorithm;model of computation;time complexity	Joseph Y.-T. Leung;Vincent K. M. Yu;W.-D. Wei	1994	Discrete Applied Mathematics	10.1016/0166-218X(92)00037-M	mathematical optimization;combinatorics;mathematics;algorithm	Theory	15.794554501725065	10.157955336272455	158227
31befef4b332e981b67657882e1f5df38847d91c	multiclass job scheduling on a single machine: updating optimal control strategies when due-dates change in real-time	dynamic programming;single machine scheduling closed loop systems dynamic programming optimal control;theoretical framework;single machine scheduling;cost function;job shop scheduling;closed loop systems;real time;closed loop control;dynamic program;optimal control;single machine;loop scheduling;vectors;sufficient conditions multiclass job scheduling single machine optimal control control theoretic framework closed loop control open loop scheduling decisions dynamic programming;process control;optimal control real time systems job shop scheduling single machine scheduling cost function process control vectors;job scheduling;real time systems	The problem of scheduling jobs, belonging to different classes, on a single machine, can be dealt with under a control-theoretic framework, with the aim of determining optimal (closed-loop) control strategies, instead of optimal (open-loop) scheduling decisions. In the model considered by the authors, optimal control strategies can be determined through a constructive procedure, based on the application of dynamic programming. However, in the case that one or more due-dates change in real-time, the strategies (determined off-line and used in real-time to find, at each decision instant, the optimal actions to be adopted) may become invalid. In this paper, sufficient conditions about the validity of the optimal control strategies are provided, in connection with some specific cases of change of due-dates; moreover, the algorithm to be used to determine the new strategies, when these conditions are violated, is also provided in the paper.	algorithm;automated reasoning;dynamic programming;i/o request packet;job scheduler;job stream;loop scheduling;online and offline;optimal control;real-time clock;real-time transcription;scheduling (computing);theory	Davide Giglio;Riccardo Minciardi	2011	IEEE Conference on Decision and Control and European Control Conference	10.1109/CDC.2011.6161086	control engineering;job shop scheduling;mathematical optimization;real-time computing;optimal control;computer science;job scheduler;dynamic programming;process control;control theory;mathematics	Robotics	10.881597500372056	7.476220593042621	158536
3325c87270bb0f7c42e4f6f76fc0a9d0c7e70341	single machine scheduling with precedence constraints and positionally dependent processing times	t technology general;single machine scheduling;learning;positionally dependent processing time;qa75 electronic computers computer science;precedence constraints;scheduling;precedence constraint;deterioration	In many real-life situations the processing conditions in scheduling models cannot be viewed as given constants since they vary over time thereby affecting actual durations of jobs. We consider single machine scheduling problems of minimizing the makespan in which the processing time of a job depends on its position (with either cumulative deterioration or exponential learning). It is often found in practice that some products are manufactured in a certain order implied, for example, by technological, marketing or assembly requirements. This can be modeled by imposing precedence constraints on the set of jobs. We consider scheduling models with positional deterioration or learning under precedence constraints that are built up iteratively from the prime partially ordered sets of a bounded width (this class of precedence constraints includes, in particular, series-parallel precedence constraints). We show that objective functions of the considered problems satisfy the job module property and possess the recursion property. As a result, the problems under consideration are solvable in polynomial time.	scheduling (computing);single-machine scheduling	Alexandre Dolgui;Valery S. Gordon;Vitaly A. Strusevich	2012	Computers & OR	10.1016/j.cor.2010.06.004	mathematical optimization;real-time computing;computer science;scheduling;precedence diagram method	Arch	15.039581189778263	9.441802504779824	158544
d68a23de92537eff68254c4ea2749c0c18ca0282	improving time bounds on maximum generalised flow computations by contracting the network	previous best time bound;m3 log b;improving time bounds;supply-scaling algorithm;m2n log b;interior-point method;maximum generalised network flow;maximum generalised flow;resulting algorithm;supply-scaling algorithmic framework;network-modification operation;maximum generalised flow computations;network flow;interior point method	We consider the maximum generalised network flow problem and a supply-scaling algorithmic framework for this problem. We present  three network-modification operations, which may significantly decrease the size of the network when the remaining node supplies  become small. We use these three operations in Goldfarb, Jin and Orlin’s supply-scaling algorithm and prove a Õ(m  2  n log B) bound on the running time of the resulting algorithm. The previous best time bounds on computing maximum generalised flows  were the O(m  1.5  n  2 log B) bound of Kapoor and Vaidya’s algorithm based on the interior-point method, and the Õ(m  3 log B) bound of Goldfarb, Jin and Orlin’s algorithm.  	computation	Tomasz Radzik	2002		10.1007/3-540-45465-9_52	mathematical optimization;flow network;computer science;linear programming;calculus;mathematics;approximation algorithm;algorithm	Theory	21.379322628895874	17.910328874910935	158808
ca3b36a3713da470b120d8109773e06b145dcba0	subquadratic submodular function minimization		Submodular function minimization (SFM) is a fundamental discrete optimization problem which generalizes many well known problems, has applications in various fields, and can be solved in polynomial time. Owing to applications in computer vision and machine learning, fast SFM algorithms are highly desirable. The current fastest algorithms [Lee, Sidford, Wong, 2015] run in <i>O</i>(<i>n</i><sup>2</sup>log<i>nM</i>Â·+<i>n</i><sup>3</sup>log<sup><i>O</i>(1)</sup><i>nM</i>) time and <i>O</i>(<i>n</i><sup>3</sup>log<sup>2</sup><i>n</i>Â·+<i>n</i><sup>4</sup>log<sup><i>O</i>(1)</sup><i>n</i>)time respectively, where <i>M</i> is the largest absolute value of the function (assuming the range is integers) and is the time taken to evaluate the function on any set. Although the best known lower bound on the query complexity is only Î©(<i>n</i>) [Harvey, 2008], The main contribution of this paper are <em>subquadratic</em> SFM algorithms. For integer-valued submodular functions, we give an SFM algorithm which runs in <i>O</i>(<i>nM</i><sup>3</sup>log<i>n</i>Â·) time giving the first nearly linear time algorithm in any known regime. For real-valued submodular functions with range in [â1,1], we give an algorithm which in Ã(<i>n</i><sup>5/3</sup>Â·/Îµ<sup>2</sup>) time returns an Îµ-additive approximate solution. At the heart of it, our algorithms are projected stochastic subgradient descent methods on the Lovasz extension of submodular functions where we crucially exploit submodularity and data structures to obtain fast, i.e. sublinear time, subgradient updates. The latter is crucial for beating the <i>n</i><sup>2</sup> bound â we show that algorithms which access only subgradients of the Lovasz extension, and these include the empirically fast Fujishige-Wolfe heuristic [Fujishige, 1980; Wolfe, 1976]	approximation algorithm;computer vision;data structure;decision tree model;discrete optimization;fastest;heuristic (computer science);loss function;machine learning;mathematical optimization;optimization problem;polynomial;subderivative;subgradient method;submodular set function;time complexity	Deeparnab Chakrabarty;Yin Tat Lee;Aaron Sidford;Sam Chiu-wai Wong	2017		10.1145/3055399.3055419	mathematical optimization;combinatorics;mathematics;algorithm	Theory	21.12626687623706	17.97907558571137	159041
c3e2325d5c9f5ffd1197581cffe21f34343497d1	possible winners when new candidates are added: the case of scoring rules	economie;cas linguistique;regles;scoring rule;intellect philosophie;economies et finances;addition;intelligence;vote;computational social choice;intelligence periodique	In some voting situations, some new candidates may show up in the course of the process. In this case, we may want to determine which of the initial candidates are possible winners, given that a fixed number k of new candidates will be added. Focusing on scoring rules, we give complexity results for the above possible winner problem.	algorithm;computational complexity theory;email;emoticon;karp's 21 np-complete problems;polynomial;refinement (computing);requirements elicitation;rounding	Yann Chevaleyre;Jérôme Lang;Nicolas Maudet;Jérôme Monnot	2010			scoring rule;intelligence;computer science;artificial intelligence;addition;operations research	ECom	11.053057037412618	16.825911242862933	159272
70e9e6c54e4eca8803fb9cba07ee803bad8f2071	experimental evaluation of interchangeability in soft csps	soft constraints;con straint satisfaction problem;experimental evaluation	Freuder in [9] defined interchangeability for classical Constraint Satisfaction Problems (CSPs). Recently [2], we extended the definition of interchangeability to Soft CSPs and we introduced two notions of relaxations based on degradation δ and on threshold α (neighborhood interchangeability (NI )and α neighborhood interchangeability (αNI )). In this paper we extend the study introduced in [11] and we analyze the presence of the relaxed version of interchangeability in random soft CSPs. We give a short description of the implementation we used to compute interchangeabilities and to make the tests. The experiments show that there is high occurrence of αNI and NI interchangeability around optimal solution in fuzzy CSPs and weighted CSPs. Thus, these algorithms can be used successfully in solution update applications. Moreover, it is also showed that NI interchangeability can well approximate full interchangeability (FI ).	approximation algorithm;constraint satisfaction;elegant degradation;experiment;java;list of algorithms;preprocessor;soft computing	Nicoleta Neagu;Stefano Bistarelli;Boi Faltings	2003		10.1007/978-3-540-24662-6_8	reliability engineering;engineering;data mining;algorithm	AI	11.669911763236492	15.880769543234893	159281
f005c098d40e1a044778549b4d9ede9ca3a60095	on a new class of parallel sequencing situations and related games	cooperative game;cooperative games;scheduling;parallel machines	This paper considers a special class of sequencing situations with two parallel machines in which each agent has precisely two jobs to be processed, one on each machine. The costs of an agent depend linearly on the final completion time of his jobs. We describe a procedure that provides an optimal processing order of the jobs for some particular classes. Furthermore, we study cooperative games arising from these sequencing situations. Our main result will be on the balancedness of these games.	job stream	Pedro C. Calleja;Peter Borm;Herbert Hamers;Flip Klijn;Marco Slikker	2002	Annals OR	10.1023/A:1016360404530	real-time computing;simulation;computer science;distributed computing	ML	14.9240704382467	9.934639726639112	159373
bbad94ae035c938e9cfe43a9006b7aa58b80f456	frontiers of combining systems	software engineering;formal language;artificial intelligent	Cutting planes were introduced in 1958 by Gomory in order to solve integer linear optimization problems. Since then, they have received a lot of interest, not only in mathematical optimization, but also in logic and complexity theory. In this paper, we present some recent results on cutting planes at the interface of logic and optimization. Main emphasis is on the length and the rank of cutting plane proofs based on the Gomory-Chvátal rounding principle.	computational complexity theory;cutting-plane method;integer programming;linear programming;mathematical optimization;rounding	Jan van Leeuwen	2000		10.1007/10720084	computer science;artificial intelligence;algorithm	Logic	24.092818833535855	11.475818225886059	159508
bcdaf894cf5925cd80109e2ae31774ba82985d43	a heuristic for the multi-satellite, multi-orbit and multi-user management of earth observation satellites	search problem;generation colonne;observation par satellite;orbite;generacion columna;observacion por satelite;heuristic method;metodo heuristico;multi user;problema investigacion;satisfiability;satelite;upper bound;planificacion;satellite observation;computer experiment;satellite;tabu search heuristic;scheduling;multiple orbits;planning;tabu search;earth observation;methode heuristique;planification;orbit;probleme recherche;earth observation satellites;ordonnancement;column generation;busqueda tabu;reglamento;recherche tabou;orbita;multiple users	Earth observation satellites are platforms equipped with optical instruments that orbit the Earth in order to take photographs of specific areas at the request of users. This article is concerned with the management of several satellites performing multiple orbits over a given planning horizon. It describes a tabu search heuristic for the problem of selecting and scheduling the requests to be satisfied, under operational constraints. An upper bounding procedure based on column generation is used to evaluate the quality of the solutions. The results of extensive computational experiments performed on data provided by the French Centre National d’Études Spatiales are reported.	column generation;computation;experiment;heuristic;multi-user;scheduling (computing);tabu search	Nicola Bianchessi;Jean-François Cordeau;Jacques Desrosiers;Gilbert Laporte;Vincent Raymond	2007	European Journal of Operational Research	10.1016/j.ejor.2005.12.026	mathematical optimization;simulation;computer science;mathematics;operations research;satellite	Robotics	18.100012651162565	6.222065108707627	159782
b82e3586995af822a3b035bb718a8e5019f83271	inherent limitations of visual search and the role of inner-scene similarity	metric space;information sources;search algorithm;task difficulty;visual search;qualitative modeling;point of view;lower bound	This work focuses on inner-scene objects similarity as an information source for directing attention and for speedingup visual search. A scalar measure (similar to Kolmogorov’s 2-covering of metric spaces) is suggested for quantifying how much a visual search task can benefit from this source of information. The measure provided is algorithm independent, providing an inherent measure for tasks’ difficulty, and can be also used as a predictor for search performance. We show that this measure is a lower bound on all search algorithms performance and provide a simple deterministic algorithm that this measure bounds its performance from above. Since calculating a metric cover is NP-hard, we use both a heuristic and a 2-approximation algorithm for estimating it, in order to test the validity of our theorem on some experimental search tasks. For the same search tasks we show that our suggested algorithm performs as expected. We also suggest a few less tighter bounds which are easier to calculate. Inner-scene-similarity as a measure for search task difficulty was suggested from the psychological point of view by Duncan and Humphreys’ similarity theory[5]. As so, this work can be considered as an attempt to quantify their qualitative model.	approximation algorithm;deterministic algorithm;heuristic;information source;kerrison predictor;list of google products;np-hardness;search algorithm	Tamar Avraham;Michael Lindenbaum	2004		10.1007/978-3-540-30572-9_2	interpolation search;beam search;mathematical optimization;machine learning;mathematics;incremental heuristic search;search algorithm	ML	17.76514745410955	17.17816159712176	159901
f2205761bffae5a7b43a3e3cb2d0b05d30063123	approximation algorithms for $k$ -partitioning problems with partition matroid constraint	approximation algorithm;eptas;fptas;partition matroid	The k-partitioning problem with partition matroid constraint is to partition the union of k given sets of size m into m sets such that each set contains exactly one element from each given set. With the objective of minimizing the maximum load, we present an efficient polynomial time approximation scheme (EPTAS) for the case where k is a constant and a full polynomial time approximation scheme (FPTAS) for the case where m is a constant; with the objective of maximizing the minimum load, we present a 1 k−1 -approximation algorithm for the general case, an EPTAS for the case where k is a constant; with the objective of minimizing the l p-norm of the load vector, we prove that the layered LPT algorithm (Wu and Yao in Theor Comput Sci 374:41–48, 2007) is an all-norm 2-approximation algorithm.	approximation algorithm;parallel port;partition matroid;partition problem;polynomial;polynomial-time approximation scheme;time complexity;yao graph	Weidong Li;Jianping Li	2014	Optimization Letters	10.1007/s11590-013-0637-2	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	18.91612228372527	14.484766514364322	160032
4ba9bd5437da561b9cc60e1789696ffdf239ddf8	scheduling of drone-based material transfer system in semiconductor manufacturing		The idea of deploying unmanned aerial vehicles, also known as drones, for delivery in logistics operations has inspired this research. One conceivable scenario is to use a drone to transfer jobs between locations in a future semiconductor factory. Each job might be characterized by origin, destination, priority, and precedence-relationship. In particular, the precedence-relationship occurs when drones are competing for limited number of ports (similar to helicopter landing platform). The objective is to minimize the maximum completion time of all delivery jobs performed by a fleet of drones. Two exact approaches are presented: a mixed integer programming and a constraint programming, and tested for real-time perspective with problem instances up to 50-drone and 100-job.	constraint programming;integer programming;job stream;linear programming;logistics;real-time locating system;scheduling (computing);semiconductor device fabrication;television antenna;unmanned aerial vehicle	Andy Ham;Dong Jin Kim	2017	2017 Winter Simulation Conference (WSC)	10.1109/WSC.2017.8248085	simulation;computer science;constraint programming;real-time computing;scheduling (computing);robot;port (computer networking);probabilistic logic;drone;integer programming;semiconductor device fabrication	Robotics	12.927522802081265	4.792374746463553	160084
b98dbc6bee39ee068aa41bb53bd34067141cb254	on a stackelberg subset sum game		This contribution deals with a two-level discrete decision problem, a so-called Stackelberg strategic game: A Subset Sum setting is addressed with a set $N$ of items with given integer weights. One distinguished player, the leader, may alter the weights of the items in a given subset $L\subset N$, and a second player, the follower, selects a solution $A\subseteq N$ in order to utilize a bounded resource in the best possible way. Finally, the leader receives a payoff from those items of its subset $L$ that were included in the overall solution $A$, chosen by the follower. We assume that the follower applies a publicly known, simple, heuristic algorithm to determine its solution set, which avoids having to solve NP-hard problems. Two variants of the problem are considered, depending on whether the leader is able to control (i.e., change) the weights of its items (i) in the objective function or (ii) in the bounded resource constraint. The leader's objective is the maximization of the overall weight reduction, for the first variant, or the maximization of the weight increase for the latter one. In both variants there is a trade-off for each item between the contribution value to the leader's objective and the chance of being included in the follower's solution set. We analyze the leader's pricing problem for a natural greedy strategy of the follower and discuss the complexity of the corresponding problems. We show that setting the optimal weight values for the leader is, in general, NP-hard. It is even NP-hard to provide a solution within a constant factor of the best possible solution. Exact algorithms, based on dynamic programming and running in pseudopolynomial time, are provided. The additional cases, in which the follower faces a continuous (linear relaxation) version of the above problems, are shown to be straightforward to solve.	decision problem;dynamic programming;expectation–maximization algorithm;greedy algorithm;heuristic (computer science);linear programming relaxation;loss function;np-hardness;optimization problem;pseudo-polynomial time;subset sum problem	Ulrich Pferschy;Gaia Nicosia;Andrea Pacifici	2018	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2018.07.018	discrete mathematics;subset sum problem;mathematical optimization;decision problem;mathematics;stackelberg competition;stochastic game;bounded function	Theory	19.070473842301165	9.449887708304042	160140
b4cf4b308c686edcee519f8e9e81779bdc62ba42	a simple ptas for the dual bin packing problem and advice complexity of its online version		Recently, Renault (2016) studied the dual bin packing problem in the per-request advice model of online algorithms. He showed that given O(1/ ) advice bits for each input item allows approximating the dual bin packing problem online to within a factor of 1 + . Renault asked about the advice complexity of dual bin packing in the tape-advice model of online algorithms. We make progress on this question. Let s be the maximum bit size of an input item weight. We present a conceptually simple online algorithm that with total advice O ( s+logn 2 ) approximates the dual bin packing to within a 1 + factor. To this end, we describe and analyze a simple offline PTAS for the dual bin packing problem. Although a PTAS for a more general problem was known prior to our work (Kellerer 1999, Chekuri and Khanna 2006), our PTAS is arguably simpler to state and analyze. As a result, we could easily adapt our PTAS to obtain the advice-complexity result. We also consider whether the dependence on s is necessary in our algorithm. We show that if s is unrestricted then for small enough > 0 obtaining a 1+ approximation to the dual bin packing requires Ω (n) bits of advice. To establish this lower bound we analyze an online reduction that preserves the advice complexity and approximation ratio from the binary separation problem due to Boyar et al. (2016). We define two natural advice complexity classes that capture the distinction similar to the Turing machine world distinction between pseudo polynomial time algorithms and polynomial time algorithms. Our results on the dual bin packing problem imply the separation of the two classes in the advice complexity world. 1998 ACM Subject Classification F.2.2 Nonnumerical Algorithms and Problems	approximation algorithm;bin packing problem;complexity class;online algorithm;online and offline;ptas reduction;polynomial;set packing;time complexity;turing machine	Allan Borodin;Denis Pankratov;Amirali Salehi-Abari	2018		10.4230/OASIcs.SOSA.2018.8	online algorithm;time complexity;combinatorics;discrete mathematics;mathematics;bin packing problem;binary logarithm;pseudo-polynomial time;mathematical optimization;complexity class;turing machine;upper and lower bounds	Theory	17.11007797284433	15.567058854959434	160213
6c38cbd7c5aacb1be31b1ba83aaaf1827a15234a	expressing polynomials as the permanent of low rank square matrices	traveling salesman problem;polynomial algorithm;polynomial time;combinatorial optimization	Abstract   It is known that the problem of computing the permanent of a given matrix is #P hard. However, Alexander I. Barvinok has proven that if we fix the rank of the matrix then its permanent can be computed in strongly polynomial time. Barvinok's algorithm [Barvinok, A. I.,  Two algorithmic results for the traveling salesman problem , Math. Oper. Res. 21 (1996), 65–84.] computes the permanent of square matrices of fixed rank by constructing polynomials. We study the problem of expressing polynomials as the permanent of low rank square matrices and vice versa. We prove that the permanent of a square matrix with rank 1 is a monomial and the permanent of a square matrix (with integer entries) that has not full rank, is a polynomial with even coefficients. We also prove that, for a polynomial   f  ∈  k  [  x  ]  , there exist a square matrix of rank 2, whose permanent is the polynomial  f . Our results contribute in computing the permanent of a square matrix efficiently.		Mumtaz Ahmad	2010	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2010.05.010	time complexity;permanent;mathematical optimization;polynomial matrix;combinatorics;discrete mathematics;combinatorial optimization;mathematics;matrix polynomial;characteristic polynomial;travelling salesman problem;square root of a 2 by 2 matrix;algebra	Theory	24.537318308625576	14.462444159675643	160230
c48810b8e9c550148c43590dbc5c53024cbe674d	tree decomposition methods for the periodic event scheduling problem		This paper proposes an algorithm that decomposes the Periodic Event Scheduling Problem (PESP) into trees that can efficiently be solved. By identifying at an early stage which partial solutions can lead to a feasible solution, the decomposed components can be integrated back while maintaining feasibility if possible. If not, the modifications required to regain feasibility can be found efficiently. These techniques integrate dynamic programming into standard search methods. The performance of these heuristics are very satisfying, as the problem using publicly available benchmarks can be solved within a reasonable amount of time, in an alternative way than the currently accepted leading-edge techniques. Furthermore, these heuristics do not necessarily rely on linearity of the objective function, which facilitates the research of timetabling under nonlinear circumstances. 2012 ACM Subject Classification Mathematics of computing → Graph algorithms	algorithm;dynamic programming;heuristic (computer science);loss function;nonlinear system;optimization problem;scheduling (computing);timeline;tree decomposition	Irving van Heuven van Staereling	2018		10.4230/OASIcs.ATMOS.2018.6	event scheduling;periodic graph (geometry);mathematical optimization;computer science;tree decomposition;dynamic programming;linearity;nonlinear system;heuristics	AI	19.068369148522333	10.072407213930099	160386
3f14215b8b5c1b16e19fd834caa1724ce72b39e3	polynomial constraint satisfaction utilizing adaptive dynamic domain reduction	computers;software;program testing automatic test pattern generation computational complexity constraint handling constraint satisfaction problems divide and conquer methods;software testing;feasible area test data generation constraint solving split point;automatic test pattern generation;feasible area;test data generation;adaptive dynamics;testing;satisfiability;constraint satisfaction problems;constraint satisfaction;polynomials;divide and conquer methods;automation failure polynomial constraint satisfaction adaptive dynamic domain reduction automatic test data generation software testing solver vectors addr divide and conquer based method;indexes;program testing;vectors;computational complexity;heuristic algorithms;indexation;constraint handling;constraint solving;vectors heuristic algorithms polynomials software testing indexes computers;divide and conquer;heuristic algorithm;split point	Automation of generating test data is an adequate solution for testing software. Moreover, solving constraints is one of the most important parts of this process. Each constraint is a condition along which there is a vector with different variables' values involves in condition to satisfy the constraint. Despite the fact that previous methods have investigated the solver vectors by decreasing the value's domain, they do not have the capability of finding all solver vectors. This paper proposes Adaptive Dynamic Domain Reduction, which is referred to as ADDR, in order to find all solver vectors related to the polynomial constraints. In the proposed method, each constraint is satisfied utilizing domain reduction or a divide-and-conquer based method. In iterations of algorithm, new domains are defined for variables of a constraint with the results that choosing each arbitrary member of the domain can satisfy constraint. Moreover, union of these domains can find all solver vectors. In order to demonstrate the efficiency of the proposed method, a set of experiments is conducted. These experiments show the proposed method can further improve the process of test data generation in a situation in which complicated or simultaneous constraints may result in the automation failure.	algorithm;automation;constraint (mathematics);constraint satisfaction;experiment;iteration;polynomial;solver;test data generation	Sajjad Naghdali Zanjani;Mehdi Dehghan	2012	2012 IEEE/ACIS 11th International Conference on Computer and Information Science	10.1109/ICIS.2012.86	constraint logic programming;mathematical optimization;binary constraint;constraint satisfaction;constraint graph;theoretical computer science;mathematics;constraint;algorithm;hybrid algorithm	AI	11.316593065331736	14.993324076993058	160479
4baa9ad94394bc714ff950930bcca5b5cd73bcfe	backdoors to combinatorial optimization: feasibility and optimality	optimal solution;continuous variable;combinatorial problems;backdoor sets;decision problem;optimization problem;variable selection;search;keyword search;combinatorial optimization;structural properties	There has been considerable interest in the identification of structural properties of combinatorial problems that lead, directly or indirectly, to the development of efficient algorithms for solving them. One such concept is that of a backdoor set—a set of variables such that once they are instantiated, the remaining problem simplifies to a tractable form. While backdoor sets were originally defined to capture structure in decision problems with discrete variables, here we introduce a notion of backdoors that captures structure in optimization problems, which often have both discrete and continuous variables. We show that finding a feasible solution and proving optimality are characterized by backdoors of different kinds and size. Surprisingly, in certain mixed integer programming problems, proving optimality involves a smaller backdoor set than finding the optimal solution. We also show extensive results on the number of backdoors of various sizes in optimization problems. Overall, this work demonstrates that backdoors, appropriately generalized, are also effective in capturing problem structure in optimization problems.	algorithm;backdoor (computing);benchmark (computing);cobham's thesis;combinatorial optimization;constraint satisfaction problem;decision problem;heuristic;integer programming;linear programming;linear programming relaxation;mathematical optimization;norm (social);numerical analysis;optimization problem	Bistra N. Dilkina;Carla P. Gomes;Yuri Malitsky;Ashish Sabharwal;Meinolf Sellmann	2009		10.1007/978-3-642-01929-6_6	optimization problem;mathematical optimization;combinatorics;discrete mathematics;combinatorial optimization;computer science;decision problem;mathematics	AI	24.597752641261543	11.6370738994768	160548
b1d5c27fd387296f59ac3cbbde1cae18c36c4be2	a new formulation for the conditional p-median and p-center problems	p median;location problem;p center;probleme localisation;p center problem;localization;conditional;localizacion;location;optimisation combinatoire;p;problema p centro;localisation;problema localizacion;combinatorial optimization;probleme p centre;network;optimizacion combinatoria	In this paper we discuss the conditional p-median and p-center problems on a network. Demand nodes are served by the closest facility whether existing or new. The formulation presented in this paper provided better results than those obtained by the best known formulation.		Oded Berman;Zvi Drezner	2008	Oper. Res. Lett.	10.1016/j.orl.2008.02.001	p;mathematical optimization;internationalization and localization;combinatorial optimization;computer science;calculus;mathematics;location;algorithm	Crypto	21.539437526246058	11.760215094836289	160583
f7174546d109d1b30b1a90adc666952f51eb0452	the ring star problem: polyhedral analysis and exact algorithm	telecommunication network design;median cycle;exact algorithm;branch and cut;telecommunications	In the Ring Star Problem, the aim is to locate a simple cycle through a subset of vertices of a graph with the objective of minimizing the sum of two costs: a ring cost proportional to the length of the cycle and an assignment cost from the vertices not in the cycle to their closest vertex on the cycle. The problem has several applications in telecommunications network design and in rapid transit systems planning. It is an extension of the classical location–allocation problem introduced in the early 1960s, and closely related versions have been recently studied by several authors. This article formulates the problem as a mixed-integer linear program and strengthens it with the introduction of several families of valid inequalities. These inequalities are shown to be facet-defining and are used to develop a branch-and-cut algorithm. Computational results show that instances involving up to 300 vertices can be solved optimally using the proposed methodology. © 2004 Wiley Periodicals, Inc.	benchmark (computing);branch and cut;computation;cycle (graph theory);emoticon;exact algorithm;integer programming;john d. wiley;linear programming formulation;network planning and design;polyhedral;telecommunications network;usb on-the-go;vertex (geometry);vertex (graph theory)	Martine Labbé;Gilbert Laporte;Inmaculada Rodríguez Martín;Juan José Salazar González	2004	Networks	10.1002/net.10114	mathematical optimization;combinatorics;discrete mathematics;telecommunications;mathematics;algorithm;branch and cut	AI	22.08065649638029	14.026876358176784	160585
58b1a7629931e63b702484222a5139820cb7bf45	lot-size scheduling of two types of jobs on identical machines	changeover cost;efficient algorithm;upper bound;lot size scheduling;polynomial algorithm;lot sizing;parallel machines	Abstract   The problem of scheduling a collection of different jobs on identical parallel machines is investigated. For each job a number of unit processing time tasks, a given deadline and an upper bound on inventory are known. The optimality criterion is changeover cost which occur if different types of jobs are processed in sequence. Only unit cost are to be considered. For two job types, an efficient algorithm is presented considering only tight schedules; if more job types have to be considered the problem becomes NP-hard.	scheduling (computing)	Marcus Pattloch;Günter Schmidt	1996	Discrete Applied Mathematics	10.1016/0166-218X(95)00044-R	mathematical optimization;combinatorics;real-time computing;flow shop scheduling;computer science;mathematics;upper and lower bounds	Theory	15.678917460160973	10.28593620460003	160679
0f79a8f31f473263a564ecc84c55c4f776f6e696	a polynomially solvable special case of the unbounded knapsack problem	time complexity;polynomial time algorithm;knapsack problem;integer programming;computational complexity;integer program;combinatorial optimization;knapsack	We consider a special case of the unbounded knapsack problem that is characterized by a set of simple inequalities that relate item weights to item costs. We present an algorithm for this special case with time complexity linear in the number of items. c © 2001 Published by Elsevier Science B.V.	algorithm;decision problem;knapsack problem;time complexity	Moshe Zukerman;Long Jia;Timothy D. Neame;Gerhard J. Woeginger	2001	Oper. Res. Lett.	10.1016/S0167-6377(01)00076-1	continuous knapsack problem;mathematical optimization;combinatorics;discrete mathematics;integer programming;combinatorial optimization;generalized assignment problem;cutting stock problem;change-making problem;mathematics;pseudo-polynomial time;knapsack problem	Theory	20.342546055857195	13.329014104883607	160727
1219f5ef03c275de28005a516a032d964cb765b4	maximum utility product pricing models and algorithms based on reservation price	revenue management;product line;mixed integer program;computer experiment;product pricing;mixed integer programming	We consider a revenue management model for pricing a product line with several customer segments under the assumption that customers’ product choices are determined entirely by their reservation prices. We highlight key mathematical properties of the maximum utility model and formulate it as a mixed-integer programming problem, design heuristics and valid cuts. We further present extensions of the models to deal with various practical issues arising in applications. Our computational experiments with real data from the tourism sector as well as with the randomly generated data show the effectiveness of our approach. C&O Research Report: CORR 2007-08 Department of Combinatorics and Optimization University of Waterloo Waterloo, ON, Canada ∗Research supported in part by Discovery Grants from NSERC, a research grant from Air Canada Vacations and by a Collaborative Research and Development Grant from NSERC.	algorithm;experiment;heuristic (computer science);integer programming;procedural generation	Romy Shioda;Levent Tunçel;Tor G. J. Myklebust	2011	Comp. Opt. and Appl.	10.1007/s10589-009-9254-5	mathematical optimization;computer experiment;integer programming;mathematics	AI	16.63117116774436	4.712300206823067	160848
276c23467786e2fbf1f3741a2f1ddca400c68ce3	partial resampling to approximate covering integer programs		We consider column-sparse covering integer programs, a generalization of set cover, which have attracted a long line of research developing (randomized) approximation algorithms. We develop a new rounding scheme based on the Partial Resampling variant of the Lovász Local Lemma developed by Harris & Srinivasan (2013). This achieves an approximation ratio of 1+ ln(∆1+1) amin +O (	approximation algorithm;harris affine region detector;harris functional;like button;linear programming;long line (telecommunications);randomized algorithm;rounding;set cover problem;sparse matrix	Antares Chen;David G. Harris;Aravind Srinivasan	2016			mathematical optimization;combinatorics;discrete mathematics;mathematics;algorithm	Theory	21.19691272943367	17.26577512267962	161017
d516936018c52bd5ea4b0eee32a9ea7886a5b5dc	simultaneous balancing and scheduling of flexible mixed model assembly lines with sequence-dependent setup times	mixed model assembly lines;mixed integer program;setup time;constraint programming	We consider Simultaneous Balancing and Scheduling of Flexible Mixed Model Assembly Lines with Sequence-Dependent Setup Times (SBSFMMAL-SDST). We propose alternate Mixed Integer Programming (MIP) and Constraint Programming (CP) formulations. Our experiments show that while the MIP models could not solve relatively small instances, the CP approach seems more promising.	constraint programming;experiment;integer programming;linear programming;mixed model;scheduling (computing)	Cemalettin Öztürk;Semra Tunali;Brahim Hnich;Arslan M. Örnek	2010	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2010.05.009	mathematical optimization;constraint programming;real-time computing;computer science;distributed computing	AI	14.632391078054921	5.500053068214977	161134
899c2f0ea416db3591b5b397397bb0aa86bc9bf9	passenger delay in a rapid transit station	sistema fila espera;intermodal terminals;systeme attente;freight terminals;estacion metro;modelo prevision;duracion trayecto;subway station;travel time;urban travel;metropolitano;metropolitain;passenger;passenger traffic;time;forecast model;pasajero;trafico viajero;queueing system;retard;schedules;station metro;public transit;passager;retraso;trafic voyageur;distance;rapid transit;subways;modele prevision;duree trajet	An analytical queueing model for predicting passenger delay in a busy rapid transit station is developed and tested. The model accounts for the “lumpy” arrival pattern of passengers exiting trains. Passenger delay is divided into two components: “standard” delay and “interference” delay. Standard delay is the delay incurred when all of the passengers on a train are served before the next train arrives. Interference delay is the added delay when the next train arrives before all of the passengers are served. When a station serves two equally busy tracks, the standard delay per passenger is proportional to the headway and the utilization (arrival rate divided by service rate). The interference delay per passenger is proportional to the headway and the square of the utilization. The size of the headway reflects the “lumpiness” of the arrival pattern. When the headway is small, passengers arrive at a nearly constant rate and delay per passenger is small. When the headway is large, passengers arrive in larger ...		Randolph W. Hall	1987	Transportation Science	10.1287/trsc.21.4.279	telecommunications;schedule;engineering;automotive engineering;mathematics;transport engineering;distance	EDA	10.114170432504393	8.518074602694403	161139
19fe80f1d648e17106382ce506d95c35c95b573c	randomization improving online time-sensitive revenue maximization for green data centers	green products;processor scheduling;heuristic algorithms;deterministic algorithm randomization online time sensitive revenue maximization sustainability resource management module dispatching job scheduling energy green data center machine energy resource job request scheduling resource heuristic deterministic online algorithm randomized solution net profit competitive analysis online algorithm theoretical performance;sustainable development computer centres deterministic algorithms green computing optimisation random processes scheduling;distributed databases;schedules;algorithm design and analysis;green products algorithm design and analysis distributed databases schedules data models processor scheduling heuristic algorithms;data models	Green data centers have become more and more popular recently due to their sustainability. The resource management module within a green data center, which is in charge of dispatching jobs and scheduling energy, becomes especially critical since it directly affects a center's profit and sustainability. The thrust of managing a green data center's machine and energy resources lies at the uncertainty of incoming job requests and future showing-up green energy supplies. Thus, the decision of scheduling resources has to be made in an online manner. Some heuristic deterministic online algorithms have been proposed in recent literature. In this paper, we consider online algorithms for green data centers and introduce a randomized solution with the objective of maximizing net profit. Competitive analysis is employed to measure online algorithms' theoretical performance. Our algorithm is theoretical-sound and it outperforms the previously known deterministic algorithms in many settings using real traces.	best practice;c date and time functions;competitive analysis (online algorithm);data center;dummy variable (statistics);entropy maximization;game developers conference;heuristic;job shop scheduling;job stream;knapsack problem;linear programming;np (complexity);np-hardness;online algorithm;online and offline;polynomial-time reduction;randomized algorithm;randomness;requirement;scheduling (computing);thrust;time complexity;tracing (software);whole earth 'lectronic link;windows rt	Huangxin Wang;Jean X. Zhang;Bo Yang;Fei Li	2015	2015 Sixth International Green and Sustainable Computing Conference (IGSC)	10.1109/IGCC.2015.7393689	fair-share scheduling;data modeling;algorithm design;simulation;schedule;computer science;database;distributed computing;distributed database	Metrics	14.021326008777873	11.763401066204379	161368
3464340e238a98685e5073c7ed442289c40f9c1d	optimal slack time for schedule-based transit operations	flotte;transporte pasajero;optimisation;transport voyageur;fiabilidad;reliability;exponential distribution;travel time;optimizacion;exact solution;autobus;passenger transportation;transport routier;horario;resolucion problema;hash 0x289c438;scheduling;queueing model;waiting time;fiabilite;fleet;schedule;bus;optimization;road transportation;d g c queue;transporte por carretera;transit operation;ordonnancement;horaire;reglamento;problem solving;resolution probleme;slack time	In order to improve service reliability, many transit agencies add a significant amount of slack in the schedule. However, too much slack in the schedule reduces service frequency. We study the problem of determining the optimal slack that minimizes the passengers’ expected waiting times under schedule-based control. By associating with a D/G/c queue model, we show that the system is stable if slack is added in the schedule. For a single-bus loop transit network, we derive convexity of mean and variance of bus delays and provide an exact solution if the travel time is exponentially distributed. For the case of multiple buses and other travel time distributions, we provide several approximation approaches and compare them to simulation results. The simulation results show that our approximations are good for interval of appropriate slack, which often contains the optimal value.	approximation algorithm;glossary of computer graphics;optimization problem;queueing theory;simulation;slack variable;transaction processing system	Jiamin Zhao;Maged M. Dessouky;Satish T. S. Bukkapatnam	2006	Transportation Science	10.1287/trsc.1060.0170	exponential distribution;bus;real-time computing;simulation;computer science;engineering;operations management;operating system;reliability;mathematics;least slack time scheduling;scheduling;schedule;statistics	Metrics	16.675630782588243	5.764949683318086	161402
210e5a5df6c6bed45b0c19495f44bbf783f25f51	the counting complexity of a simple scheduling problem	comptage;p complete;execution time;machine unique;complexite calcul;polynomial interpolation;satisfiability;contaje;deadline;processing time;complejidad computacion;single machine;maquina unica;computational complexity;scheduling;counting;scheduling problem;temps traitement;temps execution;interpolacion polinomial;date limite;tiempo ejecucion;fechas ultimas;tiempo proceso;interpolation polynomiale;ordonnancement;reglamento	Let T be a set of tasks. Each task has a non-negative processing time and a deadline. The problem of determining whether or not there is a schedule of the tasks in T such that a single machine can finish processing each of them before its deadline is polynomially solvable. We prove that counting the number of schedules satisfying this condition is #P-complete. © 2009 Elsevier B.V. All rights reserved.	counting problem (complexity);decision problem;p-complete;polynomial;scheduling (computing);sharp-p	Gerardo Berbeglia	2009	Oper. Res. Lett.	10.1016/j.orl.2009.05.004	job shop scheduling;mathematical optimization;real-time computing;polynomial interpolation;p-complete;mathematics;distributed computing;computational complexity theory;scheduling;counting;algorithm;satisfiability	AI	16.86042427082018	10.716923340494988	161506
fbb9d529ad1ede2c90d50c7aebef58ef88de34fc	a real-time road pricing system: the case of a two-link parallel network	systeme temps reel;parallelisme;dynamic programming;congestion trafic;programacion dinamica;neural networks;value of time;on line testing;congestion trafico;toll road;road pricing;pricing;real time;logique floue;peage;logica difusa;beton;dynamic program;route a peage;fijacion precios;pico;peaje;hormigon;time of day;fuzzy logic;parallelism;paralelismo;traffic congestion;temps reel;peak;programmation dynamique;pic;tiempo real;real time system;sistema tiempo real;reseau neuronal;red neuronal;fixation prix;toll;congestion pricing;concrete;carretera peaje;neural network	A real-time road pricing system in the case of a two-link parallel network is proposed in this paper. The system that is based on a combination of Dynamic Programming and Neural Networks makes “on-line” decisions about road toll values. In the first phase of the proposed model, the best road toll sequences during certain time period are calculated off-line for many different patterns of vehicle arrivals. These toll sequences are computed using Dynamic Programming approach. In the second phase, learning from vehicle arrival patterns and the corresponding optimal toll sequences, neural network is trained. The results obtained during on-line tests are close to the best solution obtained off-line assuming that the arrival pattern is known. Scope and purpose The basic idea behind the concept of congestion pricing is to force drivers to travel and use transportation facilities more during off-peak hours and less during peak hours, as well as to increase the usage of underutilized routes. In this paper, congestion pricing that offers variable tolls to road users based on the time of day and level of traffic is analyzed. There is a need to develop a more concrete methodology to establish time-variable tolls that will optimize the objectives of stakeholders. This research proposes the methodology that can calculate in real-time, appropriate amount of toll to be charged based on the time of day, traffic volumes, value of time distributions and other user and system variables. 2005 Elsevier Ltd. All rights reserved.	dynamic programming;network congestion;neural networks;online and offline;real-time clock;real-time computing;real-time transcription	Dusan Teodorovic;Praveen Edara	2007	Computers & OR	10.1016/j.cor.2005.02.041	fuzzy logic;congestion pricing;pricing;simulation;concrete;floating car data;telecommunications;computer science;dynamic programming;artificial neural network	AI	10.294041776812934	7.009987127475113	161603
4a07c2d5514ae7244d774897c98f7858b504b246	dead-end elimination for weighted csp	soft neighborhood substitutability;dominance rule;weighted constraint satisfaction problem;combinatorial optimization	Soft neighborhood substitutability (SNS) is a powerful technique to automatically detect and prune dominated solutions in combinatorial optimization. Recently, it has been shown in [26] that enforcing partial SNS (PSNS) during search can be worthwhile in the context of Weighted Constraint Satisfaction Problems (WCSP). However, for some problems, especially with large domains, PSNS is still too costly to enforce due to its worst-case time complexity in O(ned) for binary WCSP. We present a simplified dominance breaking constraint, called restricted dead-end elimination (DEE), the worst-case time complexity of which is in O(ned). Dead-end elimination was introduced in the context of computational biology as a preprocessing technique to reduce the search space [13, 14, 16, 17, 28, 30]. Our restriction involves testing only one pair of values per variable instead of all the pairs, with the possibility to prune several values at the same time. We further improve the original dead-end elimination criterion, keeping the same time and space complexity as DEE. Our results show that maintaining DEE during a depth-first branch and bound (DFBB) search is often faster than maintaining PSNS and always faster than or similar to DFBB alone.	algorithm;benchmark (computing);best, worst and average case;bioinformatics;branch and bound;combinatorial optimization;common criteria;computational biology;constraint satisfaction problem;dspace;dead-end elimination;depth-first search;integer programming;isabelle;linear programming;mathematical optimization;moore neighborhood;preprocessor;time complexity	Simon de Givry;Steven David Prestwich;Barry O'Sullivan	2013		10.1007/978-3-642-40627-0_22	mathematical optimization;combinatorics;combinatorial optimization;computer science;mathematics;algorithm	AI	23.397207802841702	4.882101261810495	161621
85415db33dd776b3aadf497c3b61e3c19ed3a078	a lead-time based approach for planning rail-truck intermodal transportation of dangerous goods	modelizacion;analyse risque;iterative method;multiobjective programming;programmation multiobjectif;tiempo iniciacion;rail transportation;risk analysis;routing;gestion risque;risk management;routage;temps mise en route;riesgo accidente;transport intermodal;intermodal transportation;lead time;delai livraison;transportation risk management railroad dangerous goods risk analysis;lorry;risque accidentel;metodo iterativo;modelisation;analisis riesgo;transporte ferroviaro;planificacion;setup time;railroad;methode iterative;dangerous goods;transportation;plazo entrega;coste;planning;gestion riesgo;planification;camion;transport ferroviaire;modeling;transporte intermodal;hazard;delivery lead time;optimization model;cout;programacion multiobjetivo;enrutamiento	The remarkable growth in intermodal transportation over the past two decades has not been matched by a comparable level of academic activity, especially in the context of transporting hazardous materials (hazmats). In this paper, we present a first attempt for the development of an analytical framework for planning rail-truck intermodal transportation of hazmats. A bi-objective optimization model to plan and manage intermodal shipments is developed. To represent the current practice, the routing decisions in the model are driven by the delivery-times specified by the customers. An iterative decomposition based solution methodology which takes advantage of the problem structure is provided. A realistic problem instance based on the intermodal service network in eastern US is solved. This framework is used for developing a number of managerial insights, and for generating elements of the risk-cost frontier.		Manish Verma;Vedat Verter	2010	European Journal of Operational Research	10.1016/j.ejor.2009.06.005	planning;transport;routing;systems modeling;truck;risk analysis;economics;input/output;risk management;hazard;operations management;mathematics;iterative method;operations research	Robotics	17.716373418413426	5.5866254965202415	161639
0d8ce2d9d359dcea5a909c63f786465e149b1ab7	force: a fast and easy-to-implement variable-ordering heuristic	pre processing;variable order;placement;partitioning;backtrack search;cnf;sat;hypergraph;hypergraph partitioning;bdds;sat solver;reachability analysis	The MINCE heuristic for variable-ordering [1] can successfully reduce the size of BDDs and accelerate SAT-solving. Applications to reachability analysis have also been successful [12]. The main drawback of MINCE is its implementation complexity - the authors used a pre-existing min-cut placer [6] that is several times larger than any existing SAT solver. Tweaking MINCE is difficult.In this work we propose a replacement heuristic, FORCE which is easy to implement from scratch and tweak. It is dramatically faster than MINCE in practice. While FORCE may produce seemingly inferior variable orderings, the difference with MINCE orderings does not affect subsequent SAT-solving.	boolean satisfiability problem;heuristic;mince;maxima and minima;minimum cut;reachability;solver;tweaking	Fadi A. Aloul;Igor L. Markov;Karem A. Sakallah	2003		10.1145/764808.764839	combinatorics;computer science;theoretical computer science;mathematics;boolean satisfiability problem;algorithm;placement	Logic	13.732744742582591	16.318116252930857	161793
a87764ada132260141736bfccb0dd609404611e2	a milp model for n-dimensional allocation	mixed integer linear program;optimisation;three dimensional;milp;n dimensional allocation;scheduling problem	ij ij Q P , CONCLUSIONS A general purpose MILP model for allocation problems in any given number of dimensions is presented. The model is concerned with the allocation of items in an N-dimensional space. To demonstrate the formulation, a number of illustrative examples in different number of dimensions are solved. 1, 2, 3 and 4-dimensional problems are presented and solved using the proposed model. For a specific number of dimensions more efficient special purpose models may be created. Nonetheless, The given N-dimensional allocation model offers also in such cases a general platform as a basis for the model. The novelty of the model is the applicability on a wide variety of problems in any given number of dimensions.		Joakim Westerlund;Lazaros G. Papageorgiou;Tapio Westerlund	2007	Computers & Chemical Engineering	10.1016/j.compchemeng.2007.02.006	three-dimensional space;job shop scheduling;mathematical optimization;combinatorics;covering problems;mathematics	DB	23.616742297658046	11.338177317134534	161852
d02d0f71ce1dcb513ee1cacab11e0f6cbff41a42	random knapsacks with many constraints	probleme sac a dos;mathematics;variable aleatoire;inegalite probabilite;variable aleatoria;taux croissance;problema mochila;tasa crecimiento;optimisation combinatoire;upper bound;knapsack problem;contrainte multiple;growth rate;random variable;borne superieure;combinatorial optimization;cota superior;optimizacion combinatoria	We provide new results on asymptotic values for the random knapsack problem. For a very general model in which the parameters are determined by a rather arbitrary joint distribution, we compute the rate of growth as the number of objects increases, the number of constraints being fixed. For a particular model, we find strong bounds on the asymptotic value as the numbers of objects and constraints increase together. This paper is a continuation of the work in [3,4] on estimating the values of random knapsack problems with many decision variables. It consists of two independent parts. In Section 1, we show how to estimate the growth rate of the value of a random knapsack when the parameters are determined by a very general class of joint distributions. In Section 2, we concentrate on a particular random knapsack model, and give rather sharp new bounds on its asymptotic value. In more detail: In Section 1, we first settle a question left open in [3] related to a single-constraint random knapsack problem, then apply this new result to a multiconstraint problem. Consider the problem V, = max i XjSj, j= 1 subject to i ~~j I K, djc (03 l} j=l where the random variable pairs ( Wj, Xi) are independent, identically distributed draws from any one of a very wide class of joint distributions F,,. (In particular, we do not assume that W and X are independent.) For t > 0, let F(t) = E( W 1 ix t rW;) and G(t) = E(X 1 ix 2 tw;). Correspondence to: Professor K. Schilling, Department of Mathematics, University of Michigan-Flint, Flint, MI 48502.2186, USA. 0166-218X/94/$07.00	continuation;joint entropy;knapsack problem	Kenneth Schilling	1994	Discrete Applied Mathematics	10.1016/0166-218X(92)00125-6	random variable;mathematical optimization;combinatorics;combinatorial optimization;calculus;mathematics;upper and lower bounds;knapsack problem	Theory	19.822460404209366	14.004576134050719	161936
a6a71003ae182477f495c80d257b4c7ef66e4602	the euclidean vehicle routing problem with multiple depots and time windows		This paper studies the Euclidean vehicle routing problem with multiple depots and time windows (Euclidean VRP with MDTW). We consider the scenario where there are multiple depots which could dispatch out vehicles, and customers must be serviced within a time window which is chosen from a finite set of consecutive time windows. Specially, in an input instance of Euclidean VRP with MDTW, we require that each customer has the same unit demand, ignore the limit of vehicle number, and give a reasonable service ability to the servicing vehicles. In quasi-polynomial time, our algorithm could generate a solution with the expected length at most (1 + O()) OPT. © Springer International Publishing AG 2017.	microsoft windows;vehicle routing problem	Liang Song;Hejiao Huang	2017		10.1007/978-3-319-71147-8_31	combinatorics;discrete mathematics;vehicle routing problem;approximation algorithm;computer science;mathematical optimization;euclidean geometry;finite set	Robotics	15.92255812876348	4.744772345474288	162006
8d0d6cb5724a2e3cca61a75ecac74f8b6d212761	conjugate problems in time-dependent scheduling	time dependent;greedy heuristic;conjugate problems;heuristic algorithms;scheduling problem;time dependent scheduling;heuristic algorithm	In the paper, we consider conjugate problems which constitute a new class of mutually related timedependent scheduling problems. Any element from this class is a composite problem, being a pair of two timedependent scheduling problems connected by a conjugacy formula. We prove basic properties of conjugate problems and show the relations that hold between such problems. We also propose an approach to the construction of greedy heuristics for the conjugate problems. We illustrate applications of the results by examples.	approximation;convex conjugate;eisenstein's criterion;greedy algorithm;heuristic (computer science);referring expression generation;scheduling (computing);the matrix	Stanislaw Gawiejnowicz;Wieslaw Kurc;Lidia Pankowska	2009	J. Scheduling	10.1007/s10951-009-0121-0	heuristic;job shop scheduling;mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;dynamic priority scheduling;computer science;mathematics	Theory	20.158631079614942	11.979405018554221	162065
21efd7c01022e3555ab4e4cce67cdaa8570d44e3	minimizing the weighted number of tardy jobs with due date assignment and capacity-constrained deliveries	batching;due date assignment;scheduling;number of tardy jobs	We study a supply chain scheduling problem, where a common due date is assigned to all jobs and the number of jobs in delivery batches is constrained by the batch size. Our goal is to minimize the sum of the weighted number of tardy jobs, the due-dateassignment costs and the batch-delivery costs. We show that some well-known N P -hard problems reduce to our problem. Then we propose a pseudo-polynomial algorithm for the problem, establishing that it is N P -hard only in the ordinary sense. Finally, we convert the algorithm into an efficient fully polynomial time approximation scheme.	algorithm;job stream;polynomial;polynomial-time approximation scheme;scheduling (computing);steiner tree problem;time complexity	George Steiner;Rui Zhang	2011	Annals OR	10.1007/s10479-011-1000-6	mathematical optimization;computer science;operations management;mathematics;scheduling;algorithm	Theory	15.471758672530806	9.779203995321797	162090
af5df9a179a443583d236d0c16a19d2235828cf5	sat-based branch & bound and optimal control of hybrid dynamical systems	hybrid dynamical system;modelo dinamico;probleme satisfiabilite;optimal solution;arbre recherche;control optimo;solution optimale;control optimo matematicas;feedforward;sistema hibrido;systeme discret;qa mathematics;dynamic model;modelo hibrido;state feedback;hybrid control;commande retour etat;discrete time;logique propositionnelle;control lineal;boucle anticipation;satisfiability;constraint satisfaction;modele hybride;commande bornee;control hibrida;hybrid model;dynamical system;optimal control;optimization problem;systeme dynamique;satisfaction contrainte;qa75 electronic computers computer science;controle optimal;search trees;ciclo anticipacion;branch and bound method;mixed integer program;programacion mixta entera;arbol investigacion;control limitado;metodo branch and bound;mathematical programming;propositional logic;commande optimale;solucion optima;problema satisfactibilidad;modele dynamique;hybrid system;commande lineaire;optimal control mathematics;programmation partiellement en nombres entiers;mixed integer programming;bucle realimentacion estado;commande hybride;bounded control;satisfaccion restriccion;methode separation et evaluation;logica proposicional;sistema dinamico;sistema discreto;sat solver;tiempo discreto;temps discret;search tree;linear control;branch and bound;programmation mathematique;satisfiability problem;programacion matematica;discrete system;optimal control problem;systeme hybride	"""A classical hybrid MIP-CSP approach for solving problems having a logical part and a mixed integer programming part is presented. A Branch and Bound procedure combines an MIP and a SAT solver to determine the optimal solution of a general class of optimization prob- lems. The procedure explores the search tree, by solving at each node a linear relaxation and a satisfiability problem, until all integer variables of the linear relaxation are set to an integer value in the optimal solu- tion. When all integer variables are fixed the procedure switches to the SAT solver which tries to extend the solution taking into account logical constraints. If this is impossible, a """"no-good"""" cut is generated and added to the linear relaxation. We show that the class of problems we consider turns out to be very useful for solving complex optimal control problems for linear hybrid dynamical systems formulated in discrete-time. We de- scribe how to model the """"hybrid"""" dynamics so that the optimal control problem can be solved by the hybrid MIP+SAT solver, and show that the achieved performance is superior to the one achieved by commercial MIP solvers."""	dynamical system;optimal control	Alberto Bemporad;Nicolò Giorgetti	2004		10.1007/978-3-540-24664-0_7	mathematical optimization;integer programming;computer science;branch and price;calculus;mathematics;boolean satisfiability problem;algorithm;branch and cut	Theory	19.48917018587604	8.072076028876111	162142
c6e53f7332e28fd94912d78e081068308d32d812	a new bounding mechanism for the cnc machine scheduling problems with controllable processing times	tratamiento datos;tiempo total acabamiento;manufacturing cost;costo fabricacion;controlabilidad;machine unique;operating conditions;automated manufacturing;controllability;temps total achevement;data processing;traitement donnee;processing time;computer digital control;controlabilite;cout fabrication;single machine;maquina unica;condition operatoire;makespan;efficient frontier;scheduling;bi criteria;scheduling problem;temps traitement;machine scheduling;upper and lower bounds;controllable processing times;condicion operatoria;tiempo proceso;control numerico computador;ordonnancement;reglamento;commande numerique calculateur	In this study, we determine the upper and lower bounds for the processing time of each job under controllable machining conditions. The proposed bounding scheme is used to find a set of discrete efficient points on the efficient frontier for a bi-criteria scheduling problem on a single CNC machine. We have two objectives; minimizing the manufacturing cost (comprised of machining and tooling costs) and minimizing makespan. The technological restrictions of the CNC machine along with the job specific parameters affect the machining conditions; such as cutting speed and feed rate, which in turn specify the processing times and tool lives. Since it is well known that scheduling problems are extremely sensitive to processing time data, system resources can be utilized much more efficiently by selecting processing times appropriately. 2004 Elsevier B.V. All rights reserved.	approximation algorithm;automated planning and scheduling;computation;exact algorithm;heuristic;makespan;mathematical optimization;norm (social);scheduling (computing);time complexity;trusted computer system evaluation criteria	Rabia K. Kayan;M. Selim Akturk	2005	European Journal of Operational Research	10.1016/j.ejor.2004.07.012	efficient frontier;job shop scheduling;mathematical optimization;real-time computing;controllability;computer science;operations management;mathematics;upper and lower bounds;scheduling	AI	17.22061833806755	10.02756105624489	162175
e0b3be3d26cead88af82b4998cfeede578d3cafb	determining workstation groups in a fixed factory facility based on biological computation	production system;computational method;operating system	A strategy for making layout decisions is an important element in developing operating systems in manufacturing factories or other industrial plants. In this paper, we look at fixed factory facilities and propose a method for designing different sorts of layouts related to factories running at high-volume and producing a low-variety of products. Where many tasks are called, each with a different task time, it can be difficult to arrange a fixed factory facility in the optimal way. Therefore, we propose a computational method using DNA molecules for designing production systems by determining all the feasible workstation groups in a fixed factory facility, and we show that this computation method can be generally applied to layout decisions.	biological computation;workstation	Ikno Kim;Junzo Watada	2009		10.1007/978-3-642-04592-9_24	real-time computing;engineering;operations management;manufacturing engineering	Logic	11.173855064272551	4.308762880814319	162529
401fcf92adbe790f837a106b29ad43416e05f277	balanced offline allocation of weighted balls into bins		We propose a sorting-based greedy algorithm called SortedGreedy[m] for approximately solving the offline version of the d-choice weighted balls-into-bins problem where the number of choices for each ball is equal to the number of bins. We assume the ball weights to be nonnegative. We compare the performance of the sorting-based algorithm with a näıve algorithm called Greedy[m]. We show that by sorting the input data according to the weights we are able to achieve an order of magnitude smaller gap (the weight difference between the heaviest and the lightest bin) for small problems (≤ 4000 balls), and at least two orders of magnitude smaller gap for larger problems. In practice, SortedGreedy[m] runs almost as fast as Greedy[m]. This makes sorting-based algorithms favorable for solving offline weighted balls-into-bins problems.	greedy algorithm;online and offline;sorting;weatherstar	Ömer Demirel;Ivo F. Sbalzarini	2013	CoRR		mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	17.132990320009522	14.883355725223822	162649
59404924ceceb826ec972c4cd860b5d3e2bbce5c	parallel prefetching and caching is hard	optimisation;approximate algorithm;optimizacion;approximation algorithm;prefetching;prechargement donnee;problema np duro;cache memory;temps minimal;processing time;antememoria;instability;np hard problem;antememoire;probleme np difficile;informatique theorique;flujo inuniforme;unsteady flow;algoritmo aproximacion;instabilite;minimum time;temps traitement;optimization;inestabilidad;algorithme approximation;precargamento dato;tiempo minimo;parallel disk;tiempo proceso;disque parallele;ecoulement instationnaire;computer theory;disco paralelo;informatica teorica	In this paper we study integrated prefetching and caching in parallel disk systems. This topic has gained a lot of interest in the la st years which manifests itself in numerous recent approximation algorithms. This paper provides the first negative result in this area by showing that optimizing the stall time isAPX hard. This also implies that computing the optimal processi ng time isNP-hard, which settles an open problem posed by Kimbrel and Karlin.	approximation algorithm;cpu cache;cache (computing);linear algebra;link prefetching	Christoph Ambühl;Birgitta Weber	2004		10.1007/978-3-540-24749-4_19	cpu cache;computer science;artificial intelligence;calculus;np-hard;mathematics;approximation algorithm;algorithm;instability	Theory	17.29026743347051	11.73119259166101	162827
df82c6a15cf4ebc86227eac6c45532061703b474	two stage reentrant hybrid flow shop with setup times and the criterion of minimizing makespan	setup times;reentrant hybrid flow shop;setup time;computer experiment;scheduling problem;genetic algorithm;parallel machines;heuristics;heuristic algorithm;hybrid genetic algorithm	This paper discusses a two stage reentrant hybrid flowshop scheduling problem. The problem to be studied has two main stages: In stage one, there are g stations and in station k, there are m1k identical parallel machines and in stage two, there is a station with m2 identical parallel machines. The first stage is a reentrant shop which all jobs have the same routing over the machines of the shop and the same sequence is traversed several times to complete different levels of the jobs. Such scheduling problems occur in certain practical applications such as semiconductors, electronics manufacturing, airplane engine production, and petrochemical production. The criterion is to minimize the makespan of the system. Setup ybrid genetic algorithm etup times euristics times are implemented between jobs in both stages and between levels in stage one. There has not been any study about this real area which has two separated stages with different setup times in each one. Because of the intractability of the reentrant hybrid flow shop model, some heuristic algorithms and a random key genetic algorithm (RKGA) are proposed and compared with a new hybrid genetic algorithm (HGA). Computational experiments are performed to illustrate that the proposed HGA provides the best solutions in comparison with other algorithms.	computation;computational linguistics;experiment;genetic algorithm;hercules graphics card;heuristic;makespan;memetic algorithm;reentrancy (computing);routing;scheduling (computing);semiconductor	M. Hekmatfar;Seyyed M. T. Fatemi Ghomi;Behrooz Karimi	2011	Appl. Soft Comput.	10.1016/j.asoc.2011.08.013	heuristic;job shop scheduling;mathematical optimization;real-time computing;genetic algorithm;computer experiment;flow shop scheduling;computer science;heuristics	AI	14.058286556594545	4.826459555087179	162960
dd9c9e44b7326fbf6a9a9774b5a39dfcf9b89cfc	the control complexity of sincere strategy preference based approval voting and of fallback voting, and a study of optimal lobbying and junta distributions for sat		While voting systems were originally used in political scie nc , they are now also of central importance in various areas of computer science, such as artifi ci l ntelligence (in particular within multiagent systems). Brams and Sanver [BS06] introduced si ncere-strategy preference-based approval voting (SP-AV) and fallback voting (FV), two electio n systems which combine the preference rankings of voters with their approvals of candidate s. We study these two systems with respect to procedural control—settings in which an agent se eks to influence the outcome of elections via control actions such as adding/deleting/partiti on ng either candidates or voters. We prove that SP-AV is computationally resistant (i.e., the corresponding control problems are NP-hard) to 19 out of 22 types of constructive and destruc tive ontrol. Thus, for the 22 control types studied here, SP-AV has more resistances to control, b y three, than is currently known for any other natural voting system with a polynomial-time winn er problem. In particular, SP-AV is (after Copeland voting, see Faliszewski et al. [FHHR08a] ) the second natural voting system with an easy winner-determination procedure that is known t o have full resistance to constructive control, and unlike Copeland voting it in addition displays broad resistance to destructive control. We show that FV has full resistance to candidate control. We also investigate two hard problems related to voting, the optimal weighted lobbying problem and the winner problem for Dodgson elections. Regarding the former problem, Christian et al. [CFRS06] showed that optimal lobbying is intractable in the sense of parameterized complexity. We propose an efficient greedy algorithm that nonethele ss approximates a generalized variant of this problem, optimal weighted lobbying, and thus the ori ginal optimal lobbying problem as well. We also show that the approximation ratio of this algor ithm is tight. The problem of determining Dodgson winners is known to be com plete for parallel access to NP [HHR97]. Homan and Hemaspaandra [HH06] proposed an effici ent greedy heuristic for finding Dodgson winners with a guaranteed frequency of success, and their heuristic is indeed a “frequently self-knowingly correct algorithm.” We prove that e very distributional problem solvable in polynomial time on the average with respect to the uniform distribution has a frequently selfknowingly correct polynomial-time algorithm. Furthermor e, we study some features of probability weight of correctness with respect to Procaccia and Rosensc h in’s junta distributions [PR07].	av-test;agent-based model;approximation algorithm;commitment ordering;computer science;correctness (computer science);decision problem;farmville;greedy algorithm;heuristic;multi-agent system;np (complexity);parameterized complexity;polynomial;time complexity;william winn	Gábor Erdélyi	2009				AI	15.86387070273392	17.176370531794973	162962
27c502cda2518cebab203c8034cebab40f7fb4fb	allocation of police beats to patrol units to minimize response time to calls for service		Abstract   Optimal beat configurations to minimize response time to calls for service can be determined for a given number of police patrol beats during a shift. However, optimal manpower scheduling requires that the number of units vary by day of week. A variable beat design strategy is administratively infeasible. This model operates under a fixed beat design strategy and assigns beats to a variable number of units. The computer program improves an initial beat assignment by considering all possibilities of moving or sharing beats with other units. The new beat assignments are reevaluated till an optima is reached.	response time (technology)	Deepak Bammi	1975	Computers & OR	10.1016/0305-0548(75)90022-2	real-time computing;simulation	OS	13.75734592529303	6.03970371936691	163009
a69435fbb9af6fb3961ab2a0a83d616da35890c7	scheduling and reliable lead-time quotation for orders with availability intervals and lead-time sensitive revenues	online algorithm;complexity;lead time;service industry;scheduling;scheduling problem;competitive analysis;lead time quotation;online algorithms;competitive ratio	Pinar Keskinocak • R. Ravi • Sridhar Tayur School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, Georgia 30332-0205 Graduate School of Industrial Administration, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213 Graduate School of Industrial Administration, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213 pinar@isye.gatech.edu • ravi@cmu.edu • stayur@grobner.gsia.cmu.edu	best, worst and average case;binary prefix;chomsky hierarchy;competitive analysis (online algorithm);management science;nsa product types;online algorithm;online and offline;randomized algorithm;scheduling (computing);systems engineering	Pinar Keskinocak;R. Ravi;Sridhar R. Tayur	2001	Management Science	10.1287/mnsc.47.2.264.9836	competitive analysis;job shop scheduling;online algorithm;mathematical optimization;real-time computing;marketing;operations management	Logic	13.61687238647376	9.32755605296856	163053
596b018201b374b819db66c420807aa8e26d57b0	making ac-3 an optimal algorithm	time complexity;arc consistency;phase transition;space complexity;constraint system;coarse grained;optimal algorithm;constraint sat isfaction problem	The AC-3 algorithm is a basic and widely used arc consistency enforcing algorithm in Constraint Satisfaction Problems (CSP). Its strength lies in that it is simple, empirically efficient and extensible. However its worst case time complexity was not considered optimal since the first complexity result for AC-3 [Mackworth and Freuder, 1985] with the boundO(ed3), where e is the number of constraints and d the size of the largest domain. In this paper, we show suprisingly that AC-3 achieves the optimal worst case time complexity with O(ed2). The result is applied to obtain a path consistency algorithm which has the same time and space complexity as the best known theoretical results. Our experimental results show that the new approach to AC-3 is comparable to the traditional AC-3 implementation for simpler problems where AC-3 is more efficient than other algorithms and significantly faster on hard instances.	ac-3 algorithm;best, worst and average case;constraint satisfaction;dspace;dijkstra's algorithm;experiment;local consistency;time complexity	Yuanlin Zhang;Roland H. C. Yap	2001			phase transition;time complexity;best, worst and average case;mathematical optimization;combinatorics;discrete mathematics;average-case complexity;ac-3 algorithm;computer science;worst-case complexity;mathematics;dspace;algorithm;local consistency	AI	12.31075998378713	16.38130428123611	163061
933b085b3bbccf3ca40ad84738e735f6e7bb5ad0	on throughput maximization in constant travel-time robotic cells	travel time;robotic cell;maufacturing;polynomial time algorithm;identical parts;manufacturing;throughput maximization;lower bound;structure analysis	We consider the problem of scheduling operations in bufferless robotic cells that produce identical parts. The objective is to find a cyclic sequence of robot moves that minimizes the long-run average time to produce a part or, equivalently, maximizes the throughput rate. The robot can be moved in simple cycles that produce one unit or, in more complicated cycles, that produce multiple units. Because one-unit cycles are the easiest to understand, implement, and control, they are widely used in industry. We analyze one-unit cycles for a class of robotic cells calledconstant travel-time robotic cells. We complete a structural analysis of the class of one-unit cycles and obtain a polynomial time algorithm for finding an optimal one-unit cycle.Constant travel-time robotic cells are used in real manufacturing operations that the authors have encountered during their interactions with companies. The results and the analysis in this paper offer practitioners (i) a tool to experiment with and study the design of a proposed robotic cell during a prototyping exercise, (ii) a lower bound on the throughput of a robotic cell to help them make an informed assessment of the ultimate productivity level, and (iii) a benchmark throughput level (for comparison purposes) for robotic cells whose operations differ slightly from those discussed in this paper.	expectation–maximization algorithm;throughput	Milind Dawande;Chelliah Sriskandarajah;Suresh P. Sethi	2002	Manufacturing & Service Operations Management	10.1287/msom.4.4.296.5731	real-time computing;simulation;marketing;operations management;structural analysis;manufacturing;upper and lower bounds	Robotics	10.625916156192037	5.0713812295204095	163253
82b9465349191135a8b1e573f7684e8ead55017f	combinatorial relaxation bounds and preprocessing for berth allocation problems		We investigate an optimization problem in container ports, for which previous models based on generalized set partitioning formulations have been studied. We describe two combinatorial relaxations based on computing maximum weighted matchings in suitable graphs, providing dual bounds and a variable reduction technique.	linear programming relaxation;matching (graph theory);mathematical optimization;optimization problem;preprocessor	Evellyn Cavalcante;Johan Oppen;Phillippe Samer;Sebastián Urrutia	2016	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2016.10.022	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	23.585500748959575	15.58860926434918	163446
7e70bd4668f2b0917784f282491f32ccedc9e26c	a comparison of first-fit allocation strategies	storage management;allocation;memory utilization efficiency;first fit	Two modifications of the first-fit algorithm of storage allocation presented by Knuth are simulated. They are compared under two measures of efficiency: average allocation search time and memory utilization efficiency.	algorithm;bin packing problem	Aaron M. Tenenbaum;Erik Widder	1978		10.1145/800178.810157	real-time computing;computer science;operations management;static memory allocation;welfare economics	Theory	14.042664825399434	11.390968139221982	163608
c9a28847c9f3da30d10ef87f80e6f8b52c3834b6	power-efficient assignment of virtual machines to physical machines	scheduling;load balancing;generalized assignment;cloud computing	Motivated by current trends in cloud computing, we study a version of the generalized assignment problem where a set of virtual processors has to be implemented by a set of identical processors. For literature consistency, we say that a set of virtual machines (VMs) is assigned to a set of physical machines (PMs). The optimization criterion is to minimize the power consumed by all the PMs. We term the problem Virtual Machine Assignment (VMA). Crucial differences with previous work include a variable number of PMs, that each VM must be assigned to exactly one PM (i.e., VMs cannot be implemented fractionally), and a minimum power consumption for each active PM. Such infrastructure may be strictly constrained in the number of PMs or in the PMs' capacity, depending on how costly (in terms of power consumption) it is to add a new PM to the system or to heavily load some of the existing PMs. Low usage or ample budget yields models where PM capacity and/or the number of PMs may be assumed unbounded for all practical purposes. We study four VMA problems depending on whether the capacity or the number of PMs is bounded or not. Specifically, we study hardness and online competitiveness for a variety of cases. To the best of our knowledge, this is the first comprehensive study of the VMA problem for this cost function. Formal definition of 4 versions of the Virtual Machine Assignment problem (VMA).Study of hardness of the offline version.Study of competitiveness of the online version.Proposal of algorithms for the online version.	virtual machine	Jordi Arjona Aroca;Antonio Fernández;Miguel A. Mosteiro;Christopher Thraves;Lin Wang	2016	Future Generation Comp. Syst.	10.1016/j.future.2015.01.006	parallel computing;real-time computing;cloud computing;computer science;load balancing;operating system;distributed computing;scheduling	Arch	18.945136628646697	14.531769063010945	163653
e84295fef1975703653f1eac904e9ff9462cc2b0	an efficient genetic algorithm for job shop scheduling problems	job shop scheduling problem		genetic algorithm;job shop scheduling;scheduling (computing)	Shigenobu Kobayashi;Isao Ono;Masayuki Yamamura	1995			fair-share scheduling;job shop scheduling;flow shop scheduling;dynamic priority scheduling;rate-monotonic scheduling;lottery scheduling	AI	14.092143592206256	6.696571520312341	164122
195021d4730ca0bde4af553ded6d34eb03bfbf4a	on the relative complexities of some geometric problems.	lower bound	"""We consider a number of problems whose best known algorithms run in roughly O(n) time. While it is generally believed that these algorithms are optimal, at least up to polylogarithmic or n factors, the best known lower bound in any general model of computation is only (n logn). We characterize these problems by their relative complexities. That is, for certain pairs of problems, we show that the complexity of one problem is asymptotically bounded by the complexity of the other. Thus, a o(n)-time algorithm for the \harder"""" problem is impossible without a similar algorithm for the \easier"""" one. Conversely, any better lower bounds for the easier problem would immediately apply to the harder problem as well. This paper is similar in spirit to the earlier work of Gajentaan and Overmars [17]. They introduce the class of 3sum-hard problems, all of which are at least as hard as the following simple base problem: Given n numbers, do any three sum to zero? All of these problems seem to require (n) time to solve; thus, some earlier papers describe them with the more suggestive but misleading term \n-hard"""". (See [6].) The present classi cation of \n-hard"""" problems is not so clean. Many of our reductions introduce extra logarithmic factors. More importantly, we do not know if there is a single base problem to which all these problems can be reduced."""	3sum;algorithm;model of computation;polylogarithmic function;reduction (complexity)	Jeff Erickson	1995			mathematics;upper and lower bounds	Theory	17.153715867767207	17.30479250787563	164126
b3f5f1aea2f4d6f6c4c3177850883d639f30aac7	approximation algorithms for a combined facility location buy-at-bulk network design problem		We consider a generalization of the connected facility location problem where the clients must be connected to the open facilities via shared capacitated (tree) networks instead of independent shortest paths. This problem arises in the planning of fiber optic telecommunication access networks, for example. Given a set of clients with positive demands, a set of potential facilities with opening costs, a set of capacitated access cable types, and a core cable type of infinite capacity, one has to decide which facilities to open, how to interconnect them using a Steiner tree of infinite capacity core cables, and which access cable types to install on which potential edges such that these edges form a forest and the installed capacities suffice to simultaneously route the client demands to the open facilities via single paths. The objective is to minimize the total cost of opening facilities, building the core Steiner tree among them, and installing the access cables. In this paper, we devise a constant-factor approximation algorithm for problem instances where the access cable types obey economies of scale. In the special case where only multiples of a single cable type can be installed on the access edges, a variant of our algorithm achieves a performance guarantee of 6.72.	apx;access network;approximation algorithm;facility location problem;fiber-optic communication;optical fiber;shortest path problem;steiner tree problem	Andreas Bley;S. Mehdi Hashemi;Mohsen Rezapour	2013		10.1007/978-3-642-38236-9_8	mathematical optimization;facility location problem;1-center problem	Theory	21.631935561497837	14.442102291255972	164444
e86f44692c0b882ab8ab411fbd9b834894091e7b	ant colony optimization for the cell assignment problem in pcs networks	assignment problem;graphe biparti;empirical study;swarm intelligence;multiagent system;probleme affectation;ant colony optimization;modele mathematique;personal communication service;cell assignement;grafo bipartido;fourragement;conducta abastecimiento;ant colony;approche heuristique;foraging behavior;modelo matematico;multi agent;cell assignment;service industries;metaheuristique;optimizacion enjambre particula;industrie service;mathematical model;enfoque heuristico;optimisation essaim particule;problema asignacion;heuristic approach;sistema multiagente;metaheuristic;bipartite graph;article;probleme direct;problema directo;systeme multiagent;direct problem	Even though significant improvement to communications infrastructure has been attained in the personal communication service industry, the issues concerning the assignment of cells to switches in order to minimize the cabling and handoff costs in a reasonable time remain challenging and need to be solved. In this paper, we propose an algorithm based upon the Ant Colony Optimization (ACO) approach to solve the cell assignment problem, which is known to beNP-hard. ACO is a metaheuristic inspired by the foraging behavior of ant colonies. We model the cell assignment problem as a form of matching problem in a weighted directed bipartite graph so that our artificial ants can construct paths that correspond to feasible solutions on the graph. We explore and analyze the behavior of the ants by examining the computational results of our ACO algorithm under different parameter settings. The performances of the ACO algorithm and several heuristics and metaheuristics known in the literature are also empirically studied. Experimental results demonstrate that the proposed ACO algorithm is an effective and competitive approach in composing fairly satisfactory results with respect to solution quality and execution time for the cell assignment problem as compared with most existing heuristics or metaheuristics. 2005 Elsevier Ltd. All rights reserved.	algorithm;ant colony optimization algorithms;artificial ants;assignment problem;computation;heuristic (computer science);mathematical optimization;metaheuristic;network switch;performance;run time (program lifecycle phase)	Shyong Jian Shyu;Bertrand M. T. Lin;Tsung-Shen Hsiao	2006	Computers & OR	10.1016/j.cor.2004.11.026	foraging;mathematical optimization;ant colony optimization algorithms;bipartite graph;swarm intelligence;computer science;generalized assignment problem;artificial intelligence;ant colony;mathematical model;mathematics;assignment problem;weapon target assignment problem;empirical research;metaheuristic	AI	20.48768404162031	5.932817893827414	164617
4d40eecf1d9a7b749f1aa1cb70bba12dec8f9be3	solving conditional and composite temporal constraints	constraint theory temporal reasoning temporal databases constraint handling computational complexity;constraint propagation;forward checking;computer science process planning natural language processing databases time factors quality management calculus algebra artificial intelligence;temporal constraints;computational complexity;constraint theory;constraint handling;temporal databases;experimental evaluation;forward check strategy composite temporal constraint satisfaction problem constraint based system resolution process activity constraints composite variables constraint propagation symbolic temporal constraint;temporal reasoning	One of the main challenges when designing constraint based systems in general and those involving temporal constraints in particular, is the ability to deal with conditional constraints and composite variables. Indeed, in this particular case the set of variables involved by the constraint problem to be solved is not known in advance. More precisely, while some variables (called initial variables) are available in the initial problem, others are added dynamically to the problem during the resolution process via activity constraints and composite variables. Activity constraints allow some variables to be activated (added to the problem) when activity conditions are true. Composite variables are variables whose values are the possible variables each composite variable can take. We propose a method based on constraint propagation for solving efficiently constraint problems involving numeric and symbolic temporal constraints, composite variables and activity constraints. We call these latter problems conditional and composite temporal constraint satisfaction problems (CCTCSPs). Experimental evaluation conducted on randomly generated CCTCSPs demonstrates the efficiency of our method to solve these problems especially when using the forward check strategy during the search.	activity tracker;backtracking;constraint satisfaction problem;local consistency;procedural generation;search algorithm;software propagation;time complexity	Malek Mouhoub;Amrudee Sukpan	2004	16th IEEE International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2004.109	constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;binary constraint;decomposition method;constraint satisfaction;constraint learning;computer science;constraint graph;look-ahead;machine learning;constraint satisfaction dual problem;mathematics;complexity of constraint satisfaction;temporal database;constraint;computational complexity theory;constraint satisfaction problem;algorithm;hybrid algorithm;local consistency;backtracking	AI	11.300659014341598	15.314631921486937	164790
aede4735c65fcb00d42f1bf325825c933859e949	an optimization algorithm for the inventory routing problem with continuous moves	algoritmo aleatorizado;entrega;programacion entera;tour itineraire;algorithme glouton;availability;routing;disponibilidad;routage;branch and cut method;methode separation et coupe;algorithme randomise;greedy heuristic;programmation en nombres entiers;administracion deposito;optimisation combinatoire;busca local;livraison;tour;integer programming;vuelta;gestion stock;randomized algorithm;delivery cover inequalities;greedy algorithm;algoritmo gloton;inventory routing;delivery good;integer program;branch and cut;combinatorial optimization;metodo branch and cut;optimal algorithm;inventory control;disponibilite;local search;recherche locale;optimizacion combinatoria;enrutamiento	The typical inventory routing problem deals with the repeated distribution of a single product from a single facility with an unlimited supply to a set of customers that can all be reached with out-and-back trips. Unfortunately, this is not always the reality. We focus on the inventory routing problem with continuous moves, which incorporates two important real-life complexities: limited product availabilities at facilities and customers that cannot be served using out-and-back tours. We need to design delivery tours spanning several days, covering huge geographic areas, and involving product pickups at different facilities. We develop an integer programming based optimization algorithm capable of solving small to medium size instances. This optimization algorithm is embedded in local search procedure to improve solutions produced by a randomized greedy heuristic. We demonstrate the effectiveness of this approach in an extensive computational study.	embedded system;file spanning;greedy algorithm;heuristic;integer programming;local search (optimization);mathematical optimization;randomized algorithm;real life;routing	Martin W. P. Savelsbergh;Jin-Hwa Song	2008	Computers & OR	10.1016/j.cor.2006.10.020	mathematical optimization;greedy algorithm;integer programming;combinatorial optimization;computer science;mathematics;algorithm	AI	18.28688201608437	5.73615390533031	164998
194f71473bb13ababb9e0d08f6a6eb307273c7a0	colorful bin packing		We study a variant of online bin packing, called colorful bin packing. In this problem, items that are presented one by one are to be packed into bins of size 1. Each item i has a size si ∈ [0, 1] and a color ci ∈ C, where C is a set of colors (that is not necessarily known in advance). The total size of items packed into a bin cannot exceed its size, thus an item i can always be packed into a new bin, but an item cannot be packed into a non-empty bin if the previous item packed into that bin has the same color, or if the occupied space in it is larger than 1 − si. This problem generalizes standard online bin packing and online black and white bin packing (where |C| = 2). We prove that colorful bin packing is harder than black and white bin packing in the sense that an online algorithm for zero size items that packs the input into the smallest possible number of bins cannot exist for |C| ≥ 3, while it is known that such an algorithm exists for |C| = 2. We show that natural generalizations of classic algorithms for bin packing fail to work for the case |C| ≥ 3, and moreover, algorithms that perform well for black and white bin packing do not perform well either, already for the case |C| = 3. Our main results are a new algorithm for colorful bin packing that we design and analyze, whose absolute competitive ratio is 4, and a new lower bound of 2 on the asymptotic competitive ratio of any algorithm, that is valid even for black and white bin packing.	bin packing problem;color;competitive analysis (online algorithm);online algorithm;set packing	György Dósa;Leah Epstein	2014		10.1007/978-3-319-08404-6_15	combinatorics;mathematics;bin;algorithm;square packing in a square	Theory	17.10105899564634	15.47050211614923	165005
d45077cf4ef705f8dc9e8c87d3f5ffb24c7084b7	non-cooperative capacitated facility location games	algorithmic game theory;price of anarchy;theory of computation;graph algorithms;facility location	We study capacitated facility location games, where players control terminals and need to connect each one to a facility from a set of possible locations. There are opening costs and capacity restrictions for each facility. Also, there are connection costs for each pair of facility and terminal if such facility attends this terminal. This problem has several applications, especially in distributed scenarios where a central authority is too expensive or even infeasible to exist. In this paper, we analyze and present new results concerning the existence of equilibria, Price of Anarchy (PoA), and Stability (PoS) for metric and non-metric versions of this game. We prove unbounded PoA and PoS for some versions of the game, even when sequential versions are considered. For metric variants, we prove that sequentiality leads to bounded PoA and PoS. We analyze efficiency for capacitated facility location games (CFLG).PNE existence is NP-hard for CFLG with no cost share rules and singleton players.CFLG has unbounded Price of Anarchy (PoA), even for metric instances.Metric CFLG has bounded Price of Stability (PoS).Sequentiality leads to bounded Price of Anarchy and Stability for metric CFLG.	facility location problem;point of sale	Félix Carvalho Rodrigues;Eduardo C. Xavier	2017	Inf. Process. Lett.	10.1016/j.ipl.2016.09.001	price of stability;mathematical optimization;combinatorics;theory of computation;computer science;facility location problem;mathematics;mathematical economics;algorithmic game theory;algorithm;price of anarchy	AI	21.045645946539235	14.787932980343202	165072
190bc5dd0fbb6ea7d7de058dbac4cae5129452b6	resource contention metrics for oversubscribed scheduling problems.	optimal solution;search space;scheduling problem;resource availability	We investigate a task insertion heuristic for oversubscribed scheduling problems, max-availability, that uses a simple estimate of resource contention to assign tasks to intervals expected to have the best worst case resource availability. Prior research in value and variable ordering heuristics for scheduling problems indicated that sophisticated, but more costly measures of resource contention can outperform simpler ones by more reliably pruning the search space. We demonstrate that for oversubscribed, priority-based problems where a feasible, optimal solution may not even exist, max-availability generates schedules of similar quality to other contention based heuristics with much less computational overhead.	backtracking;best, worst and average case;computation;heuristic (computer science);overhead (computing);overselling;resource contention;robotics;schedule (project management);scheduling (computing)	Laurence A. Kramer;Stephen F. Smith	2006			fair-share scheduling;job shop scheduling;mathematical optimization;real-time computing;searching the conformational space for docking;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing	AI	14.422528108748642	9.054950824712977	165099
5935b1d491c937fd5171d62a0567cc74c79f0b7d	the complexity of policy evaluation for finite-horizon partially-observable markov decision processe	stochastic process;partially observed markov decision process;complexite calcul;decision markov;teoria decision;incomplete information;complejidad computacion;policy evaluation;computational complexity;theorie decision;informatique theorique;decision theory;finite horizon;markov decision;computer theory;health care;informatica teorica	A partially-observable Markov decision process (POMDP) is a generalization of a Markov decision process that allows for incomplete information regarding the state of the system. POMDPs are used to model controlled stochastic processes, from health care to manufacturing control processes (see 19] for more examples). We consider several avors of nite-horizon POMDPs. Our results concern the complexity of the policy evaluation and policy existence problems, which are characterized in terms of completeness for complexity classes. Although a large body of literature in mathematics, operations research, and engineering deals with optimization and approximation strategies for POMDPs, there has been little work aimed at characterizing the complexity of these problems and proving lower bounds. We prove a new upper bound of the policy evaluation problem for POMDPs, showing it is Prob-abilistic Logspace complete. From this, we prove policy existence problems for several variants of unobservable, succinctly represented MDPs to be complete for NP PP , a class for which not many natural problems are known to be complete. Our work presents a uniform approach to a wide variety of planning problems, and diiers from previous works as follows. Papadimitriou and Tsitsiklis 22] considered a diierent policy existence problem, to which the problem to determine an optimal policy does not polynomial-time reduce, whereas it does so in our work. Beauquier et al. 5] considered diierent optimality criteria. Most of the related AI literature, especially 9, 11, 10] consider computationally simpler problems without probabilistic transitions. Thus, the complexity of their problems is generally lower than of ours (except 18, 14] and one theorem in 9]).	approximation;complexity class;horizon effect;l (complexity);markov chain;mathematical optimization;operations research;partially observable markov decision process;stochastic process;time complexity;word lists by frequency	Martin Mundhenk;Judy Goldsmith;Eric Allender	1996		10.1007/BFb0029956	markov decision process;stochastic process;partially observable markov decision process;decision theory;artificial intelligence;machine learning;mathematics;computational complexity theory;complete information;algorithm;health care;statistics	AI	14.734585789479498	16.862524245392684	165321
4956f5a1ca232921ff56a5f526764ddf4d2ccfcf	on solving the most strings with few bad columns problem: an ilp model and heuristics	integer linear programming;electronic mail;greedy algorithms integer linear programming linear programming benchmark testing electronic mail optimization bioinformatics;greedy algorithms;linear programming bioinformatics combinatorial mathematics computational complexity greedy algorithms integer programming;integer programming;cplex most strings with few bad columns problem ilp model np hard combinatorial optimization problem bioinformatics integer linear programming model greedy heuristic greedy based pilot method;linear programming;optimization;combinatorial mathematics;benchmark testing;conference lecture;bioinformatics	The most strings with few bad columns problem is an NP-hard combinatorial optimization problem from the bioinformatics field. This paper presents the first integer linear programming model for this problem. Moreover, a simple greedy heuristic and a more sophisticated extension, namely a greedy-based pilot method, are proposed. Experiments show that, as expected, the greedy-based pilot method improves over the greedy strategy. For problem instances of small and medium size the best results were obtained by solving the integer linear programming model by CPLEX, while the greedy-based pilot methods scales much better to large problem instances.	bioinformatics;cplex;column (database);combinatorial optimization;experiment;greedy algorithm;heuristic (computer science);integer programming;linear programming;mathematical optimization;np-hardness;optimization problem;programming model	Evelia Lizárraga;Maria J. Blesa;Christian Blum;Günther R. Raidl	2015	2015 International Symposium on Innovations in Intelligent SysTems and Applications (INISTA)	10.1109/INISTA.2015.7276795	greedy randomized adaptive search procedure;mathematical optimization;combinatorics;greedy algorithm;integer programming;branch and price;optimal substructure;cutting stock problem;change-making problem;machine learning;mathematics;branch and cut	Theory	23.696229294626434	4.785170638679243	165373
968c004e214206f924b605b1d30f7ce4f68d5cd8	a ptas for the multiple parallel identical multi-stage flow-shops to minimize the makespan		In the parallel k-stage flow-shops problem, we are given m identical k-stage flow-shops and a set of jobs. Each job can be processed by any one of the flow-shops but switching between flow-shops is not allowed. The objective is to minimize the makespan, which is the finishing time of the last job. This problem generalizes the classical parallel identical machine scheduling (where (k = 1)) and the classical flow-shop scheduling (where (m = 1)) problems, and thus it is (text {NP})-hard. We present a polynomial-time approximation scheme for the problem, when m and k are fixed constants. The key technique is to enumerate over schedules for big jobs, solve a linear programming for small jobs, and add the fractional small jobs at the end. Such a technique has been used in the design of similar approximation schemes.	makespan;ptas reduction	Weitian Tong;Eiji Miyano;Randy Goebel;Guohui Lin	2016		10.1007/978-3-319-39817-4_22	mathematical optimization;scheduling (computing);job shop scheduling;linear programming;multiprocessor scheduling;schedule;polynomial-time approximation scheme;mathematics;flow shop scheduling	NLP	15.797171356767587	9.629618724499478	165793
07615a2bf865461447399d4bd8d1f8cf7047eaff	multiobjective optimization: improved fptas for shortest paths and non-linear objectives with applications	camino mas corto;constrained optimization;multicommodity flow;multiobjective programming;shortest path;programmation multiobjectif;optimisation;optimizacion;routing;routage;plus court chemin;problema np duro;qualite service;np hard problem;programacion lineal;general methods;probleme np difficile;community networks;mathematical programming;approximate solution;linear programming;programmation lineaire;multiobjective optimization;optimization;qos routing;programmation mathematique;programacion matematica;service quality;calidad servicio;programacion multiobjetivo;enrutamiento	We provide an improved FPTAS for multiobjective shortest paths, a fundamental (NP-hard) problem in multiobjective optimization, along with a new generic method for obtaining FPTAS to any multiobjective optimization problem with non-linear objectives. We show how these results can be used to obtain better approximate solutions to three related problems that have important applications in QoS routing and in traffic optimization.	multi-objective optimization;polynomial-time approximation scheme	George Tsaggouris;Christos D. Zaroliagis	2006		10.1007/11940128_40	mathematical optimization;routing;constrained optimization;multi-commodity flow problem;computer science;linear programming;multi-objective optimization;np-hard;mathematics;shortest path problem;service quality;algorithm	Theory	22.208517073965226	11.58875507985168	165902
9195ec9fdeb6eaa8ed0e4f38288c463e681300f4	formulating a scheduling problem with almost identical jobs by using positional completion times	lower and upper bound;scheduling problem	We present a new type of formulation for scheduling problems where jobs are identical in all aspects but one. This type of formulation is particularly useful for deriving Lagrangian lower and upper bounds for flowshop problems, where the jobs only differ in their processing times. We illustrate the effectiveness of this type of formulation for a two-machine flowshop problem where the first machine is a batching machine.		Han Hoogeveen;Steef L. van de Velde	1995		10.1007/3-540-59408-6_59	job shop scheduling;mathematical optimization;earliest deadline first scheduling;rate-monotonic scheduling;mathematics;distributed computing;multiprocessor scheduling	Networks	15.355696794892442	8.939564665698015	166134
ff608955914fb3b9224aa59d91e58c5ee61dc7e9	folk solution for simple minimum cost spanning tree problems	minimum cost spanning tree problem;simple mcst problem;eleccio social;economia del benestar;elementary cost matrix;info eu repo semantics article;jocs cooperatius;33 economia;folk solution	A minimum cost spanning tree problem analyzes how to e ciently connect a group of individuals to a source. Once the e cient tree is obtained, the addressed question is how to allocate the total cost among the involved agents. One prominent solution in allocating this minimum cost is the so-called Folk solution. Unfortunately, in general, the Folk solution is not easy to compute. We identify a class of mcst problems in which the Folk solution is obtained in an easy way.		Begoña Subiza;José-Manuel Giménez-Gómez;Josep E. Peris	2016	Oper. Res. Lett.	10.1016/j.orl.2016.06.008	mathematical optimization;mathematics;mathematical economics;distributed minimum spanning tree;algorithm	Theory	24.45914672527824	13.47480961503529	166319
9cd0a23599cfe850247e36d4400daf7fc2cc7b70	a ga-tabu algorithm for scheduling in-line steppers in low-yield scenarios	meta heuristic algorithm;scheduling algorithm;scheduling;genetic algorithm;tabu search;port capacity constraints;numerical experiment;capacity constraint;article;semiconductor;flow shop;heuristic algorithm	This paper presents a scheduling algorithm for an in-line stepper in low-yield scenarios, which mostly appear in cases when new process/production is introduced. An in-line stepper is a bottleneck machine in a semiconductor fab. Its interior comprises a sequence of chambers, while its exterior is a dock equipped with several ports. The transportation unit for entry of each port is a job (a group of wafers), while that for each chamber is a piece of wafer. This transportation incompatibility may lead to a capacity-loss, in particular in low-yield scenarios. Such a capacity-loss could be alleviated by effective scheduling. The proposed scheduling algorithm, called GA-Tabu, is a combination of a genetic algorithm (GA) and a tabu search technique. Numerical experiments indicate that the GA-Tabu algorithm outperforms seven benchmark ones. In particular, the GA-Tabu algorithm outperforms a prior GA both in solution quality and computation efforts. 2009 Elsevier Ltd. All rights reserved.	benchmark (computing);computation;experiment;genetic algorithm;numerical method;scheduling (computing);semiconductor fabrication plant;software incompatibility;software release life cycle;tabu search;wafer (electronics)	Chie-Wun Chiou;Muh-Cherng Wu	2009	Expert Syst. Appl.	10.1016/j.eswa.2009.03.064	fair-share scheduling;mathematical optimization;earliest deadline first scheduling;simulation;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;least slack time scheduling;lottery scheduling;scheduling	AI	13.428806098368135	5.169135431662949	166381
096d25d2810a7df1f30bf33376045fe052394ae9	a primal partitioning solution for the arc-chain formulation of a multicommodity network flow problem	multicommodity primal partitioning solution;networks graphs;problema transporte;transportation problem;large scale systems multicommodity network flow problems;decomposition;metodo simplejo;transportation shipping transshipment and consolidation problems;probleme transport;simplex method;industries;reseau;red;programacion lineal;particion;transbordo;partition;linear programming;transbordement;programmation lineaire;descomposicion;network flow;linear;programming;methode simplexe;flot reseau;network;transhipment	We present a new solution approach for the multicommodity network flow problem (MCNF) based upon both primal partitioning and decomposition techniques, which simplifies the computations required by the simplex method. The partitioning is performed on an arc-chain incidence matrix of the MCNF, similar within a change of variables to the constraint matrix of the master problem generated in a Dantzig-Wolfe decomposition, to isolate a very sparse, near-triangular working basis of greatly reduced dimension. The majority of the simplex operations performed on the partitioned basis are simply additive and network operations specialized for the nine possible pivot types identified. The columns of the arc-chain incidence matrix are generated by a dual network simplex method for updating shortest paths when link costs change.	flow network	Judith M. Farvolden;Warren B. Powell;Irvin Lustig	1993	Operations Research	10.1287/opre.41.4.669	partition;transportation theory;programming;mathematical optimization;combinatorics;transshipment;flow network;linear programming;mathematics;linearity;decomposition;simplex algorithm;algorithm	Theory	22.347953789819957	12.338259031781412	166539
23e4909b059ddeca590e369048abfad8a3e44e6c	applying scheduling techniques to minimize the number of late jobs in workflow systems	simulation;workflow system;scheduling;scheduling problem;workflow;genetic algorithm;earliest due date	Ordering the cases in a workflow can result in significant decrease on the number of late jobs. But merging workflow and scheduling is not trivial. This paper presents some of the problems of using scheduling results in ordering cases in a workflow and tackles two of them: the uncertainties on the cases' processing times and routing. A new approach to modeling these uncertainties is also proposed: the guess and solve technique. It consists of making a guess on the execution times and routes the case will follow, and solving the corresponding deterministic scheduling problem using a suitable technique, in this paper genetic algorithms. Simulation results show that for almost all workloads rules such as earliest due date first, and guess and solve (if the error in guessing is bound by 30%) are statistically significantly better than the commonly used FIFO rule regarding the number of late jobs.	fifo (computing and electronics);genetic algorithm;job stream;routing;scheduling (computing);simulation;single-machine scheduling	Gregório Baggio;Jacques Wainer;Clarence A. Ellis	2004		10.1145/967900.968180	fair-share scheduling;job shop scheduling;workflow;real-time computing;earliest deadline first scheduling;genetic algorithm;dynamic priority scheduling;computer science;theoretical computer science;operating system;distributed computing;scheduling;multiprocessor scheduling	Embedded	15.24462299979422	8.760954438298112	166669
03153e88d0a589cc0ac0db636eb4c6c977aea48c	heuristics for the bi-objective path dissimilarity problem	multiobjective programming;programmation multiobjectif;optimisation;metaheuristics;optimizacion;routing;heuristic method;prension;multi objective optimization;routage;metodo heuristico;riesgo accidente;gripping;risque accidentel;optimization problem;metamodel;metamodele;efficient frontier;metamodelo;bi objective programming;prehension;optimization;methode heuristique;hazard;programacion multiobjetivo;enrutamiento	In this paper the Path Dissimilarity Problem is considered. The problem has been previously studied in several contexts, the most popular motivated by the need of selecting routes for transportation of hazardous materials. The aim of this paper is to formally introduce the problem as a bi-objective optimization problem, in which a single solution consists of a set of p different paths, and two conflicting objectives arise, on one side the average length of the paths that must be kept low, and on the other side the dissimilarity among the paths in the set, that should be kept high. Previous methods are reviewed and adapted to our bi-objective problem, in this way we are able to compare the methods using the standard measures in multi-objective optimization. A new GRASP procedure is proposed and tested among the revised methods, and we show that it is able of creating better approximations of the efficient frontiers than existing methods.	algorithm;approximation;experiment;grasp;heuristic (computer science);mathematical optimization;modern portfolio theory;multi-objective optimization;optimization problem	Rafael Martí;José Luis González Velarde;Abraham Duarte	2009	Computers & OR	10.1016/j.cor.2009.01.003	metamodeling;optimization problem;efficient frontier;mathematical optimization;routing;hazard;computer science;artificial intelligence;multi-objective optimization;mathematics;algorithm;metaheuristic	AI	20.3744543121748	5.387388546672939	166707
0b9435af5eb668889d5d052bc0b57ee00a724dbc	solving the car sequencing problem via branch & bound	modelizacion;chaine fabrication;programmation logique avec contrainte;sequencage;sobrecarga;constraint logic programs;mixed model assembly lines;automovil;linea montaje;branching;modele mixte;programacion logica con restriccion;logical programming;production line;modelisation;assembly;sequencing;planificacion;branch and bound method;mixed model;programmation logique;metodo branch and bound;car sequencing;automobile;scheduling;ramificacion;surcharge;motor car;combinatorial complexity;court terme;assembly line;mixed model assembly line;ramification;planning;montage;linea fabricacion;constraint logic programming;branch bound;methode separation et evaluation;planification;montaje;modelo mixto;overload;programacion logica;modeling;ordonnancement;corto plazo;short term;chaine montage;reglamento	In a mixed-model assembly line, varying models of the same basic product are to be produced in a facultative sequence. This results to a short-term planning problem where a sequence of models is sought which minimizes station overloads. In practice - e.g. the final assembly of cars - special sequencing rules are enforced which restrict the number of models possessing a certain optional feature k to rk within a subsequence of sk successive models. This problem is known as car sequencing. So far, employed solution techniques stem mainly from the field of Logic and Constraint Logic Programming. In this work, a special Branch & Bound algorithm is developed, which exploits the problem structure in order to reduce combinatorial complexity.	branch and bound	Malte Fliedner;Nils Boysen	2008	European Journal of Operational Research	10.1016/j.ejor.2007.04.045	constraint logic programming;planning;mixed model;systems modeling;branching;production line;computer science;operations management;sequencing;mathematics;assembly;short-term memory;ramification;scheduling;branch and bound;algorithm	Theory	18.774722431364314	7.764352413960485	166804
846f53a4126f95fab8a61c05294a3e716a7acda1	grasp with exterior path-relinking and restricted local search for the multidimensional two-way number partitioning problem	restricted local search;binary combinatorial optimisation;multidimensional two way number partitioning problem;exterior path relinking;grasp	In this work, we tackle multidimensional two-way number partitioning (MDTWNP) problem by combining GRASP with Exterior Path Relinking. In the last few years, the combination of GRASP with path relinking (PR) has emerged as a highly effective tool for finding high-quality solutions for several difficult problems in reasonable computational time. However, in most of the cases, this hybridisation is limited to the variant known as interior PR. Here, we couple GRASP with the “exterior form” of path relinking and perform extensive experimentation to evaluate this variant. In addition, we enhance our GRASP with PR method with a novel local search method specially designed for the MDTWNP problem. Our computational experiments show the superiority of this approach compared with the previous best method for MDTWNP and with alternative methods for this problem that use other forms of PR.	grasp;local search (optimization);partition problem	Francisco J. Rodríguez;Fred Glover;Carlos García-Martínez;Rafael Martí;Manuel Lozano	2017	Computers & OR	10.1016/j.cor.2016.09.005	mathematical optimization;combinatorics;grasp;mathematics;geometry	AI	24.05580862305764	5.193729100408007	166829
868989116ede6bf12e426234900e204808f22f87	improvised divide and conquer approach for the lis problem		Abstract There exist many optimal (using single and multiple processors) and approximate solutions to the longest increasing subsequence (LIS) problem. Through this paper, we present the enhancement to the divide-and-conquer approach presented in paper [1] . An improved Du0026C algorithmic solution is proposed which outputs optimal solution in all cases. The proposed algorithm takes O ( n log ⁡ n ) time in best and average cases and o ( n log 2 ⁡ n ) time in worst case. The portion of the proposed solution can run in parallel using multiprocessors.		Seema Rani;Dharmveer Singh Rajpoot	2018	J. Discrete Algorithms	10.1016/j.jda.2018.01.001	discrete mathematics;combinatorics;divide and conquer algorithms;mathematics;longest increasing subsequence	AI	17.00773862051686	12.591040967047533	167025
6e5463d0360aea29d6e0d3bde07c4a5d8d076819	the travelling salesperson problem with hotel selection	science general;forecasting;optimal solution;heuristic;selection problem;optimisation;reliability;problema seleccion;metaheuristics;project management;information systems;optimizacion;maintenance;tsp;travelling salesman problem;soft or;information technology;heuristic method;packing;cib_public;recherche voisinage;metodo heuristico;salesman problem;operations research;location;investment;journal;journal of the operational research society;inventory;problema viajante comercio;purchasing;optimization problem;algorithm;search;temps calcul;cib_lpp;history of or;vehicle routing problems;hotel selection;logistics;probleme commis voyageur;marketing;scheduling;production;communications technology;travelling salesperson problem;optimization;methode heuristique;computer science;operational research;tiempo computacion;computation time;hotel;neighborhood search;applications of operational research;or society;busqueda de cercania;jors;management science;infrastructure;time windows;probleme selection	In this paper, we present the travelling salesperson problem with hotel selection (TSPHS), an extension of the TSP with a number of interesting applications. We present a mathematical formulation, explain the difference with related optimization problems and indicate what makes this problem inherently more difficult. We develop a simple but efficient heuristic that uses two constructive initialization procedures and an improvement procedure consisting of several neighbourhood search operators designed specifically for this problem, as well as some typical neighbourhoods from the literature. We generate several benchmark instances of varying sizes and compare the performance of our heuristic with CPLEX (10.0). We also generate some problems with known optimal solutions and use these to further demonstrate that our heuristic achieves good results in very limited computation times. Journal of the Operational Research Society (2012) 63, 207–217. doi:10.1057/jors.2011.18 Published online 14 September 2011	benchmark (computing);cplex;computation;goto;heuristic;local search (optimization);mathematical optimization;microsoft windows;search algorithm;travelling salesman problem	Pieter Vansteenwegen;Wouter Souffriau;Kenneth Sörensen	2012	JORS	10.1057/jors.2011.18	project management;optimization problem;logistics;simulation;heuristic;inventory;economics;forecasting;investment;computer science;marketing;operations management;reliability;mathematics;location;travelling salesman problem;management;operations research;information technology;scheduling	AI	18.1284040977028	5.148482530915654	167100
12e999aa23763bec7ebda76f63d55a79a6c760f7	on the flexibility of constraint programming models: from single to multiple time windows for the traveling salesman problem	traveling salesman problem;travelling salesman problem;flexibilidad;time window;multiple time windows;traveling salesman;problema viajante comercio;branch and bound method;metodo branch and bound;probleme commis voyageur;constraint programming;iterative cost deepening;flexibilite;methode separation et evaluation;branch and bound;flexibility	One of the major strengths of Constraint Programming is the exibility and expressiveness of models in that computational paradigm, which make it easy to add problem-dependent constraints without having to modify the solution strategy. We show here what needs to be done in order to adapt a constraint programming algorithm for the traveling salesman problem with time windows so that it can handle multiple time windows. Computational results are also presented on a set of instances created for that little-studied problem.	algorithm;computation;constraint programming;microsoft windows;programming paradigm;travelling salesman problem	Gilles Pesant;Michel Gendreau;Jean-Yves Potvin;Jean-Marc Rousseau	1999	European Journal of Operational Research	10.1016/S0377-2217(98)00248-3	constraint logic programming;traveling purchaser problem;2-opt;mathematical optimization;constraint programming;constraint satisfaction;computer science;artificial intelligence;mathematics;travelling salesman problem;algorithm;bottleneck traveling salesman problem	Theory	20.288444057076017	6.050782179282479	167380
cdd3e319568105c7529b09b7211f1d674418b0ae	solving a supply chain scheduling problem with non-identical job sizes and release times by applying a novel effective heuristic algorithm	batching;supply chain scheduling;worst case analysis;期刊论文;release times;heuristic algorithm	Solving a supply chain scheduling problem with nonidentical job sizes and release times by applying a novel effective heuristic algorithm Jun Pei, Xinbao Liu, Panos M. Pardalos, Wenjuan Fan, Ling Wang & Shanlin Yang a School of Management, Hefei University of Technology, Hefei, China b Department of Industrial and Systems Engineering, Center for Applied Optimization, University of Florida, Gainesville, FL, USA c Key Laboratory of Process Optimization and Intelligent Decision-Making, Ministry of Education, Hefei, China d Department of Computer Science, North Carolina State University, Raleigh, NC, USA Published online: 03 Apr 2014.	academy;algorithm;artificial intelligence;automation;best, worst and average case;cloud computing;combinatorial optimization;computation;computer science;data mining;decision theory;e-commerce;experiment;heuristic (computer science);information management;information system;integer programming;internet of things;job shop scheduling;jun wang (scientist);linear programming;makespan;management science;mathematical optimization;mechatronics;np-hardness;network planning and design;numerical analysis;panos;process optimization;program optimization;programming model;radio frequency;scheduling (computing);strong np-completeness;systems engineering;weitao yang	Jun Pei;Xinbao Liu;Panos M. Pardalos;Wenjuan Fan;Ling Wang;Shanlin Yang	2016	Int. J. Systems Science	10.1080/00207721.2014.902553	heuristic;mathematical optimization;real-time computing;computer science;mathematics	AI	13.531360526606663	9.137437773683619	167386
2f9502cab30964bb821a1d5d17e440d414d8ac1b	on the minimum cost multiple-source unsplittable flow problem	flujo fuente;probleme sac a dos;programacion entera;source flow;problema ufp;probleme ufp;multiplicite;metric;problema mochila;programmation en nombres entiers;90b18;optimisation combinatoire;knapsack problem;superadditive functions;flujo red;ecoulement source;integer programming;network flows;metodo plano secante;multiplicidad;metrico;network flow;methode plan secant;combinatorial optimization;multiplicity;flot reseau;metrique;unsplittable flow problem;cutting plane method;optimizacion combinatoria;90c10	The minimum cost multiple-source unsplittable flow problem is studied in this paper. A simple necessary condition to get a solution is proposed. It deals with capacities and demands and can be seen as a generalization of the well-known semi-metric condition for continuous multicommdity flows. A cutting plane algorithm is derived using a superadditive approach. The inequalities considered here are valid for single knapsack constraints. They are based on nondecreasing superadditive functions and can be used to strengthen the relaxation of any integer program with knapsack constraints. Some numerical experiments confirm the efficiency of the inequalities introduced in the paper.	algorithm;convex hull;cutting-plane method;experiment;first-class function;flow network;integer programming;knapsack problem;linear programming relaxation;max-flow min-cut theorem;numerical analysis;rounding;routing;semiconductor chip protection act of 1984;semiconductor industry;whole earth 'lectronic link	Meriema Belaidouni;Walid Ben-Ameur	2007	RAIRO - Operations Research	10.1051/ro:2007023	continuous knapsack problem;mathematical optimization;combinatorics;flow network;integer programming;combinatorial optimization;calculus;mathematics	EDA	22.04230698319222	12.23242927156375	167410
1ede7d3a7df7eee01a76da66d7de963ed93e9dd8	time-dependent networks as models to achieve fast exact time-table queries	shortest path;time dependent;efficient algorithm;space time;information system	We consider efficient algorithms for exact time-table queries, i.e. algorithms that find optimal itineraries. We propose to use time-dependent networks as a model and show advantages of this approach over space-time	algorithm;schedule	Gerth Stølting Brodal;Riko Jacob	2004	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2003.12.019	mathematical optimization;computer science;theoretical computer science;machine learning;space time;shortest path problem;information system	ECom	22.61828118083127	7.537813504182227	167642
38c22730ce80b4c08f44a6c46d26f8fb62dfdac6	energy-efficient elevating transfer vehicle routing for automated multi-level material handling systems		Elevating Transfer Vehicles (ETV) are widely utilized in automated multi-level material handling systems for transporting, storing and retrieving units vertically and horizontally. Reducing energy consumption of operating ETV is critical for improving both financial and environmental sustain-ability of these systems. We investigate an energy-efficient ETV routing problem (ETVRP), in which an ETV serves a multi-level freight handling system to transport cargo containers between airside and landside in an air cargo terminal. The problem can be regarded as a special case of Stacker Crane Problem defined on a regular grid graph constructed by uniform rectangular tiles. Even with the special grid network structure, the ETVRP is still NP-Complete in general. We manage to identify a subset of the ETVRP instances that are polynomially solvable based on the condition of free-permutation. For general ETVRPs, we develop two approximation algorithms, one of which is asymptotically optimal and has the time-complexity that grows linearly with the number of requests; the other has a bounded time-complexity and works better for instances with smaller arc lengths. Combining these two algorithms can guarantee an approximation ratio of 5/3.	approximation algorithm;asymptotically optimal algorithm;decision problem;grid network;lattice graph;loss function;material handling;np-completeness;regular grid;time complexity;vehicle routing problem	Zhou Fang;Jianfeng Mao	2017	2017 13th IEEE Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2017.8256111	vehicle routing problem;asymptotically optimal algorithm;approximation algorithm;stacker;regular grid;grid network;distributed computing;special case;bounded function;computer science	Robotics	18.791409304752023	14.108867719707538	167851
6236548b1670a8feb7e8dda3d611008a07efc8d3	the ordered distribute constraint	generalized arc-consistency;constraint limit;new constraint;new cardinality constraint;ordered distribute constraint;times v;global cardinality constraint;time complexity;ordered distribute;value v;limiting;constraint programming;computational complexity;algorithm design and analysis;schedules;algorithm;optimization	In this paper we introduce a new cardinality constraint: Ordered Distribute. Given a set of variables, this constraint limits for each value v the number of times v or any value greater than v is taken. It extends the global cardinality constraint, that constrains only the number of times a value v is taken by a set of variables and does not consider at the same time the occurrences of all the values greater than v. We design an algorithm for achieving generalized arc-consistency on Ordered Distribute, with a time complexity linear in the sum of the number of variables and the number of values in the union of their domains. In addition, we give some experiments showing the advantage of this new constraint for problems where values represent levels whose overrunning has to be under control. Finally, we present three extensions of our constraint that can be particularly useful in practice.		Thierry Petit;Jean-Charles Régin	2011	International Journal on Artificial Intelligence Tools	10.1142/S0218213011000371	constraint logic programming;mathematical optimization;binary constraint	Robotics	19.850946156677843	12.821224800938221	168069
6c8d90f28830bda307da357433bcba5a716974f6	effective algorithm and heuristic for the generalized assignment problem	decision tree;generalized assignment problem;branch and bound algorithm;solution improvement heuristic;subgradient method;upper bound;generalized assignment;branch and bound;knapsack	We present new Branch-and-Bound algorithm for the generalized assignment problem. A standard subgradient method (SM), used at each node of the decision tree to solve the Lagrangian dual, provides an upper bound. Our key contribution in this paper is a new heuristic, applied at each iteration of the SM, which tries to exploit the solution of the relaxed problem, by solving a smaller generalized assignment problem. The feasible solution found is then subjected to a solution improvement heuristic. We consider processing the root node as a Lagrangian heuristic. Computational comparisons are made with new existing methods.	algorithm;generalized assignment problem;heuristic	Salim Haddadi;Hacene Ouzia	2004	European Journal of Operational Research	10.1016/S0377-2217(02)00710-5	null-move heuristic;mathematical optimization;combinatorics;discrete mathematics;linear bottleneck assignment problem;computer science;generalized assignment problem;mathematics;weapon target assignment problem;branch and bound	Robotics	20.85889937788884	9.947433091243884	168259
0bee15723325180d0fa2d55a3d50240a20e9ce21	solution of a min-max vehicle routing problem	cutting plane;vehicle routing problem;information technology;distributed computing;vehicle routing;computer network;integer programming;distributed search;integer program;combinatorial optimization	We use a branch-and-cut search to solve the Whizzkids’96 vehicle routing problem, demonstrating that the winning solution in the 1996 competition is in fact optimal. Our algorithmic framework combines the LP-based traveling salesman code of Applegate, Bixby, Chvátal, and Cook, with specialized cutting planes and a distributed search algorithm, permitting the use of a computing network located across Rice, Princeton, AT&T, and Bonn. The 1996 problem instance was developed by E. Aarts and J. K. Lenstra, and the competition was sponsored by the information technology firm CMG and the newspaper De Telegraaf. (Combinatorial Optimization; Vehicle Routing; Integer Programming; Distributed Computing)	arjen lenstra;branch and cut;combinatorial optimization;distributed computing;distributed web crawling;integer programming;search algorithm;vehicle routing problem	David Applegate;William J. Cook;Sanjeeb Dash;André Rohe	2002	INFORMS Journal on Computing	10.1287/ijoc.14.2.132.118	mathematical optimization;static routing;simulation;computer science;destination-sequenced distance vector routing;vehicle routing problem;mathematics;distributed computing;algorithm;cutting-plane method	Theory	21.855501930015564	8.515056739407623	168486
63c0ab3ca874cfa57fa6dcae444108a30970f7c9	fast strong planning for fond problems with multi-root directed acyclic graphs	fully observable nondeterministic fond planning;strong cyclic planning;strong planning	We present a planner for addressing a difficult, yet under-investigated class of planning problems: Fully Observable Non-Deterministic planning problems with strong solutions. Our strong planner employs a new data structure, MRDAG (multi-root directed acyclic graph), to define how the solution space should be expanded. We further equip a MRDAG with heuristics to ensure planning towards the relevant search direction. We performed extensive experiments to evaluate MRDAG and the heuristics. Results show that our strong algorithm achieves impressive performance on a variety of benchmark problems: on average it runs more than three orders of magnitude faster than the state-of-the-art planners, MBP and Gamer, and demonstrates significantly better scalability.	algorithm;benchmark (computing);data structure;directed acyclic graph;experiment;feasible region;heuristic (computer science);million book project;observable;scalability	Andres Calderon Jaramillo;Jicheng Fu;Vincent Ng;Farokh B. Bastani;I-Ling Yen	2013	2013 IEEE 25th International Conference on Tools with Artificial Intelligence	10.1142/S0218213014600288	mathematical optimization;algorithm	AI	22.699959893853496	4.339307625353948	168819
bac8f1197a30d239f1fb1e0047c163e123d7cc16	comparative analysis of some metaheuristics for discrete-continuous project scheduling with activities of identical processing rates	nonlinear programming;net present value;simulated annealing;genetic algorithm;tabu search;discrete continuous project scheduling	Discrete-continuous project scheduling problems with positive discounted cash flows and maximization of the net present value are considered. A class of these problems with an arbitrary number of discrete resources and one continuous, renewable resource is taken into account. Activities are nonpreemptable, and the processing rate of each activity is the same continuous, increasing, and concave function of the amount of the continuous resource allotted to the activity at a time. Three common payment models — lump sum payment, payments at activity completion times, and payments in equal time intervals are analyzed. Adaptations of three well-known metaheuristics — simulated annealing, tabu search, and genetic algorithm are described. The paper focuses on a comparative analysis of the metaheuristics. The algorithms are computationally compared on a basis of an extensive experiment. Some conclusions and directions for future research are pointed out.	metaheuristic;schedule (project management)	Grzegorz Waligóra	2016	APJOR	10.1142/S0217595916500159	mathematical optimization;net present value;simulation;genetic algorithm;simulated annealing;tabu search;nonlinear programming;computer science;operations management;mathematics	OS	15.014317711789161	5.065142120815748	169025
dbbde3a6d3e57ec9250da60c92fd9b7e5eacc8ac	makespan minimization for multiple uniform machines	optimal solution;time complexity;makespan;computer experiment;uniform machines;scheduling;scheduling problem;parallel machines;optimal algorithm;lower bound	We consider a classical scheduling problem with makespan minimization on uniform parallel machines. From the viewpoint of workload, instead of completion time, two important theorems are developed for the problem. The first theorem provides an improved lower bound as the starting point for the search, and the second theorem further accelerates the search speed in the algorithm. Incorporating the two useful theorems, an algorithm is developed for obtaining the optimal solution. Although the developed algorithm has an exponential time complexity, extensive computational experiments demonstrate that it is quite efficient for various sizes of the problem. With the optimal algorithm, we also examine the effectiveness of the popular LPT heuristic. 2007 Elsevier Ltd. All rights reserved.	algorithm;computation;convex optimization;experiment;heuristic;load (computing);makespan;parallel computing;parallel port;requirement;scheduling (computing);time complexity	Chien-Hung Lin;Ching-Jong Liao	2008	Computers & Industrial Engineering	10.1016/j.cie.2007.11.009	time complexity;job shop scheduling;mathematical optimization;combinatorics;computer experiment;computer science;mathematics;distributed computing;upper and lower bounds;scheduling	AI	15.950978359349689	10.360688102418118	169056
b5149b6e7387e51bef84a1d1146b21e0591e2867	set covering in fuel-considered vehicle routing problems	bicriteria approximation algorithms;total unimodularity;set covering;fuel considered vehicle routing problems;lower bound	The paper studies set covering in fuel-considered vehicle routing problems (FVRP). Firstly, we study the FVRP with distance constraint and time windows (FVRP-TW) whose objective is to find a set covering with the minimum cardinality, which means the number of used vehicles is minimized and hence the fuel consumption is minimized in the real logistics. We give a bicriteria approximation algorithm for this problem. Secondly, we study the set covering in the FVRP with distance constraint and constant time windows (FVRP-CTW), which has a constant number of the time windows provided by logistics companies. We give a bicriteria approximation algorithm with ( 2 + ? , O ( log ? 1 / ? ) ) for this problem, in which the first term is the approximation ratio on the distance constraint and the second term is the approximation ratio on the cardinality of the covering set. Thirdly, we study the set covering in general FVRP and propose a lower bound for this problem which is based on total unimodularity. Finally, we design an algorithm framework based on the lower bound for solving the set covering in general FVRP. Simulation results demonstrate the effectiveness of the algorithms for solving the set covering in FVRP-TW and general FVRP.	approximation algorithm;context tree weighting;mahdiyar;set cover problem;simulation;vehicle routing problem	Liang Song;Haibin Chen;Hao Gu;Hejiao Huang;Hongwei Du	2015	Theor. Comput. Sci.	10.1016/j.tcs.2015.06.009	mathematical optimization;combinatorics;discrete mathematics;mathematics;upper and lower bounds	ECom	23.33848247955205	8.428056306500325	169058
8efd587c34088a670381c59e7dbe92b10a160810	random 3-sat and bdds: the plot thickens further	diagrama binaria decision;diagramme binaire decision;complexite calcul;satisfiability;constraint satisfaction;reduced ordered binary decision diagram;combinatorial problem;satisfaction contrainte;complejidad computacion;probleme combinatoire;problema combinatorio;computational complexity;heuristic optimization;plot;transition phase;phase transitions;transicion fase;low density;satisfaccion restriccion;parcelle;parcela;binary decision diagram	This paper contains an experimental study of the impact of the construction strategy of reduced, ordered binary decision diagrams (ROBDDs) on the average-case computational complexity of random 3-SAT, using the CUDD package. We study the variation of median running times for a large collection of random 3-SAT problems as a function of the density as well as the order (number of variables) of the instances. We used ROBDD-based pure SAT-solving algorithms, which we obtained by an aggressive application of existential quantification, augmented by several heuristic optimizations. Our main finding is that our algorithms display an “easy-hard-less-hard” pattern that is quite similar to that observed earlier for search-based solvers. When we start with low-density instances and then increase the density, we go from a region of polynomial running time, to a region of exponential running time, where the exponent first increases and then decreases as a function of the density. The locations of both transitions, from polynomial to exponential and from increasing to decreasing exponent, are algorithm dependent. In particular, the running time peak is quite independent from the crossover density of 4.26 (where the probability of satisfiability declines precipitously); it occurs at density 3.8 for one algorithm and at density 2.3 for for another, demonstrating that the correlation between the crossover density and computational hardness is algorithm dependent.	algorithm;average-case complexity;best, worst and average case;binary decision diagram;boolean satisfiability problem;computation;computational complexity theory;exptime;existential quantification;experiment;heuristic;polynomial;probabilistic analysis of algorithms;time complexity	Alfonso San Miguel Aguirre;Moshe Y. Vardi	2001		10.1007/3-540-45578-7_9	phase transition;mathematical optimization;combinatorics;constraint satisfaction;computer science;artificial intelligence;mathematics;plot;computational complexity theory;binary decision diagram;algorithm;statistics;satisfiability	Theory	11.592486582140848	18.073886459706507	169179
2a204ec613e8426a9d6116501e40a6f6e70b4fea	a practical solution using simulated annealing for general routing problems with nodes, edges, and arcs	simulated annealing;data model;computer experiment;data structure	A new practical solution of the general routing problems with nodes, edges, and arcs (NEARP) has been developed. The method is characterized by a primitive data modeling and a simple optimization procedure based on simulated annealing. The data structure of the method, that is traveling routes of a number of vehicles, is expressed as a string. The solutions generated by the proposed method are compared with those of another method by conducting computational experiments on instances of the NEARP. Moreover, it is shown that the proposed method is adaptable to additional conditions.	arcs (computing);routing;simulated annealing	Hisafumi Kokubugata;Ayako Moriyama;Hironao Kawashima	2007		10.1007/978-3-540-74446-7_10	mathematical optimization;computer science;theoretical computer science;machine learning;adaptive simulated annealing	Robotics	23.827234989091593	6.346655906387315	169263
38c0cc056566ccdb7eca3bb8df64d3cc49e67236	heuristics for short route job shop scheduling problems	metodo caso peor;tiempo total acabamiento;approximate algorithm;job shop scheduling;approximation algorithm;qa mathematics;heuristic method;temps total achevement;metodo heuristico;temps minimal;worst case analysis;key words job shop scheduling;permutation;algorithme;algorithm;makespan;scheduling;permutacion;methode cas pire;minimum time;job shop;ordonamiento;methode heuristique;job shop scheduling problem;tiempo minimo;worst case method;ordonnancement;algoritmo	We consider two “minimum”NP-hard job shop scheduling problems to minimize the makespan. In one of the problems every job has to be processed on at most two out of three available machines. In the other problem there are two machines, and a job may visit one of the machines twice. For each problem, we define a class of heuristic schedules in which certain subsets of operations are kept as blocks on the corresponding machines. We show that for each problem the value of the makespan of the best schedule in that class cannot be less than 3/2 times the optimal value, and present algorithms that guarantee a worst-case ratio of 3/2.	heuristic (computer science);job shop scheduling;scheduling (computing)	Inna G. Drobouchevitch;Vitaly A. Strusevich	1998	Math. Meth. of OR	10.1007/s001860050033	job shop scheduling;mathematical optimization;flow shop scheduling;mathematics;permutation;scheduling;algorithm	AI	17.07719383734138	10.379021972560249	169586
9b03103a992fed4d5ea36859ac9eec8e2850fb2e	membrane algorithms: approximate algorithms for np-complete optimization problems	traveling salesman problem;approximate algorithm;simulated annealing algorithm;satisfiability;optimization problem;computer experiment	A new type of approximate algorithm for optimization problems, called the membrane algorithm, is proposed. A membrane algorithm  consists of several regions separated by means of membranes; in each region we place a few tentative solutions of the optimization  problem and a subalgorithm. The subalgorithms improve the tentative solutions simultaneously. The best and worst solutions  in a region are sent to adjacent inner and outer regions, respectively. By repeating this process, a good solution will appear  in the innermost region. The algorithm terminates if a termination condition is satisfied. A simple condition is the number  of iterations, while a little more sophisticated condition becomes true if the good solution is not changed during a predetermined  number of iterations. Computer experiments show that the membrane algorithms solve the traveling salesman problem better than  the simulated annealing algorithm.  	approximation algorithm;np-completeness	Taishin Yasunobu Nishida	2006		10.1007/3-540-29937-8_11	optimization problem;extremal optimization;2-opt;mathematical optimization;greedy algorithm;cross-entropy method;simulated annealing;combinatorial optimization;theoretical computer science;machine learning;mathematics;approximation algorithm;3-opt;metaheuristic;bottleneck traveling salesman problem;quadratic assignment problem	Theory	17.627159794090044	8.23367589054423	169798
13c3bb8e01cf0b7cd7303f951baeaa35d07f0158	design and implementation of an interactive optimization system for telephone network planning	software;concepcion asistida;prevision demande;computer aided design;optimisation;forests;programacion entera;capacidad canal;network planning;optimizacion;logiciel;pacedura;browsing;protection faune;capacite canal;programmation entiere;red telefonica;explotacion forestal;systeme conversationnel;discrete location;algorithme;foret;forest logging;algorithm;modelo;planificacion;integer cutting plane;amenagement milieu;integer programming;habitat;design and implementation;channel capacity;interactive system;acondicionamiento medioambiente;animal conservation;forest planning;natural resources forest planning and the stable set problem;computer aid;sistema conversacional;biotopo;prevision demanda;conception assistee;stable set;logicial;design;asistencia ordenador;planning;optimization;modele;facilities equipment planning capacity expansion;planification;exploitation forestiere;telephone network;bosque;reseau telephonique;dispersion;facet generation;environmental management;planning applications to forest planning;programming;models;assistance ordinateur;broutage animal;biotope;algoritmo;demand forecasting;proteccion fauna	We describe an interactive optimization system for multiperiod exhaust relief planning in the local loop of a public telephone network. In exhaust relief planning in the local loop one seeks the minimum cost capacity expansion plan that meets projected demand over a given planning horizon. The problem can be modeled as an integer programming problem. However, due to cost structures and varying transmission technologies, the single-period exhaust relief planning problem is NP-complete. The size of the problem precludes the use of general purpose integer programming. Based on the mathematical structure and complexity of the problem, we decompose the optimization problem into a single-period dynamic programming problem, and a multiperiod greedy heuristic. A software system surrounds the optimization algorithm and provides interactive planning capabilities, before and after creation of the optimized plan. Important aspects of the system are the model assumptions made to keep the problem tractable, and their effect on the standardization of input data and methodology. The system is in use by several hundred outside plant planners in a major U.S. telephone company. An overview of major elements of the package is given as well as a summary of important implementation issues that arose during the first three years of the on-going project.	mathematical optimization	Carolyn Jack;Sheng-Roan Kai;Alexander Shulman	1992	Operations Research	10.1287/opre.40.1.14	planning;optimization problem;programming;design;dispersion;simulation;integer programming;telephone network;habitat;demand forecasting;operations management;biotope;mathematics;operations research;channel capacity	Robotics	17.79960105931933	5.880678661685726	169945
4171a8add98d8d54f33d319bfa0342d1cd86b987	sum-of-squares heuristics for bin packing and memory allocation	bin packing problem;bin packing;sum of squares;memory allocation	The sum-of-squares algorithm (SS) was introduced by Csirik, Johnson, Kenyon, Shor, and Weber for online bin packing of integral-sized items into integral-sized bins. First, we show the results of experiments from two new variants of the SS algorithm. The first variant, which runs in time O(n&sqrt;BlogB), appears to have almost identical expected waste as the sum-of-squares algorithm on all the distributions mentioned in the original papers on this topic. The other variant, which runs in O(nlogB) time, performs well on most, but not on all of those distributions. We also apply SS to the online memory-allocation problem. Our experimental comparisons between SS and Best Fit indicate that neither algorithm is consistently better than the other. If the amount of randomness in item sizes is low, SS appears to have lower waste than Best Fit, whereas, if the amount of randomness is high Best Fit appears to have lower waste than SS. Our experiments suggest that in both real and synthetic traces, SS does not seem to have an asymptotic advantage over Best Fit, in contrast with the bin-packing problem.	best practice;bin packing problem;experiment;heuristic (computer science);memory management;randomness;set packing;shor's algorithm;synthetic intelligence;tracing (software)	Michael A. Bender;Bryan Bradley;Geetha Jagannathan;Krishnan Pillaipakkamnatt	2007	ACM Journal of Experimental Algorithmics	10.1145/1227161.1227165	mathematical optimization;combinatorics;bin packing problem;computer science;mathematics;algorithm	Theory	15.71341454538012	12.729296736923835	170042
a625f85a913e940999bbd507091c71c4e3419511	scheduling precedence-constrained jobs with stochastic processing times on parallel machines	maastricht university;edge coloring;approximate algorithm;stochastic process;edge dominating set;coloring;clique width;digital archive;dominating set;parallel machine scheduling;weighted sums;probability distribution;open access;precedence constraint;parallel machines;publication;scientific;polynomial algorithms;lp relaxation;institutional repository	We consider parallel machine scheduling problems where the jobs are subject to precedence constraints, and the processing times of jobs are governed by independent probability distributions. The objective is to minimize the weighted sum of job completion times ∑, w, C, in expectation, where w, ⪈ 0. Building upon an LP-relaxation from [3] and an idle time charging scheme from [1], we derive the first approximation algorithms for this model.	approximation algorithm;job stream;lagrangian relaxation;linear programming relaxation;order of approximation;parallel computing;polynomial-time approximation scheme;scheduling (computing);weight function	Martin Skutella;Marc Uetz	2001			probability distribution;stochastic process;mathematical optimization;combinatorics;dominating set;linear programming relaxation;clique-width;theoretical computer science;edge coloring;publication;mathematics;distributed computing	Theory	15.558279478470482	11.831786641887952	170134
1c6fef23fb1952da93e782928c1e543c702fe9bf	a branch-and-cut algorithm for the stochastic uncapacitated lot-sizing problem	multi stage stochastic integer programming;programacion entera;branch and cut method;programmation stochastique;valid inequalities;methode separation et coupe;programmation en nombres entiers;integer programming;tamano lote;mathematical programming;taille lot;lot sizing;stochastic integer programming;polyhedral study;stochastic lot sizing;branch and cut;metodo branch and cut;stochastic programming;programmation mathematique;programacion estocastica;programacion matematica	This paper addresses a multi-stage stochastic integer programming formulation of the uncapacitated lot-sizing problem under uncertainty. We show that the classical (`, S) inequalities for the deterministic lot-sizing polytope are also valid for the stochastic lot-sizing polytope. We then extend the (`, S) inequalities to a general class of valid inequalities, called the (Q, SQ) inequalities, and we establish necessary and sufficient conditions which guarantee that the (Q, SQ) inequalities are facet-defining. A separation heuristic for (Q, SQ) inequalities is developed and incorporated into a branch-and-cut algorithm. A computational study verifies the usefulness of the (Q, SQ) inequalities as cuts.	algorithm;branch and cut;computation;heuristic;integer programming;separation logic;sound quality	Yongpei Guan;Shabbir Ahmed;George L. Nemhauser;Andrew J. Miller	2006	Math. Program.	10.1007/s10107-005-0572-9	stochastic programming;mathematical optimization;combinatorics;integer programming;mathematics;vertex enumeration problem;algorithm;branch and cut	AI	23.50431513037209	11.134357627987857	170147
ff69fff8ce125140dad235397f9afdac09358256	dijkstra's algorithm for solving the shortest path problem on networks under intuitionistic fuzzy environment		In this paper, a well known problem called the Shortest Path Problem (SPP) has been considered in an uncertain environment. The cost parameters for traveling each arc have been considered as Intuitionistic Fuzzy Numbers (IFNs) which are the more generalized form of fuzzy numbers involving a degree of acceptance and a degree of rejection. A heuristic methodology for solving the SPP has been developed, which aim to exploit tolerance for imprecision, uncertainty and partial truth to achieve tractability, robustness and low cost solution corresponding to the minimum-cost path or the shortest path. The Modified Intuitionistic Fuzzy Dijkstra’s Algorithm (MIFDA) has been proposed in this paper for solving Intuitionistic Fuzzy Shortest Path Problem (IFSPP) using the Intuitionistic Fuzzy Hybrid Geometric (IFHG) operator. A numerical example illustrates the effectiveness of the proposed method.	arcs (computing);dijkstra's algorithm;fuzzy number;heuristic;intuitionistic logic;numerical analysis;real life;rejection sampling;self-propelled particles;shortest path problem;theory	Sathi Mukherjee	2012	J. Math. Model. Algorithms	10.1007/s10852-012-9191-7	mathematical optimization;combinatorics;discrete mathematics;pathfinding;fuzzy number;euclidean shortest path;yen's algorithm;mathematics;shortest path problem;shortest path faster algorithm	AI	24.267205992507414	8.124603945483821	170257
664965cb6b58f3a9cb35351977c2c5ae6bfe807f	shortest path algorithms for functional environments	networks;sequential decision problems;shortest path algorithms;combinatorial optimisation;generalised flow	This research generalises classic shortest path algorithms to network environments in which arc-costs are governed by functions, rather than fixed weights. We show that the asymptotic efficiency of our algorithms is identical to their classic counterparts. Previous results, since Knuth in 1976, require several restrictive assumptions on the functions permitted in the network. In contrast, our algorithms require only monotonicity. We present examples illustrating that this is the largest class of functions to which classic algorithms can be generalised. Applications of this work include critical path extensions to solve sequential decision-problems, and generalised network flow with nonlinear gain functions.	algorithm;shortest path problem	Louis Boguchwal	2015	Discrete Optimization	10.1016/j.disopt.2015.09.006	mathematical optimization;combinatorics;discrete mathematics;constrained shortest path first;computer science;mathematics;shortest path problem	EDA	14.822744905456	13.729070605394345	170290
6580a2dbd09bd353825bbf5dd8757839696c9f87	a convex optimisation framework for the unequal-areas facility layout problem	chevauchement;modelizacion;programmation semi definie;semidefinite programming;convex programming;layout problem;probleme agencement;plant layout;optimum global;programmation convexe;global optimisation;overlap;global optimum;imbricacion;analyse convexe;planning installation;modelisation;mathematical programming;problema disposicion;facility layout;convex analysis;programacion semi definida;modeling;proyecto instalacion;programmation mathematique;facility layout semidefinite programming convex programming global optimisation;optimo global;programacion matematica;analisis convexo;semi definite programming;programacion convexa	The unequal-areas facility layout problem is concerned with finding the optimal arrangement of a given number of non-overlapping indivisible departments with unequal area requirements within a facility. We present a convex-optimisation-based framework for efficiently finding competitive solutions for this problem. The framework is based on the combination of two mathematical programming models. The first model is a convex relaxation of the layout problem that establishes the relative position of the departments within the facility, and the second model uses semidefinite optimisation to determine the final layout. Aspect ratio constraints, frequently used in facility layout methods to restrict the occurrence of overly long and narrow departments in the computed layouts, are taken into account by both models. We present computational results showing that the proposed framework consistently produces competitive, and often improved, layouts for well-known large instances when compared with other approaches in the literature. A Convex Optimisation Framework for the Unequal-Areas Facility Layout Problem Ibolya Jankovits∗ Chaomin Luo† Miguel F. Anjos‡ Anthony Vannelli§	anthony cleaver;approximation algorithm;computation;convex optimization;indivisible;linear programming relaxation;mathematical optimization;requirement;semidefinite programming	Ibolya Jankovits;Chaomin Luo;Miguel F. Anjos;Anthony Vannelli	2011	European Journal of Operational Research	10.1016/j.ejor.2011.04.013	convex analysis;mathematical optimization;simulation;systems modeling;mathematics;global optimum;semidefinite programming	ML	18.451150661384094	5.828153370348821	170315
f3c03f15e2729c6834e0bb33f918b7f580753fc0	the break scheduling problem: complexity results and practical algorithms		Break scheduling problems arise in working areas where breaks are indispensable, e.g., in air traffic control, supervision, or assembly lines. We regard such a problem from the area of supervision personnel. The objective is to find a break assignment for an existing shiftplan such that various constraints reflecting legal demands or ergonomic criteria are satisfied and such that staffing requirement violations are minimised. We prove the NPcompleteness of this problem when all possible break patterns for each shift are given explicitly as part of the input. To solve our problem we propose two variations of a memetic algorithm. We define genetic operators, a local search based on three neighbourhoods, and a penalty system that helps to avoid local optima. Parameters influencing the algorithms are experimentally evaluated and assessed with statistical methods. We compare our algorithms, each with the best parameter setting according to the evaluation, with the state-of-theart algorithm on a set of 30 real-life and randomly generated instances that are publicly available. One of our algorithms returns improved results on 28 out of the 30 benchmark instances. To the best of our knowledge, our improved results for the real-life instances constitute new upper bounds for this problem.	benchmark (computing);experiment;genetic operator;heuristic;human factors and ergonomics;iteration;local optimum;local search (optimization);meme;memetic algorithm;memetics;metaheuristic;np-completeness;neighbourhood (graph theory);procedural generation;real life;regular expression;scheduling (computing)	Magdalena Widl;Nysret Musliu	2014	Memetic Computing	10.1007/s12293-014-0131-0	mathematical optimization;artificial intelligence;machine learning;mathematics;algorithm	AI	15.634822990119531	4.3208494836031965	170349
7db46a7d77ec5fff0b601596430b26503894c3aa	linear programming via a quadratic penalty function	optimal solution;quadratic function;funcion cuadratica;fonction quadratique;programacion lineal;funcion penalidad;linear programming;programmation lineaire;linear program;fonction penalite;algoritmo optimo;algorithme optimal;optimal algorithm;penalty function	We use quadratic penalty functions along with some recent ideas from linear 11 estimation to arrive at a new characterization of primal optimal solutions in linear programs. The algorithmic implications of this analysis are studied, and a new, finite penalty algorithm for linear programming is designed. Preliminary computational results are presented.	algorithm;computation;linear programming;penalty method	Mustafa Ç. Pinar	1996	Math. Meth. of OR	10.1007/BF01193936	mathematical optimization;combinatorics;linear-fractional programming;quadratic function;linear programming;penalty method;mathematics;algorithm	Theory	23.529460151929946	12.306502547397075	170553
10df2e6e966c11bba98f0b7126bd73ffedd01ed1	cyclic hybrid flow-shop scheduling problem with machine setups	discrete optimization;metaheuristics	In this paper we consider an NP -hard hybrid flow shop problem with machine setups and cycletime minimization. The above issue is an important generalization of a flow-shop problem with minimization of a cycle time, and it stays in a direct relationship with a flexible job shop problem. In the hybrid problem task operations are performed by machines arranged in slots, i.e., a set of machines with the same functional properties. In this work we presented a graph model, properties of the problem and methods of determining approximate value of the optimal cycle duration. The above mentioned concepts have been used in the construction of tabu search algorithm. Computational experiments were conducted on well-known in literature examples, which confirmed high efficiency of the algorithm.	approximation algorithm;computation;computational science;discrete optimization;experiment;flow shop scheduling;job shop scheduling;mathematical optimization;optimization problem;scheduling (computing);search algorithm;tabu search;libopus	Wojciech Bozejko;Lukasz Gniewkowski;Jaroslaw Pempera;Mieczyslaw Wodecki	2014		10.1016/j.procs.2014.05.197	mathematical optimization;function problem;flow shop scheduling;computer science;machine learning	AI	15.52647216352582	6.420207921578815	170667
31d8dc5c2cf51127d19a659e4ce0559b9210e26f	heuristic algorithms for the unrelated parallel machine scheduling problem with one scarce additional resource		Abstract In this paper, we study the unrelated parallel machine scheduling problem with one scarce additional resource to minimise the maximum completion time of the jobs or makespan. Several heuristics are proposed following two strategies: the first one is based on the consideration of the resource constraint during the whole solution construction process. The second one starts from several assignment rules without considering the resource constraint, and repairs the non feasible assignments in order to obtain a feasible solution. Several computation experiments are carried out over an extensive benchmark. A comparative evaluation against previously proposed mathematical models and matheuristics (combination of mathematical models and heuristics) is carried out. From the results, we can conclude that our methods outperform the existing ones, and the second strategy performs better, especially for large instances.	algorithm;heuristic;parallel computing;scheduling (computing)	Fulgencia Villa;Eva Vallada;Luis Fanjul-Peyro	2018	Expert Syst. Appl.	10.1016/j.eswa.2017.09.054	job shop scheduling;mathematical model;machine learning;artificial intelligence;heuristics;computer science;scheduling (computing);computation;mathematical optimization;heuristic	Theory	15.84156493156604	7.017510019301917	170729
9b3e307cea9fb5cdca01b431d2f24c83354aea76	new trends in exact algorithms for the 0-1 knapsack problem	dynamic programming;dynamic program;knapsack problem;exact algorithm;state of the art;branch and bound	While the 1980s were focused on the solution of large sized ``easy'' knapsack problems (KPs), this decade has brought several new algorithms, which are able to solve ``hard'' large sized instances. We will give an overview of the recent techniques for solving hard KPs, with special emphasis on the addition of cardinality constraints, dynamic programming, and rudimentary divisibility. Computational results, comparing all recent algorithms, are presented. Ó 2000 Elsevier Science B.V. All rights reserved.	algorithm;computation;dynamic programming;knapsack problem	Silvano Martello;David Pisinger;Paolo Toth	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00260-X	continuous knapsack problem;mathematical optimization;combinatorics;computer science;cutting stock problem;change-making problem;dynamic programming;mathematics;knapsack problem;branch and bound;algorithm	AI	22.643081626827414	9.920414845240549	170761
dc17d91da33cadfb23f992af2be34c2544e57499	on cut-based inequalities for capacitated network design polyhedra	cut residual capacity inequalities;cutset polyhedra;mixed integer rounding;network design;capacitated network design;valid inequalities;integer programming;flow cutset inequalities;mixed integer rounding sndlib;survivable network design;integer program	In this article, we study capacitated network design problems. We unify and extend polyhedral results for directed, bidirected, and undirected link capacity models. Valid inequalities based on a network cut are known to be strong in several special cases. We show that regardless of the link model, facets of the polyhedra associated with such a cut translate to facets of the original network design polyhedra if the two subgraphs defined by the network cut are (strongly) connected. Our investigation of the facial structure of the cutset polyhedra allows to complement existing polyhedral results for the three variants by presenting facet-defining flow-cutset inequalities in a unifying way. In addition, we present a new class of facet-defining inequalities, showing as well that flowcutset inequalities alone do not suffice to give a complete description for single-commodity, single-module cutset polyhedra in the bidirected and undirected case – in contrast to a known result for the directed case. The practical importance of the theoretical investigations is highlighted in an extensive computational study on 27 instances from the Survivable Network Design Library (SNDlib). © 2010 Wiley Periodicals, Inc. NETWORKS, Vol. 00(00), 000–00	cut (graph theory);graph (discrete mathematics);john d. wiley;linear inequality;network planning and design;polyhedron	Christian Raack;Arie M. C. A. Koster;Sebastian Orlowski;Roland Wessäly	2011	Networks	10.1002/net.20395	mathematical optimization;network planning and design;combinatorics;discrete mathematics;integer programming;computer science;integer points in convex polyhedra;mathematics	Theory	23.889961413854007	16.34609439415195	171055
5acb4364f7cc8108a80197b501cf96cd63e3fa05	the two-machine flowshop no-wait scheduling problem with a single server to minimize the total completion time	performance measure;optimal solution;total completion time;evaluation performance;tiempo iniciacion;completion time;performance evaluation;real time;evaluacion prestacion;branch and bound algorithm;heuristic method;branching;temps achevement;problema np duro;metodo heuristico;single server;temps mise en route;np hard problem;no wait;branch and bound method;single server queue;setup time;fila 1 servidor;metodo branch and bound;computer experiment;probleme np difficile;file 1 serveur;scheduling;ramificacion;temps reel;scheduling problem;tiempo real;ramification;separate setup;methode heuristique;methode separation et evaluation;tiempo acabado;two machine flowshop;atelier monogamme;ordonnancement;flow shop;reglamento	This work studies the scheduling problem where a set of jobs are available for processing in a no-wait and separate setup twomachine flow shop system with a single server. The no-wait constraint requires that the operations of a job have to be processed continuously without waiting between two machines. The setup time is incurred and attended by a single sever which can perform one setup at a time. The performance measure considered is the total completion time. The problem is strongly NP-hard. Optimal solutions for several restricted cases and some properties for general case are proposed. Both the heuristic and the branch and bound algorithms are established to tackle the problem. Computational experiments indicate that the heuristic and the branch and bound algorithm are superior to the existing ones in term of solution quality and number of branching nodes, respectively. 2007 Elsevier Ltd. All rights reserved.	algorithm;branch and bound;computation;experiment;flip-flop (electronics);heuristic;job stream;np-hardness;scheduling (computing);server (computing);strong np-completeness;time complexity	Ling-Huey Su;Yuan-Yu Lee	2008	Computers & OR	10.1016/j.cor.2007.01.002	job shop scheduling;mathematical optimization;real-time computing;computer experiment;flow shop scheduling;branching;computer science;np-hard;mathematics;ramification;scheduling;branch and bound;algorithm	AI	17.138438115063718	9.734114919085961	171091
53f12f6f45890ed12397e6b8e855251ee4ed1e72	batch delivery scheduling with batch delivery cost on a single machine	reglamento discontinuo;constante tiempo;dynamic programming;programacion dinamica;completion time;time constant;entrega;temps polynomial;single machine scheduling;machine unique;complexite calcul;batch production;dynamic programming algorithm;procede discontinu;temps achevement;problema np duro;ejecucion programa;satisfiability;delai livraison;program execution;processing time;constrenimiento precedencia;livraison;np hard problem;complejidad computacion;single machine;maquina unica;produccion por lote;cost optimization;probleme np difficile;computational complexity;execution programme;production par lot;batch scheduling;programmation dynamique;batch process;polynomial time;plazo entrega;precedence constraint;contrainte precedence;scheduling problem;temps traitement;procedimiento discontinuo;delivery good;algoritmo optimo;ordonnancement discontinu;tiempo acabado;algorithme optimal;optimal algorithm;tiempo proceso;journal magazine article;delivery lead time;constante temps;batch delivery cost;tiempo polinomial	We consider a scheduling problem in which n independent and simultaneously available jobs are to be processed on a single machine. The jobs are delivered in batches and the delivery date of a batch equals the completion time of the last job in the batch. The delivery cost depends on the number of deliveries. The objective is to minimize the sum of the total weighted flow time and delivery cost. We first show that the problem is strongly NP-hard. Then we show that, if the number of batches is B, the problem remains strongly NP-hard when B ≤ U for a variable U ≥ 2 or B ≥ U for any constant U ≥ 2. For the case of B ≤ U , we present a dynamic programming algorithm that runs in pseudo-polynomial time for any constant U ≥ 2. Furthermore, optimal algorithms are provided for two special cases: (i) jobs have a linear precedence constraint, and (ii) jobs satisfy the agreeable ratio assumption, which is valid, for example, when all the weights or all the processing times are equal.	algorithm;dynamic programming;heuristic (computer science);job stream;moe;np-hardness;p (complexity);polynomial;pseudo-polynomial time;scheduling (computing);strong np-completeness;time complexity	Min Ji;Yong Jun He;T. C. Edwin Cheng	2007	European Journal of Operational Research	10.1016/j.ejor.2005.09.006	job shop scheduling;mathematical optimization;real-time computing;computer science;operations management;dynamic programming;mathematics;algorithm	Theory	16.935263258108275	10.203056837733158	171237
0518f91f80319d5096eb6f34ece16c3ecbca5564	no-wait scheduling in single-hop multi-channel lans	approximation ratio;traitement liste;tiempo total acabamiento;procesamiento informacion;algorithm analysis;multiprocessor;rapport approximation;probleme np complet;performance;temps total achevement;tratamiento lista;lan;processing time;no wait;makespan;informatique theorique;scheduling;information processing;temps traitement;problema np completo;analyse algorithme;rendimiento;multiprocesador;traitement information;tiempo proceso;analisis algoritmo;ordonnancement;reglamento;np complete problem;list processing;computer theory;multiprocesseur;informatica teorica	An extended version of the multiprocessor machine scheduling problem with makespan objective, which arises from single-hop multi-channel LANs, is presented in this paper. In this scheduling model, each job consists of two operations, and each operation may be processed by anyone of a given set of machines, while in the job shop scheduling problem, such a set contains only one machine. For this NP-complete problem, we first analyze the performance ratios of two simple strategies, List Scheduling and Longest Processing Time First, for the off-line cases, which have performance ratios (5/2 - 1/2m) and (2 + 1/2(m + 1)), respectively, with (m + 1) being the number of the machines. We also show that the competitive ratio of the List Scheduling strategy for the on-line cases is (7/2 - 1/2m).	scheduling (computing)	Fengfeng Zhou;Yinlong Xu;Guoliang Chen	2005	Inf. Process. Lett.	10.1016/j.ipl.2004.09.013	local area network;fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;job shop scheduling;open-shop scheduling;earliest deadline first scheduling;multiprocessing;np-complete;flow shop scheduling;information processing;performance;dynamic priority scheduling;computer science;rate-monotonic scheduling;artificial intelligence;deadline-monotonic scheduling;stride scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling;multiprocessor scheduling;algorithm;i/o scheduling	DB	16.88423896031838	10.941435151111712	171285
ad6ef6c2682ce6e6aca988a0398c15f3e5c45b12	job shop scheduling with separable sequence-dependent setups	job shop scheduling;mixed integer program;setup time;polynomial time;job shop scheduling problem;lower bound	In this paper, we consider a job shop scheduling problem in which the setup times of jobs are sequence dependent and separable from their processes. The objective of the problem is to minimize the time required to complete all jobs in the system. We formulate this problem as a mixed integer program and present a simple, polynomial time heuristic procedure for solving it. The procedure is based upon sequentially identifying a pair of operations that provide a minimum lower bound on the makespan of the associated two-jobym-machine problem with release times. A computational study demonstrates the superior performance of the new heuristic over the one developed by Zhou and Egbelu. Copyright Kluwer Academic Publishers 1997	job shop scheduling;scheduling (computing)	In-Chan Choi;Osman Korkmaz	1997	Annals OR	10.1023/A:1018918003761	time complexity;job shop scheduling;open-shop scheduling;mathematical optimization;flow shop scheduling;operations management;mathematics;upper and lower bounds;multiprocessor scheduling;algorithm	Theory	16.18775334675718	8.962852172352601	171347
537fe08049a5e0adc5977ac2a593c2d5fbbe158c	matroid secretary problem in the random assignment model	68w40;secretary problems;05b35;online selection;matroids;principal partition;68w27	In the Matroid Secretary Problem, introduced by Babaioff et al. [5], the elements of a given matroid are presented to an online algorithm in random order. When an element is revealed, the algorithm learns its weight and decides whether or not to select it. The objective is to return a maximum weight independent set of the matroid. There are different variants for this problem depending on the information known about the weights beforehand.  In the random assignment model, a hidden list of weights is randomly assigned to the matroid ground set, independently from the random order they are revealed to the algorithm. Our main result is the first constant competitive algorithm for this version of the problem, solving an open question of Babaioff et al. Our algorithm achieves a competitive ratio of 2e2/(e − 1). It exploits the notion of principal partition of a matroid, its decomposition into uniformly dense minors, and a 2e-competitive algorithm for uniformly dense matroids we also develop.  We also present constant competitive algorithms in the standard model where the weights are assigned adversarially, for various classes of matroids including cographic, low density, k-column sparse linear matroids and the case when every element is in a small cocircuit. In the same model, we give a new O(log r)-competitive algorithm for matroids of rank r which only uses the relative order of the weights seen and not their actual values, as previously needed.	competitive analysis (online algorithm);independent set (graph theory);matroid rank;online algorithm;randomness;secretary problem;sparse matrix	José A. Soto	2011		10.1137/110852061	matroid;mathematical optimization;combinatorics;graphic matroid;oriented matroid;mathematics;weighted matroid;matroid partitioning;algorithm;algebra	Theory	17.810809119871028	15.61063711876341	171379
20f595d994628a14ff76677f35ee31c4f853e7a9	"""the maximal dispersion problem and the """"first point outside the neighbourhood"""" heuristic"""	metodo caso peor;optimisation;optimizacion;heuristic method;metodo heuristico;worse case method;programacion lineal;methode cas pire;linear programming;programmation lineaire;optimization;methode heuristique;dispersion	Abstract   In this paper, we consider the problem of selecting, from a finite set  S  ⊂-  R   n  , endowed with a metric ∥ ∥,  p  maximally dispersed points. An heuristic, called the “first point outside the neighbourhood” heuristic, is studied. The main results are that the dispersion, produced by the heuristic, is never worse than   1  3   of the maximal dispersion and that, for certain values of  p , the dispersion obtained is not worse than   1  2   of the maximal dispersion.	heuristic;maximal set	Douglas J. White	1991	Computers & OR	10.1016/0305-0548(91)90040-X	mathematical optimization;combinatorics;dispersion;linear programming;calculus;mathematics;geometry	AI	23.202240579397166	13.433742486885588	171552
15eee42686eb37808d5e233b9d2b3f3b9fbe07f7	dynamic sat with decision change costs: formalization and solutions		We address a dynamic decision problem in which decision makers must pay some costs when they change their decisions along the way. We formalize this problem as Dynamic SAT (DynSAT) with decision change costs, whose goal is to find a sequence of models that minimize the aggregation of the costs for changing variables. We provide two solutions to solve a specific case of this problem. The first uses a Weighted Partial MaxSAT solver after we encode the entire problem as a Weighted Partial MaxSAT problem. The second solution, which we believe is novel, uses the Lagrangian decomposition technique that divides the entire problem into sub-problems, each of which can be separately solved by an exact Weighted Partial MaxSAT solver, and produces both lower and upper bounds on the optimal in an anytime manner. To compare the performance of these solvers, we experimented on the random problem and the target tracking problem. The experimental results show that a solver based on Lagrangian decomposition performs better for the random problem and competitively for the target tracking problem.	anytime algorithm;boolean satisfiability problem;cholesky decomposition;decision problem;encode;maximum satisfiability problem;solver	Daisuke Hatano;Katsutoshi Hirayama	2011		10.5591/978-1-57735-516-8/IJCAI11-101	mathematical optimization;combinatorics;function problem;mathematics;algorithm	AI	22.49007098650843	4.752178385710092	171654
92fbf54d589ea9ff3ff48f855c9dd1bc61c07f2c	a branch and cut algorithm for a steiner tree-star problem	telecommunications networks;node weighted steiner tree;steiner trees;digital data networks;polyhedral structure;branch and cut;steiner tree	This paper deals with a Steiner tree-star problem that is a special case of the degree constrained node-weighted Steiner tree problem. This problem arises in the context of designing telecommunications networks for digital data service, provided by regional telephone companies. In this paper, we develop an effective branch and cut procedure coupled with a suitable separation procedure that identifies violated facets for fractional solutions to the relaxed formulation. Computational results indicate that large problem instances with up to 200 nodes can be solved within acceptable time bounds.	algorithm;branch and cut;steiner tree problem	Youngho Lee;Steve Y. Chiu;Jennifer Ryan	1996	INFORMS Journal on Computing	10.1287/ijoc.8.3.194	mathematical optimization;combinatorics;discrete mathematics;steiner tree problem;computer science;mathematics	Theory	22.05714509754177	13.970312801501109	171671
4561756037f81a7dbf688d37e774ae053982fc5e	weighted-tardiness scheduling on parallel machines with proportional weights	weighting;probleme np dur;problema np duro;ponderacion;algorithme;algorithm;np hard problem;scheduling;retard;production scheduling weighted tardiness scheduling with proportional weights;parallel machines;ordonamiento;pseudopolynomial time;systeme parallele;ponderation;parallel system;retraso;ordonnancement;sistema paralelo;algoritmo	In this paper, we address the problem of scheduling a number of jobs on a bank of parallel machines to minimize the total weighted tardiness, under the assumption that the weight of each job is proportional to its processing time. The version of the problem that has general weights has been shown to be strongly NP-complete. We prove this version of the problem to be NP-complete, and give a pseudopolynomial time algorithm for solving it. We study a family of simple sequencing rules in which the jobs are sequenced in increasing order of γi = di − θpi, where di is the due date of job i, pi its processing time, wi its weight, and 0 ≤ θ ≤ 1. This family of sequencing rules generalizes the earliest due date sequencing rule. We obtain bounds on the ratio [Cγ · C*]/[Σiwipi], where Cγ and C* are the costs of the heuristic and optimal schedules, respectively. The denominator is the cost of having each job be late by its own processing time. It is intended to measure what is or is not a large deviation from optimali...		Esther M. Arkin;Robin Roundy	1991	Operations Research	10.1287/opre.39.1.64	mathematical optimization;computer science;operations management;np-hard;weighting;mathematics;scheduling;algorithm	HPC	16.975531432737643	10.44315768868774	171941
562f9781aaecd30abee8c449e3f87bc0d1b32922	on the invariance of male optimal stable matching	stable matching problem;stable matching;invariance;assignment	The stable matching problem is that of matching two sets of agents in such a manner that no two unmatched agents prefer each other to their actual partners under the matching. In this paper, we present a set of sufficient conditions on the preference lists of any given stable matching instance, under which the optimality of the original male optimal stable matching is still preserved.	stable marriage problem	R. T. Kuo;S. S. Tseng	1990	BIT		mathematical optimization;combinatorics;discrete mathematics;stable marriage problem;optimal matching;mathematics;stable roommates problem	ECom	18.331739407484317	17.761985585726247	171994
f77da74b88eb26b21f8fbcad53a7d42cf6685bec	phase transition behaviour in constraint satisfaction problems		Many problems in artificial intelligence and computer scienc e can be formulated as constraint satisfaction problems ( CSPs). A CSP consists of a set of variables among which a set of constraints are imposed, with a solution corresponding to an assignme nt for every variable such that no constraints are violated. Most forms of CSP are NP-complete. Recent research has shown that the CSP exhibits aphase transitionas a control parameter is varied. This transition lies between a region where most probl ems are easy and soluble, and a region where most problems are easy but insoluble. In the interv ening phase transition region, the average problem difficulty is greatest. Phase transition behav iour can be exploited to create test beds of hard and easy problems for CSP algorithms. In this thesis, we study the phase transition of the binaryCSP and examine various aspects of complete search algorithms for it. The phenomenon of exceptionally hard problems (‘ ehps’) is examined in detail: these are rare searches on easy problems which become exceptionally exp ensive for a particular complete algorithm following a poor early search move. An explanation f r the occurrence of ehps is proposed, and the relative susceptibility of certain algorith ms to the phenomenon is explored. We then show that the phase transition paradigm can be applied to two asks of polynomial cost complexity: attempting to establish arc and path consistency in aCSP. Phase transition behaviour analogous to that found when searching for a solution is demonst rated for these tasks, and the effectiveness and cost of establishing arc and path consistency is examined. The theme of establishing consistency in CSPs is extended by studying an algorithm which maintains arc consistency during search. Its performance is co mpared with that of an algorithm which maintains a lower level of consistency, and it is shown tha t t e higher level of consistency reduces average search cost and ehp behaviour on many types of CSP. Finally, the subject of dynamically selecting the variable to instantiate at each stage in the search process is considered. We compare a number of heuristics w hi h attempt to select the variable most likely to lead to failure, and show that the suppose d principle behind these appears to be fundamentally flawed.	artificial intelligence;constraint satisfaction problem;exptime;heuristic (computer science);local consistency;np-completeness;polynomial;programming paradigm;search algorithm	Stuart Alexander Grant	1997			mathematical optimization;artificial intelligence;mathematics;algorithm;local consistency	AI	12.48716233598354	17.671036773726826	172295
4de14ed625bb0afa04b8d7d00a035e11cf1ecd71	using dual approximation algorithms for scheduling problems: theoretical and practical results	dynamic programming;optimized production technology;approximate algorithm;approximation algorithms scheduling algorithm polynomials algorithm design and analysis performance analysis design optimization job design process design optimized production technology additives;approximation algorithms;size measurement;worst case analysis;design optimization;analysis of algorithm;polynomials;process design;additives;upper bound;optimization problem;scheduling algorithm;relative error;marine vehicles;scheduling;heuristic algorithms;scheduling theory;problem complexity;numerical algorithm;performance analysis;schedules;scheduling problem;optimization;approximation methods;job design;search problems;job listing service;combinatorial optimization;encoding;algorithm design and analysis;buildings;polynomial approximation;partitioning algorithms	The problem of scheduling a set of n jobs on m identical machines so as to minimize the makespan time is perhaps the most well-studied problem in the theory of approximation algorithms for NP-hard optimization problems. In this paper we present the strongest possible type of result for this problem, a polynomial approximation scheme. More precisely, for each e, we give an algorithm that runs in time O((n/e)1/e2) and has relative error at most e. For algorithms that are polynomial in n and m, the strongest previously-known result was that the MULTIFIT algorithm delivers a solution with no worse than 20% relative error. In addition, we present a refinement of our scheme in the case where the performance guarantee is equal to that of MUL-TIFIT, that yields an algorithm that is both more efficient and easier to analyze than MULTIFIT. In this case, in order to guarantee a maximum relative error of 1/5+2-k, the algorithm runs in O(n(k+logn)) time. The scheme is based on a new approach to constructing approximation algorithms, which we call dual approximation algorithms, where the aim is find superoptimal, but infeasible solutions, and the performance is measured by the degree of infeasibility allowed. This notion should find wide applicability in its own right, and should be considered for any optimization problem where traditional approximation algorithms have been particularly elusive.	approximation algorithm;scheduling (computing)	Dorit S. Hochbaum;David B. Shmoys	1985		10.1109/SFCS.1985.63	mathematical optimization;combinatorics;polynomial-time approximation scheme;combinatorial optimization;computer science;theoretical computer science;mathematics;scheduling;approximation algorithm	Theory	15.517876478099092	10.842175440866548	172411
817848f645a77edeb95542e2c929a3bdcbf6abf5	classical cuts for mixed-integer programming and branch-and-cut	mixed integer rounding;cutting planes;gomory cuts;branch and bound method;mixed integer program;programacion lineal;programacion mixta entera;metodo branch and bound;mathematical programming;linear programming;programmation lineaire;programmation partiellement en nombres entiers;mixed integer programming;methode separation et evaluation;branch and cut;programmation mathematique;programacion matematica;key words mixed integer programming	We review classical valid linear inequalities for mixed-integer programming, i.e., Gomory's fractional and mixed-integer cuts, and discuss their use in branch-and-cut. In particular, a generalization of the recent mixed-integer rounding (MIR) inequality and a sufficient condition for the global validity of classical cuts after branching has occurred are derived. Copyright Springer-Verlag Berlin Heidelberg 2001	branch and cut;integer programming;linear programming	Manfred W. Padberg	2001	Math. Meth. of OR	10.1007/s001860100120	mathematical optimization;combinatorics;linear programming;mathematics;algorithm;branch and cut	Robotics	23.65524501224593	11.34118009252035	172471
23e9ac4a12ea8ed566d62373b6fd4b075e155918	a tire production scheduling system for bridgestone/firestone off-the-road	assignment;generation colonne;programacion entera;decomposition;aparato produccion calor;heat supply equipment;efficiency;processes;operations research;companies;programmation en nombres entiers;pneumatique;appareil production chaleur;integer;temps calcul;programacion lineal;integer programming;studies;scheduling;manufacturing;linear programming;programmation lineaire;dantzig wolfe;algorithms;ordonamiento;planning;tires;neumatico;molde;production scheduling;tiempo computacion;computation time;moule;tyre;programming;applications;fashion;ordonnancement;mold;column generation	We describe a scheduling system for the curing operation at Bridgestone/Firestone Off-The-Road (BFOR), a manufacturer of large tires for heavy off-the-road machines such as trucks, tractors, and earthmoving equipment used in the construction, lumber, and mining industries. The huge tires, having different priorities, are built in molds and put into heaters for the curing process. The problem is to find a feasible assignment of tires to molds and molds to heaters to achieve a maximum total priority. Our system produces about 7% more tires per shift compared to the previous manual way of developing schedules and moves the company toward its goal of quick response manufacturing with low inventories. The core algorithm is a column generation procedure to produce a production schedule for one work shift. This approach is then used in a “rolling horizon” fashion. The size of the problem posed several computational challenges. Computational efficiencies come from (1) a dramatic effort to eliminate alternative so...	scheduling (computing)	Zeger Degraeve;Linus Schrage	1997	Operations Research	10.1287/opre.45.6.789	column generation;integer;planning;programming;mathematical optimization;simulation;integer programming;computer science;linear programming;operations management;tire;assignment;mathematics;scheduling;efficiency;manufacturing;decomposition;management;scheduling;algorithm	Robotics	17.426350116322386	6.7416827522804095	172568
d67c443fe648d631127c9106cb8f7d803e9b380f	makespan computation of lot switching period in single-armed cluster tools		In semiconductor manufacturing, wafer cassettes often contain two to three different wafer types due to the larger wafer size, the continual circuit width reduction and the increasing demand for customized products. Hence, the lot switching operation in which the last few wafers of the preceding lot and the first few wafers of the next lot are processed together in cluster tools occurs frequently. In this paper, we analyze an efficient robot task sequence proposed by the previous work for the lot switching operation in single-armed cluster tools and derive closed-form expressions of the makespan of the lot switching period for the first time. With this research, the completion time of a wafer lot can be easily estimated, and then idle times of tools and turnaround times of wafers can be reduced by sending automated material handling systems in advance to unload completed cassettes.	automated planning and scheduling;computation;epoch (reference date);experiment;makespan;mass effect trilogy;material handling;np (complexity);personalization;robot;semiconductor device fabrication;serverless computing;wafer (electronics)	Hyun-Jung Kim;Jun-Ho Lee	2015	2015 Winter Simulation Conference (WSC)		real-time computing;network switch;computer science;engineering;economic indicator;engineering drawing	Robotics	10.064327307221292	5.230157639079002	172718
3bdf7aaf75565268800762a684f0fce5a14a7c94	an improved genetic algorithm for the distributed and flexible job-shop scheduling problem	workload;desciframiento;assignment problem;tiempo total acabamiento;probleme affectation;flexible manufacturing systems;decodage;decoding;gestion labor;job shop scheduling;routing;flexibilidad;atelier flexible;temps total achevement;routage;entreprise etendue;algoritmo genetico;busca local;distributed scheduling;atelier multigamme;codificacion;flexible manufacturing;gestion tâche;makespan;genetic algorithms flexible manufacturing systems distributed job shop scheduling;flexible manufacturing system;scheduling;algorithme reparti;coding;empresa extendida;charge travail;improved genetic algorithm;algorithme genetique;scheduling problem;problema asignacion;genetic algorithm;extended enterprise;job shop;algoritmo repartido;sistema flexible produccion;genetic algorithms;flexibilite;refinacion;refining;task scheduling;distributed job shop scheduling;carga trabajo;job shop scheduling problem;distributed algorithm;local search;ordonnancement;recherche locale;flexibility;reglamento;codage;raffinage;enrutamiento	The Distributed and Flexible Job-shop Scheduling problem (DFJS) considers the scheduling of distributed manufacturing environments, where jobs are processed by a system of several Flexible Manufacturing Units (FMUs). Distributed scheduling problems deal with the assignment of jobs to FMUs and with determining the scheduling of each FMU, in terms of assignment of each job operation to one of the machines able to work it (job-routing flexibility) and sequence of operations on each machine. The objective is to minimize the global makespan over all the FMUs. This paper proposes an Improved Genetic Algorithm to solve the Distributed and Flexible Job-shop Scheduling problem. With respect to the solution representation for non-distributed job-shop scheduling, gene encoding is extended to include information on job-to-FMU assignment, and a greedy decoding procedure exploits flexibility and determines the job routings. Besides traditional crossover and mutation operators, a new local search based operator is used to improve available solutions by refining the most promising individuals of each generation. The proposed approach has been compared with other algorithms for distributed scheduling and evaluated with satisfactory results on a large set of distributed-and-flexible scheduling problems derived from classical job-shop scheduling benchmarks.	genetic algorithm;job shop scheduling;scheduling (computing)	L. De Giovanni;Ferdinando Pezzella	2010	European Journal of Operational Research	10.1016/j.ejor.2009.01.008	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;job shop scheduling;open-shop scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;genetic algorithm;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operations management;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;mathematics;distributed computing;scheduling;gain scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling	Robotics	19.471302254075937	5.645955464561513	172757
3d5904dee448c9197a7d926961eb66b8f99b5e14	an efficient heuristic search for optimal wavelength requirement in static wdm optical networks	strategie premier meilleur;multiplexage longueur onde;reseau communication;haute performance;wdm network;reseau optique;algoritmo busqueda;algorithm performance;calculateur;longitud onda;algorithme recherche;heuristic method;search algorithm;wdm optical network;calculadora;espace etat;combinatorial optimization problem;distributed computing;calculator;search strategy;metodo heuristico;wavelength;probabilistic approach;satisfiability;red fibra optica;optimisation combinatoire;heuristic search;combinatorial problem;probleme combinatoire;telecomunicacion optica;telecommunication optique;problema combinatorio;optical arrays;state space method;call blocking probability;methode espace etat;resultado algoritmo;enfoque probabilista;approche probabiliste;state space;reseau fibre optique;performance algorithme;alto rendimiento;optical telecommunication;calculo repartido;optical fiber network;methode heuristique;longueur onde;espacio estado;combinatorial optimization;red de comunicacion;high performance;communication network;calcul reparti;multiplaje longitud onda;metodo espacio estado;first best strategy;optimizacion combinatoria;wavelength division multiplexing;wavelength division multiplex	This paper presents a heuristic search technique for finding an optimal requirement of wavelengths to satisfy a static lightpath demand in wavelength division multiplexed (WDM) optical networks. We have formulated the problem as a combinatorial optimization problem and used a state space search algorithm based on best first search strategy to solve it. We have compared the performance of our algorithm with another well-known technique with respect to the number of wavelength requirements and call blocking probability. Simulation runs for a wide range of lightpath demands over different WDM networks show that our proposed technique is better in both the above stated dimensions.		Swarup Mandal;Debashis Saha	2003		10.1007/978-3-540-24596-4_35	telecommunications;combinatorial optimization;computer science;state space;artificial intelligence;wavelength;mathematics;algorithm;telecommunications network;wavelength-division multiplexing;satisfiability;search algorithm	Theory	20.548976845532987	7.059819476265541	172765
d60e12c7502ad5cd59ac9a72486e09857bb8df2f	local search, reducibility and approximability of np-optimization problems	complexite calcul;probleme np dur;problema np duro;optimization method;reducibility;reductibilidad;metodo optimizacion;optimization problem;np hard problem;complejidad computacion;computational complexity;methode optimisation;optimization;local search;reductibilite	The issue of determining “good” approximate solutions of NP-hard optimization problems in polynomial time is widely recognized as being relevant both from the practical point of view and from the point of view of complexity theory [ 91. Informally, we are interested in approximate solutions such that the performance ratio, that is the ratio between the value of such solution and the value of the optimum solution, is bounded by a constant, independently from the instance of the problem. Among NP-hard optimization problems, the class of problems that allow a bounded performance ratio to be achieved in polynomial time is denoted by APX while	apx;approximation algorithm;computational complexity theory;local search (optimization);mathematical optimization;np-hardness;optimization problem;point of view (computer hardware company);polynomial;relevance;time complexity	Giorgio Ausiello;Marco Protasi	1995	Inf. Process. Lett.	10.1016/0020-0190(95)00006-X	optimization problem;mathematical optimization;combinatorics;discrete mathematics;computer science;local search;np-hard;mathematics;computational complexity theory	Theory	20.57380955387986	13.814343505436701	172861
8016ebd834b35c224c77fda5636aa43186bdc212	on the minimum-cost λ-edge-connected k-subgraph problem	edge connected subgraph;valid inequalities;graph connectivity;integer programming;minimum spanning tree	In this paper, we propose several integer programming (IP) formulations to exactly solve the minimum-cost λ -edge-connected k-subgraph problem, or the (k,λ )-subgraph problem, based on its graph properties. Special cases of this problem include the well-known k-minimum spanning tree problem (if λ = 1), λ -edgeconnected spanning subgraph problem (if k = |V |) and k-clique problem (if λ = k−1 and there are exact k vertices in the subgraph). As a generalization of k-minimum spanning tree and a case of the (k,λ )-subgraph problem, the (k,2)-subgraph problem is studied, and some special graph properties are proved to find stronger and more compact IP formulations. Additionally, we study the valid inequalities for these IP formulations. Numerical experiments are performed to compare proposed IP formulations and inequalities.	algorithm;bridge (graph theory);clique (graph theory);clique problem;experiment;file spanning;graph property;integer programming;k-minimum spanning tree;minimum spanning tree;numerical method;procedural generation;randomness;strong orientation;vertex (geometry);whole earth 'lectronic link	Elham Sadeghi;Neng Fan	2016	Comput. Manag. Science	10.1007/s10287-016-0260-7	mathematical optimization;combinatorics;discrete mathematics;integer programming;connectivity;minimum spanning tree;mathematics	ECom	24.272926410675733	16.555920111373066	173190
34da5be53acf61a31e7d6cd8d1af0211759f3772	local search algorithms for partial maxsat	local search algorithm;satisfiability;local search	MAXSAT solutions, i.e., near-satisfying assignments for propositional formulas, are sometimes meaningless for real-world problems because such formulas include “mandatory clauses” that must be all satisfied for the solution to be reasonable. In this paper, we introduce Partial MAXSAT and investigate how to solve it using local search algorithms. An instance of Partial MAXSAT consists of two formulas fA and f~, and its solution must satisfy all clauses in fA and as many clauses in fB as possible. The basic idea of our algorithm is to give weight to fA-clauses (the mandatory clauses) and then apply local search. We face two problems; (i) what amount of weight is appropriate and (ii) how to deal with the common action of local search algorithms, giving weight to clauses for their own purpose, which will hide the initial weight as the algorithms proceed.	local search (optimization);maximum satisfiability problem;regular expression;search algorithm	Byungki Cha;Kazuo Iwama;Yahiko Kambayashi;Shuichi Miyazaki	1997			mathematical optimization;computer science;local search;algorithm	AI	23.03352972426262	5.066647999793794	173327
2603a9e922a606392de3e7e272853beee47eac9f	how to allocate review tasks for robust ranking	longueur chemin;matroid;comparaison par paire;approximate algorithm;articulo sintesis;article synthese;probleme np complet;approximation algorithm;rangement;rango;problema np duro;optimization method;interseccion;metodo optimizacion;matroide;52b40;optimization problem;np hard problem;graph connectivity;comparacion por pares;ranking;probleme np difficile;informatique theorique;robustesse;68r10;rang;conectividad grafo;algoritmo aproximacion;methode optimisation;paired comparison;robustness;problema np completo;peritaje;expertise;algorithme approximation;intersection;ordenamiento;review;connectivite graphe;68w25;rank;np complete problem;computer theory;robustez;informatica teorica	In the process of reviewing and ranking projects by a group of reviewers, the allocation of the subset of projects to each reviewer has major impact on the robustness of the outcome ranking. We address here this problem where each reviewer is assigned, out of the list of all projects, a subset of up to k projects. Each individual reviewer then ranks and compares all pairs of k projects. The k-allocation problem is to determine an allocation of up to k projects to each reviewer, that lie within the expertise set of the reviewer, so that the resulting union of reviewed projects has certain desirable properties. The k-complete problem is a k-allocation with the property that all pairs of projects have been compared by at least one reviewer. A k-complete allocation is desirable as otherwise there may be projects that were not compared by any reviewer, leading to possible adverse properties in the outcome ranking. When a k-complete allocation cannot be achieved, one might settle for other properties. One basic requirement is that each pair of projects is comparable via a ranking path which is a sequence of pairwise rankings of projects implying a comparison of all pairs on the path. A k-allocation with a ranking path between each pair is the connectivity-k-aloc. Since the robustness of relative comparisons deteriorates with increased length of the ranking path, another goal is that between each pair of projects there will be at least one ranking path that has at most two hops or q hops for fixed values of q. An alternative means for increasing the robustness of the ranking is to use a k-allocation with at least p disjoint ranking paths between each pair. We model all these problems as graph problems. We demonstrate that the connectivity-k-aloc problem is polynomially solvable, using matroid intersection; we prove that the k-complete problem is NP-hard unless k = 2; and we provide approximation algorithms for a related optimization problem. All other variants are shown to be NP-complete for all values of k ≥ 2.	approximation algorithm;complete (complexity);decision problem;mathematical optimization;matroid intersection;np-completeness;np-hardness;optimization problem	Dorit S. Hochbaum;Asaf Levin	2010	Acta Informatica	10.1007/s00236-010-0120-9	matroid;pairwise comparison;optimization problem;combinatorics;rank;np-complete;ranking;connectivity;intersection;np-hard;mathematics;approximation algorithm;algorithm;robustness	Web+IR	19.219086557564633	12.920898020416764	173538
71995a86e4f4086996309b7c8737b15c4ac17a3c	approximation algorithms for parallel machine scheduling with linear deterioration	simple linear deterioration;approximation algorithm;journal;makespan;scheduling;parallel machine	This paper deals with a parallel machine scheduling problem. Different from fixed processing time assumption in the classical scheduling, a job’s processing time is a simple linear increasing function of its starting time. The aim is makespan minimization, and our focus is on the casewith an arbitrary number of parallelmachines.Weprove that LIST rule is (1+bmax) m−1 m -approximationwherem is the number ofmachines and bmax is themaximum deteriorating rate of job. We then propose one heuristic LDR (Largest deteriorating Rate first). The heuristic is proved by (1 + bmin) m−1 m -approximation where bmin is the minimum deteriorating rate. We further show that this ratio is tight whenm = 2, 3 and 4. © 2012 Elsevier B.V. All rights reserved.	approximation algorithm;heuristic;ldraw;makespan;parallel computing;scheduling (computing)	Ming Liu;Feifeng Zheng;Shijin Wang;Yin-Feng Xu	2013	Theor. Comput. Sci.	10.1016/j.tcs.2012.01.020	mathematical optimization;computer science;analysis of parallel algorithms;mathematics;distributed computing;scheduling;approximation algorithm;algorithm	AI	15.844947218460646	10.345526115334202	173960
211d8f9e81e00834b412ffd9bad2dca53686d602	convex hull results for the warehouse problem		Given an initial stock and a capacitated warehouse, the warehouse problem aims to decide when to sell and purchase to maximize proﬁt. This problem is common in revenue manage-ment and energy storage. We extend this problem by incorporating ﬁxed costs and		Laurence A. Wolsey;Hande Yaman	2018	Discrete Optimization	10.1016/j.disopt.2018.06.002	mathematics;mathematical optimization;discrete mathematics;convex hull;fourier–motzkin elimination;revenue;integer programming;warehouse	Theory	15.615731556780599	4.326637357206431	174100
e545c8e204de31636779da630c6a8197f393a336	initialization in genetic algorithms for constraint satisfaction problems	workload;heuristic method;metodo heuristico;algoritmo genetico;constraint satisfaction;satisfaction contrainte;scheduling;charge travail;algorithme genetique;genetic algorithm;job shop;ordonamiento;constraint satisfaction problem;methode heuristique;satisfaccion restriccion;carga trabajo;job shop scheduling problem;ordonnancement	In this paper we propose a strategy to incorporate heuristic knowledge into the initial population of a Genetic Algorithm to solce Job Shop Scheduling problems. This is a generalization of strategy we proposed in a previous work. The experimental results reported confirm that the new strategy improves the former one. In particular, a higher diversity in achieved among the heuristic individuals, and at the same time the mean fitness is improved. Moreover, these improvements translate into a better convergence of the GA.	constraint satisfaction;genetic algorithm	Camino R. Vela;Ramiro Varela;Jorge Puente	2001		10.1007/3-540-45720-8_83	mathematical optimization;genetic algorithm;constraint satisfaction;computer science;artificial intelligence;mathematics;scheduling;constraint satisfaction problem	AI	20.52462080363593	5.963019703885394	174263
8d40e29675f17cc21d430b0334154f6b5601c27b	lagrangean/surrogate relaxation for generalized assignment problems	optimal solution;zero one programming;solution optimale;optimisation sousgradient;generalized assignment problem;subgradient method;programmation zero un;relajacion;optimisation combinatoire;lagrangean relaxation;programacion lineal;lagrangean and surrogate relaxation;surrogate relaxation;solucion optima;subgradient optimization;linear programming;programmation lineaire;relaxation;profitability;optimizacion subgradiente;combinatorial optimization;capacity constraint;local search;large scale problem;recherche locale;optimizacion combinatoria	This work presents Lagrangean/surrogate relaxation to the problem of maximum pro®t assignment of n tasks to m agents (n > m), such that each task is assigned to only one agent subject to capacity constraints on the agents. The Lagrangean/surrogate relaxation combines usual Lagrangean and surrogate relaxations relaxing ®rst a set of constraints in the surrogate way. Then, the Lagrangean relaxation of the surrogate constraint is obtained and approximately optimized (one-dimensional dual). The Lagrangean/surrogate is compared with the usual Lagrangean relaxation on a computational study using a large set of instances. The dual bounds are the same for both relaxations, but the Lagrangean/surrogate can give improved local bounds at the application of a subgradient method, resulting in less computational times. Three relaxations are derived for the problem. The ®rst relaxation considers a vector of multipliers for the capacity constraints, the second for the assignment constraints and the other for the Lagrangean decomposition constraints. Relaxation multipliers are used with ecient constructive heuristics to ®nd good feasible solutions. The application of a Lagrangean/surrogate approach seems very promising for large scale problems. Ó 1999 Elsevier Science B.V. All rights reserved.	computation;heuristic (computer science);lagrange multiplier;linear programming relaxation;subgradient method	Marcelo Gonçalves Narciso;Luiz Antonio Nogueira Lorena	1999	European Journal of Operational Research	10.1016/S0377-2217(98)00038-1	mathematical optimization;combinatorics;combinatorial optimization;generalized assignment problem;linear programming;local search;subgradient method;relaxation;mathematics;mathematical economics;profitability index	AI	18.757682283482815	6.873650912054261	174275
59fb492aec181df3c25a7ef673c66f44a91d02c7	an adaptive clustering-based genetic algorithm for the dual-gantry pick-and-place machine optimization		This research proposes an adaptive clustering-based genetic algorithm (ACGA) to optimize the pick-and-place operation of a dual-gantry component placement machine, which has two independent gantries that alternately place components onto a printed circuit board (PCB). The proposed optimization problem consists of several highly interrelated sub-problems, such as component allocation, nozzle and feeder setups, pick-and-place sequences, etc. In the proposed ACGA, the nozzle and component allocation decisions are made before the evolutionary search of a genetic algorithm to improve the algorithm efficiency. First, the nozzle allocation problem is modeled as a nonlinear integer programming problem and solved by a search-based heuristic that minimizes the total number of the dual-gantry cycles. Then, an adaptive clustering approach is developed to allocate components to each gantry cycle by evaluating the gantry traveling distances over the PCB and the component feeders. Numerical experiments compare the proposed ACGA to another clustering-based genetic algorithm LCO and a heuristic algorithm mPhase in the literature using 30 industrial PCB samples. The experiment results show that the proposed ACGA algorithm reduces the total gantry moving distance by 5.71% and 4.07% on average compared to the LCO and mPhase algorithms, respectively.	algorithmic efficiency;cluster analysis;component placement;experiment;genetic algorithm;heuristic (computer science);integer programming;mathematical optimization;nonlinear system;optimization problem;printed circuit board;printing;smt placement equipment	Tongdi He;Debiao Li;Sang Won Yoon	2018	Advanced Engineering Informatics	10.1016/j.aei.2018.04.007	mathematical optimization;genetic algorithm;data mining;engineering;heuristic (computer science);cluster analysis;component placement;integer programming;algorithmic efficiency;smt placement equipment;optimization problem	AI	13.687225182609735	4.479413545315735	174697
8d8a1d15f6e1402885a2350c9867eed08151e6c4	a new measure for the study of on-line algorithms	online algorithm;competitive analysis;on line algorithm;competitive ratio	An accepted measure for the performance of an on-line algorithm is the “competitive ratio“ introduced by Sleator and Tarjan. This measure is well motivated and has led to the development of a mathematical theory for on-line algorithms. We investigate the behavior of this measure with respect to memory needs and benefits of lookahead and find some counterintuitive features. We present lower bounds on the size of memory devoted to recording the past. It is also observed that the competitive ratio reflects no improvement in the performance of an on-line algorithm due to any (finite) amount of lookahead. We offer an alternative measure that exhibits a different and, in some respects, more intuitive behavior. In particular, we demonstrate the use of our new measure by analyzing the tradeoff between the amortized cost of on-line algorithms for the paging problem and the amount of lookahead available to them. We also derive on-line algorithms for theK-server problem on any bounded metric space, which, relative to the new measure, are optimal among all on-line algorithms (up to a factor of 2) and are within a factor of 2K from the optimal off-line performance.	amortized analysis;competitive analysis (online algorithm);online algorithm;online and offline;page replacement algorithm;paging;parsing;server (computing)	Shai Ben-David;Allan Borodin	1994	Algorithmica	10.1007/BF01294264	competitive analysis;mathematical optimization;simulation;computer science;machine learning	Theory	15.81365070868442	12.994176812322259	174859
77a041b53d2fe90654f1c91013d31c82fe638a00	an improved mst algorithm for ranking players of a round-robin tournament	digraph;upset;round robin;ranking;spanning tree;round robin tournament	The problem of ranking players in a round-robin tournament, in which the outcome of any match is a win or a loss, is to rank them according to their performances in the tournament. In this paper we have improved the previously developed majority spanning tree (MST) algorithm for solving this problem, where the number of violations has been chosen as the criterion of optimality. The performance of our algorithm is compared with that of the MST algorithm.	file spanning;genetic algorithm;minimum spanning tree;performance;round-robin scheduling	Avijit Datta;Moazzem Hossain;Mohammad Kaykobad	2008	Int. J. Comput. Math.	10.1080/00207160701332721	mathematical optimization;combinatorics;tournament selection;spanning tree;ranking;tournament sort;mathematics;algorithm	AI	18.8011818864473	12.659762136012827	174949
3c0de1d7470d854d2f7fe86e64bc07f28ad95e79	"""no more """"partial"""" and """"full looking ahead"""""""	constraint propagation;look ahead;arc consistency;constraint satisfaction	Looking ahead is a commonly used search technique in constraint satisfaction. In this paper, we examine the future role of two long established lookahead algorithms, Partial Looking Ahead (PLA) and Full Looking Ahead (FLA). We prove that PLA is inferior to Directional Arcconsistency Lookahead in that the latter will prune at least as much as the former for no more computation in each problem reduction step. Similarly, FLA is inferior to Bi-directional Arcconsistency Lookahead, an algorithm introduced in this paper. We also point out a couple of errors in fhe literature. @ 1998 Elsevier Science B.V.	algorithm;computation;constraint satisfaction;local consistency;look-ahead (backtracking);lookahead carry unit;parsing;programmable logic array;xfig	Edward P. K. Tsang	1998	Artif. Intell.	10.1016/S0004-3702(97)00064-7	mathematical optimization;computer science;machine learning;mathematics;algorithm;local consistency	AI	10.601575478478122	16.24713718955549	175074
0f58cc8f62bdd36e9ef0894082257e44b0f7f910	automated planning for liner shipping fleet repositioning	automated planning;linear programming;mixed integer programming;partial order planning	The Liner Shipping Fleet Repositioning Problem (LSFRP) poses a large financial burden on liner shipping firms. During repositioning, vessels are moved between services in a liner shipping network. The LSFRP is characterized by chains of interacting activities, many of which have costs that are a function of their duration; for example, sailing slowly between two ports is cheaper than sailing quickly. Despite its great industrial importance, the LSFRP has received little attention in the literature. We show how the LSFRP can be solved sub-optimally using the planner POPF and optimally with a mixed-integer program (MIP) and a novel method called Temporal Optimization Planning (TOP). We evaluate the performance of each of these techniques on a dataset of real-world instances from our industrial collaborator, and show that automated planning scales to the size of problems	amanda;automated planning and scheduling;decision support system;dummy variable (statistics);expectation propagation;integer programming;interaction;linear programming;memoization;one-liner program	Kevin Tierney;Amanda Jane Coles;Andrew Coles;Christian Kroer;Adam M. Britt;Rune Møller Jensen	2012			mathematical optimization;simulation;computer science;linear programming;operations research	AI	16.182374828245127	5.023575508839114	175131
a33d1339e552422c77c58ef4b7cbc4cceb4019e4	automatic assembly sequences generation by pattern-matching	logical relation;componente mecanico;assemblage;pattern recognition assembling operations research;ensamble;general and or precedence nominal precedence forms automatic assembly sequences generation pattern matching state constrained travelling salesman problem precedence logic relations knowledge acquisition;systeme intelligent;representacion sistema;assembly jig;saisie donnee;travelling salesman problem;pattern matching robotic assembly assembly systems machine intelligence induction generators manufacturing industries buildings intelligent manufacturing systems intelligent structures intelligent robots;sistema inteligente;mechanical component;automatisation;operations research;automatizacion;algorithme;composant mecanique;algorithm;util montaje;toma dato;pattern matching;knowledge acquisition;representation systeme;assembling;intelligent system;system representation;pattern recognition;concordance forme;joining;data acquisition;algoritmo;montage pour assemblage;automation	The problem of automatically finding all the feasible assembly sequences for a set of n parts that compose a mechanical object is presented. The method proposed is feasible and practical in generating all the feasible assembly sequences when the number of parts is greatly increased. Previous work has shown that the question-answer pattern required 2l operations (here l is the total number of the liaisons and is bound between n-1 and (n/sup 2/-n)/2). An efficient network partitioning and pattern-matching operation is proposed to obtain precedence relations of the parts. This approach results in only l questions to be answered. The performance shows that the proposed algorithm can achieve a 50% reduction of questions asked. The proposed method shows feasibility and economy for the assembly of a large number of parts. Detailed algorithms, analysis, and examples are presented to show the effectiveness of the scheme.<<ETX>>	algorithm;network partition;pattern matching	C. L. Philip Chen	1989	IEEE 1989 International Conference on Systems Engineering	10.1109/21.87086	mathematical optimization;computer science;artificial intelligence;automation;machine learning;pattern matching;mathematics;data acquisition;travelling salesman problem;algorithm	Robotics	18.624209170630895	7.35758639097918	175245
a53a9e80959226748a97527d0bcfd208bdfff382	new lower and upper bounds for on-line scheduling	metodo caso peor;produccion;lower and upper bound;on line;en linea;worst case analysis;on line algorithms;algorithme;upper bound;algorithm;scheduling;borne inferieure;methode cas pire;production;ordonamiento;en ligne;borne superieure;worst case method;ordonnancement;lower bound;cota superior;cota inferior;algoritmo	We investigate the problem of on-line scheduling a set of independent jobs on m parallel and identical machines with the objective of minimizing the overall finishing time. In this note, we are mainly interested in the cases where m is small. We derive results on the inevitable worst-case deviations from the optimum as encountered by any on-line algorithm. For m = 2 and m = 3, Graham's List Schedulin9 heuristic is known to be best possible. For m = 4, we will derive almost matching upper and lower bounds on the best possible worst-case guarantee for any on-line algorithm.	best, worst and average case;graham scan;heuristic;online algorithm;online and offline;scheduling (computing)	Bo Chen;André van Vliet;Gerhard J. Woeginger	1994	Oper. Res. Lett.	10.1016/0167-6377(94)90071-X	mathematical optimization;calculus;mathematics;upper and lower bounds;algorithm	Theory	16.84159629964375	11.10902092722608	175411
69292fc6cd70c756a98c544be9e0d38f25fa6e7e	algorithms for the two dimensional bin packing problem with partial conflicts	bin packing;conflicts;distance constraint;genetic algorithm	The two-dimensional bin packing problem is a well-known problem for which several exact and approximation methods were proposed. In real life applications, such as in Hazardous Material transportation, transported items may be partially incompatible, and have to be separated by a safety distance. This complication has not yet been considered in the literature. This paper introduces this extension called the two-dimensional bin packing problem with partial conflicts (2BPPC) which is a 2BP with distance constraints between given items to respect, if they are packed within a same bin. The problem is NP-hard since it generalizes the BP, already NP-hard. This study presents a mathematical model, two heuristics and a multi-start genetic algorithm for this new problem.	algorithm;bin packing problem;set packing	Khaoula Hamdi-Dhaoui;Nacima Labadie;Alice Yalaoui	2012	RAIRO - Operations Research	10.1051/ro/2012007	mathematical optimization;combinatorics;discrete mathematics;bin packing problem;genetic algorithm;computer science	Theory	22.578003409071975	7.53077911054895	175418
63f6b2c05490225089347608a1f2407af72494d8	an immune partheno-genetic algorithm for winner determination in combinatorial auctions	modelizacion;zero one programming;genetic operator;immune algorithm;sistema inmunitario;heuristic method;programmation zero un;metodo heuristico;algoritmo inmunitario;algoritmo genetico;programming model;optimisation combinatoire;resolucion problema;modelisation;combinatorial problem;programmacion cero uno;probleme combinatoire;problema combinatorio;subasta;immune system;bidding;algorithme genetique;genetic algorithm;enchere;methode heuristique;winner determination problem;combinatorial optimization;modeling;systeme immunitaire;problem solving;resolution probleme;optimizacion combinatoria;algorithme immunitaire;combinatorial auction	Combinatorial auctions are efficient mechanisms for allocating resource in complex marketplace. Winner determination, which is NP-complete, is the core problem in combinatorial auctions. This paper proposes an immune partheno-genetic algorithm (IPGA) for solving this problem. Firstly, a zero-one programming model is built for the winner determination problem with XOR-bids and OR-bids. Then, steps of constructing three partheno-genetic operators and an immune operator are introduced. In the immune operation, new heuristics are designed for vaccines selection and vaccination. Simulation results show that the IPGA achieves good performance in large size problems and the immune operator can improve the searching ability and increase the converging speed greatly.	genetic algorithm	JianCong Bai;HuiYou Chang;Yang Yi	2005		10.1007/11539902_9	mathematical optimization;systems modeling;combinatorial auction;genetic algorithm;immune system;bidding;combinatorial optimization;computer science;artificial intelligence;genetic operator;mathematics;programming paradigm;algorithm	AI	20.586880443363942	6.010519013413673	175474
261045a8242c8732bdacec1d84dc1cd49633bad4	a note on the single machine serial batching scheduling problem to minimize maximum lateness with identical processing times	single machine;precedence constraints;scheduling;precedence constraint;scheduling problem;batches;journal magazine article	Abstract   We consider the single machine, serial batching scheduling problem 1|prec; p   j  = p ; s -batch; r   j  | L  max . The complexity of this problem is reported as open in the literature. By reducing this problem to the version without precedence constraints, we show that the problem is polynomially solvable.	scheduling (computing)	J. J. Yuan;A. F. Yang;T. C. Edwin Cheng	2004	European Journal of Operational Research	10.1016/S0377-2217(03)00361-8	nurse scheduling problem;job shop scheduling;mathematical optimization;real-time computing;computer science;operations management;distributed computing;scheduling	Theory	15.719011820961809	9.560918742127384	175632
18e12588fbd5edfc1abc168df377d79969e67eba	multi-target ray searching problems	search strategy;single target;multi-target ray;optimal search cost;star search;asymptotically optimal strategy;total search cost;efficient search strategy;uniform search;fundamental search paradigm;ray search	We consider the problem of exploring m concurrent rays using a single searcher. The rays are disjoint with the exception of a single common point, and in each ray a potential target may be located. The objective is to design efficient search strategies for locating t targets (with t ≤ m). This setting generalizes the extensively studied ray search (or star search) problem, in which the searcher seeks a single target. In addition, it is motivated by applications such as the interleaved execution of heuristic algorithms, when it is required that a certain number of heuristics have to successfully terminate. We apply two different measures for evaluating the efficiency of the search strategy. The first measure is the standard metric in the context of raysearch problems, and compares the total search cost to the cost of an optimal algorithm that has full information on the targets. We present a strategy that achieves optimal competitive ratio under this metric. The second measure is based on a weakening of the optimal cost as proposed by Kirkpatrick [ESA 2009] and McGregor et al. [ESA 2009]. For this model, we present an asymptotically optimal strategy which is within a multiplicative factor of Θ(log(m − t)) from the optimal search cost. Interestingly, our strategy incorporates three fundamental search paradigms, namely uniform search, doubling and hyperbolic dovetailing. Moreover, for both measures, our results demonstrate that the problem of locating t targets in m rays is essentially as difficult as the problem of locating a single target in m− (t− 1) rays.	asymptotically optimal algorithm;coefficient;competitive analysis (online algorithm);computer multitasking;esa;heuristic (computer science);period-doubling bifurcation;search problem;terminate (software)	Spyros Angelopoulos;Alejandro López-Ortiz;Konstantinos Panagiotou	2011		10.1007/978-3-642-22300-6_4	mathematical optimization;combinatorics;simulation;mathematics	AI	18.711181750068384	15.512330008539326	175713
c41775eecb18fc61505af25e694390dac39ff047	evolution of railway network flexibility: the spanish broad gauge case	graph theory;railway network analysis;network analysis;computer algebra system;quality indicator;computer algebra systems	The length of the Spanish broad gauge network has decreased in the 1956-2006 period. When looking at different railway maps through this period, it seems that the network is offering fewer and fewer alternatives when a line is cut, that is, the network is becoming less and less flexible. The goal of this article is to prove that the flexibility of the Spanish broad gauge network has decreased substantially in the 1956-2006 period. We have considered the network as a graph (ignoring traditional railway quality indicators such as commercial speed, number of tracks, electrifications, signaling, ...) and we have chosen two simple indicators as accurate in this sense: the number of cycles (cycles provide an alternative to reach a station if there is a problem in one line) and the number of stations of intermediate degree. To achieve this, we have developed a piece of software that is an ad hoc extension of Maple's networks package.		Eugenio Roanes-Lozano;Luis M. Laita;Eugenio Roanes-Macías;Michael J. Wester;José Luis Ruiz-Lozano;Carlos Roncero	2009	Mathematics and Computers in Simulation	10.1016/j.matcom.2008.11.007	simulation;network analysis;computer science;graph theory;mathematics;network simulation;algorithm	ECom	11.615452057151877	13.72378421757435	175943
2ae0c8ddd1e18e94d4f3142111f9fb498e0eb510	a generalized wedelin heuristic for integer programming	integer programming algorithms heuristics;integer program	A important ingredient for solving hard general integer programs are heuristics that try to quickly find good feasible solutions. One of these heuristics is Wedelin’s algorithm, which works for the limited class of 0-1 integer programs. A big advantage of Wedelin’s approach is that it does not depend on a solution of the linear programming (LP) relaxation as many other heuristics do. This makes it extremely fast in practice and makes it easy to use the parallelism of the upcoming multicore CPUs, as in an integer programming (IP) solver it could be applied in parallel to the traditional branch-and-bound algorithm. In this paper, we present several extensions and generalizations to Wedelin’s algorithm (most can be handled in an implicit manner without much performance cost) and investigate different ways of improving it. We give all necessary details and parameters. We strive for an algorithm that is faster than other heuristics but achieves comparable solution quality. We evaluate the performance of the algorithm on a large set of more than 100 instances from different sources. The results indicate that our heuristic often finds solutions comparable to or even better than those found using current state-of-the-art heuristics while typically needing only a fraction of their running time. Additionally, we report positive findings on the application of the heuristic on feasibility instances from discrete tomography. Our algorithm always finds the IP optimum in less time than the simplex/barrier algorithms and often in less time than it takes the volume algorithm to find just the LP optimum.	algorithm;branch and bound;central processing unit;discrete tomography;heuristic (computer science);integer programming;linear programming relaxation;multi-core processor;parallel computing;solver;time complexity	Oliver Bastert;Benjamin Hummel;Sven de Vries	2010	INFORMS Journal on Computing	10.1287/ijoc.1090.0328	mathematical optimization;integer programming;theoretical computer science;heuristics;mathematics;algorithm	AI	22.92306915675269	5.375540444250532	175998
34accaf9a026e85e139c032ab6c601a8cf800046	genetic algorithm for burst detection and activity tracking in event streams	minimisation;bayes estimation;modelizacion;dynamic programming;algoritmo paralelo;poisson process;minimization;time scale;programacion dinamica;streaming;systeme evenement discret;parallel algorithm;sismo;statistical mechanics;transmision continua;data stream;dynamic programming algorithm;seisme;heuristic method;bayesian inference;exact solution;mecanique statistique;discrete time;metodo heuristico;minimizacion;modele potts;solucion exacta;fisica estadistica;earthquakes;algoritmo genetico;algorithme parallele;sistema acontecimiento discreto;modelisation;statistical physics;potts model;estimacion bayes;discrete event system;transmission en continu;fichier log;fichero actividad;poursuite cible;programmation dynamique;algorithme genetique;physique statistique;algorithme evolutionniste;genetic algorithm;proceso poisson;algoritmo evolucionista;methode heuristique;evolutionary algorithm;solution exacte;target tracking;tiempo discreto;mecanica estadistica;temps discret;modelo potts;modeling;log file;processus poisson;poisson distribution;estimation bayes	We introduce a new model for detection and tracking of bursts of events in a discrete temporal sequence, its only requirement being that the time scale of events is long enough to make a discrete time description meaningful. A model for the occurrence of events using with Poisson distributions is proposed, which, applying Bayesian inference transforms into the well-known Potts model of Statistical Physics, with Potts variables equal to the Poisson parameters (frequencies of events). The problem then is to find the configuration that minimizes the Potts energy, what is achieved by applying an evolutionary algorithm specially designed to incorporate the heuristics of the model. We use it to analyze data streams of very different nature, such as seismic events and weblog comments that mention a particular word. Results are compared to those of a standard dynamic programming algorithm (Viterbi) which finds the exact solution to this minimization problem. We find that, whenever both methods reach a solution, they are very similar, but the evolutionary algorithm outperforms Viterbi’s algorithm in running time by several orders of magnitude, yielding a good solution even in cases where Viterbi takes months to complete the search.	anomaly detection;blog;comment (computer programming);dynamic programming;evolutionary algorithm;genetic algorithm;heuristic (computer science);potts model;time complexity;whole earth 'lectronic link	Lourdes Araujo;José A. Cuesta;Juan Julián Merelo Guervós	2006		10.1007/11844297_31	viterbi algorithm;statistical mechanics;computer science;artificial intelligence;dynamic programming;evolutionary algorithm;mathematics;algorithm;iterative viterbi decoding;statistics	AI	19.56002100971245	8.832205852621588	176197
c4d330ed409cb2155e8f236e4db6357c71f62790	the service allocation problem at the gioia tauro maritime terminal	minimisation;mixed integer linear program;optimal solution;assignment problem;quadratic programming;minimization;trafic maritime;afectacion cuadratica;yard management;probleme affectation;programmation quadratique;trafico maritimo;branch and bound algorithm;heuristic method;layout problem;mediterranean sea;probleme agencement;metodo heuristico;minimizacion;sea traffic;algoritmo genetico;branch and bound method;container terminal;programacion mixta entera;linearisation;metodo branch and bound;linearizacion;transbordo;maritime container terminal;arreglo;algorithme genetique;conteneur;transbordement;programmation partiellement en nombres entiers;problema disposicion;problema asignacion;mixed integer programming;algorithme evolutionniste;linearization;genetic algorithm;programacion cuadratica;tabu search;algoritmo evolucionista;quadratic assignment problem;methode heuristique;arrangement;methode separation et evaluation;evolutionary algorithm;contenedor;memetic heuristic;busqueda tabu;recherche tabou;container;transhipment;quadratic assignment;affectation quadratique	The Service Allocation Problem (SAP) is a tactical problem arising in the yard management of a container transshipment terminal. The objective is the minimization of the container rehandling operations inside the yard. This study of the SAP was undertaken for the Gioia Tauro port which is located in Italy and is the main hub terminal for container traffic in the Mediterranean Sea. The SAP can be formulated as a Generalized Quadratic Assignment Problem (GQAP) with side constraints. Two mixed integer linear programming formulations are presented. The first one exploits characteristics of the yard layout at Gioia Tauro where the berth and the corresponding yard positions extend along a line. The second formulation is an adaptation of a linearization for the GQAP. In both cases only small instances can be solved optimally. An evolutionary heuristic was therefore developed. For small size instances the heuristic always yields optimal solutions. For larger sizes it is always better than a truncated branch-and-bound algorithm applied to the exact formulations.	branch and bound;cplex;computation;evolutionary algorithm;exploit (computer security);heuristic;information system;integer programming;linear programming;memetics;quadratic assignment problem;real life;usb hub	Jean-François Cordeau;Manlio Gaudioso;Gilbert Laporte;Luigi Moccia	2007	European Journal of Operational Research	10.1016/j.ejor.2005.09.004	minimisation;mathematical optimization;transshipment;genetic algorithm;integer programming;tabu search;computer science;operations management;evolutionary algorithm;mathematics;assignment problem;operations research;quadratic programming;linearization;container;branch and bound;quadratic assignment problem	AI	18.430902192168855	5.765585859600602	176231
1cf314336cc6af13025fa91b19a50960b626684e	on the traveling salesman problem with simple temporal constraints	spatial and temporal reasoning;complexity;datavetenskap datalogi;datavetenskap;computer science	Many real-world applications require the successful combination of spatial and temporal reasoning. In this paper, we study the general framework of the Traveling Salesman Problem with Simple Temporal Constraints. Representationally, this framework subsumes the Traveling Salesman Problem, Simple Temporal Problems, as well as many of the frameworks described in the literature. We analyze the theoretical properties of the combined problem providing strong inapproximability results for the general problem, and positive results for	2-opt;agent-based model;cobham's thesis;hardness of approximation;heuristic (computer science);knowledge engineering;multi-agent system;requirement;robotics;theoretical computer science;travelling salesman problem	T. K. Satish Kumar;Marcello Cirillo;Sven Koenig	2013			mathematical optimization;complexity;computer science;machine learning;mathematics;algorithm;3-opt	AI	12.936257100238272	16.05249118803518	176317
54b7eab53dda0158d179dc8636ef0e065edd837b	determining source–destination connectivity in uncertain networks: modeling and solutions	approximation algorithms;heuristic algorithms;algorithm design and analysis;testing;uncertainty;reliability;markov processes	Determination of source–destination connectivity in networks has long been a fundamental problem, where most existing works are based on deterministic graphs that overlook the inherent uncertainty in network links. To overcome such limitation, this paper models the network as an uncertain graph, where each edge $e$ exists independently with some probability $pe$ . The problem examined is that of determining whether a given pair of nodes, a source $s$ and a destination $t$ , are connected by a path or separated by a cut. Assuming that during each determining process we are associated with an underlying graph, the existence of each edge can be unraveled through edge testing at a cost of $ce$ . Our goal is to find an optimal strategy incurring the minimum expected testing cost with the expectation taken over all possible underlying graphs that form a product distribution. Formulating it into a combinatorial optimization problem, we first characterize the computational complexity of optimally determining source–destination connectivity in uncertain graphs. Specifically, through proving the NP-hardness of two closely related problems, we show that, contrary to its counterpart in deterministic graphs, this problem cannot be solved in polynomial time unless P = NP. Driven by the necessity of designing an exact algorithm, we then apply the Markov decision process framework to give a dynamic programming algorithm that derives the optimal strategies. As the exact algorithm may have prohibitive time complexity in practical situations, we further propose two more efficient approximation schemes compromising the optimality. The first one is a simple greedy approach with linear approximation ratio. Interestingly, we show that naive as it is, and it enjoys significantly better performance guarantee than some other seemingly more sophisticated algorithms. Second, by harnessing the submodularity of the problem, we further design a more elaborate algorithm with better approximation ratio. The effectiveness of the proposed algorithms is justified through extensive simulations on three real network data sets, from which we demonstrate that the proposed algorithms yield strategies with smaller expected cost than conventional heuristics.	approximation algorithm;combinatorial optimization;computational complexity theory;directed graph;dynamic programming;exact algorithm;greedy algorithm;heuristic (computer science);linear approximation;markov chain;markov decision process;mathematical optimization;np-hardness;optimization problem;p versus np problem;path (graph theory);simulation;time complexity	Luoyi Fu;Xinzhe Fu;Zhiying Xu;Qianyang Peng;Xinbing Wang;Songwu Lu	2017	IEEE/ACM Transactions on Networking	10.1109/TNET.2017.2725905	time complexity;distributed computing;mathematical optimization;heuristics;computational complexity theory;combinatorial optimization;dynamic programming;computer science;approximation algorithm;markov decision process;exact algorithm	Theory	12.954546788516549	14.309005703968754	176429
310b2c51a5fcdf73ee89b97e7e323d3cec2e1a5a	closed-loop production and automation scheduling in rmss	integrated approach;scheduling agile manufacturing production control production planning;assembly line closed loop production scheduling automation scheduling reconfigurable manufacturing systems agile production system short term production planning finishing robotic cell;agile manufacturing;production system;production control;scheduling;job shop scheduling automation schedules dynamic scheduling spraying;production planning;system architecture	Highly reconfigurable and agile production systems are selected to operate in production contexts often characterized by changes of the production requirements or changes of the part family demand. The operational level for such system architecture is expected to manage the short term production planning while guaranteeing the automation layer enables physical devices to exploit logic control tasks within the specific time buckets. The proposed work outlines an integrated approach supporting the operational level for RMSs in which the scheduling of production jobs and the scheduling of corresponding automation tasks are dynamically coupled. Connections with consolidated constraint-based representation and solving techniques are also discussed. The integrated scheduling approach has been validated with reference to a Finishing Robotic Cell (FRC) operating in a pilot assembly line.	agile software development;automation;cell (microprocessor);frame rate control;job stream;logic control;out-of-order execution;performance;requirement;scheduling (computing);software deployment;systems architecture;turbulence	Emanuele Carpanzano;Andrea Orlandini;Anna Valente;Amedeo Cesta;Riccardo Rasconi	2011	ETFA2011	10.1109/ETFA.2011.6059046	fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;flow shop scheduling;dynamic priority scheduling;computer science;engineering;artificial intelligence;genetic algorithm scheduling;operating system;two-level scheduling;scheduling;production system;scheduling;systems architecture;manufacturing engineering	Robotics	11.655469571292596	4.978348968935275	176453
4763a05c1562f201869817a01cadf7924db7194b	the resource-constrained project scheduling problem with stochastic activity durations	small to medium enterprises project management scheduling;project management;rcpsp;resource constraints project management scheduling rcpsp stochastic activity durations;scheduling;stochastic processes computational modeling schedules job shop scheduling processor scheduling optimal scheduling central processing unit;small to medium sized projects resource constrained project scheduling problem stochastic activity durations rcpsp activity duration variability stochastic resource constrained scheduling problem;stochastic activity durations;resource constraints	The Resource-Constrained Project Scheduling Problem (RCPSP) has been widely studied. A fundamental assumption of the RCPSP is that the activity durations are known before their execution. In reality, however, this is almost never the case. In this article, we illustrate why it is important to incorporate activity duration variability and develop an exact model to solve the Stochastic Resource-Constrained Scheduling Problem (SRCPSP). The performance of the model is assessed using a computational experiment. The model is intended for small-to medium sized projects where activities have a moderate-to large level of duration variability.	computation;heart rate variability;schedule (project management);scheduling (computing);spatial variability;stochastic process	Stefan Creemers	2014	2014 IEEE International Conference on Industrial Engineering and Engineering Management	10.1109/IEEM.2014.7058679	project management;fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;flow shop scheduling;economics;dynamic priority scheduling;computer science;rate-monotonic scheduling;operations management;genetic algorithm scheduling;two-level scheduling;scheduling;lottery scheduling;round-robin scheduling;scheduling	Robotics	13.787626733028944	7.891467945113578	176541
