id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
7aa54d22d7b6551b63e883d45b191dee56e3eea3	algorithms for current monitor based diagnosis of bridging and leakage faults	combinatorial circuits;fault location;logic testing;sequential circuits;bridging;combinational circuits;current monitor based diagnosis;leakage faults;ordered-pairs of sets;sequential circuits	Current monitor based diagnosis algorithms for bridging and leakage faults are presented. These algorithms do not use fault dictionaries. Instead, they use SOPS, a novel representation of fault lists. Experimental evaluation of the algorithms are presented.	algorithm;bridging (networking);dictionary;spectral leakage	Sreejit Chakravarty;Minsheng Liu	1992			embedded system;electronic engineering;real-time computing;bridging;computer science;engineering;sequential logic;combinational logic;steady state;fault detection and isolation;algorithm	EDA	22.404675325733105	51.39056462047446	46639
115fa0a39ebd95ab17860a76d3894d7463307a33	series-parallel functions and fpga logic module design	field programmable gate array;series parallel technology mapping;universal logic modules;logic synthesis;field programmable gate arrays;technology mapping;tree based technology mapping algorithm;series parallel	The need for a two-way interaction between logic synthesis and FPGA logic module design has been stressed recently. Having a logic module that can implement many functions is a good idea only if one can also give a synthesis strategy that makes efficient use of this functionality. Traditionally, technology mapping algorithms have been developed after the logic architecture has been designed. We follow a dual approach, by focusing on a specific technology mapping algorithm, namely, the structural tree-based mapping algorithm, and designing a logic module that can be mapped efficiently by this algorithm. It is known that the tree-based mapping algorithm makes optimal use of a library of functions, each of which can be represented by a tree of AND, OR, and NOT gates (series-parallel or SP functions). We show how to design a SP function with a minimum number of inputs that can implement all possible SP functions with a specified number of inputs. For instances, we demonstrate a seven-input SP function that can implement all four-input SP functions. Mapping results show that, on an average, the number blocks of this function needed to map benchmark circuits are 12% less than those for Actel's ACT1 logic modules. Our logic modules show a 4% improvement over ACT1, if the block count is scaled to take into account the number of transistors needed to implement different logic modules.	and gate;algorithm;benchmark (computing);field-programmable gate array;greedy algorithm;heuristic;logic synthesis;multiplexer;optimization problem;routing;sp-devs;series-parallel graph;transistor	Shashidhar Thakur;Martin D. F. Wong	1996	ACM Trans. Design Autom. Electr. Syst.	10.1145/225871.225891	embedded system;and-or-invert;discrete mathematics;logic synthesis;logic optimization;diode–transistor logic;logic level;logic gate;logic family;programmable logic array;computer science;theoretical computer science;programmable logic device;pass transistor logic;mathematics;sequential logic;fair computational tree logic;function block diagram;simple programmable logic device;digital electronics;programmable array logic;register-transfer level;field-programmable gate array	EDA	16.04549245469868	49.18353355109043	46644
d63c6549007e3f9ffb3ba70d3872d27b49338749	an effective built-in self-test for chargepump pll	bist;tecnologia electronica telecomunicaciones;methode essai;integrated circuit;autoprueba;circuito integrado;autotest;system on a chip;built in self test;retroaccion;sistema sobre pastilla;retroaction;mixed signal test;bucle enclavamiento fase;phase locked loop;feedback regulation;pll;systeme sur puce;test method;tecnologias;grupo a;boucle verrouillage phase;circuit integre;metodo ensayo	In order to provide an efficient test method for PLL which is a mixed-signal circuit widely used in most of SoCs, a novel BIST method is developed. The new BIST uses the change of phase differences generated by selectively alternating the feedback frequency. It provides an efficient structural test, reduces an area overhead and improves the test accessibility.	phase-locked loop	Junseok Han;DongSup Song;Hagbae Kim;Youngyong Kim;Sungho Kang	2005	IEICE Transactions	10.1093/ietele/e88-c.8.1731	embedded system;electronic engineering;phase-locked loop;telecommunications;computer science;engineering	EDA	19.35748823718695	54.69273767798483	46673
5e5392eafcabbee54710a97021427cdd7662fe40	single-cycle, pulse-shaped critical path monitor in the power7+ microprocessor	elemental semiconductors;microprocessor chips;silicon-on-insulator;8-core power7+ microprocessor;soi cpm;soi critical path monitor;digital pll;dynamic frequency adjustment;dynamic noise detection;nominal frequency;nominal voltage;power savings;processor temperature sensitivity;single-cycle pulse-shaped critical path monitor;timing measurement;turbo voltage;voltage sensitivity;critical path monitor;dvfs;calibration;process variation	A 32nm SOI critical path monitor (CPM) that can provide timing measurements to a Digital PLL for dynamic frequency adjustments in the 8-core POWER7+™ microprocessor is described. The CPM calibrates to within 2% of cycle time from nominal to turbo voltages. Its voltage sensitivity is 10mV/bit. It tracks processor temperature sensitivity to within 1.5% of nominal frequency, and has a sample jitter less than 1.5% of nominal frequency. The ability to detect noise dynamically allows the system to operate the processor closer to its optimal frequency for any given voltage, resulting in lower voltage for power savings or higher frequency for performance improvements.	critical path method;microprocessor;phase-locked loop	Alan J. Drake;Michael S. Floyd;Richard L. Willaman;Derek J. Hathaway;Joshua Hernandez;Crystal Soja;Marshall D. Tiner;Gary D. Carpenter;Robert M. Senger	2013	International Symposium on Low Power Electronics and Design (ISLPED)		embedded system;electronic engineering;real-time computing;calibration;engineering;silicon on insulator;process variation	Arch	19.263528514581434	58.91720245123427	46699
42e6fde090224103bc9ad36dae90b25f0b4bafe9	an optically differential reconfigurable gate array with a partial reconfiguration optical system and its power consumption estimation	optically differential reconfigurable gate array;estimation theory;logic arrays;partial reconfiguration;reconfigurable architectures;very large scale integration;memory reduction;photodiodes;optical arrays energy consumption holographic optical components holography field programmable gate arrays photodiodes very large scale integration circuits estimation theory hardware;optical arrays;energy consumption;optical logic;vlsi;holographic optical components;holography;circuits;power consumption;memory reduction optically differential reconfigurable gate array partial reconfiguration optical system power consumption vlsi very large scale integration;field programmable gate arrays;vlsi logic arrays reconfigurable architectures optical logic power consumption;partial reconfiguration optical system;hardware	This paper proposes an optically differential reconfigurable gate array (ODRGA) with a partial reconfiguration optical system. The ODRGA not only realizes a partial reconfiguration capability; it also reduces the amount of memory required to store reconfiguration contexts while reducing optical reconfiguration power consumption. This paper presents ODRGA-VLSI, which is available for a partial reconfiguration technique. Advantages of reducing the amount of memory and power consumption are estimated theoretically and compared with a conventional optically reconfigurable gate array.	gate array;very-large-scale integration	Minoru Watanabe;Fuminori Kobayashi	2004	17th International Conference on VLSI Design. Proceedings.	10.1109/ICVD.2004.1261015	embedded system;electronic engineering;real-time computing;computer science;engineering;electrical engineering;very-large-scale integration	EDA	15.125276105351865	59.70703525690302	46897
058c1de4151464d9ea5aab4a3bbc8ab2f99b164b	circular bist testing the digital logic within a high speed serdes	silicon;circuit faults;clocks;digital logic;built in self test;application specific integrated circuits;transmitters;logic testing;manufacturing;circuit testing;logic testing built in self test transmitters circuit testing clocks frequency application specific integrated circuits manufacturing circuit faults silicon;frequency;high speed	High Speed Serializer Deserializers (serdes) are traditionally tested using functional BIST. This paper presents an improved BlST for testing the digital part of a serdes using circular BET.	boolean algebra;built-in self-test;fault coverage;overhead (computing);serdes;simulation;while	Graham Hetherington;Richard Simpson	2003		10.1109/TEST.2003.1271111	serdes;boolean algebra;embedded system;transmitter;electronic engineering;computer science;engineering;electrical engineering;frequency;application-specific integrated circuit;manufacturing;silicon	EDA	22.880875790378408	52.61901324218882	46942
e1416a900da9bf7851fef1b6d4470eab427792da	innovative structures to test bonding alignment and characterize high density interconnects in 3d-ic		3D integration is a promising solution to meet the increased need for functionality, density and performance of future integrated circuits. But it is necessary to have a high interconnection density to reach a significant performance gain in 3D Integrated Circuits (3D-IC). The Cu-Cu hybrid bonding can offer higher interconnects density (Pitch around 2µm or less), but that generates new challenges for test and characterization. This paper focuses on test and characterization of Cu-Cu interconnects and propose smart test vehicles to measure several information after bonding: perfect alignment, misalignment (direction, value) and contact resistance. These test structures are implemented without active part for process development and also in an application circuit to assess performance of 3D-IC thanks to the DFT infrastructure. This paper describes simulation and logic synthesis results of both implementations.	electrical connection;interconnection;logic synthesis;simulation;standard-definition television;three-dimensional integrated circuit	Imed Jani;Didier Lattard;Pascal Vivet;Edith Beigné	2017	2017 15th IEEE International New Circuits and Systems Conference (NEWCAS)	10.1109/NEWCAS.2017.8010128	computer science;sheet resistance;and gate;electronic engineering;implementation;three-dimensional integrated circuit;integrated circuit;interconnection;contact resistance	EDA	12.589091420456242	57.57234848822768	46950
05748c7dd2e549fa1d778ca86f9e902738f4b29d	practical logic synthesis for cplds and fpgas with pla-style logic blocks	programmable logic devices;integrated circuit layout;field programmable gate arrays logic arrays routing logic devices logic circuits delay circuit synthesis table lookup integrated circuit interconnections logic functions;network routing;pla synt algorithm logic synthesis cplds fpgas pla style logic blocks programmable logic array storage elements clustering functional decomposition routing resource reduction encoding functions base functions;logic synthesis;programmable logic array;functional decomposition;circuit layout cad field programmable gate arrays programmable logic devices logic cad circuit cad network routing integrated circuit layout;place and route;circuit layout cad;circuit cad;field programmable gate arrays;logic cad	In some modern FPGAs and CPLDs, PLA(programmable logic array)-style logic blocks can be used as the storage elements for improved logic density and performance. PLA-style logic blocks were originally deployed in the early PLDs. Due to recent research developments in the FPGA community such as [6] and [4], PLA-style logic blocks are becoming an effective storage alternative in FPGAs. This paper presents an approach with clustering and functional decomposition to implement the circuits using the minimum number of PLA-style logic blocks. One important feature is that it simultaneously considers the routing resource reduction for better circuit performance after place-and-route. In order to effectively use PLA-style logic blocks in large clusters, functional decompositions are used to decompose large clusters so that the encoding functions and base functions can be mapped into PLA-blocks. Furthermore, implicit representation[5] of the crucial steps in the functional decomposition is used to consider 1) number of inputs, 2) number of product terms. 3) number of outputs required for the PLA-block synthesis. We have developed an algorithm called PLA_SynT that can be used in the logic synthesis flow for CPLDs and FPGAs with PLA-blocks. MCNC benchmarks are used to test PLA_SynT and the experimental results are compared with TEMPLA[1]. PLA_SynT shows 10.24% improvement over TEMPLA[1], in terms of the number of PLA-blocks needed to implement the circuit. PLA_SynT also shows 14.41% improvement over EMB_Syn[3] in circuit performances while maintaining comparable circuit areas.	algorithm;cluster analysis;complex programmable logic device;field-programmable gate array;implicit surface;logic synthesis;performance;place and route;programmable logic array;routing	Kenneth Yan	2001		10.1145/370155.370330	erasable programmable logic device;functional decomposition;embedded system;routing;computer architecture;electronic engineering;logic synthesis;macrocell array;logic optimization;diode–transistor logic;asynchronous circuit;logic gate;logic family;programmable logic array;computer science;theoretical computer science;programmable logic device;pass transistor logic;place and route;sequential logic;complex programmable logic device;integrated circuit layout;simple programmable logic device;digital electronics;programmable array logic;register-transfer level;field-programmable gate array;resistor–transistor logic	EDA	15.447464216295801	49.43200966079376	47033
d024f5f55af888b23eac817ebc6a092608c32a9a	a graph-based approach to optimal scan chain stitching using rtl design descriptions	benchmark design;mandatory logic insertion design;uses classic approximation algorithm;chain insertion;graph model;graph-based approach;salesman problem;chain insertion problem;rtl design description;best scan-stitching;stitching algorithm	benchmark design;mandatory logic insertion design;uses classic approximation algorithm;chain insertion;graph model;graph-based approach;salesman problem;chain insertion problem;rtl design description;best scan-stitching;stitching algorithm		Lilia Zaourar;Yann Kieffer;Chouki Aktouf	2012	VLSI Design	10.1155/2012/312808	scan chain;computer science;theoretical computer science;engineering drawing;algorithm	EDA	17.461641667121615	49.01036585153786	47219
7a3ed8a3ac658be04cdb61f7b13cbcfc37195b5f	4×4-bit array two phase clocked adiabatic static cmos logic multiplier with new xor	power supplies;low power electronics cmos logic circuits logic gates;cmos integrated circuits;smart card;clocks;low frequency;simulation;logic circuits;arrays;low power;logic gates;cmos logic circuits;analytical method;power dissipation;size 0 18 mum two phase clocked adiabatic static cmos logic multiplier xor power consumption adiabatic circuit radiofrequency identifications low power digital devices smart cards sensors rfid static cmos;low power electronics;cmos integrated circuits arrays clocks power dissipation power supplies simulation logic circuits;radio frequency identification;power consumption	This paper presents the simulation results of a 4×4-bit array two phase clocked adiabatic static CMOS logic (2PASCL) multiplier using 0.18 µm standard CMOS technology. We also propose a new design of 2PASCL XOR which reduces the number of transistors as well as the power consumption. Analytical method to compare the lower current flow in adiabatic circuit is also presented. At transition frequencies of 1 to 100 MHz, 4×4-bit array 2PASCL multiplier shows a maximum of 55% reduction in power dissipation to that of a static CMOS. The results indicate that 2PASCL technology can be advantageously applied to low power digital devices operated at low frequencies, such as radio-frequency identifications (RFIDs), smart cards, and sensors.	adiabatic circuit;cmos;clock rate;exclusive or;radio frequency;sensor;simulation;smart card;transistor	Nazrul Anuar;Yasuhiro Takahashi;Toshikazu Sekine	2010	2010 18th IEEE/IFIP International Conference on VLSI and System-on-Chip	10.1109/VLSISOC.2010.5642688	electronic engineering;real-time computing;adiabatic circuit;logic gate;computer science;electrical engineering;mathematics	EDA	17.811930964537137	57.47227340295984	47336
4410739eec6222ccfa5bbb26776f3156e451c8c4	the planar topology of functional programs	computer aided design;integrated circuit;very large scale integrated;vlsi design;functional programming;normal form	The use of the applicative language (FP) in VLSI design has been advocated, because it provides not only the structure of a circuit, but the planar organization of its components and their interconnections. In this paper, the leveI of geometric detail implied by the functional programming style is formalized. The notion of 'planar topology' of an integrated circuit layout is defined and shown to be the appropriate level of geometric information to infer from an FP specification of a circuit. This definition provides a normal form for the representation of the planar topology of a layout which is not only unique (modulo local operations), but is optimal over all representations of the same planar topology with respect to topological cost measures. This normal form is exploited to improve the wiring of the layouts; it is realized by the application of transformations to the FP specification. The specification of a carry-save array multiplier is used as an example to illustrate how this optimization reduces the effort required to specify an integrated circuit.	a-normal form;applicative programming language;circuit diagram;functional programming;integrated circuit layout;mathematical optimization;modulo operation;programming style;very-large-scale integration;wiring	Martine D. F. Schlag	1987		10.1007/3-540-18317-5_11	physical design;computer architecture;computer science;integrated circuit;very-large-scale integration;programming language;functional programming	EDA	12.45029352928338	50.308868438791336	47681
7123c153ae96e7a84477a2eb1d117e4eaf65d6ad	fast methods to estimate clock jitter due to power supply noise	tecnologia electronica telecomunicaciones;power supply noise;clock jitter;tecnologias;grupo a;clock distribution network;power distribution network	In this paper, we propose two methods to estimate clock jitter caused by power supply noise in a LSI (Large-Scale Integrated circuit). One of the methods enables estimation of clock jitter at the initial design stage before floor-planning. The other method reduces simulation time of clock distribution network to analyze clock jitter at the design verification stage after place-and-route of the chip. For an example design, the relative difference between clock jitter estimated at the initial design stage and that of the design verification stage is 23%. The example result also shows that the proposed method for the verification stage is about 24 times faster than the conventional one to analyze clock jitter.	power supply	Koutaro Hachiya;Takayuki Ohshima;Hidenari Nakashima;Masaaki Soda;Satoshi Goto	2007	IEICE Transactions	10.1093/ietfec/e90-a.4.741	clock synchronization;embedded system;real-time computing;data strobe encoding;jitter;clock domain crossing;clock skew;clock rate;underclocking;timing failure;synchronous circuit;clock gating;digital clock manager;cpu multiplier	EDA	20.391403692302966	54.438203510922754	47741
0dcb1709b95663c0750945049a22065819f334d5	an improved dynamic optically reconfigurable gate array	optical arrays optical receivers high speed optical techniques circuits digital audio players dna clocks frequency field programmable gate arrays computer aided instruction;three metal cmos process technology dynamic optically reconfigurable gate array photodiodes refresh transistor receiver memory 476 gate dorga circuit reconfiguration optical reconfiguration architecture pass transistor;dynamic reconfiguration;programmable logic arrays;null;transistors programmable logic arrays high level synthesis circuit layout cad optical logic cmos logic circuits photodiodes;high level synthesis;reconfigurable architecture;photodiodes;cmos logic circuits;transistors;optical logic;circuit layout cad;flip flop	To date, we have proposed dynamic optically reconfigurable gate arrays (DORGAs), the implemented photodiodes of which serve not only as receivers but also as memory. DORGA offers the merit of easily providing a high gate count optically reconfigurable gate array (ORGA) because each reconfiguration circuit consists of only a photodiode and a refresh transistor. However, even though the fast reconfiguration capability has been confirmed as less than 6 ns, such systems have a demerit: their gate arrays can not function during reconfiguration. Consequently, reconfiguration and operation of the implemented circuit on a gate array can not be executed in parallel. Because of that fact, the dynamical reconfiguration frequency of DORGA is slow compared to those of ORGAs with latches, flip-flops, or memory. For that reason, this paper proposes a new optical reconfiguration architecture. Using it, the reconfiguration and implemented circuit operation on a gate array are executable in parallel merely by adding a pass transistor. The new design of a 476-gate-count improved DORGA using a standard 0.35 /spl mu/m three-metal CMOS process technology is also shown.	and gate;cmos;computer-aided design;diagram;executable;flops;field-programmable gate array;gate count;input/output;proceedings of the ieee;reconfigurable computing;transistor;very-large-scale integration	Minoru Watanabe;Fuminori Kobayashi	2005	IEEE Computer Society Annual Symposium on VLSI: New Frontiers in VLSI Design (ISVLSI'05)	10.1109/ISVLSI.2005.16	embedded system;electronic engineering;real-time computing;logic gate;engineering;gate equivalent;programmable logic device;nand gate	EDA	18.419027183342454	51.08810369382208	47844
9837f51de194ededdfad2ac92a1ed68be4621eb6	design for mitigation of single event effects	silicon;low cost mitigation techniques;fault tolerance integrated circuit reliability nanoelectronics integrated circuit design neutron effects;thyristors;fault tolerance single event effects fault tolerant techniques low cost mitigation techniques alpha particles atmospheric neutrons nanometric designs single event transients single event upsets integrated circuit reliability neutron effects nanoelectronics integrated circuit design;fault tolerant;clocks;fault tolerant techniques;single event effects;single event effect;neutrons;error analysis;integrated circuit design;pulse circuits;nanometric designs;logic gates;single event upsets;fault tolerance;nanoelectronics;single event upset neutrons logic devices clocks silicon pulse circuits latches error analysis logic gates thyristors;atmospheric neutrons;latches;single event upset;integrated circuit reliability;neutron effects;logic devices;single event transients;alpha particles	Various fault tolerant techniques can be employed to mitigate SEUs, SETs and SELs. However, such techniques usually inquire high hardware, speed and power penalty that most commercial applications could not afford. This presentation concerns low cost mitigation techniques for single-event effects induced by alpha particles and atmospheric neutrons in advanced nanometric designs.	fault tolerance;single event upset	Michael Nicolaidis	2005	11th IEEE International On-Line Testing Symposium	10.1109/IOLTS.2005.20	embedded system;fault tolerance;electronic engineering;real-time computing;engineering	Arch	20.397123707041278	56.65138252815224	47956
56cfe27f844aa407fa5eaadac2e7310837f2ce24	stable: a new qf-bv smt solver for hard verification problems combining boolean reasoning with computer algebra	quantifier free logic;arithmetic bit level information;industrial data path modules;fixed sized bit vectors;hard verification problems;system on a chip;polynomials;boolean algebra;formal verification;engines;system on chip designs;algebra;system on chip;boolean reasoning;adders;polynomials mathematical model system on a chip adders engines algebra;mathematical model;computer algebra based engine;bit blasting;soc;smt based property checking flow;hardware description language;computer algebra;system on chip boolean algebra formal verification;arithmetic problems;arithmetic problems hard verification problems boolean reasoning computer algebra quantifier free logic fixed sized bit vectors computer algebra based engine bit blasting smt based property checking flow system on chip designs soc industrial data path modules arithmetic bit level information	This paper presents a new SMT solver, STABLE, for formulas of the quantifier-free logic over fixed-sized bit vectors (QF-BV). The heart of STABLE is a computer-algebra-based engine which provides algorithms for simplifying arithmetic problems of an SMT instance prior to bit-blasting. As the primary application domain for STABLE we target an SMT-based property checking flow for System-on-Chip (SoC) designs. When verifying industrial data path modules we frequently encounter custom-designed arithmetic components specified at the logic level of the hardware description language being used. This results in SMT problems where arithmetic parts may include non-arithmetic constraints. STABLE includes a new technique for extracting arithmetic bit-level information for these non-arithmetic constraints. Thus, our algebraic engine can solve subproblems related to the entire arithmetic design component. STABLE was successfully evaluated in comparison with other state-of-the-art SMT solvers on a large collection of SMT formulas describing verification problems of industrial data path designs that include multiplication. In contrast to the other solvers STABLE was able to solve instances with bit-widths of up to 64 bits.	64-bit computing;algorithm;application domain;bit array;bit-level parallelism;cobham's thesis;decision problem;hardware description language;linear algebra;logic level;mpsoc;quantifier (logic);satisfiability modulo theories;solver;symbolic computation;system on a chip	Evgeny Pavlenko;Markus Wedler;Dominik Stoffel;Wolfgang Kunz;Alexander Dreyer;Frank Seelisch;Gert-Martin Greuel	2011	2011 Design, Automation & Test in Europe	10.1109/DATE.2011.5763035	system on a chip;symbolic computation;computer science;theoretical computer science;programming language;algorithm	Logic	17.99984918817098	47.68196013895414	48003
78fbee163caf83656081acecfdb684578dba0f8b	scheduling tests for low power built-in self-test	switching activity;power estimation;automatic testing;automatic testing built in self test circuit testing energy consumption registers processor scheduling switching circuits logic testing fault tolerance hazards;built in self test;parameter estimation power consumption circuit reliability built in self test scheduling automatic testing circuit testing low power electronics logic testing;low power;circuit reliability;energy consumption;scheduling;logic testing;low power electronics;circuit testing;power estimation scheduling tests built in self test hazards reliability power consumption heat dissipation energy consumption switching overlapping subcircuits hierarchical approach;parameter estimation;power consumption;peak power	During test, circuits are exposed to an increased switching activity which can rise severe hazards to their reliability due to excessive power consumption and heat dissipation. We consider the problem of scheduling tests under peak power constraints such that the total energy consumption is minimized. The proposed method takes into account switching activity which occurs in overlapping regions of the subcircuits under test by means of a hierarchical approach to power estimation.	built-in self-test;scheduling (computing)	Tobias Schüle;Albrecht P. Stroele	2001		10.1109/ISCAS.2001.922031	reliability engineering;electronic engineering;real-time computing;computer science;engineering;operating system;estimation theory;scheduling;low-power electronics	EDA	20.031614289458492	57.81146056959596	48061
555f1d90ad0914e5970a4abec5a183617724bedd	generation of compact delay tests by multiple-path activation	automatic testing;multivalued logic circuits;automatic test equipment;delay circuit testing logic testing circuit faults multivalued logic robustness sequential circuits algebra system testing fault detection;logic testing;test generation;automatic test equipment multivalued logic circuits logic testing delays automatic testing;is success;iscas 89 benchmarks state transition graph state minimisation compact delay tests multiple path activation 23 value logic system robust path delay tests path faults test generator podem like branch bound search efficient path designation secondary target faults multiple faults;branch and bound;delays	We use a 23-value logic system to generate robust path delay tests. Each test is successively augmented to detect as many path faults as possible. Other features of the test generator are a podem-like branch and bound search for test, an efficient path designation based on ordering of paths, and an algorithmic selection of secondary target faults for augmenting the tests to cover multiple faults. Results for ISCAS '89 benchmarks are given. >		Soumitra Bose;Prathima Agrawal;Vishwani D. Agrawal	1993		10.1109/TEST.1993.470631	embedded system;basis path testing;automatic test equipment;electronic engineering;discrete mathematics;logic optimization;computer science;mathematics;branch and bound;algorithm	EDA	19.891177150660187	48.88471667919466	48159
5e0b1daf78d3845169a7adcf3a84b43620327702	sh-mobile - low power application processor for cellular [3g cellular phones]	digital signal processing;low power application processor;leakage current;clocks;cellular radio;leakage current reduction;size control;computer architecture;dual cpu core;3g mobile communication;low power;leakage currents;energy consumption;partial power shut down mechanism;pipelines;low power electronics;mobile handsets;digital signal processing chips;clocks energy consumption cellular phones cameras frequency pipelines computer architecture digital signal processing chips digital signal processing size control;point of view;frequency;low power consumption;leakage currents mobile handsets cellular radio 3g mobile communication microprocessor chips low power electronics;cameras;media accelerators;cellular phones;sh mobile processor;multithreshold transistors;3g cellular phones;microprocessor chips;processor internal memory;media accelerators multithreshold transistors dual cpu core 3g cellular phones sh mobile processor low power application processor leakage current reduction partial power shut down mechanism processor internal memory	Renesas Technology Corp. gains world wide support in the field of application processors for cellular phones (SH-mobile), where various performance demanding applications must be handled with very low power consumption. Techniques of the SH-mobile to reduce leakage current, such as a partial power shut down mechanism and a methodology of multi-threshold transistors are introduced. Also advantages of the SH-mobile architecture, such as dual CPU core, large internal memory, and various media accelerators, are described from a low power consumption point of view.	central processing unit;computer data storage;mobile phone;point of view (computer hardware company);spectral leakage;transistor	S. Kamae;Takahiro Irita;A. Tsukimori;S. Tarnaki;Toshihiro Hattori;Shinichi Yoshioka	2005	2005 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2005.1465844	embedded system;electronic engineering;real-time computing;computer science;engineering;electrical engineering;operating system;digital signal processing;frequency;pipeline transport;leakage;quantum mechanics;low-power electronics	Arch	14.596825717713756	58.88254122675031	48304
f47d3c68cf85f90ed3e3371bb6ba24a122262336	a reram-based nonvolatile flip-flop with self-write-termination scheme for frequent-off fast-wake-up nonvolatile processors		"""Nonvolatile flip-flops (nvFFs) enable frequent-off processors to achieve fast power-off and wake-up time while maintaining critical local computing states through parallel data movement between volatile FFs and local nonvolatile memory (NVM) devices. However, current nvFFs face challenges in large store energy (<inline-formula> <tex-math notation=""""LaTeX"""">$\text{E}_{\mathrm {S}}$ </tex-math></inline-formula>) and long voltage stress time on the device (<inline-formula> <tex-math notation=""""LaTeX"""">$\text{T}_{\mathrm {STRESS}}$ </tex-math></inline-formula>), due to wide distribution in the write time of NVM device as well as unnecessary writes. Moreover, heavy parasitic load on the power rail cause long wake-up time for restoring data from NVM to FFs. This paper proposes the resistive RAM (ReRAM)-based nvFF with self-write termination (SWT) and reduced loading on power rail to: 1) reduce 93+% waste of <inline-formula> <tex-math notation=""""LaTeX"""">$\text{E}_{\mathrm {S}}$ </tex-math></inline-formula> from fast switching or matched cells; 2) suppress endurance and reliability degradation resulted from overprogramming and long <inline-formula> <tex-math notation=""""LaTeX"""">$\text{T}_{\mathrm {STRESS}}$ </tex-math></inline-formula>; and 3) achieve reliable and 26+ times faster restore operation compared with previous nvFFs. We have fabricated a nonvolatile processor and a test chip with SWT-nvFFs using logic-process ReRAM in a 65-nm CMOS process. Measured results show sub-2-ns termination response time and sub-20-ns chip-level restore time."""	cmos;central processing unit;elegant degradation;flops;flip-flop (electronics);non-volatile memory;power supply unit (computer);resistive random-access memory;response time (technology);shutdown (computing);standard widget toolkit;thyristor;uptime	Albert Lee;Chieh-Pu Lo;Chien-Chen Lin;Wei-Hao Chen;Kuo-Hsiang Hsu;Zhibo Wang;Fang Su;Zhe Yuan;Qi Wei;Ya-Chin King;Chrong-Jung Lin;Hochul Lee;Pedram Khalili Amiri;Kang-Lung Wang;Yu Wang;Huazhong Yang;Yongpan Liu;Meng-Fan Chang	2017	IEEE Journal of Solid-State Circuits	10.1109/JSSC.2017.2700788	flip-flop;electronic engineering;chip;voltage;computer science;response time;resistive random-access memory;non-volatile memory;cmos	Arch	17.31787538941035	59.97177072986911	48323
1111026c682b58cc080ecf2e41bd4fdb86d3d980	a comment on 'graph-based algorithm for boolean function manipulation'	reduced obdd;robdds;graph based algorithm boolean function manipulation reduced ordered binary decision diagrams robdds reduced obdd;graph based algorithm;elektroteknik och elektronik;composition;logic design;boolean functions;electrical engineering electronic engineering information engineering;boolean function;boolean functions binary decision diagrams;sufficient conditions;reduced ordered binary decision diagram;reduced ordered binary decision diagrams;binary decision diagrams;data structures;error correction;boolean functions data structures error correction logic design sufficient conditions;boolean function manipulation;binary decision diagram	ÐIn this paper, a slight error in the paper of Bryant [1] is corrected. It was stated in [1] that, under a certain ordering restriction, composition of two Reduced Ordered Binary Decision Diagrams (ROBDDs) results in a reduced OBDD. We show a counterexample and explore under which conditions this statement is incorrect. Index TermsÐBoolean function, Binary Decision Diagram, composition.	algorithm;binary decision diagram;hash table	Elena Dubrova;Luca Macchiarulo	2000	IEEE Trans. Computers	10.1109/12.895944	combinatorics;discrete mathematics;data structure;computer science;mathematics;boolean function;algorithm	EDA	18.353690125309654	46.450631008861656	48443
41f9bf396e0b6c7a288cccc7410065560cb42ae1	a technique for minimizing power during fpga placement	fpga placement;capacitance field programmable gate arrays clocks ribs computational modeling layout annealing;annealing;clocks;layout;capacitance model;objective function;multi dimensional;actel igloo fpga architecture fpga placement annealing technique dynamic power reduction power aware objective function capacitance model multidimensional nonlinear regression global nets;computational modeling;global nets;fpga architecture;low power electronics;actel igloo fpga architecture;power aware objective function;ribs;multidimensional nonlinear regression;low power electronics annealing field programmable gate arrays;annealing technique;capacitance;power reduction;field programmable gate arrays;dynamic power reduction;power measurement;industrial design;nonlinear regression	This paper considers the implementation of an annealing technique for dynamic power reduction in FPGAs. The proposed method comprises a power-aware objective function for placement and is implemented in a commercial tool. In particular, a capacitance model based on multi-dimensional nonlinear regression is described, as well as a new capacitance model for global nets. The importance and advantages of these models are highlighted in terms of the overall attainable reduction in power in a real, commercially-available architecture and tool flow. The results are quantified across a range of industrial benchmarks targeting the Actelreg IGLOOtrade FPGA architecture. Power measurements show that, across a suite of 120 industrial designs, the technique described in this paper reduces dynamic power by 13% on average, with only a 1% degradation in timing performance.	elegant degradation;field-programmable gate array;loss function;nonlinear system;optimization problem;pc power management;simulated annealing	Kristofer Vorwerk;Madhu Raman;Julien Dunoyer;Yaun-Chung Hsu;Arun Kundu;Andrew A. Kennings	2008	2008 International Conference on Field Programmable Logic and Applications	10.1109/FPL.2008.4629937	layout;embedded system;real-time computing;industrial design;annealing;computer science;capacitance;computational model;rib cage;field-programmable gate array;low-power electronics;nonlinear regression	EDA	15.458927955893287	54.842777590396864	48501
3a57991aa174cef32f77f3083851c34f2b603d45	power-rail esd clamp circuit with hybrid-detection enhanced triggering in a 65-nm, 1.2-v cmos process		A power-rail electrostatic discharge clamp circuit with transient and static hybrid-detection enhanced triggering is proposed in this work. By skillfully co-optimizing the driving paths of both transient and static detection networks, the proposed circuit achieves a clamp device transient response time over 2 times longer than its RC time constant, which endows the proposed circuit with both promoted area-efficiency and safe clamping behaviors. Besides, the proposed circuit effectively combines the advantages of transient and static ones with tiny leakage current penalties. All investigated circuits are fabricated in a 65-nm CMOS process using 1.2-V thin-oxide devices. Simulation and test results are discussed in detail in this work to validate the proposed circuit.	cmos;clamper (electronics);clamping (graphics);discharger;rc time constant;response time (technology);simulation;spectral leakage	Guangyi Lu;Yuan Wang;Yize Wang;Xing Zhang	2017	2017 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2017.8050381	computer science;electronic engineering;rc time constant;clamp;electrostatic discharge;leakage (electronics);electronic circuit;cmos;transient response;clamper	EDA	18.766892219668275	57.32299677704098	48570
8477f6ac834ec50e66704183f667434e66af235d	multiple-valued logic circuits design using negative differential resistance devices	cmos technology;monostable to multistable logic;design engineering;logic design;negative differential resistance;circuit design;multivalued logic circuits;logic circuits logic devices cmos logic circuits logic design design engineering circuit topology circuit simulation cmos technology control engineering computing robot control;logic circuits;design space;circuit topology;monostable to multistable transition logic operating principle;multiple valued logic circuits design;circuit simulation;atomic multiple valued circuit;atomic multiple valued circuit multiple valued logic circuits design negative differential resistance monostable to multistable transition logic operating principle;robot control;cmos logic circuits;resonant tunneling devices;multivalued logic circuits logic design;control engineering computing;multiple valued;logic devices;multiple valued logic	In this paper, we present a novel multiple-valued logic circuit design style based on negative differential resistance (NDR) devices and the mono stable-to-multistable transition logic (MML) operating principle. We introduce an innovative topology that considerably enhances the design space of MML circuits thus providing more functionality achievable within an atomic multiple-valued circuit. The functional correctness of the design is proved by simulations.	bounce message;circuit design;correctness (computer science);logic gate;logic level;low-power broadcasting;simulation;three-valued logic;transistor	Krzysztof S. Berezowski;Sarma B. K. Vrudhula	2007	37th International Symposium on Multiple-Valued Logic (ISMVL'07)	10.1109/ISMVL.2007.36	topology;embedded system;electronic engineering;logic synthesis;logic optimization;logic gate;logic family;computer science;artificial intelligence;circuit design;control theory;mathematics;robot control;cmos	EDA	15.874389244381954	58.46633681771502	48604
f1799580562535723115b5b8d781b4cb0a0a0810	the effects of defects on high-speed boards	high speed boards defects;signal design clocks moore s law optical propagation capacitors connectors power transmission lines printed circuits circuit testing integrated circuit packaging;printed circuit boards high speed boards defects;printed circuit boards;printed circuit testing;printed circuit board;high speed	Printed circuit boards are steadily becoming faster. They have higher clock speeds, and edge rates on data signals have dropped down into the 100's of picoseconds. This presents some new challenges to the board test world because certain defects we did not do a good job covering in the past can no longer be ignored	defective by design;experiment;functional programming;my life as a teenage robot;pci express;printed circuit board;signal integrity;software bug;software propagation;system testing;the 100	Kenneth P. Parker	2005	IEEE International Conference on Test, 2005.	10.1109/TEST.2005.1583975	embedded system;electronic engineering;diagnostic board;tape-out;computer science;engineering;electrical engineering;circuit design;flying probe;printed circuit board;engineering drawing	Robotics	22.945990440534608	53.63540629508286	48618
558972f905b8f5416c3f00591325cce2b7d55660	simultaneous placement and module optimization of analog ic's	topology;minimization;design automation;integrated circuit layout;analog integrated circuits simulated annealing integrated circuit layout minimization analog circuits circuit synthesis analog computers topology design automation wiring;simulated annealing;analog circuits;analog integrated circuits;analog computers;wiring;high performance;circuit synthesis	New placement techniques are presented which substantially improve the process of automatic layout generation of analog IC's. Extremely tight specifications can be enforced on high-performance analog circuits by using simultaneous placement and module optimization. An algorithmic approach to module generation provides alternative sets of modules optimized with respect to area and performance but equivalent in terms of parasitics and topology. The final module selection is performed during the placement phase, based on Simulated Annealing. The flexibility of the annealing algorithm has been significantly improved, thus making it possible to more efficiently exploit the tradeoffs between area, parasitics and matching.	algorithm;analogue electronics;automatic layout;mathematical optimization;simulated annealing	Edoardo Charbon;Enrico Malavasi;Davide Pandini;Alberto L. Sangiovanni-Vincentelli	1994	31st Design Automation Conference	10.1145/196244.196261	mixed-signal integrated circuit;embedded system;analog computer;electronic engineering;simulated annealing;electronic design automation;analogue electronics;ic layout editor;computer science;electrical engineering;integrated circuit layout;computer engineering;analog multiplier	EDA	13.81145861124352	51.705620097771764	48656
d3e9d846808a59ebec5c0b6300c3abdfd7047aa5	on mixed ptl/static logic for low-power and high-speed circuits	low power;high speed	We present more evidence in a 0.25 &#956;m CMOS technology that the pass-transistor logic (PTL) structure that mixes conventional PTL structure with static logic gates can achieve better performance and lower power consumption compared to conventional PTL structure. The goal is to use the static gates to perform both logic functions as well as buffering. Our experimental results demonstrate that the proposed mixed PTL structure beats pure static structure and conventional PTL in 9 out of 15 test cases for either delay or power consumption or both in a 0.25 &#956;m CMOS process. The average delay, power consumption, and power-delay product of the proposed structure for 15 test cases are 10&#37; to 20&#37; better of than the pure static implementations and up to 50&#37; better than the conventional PTL implementations.	dynamic logic (digital electronics);low-power broadcasting;pass transistor logic	Geun Rae Cho;Tom Chen	2001	VLSI Design	10.1155/2001/59548	electronic engineering;real-time computing;computer science;mathematics;algorithm	EDA	17.47947132477652	56.86054302764689	48722
42b8d98837e9db498a0656ba286e7d8cd14598a4	0.5-v 50-mv-swing 1.2-ghz 28-nm-fd-soi 32-bit dynamic bus architecture with dummy bus	current 1 1 mua fd soi dynamic bus architecture dummy bus low power high speed robust bus dynamic driver dynamic receiver small leakage current stacked mosfets power lines active mode bus voltage detecting point bus swing reduction monte carlo simulation power supply bounce noise frequency 1 2 ghz word length 32 bit voltage 0 5 v voltage 50 mv size 28 nm capacitance 1 pf;silicon on insulator leakage currents low power electronics monte carlo methods mosfet semiconductor device noise;32 bit dynamic bus architecture 0 5 v 50 mv swing dynamic bus stacked mosfets dummy bus;dummy bus;32 bit dynamic bus architecture;robustness capacitance;0 5 v 50 mv swing dynamic bus;stacked mosfets	To achieve a 0.5-V low-power high-speed robust bus, a dynamic bus architecture, combined with a dynamic driver and a dynamic receiver for small leakage current with stacked MOSFETs, is proposed. In particular, the dynamic driver enables high speed even at 0.5 V with increased gate-over-drive by changing the power lines from VDD/2 in the standby mode to VDD in the active mode. It further speeds up with the help of another proposal of a dummy bus for tracking the bus-voltage detecting point for reducing the bus swing. Robustness of each proposal is investigated by Monte Carlo simulation. Then, a 0.5-V 28-nm-FD-SOI 32-bit bus architecture using the proposals is evaluated by simulation. The power-supply bounce noise and the reduction are also investigated here through the layout. As a result, it turns out that the architecture has a potential of operating a 1-pF bus at a 50-mV swing, 1.2 GHz, and a standby current of 1.1 μA, with x3-5 faster and more than two-order lower standby current than the conventional static architecture.	32-bit;die shrink;dummy variable (statistics);low-power broadcasting;monte carlo method;power supply;sensor;simulation;sleep mode;spectral leakage;swing (java);value-driven design	Khaja Ahmad Shaik;Kiyoo Itoh;Amara Amara	2016	2016 17th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2016.7479231	embedded system;electronic engineering;real-time computing;slack bus;three-state logic;iebus;engineering	Arch	18.16685686522677	58.44098764248386	48811
fd6d9c140c183ff02c9a038a6a8baae66d745f90	concurrent error detection using monitoring machines	circuit faults;concurrent error detection;sequential circuits;monitoring machines;computerized monitoring;condition monitoring;finite state machine synthesis;fault detection;logic testing;circuit testing;fault coverage analysis;condition monitoring circuit faults electrical fault detection fault detection circuit testing logic testing sequential circuits delay computerized monitoring hardware;electrical fault detection;hardware	GROWTH IN CHIP complexity and increasing demand for computers for critical applications have generated tremendous interest in design techniques to improve digitalcircuit testability and reliability. Researchers have proposed and adopted several approaches to the design of the data path and control logic of digital systems. The approaches differ in the circuit-testing method (on line or off line), time they are incorporated (preor postsynthesis), and additional hardware required. These differences allow trade-offs among fault detection capability, error detection latency, and hardware overhead. In circuits implementingsystemlevel functions, the correctness of the overall operation critically depends on the correctness of the control logic. Because controller circuits continuously generate signals for other data path and control	computer;correctness (computer science);digital electronics;error detection and correction;fault detection and isolation;overhead (computing)	Rubin A. Parekhji;G. Venkatesh;Sunil D. Sherlekar	1995	IEEE Design & Test of Computers	10.1109/MDT.1995.466370	embedded system;electronic engineering;real-time computing;computer science;engineering;stuck-at fault;sequential logic;fault detection and isolation	EDA	20.844479586932373	51.535173577488806	49025
933bb06bc14c025e5cd43d620eb4d52b371508df	dynamic data stability in sram cells and its implications on data stability tests	cmos technology;cmos memory integrated circuits;data stability tests;circuit stability;dynamic stress;sram chips circuit stability cmos memory circuits;dynamic data;sram cells;defective cells;cmos memory circuits;static data stability;130 nm;fault detection;test methods;130 nm dynamic data stability sram cells data stability tests static data stability dynamic stress defective cells fault detection cmos technology;dynamic data stability;random access memory testing stability criteria circuit faults cmos technology circuit noise fault detection feedback voltage noise figure;sram chips	The paper discusses the concept of dynamic data stability in the SRAM cells. It is shown that the criteria for the absolute static data stability in an SRAM cell is a sub-set of its dynamic data stability. Hence, test methods that are based on dynamic stress of the cell have limited success in discovering the defective cells. Hammer test, for example, fails to discover the faults in an SRAM cell when it is data stable in the dynamic sense but not statically data stable. It will be shown that a long cell access time can detect such faults as it reduces the effect of the dynamic data stability. This method can be combined with stressed cell methods to achieve higher accuracy. Simulation results in a 130nm CMOS technology confirm the method with a good success	access time;cmos;cell (microprocessor);dynamic data;row hammer;simulation;static random-access memory	Mohammad Sharifkhani;Shah M. Jahinuzzaman;Manoj Sachdev	2006	2006 IEEE International Workshop on Memory Technology, Design, and Testing (MTDT'06)	10.1109/MTDT.2006.12	embedded system;electronic engineering;real-time computing;dynamic data;computer science;engineering;test method;cmos;fault detection and isolation;statistics	Visualization	22.249997006622195	55.64235073798488	49085
2401041da6fda15d56e33e2fc34372ab44a5122f	go based hierarchical framework for inference of gene regulatory networks	gene regulatory network	A clock delay circuit of the type used in semiconductor dynamic read/write memory device employs pull-up and pull-down output transistors connected in series between a voltage supply and ground. Excess current in this series path is minimized by a circuit holding the gate of the output pull-up transistor to a low voltage until the gate of the pull-down transistor goes low. Then, the gate of the pull-up transistor is booted above the supply voltage. Also, tendency for the output voltage to rise above ground during the delay period is avoided.		Kumar Abhishek;Harish Karnick	2008			voltage;semiconductor;gene regulatory network;transistor;inference;low voltage;electrical engineering;computer science	Logic	18.053467615767968	58.14446667102835	49142
3abec0fdce4b138ffb0331c7925c4223ea6783ac	post-silicon timing diagnosis made simple using formal technology	formal verification;program debugging;synchronisation;intel;lada machines;formal technology;laser-assisted device alternation machines;microprocessor core operating frequencies;post silicon synchronization debugging;post-silicon timing diagnosis	With the increasing demand for microprocessor core operating frequencies, debugging post silicon synchronization (or speed) failures is a critical time consuming post silicon debug activity. Inability to complete the isolation of all possible speed failures on time, forces companies to go to market with products that run at a lower frequency than their upper frequency limits. This might cause revenue losses or lead to loss of market segment shares. Laser-Assisted Device Alternation (LADA) machines are the main vehicle for debugging post silicon speed failures at Intel. Operating such expensive machines consumes a substantial portion of the overall post silicon debug effort. Moreover, with the increasing complexity of manufacturing processes, these machines need to be renewed from one process generation to the next, which increases the product cost. This paper describes a novel method, based on formal technology, which brings a productivity breakthrough in isolating post-silicon speed failures. We demonstrate that in many cases optical probing using LADA can be fully replaced by our approach.	algorithm;debugging;failure;glitch;goto;microprocessor;multi-core processor;multiplexer;sensor;the third manifesto	Daher Kaiss;Jonathan Kalechstain	2014	2014 Formal Methods in Computer-Aided Design (FMCAD)	10.1109/FMCAD.2014.6987605	embedded system;real-time computing;algorithm	AI	10.658659232345851	55.926706089124615	49194
af676bdbad3f684b977d5812d11cfafc279d1ca8	a 7uw deep-sleep, ultra low-power wlan baseband lsi for mobile applications	mobile application low power power gating on chip regulator baseband lsi wireless lan ieee802 11n;ultra low power;ieee 802 11n single input single output wireless lan;power 7 muw deep sleep ultra low power wlan baseband lsi ieee 802 11n single input single output wireless lan mobile applications on chip power gating high throughput technology stand by power consumption built in wake up timer on chip cpu;high throughput technology;built in wake up timer;baseband lsi;wireless lan power demand large scale integration logic gates system on a chip phasor measurement units throughput;on chip cpu;phasor measurement unit;power gating;on chip regulator;system on a chip;ieee802 11n;chip;mobile applications;low power;large scale integration;logic gates;mobile radio;power 7 muw;low power electronics;deep sleep ultra low power wlan baseband lsi;wireless lan;radiofrequency integrated circuits;power demand;logic gate;on chip power gating;mobile application;phasor measurement units;wireless lan large scale integration low power electronics mobile radio radiofrequency integrated circuits;stand by power consumption;throughput	Low power IEEE 802.11n single input single output (SISO) wireless LAN (WLAN) baseband LSI has been developed for mobile applications. The multiple low power technologies such as on-chip power gating and high throughput technologies for expanding idle time are applied to the LSI. By minimizing always-on circuits and implementing them using thick gate-oxide transistors, 7uW stand-by power consumption is achieved with negligible shutdown/restart transition time. The built-in wake-up timer and on-chip CPU enables continuous transmit/receive operation without an external intervention.	555 timer ic;baseband;built-in self-test;central processing unit;gate oxide;high availability;integrated circuit;low-power broadcasting;mobile app;power gating;rise time;shutdown (computing);soft-in soft-out decoder;throughput;transistor	Daisuke Taki;Tatsuo Shiozawa;Kuniaki Ito;Youichiro Shiba;Kouji Horisaki;Hirotsugu Kajihara;Toshiyuki Yamagishi;Masahiro Sekiya;Akira Yamaga;Tetsuya Fujita;Hiroyuki Hara;Masanori Kuwahara;Toshio Fujisawa;Yasuo Unekawa	2011	2011 IEEE Cool Chips XIV	10.1109/COOLCHIPS.2011.5890931	embedded system;electronic engineering;real-time computing;engineering	EDA	15.431287205145493	58.8158903802126	49209
65766c79733bf206f56681b0aa9834f5f71f2ba1	a novel hybrid fifo asynchronous clock domain crossing interfacing method	pausable clocking;clock domain crossing;phase shift;circuit simulation;cdc;gals;fifo	Multi-clock domain circuits with Clock Domain Crossing (CDC) interfaces are emerging as an alternative to circuits with a global clock. CDC interfaces are susceptible to metastability, hence their design is very challenging. This paper presents a hybrid FIFO-asynchronous method for constructing robust CDC interfaces. The proposed design can handle arbitrary clock frequency ratios between the sender and receiver with random phase shifts. The proposed design avoids latency due to synchronizers with the asynchronous protocol modifications. Circuit simulation results confirm the operation and robustness of the design at maximum workloads, and arbitrary frequency ratios, over a temperature range of -50 to 50 degrees Celsius. The interface offers a maximum throughput of 606 million transfers per second without pausing the clock.	cmos;clock rate;clock signal;fifo (computing and electronics);maximum throughput scheduling;metastability in electronics;simulation	Zaid Al-bayati;Otmane Aït Mohamed;Syed Rafay Hasan;Yvon Savaria	2012		10.1145/2206781.2206847	fifo;asynchronous system;embedded system;electronic engineering;real-time computing;asynchronous circuit;clock angle problem;vector clock;clock domain crossing;clock skew;computer science;operating system;phase;clock drift;synchronous circuit;clock gating;digital clock manager;clock signal;cpu multiplier	EDA	15.318418486272202	57.161981464668436	49540
42e378d940e4e305617ace930aa837e99d5d7e2c	design-for-testability using test design yield and decision theory	performance measure;design for testability;design for testability ic testing logic cad asic test design yield decision theory prediction estimation test cost vlsi;design automation;vlsi circuit cad decision support systems economics integrated circuit testing integrated logic circuits logic cad;automatic testing;test design yield;process design;test cost;estimation;application specific integrated circuits;decision theory;decision support systems;integrated circuit testing;vlsi;system testing;circuit testing;circuit cad;asic;integrated logic circuits;economics;logic cad;prediction;decision theory design for testability costs system testing automatic testing circuit testing application specific integrated circuits design automation process design decision making;ic testing	In this paper, a framework for prediction and estimation of the test yield and test cost of VLSI systems during the design for testability stage is given. As a new important extension, we present here a technique to evaluate the set of possible solutions and to select the most-effective one, This technique is based on the evaluation of test-re1 ated performance measures and on decision theory. As a result, a new level of design and test integration is obtained.	decision theory;design for testing;test design;very-large-scale integration	Bozena Kaminska;Yvon Savaria	1989		10.1109/TEST.1989.82379	reliability engineering;electronic engineering;decision support system;electronic design automation;computer science;application-specific integrated circuit;statistics;computer engineering	EDA	23.788470003684292	55.83178351871726	49597
5969866634f6f0d81800f72ed3b9c49a945b3db7	functional fault model definition for bus testing	system on a chip design functional fault model definition bus testing soc marching test patterns amba ahb;integrated circuit design;fault tolerant computing;system on chip;integrated circuit interconnections;integrated circuit testing;system on chip fault tolerant computing integrated circuit design integrated circuit interconnections integrated circuit testing	In this paper we present a new fault model for testing bus components using their functionality. With the aim of a new fault model definition all components in a bus except cores of the SoC will be tested as fast as possible. According to the proposed method in this paper, at first, wires and small components will be tested by marching test patterns as the test data and, after that based on a proposed method; the new format faults for the bus will be used. Using AMBA-AHB as the experimental result, the new fault model shows efficiency in comparison with corresponding stuck-at.	advanced microcontroller bus architecture;fault model;test card;test case;test data	Elmira Karimi;M. H. Haghbayan;Adele Maleki;Mahmoud Tabandeh	2013	East-West Design & Test Symposium (EWDTS 2013)	10.1109/EWDTS.2013.6673089	physical design;embedded system;computer architecture;electronic engineering;fault coverage;engineering;stuck-at fault;automatic test pattern generation;system bus	EDA	10.965521485336447	53.467792831048165	49712
1068f650e8934acacf23530733785962266bc934	hierarchical functional timing analysis	logic design combinational circuits timing delays;generalized delay model;sensitization criterion;timing permission delay effects performance analysis circuit analysis computing combinational circuits circuit analysis signal analysis propagation delay error correction;timing characterization;logic design;placement;signal analysis;flip flops;delay effects;topological analysis;incremental timing analysis hierarchical functional timing analysis combinational circuits sensitization criterion xbdo delay model generalized delay model timing characterization topological analysis generalized gates tight sensitization criteria;synthesis;incremental timing analysis;generalized gates;circuit analysis;low power;permission;propagation delay;error correction;performance analysis;timing analysis;codec;xbdo delay model;tight sensitization criteria;combinational circuit;hierarchical functional timing analysis;circuit analysis computing;voltage scaling;level converters;mpeg4;delays;combinational circuits;design automatian;timing	We propose a hierarchical timing analysis technique for combinational circuits under the tightest known sensitization criterion, the XBDO delay model. Given a hierarchical combinational circuit, a generalized delay model of each left module is characterized first. Since this timing characterization step takes into account false paths in each module, the delay model is more accurate than the one obtained by topological analysis. Then topological delay analysis is performed on the circuit composed of generalized gates replacing the leaf modules, where the “gate” delay model is the derived one. As far as the authors know, this is the first result that shows that hierarchical analysis is possible under state-of-the-art tight sensitization criteria. We demonstrate by experimental results that loss of accuracy in using the hierarchical approach is very minimal in practice. The theory developed in this paper also provides a foundation for incremental timing analysis under accurate sensitization criteria.	combinational logic;logic gate;propagation delay;static timing analysis	Yuji Kukimoto;Robert K. Brayton	1998		10.1145/277044.277197	embedded system;electronic engineering;real-time computing;delay calculation;computer science;elmore delay;signal processing;combinational logic;algorithm	EDA	20.461258212139935	48.578365483210185	49804
2dae13f6550f6043695d2a04e40a049c01026e95	fastplace 3.0: a fast multilevel quadratic placement algorithm with placement congestion control	circuit layout cad;mixed analogue-digital integrated circuits;pattern clustering;quadratic programming;fastplace 3.0;iterative local refinement;large-scale mixed-size designs;legalization technique;multilevel global placement framework;multilevel quadratic placement algorithm;placement blockages;placement congestion constraints;placement congestion control;two-level clustering scheme	In this paper, we present FastPlace 3.0 - an efficient and scalable multilevel quadratic placement algorithm for large-scale mixed-size designs. The main contributions of our work are: (1) A multilevel global placement framework, by incorporating a two-level clustering scheme within the flat analytical placer FastPlace (Viswanathan and Chu, 2005) and Viswanathan et al., 2006), (2) An efficient and improved iterative local refinement technique that can handle placement blockages and placement congestion constraints. (3) A congestion aware standard-cell legalization technique in the presence of blockages. On the ISPD-2005 placement benchmarks (Nam et al., 2005), our algorithm is 5.12times, 11.52times and 16.92times faster than mPL6, Capo10.2 and APlace2.0 respectively. In terms of wirelength, we are on average, 2% higher as compared to mPL6 and 9% and 3% better as compared to Capo10.2 and APlace2.0 respectively. We also achieve competitive results compared to a number of academic placers on the placement congestion constrained ISPD-2006 placement benchmarks (Nam, 2006).	algorithm;benchmark (computing);cluster analysis;iterative method;nam;network congestion;refinement (computing);scalability;standard cell	Natarajan Viswanathan;Min Pan;Chris C. N. Chu	2007	2007 Asia and South Pacific Design Automation Conference		mathematical optimization;electronic engineering;computer science;theoretical computer science;network congestion;quadratic programming	EDA	15.190048697533678	52.96183582145514	49899
bb384131eab6907d14280bf034770e9acf273f4c	placement-driven partitioning for congestion mitigation in monolithic 3d ic designs	metals;steiner trees;routing;three dimensional displays routing integrated circuits metals logic gates steiner trees solid modeling;power delay product monolithic 3d ic designs placement driven partitioning congestion mitigation modified 2d placement high quality m3d placement solutions monolithic intertier routing supply routing demand min overflow partitioner routed wirelength;logic gates;three dimensional displays;solid modeling;three dimensional integrated circuits network routing;routing congestion monolithic 3d placement partitioning;integrated circuits	Monolithic 3D (M3D) is an emerging technology that enables integration density which is orders of magnitude higher than that offered by through-silicon-vias. In this paper, we demonstrate that a modified 2D placement technique coupled with a post-placement partitioning step is sufficient to produce high-quality M3D placement solutions. We also present a commercial router-based monolithic intertier via insertion methodology that improves the routability of M3D ICs. We demonstrate that, unlike in 2D ICs, the routing supply and demand in M3D ICs are not completely independent of each other. We develop a routing demand model for M3D ICs, and use it to develop an    ${O}({N})$    min-overflow partitioner that enhances routability by off-loading demand from one tier to another. This technique reduces the routed wirelength and the power delay product by up to 7.44% and 4.31%, respectively. This allows a two-tier M3D IC to achieve, on average, 19.9% and 11.8% improvement in routed wirelength and power delay product over 2D, even with reduced metal layer usage.	network congestion;three-dimensional integrated circuit	Shreepad Panth;Kambiz Samadi;Yang Du;Sung Kyu Lim	2015	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/TCAD.2014.2387827	routing;electronic engineering;static routing;real-time computing;logic gate;steiner tree problem;computer science;engineering;solid modeling;routing;computer network;placement	EDA	15.192901148030861	53.13930071697469	49971
244e772001d6f3068c1046a65d3327d7a4cf1bf1	spram (spin-transfer torque ram) design and its impact on digital systems	torque;low power non volatile memory;random access memory;logic design;power efficiency;resistance;spram;chip;voltage 1 8 v;digital system;tunnelling;low power;storage capacity 2 mbit spram spin transfer torque ram digital system low power non volatile memory logic process tunneling barrier cell voltage 1 8 v size 0 2 mum;spin transfer torque ram;tunneling barrier cell;storage capacity 2 mbit;digital systems;low power electronics;logic process;writing;driver circuits;random access storage;tunneling magnetoresistance;direct current;magnetization;tunnelling logic design low power electronics random access storage;size 0 2 mum;logical process;torque digital systems writing read write memory random access memory laboratories magnetic memory magnetization circuits magnetic devices	To demonstrate circuit technologies for potential low-power non-volatile RAM, or universal memory, we fabricated a 1.8 V 2-Mb SPRAM (SPin-transfer torque RAM) chip using a 0.2-mum logic process with a MgO tunneling barrier cell. This chip features an array scheme with bit-by-bit bidirectional current writing to enable proper spin-transfer torque writing and parallel-direction current reading for preventing read disturbance. In addition, this memory can improve the power efficiency of digital equipment.	digital electronics;ikeda map;low-power broadcasting;non-volatile memory;performance per watt;quantum tunnelling;random-access memory;tunneling protocol;universal memory	Takayuki Kawahara;Riichiro Takemura;Hiromasa Takahashi;Hideo Ohno	2007	2007 14th IEEE International Conference on Electronics, Circuits and Systems	10.1109/ICECS.2007.4511164	electronic engineering;computer hardware;engineering;electrical engineering;magnetoresistive random-access memory	EDA	16.657407260089354	59.461217774909564	49994
e21b5f5bdbcdef7700e351811a7f31b99c57ab98	zero capacitor embedded memory technology for system on chip	45 nm zero capacitor embedded memory system on chip floating body effect silicon on insulator single transistor dram memory density finfet;silicon on insulator;embedded systems;integrated circuit design;memory density;capacitors system on a chip random access memory silicon on insulator technology capacitance physics scalability intersymbol interference time measurement finfets;system on chip;45 nm;mosfet;floating body effect;single transistor dram;new physics;dram chips;finfet;zero capacitor embedded memory;system on chip dram chips embedded systems integrated circuit design mosfet silicon on insulator	By harnessing the floating body (FB) effect of silicon on insulator devices, the authors introduced a true capacitor-less, single transistor DRAM - named Z-RAMtrade (zero capacitance DRAM) - which is capable of doubling memory density when compared to existing embedded DRAM technology (and achieving five times the density of current embedded SRAM), yet requires no exotic materials, no extra mask steps and no new physics. As no capacitor is required, the Z-RAM cell can readily be scaled as far as the transistor. The technology's bit-cell scalability was demonstrated at the 45nm node. It is easily envisaged that Z-RAM technology will scale well to at least the 22nm process node and ISi has already measured suitable characteristics in the FinFET transistors that may well be used at that time	areal density (computer storage);bit cell;cell (microprocessor);dynamic random-access memory;edram;embedded system;period-doubling bifurcation;scalability;silicon on insulator;static random-access memory;system on a chip;topological insulator;transistor;z-ram	Serguei Okhonin;Pierre Fazan;Mark-Eric Jones	2005	2005 IEEE International Workshop on Memory Technology, Design, and Testing (MTDT'05)	10.1109/MTDT.2005.4655409	physics beyond the standard model;system on a chip;floating body effect;embedded system;electronic engineering;computer hardware;computer science;silicon on insulator;integrated circuit design	EDA	16.66896274778128	59.70828510821537	50234
ac9b62f188096bac0ad2a6539a5268c9045cc9ad	concurrent error detection of combinational circuits by the method of boolean complement on the base of «2-out-of-4» code	complexity theory;rail transportation;logic functions;ieee members;buildings;combinational circuits;automation	The article provides a structure of combinational circuit concurrent error detection (CED) systems, that implements the principle of Boolean complement of logic functions, on the base of constant-weight code «2-out-of-4» (2/4-code). It also shows the benefits of using the 2/4-code in comparison with code «1-out-of-4» (1/4-code) for organization of CED systems of combinational circuits.	boolean algebra;combinational logic;constant-weight code;error detection and correction;logic gate	Valery V. Sapozhnikov;Vladimir V. Sapozhnikov;Dmitry V. Efanov	2016	2016 IEEE East-West Design & Test Symposium (EWDTS)	10.1109/EWDTS.2016.7807677	boolean circuit;discrete mathematics;theoretical computer science;mathematics;sequential logic;combinational logic;algorithm	EDA	22.017073782181214	48.47762567187296	50283
1698d95fa5823af1bb271dd9ee92bea2645ddd05	an improved current mirror cell	mirrors;cmos technology;mosfets;minerals;cmos process;dh hemts;analog circuits;circuit simulation;petroleum;voltage;mirrors circuit simulation voltage mosfets petroleum minerals dh hemts analog circuits cmos process cmos technology	A new configuration for the design of a current mirror is presented. The proposed configuration eliminates the DC matching error caused by the difference between drain-to-source voltages of both input and output transistors. The circuit can be used to enhance the accuracy of analog circuits for current levels from 0 to few hundreds microamperes The proposed configuration was verified by HSPICE simulator level 49 in 0.8μm CMOS process technology. Simulation results show that DC matching error is substantially reduced compared to the cascade configuration.	analogue electronics;cmos;current mirror;input/output;spice 2;simulation;transistor	Munir A. Al-Absi	2006	IEEE International Conference on Computer Systems and Applications, 2006.	10.1109/AICCSA.2006.205133	embedded system;voltage;analogue electronics;computer science;cmos;petroleum	EDA	17.970102201660314	57.79748012188632	50391
6ba3505978740647cef34a76d621762eda447b4b	design for testability: using scanpath techniques for path-delay test and measurement	design for testability;circuit faults;clocks;flip flops;digital integrated circuits;integrated circuit testing;circuit testing;integrated circuit measurements;tests and measurements;design for testability circuit testing integrated circuit testing flip flops integrated circuit measurements circuit faults frequency clocks digital integrated circuits electrical fault detection;frequency;flip flop;electrical fault detection	2. Summary This paper presents techniques for using scanpath techniques in testing and measuring path-delays in a digital integrated circuit. Whereas scanpath techniques have been used by others[2],[3] for detection of stuck-at type failures their use in detecting timing faults and measuring propagation delays through combinational circuit element:; inslide complex digital chips appears to be new. In particular, the double-strobe flip-flop which enables generation and application of path-delay test patterns using regularly available scanpath methods appears to be novel and provides a siignific(ant advancement of the scanpath methodology. Deslign of the double-strobe flip-flop using CMOS gate-array technology is included in the paper. This flip-flop, which was designed at Hewlett Packard is also available to gate-array users through Motorola.	cmos;combinational logic;design for testing;digital electronics;electrical element;flops;flip-flop (electronics);gate array;integrated circuit;logic gate;propagation delay;sensor;software propagation;test card	Bulent I. Dervisoglu;Gayvin E. Stong	1991		10.1109/TEST.1991.519696	mixed-signal integrated circuit;physical design;embedded system;electronic engineering;real-time computing;engineering;automatic test pattern generation;frequency;circuit design;design for testing;circuit extraction;discrete circuit;integrated circuit design	EDA	22.76631928881347	52.79455574072884	50780
181f2e19b996859a549a7eeb72fa3e49896380fa	space and time compaction schemes for embedded cores	compaction system testing circuit testing bandwidth circuit faults system on a chip transportation sequential analysis computer science data engineering;automatic testing combinational circuits sequential circuits logic testing integrated circuit testing vlsi application specific integrated circuits;test access mechanism;automatic testing;sequential circuits;test bandwidth minimisation space compaction scheme time compaction scheme embedded core testing system on a chip soc cores asic test access mechanism test data aliasing free compaction scheme combinational cores sequential cores;system on a chip;chip;application specific integrated circuits;logic testing;integrated circuit testing;vlsi;compact scheme;combinational circuits	Testing embedded cores in a System-on-a-chip necessitates the use of a Test Access Mechanism, which provides for transportation of the test data between the chip and the core I/Os. The trade-off between test application time, test bandwidth and area overhead should be exploited since it imposes certain restrictions on the Test Access Mechanism to be implemented. We outline an aliasing-free space and time compaction scheme, for both combinational and sequential cores, which minimizes the required test bandwidth and reduces the test bandwidth consumption at the core output side. The experimental results show that the test bandwidth gain is achieved with almost no increase in test application time.	aliasing;benchmark (computing);combinational logic;data compaction;embedded system;multi-core processor;nehalem (microarchitecture);overhead (computing);software propagation;superposition principle;system on a chip;test data;test set	Ozgur Sinanoglu;Alex Orailoglu	2001		10.1109/TEST.2001.966670	chip;system on a chip;embedded system;electronic engineering;real-time computing;telecommunications;computer science;automatic test pattern generation;test compression;sequential logic;application-specific integrated circuit;very-large-scale integration;combinational logic	EDA	19.48469916851093	52.46072544867108	50821
346ea698d253b43a1281ffcec1e4c724b87dc9e4	a new quality estimation methodology for mixed-signal and analogue ics	ic product quality;analogue ics;mixed signal ics;inductive fault analysis;analogue integrated circuits;quality estimation methodology;fault analysis;manufacturing test program quality estimation methodology mixed signal ics analogue ics ic product quality inductive fault analysis quality related parameters;mixed analogue digital integrated circuits;integrated circuit manufacture quality control mixed analogue digital integrated circuits analogue integrated circuits production testing;circuit faults circuit testing integrated circuit testing integrated circuit modeling production circuit simulation circuits and systems system testing virtual manufacturing analog integrated circuits;product quality;production testing;quality control;quality related parameters;manufacturing test program;integrated circuit manufacture	IC product quality is commonly described as the faulty device level at shipment and is becoming an increasingly important metric in the Microelectronics Industry. This paper presents and demonstrates a quality estimation approach based on Inductive Fault Analysis for mixed-signal and analogue ICs, that quantitatively models the quality related parameters prior to production. It is shown how the approach can be used to optimise the manufacturing test program.	mixed-signal integrated circuit	Thomas Olbrich;Ian A. Grout;Y. E. Aimine;Andrew M. D. Richardson;J. Contensou	1997		10.1109/EDTC.1997.582419	reliability engineering;electronic engineering;engineering;electrical engineering	SE	23.606307358850696	55.70017860843273	51040
dc335545464fe69118a029e10e6f1dea3787a60d	full-ic manufacturability check based on dense silicon imaging	opc;photolithography simulation;design for manufacture;opc psm design for manufacturability photolithography simulation ret;design for manufacturability;ret opc psm design for manufacturability photolithography simulation;psm;computational efficiency;ret	With the increased design complexities brought in by applying different Reticle Enhancement Technologies (RETs) in nanometer-scale IC manufacturing process, post-RET sign-off verification is quickly becoming necessary. By introducing innovative algorithms for lithographic modeling, silicon imaging and yield problem locating, this paper describes a new methodology of IC manufacturability verification based on Dense Silicon Imaging (DSI). Necessity of imaging based verification is analyzed. Existing post-RET verification methods are reviewed and compared to the new methodology. Due to the greatly improved computational efficiency produced by algorithms such as the ∼16*log2N/log2M times faster Specialized FFT, DSI based manufacturability checks on full IC scale, which were impractical for applications before, are now realized. Real verification example has been demonstrated and studied as well.	algorithm;binary logarithm;design for manufacturability;fast fourier transform;formal verification;resolution enhancement technology;semiconductor;silicon imaging	Xiaolang Yan;Zheng Shi;Ye Chen;Yue Ma;Gensheng Gao	2005	Science in China Series F: Information Sciences	10.1360/04yf0115	design for manufacturability	EDA	12.694579908958536	55.414178580243664	51291
522689dd175d1091490bc21c1282361d1b873707	mtj-based asynchronous circuits for re-initialization free computing against power failures		This paper introduces CMOS/magnetic tunnel junction (MTJ)-based asynchronous single-track circuits for re-initialization free computing against power failures. In energy-harvesting applications, data processed might be lost due to frequent power failures, which usually requires the initialization phase after the power supply is recovered. To prevent the re-initialization for energy-efficient computing, the proposed single-track circuits are designed using MTJ devices as nonvolatile storage elements. As MTJ devices store data without power supply, data processed are immediately backed up to MTJ devices and are restored when necessary in order to continue operations. For safe restore operations, the proposed circuits eliminate metastable states that might occur in the backup phase. To evaluate the performance overheads due to the nonvolatile operations, the proposed single-track circuits are designed using 65nm CMOS/MTJ technologies and are compared with conventional volatile single-track circuits in several benchmarks.	backup;cmos;power supply	Naoya Onizawa;Masashi Imai;Takahiro Hanyu;Tomohiro Yoneda	2017	2017 23rd IEEE International Symposium on Asynchronous Circuits and Systems (ASYNC)	10.1109/ASYNC.2017.11	initialization;embedded system;asynchronous communication;electronic circuit;tunnel magnetoresistance;non-volatile memory;backup;cmos;pipeline transport;engineering	Arch	18.168455818536966	60.24726230049636	51481
8d22115f62dd1ada73db5ea8ccd849d7aa7927f0	a 2mb reram with two bits error correction codes circuit for high reliability application	decoding computer architecture microprocessors random access memory resistance reliability programming	A 2-Mb resistive random access memory (ReRAM) is demonstrated in 0.13-um CMOS logic process. The paper describes the cell, chip architecture, and circuit techniques to ReRAM design; The 2-Mb ReRAM chip features three circuit technologies to improve the memory yield and performance: 1) for a better endurance and resistance distribution a ramped current pulse write driver (RCPWD) circuit is designed, 2) considering process variation and verify used, a programmable reference sense amplifier (PRSA) for stable read operation is designed, and 3) for improving the yield and reliability for some special application, a double error correction codes (DEC) circuit is introduced for yield requirement of high reliability applications.	cmos;code;ecc memory;error detection and correction;forward error correction;random access;resistive random-access memory;sense amplifier	Jianguo Yang;Ying Meng;Xiaoyong Xue;Ryan Huang;Q. T. Zhou;J. G. Wu;Yinyin Lin	2013	2013 IEEE 10th International Conference on ASIC	10.1109/ASICON.2013.6811970	electronic engineering;parallel computing;computer hardware;computer science	EDA	17.340050783448262	59.7533364947255	51864
d8e7baa73eb5397fd5a3071bd84aa6307d133de0	modeling and simulation for crosstalk aggravated by weak-bridge defects between on-chip interconnects	crosstalk;modeling and simulation;time delay;chip;delay errors crosstalk modeling crosstalk simulation weak bridge defects on chip interconnects induced signal delay hspice timing characteristics delay characteristics;integrated circuit design;crosstalk bridge circuits integrated circuit interconnections circuit faults coupling circuits capacitance delay effects timing circuit testing logic;integrated circuit interconnections;delay circuits;delays circuit analysis computing spice integrated circuit design integrated circuit interconnections crosstalk delay circuits bridge circuits timing;circuit analysis computing;spice;bridge circuits;analytical model;delays;timing	This paper presents comprehensive analytic models that consider both the case of a weak bridge, and the combination of a weak bridge and crosstalk between two interconnects. Our models capture the induced signal delay and pulse as a function of the parameters of the circuit and input signals. Our results are compared with HSPICE and shown to be accurate. A simulator is developed that implements our models and accurately captures timing (delay) characteristics of a circuit. We contrast our results with others, and show the benefits of this new model as well as the ability to predict the range of resistance that leads to delay errors.	algorithm;benchmark (computing);computer simulation;coupling (electronics);crosstalk;electrical connection;entity;randomness;resistive touchscreen;spice 2;signal transition;simulation;speaker wire;test card	Lei Wang;Sandeep K. Gupta;Melvin A. Breuer	2004	13th Asian Test Symposium	10.1109/ATS.2004.58	chip;embedded system;electronic engineering;real-time computing;crosstalk;telecommunications;computer science;engineering;modeling and simulation;integrated circuit design	EDA	22.46224685942867	56.50619050855931	51943
13a0a70740754818cb326fcda3c687533227c88a	architectures for function evaluation on fpgas	digital signal processing;field programmable gate array;evaluation function;design automation;design engineering;sine function;power of 2 function;field programmable gate arrays polynomials function approximation hardware design engineering digital signal processing minimax techniques costs arithmetic design automation;polynomials;power of 2 function function evaluation fpga architecture sine function;conference paper;minimax techniques;efficient implementation;function approximation;function evaluation;word length;fpga architecture;arithmetic;field programmable gate arrays function evaluation;field programmable gate arrays;polynomial approximation;hardware	This paper presents a new family of architectures for multi-cycle area-efficient evaluation of elementary and composite functions, and an exploration of the design tradeoffs for implementation on Field Programmable Gate Arrays (FPGAs). The method is exemplified with two common functions, sine and power-of-2. To test the performance of each design, we compare the proposed architecture to an established table-based method for several different input word-lengths and output precision requirements. FPGA-based results are presented, illustrating both the technology-independent and the technology-specific attributes of the tradeoff of area and speed between the proposed techniques.	field-programmable gate array;requirement	Nalin Sidahao;George A. Constantinides;Peter Y. K. Cheung	2003		10.1109/ISCAS.2003.1206096	embedded system;electronic engineering;electronic design automation;computer science;theoretical computer science;field-programmable gate array;computer engineering	EDA	11.167992142484925	46.48661820691403	52067
ff12240cfb2fa15cc55d9ebdc76434792bad1702	bists for post-bond test and electrical analysis of high density 3d interconnect defects		Cu-Cu hybrid bonding offers very high density interconnects (pitch around 2 μm or less) in 3D stacking integrated circuits (HD 3D-IC), but the smaller the Cu pad size, the more the fabrication and bonding defects have an important impact on yield and performance. Defects such as bonding misalignment, micro-voids and contact defects at the copper surface, can affect the electrical characteristics and the life time of 3D-IC considerably. In this paper, we propose two complementary test and characterization structures dedicated to high density 3D-IC interconnects. The first test structure permits to measure the misalignment defect with a great accuracy and the second to measure the RC delay of a periodic signal applied to a daisy chain composed of 3D Cu-Cu interconnects. The measured misalignment values and propagation delays allows to detect Cu-Cu full open, misalignment, and micro-voids, in order to assess performance of high density 3D Integrated Circuit. Both test structures are implemented as BIST engines, which are integrated and controlled with IEEE 1687, for an overall negligible area cost.	built-in self-test;daisy digital talking book;daisy chain (electrical engineering);electrical connection;propagation delay;rc time constant;software bug;software propagation;stacking;three-dimensional integrated circuit	Imed Jani;Didier Lattard;Pascal Vivet;Lucile Arnaud;Edith Beigné	2018	2018 IEEE 23rd European Test Symposium (ETS)	10.1109/ETS.2018.8400698	built-in self-test;daisy chain;stacking;electronic engineering;computer science;rc time constant;interconnection;integrated circuit	EDA	21.696524727025785	55.011875377739166	52108
529f74d4bad0cc93845407eaf13fe0836a090a1a	design and test of a novel programmable clock generator semi-custom core for energy-efficient systems-on-chips	energy efficient;system on chip		clock generator;semiconductor industry;system on a chip	Mauro Olivieri;Simone Smorfa;Alessandro Trifiletti	2005	J. Low Power Electronics	10.1166/jolpe.2005.041	system on a chip;embedded system;computer architecture;computer hardware;computer science;efficient energy use;digital clock manager	EDA	15.203284866276585	58.229013660557825	52122
7bdfe33b8d667c000623b4cdb07dce96e8234090	a survey of digital computer memory systems	informatica;economy digital computer memory systems storage systems reaction time historical approach evaluation criteria applicability construction operation speed latency time memory span;memoire;magnetismo;electrňnica;electrostatique;electrostatics;history;magnetism;electronique;virtual reality decision support systems humans delay;magnetisme;technology;diode;century 20;data processing;history digital storage;calculating machine;memoria;siecle 20;technologie;electronics;maquina calculadoras;memory systems;informatique;digital storage;machine a calculer;siglo 20;reaction time;memory;tecnologia;electrostatica	Many types of storage and memory systems have been proposed for use in digital computing systems. The survey paper discusses only the various systems whose reaction time is faster than human reaction time and employs a historical approach to the subject. Criteria for evaluation are discussed as well as comparisons among the different systems as to general applicability, ease of construction and use, speed of operation, latency time, memory span, and economy.	computer memory	J. P. Eckert	1998	IEEE Annals of the History of Computing	10.1109/85.728227	magnetism;electronics;simulation;data processing;computer science;engineering;electrical engineering;artificial intelligence;operating system;database;memory;algorithm;electrostatics;diode;technology	Embedded	12.510189727887058	59.60341388566115	52146
c1f82db8f2bb959fdd6af309f716acecfc47c5c9	practical challenges in logic bist implementation – case studies	reliability automatic test pattern generation built in self test integrated circuit testing integrated logic circuits logic testing;software tool;reliability;circuit faults;atpg logic built in self test technology turbobist logic software tool digital integrated circuits at speed testing simple test interface test cost reliability;clocks;logic built in self test;automatic test pattern generation;testing;test cost;turbobist logic software tool;at speed testing;built in self test;logic gates;digital integrated circuits;logic testing;integrated circuit testing;built in self test logic testing integrated circuit testing system testing software tools logic design logic circuits integrated circuit technology digital integrated circuits computer industry;logic built in self test technology;integrated logic circuits;simple test interface;industrial design;atpg	"""TurboBIST-Logic (TBL) is a software tool suite for incorporating logic built-in self-test (BIST) technology into digital Integrated Circuits and has been used by a variety of industrial designs globally since 2002. This abstract describes major features of TBL, and uses three industrial cases to show practical issues encountered and solved over the years. It also discusses an important new trend in going """"hybrid,"""" a flexible combination of capture-clocking schemes, with the goal to achieve an ever more optimal result over stand-alone schemes. Each of the three cases had its unique requirements for logic BIST, some needing to customize an existing solution, but all were set to achieve common BIST goals of at-speed testing, simple test interface to/from ATE, low test cost, high product reliability, and repeat testability investment reuse from IC, board, system, to in-field diagnosis."""	clock rate;integrated circuit;logic built-in self-test;logic programming;programming tool;requirement	Shianling Wu;Hiroshi Furukawa;Boryau Sheu;Laung-Terng Wang;Hao-Jan Chao;Lizhen Yu;Xiaoqing Wen;Michio Murakami	2008	2008 17th Asian Test Symposium	10.1109/ATS.2008.59	computer architecture;electronic engineering;industrial design;computer science;engineering;automatic test pattern generation;computer engineering	EDA	10.474730076124048	53.423341451680265	52239
23210d367347e7db5c384ebd308d58486fbc4b3e	embedded high-precision frequency-based capacitor measurement system	embedded capacitor measurement;capacitor value;embedded high precision frequency based capacitor measurement system;doe methodology embedded high precision frequency based capacitor measurement system electrical value measurement ring oscillator calibration system power supply variation automated measurement measurement process variations digital signature capacitor value design of experiment methodology;doe methodology;oscillators;measurement systems;ring oscillator;testing;automated measurement;design of experiment methodology;embedded systems;design of experiments;electrical value measurement;process variations;testing decision support systems;power supply variation;digital signature;capacitors;capacitance measurement;ring oscillator process variations embedded capacitor measurement;decision support systems;oscillators calibration capacitance measurement capacitors computerised instrumentation design of experiments embedded systems measurement systems;computerised instrumentation;calibration;measurement process variations;calibration system	This paper presents a direct way to measure the electrical value of capacitors embedded in a circuit using a ring-oscillator. A calibration system ensures robustness towards temperature, power supply and process variations. The measurement is largely automated to minimize the use of external instrumentation and to speed-up the measurement process while giving a digital signature of the capacitor value. Design-Of-Experiment (DOE) methodology has been conducted in order to validate the ability of the system to measure robustly a large range of small capacitors.	digital signature;embedded system;power supply;ring oscillator;system of measurement	Loïc Welter;Philippe Dreux;Jean Michel Portal;Hassen Aziza	2013	2013 IEEE 19th International On-Line Testing Symposium (IOLTS)	10.1109/IOLTS.2013.6604061	control engineering;digital signature;electronic engineering;calibration;capacitor;decision support system;computer science;engineering;electrical engineering;ring oscillator;system of measurement;software testing;design of experiments;oscillation;statistics	Embedded	23.983065876202982	55.5955831934676	52263
1244634f8a9ed2516418cc4f19ce1398275bb14a	high performance cmos 2-input nand based on low-race split-level charge-recycling pass-transistor logic	cmos integrated circuits;cmos technology;low energy;low race split level charge recycling pass transistor logic;logic circuits;high output load operation;cmos logic circuits recycling cmos technology energy efficiency logic design logic gates performance loss circuit simulation delay energy consumption;low voltage;logic gates;pass transistor logic;chargerecycling;transistors;chargerecycling lowvoltage lowenergy high capacitive load;driver circuits;charge recycling;logic circuits cmos integrated circuits;capacitance 1 pf;high capacitive load;cmos two input nand;lowvoltage;energy delay product;digital audio players;capacitive loading condition;high performance;recycling;size 65 nm;capacitance 1 pf cmos two input nand low race split level charge recycling pass transistor logic cmos technology capacitive loading condition energy delay product high output load operation size 65 nm;lowenergy	This paper presents the design of a highly efficient CMOS 2–input NAND (gcr–nand). When implemented on a 65nm CMOS technology, under 1pF capacitive loading condition, gcr–nand has a lower active area (3.4 times lower), and energy–delay product (56%) than the reference 2–input NAND (lscpl–nand). Furthermore, gcr–nand is able to operate under a high output load. Keywords-low–voltage; low–energy; high capacitive load; charge–recycling	cmos;nand gate;pass transistor logic	Jose Carlos Garcia-Montesdeoca;Juan A. Montiel-Nelson;Saeid Nooshabadi	2009	2009 12th Euromicro Conference on Digital System Design, Architectures, Methods and Tools	10.1109/DSD.2009.181	embedded system;logic gate;gate equivalent;nand gate;cmos	EDA	17.187867836563605	57.91392116267006	52328
cd14f5188bf24dbec48dd5c9f9a300e3d8cd9c09	sat-based test pattern generation with improved dynamic compaction	circuit faults sorting compaction heuristic algorithms test pattern generators engines;boolean functions;computability;automatic test pattern generation;sat based test pattern generation industrial circuit iscas dynamic compaction technique sat based atpg method optimisation advanced sat solving technique hard to detect fault;fault diagnosis automatic test pattern generation boolean functions computability;fault diagnosis	During the last years, SAT-based ATPG has been proved to be a powerful complement of traditional structural approaches. It outperforms structural methods when applied to hard-to-detect faults, and it can be combined with advanced SAT solving techniques in order to compute provably optimal solutions to complex test generation problems with optimisation goals. However, one weakness of SAT-based ATPG methods is their relatively high pattern count, which results largely from the over specification of the generated patterns. In order to overcome this weakness, we present a dynamic compaction technique specifically designed to work with SAT-based ATPG. We systematically investigate the impact of a conflict limit parameter and of several fault list sorting strategies on both test compactness and run-time. Using the best parameter combination, our SAT-based algorithm was able to generate with feasible computational effort more compact test sets for ISCAS circuits than a commercial structural tool, and the pattern counts for industrial circuits were reduced significantly.	algorithm;boolean satisfiability problem;computation;data compaction;linear programming relaxation;mathematical optimization;simulation;solver;sorting;test card;test set;true quantified boolean formula	Alexander Czutro;Sudhakar M. Reddy;Ilia Polian;Bernd Becker	2014	2014 27th International Conference on VLSI Design and 2014 13th International Conference on Embedded Systems	10.1109/VLSID.2014.17	discrete mathematics;fault coverage;computer science;theoretical computer science;automatic test pattern generation;mathematics;computability;boolean function;algorithm	EDA	17.898466639677075	48.05804989086435	52363
a1e0bafa76c1bb3782449cbd2ac37fc1ecae20fd	mram-on-fdsoi integration: a bit-cell perspective		In this paper we discuss the potential foundry announced hybrid integration of magnetic random access memory (MRAM) on fully depleted silicon-on-insulator (FD-SOI) technology. The spin transfer torque magnetic tunnel junction (STT-MTJ) and the next generation voltage-controlled magnetic anisotropy (VCMA) MTJ are separately integrated into a 28 nm FD-SOI process. Circuit-level design strategies are explored that use FD-SOI leverage and spin-device characteristic to realize writing and reading power-delay efficiency, robust and reliable performance in a 1-transistor 1-MTJ (1T1M) bit cell. Process variation aware strategies for MTJ-FDSOI integration are proposed to compensate failure operations, by using the dynamic step-wise back-bias and the flip-well back-bias. A qualitative summary demonstrates that the MRAM-on-FDSOI integration offers attractive performance for future non-volatile CMOS integration.	bit cell;cmos;cell (microprocessor);level design;magnetoresistive random-access memory;non-volatile memory;random access;silicon on insulator;topological insulator	Hao Cai;Yilin Wang;Lirida A. B. Naviner;Xinning Liu;Jun Yang	2018	2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)	10.1109/ISVLSI.2018.00056	magnetic anisotropy;bit cell;transistor;tunnel magnetoresistance;process variation;magnetoresistive random-access memory;spin-transfer torque;computer science;cmos;electronic engineering	Arch	16.912682785298916	60.218195661296775	52406
f39957b7c525b6ced28e5f31551171da5a667fdb	comparative analysis of different implementations of multiple-input signature analyzers	error aliasing;signature analysis;circuit commutation;multientry;bist;built in testing;comparative analysis;data compression;integrated circuit;analyse signature;detection panne;switching circuits;linear feedback shift registers;estudio comparativo;failure detection;switching circuits automatic testing data compression integrated circuit testing logic testing shift registers;automatic testing;entrada multiple;circuito integrado;finite state switching circuits;etude comparative;polynomial division;entree multiple;aliasing patterns;shift registers;logic testing;comparative study;integrated circuit testing;switching circuit;circuito conmutacion;polynomials circuit testing data compression switching circuits linear feedback shift registers microelectronics hardware automatic testing built in self test performance analysis;error detection;error detection error aliasing linear feedback shift registers bist multiple input signature analyzers data compression built in testing finite state switching circuits characteristic polynomial polynomial division aliasing patterns;multiple input signature analyzers;characteristic polynomial;deteccion falla;circuit integre;analisis firma	Signature analysis is an accepted method of obtaining data compression for built-in testing applications. The author deals with a unified approach to the analysis of multiple-input signature analyzers by considering them as finite state switching circuits. This approach is used to investigate and compare different implementations, and it is shown that there is a large range of alternatives to achieve a given characteristic polynomial. Particular emphasis is placed on the two most common implementations. It is shown that both perform polynomial division, with each input of one circuit being equivalent to a combination of inputs of the other. The approach also gives a method of expressing aliasing patterns for both implementations, which leads to a study of the differences with regard to certain error detection capabilities. >		Peter C. Maxwell	1988	IEEE Trans. Computers	10.1109/12.8706	data compression;qualitative comparative analysis;embedded system;parallel computing;error detection and correction;computer science;theoretical computer science;integrated circuit;comparative research;mathematics;polynomial long division;shift register;characteristic polynomial;algorithm;statistics	Vision	21.580788110984756	48.673117711773	52478
2b14dd82116d58ec3cf66bd8eb2212ce5c9172a3	intermittent resistance fault detection at board level		interconnection reliability issues threat the dependability of highly dependable systems. One of the most challenging interconnection-induced reliability threats is intermittent resistive faults (IRFs). They may occur randomly in time, duration and amplitude in every interconnection. The occurrence rate can vary from a few nanoseconds to months. As a result, evoking and detecting such faults is a major challenge. In this paper, IRF detection at the board level has been investigated by introducing a new digital IRF monitor. This monitor has been validated by using hardware-based fault injection. Two widely used on-board transmission protocols —UART and SPI —have been used as case studies. In addition, one fault management framework —based on the IJTAG standard —has been implemented to collect and characterize information from the monitors. The experimental results show that the proposed monitor is effective in detecting IRFs at the board level.	dependability;fault injection;information retrieval facility;interconnection;on-board data handling;online and offline;randomness;resistive touchscreen;sensor;serial communication;streaming media	Hassan Ebrahimi;Hans G. Kerkhoff	2018	2018 IEEE 21st International Symposium on Design and Diagnostics of Electronic Circuits & Systems (DDECS)	10.1109/DDECS.2018.00031	fault injection;universal asynchronous receiver/transmitter;computer science;interconnection;real-time computing;fault detection and isolation;fault management;amplitude;resistive touchscreen;dependability	Arch	21.282977976466917	55.76368428520355	52559
de392bd30651a2e831087bb8ec65aa086b34556e	gene expression programming-based method of optimal frequency set determination for purpose of analogue circuits' diagnosis	circuit under test;fault tolerant;frequency response;gene expression programming;fault diagnosis	  This paper presents a method for optimal frequency search with the use of Gene Expression Programming (GEP). It includes a  brief summary of material of analogue circuits fault diagnosis and introduction to GEP. Developed method belongs to SBT diagnosis  routines’ group. Frequency responses for chosen hard faults of a circuit under test as well as for an intact circuit are simulated  before test. There are ambiguity sets provided to avoid a fault tolerance masking effect.    	gene expression programming	Piotr Jantos;Damian Grzechca;Tomasz Golonek;Jerzy Rutkowski	2008		10.1007/978-3-540-75175-5_98	fault tolerance;frequency response;real-time computing;computer science;gene expression programming	EDA	24.330103563198676	50.742371427970255	52763
c2f067394cd6eabdeefa3013862f841c9873df47	iris template extraction via bit inconsistency and grit		A 2/N mode clock generator that generates bus clock signals through the use of bus clock enable signals selecting bus clock pulses that are in phase and out of phase with a core clock signal. The clock generator maintains synchronization between the bus clock signal and the core clock signal so that they are always in a predetermined phase relationship.		Gerry V. Dozier;Marios Savvides;Kelvin S. Bryant;Taihei Munemoto;Karl Ricanek;Damon L. Woodard	2009		10.1007/978-0-387-73003-5_165	engineering drawing	NLP	20.467201342422687	54.321718626978516	52824
3ad411522c6005c7a3ee51a070d3de304350b4d1	druping for interpolates	interpolation;theorem proving computability formal verification interpolation logic gates;color;sat based model checking algorithm druping drup proofs interpolants interpolation algorithm resolution proof sat solver unsatisfaible formula replacing resolution step and and or gates performance degradation memory requirement proof logging cnf drup based interpolation framework minisat;model checking;safety;context;interpolation color reactive power model checking safety partitioning algorithms context;partitioning algorithms;reactive power	"""We present a method for interpolation based on DRUP proofs. Interpolants are widely used in model checking, synthesis and other applications. Most interpolation algorithms rely on a resolution proof produced by a SAT-solver for unsatisfaible formulas. The proof is traversed and translated into an interpolant by replacing resolution steps with AND and OR gates. This process is efficient (once there is a proof) and generates interpolants that are linear in the size of the proof. In this paper, we address three known weakness of this approach: (i) performance degradation experienced by the SAT-solver and the extra memory requirements needed when logging a resolution proof; (ii) the proof generated by the solver is not necessarily the """"best"""" proof for interpolantion, and (iii) combining proof logging with pre-processing is complicated. We show that these issues can be remedied by using DRUP proofs. First, we show how to produce an interpolant from a DRUP proof, even when pre-processing is enabled. Second, we give a novel interpolation algorithm that produces interpolants partially in CNF. Third, we show how DRUP proof can be restructured on-the-fly to yield better interpolants. We implemented our DRUP-based interpolation framework in MiniSAT, and evaluated its affect using Avy - a SAT-based model checking algorithm."""	algorithm;boolean satisfiability problem;conjunctive normal form;elegant degradation;experiment;interpolation;model checking;preprocessor;probabilistically checkable proof;requirement;resolution (logic);solver	Arie Gurfinkel;Yakir Vizel	2014	2014 Formal Methods in Computer-Aided Design (FMCAD)	10.1109/FMCAD.2014.6987601	model checking;interpolation;computer science;theoretical computer science;ac power;proof complexity;algorithm	Logic	18.5404014779345	48.274837760408175	52885
1fd3f9fc12f9a640b29f484f369648c432fc5d3d	fast and effective placement refinement for routability	vlsi integrated circuit design linear programming network routing;routing agriculture frequency modulation benchmark testing runtime very large scale integration white spaces;vlsi design flow congestion refinement of placement routability mixed size placement solution congestion congestion driven module shifting technique congestion driven detailed placement technique cddp technique routing resource allocation g cell boundary shifting linear program lp formulation global routing grid routing demand distribution congestion reduction half perimeter wirelength congestion factor movable macroblock fixed macroblock ispd gr benchmark suite ispd05 06 derived global routing benchmark;network routing;integrated circuit design;linear programming;vlsi;routing congestion physical design placement	In this brief, we propose congestion refinement of placement (CROP) for improving the congestion of mixed-size placement solutions. CROP consists of a congestion-driven module shifting technique and a congestion-driven detailed placement (CDDP) technique. The shifting technique is proposed for better allocation of routing resources. We shift modules based on the shifting of G-cell boundaries. Shifting in each direction can be formulated as a linear program (LP) for resizing each cell in the global routing grid (i.e., G-cell). We degenerate and solve the LP by a very efficient longest path computation. Then the CDDP technique is proposed for distributing the routing demands better. Congestion reduction is realized by weighting the half-perimeter wirelength with the congestion factor during detailed placement. Theoretically, our tool is capable of handling most mixed-size placement benchmarks with movable and/or fixed macro (FM) blocks. In order to better analyze its performance, the ISPD-GR benchmark suite (ISPD05/06 derived global routing benchmarks) with FM modes is developed. The experimental results show that CROP effectively alleviates congestion for unroutable placement solutions in short runtimes for different placers.	benchmark (computing);computation;display resolution;fm broadcasting;international symposium on physical design;linear programming;longest path problem;network congestion;perimeter;refinement (computing);router (computing);routing	Yanheng Zhang;Chris C. N. Chu	2013	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2012.2214408	embedded system;mathematical optimization;routing;electronic engineering;static routing;real-time computing;computer science;linear programming;dynamic source routing;multipath routing;destination-sequenced distance vector routing;very-large-scale integration;routing;computer network;placement;integrated circuit design	EDA	15.113949180633451	52.63314049726266	52946
74d6e3c6a0fa2dcde8b7d58430d37f8dd22fc4ca	dominant critical gate identification for power and yield optimization in logic circuits	process variation;low vt;yield;optimization problem;technology scaling;process variations;leakage power;random process;critical path	With increasing process variations, low-VT swapping is an effective technique that can be used to improve timing yield without having to modify a design following placement and routing. Gate criticality, defined as the probability that a gate lies on a critical path, forms the basis for existing low-VT swapping techniques. This paper presents a simulation-based study that challenges the effectiveness of low-VT swapping based on the conventional definition of gate criticality, especially as random process variations increase with technology scaling. We introduce dominant gate criticality to address the drawbacks of the conventional definition of gate criticality, and formulate dominant critical gate ranking in the presence of process variations as an optimization problem. Simulation results for 12 benchmark circuits from the ISCAS and OpenSPARC suites to achieve timing yields of 95% and 98% indicate that low-VT swapping based on dominant gate criticality reduces leakage power overhead by 61% and 42% for independent and correlated process variations, respectively, over low-VT swapping based on  conventional gate criticality.	benchmark (computing);critical path method;criticality matrix;image scaling;logic gate;mathematical optimization;opensparc;optimization problem;overhead (computing);paging;place and route;routing;self-organized criticality;simulation;spectral leakage;stochastic process	Mihir R. Choudhury;Masoud Rostami;Kartik Mohanram	2010		10.1145/1785481.1785526	optimization problem;stochastic process;yield;electronic engineering;real-time computing;computer science;engineering;critical path method;process variation;statistics	EDA	20.114117987803976	57.41331985107064	52983
01fe01ca8250654dad5034fb5e84df3763b3674e	a robust power gating structure and power mode transition strategy for mtcmos design	circuit verrouillage;spurious switching;switching activity;nudo estructura;cmos integrated circuits;leakage;switching;integrated circuit design cmos integrated circuits;short circuit current;veille electrique;nodes;distribution courant;voltage threshold;short circuit currents;courant court circuit;power gating;power mode transition ground bounce leakage multithreshold cmos mtcmos power gating;tecnologia mos complementario;current distribution;integrated circuit design;power mode transition;multithreshold cmos mtcmos;electrical standby;scheduling;circuito enganche;conmutacion;distribucion corriente;spurious switching power gating power mode transition multithreshold cmos mtcmos ground bounce circuit registers sleep transistors;mtcmos;sleep transistors;noeud structure;seuil tension;reactivation;reactivacion;multithreshold cmos;ground bounce;circuit registers;robustness logic devices mosfets turning cmos technology cmos logic circuits power supplies threshold voltage logic gates registers;technologie mos complementaire;latch circuit;commutation;ordonnancement;complementary mos technology;reglamento;umbral tension;espera electrica;uniform distribution;transistor;design methodology	The large magnitude of supply/ground bounces, which arise from power mode transitions in power gating structures, may cause spurious transitions in a circuit. This can result in wrong values being latched in the circuit registers. We propose a design methodology for limiting the maximum value of the supply/ground currents to a user-specified threshold level while minimizing the wake up (sleep to active mode transition) time. In addition to controlling the sudden discharge of the accumulated charge in the intermediate nodes of the circuit through the sleep transistors during the wake up transition, we can eliminate short circuit current and spurious switching activity during this time. This is, in turn, achieved by reducing the amount of charge that must be removed from the intermediate nodes of the circuit and by turning on different parts of the circuit in a way that causes a uniform distribution of current over the wake up time. Simulation results show that, compared to existing wakeup scheduling methods, the proposed techniques result in a 1-2 orders of magnitude improvement in the product of the maximum ground current and the wake up time	algorithm;bounce message;cluster analysis;computational complexity theory;discharger;multi-threshold cmos;power gating;scheduling (computing);short circuit;simulation;transistor;uptime	Afshin Abdollahi;Farzan Fallah;Massoud Pedram	2007	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2007.891093	electronic engineering;design methods;telecommunications;computer science;engineering;electrical engineering;short circuit;ground bounce;leakage;uniform distribution;node;cmos;scheduling;transistor;integrated circuit design	EDA	18.23714372087708	56.388020089149805	53060
30ec0de9a40eaa34a73a43d5b68cae49ad9b5320	optimum wire sizing of rlc interconnect with repeaters	on chip inductance;anchura raya espectral;dimensionnement;impedance;interconnection;integrated circuit;dissipation energie;largeur raie;circuit rlc;dimensioning;impedancia;circuito integrado;repeater;energy dissipation;satisfiability;rlc circuit;repeteur;chip;interconexion;high strength current;wire sizing;transient power dissipation;propagation delay;power dissipation;line width;inductancia;interconnexion;low power electronics;courant intense;circuito rlc;corriente intensa;inductance;disipacion energia;temps retard;low power design;delay time;power delay product;repetidor;dimensionamiento;electronique faible puissance;tiempo retardo;high speed;circuit integre;repeater insertion	Repeaters are often used to drive high impedance interconnects. These lines have become highly inductive and can affect signal behavior. The line inductance should therefore be considered in determining the optimum number and size of the repeaters driving a line. The optimum repeater system uses uniform repeater insertion in order to achieve the minimum propagation delay. A tradeoff exists, however, between the transient power dissipation and the minimum propagation delay in sizing long interconnects driven by the optimum repeater system. Optimizing the line width to achieve the minimum power delay product, however, can satisfy current high speed, low-power design objectives. A reduction in power of 65% and delay of 97% is achieved for an example repeater system.The Power-Delay-Area-Product (PDAP) criterion is introduced as an efficient technique to size the interconnect within a repeater system. A reduction in buffer area of 67% and interconnect area of 46% is achieved based on the PDAP.	rlc circuit	Magdy A. El-Moursy;Eby G. Friedman	2004	Integration	10.1016/j.vlsi.2004.04.001	electronic engineering;telecommunications;computer science;engineering;electrical engineering;dissipation	EDA	18.275841149127192	55.16719166214584	53102
3e2785c825677e2bae2eef279bce2fa7c1d0e573	data-retention flip-flops for power-down applications	cmos memory circuits;clocks;flip-flops;integrated circuit design;integrated circuit modelling;integrated circuit testing;logic design;logic gates;logic simulation;logic testing;low-power electronics;shift registers;0.25 micron;70 nm;cmos process;clock circuit;conventional balloon process;cross-coupled inverters;data gating circuit;data preserving latches;data retention flip flops;flip flop fabrication;flip-flop testing;power down mode;power-down applications;shift register;transmission gate flip-flop	A novel technique for retaining data in flip-flops in power-down applications is presented. In flip-flops data is stored in cross-coupled inverters. Cross-coupled inverters can hold their states in the power down mode, if their inputs are properly gated. Based on this fact, simple clock and data gating circuitries are employed in flip-flops to retain their data in the power-down mode without using any extra data-preserving latches. In a predictive 70 nm technology node, a transmission-gate flip-flop based on the proposed data-retention scheme exhibits 18X reduction in standby leakage compared to a conventional transmission-gate flip-flop. The proposed data-retention scheme also exhibits 40% area reduction compared to the conventional balloon scheme. A 16-bit shift-register using data-retention flip-flops has been successfully fabricated and tested in a 0.25 /spl mu/m CMOS process.	16-bit;cmos;flops;flip-flop (electronics);inverter (logic gate);logic gate;semiconductor device fabrication;shift register;spectral leakage	Hamid Mahmoodi;Kaushik Roy	2004	2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No.04CH37512)		embedded system;electronic engineering;real-time computing;computer science;engineering;operating system;shift register	Arch	17.752973746514055	58.18914177065364	53242
0f2e6907c8ec7958d6e094dc9ff8389940abdc70	three-dimensional cache design exploration using 3dcacti	cache storage;architectural design;integrated circuit;integrated circuit layout;cache memory;three dimensional;circuit simulation;technology scaling;memory architecture;integrated circuit interconnections;cache storage integrated circuit layout memory architecture logic cad integrated circuit interconnections;3d layouts 3dcacti interconnects deep submicron designs 3d integrated circuits cache memories delay model energy model cache partitioning circuit simulation;logic cad;integrated circuit interconnections delay cache memory design methodology wires space technology computer science design engineering power engineering and energy integrated circuit technology	As technology scales, interconnects dominate the performance and power behavior of deep submicron designs. Three-dimensional integrated circuits (3D ICs) have been proposed as a way to mitigate the interconnect challenges. In this paper, we explore the architectural design of cache memories using 3D circuits. We present a delay and energy model, 3DCacti, to explore different 3D design options of partitioning a cache. The tool allows partitioning of the cache across different device layers at various levels of granularity. The tool has been validated by comparing its results with those obtained from circuit simulation of custom 3D layouts. We also explore the effects of various cache partitioning parameters and 3D technology parameters on delay and energy to demonstrate the utility of the tool.	cpu cache;electrical connection;electronic circuit simulation;integrated circuit;very-large-scale integration	Yuh-Fang Tsai;Yuan Xie;Narayanan Vijaykrishnan;Mary Jane Irwin	2005	2005 International Conference on Computer Design	10.1109/ICCD.2005.108	mixed-signal integrated circuit;physical design;three-dimensional space;pipeline burst cache;computer architecture;electronic engineering;parallel computing;cpu cache;computer science;electrical engineering;integrated circuit;circuit design;integrated circuit layout;circuit extraction	EDA	13.13359115481906	54.3091185417198	53411
27b68e3b79009f1e6b56b8bdc134ee534ac0162c	self-stabilizing microprocessor: analyzing and overcoming soft errors	microprocessors;microprocessor;automatic repair;np hard problem self stabilizing microprocessor soft errors self healing automatic recovery automatic repair autonomic computing microprocessor reliability digital circuits logical masking;fault tolerance microprocessor chips logic design;logic design;microprocessor reliability;self stabilizing microprocessor;np hard problem;self stabilization;automatic recovery;state space;fault tolerance;single event upset self stabilization microprocessor soft errors;single event upset;soft errors;digital circuits;autonomic computing;soft error;microprocessors logic design;logical masking;self healing;lower bound;microprocessor chips	Soft errors are changes in memory value caused by external radiation or electrical noise. Decreases in computing feature sizes and power usages and shorting the microcycle period enhance the influence of soft errors. Self-stabilizing systems are designed to be started in an arbitrary, possibly a corrupted, state due to, say, soft errors, and to converge to a desired behavior. Self-stabilization is defined by the state space of the components and is essentially a well-founded, clearly defined form of the terms self-healing, automatic-recovery, automatic-repair, and autonomic-computing. To implement a self-stabilizing system, one needs to ensure that the microprocessor that executes the program is self-stabilizing. A self-stabilizing microprocessor copes with any combination of soft errors, converging to perform fetch-decode-execute in fault-free periods. Still, it is important that the microprocessor will avoid convergence periods if possible by masking the effect of soft errors immediately. In this work, we present design schemes for a self-stabilizing microprocessor and a new technique for analyzing the effect of soft errors. Previous schemes for analyzing the effect of soft errors were based on simulations. In contrast, our scheme computes a lower bound on microprocessor reliability and enables the microprocessor designer to evaluate the reliability of the design and to identify reliability bottlenecks. When analyzing the resiliency of digital circuits to soft errors, we examine the logical masking, i.e., errors in internal nodes of the circuits that are masked later by the computation. We show that the problem of computing the reliability of a circuit such that logical masking is taken into account is an NP-hard problem.	algorithm;autonomic computing;computation;converge;digital electronics;microprocessor;np-hardness;noise (electronics);self-stabilization;simulation;soft error;state space	Shlomi Dolev;Yinnon A. Haviv	2006	IEEE Transactions on Computers	10.1109/TC.2006.61	embedded system;self-stabilization;fault tolerance;parallel computing;logic synthesis;real-time computing;soft error;computer science;state space;electrical engineering;operating system;np-hard;upper and lower bounds;digital electronics;autonomic computing	EDA	18.22338669733392	51.59433620726963	53557
c8007a85f189a5e6109b20d796b8ed518b09118b	a new decompressor with ordered parallel scan design for reduction of test data and test time	integrated circuit testing automatic test pattern generation data compression design for testability electronic engineering computing;clocks;multiplexing;computer architecture;shift registers clocks broadcasting computer architecture design methodology multiplexing;shift registers;broadcasting;test application time broadcast ratio decompressor paralll chain test data volume;heuristic method ordered parallel scan design test data reduction test time reduction design for testability test data compression technique broadcast based decompressor bidirectional shift register;design methodology	Scan design is regarded as the best design-for-testability (DfT) discipline. High test data volume and long test time are always two major concerns that our work here addresses. Here we combine a test data compression technique and broadcast-based decompressor architecture to relieve these problems. We propose a new decompressor architecture with bidirectional shift register as a source chain to broadcast compressed data into parallel scan chains. It enables one more broadcasting mode which leads to a higher broadcast ratio. We also propose a heuristic method to order the scan cells in each sub scan chain to improve the broadcast ratio so as to reduce the test data and test time. We apply our method on several benchmark circuits and the experimental results show that our method can reduce test data volume by 22.8% and shorten test application time by 19.5% on average with low area overhead in comparison to other state-of-the-art approaches.	apple multiple scan 14 display;asynchronous i/o;benchmark (computing);computer data storage;data compression;design for testing;gary kimura;heuristic;input/output;interval exchange transformation;joseph d. novak;overhead (computing);routing;segmented scan;shift register;test card;test compression;test data	Tingting Yu;Aijiao Cui;Mengyang Li;André Ivanov	2015	2015 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2015.7168715	embedded system;electronic engineering;parallel computing;real-time computing;design methods;telecommunications;computer science;automatic test pattern generation;operating system;test compression;shift register;broadcasting;multiplexing	EDA	19.597646723757652	52.82155719667749	53636
385b9a2be137e97e9e02de0aa5567f3ed849e364	a design for test technique for parametric analysis of sram: on-die low yield analysis	sram cell;on-die low yield analysis;nm cmos process technology;concept on-die lya;parametric analysis;non-destructive highspeed parametric analysis;microprocessor sram;leakage distortion;new process;failure analysis engineer;test technique;process technology;cache memory;fault isolation;multiplexing;failure analysis;transistor;interconnection;cmos integrated circuits;static random access memory;implementation;integrated circuit;design for testability;design for test;die	Parametric analysis of microprocessor SRAM through special design for test features (DFT) is used extensively by fault isolation and failure analysis engineers to find and characterize defects. Unfortunately, a growing amount of leakage on each new process is distorting these low yield analysis (LYA) testmode l-V curves, making it increasingly difficult to find and differentiate defects. The goal of This work is to discuss the simulation and silicon results of a concept on-die LYA (ODLYA) circuit implemented in a 65 nm CMOS process technology. ODLYA is used to curve-trace individual transistors within an SRAM cell and read out results in an automated fashion. Taking measurements on-die eliminates interconnect-dominated IR drop and leakage distortion from several levels of multiplexing. The proposed implementation enables non-destructive high-speed parametric analysis with less dependency on growing cache sizes, number of cores, and scaling process technologies.	cmos;cell (microprocessor);design for testing;distortion;failure analysis;fault detection and isolation;image scaling;microprocessor;multiplexing;simulation;spectral leakage;static random-access memory;transistor	Benjamin M. Mauck;Vishnumohan Ravichandran;Usman Azeez Mughal	2004	2004 International Conferce on Test	10.1109/ITC.2004.9	embedded system;electronic engineering;telecommunications;computer science;engineering;electrical engineering;design for testing	EDA	20.322477439978385	57.20917583418747	53674
8ca65ee142e3a6ee8b52ccccad3b6e62b9837f8c	dynamic operand transformation for low-power multiplier-accumulator design	mac design approach;hardware computer science tree data structures wires latches logic compressors encoding delay design optimization;logic design;logic;wires;tree data structures;design optimization;integrated circuit design;low power;hamming distance;compressors;computed hamming distance;power dissipation;integrated circuit design low power electronics logic design digital arithmetic integrated logic circuits;low power electronics;dynamic operand transformation;digital arithmetic;low power multiplier accumulator design;portable battery operated devices;low power computation circuits;latches;computed hamming distance dynamic operand transformation low power multiplier accumulator design portable battery operated devices low power computation circuits mac design approach power consumption reduction;computer science;integrated logic circuits;power consumption;encoding;power consumption reduction;hardware	The design of portable battery-operated devices requires low-power computation circuits. This paper presents a new multiplier-accumulator (MAC) design approach, which in contrast to existing methods exploits dynamic operand transformation to reduce power consumption. The key idea is to compare current values of input operands with previous values and depending on computed Hamming distance to use either original or two’s complement form of the operands in order to decrease the transition activity of multiplication. Experiments show that such a formulation outperforms the related approaches minimizing the power dissipation of traditional MAC design almost by half with 31% area and 12% delay overhead. The circuit implementation is outlined.	accumulator (computing);adder (electronics);cpu power dissipation;computation;experiment;hamming distance;low-power broadcasting;mathematical optimization;multiply–accumulate operation;operand;overhead (computing);prototype;two's complement	Masayoshi Fujino;Vasily G. Moshnyaga	2003		10.1109/ISCAS.2003.1206276	embedded system;electronic engineering;real-time computing;hamming distance;computer science;theoretical computer science;mathematics;logic;encoding;integrated circuit design	EDA	13.201089060315052	47.85748513315749	53743
3aa42957a2f0334b0d18ee1736708995f90dae97	a new efficient approach to statistical delay modeling of cmos digital combinational circuits	process variation;building block;statistical evaluation;combinational circuit;monte carlo analysis	This paper presents one of the first attempts to statistically characterize signal delays of basic CMOS digital combinatorial circuits using the transistor level approach. Hybrid analytical/iterative delay expressions in terms of the transistor geometries and technological process variations are created for basic building blocks. Local delays of blocks along specific signal paths are combined together for the analysis of complex combinational VLSI circuits. The speed of analysis is increased by 2 to 4 orders of magnitude relative to SPICE, with about 5–10% accuracy. The proposed approach shows good accuracy in modeling the influence of the “noise” parameters on circuit delay relative to direct SPICE-based Monte Carlo analysis. Examples of statistical delay characterization are shown. The important impact of the proposed approach is that statistical evaluation and optimization of delays in much larger VLSI circuits will become possible.	cmos;code generation (compiler);combinational logic;iterative method;mathematical optimization;monte carlo method;quantum decoherence;rc time constant;spice;statistical machine translation;transistor;very-large-scale integration	Syed A. Aftab;M. A. Styblinski	1994		10.1145/191326.191407	electronic engineering;computer science;theoretical computer science;mathematics;combinational logic;process variation;algorithm;statistics;monte carlo method	EDA	22.738927766563204	57.99205384791597	54086
3b8dd715384363567412c5857425c934ca96b5c8	decomposition technologies for advanced nodes	advanced lithography;layout decomposition;multi patterning;ic manufacturing multi patterning layout decomposition advanced lithography;photolithography integrated circuit layout masks;ic manufacturing;layout shape capacitance silicon metals color integrated circuits;feature size decomposition technology layout pitch lithographic process multiple masks multipatterning technology ic design flow eda tools	We present an overview of several techniques that are used when the layout pitch and feature size become significantly smaller than the minimum resolution of the lithographic process. These technologies, known collectively as multi-patterning (MP) share the common approach: a single layer is decomposed into two or more masks and printed in multiple stages. However, a great variety of approaches exists when it comes to details. There are several different ways to combine multiple masks into one final layer, each with its own advantages and drawbacks. The choice of multi-patterning technology is closely connected with the process technology, of course, but it turns out to have major implications on the entire IC design flow. We will review the major types of multi-patterning technologies, their impact on the lithographic process, yield, and design flow, and the requirements they impose on designers and on the EDA tools.	design flow (eda);integrated circuit design;printing;requirement;variable shadowing	Fedor G. Pikus	2016	2016 17th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2016.7479215	electronic engineering;ic layout editor;engineering;nanotechnology;integrated circuit layout;engineering drawing	EDA	12.875988406428908	54.89514896224976	54146
248c4d93d16231ad431baccc129533f4d5e1d2ed	(when) will fpgas kill asics? (panel session)	interconnect;current test;iddt;boundary scan;time to market;logic gate	There was a time - in the dim historical past - when foundries actually made ASICs with only 5000 to 50,000 logic gates. But FPGAs and CPLDs conquered those markets and pushed ASIC silicon toward opportunities with more logic, volume, and speed. Today's largest FPGAs approach the few-million-gate size of a typical ASIC design, and continue to sprout embedded cores, such as CPUs, memories, and interfaces. And given the risks of nonworking nanometer silicon, FPGA costs and time-to-market are looking awfully attractive. So, will FPGAs kill ASICs? ASIC technologists certainly think not. ASICs are themselves sprouting patches of programmable FPGA fabric, and pushing new realms of size and especially speed. New tools claim to have tamed the convergence problems of older ASIC flows. Is the future to be found in a market full of FPGAs with ASIC-like cores? ASICs with FPGA cores? Other exotic hybrids? Our panelists will share their disagreements on these prognostications.	application-specific integrated circuit;central processing unit;complex programmable logic device;embedded system;field-programmable gate array;logic gate;realms;sprout (computer)	Rob A. Rutenbar;Max Baron;Thomas Daniel;Rajeev Jayaraman;Zvi Or-Bach;Jonathan Rose;Carl Sechen	2001		10.1145/378239.378499	embedded system;electronic engineering;real-time computing;boundary scan;logic gate;computer science;engineering;electrical engineering;operating system;interconnection	EDA	10.084010690771859	56.21974842324692	54165
c0f9b53177d9a9e61f178e8f36a7e21ddcb84f50	model of conceptual design of complex electronic systems	complex electronic system;conceptual design;integrated circuit design;layout;algorithm design and analysis;conceptual framework;channel;process design;design automation;fabrication;routing;concept formation;bit slice;placement	Due to the ever increasing complexity of electronic system (ES) design, the conceptual design phase and its realization in later phases of the design stream have become increasingly important. In this paper, we describe the proposed general strategy of concept formation for abstract levels of ES design. As a general method of conceptual decision making, a procedure for the inheritance of alternative variants using the key conceptual primitive is proposed. We emphasize the role of personal constructs as the linking units in the hierarchy of the inheriting concepts. In addition we introduce the idea of mental simulation as an informal individual procedure which is based on the intuitive mechanism of concept formation. Finally, we discuss the main components of a directive conceptual framework.	concept learning;conceptual schema;directive (programming);simulation	Alexander N. Soloviev;Alexander L. Stempkovsky	1995			layout;process design;embedded system;algorithm design;routing;conceptual model;electronic engineering;simulation;concept learning;electronic design automation;computer science;systems engineering;engineering;bit slicing;conceptual schema;operating system;conceptual design;conceptual framework;fabrication;engineering drawing;algorithm;computer network;placement;integrated circuit design;channel	EDA	11.959204025387596	50.83745008818886	54203
8ed1cfa0933d260c1afff5222b05715a77d9461d	nostradamus: a floorplanner of uncertain designs	vlsi;circuit layout cad;delays;integrated circuit layout;modules;network routing;nostradamus;vlsi;approximate area;chip planning;delay;design process;floorplanner;input characteristics;modules;output characteristics;reconfigurable computing;uncertain designs	Floorplanning is an early phase in chip planning. It provides information on approximate area, delay, power, and other performance measures. Careful oorplanning is thus of extreme importance. In many applications while a good oorplan is needed, not all modules' information are available, or even worse, part of the provided information is inaccurate. Floorplanning with uncertainty is the problem of obtaining a good oorplan under uncertainty. In this paper, the oorplanning problem with uncertainty is formulated. It is established that traditional oorplanners are incapable of handling uncertainty. An e ective method for dealing with uncertain data is proposed. Experiments show that, for example, with up to 30% input uncertainty an area estimate with less than 7% error can be obtained.	approximation algorithm;experiment;floorplan (microelectronics);uncertain data;uncertainty principle	Kia Bazargan;Samjung Kim;Majid Sarrafzadeh	1999	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.752923	chip;embedded system;floorplan;routing;electronic engineering;real-time computing;index term;reconfigurable computing;computer science;engineering;electrical engineering;control reconfiguration;adaptive system;integrated circuit;computer aided design;modular programming;integrated circuit layout;very-large-scale integration	Robotics	24.063468233469678	57.017111442856944	54335
71bee080bfd5bc1ddf983d94e2836bf9352e0e13	optimal test margin computation for at-speed structural test	statistical timing;shipped product quality loss;statistical timing analysis;process variation;circuit testing face detection manufacturing processes delay frequency voltage temperature aging semiconductor device modeling timing;quality control integrated circuit design integrated circuit testing;optimal test margin computation;yield shipped product quality loss statistical timing analysis test margin;optimal method;aging;yield;per chip test margin;chip;integrated circuit design;structural testing;manufacturing processes;process monitoring;semiconductor device modeling;test coverage;voltage;integrated circuit testing;per chip test margin optimal test margin computation at speed structural test statistical timing wafer testing scribe line structures on chip process monitoring circuitry;at speed structural test;age effect;scribe line structures;circuit testing;on chip process monitoring circuitry;temperature;product quality;face detection;frequency;quality control;test margin;wafer testing;timing	In the face of increased process variations, at-speed manufacturing test is necessary to detect subtle delay defects. This procedure necessarily tests chips at a slightly higher speed than the target frequency required in the field. The additional performance required on the tester is called test margin . There are many good reasons for margin, including voltage and temperature requirements, incomplete test coverage, aging effects, coupling effects, and accounting for modeling inaccuracies. By taking advantage of statistical timing, this paper proposes an optimal method of test margin determination to maximize yield while staying within a prescribed shipped product quality loss limit. If process information is available from the wafer testing of scribe-line structures or on-chip process monitoring circuitry, this information can be leveraged to determine a per-chip test margin which can further improve yield.	computation;electronic circuit;fault coverage;requirement;wafer testing	Jinjun Xiong;Vladimir Zolotov;Chandu Visweswariah;Peter A. Habitz	2009	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2009.2024709	chip;reliability engineering;yield;quality control;face detection;electronic engineering;semiconductor device modeling;real-time computing;voltage;wafer testing;temperature;computer science;engineering;frequency;test compression;code coverage;process variation;quantum mechanics;integrated circuit design	EDA	22.522689311176023	54.96964914349322	54381
89ec58de4b1dc15bf02c5ac4c1210aec2e4a0c39	clock-delayed domino for dynamic circuit design	dynamic circuit;carry logic;self timed dynamic logic family;synthese circuit;concepcion circuito;design tool;puerta logica;adder;metodologia;logic design;clocks;32 bit;inverting outputs;2 1 ns;scalable cmos design rules;circuit design;clocks circuit synthesis delay adders pulse inverters logic circuits cmos logic circuits logic design cmos process logic functions;adicionador;logic circuits;circuito logico;cmos process;tecnologia mos complementario;indexing terms;pulga electronica;methodologie;dynamic logic circuit;integrated circuit design clocks delays logic cad carry logic adders cmos logic circuits;chip;design rules;porte logique;dynamic logic;integrated circuit design;1 0 micron;clock delayed domino;single rail gates;conception logique;circuit logique;dynamic circuit design;grande vitesse;adders;cmos logic circuits;logic functions;carry look ahead;pulse inverters;dynamic logic clocking;sintesis circuito;conception circuit;gran velocidad;additionneur;self timed circuits;2 1 ns clock delayed domino dynamic circuit design self timed dynamic logic family single rail gates noninverting outputs inverting outputs logic design carry look ahead adder cmos process scalable cmos design rules 32 bit 0 8 micron 1 0 micron;methodology;inverting single rail dynamic gates;technologie mos complementaire;noninverting outputs;logic cad;concepcion logica;logic circuit;logic gate;puce electronique;high speed;circuit dynamique;0 8 micron;circuit synthesis;circuito dinamico;complementary mos technology;delays;carry look ahead adder;timing	Clock-delayed (CD) domino is a self-timed dynamic logic family developed to provide single-rail gates with inverting or noninverting outputs. CD domino is a complete logic family and is as easy to design with as static CMOS circuits from a logic design and synthesis perspective. Design tools developed for static CMOS are used as part of a methodology for automating the design of CD domino circuits. The methodology and CD domino's characteristics are demonstrated in the design of a 32-b carry look-ahead adder. The adder was fabricated with MOSIS's 0.8-/spl mu/m CMOS process with scalable CMOS design rules that allow a 1.0-/spl mu/m drawn gate length. Measurements of the adder show a worst case addition of 2.1 ns. The CD domino adder is 1.6/spl times/ faster than a dual-rail domino adder designed with the same cell library and technology.	circuit design	Gin Yee;Carl Sechen	2000	IEEE Trans. VLSI Syst.	10.1109/92.863622	electronic engineering;real-time computing;logic gate;computer science;electrical engineering;serial binary adder;adder	EDA	18.41893677924591	54.113191845388	54382
872d60ff5ffdf1b5a98c7a006abf738ba9b44c94	automatic design of optimal concurrent fault detector for linear analog systems	concurrent;state space methods;analogue computers;circuit faults;particle measurements;extended state space model;detection;residual;fault tolerant computing;fault detection electrical fault detection hardware signal processing state space methods redundancy mathematical model circuit faults voltage particle measurements;analogue computers error detection fault tolerant computing;redundancy;netlist;linear analog systems;signal processing;state space;fault detection;voltage;fault detector;netlist description;mathematical model;concurrent fault detection;optimal design;netlist description fault detector linear analog systems concurrent fault detection extended state space model;error detection;state space model;electrical fault detection;hardware	This paper presents a generalized strategy for optimal design of on-line integrated fault detector for linear analog systems. The method consists in processing the available node voltage signals to provide a residual signal that carries information about the faults. Contrary to previously proposed techniques dealing only with the particular case of state variable systems, the use of extra circuitry with the objective of concurrent fault detection is extended here without limitation to a larger class of linear analog systems for which the state variables do not necessary need to be available as measurable voltages. This requires the use of an extended state space model for any linear analog system. For this purpose, an algorithm providing the extended state space model from a netlist description is developed and implemented.	algorithm;analogue electronics;electronic circuit;error detection and correction;fault detection and isolation;fault model;maximal set;netlist;nonlinear system;online and offline;optimal design;state space;state-space representation	Emmanuel Simeu;Arno W. Peters;Iyad Rayane	1999	Digest of Papers. Twenty-Ninth Annual International Symposium on Fault-Tolerant Computing (Cat. No.99CB36352)	10.1109/FTCS.1999.781049	embedded system;electronic engineering;real-time computing;computer science	EDA	24.38414415112157	50.60601718397499	54463
62daba1a245e7ee13e96fcd1d8317dcf18a2f946	a built-in self-test scheme for differential ring oscillators	ring oscillators;voltage control;bist;circuit under test;circuit faults;fault coverage built in self test scheme differential ring oscillators bist voltage controlled ring oscillators circuit under test bridging faults digital fail pass indication signal;automatic testing;ring oscillator;digital fail pass indication signal;built in self test ring oscillators circuit testing circuit faults automatic testing voltage controlled oscillators voltage control electrical fault detection fault detection circuit simulation;circuit simulation;built in self test;voltage controlled ring oscillators;fault detection;integrated circuit testing;mixed analogue digital integrated circuits;built in self test scheme;bridging faults;voltage controlled oscillators;fault coverage;mixed analogue digital integrated circuits built in self test voltage controlled oscillators integrated circuit testing;circuit testing;electrical fault detection;differential ring oscillators	In this paper a new built-in self-test (BIST) scheme is proposed suitable for testing differential voltage controlled ring oscillators. The proposed testing-scheme is capable of detecting single realistic faults of the circuit under test. These faults can be either short or bridging faults between circuit nodes or open faults at the circuit branches. The test result is provided by a digital fail/pass indication signal. Exhaustive simulations have revealed the effectiveness of the proposed technique regarding its fault coverage.	bridging (networking);built-in self-test;built-in test equipment;fault coverage;sensor;shift register;simulation;test strategy;voltage-controlled oscillator	Lampros Dermentzoglou;Yiorgos Tsiatouhas;Angela Arapoyanni	2005	Sixth international symposium on quality electronic design (isqed'05)	10.1109/ISQED.2005.2	embedded system;electronic engineering;real-time computing;fault coverage;computer science;engineering;ring oscillator;fault detection and isolation	EDA	23.21023570495108	52.58096161239037	54496
0d5dd75515d5e2d04f3f65f2f21ee8197c6b257a	a functional approach to delay faults test generation for sequential circuits	delays logic testing sequential circuits;functional testing;optimization delay faults test generation sequential circuits functional test pattern generator functional fault model stuck at fault coverage undetected faults delay fault coverage;sequential circuits;pattern generation;logic testing;test generation;fault coverage;delay circuit faults circuit testing sequential circuits sequential analysis pattern analysis test pattern generators fault diagnosis electrical fault detection fault detection;fault model;delays	I n thzs paper we present an analysis of the coverage of delay fau l t s i n sequentaal circuzts by a functional test pat tern generator. Relationships are znvestigated between a functaonal fault model and delay faults, with correlatzons t o the stuck-at fau l t coverage. Undetected fau l t s are identified and an algorithm to zmpmve the delay fau l t coverage zs proposed. T h e final approach generates a functzonal test f o r seqtiential circnzts with optzmization and reaches complete coverage of detectable delay faults with short tests.	algorithm;fault model;functional approach;functional testing	Franco Fummi;Donatella Sciuto;Micaela Serra	1994		10.1109/EDTC.1994.326899	reliability engineering;electronic engineering;fault;real-time computing;fault coverage;fault indicator;stuck-at fault;automatic test pattern generation	EDA	21.634478540560455	51.29060638492751	54569
08e13f704bd1d39b34dbbccf44fde551a2903a2d	crosstalk constrained global route embedding	satisfiability;global routing;empirical model;capacity constraint	Route Embedding, a new method for mitigating the impact of crosstalk, is presented. It modifies a set of global-route structures to prevent timing and noise-margin violations caused by crosstalk, while maintaining routing constraints. An accurate and computationally-efficient empirical model for crosstalk impact is presented which by capturing noise and delay-changes on coupled conductors, permits a performance-driven approach to addressing crosstalk. Linearized crosstalk constraints are derived and satisfied for the expected noise and wire-delays at critical signal sinks. Unsatisfied constraints are resolved by inserting ground shields and by selective re-route through uncongested regions. Routing capacity constraints are enforced to guarantee a detailed routing solution.	crosstalk;noise margin;routing	Phiroze N. Parakh;Richard B. Brown	1999		10.1145/299996.300077	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;empirical modelling;satisfiability	EDA	16.52842011085015	52.29805678045566	54667
fdf69b741dd8ae56554d58c267282a81c64eed5b	temperature-adaptive energy reduction for ultra-low power-supply-voltage subthreshold logic circuits	cmos integrated circuits;ultra low power;cmos technology;low power electronics logic circuits logic design;fluctuations;high temperature;ultra low voltage;logic design;clocks;energy efficient;temperature sensors;logic circuits;adaptive dynamics;temperature adaptive energy reduction;elevated temperature;active mode energy consumption;high temperature energy efficiency temperature adaptive energy reduction ultralow power supply voltage constant frequency subthreshold logic circuit active mode energy consumption temperature adaptive dynamic supply voltage tuning technique;energy consumption;temperature adaptive dynamic supply voltage tuning technique;dynamic scaling;low power electronics;constant frequency subthreshold logic circuit;temperature;high temperature energy efficiency;integrated circuits;ultralow power supply voltage;logic circuits temperature energy consumption clocks dynamic voltage scaling timing circuit optimization energy efficiency degradation frequency;circuit optimization	Circuits optimized for minimum energy consumption operate typically in the subthreshold regime with ultra-low power-supply-voltages. Speed of subthreshold logic circuits is enhanced with an increase in the die temperature. The excessive timing slack observed in the clock period of constant-frequency subthreshold logic circuits at elevated temperatures provides new opportunities to lower the active mode energy consumption. Temperature-adaptive dynamic supply voltage tuning technique is proposed in this paper to enhance the high temperature energy efficiency of ultra-low-voltage subthreshold logic circuits. Results indicate that the energy consumption of subthreshold logic circuits can be lowered by up to 40% by dynamically scaling the supply voltage without degrading the clock frequency at elevated temperatures.	clock rate;digital electronics;image scaling;logic gate;power supply;ultra-low-voltage processor	Ranjith Kumar;Volkan Kursun	2007	2007 14th IEEE International Conference on Electronics, Circuits and Systems	10.1109/ICECS.2007.4511231	control engineering;electronic engineering;engineering;electrical engineering;pass transistor logic;subthreshold conduction	EDA	19.009563934141795	58.73388293417552	54742
213794771a6e41084a6d5f717e20a4d889bb86d3	power efficiency as the #1 design constraint: technical perspective	power efficiency	MooRE’S LAW,2 AND the associated observations on scaling by Bob Dennard,1 describe many of the key technical foundations that have given rise to the amazing growth of the modern semiconductor industry. But, taking a step back from these insightful assertions, we can see an even bigger picture emerge related to energy usage and power consumption. The earliest computers, such as the machine envisioned by Charles Babbage in 1822, were mechanical marvels. Although simultaneously amazing and underappreciated, they certainly set the stage for modern computing era. As it turns out, these machines consumed very large amounts of power (for the time), and were quickly replaced by more power-efficient, electro-mechanical, relay-based systems. This shift enabled larger machines with more capability, but they too soon hit the practical “power wall” of the time. In 1946, the first vacuum tube-based computers were designed, and once again, these set a new standard in capability and power efficiency for the day, eventually replacing the relay-based systems. This pattern repeated with the invention of the discrete transistor, the integrated circuit, the bipolar-based integrated circuits, and the FET-based integrated circuits. The key point here is that these technology transitions were driven in equal parts by the new capability they brought to light and the improved power efficiency they offered. That brings us to modern VLSIbased systems. Once again, our current technology of choice, CMOSbased integrated circuits in particular, has hit a modern day “power wall.” There are, of course, lots of highly innovative process technology tweaks and circuit design tricks to extend the life of the CMOS-based era, but these are really only buying time until a fundamentally new technology option becomes practical. Unfortunately, although there are several interesting contenders, it doesn’t appear any of these will be practical within the next decade. While the technologists and circuit designers continue to extend the life of CMOS, it is also time for computer architects to innovate on fundamentally more power-efficient algorithms and machine organizations. The following paper by Hameed et al. provides a deep dive into a specific application to highlight some of the most significant differences in power efficiency between a general-purpose processor and a specialpurpose ASIC. By looking at a range of design options associated with improving the power efficiency of a general-purpose processor running H.264 HD video encode, they uncover an option that effectively uses the instruction orchestration aspect of the general-purpose processor to control the sequencing through a pipeline of customized special-purpose blocks. The new complexity associated with these customized logic blocks notwithstanding, they illustrate a power efficiency improvement of nearly three orders of magnitude. The power efficiency and performance advantages of special-purpose ASICs versus general-purpose processors in not new, nor is it surprising. In fact, the essence of these differences is reflected in the computer architects’ mantra of “optimizing for the common case.” In the 1968 seminar paper “On the Design of Display Processors” by T.H. Myer and Ivan Sutherland, this trade-off between generality and complexity is particularly well described with relevant examples from that time period. In particular, they observe that the appropriate solution is both application and technology dependent, and from that, they coin the phrase “The Wheel of Reincarnation” to illustrate these shifting optimizations. But this paper goes a step beyond the general observation and quantitative analysis of a particular application. It also sets the stage for designing future machines that are prepared for higher-level hardware abstractions. This proposal implies some profound implications for application analysis, algorithm design, machine organization, and associated design methodologies. Combined, they may offer improvements in power efficiency, raw performance, and design productivity. This triple play is particularly significant at this point in time, as the industry must simultaneously work around the ongoing CMOS “power wall” while also investing to find that next technology to reset the power-efficiency bar.	algorithm design;application-specific integrated circuit;babbage;cmos;central processing unit;circuit design;complexity;computer;design closure;encode;general-purpose markup language;general-purpose modeling;h.264/mpeg-4 avc;performance per watt;reincarnation;relay;semiconductor industry;transistor	Charles R. Moore	2011	Commun. ACM	10.1145/2001269.2001290	electrical efficiency;computer science	Arch	11.158993664357489	57.49410062532574	54813
e30a94279dc76722af10791e89ca6c2441f4d49b	scaling cmos beyond si finfet: an analog/rf perspective		FinFET has been introduced in the 22/16nm node to continue CMOS logic scaling. The very tight pitches foreseen for the coming generation necessitate the introduction of different scaling boosters. In this paper, we review how these elements affect the analog device performance. The benefits of alternative channel material for dedicated RF applications and the related integration challenges are also discussed.	2.5d;analog device;cmos;image scaling;radio frequency	Bertrand Parvais;Geert Hellings;Marco Simicic;Pieter Weckx;Jérôme Mitard;Doyoung Jang;Veeresh Deshpande;B. van Liempc;A. Veloso;A. Vandooren;N. Waldron;Piet Wambacq;Nadine Collaert;Diederik Verkest	2018	2018 48th European Solid-State Device Research Conference (ESSDERC)	10.1109/ESSDERC.2018.8486857	electronic engineering;analog device;materials science;scaling;logic gate;cmos;gallium arsenide;communication channel	EDA	12.177573425275458	57.51951740104782	54833
8dbb1f45edfe56670a5b6ea54f553a68631b61b2	compact-2d: a physical design methodology to build commercial-quality face-to-face-bonded 3d ics		The recent advancement of wafer bonding technology offers fine-grained and silicon-space overhead-free 3D interconnections in face-to-face (F2F) bonded 3D ICs. In this paper, we propose a full-chip RTL-to-GDSII physical design solution to build high-density and commercial-quality two-tier F2F-bonded 3D ICs. The state-of-the-art flow named Shrunk-2D (S2D) requires shrinking of standard cells and interconnects by a factor of 50% to fit into the target 3D footprint of a two-tier design. This, unfortunately, necessitates commercial place/route engines that handle one node smaller geometries, which can be challenging and costly. Our flow named Compact-2D (C2D) does not require any geometry shrinking. Instead, C2D implements a 2D IC with scaled interconnect RC parasitics, and contracts the layout to the F2F design footprint. In addition, C2D offers post-tier-partitioning optimization that is shown to be effective in fixing timing violations caused by inter-tier 3D routing, which is completely missing in S2D. Lastly, we present a methodology to recycle the routing result of post-tier-partitioning optimization for final GDSII generation. Our experimental results show that at iso-performance, C2D offers up to 26.8% power reduction and 15.6% silicon area savings over commercial 2D ICs without any routing resource overhead.	electrical connection;mathematical optimization;multitier architecture;overhead (computing);physical design (electronics);place and route;routing;wafer bonding	Bon Woong Ku;Kyungwook Chang;Sung Kyu Lim	2018		10.1145/3177540.3178244	mathematical optimization;parasitic extraction;physical design;computer science;wafer bonding;electronic engineering	EDA	15.118084734341105	53.531815899743016	54841
20aa8b8582344da1263e934f55b1099fa3cbb405	a graph reduction approach to symbolic circuit analysis	symbolic circuit analysis;analogue circuits;graph reduction approach;large analog circuit;graph reduction process;new graph reduction approach;symbol manipulation;graph reduction;symbolic analog circuit simulator;binary decision diagram;recursive sign determination algorithm;frequency domain;graph theory;circuit simulation;analog circuits	A new graph reduction approach to symbolic circuit analysis is developed in this paper. A Binary Decision Diagram (BDD) mechanism is formulated, together with a specially designed graph reduction process and a recursive sign determination algorithm. A symbolic analog circuit simulator is developed using a combination of these techniques. The simulator is able to analyze large analog circuits in the frequency domain. Experimental results are reported.	algorithm;analogue electronics;binary decision diagram;electronic circuit simulation;graph reduction;network analysis (electrical circuits);recursion;symbolic circuit analysis	Guoyong Shi;Weiwei Chen;C.-J. Richard Shi	2007	2007 Asia and South Pacific Design Automation Conference		equivalent circuit;a symbolic analysis of relay and switching circuits;circuit diagram;discrete mathematics;analogue electronics;computer science;graph theory;theoretical computer science;graph reduction;circuit extraction;programming language;binary decision diagram;frequency domain;symbolic trajectory evaluation;algorithm	EDA	20.984273181066083	46.49589507005878	55019
4f7228d5b5ff9f88afbc54f6fe0ad4a4226fe11e	action: combining logic synthesis and technology mapping for mux-based fpgas	minimisation;field programmable gate array;minimization;sis structure;diagrama binaria decision;diagramme binaire decision;estructura sis;algorithme glouton;on line;en linea;logic;minimizacion;red puerta programable;reseau porte programmable;logic synthesis;structure sis;estructura datos;retard;fpgas;greedy algorithm;technology dependent synthesis;algoritmo gloton;en ligne;structure donnee;bdds;technology mapping;retraso;data structure;logique;logica;binary decision diagram	Technology mapping for Multiplexor (MUX) based field programmable gate arrays (FPGAs) has widely been considered. Here, a new algorithm is proposed that applies techniques from logic synthesis during technology mapping, i.e., the target technology is considered in the minimization process. Binary decision diagrams (BDDs) are used as an underlying data structure combining both structural and functional properties. The algorithm uses local don't cares obtained by a greedy algorithm. To evaluate a netlist, a fast technology mapper is used. Since most of the changes to a netlist are local, re-mapping can also be done locally, allowing a fast but reliable evaluation after each modification. Both area and delay minimization are addressed in this paper. We compare the approach to several previously published algorithms. In most cases these results can be further improved. Compared to SIS, an improvement of 23% for area and 18% for delay can be observed on average.	field-programmable gate array;logic synthesis;multiplexer	Wolfgang Günther;Rolf Drechsler	2000	Journal of Systems Architecture	10.1016/S1383-7621(00)00027-8	embedded system;parallel computing;data structure;telecommunications;computer science;theoretical computer science;algorithm;field-programmable gate array	EDA	16.521085268359524	50.48160549139238	55098
3352f04c095d5d9f8c1b50453d8899a9c69933e6	high-level synthesis for easy testability	design for testability;register allocation;testable designs;cad;high level synthesis design for testability circuit cad integrated circuit design;test analysis;high level synthesis circuit testing integrated circuit interconnections built in self test hardware costs circuit synthesis registers automatic testing robots;behavioral level;design quality;testability;optimized test area overhead;interconnection network;high level synthesis;integrated circuit design;interconnect network generation;circuit cad;datapath high level synthesis;design quality improvement;testable designs high level synthesis cad testability design quality improvement datapath high level synthesis register allocation interconnect network generation test analysis behavioral level optimized test area overhead	This paper presents an attempt towards design quality improvement by incorporation of testability features during datapath high-level synthesis. This method is based on the use of hardware sharing possibilities to improve the testability of the circuit without a time consuming re-synthesis process. This is achieved by incorporating test constraints during register allocation and interconnect network generation. The main features of this method are: a test analysis at the behavioral level rather than at a structural one; the non limitation on the behavioral descriptions (loops, control constructs are supported); and the optimized test area overhead and CPU time compared to standard approach. The method was applied to several benchmarks resulting in easily testable designs for almost the same area costs as the original (without testability) designs.	benchmark (computing);central processing unit;control flow;datapath;high- and low-level;high-level synthesis;overhead (computing);register allocation;software testability	Marie-Lise Flottes;D. Hammad;Bruno Rouzeyre	1995		10.1109/EDTC.1995.470392	computer architecture;electronic engineering;parallel computing;engineering;test compression	EDA	12.842100747233202	51.61533757675627	55195
053bfb93bbbc14661663df6cded6a061925b9ce2	industrial experience with adoption of edt for low-cost test without concessions	automotive engineering;design for testability;pulp manufacturing;automatic test pattern generation;automatic testing;design flow;manufacturing automation;data communication;wireless communication;system on chip;logic testing;automatic testing costs logic testing automatic test pattern generation manufacturing automation design for testability pulp manufacturing automotive engineering wireless communication data communication	This paper discusses the adoption of Embedded Deterministic Test (EDT) at Infineon Technologies as a means to reduce the cost of manufacturing test without compromising test quality. The System-onChip (SoC) design flow and the changes necessary to successfully implement EDT are presented. Experimental results for three SoC designs targeted for automotive, wireless, and data communication applications are provided. These results demonstrate that EDT, with no performance impact, little area overhead, and minimal impact to the flow, results in a significant reduction of scan test data volume and scan test time while maintaining the test quality levels.	event dispatching thread;fault coverage;overhead (computing);test data	Frank Poehl;Matthias Beck;Ralf Arnold;Peter Muhmenthaler;Nagesh Tamarapalli;Mark Kassab;Nilanjan Mukherjee;Janusz Rajski	2003		10.1109/TEST.2003.1271110	system on a chip;embedded system;computer science;engineering;design flow;automatic test pattern generation;design for testing;wireless;manufacturing engineering;computer engineering	EDA	10.088873497951719	55.12359586577904	55208
ab29befa041e7c91cc605f26977a5b7e687d8189	partitioning algorithms for layout synthesis from register-transfer netlists	circuit layout cad;i/o pin locations;critical paths;floorplan;general bit-sliced layouts;layout synthesis;overall area utilization;partitioning algorithms;register-transfer netlists;sliced-layout architecture;total wire length	A partitioning methodology that exploits the regularity of register-transfer components is presented, and partitioning algorithms that are used to generate the floor plan are described. The partitioning algorithms not only select the layout style best suited for each component, but also consider critical paths, I/O pin locations, and connections between components. This approach improves the overall area utilization and minimizes the wire length on the critical paths	algorithm;netlist	Allen C.-H. Wu;Daniel Gajski	1990		10.1109/ICCAD.1990.129864	computer architecture;electronic engineering;parallel computing;computer science;electrical engineering;critical path method;very-large-scale integration	EDA	14.52545138340557	51.998972539782656	55324
9a81fb07002ab1881bf851749606dc2947b35845	soc - the road ahead	optimal solution;cycle time;cmos integrated circuits;form factor;development process;system on a chip;circuit complexity;chip;integrated circuit design;technology scaling;system on chip;circuit optimisation system on chip integrated circuit design cmos integrated circuits circuit complexity integrated circuit reliability;next generation;integrated circuit reliability;circuit optimisation;cmos technology soc design semiconductor technology single chip integration	System-on-a-Chip is an evolving definition where a current generation system implemented with multiple chips on a board translates to a system-on-a-chip for the next generation. This is enabled by advances in the semiconductor technology which support increasing levels of single chip integration. For system components which can be efficiently implemented in CMOS, integrating them on a single chip (SoC) offers the most optimal solution in terms of die size, unit cost, form factor, power, performance and reliability. The SoC development process however implies longer cycle time and high NRE costs. This makes SoCs economically viable only for high volume, high NR applications. The increasing complexity of the systems coupled with the technology scaling challenges have significant negative impact on both the cycle time and the NRE costs. The SoC design challenge in business terms is then to improve execution efficiency at a rate faster than the complexity increase, so as to increase the TAM serviced by SoCs. This talk will cover the system and technology trends, highlight their implications and discuss directions to address the ever increasing SoC design challenge.	cmos;ibm tivoli access manager;image scaling;next-generation network;noise reduction;semiconductor;system on a chip	Mahesh Mehendale	2006		10.1109/VLSID.2006.149	system on a chip;embedded system;electronic engineering;real-time computing;computer science;engineering	EDA	11.560681641890191	56.871573381453906	55460
3d89b6824944360f902bd6cd74e8ff3a49dfb0a4	robust evaluation of weighted random logic bist structures in industrial designs	minimization;probability;logic design;boolean functions;probability built in self test cmos logic circuits logic design logic testing;polynomials;built in self test;logic gates;data structures;cmos logic circuits;logic testing;robustness;boolean functions data structures built in self test polynomials minimization robustness logic gates;memory consumption weighted random logic bist structures industrial designs signal probabilities wrl bist structures modern cmos designs on line in system tests safety applications automotive designs prelayout netlists post layout netlists	This paper presents a highly robust approach to exactly analyze signal probabilities of Weighted Random Logic (WRL) BIST structures. WRL BIST structures are implemented in modern CMOS designs to ensure high defect coverage for example during on-line in-system tests, which are executed periodically in safety applications as needed in automotive designs. Furthermore the paper describes a novel design flow which automatically identifies and evaluates WRL BIST structures in large industrial designs. The complete design flow from calculating the weighted random logic up to its automatic identification and evaluation in pre- and post-layout netlists is discussed in detail. The effectiveness of the new approach has been evaluated on 10 industrial designs and various other test cases. The results show that the memory consumption of the proposed technique does not grow despite of an immense increase of the circuit size.	automatic identification and data capture;cmos;line level;logic built-in self-test;online and offline;random logic;software bug;test case	Rene Krenz-Baath;Friedrich Hapke;Rolf Hinze;Reinhard Meier;Maija Ryynaenen;Andreas Glowatz	2012	2012 15th Euromicro Conference on Digital System Design	10.1109/DSD.2012.115	logic synthesis;logic optimization;logic level;data structure;logic gate;logic family;computer science;theoretical computer science;probability;sequential logic;boolean function;programming language;digital electronics;algorithm;robustness;polynomial	EDA	21.4122774632647	51.979957173494135	55512
680e7bcfae264574526f7ccb9c4d0ebee49e8ec9	efficient testing of clock regenerator circuits in scan designs	microprocessors;pulp manufacturing;test pattern generation;circuit faults;fault simulation;clocks;very large scale integration;clock regenerators;indexing terms;microprocessor testing;test pattern generators;permission;test generation;power generation;circuit testing clocks microprocessors hardware permission circuit faults pulp manufacturing test pattern generators very large scale integration power generation;circuit testing;test pattern generator;hardware	This paper describes the use of a high-level view (functionalview) of a clock regenerator circuit for generating effective andinexpensive manufacturing tests. It is shown that the tests generatedfrom the traditional, structural view add hardwareoverhead, increase design time and potentially lower effectiveyield when compared to the tests generated from the functionalview. A test generation procedure is described and successfullyused on a microprocessor design.	high- and low-level;microprocessor;processor design	Rajesh Raina;Robert Bailey;Charles Njinda;Robert F. Molyneaux;Charlie Beh	1997		10.1145/266021.266042	electricity generation;embedded system;electronic engineering;real-time computing;index term;computer science;engineering;electrical engineering;very-large-scale integration	EDA	19.539555099021563	50.75603658423538	55556
308bca3b25924726ba4056aec0236542873be068	input necessary assignments for testing of path delay faults in standard-scan circuits	circuit faults;circuit testing delay circuit faults fault diagnosis electrical fault detection fault detection polynomials benchmark testing compaction clocks;input necessary assignments;test generation broadside tests necessary assignments path delay faults scan circuits;longest path;indexing terms;data mining;runtime;test generation process;necessary assignments;compaction;benchmark circuits;polynomial time;standard scan circuits;test generation;path delay fault;broadside tests;circuit testing;path delay faults;scan circuits;benchmark testing;fault diagnosis;polynomial time path delay faults standard scan circuits test generation process benchmark circuits input necessary assignments	We consider the use of necessary assignments for input lines, referred to as input necessary assignments, as part of a test generation process for path delay faults in standard-scan circuits. Input necessary assignments are computed in polynomial time and provide a unified framework for identifying undetectable faults and generating tests for detectable faults. Within this framework, large numbers of path delay faults can be considered efficiently and accurately. The proposed test generation procedure is able to resolve large numbers of path delay faults associated with the longest paths in benchmark circuits by detecting the faults using broadside tests or showing that they are undetectable by such tests. We also consider the use of input necessary assignments for test compaction.	benchmark (computing);data compaction;longest path problem;polynomial;sensor;time complexity;unified framework	Irith Pomeranz;Sudhakar M. Reddy	2011	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2009.2031865	time complexity;compaction;benchmark;electronic engineering;real-time computing;index term;longest path problem;computer science;engineering;algorithm	EDA	21.149582538201702	50.93806939177711	55729
2227c076e78bb87aad8718c860a346056535c9f2	operational simulation of an x-ray lithography cell: comparison of 200mm and 300mm wafers	performance measure;critical dimension;integrated memory circuits x ray lithography production control semiconductor device manufacture simulation;integrated memory circuits;simulation;chip;memory chips operational simulation x ray lithography cell semiconductor wafer fab proximity x ray lithography computer chips simulation model synchrotron exposure radiation unit cell design processing times semi e 10 equipment states 200 mm wafers 300 mm wafers average wafer throughput number of chips per wafer;simulation experiment;production control;semiconductor device manufacture;next generation;simulation model;x rays;x ray lithography synchrotrons throughput production costs semiconductor device modeling frequency estimation ultraviolet sources systems engineering and theory microelectronics;x ray lithography	We review progress on a project to evaluate prospec operations in a semiconductor wafer fab that employs n generation, proximity X-ray lithography to pattern th critical dimensions of computer chips. A simulation mod is developed that captures the processing of wafers thro an X-ray lithography cell using a synchrotron as the sou of exposure radiation. The model incorporates the b current information on unit-cell design and process times and implements a range of events that interrupt flow of wafers processing on the cell. Performan measures estimated from the simulation include the wee throughput for the cell and the frequency of SEMI Eequipment states for the corresponding exposure t Simulation experiments are conducted to compare performance of a cell fabricating 200mm wafers with th of a cell fabricating 300mm wafers, for each of thr different chip sizes. Results illustrate the anticipa dependence of average wafer throughput on wafer size assumptions regarding the number of chips per wafer, w a maximum of approximately 3400 wafers/week f 200mm wafers with 25x25mm field size. Ignoring wafe sort losses, however, a maximum throughput approximately 410,000 chips/week is realized for 300m wafers with 11x22mm fields. Remarkably, the distributi of equipment states remains relatively unchanged ac simulation experiments.	experiment;integrated circuit;maximum throughput scheduling;reflow soldering;semiconductor fabrication plant;simulation;wafer (electronics)	K. Preston White;Walter J. Trybula	1999		10.1145/324138.324540	chip;electronic engineering;simulation;computer science;electrical engineering;simulation modeling;x-ray lithography;critical dimension	HPC	13.603506851085958	59.22364563201664	55801
ad6e649b931f042172543f5af0cf05ef271a2fc5	proteus : a logic verification system for combinational circuits	combinational circuit		combinational logic	Alberto L. Sangiovanni-Vincentelli;Ruey-Sing Wei	1986			computer science;electronic engineering;logic optimization;boolean circuit;sequential logic;computer architecture;programmable logic device;combinational logic	EDA	19.24934248695849	47.206065463508466	55808
d15e261d70df4008b79b5c37e179676c91f375a0	formal verification of clock domain crossing using gate-level models of metastable flip-flops		Verifying clock domain boundary logic is a major challenge to the design of modern multi-clock systems. We present a novel verification approach that addresses the issue of domain crossing failures at a fundamental level. The approach relies on substituting flip-flops with model circuits and applying topological transformations to simulate the transfer of timing violations in gate-level netlists. This makes timing violations and their effects reproducible in discrete cycle-based simulation and amenable for identification and debugging similar to typical synchronous design failures. We show that this approach, when combined with formal verification, is inherently capable of reproducing many of the problematic issues at clock domain boundaries and outperforms the structural and functional heuristics used by state of the art commercial tools in several respects. It reports fewer false positives, can be applied to non-stereotypical designs, can determine failure consequences, can demonstrate failures in signal waveforms and requires no input from the designer about what design patterns are used. Case examples and verification results of several multi-clock testbench designs are presented.	clock signal;debugging;design pattern;flops;finite-state machine;flip-flop (electronics);formal verification;glitch;heuristic (computer science);input/output;lossy compression;metastability in electronics;pixel;simulation;software propagation;synchronous circuit;test bench;throughput	Ghaith Tarawneh;Andrey Mokhov;Alexandre Yakovlev	2016	2016 Design, Automation & Test in Europe Conference & Exhibition (DATE)		market research;embedded system;synchronization;electronic engineering;real-time computing;logic gate;telecommunications;clock domain crossing;formal verification;computer science;electrical engineering;theoretical computer science;operating system;programming language;metastability;algorithm;functional verification	EDA	21.460143688984637	56.84713838623076	55855
b7e277906b51f653f52414b695cb210b9a1e3f4d	a scan disabling-based bast scheme for test cost and test power reduction	scan chain disabling;test power reduction;test data volume compression;design for testability dft			Zhiqiang You;Weizheng Wang;Peng Liu;Jishun Kuang;Zheng Qin	2012	IEICE Electronic Express	10.1587/elex.9.111	electronic engineering;engineering;test compression;forensic engineering;engineering drawing	EDA	20.83270187386553	53.35925688035937	55868
2e7c699a10db4f96966b1df6ec4051284d8fecd0	a 32-bit, 200-mhz gaas risc for high-throughput signal processing environments	silicon;fabrication;microprocessors;reduced instruction set computing;iii v semiconductor materials;chip;gallium arsenide;signal processing;process control;assembly systems;high throughput;communication system control;gallium arsenide reduced instruction set computing signal processing microprocessors communication system control process control silicon fabrication iii v semiconductor materials assembly systems	GaAs technology has matured sufficiently to allow fabrication of an entire RISC on one chip. GaAs also supports 200-MHz clock rates and 100-MIPS instruction rates.	32-bit;clock rate;semiconductor device fabrication;signal processing;throughput	Barbara A. Naused;Barry K. Gilbert	1987	IEEE Micro	10.1109/MM.1987.304908	chip;high-throughput screening;embedded system;reduced instruction set computing;gallium arsenide;telecommunications;computer science;operating system;signal processing;process control;silicon;fabrication	Arch	13.921335376412012	58.803400825938624	55965
15cfc8bde62506ccebd5159603ba22b494c860d3	semi-analytical current source modeling of near-threshold operating logic cells considering process variations	statistical timing analysis;process variation;process variation near threshold computing statistical timing analysis current source modeling;current source modeling;near threshold computing	Operating circuits in the ultra-low voltage regime results in significantly lower power consumption but can also degrade the circuit performance. In addition, it leads to higher sensitivity to various sources of variability in VLSI circuits. This paper extends the current source modeling (CSM) technique, which has successfully been applied to VLSI circuits to achieve very high accuracy in timing analysis, to the near-threshold voltage regime. In particular, it shows how to combine non-linear analytical models and low-dimensionality CSM lookup tables to simultaneously achieve modeling accuracy, space and time efficiency, when performing CSM-based timing analysis of VLSI circuits operating in near-threshold regime and subject to process variability effects.	community climate system model;current source;heart rate variability;lookup table;nonlinear system;semiconductor industry;static timing analysis;very-large-scale integration	Qing Xie;Tiansong Cui;Yanzhi Wang;Shahin Nazarian;Massoud Pedram	2013	2013 IEEE 31st International Conference on Computer Design (ICCD)	10.1109/ICCD.2013.6657079	electronic engineering;real-time computing;computer science;electrical engineering;process variation	EDA	21.650572873006453	58.65328186379781	55987
2c545ddc7f67159005aa9b3582297c2e66101bf1	minimization of the expected path length in bdds based on local changes	low power;low maximal;expected path length;local change;average path delay;bdd size;low cost;low area overhead;evaluation time;bdd minimization;time complexity;minimization;boolean functions;chip;circuits;data structures;logic synthesis;pass transistor logic;logic	In many verification tools methods for functional simulation based on reduced ordered Binary Decision Diagrams (BDDs) are used. The evaluation time for a BDD can be crucial and is measured by the expected path length of the BDD.In this paper a new technique for BDD minimization with respect to the expected path length is suggested to reduce evaluation time. It is based on sifting and, unlike previous approaches, performs variable swaps with the same time complexity as the original sifting algorithm.Another field of application for BDDs is logic synthesis, often targeting Pass Transistor Logic (PTL) because of low power and low cost. A minimization of BDD size and chip area can lead to poor timing performances. We suggest to also use our method here, as the resulting BDDs show a very low maximal and average path delay. This supports the synthesis of high-speed PTL circuits at low area overhead.Exprimental results are given to show the efficiency of our approach.	algorithm;binary decision diagram;logic simulation;logic synthesis;maximal set;overhead (computing);pass transistor logic;performance;time complexity	Rüdiger Ebendt;Wolfgang Günther;Rolf Drechsler	2004	ASP-DAC 2004: Asia and South Pacific Design Automation Conference 2004 (IEEE Cat. No.04EX753)	10.1145/1015090.1015321	chip;time complexity;electronic engineering;logic synthesis;data structure;computer science;theoretical computer science;pass transistor logic;mathematics;logic;algorithm	EDA	18.14960042908741	52.08704439486405	55997
5eac89e3ce9c3cad1b6360cc851c672c609ac396	srsl pipelining of coarse-grain datapaths	oscillations;fifos;clockless handshake mechanism;coarse grain synchronization;synchronisation;logic gates;combinational network;embedded logic;synchronisation combinational circuits logic gates pipeline arithmetic;coarse grain synchronization srsl pipelining coarse grain datapaths self resetting stage logic embedded logic fifos clockless handshake mechanism reset network combinational network;srsl pipelining;reset network;coarse grain datapaths;coarse grained;self resetting stage logic;pipeline arithmetic;combinational circuits	In this paper, we propose a clockless handshake mechanism based on self-resetting stage logic targeted for pipelined datapaths. In this logic, a stage resets itself after it completes the evaluation of its embedded logic. As such, a stage oscillates between a reset phase and an evaluate phase thus completing a single period. This handshake mechanism is incorporated into two distinct pipelines where its coordination is limited to each pair of neighboring stages in the first pipeline, while it is driven by the last stage in the second pipeline. Implementation results of both pipelines show that they can reach throughputs of several hundred Mega outputs per second, while they can easily reach the 1.4 Giga outputs per second if implemented as FIFOs.	asynchronous circuit;datapath;embedded system;fifo (computing and electronics);offset binary;pipeline (computing);throughput	Abdelhalim Alsharqawi;Abdel Ejnioui	2005	2005 12th IEEE International Conference on Electronics, Circuits and Systems	10.1109/ICECS.2005.4633511	electronic engineering;parallel computing;real-time computing;computer science	EDA	13.970614348938934	60.03002437800663	56120
bd89b7233bf78ab6e5f06e89bad080e437cd7257	an unconventional computing technique for ultra-fast and ultra-low power data mining	software based solution ultra fast ultra low power data mining unconventional computing technique probabilistic based pattern recognition analysis smart pulse based stochastic logic block;data mining;pattern recognition;databases logic gates probabilistic logic data mining clocks switches;probabilistic logic data mining logic gates pattern recognition;data mining stochastic logic pattern recognition;stochastic logic	In this work we review the basic principles of stochastic logic and propose its application to probabilistic-based pattern-recognition analysis. The proposed technique is the implementation of a parallel comparison of data with respect to various pre-stored categories. We design smart pulse-based stochastic-logic blocks to provide an efficient pattern recognition analysis. The proposed architecture can speed-up the screening process of huge databases by two orders of magnitude with respect classical software-based solutions, thus implying a great improvement in terms of total performance (speed and power dissipation).	algorithm;comparator;data mining;database;digital electronics;electronic circuit;mined;pci express;pattern recognition;unconventional computing	Vicent Canals;Antoni Morro;Antoni Oliver;Miquel L. Alomar;Josep L. Rosselló	2015	2015 25th International Workshop on Power and Timing Modeling, Optimization and Simulation (PATMOS)	10.1109/PATMOS.2015.7347585	logic synthesis;logic optimization;probabilistic ctl;computer science;theoretical computer science;machine learning;data mining;sequential logic	EDA	14.739703094995049	58.06627182101556	56209
fe3faf1bd35cb104a5a0a79d5c45ccd29221b427	a low-power enhanced bitmask-dictionary scheme for test data compression	system on chip integrated circuit design integrated circuit testing low power electronics;dictionaries vectors test data compression indexes hardware encoding switches;power consumption low power enhanced bitmask dictionary scheme test data compression system on chip digital design testing slice partitioning multiple dictionaries bitmask approach slice bit reordering method compression efficiency;test compression;dictionary;bitmask;low power scan testing;low power scan testing test compression dictionary bitmask	Long test application time for a System on Chip (SoC) is a major problem in digital design testing. This problem mostly originates from large test data. High volume test data not only increases required ATE memory and bandwidth, but also increases test time. Test compression reduces test data volume without any impact on its coverage. This work proposes two novel efficient test data compression schemes. These schemes suggest a slice partitioning along with a multiple dictionaries bitmask approach, and also a slice bit reordering method. These approaches are combined with low power method to decrease power consumption without sacrificing compression efficiency. Experimental results show improvements in compression efficiency and power consumption when compared with the existing works.	data compression;dictionary;logic synthesis;mask (computing);power iteration;system on a chip;test compression;test data	Vahid Janfaza;Payman Behnam;Behjat Forouzandeh;Bijan Alizadeh	2014	2014 IEEE Computer Society Annual Symposium on VLSI	10.1109/ISVLSI.2014.103	data compression ratio;electronic engineering;parallel computing;computer science;theoretical computer science;test compression	EDA	19.790229163004046	53.11136062779741	56213
70fc4988b171888626f8c99e554f625291062aef	nim- a noise index model to estimate delay discrepancies between silicon and simulation	cmos integrated circuits;spice;circuit simulation;delay estimation;integrated circuit design;integrated circuit modelling;integrated circuit noise;logic design;timing circuits;cmos technology;spice simulation;circuit design;delay discrepancy;delay estimation;dynamic ir-drop;noise index model;path delay;presilicon modeling;silicon measurement;silicon timing;size 65 nm;switching activity;timing discrepancy;timing mismatch;timing specification;ir-drop;path delay test;performance test;post-silicon measurement;power supply noise;timing mismatch	As CMOS technology continues to scale, the accurate prediction of silicon timing through the use of pre-silicon modeling and analysis has become especially difficult. These timing mismatches are important because they make it hard to accurately design circuits that meet timing specifications at first-silicon. Among all the parameters leading to the timing discrepancy between simulation and silicon, this paper studies the effect of dynamic IR-drop on the delay of a path. We propose a noise index model, NIM, which can be used to predict the mismatch between expected and real path delays. The noise index considers both the proximity of switching activity to the path and physical characteristics of the design. To evaluate the method, we performed silicon measurements on randomly selected paths from an industrial 65nm design and compared these with Spice simulations. We show that a very strong correlation exists between the noise index model and the deviations between simulations and silicon measurements.	cmos;delay calculation;discrepancy function;nim;randomness;spice;simulation	Elif Alpaslan;Jennifer Dworak;Bram Kruseman;Ananta K. Majhi;Wilmar M. Heuvelman;Paul van de Wiel	2010	2010 Design, Automation & Test in Europe Conference & Exhibition (DATE 2010)			EDA	22.389320674843315	57.47823563925631	56299
41d924c57963202a74a174ec7e5936e0cb88a251	fast hierarchical test path construction for circuits with dft-free controller-datapath interface	controller datapath circuit;test generation;transparency;fault coverage;influence tables;hierarchical test path;exhaustive search	Hierarchical approaches address the complexity of test generation through symbolic reachability paths that provide access to the I/Os of each module in a design. However, while transparency behavior suitable for symbolic design traversal can be utilized for constructing reachability paths for datapath modules, control modules do not exhibit transparency. Therefore, incorporating such modules in reachability path construction requires exhaustive search algorithms or expensive DFT hardware. In this paper, we discuss a fast hierarchical test path construction method for circuits with DFT-free controller-datapath interface. A transparency-based RT-Level hierarchical test generation scheme is devised for the datapath, wherein locally generated vectors are translated into global design test. Additionally, the controller is examined through the introduced concept of influence tables, which are used to generate valid control state sequences for testing each module through hierarchical test paths. Fault coverage and vector count levels thus attained match closely those of traditional test generation methods, while sharply reducing the corresponding computational cost and test generation time.	algorithmic efficiency;backtracking;brute-force search;computation;datapath;decision table;fault coverage;overhead (computing);reachability;search algorithm;software design	Yiorgos Makris;Jamison Collins;Alex Orailoglu	2002	J. Electronic Testing	10.1023/A:1013723905896	reliability engineering;embedded system;electronic engineering;real-time computing;fault coverage;computer science;theoretical computer science;automatic test pattern generation;machine learning;brute-force search;transparency;algorithm	EDA	19.90613085023862	47.811385823136355	56312
493b2112d87dd986c4675d1c308d2ae7d14afd7d	boolean process-an analytical approach to circuit representation (ii)	design for testability;timing behavior;input transitions;logic design;boolean functions;circuit analysis circuit testing timing delay boolean algebra very large scale integration logic hardware clocks circuit synthesis;waveform polynomials;design for testability boolean functions vlsi integrated circuit design logic design polynomials waveform analysis timing;vlsi design;polynomials;boolean algebra;integrated circuit design;circuit analysis hazards very large scale integration timing circuit testing boolean functions propagation delay logic testing data structures polynomials;vlsi circuits;waveform functions;circuit representation;vlsi;waveform functions boolean process circuit representation vlsi design performance factors logical design vlsi circuits circuit timing behavior boolean variables edge sequence ladder function timing behavior ic design test pair multiple transition delay testing delay control;circuit delay boolean process logical design vlsi circuits performance enhancement circuit representation timing behavior logical behavior waveform functions mathematical tools waveform polynomials input transitions;circuit delay;boolean process;circuit cad;integrated logic circuits;performance enhancement;logical behavior;waveform analysis;logical design;mathematical tools;circuit cad vlsi integrated circuit design boolean algebra logic design integrated logic circuits delays;delays;timing	One of the most important and challenging problems in today's VLSI design is that of incorporating performance factors in the physical and logical design of VLSI circuits. In order to precisely describe circuit timing behavior, an analytical approach is introduced in this paper. A Boolean process is defined, which is a family of Boolean variables relevant to the time parameter t. A real-valued sample of a Boolean process is a waveform. Any waveform is an expression of a basic waveform. The edge sequence of a waveform is represented by a ladder function. This analytical approach enables us to describe the circuit timing behavior in an accurate way, and is applicable to IC design and test. Interestingly, it is suggested that a test pair with multiple transition might be efficient for delay testing if the initial delay can be controlled. >		Yinghua Min;Zhuxing Zhao;Zhongcheng Li	1995		10.1109/ATS.1995.485312	boolean circuit;and-inverter graph;circuit minimization for boolean functions;electronic engineering;discrete mathematics;boolean network;computer science;engineering;theoretical computer science;mathematics;very-large-scale integration	EDA	20.724681244226595	46.75293545400133	56349
6ba18b41028cbb90da3a543083d9a9587db0cede	efficient diagnosis of scan chains with single stuck-at faults	silicon;design for testability;scan chain;circuit faults;integrated circuit yield;clocks;scan chain fault location;very large scale integration;flip flops;cell flip flop;yield improvement;testing;scan chains;data mining;ic manufacturers;failure analysis;logic testing design for testability failure analysis fault location flip flops integrated circuit testing integrated circuit yield integrated logic circuits;ieee;fault diagnosis flip flops design for testability testing failure analysis fault location very large scale integration costs hardware computer science;design for testa;single stuck at fault;logic testing;integrated circuit testing;design for testability scan chain fault location single stuck at fault ic manufacturers yield improvement failure analysis scan chains cell flip flop;computer science;integrated logic circuits;diagnosis;design for testa diagnosis scan chain fault location;flip flop;fault diagnosis;hardware;fault location	Locating the scan chain fault is a critical step for IC manufacturers to analyze failure for yield improvement. In this paper, we propose a diagnosis scheme to locate the single stuck-at fault in scan chains. Our diagnosis scheme is an improved design to a previously proposed scheme which can diagnose the output of each cell flip-flop in the scan chain. With our scheme, not only the output of each cell flip-flop can be diagnosed, but also the inverse output of each cell flip-flop and the serial input of the scan chain as well. Our proposed diagnosis scheme is efficient and takes (4n+6) clock cycles in the worst case for an n-bit scan chain.	best, worst and average case;clock signal;flops;find first set;flip-flop (electronics);scheme;stuck-at fault	Hsin-Chou Chi;Hsi-Che Tseng;Chih-Ling Yang	2009	2009 43rd Annual Conference on Information Sciences and Systems	10.1109/CISS.2009.5054767	embedded system;failure analysis;scan chain;real-time computing;computer science;design for testing;software testing;very-large-scale integration;silicon	EDA	21.090545088304246	52.036434236724155	56357
9ed63ac6dc98797cc8d96eb2871d681f33e69d63	on the effects of test compaction on defect coverage	test sets;test compaction;surrogate faults;test generation test compaction defect coverage test sets fault modeling surrogate faults;fault modeling;integrated circuit testing fault diagnosis;integrated circuit testing;test generation;defect coverage;fault diagnosis;compaction circuit faults fault detection circuit testing cities and towns electrical fault detection physics computing delay voltage test pattern generators	We study the effects of test compaction on the defect coverage of test sets for modeled faults. Using a framework proposed earlier, defects are represented by surrogate faults. Within this framework, we show that the defect coverage does not have to be sacrificed by test compaction, if the test set is computed using appropriate test generation objectives. Moreover, two test sets, one compacted and one non-compacted, generated using the same test generation objectives, typically have similar defect coverages, even if the compacted one is significantly smaller than the uncompacted one. Test generation procedures and experimental results to support these claims are presented.	data compaction;software bug	Sudhakar M. Reddy;Irith Pomeranz;Seiji Kajihara	1996		10.1109/VTEST.1996.510889	structural engineering;reliability engineering;electronic engineering;fault coverage;engineering;stuck-at fault;automatic test pattern generation;test compression	SE	21.9948469317109	53.18578607156914	56449
7abd9c4e0b3c2f19c68690e037d3d2c30bd63b10	a temperature-aware time-dependent dielectric breakdown analysis framework	reliability;technology scaling;time dependent dielectric breakdown;complex system;critical path;inter metal dielectric leakage;timing	The shrinking of interconnect width and thickness, due to technology scaling, along with the integration of low-k dielectrics, reveal novel reliability wear-out mechanisms, progressively affecting the performance of complex systems. These phenomena progressively deteriorate the electrical characteristics and therefore the delay of interconnects, leading to violations in timing-critical paths. This work estimates the timing impact of Time-Dependent Dielectric Breakdown (TDDB) between wires of the same layer, considering temperature variations. The proposed framework is evaluated on a Leon3 MP-SoC design, implemented at a 45nm CMOS technology. The results evaluate the system's performance drift due to TDDB, considering different physical implementation scenarios.		Dimitris Bekiaris;Antonis Papanikolaou;Christos Papameletis;Dimitrios Soudris;George Economakos;Kiamal Z. Pekmestzi	2010		10.1007/978-3-642-17752-1_8	complex systems;electronic engineering;electrical engineering;critical path method;reliability;statistics	Vision	20.66739655739676	58.735298224878974	56472
2880ce4ba3a01f4bfe41e9223519c0cdb72491d4	a low cost test data compression technique for high n-detection fault coverage	logic testing automatic test pattern generation data compression;data compression;stuck at faults low cost test data compression technique high n detection fault coverage weighted random pattern testing atpg;test data compression;automatic test pattern generation;pattern generation;costs test data compression circuit faults circuit testing test pattern generators automatic test pattern generation automatic testing fault detection national electric code system testing;compression test;weighted random pattern testing;low cost test data compression technique;stuck at faults;logic testing;fault coverage;test pattern generator;high n detection fault coverage;atpg	This paper presents a test data compression scheme that combines weighted random pattern testing and LFSR reseeding. Test patterns generated by the proposed decompressor can achieve high n-detection fault coverage. The proposed technique computes weight sets from a set of test cubes that are generated by a traditional 1-detection ATPG tool. The computed weight sets are modified to achieve high n-detection fault coverage. The proposed decompressor can be implemented with low area overhead. Since the proposed technique requires no special ATPG that is customized for the proposed scheme, it can compress test patterns generated by any ATPG tool and generate test patterns from the compressed test data that achieve high n-detection fault coverage. Experimental results show that test patterns generated by the proposed decompressor can achieve very high 5-detection stuck-at fault coverage and high compression for large benchmark circuits.	benchmark (computing);data compression;fault coverage;linear-feedback shift register;olap cube;overhead (computing);pseudorandomness;random testing;rough set;sion's minimax theorem;stuck-at fault;test card;test data;test set	Seongmoon Wang;Zhanglei Wang;Wenlong Wei;Srimat T. Chakradhar	2007	2007 IEEE International Test Conference	10.1109/TEST.2007.4437612	reliability engineering;electronic engineering;real-time computing;fault coverage;computer science;engineering;stuck-at fault;automatic test pattern generation;test compression	EDA	20.537931774648776	51.82212645820862	56672
1569b28746687ac8a24a6fb44d5fbc8d7e735dec	testability analysis and fault modeling of bicmos circuits	defects;testability;faults;fault coverage;fault model;modeling;logic gate;bicmos	Defect models have been used for testability analysis of BiCMOS circuits and the results have been compared with an analysis of CMOS circuits. Using a nominal point approach, faults generated are classified as logical or performance degradation faults. It is found that logical fault testing can only cover a small percentage of the total fault set, 54% for BiCMOS, versus 69% for equivalent CMOS gates. Delay faults and current faults are analyzed as applied to BiCMOS and CMOS gates. It is shown that logical fault testing in conjunction with either delay fault testing or current fault testing promises the highest fault coverage for BiCMOS logic gates, around 95%.	bicmos;cmos;elegant degradation;fault coverage;logic gate;software bug	Dhamin Al-Khalili;Come Rozon;B. Stewart	1992	J. Electronic Testing	10.1007/BF00134731	testability;embedded system;electronic engineering;real-time computing;systems modeling;fault coverage;logic gate;engineering;stuck-at fault;fault model;fault;bicmos	EDA	22.664106728543985	53.824994024937986	56695
bd81b65860195669f607b1a4f4cef5e55e2f3eac	known-good-die test methods for large, thin, high-power digital devices		The testing of large high-power devices which are destined for 2.5D or 3D applications requires many new techniques and solutions. This paper discusses some of the tradeoffs we looked at when striving to achieve true Known-Good-Devices (KGD) of large thin high-power logic devices. It is expected that the approach explored with this effort will significantly improve the post-assembly 2.5D/3D yield by bringing forward various high and low temperature tests which previously have not been possible to do. This paper discusses the challenges with wafer probing of this class of devices, analyzes the value of doing pre-insertion and/or partial assembly testing of this type of device. Also discussed in this paper are the various steps used to confirm the appropriateness of a recently introduced probe solution, Advantest HA1000, for meeting the demanding needs of singulated die level testing.	2.5d;3d computer graphics;assembly language;die (integrated circuit);experiment;franco iacomella;jones calculus;norm (social);pete becker;power semiconductor device;semiconductor device fabrication;system on a chip;wafer (electronics)	Dave Armstrong;Gary Maier	2016	2016 IEEE International Test Conference (ITC)	10.1109/TEST.2016.7805851	embedded system;electronic engineering;telecommunications;engineering;electrical engineering	EDA	11.658243883253354	57.61642420610056	56980
cfcbc759a4540f14d935a6445186b3a986e2e232	effective corner-based techniques for variation-aware ic timing verification	verification;timing corner variability verification;process variation;timing integrated circuit modeling laboratories process design design engineering digital integrated circuits delay information systems computer science knowledge engineering;information systems;integrated circuit;design engineering;corner;clocks;space exploration;process design;upper bound;digital integrated circuits;integrated circuit modeling;computer science;variability;process engineering;timing;knowledge engineering	Traditional integrated circuit timing sign-off consists of verifying a design for a set of carefully chosen combinations of process and operating parameter extremes, referred to as corners. Such corners are usually chosen based on the knowledge of designers and process engineers, and are expected to cover the worst-case fabrication and operating scenarios. With increasingly more detailed attention to variability, the number of potential conditions to examine can be exponentially large, more than is possible to handle with straightforward exhaustive analysis. This paper presents efficient yet exact techniques for computing worst-delay and worst-slack corners of combinational and sequential digital integrated circuits. Results show that the proposed techniques enable efficient and accurate detection of failing conditions while accounting for timing variability due to process variations.	best, worst and average case;branch and bound;combinational logic;computation;failure;heart rate variability;integrated circuit;relevance;slack variable;static timing analysis;verification and validation	Luís Guerra e Silva;Joel R. Phillips;Luís Miguel Silveira	2010	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2009.2034343	process design;embedded system;electronic engineering;verification;simulation;computer science;engineering;electrical engineering;space exploration;integrated circuit;knowledge engineering;upper and lower bounds;process variation;information system;algorithm;computer engineering	EDA	23.68705133707577	57.00385612901594	56998
abd67737262c5becd635041ea22feea1507e9925	reducing power consumption with relaxed quasi delay-insensitive circuits	global routing networks;2 phase buffer;rails;signal generators;qdi;circuit template;converters;global routing networks dynamic power consumption relaxed quasidelay insensitive circuits circuit template voltage converters asynchronous channels nonperformance critical components multiple voltage domains 2 phase buffer static switching networks;mosfets;clocks;two phase;multiple voltage domains;voltage converters;convertors;wires;logic circuits;fpga;dynamic power consumption;buffer circuits;energy consumption delay voltage logic circuits asynchronous circuits timing robustness power generation signal generators clocks;low voltage;relaxed quasidelay insensitive circuits;static switching networks;quasi delay insensitive;two phase asynchronous qdi fpga voltage scaling;energy consumption;global routing;high voltage;voltage;delay circuits;power generation;robustness;asynchronous circuits;delay circuits asynchronous circuits buffer circuits convertors;power consumption;switches;voltage scaling;switching network;nonperformance critical components;asynchronous;asynchronous channels;timing	This paper introduces novel circuits to mitigatepower consumption in asynchronous logic. By exposing a preexisting timing assumption in quasi-delay insensitive (QDI) circuits, we develop a set of circuit templates that reduce dynamic power consumption while maintaining the robustness of QDI circuits. We refer to these as relaxed quasi delay-insensitive circuits (RQDI). Power consumption is reduced in four ways. First, we present a circuit template that saves power by reducing the logic required to generate enable/acknowledge signals. Second, we develop voltage converters for asynchronous channels that allow non-performance critical components to be moved to lower voltage domains. Third, we propose a circuit template that improves upon the use of multiple voltage domains by keeping the data logic in the high voltage domain, but moves the enable/acknowledge logic to the low voltage domain. Fourth, we utilize a novel 2-phase buffer to half the switching in global routing and static switching networks. Experiments show that we can reduce energy by 30-50%, with a minimal impact on area and performance.	asynchronous circuit;benchmark (computing);bounce address;delay insensitive circuit;dynamic voltage scaling;integrated circuit;network switch;overhead (computing);phase converter;routing	Christopher LaFrieda;Rajit Manohar	2009	2009 15th IEEE Symposium on Asynchronous Circuits and Systems	10.1109/ASYNC.2009.9	control engineering;electronic engineering;real-time computing;asynchronous circuit;computer science	EDA	16.955776698347748	55.84538514422482	57039
04f8e8a43af954493c88ea1900ccdd73fb7f3d35	high-performance routing at the nanometer scale	algorithms;cad;very large scale integration (vlsi);network routing;core routing;global routing contest;vlsi;negotiated-congestion routing;high-performance routing;nanometer scale;nanometer scale routing;fgr router;vlsi;design automation;integrated circuit design;routing;computer-aided design;nanoelectronics	In this work we describe significant improvements to core routing technologies and outperform the best results from the ISPD '07 Global Routing Contest, as well as previous literature, in terms of route completion, runtime and total wirelength. In particular, our router, FGR, improves upon wirelengths produced by BoxRouter and MaizeRouter in March 2007 by 9.9% and 8.4%, respectively. Additionally, we reveal the mathematical basis of negotiated-congestion routing, offer comprehensive analysis of existing routing techniques and discuss several applications at the nanometer scale.	international symposium on physical design;network congestion;router (computing);routing	Jarrod A. Roy;Igor L. Markov	2007	2007 IEEE/ACM International Conference on Computer-Aided Design	10.1145/1326073.1326175	nanoelectronics;policy-based routing;routing table;routing;electronic engineering;static routing;simulation;hierarchical routing;dsrflow;zone routing protocol;telecommunications;equal-cost multi-path routing;computer science;engineering;dynamic source routing;electrical engineering;multipath routing;ring oscillator;very-large-scale integration;link-state routing protocol;metrics;routing information protocol	EDA	14.720254234618318	52.72681606172195	57071
8ad2e29b11fb1a74b8ea22df1adce3552ee4223d	versapower: power estimation for diverse fpga architectures	cmos integrated circuits;computer architecture;spice cmos integrated circuits computer architecture field programmable gate arrays logic cad;field programmable gate arrays;size 130 nm versapower power estimation diverse fpga architecture field programmable gate array academic fpga cad tool versatile place and route 6 0 vpr fracturable look up table complex logic block cmos technology spice hdl power consumption size 22 nm size 45 nm;logic cad;spice;multiplexing field programmable gate arrays table lookup solid modeling transistors wires capacitance	This paper presents VersaPower, a tool capable of modelling the power usage of many different field programmable gate array (FPGA) architectures.The latest release of the academic FPGA CAD tool, Versatile Place and Route 6.0 (VPR), supports new architecture features such as fracturable look-up tables and complex logic blocks. Past FPGA power models do not support these new features. VersaPower is designed to work closely with VPR to provide power estimation for any architecture supported by this new CAD flow. This allows researchers to investigate the effects on power usage of both new FPGA architectures, as well as new CAD algorithms. VersaPower is designed to operate with modern CMOS technologies, and is validated against SPICE using 22 nm, 45 nm and 130 nm technologies. Results show that for common architectures, roughly 60% HDL of power consumption is due to the routing fabric, 30% from logic blocks and 10% from the clock network. Architectures ODN supporting fracturable LUTs require 5-10% more power, as each CLB has additional I/O pins, increasing the sizes of local interconnect crossbars and connection boxes.	access network;algorithm;cmos;clock network;computer-aided design;field-programmable gate array;hardware description language;input/output;lookup table;place and route;routing;spice	Jeffrey B. Goeders;Steven J. E. Wilton	2012	2012 International Conference on Field-Programmable Technology	10.1109/FPT.2012.6412139	embedded system;computer architecture;macrocell array;logic gate;reconfigurable computing;programmable logic array;computer science;programmable logic device;simple programmable logic device;cmos;programmable array logic;field-programmable gate array	EDA	11.741465480044912	52.513788527482355	57174
c98d9065a974adfb8962a59258881436fa68fcb3	finfet sram design challenges	microprocessors;high definition video finfets sram cells computer architecture microprocessors robustness;fin pitch sram finfet write assist read assist vmin;finfets;computer architecture;sram cells;high definition video;robustness	The utilization of FinFET devices in the SRAM cell provides many benefits over planar bulk devices due to the fully-depleted behavior with improved subthreshold slope, short-channel effects, drive current, and mismatch. However, the quantized nature of the fins results in several new challenges as compared to planar devices. For the layout of the SRAM cell with FinFETs, the cell width needs to match up with the periphery fin pitch to provide a smooth transition from the cell array to the periphery. For the highest-density SRAM cell comprised of single fins for each device, the minimum Vdd (Vmin) of the write operation becomes substantially worse than the read operation, thus requiring the use of write assist techniques for low Vdd operation. This paper highlights tradeoffs in cell size and Vmin for different FinFET cell configurations and the simulated Vmin improvements with several different assist approaches.	cell (microprocessor);static random-access memory	David C. Burnett;Sanjay Parihar;Hema Ramamurthy;Sriram Balasubramanian	2014	2014 IEEE International Conference on IC Design & Technology	10.1109/ICICDT.2014.6838606	electronic engineering;parallel computing;real-time computing;engineering	EDA	17.768270075876643	60.321925680298314	57343
8e392ea292db61ec536539d993c7c55262c9c2d1	efficient diagnosis algorithms for drowsy srams	random access memory;static random access memory;probability density function;system on chip integrated circuit design sram chips;data mining;random access memory fault diagnosis testing power supplies system on a chip sram chips fault location fault detection dynamic voltage scaling failure analysis;system on a chip;chip;integrated circuit design;drowsy static random access memories memory cores system on chip memory yield improvement diagnosis algorithms;complex system;system on chip;diagnosis algorithms;heuristic algorithms;drowsy static random access memories;memory yield improvement;memory cores;couplings;algorithm design and analysis;sram chips	Memory cores usually occupy a signif cant portion of the chip area of a complex system-on-chip. Thus, the yield of memory cores dominates the yield of the chip. Diagnosis and repair are two important techniques for memory yield improvement. In this paper, we propose two eff cient diagnosis algorithms for drowsy static random access memories (SRAMs). The f rst diagnosis algorithm, March D2, can be used to distinguish drowsy faults (DFs) from non-drowsy faults (NDFs). The second diagnosis algorithm, March D6, can distinguish different fault types of DFs. The March D2 and March D6 require 23N and (10log2N+17)N Read/Write operations, respectively, for testing an N × W -bit drowsy SRAM.	complex system;medical algorithm;random access;static random-access memory;system on a chip	Bing-Wei Huang;Jin-Fu Li	2009	2009 10th International Symposium on Quality Electronic Design	10.1109/ISQED.2009.4810307	system on a chip;embedded system;complex systems;parallel computing;real-time computing;computer science;operating system;statistics	Arch	20.16412584013054	53.244002295310594	57488
dacd9fffd720fae8e7eff6f67ba65b8c7cd920d2	improving fpga design with monolithic 3d integration using high dense inter-stack via		This paper proposes to use the high density of vias enabled by monolithic 3D integration to produce multi-stack FPGA designs with improved performance and functionality. The use of fine grain vertical interconnects enables reconfiguration of FPGA logic within a few clock cycles, as shown in our design that features dynamic reconfiguration capabilities through the use of a pair of configuration memories on the upper stack. Along with the reconfigurability feature, results show that our SLICE design offers an area reduction of 23% compared to a standard design without reconfiguration capability. Our analysis of FPGA switch box logic and physical design with M3D vias provides insights into the sources of benefits from vertical routing in a multi-stacked design. We also discuss the design overheads involved in incorporating multiple inter-stack vias for better and faster communication among logic routed in different design stacks.	circuit design;clock signal;electrical connection;field-programmable gate array;kvm switch;multiplexing;physical design (electronics);reconfigurability;routing;signal integrity;stacking;via (electronics)	Srivatsa Rangachar Srinivasa;Karthik Mohan;Wei-Hao Chen;Kuo-Hsinag Hsu;Xueqing Li;Meng-Fan Chang;Sumeet Kumar Gupta;Jack Sampson;Narayanan Vijaykrishnan	2017	2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)	10.1109/ISVLSI.2017.31	field-programmable gate array;stack (abstract data type);control reconfiguration;% area reduction;physical design;embedded system;solid modeling;engineering;reconfigurability	EDA	12.24591797562115	52.411093238724256	57564
e94f4ba8e415bf1417707d45dcb50b39c4ea3487	genetic-algorithm-based test generation for current testing of bridging faults in cmos vlsi circuits	i sub ddq current testing;adaptive genetic algorithm;automatic testing;circuit testing circuit faults very large scale integration system testing automatic test pattern generation sequential circuits automatic testing cmos digital integrated circuits laboratories test pattern generators;logic testing cmos digital integrated circuits vlsi automatic testing genetic algorithms integrated circuit testing fault location;cmos digital integrated circuits;cmos vlsi circuits;logic testing;two line bridging fault set;integrated circuit testing;vlsi;bridging faults;test generation;genetic algorithm;genetic algorithms;compact test set generation;cmos digital circuits;digital circuits;automatic test pattern generator;ga based test generators;compact test set generation ga based test generators atpg bridging faults cmos vlsi circuits automatic test pattern generator i sub ddq current testing cmos digital circuits two line bridging fault set adaptive genetic algorithm;fault location;atpg	An efficient automatic test pattern generator for IDDQ current testing of CMOS digital circuits is presented. The complete two-line bridging fault set is considered. Genetic algorithms are used to generate compact test sets. Experimental results for ISCAS85 and ISCAS89 benchmark circuits are presented.	benchmark (computing);bridging (networking);bridging fault;cmos;digital electronics;fault coverage;genetic algorithm;iddq testing;test card;very-large-scale integration	Terry Lee;Ibrahim N. Hajj;Elizabeth M. Rudnick;Janak H. Patel	1996		10.1109/VTEST.1996.510893	computer architecture;electronic engineering;genetic algorithm;computer science;electrical engineering;test compression;computer engineering	EDA	21.2409943930078	50.328733193057616	57595
4d2d88a3228733c6be6c12a6f04a0c85fa9bb895	a cocktail approach on random access scan toward low power and high efficiency test	automatic test pattern generation;boundary scan testing;circuit testing;logic testing;sequential circuits;bit propagation;cocktail scan scheme;constrained static compaction;cycle random scan test;low power test;random access scan;random seed patterns;scan design;sequential circuits;test vector dropping	Scan design, providing a good test solution to sequential circuits, suffers large data volume, long test time and high test power problem. Recently, the random access scan (RAS) scheme offers a solution to alleviate the above problems (Baik et al., 2004). In this paper, based on RAS, a cocktail scan scheme is proposed and demonstrated to improve the test efficiency significantly. The scheme adopts a two-phase approach, firstly by using a cycle random scan test with a few random seed patterns to test the DUT and secondly, by using the RAS mechanism to test the circuit. Due to employment of a revised process and several strategies, namely, test response abundant, constrained static compaction, and bit propagation before test vector dropping, it is very effective in reducing bit flipping and test data volume, consequently, the test application time and power. Experimental results show that the scheme can achieve 86% reduction in test data volume and 10 times of speedup in test application time.	data compaction;device under test;random access;random seed;software propagation;speedup;test data;test vector;two-phase locking	Krishnendu Chakrabarty;Jiaming James Chen	2005	ICCAD-2005. IEEE/ACM International Conference on Computer-Aided Design, 2005.		electronic engineering;scan chain;real-time computing;boundary scan;engineering;automatic test pattern generation;test compression;sequential logic;algorithm	EDA	19.815716070838786	53.47291987307907	57619
ae7fe1a38f396446aa6f702aa68922efe9a6e7cf	detection of delay faults in memory address decoders	gray code;ram testing;high density;memory access;built in self test;delay testing;design for test;stuck open faults	In this paper we present an efficient test concept for detection of delay faults in memory address decoders based on the march test tactic. The proposed Transition Sequence Generator (TSG) generates an optimal transition sequence for sensitization of the delay faults in address decoders by Hayes’s transformation on a reflected Gray code. It can be used for parallel Built-In Self-Testing (BIST) of high-density RAMs. We also present an efficient Design For Test (DFT) approach for immediate detection of the effects of the delay faults in the address decoders which does not change memory access time. It requires extra logic to be attached to the outputs of the address decoders. This DFT approach can be used to increase memory testability for both on-line and off-line testing of singleand multi-port RAMs.	access time;address decoder;built-in self-test;cas latency;design for testing;field-programmable gate array;hayes microcomputer products;memory address;online and offline;random-access memory	Emil Gizdarski	2000	J. Electronic Testing	10.1023/A:1008322103755	gray code;electronic engineering;parallel computing;real-time computing;computer science;physical address;design for testing;algorithm	EDA	20.255562866456017	51.12849416307459	57627
81810826fbec81a6b4289e08ff11b8986c5eb011	power-efficient asynchronous design	synchronous designs power efficient asynchronous design low power consumption asynchronous logic;clocks logic design timing energy consumption microprocessors pipelines asynchronous circuits delay encoding voltage;logic design;power efficiency;low power;low power electronics;asynchronous circuits;low power electronics asynchronous circuits logic design;low power consumption	The potential advantage of low power consumption is one of the main reasons why asynchronous logic attracts attention from both industrial and academic circles. A number of low-power asynchronous designs have been proposed since the 1990s. In this paper, an attempt is made to compare the power-efficiency of asynchronous and synchronous designs, and to evaluate low-power asynchronous techniques	asynchronous circuit;best, worst and average case;clock gating;clock signal;glitch;idle (cpu);low-power broadcasting;requirement;synchronous circuit	Yijun Liu;Zhenkun Li;Pinghua Chen;Guangcong Liu	2007	20th International Conference on VLSI Design held jointly with 6th International Conference on Embedded Systems (VLSID'07)	10.1109/VLSID.2007.128	asynchronous system;embedded system;electronic engineering;logic synthesis;real-time computing;electrical efficiency;asynchronous circuit;computer science;operating system;asynchronous array of simple processors;low-power electronics;computer engineering;synchronizer	EDA	15.663064543050913	56.66449973739182	57671
26a259aa493a33bceb6afe81c759636663fa75e4	multiple-v/sub dd/ multiple-v/sub th/ cmos (mvcmos) for low power applications	threshold voltage optimization;cmos integrated circuits;power estimates;leakage current;critical paths;power estimation;standby leakage reduction;leakage reduction;delay estimates;supply voltage optimization;circuit cad cmos integrated circuits low power electronics integrated circuit design delay estimation table lookup circuit simulation circuit optimisation genetic algorithms;cmos design technique low power applications multiple v sub dd design technique multiple v sub th design technique performance constraints genetic algorithm based vector control technique critical paths noncritical paths delay estimates power estimates table lookup methods hspice simulations supply voltage optimization threshold voltage optimization standby leakage reduction;multiple v dd design technique;threshold voltage delay estimation power dissipation leakage current low voltage propagation delay circuit simulation genetic algorithms energy consumption circuit synthesis;integrated circuit design;circuit simulation;low voltage;design technique;low power;leakage power;multiple v th design technique;energy consumption;threshold voltage;propagation delay;critical path;power dissipation;low power electronics;hspice simulations;table lookup methods;vector control;genetic algorithm;genetic algorithms;circuit cad;circuit optimisation;performance constraints;table lookup;high performance;delay estimation;circuit synthesis;cmos design technique;noncritical paths;genetic algorithm based vector control technique;low power applications	In this paper, multiple-Vdd and multiple-Vth design techniques are combined to simultaneously achieve high performance and low power. The transistors in critical path(s) are assigned a higher supply voltage and a lower threshold voltage for high performance, while the transistors in non-critical paths may have a lower supply voltage and/or a higher threshold voltage to suppress dynamic power and leakage power. Accurate delay and power estimates using table look-up methods based on HSPICE simulations are used for supply voltage and threshold voltage optimization. Several algorithms for Vdd and Kh assignments under performance constraints are proposed and a genetic algorithm based vector control t,echnique is presented for standby leakage reduction. For the ISCAS benchmark circuits, multiple&, multiple-l/th CMOS (MVCMOS) design technique can reduce dynamic and leakage power dissipations by around 20% and 70%, respectively.	benchmark (computing);cmos;genetic algorithm;lookup table;mathematical optimization;spice 2;simulation;spectral leakage;transistor	Kaushik Roy;Liqiong Wei;Zhanping Chen	1999		10.1109/ISCAS.1999.777879	electronic engineering;real-time computing;genetic algorithm;computer science;engineering;electrical engineering	EDA	16.941040853335593	54.75641413794506	57715
10c144ec70785658f35b1e0765a2800f5d01fadf	generating routing-driven power distribution networks with machine-learning technique	electro migration em;machine learning technique;power grid design;proceedings paper;gaussian process;routing driven;ir drop;power distribution network	As technology node keeps scaling and design complexity keeps increasing, power distribution networks (PDNs) require more routing resource to meet IR-drop and EM constraints. This paper presents a design flow to generate a PDN that can result in minimal overhead for the routing of the underlying standard cells while satisfying both IR-drop and EM constraints based on a given cell placement. The design flow relies on a machine-learning model to quickly predict the total wire length of global route associated with a given PDN configuration in order to speed up the search process. The experimental results based on various 28nm industrial block designs have demonstrated the accuracy of the learned model for predicting the routing cost and the effectiveness of the proposed framework for reducing the routing cost of the final PDN.	design flow (eda);image scaling;machine learning;overhead (computing);routing;semiconductor device fabrication	Wen-Hsiang Chang;Li-De Chen;Chien-Hsueh Lin;Szu-Pang Mu;Mango Chia-Tso Chao;Cheng-Hong Tsai;Yen-Chih Chiu	2016		10.1145/2872334.2872353	routing;static routing;destination-sequenced distance vector routing;gaussian process;mathematics;power network design;statistics	EDA	15.810909603510606	53.725849684471314	57739
93d684ed9574f3a2f053569a354935ff77c20866	pgirem: reliability-constrained ir drop minimization and electromigration assessment of vlsi power grid networks using cooperative coevolution		Due to the resistance of metal wires in power grid network, voltage drop noise occurs in the form of IR drop which may change the output logic of underlying circuits and may affect the reliability performance of a chip. Further, it is necessary to handle different reliability constraints while designing a robust power grid network for a chip. Any violation of such constraints may increase the occurrences of IR drop. Therefore, there is a need to minimize the IR drop without violating the reliability constraints. In this paper, the IR drop minimization problem is formulated as a single objective large-scale variable minimization problem subjected to different reliability constraints, such as IR drop constraints, electromigration constraints, minimum width constraints, metal area constraints. At first, the large-scale minimization problem is divided into several subproblems using a divide and conquer based decomposition strategy, called Cooperative Coevolution. Secondly, each subproblem is solved using self-adaptive differential evolution with neighborhood search. Finally, electromigration (EM) assessment is done for the power grid networks using Black's equation to demonstrate the optimism in the predicted time-to-failure (TTF) after minimization of the IR drop.	benchmark (computing);black's equation;cooperative coevolution;differential evolution;electromigration;grid network;local search (optimization);mathematical optimization;optimization problem;test template framework;very-large-scale integration	Sukanta Dey;Satyabrata Dash;Sukumar Nandi;Gaurav Trivedi	2018	2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)	10.1109/ISVLSI.2018.00018	differential evolution;cooperative coevolution;power network design;grid;divide and conquer algorithms;mathematical optimization;electromigration;voltage drop;mathematics;grid network	EDA	16.050592264483242	53.76794985660561	57743
42475252a1d908e79fe05b9eeb490c643690e0b3	ufo: unified convex optimization algorithms for fixed-outline floorplanning considering pre-placed modules	floorplanning;second order cone programming;mathematical model equations convex functions shape integrated circuit modeling force computational modeling;pre placed modules fixed outline floorplanning;convex optimization method;unified convex optimization algorithm;convex programming;convex optimization;constraint graphs;push pull model;indexing terms;ufo methodology;force;fixed outline;convex functions;computational modeling;shape;second order cone program;preplaced modules;convex function;matlab unified convex optimization algorithm preplaced modules fixed outline floorplanning convex optimization method local legalization phase push pull model constraint graphs second order cone programming ufo methodology convex function;integrated circuit modeling;mathematical model;circuit layout cad;pre placed modules;fixed outline floorplanning;convex programming circuit layout cad;matlab;local legalization phase	In this paper, we apply two convex optimization methods, named UFO, for fixed-outline floorplanning. Our approach consists of two stages which are a global distribution stage and a local legalization stage. In the first stage, we first transform modules into circles and use a pull-push model to distribute modules among a fixed outline under the wirelength consideration. Because good results can be obtained after the first stage, we do not need to consider wirelegnth in the second stage; thus, we can devote to legalize modules. To keep the good results of the first stage, we propose a procedure to extract the geometric relations of modules from a layout and record them by constraint graphs. Then, a quadratic function as well as non-overlap and boundary constraints are formulated to determine the locations and shapes of modules. We have implemented the two convex functions on Matlab, and experimental results have demonstrated that UFO clearly outperforms the results reported in the literature on the GSRC benchmark.	algorithm;benchmark (computing);convex function;convex optimization;floorplan (microelectronics);matlab;mathematical optimization;push technology;quadratic function	Jai-Ming Lin;Hsi Hung	2010	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2011.2114531	convex function;mathematical optimization;combinatorics;convex optimization;mathematics;engineering drawing	EDA	14.603719396053126	50.41402953096415	57828
fb4d216ce937c62a054e9ce5bb9d28461fe199eb	algebraic survivor memory management design for viterbi detectors	algorithmic;dynamic programming;viterbi detectors;detectors;memory management;register exchange implementation;hardware complexity;very large scale integration;storage management;algebraic survivor memory management design;memory management viterbi algorithm delay detectors automata hardware energy consumption very large scale integration dynamic programming energy management;pipeline architectures;minimal latency;automata;viterbi detection;algebraic formulation;trace back scheme;energy consumption;memory architecture;viterbi algorithm;architectural solutions;memory architecture storage management chips storage management viterbi detection dynamic programming pipeline arithmetic;pipeline architectures viterbi detectors algebraic survivor memory management design register exchange implementation minimal latency hardware complexity power consumption trace back scheme algebraic formulation algorithmic architectural solutions vlsi dynamic programming;vlsi;storage management chips;power consumption;pipeline arithmetic;energy management;hardware	The problem of survivor memory management of a Viterbi detector is classically solved either by a register-exchange implementation which has minimal latency, but large hardware complexity and power consumption, or by a trace-back scheme with small power consumption, but larger latency. Here an algebraic formulation of the survivor memory management is introduced which provides a framework for the derivation of new algorithmic and architectural solutions. This allows for solutions to be designed with greatly reduced latency andor complexity, as well as for achieving a tradeoff between latency and complexity. VLSI case studies of specific new solutions have shown that at minimal latency more than 50% savings are possible in hardware complexity as well as power consumption.	memory management;sensor;very-large-scale integration	Gerhard P. Fettweis	1995	IEEE Trans. Communications	10.1109/26.412720	parallel computing;real-time computing;computer science;electrical engineering;theoretical computer science;very-large-scale integration	Embedded	14.471395415359652	47.492947536596176	58108
f9418381d3375c3a053afb58a207d362057b4d46	a low-power field-programmable gate array routing fabric	field programmable gate array;evaluation performance;champ faible;interconnection;cmos technology;performance evaluation;ligne de base;integrated circuit;low field;routing;implementation;evaluacion prestacion;circuito integrado;tecnologia mos complementario;red puerta programable;dynamic power consumption;reseau porte programmable;network routing;interconexion;field programmable gate arrays routing fabrics delay energy consumption cmos technology switches cmos logic circuits logic programming integrated circuit interconnections;low power;logic programming;energy consumption;integrated circuit interconnections;cmos logic circuits;cmos technology low power field programmable gate array routing fabric dynamic power consumption average net delays;network routing cmos logic circuits field programmable gate arrays low power electronics;interconnexion;low power electronics;routing architecture fabric;performance analysis;baseline;linea de base;average net delays;fabrics;temps retard;campo debil;delay time;power consumption;field programmable gate arrays;consommation energie electrique;implementacion;technologie mos complementaire;routing architecture fabric field programmable gate arrays fpgas low power performance analysis;switches;electronique faible puissance;tiempo retardo;circuit integre;complementary mos technology;routing fabric;field programmable gate arrays fpgas	This paper describes a new programmable routing fabric for field-programmable gate arrays (FPGAs). Our results show that an FPGA using this fabric can achieve 1.57 times lower dynamic power consumption and 1.35 times lower average net delays with only 9% reduction in logic density over a baseline island-style FPGA implemented in the same 65-nm CMOS technology. These improvements in power and delay are achieved by 1) using only short interconnect segments to reduce routed net lengths, and 2) reducing interconnect segment loading due to programming overhead relative to the baseline FPGA without compromising routability. The new routing fabric is also well-suited to monolithically stacked 3-D-IC implementation. It is shown that a 3-D-FPGA using this fabric can achieve a 3.3 times improvement in logic density, a 2.51 times improvement in delay, and a 2.93 times improvement in dynamic power consumption over the same baseline 2-D-FPGA.	application-specific integrated circuit;baseline (configuration management);cmos;field-programmable gate array;input/output;lattice boltzmann methods;lazy loading;multiplexer;overhead (computing);place and route;routing;torch;transistor	Mingjie Lin;Abbas El Gamal	2009	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2008.2005098	embedded system;routing;electronic engineering;computer science;engineering;electrical engineering;field-programmable gate array	EDA	14.37666539942301	57.50617268139116	58310
da41798f11aa3274a116326fa688a0f9594530c3	invited paper: design criteria for dependable system-on-chip architectures	system reliability;semiconductor technology;design process;network on chip;design criteria;semiconductor device reliability;large scale system;chip;networks on chip dependable system on chip architectures semiconductor technology transistor devices soft errors soc architectures lifetime maintainability noc;dependable systems;semiconductor technology network on chip semiconductor device reliability;soft error	The rapid improvement of semiconductor technologies is the enabling factor for the design of large-scale System-on-Chip (SoC) architectures. At the same time the scale-down of feature sizes in silicon technologies brings up new challenges as parameter variations of the transistor devices, an increased vulnerability for wear-out effects during the lifetime of the device and increased sensitivity for soft-errors. The overall system reliability is therefore an important topic to be addressed in the SoC design process as well as economic considerations related to manufacturing yield and lifetime maintainability. The aim of this contribution is to outline implications for the design process and to illustrate the dependability aspects at the example of SoC communication architectures being implemented as Networks-on-Chip (NoCs).	dependability;mpsoc;semiconductor;transistor	Thomas Hollstein;Faizal Arya Samman;Ashok Jaiswal;Haoyuan Ying;Manfred Glesner;Klaus Hofmann	2011	6th International Workshop on Reconfigurable Communication-Centric Systems-on-Chip (ReCoSoC)	10.1109/ReCoSoC.2011.5981518	chip;embedded system;design process;soft error;telecommunications;computer science;network on a chip	EDA	10.477862860588237	58.32282711684408	58468
73be1a358151623d18ec508cbd84e1c0cb15a152	a test architecture for system-on-a-chip	intellectual property;test access mechanism;chip level controller system on a chip test architecture configurable tam bus compliant test access mechanism jtag tam bus controller intellectual property cores boundary scan operation;system on a chip;boundary scan testing;chip;built in self test;system on chip;test coverage;integrated circuit testing;integrated circuit testing system on chip boundary scan testing built in self test;boundary scan testing self testing integrated circuit testing	This paper proposes a configurable TAM-Bus, a P1500 compliant Test Access Mechanism (TAM), and the TAMBus controller (TAM-controller) that is interfaced with JTAG at chip level of chip. All IP (Intellectual Property) cores’ test can be controlled through the TAP under the control of the TAM-controller. The test architecture we presented has been implemented in an industry SoC. The test coverage remains 99.40%. The overhead increases only 0.17% due to TAM. The experiment results demonstrate that the test architecture can offer the solution for testing SoC.	fault coverage;ibm tivoli access manager;jtag;next-generation network;overhead (computing);system on a chip	Yongsheng Wang;Liyi Xiao;Mingyan Yu;Jinxiang Wang;Yizheng Ye	2003		10.1109/ATS.2003.1250875	system on a chip;embedded system;electronic engineering;real-time computing;boundary scan;computer science;engineering	SE	11.012277476270292	53.876218072726886	58502
a489d089ed47b3f33955c4ecc193fd2ad6cbcb71	a 0.3v-to-1.1v standard cell library in 40nm cmos	libraries standards delays benchmark testing clocks foundries reliability;microprocessor chips cmos integrated circuits;voltage 0 3 v to 1 1 v process variation noise margin detailed sizing constraint sizing method cmos standard cell library processor energy efficiency size 40 nm	Processor operating over a wide voltage range achieves better possible energy efficiency while satisfying varying performance demands of the applications. To enable such a processor that can operate correctly and efficiently, a standard cell library specific for wide voltage operation is necessary. This paper describes a 40nm 0.3V-1.1V CMOS standard cell library by using sizing method to optimize the original one provided by foundry. By detailed sizing constraint, individual cells show better noise margin under process variation at 0.3 V and 0.6V, faster speed at 0.6V and 1.1V. Evaluation with benchmark circuits form ISCAS'89 and ITC'99 show 4.5%-6.9% speed improvement and 6.7%-22.3% less power comsumption synthesized at 0.6V compared with the foundry-provided one.	benchmark (computing);cmos;cell (microprocessor);mike lesser;noise margin;standard cell	Jintao Li;Ming Liu;Hong Chen;Zhihua Wang	2015	2015 IEEE 11th International Conference on ASIC (ASICON)	10.1109/ASICON.2015.7516884	electronic engineering;real-time computing;engineering;electrical engineering	EDA	16.19737804956774	56.19447329775888	58626
a11b1422eac550851f629e9b4f587410ad0d173c	novel 7t sram cell for low power cache design	cache storage;7t sram cell;sram chips cache storage integrated circuit design low power electronics;hspice simulation;random access memory energy consumption capacitance feedback stability degradation voltage delay mosfets cmos technology;integrated circuit design;low power cache design;hspice simulation 7t sram cell low power cache design on chip cache write operation;low power electronics;on chip cache;write operation;sram chips	Low-power on-chip cache is a crucial part in many applications. Conventional write operation depends on discharging/charging large bit lines capacitance which causes high power consumption. We propose a 7T SRAM cell that only depends on one of the bit lines during a write operation and reduce the write power consumption. HSPICE simulation shows that at least 49% write power saving, higher stability, and no performance degradation with additional 12.25% silicon area	cpu cache;cell (microprocessor);elegant degradation;low-power broadcasting;spice 2;simulation	Ramy E. Aly;Md. Ibrahim Faisal;Magdy A. Bayoumi	2005	Proceedings 2005 IEEE International SOC Conference	10.1109/SOCC.2005.1554488	electronic engineering;parallel computing;cpu cache;tag ram;computer hardware;computer science;operating system;low-power electronics;integrated circuit design	EDA	17.648872332360952	59.12645768287271	58772
5d3fec5dbbb040329ffc0262a9317f32ea716ab0	why automate optical inspection	printed circuit testing integrated circuit testing automatic testing automatic optical inspection;automatic testing;automatic optical inspection;automatic optical inspection humans assembly circuit testing particle beam optics automatic control automation printed circuits quality assurance electrical fault detection;integrated circuit testing;printed circuit testing;ic testing automated optical inspection aoi in circuit test universality pcb testing	New developments in circuit board assembly cannot take place without correspondin,g changes in quality assurance technology. We are presently in the midst of a mass conversion to double-sided reflow technology. In-circuit testing has been our principal tool for detecting and diagnosing faults for the past 20 years. By removing a design-for testability barrier that plagued earlier methods of test, in-circuit test made it possible to build large complex boards without fear of untestability. It is a strong, simple, universal approach to the quallity assurance problem. Although its universality remains high, in-circuit’s strength and simplicity decline as fixturing becomes difficult. Several technologies now compete to fill the gap.	design for testing;in-circuit test;list of code lyoko episodes;printed circuit board;reflow soldering;sensor;universal turing machine	Douglas W. Raymond;Dominic F. Haigh	1997		10.1109/TEST.1997.639723	embedded system;electronic engineering;automated x-ray inspection;engineering;engineering drawing;automated optical inspection	SE	24.035633988297903	53.752443586941155	58827
16e1c2351badce5f0d25873ecaa6aa0780d3419f	utilizing ate vector repeat with linear decompressor for test vector compression	logic testing automatic test equipment;vectors system on chip pins hardware memory management bandwidth logic gates;scan vector sequence ate vector repeat linear decompressor test vector compression automatic test equipment	Previous approaches for utilizing automatic test equipment (ATE) vector repeat are based on identifying runs of repeated scan data and directly generating that data using ATE vector repeat. Each run requires a separate vector repeat instruction, so the amount of compression is limited by the amount of ATE instruction memory available and the length of the runs (which typically will be much shorter than the length of a scan vector). In this paper, a new and more efficient approach is proposed for utilizing ATE vector repeat. The scan vector sequence is partitioned and decomposed into a common sequence which is the same for an entire cluster of test cubes and a unique sequence that is different for each test cube. The common sequence can be generated very efficiently using ATE vector repeat. Experimental results demonstrate that the proposed approach can achieve much greater compression while using many fewer vector repeat instructions compared with previous methods.	built-in test equipment;data compression;nonlinear system;olap cube;test set;test vector	Joon-Sung Yang;Jinkyu Lee;Nur A. Touba	2014	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2014.2314307	embedded system;electronic engineering;computer hardware;engineering;test compression	EDA	20.13335432557375	52.02216520293561	58880
ad8f27bf13c54d23114cfb11f10f0583ac261c39	impact of fin-height on sram soft error sensitivity and cell stability	static noise margin;process variations;soft errors;finfet	FinFET technology has become the most promising alternative to continue CMOS scaling due to its improved short channel effects. Design flexibility reduces on FinFET based circuits such as SRAM cells due to the effective channel width is determined by an integer number of fins. In this work, the impact of fin height size of FinFET transistors on the simultaneous behavior of soft error sensitivity and SRAM cell static noise margin is investigated. 3-D TCAD Sentarus environment is used to quantify the amount of collected and critical charges of an SRAM cell due to a heavy ion strike while Mix-Mode Hspice-TCAD simulation is used for stability analysis. Even more, the influence of process variations on sensitivity to soft errors and cell stability is considered. A 10 nm-SOI Tri-Gate FinFET technology is used. Results show that increasing the fin height of FinFET transistors considerably increases SRAM cell sensitivity to soft errors but improves its stability. This suggests that the optimum fin height value of FinFET transistors of an SRAM cell depends on the best tradeoff between soft error robustness and stability.	soft error;static random-access memory	Hector Villacorta;Jaume Segura;Víctor H. Champac	2016	J. Electronic Testing	10.1007/s10836-016-5591-3	electronic engineering;real-time computing;engineering;electrical engineering	HCI	19.352947018681594	59.50862909764619	58942
9cc66de166ca65817a053f8f5463477bd40010bb	post-processing of supergate networks aiming cell layout optimization		Recently, methods for switch network generation have gain relevance. The main goal of these techniques is to minimize the number of transistors in the logical arrangement. However, theses methods do not consider optimizations at layout level. In this paper, we propose a post-processing technique in a state-of-art method for network generation to improve some layout aspects such as area, delay, power and parasitic capacitance. Experiments performed over a well-known benchmark demonstrate that the proposed technique allows average gains of 7.48% and 8.48% in the cell area and wirelength, respectively. Electrical characterization results have also shown improvements for propagation delay, transition delay, leakage and switching power in 4.18%, 4.94%, 7.52% and 12.40%, in that order.	benchmark (computing);cell (microprocessor);digital electronics;experiment;kalman filter;mathematical optimization;propagation delay;relevance;software propagation;spectral leakage;transistor;video post-processing	Gustavo H. Smaniotto;Regis Zanandrea;Maicon Schneider Cardoso;Renato Souza de Souza;Matheus T. Moreira;Felipe de S. Marques;Leomar S. da Rosa	2017	2017 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2017.8050570	network switch;electronic engineering;computer science;propagation delay;transistor;leakage (electronics);parasitic capacitance	EDA	16.671811251209526	55.00792235985493	58975
276e8d0a9a547c737cf91796be0252d09f3ba9b6	timing analysis for synthesis in microprocessor interface design	computer interfaces;optimisation;combinatorial optimization;complexity;interface path delays;interface synthesis;interval arithmetic;microprocessor interface design;microprocessor-based systems;system design;system integration;timing analysis	Design automation techniques are playing an important role in controlling the complexity of system design. Our work is inscribed in tlw &sign automation of microprocessor-based systems which necessitates the design of interjizces for system integration. During the interface synthesis if is required to validate the timing of a design yet to be iinplemented. In this paper we present a novel methodology to timing analysis that can determine tight bounds on interjlzce path delays based on the given timing information. The timing analysis for synthesis problem is formulated as a combinatorial optimization problem using interval arithmetic techniques. L Introduction The design of interface circuits emphasizes the synthesis of cnntrol logic [4]. Other resea.mh work [9] indicates that controller design can benefit from a delay-insensitive design methodology which produces robust circuits that behave correctly even in the presence of variations on gate and wire delays. However it is not always possible to neglect timing information corresponding to either internal circuit delays or constraints on the environment for proper circuit operation [10]. This is particularly true in the design of microprocessor-based systems whose protocols specify {ieadlines to meet. In this paper we discuss a Petri net based repment.ation forma.hsm that allows us to nmsou about known circuit path delays and environmental timing constraints. Although our approach shares similarities with other work in the area of interface synthesis and controller design, our aim is to break a recurrent problem encountered during :synthesis: a solution must be first offered to be able to (determine if it satisfies the design constraints. The main :result of this paper is a novel approach to time analysis that “bwdcs this cycle by finding bounds on the delays of the circuit to be synthesized before the actual circuit implementation takes place. In the following section we survey related work. Our representation formaiism is based on a timed Petri net which is presented in section 3. Section 4 is devoted to the discussion of the details of the timing anrdysis methodology. An example is given in section 5 to illustrate our approach. Finally future work is pointed in the conclusions.	algorithm;combinatorial optimization;delay calculation;delay insensitive circuit;interval arithmetic;logic gate;mathematical optimization;microprocessor;optimization problem;petri net;static timing analysis;system integration;systems design;timing closure	Marco A. Escalante;Nikitas J. Dimopoulos	1994			control engineering;computer architecture;real-time computing;computer science;static timing analysis	EDA	10.588747306449719	50.739004698020544	58991
7ef5952c517bfe96298d9af93deb993d3f999ed5	selective-run built-in self-test using an embedded processor	design for testability;processor based testing;system on a chip;chip;built in self test;soc testing;fault coverage;pseudo random number generator;embedded processor	Many systems-on-a-chip (SOCs) include processors as central units to implement diverse algorithms and control peripheral units such as embedded cores. The computing power of the embedded processor can be used to self-test its own functions as well as to test the other cores within the chip boundary. In BIST methodology, pseudo-random pattern testing can reduce the memory requirements. In addition to general pseudo-random pattern testing, this paper proposes and evaluates a novel selective-random pattern test technique. This technique increases the fault coverage while significantly reducing test application time. This also greatly decreases the memory requirements compared to traditional BIST schemes. The cost for extra hardware is low and the technique is easily integrated with parallel scan and boundary scan designs.	algorithm;boundary scan;built-in self-test;central processing unit;embedded system;fault coverage;peripheral;pseudorandomness;requirement;system on a chip	Sungbae Hwang;Jacob A. Abraham	2002		10.1145/505306.505333	chip;system on a chip;embedded system;computer architecture;parallel computing;fault coverage;computer science;test compression;design for testing;pseudorandom number generator	EDA	19.981525045921558	52.02246681663378	59066
043b266a6057978cbd310260f2a8b35397514df6	litho and design: moore close than ever	moore s law;spectrum;dfm;design rules;lithography;optimal design;numerical aperture	As the gap between the lithography wavelength and critical feature size has continued to increase, the semiconductor industry has had to adjust. Previously, scaling along Moore's Law had relied on improvement in lithography equipment, occasionally by reducing the wavelength and frequently by improving the effective numerical aperture. For a few years now, this scaling has relied more on optimization of the lithography process and on deeper co-optimization between process and design. Recently, a key element of lithography optimization has been computational lithography, which in turn has consisted of two advanced features: inverse lithography, and source-mask optimization. The second prong of scaling, co-optimization between process and design, has involved close cooperation between the two camps, using tools and methods that have been given the umbrella label of DFM. While some of the mystique surrounding DFM continues to linger, we at Intel have always believed that DFM is defined in terms of the results it produces. In that sense, DFM is a broad set of practices that helps produce compelling products at high yield levels on a competitive schedule. While the fundaments of these practices have existed for many years, the volume of effort and degree of sophistication have increased with each technology generation. By co-optimizing design and process early in the development cycle for a given node, we arrive at a set of design rules that meet the process and design requirements. The thoroughness of this early work results in these rules being stable through the development cycle. The application of these practices to 32 nm and 22 nm nodes, with ongoing refinements to meet new challenges, is ensuring the continued march of Moore's Law.  This paper will cover the spectrum of lithography options that lie ahead, computational lithography solutions that are helping drive Moore's Law, and the general implications of both on design.	computational lithography;design for manufacturability;image scaling;mathematical optimization;matrox mystique;moore's law;numerical analysis;numerical aperture;requirement;semiconductor industry	Vivek Singh	2011		10.1145/1960397.1960432	lithography;spectrum;optimal design;numerical aperture;nanotechnology;mathematics;moore's law;design for manufacturability;physics	EDA	11.152519534289176	57.53911573063947	59081
3b42354f934699cd06c883dab9ff079e0f7488b4	yield optimization by design centering and worst-case distance analysis	process variation;worst case distance;spice vlsi circuit optimisation circuit cad;parametric yield;vlsi design;optimization scheme yield optimization design centering worst case distance analysis process variations parametric yield vlsi circuits optimum parameter values vlsi parametric yield gradient dependent techniques;design optimization very large scale integration circuit optimization failure analysis robustness design engineering cost function circuit simulation;vlsi;optimization;profitability;circuit cad;design centering;circuit optimisation;spice	Process variations invariably give rise to a parametric yield below 100% for VLSI circuits. Improving the yield by choosing a set of optimum parameter values does not incur any extra cost, and it is a preferred method as it directly translates into profits. This paper presents an efficient and novel method to improve the VLSI parametric yield by selecting optimum parameter values. This method utilizes the Worst-Case Distance Analysis, Design Centering and Gradient-Dependent techniques. One circuit example is presented to demonstrate the optimization scheme.	gradient;mathematical optimization;very-large-scale integration;worst-case distance	G. S. Samudra;H. M. Chen;D. S. H. Chan;Yaacob Ibrahim	1999		10.1109/ICCD.1999.808550	mathematical optimization;electronic engineering;computer science;engineering;electrical engineering;very-large-scale integration;engineering drawing	EDA	16.698752032251825	53.67015816933354	59217
df165b8779042f8717d0a8e3cb3648d744bb4feb	fast identification of operating current for toggle mram by spiral search	bist;reliability;operating current search method toggle mram spiral search magnetic random access memory nonvolatile memory deep submicron process technologies;high density;cell size;testing mram bist characterization yield enhancement reliability;mram devices;dynamic reconfiguration;radiation detectors;toggle mram;search methods;search method;magnetic random access memory;testing;chip;computer architecture;productive life;deep submicron process technologies;nonvolatile memory;non volatile memory;spirals;yield enhancement;characterization;operating current search method;integrated circuit reliability;mram;spiral search;high speed;spirals circuit testing random access memory search methods semiconductor device measurement performance evaluation mass production magnetic materials magnetic tunneling nonvolatile memory;magnetic tunneling	Magnetic Random Access Memory (MRAM) is a non-volatile memory which is widely studied for its high speed, high density, small cell size, and almost unlimited endurance. However, for deep-submicron process technologies, significant variation in MRAM cells' operating regions results in write failures in cells and reduces the production yield. Currently, memory designers characterize failed MRAM chips to find a suitable current level for reconfiguring their operating current, which is time-consuming. In this paper, we propose an efficient operating current search method and a built-in circuit for toggle MRAM, which can rapidly find a customized operating current for each MRAM chip. With the built-in circuit, an MRAM chip can dynamically reconfigure its operating current automatically. Production yield and product life-time thus can be increased.	canonical account;feature toggle;magnetoresistive random-access memory;non-volatile memory;random access;switch;very-large-scale integration;volatile memory	Sheng-Hung Wang;Ching-Yi Chen;Cheng-Wen Wu	2010	Design Automation Conference	10.1145/1837274.1837506	electronic engineering;parallel computing;non-volatile memory;computer hardware;telecommunications;computer science;engineering;electrical engineering;operating system	EDA	13.508104008711097	58.50994521232086	59269
b42315b1bccee85fbaafc60e35ccf42d461447c2	probabilistic error modeling for nano-domain logic circuits	belief networks;radiation related errors;conditional independence;bayesian network;probabilistic error modeling;art;nano domain computing;network synthesis;circuit faults;approximation error;probabilistic error model bayesian networks dynamic errors;uncertainty;circuit design;bayesian methods;logic circuits;inference mechanisms;approximate bayesian inference;computer networks;probabilistic model;computational modeling;inverse problem;logic gates;error tolerant designs;nanoscale devices;probabilistic error model;logic gates probabilistic error modeling nano domain logic circuits radiation related errors nano domain computing output error probability dynamic error encoded model bayesian networks bayesian inference schemes error sensitivity stochastic sampling schemes error tolerant designs;output error;output error probability;error sensitivity;error statistics;error probability;approximate inference;logic circuits error probability bayesian methods computer networks uncertainty circuit faults nanoscale devices logic devices art computational modeling;network synthesis belief networks error statistics inference mechanisms logic cad logic circuits logic gates;logic cad;nano domain logic circuits;logic devices;bayesian inference schemes;dynamic error encoded model;bayesian networks;stochastic sampling schemes;dynamic errors	In nano-domain logic circuits, errors generated are transient in nature and will arise due to the uncertainty or the unreliability of the computing element itself. This type of errors - which we refer to as dynamic errors - are to be distinguished from traditional faults and radiation related errors. Due to these highly likely dynamic errors, it is more appropriate to model nano-domain computing as probabilistic rather than deterministic. We propose a probabilistic error model based on Bayesian networks to estimate this expected output error probability, given dynamic error probabilities in each device since this estimate is crucial for nano-domain circuit designers to be able to compare and rank designs based on the expected output error. We estimate the overall output error probability by comparing the outputs of a dynamic error-encoded model with an ideal logic model. We prove that this probabilistic framework is a compact and minimal representation of the overall effect of dynamic errors in a circuit. We use both exact and approximate Bayesian inference schemes for propagation of probabilities. The exact inference shows better time performance than the state-of-the art by exploiting conditional independencies exhibited in the underlying probabilistic framework. However, exact inference is worst case NP-hard and can handle only small circuits. Hence, we use two approximate inference schemes for medium size benchmarks. We demonstrate the efficiency and accuracy of these approximate inference schemes by comparing estimated results with logic simulation results. We have performed our experiments on LGSynth'93 and ISCAS'85 benchmark circuits. We explore our probabilistic model to calculate: 1) error sensitivity of individual gates in a circuit; 2) compute overall exact error probabilities for small circuits; 3) compute approximate error probabilities for medium sized benchmarks using two stochastic sampling schemes; 4) compare and vet design with respect to dynamic errors; 5) characterize the input space for desired output characteristics by utilizing the unique backtracking capability of Bayesian networks (inverse problem); and 6) to apply selective redundancy to highly sensitive nodes for error tolerant designs.	approximation algorithm;backtracking;bayesian network;benchmark (computing);best, worst and average case;business logic;conditional entropy;error-tolerant design;experiment;gnu nano;logic gate;logic simulation;np-hardness;sampling (signal processing);software propagation;statistical model	Thara Rejimon;Karthikeyan Lingasubramanian;Sanjukta Bhanja	2009	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2008.2003167	logic gate;computer science;theoretical computer science;machine learning;bayesian network;statistics	EDA	22.71904747190531	58.201753312601234	59343
f0da7bb60a0ae991e6fed57ab38c1c0cd19d240a	stimulus generation for interface protocol verification using the nondeterministic extended finite state machine model	protocols;protocols automata binary decision diagrams system on a chip data structures boolean functions controllability design engineering acceleration process design;protocol verification;random simulation stimulus interface protocol verification stimulus biasing nondeterministic extended finite state machine automatic stimulus generation;integrated circuit design;finite state machines;extended finite state machine;proceedings paper;circuit cad;logic cad finite state machines integrated circuit design protocols circuit cad;logic cad	Verifying if an integrated component is compliant with certain interface protocol is a big issue in component-based SOC designs. Massive constrained random simulation stimuli are becoming crucial to achieve a high verification quality. To further improve the quality, the stimulus biasing technique should be used to guide the simulation to hit design corners. In this paper, we model the interface protocol with the nondeterministic extended finite state machine (NEFSM), and then propose an automatic stimulus generation approach based on the NEFSM. This approach is capable of providing numerous biasing options. Experiment results demonstrate the high controllability and efficiency of our stimulus generation scheme.	biasing;component-based software engineering;correctness (computer science);extended finite-state machine;hardware acceleration;hardware description language;logic synthesis;overhead (computing);simulation;speedup;system on a chip	Che-Hua Shih;Juinn-Dar Huang;Jing-Yang Jou	2005	Tenth IEEE International High-Level Design Validation and Test Workshop, 2005.	10.1109/HLDVT.2005.1568819	embedded system;extended finite-state machine;communications protocol;real-time computing;computer science;theoretical computer science;operating system;finite-state machine;programming language;algorithm;integrated circuit design	EDA	14.085346567197009	55.278267223437986	59435
3266e0bed0873805fb837c902ecde6794ab2e32e	optimization of noc wrapper design under bandwidth and test time constraints	wrapping;optimisation;network on chip;bandwidth efficiency;wrapping network on chip optimisation;wrapper design;test time constraints;test time constraints optimization networks on chip wrapper design bandwidth efficiency;and type 2;networks on chip;optimization;test scheduling;constraint optimization design optimization network on a chip bandwidth time factors delay scheduling circuit testing integrated circuit interconnections throughput;optimal algorithm;time constraint	In this paper, two wrapper designs are proposed for core- based test application based on Networks-on-Chip (NoC) reuse. It will be shown that the previously proposed NoC wrapper does not efficiently utilize the NoC bandwidth, which may result in poor test schedules. Our wrappers (Type 1 and Type 2) complement each other to overcome this inefficiency while minimizing the overhead. The Type 2 wrapper uses larger area overhead to increase bandwidth efficiency, while the Type 1 takes advantage of some special configurations which may not require a complex and high-cost wrapper. Two wrapper optimization algorithms are applied to both wrapper designs under channel bandwidth and test time constraints, resulting in very little or no increase in the test application time compared to conventional TAM approaches.	algorithm;chomsky hierarchy;ibm tivoli access manager;mathematical optimization;nsa product types;network on a chip;overhead (computing);spectral efficiency;system on a chip	Fawnizu Azmadi Hussin;Tomokazu Yoneda;Hideo Fujiwara	2007	12th IEEE European Test Symposium (ETS'07)	10.1109/ETS.2007.30	electronic engineering;parallel computing;real-time computing;computer science;engineering;network on a chip;spectral efficiency	EDA	11.948824469373582	53.963504675149196	59458
d4aecd0f2c9d483eb3155cc551ad20784cfa3f0e	aggressive register unsharing based on ssa transformation for clock enhancement in high-level synthesis	static single assignment transformation high level synthesis multiplexer;open source compiler;clock period reduction;clocks;resource management;compiler intermediate representation;multiplexing equipment;clocks high level synthesis registers integrated circuit interconnections frequency multiplexing productivity resource management partitioning algorithms electronic equipment testing;high level synthesis;aggressive register unsharing;registers;static single assignment;static single assignment transformation;multiplexer;optimization;coins aggressive register unsharing ssa transformation high level synthesis clock frequency clock period reduction multiplexers static single assignment transformation compiler intermediate representation open source compiler;coins;functional unit;multiplexing equipment clocks;gsm;ssa transformation;multiplexers;clock frequency;benchmark testing;open source;intermediate representation	A novel high-level synthesis (HLS) technique to improve the clock frequency is presented. Our technique aims at the reduction of the clock period by eliminating interconnections, specifically multiplexers (MUXs). MUXs are generally inserted before shared functional units and shared registers. However, MUXs are also inserted before a register even if the register is not shared by multiple variables at all. This paper proposes aggressive register unsharing to remove these MUXs and to improve the clock frequency. Our proposed technique employs static single assignment (SSA) transformation, which is mainly used as a compiler intermediate representation, to behavioral descriptions. This technique is widely applicable to a variety of HLS tools because it is completely independent of the HLS tools. We have developed a complete synthesis framework using an open source compiler, COINS, for SSA transformation, a commercial HLS tool, and an in-house converter which refines a COINS-generated code into one compatible with the HLS tool. Six sets of experiments showed the clock frequency improvement by up to 61.5% and on average 26.7% with the acceptable overhead on the circuit area by on average 10.6%.	assignment (computer science);coins;clock rate;compiler;experiment;high- and low-level;high-level synthesis;intermediate representation;multiplexer;open-source software;overhead (computing);shared register;static single assignment form	Toshinobu Matsuba;Yuko Hara-Azumi;Hiroyuki Tomiyama;Shinya Honda;Hiroaki Takada	2010	2010 Fifth IEEE International Symposium on Electronic Design, Test & Applications	10.1109/DELTA.2010.41	multiplexer;embedded system;electronic engineering;parallel computing;real-time computing;telecommunications;computer science;resource management;operating system	EDA	10.912285592188777	53.59279732525477	59537
7cbd2783179e157f5ae885ce9bc637e5206d727f	new test data decompressor for low power applications	switching activity;integrated circuit testing integrated circuit reliability;design for testability;reliability;circuit noise;automatic test pattern generation;low power test scheme;compression ratios data decompressor low power test scheme industrial circuits switching activity;circuit testing automatic test pattern generation logic testing power dissipation test pattern generators integrated circuit reliability design for testability graphics voltage circuit noise;low power;test pattern generators;data decompressor;power dissipation;theory;voltage;logic testing;compression ratios;integrated circuit testing;compression ratio;vlsi test;algorithms;design;circuit testing;industrial circuits;integrated circuit reliability;compression;vlsi test algorithms design reliability theory compression low power;graphics	The paper presents a novel low power test scheme integrated with the embedded deterministic test environment. It reduces significantly switching rates in scan chains with minimal hardware modification. Experimental results obtained for industrial circuits clearly indicate that switching activity can be reduced up to 150 times along with improved compression ratios.	deployment environment;embedded system;test data	Grzegorz Mrugalski;Janusz Rajski;Dariusz Czysz;Jerzy Tyszer	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278617	embedded system;electronic engineering;real-time computing;computer science;test compression;compression ratio	EDA	20.48748160649059	53.53912143669456	59757
d2dfc715f31b6b33118c5ca36e4bc831f68422a9	do the designs work ?	libraries;reliability engineering;reliability;hierarchical;programming environments;design process;design engineering;very large scale integration;standard cells;design education;very large scale integration computer aided engineering computer science education feedback process design environmental management engineering management libraries reliability engineering design engineering;vlsi design;process design;vlsi cad cam circuit cad education electronic engineering computing programming environments;computer science education;feedback;engineering management;computer aided engineering;cad cam;vlsi;design education circuit cad vlsi design hierarchical standard cells reliability cae computer aided engineering;circuit cad;electronic engineering computing;environmental management;cae	Early experiences teaching a Mead-Conway based VLSI Design course showed me that students could relatively easily lay out a several thousand transistor, full-custom chip. There was, however, no way of assuring whether or not their design would work unless one happened to notice that one of the polysilicon lines was unconnected, to say nothing of spotting timing problems. This has led to significant modifications and, I believe, improvements in our approach to VLSI design. Interestingly, and not surprisingly, our approach has evolved toward industrial practice.	conway's game of life;full custom;transistor;very-large-scale integration	Kenneth Rose	1988		10.1109/TEST.1988.207804	design closure;electronic engineering;systems engineering;engineering;electrical engineering;software engineering;very-large-scale integration;design education;computer engineering	EDA	10.137017179558178	52.697040781430886	60462
fc113c3c619eea54d59a4a21c760036180f3fba0	phifact, a boolean preprocessor for multi-level logic synthesis	institutional repositories;shared circuit parts boolean preprocessor multi level logic synthesis phifact boolean optimization decomposition merging structural analysis;fedora;cost function;logic cad boolean algebra;design space;vital;boolean algebra;logic synthesis;vtls;logic cad;ils;boolean functions circuits merging phase detection cost function space technology libraries laboratories design optimization control systems;structure analysis	PHIFACT is a multi-level Boolean optimization program characterized by a controlled time-area trade-off. Its first phase, the Boolean phase, uses Boolean techniques of decomposition and merging to carry out a structural analysis and, in particular, to detect shared circuit parts. Its second phase, the restructuring phase, carries out a systematic exploration of the area-time design space by applying a user controlled sequence of transformations minimizing a parameterized cost function. The obtained results show the feasibility of full Boolean computations and open the way to an important family of new structural analysis techniques. >	boolean algebra;logic synthesis;preprocessor	F. Crowet;Marc Davio;C. Dierieck;J. Durieu;Guillaume Louis;Chantal Ykman-Couvreur	1990		10.1109/ICCAD.1990.129966	boolean algebra;boolean circuit;and-inverter graph;circuit minimization for boolean functions;electronic engineering;discrete mathematics;reed–muller expansion;logic synthesis;boolean domain;boolean expression;product term;standard boolean model;computer science;theoretical computer science;structural analysis;combinational logic;boolean function;algorithm	EDA	16.063775018449633	47.824004325826486	60566
b3bfc29b2a700011ab1e8c7d4017a170e2fc4741	nano-technology aware investigations on fault-masking techniques in the presence of high fault probabilities	cmos integrated circuits;probability;circuit faults;fault tolerant;decoding;stochastic method;wires;nanotechnology;fault masking;nano computing;circuit faults decoding wires logic gates tunneling magnetoresistance equations fault tolerance;error correcting codes;redundancy;error correction code;logic gates;stochastic methods nanotechnology aware investigations fault masking techniques high fault probability nanoarchitectures cmos technology redundant codes circuit structures;stochastic processes;fault tolerance;failure rate;tunneling magnetoresistance;nano computing fault tolerance fault masking redundancy error correcting codes;stochastic processes cmos integrated circuits fault tolerance nanotechnology probability redundancy	Nano-architectures are promising alternatives for current CMOS technology, which is facing serious challenges for further down-scaling. However, high failure rates — compared to the conventional CMOS process — lead to multiple faults during lifetime operation of nano-architectures. In this paper, we investigate the outcome of traditional fault-masking techniques in the presence of high fault probabilities. Redundant codes and circuit structures are evaluated in a generic way, using stochastic methods. The original goal was to provide a means to decide, under which conditions, which fault-masking techniques are worthwhile. Our results, however, suggest, that these techniques require extremely low fault rates and/or cause extraordinarily high additional cost.	cmos;code;code word;dependability;fault tolerance;gnu nano;general protection fault;image scaling;software deployment	Matthias Sand;Volkmar Sieh;Dietmar Fey	2010	2010 International Conference on High Performance Computing & Simulation	10.1109/HPCS.2010.5547139	stochastic process;fault tolerance;parallel computing;real-time computing;computer science;theoretical computer science	HPC	10.306239609509264	59.60737083887283	60695
1331929e7d464afbdc3007ab3d5ddfc0a1a8a3cb	hardware architecture and vlsi implementation of a low-power high-performance polyphase channelizer with applications to subband adaptive filtering	hardware very large scale integration adaptive filters computer architecture circuits system performance power system modeling computational complexity flip flops computational modeling;optimisation;352 mw;subband adaptive filtering;low power channelizer;very large scale integration;flip flops;dual vdd scheme;commutator;352 mw polyphase channelizer hardware architecture low power channelizer high performance polyphase channelizer vlsi implementation subband adaptive filtering optimization hardware complexity system performance tradeoffs fixed point modeling computational complexity reduction commutator dual vdd scheme level converting flip flops;vlsi design;hardware complexity system performance tradeoffs;system performance;hardware architecture;fixed point;chip;computer architecture;adaptive filters;computational modeling;level converting flip flops;low power;computational complexity;fixed point modeling;low power electronics;vlsi;optimization;circuits;vlsi implementation;flip flops adaptive filters low power electronics vlsi optimisation computational complexity;power system modeling;computational complexity reduction;high performance;polyphase channelizer hardware architecture;high performance polyphase channelizer;adaptive filter;flip flop;hardware	The polyphase channelizer is an important component of a subband adaptive filtering system. This paper presents an efficient hardware architecture and VLSI implementation of a low-power high-performance polyphase channelizer, integrating optimizations at algorithmic, architectural and circuit level. At the algorithm level, a computationally efficient structure is derived. Tradeoffs between hardware complexity and system performance are explored during the fixed-point modeling of the system. A computational complexity reduction technique is also employed to reduce the complexity of the hardware architecture. Circuit-level optimizations, including an efficient commutator implementation, dual-VDD scheme and novel level-converting flip-flops, are also integrated. Simulation results show that the design consumes 352 mW power with system throughput of 480 million samples per second (MSPS). A test chip has been submitted for fabrication to validate the proposed hardware architecture and VLSI design techniques.	adaptive filter;algorithm;algorithmic efficiency;computational complexity theory;flops;flip-flop (electronics);low-power broadcasting;polyphase matrix;polyphase quadrature filter;reduction (complexity);sampling (signal processing);simulation;throughput;value-driven design;very-large-scale integration	Yongtao Wang;Hamid Mahmoodi;Lih-Yih Chiou;Hunsoo Choo;Jongsun Park;Woopyo Jeong;Kaushik Roy	2004	2004 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2004.1327056	adaptive filter;parallel computing;real-time computing;computer science;electrical engineering;hardware architecture;very-large-scale integration	EDA	12.331739869573072	47.07078656855785	60719
d194d72eeddfd1d12bdc480cac3e59ac3077722a	boolean matching in logic synthesis	boolean functions;logic cad;boolean matching;don't cares;gates;logic synthesis;technology mapper;tree matching algorithms	A new formulation for finding the existence of a Boolean match between two functions with don't cares is presented. An algorithm for Boolean matching is de veloped based on this new formulation and is used within atechnology mapper as a substitute for tree matching algorithms. The new algorithm is fast and uses symme tries ofthe gates inthe library tospeed up the matching process. Local don't cares are computed for each function being mapped interms of its inputs. To reduce the frequency in which Boolean matching is used, the gates in the library are grouped into classes such that itis sufficient to tryto match a function with the class repre sentative. Experimental results show significant improvement inthe final area ofthe mapped circuits. •This project was supported in partby NSF/DARPA under contract number MIP-8719546 and MIP9002962 and grants from IBM and DEC.	algorithm;don't-care term;ibm notes;logic synthesis	Hamid Savoj;Mário J. Silva;Robert K. Brayton;Alberto L. Sangiovanni-Vincentelli	1992			boolean circuit;and-inverter graph;circuit minimization for boolean functions;electronic engineering;discrete mathematics;boolean network;boolean domain;data structure;boolean expression;logic gate;computer science;theoretical computer science;mathematics;boolean function;algorithm;parity function	EDA	17.916752359917037	46.942215768121805	60767
f29279147137668af8162f727fc3a1ecf2fba81f	fast bit screening of automotive grade eeproms—continuous improvement exercise	automotive engineering;quality assurance;microprocessors;reliability;dppm;fast bits;charge accumulation;semiconductor device reliability;semiconductor device reliability automotive charge accumulation dppm electrically eraseable programmable read only memory eeprom endurance fast bits oxide part average testing pat quality assurance screening methodology;automotive;testing;computer architecture;screening methodology;eprom;production;oxide;eprom computer architecture microprocessors testing reliability production automotive engineering;electrically eraseable programmable read only memory eeprom;endurance;part average testing pat	This paper presents the optimization of an existing electrically eraseable programmable read-only memory (EEPROM) production test flow by means of thorough analysis of the faulty dice and the test flow, which leads to an increase in the yield, a significant decrease in test time, and a decrease in the dppm (increase in quality) level leaving the factory. In order to manufacture high quality and cost-effective EEPROMs suitable for automotive underhood applications, several topics must be taken into account. In addition to a high reliability EEPROM technology, the choice of an advanced memory architecture including error correction code and a highly sophisticated screening methodology in production test is necessary to achieve high quality in the field. The EEPROM production test flow must not only be able to screen out weaknesses in the process but must also be cost efficient. A majority of the tests executed in the EEPROM test flow are needed to check the quality of the processed oxides, which are the basic elements to realize the EEPROM function of the memory. Most of these tests are complex and time-consuming.	bit cell;cost efficiency;display resolution;eeprom;error detection and correction;mathematical optimization;maverick framework;programmable read-only memory	Peter G. Sarson;Gregor Schatzberger;Friedrich Peter Leisenberger	2017	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2016.2634589	quality assurance;embedded system;electronic engineering;computer hardware;computer science;engineering;electrical engineering;operating system;reliability;software testing;eprom	EDA	21.384930758720067	53.74715938693687	60796
4016be60a5cabcc5ffe940cc5faea53a50a90f9b	compact library of efficient polymorphic gates based on ambipolar transistors	impedance;switching circuits;logic gates;integrated circuit modeling	Main goal of this paper is to propose a compact library of polymorphic gates based on suitable type of reconfigurable transistors. In fact, their exploitation brings a significant advantage for space-efficient synthesis of complex polymorphic circuits. Actual behaviour of those transistors closely depends on so called ambipolar property. That particular aspect simply allows the selection of n- or p- channel operating mode of the transistor structures which is controlled by means of switching the voltage level at a dedicated control electrode. The gates were developed by an evolution approach using Cartesian genetic programming. Various discrete switch-level ambipolar transistor models extended by taking into account the threshold voltage drop degradation effect were used. A diverse range of polymorphic gates were designed, which clearly shows significant transistor savings compared to the conventional approaches. Finally, the individual components that belong to the library also suggest the opportunity how to considerably reduce the target size of complex polymorphic circuits.	cartesian closed category;elegant degradation;genetic programming;transistor model	Jan Nevoral;Vaclav Simek;Richard Ruzicka	2017	2017 12th International Conference on Design & Technology of Integrated Systems In Nanoscale Era (DTIS)	10.1109/DTIS.2017.7930180	electronic engineering;nor logic;engineering;electrical engineering;pass transistor logic;nanotechnology	EDA	15.382625075349827	57.55313075653244	60895
99abcdd89332089c644d2414e4255c9835ed7b44	an analysis of atpg and sat algorithms for formal verification	hardware verification;boolean functions;search engines;computability;automatic test pattern generation;state of the art solvers;automatic test pattern generation algorithms;satisfiability;depth first decision orderings satisfiability automatic test pattern generation algorithms state of the art solvers hardware verification breadth first decision orderings;boolean algebra;sat;boolean algebra formal verification logic cad automatic test pattern generation computability;formal verification;data structures;logic testing;performance analysis;algorithms;breadth first decision orderings;automatic test pattern generator;logic cad;algorithm design and analysis;depth first decision orderings;flexible printed circuits;algorithm design and analysis automatic test pattern generation formal verification data structures boolean functions hardware performance analysis flexible printed circuits search engines logic testing;hardware;atpg	We analyze the performance of satisfiability (SAT) and Automatic Test Pattern Generation (ATPG) algorithms in two state-of-the-art solvers. The goal is to best understand how features of each solver are suited for hardware verification. For ATPG, we analyze depth-first and breadth-first decision orderings and effects of two weighting heuristics in the decision ordering, and also study the effect of randomization of decisions. Features of ATPG and SAT that affect their robustness and flexibility on real circuits are studied, and the two solvers are compared on 24 industrial circuits. We further analyze the results to identify the strengths and shortcomings of each solver. This will enable incorporation of features from each solver in order to optimize performance, since they both operate on the same principles.		Ganapathy Parthasarathy;Chung-Yang Huang;Kwang-Ting Cheng	2001		10.1109/HLDVT.2001.972826	data structure;computer science;theoretical computer science;automatic test pattern generation;programming language;algorithm	EDA	17.97570158304259	48.20720009150445	61275
592e1f496761746ec0e60857b3695654027a881f	a hardware memetic accelerator for vlsi circuit partitioning	reconfigurable computing;circuit partitioning;hardware accelerator;fpga;memetic algorithm;memetic algorithms;handel c;place and route;genetic algorithm;genetic algorithms;optimal algorithm;software implementation	During the last decade, the complexity and size of circuits have been rapidly increasing, placing a stressing demand on industry for faster and more efficient CAD tools for VLSI circuit layout. One major problem is the computational requirements for optimizing the place and route operations of a VLSI circuit. Thus, this paper investigates the feasibility of using reconfigurable computing platforms to improve the performance of CAD optimization algorithms for the VLSI circuit partitioning problem. The proposed Genetic Algorithm architecture achieves up-to 5x speedup over conventional software implementation while maintaining on average 88% solution quality. Furthermore, a reconfigurable computing based Hybrid Memetic Algorithm improves upon this solution while using a fraction of the execution time required by the conventional software based approach.	circuit diagram;computer program;computer-aided design;field-programmable gate array;genetic algorithm;local search (optimization);mathematical optimization;memetic algorithm;memetics;partition problem;place and route;reconfigurable computing;requirement;run time (program lifecycle phase);speedup;very-large-scale integration	Stephen Coe;Shawki Areibi;Medhat A. Moussa	2007	Computers & Electrical Engineering	10.1016/j.compeleceng.2007.02.003	parallel computing;real-time computing;genetic algorithm;computer science;artificial intelligence;theoretical computer science;memetic algorithm	EDA	10.26313014657776	49.05239035331165	61355
60b32f74cce0ac1965cd42354fb14b984bc9f4ce	impact of test compression on power supply noise control	compression constraints test compression power supply noise control embedded deterministic test edt psn control algorithm;very large scale integration;nanotechnology;power supplies to apparatus interference suppression;fault tolerant systems;power supply noise;test compaction compression power supply noise;fault tolerance;decision support systems;decision support systems fault tolerance fault tolerant systems very large scale integration nanotechnology discrete fourier transforms;discrete fourier transforms;test compaction compression	Compaction and compression are commonly used to minimize test data volume and test application time. Both techniques can greatly affect power supply noise (PSN) during test, as these techniques take advantage of the fact that test patterns have low care-bit density. However, there is little prior work studying how compression affects PSN. In this work, embedded deterministic test (EDT) and Illinois Scan patterns are generated with and without compaction. Our previous PSN control algorithm is extended to incorporate the compression constraints and applied to these patterns. The experimental results show that with the PSN control algorithm, EDT lowers the maximal PSN by 24.15% and Illinois Scan lowers it by 2.77% on un-compacted patterns. The maximal PSN is 22.32% and 6.94% lower on compacted patterns.	algorithm;areal density (computer storage);data compaction;embedded system;event dispatching thread;maximal set;power supply;test card;test compression;test data	Tengteng Zhang;D. M. H. Walker	2015	2015 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFTS)	10.1109/DFT.2015.7315155	embedded system;fault tolerance;electronic engineering;real-time computing;decision support system;computer science;engineering;electrical engineering;operating system;nanotechnology;very-large-scale integration	EDA	19.992856068791163	53.48697409587344	61399
deff93d5375c1407d9421aa47494dbd4b9783513	minimizing detection-to-boosting latency toward low-power error-resilient circuits	resilient circuits;reliability;dynamic voltage scaling;flip flop clustering;time borrowing;local boosting;latch clustering	Dynamic voltage scaling (DVS) has become one of the most effective approaches to achieve ultra-low-power SoC. To eliminate timing errors arising from DVS, several error-resilient circuit design techniques were proposed to detect and/or correct timing violations. The most recently proposed time-borrowing-and-local-boosting (TBLB) technique has the advantage of lower power consumption and less performance degradation due to the needlessness of pipeline stalls. On the other hand, to make the best use of the TBLB technique, the latency from error detection to voltage boosting for TBLB latches must be carefully considered, especially during physical design. To address this issue, this paper first introduces the behavior of TBLB circuits, and then presents two major design styles of TBLB latches, including TBLB macros and multi-bit TBLB latches, for reducing detection-to-boosting latency. The corresponding physical synthesis methodologies for both design styles are further proposed. Experimental results based on the IWLS benchmarks show that the proposed physical synthesis approach for resilient circuits with multi-bit TBLB latches is very effective in reducing the delay of both combinational and error-detection circuits, which indicates better circuit reliability. To our best knowledge, this is the first work in the literature which introduces the physical synthesis methodologies for TBLB resilient circuits.	low-power broadcasting	Chih-Cheng Hsu;Masanori Hashimoto;Mark Po-Hung Lin	2017	Integration	10.1016/j.vlsi.2017.01.002	embedded system;electronic engineering;parallel computing;real-time computing;engineering;reliability;statistics	EDA	18.88942981525152	57.65722859582047	61403
0dc93577ef75fdbf3341f122bca3d779b0f4827b	assist (allied signal's standardized integrated scan test)	automatic testing;design practice;vlsi application specific integrated circuits automatic testing digital integrated circuits integrated circuit testing logic testing;digital integrated circuits;application specific integrated circuits;application specific integrated circuit;aerospace testing read write memory system testing cyclic redundancy check automatic testing very large scale integration logic testing microprocessors observability fault detection;logic testing;integrated circuit testing;observability vlsi debugging assist system level testability very high speed integrated circuit application specific integrated circuits memories board system level interconnections fixed instruction set testability controller testability module scan based cells visibility functions;vlsi;high speed integrated circuits	A system-level testability approach has been developed for testing VHSIC (very-high-speed-integrated-circuit) level ASICs (application-specific integrated circuits), memories, and board/system-level interconnections. A structured approach to testability, which is implemented with a minimum impact on current design practices, is discussed. A fixed instruction set is defined so that a single testability controller, a single testability module, and scan based cells can be developed to meet all testability requirements. The testability approach has many features, including visibility functions for normal and test data, for enhanced observability. The isolation of failures on boards or devices can be accomplished with the debug facilities. Device and memory initialization is executed through the testability bus. At-speed testing can be implemented to detect the process defects which cause timing-related faults. >		Gordon Sapp	1990		10.1109/TEST.1990.114005	embedded system;electronic engineering;real-time computing;computer science;test compression;application-specific integrated circuit;system testing	EDA	22.185989130997296	50.9244072259964	61668
84812d05201dab992e7031641f3751535337ec07	ifill: an impact-oriented x-filling method for shift- and capture-power reduction in at-speed scan-based testing	error detection and correction;error tolerance;circuit switched;dna self assembly;tiling;shift power reduction;integrated circuit testing boundary scan testing integrated circuit reliability;checkpointing;capture power reduction;boundary scan testing;circuit switching;circuit reliability;at speed scan based testing;integrated circuit testing;normal modes;manufacturing test ifill x filling technique shift power reduction capture power reduction at speed scan based testing circuit reliability circuit switching;ifill;power reduction;power consumption;integrated circuit reliability;x filling technique;manufacturing test;circuit testing energy consumption power dissipation benchmark testing system testing laboratories power engineering computing computer architecture content addressable storage computer science	In scan-based tests, power consumptions in both shift and capture phases may be significantly higher than that in normal mode, which threatens circuits' reliability during manufacturing test. In this paper, by analyzing the impact of X-bits on circuit switching activities, we present an X-filling technique that can decrease both shift- and capture-power to guarantees the reliability of scan tests, called iFill. Moreover, different from prior work on X-filling for shift-power reduction which can only reduce shift-in power, iFill is able to decrease power consumptions during both shift-in and shift-out. Experimental results on ISCAS'89 benchmark circuits show the effectiveness of the proposed technique.	benchmark (computing);circuit switching;normal mode	Jia Li;Qiang Xu;Yu Hu;Xiaowei Li	2008	2008 Design, Automation and Test in Europe	10.1145/1403375.1403663	embedded system;electronic engineering;real-time computing;telecommunications;computer science;engineering;circuit switching	EDA	20.55731537089505	53.78924123237221	61753
d1313432c3deeb889da65cb558ba80a3a4c1ea82	highly efficient test response compaction using a hierarchical x-masking technique	design for testability;circuit faults;industrial designs efficient test response compaction hierarchical x masking technique high effective compactor architecture hierarchical configurable masking register x densities masking logic scan chains mask control signals automated test equipment timing flexibility multisite testing;x masking;x values design for testability dft test response compaction x masking;loading;automatic test equipment;logic circuits;x values;hierarchical x masking technique;testing;scan chains;masking logic;shift registers automatic test equipment logic circuits logic testing masks;mask control signals;compaction;registers;design for testability dft;shift registers;compaction testing loading timing latches registers circuit faults;logic testing;test response compaction;automated test equipment;multisite testing;latches;automated test equipment timing flexibility;industrial designs;masks;dynamic adaptation;high effective compactor architecture;efficient test response compaction;x densities;industrial design;hierarchical configurable masking register;timing	This paper presents a highly effective compactor architecture for processing test responses with a high percentage of x-values. The key component is a hierarchical configurable masking register, which allows the compactor to dynamically adapt to and provide excellent performance over a wide range of x-densities. A major contribution of this paper is a technique that enables the efficient loading of the x-masking data into the masking logic in a parallel fashion using the scan chains. A method for eliminating the requirement for dedicated mask control signals using automated test equipment timing flexibility is also presented. The proposed compactor is especially suited to multisite testing. Experiments with industrial designs show that the proposed compactor enables compaction ratios exceeding 200x.	1-bit architecture;algorithm;built-in test equipment;canonical account;cell (microprocessor);data compaction;data masking;device under test;directshow;fault coverage;fault model;push-button;test automation	Thomas Rabenalt;Michael Richter;Frank Poehl;Michael Gössel	2012	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2011.2181847	embedded system;automatic test equipment;computer architecture;electronic engineering;real-time computing;industrial design;computer science;engineering	EDA	20.386255183418307	51.74771532634042	61850
7dac3437d9ab69e1d6b16e142a27a2b2768b7e89	hazard-free self-timed design: methodology and application	logic hazard;vlsi cmos implementation;new variable;measured performance;equation hazard;signal-transition graph constraint;hazard-free self-timed design;delay model;implementation guarantees immunity;integrity guarantees immunity	This paper introduces an original methodology for hazard-free self-timed design, assuming the worst conditions for robustness. Hazards are classified under three types. Equation hazards are eliminated by an optimal covering. A new variable, labeled state-trajectory is proposed: its integrity guarantees immunity to function hazards. The choice of the delay model for implementation guarantees immunity to logic hazards. Signal-transition graph constraints support safe interaction with synchronous processes. The method was applied to the VLSI CMOS implementation of a router for a parallel machine. Specific cells are designed. Measured performances are presented.		Eric Senn;Pietro Perona	2000	Integrated Computer-Aided Engineering		real-time computing;computer science;artificial intelligence	EDA	22.685897581477136	48.32787114344165	61924
457b60c4e64bc1c3bef0baa3fb29ae67d495e798	new power gating structure with low voltage fluctuations by bulk controller in transition mode	leakage current;low voltage voltage control power supplies voltage fluctuations circuit noise circuit simulation energy consumption leakage current cmos technology switches;power gating;voltage fluctuations power gating structure bulk controller system on a chip leakage power consumption subthreshold leakage current reduction sleep transistors vdd voltage drop ground bounce inductive noise power supply line instantaneous current;system on a chip;power supply;integrated circuit design;low voltage;leakage power;system on chip;low power electronics;power consumption;system on chip integrated circuit design low power electronics power consumption	System-on-a-chip with multiple power domains reduces leakage power consumption by power gating which shut off the idle blocks. Power gating is an effective technology to reduce sub-threshold leakage current. However, without good understanding and careful design, negative effects of power gating may overwhelm the potential gain and make the technique not worth the effort. For example, power gating may cause instantaneous current when sleep transistors are turned on. And instantaneous current will lead to VDD voltage drop, ground bounce, and inductive noise in power supply line. To reduce the ground bounce, we proposed new power gating structures with added bulk controller when sleep transistors are turned on. Simulation results show that the maximum voltage fluctuations for our power gating structures are smaller than those for the other power gating structures. Our power gating structures reduce the instantaneous current and voltage fluctuations in the power supply line.	ground bounce;power domains;power gating;power supply;quantum fluctuation;shutdown (computing);simulation;spectral leakage;system on a chip;transistor;value-driven design	Chung-Yu Chang;Wei-Bin Yang;Ching-Ji Huang;Cheng-Hsing Chien	2007	2007 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2007.378656	power supply rejection ratio;power gain;system on a chip;embedded system;power module;electronic engineering;switched-mode power supply applications;power factor;computer science;engineering;electrical engineering;operating system;constant power circuit;power supply unit;switched-mode power supply;clock gating;volt-ampere;voltage optimisation;power semiconductor device;low-power electronics;voltage regulation	Arch	18.354904508969366	57.28319975413856	62026
2071ca6cc83208ef6d51d5ed260627387a2b0cd7	a comparative study of the design of synchronous and asynchronous self-checking risc processors	high clock speed;comparative study;asynchronous self-checking risc processors;reduced power;deep sub-micron technology;afault coverage;anarea overhead;asynchronous ced processor;use ofconcurrent error detection;vlsi circuit;high power consumption;area overhead;error detection;risc processors;reduced instruction set computing;fault coverage	The use of deep sub-micron technology raises a number of concerns about reliability in VLSI circuits. Shrinking geometries and reduced power supplies leave the circuits vulnerable to 'soft' and transient errors. The combination of high clock speed and large circuit area result in high power consumption and skew in clock distribution. This paper investigates the use of concurrent error detection (CED) and asynchronous design to overcome these problems. Four pipelined processor designs are compared - two synchronous, two asynchronous with one of each type using CED. Initial results indicate an area overhead of 12% in return for a fault coverage of 98.54% of all unidirectional errors. Additionally, the asynchronous CED processor has an area overhead of only 4% when compared to the synchronous non-CED design.	asynchronous i/o;asynchronous circuit;central processing unit;clock rate;error detection and correction;fault coverage;instruction pipelining;overhead (computing);power supply;very-large-scale integration	P. D. Hyde;G. Russell	2004	Proceedings. 10th IEEE International On-Line Testing Symposium	10.1109/IOLTS.2004.2	asynchronous system;embedded system;reduced instruction set computing;computer architecture;electronic engineering;parallel computing;real-time computing;asynchronous circuit;computer science;operating system;synchronous circuit;synchronizer	EDA	19.505622554436915	54.97397126734254	62105
faa62d416cdebf41acc58e4d20f042fa0942aa52	design of ghz vlsi clock distribution circuit	clock signal;very large scale integration clocks routing frequency circuit optimization wire delay transmission line theory distributed parameter circuits circuit synthesis;transmission line based simulator;integrated circuit layout;clocks;routing;very large scale integration;simultaneous balanced planar tree routing;clock distribution circuit;distributed parameter circuits;clock circuit performance;signal integrity;buffer circuits;pipeline fashion;network routing;transmission line theory;wire;clock distribution;vlsi;logic cad vlsi microprocessor chips clocks pipeline processing integrated circuit layout buffer circuits network routing;industrial ghz cpu;optimal buffer insertion;frequency;logic cad;optimal algorithm;buffer insertion;industrial ghz cpu vlsi clock distribution circuit clock signal pipeline fashion simultaneous balanced planar tree routing optimal buffer insertion transmission line based simulator clock circuit performance;circuit synthesis;pipeline processing;circuit optimization;microprocessor chips;transmission line	In this paper, we derive a formula for running the clock signal in a pipeline fashion to meet the GHz frequency challenge. Moreover we present an optimal algorithm for simultaneous balanced planar tree routing and optimal buffer insertion to reach the GHz limit. To ensure the signal integrity, we have developed a very efficient transmission line based simulator, which plays a key role in verifying the clock circuit performance. The proposed method is successfully used to design a real industrial GHz CPU.	very-large-scale integration	X. Zeng;Dengji Zhou	2001		10.1109/ISCAS.2001.922067	embedded system;routing;electronic engineering;real-time computing;asynchronous circuit;clock domain crossing;clock skew;computer science;electrical engineering;transmission line;very-large-scale integration;synchronous circuit;digital clock manager;cpu multiplier	EDA	15.695201528528978	52.07188054643623	62155
217294bc3ce42d0b4998c3713bf90b2ee71be4ae	demonstration of integrated micro-electro-mechanical switch circuits for vlsi applications	monolithic integration;cmos integrated circuits;oscillations;test chip;memory function;switching circuits;building block;integrated microelectromechanical switch circuits;oscillators;vlsi circuit testing microswitches;carry generation block;transient analysis;i o function;logic gates;microswitches;micro electro mechanical;vlsi;carry generation block integrated microelectromechanical switch circuits vlsi application test chip monolithic integration logic function timing function i o function memory function;circuit testing;switches;vlsi application;logic function;timing function;switches switching circuits very large scale integration circuit testing logic testing monolithic integrated circuits logic circuits timing inverters oscillators	Due to transistor leakage, CMOS circuits have a well-defined lower limit on their achievable energy efficiency [1]. Once this limit is reached, power-constrained applications will face a cap on their maximum throughput independent of their level of parallelism. Avoiding this roadblock requires an alternate switching device with steeper sub-threshold slope—i.e., lower VDD/Ion for the same Ion/Ioff [2]. One promising class of such devices with nearly ideal Ion/Ioff characteristics are electro-statically actuated micro-electro-mechanical (MEM) switches [6]. Although mechanical movement makes MEM circuit delay significantly larger than that of CMOS, we have recently shown that with optimized circuit topologies MEM switches may potentially enable ∼10x lower energy over CMOS at up to ∼100MHz frequencies [3].	cmos;maximum throughput scheduling;network switch;parallel computing;spectral leakage;transistor;value-driven design;very-large-scale integration	Fred Chen;Matthew Spencer;Rhesa Nathanael;Chengcheng Wang;Hossein Fariborzi;Abhinav Gupta;Hei Kam;Vincent Pott;Jaeseok Jeon;Tsu-Jae King Liu;Dejan Markovic;Vladimir Stojanovic;Elad Alon	2010	2010 IEEE International Solid-State Circuits Conference - (ISSCC)	10.1109/ISSCC.2010.5434010	control engineering;electronic engineering;computer science;engineering;electrical engineering;oscillation;quantum mechanics	EDA	16.7089202781656	57.989760519750696	62235
cd6c9430b6fb0e860c25a337d25022280dfaa361	voltage-based electromigration immortality check for general multi-branch interconnects	stress;cathodes;current response;metals;wires;algorithm;mathematical model;electromigration;rc;steady state;current density	As VLSI technology features are pushed to the limit with every generation and with the introduction of new materials and increased current densities to satisfy the performance demands, Electromigration (EM) is projected to be a key reliability issue for current and future VLSI technologies. Existing EM signoff mainly relies on current density-based assessment using Black's equation and Blech product. This model does not work well for multi-branch interconnect wires as the stresses developed in each wire segment is not independent of one another. In this paper, we present a novel and fast EM Immortality check for general multi-branch interconnect trees. Instead of using current density as the key parameter as in traditional methods, the new method estimates the EM-induced stress in general multi-branch interconnects based on the terminal voltages or potentials. It can be viewed as the Blech product for multi-branch interconnects for fast check of EM immortality of wires. Besides, this voltage-based EM (VBEM) assessment technique can naturally comprehend the impact of the topology of the wire structure on EM-induced stress. As a result, this new VBEM analysis method is very amenable to EM violation fixing as it brings new capabilities to the physical design stage. The VBEM stress estimation method is based on the fundamental steady-state stress equations. This approach eliminates the need for complex look-up tables for different geometries and can be implemented in CAD tools very easily as we demonstrate on real design examples. We show that its solution is consistent with the physics-based dynamic EM stress evaluations from the numerical analysis by COMSOL.	black's equation;computer-aided design;electrical connection;electromigration;lookup table;numerical analysis;physical design (electronics);steady state;very-large-scale integration	Zeyu Sun;Ertugrul Demircan;Mehul D. Shrof;Taeyoung Kim;Xin Huang;Sheldon X.-D. Tan	2016	2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1145/2966986.2967083	embedded system;electromigration;electronic engineering;telecommunications;engineering;electrical engineering;cathode;mathematical model;stress;forensic engineering;steady state;algorithm;current density;quantum mechanics	EDA	22.676501944753365	59.25789985717619	62302
45f04dd10254850ca3c2736146e3a58cb6d5a06b	a new design and simulation of reversible gates in quantum-dot cellular automata technology		Power dissipation is the main limitation of all the nano electronics design techniques including Quantumdot Cellular Automata (QCA). The reversible computing is considered as the reliable solution to lower the power dissipation. In this paper, the contribution is divided into three parts. In the first part, a multi-objective synthesis method is presented for reversible functions (with the objective priority of gate counts (majority gates), gate levels, the number of NOT gates, and control inputs which are the input cells with fixed polarization used for programming 2-input OR and AND gates). Based on the proposed method, a new synthesis of many of well-known reversible gates is proposed. In the second part, a new method for converting irreversible functions to the reversible one in QCA technology is presented. This method has advantages such as: having of a minimum number of garbage outputs, converting of irreversible functions to reversible one directly and as optimal (So, in this method, a sub-optimal method of using of conventional reversible blocks such as Toffoli and Fredkin are not used), and so on. For showing the efficiency of the proposed method, it is applied to the 13 standard combinational functions. In the third part, new designs of QCA layouts are presented for gates synthesized in the previous section. Results show that our proposed method outperforms the best available methods in terms of area, complexity (cell amount), delay (clocking zones), and also in logic level in terms of levels, Control inputs, number of majority and NOT gates.	automata theory;cpu power dissipation;clock rate;combinational logic;complexity;electronic design automation;gnu nano;logic level;majority function;polarization (waves);qualitative comparative analysis;quantum dot cellular automaton;reversible computing;simulation	Moein Sarvaghad-Moghaddam;Ali Asghar Orouji	2018	CoRR		and gate;electronic engineering;theoretical computer science;garbage;cellular automaton;toffoli gate;quantum dot cellular automaton;nanoelectronics;logic level;computer science;reversible computing	EDA	15.798961294196063	46.406651767351605	62423
38e5d79d9f97a6ce76a61ed7832f4cee4b030bba	circuit-level modeling and detection of metallic carbon nanotube defects in carbon nanotube fets	metallic carbon nanotubes;high coverage;nano-scaled device;circuit-level modeling;carbon nanotube fets;metallic carbon nanotube defect;nano-scaled defect;metallic nanotube fault;high performance;so-called chirality;carbon nanotube;defective cntfets;single stuck-at fault test;field effect transistor;fault detection;fault model;manufacturing;carbon nanotubes;field effect transistors;cntfet;nanotechnology	Carbon Nanotube Field Effect Transistors (CNTFET) are promising nano-scaled devices for implementing high performance, very dense and low power circuits. The core of a CNTFET is a carbon nanotube. Its conductance property is determined by the so-called chirality of the tube; chirality is difficult to control during manufacturing. This results in conducting (metallic) nanotubes and defective CNTFETs similar to stuck-on (SON or source-drain short) faults, as encountered in classical MOS devices. This paper studies this phenomenon by using layout information and presents modeling and detection methodologies for nano-scaled defects arising from the presence of metallic carbon nanotubes. For CNTFET-based circuits (e.g. intramolecular), these defects are analyzed using a traditional stuck-at fault model. This analysis is applicable to primitive and complex gates. Simulation results are presented for detecting modeled metallic nanotube faults in CNTFETs using a single stuck-at fault test set. A high coverage is achieved (~98%).	chirality (chemistry);conductance (graph);fault model;field effect (semiconductor);gnu nano;sensor;simulation;stuck-at fault;test set;transistor	Hamidreza Hashempour;Fabrizio Lombardi	2007	2007 Design, Automation & Test in Europe Conference & Exhibition		carbon nanotube field-effect transistor;field-effect transistor;electronic engineering;carbon nanotube	EDA	22.037281474885077	58.76547059321857	62493
d7d4d1662734e63bb0b018fc81d8697457260cb0	achieving board-level bist using the boundary-scan master	automatic testing;electronic equipment testing;packaging;built in self test;logic testing;access protocols;system testing;circuit testing;built in self test circuit testing system testing automatic testing logic testing electronic equipment testing packaging throughput hardware access protocols;throughput;hardware	A board-level test strategy based on ANSIhEEE Std 1149.1-1990 is presented. A essential component of tlhis strategy is an intelligent parallel-serial protocol conviersion dievice-the Boundary-Scan Master (BSM). With the BSM, we can rapidly realize generic board level Built., In Self-Test (BIST) with a minimal amount of effort.	boundary scan;built-in self-test	Najmi T. Jarwala;Chi W. Yau	1991		10.1109/TEST.1991.519729	non-regression testing;embedded system;black-box testing;packaging and labeling;throughput;electronic engineering;software performance testing;white-box testing;manual testing;integration testing;computer science;engineering;acceptance testing;conformance testing;smoke testing;software testing;real-time testing;system testing;test management approach;computer engineering	Robotics	10.23580570573114	53.71995417977992	62584
5f6399efb3143022801202b84164e9a7ca62b4f2	alleviate chip i/o pin constraints for multicore processors through optical interconnects	wavelength division multiplexing multichip modules multiprocessing systems optical interconnections;chip pin counts chip i o pin constraints multicore processors optical interconnects electrical interconnects receiver sensitivities crosstalk noises attenuations;optical interconnections optical waveguides limiting optical transmitters optical receivers energy consumption crosstalk	Chip I/O pins are an increasingly limited resource and significantly affect the performance, power and cost of multicore processors. Optical interconnects promise low power and high bandwidth, and are potential alternatives to electrical interconnects. This work systematically developed a set of analytical models for electrical and optical interconnects to study their structures, receiver sensitivities, crosstalk noises, and attenuations. We verified the models by published implementation results. The analytical models quantitatively identified the advantages of optical interconnects in terms of bandwidth, energy consumption, and transmission distance. We showed that optical interconnects can significantly reduce chip pin counts. For example, compared to electrical interconnects, optical interconnects can save at least 92% signal pins when connecting chips more than 25 cm (10 inches) apart.	analytical engine;central processing unit;crosstalk;electrical connection;input/output;multi-core processor;speaker wire	Zhehui Wang;Jiang Xu;Peng Yang;Xuan Wang;Zhe Wang;Luan H. K. Duong;Zhifei Wang;Haoran Li;Rafael Kioji Vivas Maeda;Xiaowen Wu;Yaoyao Ye;Qinfen Hao	2015	The 20th Asia and South Pacific Design Automation Conference	10.1109/ASPDAC.2015.7059107	embedded system;electronic engineering;parallel computing;engineering	EDA	14.366675985165212	56.946081176132004	62638
9d82c873beedd6589a6544e98d4158b38b9f1572	interposer test: testing pcbs that have shrunk 100x		Silicon Interposer is the new PCB where silicon of different process technologies (like logic, DRAM, analog, etc.) can be bonded onto and integrated into the same package. Silicon interposer has microbumps on one side and flipchip (C4) bumps on the other, and signal on one side are connected to the other with TSV (Through Silicon Vias). Die to die interconnects are just wires from one microbump to another without connecting to any C4 on the bottom side. Essentially, these are tiny PCBs that have their dimensions shrink by 100x. Conceptually PCB essentially are just interconnects so testing really are just open/short and maybe leakage, i.e., ONLY if you can connect (or probe) to the microbumps. However, at 40–50um pitch, they are almost half the pitch of the most advanced flipchip bump technology with tens of thousands of microbumps in a typical application. The tight pitch and mass quantity of microbumps would drive for new probe technologies (read, more expensive) and complex test optimization at the ATE side. There is also no transistors (nor diodes) on this new PCB, so all you learnt about DFT is out the window. At the same time, it is expected to have zero test cost (as yield should be high). Some in the industry have suggested “Pretty Good Interposer”, only testing for systematics and not defects. Is, “pretty good”, good enough to stand in for “known good”? It all depends on what you put on these interposers and potentially yield loss can kill a product's viability. This talk will try to elaborate the challenges and will try to propose new test methods for testing these new, miniature PCB.	interposer	T. M. Mak	2014		10.1109/TEST.2014.7035334	electronic engineering;engineering;electrical engineering;forensic engineering	SE	11.484757356734704	57.34056359070161	62669
7498a96ddd0386f5bdb2d817c950484241e82e8f	a genetic algorithm high-level optimizer for complex datapath and data-flow digital systems	field programmable gate array;data type;high level synthesis;digital systems;resource sharing;genetic algorithm;optimization;digital circuits;hardware description language;data flow;fitness function	In this paper we present a methodology for optimizing complex datapath oriented digital circuits. An optimizer was developed based on the earlier development of an automatic circuit synthesizer that synthesizes hardware description language specifications based on available functional modules. A genetic algorithm is tailored to the problem of digital circuit optimization through the development of specific structures and procedures. In particular, a concise encoding of the circuit is developed that the genetic algorithm can manipulate. Specific crossover and mutation mechanisms are also developed to complement the functionality of the synthesizer. The searches are effected by altering module data type, hardware resource sharing, and module implementation version. A fitness function is derived that makes use of a number of optimization parameters to objectively evaluate each particular circuit. The features of each circuit are calculated and estimated during the analysis phase. # 2006 Elsevier B.V. All rights reserved.	dataflow;datapath;digital electronics;fitness function;genetic algorithm;hardware description language;high- and low-level;mathematical optimization	Zoran A. Salcic;George G. Coghill;R. Bruce Maunder	2007	Appl. Soft Comput.	10.1016/j.asoc.2006.06.004	shared resource;data flow diagram;real-time computing;genetic algorithm;data type;computer science;theoretical computer science;machine learning;hardware description language;high-level synthesis;fitness function;digital electronics;register-transfer level;field-programmable gate array	EDA	10.811305986233684	48.975678621566324	62700
1be08666d036f5f4741bf9f537b8ff1974fd5a6b	correlating defects to functional and i/sub ddq/ tests	cmos digital ics defect correlation functional tests i sub ddq tests failure screening curve fitting correlation data defect quality multiple test types pattern sensitive defects pattern insensitive defects qc;failure analysis;cmos digital integrated circuits;integrated circuit testing;testing fault detection equations semiconductor device modeling mosfets application specific integrated circuits cmos technology curve fitting manufacturing mos devices;curve fitting;quality control;quality control integrated circuit testing cmos digital integrated circuits failure analysis curve fitting	Functional tests and I/sub DDQ/ tests are studied to determine their effectiveness toward screening failures. A model is presented for curve fitting correlation data between fault coverages and defect quality employing the Williams and Brown defect level to fault coverage equation. The model is used for multiple test types. Empirical data were gathered to demonstrate its effectiveness over functional and I/sub DDQ/ tests. I/sub DDQ/ test data demonstrates two categories of I/sub DDQ/ defects: pattern sensitive and pattern insensitive defects.		Theo J. Powell;James R. Pair;Bernard G. Carbajal	1996		10.1109/TEST.1996.557075	reliability engineering;embedded system;failure analysis;quality control;electronic engineering;engineering;statistics;curve fitting	Logic	22.988585872663506	54.83594281424109	62791
abdac6546656bc220409593ab45e7c24dc243286	a 40 nm 512 kb cross-point 8 t pipeline sram with binary word-line boosting control, ripple bit-line and adaptive data-aware write-assist	static random access memory sram;voltage control adaptive control circuit stability cmos memory circuits detector circuits integrated circuit design sram chips;boosting pipelines sram cells delays latches logic gates;adaptive data aware write assist adawa;write ability;ripple bit line;article;adaptive voltage detector avd;write ability adaptive data aware write assist adawa adaptive voltage detector avd ripple bit line static random access memory sram	This paper presents a cross-point 512 kb 8 T pipeline static random-access memory (SRAM). The cross-point structure eliminates write half-select disturb to facilitate bit-interleaving architecture for enhanced soft error immunity. The design employs boosted word-line (WL) for improving both read performance and write-ability. A ripple bit-line (RiBL) structure provides 30%-44% read access performance improvement and 2 ×-3.5 × variation immunity at 0.7 V compared with the conventional hierarchical bit-line (HiBL) schemes. An adaptive data-aware write-assist (ADAWA) with VCS tracking is employed to further enhance the write-ability while ensuring adequate stability for half-selected cells on the selected bit-lines. An adaptive voltage detector (AVD) with binary boosting control is used to mitigating gate electric over-stress. The design is implemented in UMC 40 nm low-power (40LP) CMOS technology. The 512 kb test chip operates from 1.5 V to 0.65 V, with maximum operation frequency of 800 MHz@1.1 V and 200 MHz@0.65 V. The measured power consumption is 0.5 mW/MHz (active) and 4.4 mW (standby) at 1.1 V, and 0.107 mW/MHz (active) and 0.367 mW (standby) at 0.65 V.	boosting (machine learning);cmos;error detection and correction;forward error correction;low-power broadcasting;random access;ripple effect;sleep mode;soft error;static random-access memory;veritas cluster server	Nan-Chun Lien;Li-Wei Chu;Chien-Hen Chen;Hao-I Yang;Ming-Hsien Tu;Paul-Sen Kan;Yong-Jyun Hu;Ching-Te Chuang;Shyh-Jye Jou;Wei Hwang	2014	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2014.2336531	electronic engineering;parallel computing;real-time computing;computer science	Arch	17.83793478626978	59.00626564019138	62937
93a15dd55013b2e5071d88bcf46661ed0f07d6b2	smart-substrate multichip-module systems	smart substrate multichip module systems incremental test microcontroller emulator test logic;logic design;multichip module;multichip modules;logic testing;logic design logic testing multichip modules;costs system testing packaging circuit testing manufacturing multichip modules system performance conductors power generation economics prototypes	This implementation strategy enables incremental test of all system components, providing an alternative solution to the known good die testing problem. The authors present a simple microcontroller emulator designed and fabricated for study of the test logic needed as a key component of this method.<<ETX>>	die (integrated circuit);emulator;microcontroller	Wojciech Maly;Derek Feltham;Anne E. Gattiker;Mark D. Hobaugh;Kenneth Backus;Michael E. Thomas	1994	IEEE Design & Test of Computers	10.1109/54.282446	embedded system;electronic engineering;logic synthesis;logic family;computer science;engineering;computer engineering	EDA	10.25387439947251	53.34511865018331	63064
78226ec9612769e47f04ef851e747eecd6fbcd30	placement-aware clustering for integrated clock and power gating	cmos integrated circuits;cluster algorithm;pattern clustering;cmos technology;integrated clock grating;clocks;leakage reduction;power gating;logic circuits;clocks character generation clustering algorithms timing cmos technology electronic design automation and methodology logic circuits integrated circuit synthesis testing algorithm design and analysis;testing;layout;clock gating;layout oriented synthesis flow;cmos technology library;power gating circuitry;integrated circuit design;electronic design automation and methodology;commercial synthesis tool;logic gates;registers;pattern clustering clocks cmos integrated circuits integrated circuit design;character generation;industrial design flow;clustering algorithms;integrated circuit synthesis;placement aware clustering;size 65 nm placement aware clustering integrated clock grating power gating circuitry industrial design flow commercial synthesis tool layout oriented synthesis flow cmos technology library;size 65 nm;algorithm design and analysis;industrial design;timing	Clock-gating and power-gating are the most widely used solutions for reducing dynamic and static power. They can be potentially integrated so that clock-gating conditions can be used to control the power-gating circuitry thus also reducing static power. This integration becomes however difficult when applied in an industrial design flow. Even if both clock and power-gating are supported by most commercial synthesis tools, their combined implementation requires some flexibility in the back-end tools that is not currently available.	algorithm;clock gating;cluster analysis;electronic circuit;overhead (computing);power gating;real life;spectral leakage	Letícia Maria Veiras Bolzani;Andrea Calimera;Alberto Macii;Enrico Macii;Massimo Poncino	2009	2009 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2009.5118107	embedded system;computer architecture;electronic engineering;real-time computing;industrial design;logic gate;computer science;engineering;common power format;cmos	Arch	15.32131021723466	54.263458896112816	63148
8df6a6c78767fc2de4da27f8a5e7167b0d992df0	a hybrid methodology for switching activities estimation	circuit simulation switching circuits energy consumption capacitance cmos logic circuits large scale integration logic circuits data structures boolean functions very large scale integration;switching activity;switching;probability;boolean functions;sequential circuits;probabilistic approach;probabilistic model;hybrid approach;spatial correlation;cmos logic circuits;vlsi;switching cmos logic circuits sequential circuits circuit analysis computing boolean functions probability delays vlsi;correlated data;circuit analysis computing;delays;cmos circuits hybrid methodology switching activities estimation internal nodes logic circuits simulation based technique probability based technique user specified control sequence probabilistic model bdd binary decision diagrams	In this paper, we propose a hybrid approach for estimating the switching activities of the internal nodes in logic circuits. The new approach combines the advantages of the simulation-based techniques and the probability-based techniques. We use the user-specified control sequence for simulation, and treat the weakly correlated data inputs using the probabilistic model. The new approach, on one hand, is more accurate than the probabilistic approaches because the strong temporal and spatial correlations among control inputs are well taken into consideration. On the other hand, the new approach is much more efficient than the simulation-based approaches because the weakly correlated data inputs are not explicitly simulated. We also discuss the situation where BDD's are built in terms of internal nodes so that large circuits can he handled. Extensive experimental results are presented to show the effectiveness and efficiency of our algorithms.		David Ihsin Cheng;Kwang-Ting Cheng;Deborah C. Wang;Malgorzata Marek-Sadowska	1998	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.703825	statistical model;electronic engineering;spatial correlation;computer science;theoretical computer science;machine learning;probability;mathematics;sequential logic;very-large-scale integration;boolean function;statistics	EDA	22.960148987706493	51.213096178569025	63244
5621631abebf583c47fea54af9596c81cdc3c416	derivation of minimal complete sets of test-input sequences using boolean differences	boolean differences;fault detection;error diagnosis;switching network reliability and maintenance;switching network;boolean differences error diagnosis fault detection switching network reliability and maintenance;fault detection and diagnosis	This paper deals with a fault detection and diagnosis technique based on Boolean differences. A brief review of the notion of a Boolean difference is presented, and the concept of partial Boolean difference is introduced. An algorithm for obtaining minimal, complete sets of test-input sequences based on the partial Boolean differences of a switching function is formulated, and illustrations demonstrating the use of the technique are presented.	algorithm;fault detection and isolation	Peter N. Marinos	1971	IEEE Transactions on Computers	10.1109/T-C.1971.223077	boolean circuit;and-inverter graph;circuit minimization for boolean functions;discrete mathematics;standard boolean model;computer science;theoretical computer science;mathematics;fault detection and isolation;algorithm	EDA	22.735317557683683	46.9217844413306	63367
33f7f571327613cdc8c1df751692f7d5be61e301	efficient sat solving: beyond supercubes	design automation;supercubing;learning;design engineering;boolean functions;application software;search space;business continuity engines electronic design automation and methodology permission computer science application software robustness design engineering design automation artificial intelligence;extensive benchmark runs;sat solving;supercubes;boolean satisfiability;sat;electronic design automation and methodology;formal verification;engines;business continuity;permission;synthetic benchmarks;search space pruning;artificial intelligence;robustness;eda applications;circuit cad;computer science;learning artificial intelligence;primary boolean reasoning engine;boolean functions circuit cad learning artificial intelligence;search space pruning sat solving supercubes boolean satisfiability primary boolean reasoning engine eda applications supercubing b cubing practical solver extensive benchmark runs real problems synthetic benchmarks zchaff formal verification learning;real problems;practical solver;zchaff;b cubing	SAT (Boolean satisfiability) has become the primary Boolean reasoning engine for many EDA applications, so the efficiency of SAT solving is of great practical importance. Recently, Goldberg et al introduced supercubing, a different approach to search-space pruning, based on a theory that unifies many existing methods. Their implementation reduced the number of decisions, but no speedup was obtained. In this paper, we generalize beyond supercubes, creating a theory we call B-cubing, and show how to implement Bcubing in a practical solver. On extensive benchmark runs, using both real problems and synthetic benchmarks, the new technique is competitive on average with the newest version of ZChaff, is much faster in some cases, and is more robust.	benchmark (computing);boolean satisfiability problem;chaff algorithm;dhrystone;semantic reasoner;solver;speedup	Domagoj Babic;Jesse D. Bingham;Alan J. Hu	2005	Proceedings. 42nd Design Automation Conference, 2005.	10.1145/1065579.1065774	embedded system;mathematical optimization;electronic engineering;application software;electronic design automation;formal verification;#sat;computer science;theoretical computer science;operating system;machine learning;mathematics;boolean satisfiability problem;programming language;algorithm;robustness	EDA	17.2868879780706	47.41903810223015	63369
0248da26006214f8e5ba7313de39331c5d736495	ultra-low power hybrid cmos-magnetic logic architecture	stt clock;magnetic logic;cmos integrated circuits;tmr based differential read;nanomagnetics cmos integrated circuits low power electronics magnetic logic magnetic tunnelling;22 nm cmos integration;nanomagnetic logic;variability tolerant;spin transfer torque;variability tolerant low power mtj nanomagnetic logic spin transfer torque stt clock stt write tmr based differential read 22 nm cmos integration;mtj;stt write;low power;magnetic tunnelling;low power electronics;computer architecture clocks microprocessors magnetic tunneling transistors couplings cmos integrated circuits;spin transfer torque current ultra low power hybrid cmos magnetic logic architecture dipolar magnetic coupling single layer nanomagnets nanomagnetic logic miltilayer magnetic tunnel junctions;nanomagnetics	Dipolar magnetic coupling between single layer nanomagnets is used in nanomagnetic logic (NML). Apart from writing and reading, nanomagnets are also clocked using external magnetic fields generated by current carrying wires. The related current ranges in mA and consumes large power. Also, the fields cannot sharply terminate at boundaries between nanomagnets that are required to be in different clock zones. The above concerns motivated us to look into alternate magnetic devices to realize magnetic logic. We therefore suggested miltilayer magnetic tunnel junctions (MTJs) for logic. We have observed that MTJ free layers can interact with their neighbors through magnetic coupling. In this paper we have proposed use of this coupling for effective logic computation. MTJs are also CMOS friendly, a property that we used to write, clock and read from logic. CMOS integration also improves control over individual elements in logic. In this paper we have used these properties to present a novel CMOS-MTJ integrated architecture that: a) computes logic using magnetic coupling between MTJs and b) writes, clocks and reads from logic using spin transfer torque (STT) current that is more energy efficient. A feasibility study of this CMOS-MTJ integration in 22 nm CMOS technology node is also presented. The proposed architecture achieves an energy reduction >;95% in adders and multipliers when compared to traditional designs using single layer nanomagnets.	cmos;clock rate;computation;emoticon;heart rate variability;in-memory database;inductive coupling;magnetic logic;magnetoresistive random-access memory;radiation hardening;selectivity (electronic);semiconductor device fabrication;terminate (software)	Jayita Das;Syed M. Alam;Sanjukta Bhanja	2012	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2012.2185311	embedded system;and-or-invert;spin-transfer torque;electronic engineering;logic level;logic gate;logic family;computer science;engineering;electrical engineering;pass transistor logic;cmos;quantum mechanics;low-power electronics	EDA	16.35173656716926	59.03919646181555	63563
0d09589eee828db387b222e280c298510c4cb544	a novel design of low power double edge-triggered flip-flop	low power consumption;power saving;flip-flop;low-power electronics;hspice simulations;clock signal;clocks;logic design;double edge-triggered (det);det;flip-flops;low power double edge-triggered flip-flop;low power electronics	A double edge-triggered (DET) flip-flop operates on both the rising and falling edges of a clock signal. In this paper, a novel DET flip-flop, suitable for low-power applications, is proposed, Several HSPICE simulations with different input sequences show that the proposed DET flip-flop results in significant power saving as compared to existing DET flip-flops.	clock signal;detection error tradeoff;flops;flip-flop (electronics);low-power broadcasting;spice 2;simulation	Chien-Cheng Yu;Kuan-Ting Chen	2012	2012 5th International Conference on BioMedical Engineering and Informatics	10.1109/BMEI.2012.6513131	embedded system;logic synthesis;real-time computing;computer science;low-power electronics	EDA	17.203058281073478	57.634224476402196	63577
26887bb805cd16b581bb95b7e1532cea1cef0209	practical fault coverage of supply current tests for bipolar ics	process variation;functional testing;current supplies circuit testing circuit faults logic testing logic circuits electrical fault detection cmos logic circuits fault detection integrated circuit testing semiconductor device modeling;stuck at fault models fault coverage supply current tests bipolar ic bipolar integrated circuits bipolar logic circuits high speed logic circuits quiescent supply current test method bipolar circuit tests open faults bipolar logic ic production tests iscas 85 benchmark circuits test input vectors;bipolar integrated circuits;logic testing;test methods;integrated circuit testing;fault diagnosis integrated circuit testing bipolar integrated circuits logic testing bipolar logic circuits high speed integrated circuits;fault coverage;bipolar logic circuits;fault model;high speed;high speed integrated circuits;fault diagnosis	Bipolar logic circuits are indispensable for implementing high-speed logic circuits. Since quiescent supply current flows into the circuits without faults, they can not be tested by a conventional IDDQ test method. We proposed a quiescent supply current test method which is applicable for the bipolar circuit tests, and examined the testability of open faults under an ideal assumption that there are not any process variations. Actually, there are some variations in the quiescent supply current of each gate in implemented logic circuits. Thus, It is necessary to examine the practical testability of the test method before applying to production tests of bipolar logic ICs. In this paper, the practical testability obtained under an assumption that there are some unit-to-unit variations of supply current among gates is examined for ISCAS-85 benchmark circuits. The experimental results show that larger fault coverage can be obtained with a smaller number of test input vectors by our supply current test method than the functional test one based on stuck-at fault models.	benchmark (computing);fault coverage;fault model;functional testing;iddq testing;integrated circuit;logic gate;software testability;stuck-at fault;turing test	Isao Tsukimoto;Masaki Hashizume;Hiroyuki Yotsuyanagi;Takeomi Tamesada	2004	Proceedings. DELTA 2004. Second IEEE International Workshop on Electronic Design, Test and Applications	10.1109/DELTA.2004.10035	mixed-signal integrated circuit;electronic engineering;real-time computing;logic optimization;diode–transistor logic;logic level;fault coverage;logic gate;logic family;depletion-load nmos logic;engineering;electrical engineering;stuck-at fault;automatic test pattern generation;pass transistor logic;functional testing;fault model;integrated injection logic;pull-up resistor;test method;process variation;digital electronics;resistor–transistor logic;emitter-coupled logic	EDA	22.951949144474696	52.62632968414008	63603
f6734ccfcbb264a0e3e50cbfff9f12a876d52779	high-speed, low-power quasi delay insensitive handshake circuits based on finfet technology	hspice;mosfet asynchronous circuits buffer circuits;logic gates inverters pipelines power demand finfets throughput;buffer circuits;hadshake circuits;pchb;size 25 nm precharge phase evaluate phase power consumption independent gate finfet pre charged full buffer pre charged half buffer transistors shrinkage sizing asynchronous circuits low power quasidelay insensitive handshake circuits high speed quasidelay insensitive handshake circuits;asynchronous circuits;pcfb;mosfet;independent gate finfet;finfet;hspice asynchronous circuits hadshake circuits pchb pcfb finfet independent gate finfet	FinFET transistor is a promising alternative to CMOS transistor beyond 25nm technology. Independent-Gate FinFET (IGFinFET) are particularly interesting, as they have double gates and offer various options to designers. In the context of this technology, asynchronous circuits are being considered. Due to sizing and transistors shrinkage, synchronous circuits have encountered problems such as clock skew and clock tree distribution, whereas asynchronous circuits have addressed these problems by removing the global clock. Pre-Charged Half and Full Buffer (PCHB, PCFB) are asynchronous design template blocks to which high level descriptions are synthesized. In this paper, using different IGFinFET configurations, we reduce PCHB (PCFB) handshaking circuits area and power consumption by 21% and 19% (by 21% and 15%), respectively. In addition, by suitably biasing IGFinFET transistors, during the handshaking phase, we can enter evaluate and precharge phases earlier in PCHB (PCFB) circuits and thus increase throughput by 11% (9%) and decrease power consumption by 7% (5%) with no area overhead.	16-bit;4-bit;asynchronous circuit;biasing;cmos;clock signal;clock skew;critical path method;emoticon;handshaking;high-level programming language;low-power broadcasting;overhead (computing);power inverter;software propagation;suicidegirls;throughput;time-varied gain;transistor;weak ai;xfig	Mohammad Yousef Zarei;Mahdi Mosaffa;Siamak Mohammadi	2014	2014 27th International Conference on VLSI Design and 2014 13th International Conference on Embedded Systems	10.1109/VLSID.2014.91	electronic engineering;real-time computing;engineering;electrical engineering	EDA	16.69646867573496	57.069177740434775	63630
e73ba5f98b1a40e1b93a1e4d5a4783dbe5a68196	aging comparative analysis of high-performance finfet and cmos flip-flops		This paper presents a comparative performance analysis to investigate the impact of aging mechanisms on various flip-flops in CMOS and FinFET technologies. We consider Bias Temperature Instability (BTI) and Hot Carrier Injection (HCI) effects on the robustness of high performance flip-flops. To apply BTI and HCI aging mechanisms, we utilize long-term model to estimate ∆ Vth and employ the updated Vth in transistor model file. The simulation results on performance analysis indicate the high ranking of various flip-flops considering speed and power consumption in each CMOS and FinFET technologies, moreover, approve the superiority of static FinFET flip-flops over CMOS flip-flops. In addition, a comparative analysis considering temperature and VDD variations over different FinFET flip-flop structures demonstrates the average percentages of TDQmin and PDP degradation against aging mechanisms are significantly less than similar CMOS flip-flops.	cmos;flops;flip-flop (electronics);qualitative comparative analysis	Shiva Taghipour;Rahebeh Niaraki Asli	2017	Microelectronics Reliability	10.1016/j.microrel.2016.12.012	embedded system;electronic engineering;engineering;electrical engineering	HPC	19.011124646876596	59.44780665116553	63691
df4a8b197f356f7c93db6eafb5172af600bbcad5	an overlap-contention free true-single-phase clock dual-edge-triggered flip-flop	clock overlap;scaled power supply;complementary metal oxide semiconductor;logic failure;dual edge triggered flip flop;clock edge;power saving;cmos technology;det ff;ck to q delay;nanometer technology;clocks;single edge synchronous system;clock network;voltage 500 mv overlap contention free true single phase clock dual edge triggered flip flop single edge synchronous system clock frequency power saving clock network register clock edge clock overlap internally generated inverted clock logic failure scaled power supply nanometer technology static det flip flop det ff cmos technology ck to q delay power delay product complementary metal oxide semiconductor size 40 nm;flip flops;voltage 500 mv;inverters;internally generated inverted clock;size 40 nm;logic gates;cmos digital integrated circuits;synchronization;nanoelectronics;robustness;trigger circuits;clocks logic gates latches synchronization robustness delays inverters;latches;power delay product;static det flip flop;clock frequency;overlap contention free true single phase clock;trigger circuits clocks cmos digital integrated circuits flip flops nanoelectronics;register;delays	Dual-edge-triggered (DET) synchronous operation is a very attractive option for low-power, high-performance designs. Compared to conventional single-edge synchronous systems, DET operation is capable of providing the same throughput at half the clock frequency. This can lead to significant power savings on the clock network that is often one of the major contributors to total system power. However, in order to implement DET operation, special registers need to be introduced that sample data on both clock-edges. These registers are more complex than their single-edge counterparts, and often suffer from a certain amount of clock-overlap between the main clock and the internally generated inverted clock. This overlap can cause contention inside the cell and lead to logic failures, especially when operating at scaled power supplies and under process variations that characterize nanometer technologies. This paper presents a novel, static DET flip-flop (DET-FF) with a true-single-phase clock that completely avoids clock overlap hazards by eliminating the need for an inverted clock edge for functionality. The proposed DET FF was implemented in a standard 40nm CMOS technology, showing full functionality at low-voltage operating points, where conventional DET-FFs fail. Under a near-threshold, 500mV supply voltage, the proposed cell also provides a 35% lower CK-to-Q delay and the lowest power-delay-product compared to all considered DET-FF implementations.	cmos;clock network;clock rate;detection error tradeoff;flops;flip-flop (electronics);interrupt;low-power broadcasting;operating point;power supply;signal edge;throughput;total system power	Andrea Bonetti;Adam Teman;Andreas Peter Burg	2015	2015 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2015.7169017	clock synchronization;embedded system;electronic engineering;real-time computing;asynchronous circuit;telecommunications;clock domain crossing;clock skew;computer science;engineering;underclocking;timing failure;clock drift;synchronous circuit;clock gating;digital clock manager;cmos;cpu multiplier	Arch	17.953614698622022	58.206944815517225	63743
cf28751c0cf32e1da64dc72e472a733ac57e855b	power supply voltage dependence of within-die delay variation of regular manual layout and irregular place-and-route layout	design methodology;low voltage;place and route	Dependence of within-die delay variations on power supply voltage (VDD) is measured down to 0.4 V. The VDD dependence of the within-die delay variation of manual layout and irregular auto place and route (P&R) layout are compared for the first time. The measured relative delay (=sigma/average) variation difference between the manual layout and the P&R layout decreases from 1.56% to 0.07% with reducing VDD from 1.2 V to 0.4 V, because the random delay variations due to the random transistor variations dominate total delay variations instead of the delay variations due to interconnect length variations at low VDD. key words: within-die delay variation, design methodology, low voltage	place and route;power supply;transistor;value-driven design	Tadashi Yasufuku;Yasumi Nakamura;Piao Zhe;Makoto Takamiya;Takayasu Sakurai	2011	IEICE Transactions		electronic engineering;design methods;telecommunications;engineering;electrical engineering;integrated circuit;interconnection;power electronics;place and route;low voltage;die;transistor	Arch	20.483514643813788	57.30037619495318	63881
0876a3e35538336c9e1fcbab9852c72226648c9c	diode-footed domino: a leakage-tolerant high fan-in dynamic circuit design style	leakage currents logic circuits cmos logic circuits logic cad;mirrors;circuit noise;current mirror;subthreshold current;wide fan in gates;mosfets;circuit speed;leakage immunity;dynamic multiplexers diode footed domino leakage tolerant design high fan in dynamic logic circuits nmos transistor domino circuit network stacking effect evaluation path leakage deep submicron subthreshold leakage input noise circuit speed current mirror evaluation network evaluation current leakage immunity noise immunity circuit simulation wide fan in gates berkeley predictive technology models dynamic comparators;circuit design;logic circuits;indexing terms;noise robustness;dynamic logic;leakage tolerant design;circuit simulation;design technique;technology scaling;noise immunity;stacking;dynamic multiplexers;leakage currents;threshold voltage;deep submicron subthreshold leakage;cmos logic circuits;evaluation current;dynamic comparators;nmos transistor;diodes;predictive models;diode footed domino;high fan in dynamic logic circuits;domino circuit network;power consumption;diodes circuit synthesis circuit noise predictive models logic circuits mosfets stacking noise robustness subthreshold current mirrors;input noise;evaluation path leakage;logic cad;circuit synthesis;berkeley predictive technology models;stacking effect;evaluation network	A leakage-tolerant design technique for high fan-in dynamic logic circuits is presented. An NMOS transistor with gate and drain terminals tied together (diode) is added in series with the evaluation network of standard domino circuits. Due to the stacking effect, the leakage of the evaluation path significantly decreases, thereby improving the robustness of the circuit against deep-submicron subthreshold leakage and input noise. To improve the speed of the circuit, a current mirror is also employed in the evaluation network to increase the evaluation current. The proposed technique (diode-footed domino) exhibits considerable improvement in leakage and noise immunity as compared to the standard domino circuits. Simulation results of wide fan-in gates designed using Berkeley Predictive Technology Models of 70-nm technology demonstrate at least 1.9/spl times/ noise-immunity improvement at the same delay compared to the standard domino circuits. Dynamic comparators and multiplexers are designed using the diode-footed domino and conventional techniques to demonstrate the effectiveness of the proposed scheme in improving leakage-tolerance and performance of high fan-in circuits.	cmos;circuit design;comparator;current mirror;diode;diode–transistor logic;dynamic logic (modal logic);fan-in;keeper (password manager);logic gate;multiplexer;nmos logic;series and parallel circuits;simulation;spectral leakage;stacking;transistor;upsizing (database);very-large-scale integration	Hamid Mahmoodi;Kaushik Roy	2004	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2004.823665	dynamic logic;control engineering;electronic engineering;nmos logic;index term;current mirror;logic gate;computer science;engineering;electrical engineering;stacking;circuit design;predictive modelling;threshold voltage;diode	EDA	17.929384283785755	58.738263665971616	63941
1d500b9788ad9608ec3c584c0a22059bbdb0ac9a	a layout-based approach for multiple event transient analysis	cmos integrated circuits;layout logic gates transient analysis estimation integrated circuit modeling runtime benchmark testing;integrated circuit layout;logic design;transient analysis cmos integrated circuits integrated circuit layout integrated circuit modelling logic design radiation hardening electronics;error propagation transient errors soft errors;transient analysis;error propagation;integrated circuit modelling;radiation hardening electronics;soft errors;multiple event transient analysis netlist based techniques adjacent cells identification layout based technique layout analysis logic level netlist fault models soft error rate estimation technique single event transients multiple event transients cmos technology;transient errors	With the emerging nanoscale CMOS technology, Multiple Event Transients (METs) originated from radiation strikes are expected to become more frequent than Single Event Transients (SETs). In this paper, a fast and accurate layout-based Soft Error Rate (SER) estimation technique with consideration of both SET and MET fault models is proposed. Unlike previous techniques in which the adjacent MET sites are obtained from logic-level netlist, we perform a comprehensive layout analysis to extract MET adjacent cells. It is shown that layout-based technique is the only effective solution for identification of adjacent cells as netlist-based techniques significantly underestimate the overall SER.	cmos;fault model;logic level;netlist;soft error	Mojtaba Ebrahimi;Hossein Asadi;Mehdi Baradaran Tahoori	2013	2013 50th ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2463209.2488858	physical design;embedded system;electronic engineering;logic synthesis;real-time computing;ic layout editor;computer science;electrical engineering;propagation of uncertainty;integrated circuit layout;circuit extraction;cmos	EDA	21.551349884630515	56.980475385628075	63943
b3b5693c95d85d393c2b2c656ae5c641fdd82bb8	simulated annealing based yield enhancement of layouts	circuit layout cad simulated annealing vlsi network routing;simulated annealing;network routing;vlsi;circuit layout cad;defect tolerance;vlsi yield enhancement deft defect tolerant layouts fabrication induced defects overlaps nonadjacent tracks area layout synthesis systems simulated annealing;simulated annealing fabrication routing very large scale integration circuit faults circuit synthesis wire control system synthesis computational modeling area measurement	In this paper we present VEF7, a system for synthesizing defect-tolerant layouts, that ingrains tolerance t o fabrication induced defects. This is accomplished by dispersing nets with large overlaps into nonadjacent tracks. V f 3 7 also affords tradeoffs between area (measured as the number of tracks) and yield of the resulting layout. The defect-tolerant layouts synthesized by D f F 7 have been consistently superior to those generated by other layout synthesis systems.	simulated annealing;software bug;speech synthesis	Ramesh Karri;Alex Orailoglu	1994		10.1109/GLSV.1994.289975	structural engineering;routing;electronic engineering;simulated annealing;computer science;engineering;very-large-scale integration;engineering drawing;computer network	EDA	14.694763301841506	51.47057957516542	63947
6fb8dc63d35cb410f472ab2ba8e90fff95ed84ab	stream synthesis for efficient power simulation based on spectral transforms	switching activity;power estimation;high level synthesis;low voltage;low power;indexation;control flow;estimation error;power consumption;digital circuits;cmos	In this paper, we present a power estimation technique for control-flow intensive designs that is tailored towards driving iterative high-level synthesis systems, where hundreds of architectural trade-offs are explored and compared. Our method is fast and relatively accurate. The algorithm utilizes the behavioral information to extract branch probabilities, and uses these in conjunction with switching activity and circuit capacitance information, to estimate the power consumption of a given architecture. We test our algorithm using a series of experiments, each geared towards measuring a different indicator. The first set of experiments measures the algorithm's accuracy when compared to the actual circuit power. The second set of experiments measures the average tracking index, and tracking index fidelity for a series of architectures. This index measures how well the algorithm makes decisions when comparing the relative power consumption of two architectures contending as low-power candidates. Results indicate that our algorithm achieved an average estimation error of 11.8% and an average tracking index of 0.95 over all examples.	algorithm;control flow;experiment;high- and low-level;high-level synthesis;iteration;low-power broadcasting;mean squared error;simulation	Alberto Macii;Enrico Macii;Massimo Poncino;Riccardo Scarsi	1998		10.1145/280756.280764	control engineering;embedded system;electronic engineering;real-time computing;computer science;engineering;electrical engineering;low voltage;high-level synthesis;control flow;cmos;digital electronics;statistics	EDA	19.13252829055699	57.348110438233924	63958
16b4ab938d700a722c68c05b80685627156287a2	automated synthesis of skew-based clock distribution networks	clock distribution network	In this paper a top-down methodology is presented for synthesizing clock distribution networks based on application-dependent localized clock skew. The methodology is divided into four phases: 1) determination of an optimal clock skew schedule for improving circuit performance and reliability; 2) design of the topology of the clock tree based on the circuit hierarchy and minimum clock path delays; 3) design of circuit structures to implement the delay values associated with the branches of the clock tree; and 4) design of the geometric layout of the clock distribution network. Algorithms to determine an optimal clock skew schedule, the optimal clock delay to each register, the network topology, and the buffer circuit dimensions are presented.	clock signal	José Luis Neves;Eby G. Friedman	1998	VLSI Design	10.1155/1998/72951	clock synchronization;electronic engineering;real-time computing;asynchronous circuit;clock angle problem;vector clock;clock domain crossing;clock skew;computer science;distributed computing;timing failure;synchronous circuit;matrix clock;clock gating;digital clock manager;static timing analysis;clock signal;cpu multiplier	EDA	16.593939453534635	52.04263108371043	64064
0e63b75249981e28d6761306e9a48ae01c7ce46a	an efficient divide and conquer algorithm for exact hazard free logic minimization	exact hazard-free logic minimization;efficient heuristic algorithm;search space;exact hazard-free minimization;efficient divide;promising framework;significant part;proposed algorithm;divide and conquer;logic design;asynchronous logic;combinational circuits;heuristic algorithm;algorithm design and analysis;hazards;communications technology	In this paper we introduce the first divide and conquer algorithm that is capable of exact hazard-free logic minimization in a constructive way. We compare our algorithm with the method of Dill/Nowick, which was the only known method for exact hazard-free minimization. We show that our algorithm is much faster than the method proposed by Dill/Nowick by avoiding a significant part of the search space. We argue that the proposed algorithm is a promising framework for the development of efficient heuristic algorithms.	algorithm;circuit minimization for boolean functions;heuristic	J. W. J. M. Rutten;Michel R. C. M. Berkelaar;C. A. J. van Eijk;M. A. J. Kolsteren	1998			heuristic;mathematical optimization;divide and conquer algorithms;asynchronous circuit;computer science;theoretical computer science;combinational logic;algorithm	EDA	16.728999385988022	48.16499376900205	64131
5b12029427a052e35c9a2879da91aaabaefc5ac9	efficient testing of multi-output combinational cells in nano-complementary metal oxide semiconductor integrated circuits	faulty behaviours;fault simulation;faulty cell throughout;symbolic fault simulation algorithm;computability;automatic test pattern generation;sat based test generation procedure;single simulation step;logic testing automatic test pattern generation cmos logic circuits combinational circuits computability fault simulation integrated circuit testing;combinational benchmarks nanocomplementary metal oxide semiconductor integrated circuits multioutput combinational logic cells symbolic fault simulation algorithm bit level parallelism faulty cell throughout faulty behaviours single simulation step sat based test generation procedure;cmos logic circuits;logic testing;integrated circuit testing;bit level parallelism;multioutput combinational logic cells;combinational benchmarks;nanocomplementary metal oxide semiconductor integrated circuits;combinational circuits	This study addresses the problem of efficient fault simulation and test generation in circuits using multi-output combinational logic cells. A symbolic fault simulation algorithm is proposed to exploit bit-level parallelism in order to represent the propagation of the output value of faulty cells throughout the circuit, thus accounting for different faulty behaviours in a single simulation step. A satisfiability (SAT)-based test generation procedure is also provided and it early discovers sets of undetectable behaviours. Results for a set of combinational benchmarks show the feasibility of the proposed approach.		L. Valenti;Marcello Dalpasso;Michele Favalli	2014	IET Computers & Digital Techniques	10.1049/iet-cdt.2013.0077	electronic engineering;parallel computing;computer science;automatic test pattern generation;computability;combinational logic;algorithm	EDA	20.24553497876896	49.59945965179893	64171
d6f9dbcdb93fc1d35c25dc7971141f9ec0f4e1dd	routability-driven fpga placement contest	contest;placement;fpga;congestion;routability	The advances of FPGA technology and increasing size of FPGA designs pose great challenges on FPGA design tools. Deep research on FPGA physical design problems is paramount to improve industrial tools. This contest is the first ISPD contest on FPGA CAD tools. Routability driven FPGA placement, in context of large designs modern FPGA architecture, is one of the best topics to start the effort.	computer-aided design;field-programmable gate array;international symposium on physical design;physical design (electronics)	Stephen Yang;Aman Gayasen;Chandra Mulpuri;Sainath Reddy;Rajat Aggarwal	2016		10.1145/2872334.2886419	embedded system;parallel computing;computer hardware;computer science;fpga prototype;field-programmable gate array;placement	EDA	11.832945811382137	55.28070970969595	64358
17e89b718f73366b6f734f805338bd53c95b34a3	an integration of memory-based analog signal generation into current dft architectures	design for testability;signal generators;device under test;delta sigma modulation;signal sampling;automatic test pattern generation;flip flops;general techniques;indexing terms;boundary scan testing;built in self test;digital integrated circuits;signal generators circuit testing digital integrated circuits integrated circuit testing pulse modulation encoding pulse circuits digital modulation design for testability logic devices;sigma delta modulation;integrated circuit testing;mixed analogue digital integrated circuits;random access storage;sigma delta modulator;automatic test pattern generation design for testability built in self test boundary scan testing mixed analogue digital integrated circuits integrated circuit testing sigma delta modulation encoding flip flops signal sampling delta sigma modulation signal generators random access storage;design for test;short period;encoding;flip flops memory based analog signal generation integration into dft architectures mixed analog digital ic testing digital encoding serial bit stream aperiodic pulse density modulated device under test stimulation short periodic approximation analog test scheme digital test environment scan based storage ram based storage design for test logic 1149 1 1990 jtag architecture rambist controller minimal additional hardware overhead sigma delta modulation testing boundary scan;mixed analog digital integrated circuits	One method for the testing of mixed analog/digital integrated circuits involves the digital encoding of analog signals into an aperiodic pulse-density modulated (PDM) serial bit stream and using it to stimulate a device under test (DUT). This paper describes a method for obtaining a short periodic approximation of the PDM pattern and identifies two methods of integrating this analog test scheme into the current digital test environment: RAM- and scan-based storage. Using such design-for-test logic as the 1149.1-1990 JTAG architecture and a typical RAMBIST controller, these analog signal generation techniques can be added to digital integrated circuits (IC's) with minimal additional hardware overhead.	analog signal	Evan M. Hawrysh;Gordon W. Roberts	1998	IEEE Trans. Instrumentation and Measurement	10.1109/19.744341	mixed-signal integrated circuit;analog device;embedded system;electronic engineering;real-time computing;analog image processing;digital signal;computer science;engineering;delta-sigma modulation;design for testing;analog multiplier	Arch	24.30201883463612	51.636592319533754	64366
e6964dc13e8dc8df52f84c3de480dfdbcecb7c69	use of spoof's in the analysis of faulty logic networks	circuit faults;fault tolerant;logic design;boolean functions;switching circuits;fault detection and diagnosis fault equivalence fault tolerant computing reliability of digital systems spoof s;reliability of digital systems;fault tolerant computing;logic gates;fault equivalence;digital systems;fault detection;intelligent networks;spoof s;fault detection and diagnosis;fault diagnosis;computer network reliability	In general, one cannot predict the effects of possible failures on the functional characteristics of a logic network without knowlegde of the structure of that network.	spoofing attack	Frederick W. Clegg	1973	IEEE Transactions on Computers	10.1109/T-C.1973.223699	intelligent network;fault tolerance;logic synthesis;real-time computing;logic gate;telecommunications;computer science;distributed computing;boolean function;fault detection and isolation;algorithm	Visualization	23.092722550494994	49.812351132779206	64401
cdadd4220658c885338d9e898ddcc5892b549d1c	design validation on multiple-core cpu supported low power states using platform based infrared emission microscopy (pirem) technique	silicon;voltage control;microprocessors;rails;thermal sensors;silicon infrared imaging microcomputers;phase lock loop;phase locked loops;low power;silicon phase locked loops microprocessors voltage control rails thermal management thermal sensors;operating system;infrared imaging;cost effectiveness;infrared;thermal management;microcomputers;customer applications multiple core cpu supported low power states platform based infrared emission microscopy post silicon design validation methodology irem imaging techniques ia 32 multiple core nehalem microprocessor family irem characterization debug techniques windows linux operating systems	An innovative post-silicon design validation methodology using recognized industry wide IREM imaging techniques in conjunction with full PC platform enablement was developed, and successfully applied to the IA-32 multiple-core (MC) Nehalem® microprocessor family [1]. Conventional structural based “tester” IREM characterization and debug techniques can, for the first time, be extended to the “platform” environment. IREM images can now be examined for design validations by running Windows/Linux® operating systems (OS) with market available benchmark software applications. This approach has been proven to be a faster, and significantly more cost effective, approach for post silicon design validation, power debug on low power Energy Star® states, and realistic customer applications.	benchmark (computing);central processing unit;debugging;ia-32;linux;microprocessor;microsoft windows;nehalem (microarchitecture);operating system;personal computer	Yuan-Chuan Steven Chen;Dave Budka;Auston Gibertini;Dan Bockelman;Yutien Lin	2012	Proceedings of Technical Program of 2012 VLSI Design, Automation and Test	10.1109/VLSI-DAT.2012.6212615	embedded system;electronic engineering;real-time computing;engineering	EDA	10.615769817868948	55.454169985044174	64483
88bf2cf6d2cb2406e4d9df073d4695c9ed495361	hd/sup 2/bist: a hierarchical framework for bist scheduling, data patterns delivering and diagnosis in socs	chip;built in self test;complex system;scheduling;logic testing;built in self test circuit testing system testing electronic equipment testing costs logic testing hardware energy consumption large scale integration automatic logic units;integrated circuit testing;built in test;circuit layout cad;test interface hd sup 2 bist hierarchical framework bist scheduling data patterns delivery embedded cores full scan cores partial scan cores bist ready cores built in test architectures soc test strategy test access method p1500 standard;access method;integrated circuit testing built in self test scheduling logic testing circuit layout cad	1 This paper proposes HDBIST, a complete hierarchical framework for BIST scheduling, data patterns delivering, and diagnosis of a complex system including embeddedcores with different test requirements as Full Scan cores, Partial Scan cores, or BIST-ready cores. The main goal of HDBIST is to maximize and simplify the reuse of the built-in test architectures, giving the chip designer the highest flexibility in planning the overall SoC test strategy. HDBIST defines a Test Access Method (TAM) able to provide a direct “virtual” access to each core of the system, and can be conceptually considered as a powerful complement to the P1500 standard, whose main target is to make the test interface of each core independent from the vendor. 1 This work was partially supported by POLITECNICO DI TORINO under the project GIOVANI RICERCATORI 1999.	built-in self-test;scheduling (computing);system on a chip	Alfredo Benso;Silvia Chiusano;Stefano Di Carlo;Paolo Prinetto;Fabio Ricciato;Maurizio Spadari;Yervant Zorian	2000		10.1109/TEST.2000.894300	chip;embedded system;complex systems;computer architecture;real-time computing;telecommunications;computer science;engineering;operating system;access method;scheduling	EDA	11.065947658355745	53.456162766290085	64757
5513beb9c4d9b9b2168971310867d0de302c65f7	a technique of analog circuits testing and diagnosis based on neuromorphic classifier		The technique of functional testing the analog integrated circuits based on neuromorphic classifier (NC) has been proposed. The structure of NC providing detection both catastrophic and parametric faults taking into account the tolerance on parameters of internal components has been described. The NC ensures the associative fault detection reducing a time on diagnosis in comparison with parametric tables. The approach to selection of essential characteristics used for the NC training has been represented. The wavelet transform of transient responses, Monte Carlo method and statistical processing are used for the essential characteristics selection with maximum distance between faulty and fault-free conditions. The experimental results for the active filter demonstrating high fault coverage and low likelihood of alpha and beta errors at diagnosis have been shown.	integrated circuit;neuromorphic engineering	Sergey G. Mosin	2015		10.1007/978-3-319-28658-7_33	wavelet transform;fault coverage;monte carlo method;artificial intelligence;fault detection and isolation;functional testing;parametric statistics;computer science;active filter;neuromorphic engineering;pattern recognition	EDA	24.140570407826342	51.526268837077424	64883
6ab3728bc1ac809dda7a2c32367eaf4cbd5e3c7b	crosstalk noise minimization in domino logic design	crosstalk minimization logic design routing computational intelligence society circuit noise timing delay effects logic circuits coupling circuits;optimal solution;crosstalk noise;crosstalk;logic design;information search;network routing;network routing logic design crosstalk integrated circuit noise;routing algorithm;integrated circuit noise;deep submicron integrated circuit crosstalk noise minimization domino logic design crosstalk immunity set capacitive cross coupling cis identification cis phase assignment routing algorithm	Based on the new concept of crosstalk immunity set (CIS), procedures to minimize capacitive crosscoupling effects are developed for domino logic circuit. The nets in a CIS are by definition free from capacitive crosscoupling effects in any combination of input vectors. New algorithms for CIS identification and CIS-driven phase assignment are proposed to maximize the chance of crosstalk minimization in routing step. Our routing algorithm augmented with CIS information searches for optimal solution to minimize maximum crosstalk the circuit would experience. Experimental results show that the reduction of maximum crosstalk is as much as 30% with CIS-augmented routing.	crosstalk;domino logic	Ki-Wook Kim;Sung-Mo Kang	2001	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.945305	routing;electronic engineering;logic synthesis;real-time computing;crosstalk;computer science;theoretical computer science;routing;computer network	EDA	16.56379609229776	51.49710422130129	65098
6094cb4e24a62a39a7b5ffee0d68bd3322a52876	level-converting retention flip-flop for reducing standby power in zigbee socs	voltage control;latches transistors leakage currents voltage control zigbee regulators system on chip;zigbee flip flops mosfet random access storage system on chip uhf integrated circuits voltage regulators;leakage currents;system on chip;zigbee;transistors;thick oxide transistor i o supply voltage retention flip flop rff standby leakage current standby mode;power 350 25 pw level converting retention flip flop standby power reduction zigbee soc systems on chip voltage regulator core supply voltage generation logic state slave latch thick oxide transistor i o supply voltage embedded nmos pass transistor level conversion scheme low only signal transmitting technique retention latch data to output path static ram based rff size 0 13 mum voltage 1 2 v voltage 2 5 v frequency 300 mhz energy 191 70 fj;latches;regulators	In this paper, we propose a level-converting retention flip-flop (RFF) for ZigBee systems-on-chips (SoCs). The proposed RFF allows the voltage regulator that generates the core supply voltage (VDD,core) to be turned off in the standby mode, and it thus reduces the standby power of the ZigBee SoCs. The logic states are retained in a slave latch composed of thick-oxide transistors using an I/O supply voltage (VDD,IO) that is always turned on. Level-up conversion from VDD,core to VDD,IO is achieved by an embedded nMOS pass-transistor level-conversion scheme that uses a low-only signal-transmitting technique. By embedding a retention latch and level-up converter into the data-to-output path of the proposed RFF, the RFF resolves the problems of the static RAM-based RFF, such as large dc current and low readability caused by threshold drop. The proposed RFF does not also require additional control signals for power mode transitioning. Using 0.13-μm process technology, we implemented an RFF with VDD,core and VDD,IO of 1.2 and 2.5 V, respectively. The maximum operating frequency is 300 MHz. The active energy of the RFF is 191.70 fJ, and its standby power is 350.25 pW.	clock rate;embedded system;experiment;flops;flip-flop (electronics);input/output;nmos logic;power management;simulation;sleep mode;software deployment;spectral leakage;static random-access memory;system on a chip;transistor;transmitter;value-driven design;voltage regulator	Jung-Hyun Park;Heechai Kang;Dong-Hoon Jung;Kyungho Ryu;Seong-ook Jung	2015	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2014.2311851	system on a chip;embedded system;electronic engineering;real-time computing;computer science;engineering;electrical engineering;transistor	EDA	17.391304121024667	58.35641033685692	65104
600e2ccfae9e0ec5647c85f32de8719492a641ef	cooperative approach to a practical analog lsi layout system	rule based;satisfiability;large scale integration humans circuit synthesis signal processing algorithms analog computers circuit simulation wiring signal processing analog circuits digital circuits;chip;analog circuits;circuit simulation;large scale integration;signal processing;system integration;analog computers;humans;expert knowledge;digital circuits;wiring;signal processing algorithms;circuit synthesis	A system for analog LSI layout design is developed based on a human-computer cooperative approach. It can handle the many layout constraints which ensure circuit functionality. The system integrates expert knowledge with chip minimization algorithms. It consists of a rule-based layout constraint extractor, a floor planner based on a block size estimation technique, cell placement based on the circuit diagram, a grid-free maze router, rule-based layout improvement, and a space expansion router that meets the requirement for high wireablity while satisfying complex constraints. This system is applied to several actual analog LSIs for signal processing and the DC/AC parameters of the fabricated chips are evaluated. Close matching with simulated circuits demonstrates that this system meets the requirements for practical usage.	ac adapter;algorithm;block size (cryptography);circuit diagram;logic programming;maze runner;randomness extractor;requirement;router (computing);signal processing	Masato Mogaki;Yoichi Shiraishi;Mitsuyuki Kimura;Tetsuro Hino	1993	30th ACM/IEEE Design Automation Conference	10.1145/157485.165027	chip;embedded system;analog computer;electronic engineering;analogue electronics;ic layout editor;computer science;electrical engineering;signal processing;design layout record;integrated circuit layout;digital electronics;system integration;computer engineering;satisfiability	EDA	12.725365253805677	50.53295484289798	65111
78ad0c0f3595c9d54823945859bc998253407769	rex, automatic extraction of rt-level descriptions from integrated circuit layout data			circuit diagram;integrated circuit layout	Wolfgang Nebel	1986				EDA	12.91048339984222	50.53402631516515	65186
52712c359533100b96848509257faf4ecb23437c	comparison of boolean satisfiability encodings on fpga detailed routing problems	error detection and correction;encoding field programmable gate arrays routing data structures boolean functions portfolios design automation scalability availability multicore processing;parallel strategies;design automation;boolean functions;availability;routing;error tolerance;dna self assembly;tiling;portfolios;checkpointing;boolean algebra;boolean satisfiability;data structures;global routing;multicore processing;symmetry breaking;multicore cpu;field programmable gate arrays boolean algebra;scalability;field programmable gate arrays;encoding;equivalent boolean satisfiability;fpga detailed routing problems;symmetry breaking heuristics;parallel strategies equivalent boolean satisfiability symmetry breaking heuristics fpga detailed routing problems multicore cpu	We compare 12 new encodings for representing of FPGA detailed routing problems as equivalent Boolean Satisfiability (SAT) problems against the only 2 previously used encodings. We also consider two symmetry-breaking heuristics. Compared to other methods for FPGA detailed routing, SAT-based approaches have the advantage that they can prove the unroutability of a global routing for a particular number of tracks per channel, and that they consider all nets simultaneously. The experiments were run on the standard MCNC benchmarks. The combination of one new encoding with a new symmetry-breaking heuristic resulted in speedup of 3 orders of magnitude or 1,139x of the total execution time on the collection of benchmarks, when proving the unroutability of FPGA global routings. The maximum obtained speedup was 9,499x on an individual benchmark. On the other hand, most of the encodings had comparable and very efficient performance when finding solutions for configurations that were routable. The availability of many SAT encodings, that can each be combined with various symmetry-breaking heuristics, opens the possibility to design portfolios of parallel strategies---each a combination of a SAT encoding and a symmetry-breaking heuristic---that can be run in parallel on different cores of a multicore CPU in order to reduce the solution time, with the rest of the runs terminated as soon as one of them returns an answer. We found that a portfolio of three particular parallel strategies produced additional speedup of more than 2x.	benchmark (computing);boolean satisfiability problem;cpu cache;central processing unit;experiment;field-programmable gate array;heuristic (computer science);multi-core processor;routing;run time (program lifecycle phase);speedup;symmetry breaking	Miroslav N. Velev;Ping Gao	2008	2008 Design, Automation and Test in Europe	10.1145/1403375.1403682	multi-core processor;boolean algebra;embedded system;availability;symmetry breaking;routing;parallel computing;scalability;error detection and correction;data structure;electronic design automation;computer science;theoretical computer science;boolean function;boolean satisfiability problem;algorithm;field-programmable gate array;encoding	EDA	10.424573394245025	48.18350462669058	65231
49771d339847ba7e7081e152dd88dc5d6f672615	cost-performance co-analysis in vlsi implementation of existing and new defuzzification methods	vlsi fuzzy control fuzzy set theory fuzzy systems hardware description languages integrated circuit design;fuzzy membership function;defuzzification method;fuzzy control;hardware description languages;cost performance analysis;very large scale integration hardware costs fuzzy control fuzzy set theory fuzzy systems power demand application software power engineering computing analytical models;fuzzy set theory;fuzzy membership function cost performance analysis vlsi implementation defuzzification method hardware implementation c model accuracy analysis simulation hdl model;integrated circuit design;accuracy analysis simulation;hdl model;c model;vlsi;accuracy analysis;difference set;vlsi implementation;hardware implementation;fuzzy systems	In this paper, three novel defuzzification methods are presented which are appropriate for low-cost hardware implementations. An elaborate set of ten different defuzzification methods including our three newly-proposed ones are introduced. The C models for all of these methods are prepared for the accuracy-analysis simulations. The HDL models are also developed and synthesized to analyze the implementation cost of each method. This makes it possible to compare the accuracy of these different methods while considering their VLSI implementation costs. The accuracy analysis simulations are performed on six different sets of output fuzzy membership functions with various features to achieve more general and reliable results. A two-dimensional diagram of cost-accuracy analysis is introduced which helps the designers to choose the defuzzification method which best suits their application	defuzzification;diagram;hardware description language;simulation;very-large-scale integration	Abbas BanaiyanMofrad;Sied Mehdi Fakhraie;Hamid Reza Mahdiani	2005	International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)	10.1109/CIMCA.2005.1631367	defuzzification;computer science;artificial intelligence;theoretical computer science;machine learning;fuzzy set;very-large-scale integration;hardware description language;algorithm;fuzzy control system;difference set;integrated circuit design	Robotics	10.957635214594301	47.12407786930467	65271
6608d3c2ed35926bd78667565269f5399472a9c7	an efficient eigenvector approach for finding netlist partitions	graph underestimation model;graph theory;optimisation;initial node partitions;representation graphique;design automation;printed circuits;mathematics;helium;lower bounds;multiblock node interchange heuristic;interchange heuristics;printed circuit design;pcb layout;systems engineering and theory;netlist partition;approximation;methode partition;ic layout;computer aided manufacturing;number of cut nets;interconnexion;blocks of fixed module size;netlist partitioning;joining processes;vlsi;councils;circuit layout cad;hypergraph;weighted graph;integrated logic circuits;netlist partitioning pcb layout ic layout eigenvector technique initial node partitions interchange heuristics hypergraph weighted graph number of cut nets netlist partition blocks of fixed module size graph underestimation model lower bounds multiblock node interchange heuristic;vlsi circuit layout cad graph theory integrated logic circuits printed circuit design;eigenvector technique;computer aided manufacturing benchmark testing printed circuits councils mathematics systems engineering and theory joining processes design automation;circuit imprime;vecteur propre;benchmark testing;lower bound;circuit integre;eigenvectors;hypergraphe;conception modulaire	A fast eigenvector technique for obtaining good initial node partitions of netlists for use in interchange heuristics is described. The method is based on approximating the netlist or hypergraph by a weighted graph, G, such that the sum of the cut edges in G tightly underestimates the number of cut nets in any netlist partition. An eigenvector technique of Barnes [2] is used to partition the graph G into k blocks of fixed module size. Another feature of this graph underestimation model of the netlist is that it allows us to obtain lower bounds on the actual number of cut nets. A multiblock node interchange heuristic of Sanchis [20] is tested on the one resulting netlist partition obtained by this new eigenvector approach on a variety of small to large sized benchmark netlist partitioning problems (between 300 to 12 000 modules and nets). Test results on the larger netlists show that in most cases this eigenvector-node interchange approach yields netlist partitions with comparable or fewer cut nets than the best netlist partitions obtained by using node interchange heuristics alone on many random initial netlist partitions. Moreover, the running time of this method is a small fraction of the previous node interchange methods.	benchmark (computing);bridge (graph theory);heuristic (computer science);netlist;time complexity	Scott W. Hadley;Brian L. Mark;Anthony Vannelli	1992	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.144852	benchmark;mathematical optimization;combinatorics;discrete mathematics;eigenvalues and eigenvectors;computer science;graph theory;theoretical computer science;approximation;mathematics;integrated circuit layout;very-large-scale integration;upper and lower bounds;printed circuit board;helium	EDA	15.718577036151974	50.20631123780106	65352
5bfb203d88c8844e6eef1ece0d300db17d8e4b49	self-testing of fpga delay faults in the system environment	fault location field programmable gate arrays logic testing automatic testing integrated circuit testing delays table lookup;bist;automatic testing;built in self test field programmable gate arrays delay automatic testing test pattern generators table lookup;random testing;fpga;delay faults;logic testing;integrated circuit testing;field programmable gate arrays;fpga testing fpga delay faults system environment self testing user defined function lut based fpgas xor function random testing;table lookup;delays;fault location	We propose a procedure for self-testing of an FPGA programmed to implement a user-defined function. The procedure is intended to improve the detectability of FPGA delay faults. This improvement is obtained by modifying the functions of LUTs in the section under test, so that each LUT implements a XOR function. We show that, despite many potential problems, the proposed modification can significantly enhance the susceptibility of FPGA delay faults to random testing.	exclusive or;field-programmable gate array;random testing;user-defined function	Andrzej Krasniewski	2000		10.1109/OLT.2000.856610	embedded system;electronic engineering;real-time computing;orthogonal array testing;computer science;field-programmable gate array	EDA	20.680686832471874	51.07318831007791	65364
d5d4329e7649d225981c82404262594709712533	characterization and analysis of errors in circuit test	circuit test;characteristic equation;test site;printed circuit manufacture production testing printed circuit testing assembling fault diagnosis;type i error;production testing circuit test characteristic equations physical defects logical faults pseudo faults type i error defective circuits electronic circuit board assembly test site;physical defects;logical faults;circuit testing error analysis circuit faults electrical fault detection fault detection computer errors electronic equipment testing system testing circuit analysis computing equations;assembling;electronic circuit board assembly;pseudo faults;printed circuit manufacture;printed circuit testing;production testing;characteristic equations;fault diagnosis;defective circuits	Characteristic equations for a general testing model are developed which include the effect of errors in testing. Physical defects are related to logical faults in a circuit and, in contrast to previous works, a requirement that a defect causes at least one fault is modelled. The concept of pseudo-faults is introduced and applied to the general testing model to characterize Type I error which occurs when a good circuit fails the test. Pseudo-jaults are seen to affect circuits randomly and occur independently of other defects due to the interaction becween the test and the circuit, affecting both defective arid good circuits. Data taken from an electronic circuit board assembly and test site is presented ,in support of the general testing model.	electronic circuit;in-circuit test;printed circuit board;randomness;requirement;software bug	Thomas A. Ziaja;Earl E. Swartzlander	1995		10.1109/DFTVS.1995.476960	reliability engineering;electronic engineering;type i and type ii errors;engineering;stuck-at fault;automatic test pattern generation;characteristic equation;statistics;computer engineering	EDA	23.769330035671253	53.19198891626958	65511
479b89f6a787e47b17e6ad1fdd1db9c201b25e72	1.9 ghz 1.05v 16-bit risc core for high density and low power operation in 28nm technology	standards;clocks;reduced instruction set computing;ground penetrating radar;threshold voltage;integrated circuits	Currently the advancement in widespread use of portable devices significantly increases importance of low power design of ICs using different low power techniques, such as power gating, multi voltage etc. Most of these techniques rely on different supply schemes for different areas and blocks of an IC to reduce dynamic and/or static (leakage) power. Thus these techniques are mostly applicable to Systems-On-Chip (SoCs) and their components, such as analog IPs and digital cores. This paper presents area and power optimization approach implemented on simple RISC core ready to be integrated into SoC. Proposed approach uses combination of several low power techniques to achieve desired result for custom-developed RISC core. Results present significant power reduction with acceptable high performance.	16-bit;integrated circuit;mathematical optimization;personal digital assistant;power gating;power optimization (eda);spectral leakage;system on a chip	Davit Babayan;Eduard Babayan;Poghos Petrosyan;Anna Tumanyan;Emil Kagramanyan;Tigran Hakhverdyan	2016	2016 IEEE East-West Design & Test Symposium (EWDTS)	10.1109/EWDTS.2016.7807658	embedded system;electronic engineering;real-time computing;engineering	EDA	15.153044971822888	56.78383489431562	65515
1ef629f19d71c95838b345daf94c7a08ed2745aa	a built-in self-test circuit with timing margin test function in a 1gbit synchronous dram	cycle time;ac timing comparator;signal generators;high speed drams;clocks;lfsr;automatic testing;phase lock loop;220 ps;ac generators;phase locked loops;chip;automatic testing dram chips built in self test timing integrated circuit testing;built in self test;bist circuit;pll circuit;200 mhz;phase locked loop;integrated circuit testing;timing margin test function;synchronous dram;80 ns built in self test bist circuit timing margin test function synchronous dram phase locked loop pll circuit delayed timing generator ac timing comparator reference signals lfsr high speed drams dynamic ram 64 mbit to 1 gbit 200 mhz 220 ps;circuit testing;circuit testing timing built in self test delay costs signal generators phase locked loops ac generators clocks frequency;delay time;64 mbit to 1 gbit;frequency;delayed timing generator;high speed;dram chips;80 ns;dynamic ram;reference signals;timing	This paper describes the implementation of a BIST circuit with timing margin test functions to a 200 MHz 1 Gbit synchronous DRAM. 220 ps-resolution timing signals with up to 80 ns cycle time are generated by a phase-locked loop (PLL) circuit and a delayed timing generator. These timing signals are used not only as actual control signals but also as reference signals in an AC timing comparator. The entire BIST circuit, which includes 20/spl times/4 bit LFSRs, occupies only 0.8% of the chip area. A cost evaluation of the BIST shows that the technology is effective for 64 Mbit high-speed DRAMs and beyond.	built-in self-test;distribution (mathematics);dynamic random-access memory	Narumi Sakashita;Fumihiro Okuda;Ken'ichi Shimomura;Hiroki Shimano;Mitsuhiro Hamada;Tetsuo Tada;Shinji Komori;Kazuo Kyuma;Akihiko Yasuoka;Haruhiko Abe	1996		10.1109/TEST.1996.556977	embedded system;electronic engineering;real-time computing;phase-locked loop;computer science;engineering;static timing analysis	EDA	24.079308998352897	52.42107100952038	65609
60eeaa90da5938245cd1dd1990947b9ee0a8e8d8	two novel low power and very high speed pulse triggered flip-flops	low power;vlsi;pulse triggered;high speed;flip flop	Summary#R##N##R##N#Two novel low power and high-speed pulse triggered flip-flops were presented in this paper. Short circuit current was controlled, and race condition between pull-up and pull-down branches was removed, which caused reduction of power consumption. On the other hand, the number of stack transistors in the discharging path was reduced which decreased delay of the flip-flops. The first proposed flip-flop reduced the number of transistors and the second proposed flip-flop used conditional data mapping and removed floating node of the first flip-flop. Post-layout simulation result showed that the first proposed flip-flop reduced 21% of power delay product and the second proposed flip-flop reduced 16% of power delay product in comparison with other flip-flops in 50% of data switching activities. Copyright © 2014 John Wiley & Sons, Ltd.	flops;flip-flop (electronics)	Ramin Razmdideh;Mohsen Saneei	2015	I. J. Circuit Theory and Applications	10.1002/cta.2048	electronic engineering;telecommunications;computer science;engineering;electrical engineering;very-large-scale integration	EDA	17.477082858501486	58.1277576112155	65676
f7d11d431863ccf298a5b64d5f659fc6b940ce8f	memory elements based on minority-3 gates and inverters implemented in 90 nm cmos	cmos integrated circuits;process variation;logic;semiconductor device measurement;inverters;cmos process;layout;sections;strontium;circuit topology;chip;logic gates;transistors;voltage;nanoelectronics;inverters latches strontium logic sections cmos process voltage semiconductor device measurement circuit topology nanoelectronics;latches;monte carlo simulation	Two memory elements, or latches, are introduced. They are similar in functionality to widely used NOR- and NAND-based crosscoupled latches, but unlike the traditional latces they do not risk to produce stable states where Q and Q' have identical binary values. The suggested solutions are built from two inverters and one minority-3 gate. Monte Carlo simulations in 90 nm CMOS are used to demonstrate that the circuits may maintain the digital abstraction under mismatch and process variations for a supply voltage down to 140 mV at 20 degrees C and 100 nm gate lengths. Chip measurements are included. Reliability issues for low fan-in threshold gates might favour them over some traditional Boolean implementations, which may contribute to increased use of CMOS threshold gates, if proven.	boolean algebra;cmos;digital electronics;flops;fan-in;flip-flop (electronics);inverter (logic gate);monte carlo method;nand gate;power inverter;simulation;transistor	Snorre Aunet;Amir Hasanbegovic	2010	13th IEEE Symposium on Design and Diagnostics of Electronic Circuits and Systems	10.1109/DDECS.2010.5491770	nanoelectronics;chip;layout;and-or-invert;electronic engineering;real-time computing;voltage;nor logic;strontium;computer science;engineering;electrical engineering;process variation;logic	EDA	18.18956460606134	58.38131234942162	65762
a24a21b199fe94e0dfd5d72cb7dfaabc20f394ed	the implementation of pseudo-random memory tests on commercial memory testers	pr memory test implementation;new technology;probability;pseudo random memory tests;memory testing;automatic test equipment;fault detection production cache memory decoding random access memory robustness frequency automatic testing built in self test;built in self test;commercialmemory testers;random processes;cache memories commercial memory testers defect level shipped memory parts fault coverage deterministic tests probability of occurrence pseudo random memory tests;fault coverage;production testing;semiconductor storage;built in self test automatic test equipment semiconductor storage random processes probability fault diagnosis production testing;large classes;fault diagnosis	The increasing emphasis on reducing the defect level of shipped memory parts demands very high fault coverage of memory tests. Deterministic tests have the advantage of 100% fault coverage for the targeted (i.e., anticipated) faults. However, with each new technology, new layout and new fab process, new types of defects will show up; the probability of occurrence of these defects is not known before production start and, in addition, may vary during the time period the parts are produced. Pseudo-random (PR) memory tests are tests which have the capability to detect any fault (defect) of any model; albeit with some probability less than 100%; the fault coverage is modular and depends on the test time, which makes them very attractive. However, problems arise when commercial testers have to be used for applying PR tests. This paper illustrates these problems and shows how they can be overcome. The results are applicable to a large class of commercial memory testers thereby making them useable for PR memory tests.	fault coverage;memory management;random-access memory;semiconductor device fabrication;semiconductor fabrication plant;software bug;usability	Ad J. van de Goor;Mike Lin	1997		10.1109/TEST.1997.639618	stochastic process;embedded system;automatic test equipment;parallel computing;real-time computing;fault coverage;engineering;probability;statistics	Logic	21.809908885415755	53.208090823358646	65813
ceff67fc1d2ab2c51b6b7cf8b62910bf40829470	sat-based unbounded symbolic model checking	symbol manipulation sat based unbounded symbolic model checking boolean satisfiability checking state sets transition relation logical operation conjunctive normal form formulas satisfy all procedure search space two level logic minimization cache table formal verification;symbol manipulation;data structures boolean functions circuits equations formal verification explosions logic minimization system on a chip algorithm design and analysis;boolean functions;search space;indexing terms;satisfiability;fixed point;boolean satisfiability;formal verification;model checking;integrated circuit testing;formal verification circuit analysis computing integrated circuit testing boolean functions symbol manipulation;symbolic model checking boolean satisfiability checking sat formal verification symbol manipulation;conjunctive normal form;symbolic model checking;circuit analysis computing;binary decision diagram	This paper describes a Boolean satisfiability checking (SAT)-based unbounded symbolic model-checking algorithm. The conjunctive normal form is used to represent sets of states and transition relation. A logical operation on state sets is implemented as an operation on conjunctive normal form formulas. A satisfy-all procedure is proposed to compute the existential quantification required in obtaining the preimage and fix point. The proposed satisfy-all procedure is implemented by modifying a SAT procedure to generate all the satisfying assignments of the input formula, which is based on new efficient techniques such as line justification to make an assignment covering more search space, excluding clause management, and two-level logic minimization to compress the set of found assignments. In addition, a cache table is introduced into the satisfy-all procedure. It is a difficult problem for a satisfy-all procedure to detect the case that a previous result can be reused. This paper shows that the case can be detected by comparing sets of undetermined variables and clauses. Experimental results show that the proposed algorithm can check more circuits than binary decision diagram-based and previous SAT-based model-checking algorithms.	model checking	Hyeong-Ju Kang;In-Cheol Yong Park	2005	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/TCAD.2004.841068	model checking;conjunctive normal form;discrete mathematics;index term;formal verification;computer science;theoretical computer science;mathematics;fixed point;boolean function;boolean satisfiability problem;binary decision diagram;algorithm;satisfiability	EDA	19.19911462900033	48.403872232718165	65888
557a3e2404ffa7c5c99a5b0a0d501419044f28c5	methods for minimizing dynamic power consumption in synchronous designs with multiple supply voltages	mixed integer linear program;graph theory;optimal solution;cyclic graphs;supply voltage scaling down;clocks;sequential circuits;heuristic method;cmos circuits;dynamic voltage scaling;acyclic design;indexing terms;mathematical programming formulations;software performance;synchronous designs;integrated circuit design;multiphase clocked sequential circuits;mixed integer linear programming;integer programming;cmos digital integrated circuits;heuristic methods;mathematical programming;energy consumption;critical path;cmos logic circuits;dynamic power consumption minimization;digital design;low power electronics;low dynamic power designs;linear programming;cyclic design;linear program;cmos logic circuits sequential circuits logic cad circuit cad integrated circuit design low power electronics linear programming integer programming graph theory;synchronous digital design;exact methods;low dynamic power designs dynamic power consumption minimization performance constraints synchronous digital design multiple supply voltages acyclic design cyclic design software pipelining cmos circuits supply voltage scaling down cyclic graphs acyclic graphs synchronous designs multiphase clocked sequential circuits heuristic methods mathematical programming formulations exact methods mixed integer linear programming linear programming run time;circuit cad;multiple supply voltages;acyclic graphs;energy consumption dynamic voltage scaling clocks pipeline processing sequential circuits mathematical programming mixed integer linear programming linear programming cmos digital integrated circuits software performance;power reduction;software pipelining;power consumption;performance constraints;logic cad;run time;pipeline processing	We address the problem of minimizing dynamic power consumption under performance constraints by scaling down the supply voltage of computational elements off critical paths. We assume that the number of possible supply voltages and their values are known for each computational element. We focus on solving this problem on cyclic and acyclic graphs corresponding to synchronous designs. We consider multiphase clocked sequential circuits derived using software pipelining techniques. In this paper, we present exact and heuristic methods to solve the problem. The proposed methods take the form of mathematical programming formulations and their associated solution algorithms. The exact methods are based on a mixed integer linear programming formulation of the problem. The heuristic methods are based on linear programming formulations derived from the exact problem formulation. Solution methods are analyzed experimentally in terms of their run time and effectiveness in finding designs with lower dynamic power using circuits from the ISCAS89 benchmark suite. Power reduction factors as high as 69.75% were obtained compared to designs using the highest supply voltages. One of the heuristic methods leads to solutions that are near optimal, typically within 5% from the optimal solution. Low dynamic-power designs with no or a small number of level converters, are also obtained.	approximation algorithm;benchmark (computing);clock rate;computation;decision problem;design space exploration;directed acyclic graph;experiment;heuristic;image scaling;integer programming;linear programming formulation;mathematical optimization;np-hardness;pipeline (computing);run time (program lifecycle phase);software pipelining;time complexity	Noureddine Chabini;Ismaïl Chabini;El Mostapha Aboulhamid;Yvon Savaria	2003	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/TCAD.2002.807894	software pipelining;mathematical optimization;electronic engineering;real-time computing;index term;software performance testing;computer science;linear programming;critical path method;sequential logic;low-power electronics;integrated circuit design	EDA	17.03078070493991	52.554567592426054	65983
113b49aad07ad4d2e019367a68afcedace705e6b	in-situ timing monitoring methods for variation-resilient designs	timing integrated circuit design large scale integration;monitoring delays clocks throughput pipelines flip flops;clocks;flip flops;timing monitoring;timing error detection;monitoring;pipelines;design margin timing monitoring variation timing error prediction timing error detection;pipeline designs in situ timing monitoring methods variation resilient designs process voltage and temperature variations pvt variations integrated circuit designs large scale integration lsi circuits timing errors in situ timing monitoring technique variation resilient design techniques prediction based methods suspicious timing error prediction step;timing error prediction;variation;delays;design margin;throughput	"""With technology scaling, process, voltage, and temperature (PVT) variations pose great challenges on integrated circuit designs. Conventionally, LSI circuits are designed by adding pessimistic timing margin to guarantee """"always correct"""" operations even under worst-case conditions. However, due to the increasing PVT variations, unacceptable larger design guard band should be reserved to avoid timing errors on critical paths of circuits, which will therefore lead to very inefficient designs in terms of power and performance. For this reason, in-situ timing monitoring technique has gained great research interest. In this paper, we will review existing variation-resilient design techniques with particular emphasis on in-situ timing monitoring techniques including both detection and prediction-based methods. The effectiveness of in-situ timing monitoring techniques will be discussed. Finally, we show an example of in-situ timing monitoring technique called STEP with applications to general pipeline designs."""	best, worst and average case;iso 10303;image scaling;integrated circuit;transponder timing	Youhua Shi;Nozomu Togawa	2014	2014 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)	10.1109/APCCAS.2014.7032886	embedded system;throughput;electronic engineering;real-time computing;factor of safety;computer science;engineering;pipeline transport;theme and variations;static timing analysis	EDA	20.140823380816325	57.77009544031615	66007
1edcdf21ccbceed497ba7f4526084c0e3f289e8d	power-aware noc reuse on the testing of core-based systems	test access mechanism;availability;network on a chip system testing energy consumption system on a chip benchmark testing costs bandwidth time to market communication switching availability;system on a chip;chip;energy consumption;system testing;bandwidth;time to market;power consumption;communication switching;network on a chip;benchmark testing	This work discusses the impact of power consumption on the test time of core-based systems, when an available on-chip network is reused as test access mechanism. A previously proposed technique for the reuse of an on-chip network is extended to consider power consumption during test, while minimizing the system testing time. Experimental results with the ITC’02 SoC benchmarks show that although power constraints can preclude the full exploration of the network parallelism, this platform is still a powerful mechanism for the system test time reduction at a very low	network on a chip;parallel computing;system testing	Érika F. Cota;Luigi Carro;Flávio Rech Wagner;Marcelo Lubaszewski	2003		10.1109/TEST.2003.1270888	chip;system on a chip;embedded system;benchmark;availability;parallel computing;real-time computing;telecommunications;computer science;engineering;operating system;network on a chip;system testing;bandwidth	EDA	11.788318784676049	54.06461829390206	66010
54714e2deb3e3f56260e2c61c76143fb66e12200	a 500mhz random-access embedded 1mb dram macro in bulk cmos	cycle time;silicon on insulator;system on chip cmos memory circuits dram chips silicon on insulator;frequency 500 mhz;soft error rate;bitline sense amplifier;soc integration;storage capacity 1 mbit;cmos memory circuits;system on chip;random access memory reservoirs tin capacitors variable structure systems built in self test timing testing graphics turning;twin tub soi cmos process;random access embedded dram macro;random access;size 65 nm;dram chips;size 65 nm random access embedded dram macro twin tub soi cmos process bitline sense amplifier soc integration storage capacity 1 mbit frequency 500 mhz;reading and writing	From 90 nm and below, SoC integration is reaching the point where it makes technical and economic sense to integrate embedded DRAM (eDRAM) onto a die. While eDRAMs have 2.5x to 4x density compared to SRAMs and have lower soft-error rate they are slower in operation. In a conventional DRAM with a single column access device for read and write, a write operation is started only after the bitline sense amplifiers are turned on and the bitlines are well on their way to full restoration. This is to avoid destroying data due to premature access to global bitlines in the non-writing columns. This delay in the write operation increases row cycle time to allow the storage node to be fully written. Accelerating write cycle with early access only in the required columns requires a large area penalty because local sense amplifiers in one bank are usually grouped into a large block where all control signals are shared. Also an embedded DRAM in a standard 65 nm twin-tub SOI CMOS process that uses a local sense amplifier with VDD sensing and separate ports for read and write, with these operations synchronized with sensing is described. This eDRAM speeds up the row cycle with low area overhead by reducing the number of signals to control the ports and making write and read operations indistinguishable at the bank level.	cmos;circuit restoration;column (database);dynamic random-access memory;edram;early access;embedded system;overhead (computing);sense amplifier;silicon on insulator;soft error;tub file;value-driven design;washing machine	Sergey Romanovsky;Atul Katoch;Arun Achyuthan;C. O'Connell;Sreedhar Natarajan;C. Huang;Chuan-Yu Wu;Min-Jer Wang;C. J. Wang;P. Chen;R. Hsieh	2008	2008 IEEE International Solid-State Circuits Conference - Digest of Technical Papers	10.1109/ISSCC.2008.4523161	system on a chip;electronic engineering;parallel computing;computer hardware;cycle time variation;computer science;engineering;silicon on insulator;random access	EDA	16.668706596066638	59.37391756134886	66036
a82ad8def9c377894fcf582011767bcd73c396d9	error resilient obdds	boolean functions;binary decision diagrams boolean functions reactive power benchmark testing indexes;binary decision diagrams;data structures;data structures binary decision diagrams boolean functions;self repairing obdd error resilient obdd ordered binary decision diagram data structure boolean function manipulation cad integrated circuit verification integrated circuit synthesis	Ordered Binary Decision Diagrams (OBDDs) are a widely used data structure for Boolean function manipulation. In particular, OBDDs are commonly used in CAD for the synthesis and verification of integrated circuits. The purpose of this paper is to design an error resilient version of this data structure, i.e., self-repairing OBDDs.We describe some strategies that make reduced OBDDs resilient to errors in the indexes, that are associated to the input variables, or in the edges. The solutions we propose allow to efficiently restore via software the corrupt OBDD without changing the data structure, but rather exploiting its inherent redundancy, as well as the redundancy introduced by its efficient implementations.	binary decision diagram;data structure;integrated circuit	Anna Bernasconi;Valentina Ciriani;Lorenzo Lago	2013	2013 IEEE 16th International Symposium on Design and Diagnostics of Electronic Circuits & Systems (DDECS)	10.1109/DDECS.2013.6549826	data structure;boolean expression;computer science;theoretical computer science;boolean function;programming language;binary decision diagram;algorithm	Logic	19.288735030194175	48.53201202352359	66120
c806cc6ae58c3965b4eb55d8849f22c70fa3f114	timing analysis using functional analysis	digital circuit;logic design;analyse fonctionnelle;arrival time;logic testing logic circuits logic design;logic circuits;circuito logico;arrival time timing analysis functional analysis logic circuits block oriented algorithm;algorithme;circuit numerique;algorithm;functional analysis;circuit logique;logic testing;circuito numerico;timing analysis;temps retard;timing functional analysis slabs concurrent computing signal analysis algorithm design and analysis collaboration parallel processing broadcasting very large scale integration;delay time;block oriented algorithm;logic circuit;tiempo retardo;algoritmo;analisis funcional	The usual block-oriented timing analysis for logic circuits does not take into account functional relations between signals. If functional relations are taken into consideration, it could be found that a long path is never activated. This results in more accurate delays. A comparison is made of three arrival time functions, A, B, and R. A is the arrival time as given by exhaustive simulation; B is the arrival time as calculated by a usual block-oriented algorithm; and R is the arrival time, that does functional analysis. It is shown that B contained in R contained in A. The first relation means that R is never more conservative than B and whenever the containment is proper, R is an improvement over B. The second relation means that R is correct in the sense that it will never assert a signal to be valid when it is not valid according to the ideal A. Experimental results showing how often R is an improvement over B are presented. >	static timing analysis	Daniel Brand;Vijay S. Iyengar	1988	IEEE Trans. Computers	10.1109/12.5996	functional analysis;parallel computing;real-time computing;logic gate;computer science;artificial intelligence;algorithm	Embedded	20.480422164888548	48.805127327770116	66247
9c343eccbabf32360355c444cbc17a3bc3b61058	the next big thing in chipmaking	processor performance;chipmaking approach;logic design;energy efficient;logic gate chipmaking approach transistor technology vlsi electronic design automation logic design;processor performance chipmaking;production process;chip;logic gates;transistor technology;chipmaking;vlsi;vlsi electronic design automation logic design logic gates;transistors silicon on insulator technology production silicon compounds dielectrics and electrical insulation high k dielectric materials high k gate dielectrics manufacturing energy efficiency clocks;logic gate;metal oxide semiconductor;electronic design automation	A new chipmaking approach marks the biggest change in transistor technology since the introduction of polysilicon-gate, metal-oxide-semiconductor. This could overcome the most substantial roadblock to continuing to use current production processes to shrink transistor elements and thereby increase chip performance. AMD, IBM, and Intel have announced plans to replace the silicon dioxide insulator layer of processors with new hafnium-based high-k materials, which increase charge transmission and reduce electrical leakage. To accommodate this, they replace the doped polysilicon used in transistor gates with a combination of metals. This solves a key problem: building transistors smaller horizontally so that manufacturers can pack more of them onto chips while increasing energy efficiency and continuing to use current chipmaking techniques, thereby avoiding expensive fabrication-plant changes. Many real advances are likely to come not from new materials but from the development of better muticore chips - which improve performance by having multiple cores run tasks in parallel rather than by increasing clock speed - as well as from the optimization of applications for these processors	central processing unit;clock rate;doping (semiconductor);electrical connector;high-κ dielectric;mathematical optimization;semiconductor;silicon-germanium;spectral leakage;the next big thing;topological insulator;transistor;transistor–transistor logic	George Lawton	2007	Computer	10.1109/MC.2007.148	electronic design automation;logic gate;computer science	Arch	12.692473742010625	58.253755730255364	66325
a04515bdc2a5ee0b3893c60731fbe5693b857f89	experiences of parallel processing with direct cover algorithms for multiple-valued logic minimization	many valued logics;search problems many valued logics minimisation of switching nets parallel processing;minimisation of switching nets;exact solution;speed parallel neighbourhood decoupling parallel processing direct cover algorithms multiple valued logic minimization intel ipsc 2 cad tool hamlet parallel version search tree multiple branches optimality;search trees;parallel computer;search problems;parallel implementation;parallel processing neodymium concurrent computing cmos logic circuits logic devices programmable logic arrays minimization methods heuristic algorithms logic design very large scale integration;parallel processing;exhaustive search;multiple valued logic	The implementation of the direct cover algorithm, a heuristic, on a real parallel computer system, Intel iPSC/2, is reported. A CAD tool, HAMLET, that is based on direct cover algorithms has been ported to iPSC/2. Parallel neighborhood decoupling (PND), a parallel version of ND that runs faster than ND, is used, as well as another parallel implementation of ND, multibranch ND (Multi-ND), which allows each processor to search one path of the search tree until the number of processors is exhausted. Searching in multiple branches guarantees a higher probability of reaching an exact solution. In addition, Multi-ND uses less communication than PND, since once a process is assigned a task it will remain isolated from the host until there is a need to report its solution. The results show that Multi-ND outperforms PND in both optimality and speed. >	algorithm;circuit minimization for boolean functions	Chyan Yang;Onur Oral	1992		10.1109/ISMVL.1992.186780	embedded system;parallel processing;electronic engineering;parallel computing;computer science;artificial intelligence;theoretical computer science;machine learning;brute-force search;analysis of parallel algorithms;algorithm	EDA	15.518641070175946	48.354351072322615	66430
5739869d4678b958c735f6046765ff077fa09076	an optimistic ternary simulation of gate races	modelizacion;analyse fonctionnement;simulation;circuit stability;simulacion;circuito logico;network analysis;estabilidad circuito;modelisation;circuit logique;stabilite circuit;operation study;analyse circuit;modeling;logic circuit;analisis funcionamiento;analisis circuito	Abstract The detection of timing problems in digital networks is of considerable importance. In particular it is desirable to have efficient methods for discovering critical races and hazards. Unfortunately, commercial simulators rarely provide such facilities; in fact, the simulators usually assume that all the gate delays are exactly equal. In contrast to this, binary race analysis frequently assumes that gate delays can be arbitrarily large, though finite. An exception to this is the almost-equal-delay race model, where gates have different delays, but the difference between any two delays cannot be arbitrary. The difficulty with the use of this model is that it is computationally very inefficient. In this paper we define a new ternary model which is very closely related to the binary almost-equal-delay model. Moreover, the ternary model is considerably more efficient, as efficient as the unit delay model; consequently, it could easily be incorporated in simulators.	simulation	Carl-Johan H. Seger;Janusz A. Brzozowski	1988	Theor. Comput. Sci.	10.1016/0304-3975(88)90107-7	systems modeling;logic gate;network analysis;computer science;control theory;mathematics;algorithm	ECom	23.628174712933106	48.06244815094521	66684
82edab9ef693e4cd1235dff24b2aea9d46c5e91a	reliability of cmos integrated circuits	voltage control;cmos integrated circuits;mos devices;cmos technology;integrated circuit;technology assessment;failure mode;packaging;failure analysis;cmos digital integrated circuits;digital integrated circuits;integrated circuit technology;failure mechanism;failure rate;reliability analysis;integrated circuit reliability cmos integrated circuits cmos digital integrated circuits mos devices cmos technology packaging voltage control integrated circuit technology substrates digital integrated circuits;substrates;integrated circuit reliability	CMOS IC s are being produced using a variety of processes, and considerable data is now available on their reliability and failure mechanisms.	cmos;failure cause;integrated circuit	George L. Schnable;Larry J. Gallace;Henry L. Pujol	1978	Computer	10.1109/C-M.1978.217937	cmos	EDA	22.234053624782202	55.28580101351904	66727
0f5a34d4b11e570e6808ff7f1d2212cba4840f43	analysis of bti aging of level shifters	thermal variables control;negative bias temperature instability;degradation;standards;delay level shifters bti aging multi power domains;degradation delays aging standards negative bias temperature instability thermal variables control threshold voltage;aging;threshold voltage;low supply voltages level shifters delay bias temperature instability aging bti aging analysis indispensable blocks energy efficient systems multiple supply voltages aging induced delay degradation standard cmos logic differential signaling structure;delays;phase shifters ageing cmos logic circuits energy conservation low power electronics	This paper provides a comprehensive evaluation of the effects of Bias Temperature Instability (BTI) aging on the delay of level shifters. The latter are indispensable blocks in energy efficient systems with multiple supply voltages. Our results show that conventional level-up shifters exhibit significantly more aging-induced delay degradation compared to standard logic cells. Our experiments performed in a predictive 32nm technology indicate those designs can suffer from more than 200% increase in their delay after 5 years due to BTI aging compared to an average of 20% delay rise in the case of standard CMOS logic. Our investigations show that the reason behind this phenomenon is the differential signaling structure present in the majority of conventional level up shifters, combined with the use of low supply voltages.	btrieve;cmos;differential signaling;elegant degradation;experiment;instability;logic level	Jiajing Cai;Basel Halak;Daniele Rossi	2016	2016 IEEE 22nd International Symposium on On-Line Testing and Robust System Design (IOLTS)	10.1109/IOLTS.2016.7604662	reliability engineering;negative-bias temperature instability;electronic engineering;real-time computing;degradation;engineering;electrical engineering;threshold voltage	Arch	19.630549821300658	59.06180596558377	66735
3c2eb6c9a13ff99f42a42fd1304715b15cae8844	reinventing eda with manycore processors	software;microprocessors;manycore;computer aided design;design automation;design process;manycore microprocessor systems;integrated circuit;parallelization eda manycore microprocessor systems computer aided design cad integrated circuit design design for manufacturability;cad;design for manufacture;eda;industries;usa councils;electronic design automation and methodology design automation microprocessors moore s law design methodology process design manufacturing processes multicore processing computer industry manufacturing industries;integrated circuit design;parallel processing circuit cad design for manufacture integrated circuit design microprocessor chips;multicore;design for manufacturability;parallelization;software algorithms;circuit cad;speedup;program processors;parallel processing;microprocessor chips;eda multicore manycore software parallelization speedup;design methodology	Faced with continually coping with Moore's Law, computer-aided design (CAD) for integrated circuits is used to facing challenges in our ever-evolving design problem. Increasing device complexity is a perennial challenge and has led to several discontinuities in design methodology. Over the last decade deep submicron physical effects have significantly complicated the design process and required new efforts in design for manufacturability. With the emergence of multicore and manycore microprocessor systems we face a new type of challenge: Not only will our design object (the microprocessor systems themselves) take another leap in complexity, but for the first time in our industry's history we will need to fundamentally change the way we design and implement our software solutions as well. In this panel a broad set of representatives at the front lines of addressing this challenge will outline how they plan to respond. Representative questions to the panelists include:  Does your company have a similar corporate-level strategy for parallelizing CAD applications? Or is each business unit or product group left to craft its own strategy?	central processing unit;computer-aided design;design for manufacturability;emergence;integrated circuit;manycore processor;microprocessor;moore's law;parallel computing;very-large-scale integration	Sachin S. Sapatnekar;Eshel Haritan;Kurt Keutzer;Anirudh Devgan;Desmond Kirkpatrick;Stephen Meier;Duaine Pryor;Tom Spyrou	2008	2008 45th ACM/IEEE Design Automation Conference	10.1145/1391469.1391502	embedded system;parallel processing;computer architecture;electronic engineering;parallel computing;electronic design automation;computer science;engineering;operating system;design for manufacturability;computer engineering	EDA	10.46417494084909	56.29342031098787	66860
192f677559fa3fce3da8e2300f2ba46942a2b405	design of a ternary edge-triggered d flip-flap-flop for multiple-valued sequential logic		Development of large computerized systems requires both combinational and sequential circuits. Registers and counters are two important examples of sequential circuits, which are widely used in practical applications like CPUs. The basic element of sequential logic is Flip-Flop, which stores an input value and returns two outputs (Q and Q ). This paper presents an innovative ternary D Flip-Flap-Flop, which offers circuit designers to customize their design by eliminating one of the outputs if it is not required. This unique feature of the new design leads to considerable power reduction in comparison with the previously presented structures. The proposed design is simulated and tested by HSPICE and 45 nm CMOS technology.	cmos;central processing unit;combinational logic;flip-flop (electronics);parameter (computer programming);spice 2;sequential logic	Reza Faghih Mirzaee;Niloofar Farahani	2016	CoRR		ternary operation	EDA	16.62877249498011	57.144326310955535	67004
77245d029ab3370723894292864cd00b35303e75	statistical analysis driven synthesis of application specific asynchronous systems	tecnologia electronica telecomunicaciones;asynchronous system;statistical analysis;scheduling;tecnologias;grupo a;binding	In this paper, we propose an effective asynchronous datapath synthesis system to optimize statistical performance of asynchronous systems. The proposed algorithm is a heuristic method which simultaneously performs scheduling and resource binding. During the design process, decisions will be made based on the statistical schedule length analysis. It is demonstrated that asynchronous datapaths with the reduced mean total computation time are successfully synthesized for some datapath synthesis benchmarks.	asynchronous circuit	Koji Ohashi;Mineo Kaneko	2007	IEICE Transactions	10.1093/ietfec/e90-a.3.659	asynchronous system;embedded system;parallel computing;real-time computing;telecommunications;computer science;scheduling;statistics	EDA	17.448521963271187	52.33550990669286	67063
5fcf59fdb21f529b9ef0b03997194171cfa418b5	test compression improvement with edt channel sharing in soc designs	system on chip pins automatic test pattern generation encoding hardware ip networks;embedded deterministic test edt channel sharing innovative test compression technology system on chip scan input channels multiple cores dft compression architecture data channels control channels test compression planning core based soc design flow;system on chip data compression design for testability integrated circuit design integrated circuit testing	This paper proposes an innovative test compression technology for system-on-chip (SoC) designs to share scan input channels across multiple cores which use EDT [1] compression. A new DFT compression architecture is proposed to separate control and data channels such that the control channels can be individually accessible, whereas data channels can be shared among a group of cores. The paper illustrates the benefits of the proposed technology in both the enhancement of compression ratios and the flexibility of test compression planning in a core-based SoC design flow. Experimental results with a few large industrial SoCs demonstrate that using the proposed technology the compression can be improved up to 1.87X.	event dispatching thread;fault coverage;olap cube;run time (program lifecycle phase);semiconductor intellectual property core;system on a chip;test compression	Yu Huang;Mark Kassab;Jay Jahangiri;Janusz Rajski;Wu-Tung Cheng;Dongkwan Han;Jihye Kim;Kun Young Chung	2014	2014 IEEE 23rd North Atlantic Test Workshop	10.1109/NATW.2014.14	embedded system;electronic engineering;computer hardware;engineering;design for testing	EDA	11.317985048064255	54.08289812670543	67078
bf125ee4a9c819598275473426854624299eb44e	automatic design validation framework for hdl descriptions via rtl atpg	observability;vhdl high level design validation rtl atpg hdl description automatic design validation framework variable assignments conditional statements arithmetic expressions controllability observability itc99 benchmark circuits industrial circuit design error coverage verilog;automatic test pattern generation;logic testing hardware description languages automatic test pattern generation high level synthesis observability;hardware description languages;hardware design languages high level synthesis observability logic circuit testing;high level synthesis;logic testing;automatic test pattern generator;register transfer level	We present a framework for high-level design validation using an efficient register-transfer level (RTL) automatic test pattern generator (ATPG). The RTL ATPG generates the test environments for validation targets, which include variable assignments, conditional statements, and arithmetic expressions in the HDL description. A test environment is a set of conditions that allow for full controllability and observability of the validation target. Each test environment is then translated to validation vectors by filling in the unspecified values in the environment. Since the observability of error effect is naturally handled by our ATPG, our approach is superior to methods that only focus on the excitation of HDL descriptions. The experimental results on ITC99 benchmark circuits and an industrial circuit demonstrate that very high design error coverage can be obtained in a small CPU times.	algorithm;algorithmic efficiency;benchmark (computing);central processing unit;computation;deployment environment;display resolution;experiment;hardware description language;high- and low-level;level design;linear programming relaxation;register-transfer level;software propagation;test card	Liang Zhang;Michael S. Hsiao;Indradeep Ghosh	2003		10.1109/ATS.2003.1250800	computer architecture;electronic engineering;real-time computing;observability;computer science;engineering;theoretical computer science;automatic test pattern generation;hardware description language;high-level synthesis;register-transfer level	EDA	19.357849430341744	49.26187204865944	67266
2e16bdc47446b9d1edabcb27f97960d36cbe426d	veriful: verification using functional learning	functional learning;boolean functions combinational circuits logic cad learning systems logic design;combinational circuits circuit synthesis logic design automatic test pattern generation design automation boolean functions logic circuits digital circuits observability industrial relations;logic design;obdd;boolean functions;functional manipulation;boolean function;ordered binary decision diagram;learning systems;learning technique;learning system;veriful;ordered binary decision diagrams;combinational circuit verification;design verification;combinational circuit;ordered binary decision diagrams veriful combinational circuit verification combinational circuit design learning technique functional learning obdd functional manipulation;combinational circuit design;logic cad;combinational circuits	It is well known that learning (i.e., indirect implications) based techniques perform very well in many instances of combinational circuit verification when the two circuits being verified have many corresponding internal equivalent points. We present some results on combinational circuit design verification using a powerful, and highly general learning technique called functional learning. Functional learning is based on OBDDs and hence can efficiently learn novel implications based on functional manipulation.	circuit design;combinational logic;logic gate	Rajarshi Mukherjee;Jawahar Jain;Masahiro Fujita	1995		10.1109/EDTC.1995.470358	electronic engineering;theoretical computer science;mathematics;high-level verification;active learning;algorithm;functional verification	EDA	19.537804921825163	48.03704796654402	67495
16391dd6a5f15767eff6d0c7042f37dfae62aaa0	an efficient, bus-layout based method for early diagnosis of bussed driver shorts in printed circuit boards	parallel testvec- tor ptv.;early repair;production yield;field survivability;driver abuse;bussed driver;short;open;printed circuit board;layout-based approach;bussed driver short;subsequent rest;board-level shorts diagnosis;early diagnosis;printed circuit boards;fault coverage	This paper presents a new, layout-based approach to board-level shorts diagnosis for bussed drivers, with the goal of early repair of interconnect shorts so as to minimize (a) fault masking during opens testing and (b) driver abuse. This approach leads to an early diagnosis of more than 96% of shorts and simplifies the subsequent rest for opens considerably. Besides, this approach improves the production yield and field survivability of boards.	emoticon;printed circuit board;printing	Kanad Chakraborty;Pinaki Mazumder	1996	Proceedings of International Conference on Computer Aided Design	10.1145/244522.244970	embedded system;electronic engineering;computer science;engineering;electrical engineering;printed circuit board	EDA	23.81667278711972	53.74294351076452	67505
891516a3ebc32e988125646d9c5abfd129216ccf	submicron bicmos technologies for supercomputer and high speed system implementation	random access memory;cmos technology;integrated memory circuits;first level cache;integrated memory circuits bimos integrated circuits integrated circuit technology;7 ns;cache memory;submicron process technologies;bicmos integrated circuits;cmos process;supercomputer;bicmos integrated circuits supercomputers cmos technology cmos process application specific integrated circuits random access memory costs resistors cache memory semiconductor device manufacture;7 ns submicron process technologies supercomputer high speed system first level cache second level cache main memory bicmos cpu standard cells ecl gate density embedded cmos bicmos sram x9 cache memories ecl i o srams access time;integrated circuit technology;application specific integrated circuits;semiconductor device manufacture;x9 cache memories;resistors;second level cache;ecl i o srams;high speed system;embedded cmos;bicmos sram;high speed;cpu standard cells;supercomputers;main memory;bimos integrated circuits;access time;ecl gate density;bicmos	This paper describes submicron process technologies that allow a full implementation of CPU, first level Cache, second level Cache, and the main memory in a BiCMOS approach. CPU Standard Cells up to l00K ECL gate density with embedded CMOS and BiCMOS SRAM, X9 Cache memories, and 1 Meg ECL U0 SRAMs with less than 7ns access time are achieved. INTRODUCTION State-of-the-art BiCMOS technologies are vital tools of today's manufacturing and as such they are being extensively used to realize high performance semiconductor products while maintaining high density at moderate power consumption. Due to extra processing steps, cost per wafer for BiCMOS processes is higher than pure CMOS or Bipolar technologies. However, due to performance and density improvement BiCMOS processes enjoy lower cost per gate than ECL at a lower power level, comparable to CMOS products. For memory products BICMOS processes offer higher speed performance along with TTL and ECL I/O options. Using BiCMOS processes tailored for ASIC applications, on the other hand, memory arrays can be incorporated into existing or new designs adding to product versatility and leading to increased performance for systems employing such products. In this paper two major BiCMOS technology families are discussed and compared in terms of processing and device performance. In addition areas of application for each one of these processes as related to the total system solution will be explored. ASIC & MEMORY BICMOS FAMILIES Currently two major high performance BiCMOS technology families exist in National Semiconductors. A technology road map for these process families is shown in TABLE-I. Advanced BiCMOS process family, known as ABiC, is the family of BiCMOS technologies developed for high performance ASIC applications with emphasis on embedded CMOS, BiCMOS or ECL memory as well as BiCMOS and ECL gate array and standard cells. In development of ABiC process, National Semiconductor's state-of-the-art ASPECT process [ 1,2], has been successfully combined with high performance CMOS process [3,4,5]. The second technology family, known as BiCMOS, is mainly developed for SRAM applications where dense 4T MOS memory cells combined with high speed bipolar logic leads to very high levels of device integration. Final bipolar and CMOS device cross sections for current generation of the ABiC family, ABiC IV, are shown in Fig.1. In Fig.2 process cross section for the 0.8 pm BiCMOS IV technology [6,7] is shown. Despite differences in architecture a high degree of similarity and synergy exists between these processes. Device isolation in both processes is accomplished using an advanced, low encroachment fully recessed oxide isolation process optimized for small birds beak and planarity as well as defect density. The N+ and P+ twin buried layers form retrograde well profiles for CMOS transistors and result in soft error and latch up immunity. The gate oxide is 150 A thick and in the ABiC IV process is protected by a thin layer of polysilicon during subsequent masWetch process. The major difference between technologies is in the use of the polysilicon 1ayers.As shown in Fig.1, in the ABiC IV a single layer of polysilicon is used for simultaneous formation of gate, emitter, sourceldrain and base contacts as well as several high precision poly resistors. The same layer of polysilicon is silicided and used for local interconnection, increasing design flexibility and packing density. The BiCMOS IV process on the other hand is a double poly technology where the first poly layer forms the gate of the CMOS devices. The second poly layer foms emitter of bipolar transistors as well as high value load resistors for high density 4T cell memory implementation. The area of memory cell in BiCMOS IV is about 37 pm2. The second layer of poly is also selectively silicided, facilitating the formation of low-resistance local interconnects leading to smaller memory foot print and pitch. In contrast, 6T memory cells are more appropriate in ABiC IV where a larger memoxy cell area of about 100 pm2 can be tolerated. Other key features for these technologies are summarized in TABLE-II. ELECTRICAL PERFORMANCE Key device electrical parameters are summarized in TABLE-III. Both technologies enjoy respectable Idsat of 0.4 mA/pm for NMOS and 0.2 mA/pm for PMOS devices and for nominal effective channel length of 0.6 pm. Unity gain frequency, Ft, is about 15 GHz for bipolar transistors. ABiC IV devices , however, have lower extrinsic base resistance as well as S/D resistance due to self aligned silicide. Smaller bipolar foot print in ABiC IV leads to reduced device capacitance as shown in TABLE-111. Gate delay information for ABiC IV and BiCMOS IV are summarized in TABLE-IV. From TABLE-IV both technologies offer similar high performance for CMOS and BiCMOS gates. Delay x power products for several high performance technologies including ABiC IV and BiCMOS IV is given in Fig.3 .ECL performance in ABiC IV technology is superior due to highly optimized bipolar architecture and with gate delay of about 200 psec at 50 pA of current, high levels of integration can be achieved.ABiC IV also offers optimal interconnection performance of less than 1 pS/mil ( 40 pS/mm) for 4 layers of interconnection. CH2909-019010000/0007$01 .OO	access time;application-specific integrated circuit;bicmos;cmos;cpu cache;central processing unit;cross section (geometry);electrical connection;embedded system;emitter-coupled logic;fractal dimension;gate array;gate oxide;input/output;interconnection;lambert's cosine law;magnetoencephalography;memory cell (binary);nmos logic;pm2;pmos logic;ps-algol;performance;pitch (music);planar graph;programming in the large and programming in the small;propagation delay;semiconductor;set packing;soft error;software bug;static random-access memory;supercomputer;synergy;transistor;transistor–transistor logic;unity	B. Bastani;M. Biswal;Ali Iranmanesh;C. Lage;L. Bouknight;V. Ilderem;A. Solheim;W. Burger;R. Lahri;J. Small	1990		10.1109/ICCD.1990.130145	resistor;embedded system;electronic engineering;supercomputer;parallel computing;cpu cache;access time;computer science;operating system;application-specific integrated circuit;cmos;bicmos	EDA	14.048698230480596	58.329673631038034	67568
008ab1c105be1707e82f2e1fa6520429a67f5f45	the design of a low power asynchronous multiplier	integrated circuit modelling asynchronous circuits multiplying circuits low power electronics spice high level synthesis integrated circuit design circuit cad logic design shift registers;microprocessors;power saving;multiplier;cmos technology;multiplying circuits;energy consumption algorithm design and analysis cmos logic circuits logic design signal processing algorithms logic circuits cmos technology power dissipation clocks very large scale integration;logic design;clocks;benchmark;logic circuits;booth s algorithm;high level synthesis;integrated circuit design;ieee computer society;low power;model transitions low power asynchronous multiplier design multiplier operand statistics distribution characteristics positive inputs power consumption asynchronous control radix 2 algorithm split registers power savings input significant bits radix 4 modified booth algorithm unified registers hspice simulations benchmark program input vectors high level software model;thesis;integrated circuit modelling;energy consumption;cmos logic circuits;power dissipation;shift registers;low power electronics;asynchronous circuits;asynchronous logic;circuit cad;power consumption;signal processing algorithms;drntu engineering electrical and electronic engineering electronic circuits;spice;algorithm design and analysis	In this paper we investigate the statistics of multiplier operands and identify two characteristics of their distribution that have important consequences for the design of low power multipliers: most inputs are positive, and most inputs have a small number of significant bits. These characteristics are exploited in the design of a multiplier that employs three techniques to minimize power consumption: asynchronous control, a radix-2 algorithm, and split registers. The power savings resulting from the use of these techniques are 55%, 23% and 12% respectively when compared to a synchronous multiplier using a radix-4 modified Booth's algorithm with unified registers. The results are derived from HSPICE simulations using input vectors from benchmark programs. A high-level software model is also used to compare the numbers of transitions in the various models.	asynchronous circuit;benchmark (computing);booth's multiplication algorithm;high- and low-level;operand;power glove;spice 2;simulation;synchronous circuit	Yijun Liu;Stephen B. Furber	2004	Proceedings of the 2004 International Symposium on Low Power Electronics and Design (IEEE Cat. No.04TH8758)	10.1145/1013235.1013310	algorithm design;electronic engineering;logic synthesis;real-time computing;benchmark;asynchronous circuit;logic gate;computer science;booth's multiplication algorithm;dissipation;theoretical computer science;shift register;multiplier;high-level synthesis;cmos;low-power electronics;integrated circuit design	Arch	13.336091600842112	48.67136331988957	67603
4f86426d8fc811c1c454eddbf062373787ac04c9	implications of device timing variability on full chip timing	function block;yield;chip;process variations;probability distribution;ssta;design margins;quantitative evaluation	As process technologies continue to scale, the magnitude of within-die device parameter variations is expected to increase and may lead to significant timing variability. This talk presents a quantitative evaluation of how low level device timing variations impact the timing at the functional block level. We evaluate two types of timing variations: random and systematic variations. The study introduces random and systematic timing variations to several functional blocks in Intel® Core™ Duo microprocessor design database and measures the resulting timing margins. The primary conclusion of this research is that as a result of combining two probability distributions (the distribution of the random variation and the distribution of path timing margins) functional block timing margins degrade non-linearly with increasing variability	heart rate variability;processor design;transponder timing	Ed Grochowski;Murali Annavaram;Paul Reed	2007	2007 IEEE 13th International Symposium on High Performance Computer Architecture	10.1145/1353629.1353644	chip;probability distribution;yield;real-time computing;mathematics;statistics	Arch	22.159410347652265	57.72940763318149	67671
b85e28ebf758a33c07ddd5d2d83b0b56cdcbd00d	test pattern decompression in parallel scan chain architecture	test pattern compression;hardware clocks vectors broadcasting shift registers automata compression algorithms;clocks;embedded deterministic test test pattern compression scan based designs test data compression;test data compression;automatic test pattern generation;logic gates automatic test pattern generation clocks flip flops integrated circuit testing;flip flops;scan based designs;test sequence control parallel scan chain architecture test pattern decompression test data volume compression hardware overhead test pattern broadcast test response compaction xor less structure ring generators pattern space basic gates clock cycles flip flops memory requirements test compression compaction tools;logic gates;embedded deterministic test;integrated circuit testing	The paper presents a test-data volume-compression method which reduces test time and hardware overhead by test pattern broadcast into parallel scan chains. The proposed hardware enables efficient test pattern decompression and test response compaction. It uses a XOR-less structure instead of ring generators for test pattern decompression. Decompressed test vectors are obtained from the previously generated ones by simple shift operations only. The compression algorithm can search in a wider pattern space when finding the best fitting decompressor seed sequence because of this arrangement. The faults of basic gates can be covered by the patterns easily obtained in the decompressor during several clock cycles as a majority of faults can be tested by patterns that differ in a few shift operations only. The paper describes a test pattern decompressor hardware including its controller. The decompressor reduces the number of flip-flops containing information about previously generated pattern by test pattern broadcast into parallel scan chains. The memory requirements, test time and hardware overhead are compared with the parameters of circuits designed by the industrial test compression and compaction tools. The hardware realization can be modified according the required tradeoff between the complexity of test sequence control and the hardware overhead.	algorithm;automaton;benchmark (computing);built-in test equipment;clock signal;data compaction;data compression;exclusive or;experiment;flops;flip-flop (electronics);overhead (computing);requirement;sed;test card;test compression	Martin Chloupek;Jiri Jenícek;Ondřej Novák;Martin Rozkovec	2013	2013 IEEE 16th International Symposium on Design and Diagnostics of Electronic Circuits & Systems (DDECS)	10.1109/DDECS.2013.6549820	embedded system;electronic engineering;parallel computing;real-time computing;logic gate;computer science;automatic test pattern generation;test compression;design for testing	EDA	19.970872581545272	51.35312555641744	67717
c7298fafadceacbb138809ca0db91e462f7d3ff9	a built-in self-repair circuit for restructuring mesh-connected processor arrays by direct spare replacement	graph theory;self repair;fault tolerance;built in circuit;mesh array	We present a digital circuit for restructuring a mesh-connected processor array with faulty processing elements which are directly replaced by spare processing elements located at two orthogonal sides of the array. First, the spare assignment problem is formalized as a matching problem in graph theory. Using the result, we present an algorithm for restructuring the array in a convenient form for finding a matching by a digital circuit. Second, the digital circuit which exactly realizes the algorithm is given. The circuit can be embedded in a target processor array to restructure very quickly the array with faulty processing elements without the aid of a host computer. This implies that the proposed system is effective in not only enhancing the run-time reliability of a processor array but also such an environment that the repair by hand is difficult or a processor array is embedded within a VLSI chip where faulty processor elements cannot be monitored externally through the boundary pins of the chip, and so on. Third, the data about the array reliability considering not only faults in processors but also in that digital circuit are given, and then the effectiveness of our scheme is shown.		Itsuo Takanami;Tadayoshi Horita;Masakazu Akiba;Mina Terauchi;Tsuneo Kanno	2016	Trans. Computational Science	10.1007/978-3-662-50412-3_7	hashed array tree;embedded system;electronic engineering;array data structure;real-time computing;engineering;sparse array	EDA	23.3950392523637	48.726425456795766	67859
e459973983714edb6eee3ae11295cdbbb1698950	low-leakage soft error tolerant port-less configuration memory cells for fpgas	leakage current;soft error rate;particle strike;configuration memory cell;critical charge;charge sharing	As technology scales the area constraint is becoming less restrictive, but soft error rate and leakage current are drastically increased with technology down scaling. Therefore, in nano-scaled CMOS technology, the reduction of soft error rate and leakage current is the most important challenge in designing field programmable gate arrays (FPGA). To overcome these difficulties, based on the observations that most configuration bit-streams of FPGA are zeros across different designs and that configuration memory cells are not directly involved with signal propagation delays in FPGA, this paper presents a new family of configuration memory cells for FPGAs in nano-scaled CMOS technology. When zeros are stored in the cells, the injected glitch due to particle strike is removed from the stroked node by pull-up or pull-down network of the cells. Thus, our proposed cells are completely hardened and cannot flip from particle strikes at the sensitive cell nodes when zeros are stored in the cells. Furthermore, in the proposed cells, when zeros are stored, the sub-threshold leakage current components are reduced by using stacks of transistors in series. These new cells are port-less and the storage nodes of cells are manipulated through the transistors which apply the supply voltages to the cell. Simulation results show that the proposed cells are working correctly during their configuration and idle cycles and that our cells have a lower soft error rate and leakage current in 22-nm, as well as 65-nm technologies.	error-tolerant design;field-programmable gate array;soft error;spectral leakage	Arash Azizi Mazreah;Mohammad T. Manzuri Shalmani	2013	Integration	10.1016/j.vlsi.2012.08.001	embedded system;electronic engineering;real-time computing;engineering;electrical engineering;leakage	EDA	17.24547806540517	59.139319832174664	67947
c9bd16f9fc0da3e31d36854bddcfd03df4e98cbb	simulated annealing based parallel state assignment of finite state machines	gain estimate graph;state assignment;logic cad finite state machines simulated annealing state assignment vlsi parallel algorithms circuit cad;simulated annealing;portability;memory scalability;fsm simulated annealing based state assignment parallel state assignment finite state machines vlsi cad parallel algorithm parallel annealing strategy dynamic repartitioning state space mimd machine portability superlinear speedups;finite state machines;vlsi;simulated annealing automata very large scale integration parallel algorithms encoding sequential circuits design automation circuit testing logic testing contracts;circuit cad;logic cad;parallel algorithms	Simulated annealing has been an effective tool in many optimization problems in VLSI CAD but its time requirements are prohibitive. In this paper, we report a parallel algorithm for a well established, simulated annealing based algorithm for the state assignment problem for finite state machines. Our parallel annealing strategy uses parallel moves by multiple processes, each performing local moves within its assigned sub-space of the state encoding space. The novelty is in the dynamic repartitioning of the state space among processors, so that each processor gets to perform moves on the entire space over time. This is important to keep the quality of the parallel algorithm comparable to the serial algorithm. On the average our algorithm gives quality results within 0.05% of the serial algorithm on 64 processors. Our algorithm is portable across a wide range of MIMD machines and gives superlinear speedups on all of them. For a large circuit, the run-time has been reduced from 11 hours to 10 minutes on a 64 processor machine.	finite-state machine;simulated annealing	Gagan Hasteer;Prithviraj Banerjee	1997		10.1109/ICVD.1997.567963	parallel computing;real-time computing;simulated annealing;computer science;theoretical computer science;parallel algorithm;very-large-scale integration;finite-state machine	EDA	10.282685170056087	47.76912797198659	67957
7a029fc771c6689ecd14806f3bcbe7ca6977b42d	on routability prediction for field-programmable gate arrays	field programmable gate array;design engineering;logic design;routing;very large scale integration;programmable logic arrays;field programmable gate arrays routing logic design switches logic devices very large scale integration programmable logic arrays predictive models design engineering wiring;place and route;predictive models;field programmable gate arrays;wiring;switches;logic devices	Efficient utilization of Field Programmable Gate Arrays (FPGAs) depends on the ability to determine whether designs will exceed the logic or routing capacities of the devices. Here, we focus on the problem of assessing the routability of designs for FPGAs before place-and-route. Specifically, we identify the relevant wireability theories, modify and adapt the theories for FPGAs, and conduct experiments to validate the theories.	experiment;field-programmable gate array;lookup table;place and route;programmable logic device;routing;standard cell;theory	Pak K. Chan;Martine D. F. Schlag;Jason Y. Zien	1993	30th ACM/IEEE Design Automation Conference	10.1145/157485.164915	erasable programmable logic device;embedded system;electronic engineering;logic synthesis;macrocell array;logic gate;logic family;programmable logic array;computer science;engineering;theoretical computer science;programmable logic device;pass transistor logic;complex programmable logic device;simple programmable logic device;programmable array logic;field-programmable gate array;computer engineering	EDA	13.258563542335152	52.223669712298566	67989
70a023a52a8d8468a96e8d1f739e8aac8b8dd5bd	an efficient test procedure for functional faults in semiconductor random access memories		This paper proposes a new procedure for testing semiconductor random access memories (RAMs). The test procedure detects simultaneously present functional faults such as stuck-at faults, transition faults and coupling faults and requires 19N operations, which is an improvement over conventional procedures. Thus testing time is reduced by the smaller number of operations of the test procedure, test generation and applications are simplified by the linear address marching.	random access;semiconductor	Yun-Hong Kim;In-Sik Hong;Jun-Mo Jung;Young-Oo Kim;In-Chil Lim	1991	Journal of Circuits, Systems, and Computers	10.1142/S0218126691000069	electronic engineering;parallel computing;engineering;algorithm	EDA	21.225806996546716	52.27857075025977	68014
992ad8171ee3b344bca06757d3d6c2177624cd32	efficient pattern mapping for deterministic logic bist	efficient pattern mapping;deterministic logic bist;novel dlbist synthesis procedure;dlbist synthesis algorithms increase;binary decision diagram;computing time;circuit size;deterministic logic;memory consumption;logic bist;dlbist method;new algorithm;bdds;attractive test strategy;circuit complexity;industrial design	Deterministic logic BIST (DLBIST) is an attractive test strategy, since it combines advantages of deterministic external testing and pseudo-random LBIST. Unfortunately, previously published DLBIST methods are unsuited for large ICs, since computing time and memory consumption of the DLBIST synthesis algorithms increase exponentially, or at least cubically, with the circuit size. In this paper, we propose a novel DLBIST synthesis procedure that has nearly linear complexity in terms of both computing time and memory consumption. The new algorithms are based on binary decision diagrams (BDDs). We demonstrate the efficiency of the new algorithms for industrial designs up to 2M gates.	algorithm;binary decision diagram;computational complexity theory;fault coverage;logic built-in self-test;overhead (computing);pseudorandomness;requirement;simulation;test set;test strategy	Valentin Gherman;Hans-Joachim Wunderlich;Harald P. E. Vranken;Friedrich Hapke;Michael Wittke;Michael Garbers	2004	2004 International Conferce on Test	10.1109/ITC.2004.66	circuit complexity;boolean circuit;electronic engineering;logic optimization;industrial design;computer science;theoretical computer science;mathematics;binary decision diagram;algorithm	EDA	19.91227506154601	50.075853072255136	68032
f82d607f87793590bcc4b47f9a5f74c85a6b2f9b	a novel and efficient routing architecture for multi-fpga systems	prototipificacion rapida;reconfiguration;computing machine;concepcion asistida;field programmable gate array;evaluation performance;computer aided design;reconfigurable systems;reconfiguracion;arquitectura circuito;emulateur;reconfigurable system;fpid;performance evaluation;multi fpga system;reconfigurable computing;routing;cad;prototypes;evaluacion prestacion;hcgp algorithm;logic;partitioning;circuit architecture;wires;indexing terms;systeme reconfigurable;red puerta programable;reconfigurable components;reseau porte programmable;system level;network routing;experimental result;chip;routing computer architecture field programmable gate arrays costs logic devices prototypes vehicles wires integrated circuit interconnections partitioning algorithms;computer architecture;rapid prototyping;hybrid complete graph and partial crossbar routing architecture;particion;chemin critique;critical path;integrated circuit interconnections;field programmable interconnect device;hcgp algorithm multi fpga system field programmable interconnect device hybrid complete graph and partial crossbar routing architecture fpid critical path delay design field programmable gate array cad;architecture circuit;partition;resultado experimental;routing algorithm;conception assistee;machine calcul;design;critical path delay;encaminamiento;vehicles;emulador;field programmable gate arrays;resultat experimental;grafo completo;logic cad;complete graph;graphe complet;maquina calculo;logique;logica;emulator;recorrido critico;logic devices;logic cad field programmable gate arrays network routing;prototypage rapide;acheminement;partitioning algorithms	Multi-FPGA systems (MFSs) are used as custom computing machines, logic emulators and rapid prototyping v ehicles. A key aspect of these systems is their programmable routing architecture which is the manner in which wires, FPGAs and Field-Programmable Interconnect De vices (FPIDs) are connected. Se veral routing architectures for MFSs ha ve been proposed [Arno92] [Butt92] [Hauc94] [Apti96] [Vuil96] [Babb97] and pre vious research has sho wn that the partial crossbar is one of the best e xisting architectures [Kim96] [Khal97]. In this paper we propose a new routing architecture, called the Hybrid CompleteGraph andPartial-Crossbar (HCGP) which has superior speed and cost compared to a partial crossbar . The new architecture uses both hardwired and programmable connections between the FPGAs. W e compare the performance and cost of the HCGP and partial crossbar architectures e xperimentally, by mapping a set of 15 lar ge benchmark circuits into each architecture. A customized set of partitioning and inter -chip routing tools were de veloped, with particular attention paid to architecture-appropriate inter -chip routing algorithms. We show that the cost of the partial crossbar (as measured by the number of pins on all FPGAs and FPIDs required to fit a design), is on a verage 20% more than the ne w HCGP architecture and as much as 25% more. Furthermore, the critical path delay for designs implemented on the partial crossbar were on a verage 20% more than the HCGP architecture and up to 43% more. Using our e xperimental approach, we also e xplore a key architecture parameter associated with the HCGP architecture: the proportion of hard-wired connections v ersus programmable connections, to determine its best v alue.	algorithm;benchmark (computing);computer;computer-aided design;critical path method;crossbar switch;emulator;experiment;field-programmable gate array;open research;rapid prototyping;routing;von neumann architecture;xplore	Mohammed A. S. Khalid;Jonathan Rose	2000	IEEE Trans. VLSI Syst.	10.1109/92.820759	embedded system;routing;electronic engineering;parallel computing;computer science;engineering;operating system;computer aided design;field-programmable gate array;computer network	Arch	13.811129956823923	50.4545725594565	68156
700cdc03543fb7d04766b4a1d750133a47b1fbd8	pseudo pin assignment for single-layer over-the-cell routing	cmos integrated circuits;pins;m2 layer;cmos technology;routing;paper technology;cmos double metal gate array technology;wires;one layer routine cmos double metal gate array technology m2 layer over the cell routing;cmos integrated circuits circuit layout cad;circuit layout cad;routing pins wires cmos technology paper technology wiring mesh generation;wiring;mesh generation;one layer routine;over the cell routing	In a CMOS double metal gate-array technology, only M2 layer is available for over-the-cell routing. ‘This paper prescnts a systematic algorithm which intelligcntly converts global wires into pseudo pins and assigns them to each row of cells. The final positions of pseudo pins not only provide a feasible solution for onc-layer routing over the cclls, but also minimize wire densities in the adjacent two-laycr routing channels.	algorithm;cmos;gate array;metal gate;routing	Howard H. Chen	1990		10.1109/ICCD.1990.130245	embedded system;electronic engineering;static routing;equal-cost multi-path routing;computer science;engineering;dynamic source routing;electrical engineering;destination-sequenced distance vector routing;link-state routing protocol;cmos;routing information protocol;computer network	EDA	14.761518162218666	51.73694630018853	68323
588321427a8a8b9a480d9eb1ae62805da267f3de	interconnect optimization strategies for high-performance vlsi designs	design optimization very large scale integration integrated circuit interconnections repeaters wires electrical capacitance tomography clocks silicon wiring routing;integrated circuit layout;physical design;vlsi design;signal integrity;network routing;chip;integrated circuit interconnections;shield wires interconnect optimization strategies high performance vlsi designs interconnect tuning repeater insertion interconnect delay multilayer interconnect global wiring layers bus routing shielding spacing rules signal integrity line pitch;vlsi;capacitance integrated circuit interconnections vlsi circuit optimisation integrated circuit layout network routing delays;capacitance;circuit optimisation;high performance;delays	Interconnect tuning and repeater insertion are necessary to optimize interconnectdelay, signalperformance and integrity, and interconnectmanufacturability and reliability. Repeater insertion in interconnects is an increasingly important element in the physicaldesign of high-performance VLSI systems. By interconnect tuning, we refer to the selection of line thicknesses, widths and spacings in multi-layer interconnect to simultaneously optimize signal distribution, signal performance, signal integrity, and interconnect manufacturability and reliability. This is a key activity in most leading-edge design projects, but has received little attention in the literature. Our work provides the first technology-specific studies of interconnect tuning in the literature. We centeron global wiring layers and interconnect tuning issues related to bus routing, repeater insertion, and choice of shielding/spacing rules for signal integrity and performance. We address four basic questions. (1) How should width and spacing be allocated to maximize performance for a given line pitch? (2) For a given line pitch, what criteria affect the optimal interval at which repeaters should be inserted into global interconnects? (3) Under what circumstances are shield wires the optimum technique for improving interconnectperformance? (4) In global interconnect with repeaters, what other interconnect tuning is possible? Our study of question (4) demonstrates a new approach of offsetting repeater placements that can reduce worst-case cross-chip delays by over 30% in current technologies.	best, worst and average case;cpu power dissipation;database tuning;design for manufacturability;dot pitch;electrical connection;intel quickpath interconnect;layer (electronics);noise margin;pitch (music);repeater insertion;routing;signal integrity;very-large-scale integration;wiring	Andrew B. Kahng;Sudhakar Muddu;Egino Sarto	1999		10.1109/ICVD.1999.745199	embedded system;electronic engineering;computer science;engineering;electrical engineering;very-large-scale integration;interconnect bottleneck	EDA	14.588799057450561	52.515420222588055	68368
e4d691fb0cab9e26cb77723be872c8d0453c48b2	mtbf estimation in coherent clock domains	mean time between failures mtbf;metastability;coherent clocks synchronization metastability mean time between failures mtbf;clocks;flip flops;failure analysis;coherent clocks;synchronization;mean time between failures coherent clock domains ratiochronous clocks multisynchronous clocks mesochronous clocks n flip flop synchronizers specialized synchronizers standard mtbf formula failure rate data edges sampling clock cycle common source phase distributions metastability failure;integrated circuit reliability clocks failure analysis flip flops;integrated circuit reliability	Special synchronizers exist for special clock relations such as mesochronous, multi-synchronous and ratiochronous clocks, while variants of N-flip-flop synchronizers are employed when the communicating clocks are asynchronous. N-flip-flop synchronizers are also used in all special cases, at the cost of longer latency than when using specialized synchronizers. The reliability of N-flip-flop synchronizers is expressed by the standard MTBF formula. This paper describes cases of coherent clocks that suffer of a higher failure rate than predicted by the MTBF formula, that formula assumes uniform distribution of data edges across the sampling clock cycle, but coherent clocking leads to drastically different situations. Coherent clocks are defined as derived from a common source, and phase distributions are discussed. The effect of jitter is analyzed, and a new MTBF expression is developed. An optimal condition for maximizing MTBF and a circuit that can adaptively achieve that optimum are described. We show a case study of metastability failure in a real 40nm circuit and describe guidelines used to increase its MTBF based on the rules derived in the paper.	clock rate;clock signal;coherent;flops;failure rate;flip-flop (electronics);mean time between failures;mesochronous network;sampling (signal processing)	Salomon Beer;Ran Ginosar;Rostislav Dobkin;Yoav Weizman	2013	2013 IEEE 19th International Symposium on Asynchronous Circuits and Systems	10.1109/ASYNC.2013.19	clock synchronization;embedded system;electronic engineering;real-time computing;computer science	Embedded	23.53741201733905	52.67849463497601	68460
06f981374b7ae305f5de07993e19eb88f7dfc91a	a new layout optimization methodology for cmos complex gates	cmos integrated circuits;optimisation;optimized net list efficient algorithms heuristics layout optimization methodology cmos complex gates delayed binding;efficient algorithm;heuristic programming;optimization methods mos devices delay very large scale integration logic functions cmos logic circuits;logic gates;optimisation circuit layout cad cmos integrated circuits delays heuristic programming integrated logic circuits logic gates;circuit layout cad;integrated logic circuits;delays	Efficient algorithms for the layout generation of CMOS complex gates are presented. Heuristics which use the concept of delayed binding are introduced. An optimized net list is decided during the layout generation phase, rather than before. Examples are given showing that this approach can achieve a considerable improvement over previous ones. >	cmos;mathematical optimization	C. Y. Roger Chen;Cliff Yungchin Hou	1988		10.1109/ICCAD.1988.122530	and-or-invert;computer architecture;electronic engineering;nmos logic;nor logic;logic optimization;logic gate;logic family;ic layout editor;depletion-load nmos logic;computer science;theoretical computer science;pass transistor logic;integrated circuit layout;integrated injection logic;cmos;digital electronics;standard cell	EDA	16.48396734526317	49.85283217015846	68615
6142a3b6bc9dc80e28861379a23c3cdb1e6ebefa	a dual redundancy radiation-hardened flip-flop based on c-element in 65nm process	clocks;flip flops;inverters;transistors;single event upsets;latches;tunneling magnetoresistance	We propose a radiation-hardened flip-flop immune to the Single Event Upset (SEU) effect. Immunity was achieved through the use of C-elements and redundant storage elements. We take advantage of the property of C-element in which it enters a high impedance mode when its inputs are of different logic values. Redundant storage nodes are then used to drive the C-elements so that a single upset pulse in any storage will be prevented from altering the state of the output of the Flip-Flop. The Flip-Flop was implemented using 48 transistors and occupied an area of 30.78 um2, using 65nm CMOS process. It consumed 22.6% less transistors as compared to the traditional SEU resilient TMR Flip-flop.	c-element;cmos;characteristic impedance;computer simulation;flops;flip-flop (electronics);high impedance;radiation hardening;single event upset;standard cell;transistor;triple modular redundancy;very-large-scale integration	Gibran Limi Jaya;Shoushun Chen;Liter Siek	2016	2016 International Symposium on Integrated Circuits (ISIC)	10.1109/ISICIR.2016.7829721	embedded system;electronic engineering;real-time computing;engineering	Arch	17.94957707163529	58.0141488357848	68624
0384cd7783867a14567f54995dfc11c471948d19	algorithmic level design space exploration tool for creation of highly optimized synthesizable circuits	design automation;evolutionary computation;network synthesis;multiobjective evolutionary algorithms highly optimized synthesizable circuits algorithmic level design space exploration tool;multi objective;multi objective evolutionary algorithm;network synthesis aerospace components evolutionary computation;algorithm design and analysis space exploration design optimization circuit synthesis signal processing algorithms spirals digital signal processing prototypes evolutionary computation electronic design automation and methodology;high level synthesis;evolutionary algorithms;design space exploration;evolutionary algorithm;evolutionary algorithms design automation high level synthesis multi objective;aerospace components	This paper presents some of the results obtained by using a prototype algorithmic level design space exploration tool currently under development. The tool is based upon multi-objective evolutionary algorithms. The paper highlights the tool's benefits and discusses its current abilities in terms of its experimental applications.	design space exploration;evolutionary algorithm;level design;logic synthesis;prototype	Nazish Aslam;Tughrul Arslan;Ahmet T. Erdogan	2007	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.366177	evolutionary programming;network synthesis filters;simulation;interactive evolutionary computation;computer science;computer-automated design;theoretical computer science;machine learning;evolutionary algorithm;high-level synthesis	EDA	10.877690117918942	49.417763407630694	68654
9b3def6351779a52549ddc77f4222ce2e2c299cc	on crossing minimization problem	minimisation;algorithme rapide;graph theory;concepcion asistida;homotopie;minimization;computer aided design;optimisation;vlsi crossing minimization problem global routing postoptimization redundant crossings constrained cmp unconstrained cmp time bounds plane embedding information graph based framework junction terminal assignment;circuit graphe;optimizacion;integrated circuit;integrated circuit layout;routing;implementation;homotopia;layout problem;routing circuits minimization topology very large scale integration wiring manufacturing processes data structures multichip modules wire;probleme agencement;circuito integrado;minimizacion;indexing terms;circuito grafo;homotopy;network routing;ejecucion;redundancy;circuit layout cad vlsi integrated circuit layout graph theory redundancy network routing circuit optimisation;graph circuit;global routing;fast algorithm;vlsi;conception assistee;problema disposicion;circuit layout cad;optimization;encaminamiento;circuit optimisation;algoritmo rapido;circuit integre;acheminement	In this paper we consider a problem related to global routing post-optimization: the crossing minimization problem (CMP). Given a global routing representation, the CMP is to minimize redundant crossings between every pair of nets. In particular, there are two kinds of CMP: constrained CMP (CCMP) and unconstrained CMP (UCMP). These problems have been studied previously in Groe89], where an O(m 2 n) algorithm was proposed for CCMP, and in MS95], where an (mn 2 + 2) algorithm was proposed for UCMP, where m is the total number of modules, n is the number of nets, and is the number of crossings deened by an initial global routing topology. We present a simpler and faster O(mn) algorithm for CCMP and an O(n(m +)) time algorithm for UCMP. Both algorithms improve over the time bounds of the previously proposed algorithms. The novel part of our algorithm is that it uses the plane embedding information of globally routed nets in the routing area to construct a graph-based framework and obtain a good junction terminal assignment that minimizes the number of crossings.	algorithm;crossing number (graph theory);mathematical optimization;quadratic unconstrained binary optimization;routing	Hsiao-Feng Steven Chen;D. T. Lee	1998	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.703928	mathematical optimization;routing;electronic engineering;computer science;electrical engineering;graph theory;theoretical computer science;computer aided design;engineering drawing;computer network	EDA	15.69911158687291	50.64199839541439	68684
2fa09abdd81df92cecae9db02a7e2e78e659a5cd	defect-aware nanocrossbar logic mapping using bipartite subgraph isomorphism & canonization	computers;bipartite subgraph isomorphism;graph theory;defect aware nanocrossbar logic mapping;logic arrays;reconfigurable architectures fault tolerance bipartite subgraph isomorphism nanelectronics;design automation;fault tolerant;sorting;reconfigurable architectures;logic function mapping;nanelectronics;programmable logic arrays;iterative algorithm;arrays;iterative methods;search tree defect aware nanocrossbar logic mapping bipartite subgraph isomorphism np complete problem logic function mapping kns 2ds algorithm k neighbor sort 2d sort iterative rough canonizer;search trees;reconfigurable architecture;computational complexity;2d sort;cmos logic circuits programmable logic arrays iterative algorithms logic functions runtime np complete problem reconfigurable architectures reconfigurable logic nanowires diodes;fault tolerance;nanoelectronics;logic functions;k neighbor sort;tree searching computational complexity graph theory iterative methods logic arrays nanoelectronics;tree searching;search tree;kns 2ds algorithm;iterative rough canonizer;np complete problem	This paper addresses the NP-complete problem of mapping a logic function on to a nanocrossbar with a known defect map. We first show that this problem can be transformed into a Bipartite SubGraph Isomorphism (BSGI) problem. Then we present our proposed KNS-2DS algorithm, which canonizes both graphs in N2 time (N being the number of nodes) and then matches them in N3 time in the worst case. KNS-2DS uses a K-Neighbor Sort (KNS) to initialize our main contribution 2D-Sort (2DS). 2DS is an iterative rough canonizer that lets a straightforward matching algorithm complete the job. Our algorithm offers very short run-times (due to canonization) compared to previous work and has success on all benchmarks. KNS-2DS is also novel from the perspective of the BSGI problem in the sense that it is based on canonization but not on a search tree with backtracking.	algorithm;backtracking;benchmark (computing);best, worst and average case;boolean algebra;iterative method;np-completeness;search tree;software bug;subgraph isomorphism problem	Sezer Gören;H. Fatih Ugurdag;Okan Palaz	2010	2010 15th IEEE European Test Symposium	10.1109/ETSYM.2010.5512747	fault tolerance;discrete mathematics;electronic design automation;computer science;graph theory;theoretical computer science;mathematics;iterative method;algorithm	Embedded	16.557803475342723	48.62108389295729	68748
32b2b50c404f4f432a47f1304a45be2741a0559e	power-optimal simultaneous buffer insertion/sizing and uniform wire sizing for single long wires	minimisation;wire delay power dissipation capacitance chromium mos devices circuits threshold voltage power engineering and energy power engineering computing;optimal solution;mos devices;bisuws;buffer circuits;wire;power engineering and energy;power engineering computing;bisuws power optimality simultaneous buffer insertion sizing uniform wire sizing vlsi single long wires power dissipation minimization interconnect wire;single long wires;threshold voltage;chromium;integrated circuit interconnections;power dissipation;power optimality;circuit optimisation power consumption buffer circuits integrated circuit interconnections minimisation;power optimization;vlsi;power dissipation minimization;interconnect wire;circuits;uniform wire sizing;capacitance;power consumption;circuit optimisation;simultaneous buffer insertion sizing;buffer insertion	This paper studies the problems of minimizing power dissipation of an interconnect wire by simultaneously considering buffer insertion/sizing and wire sizing. We obtain optimal solutions for the problems of optimizing power dissipation for simultaneous buffer insertion/sizing and uniform wire sizing (BISUWS) under the delay constraints. These solutions can be used to estimate the power dissipation in the interconnect designs.	cpu power dissipation;elmore delay	Ruiming Li;Dian Zhou;Jin Liu;Xuan Zeng	2005	2005 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2005.1464537	minimisation;electronic engineering;chromium;engineering;electrical engineering;capacitance;threshold voltage;engineering drawing;power optimization	EDA	16.387947043531053	53.83955719561696	68918
90c1e0b65cc14fe00f2ab32864fc322d9435cc72	symmetry constraint based on mismatch analysis for analog layout in soi technology	mismatch analysis;combination effect;soi technology;symmetry constraint;configurable optimization process;common centroid technology;random mismatch;thermal-induced mismatch;systematic mismatch;analog layout;different sensitivity;mismatch elimination;vlsi technology;silicon on insulator;analog circuits;integrated circuit layout;optimization;thermal conductivity;vlsi;very large scale integration	The conventional tools for mismatch elimination such as geometric symmetry and common centroid technology can only eliminate systematic mismatch, but can do little to reduce random mismatch and thermal-induced mismatch. As the development of VLSI technology, the random mismatch is becoming more and more serious. And in the context of Silicon on Insulator (SOI), the self-heating effect leads to unbearable thermal-induced mismatch. Therefore, in this paper, we first propose a new model which can estimate the combination effect of both random mismatch and thermal-induced mismatch by mismatch analysis and SPICE simulation. And in order to meet the different sensitivities of different symmetry pairs, an automatic classification tool and a configurable optimization process are also introduced. All of these are embedded in the floorplanning process. The final experimental results prove the effectiveness of our method.	embedded system;floorplan (microelectronics);mathematical optimization;spice;silicon on insulator;simulation;thermal grease;topological insulator;very-large-scale integration	Jiayi Liu;Sheqin Dong;Xianlong Hong;Yibo Wang;Ou He;Satoshi Goto	2008	2008 Asia and South Pacific Design Automation Conference		electronic engineering;computer science;engineering;electrical engineering;silicon on insulator;integrated circuit layout;very-large-scale integration;engineering drawing	EDA	17.834844239615762	53.68291222693125	68977
5c534a1cfbf3e127192a3c781ec6bc1f9ee2f1a5	implementing a margolus neighborhood cellular automata on a fpga	field programmable gate array;random access memory;fiabilidad;reliability;sistema experto;cell system;memoria acceso directo;implementation;rule based;base connaissance;red puerta programable;reseau porte programmable;systeme cellulaire;sistema celular;parametre critique;fiabilite;memoire acces direct;automate cellulaire;parametro critico;horloge;base conocimiento;systeme expert;implementacion;cellular automata;clock;cellular automaton;reloj;critical parameter;automata celular;knowledge base;expert system	Margolus neighborhood is the easiest form of designing Cellular Automata Rules with features such as invertibility or particle conserving. In this paper we introduce a notation to describe completely a rule based on this neighborhood and implement it in two ways: The first corresponds to a classical RAM-based implementation, while the second, based on concurrent cells, is useful for smaller systems in which time is a critical parameter. This implementation has the feature that the evolution of all the cells in the design is performed in the same clock cycle.	block cellular automaton;field-programmable gate array;moore neighborhood;norman margolus	Joaquín Cerdá;Rafael Gadea Gironés;Guillermo Payá Vayá	2003		10.1007/3-540-44869-1_16	cellular automaton;clock;reversible cellular automaton;computer science;artificial intelligence;reliability;implementation;algorithm;field-programmable gate array	Robotics	18.371200147526604	49.80588770828949	69020
1c96394aa3fec23e12a807d1ca461b411e60c534	pulse generation for on-chip data transmission	energy efficiency;data transmission;pulse signalling;power saving;network on chip;energy efficient;interconnect;low swing;wires;inverters;signal integrity;interconnection network;chip;pulse generation;pulse generation data communication wire voltage network on a chip space vector pulse width modulation signal design delay integrated circuit interconnections energy efficiency;low latency;pulse based data transmission;pulse generators;rlc circuits;rc model;size 1 25 mm to 3 mm pulse based data transmission on chip data transmission pulse generator signal integrity full pulse based asynchronous network on chip noc rc model rlc model energy efficiency inductance;partial discharges;asynchronous circuits;inductance;on chip data transmission;repeaters;pulse generator;on chip communication;noc;size 1 25 mm to 3 mm;rlc circuits asynchronous circuits inductance network on chip pulse generators;high performance;discharges;energy efficiency interconnect on chip communication pulse signalling repeaters network on chip low swing;full pulse based asynchronous network on chip;throughput;rlc model	Pulse-based data transmission has been demonstrated as a power-saving and high performance alternative to level-based signalling over global distances. Key to its correct operation is the use of reliable and low latency pulse generators. We propose a simple design of pulse generator, evaluate its performance and show a design that offers greater safeguards against malformed input signals. We show how performance scales with interconnect length, consider signal-integrity issues and also present a method of repeating the signal to allow transmission over wire lengths exceeding 3mm, and data rates exceeding 1Gbit/s. Results are presented by simulation as part of a a full pulsebased asynchronous Network-on-Chip. Simulation in a NoC context produces much more accurate results for factors such as delay than when simulating in isolation. Our simulations are carried out using a full RLC model, as opposed to the more common RC model. Inclusion of inductance further increases our result’s accuracy, especially when compared to previous work. Finally, we see that the energy efficiency of our approach is comparable to other contemporary designs in the literature and is especially efficient over wire lengths in the range 1.25mm to 3mm.	chopper (electronics);crosstalk;electronic circuit;network on a chip;pulse generator;pulse-width modulation;rlc circuit;radio-controlled model;self-organized criticality;signal integrity;simulation;stateful firewall	Simon Hollis	2009	2009 12th Euromicro Conference on Digital System Design, Architectures, Methods and Tools	10.1109/DSD.2009.176	pulse generator;embedded system;telecommunications;computer science;efficient energy use;network on a chip	EDA	15.160668420565836	57.34218467194914	69067
6ae327fae70372d06e438e6a6c418fea7a7c0020	the construction of minimal area power and ground nets for vlsi circuits	very large scale integration;optimization;monte carlo method;threshold voltage;integrated circuit;logic;simulated annealing;current density	This paper deals with the problem of sizing power and ground nets in integrated circuits composed of modules, where the nets are routed in the channels between the modules. Constraints are assumed on allowable voltage drops between the chip's power and ground pads and the module's power and ground pins. Maximum current drain into each module is also assumed to be known. A procedure for determining the width of each branch in the power and ground trees is presented, where the objective is to minimize the area of the power and ground nets subject to several constraints, such as IR voltage drop and metal migration.	algorithm;computation;constant current;current source;electromigration;integrated circuit;routing;time complexity;tor messenger;very-large-scale integration	Salim U. Chowdhury;Melvin A. Breuer	1985	22nd ACM/IEEE Design Automation Conference	10.1145/317825.317996	embedded system;mathematical optimization;electronic engineering;simulated annealing;computer science;engineering;electrical engineering;integrated circuit;threshold voltage;logic;current density;monte carlo method	EDA	18.745272349551712	55.98263536727958	69072
c5a22c4a00a839276d582223558578f15519b347	temperature-aware leakage estimation using piecewise linear power models	leakage estimation;power models;temperature-aware;piecewise linear	Due to the superlinear dependence of leakage power consumption on temperature, and spatial variations in on-chip thermal profiles, methods of leakage power estimation that are known to be accurate require detailed knowledge of thermal profiles. Leakage power depends on the integrated circuit (IC) thermal profile and circuit design style. Here, we show that piecewise linear models can be used to permit accurate leakage estimation over the operating temperature ranges of the ICs. We then show that for typical IC packages and cooling structures, a given amount of heat introduced at any position in the active layer will have a similar impact on the average temperature of the layer. These two observations support the proof that, for wide ranges of design styles and operating temperatures, extremely fast, coarse-grained thermal models, combined with piecewise linear leakage power consumption models, enable the estimation of chip-wide leakage power consumption. These results are further confirmed through comparisons with leakage estimates based on detailed, time-consuming thermal analysis techniques. Experimental results indicate that, when compared with a leakage analysis technique that relies on accurate spatial temperature estimation, the proposed technique yields a 59,259× to 1,790,000× speedup in estimating leakage power consumption, while maintaining accuracy. key words: temperature-aware, power models, leakage estimation	circuit design;computer cooling;estimation theory;integrated circuit;linear model;piecewise linear continuation;spectral leakage;speedup;thermal profiling	Yongpan Liu;Huazhong Yang	2010	IEICE Transactions		mathematical optimization;electronic engineering;piecewise linear function;engineering;control theory	EDA	21.609039338933147	58.83711130318422	69186
fc45aa58278792461f74dfb07292768749765c72	a synthesis method to propagate false path information from rtl to gate level	circuit faults;logic design;vlsi circuit design;logic circuits;gate level;integrated circuit design;vlsi circuit testing;logic synthesis;logic gates;registers;logic testing;integrated circuit testing;vlsi circuit design register transfer level gate level false path information propagation synthesis method rtl circuit logic synthesis vlsi circuit testing;joining processes;vlsi;signal mapping;circuit synthesis circuit testing timing logic testing logic design signal synthesis signal mapping hardware logic circuits joining processes;circuit testing;signal synthesis;register transfer level;rtl circuit;vlsi integrated circuit design integrated circuit testing;false path information propagation synthesis method;benchmark testing;circuit synthesis;hardware;timing	This paper proposes a new synthesis method for propagating information of paths from register transfer level (RTL) to gate level. The method enables false path identification at RTL without not only enforcing strong constraints on logic synthesis but also loss of the information about false paths identified. Experiments show that the proposed method can reduce hardware and timing overhead and improve propagability of false path information through logic synthesis compared with the previous methods.	experiment;goodyear mpp;least squares;logic synthesis;mebibyte;overhead (computing);register-transfer level;tseng labs	Satoshi Ohtake;Hiroshi Iwata;Hideo Fujiwara	2010	13th IEEE Symposium on Design and Diagnostics of Electronic Circuits and Systems	10.1109/DDECS.2010.5491787	embedded system;computer architecture;electronic engineering;logic synthesis;real-time computing;logic gate;computer science	EDA	19.56386502032014	50.6245635693913	69189
82d248fab38711a23e5235f8f95fb0fd0e000159	mems fault model generation using caramel	micromechanical devices testing contamination atmospheric modeling fabrication design for testability solid modeling analytical models materials reliability microelectromechanical systems;electromechanical simulator abaqus mems fault model caramel process simulator codef reliability analysis contamination particles geometrical properties material properties microelectromechanical systems mesh description defective layout;failure analysis;circuit simulation;micromechanical devices;integrated circuit testing;reliability analysis;microelectromechanical system;integrated circuit reliability;process simulation;fault model;circuit simulation micromechanical devices failure analysis integrated circuit testing fault diagnosis integrated circuit reliability digital simulation;digital simulation;fault diagnosis;material properties	We have enhanced the process simulator CODEF (1996) into a tool called CARAMEL (Contamination And Reliability Analysis of MicroElectromechanical Layout) for analyzing the impact of contamination particles on the geometrical and material properties of microelectromechanical systems (MEMS). CARAMEL accepts as input a microelectromechanical layout, a particulate description, and a process recipe. CARAMEL produces a mesh description of the defective layout that is completely compatible with the electromechanical simulator ABAQUS (1995). Analysis of CARAMEL's output indicates that a wide range of defective structures are possible due to the presence of contaminations. Moreover, electromechanical simulations of CARAMEL's mesh representations of defective layout has revealed that a wide variety of faulty behaviors are associated with these defects. In this paper, we describe CARAMEL and its application to the development of realistic fault models for MEMS.	fault model;microelectromechanical systems	Abhijeet Kolpekwar;Chris S. Kellen;R. D. Blanton	1998		10.1109/TEST.1998.743199	material properties;reliability engineering;embedded system;failure analysis;electronic engineering;process simulation;engineering;fault model	NLP	24.375167057517235	53.36695479098674	69321
a9c7511c7699d4eca29fba1423f48844688d8595	benchmarking of monolayer and bilayer two-dimensional transition metal dichalcogenide (tmd) based logic circuits and 6t sram cells	monolayer;6t sram cells;bilayer;transition metal dichalcogenide tmd;two dimensional 2d materials;logic circuits;low power;variability	We evaluate and benchmark the performance of logic circuits and stability/performance of 6T SRAM cells using monolayer and bilayer TMD devices based on ITRS 2028 (5.9nm) technology node. For the performance benchmarking of logic circuits, the tradeoff between electrostatic integrity (monolayer favored) and carrier mobility (bilayer favored), and the issues regarding the uncertainties in the mobility ratio and source/drain series resistance, the underlap device design, and the off-current spec., etc. are comprehensively addressed. In the evaluation of SRAM cells, the cell immunity to random variations is focused. Besides, the impact of high RSD of TMD materials on RSNM variability is also investigated. The source/drain underlap design is shown to alleviate the larger variability of bilayer SRAM cells. Finally, with superior electrostatics and immunity to random variations, the monolayer TMD devices are favored for low-power logic and SRAM applications; while the bilayer devices, with higher carrier mobility, are more suitable for high-performance logic and SRAM applications.	benchmark (computing);electron mobility;heart rate variability;logic gate;low-power broadcasting;really simple discovery;semiconductor device fabrication;series and parallel circuits;spatial variability;spec#;static random-access memory;tip-magnetic driving;transition metal dichalcogenide monolayers	Chang-Hung Yu;Pin Su;Ching-Te Chuang	2016		10.1145/2934583.2934630	electronic engineering;logic gate;engineering;electrical engineering;nanotechnology;monolayer;bilayer	EDA	17.927197693916998	60.2539862010409	69482
4138b69634cc4035cddea2e3de47987ff0df503f	model and solution strategy for placement of rectangular blocks in the euclidean plane	modelizacion;block design;concepcion asistida;computer aided design;optimisation;printed circuits;optimizacion;plano bloque;printed circuit;sine wave shaped penalty function total wire length minimisation placement rectangular blocks euclidean plane nonlinear optimization model wire connections cad tool vlsi printed circuit board layout designs;implantation;euclidean distance;plan bloc;wire very large scale integration mathematical model integrated circuit interconnections routing design automation algorithm design and analysis equations constraint optimization printed circuits;lennard jones;algorithme;modelisation;algorithm;algorritmo;mathematical model;vlsi;conception assistee;circuit layout cad;optimization;printed circuit board;nonlinear optimization;modeling;circuit imprime;implantacion;vlsi circuit layout cad optimisation printed circuits;circuito imprimido;penalty function	The authors describe a nonlinear optimization model for the placement of rectangular blocks with some wire connections among them in the Euclidean plane, so that the total wire length is minimized. Such a placement algorithm is useful as a CAD tool for VLSI and printed-circuit-board layout designs. The model ensures that the blocks will not overlap and minimizes the sum of the distances of the interconnections of the blocks with respect to their orientation as well as their position. Mechanisms are presented for solving more restrictive placement problems, including one in which there is a set of equally spaced, discrete angles to be used in the placement. The mathematical model is based on the Lennard-Jones 6-12 potential equation, on a sine-wave-shaped penalty function, and on minimizing the sum of the squares of the Euclidean distances of the block interconnections. Experimental results are presented to show that good placements are achieved with these techniques. >		Amir Alon;Uri M. Ascher	1988	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.3171	mathematical optimization;electronic engineering;nonlinear programming;computer science;engineering;electrical engineering;computer aided design;mathematics;printed circuit board;engineering drawing	EDA	15.109829884845745	50.71073042415658	69622
4c12e12b11c7fccbaccea6df7dda866390a725b5	transistor count optimization in ig finfet network design	finfets logic gates merging optimization integrated circuits;digital ic design finfet cad tool logic synthesis factorization graph theory transistor network logic gate	Double-gate devices, like independent-gate (IG) FinFET, have introduced new possibilities and challenges in synthesis of transistor networks. Existing factorization methods and graph-based optimizations are not actually the most effective way to generate optimized IG FinFET based networks because only reducing the number of literals in a given Boolean expression does not guarantee the minimum transistor count. This paper presents two novel methods aiming the minimization of the number of devices in logic networks. The first contribution is a method for defactoring Boolean expressions able to apply the conventional factorization algorithms together with IG FinFET particularities, so improving it. The second contribution is a novel graph-based method that improves even more transistor arrangements by exploiting enhanced nonseries-parallel associations. Experimental results shown a significant reduction in the size of transistor networks delivered by the proposed methods.	algorithm;apollonian network;boolean expression;transistor count	Vinicius Neves Possani;André Inácio Reis;Renato Perez Ribas;Felipe de S. Marques;Leomar S. da Rosa	2017	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2016.2629451	electronic engineering;transistor count;diode–transistor logic;computer science;logic gate;boolean expression;theoretical computer science;transistor;pass transistor logic;logic family;network planning and design	EDA	16.19932590191308	51.749733340058235	69698
a16085ef11a763b980e7076133e8f47e26ee4f7b	fast second-order statistical static timing analysis using parameter dimension reduction	statistical timing;second order;verification;process variation;reduced rank regression fast second order statistical static timing analysis parameter dimension reduction nanometer vlsi design computational complexity parameter dimensionality;vlsi computational complexity network analysis regression analysis;dimension reduction;fast second order statistical static timing analysis;performance;timing principal component analysis performance analysis algorithm design and analysis circuit optimization runtime computational efficiency circuit analysis robustness context modeling;parameter dimensionality;vlsi design;parameter dimension reduction;network analysis;first order;computational complexity;parameter dimension reduction algorithms performance verification statistical timing process variation;reduced rank regression;vlsi;timing analysis;static timing analysis;algorithms;regression analysis;nanometer vlsi design;second order statistics;statistical static timing analysis;industrial design	The ability to account for the growing impacts of multiple process variations in modern technologies is becoming an integral part of nanometer VLSI design. Under the context of timing analysis, the need for combating process variations has sparkled a growing body of statistical static timing analysis (SSTA) techniques. While first-order SSTA techniques enjoy good runtime efficiency desired for tackling large industrial designs, more accurate second-order SSTA techniques have been proposed to improve the analysis accuracy, but at the cost of high computational complexity. Although many sources of variations may impact the circuit performance, considering a large number of inter-die and intra-die variations in the traditional SSTA analysis is very challenging. In this paper, we address the analysis complexity brought by high parameter dimensionality in static timing analysis and propose an accurate yet fast second-order SSTA algorithm based upon novel parameter dimension reduction. By developing reduced-rank regression based parameter reduction algorithms within block-based SSTA flow, we demonstrate that accurate second order SSTA analysis can be extended to a much higher parameter dimensionality than what is possible before. Our experimental results have shown that the proposed parameter reduction can achieve up to 10X parameter dimension reduction and lead to significantly improved second-order SSTA analysis under a large set of process variations.	algorithm;computational complexity theory;dimensionality reduction;first-order predicate;floor and ceiling functions;statistical static timing analysis;very-large-scale integration	Zhuo Feng;Peng Li;Yaping Zhan	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278540	econometrics;industrial design;computer science;theoretical computer science;very-large-scale integration;static timing analysis;algorithm;statistics	EDA	23.229761332872112	58.409368725345075	69753
1a6ac303ef645d97c59eedfe52d24fc4cea6090f	design of low-voltage cmos pipelined adcs using 1 pico-joule of energy per conversion	10 bit low voltage pipelined adcs cmos optimization methodology genetic algorithms multi bit architectures supply voltage clock boosting techniques switched opamp techniques power efficiency 1 pj 1 5 v;clocks;power efficiency;integrated circuit design;design optimization voltage pipelines cmos technology algorithm design and analysis clocks power dissipation energy resolution genetic algorithms image resolution;low voltage;low power;analogue digital conversion;clocks low power electronics integrated circuit design pipeline processing circuit optimisation genetic algorithms analogue digital conversion;low power electronics;genetic algorithms;circuit optimisation;pipeline processing	This paper presents an optimization methodology based on genetic algorithms for designing low-voltage low-power pipelined ADC’s. It is demonstrated that multi-bit rather than minimum resolution-per-stage architectures are better suited for low-voltage operation and also that, either switched-opamp or clock-boosting techniques can produce equivalent realizations in terms of power efficiency. By carefully tailoring the pipelined architecture with the proposed optimization approach it is clearly demonstrated by means of a 1.5V, 10b, 40 MS/s pipeline ADC design example that, reducing the supply voltage does not necessarily increases the used energy per conversion.	analog-to-digital converter;cmos;genetic algorithm;joule;low-power broadcasting;mathematical optimization;operational amplifier;performance per watt	Bruno Vaz;Nuno F. Paulino;João Goes;R. Costa;Romero Tavares;Adolfo Steiger-Garção	2002		10.1109/ISCAS.2002.1009992	embedded system;electronic engineering;real-time computing;genetic algorithm;electrical efficiency;computer science;engineering;electrical engineering;low voltage;low-power electronics;integrated circuit design	Arch	16.10957370687097	55.46421775737903	69891
1f7105626972067c896ef03f7335624849764c1d	current testing in dynamic cmos circuits	current testing;cmos integrated circuits;integrated circuit;test methods;test technique;dynamic cmos	Current testing of dynamic CMOS integrated circuits with single phase clock is investigated. The analysis is performed on a single phase stage dynamic module in the presence of internal bridging defects of low resistance. These defects produce intermediate voltage levels which cause difficulties to the logic testing methods based on voltage level comparison. It is shown that current testing may be an effective complement to the usual logic methods. Theoretical bounds on the coverage of single internal bridges obtainable by current testing are given.		Joan Figueras;Michel Renovell	1995	J. Electronic Testing	10.1007/BF00993135	embedded system;electronic engineering;computer science;engineering;electrical engineering;integrated circuit;integrated injection logic;test method;cmos;statistics	EDA	22.679102501100456	53.786438984647305	69926
c7b8e6d590b35c229050b8632bdbe3a093ae1b8e	aliasing reduction in accumulator-based response verification	probability;circuit faults;probability built in self test integrated circuit testing;built in self test;monitoring;compaction;adders;hardware compaction monitoring built in self test probability circuit faults adders;circuit under test aliasing reduction accumulator based response verification built in self test aliasing probability;hardware	One of the well-known problems in response verification is aliasing, i.e., the event that a series of responses containing errors results in a signature equal to that of the error-free response sequence. In this paper, we propose a scheme to reduce aliasing in accumulator-based response verification. The proposed scheme is based on monitoring the value of the carry output of the accumulator. Experimental study indicates that the proposed scheme achieves significantly less hardware overhead for the same reduction in the aliasing probability than previously proposed schemes.	accumulator (computing);aliasing;built-in self-test;carry (arithmetic);fault model;overhead (computing);whole earth 'lectronic link	Ioannis Voyiatzis	2014	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2014.2351582	compaction;embedded system;electronic engineering;real-time computing;computer science;probability;mathematics;adder;statistics	EDA	20.617110648040285	51.06768755583882	70049
6a1bec586dfe4278e0391c8cc8d1491342fa73fc	over-the-cell routers for new cell model	circuit layout cad;network routing;c;icr-2;icr-3;primary 1;sun sparcstation;benchmarks;over-the-cell routing techniques;standard cell design;three-layer;two-layer	In this paper, we present new over-the-cell routing techniques for standard cell design style. We have developed both a two-layer and a three-layer router. The key feature of our routers is use of new cell model, in which the terminals are located in the middle of the cells in the second metal layer. This model is similar to one currently being developed for three-layer cell libraries in industry. We have implemented both of our routers in C on a SUN SPARCstation 1+ and tested them with several benchmarks including PRIMARY I and PRIMARY I1 from MCNC. Both of our routers out-perform all existing routers. In addition, both ICR-2 and ICR-3 are very fast, for example, ICR-3 completes the routing of entire PRIMARY I benchmark in 5.8 secs. development in industry, and hence the ICR-3 router is suitable for industrial designs. 2 The Existing and New Cell Models In this section, we describe the differences between the existing and the new cell model and their effects on routing techniques.	benchmark (computing);cell (microprocessor);library (computing);multitier architecture;router (computing);routing;standard cell	Bo Wu;Naveed A. Sherwani;Nancy D. Holmes;Majid Sarrafzadeh	1992			policy-based routing;routing domain;embedded system;routing;enhanced interior gateway routing protocol;electronic engineering;static routing;source routing;real-time computing;simulation;telecommunications;computer science;engineering;operating system;routing protocol;computer network	Networks	14.237215228814376	52.09330082519266	70258
a3050691ddea2c9bbc6147ae6136a085dfa89a1f	an efficient logic emulation system	large digital logic designs;field programmable gate array;logic cad logic arrays;logic arrays;pins;logic design;routing;partial crossbar;interconnection architecture;architecture development;emulation;automatic logic units;digital logic;fpga utilization;architecture development logic emulation system realizer field programmable gate arrays large digital logic designs fpga utilization interconnection architecture partial crossbar system level placement routing complexity bounded interconnect delay hierarchical expansion multiboard system xilinx xc3090 fpgas cpu datapath logic verification;logic verification;xilinx xc3090 fpgas;cpu datapath;emulation field programmable gate arrays logic design integrated circuit interconnections hardware logic arrays pins logic devices automatic logic units routing;integrated circuit interconnections;bounded interconnect delay;system level placement;hierarchical expansion;field programmable gate arrays;logic emulation system;logic cad;routing complexity;logic devices;realizer;hardware;multiboard system	The Realizer, is a logic emulation system that automatically configures a network of field-programmable gate arrays (FPGAs) to implement large digital logic designs, is presented. Logic and interconnect are separated to achieve optimum FPGA utilization. Its interconnection architecture, called the partial crossbar, greatly reduces system-level placement and routing complexity, achieves bounded interconnect delay, scales linearly with pin count, and allows hierarchical expansion to systems with hundreds of thousands of FPGA devices in a fast and uniform way. An actual multiboard system has been built, using 42 Xilinx XC3090 FPGAs for logic. Several designs, including a 32-b CPU datapath, have been automatically realized and operated at speed. They demonstrate very good FPGA utilization. The Realizer has applications in logic verification and prototyping, simulation, architecture development, and special-purpose execution. >	emulator	Joseph Varghese;Michael Butts;Jon Batcheller	1993	IEEE Trans. VLSI Syst.	10.1109/92.238418	embedded system;computer architecture;electronic engineering;parallel computing;logic synthesis;logic optimization;logic gate;logic family;reconfigurable computing;computer science;pass transistor logic;field-programmable gate array	EDA	11.385064265004083	49.222580498728085	70267
49c7720e8e64038810a1da6decdf35654d94d59e	a network flow approach for hierarchical tree partitioning	integer linear programming;pins;approximate algorithm;cost function;iterative algorithms;tree data structures;linear constraint;computer networks;upper bound;objective function;graph partitioning;permission;partitioning algorithms cost function permission iterative algorithms circuits heuristic algorithms tree data structures computer networks pins upper bound;heuristic algorithms;linear program;circuits;covering problems;network flow;divide and conquer;heuristic algorithm;partitioning algorithms	Network flow approaches have been used for partitioning with successin the past. However, most of them can not deal with size constraintsdirectly in partitioning. Instead, they incorporate the sizeconstraints implicitly in the objective function. This paper presentsa new network flow approach for partitioning circuits into treehierarchies. We formulate a linear program for the hierarchicaltree partitioning problem by spreading metrics proposed in [Divide-and-conquer approximation algorithms via spreading metrics, Fast approximate graph partitioning algorithms].The size constraints in partitioning can be formulated directly aslinear constraints. Motivated by the duality between the linear programsfor partitioning and network flow problems, we devise aheuristic algorithm based on network flow and spreading metriccomputations. Experimental results demonstrate that the new algorithmcan generate better solutions for MCNC benchmarks.	approximation algorithm;flow network;graph partition;linear programming;loss function;optimization problem;partition problem	Ming-Ter Kuo;Chung-Kuan Cheng	1997		10.1145/266021.266269	heuristic;mathematical optimization;electronic circuit;divide and conquer algorithms;flow network;integer programming;covering problems;computer science;linear programming;graph partition;space partitioning;theoretical computer science;machine learning;tree;upper and lower bounds;set partitioning in hierarchical trees	EDA	15.849661555198328	51.06734711473287	70366
759eaf9c296f52d5cc90fc04b07af8d646938080	design of high speed digital circuits with e-tspc cell library	prescaler;tspc;high speed digital circuit;design method;true single phase clock;standard cell;power reduction;digital circuits;high speed	The application of a standard cells library with Extended True Single Phase Clock (E-TSPC) blocks in the design of high speed digital circuits is analyzed. The E-TSPC technique has been efficiently employed for attaining high speed in digital circuits, mainly in prescalers, but it has been usually done by applying time consuming full custom design method. In order to evaluate advantages and disadvantages of different design methods, full custom, conventional standard cells, and standard cells with E-TSPC blocks, have been applied to implement 32/33 dual-modulus prescalers in a 0.35μm CMOS technology. Simulation results of the prescalers revealed that the E-TSPC standard cell implementations have a speed decline and a power increase of less than 21% and 31%, respectively, compared with full custom implementations, but a speed improvement and power reduction of more than 168% and 51%, respectively, compared with conventional standard cells implementations.	cmos;digital electronics;full custom;modulus robot;simulation;standard cell	João Navarro;Gustavo C. Martins	2011		10.1145/2020876.2020915	embedded system;electronic engineering;design methods;computer hardware;computer science;electrical engineering;digital electronics;standard cell	EDA	16.644056759361106	57.25493966433535	70449
e546db17a8db9f44abf96a79b7e49f85c2242b0d	comparative bti reliability analysis of sram cell designs in nano-scale cmos technology	silicon;size 32 nm;8t;voltage control;cmos integrated circuits;n channel mosfet;random access memory;reliability;comparative analysis;random access memory aging transistors silicon threshold voltage reliability voltage control;leakage power sram 6t 8t 10t bias temperature instability bti effect mosfet nano scale cmos voltage scaling sram static noise margin snm write margin access time;6t;nano scale cmos;leakage power reduction;aging;static noise margin snm;static noise margin;snm;nanoscale cmos technology;sram chips cmos integrated circuits dielectric materials hafnium compounds integrated circuit reliability mosfet;hfo 2 comparative bti reliability analysis sram cell designs nanoscale cmos technology bias temperature instability high k dielectric material p channel mosfet n channel mosfet power consumption reduction static noise margin snm leakage power reduction size 32 nm voltage 0 42 v voltage 0 9 v;leakage power;bias temperature instability bti effect;threshold voltage;transistors;p channel mosfet;bias temperature instability;voltage 0 42 v;reliability analysis;dielectric materials;mosfet;sram;voltage 0 9 v;power consumption;integrated circuit reliability;hafnium compounds;voltage scaling;write margin;power consumption reduction;high k dielectric material;10t;access time;sram cell designs;hfo 2;sram chips;comparative bti reliability analysis	Bias Temperature Instability (BTI) causes significant threshold voltage shift in MOSFET using Hafnium-dioxide (HfO2) High-k dielectric material. Negative BTI and Positive BTI are two types of BTI effects observed in p-channel and n-channel MOSFET. BTI affects the stability and reliability of conventional six transistor (6T) SRAM design in nano-scale CMOS technology. Eight transistor (8T) and Ten transistor (10T) SRAM cell designs are known for their ability to operate at lower supply voltages to reduce power consumption. In this paper, we present a comparative analysis of different SRAM cell designs in terms of their reliability against BTI effects. For a fair comparison, voltage scaling is applied to the 8T and 10T cells to a level where they show same Static Noise Margin (SNM) as that of the 6T cell at nominal supply voltage. In a predictive 32 nm CMOS technology, the supply voltage of 8T and 10T cells is reduced to 0.42 V which is 54% lower than the nominal supply voltage (0.9 V), which the 6T cell is biased at. Due to lower supply voltage in 8T and 10T SRAM designs, the impact of BTI is lower and reliability is far better than the 6T SRAM design, while achieving significant leakage power reduction. Based on the simulation results, we recommend designing SRAM arrays using 8T SRAM cell or 10T SRAM cell in future nano-scale CMOS where BTI effect is a reliability barrier for SRAM design.	access time;btrieve;cmos;cell (microprocessor);dynamic voltage scaling;gnu nano;high-κ dielectric;image scaling;metal gate;negative-bias temperature instability;noise margin;qualitative comparative analysis;simulation;spectral leakage;static random-access memory;transistor	Shreyas Kumar Krishnappa;Hamid Mahmoodi	2011	2011 12th International Symposium on Quality Electronic Design	10.1109/ISQED.2011.5770755	qualitative comparative analysis;electronic engineering;real-time computing;static random-access memory;access time;computer science;engineering;electrical engineering;operating system;reliability;silicon;threshold voltage;cmos;transistor;dielectric	EDA	19.209916468215386	59.322392447028406	70511
b8bf07a6e90fd93545b2cebcda2a81a81596f1ce	concurrent wire spreading, widening, and filling	open space;automated design;automated design tools;filling algorithms design performance experimentation manufacturing defect limited yield wire spreading wire widening;performance;wires concurrent engineering;defect limited yield;concurrent wire spreading;wires;filling;wire spreading;random defect;wire widening;wire filling;design rules;wire filling routing algorithm design and analysis integrated circuit synthesis switches manufacturing permission space technology silicon;metal density uniformity;metal density uniformity concurrent wire spreading wire widening wire filling automated design tools random defect induced interruptions yield loss random defect routing metal layers;manufacturing;yield loss;algorithms;design;routing metal layers;experimentation;concurrent engineering;random defect induced interruptions	"""Automated design tools produce layouts complying with all design rules (DRs). However, most wires are designed with minimum width, making them susceptible to random defect induced interruptions (opens). Spaces between wires are also often designed at minimum size, causing yield loss from random defect induced connections (shorts). SFF (""""Spread - Fatten - Fill"""") is a methodology to improve layout - specifically for routing metal layers - in terms of yield loss related to opens and shorts. Additionally, a novel fill concept improves metal density uniformity. In this paper, we will explain issues that were observed and addressed in the implementation on a real layout, and present results achieved in the first experiment on silicon."""	approximation algorithm;circuit complexity;clock network;design for manufacturability;electronic design automation;embedded system;international conference on computer-aided design;jog dial;liang-jie zhang;local optimum;routing;software bug;spaces;wiring;yang	Olivier Rizzo;Hanno Melzner	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278569	structural engineering;design;electronic engineering;performance;engineering;manufacturing;engineering drawing;concurrent engineering	EDA	15.31174952749448	51.89579764134349	70569
abf5561221d9d375deb5a6afc0980905cdf164ec	a leakage current suppression technique for cascade sram array in 55 nm cmos technology	sram array standby leakage inactive mode low leakage spice	Sub-threshold leakage is a major issue for low power circuits design, especially for SRAM design in SoC. Sub-threshold leakage can be decreased by scaling down supply voltage. However, this may dramatically increase the circuit delay. In this paper, we propose a novel 6 T SRAM array structure with a switch module which operates in the near threshold region to reduce the leakage current. In order to verify our proposed leakage reduction scheme, we designed and simulated an 8192 kB SRAM array based on a 16 KB single port SRAM cell memory model in 55 nm process. Several 6 T SRAM Array instances are implemented in 55-nm 1P6M CMOS technology to measure the standby current of the proposed scheme as well. With the proposed technique, we achieved 28.3% reduction for leakage current compared to traditional 6 T SRAM array, in standby mode where gate leakage is dominant. The total penalty is 2% area increase and 1% speed reduction.	cmos;cell (microprocessor);embedded system;image scaling;spice 2;simulation;sleep mode;spectral leakage;static random-access memory;system on a chip;writing commons;zero suppression	Hongming Chen;Yuhua Cheng	2014	Science China Information Sciences	10.1007/s11432-014-5060-5	embedded system;real-time computing;computer science	EDA	17.603774153991665	58.49445784866186	70594
13c97aeb6563a0eeb64e1cb5cd516699fcd06170	minimum implant area-aware placement and threshold voltage refinement	milp implant area aware placement threshold voltage refinement leakage power consumption integrated circuit design minia mixed integer linear programming;low power electronics integer programming integrated circuit design linear programming;standards;layout;threshold voltage;implants threshold voltage standards timing integrated circuits computer science layout;implants;computer science;integrated circuits;timing	Threshold voltage assignment is a very effective technique to reduce leakage power consumption in modern integrated circuit design. As feature size continues to decrease, the layout constraints [called minimum implant area (MinIA) constraints] on the implant area, which determines the threshold voltage of a device, are becoming increasingly difficult to satisfy. It is necessary to take these constraints into consideration during the placement stage. In this paper, we propose to resolve the MinIA constraint violations of a given placement by performing simultaneous detailed placement and threshold voltage refinement. We first present an optimal and efficient mixed integer-linear programming (MILP)-based algorithm to handle intrarow MinIA constraints. We then extend the MILP-based algorithm to handle both inter-row and intrarow MinIA constraints. Both of our algorithms guarantee to fix all MinIA constraint violations. Experimental results demonstrate that our algorithms only perturb the original placement and threshold voltage assignment solutions minimally to eliminate all violations and are fast in practice.	algorithm;displacement mapping;integer programming;integrated circuit design;linear programming;overhead (computing);perturbation theory;refinement (computing);spectral leakage;star filler	Wai-Kei Mak;Wan-Sin Kuo;Shi-Han Zhang;Seong-I Lei;Chris C. N. Chu	2016	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/ASPDAC.2016.7428010	layout;electronic engineering;real-time computing;computer science;threshold voltage;engineering drawing	EDA	15.770706465983254	53.697011787282044	70669
8464d7aae73461d5cd2e20be2e126ecad0e06d6d	versatile framework for power delivery exploration		Over the past decades, aggressive voltage scaling combined with increased power demands has placed stringent requirements on on-chip power quality. Unwanted voltage fluctuations and droops may cause a variety of issues, ranging from glitch power to device malfunction. If revealed at the later stages of the design process, mitigation techniques may become unbearably costly in both time and money. A framework for exploratory power delivery optimization is described to enhance the power delivery network during early stages of the design process in accordance with design specifications. The power delivery design process is converted into a constrained minimization problem, consisting of design metrics combined into objective and constraint functions. The framework supports the optimization of the power network characteristics while considering external, non-electrical design specifications, such as cost and area, providing a comprehensive network analysis capability. In one case study, a 15% reduction in decoupling capacitor placement along with a 38.6% reduction in power consumption is achieved while satisfying performance and power quality constraints.	circuit topology;coupling (computer programming);dynamic voltage scaling;electric power quality;estimation theory;glitch;image scaling;mathematical optimization;quantum fluctuation;requirement;simulation;social network analysis	Rassul Bairamkulov;Kan Xu;Eby G. Friedman;Mikhail Popovich;Juan Ochoa;Vaishnav Srinivas	2018	2018 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2018.8351478	system on a chip;network analysis;capacitor;decoupling capacitor;engineering design process;electronic engineering;glitch;ranging;computer science;design process;control engineering	EDA	20.98699870316006	57.31150580098529	70778
39faa21eabb61b5417a50aa6a077a115fa173232	improved technology mapping using a new approach to boolean matching	circuit optimisation boolean functions combinational circuits probability logic cad;probability;boolean functions;boolean matching;boolean function;combinational circuits technology mapping boolean matching obdds specific probability values library cells iscas85 benchmark circuits logic synthesis computer aided synthesis;specific probability values;boolean functions logic circuits libraries circuit synthesis data structures space technology laboratories instruments logic design equations;obdds;library cells;computer aided synthesis;logic synthesis;iscas85 benchmark circuits;technology mapping;circuit optimisation;combinational circuit;logic cad;combinational circuits	We present an improved method for technology mapping using a new approach to the Boolean matching problem. Signatures computed over OBDDs using a set of specific probability values determine matches between library cells and portions of the netlist. Unlike some previous methods, which may require creation of up to O(n!) OBDDs for all possible permutations of module's inputs, our method requires exactly one OBDD to be created for the portion of the netlist being matched. Some results obtained on ISCAS85 benchmark circuits suggest the viability and validity of our approach.	benchmark (computing);binary decision diagram;electronic signature;netlist	B. Kapoor	1995		10.1109/EDTC.1995.470415	discrete mathematics;theoretical computer science;mathematics;algorithm	EDA	18.21474198418808	47.23848795353778	70997
ddb20a65952d1b8c78ec558b7dcc397327f95865	block-oriented random access mnos memory	data access;cost effectiveness;random access	MNOS storage elements have been used to realize a block-oriented all electronic secondary memory module. This nonvolatile storage unit offers 10-microsecond data access and reliable error free operation. BORAM modules provide an immediately available cost effective alternative to electromechanical storage in severe environment applications. The text below describes an 18-million-bit advanced development model of a BORAM module and briefly outlines the growth potential of MNOS BORAM systems.	access time;auxiliary memory;data access;mnos;memory module;random access;random-access memory;requirement;rugged computer	J. E. Brewer;D. R. Hadden	1974		10.1145/1500175.1500331	electronic engineering;computer hardware;computer science;database	OS	12.66234953246001	59.23285307899904	71035
3e3b2fa827fd070cf4e733d19a82bf4e9c35f266	a fast dynamic 64-bit comparator with small transistor count		In this paper, we propose a 64-bit fast dynamic CMOS comparator with small transistor count. Major features of the proposed comparator are the rearrangement and re-ordering of transistors in the evaluation block of a dynamic cell, and the insertion of a weak n feedback inverter, which helps the pull-down operation to ground. The simulation results given by pre-layout tools, e.g. HSPICE, and post-layout tools, e.g. TimeMill, reveal that the delay is around 2.5 ns while the operating clock rate reaches 100 MHz. A physical chip is fabricated to verify the correctness of our design by using UMC (United Microelectronics Company) 0.5 μm (2P2M) technology.	64-bit computing;comparator;transistor count	Chua-Chin Wang;Ya-Hsin Hsueh;Hsin-Long Wu;Chih-Feng Wu	2002	VLSI Design	10.1080/10655140290011204	embedded system;electronic engineering;computer hardware;computer science;electrical engineering;comparator applications	EDA	17.07641838584742	58.036705276150535	71073
c1bdd0bb36629b6ce6014644a319d08dd0f4611b	stop & go bist	thermal constraints;bist;automatic test pattern generation built in self test microprocessor chips cooling integrated circuit testing;automatic test pattern generation;ip cores;built in self test circuit testing circuit faults delay integrated circuit testing application software clocks thermal force automatic testing energy consumption;built in self test;heat dissipation two pattern testing at speed bist method cool down periods scalable architecture ip cores delay testing stop go bist idle clock cycles;delay testing;integrated circuit testing;cooling;microprocessor chips	A BIST method enabling two-pattern testing at-speed without violating thermal constraints by introducing cool down periods is proposed. The application of the method is demonstrated based on a scalable BIST architecture. Applicability on IP cores is given since only a two-pattern tes t set is required as input.	built-in self-test;scalability	Ilia Polian;Bernd Becker	2002		10.1109/OLT.2002.1030198	embedded system;electronic engineering;real-time computing;engineering;automatic test pattern generation	EDA	20.447220299731924	53.934892042452255	71157
3b406813e2711dd4b20eb6fea1742932dce758d4	asynchronous ripple carry adder based on area optimized early output dual-bit full adder		This technical note presents the design of a new area optimized asynchronous early output dual-bit full adder (DBFA). An asynchronous ripple carry adder (RCA) is constructed based on the new asynchronous DBFAs and existing asynchronous early output single-bit full adders (SBFAs). The asynchronous DBFAs and SBFAs incorporate redundant logic and are encoded using the delay-insensitive dual-rail code (i.e. homogeneous data encoding) and follow a 4-phase return-to-zero handshaking. Compared to the previous asynchronous RCAs involving DBFAs and SBFAs, which are based on homogeneous or heterogeneous delay-insensitive data encodings and which correspond to different timing models, the early output asynchronous RCA incorporating the proposed DBFAs and/or SBFAs is found to result in reduced area for the dual-operand addition operation and feature significantly less latency than the asynchronous RCAs which consist of only SBFAs. The proposed asynchronous DBFA requires 28.6% less silicon than the previously reported asynchronous DBFA. For a 32-bit asynchronous RCA, utilizing 2 stages of SBFAs in the least significant positions and 15 stages of DBFAs in the more significant positions leads to optimization in the latency. The new early output 32-bit asynchronous RCA containing DBFAs and SBFAs reports the following optimizations in design metrics over its counterparts: i) 18.8% reduction in area than a previously reported 32-bit early output asynchronous RCA which also has 15 stages of DBFAs and 2 stages of SBFAs, ii) 29.4% reduction in latency than a 32-bit early output asynchronous RCA containing only SBFAs.	32-bit;adder (electronics);asynchronous circuit;cpu power dissipation;circuit design;code;delay insensitive circuit;digital signal processing;handshaking;mathematical optimization;nx bit;operand;ripple effect	P. Balasubramanian	2018	CoRR		latency (engineering);computer science;handshaking;parallel computing;real-time computing;homogeneous;asynchronous communication;adder	EDA	13.461281851532686	46.465377444206844	71313
0448e2b1a71e0f62051c7e37c65ebe22e3e4a2fb	simultaneous circuit transformation and routing	decision diagrams;implication flow graph simultaneous circuit transformation routing symbolic representation wire reconnection logic representation global flow optimization techniques;integrated circuit;integrated circuit layout;optimization technique;routing;routing wire flow graphs integrated circuit interconnections optimization methods phase estimation electrical capacitance tomography logic design circuit synthesis data analysis;global flow optimization;flow graphs;network routing;high level synthesis;logic synthesis;circuit cad network routing integrated circuit layout circuit layout cad flow graphs decision diagrams high level synthesis circuit optimisation;optimal routing;routing algorithm;circuit layout cad;circuit cad;circuit optimisation	In this paper, we propose a new methodology to integrate circuit transformation into routing. More specifically, this paper shows an approach for performing routing and wire reconnection simultaneously. To accomplish this, we introduce a new logic representation that implements all possible wire reconnections implicitly by enhancing global flow optimization techniques. Since our method takes into account circuit transformation during routing phase where the accurate physical information is available, we can obtain better results than the conventional routing algorithms. In addition, we can succeed in routing even if other routers like rip-up and reroute methods fail. The algorithm has been implemented and the experimental results are presented. We believe this is the first approach which combines them completely.	algorithm;mathematical optimization;physical information;routing	Hiroaki Yoshida;Motohiro Sera;Masao Kubo;Masahiro Fujita	2002		10.1109/ASPDAC.2002.994966	routing table;routing domain;embedded system;routing;electronic engineering;static routing;dsrflow;equal-cost multi-path routing;computer science;dynamic source routing;theoretical computer science;multipath routing;destination-sequenced distance vector routing;routing protocol;link-state routing protocol;triangular routing;path vector protocol;engineering drawing;geographic routing;routing;computer network	EDA	15.5787044183554	50.88851255220928	71334
d5801834fbc595c5816f96ac113880bedb909218	automatic synthesis of dut board circuits for testing of mixed signal ics	circuit testing circuit synthesis signal synthesis automatic testing system testing integrated circuit testing signal design libraries relays rivers;automatic test equipment;integrated circuit testing;mixed analogue digital integrated circuits;ates dut board circuits mixed signal ics product delivery cycle mixed signal tester test information final load board circuitry;mixed analogue digital integrated circuits automatic test equipment integrated circuit testing	Test development is without doubt the major bottleneck in the product delivery cycle of mixed signal ICs. One of the most time consuming tasks during the test development phase is the design of the DUT board where the IC is to be inserted to run on a mixed signal tester. This paper describes a new methodology of capturing test information for an IC through test module schematics and then using an automatic tool to synthesize the final load board circuitry to be used on mixed signal ATEs.<<ETX>>	dut board;electronic circuit;mixed-signal integrated circuit;schematic	William H. Kao;Jean Qincui Xia	1993	Digest of Papers Eleventh Annual 1993 IEEE VLSI Test Symposium	10.1109/VTEST.1993.313319	embedded system;automatic test equipment;electronic engineering;computer science;engineering;computer engineering	EDA	10.734478315160139	52.1240995617201	71658
2ad6345ee75d5c7f84bec9af77d9cc4257dda346	temperature and data size trade-off in dictionary based test data compression	dictionary based coding;don t care filling;test compression;peak temperature reduction	This paper proposes a new thermal-aware test data compression technique using dictionary-based coding. Large test data volume and rise in chip temperature during a test, are the two major challenges for the test engineers. Efficient filling of the don't care bits of the test patterns minimises the transition count in the scan chains, which in turn reduces the temperature of the chip to a large extent. On the other hand, high test data compression can be achieved by filling the don't-cares in a manner to get more similar sub-vectors within the test vectors. Although, both the problems rely on don't-care bit filling, most of the existing works have considered them separately. Moreover, it has been observed that, in general, thermal-aware don't-care filling leads to poor test compression, while a compression-aware don't-care filling produces high temperature. However, a high test compression with low-temperature is the most desirable expectation. In our work, we have combined the temperature reduction and the test data compression into a single problem and solved it. We have presented an integrated approach that can perform a trade-off between temperature and test compression. Experimental results on ISCAS'89, ITC'99 and IWLS'05 benchmarks show the flexibility of the proposed method to achieve a balance between temperature and test compression. The work has further been extended to reduce temperature without sacrificing compression.	best, worst and average case;binary space partitioning;data compression;data dictionary;don't-care term;mathematical optimization;test card;test compression;test data;test engineer	Rajit Karmakar;Santanu Chattopadhyay	2017	Integration	10.1016/j.vlsi.2016.11.002	data compression ratio;electronic engineering;simulation;image compression;engineering;test compression;engineering drawing	ML	20.343800230605833	53.902240477770405	71892
2ca27bfcc2e98ee6482d9a1e639e7f5242a0b1f4	the amulet chips: architectural development for asynchronous microprocessors	random access memory;low energy;logic design;energy demand;clocks;microprocessors clocks pipeline processing synchronization circuits computer architecture silicon read only memory manufacturing computer science;clock signal amulet chips architectural development asynchronous microprocessors arm architecture university of manchester asynchronous logic self timed processor system on chip synchronous systems amulet1 3 embedded applications wide spectrum electromagnetic emission wireless applications voltage variation energy demands power supply conventional tool flows architectural features amulet series register forwarding cache line fetching nonlocal synchronisation;spectrum;synchronous system;power supply;chip;asynchronous system;system recovery;system on chip;registers;synchronization;system on chip asynchronous circuits logic design microprocessor chips;pipelines;asynchronous circuits;pipeline processing;energy saving;microprocessor chips	During the 1990s a series of asynchronous microprocessors based on the ARM architecture was developed at the University of Manchester. The objective was to demonstrate that it was feasible to implement a commercial architecture with asynchronous logic and that certain advantages could be gained from a self-timed processor. By carrying these designs through to silicon it was demonstrated that processors, caches and whole systems-on-chip could be built without clocks and could perform competitively with ‘conventional’, synchronous systems.	amulet microprocessor;arm architecture;asynchronous circuit;cpu cache;central processing unit;system on a chip	Jim D. Garside;Stephen B. Furber;Steve Temple;Viv Woods	2009	2009 16th IEEE International Conference on Electronics, Circuits and Systems - (ICECS 2009)	10.1109/ICECS.2009.5411006	embedded system;electronic engineering;real-time computing;computer science	EDA	14.067583425112757	58.14497922500128	72024
70ed094cf1aded948ea40a0d636e5c0f73aa3852	multiple-valued logic gates using asymmetric single-electron transistors	low power dissipation multiple valued logic gates asymmetric single electron transistors tunneling junctions coulomb staircase characteristics set arbitrary radix 4 literal gate mv analog digital conversion circuits;tunnelling analogue digital conversion logic gates low power electronics multivalued logic circuits single electron transistors;asymmetric single electron transistors;multivalued logic circuits;analog digital conversion;multiple valued logic single electron transistor asymmetric literal gate;single electron transistors;logic circuits;inverters;mv analog digital conversion circuits;junctions;multiple valued logic gates;arbitrary radix 4 literal gate;tunnelling;low power;coulomb staircase characteristics;logic gates;tunneling junctions;low power dissipation;semiconductor device modeling;cmos logic circuits;analogue digital conversion;single electron transistor;power dissipation;voltage;equivalent circuits;literal gate;low power electronics;diodes;logic gates single electron transistors tunneling capacitance cmos logic circuits voltage equivalent circuits diodes power dissipation logic circuits;capacitance;temperature;asymmetric;multiple valued;set;logic gate;tunneling;multiple valued logic	This paper proposes novel multiple-valued (MV) logic gates by using asymmetric single-electron transistors (SETs). Asymmetric single-electron transistors have two tunneling junctions with largely different resistances and capacitances. We fully exploited the unique Coulomb staircase characteristic of asymmetric SETs to compactly finish logic operations. We build MV literal gates with wide range of radixes by using a pair of asymmetric SETs. We showed that, arbitrary radix-4 literal gate can be realized using a pair of asymmetric SETs. We also proposed MV analog-digital conversion circuits. The MV logic gates have very compact structures and low power dissipation.	analog-to-digital converter;electron;integrated circuit;literal (computer programming);literal (mathematical logic);logic gate;one-electron universe;transistor;tunneling protocol	Wancheng Zhang;Nan-Jian Wu;Tamotsu Hashizume;Seiya Kasai	2009	2009 39th International Symposium on Multiple-Valued Logic	10.1109/ISMVL.2009.13	and-or-invert;electronic engineering;nmos logic;logic gate;three-input universal logic gate;electrical engineering;pass transistor logic;mathematics;algorithm;quantum mechanics	Arch	15.995876920791302	58.39876168834323	72093
87b9896f8dc93d7cfbfc7af222d58402c9f5d1eb	a 128 kb hfo2 reram with novel double-reference and dynamic-tracking scheme for write yield improvement	dynamic read;dynamic tracking;double reference;reram	A 128Kb HfO2 Resistive Random Access Memory (ReRAM) chip is developed based on HHNEC 0.13 μm 1P8M CMOS process. ReRAM is suffering the write yield problem due to the tail-bit issues and large resistance variations at high temperature. In this paper a novel DoubleReference and Dynamic-Tracking Write (DR-DTW) scheme and a Dynamic read scheme are proposed to fix these issues. The experiment results show that the tail-bit issues are almost eliminated and the write yield is improved greatly compared with traditional write scheme.	cmos;lattice problem;random access;resistive random-access memory;voltage reference;web server	Cheng-Ying Chen;Hongbin Sun;Haihua Shen;Feng Zhang	2016	IEICE Electronic Express	10.1587/elex.13.20160061	electronic engineering;parallel computing;resistive random-access memory;computer hardware	EDA	17.214677047657737	60.19294164273253	72137
07149d507da56de402724f967f60050c8e1683bd	multifrequency tam design for hierarchical socs	hierarchical system;test access mechanism;automatic test pattern generation;automatic test equipment;mega cores;indexing terms;system on a chip;chip;electronic test;system on chip;automatic test equipment system on chip integrated circuit testing automatic test pattern generation;integrated circuit testing;system on a chip system testing space exploration electronic equipment testing automatic testing automation transportation frequency conversion benchmark testing algorithm design and analysis;test access mechanism electronic test mega cores system on a chip;test access mechanism multifrequency tam design system on a chip electronic test automation test access mechanisms hierarchical soc testing test data transportation frequency converters tam design algorithms	The emergence of megacores in hierarchical system-on-a-chip (SOC) presents new challenges to electronic test automation. This paper describes a new framework for designing test access mechanisms (TAMs) for modular testing of hierarchical SOCs. We first explore the concept that TAMs on the same level of design hierarchy employ multiple frequencies for test data transportation. Then we extend this concept to hierarchical SOCs and, by introducing frequency converters at the inputs and outputs of the megacores, the proposed solution not only removes the constraint that the system level TAM width must be wider than the internal TAM width of the megacores, but also facilitates rapid exploration of the tradeoffs between the test application time and the required test area. Experimental results for the ITC'02 SOC Test Benchmarks show that the proposed TAM design algorithms increase the size of the solution space that is explored, which, in turn, will lower the test application time when compared to the existing solutions.	algorithm;design space exploration;emergence;feasible region;frequency changer;ibm tivoli access manager;overhead (computing);system on a chip;systems integrator;test automation;test data	Qiang Xu;Nicola Nicolici	2006	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2005.852440	system on a chip;embedded system;automatic test equipment;electronic engineering;real-time computing;computer science;engineering;automatic test pattern generation;operating system;design for testing;test harness	EDA	11.476456891452129	53.934478500063754	72269
9b6f319a22f89e6e38dc5b919daeacb9e8e1f099	efficient test and repair architectures for 3d tsv-based random access memories	random access memory;three dimensional integrated circuits integrated circuit testing redundancy semiconductor storage sram chips stacking;circuit faults;matching algorithm 3d tsv based random access memories 3d ic repair architecture 3d ic test architecture stacked memory dies processor die known good die test kgd test known good stack test kgs test small size redundant memory faulty cells repair bist modules bira modules redundancy analysis die stacking yield management 1149 1 based test interface test pads;maintenance engineering;stacking redundancy maintenance engineering three dimensional displays built in self test circuit faults random access memory;built in self test;redundancy;stacking;three dimensional displays	In this paper, we propose a test and repair architecture for 3D ICs consisting of stacked memory dies (slave dies) and a processor die (master die). The proposed architecture supports known-good-die (KGD) test, known-good-stack (KGS) test, and final test and repair. However, instead of incorporating spare elements in each memory die, a small-size redundant memory is incorporated into the processor die. That is, the added redundancy can be used globally for repairing faulty cells among all other stacked memory dies. Each slave die contains the BIST and BIRA modules for performing KGD and KGS tests and redundancy analysis. The results of redundancy analysis then can be used for die stacking, yield management, and BISR (built-in self-repair) after the final test. An 1149.1-based test interface is added for each slave die and only four test pads are required for test and repair purposes. Based on the results of the BIRA module, a simple matching algorithm is proposed to increase the stacking yield. According to experimental results, the hardware overhead for an 8K × 32-bit SRAM is only 2.6%. Moreover, the stacking yield can be improved significantly.	32-bit;8k resolution;access time;algorithm;built-in self-test;die (integrated circuit);electronic circuit;focus stacking;heuristic;kgs go server;overhead (computing);random access;static random-access memory;test case;through-silicon via	Shyue-Kung Lu;Uang-Chang Lu;Seng-Wen Pong;Hao-Cheng Cheng	2013	2013 International Symposium onVLSI Design, Automation, and Test (VLSI-DAT)	10.1109/VLDI-DAT.2013.6533889	embedded system;electronic engineering;engineering;test compression;engineering drawing	EDA	20.62339981698045	52.170362199353875	72448
c15bb68fa2596b105faa8909b53150760604cae9	defect tolerance for molecular electronics-based nanofabrics using built-in self-test procedure	fault diagnosis nanoelectronics molecular electronics built in self test automatic test pattern generation integrated circuit testing logic testing integrated circuit reliability fault tolerance;fault tolerant;automatic test pattern generation;defect density;built in self test;fault tolerance;nanoelectronics;logic testing;integrated circuit testing;nanofabric diagnosis defect tolerance molecular electronics based nanofabrics built in self test procedure test pattern generator response analyzer high defect density diagnostic procedure defect database;test pattern generator;defect tolerance;integrated circuit reliability;molecular electronics;fault diagnosis;built in self test testing reconfigurable logic circuit faults switches field programmable gate arrays fault tolerance nanoscale devices logic devices manufacturing	A BIST procedure is proposed for testing and fault tolerance of molecular electronics-based nanofabrics. The nanofabrics are assumed to include up to 10/sup 10/ gates: this requires new test strategies that can efficiently test and diagnose the nanofabric in a reasonable time. Our BIST procedure utilizes nanofabric's components as test pattern generator and response analyzer. The proposed technique tests the components in parallel with a low number of test configurations reducing the test time significantly. Due to high defect density of nanofabrics, a diagnostic procedure needs to be done to achieve a high recovery. A defect database is created to be used by compilers during configuring the nanofabric to avoid defective components. This results in a reliable system constructed using unreliable components.	built-in self-test;compiler;fault tolerance;residential gateway;series and parallel circuits;software bug;test card	Mark Mohammad Tehranipoor	2005	20th IEEE International Symposium on Defect and Fault Tolerance in VLSI Systems (DFT'05)	10.1109/DFTVS.2005.27	reliability engineering;fault tolerance;electronic engineering;computer science;engineering;nanotechnology;computer engineering	EDA	22.234643595539293	51.964184764637245	72555
598028651eed2ccbd73929c21fffb65dc0e177b8	a systems theoretic approach to behavioural modeling and simulation of analog functional blocks	systems theoretic approach;nonlinear functional block;electrical signal;complex analog module;analog functional block;practical circuit simulation;behavioral level;efficiency problem;frequent accuracy;analog simulation methodology;new approach;electrical signals;analog circuits;hardware description languages;computational modeling;system theory;switches;algebra;modeling and simulation;computer science;computer simulation	Analog simulation methodologies for the generation of macromodels of analog functional blocks, as reported in literature, are of limited use in practical circuit simulation due to frequent accuracy and efficiency problems. In this paper, a new approach to model the behavior of nonlinear functional blocks is proposed. The approach is based upon the principles of systems theory. The outlined methodology supports the mapping of models from component into behavioral level. The nonlinearity of complex analog modules is reflected efficiently while the electrical signals are maintained.	electronic circuit simulation;nonlinear system;systems theory	Ralf Rosenberger;Sorin A. Huss	1998			equivalent circuit;mixed-signal integrated circuit;control engineering;electronic engineering;computer science;theoretical computer science;circuit design;modeling and simulation;hardware description language;circuit extraction;electronic circuit simulation;systems theory	EDA	21.305521323992842	46.390346543417174	72598
a9771a3b3e74822b1672cbdf5edd2a0b7d4ff0f3	fast identification of robust dependent path delay faults	circuit faults;computer aided manufacturing;logic testing;path delay fault;robustness;circuit testing;computer science;digital circuits;fault diagnosis robustness delay circuit testing circuit faults timing logic testing computer science computer aided manufacturing digital circuits;fault diagnosis;timing	Recently, it has been shown in [1] and [2] that in order to verify the correct timing of a manufactured circuit not all of its paths need to be considered for delay testing. In this paper, a theory is developed which puts the work of these papers into a common framework, thus allowing for a better understanding of their relation. In addition, we consider the computational problem of identifying large sets of such not-necessary-to-test paths. Since the approach of [1] can only be applied for small scale circuits, we develop a new algorithm which trades quality of the result against computation time, and allows handling of large circuits with tens of millions of paths. Experimental results show that enormous improvements in running time are only paid for by a small decrease in quality.	algorithm;computation;computational problem;time complexity	Uwe Sparmann;D. Luxenburger;Kwang-Ting Cheng;Sudhakar M. Reddy	1995	32nd Design Automation Conference	10.1145/217474.217517	electronic engineering;real-time computing;delay calculation;computer science;electrical engineering;distributed computing;programming language;digital electronics;robustness;computer-aided manufacturing	EDA	21.263983866401386	51.60474326959458	72976
de83baf3f671ba6ee9d49fe7972f498d98de5f6f	novel architecture for on-chip ac characterization of i/os	system on chip automatic test pattern generation built in self test delays integrated circuit testing nanotechnology;automatic test pattern generation;nanotechnology;chip;built in self test;system on chip;propagation delay;duty cycle;integrated circuit testing;opcodes on chip ac characterization nanometer technologies i o timing parameters testing process complexities stiobisc propagation delay voltage rise times voltage fall times maximum operating frequency duty cycle variation on chip testing;circuit testing delay costs automatic testing semiconductor device measurement debugging silicon threshold voltage performance evaluation microelectronics;delays	In nanometer technologies, the testing of I/O timing parameters is becoming more difficult and critical due to process complexities, thereby requiring the use of increasingly expensive test equipment and test time. To analyze the impact of process spread and to minimize the cost involved in characterization of I/O pin AC parameters, we present a comprehensive test system -STIOBISC- for on-chip measurement of I/O pin AC parameters such as propagation delay, voltage rise/fall times and maximum operating frequency with corresponding duty cycle variation. The proposed design gives the test engineer freedom to do complete testing on-chip on a large number of samples, with few opcodes using an inexpensive tester in a much shorter duration	algorithm;anurag kumar;built-in test equipment;clock rate;duty cycle;embedded system;input/output;opcode;propagation delay;software propagation;system on a chip;test engineer	N. Vijayaraghavan;Balwant Singh;Saurabh Singh;Vishal Srivastava	2006	2006 IEEE International Test Conference	10.1109/TEST.2006.297697	chip;system on a chip;embedded system;propagation delay;electronic engineering;real-time computing;telecommunications;computer science;engineering;electrical engineering;automatic test pattern generation;duty cycle;computer network	EDA	21.434795386143392	55.7550113433116	73008
59d963db80a951ed157563f6b986fd62637b6e46	novel approaches for fault detection in two-dimensional combinational arrays	observability;logic arrays;two dimensions;cellular arrays;fault detection;logic testing;2d combinational arrays fault detection constant testability orthogonal arrays two dimensional arrays combinational cells testability condition co testability observability maximum minimum comparison;fault detection fault tolerant systems very large scale integration;cellular arrays combinational circuits logic arrays observability logic testing fault diagnosis;fault diagnosis;combinational circuits	This paper presents new approaches for the constant (C)-testability of orthogonal (two-dimensional) arrays of combinational cells. A novel testability condition referred to as CO-testability is introduced: a testing approach for CO-testability is fully characterized based on adding states to the table of a cell. A second approach is also proposed. this approach is based on adding a variable number of additional states to a cell with a known table. This approach requires at most (m+k+/spl alpha/)(n+k+/spl alpha/)( m/k+1)(n/k+1) tests, where m and n are the number of states in the two dimensions of signal flow, /spl alpha/=1(0) if (partial) fail observability is applicable to the state table and k is the variable number of additional states per direction (2/spl les/k/spl les/m.n). As an example, the proposed approaches have been applied to a two-dimensional array for maximum/minimum comparison.	combinational logic	Xiao-Tao Chen;Wei-Kang Huang;Nohpill Park;Fred J. Meyer;Fabrizio Lombardi	2001		10.1109/DFTVS.2001.966765	electronic engineering;two-dimensional space;observability;computer science;theoretical computer science;mathematics;combinational logic;fault detection and isolation;algorithm	EDA	22.497982059611985	49.04616601404166	73104
111214a134ab408cf2c4eebd716af662772ac055	incorporating timing constraints in the efficient memory model for symbolic ternary simulation	timing circuit simulation computational modeling computer simulation delay effects computer science time factors wire digital circuits hazards;behavior modeling;setup time;formal verification;delays logic cad formal verification timing;logic cad;timing parameters timing constraints symbolic ternary simulation memory model setup time hold time minimum delay maximum delay behavioral model;delays;timing;memory model;time constraint	This paper introduces the four timing constraints of setup time, hold time, minimum delay, and maximum delay in the Efficient Memory Model (EMM). The EMM is a behavioral model, where the number of symbolic variables used to characterize the initial state of the memory is proportional to the number of distinct symbolic memory locations accessed. The behavioral model provides a conservative approximation of the replaced memory array, while allowing the address and control inputs of the memory to accept symbolic ternary values. If a circuit has been formally verified with the behavioral model, the system is guaranteed to function correctly with any memory implementation whose timing parameters are bounded by the ones used in the verification.	approximation;behavioral modeling;flip-flop (electronics);formal verification;memory model (programming);simulation	Miroslav N. Velev;Randal E. Bryant	1998		10.1109/ICCD.1998.727081	behavioral modeling;memory model;real-time computing;simulation;delay calculation;formal verification;computer science;theoretical computer science;programming language;static timing analysis;symbolic trajectory evaluation	EDA	18.501144941087627	50.293335248099694	73129
87d5f14fdbf911ff6be4f52c63e276e61f223d47	a unified framework for generating all propagation functions for logic errors and events	verification;boolean difference function;propagation functions;logic simulation;circuit faults;boolean functions;iscas 85 benchmark;event propagation;automatic test pattern generation;sequential circuits;unified framework;testing;timing verification;boolean functions sequential circuits combinational circuits logic testing logic simulation automatic test pattern generation binary decision diagrams;boolean expression diagrams;automatic test pattern generation circuit faults data structures boolean functions circuit testing logic testing combinational circuits timing fault detection computer errors;binary decision diagrams;timing analysis unified framework propagation functions logic errors logic events boolean difference function combinational circuit logic defect testing event propagation timing verification function representation environments binary decision diagrams boolean expression diagrams boolean networks iscas 85 benchmark iscas 89 benchmarks automatic test pattern generation delay testing;iscas 89 benchmarks;logic defect testing;boolean networks;function representation environments;delay testing;data structures;function representation;boolean network;fault detection;logic testing;timing analysis;generating function;circuit testing;combinational circuit;automatic test pattern generator;computer errors;logic errors;combinational circuits;logic events;binary decision diagram;timing;atpg	We present a generic framework that supports efficient generation of the traditional Boolean difference function of some output with respect to any line in a combinational circuit, which is important when testing for logic defects. The framework also allows for the generation of generalized Boolean difference functions, which reflect sensitivity on event propagation from a given line to some circuit output. This generalized function could apply in timing verification, analysis, and test. We implemented the proposed framework using various function representation environments, including binary decision diagrams, Boolean expression diagrams, and Boolean networks, and report experimental results on the ISCAS'85 and ISCAS'89 benchmarks.	binary decision diagram;boolean expression;boolean network;boolean satisfiability problem;central processing unit;combinational logic;function representation;line level;logic error;logic gate;propagation of uncertainty;requirement;software propagation;static timing analysis;unified framework	Maria K. Michael;Themistoklis Haniotakis;Spyros Tragoudas	2004	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2004.828112	boolean algebra;boolean circuit;and-inverter graph;circuit minimization for boolean functions;discrete mathematics;boolean network;boolean domain;majority function;data structure;boolean expression;standard boolean model;computer science;maximum satisfiability problem;theoretical computer science;automatic test pattern generation;mathematics;combinational logic;boolean function;boolean satisfiability problem;algorithm	EDA	19.945874664842336	48.9359544399102	73269
6dc2ce4f4695c9509728c03f3d01d272b390205d	power and thermal effects of sram vs. latch-mux design styles and clock gating choices	clocks sram chips circuit simulation thermal management packaging flip flops multiplexing equipment integrated circuit design low power electronics;thermal management packaging;power density;clocks;energy efficient;circuit design;flip flops;multiplexing equipment;clock gating;integrated circuit design;circuit simulation;thermal treatment;circuit design thermal effects sram latch mux design styles clock gating energy efficiency queue structure array structures power dissipation thermal treatments multiplexer circuit level simulations;power dissipation;low power electronics;temperature;high performance;architecture;power;random access memory clocks circuit simulation signal design permission computer science design engineering power engineering and energy energy efficiency thermal engineering;thermal effects;sram chips	"""This paper studies the impact on energy efficiency and thermal behavior of design style and clock-gating style in queue and array structures. These structures are major sources of power dissipation, and both design styles and various clock gating schemes can be found in modern, high-performance processors. Although some work in the circuits domain has explored these issues from a power perspective, thermal treatments are less common, and we are not aware of any work in the architecture domain.We study both SRAM and latch and multiplexer (""""latch-mux"""") designs and their associated clock-gating options. Using circuit-level simulations of both design styles, we derive power-dissipation ratios which are then used in cycle-level power/performance/thermal simulations. We find that even though the """"unconstrained"""" power of SRAM designs is always better than latch-mux designs, latch-mux designs dissipate less power in practice when a structure's average occupancy is low but access rate is high, especially when """"stall gating"""" is used to minimize switching power. We also find that latch-mux designs with stall gating are especially promising from a thermal perspective, because they exhibit lower power density than SRAM designs. Overall, when combined with implementation and verification challenges for SRAMs, latch-mux designs with stall gating appear especially promising for designs with thermal constraints. This paper also shows the importance of considering the interaction between architectural and circuit-design choices when performing early-stage design exploration"""	architecture domain;cpu power dissipation;central processing unit;clock gating;multiplexer;simulation;static random-access memory	Yingmin Li;Mark Hempstead;Patrick Mauro;David M. Brooks;Zhigang Hu;Kevin Skadron	2005	ISLPED '05. Proceedings of the 2005 International Symposium on Low Power Electronics and Design, 2005.	10.1145/1077603.1077647	embedded system;electronic engineering;real-time computing;thermal treatment;temperature;engineering;architecture;circuit design;power density;power;clock gating;thermodynamics;integrated circuit design	EDA	14.64759202678937	56.28492263563256	73281
f0ea0f1de024290a141bb6ff8efd76a95ea02353	shaper: synthesis for hybrid fpga architectures containing pla elements using reconvergence analysis	field programmable gate array;programmable logic device;circuit design;simulation;reactions;cell;biology;programmable logic array;fpga architecture;lookup table;technology mapping;reconfigurable hardware	This paper discusses the technology mapping problem on Hybrid Field Programmable Architectures (HFPA). HFPAs are realized using a combination of the following programmable logic devices, namely, Lookup Tables (LUTs) and Programmable Logic Arrays (PLAs). The HPFAs provide the designers with the advantages of both LUT-based Field Programmable Gate Arrays and PLAs. Specifically, use of PLAs can result in reduction of area required for mapping a circuit. Designing a methodology that maps a given circuit on to the HFPA that exploits the above-mentioned advantages to the maximum is a problem of very great research and commercial interest. This paper presents the SHAPER, which maps the circuits onto HFPAs using reconvergence analysis. Empirically, it is shown that SHAPER yields 18% better area-reduction than the previous known algorithms.	algorithm;field-programmable gate array;lookup table;map;programmable logic array;programmable logic device	A. Manoj Kumar;B. Jayaram;V. Kamakoti	2004		10.1145/968280.968333	erasable programmable logic device;cell;embedded system;computer architecture;parallel computing;macrocell array;chemical reaction;lookup table;reconfigurable computing;programmable logic array;computer science;circuit design;programmable logic device;complex programmable logic device;simple programmable logic device;programmable array logic;field-programmable gate array	EDA	11.871782828481482	49.34821514916798	73329
4d97153d2f70cd75aa8eb5c5abb43141d91be337	steady and transient state analysis of gate leakage current in nanoscale cmos logic gates	leakage current;rate of change;nanoscale cmos logic gate;transients cmos logic circuits leakage currents logic gates nanoelectronics;tunneling capacitance steady state analysis transient state analysis gate leakage current nanoscale cmos logic gate nand gate nor gate;logic gates;leakage currents;cmos logic circuits;tunneling capacitance;nor gate;nanoelectronics;transient state analysis;transient analysis cmos logic circuits leakage current logic gates tunneling gate leakage steady state capacitance logic design process design;transients;nand gate;steady state analysis;logic gate;state transition;gate leakage current;steady state	Gate leakage (direct tunneling current for sub-65 nm CMOS) can severely affect both the transient and steady state behaviors of CMOS circuits. In this paper we quantify the transient and steady-state gate leakage effects as capacitances and state independent (equiprobable) average values, respectively. These metrics are characterized for two universal logic gates, 2-input NAND and NOR, and their sensitivity to variations in process and design parameters is studied. The effective tunneling capacitance of a logic gate is defined as the maximum change in tunneling current with respect to the rate of change of input voltage. It is an unique and novel metric and to our knowledge proposed here for the first time with respect to a logic gate. This metric concisely encapsulates both qualitative as well as quantitative information about the swing in tunneling current during state transitions while simultaneously accounting for the transition rate and represents the capacitive load of the logic gate due to transience in tunneling.	algorithm;cmos;circuit design;gate dielectric;gate oxide;library (computing);logic gate;nand gate;nor gate;power supply;quantum tunnelling;spectral leakage;steady state;thickness (graph theory);transient state;tunneling protocol	Saraju P. Mohanty;Elias Kougianos	2006	2006 International Conference on Computer Design	10.1109/ICCD.2006.4380819	control engineering;electronic engineering;nor gate;logic gate;gate equivalent;electrical engineering;pass transistor logic;nand gate;xnor gate;steady state;cmos;algorithm	EDA	20.73425425676702	58.978330738755005	73570
5cbe3c2ce985a9e4a57f679edd82ca63b8c3daf7	a new approach for combining yield and performance in behavioural models for analogue integrated circuits	yield prediction;circuit yield analogue integrated circuit behavioural models analogue circuit topology multiobjective evolutionary algorithm monte carlo simulation verilog a simulation ota circuit higher level filter design transistor level simulations;evolutionary computation;thermal aware design;integrated circuit yield;integrated circuit;analogue integrated circuit behavioural models;higher level filter design;temperature control;hardware description languages;multi objective evolutionary algorithm;operational amplifiers;circuit yield;analogue circuit topology;verilog a simulation;circuit topology;multiobjective evolutionary algorithm;network topology;filter design;integrated circuit design;circuit simulation;analogue integrated circuits;computational modeling;ota circuit;analog integrated circuits;integrated circuit modeling;performance analysis;operational amplifiers analogue integrated circuits evolutionary computation hardware description languages integrated circuit design integrated circuit yield monte carlo methods network topology;predictive models;static and dynamic optimization;hierarchical design;integrated circuit yield integrated circuit modeling analog integrated circuits circuit simulation computational modeling algorithm design and analysis predictive models circuit topology performance analysis evolutionary computation;monte carlo simulation;dynamic frequency scaling;algorithm design and analysis;monte carlo methods;transistor level simulations	A new algorithm is presented that combines performance and variation objectives in a behavioural model for a given analogue circuit topology and process. The tradeoffs between performance and yield are analysed using a combination of a multi-objective evolutionary algorithm and Monte Carlo simulation. The results indicate a significant improvement in overall simulation time and efficiency compared to conventional simulation based approaches, without a corresponding drop in accuracy. This approach is particularly useful in the hierarchical design of large and complex circuits where computational overheads are often prohibitive. The behavioural model has been developed in Verilog-A and tested extensively with practical designs using the Spectre#8482; simulator. A benchmark OTA circuit was used to demonstrate the proposed algorithm and the behaviour has been verified with transistor level simulations of this circuit and a higher level filter design. This has demonstrated that an accurate performance and yield prediction can be achieved using this model, in a fraction of the time of conventional simulation based methods.	analogue electronics;benchmark (computing);circuit topology;evolutionary algorithm;filter design;integrated circuit;monte carlo method;simulation;transistor;verilog;verilog-a	Sawal Ali;Reuben Wilcock;Peter R. Wilson;Andrew D. Brown	2008	2008 Design, Automation and Test in Europe	10.1145/1403375.1403414	control engineering;electronic engineering;simulation;computer science;statistics;monte carlo method;evolutionary computation	EDA	24.375880281021626	58.105649687408885	73572
88278a323b07407ff26fd201febd1a9d1cdc2e11	estimation of signal arrival times in the presence of delay noise	capacitance;circuit analysis computing;crosstalk;delays;integrated circuit noise;nanoelectronics;parameter estimation;probability;timing;monte carlo simulations;spice;capacitive coupling noise;delay noise;interconnects;nanometer circuits;probabilistic approach;reliability issue;signal arrival time estimation;signal delay	Delay due to capacitive coupling of interconnects has become an important reliability issue in the design of nanometer circuits. In this paper we present a probabilistic approach towards analyzing the impact of capacitive coupling noise on signal delay. The variation in the delay is due to the variation in the relative arrival times of the aggressors and the victim. We derive expressions for the moments of the victim voltage in the presence of noise. From these we compute estimates of the earliest and latest possible arrival times of the victim. We compare the analytical results with Monte Carlo simulations using SPICE. Even though the analytical calculations are 200 times faster than the Monte Carlo simulations, the differences in the estimates of the mean and standard deviation of the arrival time is no more than 2.8%. In addition, the width of the timing intervals using the proposed approach is reduced by as much as 48% with a confidence level of 0.984. That is 98.4% of the Monte Carlo simulations result in an arrival time that falls within the derived interval which is 48% shorter.		Sarvesh Bhardwaj;Sarma B. K. Vrudhula;David Blaauw	2002		10.1109/ICCAD.2002.1167567	nanoelectronics;parameterized complexity;electronic engineering;real-time computing;crosstalk;confidence interval;computer science;electrical engineering;probability;mathematics;capacitance;microelectromechanical systems;estimation theory;standard deviation;statistics;monte carlo method	EDA	22.555217626420077	57.632208418289146	73576
77d303d41085ad7bb5812fb58b381a553a31c942	a new design method for self-checking unidirectional combinational circuits	new design method;single stuck-at fault;aberger code;self-checking unidirectional combinational circuits;single gate fault;new design method;unidirectional combinational circuit;circuit transformation is16;known method;previous method;berger code;new method;unidirectionalcombinational circuit;original circuit	In this paper, a new method for the design of unidirectional combinational circuits is proposed. Carefully selected non-unidirectional gates of the original circuit are duplicated such that every single gate fault can only be propagated to the circuit outputs on paths with either an even or an odd number of inverters. Unlike previous methods, it is not necessary to localize all the inverters of the circuit at the primary inputs. The average area over head for the described method of circuit transformation is 16% of the original circuit, which is less than half of the area overhead of other known methods. The transformed circuits are monitored by Berger codes, or by the least significant two bits of a Berger code. All single stuck-at faults are detected by the method proposed.	benchmark (computing);berger code;combinational logic;electronic circuit;experiment;inverter (logic gate);overhead (computing);power inverter;simulation;vertical blanking interval	V. V. Saposhnikov;Andrej A. Morosov;Vl. V. Saposhnikov;Michael Gössel	1998	J. Electronic Testing	10.1023/A:1008257118423	equivalent circuit;electronic engineering;computer science;theoretical computer science;circuit extraction;algorithm	EDA	21.883953575038255	51.382860172800136	73641
134a70189478c5f33e8ffb8185d00a2eebd94b0f	power-aware partitioning of data converters	switching activity;data conversion;ultra low power;communication system;data converters low power design shift registers serializers;converters;clocks;data stream;radiation detectors;data converters;clock gating;computer architecture;power aware computing;total power;computer architecture shift registers clocks converters optimization radiation detectors;shift registers;optimization;low power design;power consumption;shift registers data conversion logic partitioning power aware computing;ultra low power industrial design power aware partitioning serial data streaming modern communication system power consuming conventional n bit registers standard data converter switching activity reduction power consumption register banks clock gating technique data converters base band radio;logic partitioning;industrial design;serializers	Serial data streaming, one of the most important functions in modern communication systems, is becoming more and more power consuming as bit-rate is increasing without standstill.	filter bank;low-power broadcasting;overhead (computing);power architecture;shift register	Alberto Bonanno;Alberto Bocca;Alberto Macii;Enrico Macii	2010	2010 18th IEEE/IFIP International Conference on VLSI and System-on-Chip	10.1109/VLSISOC.2010.5642687	embedded system;electronic engineering;parallel computing;real-time computing;industrial design;data conversion;computer science;shift register;particle detector;clock gating;communications system	EDA	10.907560858130006	48.02178528830394	73745
4ff65b7e1e6f40297fdbc07b6e20dbb6fcedc21c	early assessment of seu sensitivity through untestable fault identification	circuit faults integrated circuit modeling sensitivity testing single event upsets logic gates field programmable gate arrays;digital circuits seu sensitivity untestable fault identification single event upsets static analysis formal specification language linear temporal logic model checking tool itc99 benchmark fault injection experiments;fault injection automatic test generation computer aided de sign model checking sal seu sensitivity analysis single event upset untestability proof;radiation hardening electronics benchmark testing digital integrated circuits fault diagnosis formal specification integrated circuit testing	Modern digital circuits are, with each technological evolution, increasingly affected by Single Event Upsets (SEUs). In this paper we propose a static analysis approach for the estimation of the SEU sensitivity of the system under design by identifying untestable faults. The approach relies on a formal specification language to model circuits at the gate-level and on the Linear Temporal Logic (LTL) to express untestability properties that are then evaluated using a model-checking tool. The proposed approach can be applied early during the design process, since it can be individually applied to sub-systems as soon as they are designed, before the whole system is implemented and since it does not require a specific workload to be defined. The approach has been implemented and applied to a set of circuits from the ITC99 benchmark and has been validated against fault injection experiments.	benchmark (computing);digital electronics;experiment;flops;fault injection;flip-flop (electronics);formal specification;linear temporal logic;model checking;single event upset;specification language;static program analysis;triple modular redundancy;vii	Luca Cassano;Hipólito Guzmán-Miranda;Miguel A. Aguirre	2014	2014 IEEE 20th International On-Line Testing Symposium (IOLTS)	10.1109/IOLTS.2014.6873692	reliability engineering;electronic engineering;real-time computing;engineering;stuck-at fault	SE	19.20429903818582	49.2714000068122	73964
3e19a024a16c814d7619a540525735163012ecf5	analytical power/timing optimization technique for digital system	digital logic;satisfiability;timing optimization;digital systems;logic gate;power minimization	A method for logic gate delay assignment is described which achieves power minimization of digital logic while satisfying system timing. The logic gates are described by a single design parameter macromodel. A Newton optimization scheme is employed using exact sparse updating. Systems consisting of up to 1200 digital logic gates have been optimized. A companion paper describes how a further optimization of the system is achieved if power-oriented placement improvement is included in the optimization procedure.	boolean algebra;digital electronics;logic gate;macromodel;mathematical optimization;newton;newton's method;propagation delay;sparse matrix	Albert E. Ruehli;Peter K. Wolff;Gerald Goertzel	1977			boolean algebra;electronic engineering;logic synthesis;logic optimization;diode–transistor logic;logic level;asynchronous circuit;delay calculation;logic gate;logic family;programmable logic array;computer science;theoretical computer science;pass transistor logic;sequential logic;digital electronics;register-transfer level;algorithm;satisfiability	EDA	17.1905380562631	48.07166079236336	73987
bf432442787e09619e4d4335d8e918264e0d9735	architecture considerations for mixed signals fpgas	bit level pipelined;fpga;recursive algorithms;circuit latency	This poster describes the implementation of a 400-MHz frequency counter in an XC4002XL FPGA. In addition to speed, other objectives were low power and efficient resource utilization. These objectives were met using a semisynchronous design technique where pairs of flip-flops operate as synchronous state machines that are cascaded asynchronously. XC4OOOXL CLBs each contain two flip-flops that share a common clock input. This common clock permits the pair of flip-flops to operate synchronously in spite of clock routing on local interconnect. A fully asynchronous design would waste half of the flip-flops since there would be no individual clock access. The outcome of the project was a full-featured frequency counter that operates at 400 MHz, consumes only 130 mW at the maximum input frequency, and occupies 56 CLBs, less than 90% of an XC4002XL.	asynchronous circuit;flops;field-programmable gate array;flip-flop (electronics);frequency counter;routing	Luigi Carro	1999		10.1145/296399.296474	embedded system;computer architecture;parallel computing;real-time computing;computer science;field-programmable gate array	EDA	13.807944234851952	60.26611116746962	74052
ba040e2f7d713cde3d05de3ddcd12fc4034f395b	performance model for inter-chip communication considering inductive cross-talk and cost	inductive cross talk;crosstalk;bus speed;crosstalk integrated circuit interconnections integrated circuit modelling printed circuit design integrated circuit packaging system buses;printed circuit design;ic i o subsystem;chip;system buses;slew rate;i o cost minimization;integrated circuit modelling;integrated circuit interconnections;analytical method;signal to power ground ratio inter chip communication performance model inductive cross talk ic i o subsystem throughput ic package bus size bus speed i o cost minimization bus width slew rate;performance model;bus width;signal to power ground ratio;bus size;cost effectiveness;ic package;integrated circuit packaging;inter chip communication performance model;analytical model;throughput	We present an analytical method to perform the design of the I/O subsystem of an IC given its throughput requirements. Our method can be used to select the IC package, along with the bus size and speed so as to minimize I/O cost. We have validated our model by conducting simulations on three industry-standard packages while varying the bus width, slew rate, and signal-to-power ground ratio. Our experimental results track closely with the analytical model. We demonstrate for the packages considered that it is more cost effective to use faster, narrower busses rather than slower wider busses to achieve a desired system throughput.	bus (computing);crosstalk;dual in-line package;input/output;requirement;simulation;throughput	Brock J. LaMeres;Sunil P. Khatri	2005	2005 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2005.1465540	slew rate;chip;embedded system;throughput;electronic engineering;crosstalk;cost-effectiveness analysis;computer hardware;telecommunications;integrated circuit packaging;computer science;engineering;electrical engineering	EDA	14.479093839442974	56.91040295507859	74081
bb7c76d77ee7320cc816c97726ab61106859ad9a	dynamic management of thermally-induced clock skew: an implementation perspective	cycle time;gestion temperature packaging electronique;thermal management packaging;haute performance;integrated circuit;execution time;implementation;circuit vlsi;circuito integrado;tecnologia mos complementario;vlsi design;signal integrity;conception circuit integre;chip;integrated circuit design;vlsi circuit;thermal behavior;comportamiento termico;alto rendimiento;temps execution;temps retard;delay time;circuito vlsi;tiempo ejecucion;implementacion;technologie mos complementaire;tiempo retardo;high performance;thermal management;clock skew;circuit integre;complementary mos technology;comportement thermique	High performance VLSI designs require strict control over clock skew since skew directly impacts the cycle time calculation. For nano-meter CMOS designs, clock-skew and signal integrity are tremendously affected by process and temperature variations. A successful high performance VLSI design should not only aim to minimize the clock skew, but also control it while the chip is running. The issues rising out of temperature variations are particularly tough to tackle because of its dynamic, run-time nature. Although techniques for clock skew management/tuning due to temperature do exist in literature, they have mainly focused on how to solve skew issues, and have usually regarded the implementation of the thermal management scheme as a secondary problem. In this work we focus on the implementation issues involved in the implementation of a thermal management unit (TMU) relative to a skew management scheme based on the insertion of variable delay buffers (VDBs). We demonstrate the feasibility of the VDB-based methodology, and compare different implementation styles, showing that the most efficient TMU can be implemented with negligible overhead in various physical level metrics (0.67% in area, 0.62% in wire-length, 0.33% in power, and 0.37% in via-number).	cmos;clock signal;clock skew;gnu nano;overhead (computing);run time (program lifecycle phase);signal integrity;simulation;texture mapping unit;thermal management of high-power leds;very-large-scale integration	Ashutosh Chakraborty;Karthik Duraisami;Ashoka Visweswara Sathanur;Prassanna Sithambaram;Alberto Macii;Enrico Macii;Massimo Poncino	2006		10.1007/11847083_21	chip;embedded system;real-time computing;thermal management of electronic devices and systems;telecommunications;clock skew;cycle time variation;computer science;signal integrity;engineering;electrical engineering;operating system;integrated circuit;timing failure;very-large-scale integration;implementation;integrated circuit design	EDA	18.43427778342362	54.90941093021228	74106
de326116e13cf7382982b91f402f4c1ff33043f4	advances in concurrent multilevel simulation	verification;concepcion asistida;computer aided design;convergence;list events;metodologia;circuit faults;fault simulation;integrated circuit;switching circuits;concurrent fault simulation;simulation;ordered activity propagation;simulacion;circuito integrado;simulateur mozart;methodologie;simulator;multilist traversal;circuit simulation;circuit simulation circuit faults switching circuits switches discrete event simulation circuit testing logic programming integrated circuit interconnections convergence joining processes;simulador;logic programming;levels of abstraction;integrated circuit interconnections;switch gate and rt levels;simulateur;joining processes;fraternal event processing;conception assistee;circuit testing;verificacion;methodology;switches;circuit integre;ordered activity propagation concurrent fault simulation switch gate and rt levels multilist traversal fraternal event processing list events;discrete event simulation;simulation faute	Fault simulation of circuits described at multiple levels of abstraction (RT, gate, switch) is a major problem in the area of CAD and testing. Although the concurrent paradigm is generally acknowledged as the most efficient, several techniques are crucial to successfully extend it to multilevel simulation of large circuits. In particular, based on multilist traversal, fraternal event processing, list events, and levelizing, advances are presented here in simulation speed, accuracy, and generality. For zero-delay elements, the simulation of irrelevant activity is avoided, but the accuracy of structural (interconnect) logic simulation is maintained. What is described here has been implemented in MOZART, and detailed experimental results are reported. Relative to the good machine, the average faulty machine is simulated 900 to 17 000 times faster. The approach presented is not restricted to fault simulation, and is thus applicable to the new area of concurrent case simulation.	complex event processing;computer-aided design;electronic circuit simulation;logic simulation;principle of abstraction;programming paradigm;relevance	Silvano Gai;Fabio Somenzi;Ernst G. Ulrich	1987	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.1987.1270341	embedded system;electronic engineering;parallel computing;real-time computing;verification;convergence;network switch;computer science;electrical engineering;discrete event simulation;operating system;integrated circuit;computer aided design;logic simulation;methodology;programming language;logic programming;algorithm	EDA	20.1380231683944	49.643509437874656	74131
10a88d81be7adcce5661877630d5881dff15aabb	optimization and selection of diagnosis-oriented fault-insertion points for system test	circuit faults;diagnosis oriented fault insertion points;diagnostic accuracy;optimal method;edit distance;system on chip boundary scan testing fault diagnosis integer programming integrated circuit reliability integrated circuit testing linear programming;optimization method;boundary scan testing;accuracy;integer linear programming model fault insertion test error flow diagnosis efficient fault insertion point;integer programming;system on chip;registers;dictionaries;manufacturing;error flow;integrated circuit testing;linear programming;integer linear programming model diagnosis oriented fault insertion points system test optimization method fault diagnosis;optimization;diagnosis efficient fault insertion point;integrated circuit reliability;circuit faults dictionaries conferences accuracy registers manufacturing optimization;fault insertion test;system test;integer linear program;conferences;fault diagnosis;open source;integer linear programming model	"""Hardware fault-insertion test is a promising method to diagnose functional failures and target ''no trouble found (NTF)"""" problems in electronic systems. However, it is costly and impractical to equip all the potential fault sites with fault-insertion hardware. We present an optimization method to select the most effective outputs of a module where fault insertion logic must be placed to facilitate diagnosis. Faults inserted at the selected outputs are able to generate fault syndromes that are most similar to the errors produced by defects inside the module. This approach also ensures that the ambiguous fault candidates from other modules are maximally removed from the set of suspects. A fault syndrome is defined by the order of error occurrence at the observation points, and it is referred as an error flow. The similarity between two error flows is measured by the metric of edit distance. An integer linear programming model is used to maximize diagnostic effectiveness with a small number of fault-insertion points. Results on diagnostic accuracy for an open-source RISC highlight the effectiveness of the proposed method compared to a baseline random fault-insertion scheme."""	baseline (configuration management);edit distance;fault (technology);insertion sort;integer programming;linear programming;mathematical optimization;national transfer format;open-source software;optimization problem;programming model;randomness;software bug;system on a chip	Zhaobo Zhang;Zhanglei Wang;Xinli Gu;Krishnendu Chakrabarty	2010	2010 19th IEEE Asian Test Symposium	10.1109/ATS.2010.79	system on a chip;embedded system;electronic engineering;real-time computing;integer programming;edit distance;fault coverage;computer science;linear programming;stuck-at fault;fault model;accuracy and precision;processor register;manufacturing;system testing;algorithm	Embedded	21.957496613589917	52.138728426016336	74150
c1b89d8d719c127fe3ed5a5f21aa9466f55e4f61	an effective methodology for mixed scan and reset design based on test generation and structure of sequential circuits	design for testability;circuit under test;logic simulation;circuit testing flip flops circuit faults design for testability controllability sequential circuits fault detection hardware electronic equipment testing sequential analysis;circuit faults;reset selection;logic simulation sequential circuits logic testing integrated circuit testing flip flops automatic test pattern generation boundary scan testing design for testability fault diagnosis;automatic test pattern generation;sequential circuits;controllability;flip flops;reachable states;dft sequential circuits mixed partial scan reset design test generation flip flop selection methodology reachable states required states hard to detect faults structural connection relationship test pattern simulation circuit under test mixed partial scan reset selection testability;sequential analysis;electronic equipment testing;hard to detect faults;structural connection relationship;testability;boundary scan testing;required states;flip flop selection methodology;fault detection;logic testing;integrated circuit testing;test generation;circuit testing;mixed partial scan;test pattern simulation;mixed partial scan reset design;dft;flip flop;fault diagnosis;hardware	In this paper, a flip-flop selection methodology, which utilizes reachable states of flip-flops, required states for hard-to-detect faults, which are obtained from test generation, and the structural connection relationship of flip-flops, to achieve a nearly optimal mixed partial-scan/reset design, is proposed. The methodology first generates and simulates test patterns for the circuit-under-test to obtain information of reachable states and states needed for excitation and propagation of hard-to-detect faults. It then searches the connection relationship among flip-flops and arranges flip-flops in an appropriate order for mixed partial scan and reset selection. Experimental results show that the method achieves higher testability than reported methods with a lesser number of scan/reset flip-flops.		Hsing-Chung Liang;Chung-Len Lee	1999		10.1109/ATS.1999.810747	testability;embedded system;electronic engineering;real-time computing;controllability;computer science;engineering;automatic test pattern generation;sequential analysis;logic simulation;discrete fourier transform;design for testing;sequential logic;fault detection and isolation	EDA	21.728045588144074	51.019764976267666	74171
bd325acfaa380b2e8c6bc2f1b2fa6d3838b2f463	improved match-line test and repair methodology including power-supply noise testing for content-addressable memories	circuit testing computer aided manufacturing cadcam life testing circuit noise built in self test noise robustness system testing hardware stress;power supply circuits;circuit noise;chip;embedded systems;built in self test;power supply noise;match line steering match line testing power supply noise testing embedded content addressable memory design power hungry circuits cam induced power supply noise programmable bist patterns;logic testing;integrated circuit testing;content addressable memory;power supply circuits built in self test circuit noise content addressable storage embedded systems integrated circuit testing logic testing;content addressable storage	This paper describes a novel test and repair methodology for an embedded content-addressable memory (CAM) design. Exhaustive match-line testing is used to ensure correct search operation after manufacturing, while search margin testing is used to provide robust functionality for the life of the product. With CAM being one of the most power-hungry circuits on chip, it is also important to test the effects of CAM-induced power-supply noise. Programmable BIST patterns induce worst-case power-supply noise in the system and then test CAM sensitivity to it. Fails in the CAM are detected by BIST and repaired using row redundancy with word-line and match-line steering. Hardware results stress the importance of this test and repair methodology	best, worst and average case;built-in self-test;content-addressable memory;embedded system;power supply	Rahul Nadkarni;Igor Arsovski;Reid Wistort;Valerie Chickanosky	2006	2006 IEEE International Test Conference	10.1109/TEST.2006.297700	chip;embedded system;electronic engineering;real-time computing;telecommunications;computer science;engineering;content-addressable memory	EDA	22.047436228316876	53.39744414310492	74438
1bf038d7f721eeeaff8b93238d4449961e500f81	a new and accurate interconnection delay time evaluation in a general tree-type network	integrated circuit interconnections;integrated logic circuits;delay time;logic cad;timing	In all recent technologies the delay caused by interconnection wires is essential in the evaluation of the switching speed of integrated structures. Completely wrong results, would result if this were neglected. By considering a distributed RC network to model the interconnection lines, we proposed a new analytical delay time expression for a general tree type network, with full incorporation of technology design parameters. A computationally simple technique is presented and comparisons with HSPICE simulation results show the accuracy of the developed model in timing verification.	interconnection;rc circuit;spice 2;simulation;static timing analysis;vergence	Denis Deschacht;Christophe Dabrin	1995		10.1145/224818.224923	control engineering;electronic engineering;real-time computing;delay calculation;computer science;elmore delay	EDA	23.63287934962625	50.94585502670028	74654
af7c054ee7f7aeb43fd232531e61efb9db6c78dc	mapping arbitrary logic functions into synchronous embedded memories for area reduction on fpgas	field programmable gate arrays;logic design;ram-map;stratix device;area reduction;area-prediction cost function;embedded memory mapping;field programmable gate array;logic functions;synchronous embedded memories;technology mapping	This work describes a new mapping technique, RAM-MAP, that identifies parts of circuits that can be efficiently mapped into the synchronous embedded memories found on field programmable gate arrays (FPGAs). Previous techniques developed for mapping into asynchronous embedded memories cannot be used because modern FPGAs do not have asynchronous embedded memories. After technology mapping, an area-prediction cost function is used to guide the selection of logic cones to be placed in embedded memories. Extra logic is added to compensate for missing asynchronous functionality on the synchronous memories. Experiments conducted on Altera's Stratix device family indicate that this embedded memory mapping technique can provide an average area reduction of 6.2% and up to 32.5% on a large set of industrial designs. A small architecture change that increases the size of the FPGA fabric by 0.05% can increase the average area reduction to 14.1% and up to 59.1% on the same design set	embedded system;field-programmable gate array	Gordon R. Chiu;Deshanand P. Singh;Valavan Manohararajah;Stephen Dean Brown	2006		10.1109/ICCAD.2006.320077	embedded system;electronic engineering;parallel computing;real-time computing;industrial design;computer science;field-programmable gate array	EDA	13.293115470393264	48.35531198216579	74691
3736a74be274c6b8c148ef9da3a849bd0c7f273a	impact of leakage power reduction techniques on parametric yield - low-power design of digital integrated circuits under process parameter variations			integrated circuit;low-power broadcasting;spectral leakage	Sudip Roy;Ajit Pal	2013				EDA	19.128556391541597	57.983263296632856	74806
bb0e5e0f9b3db90f49ebf5abd9e690877b2a5972	the power of exhaustive bridge diagnosis using iddq speed, confidence, and resolution	circuit design;logic circuits;bridge circuits circuit faults application specific integrated circuits power system modeling predictive models production failure analysis circuit synthesis circuit testing fault diagnosis;failure analysis;application specific integrated circuits;logic testing;fault model;physical failure analysis exhaustive bridge diagnosis high speed diagnosis two node bridging defects logic circuit i ddq testing asic diagnostic resolution bridge fault model;high speed;fault diagnosis;diagnostic method;logic testing application specific integrated circuits failure analysis fault diagnosis logic circuits	A method is presented for high-speed diagnosis of all two-node bridging defects in a logic circuit using IDDQ. The method is tractable for large industrial circuit designs, requiring less than two CPU minutes to evaluate the ten trillion bridging defects on a 4.5-million gate ASIC. More significant than the speed of the method, however, is the precise diagnostic resolution typically achieved when the list of bridge faults diagnosed is examined in light of the circuit's physical layout. The robustness of the IDDQ bridge fault model and the near impossibility of matching a long IDDQ signature by chance result in a confidence in the results rarely matched by diagnostic methods that must rely on modeling the logical behavior of a bridging defect. Performance data and results from physical failure analysis are presented for a variety of production ASIC designs	application-specific integrated circuit;bridging (networking);central processing unit;cobham's thesis;failure analysis;fault model;iddq testing;integrated circuit layout;logic gate;randomness;software bug	Doug Heaberlin	2006	2006 IEEE International Test Conference	10.1109/TEST.2006.297692	reliability engineering;failure analysis;electronic engineering;real-time computing;logic gate;engineering;stuck-at fault;circuit design;fault model;application-specific integrated circuit;circuit extraction	EDA	22.67752797278005	53.8149456498597	74943
2f15a37ac464e415459fd3d5109fa558e6e99b50	the practical application of retiming to the design of high-performance systems	practical application;high-performance system;logic design;design process;propagation delay;clock skew	Many advances have been made recently in the theory of circuit retiming, especially for circuits that use level-sensitive latches. In spite of this, automatic retiming tools have seen relatively little use in practice. One reason for this is the lack of good speedup results when retiming has been applied to real circuits. Another reason is that retiming has used a rather simple circuit model which reduces its utility in practice. This paper addresses both of these issues. We suggest that the reason for the poor results reported for retiming is that retiming has been applied too late in the design process when there is little exibility for performance improvement. We give an example of using retiming early in the design process to achieve better performance while at the same time simplifying the design process itself. We then describe an extension to the retiming circuit model that includes clock skew as well as latch propagation delay, setup and hold parameters. Including these parameters allows retiming to generate the fastest circuit subject to a given amount of clock skew, or generate the most robust circuit with respect to skew for a given clock frequency. This gives level-clocked circuits yet another advantage over edge-clocked circuits since edge-clocked circuits require margin for clock skew while level-clocked circuits can be retimed to be inherently skew-tolerant. We illustrate these techniques using a serial-parallel multiplier circuit.	clock rate;clock skew;fastest;propagation delay;retiming;software propagation;speedup;yet another	Brian Lockyear;Carl Ebeling	1993		10.1145/259794.259843	propagation delay;electronic engineering;parallel computing;logic synthesis;real-time computing;design process;asynchronous circuit;clock domain crossing;clock skew;computer science;retiming;digital clock manager	EDA	17.634594045483645	53.156454243608856	74959
2af677219caba97a2043f3a577519c5a4db2ec77	"""low power technology mapping for lut based fpga """"a genetic algorithm approach"""""""	table lookup field programmable gate arrays genetic algorithms minimization combinational circuits switching circuits switches capacitance biological cells logic circuits;transition probability;low power electronics field programmable gate arrays logic cad genetic algorithms table lookup combinational circuits;low power;low power electronics;lookup table;genetic algorithm;genetic algorithms;field programmable gate arrays;technology mapping;combinational circuit;connection switch low power technology mapping fpga genetic algorithm lookup table combinational circuit power minimization np complete problem logic circuit transition probability chromosome fitness;table lookup;logic cad;power minimization;combinational circuits	In this paper we consider the problem of LookUp Table(LUT) based FPGA technology mapping for power minimization in combinational circuits. The problem has been previously proven to be NP-complete and here we present an efficient Genetic Algorithm solution for it. Considering that the connection switches posses large resistance and capacitance in LUT based FPGA, the fitness of the chromosome is selected based on its ability to reduce the transition probability on “visible” edges of mapped logic circuits by hiding the paths with high transition activity in the “invisible” edges. Meanwhile, the number of LUT is also kept small.	benchmark (computing);central processing unit;combinational logic;covering problems;field-programmable gate array;genetic algorithm;logic gate;lookup table;markov chain;np-completeness;network switch;software release life cycle;very-large-scale integration	Rohit Pandey;Santanu Chattopadhyay	2003		10.1109/ICVD.2003.1183118	electronic engineering;genetic algorithm;computer science;theoretical computer science;combinational logic;algorithm	EDA	16.18445481799096	49.37465793650348	75095
85e65231448b7cfd209d2b241625db6716fe4913	cellular array-based delay-insensitive asynchronous circuits design and test for nanocomputing systems	circuit design;layout;delay insensitive;stuck at fault;asynchronous circuit;delay insensitive circuit;cellular arrays;system design;reed muller;reed muller expression;nanoscale circuit	This paper presents the design, layout, and testability analysis of delay-insensitive circuits on cellular arrays for nanocomputing system design. In delay-insensitive circuits the delay on a signal path does not affect the correctness of circuit behavior. The combination of delayinsensitive circuit style and cellular arrays is a useful step to implement nanocomputing systems. In the approach proposed in this paper the circuit expressions corresponding to a design are first converted into Reed-Muller forms and then implemented using delay-insensitive ReedMuller cells. The design and layout of the Reed-Muller cell using primitives has been described in detail. The effects of stuck-at faults in both delay-insensitive primitives and gates have been analyzed. Since circuits implemented in Reed-Muller forms constructed by the Reed-Muller cells can be easily tested offline, the proposed approach for delay-insensitive circuit design improves a circuit’s testability. Potential physical implementation of cellular arrays and its area overhead are also discussed.	1-bit architecture;and gate;circuit design;correctness (computer science);delay insensitive circuit;exclusive or;fault tolerance;muller automaton;multiplexer;nanocomputer;online and offline;overhead (computing);reed–muller code;requirement;software testability;systems design;xor gate	Jia Di;Parag K. Lala	2007	J. Electronic Testing	10.1007/s10836-006-0549-5	equivalent circuit;layout;physical design;embedded system;electronic engineering;real-time computing;asynchronous circuit;computer science;stuck-at fault;circuit design;circuit extraction;systems design	EDA	19.36091970180775	47.24264618061987	75154
208ee112c1b88458947adf831266dfe5b758a0e9	the case for outsourcing dft	computer aided software engineering outsourcing logic testing design for testability built in self test integrated circuit testing logic design digital integrated circuits propagation delay test equipment;design for testability;outsourcing;analog ic fault coverage;and mixed signal;mixed signal circuits;analog failures;mixed analogue digital integrated circuits;test accuracy;fault coverage;test time;outsourcing design for testability analog ic fault coverage mixed signal circuits analog failures test equipment test accuracy test time;test equipment;outsourcing design for testability mixed analogue digital integrated circuits;mixed analog digital integrated circuits	"""The author discusses about outsourcing analog/mixed-signal DFT. At present we still lack a """"SAF"""" metric for measuring analog IC fault coverage, as most analog faults that are found by testing are of a parametric variety, and can not be measured or scored (as in the SAF coverage grade) by using Boolean techniques. To analyze analog and mixed-signal (A/MS) logic for testability, one has to know what the analog failures are that need to be detected, what the capability of the test equipment will be for these measurements, what the error or repeatability will be, and what the trade off is going to be between increased test accuracy and test time"""	built-in test equipment;fault coverage;mixed-signal integrated circuit;outsourcing;repeatability;software testability;store and forward	Jeffrey L. Roehr	2005	IEEE International Conference on Test, 2005.	10.1109/TEST.2005.1584134	mixed-signal integrated circuit;reliability engineering;embedded system;automatic test equipment;electronic engineering;fault coverage;computer science;engineering;automatic test pattern generation;test compression;design for testing;outsourcing;computer engineering	EDA	22.597393180024678	53.26787625639365	75169
11b36c8f74a15f51232bbb29e84da6c92c1b0fcf	a fully-automated desynchronization flow for synchronous circuits	synchronisation electronic design automation pipeline processing;reliability;desynchronization;performance;desynchrouization algorithms design performance reliability eda variability adaptive circuits;design flow;eda;contemporary synchronous eda tool;electronic design automation fully automated desynchronization flow synchronous circuit contemporary synchronous eda tool pipelined processor;adaptive circuits;synchronisation;electronic design automation and methodology automatic control libraries performance analysis latches registers integrated circuit reliability permission timing asynchronous circuits;technology scaling;desynchrouization;algorithms;design;pipelined processor;variability;algorithm design;fully automated desynchronization flow;pipeline processing;synchronous circuit;design methodology;electronic design automation	Variability is one of the fundamental problems faced by nano-scale electronic circuits and is expected to become even worse as process technology scales. Desynchronization is a design methodology, which converts a synchronous gate-level circuit into a more robust asynchronous one. In this paper, we describe the first fully-automated desynchronization design flow, based only on contemporary synchronous EDA tools and a new point tool for performing the desynchronization transformation. The flow was used to implement, down to mask layout level, a simple pipelined processor in a 90nm industrial library. We show that the desynchronization methodology can be easily integrated into contemporary industrial EDA flows. Results, on the design implemented, indicate that desynchronized circuits exhibit increased variability tolerance and better average case performance, for a small area and power overhead.	best, worst and average case;central processing unit;core (optical fiber);dlx;dynamic voltage scaling;electronic circuit;flops;flip-flop (electronics);gnu nano;heart rate variability;image scaling;instruction pipelining;integrated circuit layout;master/slave (technology);overhead (computing);pipeline (computing)	Nikolaos Andrikos;Luciano Lavagno;Davide Pandini;Christos P. Sotiriou	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278722	embedded system;algorithm design;design;electronic engineering;real-time computing;electronic design automation;computer hardware;performance;telecommunications;computer science;design flow;reliability;synchronous circuit;algorithm	EDA	14.73441356802725	54.92530158843184	75215
e784bb3c696e1ec733c1f72183a6cefcef3cf380	high light-load efficiency charge pumps	degradation;charge pumps charge transfer mosfets circuit simulation timing spice low voltage energy consumption cmos process degradation;integrated circuit design voltage multipliers cmos analogue integrated circuits power consumption network analysis;mosfets;cmos voltage doubler;light load charge pumps;charge transfer;cmos process;network analysis;integrated circuit design;circuit simulation;low voltage;maximum current capability;cmos analogue integrated circuits;energy consumption;charge pumps;cmos voltage doubler high efficiency charge pumps light load charge pumps light load efficiency undesired charge transfer maximum current capability power consumption cmos charge pumps;settore ing inf 01 elettronica;light load efficiency;high efficiency charge pumps;power consumption;charge pump;spice;voltage multipliers;high light;cmos charge pumps;undesired charge transfer;timing	We first analyze the undesired charge transfer occurring in charge pumps; we then present a circuit which is less susceptible to this issue, resulting in significant improvements of the light-load efficiency in charge pumps which must have a sufficiently high maximum current capability. SPICE simulations confirm the theoretical results.	spice;simulation	Christian Falconi;Giancarlo Savone;Arnaldo D'Amico	2005	2005 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2005.1464980	embedded system;electronic engineering;charge pump;degradation;network analysis;computer science;engineering;electrical engineering;charge-transfer complex;low voltage;integrated circuit design	Arch	19.972952563749097	58.429532956904	75269
37332f26a19d25a875fc3f1a40f189aaf305056c	a practical application of full-feature alternating phase-shifting technology for a phase-aware standard-cell design flow	opc;design layouts full feature alternating phase shifting technology phase aware standard cell design flow optical proximity correction phase shifting masks altpsm eda methodology design productivity structured custom design styles synthesis automatic place and route;electronic design automation phase shifting masks cellular arrays proximity effect lithography photolithography integrated circuit layout circuit layout cad;off axis illumination;proximity effect lithography;integrated circuit;integrated circuit layout;phase shifting;quadrupole;optical proximity correction;design flow;phase shift;scattering bars;silicon integrated circuit technology electronics industry integrated optics photonic integrated circuits integrated circuit yield production portfolios electronic design automation and methodology productivity;cellular arrays;lithography;sraf;quasar;cost effectiveness;place and route;circuit layout cad;phase shifting masks;photolithography;psm;phase shift mask;oai;ret;electronic design automation	As the semiconductor industry enters the subwavelength era where silicon features are much smaller than the wavelength of the light used to create them, a number of “subwavelength” technologies such as Optical Proximity Correction (OPC) and PHase-Shifting Masks (PSM) have been introduced to produce integrated circuits (ICs) with acceptable yields. An effetive approach to subwavelength IC production includes a combination of these techniques, including OPC and PSM. Nevertheless, as we approach silicon features of 0.10 μ and below, Alternating PSM (AltPSM ICs must guarantee correct generation of AltPSM layouts, maintain or improve today's design productivity, and leverage existing tools and flows. The implementation of such a methodology becomes more complex as phase shifting is applied to all critical features, including those outside of transistor gates. In this paper, we present a methodology targeted for standard-cell or structured-custom design styles. We also present examples of designs that start from standard-cells created in a manner in which all issues regarding generation of AltPSM are effectively considered, and are used in a typical cell-based (synthesis-Automatic Place & Route) flow to produce design layouts that are ready for cost-effective silicon manufacturing.	design flow (eda);integrated circuit;open platform communications;semiconductor industry;standard cell;transistor;transistor–transistor logic	Michael Sanie;Michel Côté;Philippe Hurat;Vinod Malhotra	2001		10.1145/378239.378346	lithography;embedded system;electronic engineering;electronic design automation;computer science;engineering;electrical engineering;phase;engineering drawing	EDA	13.126674133146892	55.086126263574286	75337
2b4cad8b93e0aeef8eaaf3ffcde76f133dd916c9	automatic generation of inexact digital circuits by gate-level pruning	silicon adders elemental semiconductors logic design low power electronics power consumption;wires;gate level pruned high speed adder automatic generation inexact digital circuits gate level pruning approximate circuits power consumption cad tools digital design flow critical path delay silicon area power savings;error analysis;pruning;logic gates;adders;probabilistic logic;approximate computing;adders logic gates delays probabilistic logic wires hardware error analysis;delays;hardware;approximate adder	Inexact or approximate circuits show great ability to reduce power consumption at the cost of occasional errors in comparison to their conventional counterparts. Even though the benefits of such circuits have been proven for many applications, they are not wide spread owing to the absence of a clear design methodology and the required CAD tools. In this regard, this paper presents a methodology to automatically generate inexact circuits starting from a conventional design by adding only one small step in the digital design flow. Further, this paper also demonstrates that achieving pruning at gate-level can lead to substantial savings in terms of power consumption, critical path delay and silicon area. An order of magnitude area and power savings is demonstrated for a 64-bit gate level pruned high-speed adder for a 10% relative error magnitude.	64-bit computing;adder (electronics);approximation algorithm;approximation error;computer simulation;computer-aided design;critical path method;digital electronics;logic synthesis	Jeremy Schlachter;Vincent Camus;Christian C. Enz;Krishna V. Palem	2015	2015 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2015.7168598	electronic engineering;logic gate;computer science;engineering;theoretical computer science;pruning;probabilistic logic;algorithm;adder	EDA	19.471286472969542	55.982563208353014	75377
2bd7eed691bd09ee5369980e1ef50906bfd90d66	logic synthesis for switching lattices by decomposition with p-circuits	switching lattices;logic synthesis;boolean functions decomposition	In this paper we propose a novel approach to the synthesis of minimal-sized lattices, based on the decomposition of logic functions. Since the decomposition allows to obtain circuits with a smaller area, our idea is to decompose Boolean functions with separate lattices, according to the P-circuits decomposition scheme, and then to implement the decomposed blocks with physically separated regions in a single lattice. Experimental results show that about 35% of the considered benchmarks achieve a smaller area when implemented using the proposed decomposition for switching lattices, with an average gain of at least 24%.	benchmark (computing);computation;electronic circuit;logic synthesis;preprocessor;time complexity	Anna Bernasconi;Valentina Ciriani;Luca Frontini;Valentino Liberali;Gabriella Trucco;Tiziano Villa	2016	2016 Euromicro Conference on Digital System Design (DSD)	10.1109/DSD.2016.75	embedded system;logic synthesis;computer science;theoretical computer science	EDA	15.595281378943202	47.70203029152823	75403
57693bd085f44d31e1426145926bd9e09e877e45	towards scalable system-level reliability analysis	analytical models;reliability engineering;early quantification technique;cmos technology;boolean functions;early quantification reliability analysis sat assisted simulation;computability;construction industry;sat assisted simulation scalable system reliability analysis system level design binary decision diagram early quantification technique complex system;runtime;scaling circuits approximation theory binary decision diagrams circuit analysis computing computability embedded systems integrated circuit design integrated circuit reliability;failure analysis;approximation theory;embedded systems;integrated circuit design;binary decision diagrams;sat assisted simulation;complex system;early quantification;boolean functions data structures system level design analytical models binary decision diagrams failure analysis cmos technology scalability runtime system testing;data structures;scalable system;scaling circuits;system level design;system testing;reliability analysis;scalability;integrated circuit reliability;circuit analysis computing;binary decision diagram	State-of-the-art automatic reliability analyses as used in system-level design approaches mainly rely on Binary Decision Diagrams (BDDs) and, thus, face two serious problems: (1) The BDDs exhaust available memory during their construction and/or (2) the final size of the BDDs is, sometimes up to several orders of magnitude, larger than the available memory. The contribution of this paper is twofold: (1) A partitioning-based early quantification technique is presented that aims to keep the size of the BDDs during construction at minimum. (2) A SAT-assisted simulation approach aims to deliver approximated results when exact analysis techniques fail because the final BDDs exhaust available memory. The ability of both methods to accurately analyze larger and more complex systems than known approaches is demonstrated for various test cases.	approximation algorithm;binary decision diagram;complex systems;electronic system-level design and verification;level design;reliability engineering;scalability;simulation;test case	Michael Glaß;Martin Lukasiewycz;Christian Haubelt;Jürgen Teich	2010	Design Automation Conference	10.1145/1837274.1837334	embedded system;failure analysis;complex systems;electronic engineering;real-time computing;scalability;data structure;computer science;theoretical computer science;computability;electronic system-level design and verification;boolean function;cmos;system testing;binary decision diagram;algorithm;integrated circuit design;approximation theory	EDA	23.035683731813794	57.74455815317634	75439
58da30ef15dc464489893463c933a1bb8982561d	electrical modeling and simulation challenges in chip-package codesign	modeling and simulation;digital simulation circuit cad semiconductor device packaging semiconductor device models;integrated circuit interconnections packaging delay effects clocks microprocessors computational modeling circuit simulation computer simulation power system interconnection crosstalk;semiconductor device packaging;simulation functional block integration packaging chip package codesign;holistic approach;function block;chip;interconnects;semiconductor device models;ics;circuit cad;microprocessor design;microelectronics;high performance;digital simulation	Design innovation, device scaling, larger wafers, and yield improvement have fueled the semiconductor industry’s rapid growth over the past 20 years. Among these factors, device scaling stands out as the principal technological contributor to productivity growth. Although today’s products have feature sizes of 250 nanometers, the 1997 National Technology Roadmap for Semiconductors calls for further downsizing: 100-nm technology by 2006 and 50-nm by 2012. The semiconductor industry appears confident that feature sizes of 100 nm are achievable without major breakthroughs in photolithography. This size reduction implies significantly higher device switching speeds and faster circuits. With anticipated gate delays of less than 5 picoseconds for 100-nm technologies and gate rise/fall time at approximately 10% of the clock period, microprocessors with 3-GHz on-chip clock frequency are within reach by 2006, and 20-GHz clock speeds on chip will ultimately follow. However, the resulting high-density circuits will be so complex that device interconnectivity will become the impeding factor in achieving the desired performance. Today’s high-end microprocessors require six levels of interconnection; designers anticipate as many as nine levels for the 100nm technology of 2006. The design challenges are many.	and gate;clock rate;fall time;image scaling;interconnection;microprocessor;semiconductor industry;simulation;the 100	Andreas C. Cangellaris	1998	IEEE Micro	10.1109/40.710871	chip;embedded system;telecommunications;computer science;modeling and simulation;internet connection sharing;microelectronics	EDA	14.110137978032819	57.74965728284014	75628
59036a9282f5291ad69247528271d5231bfd223a	deterministic seed selection and pattern reduction in logic bist	cadence encounter true time 13 1 atpg deterministic seed selection pattern reduction logic bist ad hoc technique random test patterns offline algorithm deterministic test patterns automatic test pattern generator seed activated linear feedback shift register lfsr design under test dut fault coverage iscas 89 designs;at speed testing lbist random patterns lfsr seed selection scan chain atpg misr dft;built in self test system on chip circuit faults vectors test pattern generators;shift registers automatic test pattern generation built in self test logic testing	A new ad-hoc technique to select the proper seed and the number of the random test patterns to be generated is presented. This technique uses an offline algorithm to search and classify the random patterns based on the deterministic test patterns generated by the automatic test pattern generator (ATPG). The seed activated linear feedback shift register (LFSR) generates exhaustive test patterns which are applied on any design under test (DUT). The responses are received at the output of the scan chains in the DUT and they are compressed to produce a signature. It is shown that this scheme produces the same fault coverage with lesser number of random test patterns than an arbitrary seed. Also, this technique helps to estimate the number of BIST test patterns to be generated to achieve specific fault coverage. Results on six ISCAS-89 designs with the help of Cadence Encounter true time 13.1 ATPG is shown.	device under test;fault coverage;hoc (programming language);linear-feedback shift register;logic built-in self-test;mike lesser;online algorithm;online and offline;seed;test card	Ramesh Bhakthavatchalu;Sreeja Krishnan;V. Vineeth;M. Nirmala Devi	2014	18th International Symposium on VLSI Design and Test	10.1109/ISVDAT.2014.6881039	electronic engineering;real-time computing;fault coverage;computer science;automatic test pattern generation;test compression;algorithm	EDA	20.632074866423626	51.58191781887388	76023
787da5d476bc8a4a62d3f1def0a8a19e93f694d2	integrated vlsi layout compaction and wire balancing on a shared memory multiprocessor: evaluation of a parallel algorithm	layout compaction;bbn butterfly machine vlsi layout compaction wire balancing shared memory multiprocessor parallel algorithm layout compaction dual transshipment problem;wire balancing;design automation;parallel algorithm;very large scale integration;dual transshipment problem;circuit layout;software performance evaluation;simplex method;physics computing;process design;very large scale integration compaction wire circuits parallel algorithms design automation process design parallel processing network topology physics computing;chip;wire;network topology;vlsi physical design;shared memory systems;compaction;vlsi;circuit layout cad;circuits;vlsi layout;bbn butterfly machine;shared memory systems vlsi parallel algorithms circuit layout cad circuit layout software performance evaluation;parallel processing;vlsi layout compaction;shared memory multiprocessor;parallel algorithms	We first present a unified formulation to three problems in VLSI physical design: layout compaction, wire balancing and integrated layout compaction and wire balancing problem. The aim of layout compaction is to achieve minimum chip width. Whereas wire balancing seeks to achieve minimum total wire length, integrated layout compaction and wire balancing seeks to minimize wire length maintaining the chip width at the optimum value. Our formulation is in terms of the dual transshipment problem. We then review our recent work on a parallel algorithm for the dual transshipment problem. We show how this algorithm called Modified Network Dual Simplex Method provides a unified approach to solve the three problems mentioned above and present experimental results. Our implementations have been on the BBN Butterfly machine. We draw attention to certain rather unusual results and argue that if the MNDS method is used then integrated layout compaction and wire balancing will achieve minimum chip width and a total wire length close to the optimum achieved by the wire balancing algorithm. >	data compaction;multiprocessing;parallel algorithm;shared memory;very-large-scale integration	Prasad R. Chalasani;Krishnaiyan Thulasiraman;M. A. Corneau	1994		10.1109/ISPAN.1994.367165	computer architecture;parallel computing;computer science;engineering drawing	HPC	14.589130744325132	52.2824418151819	76031
5734c35482b191fcd814d643366e89b7e41f7a3c	improved methods for worst-case analysis and optimization incorporating operating tolerances	fluctuations;integrated circuit;operant conditioning;worst case analysis;circuit topology;integrated circuit design;electronic design automation and methodology;circuit simulation;voltage;manufacturing;performance analysis;software package;performance bounds;integrated circuit synthesis;optimization methods manufacturing fluctuations performance analysis circuit optimization circuit simulation voltage circuit topology electronic design automation and methodology integrated circuit synthesis;circuit optimization;optimization methods	Worst-case analysis is commonly used in integrated circuit design to verify a satisfactory circuit performance with regard to changes in the manufacturing conditions. However, worst-case analysis is often carried out using approximate worst-case parameter sets, that do not consider fluctuations in the operating conditions. This paper presents a new approach to the worst-case design of integrated circuits that takes account of fluctuations in the operating conditions. It provides unique and realistic worst-case manufacturing conditions and worst-case operating conditions for given circuit specifications. These specifications may be either, minimum yield requirements or, lower and upper performance bounds. A software package for worst-case analysis and optimization is presented and illustrated by two examples.	approximation algorithm;best, worst and average case;integrated circuit design;mathematical optimization;program optimization;requirement	Helmut E. Graeb;Claudia U. Wieser;Kurt Antreich	1993	30th ACM/IEEE Design Automation Conference	10.1145/157485.164641	topology;control engineering;electronic engineering;voltage;engineering;electrical engineering;integrated circuit;operant conditioning;manufacturing;computer engineering;integrated circuit design	EDA	24.016641704176138	57.11956877891367	76095
9f1cc56976aef84f26eb5aa7fd835fca8ecb4571	optimization algorithms for the design of digital microfluidic biochips: a survey	digital microfluidic biochips;optimization algorithm;optimization technique;digital microfluidic biochip;design automation;successful biochip design;geometry level;biochip design automation work;physical level simulation;geometry level synthesis;design process complex;biochip design	Digital microfluidic biochip revolutionizes the medical diagnosis process rendering multiple tasks executed on a single chip. Incorporation of multiple functionality makes the design process complex and costly for digital microfluidic biochip. Physical simulation for the device components in a biochip is essential in todays manufacturing industry. In this paradigm, design automation and development of computer-aided-design tool that can perform physical level simulation and testing becomes crucial for a successful biochip design. This paper presents a comprehensive survey on design automation for biochip. Initially, a brief description on popular optimization techniques and some heuristic algorithms to solve various optimization problems is presented, followed by a review on biochip design automation works. Generally, architectural and geometry level synthesis for biochip design is performed using optimization techniques. Hence, some recent works on bioassay analysis, resource binding, and scheduling in geometry level are discussed. Finally the survey concludes with some possible future research directions.	algorithm	Indrajit Pan;Ritwik Mukherjee;Hafizur Rahaman;Tuhina Samanta;Parthasarathi Dasgupta	2013	Computers & Electrical Engineering	10.1016/j.compeleceng.2012.10.003	electronic engineering;bioinformatics;engineering	HCI	11.184567300835607	50.481174386651354	76326
22edfffe6e832e8586e9d9712de9a2433321a992	on valid clocking for combinational circuits	clocks combinational circuits delay latches pipeline processing sun;iscas benchmark circuits valid clocking combinational circuits clock period functionally sensitizable paths wavepipelined circuits path delays two vector model;combinatorial circuits;logic testing combinatorial circuits delays;logic testing;combinational circuit;delays	In this paper we consider the problem of determining a valid clock setting for a combinational circuit. The performance of a circuit depends on its clock period. The shorter a valid clock period is, the better the performance is. We rst consider the cases in which the primary input and output latches are triggered by the same clock signal but diierent phases. We have proposed two new bounds for clock period by considering a type of paths called functionally sensitizable paths. Then these results are extended to wavepipelined circuits. We have compared the new bounds with the previously proposed bounds and it has been shown that these new bounds may have better performance for certain combinational circuits. We have also given an example to show that the path delays obtained by two-vector model may not be valid when used for clock setting. The bounds on clock period can alternatively be viewed as optimization objectives. We present some experimental results to show various bounds on clock period for ISCAS benchmark circuits and discuss the potential complexity of optimizing circuits with these bounds.	benchmark (computing);clock rate;clock signal;combinational logic;input/output;logic gate;mathematical optimization	Shangzhi Sun;David Hung-Chang Du;Yaun-Chung Hsu;Hsi-Chuan Chen	1994		10.1109/ICCD.1994.331931	electronic engineering;real-time computing;asynchronous circuit;clock domain crossing;clock skew;computer science;combinational logic;synchronous circuit;clock gating;digital clock manager;algorithm;clock signal	EDA	19.40447652583879	51.43262188625301	76344
d5815c2b5ceb20df5636b8ef12a4fd971a052aae	verification of asynchronous circuits with bounded inertial gate delays	logic cad asynchronous circuits delays signal flow graphs ternary logic hazards and race conditions formal verification;ternary logic asynchronous circuits bounded inertial gate delays signal transition graph gate level implementation stg;signal flow graphs;asynchronous circuit;formal verification;hazards and race conditions;ternary logic;asynchronous circuits;logic cad;asynchronous circuits delay circuit simulation hazards circuit testing multivalued logic packaging signal generators circuit synthesis design engineering;delays	Veri fy ing t h e correctness of a synchronous circuit:; i s one of t h e m o s t i m p o r t a n t t a sk in asyn,ch,ron.ous des ign. However , t h e absence of t h e global clock u n d t h e var ia t ion of gate delays in asynchronous circui ts m a k e s t h e veri f icat ion a fo rmidab le ta sk . In th i s paper , a veri f icat ion me thod wh ich can cover all t h e devia t i o n o f gate-level i m p l e m e n t a t i o n of a n a s y n c h r o n m s circui t f r o m the specified behavior g i v e n by t h e STG i s proposed. The t e r n a r y logic i s used in order t o describe the behaviors of ga te s w i th bounded iner t ia l delays	correctness (computer science);delay calculation;i/o controller hub;star trek generations;synchronous circuit;triple des	J. Gong;Eddie M. C. Wong	1998		10.1109/ATS.1998.741646	asynchronous system;electronic engineering;real-time computing;logic optimization;asynchronous circuit;formal verification;computer science;theoretical computer science;logic simulation;sequential logic;programming language;clock signal	Vision	20.75458514473453	47.411609044561125	76346
742b6b33a6ec957cb7d934ec01be50d2dba06aa9	fast signature computation for linear compactors	detection probability;circuit faults;fault simulation;application software;very large scale integration;testing;circuit simulation;computational modeling;built in self test;compaction;central processing unit;circuit faults compaction built in self test computational modeling circuit simulation testing application software very large scale integration laboratories central processing unit	Compaction simulation time is a costly (CPU) process when performing fault simulation of BIST circuits. In this paper, we present a compaction simulation algorithm for linear compactors. Basic look-up operations are used to reduce compaction time significantly and memory requirements for the tables are small. With this algorithm, the compaction of an M-bit sequence by a k-bit linear compactor requires M + s2 7 k-bit words of memory where s, 1 and m can be any value such that T and f are integers, and where pAerr is the proportion of errors in the signature and pRSrr the proportion of errors in the CUT’S response. Both pRSTr and pAeTr range between [0,1]. However, for a large proportion of faults in a CUT, the detection probabilities are low, making pAS7? and pR,?? low as well. Simulation results demonstrating the speed of the compaction algorithm are given. + s pR.,, ) + operations and 12 x(‘ P A s r t	algorithm;built-in self-test;central processing unit;computation;data compaction;lookup table;requirement;simulation	D. Lambidonis;André Ivanov;Vinod K. Agarwal	1991		10.1109/TEST.1991.519746	compaction;computer architecture;electronic engineering;application software;computer science;operating system;central processing unit;software testing;very-large-scale integration;computational model;computer engineering	EDA	20.034622383883896	49.97694506141428	76452
5c93dff5cd9770b898bb1fcc68b78809336d828b	topology exploration for energy efficient intra-tile communication	communication architecture;total chip energy;esb bus;energy efficient intra-tile communication;star topology;standard linear bus topology;optimal topology;energy optimal netlist;topology exploration;energy efficient architecture style;minimum energy operation;netlist topology;chip;energy optimization;energy efficient	With technology nodes scaling down, the energy consumed by the on-chip intra-tile interconnects is beginning to have a significant impact on the total chip energy. The energy-optimal sectioned bus (ESB) template is an energy efficient architecture style for on-chip communication between components. To achieve minimum energy operation, the netlist topology of the ESB bus should however be optimized accordingly. In this paper we present a strategy for the definition of an energy optimal netlist for the ESB bus. An initial floorplanning stage provides information about the eventual lengths of the interconnect wires and a subsequent exploration step defines the optimal topology for the communication architecture. We motivate that a star topology generated using wire length prediction can be up to a factor 4 more energy efficient compared to standard linear bus topologies.	a* search algorithm;bus network;electrical connection;floorplan (microelectronics);image scaling;netlist;run-length encoding;star network	Jin Guo;Antonis Papanikolaou;Francky Catthoor	2007	2007 Asia and South Pacific Design Automation Conference		chip;embedded system;electronic engineering;star network;telecommunications;computer science;engineering;efficient energy use;engineering drawing;bus network	EDA	15.226292102700205	54.81694378411033	76471
7f4372d0dd859f5e10b21612e344cbdf8d06e8d9	a temperature-aware placement and routing algorithm targeting 3d fpgas		In current reconfigurable architectures, the interconnect structures increasingly contribute to the delay and power consumption budget. The demand for increased clock frequencies and logic availability (smaller area foot print) makes the problem even more important, leading among others to rapid elevation in power density. Three-dimensional (3D) architectures are able to alleviate this problem by accommodating a number of functional layers, each of which might be fabricated in different technology. Since power consumption is a critical challenge for implementing applications onto reconfigurable hardware, a novel temperature-aware placement and routing (P&R) algorithm targeting 3D FPGAs, is introduced. The proposed algorithm achieves to redistribute the switched capacitance over identical hardware resources in a rather “balanced” profile, reducing among others the number of hotspot regions, the maximal values of power sources at hotspots, as well as the percentage of device area that consumes high power. For evaluation purposes, the proposed approach is realized as a new CAD tool, named 3DPRO (3D-Placement-and-Routing-Optimization), which is part of the complete framework, named 3D MEANDER. Comparing to alternative solutions, the proposed one reduces the percentage of silicon area that operates under high power by 63%, while it leads to energy savings (about 9%), with an almost negligible penalty in application’s delay ranging from 1% up to 5%.	algorithm;clock rate;computer-aided design;field-programmable gate array;hotspot (wi-fi);java hotspot virtual machine;maximal set;norm (social);place and route;power management;reconfigurable computing;routing	Kostas Siozios;Dimitrios Soudris	2008		10.1007/978-3-642-12267-5_12	embedded system;electronic engineering;real-time computing;engineering	EDA	13.949887515079801	54.57283202411516	76545
b2c06947cb676fb3e84c01415f3aa7f6248ffa8e	implementing a fuzzy processor on programmable logic circuits: modularization criteria	programmable logic	In this communication, we propose a scheme for implementing a fuzzy processor on pro-grammable logic circuits (FPGA), utilizing pipelined structures. We have partitioned the processor structure in several sections, which correspond to diierent i n tegrated circuits. Such I.C. carry out the operations in-herents in a fuzzy process (fuzziiers, inference engine, defuzziiers) in a very eecient an exible manner maintaining a low cost per prototype.	field-programmable gate array;fuzzy logic;inference engine;logic gate;programmable logic device;prototype	Esperanza M. López;Alfonso Aniorte Carbonell;Ramón Ruiz Merino	1999			solar mirror;deformation (mechanics);deformation (engineering);mechanics;electronic circuit;yield (engineering);algorithm;membrane;function block diagram;computer science;planar	EDA	11.91839529404795	48.51659659770986	76726
6526cc6b3d9dc4971150f8f81a6733d0221819c4	enhancing bist quality of sequential machines through degree-of-freedom analysis	vlsi built in self test sequential circuits sequential machines fault diagnosis integrated circuit testing automatic testing;sequential machines;degree of freedom;automatic testing;sequential circuits;built in self test circuit testing sequential circuits circuit faults strontium computer science automatic testing flip flops test pattern generators sequential analysis;at speed testing bist quality sequential machines degree of freedom analysis sequential circuits input sequence uniform mobility degree of freedom reachability emittability fault efficiency nonscan scheme test application time vlsi fault efficiencies;built in self test;integrated circuit testing;vlsi;fault diagnosis	Designing a BIST structure for sequential circuits is rather a complex problem as some states remain unreachable and some act as the sink under any input sequence. This paper reports an efficient scheme to provide uniform mobility, referred to as degree of freedom, in a sequential machine by enhancing the reachability as well as the emittability of the states. The uniform mobility of states ensures higher fault efficiency in a BIST structure of the circuit. Moreover, as a non-scan scheme, the technique provides lower test application time and at-speed testing.	built-in self-test	Biplab K. Sikdar;Samir Roy;Debesh Kumar Das	2001		10.1109/ATS.2001.990297	electronic engineering;real-time computing;computer science;engineering;automatic test pattern generation;sequential logic;very-large-scale integration;degrees of freedom;algorithm	EDA	21.456246037481737	51.170242462904575	76761
1a8235efe32b14e3297600e607c5b148f6d94317	accurate prediction of the impact of on-chip inductance on interconnect delay using electrical and physical parameter-based rsf	response surface methodology;inductance wire delay estimation electronic design automation and methodology process design integrated circuit interconnections response surface methodology delay effects rlc circuits system on a chip;vlsi inductance integrated circuit interconnections response surface methodology integrated circuit modelling delay estimation;chip;design rules;100 nm on chip inductance interconnect delay on chip wire delay response surface functions rc wire model rlc wire model parameter variations wire resistance wire capacitance rlc delay calculation;integrated circuit modelling;integrated circuit interconnections;vlsi;inductance;response surface;delay estimation;resistance capacitance	This paper proposes a new methodology to accurately predict the impact of inductance on on-chip wire delay using response surface functions (RSF). The proposed methodology consists of two stages which involves first calculating the delay difference between RC and RLC wire models for a set of parameter variations, then building RSFs using electrical parameters such as wire resistance, capacitance, etc., and physical parameters such as wire width, pitch, etc. as variables. The proposed methodology can help 1) to define design rules for avoiding inductance effects, 2) to point out wires that require RLC delay calculation, and 3) to estimate and correct the delay when using an RC model. An example design rule for limiting self inductance and accurate estimation of the delay difference for a 100 nm technology node is also presented.	delay calculation;rlc circuit;radio-controlled model;reasonable server faces;response surface methodology;semiconductor device fabrication;wire wrap	Takashi Sato;Toshiki Kanamoto;Atsushi Kurokawa;Yoshiyuki Kawakami;Hiroki Oka;Tomoyasu Kitaura;Hiroyuki Kobayashi;Masanori Hashimoto	2003		10.1145/1119772.1119802	equivalent series inductance;embedded system;electronic engineering;response surface methodology;delay calculation;telecommunications;computer science;engineering;electrical engineering;power network design	EDA	23.143772639133058	56.78922656841633	76767
7073d228b560a46c0b1fcec86d89aa28f3266cc6	gate-level aged timing simulation methodology for hot-carrier reliability assurance	cmos integrated circuits;slew rate propagation method;aging;full chip circuit capacity;circuit simulation;integrated circuit modelling;degradation sensitive critical paths;ageing;i v characteristics;vlsi;hot carriers;gate primitive decomposition method;integrated circuit reliability;hot carrier reliability assurance;transistor level approach;clock skew;gate level aged timing simulation methodology;stress representation;compact model;ratio based model;timing	This paper presents a new aged timing simulation methodology that can be used for hot-carrier reliability assurance of VLSI. This methodology consists of a compact model and a unique algorithm. The ratio based model simplifies the aging I-V characteristics of MOSFET over time into the aged timing and the corresponding ratio at gate-level. A new algorithm is proposed including a gate primitive decomposition method and an aged slew rate propagation method. This algorithm provides good stress representation and can achieve comparable accuracy with the conventional transistor-level approach. The above methodology has been implemented in a new simulator. Experimental results demonstrate that the simulator based on this methodology realizes full-chip circuit capacity and can be applied to various reliability analyses including degradation-sensitive critical paths and clock skew.	simulation;timing closure	Yoshiyuki Kawakami;Jingkun Fang;Hirokazu Yonezawa;Nobufusa Iwanishi;Lifeng Wu;Alvin I-Hsien Chen;Norio Koike;Ping Chen;Chune-Sin Yeh;Zhihong Liu	2000		10.1109/ASPDAC.2000.835112	ageing;embedded system;electronic engineering;real-time computing;computer science;engineering	EDA	21.55760947361469	55.49465720467518	76781
21662eaf3c4dffc1683326060c3ba2e6f53cc046	quantitative analysis of very-low-voltage testing	static cmos chips;cmos integrated circuits;whi;test conditions;early life failures;test speed;failure analysis;rated conditions;low voltage;very low voltage testing;threshold voltage;integrated circuit noise integrated circuit testing cmos integrated circuits vlsi failure analysis;supply voltage;integrated circuit testing;vlsi;quantitative analysis;vlsi quantitative analysis very low voltage testing static cmos chips supply voltage threshold voltage rated conditions early life failures test conditions test speed;integrated circuit noise;threshold voltage circuit testing cmos technology delay circuit simulation cmos integrated circuits integrated circuit noise cmos digital integrated circuits cmos process mosfets	Some weak static CMOS chips can be detected by testing them with a very low supply voltage -between 2 and 2.5 times the threshold voltage Vt of the transistors. A weak chip is one that contains a flaw -an imperfection that does not interfere with correct operation at rated conditions but which may cause intermittent or early-life failures. This paper considers several types of flaws and derives the test conditions for them. It also proposes two approaches for determining the appropriate test speed for very-low-voltage testing.	burn-in;cmos;deployment environment;flaw hypothesis methodology;gate oxide;integrated circuit;sensor;software bug;transistor	Jonathan T.-Y. Chang;Edward J. McCluskey	1996		10.1109/VTEST.1996.510876	reliability engineering;embedded system;failure analysis;electronic engineering;quantitative analysis;engineering;electrical engineering;very-large-scale integration;threshold voltage;low voltage;cmos	SE	22.52241353947946	54.31467987658885	76791
3d48bba91d3ac6112c1603c0bd8fe375dcf9d677	the complexity of fault detection in mos vlsi circuits	concepcion circuito;puerta logica;mos technology;etude theorique;circuit design;circuit vlsi;tecnologia mos complementario;test;vlsi fault location logic gates logic testing mos integrated circuits;electrical fault detection very large scale integration cmos logic circuits robustness logic testing logic gates circuit faults circuit testing mos devices logic design;ensayo;algorithme;porte logique;algorithm;essai;vlsi circuit;detection defaut;logic gates;fault detection;mos integrated circuits;logic testing;estudio teorico;vlsi;tecnologia mos;conception circuit;transistor level test generation tools fault detection mos vlsi circuits channel connected subcircuit decision subproblems test vector initializing vector test pair np complete nmos cmos logic gates linear complexity stuck open fault subtest pair linear time algorithm;circuito vlsi;theoretical study;technologie mos complementaire;initialization vector;logic gate;deteccion imperfeccion;series parallel;complementary mos technology;technologie mos;defect detection;algoritmo;fault location	This paper considers the fault detection problem for a single fault in a single MOS channel-connected subcircuit. We identify the following three decision sub-problems : (i) decide if a test vector exists; (ii) decide if an initializing vector exists; and (iii) decide if a test pair is robust. We prove that each of these problems is NP complete. More importantly, we prove that the rst two remain NP complete for the simplest subcircuit design styles, namely series/parallel nMOS or CMOS logic gates. The third subproblem is shown to be of linear complexity for a CMOS logic gate with a stuck-open fault. We illustrate that a test pair that is not robust may contain a robust sub-test pair, and give a necessary and su cient condition for this to happen in CMOS logic gates. This leads to a linear-time algorithm for CMOS logic gates which tests for robustness and, if possible, derives a robust test pair from a possibly non-robust pair. The implications of these complexity results on practical transistor-level test generation tools are discussed. This work was supported by the Semiconductor Research Corporation under Contract SRC RSCH 84-06-049. y F. N. Najm is now with the Semiconductor Process and Design Center, Texas Instruments Inc., P.O. Box 655621, MS 369, Dallas, Texas 75265	algorithm;cmos;fault detection and isolation;logic gate;nmos logic;np (complexity);np-completeness;semiconductor research corporation;test vector;time complexity;transistor;very-large-scale integration	Farid N. Najm;Ibrahim N. Hajj	1990	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.59075	and-or-invert;electronic engineering;logic gate;computer science;engineering;electrical engineering;algorithm	EDA	16.984281024077205	49.80615872886041	76801
01369a2366bb6571f09485f6cdb8f37cc7a42049	analysis of time-dependent dielectric breakdown induced aging of sram cache with different configurations		Article history: Received 21 May 2017 Received in revised form 11 June 2017 Accepted 20 June 2017 Available online xxxx Time dependent dielectric breakdown degrades the reliability of SRAM cache. A novel methodology to estimate SRAMcache reliability andperformance is presented. The performance and reliability characteristics are obtained from activity extraction and Monte Carlo simulations, considering device dimensions, process variations, the stress probability, and the thermal distribution. Based on the reliability-performance estimation methodology, caches with various settings on associativity, cache line size, and cache size are analysed and compared. Experiments show that there exists a contradiction between performance and reliability for different cache configurations. Understanding the variation of performance and reliability can provide SRAM designers with insight on reliability-performance trade-offs for cache system design. © 2017 Published by Elsevier Ltd.	benchmark (computing);best, worst and average case;big data;btrieve;cpu cache;duty cycle;experiment;hot-carrier injection;instability;microprocessor;monte carlo method;simulation;static random-access memory;systems design;worst-case scenario	Rui Zhang;Taizhi Liu;Kexin Yang;Linda S. Milor	2017	Microelectronics Reliability	10.1016/j.microrel.2017.06.040	parallel computing;static random-access memory;electronic engineering;cache;engineering;dielectric strength;systems design;cpu cache;monte carlo method	EDA	20.529046444500633	59.37439480406332	76819
92ba8ccf39c9577b1664610f2c83f5596002dada	canonical ordering of instances to immunize the fpga place and route flow from eco-induced variance	fpga place and route flow post routing delay variance random instance shuffling zero variance post packer place and route flow isolation perturbation minimization fast canonical ordering technique design iteration timing constraints nongreedy heuristics fast greedy heuristics instance list order variation predictability variance reduction technique embedded system companies design optimization solution space exploration fpga tools pre eco stage post routing delay characteristics circuit netlist technological problem correction timing problem correction functional problem correction design changes fpga based design engineering change order eco induced variance;integrated circuit layout;logic design;timing circuits;network routing;canonical ordering place and route eco delay variance;embedded systems;field programmable gate arrays delays routing noise algorithm design and analysis table lookup;delay circuits;timing circuits circuit optimisation delay circuits embedded systems field programmable gate arrays integrated circuit layout logic design network routing;field programmable gate arrays;circuit optimisation	Engineering change order (ECO)s for FPGA-based designs often require design changes late in the design process in order to correct functional, timing, and/or technological problems. Typically, after an ECO process a small portion of the circuit netlist is changed. To take advantage of the enormous resources and time already spent on place and route flow, it is desirable to maintain similar post-routing delay characteristics to the pre-ECO stage to avoid further expensive design iterations. Most FPGA tools use the variance to their advantage to explore the solution space in the design optimization phase. FPGA companies can afford to run multiple passes and just retain the best solution. The embedded systems companies cannot afford multiple pass compile times especially in ECO situations. Note that the variance reduction technique proposed in this paper is applicable only in the ECO situations and not during design optimization phase where variance plays an advantageous role. Predictability is not just unique to ECO, but success of an ECO is highly dependent on predictability and that's where the proposed approach plays a crucial role. The ECO process may change a small subset of the circuit netlist, which may result in a minor variation in the instance list order seen by the packer. Most packing heuristics, including fast greedy heuristics as well as relatively slower non-greedy heuristics, process the input netlist in a certain order and have varying degrees of dependence on the initial instance order. Even a slight variation may result in a substantially different packing and the subsequent placement and routing results may also change. In the worst case, the post-routing delay may fail timing constraints and require inexpensive design iteration. In this paper, we propose a fast canonical ordering technique that either guarantees a unique instance order if the ECO process caused a change in the initial instance order or minimizes the perturbation to the instance order as seen by the packer stage from any significant ECO-induced change to the initial instance order. This helps in isolating the postpacker place and route flow from netlist changes and drastically reduces the variance in post routing delay. Experimental results demonstrate zero variance against random shuffling of instances before the packer stage (to simulate an ECO scenario). Experimental results for other non-functional or slight functional modifications to the input netlist show greatly reduced post-routing delay variance.	best, worst and average case;compiler;embedded system;engineering change order;executable compression;feasible region;field-programmable gate array;greedy algorithm;heuristic (computer science);iteration;mathematical optimization;netlist;place and route;quadrature mirror filter;routing;semiconductor;set packing;simulation;turing completeness;variance reduction	Avijit Dutta;Neil Tuttle;Krishnan Anandh	2013	International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2013.6523635	embedded system;mathematical optimization;routing;electronic engineering;logic synthesis;real-time computing;simulation;computer science;operating system;integrated circuit layout;algorithm;field-programmable gate array	EDA	16.58876716914236	52.71428032578584	76866
700a0d7dbc643203e16b596acc0efd6bbf8a23e9	a fast graph-based alternative wiring scheme for boolean networks	redundancy addition and removal;graph theory;area reduction fast graph based alternative wiring scheme boolean networks graph based local pattern search methods rewiring tool minimal graph patterns cpu time reduction sis algebraic operations netlist perturbing engine logic minimization;assignment problem;integrated circuit layout;graph based local pattern search methods;boolean functions;minimisation of switching nets;automatic test pattern generation;automatic testing;search problems vlsi minimisation of switching nets integrated circuit layout circuit layout cad high level synthesis integrated logic circuits graph theory network topology;search method;automatic logic units;wires;logic circuits;sis algebraic operations;area reduction;netlist perturbing engine;graph matching;logic minimization;birth disorders;graph based pattern matching;network topology;high level synthesis;logic synthesis;boolean networks;rewiring tool;fast graph based alternative wiring scheme;boolean network;logic testing;vlsi;quantitative analysis;circuit layout cad;circuit testing;test pattern generator;search problems;integrated logic circuits;wiring;cpu time reduction;minimal graph patterns;alternative wiring;forward search;wiring wires logic testing circuit testing automatic test pattern generation birth disorders automatic logic units boolean functions logic circuits automatic testing	Alternative wiring techniques have been shown to be very useful for many EDA problems. The currently used rewiring techniques are mainly ATPG based. In this paper, we study the approach of applying purely graph-based local pattern search methods in locating alternative wires. The method searches minimal graph patterns containing alternative wires that limited to 2 edges distant from the target wire. The experimental result shows that this scheme is very fast and has the advantage of searching both the nearby forward and backward alternative wires easily. The overall number of alternative wires searched is quite comparable (104%), compared to the forward search only RAMBO version [10], [11], and the CPU time is 200 times faster. We also illustrate its usage, among many others, by a simple coupling with the SIS algebraic operations and let this rewiring tool serve as a netlist-perturbing engine for logic minimization. The coupling scheme shows a further reduction of 8.5% in area compared to applying algebraic script alone, with a nearly negligible CPU overhead spent in rewiring. key words: rewiring, logic synthesis, circuit minimization, re-	boolean network;central processing unit;circuit minimization for boolean functions;electronic design automation;logic synthesis;netlist;overhead (computing);pattern search (optimization);wiring	Yu-Liang Wu;Wangning Long;Hongbing Fan	2000		10.1109/ICVD.2000.812620	electronic engineering;discrete mathematics;logic synthesis;boolean network;logic gate;computer science;quantitative analysis;graph theory;theoretical computer science;automatic test pattern generation;mathematics;assignment problem;integrated circuit layout;very-large-scale integration;boolean function;high-level synthesis;network topology;algorithm;matching	EDA	16.86559479586033	49.26855474096241	76918
20659b92bbd3ee62458f255a92a067e7df898a11	hierarchical partitioning	design hierarchy;partitioning;logic emulation;clustering;fpgas;logic partitioning;logic cad	Partitioning of digital circuits has become a key problem area during the last five years. Benefits from new technologies like Multi-Chip-Modules or logic emulation strongly depend on partitioning results. Most published approaches are based on abstract graph models constructed from flat netlists, which consider only connectivity information. The approach presented in this paper uses information on design hierarchy in order to improve partitioning results and reduce problem complexity. Designs up to 150k gates have been successfully partitioned by descending and ascending the hierarchy. Compared to a standard k-way iterative improvement partitioning approach results are improved by up to 65% and runtimes are decreased by up to 99%.	binary space partitioning;digital electronics;emulator;iterative method;netlist	Dirk Behrens;Klaus Harbich;Erich Barke	1996	Proceedings of International Conference on Computer Aided Design	10.1145/244522.244861	embedded system;discrete mathematics;computer science;theoretical computer science;cluster analysis;algorithm;field-programmable gate array	EDA	15.40528742582267	49.30838310019172	77145
6308902a4ae338f39fc5f868b962419cb6051b64	clock gating effectiveness metrics: applications to power optimization	cycle time;clock gating efficiency;optimisation;clock gating logic;instruments;cost function;power estimation;clocks;logic;optimisation application specific integrated circuits clocks logic circuits low power electronics;biological system modeling;logic circuits;physical design;clock gating;design optimization;clocks design optimization signal synthesis registers instruments timing cost function application specific integrated circuits logic quality assessment;quality assessment;logic gates;estimation;registers;application specific integrated circuits;low power electronics;power optimization;optimization;signal synthesis;size 65 nm clock gating effectiveness metrics power estimation clock gating logic power optimization clock gating efficiency;switches;size 65 nm;clock gating effectiveness metrics;timing	Effective implementation and efficient utilization of clock gating logic is a critical element for dynamic power optimization. In this paper we propose three new clock gating effectiveness metrics to assess the quality of clock gating. We then propose applications of these metrics combined with RT level activity profiles, that enable accurate power estimation at downstream physical design stages. The approach apart from providing power optimization quality assessment, also provides 10X improvement in power estimation cycle time. Results on a 65 nm design have been presented to prove the claim.	clock gating;critical graph;downstream (software development);mathematical optimization;physical design (electronics);power optimization (eda)	Jithendra Srinivas;Madhusudan Rao;Sukumar Jairam;H. Udayakumar;Jagdish C. Rao	2009	2009 10th International Symposium on Quality Electronic Design	10.1109/ISQED.2009.4810342	control engineering;embedded system;electronic engineering;real-time computing;logic gate;computer science;operating system	Arch	15.580344676056818	54.55203567477793	77228
3a5389216486949065ae7d64860b4eae79d031d6	re-configurable embedded core test protocol	hardware overhead;popular test methodology;expensive automatic test equipment;re-configurable embedded core test;conventional soc test method;test server;new test protocol;embedded test protocol;test protocol;test parameter;test packet;chip;automatic test equipment;test methods;system on chip	We report on a new, reconfigurable, packet-based, embedded test protocol that supports several popular test methodologies (boundary scan, full-scan and BIST among others) for testing multi-core SOCs. Unlike the conventional SOC test methods that require use of an expensive automatic test equipment, our proposal uses on-chip embedded cores that serve as microtesters. The protocol is implemented using two embedded cores: Test Server and Test Client. The Test Server delivers test parameters as test packets to Test Clients. Experimental results show that our new test protocol can be implemented with low (less than 2%) hardware overhead. Since hardware overhead for our test protocol does not grow as the size of SOCs, it will be even lower for large SOCs.	boundary scan;built-in self-test;built-in test equipment;embedded system;multi-core processor;network packet;overhead (computing);system on a chip;turing test	Seongmoon Wang;Srimat T. Chakradhar;Kedarnath J. Balakrishnan	2004	ASP-DAC 2004: Asia and South Pacific Design Automation Conference 2004 (IEEE Cat. No.04EX753)	10.1145/1015090.1015145	chip;system on a chip;embedded system;automatic test equipment;real-time computing;white-box testing;telecommunications;integration testing;computer science;automatic test pattern generation;operating system;test compression;test method;test management approach;test harness	EDA	10.5899091240277	53.92423770205103	77311
30957eea47a02e1897be327d12235c59547253d0	diagnosis in modern design - just the tip of the iceberg	silicon;impedance;art;software libraries;testing;computer hacking;research and development;modems testing productivity research and development software libraries art computer hacking silicon impedance costs;modems;productivity	When test is done right, that is to an acceptable quality specification (and without impeding productivity and cost), defective parts fail the screening process. Without splitting hairs on definition, diagnosis and debug digs deeper to determine why the part is unacceptable. Troubleshooting how and why a part (or system) fails is important. For example, this may be needed for yield improvement, process monitoring, debugging the design function, failure mode learning for R&D, or just getting a working first prototype. But the detective work can become tricky. One reason for this is that, while many segments of the product creation flow (e.g. the design and test development flows) have benefited from years of study and automation, diagnosis has somewhat lagged in the formalization of techniques. Also, the test floor equipment have been traditionally designed and operated for pass/fail oriented testing. Unless this situation improves, an effective diagnosis-friendly environment may be elusive when it is needed most.	debugging;failure cause;prototype	Fidel Muradali	2003		10.1109/TEST.2003.1271142	embedded system;electronic engineering;productivity;engineering;electrical engineering;software engineering;electrical impedance;software testing;silicon;computer engineering	SE	23.915315715723132	53.80796188639063	77312
8d9b3071f60a10cf903a29a39bb9cbb3c04313eb	case study of yield learning through in-house flow of volume diagnosis	silicon;si yield learning in house flow volume diagnosis statistical analysis physical failure analysis economical way single iteration industrial cases;integrated circuit layout;yield learning volume diagnosis layout aware diagnosis;elemental semiconductors;failure analysis;integrated circuit design;statistical analysis digital integrated circuits elemental semiconductors failure analysis integrated circuit design integrated circuit layout silicon;statistical analysis;digital integrated circuits;failure analysis silicon integrated circuits systematics statistical analysis production layout	To find out the root causes of yield loss is always expensive and time-consuming. In this paper, we have developed an in-house flow of volume diagnosis. With the power of performing statistical analysis on the large volume of diagnosis results, we demonstrate that to do physical failure analysis could be in a more economical way. By utilizing the in-house flow of volume diagnosis, we could find out the defects which cause the yield loss primarily with only a few samples of failing dies in a single iteration. The industrial cases demonstrate the efficiency proved by the silicon data.	die (integrated circuit);failure analysis;iteration	Pei-Ying Hsueh;Shuo-Fen Kuo;Chao-Wen Tzeng;Jih-Nung Lee;Chi-Feng Wu	2013	2013 International Symposium onVLSI Design, Automation, and Test (VLSI-DAT)	10.1109/VLDI-DAT.2013.6533861	physical design;electronic engineering;engineering;operations management;circuit extraction;engineering drawing	Arch	23.319363162622192	55.59603502600946	77354
c09614859631218587f293855ca4a38c1e867cc0	screening minvdd outliers using feed-forward voltage testing	feedforward systems;nearest neighbor searches;nearest neighbor residual statistical post processing;bist;full vector set search routines;vdd burn in shifts;feed forward full vector set low voltage testing;feed forward;feedforward;integrated circuit yield;fvs;logic design;delta vdd;minvdd outlier screening;rvs fvs correlation data;boundary scan testing;failure analysis;scan testing;low voltage;feedforward systems large scale integration logic testing production logic design low voltage nearest neighbor searches costs integrated circuit testing laboratories;built in self test;large scale integration;statistical analysis;nearest neighbor;logic testing;integrated circuit testing;reduced vector set binary search;production;binary search;vdd burn in shifts bist failure analysis scan testing minvdd outlier screening feed forward voltage testing minvdd testing full vector set search routines test time reduced vector set binary search rvs intrinsic defect free minvdd die measurements feed forward full vector set low voltage testing fvs delta vdd nearest neighbor residual statistical post processing spp rvs fvs correlation data minvdd yield fallout;test time;feed forward voltage testing;rvs;integrated circuit reliability;statistical analysis integrated circuit testing integrated circuit reliability logic testing integrated circuit yield built in self test failure analysis boundary scan testing feedforward;spp;intrinsic defect free minvdd die measurements;correlated data;minvdd testing;minvdd yield fallout	MinVDD testing using full vector set search routines consumes too much test time. A 3-step process is proposed using: (1) a reduced vector set (RVS) binary search to measure the intrinsic (defect free) minVDD for a die; (2) a feed-forward to the full vector set (FVS) for low voltage testing; and (3) delta VDD and nearest neighbor residual statistical post-processing (SPP) are applied to the data to screen the minVDD outliers that are identified using the RVS binary search. RVS vs. FVS correlation data is shown on 3 products. Data shows minVDD yield fallout of 0.2-0.8% and 20% of the minVDD outliers shows significant VDD shifts in burn-in.		Robert Madge;B. H. Goh;V. Rajagopalan;C. Macchietto;W. Robert Daasch;Chris Schuermyer;C. Taylor;David Turner	2002		10.1109/TEST.2002.1041819	electronic engineering;real-time computing;computer science;engineering;feed forward;statistics	HCI	22.63860978853565	55.17259064804521	77374
a2f519ee442a8627a334928fdfadfc4ec664f22e	the changing semiconductor industry: from components to silicon systems	personal computer;mobile phone;technological forecasting electronics industry;electronics industry;mobile communication;growth rate;electronics industry silicon random access memory production microcomputers mobile communication mobile handsets electronic equipment fluctuations aging;business boom semiconductor industry semiconductor market trend continued growth silicon design;technological forecasting	Over the last 30 years the global semiconductor market has grown at an average rate of 17 %, to its present size of $130 billion/year. And it is not showing any signs of slowing. With the advent of the personal computer and more recently the growth of mobile communications, especially mobile phones, the semiconductor content of electronic equipment has been rising dramatically. This trend will only continue as devices get smarter and estimates predict the continued growth of the semiconductor industry to a figure of almost $250 billion/year by 2003.	mobile phone;personal computer;semiconductor industry;silicon systems	Theo A. C. M. Claasen	1999		10.1109/EURMIC.1999.793131	simulation;engineering;electrical engineering;operations management	ML	10.276486085311621	56.537881555804006	77415
eece636d9d2593ec02ade558c01992665a465339	true single-phase energy-recovering logic for low-power, high-speed vlsi	energy efficiency;very large scale integration clocks cmos logic circuits adders energy consumption frequency latches energy dissipation logic devices logic circuits;carry lookahead adder;pass transistors;multiple clock generators;mosis;low energy;clocks;energy efficient;very large scale integration;energy recovery;low swing;clock skew management problems;0 5 micron;clock distribution networks;interconnect network;pipelined carry lookahead adders;dynamic logic;circuit simulation;mos logic circuits;low power;high speed vlsi;energy consumption;system design;adders;adder architecture;80 to 280 mhz single phase energy recovering logic high speed vlsi low power electronics dynamic logic families cascaded gates multi phase clocks multiple clock generators energy consumption clock distribution networks clock skew management problems energy efficiency operating speed hspice simulations pipelined carry lookahead adders adder architecture vlsi system design mosis 0 5 micron;low power electronics;fpgas;hspice simulations;cascade networks;vlsi;80 to 280 mhz;dual voltage;operating speed;adders high speed integrated circuits vlsi low power electronics mos logic circuits cascade networks clocks spice circuit simulation;dynamic logic families;multi phase clocks;embedded;clock distribution network;spice;clock skew;high speed;single phase energy recovering logic;power;high speed integrated circuits;vlsi system design;cascaded gates	In dynamic logic families that rely on energy recovery to achieve low energy dissipation, the flow of data through cascaded gates is controlled using multi-phase clocks. Consequently, these families require multiple clock generators and can exhibit increased energy consumption on their clock distribution networks. Moreover, they are not attractive for high-speed design due to clock skew management problems. In this paper, we present TSEL, the first energy-recovering logic family that operates with a single-phase clocking scheme. TSEL outperforms previous energy-recovering logic families in terms of energy efficiency and operating speed. In IISPICE simulations with a standard 0.5µm technology from MOSIS, pipelined carry-lookahead adders in TSEL function correctly for operating frequencies exceeding 280MHz. For operating frequencies above 80MHz, they dissipate considerably less energy per operation than alternative implementations of the same adder architecture in other energy-recovering logic families. In comparison with their CMOS counterparts, the TSEL adders dissipate about half as much energy at 280MHz. Our results indicate that TSEL is an excellent candidate for high speed and low power VLSI system design.	adder (electronics);cmos;clock rate;clock signal;clock skew;dataflow;logic family;low-power broadcasting;mosis;parsing;simulation;systems design;very-large-scale integration	Suhwan Kim;Marios C. Papaefthymiou	1998		10.1145/280756.280879	embedded system;electronic engineering;parallel computing;real-time computing;computer science;efficient energy use;very-large-scale integration	Arch	16.846960995858243	57.48900069412058	77486
1943da8042c89a8f0902679fcf3f4a3e28a108fa	current status and future prospect of phase change memory	reliability phase change memory pram nonvolatile memory electrical characteristic;phase change;random access memory;phase change memories;phase change memories circuit reliability;phase change random access memory;solid state circuits;circuit reliability;nonvolatile memory;non volatile memory;phase change memory;phase change random access memory solid state circuits nonvolatile memory	This paper reviews recent progress and future outlook of PRAM as a promising candidate for emerging non-volatile memory. Electrical characteristics and reliability issues of PRAM with scale-down of the device dimension are discussed. Despite remarkable progress of PRAM properties in recent last decades, there are still several fundamental issues to resolve for broadening its application area. Several suggestions to overcome these property issues are introduced with recent experimental results.	microsoft outlook for mac;non-volatile memory;phase-change memory;volatile memory	Byeungchul Kim;Yoon-Jong Song;Sujin Ahn;Younseon Kang;Hoon Jeong;Dongho Ahn;Seokwoo Nam;Gitae Jeong;Chilhee Chung	2011	2011 9th IEEE International Conference on ASIC	10.1109/ASICON.2011.6157176	psychology;interleaved memory;electronic engineering;semiconductor memory;parallel computing;sense amplifier;memory refresh;artificial intelligence;computer memory	Robotics	12.918384309120023	59.5767804447368	77990
abcd50b7d61797317c01c75e6c0f8e6d67014bab	design methodology for area and energy efficient oxram-based non-volatile flip-flop		With the introduction of the Internet of Things (IoT), power consumption became a major design issue in modern system-on-chips. In advanced technologies, leakage power has become a dominant component, especially during sleep periods. Leakage mainly comes from volatile memory elements, e.g., flip-flops that cannot be power-gated in order to retain their states. Non-Volatile Flip-Flop (NVFF) using emerging memory technologies, such as Resistive Random Access Memories (RRAM), are popular solutions to address this issue. In NVFF design, the resistance values of the memory element have a direct impact on the area and energy overhead of the structure. In this paper, we present a design methodology for area and energy efficient RRAM-based NVFF. By characterizing the optimal lower bound of the RRAM resistance ratio required for properly restoring the FF, the store and restore operations can be performed using optimal programming circuit area and energy. Four Transmission-Gate (TG) NVFF topologies implemented in 180nm CMOS technology were analyzed using the proposed methodology. The presented methodology shows that differential NVFF provides minimum restore resistance ratio down to 1.02 considering CMOS and RRAM variability. This enables improvements in terms of store energy (34%) and area overhead (40%) compared to reported state-of-the-art NV-TGFFs design approaches.	cmos;flops;heart rate variability;internet of things;logic gate;non-volatile memory;nv network;overhead (computing);power glove;random access;resistive random-access memory;spectral leakage;volatile memory	M. Nataraj;A. Levisse;Bastien Giraud;Jean-Philippe Noël;Pascal Andreas Meinerzhagen;Jean Michel Portal;Pierre-Emmanuel Gaillardon	2017	2017 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2017.8050759	flip-flop;electronic engineering;network topology;computer science;efficient energy use;resistive random-access memory;volatile memory;embedded system;energy storage;random access;cmos	EDA	17.913208597097427	59.20257333052696	78263
d0caeef57c4be2e75f5d42bc65da562e5e2a0f10	the challenges of analog circuits on nanoscale technologies	moores law analog circuits nanoscale technologies systems on chip analog signal circuits mixed signal circuits digital die;system on chip analogue circuits nanotechnology;mixed signal design vlsi circuits analog circuit design;analog circuits transistors redundancy signal to noise ratio oscillators voltage control	As Systems on Chip increase the portions of systems that are being integrated, the number and variety of analog/mixed signal circuits that are needed on a single chip are growing. At the same time, for reasons of cost, performance, and power the manufacturing of these nominally digital die is being scaled to ever smaller feature sizes. Unfortunately scaling to smaller devices does not deliver power or performance benefits for classical analog circuits. How are we going to bridge the gap between these two trends and keep Moore's Law alive?	analogue electronics;image scaling;mixed-signal integrated circuit;moore's law;system on a chip;transistor	Gregory F. Taylor	2014	Proceedings of the IEEE 2014 Custom Integrated Circuits Conference	10.1109/CICC.2014.6945999	mixed-signal integrated circuit;electronic engineering;electronics;high impedance;electrical engineering;clock signal;computer engineering;analog multiplier	EDA	12.185430022054682	57.20857635327838	78301
966b2256888a67d4912e3ed73457332844279480	power-yield enhancement for field programmable gate arrays under process variations	concepcion asistida;field programmable gate array;leakage;computer aided design;diseno circuito;process variation;circuit design;fpga;red puerta programable;reseau porte programmable;yield;algorithme;etat actuel;algorithm;miniaturisation;low power;state of the art;low power electronics;conception assistee;estado actual;conception circuit;miniaturization;miniaturizacion;electronique faible puissance;algoritmo	Leakage power is a paramount concern in the design of Field Programmable Gate Arrays (FPGAs), and process variations have aggravated the problem. At the 45 nm technology node and beyond leakage variations can diminish the power yield of a design. To handle the increased complexity of the state-of-the-art designs, FPGAs have been scaled in size and complexity, leading to increased leakage, and more variation in leakage power. In this paper impact of process variations on the leakage in FPGAs is analyzed and variability aware CAD algorithms for mitigating the impact of process variations are developed. A programmable dual-Vdd FPGA architecture is selected on which these algorithms are implemented to evaluate the improvement in the power yield of FPGAs. The results indicate that the proposed CAD technique leads to 3%-9% improvement in the power yield.	field-programmable gate array	Akhilesh Kumar;Mohab Anis	2010	J. Low Power Electronics	10.1166/jolpe.2010.1081	embedded system;electronic engineering;telecommunications;computer science;engineering;electrical engineering;computer aided design;field-programmable gate array	EDA	18.649327630129903	55.01772461577589	78319
64cfe502aceaa130609f974ce026581e8fca10b2	enhanced network flow algorithm for yield optimization	convex objective functions;cmos integrated circuits;topology;routing integrated circuit yield circuit faults permission constraint optimization design optimization topology crosstalk algorithm design and analysis white spaces;circuit faults;integrated circuit yield;layout area;constraint optimization;enhanced network flow algorithm;integrated circuit layout;crosstalk;routing;constraint graph algorithm;efficient algorithm;white spaces;wire length;submicron cmos processes enhanced network flow algorithm yield optimization constraint graph algorithm computationally expensive problem network flow problem layout area convex objective functions circuit performance functions wire length cross talk power;design optimization;network flow problem;chip;objective function;computationally expensive problem;permission;submicron cmos processes;vlsi;graph algorithm;constraint theory;yield optimization;circuit performance functions;circuit layout cad;network flow;circuit optimisation;power;algorithm design and analysis;fault diagnosis;cross talk	A novel constraint-graph algorithm for the optimization of yield is presented. This algorithm improves the yield of a layout by carefully spacing objects to reduce the probability of faults due to spot defects. White space between objects is removed and spacing in tightly packed areas of the layout is increased. The computationally expensive problem of optimizing yield is transformed into a network ow problem, which can be solved via known e cient algorithms. Yield can be improved either without changing the layout area, or if necessary by increasing the layout area to maximize the number of good chips per wafer. Our method can in theory provide the best possible yield achievable without modifying the layout topology. The method is able to handle a general class of convex objective functions, and can therefore optimize not only yield, but other circuit performance functions such as wire-length, cross-talk and power.	algorithm;analysis of algorithms;constraint graph;crosstalk;list of algorithms;mathematical optimization;maximum flow problem;program optimization	Cyrus Bamji;Enrico Malavasi	1996		10.1145/240518.240660	mathematical optimization;constrained optimization;electronic engineering;crosstalk;telecommunications;computer science;engineering drawing	EDA	15.891697178884499	51.715368334497136	78347
01023738003e1d498891ea67817f71b0c8f74986	an area-efficient, pulse-based interconnect	pulse based interconnection;parallel interconnection;design process;0 18 micron area efficient interconnection pulse based interconnection on chip interconnects integrated circuit interconnection asynchronous gasp architecture circuit simulation parallel interconnection;electromagnetic compatibility;low complexity;international technology roadmap for semiconductors;integrated circuit interconnections asynchronous circuits integrated circuit design;signal integrity;chip;clock distribution;integrated circuit interconnection;integrated circuit design;on chip interconnects;circuit simulation;long distance;area efficient interconnection;integrated circuit interconnections;0 18 micron;interconnected system;asynchronous circuits;asynchronous gasp architecture;power consumption;clocks wire power system interconnection delay protocols cmos technology signal design conductors pulse inverters encoding;asynchronous logic circuits	We present a new style of long-distance, on-chip interconnects based loosely on the asynchronous GasP architecture, with a number of advantages over conventional interconnect. Most significant are a low wire count, a low area requirement, the absence of a global clock and simple composition with existing designs. We give some sample throughput and latency figures from simulation on a 0.18 mum technology, and show that it is viable for use with modern interconnect requirements, is of low complexity, and has a lower area requirement than parallel interconnect over distances as short as 1 mm	electrical connection;requirement;simulation;throughput	Simon Hollis;Simon W. Moore	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1693120	chip;embedded system;electronic engineering;parallel computing;design process;telecommunications;signal integrity;engineering;electrical engineering;electromagnetic compatibility;integrated circuit design	EDA	13.818949253836657	57.02113142361515	78468
63ef41bb2cdac24e9671a78a7ca891b95adef3a4	bist-based fault diagnosis in the presence of embedded memories	fault simulation;fault diagnosis built in self test logic testing;built in self test;logic testing;automatic test pattern generation bist based fault diagnosis embedded memories fault simulation bist logic embedding prelogic postlogic;fault diagnosis built in self test circuit faults logic testing circuit testing computer aided manufacturing random access memory read write memory jacobian matrices discrete event simulation;automatic test pattern generator;fault diagnosis	An eficient method is described fo r using fault simulation as a solution to the diagnostic problem created by the presence of embedded memories in BIST designs. The simulation is event-table-driven. Special techniques are described to cope with the faults in the Prelogic, Postlogic, and the logic embedding the memory control or address inputs. I t is presumed that the memory itself has been previously tested, using automatic test pattern generation (ATPG) techniques via the correspondence inputs, and has been found to be fault-free.	built-in self-test;decision table;embedded system;simulation;test card	Jacob Savir	1997		10.1109/ICCD.1997.628847	electronic engineering;parallel computing;real-time computing;fault coverage;computer science;stuck-at fault;automatic test pattern generation;fault model	EDA	20.238926223622805	50.20423520529445	78557
3266ed3925f13e9df6a021a7bc9a0d17d234cdb1	evolutionary design of digital circuits using genetic programming		For simple digital circuits, conventional method of designing circuits can easily be applied. But for complex digital circuits, the conventional method of designing circuits is not fruitfully applicable because it is time-consuming. On the contrary, Genetic Programming is used mostly for automatic program generation. The modern approach for designing Arithmetic circuits, commonly digital circuits, is based on Graphs. This graph-based evolutionary design of arithmetic circuits is a method of optimized designing of arithmetic circuits. In this paper, a new technique for evolutionary design of digital circuits is proposed using Genetic Programming (GP) with Subtree Mutation in place of Graph-based design. The results obtained using this technique demonstrates the potential capability of genetic programming in digital circuit design with limited computer algorithms. The proposed technique, helps to simplify and speed up the process of designing digital circuits, discovers a variation in the field of digital circuit design where optimized digital circuits can be successfully and effectively designed .	algorithm;arithmetic circuit complexity;arithmetic logic unit;combinational logic;continuous design;digital electronics;electronic circuit;fitness function;genetic programming;graph of a function;integrated circuit design;mutation testing;sequential logic;speedup;tree (data structure)	S. M. Ashik Eftekhar;Sk. Mahbub Habib;M. M. A. Hashem	2003	CoRR		mixed-signal integrated circuit;computer science;theoretical computer science;algorithm	EDA	17.47907697091324	48.95577015858712	78590
7bf86e878d2056f071bdf8b65cc3c32a9c1805db	thermal characterization and optimization in platform fpgas	circuit optimisation;field programmable gate arrays;iterative methods;thermal management (packaging);virtex-4 fpga;architecture-level temperature simulator;iterative placement;thermal characterization;platform fpgas;virtex4;placement;temperature;thermal	Increasing power densities in field programmable gate arrays (FPGAs) have made them susceptible to thermal problems. The advent of platform FPGAs has further exacerbated the problems by increasing the power density variations on the FPGA fabric. Therefore, we need to characterize the die temperature of platform FPGAs. In this paper, we first estimate the temperature distribution within a Virtex-4 FPGA by feeding the block power numbers in an architecture-level temperature simulator calibrated to reflect a real FPGA package. We analyze the impact of different hard-wired blocks on the temperature profile, and observe that they introduce intra-die variation in temperature of up to 20degC. Next, we evaluate the influence of placement on temperature. Our experiments indicate a decrease in peak temperature by changing the placement of hard blocks, especially the high-speed transceivers. We further propose an iterative placement technique to reduce the peak temperature, and apply it on real designs. Finally, we propose alternate organizations of the hard blocks in the FPGA fabric to reduce temperature	field-programmable gate array;mathematical optimization	Priya Sundararajan;Aman Gayasen;Narayanan Vijaykrishnan;Tim Tuan	2006		10.1109/ICCAD.2006.320154	embedded system;electronic engineering;real-time computing;reconfigurable computing;computer science;engineering;field-programmable gate array	EDA	22.41318266016063	60.095661881527775	79024
6d0ce5aa0929064e570e4ef7c0b33c0fa915206c	efficient modular design of tsc checkers for m-out-of-2m codes	tolerancia falta;detection erreur;deteccion error;fiabilidad;reliability;vlsi mos implementation;adder;mos technology;full adder;integrated circuit;logic design;implementation;cost reduction;adicionador;circuito integrado;testeur code;code checker;totally self checking checkers;ejecucion;trees;circuit faults design methodology very large scale integration circuit testing fault detection mosfets digital systems large scale integration built in self test telecommunication computing;design method;logic design adders codes;codes;adders;fiabilite;fault tolerance;vlsi mos implementation totally self checking checkers modular design codes full adder half adder trees;modular design;tecnologia mos;provador codigo;additionneur;error detection;tolerance faute;circuit integre;half adder;technologie mos	A design method of totally self-checking (TSC) m-out-of-2m code checkers is presented. The design is composed basically of two full-adder/half-adder trees, each summing up the ones received on m input lines, and a k-variable two-pair two-rail code tree that compares the outputs of the two-adder tree. The only modules used are full-adders, half-adders, and two-variable TSC two-rail code checkers. This method is well suited for VLSI MOS implementation and, compared to previous methods, it results in significant circuit cost reduction and smaller test set, without sacrificing performance. Also, the proposed design has the advantages of a modular design. >	modular design;remote desktop services	Antonis M. Paschalis;Dimitris Nikolos;Constantin Halatsis	1988	IEEE Trans. Computers	10.1109/12.2167	embedded system;parallel computing;computer science;operating system;adder;statistics	EDA	21.619035914644375	48.31062012217493	79088
16df934cf3b2ac3843d6efafcaa7bfbb1a637026	integrated floorplanning with buffer/channel insertion for bus-based microprocessor designs	floorplanning;interconnect estimation;routability;time constraint	A new approach to the interconnect-driven floorplanning problem that integrates bus planning with floorplanning is presented. The integrated floorplanner is intended for bus-based designs. Each bus consists of a large number of wires. The floorplanner ensures routability by generating the exact location and shape of interconnects (above and between the circuit blocks) and optimizes the timing. Experiments with MCNC benchmarks clearly show the superiority of integrated floorplanning over the classical floorplan-analyze-and-then-re-floorplan approach. Our floorplans are routable, meet all timing constraints, and are on average 12-13% smaller in area as compared to the traditional floorplanning algorithms.	algorithm;electrical connection;floorplan (microelectronics);microprocessor;routing	Faran Rafiq;Malgorzata Chrzanowska-Jeske;Hannah Honghua Yang;Naveed A. Sherwani	2002		10.1145/505388.505403	embedded system;floorplan;parallel computing;computer science	EDA	14.18433565646267	52.666596384746356	79148
750870bb0e4b91fef387b87c148da0319a0910ad	asynchronous circuits as alternative for mitigation of long-duration transient faults in deep-submicron technologies	digital circuit;clocked device;integrated circuit;regimen transitorio;electronic component;circuito integrado;asynchronous circuit;circuit numerique;miniaturisation;unsteady state;dispositif cadence;circuit asynchrone;circuit synchrone;defaillance;circuito numerico;transient fault;circuito asincrono;regime transitoire;horloge;composant electronique;miniaturization;failures;miniaturizacion;circuito sincrono;clock;fallo;reloj;circuit integre;synchronous circuit;componente electronico	The use of deeper-submicron technologies in integrated circuits worsens the effects of transient faults. In fact, the transient-fault durations become as important as the clock periods of synchronous circuits. Electronic systems are thus more vulnerable to failure situations. Nevertheless, this paper shows innovatively that such a worse scenario does not happen in asynchronous circuits. This additional novel benefit pushes on the asynchronous design as a better alternative to mitigate transient faults in deep-submicron technology-based circuits.	very-large-scale integration	Rodrigo Possamai Bastos;Gilles Sicard;Fernanda Gusmão de Lima Kastensmidt;Marc Renaudin;Ricardo Augusto da Luz Reis	2010	Microelectronics Reliability	10.1016/j.microrel.2010.07.014	clock;embedded system;electronic engineering;asynchronous circuit;computer science;engineering;electrical engineering;integrated circuit;electronic component;miniaturization;synchronous circuit;digital electronics	EDA	19.583925965223017	55.085630519356826	79357
1d5e637524d86f2f851343a753ae855737cb69bc	bist-based diagnosis scheme for field programmable gate array interconnect delay faults	aide diagnostic;field programmable gate array;high resolution;interconnection;integrated circuit;autoprueba;circuito integrado;red puerta programable;island style fpga;autotest;reseau porte programmable;interconexion;haute resolution;built in self test;built in self test based diagnosis scheme;faulty segment candidates;field programmable gate arrays built in self test fault diagnosis;interconnexion;alta resolucion;island style fpga built in self test based diagnosis scheme field programmable gate array delay fault interconnection faulty segment candidates;temps retard;delay time;field programmable gate arrays;tiempo retardo;diagnostic aid;circuit integre;delay fault interconnection;fault diagnosis;ayuda diagnostica	A new built-in self-test (BIST)-based diagnosis scheme for field programmable gate array (FPGA) interconnect delay faults is proposed. Faulty paths can be located after configuring the output response analyser of the BIST circuit as a scan chain. By analysing these faulty paths, segment fault candidates can be obtained. The proposed diagnosis scheme can find effective test paths to locate faulty segment candidates. Experimental results for an island-style FPGA show high diagnosis resolution in locating the faulty paths, under single- and double-fault models caused by single and double defects, respectively.	built-in self-test;field-programmable gate array	Yen-Lin Peng;Cheng-Wen Wu;Jing-Jia Liou;Chih-Tsun Huang	2007	IET Computers & Digital Techniques	10.1049/iet-cdt:20060197	embedded system;electronic engineering;real-time computing;computer science;engineering;field-programmable gate array	EDA	22.20236824739006	50.79915341752456	79522
7fe5c93ee90b363e8b313e06ac22d85fa0c83e37	bit-level pipelined 2-d digital filters for real-time image processing	digital filters iir filters finite impulse response filter pipeline processing costs systolic arrays two dimensional displays refining throughput manufacturing;systolic arrays;real time;iir filter;systolic array;picture processing;digital filter;latches bit level systolic arrays 2d fir filters bit level pipelined filters 2d iir filters finite implulse response 2d iteration parallel architectures real time image processing infinite impulse response systolic architectures throughput rate manufacturing costs word length control circuitry bit level cells;two dimensional digital filters;word length;cost effectiveness;infinite impulse response;digital signal processing chips;two dimensional digital filters digital signal processing chips picture processing pipeline processing systolic arrays;high throughput;real time image processing;real time application;pipeline processing	Bit-level systolic arrays for real-time 2-D FIR and IIR filters are presented. Two-dimensional iteration and retiming techniques are depicted to illustrate block pipeline 2-D IIR filters, which guarantee high throughput operation for real-time applications. The block (parallel) systolic architectures are refined down to the bit level. By doing so we increase the filter’s throughput rate as well as decrease the filter’s development and manufacturing costs. We improve the AP figure from O ( N Z W 3 ) by the previous design to O ( N 2 W 2 ) , i.e., by a factor of O( W ) . Pipelining at the bit level is the major reason for this improvement. Another advantage of our design is that it has a simpler wire routing and control circuitry. In summary, our systolic-array realizations are 1) more cost effective; 2) more regular structurally; 3) composed of bit-level cells and latches; 4) fully pipelined at the bit level.	bit-level parallelism;digital filter;electronic circuit;finite impulse response;image processing;infinite impulse response;iteration;pipeline (computing);real-time clock;retiming;routing (electronic design automation);systolic array;throughput	Cheng-Wen Wu	1991	IEEE Trans. Circuits Syst. Video Techn.	10.1109/76.109143	computer vision;parallel computing;real-time computing;computer science;infinite impulse response	EDA	12.677548960365211	46.95484697930391	79565
c8a6bd829fa08ca0c7cdd5dc4bffd654eec226be	a set of programs for mos design	circuit extraction;various design support package;cell documentation system;connectivity checking;timing simulation;mos design;logic simulation;standard cell mos circuit;custom hand;circuit simulation;design tolerance checking;connection;logic circuits;user interface;documentation;user interfaces;packaging;circuit analysis;logic design	A set of programs used in the design of custom hand packed and standard cell MOS circuits is described. The programs cover logic simulation, filter analysis, circuit simulation, timing simulation, circuit extraction from layout, design tolerance checking, connectivity checking and user interface facilities. A cell documentation system is used to tie together the various design support packages.	circuit extraction;documentation;electronic circuit simulation;logic simulation;standard cell;timing closure;user interface	G. Sakauye;Anna Lubiw;J. Royle;R. Epplett;Jeffrey Tweedale;E. S. Y. Shew;E. Attfield;Franc Brglez;Philip S. Wilcox	1981	18th Design Automation Conference		physical design;embedded system;computer architecture;electronic engineering;computer science;theoretical computer science;operating system;circuit extraction;user interface	EDA	12.040286865714357	51.095078259318036	79696
d4b101c90b5f3ec1ddffdc6313f70646c1eb5cf2	testable designs of sequential circuits under highly observable condition	electron beams;observability;circuit faults;very large scale integration;sequential circuits;controllability;sequential analysis;failure analysis;circuit testing sequential analysis sequential circuits circuit faults electron beams observability controllability very large scale integration failure analysis electrical fault detection;circuit testing;electrical fault detection	I t is assumed that the outputs of all gates in a circuit are observable under the highly observable condition. This paper presents two kinds of testable sequential circuits: k-UCP sequential circuits and k-UCP scan circuits, under the highly observable condition. The combinational portions in both kinds of circuits are kUCP circuits which consist of only k-input gates and inverters. All stuck-at faults in a k-UCP sequential circuit and a k-UCP scan circuit can be tested by 3(k + 1 ) and k + 1 test vectors respectively under the highly observable condition.	combinational logic;emi (protocol);inverter (logic gate);observable;sequential logic	Xiaoqing Wen;Kozo Kinoshita	1992		10.1109/TEST.1992.527884	equivalent circuit;failure analysis;electronic engineering;scan chain;real-time computing;observability;controllability;engineering;sequential analysis;control theory;mathematics;sequential logic;very-large-scale integration	EDA	22.888307524125025	52.13606975639655	79756
236a34780b8d03552ba99d717ad8ab6e12890ad6	back-traced deductive-parallel fault simulation for digital systems	back traced simulation;parallelsimulation;fault simulation;integrated circuits fault simulation automatic test pattern generation digital signal processing chips;automatic test pattern generation;re convergentfan outs;fault analysis model;fault analysis;digital systems;digital design;digital systems circuit faults circuit testing circuit simulation system testing analytical models algorithm design and analysis digital circuits process design automatic test pattern generation;digital systems back traced deductive parallel fault simulation automatic test pattern generation reconvergent fan outs fault analysis model parallel simulation digital designs processing;digital signal processing chips;automatic test pattern generator;high performance;data structure;integrated circuits;parallel simulation;process evaluation;deductive;atpg	A high performance back-traced deductive-parallel (BDP) fault simulation method based on the superposition procedure is oriented on using large digital designs processing. Evaluation of RT and gate level design description is proposed in this work. The data structure and program are developed for algorithms realization of the proposed method and integration with automatic test pattern generation systems.	and gate;algorithm;bandwidth-delay product;data structure;digital electronics;level design;simulation;test card	Vladimir Hahanov;Raimund Ubar;Stanley Hyduke	2003	Euromicro Symposium on Digital System Design, 2003. Proceedings.	10.1109/DSD.2003.1231969	computer architecture;fault coverage;data structure;computer science;stuck-at fault;automatic test pattern generation	EDA	19.72164529989892	49.41853333459257	79846
26672c832e3671645169fe5cab6decb16677332e	fixed origin corner square inspection layout regularity metric	monte carlo methods;integrated circuit layout;integrated circuit manufacture;photolithography;monte carlo analysis;fixed origin corner square inspection layout regularity metric;integrated circuits;layout printability;link layout regularity;lithography manufacturing process;process variations reduction;systematic subwavelength lithography variations	Integrated circuits suffer from serious layout printability issues associated to the lithography manufacturing process. Regular layout designs are emerging as alternative solutions to help reducing these systematic subwavelength lithography variations. However, there is no metric to evaluate and compare the layout regularity of those regular designs and there is no methodology to link layout regularity to the reduction of process variations. In this paper we propose a new layout regularity metric called Fixed Origin Corner Square Inspection (FOCSI). We also provide a methodology using the Monte Carlo analysis to evaluate and understand the impact of regularity on process variability.	computational lithography;heart rate variability;integrated circuit;monte carlo method	Marc Pons;Marc-Nicolas Morgan;Christian Piguet	2012	2012 Design, Automation & Test in Europe Conference & Exhibition (DATE)		lithography;fourier transform;mathematical optimization;electronic engineering;engineering;engineering drawing;statistics;monte carlo method	EDA	22.91552473856473	58.16164762534073	79949
6a108d0c4bf457f4aa18b65a3530be636789bb91	a fast extraction algorithm for defect-free subcrossbar in nanoelectronic crossbar	reconfigurable architectures;nanotechnology;balanced biclique;defect tolerant	Due to the super scale, high defect density, and per-chip designing paradigm of emerging nanoelectronics, the runtime of the algorithms for defect-tolerant design is of vital importance from the perspective of practicability. In this article, an efficient and effective heuristic defect-free subcrossbar extraction algorithm is proposed which improves performance by mixing the heuristics from two state-of-the-art algorithms and then is speeded up significantly by considerably reducing the number of major loops. Compared with the current most effective algorithm that improves the solution quality (i.e., size of the defect-free subcrossbar obtained) at the cost of high time complexity O(n3), the time complexity of the proposed heuristic algorithm is proved to be O(n2). Using a large set of instances of various scales and defect densities, the simulation results show that the proposed algorithm can offer similar high-quality solutions as the current most effective algorithm while consuming much shorter runtimes (reduced to about 1/3 to 1/5) than the current most effective algorithm.	algorithm;angular defect;crossbar switch;heuristic (computer science);programming paradigm;simulation;software bug;time complexity	Bo Yuan;Bin Li	2014	JETC	10.1145/2517137	parallel computing;computer science;theoretical computer science;nanotechnology;algorithm	EDA	14.438970126797834	53.70815935312143	80194
28e2c408f1ac30a00075a6c6cb3b4b37dac041e2	design space minimization with timing and code size optimization for embedded dsp	minimisation;unfolding;optimization technique;satisfiability;design optimization;design space;high level synthesis;integrated circuit design;code size;digital signal processing chips;design space exploration;code size reduction;dsp processors;retiming;timing	One of the most challenging problems in high-level synthesis is how to quickly explore a wide range of design options to achieve high-quality designs. This paper presents an Integrated Framework for Design Optimization and Space Minimization (IDOM) towards finding the minimum configuration satisfying timing and code size constraints. We show an effective way to reduce the design space to be explored through the study of the fundamental properties and relations among multiple design parameters, such as retiming value, unfolding factor, timing, and code size. Theoreies are presented to produce a small set of feasible design choices with provable quality. IDOM algorithm is proposed to generate high-quality design by integrating performance and code size optimization techniques. The experimental results on a set of DSP benchmarks show the efficiency and effectiveness of the IDOM algorithm. It constantly generates the minimal configuration for all the benchmarks. The cost of design space exploration using IDOM is only 3% of that using the standard method.	algorithm;benchmark (computing);design space exploration;embedded system;graph (discrete mathematics);high- and low-level;high-level synthesis;iterated function;iteration;mathematical optimization;provable security;retiming;scheduling (computing);unfolding (dsp implementation)	Qingfeng Zhuge;Zili Shao;Bin Xiao;Edwin Hsing-Mean Sha	2003	First IEEE/ACM/IFIP International Conference on Hardware/ Software Codesign and Systems Synthesis (IEEE Cat. No.03TH8721)	10.1145/944645.944685	computer architecture;parallel computing;real-time computing;computer science	EDA	14.407797359609996	49.015664604826995	80199
139dbba2323de395fcc29a6dbbd7608b7ab8b566	evaluation of fpga routing architectures under process variation	process variation;standard deviation;unidirectional;bidirectional;fpga routing architecture	Uncertainty in performance of FPGAs is becoming an important issue due to increased process variations in nanometer regime. Therefore, it is vital to decrease the impact of variability in these devices. FPGA routing architecture enhancement can be an effective way, because as feature size scales down, routing delay dominates logic circuit delay. In this paper, unidirectional and bidirectional routing architectures are compared. We show that bidirectional architecture is better in terms of robustness against variation when short wire segments are considered. However as wire length increases, unidirectional routing architecture would be the preferred option. Experimental results show that in unidirectional routing architecture towards bidirectional for wire length of 8, it has obtained 36% and 20% improvement in standard deviation and 3¼+Ã of circuit delay, respectively.	field-programmable gate array;logic gate;routing;spatial variability	Fatemeh Sadat Pourhashemi;Morteza Saheb Zamani	2011		10.1145/1973009.1973080	electronic engineering;static routing;real-time computing;equal-cost multi-path routing;engineering;multipath routing;distributed computing;standard deviation;process variation;statistics	EDA	14.772673688530325	57.094932134026074	80258
58245d26c686d9e6cfd24edf9c5c6deed34ae942	a protocol extraction strategy for control point insertion in design for test of transition signaling circuits	control point insertion;test length reduction;major difficulty;test length;gap detection;gap matching;safe hazard-free test;protocol extraction strategy;observation point;safe behavior;area overhead	Control/observation points have been used to detect undetectable faults in delay-insensitive/speed-independent circuits but no techniques exist so far for its use in reducing the test length. The major difficulty is in deriving a safe hazard-free test. A theory for control point insertion is presented for the purpose of test length reduction of transition signaling circuits. It is based on extraction of safe behaviors from the original usage protocol via gap detection (identification of unnecessary behavior) and gap matching (jumping from one partial state to another). The area overhead is low, requires only a single input pad, and can give significant reductions in test length.	cell signaling;control point (mathematics);design for testing	Hon Fung Li;P. N. Lam	1995			embedded system;electronic engineering;real-time computing;computer science;engineering;design for testing;computer network	EDA	21.359912566222064	51.159216394350906	80328
28edfb2d121d8d37f671fa8f6e5086867ace8dcf	an rtl-to-gds2 design methodology for advanced system lsi	system lsis;key area;rtl-to-gds2 design methodology;advanced system;design productivity;leading edge device;design methodology;variation aware design;low power design;starcad-cel design methodology;design for manufacture;integrated circuit design	STARC is developing an RTL-to-GDS2 design methodology for 32nm (and 28nm) system LSIs called STARCAD-CEL. The design methodology focuses on four key areas: low power design, variation aware design and design for manufacturability as well as design productivity. This paper examines several techniques we used to solve issues the in design of challenging, leading edge devices. It also describes the effectiveness of the STARCAD-CEL design methodology when applied to the four key areas.	design for manufacturability;edge device	Nobuyuki Nishiguchi	2011	16th Asia and South Pacific Design Automation Conference (ASP-DAC 2011)		iterative design;physical design;electronic engineering;design methods;systems engineering;engineering;design flow;computer-automated design;circuit design;design technology;design for manufacturability;engineering drawing;standard cell;integrated circuit design	EDA	12.69331907027148	55.23958049437601	80457
929c494c43f67da67787d297bc72af7d4427e4ef	a multilevel analytical placement for 3d ics	integrated circuits;nonlinear programming;3d ic;3d placement method;area density constraint;density penalty function;device layer assignment;discrete layer assignment;multilevel analytical placement;multilevel nonlinear programming;three-dimensional ic technologies	In this paper we propose a multilevel non-linear programming based 3D placement approach that minimizes a weighted sum of total wirelength and TS via number subject to area density constraints. This approach relaxes the discrete layer assignments so that they are continuous in the z-direction and the problem can be solved by an analytical global placer. A key idea is to do the overlap removal and device layer assignment simultaneously by adding a density penalty function for both area & TS via density constraints. Experimental results show that this analytical placer in a multilevel framework is effective to achieve trade-offs between wirelength and TS via number. Compared to the recently published transformation-based 3D placement method [1], we are able to achieve on average 12% shorter wirelength and 29% fewer TS via compared to their cases with best wirelength; we are also able to achieve on average 20% shorter wirelength and 50% fewer TS via number compared to their cases with best TS via numbers.	linear programming;nonlinear programming;nonlinear system;penalty method;weight function	Jason Cong;Guojie Luo	2009	2009 Asia and South Pacific Design Automation Conference		embedded system;mathematical optimization;electronic engineering;telecommunications;nonlinear programming;computer science;electrical engineering;theoretical computer science;penalty method;density functional theory;scheduling;algorithm	EDA	14.909487322431932	53.01517605130551	80779
e0862b2042bcd323829260a1e610e7d3ddcfb9de	online test vector insertion: a concurrent built-in self-testing (cbist) approach for asynchronous logic	rails;protocols;circuit faults;4 phase data stream online test vector insertion concurrent built in self testing asynchronous logic fault tolerant systems elastic timing behaviour null phase;integrated circuit testing asynchronous circuits built in self test fault tolerance;testing;built in self test;vectors;fault tolerant systems;pipelines;fault tolerance;online test vector insertion;null phase;integrated circuit testing;concurrent built in self testing;asynchronous circuits;asynchronous logic;elastic timing behaviour;4 phase data stream;protocols vectors circuit faults rails delays pipelines testing;delays	Complementing concurrent checking with online testing is crucial for preventing fault accumulation in fault-tolerant systems with long mission times. While implementing a non-intrusive online test is cumbersome in a synchronous environment, this task becomes even more challenging in asynchronous designs. The latter receive increasing attention, mainly due to their elastic timing behaviour; however the issues related with their testing remain a key obstacle for their wide adoption. In this paper we present a novel approach for testing of asynchronous circuits that leverages the redundancy present in the conventional 4-phase protocol for implementing a fully transparent and fully concurrent test procedure. The key idea is to use the protocol's unproductive NULL phase for processing test vectors, thus effectively interleaving the incoming 4-phase data stream with a test data stream in a 2-phase fashion. We present implementation templates for the fundamental building blocks required and give a proof-of-concept by an example application that also serves as a platform for evaluating the overheads of our solution which turn out to be moderate.	asynchronous circuit;best, worst and average case;blu-ray;built-in self-test;combinational logic;complexity;concurrency (computer science);fault coverage;fault tolerance;forward error correction;image scaling;spacer gif;test data;test vector;tree accumulation;triple modular redundancy	Jürgen Maier;Andreas Steininger	2014	17th International Symposium on Design and Diagnostics of Electronic Circuits & Systems	10.1109/DDECS.2014.6868759	embedded system;communications protocol;fault tolerance;electronic engineering;real-time computing;asynchronous circuit;computer science;engineering;pipeline transport;software testing	EDA	20.939938808613196	51.83739349643153	80780
af694026f966a54d449e6c249bc8d6435cc77bd6	the superchip: innovative teaching of ic design and manufacture	software;cmos integrated circuits;test vectors;metals;ic design;chip architecture;layout;education pulp manufacturing testing consumer electronics hardware design engineering collaborative work circuits costs standards development;chip;integrated circuit design;integrated circuit testing cmos integrated circuits integrated circuit design;logic gates;ic cmos process technology superchip ic design test vectors chip architecture;integrated circuit modeling;integrated circuit testing;ic cmos process technology;superchip;integrated circuits	In this paper we describe how through intelligent chip architecture, a large cohort (~100 students) of undergraduates can be given effective practical insight into IC design by designing and manufacturing their own individual ICs. To achieve this, the ldquoSuperchiprdquo has been developed, which allows (without excessive cost in terms of time or resources) multiple student designs to be fabricated on a single IC, and encapsulated in a standard package. We demonstrate how the practical process has been tightly coupled with theoretical aspects of the degree course and how transferable skills are incorporated into the design exercise. The paper provides details of the chip architecture, test regime, test vectors, and an example design.	integrated circuit design;test vector	Peter R. Wilson;Reuben Wilcock;Iain McNally;Matthew Swabey;Bashir M. Al-Hashimi	2008	2008 IEEE Custom Integrated Circuits Conference	10.1109/CICC.2008.4672140	electronic engineering;computer science;engineering;electrical engineering;computer engineering;integrated circuit design	EDA	10.037813353010266	52.83898061445132	80869
24da4675701f724d39ed8086bc4bed73a3e9bffe	power and thermal constraints of modern system-on-a-chip computer	energy;thermal;power	Power and thermal are major constraints for delivering compute performance in high-end CPU and are expected to be so in the future. For high end processors, junction temperature has been considered the toughest physical constraint that needs to be tightly managed. Recent trends in form-factors and the increased focus on thin and light systems such as Ultra Book, tablet computers and smartphones, shift the challenge away from junction temperature. Ergonomic thermal considerations and power delivery are becoming the limiters for delivering high computational performance density and need to be managed and controlled. In this paper we describe the major physical constraints, design considerations and modern power and thermal management techniques and demonstrate them on an Intel Core(tm) i7 system.	central processing unit;computation;human factors and ergonomics;junction temperature;limiter;smartphone;system on a chip;tablet computer;thermal management (electronics);ultrabook	Efraim Rotem;Ran Ginosar;Avi Mendelson;Uri C. Weiser	2013	19th International Workshop on Thermal Investigations of ICs and Systems (THERMINIC)	10.1016/j.mejo.2015.09.002	thermal;electronic engineering;energy;telecommunications;engineering;electrical engineering;power;physics;quantum mechanics;mechanical engineering	Arch	13.037879522452858	58.239414061605174	80924
33b8bd89df5896eaac59f5034886902493466ea0	a highly efficient redundancy scheme: self-purging redundancy	reliability;switch;coverage factors;reliability function;dormancy factors;probability of failure;mission time;self purging redundancy;convolutions;convolutions coverage factors dormancy factors mission time poisson distribution reliability self purging redundancy switch;poisson distribution	The goals of this paper are to present an efficient redundancy scheme for highly reliable systems, to give a method to compute the exact reliability of such systems and to compare this scheme with other redundancy schemes. This redundancy scheme is self-purging redundancy, a scheme that uses a threshold voter and that purges the failed modules. Switches for self-purging systems are extremely simple: there is no replacement of the failed modules and module purging is quite simply implemented. Because of switch simplicity, exact reliability calculations re possible. The effects of switch reliability are quantitatively examined. For short mission times, switch reliability is the most important factor: self-purging systems have a probability of failure several times larger than the figure obtained when switches are assumed to be perfect. The influence of the relative frequency of the diverse types of failures (permanent, intermittent, stuck-at, multiple,...) is also investigated. Reliability functions, mission time improvements, and switch efficiency are computed and displayed. Self-purging systems are compared with other redundant systems, like hybrid or NMR, for their relative merits in reliability gain, simplicity, cost, and confidence in the reliability estimation. The high confidence in the reliability evaluation of self-purging systems makes them a standard for the validation of several models that have been proposed to take into account switch reliability. The accuracy of the models using coverage factors can be evaluated in this way.	network switch	Jacques Losq	1976	IEEE Transactions on Computers	10.1109/TC.1976.1674656	triple modular redundancy;dual modular redundancy;real-time computing;switch;reliability;mathematics;poisson distribution;convolution;statistics	Metrics	10.295201452366538	59.85212452826475	81287
0753a4fe4bcaa0b90e2d6825cd74f197cbef783b	on the trade-off between power and flexibility of fpga clock networks	energy efficient;clock distribution networks;fpga;satisfiability;clock aware placement;low power design;power consumption;clock distribution network	FPGA clock networks consume a significant amount of power, since they toggle every clock cycle and must be flexible enough to implement the clocks for a wide range of different applications. The efficiency of FPGA clock networks can be improved by reducing this flexibility; however, reducing the flexibility introduces stricter constraints during the clustering and placement stages of the FPGA CAD flow. These constraints can reduce the overall efficiency of the final implementation. This article examines the trade-off between the power consumption and flexibility of FPGA clock networks.  Specifically, this article makes three contributions. First, it presents a new parameterized clock-network framework for describing and comparing FPGA clock networks. Second, it describes new clock-aware placement techniques that are needed to find a legal placement satisfying the constraints imposed by the clock network. Finally, it performs an empirical study to examine the trade-off between the power consumption of the clock network and the impact of the CAD constraints for a number of different clock networks with varying amounts of flexibility.  The results show that the techniques used to produce a legal placement can have a significant influence on power and the ability of the placer to find a legal solution. On average, circuits placed using the most effective techniques dissipate 5% less overall energy and are significantly more likely to be legal than circuits placed using other techniques. Moreover, the results show that the architecture of the clock network is also important. On average, FPGAs with an efficient clock network are up to 14.6% more energy efficient compared to other FPGAs.	benchmark (computing);clock network;clock signal;cluster analysis;computer-aided design;feature toggle;field-programmable gate array;loss function;placement (eda);simulated annealing	Julien Lamoureux;Steven J. E. Wilton	2008	TRETS	10.1145/1391732.1391733	clock synchronization;embedded system;parallel computing;real-time computing;clock skew;computer science;underclocking;timing failure;efficient energy use;clock gating;digital clock manager;field-programmable gate array;cpu multiplier;satisfiability	EDA	15.118505276537254	54.24291466527349	81523
12ef5bffb9546790a568421bfbb7fa5d126d9001	equivalence checking of reversible circuits	toggle equivalence;common specification;satisfiability;scalable logic synthesis;logic synthesis;scalable equivalence checking;combinational circuit;equivalence checking	"""In this paper we develop a theory of equivalence checking (EC) and logic synthesis of circuits with a common specification (CS). We show that two combinational circuits <i>N</i><inf>1</inf> <i>N</i><inf>2</inf> have a CS iff they can be partitioned into subcircuits that are connected """"in the same way"""" and are <i>toggle equivalent</i>. This fact allows one to represent a specification of a circuit implicitly as a partitioning into subcircuits. We give an efficient procedure for checking if circuits <i>N</i><inf>1</inf>, <i>N</i><inf>2</inf> have the same predefined specification. As a """"by-product"""", this procedure performs EC of <i>N</i><inf>1</inf> and <i>N</i><inf>2</inf>. We show how, given a circuit <i>N</i><inf>1</inf> with a predefined specification, one can efficiently build a circuit <i>N</i><inf>2</inf> satisfying the same specification. We give experimental evidence that EC of <i>N</i><inf>1</inf> <i>N</i><inf>2</inf> is hard if their CS is unknown."""	combinational logic;computational complexity theory;feature toggle;formal equivalence checking;logic gate;logic synthesis;turing completeness;verification and validation	Eugene Goldberg	2005	2009 39th International Symposium on Multiple-Valued Logic	10.1145/1057661.1057687	embedded system;discrete mathematics;logic synthesis;computer science;theoretical computer science;formal equivalence checking;mathematics;combinational logic;algorithm;satisfiability	EDA	19.138938380572796	47.90184692943502	81549
0e0150e023dedf926cd59c89a3c634d8a3d42ff7	acclaim - a computer aided design system	automated circuit card layout;design system;computer program;realizable gate;printed circuit card;boolean equation;connection signal path;topologically configures;etching template;fortran iv;logical element;computer aided design	ACCLAIM—<underline>A</underline>utomated <underline>C</underline>ircuit <underline>C</underline>ard <underline>L</underline>ayout <underline>a</underline>nd <underline>Im</underline>plementation—is a family of computer programs, written in FORTRAN IV, which reduces Boolean equations to logical elements, translates the logical elements to physically realizable gates, synthesizes the gates into a switching network, and topologically configures a printed circuit card. It then determines the connection signal paths and produces artwork which is photographically processed into an etching template.	computer program;computer-aided design;fortran;integrated circuit;printed circuit board;printing	Miles D. Aakhus;D. Michael Seeman;Donna C. Mazzola;Eugene J. Ptak	1968		10.1145/800167.805407	embedded system;electronic engineering;computer science;electrical engineering;theoretical computer science;mathematics;engineering drawing;algorithm	EDA	12.756701584602244	50.54672706573203	81622
dd349f033ca76208ee926d0e68fe0ce7ce114666	ultra-low-power, high-density spintronic programmable logic (spl)	voltage control cmos logic circuits low power electronics magnetic anisotropy magnetic tunnelling magnetoelectronics mram devices programmable logic devices spin hall effect;perpendicular magnetic anisotropy;sensors;stt ram ultra low power spintronic programmable logic high density spintronic programmable logic nonvolatile spintronic programmable logic spl structure magnetic tunnel junction mtj compact device model cmos technology back end of line beol gate voltage modulated spin hall effect v she switching voltage controlled magnetic anisotropy vcma effect parallel configuration method write circuit spin transfer torque memory;hall effect;gate voltage modulated she switching spin electronics magnetic tunnel junction mtj voltage controlled magnetic anisotropy vcma perpendicular magnetic anisotropy pma spin hall effect she;critical current density superconductivity;switches magnetic tunneling critical current density superconductivity sensors table lookup hall effect perpendicular magnetic anisotropy;switches;table lookup;magnetic tunneling	A non-volatile spintronic programmable logic (SPL), based on a 3-teriminal magnetic tunnel junction (MTJ), is presented and simulated using a compact device model. The SPL structure is compatible with CMOS technology and can be fabricated in the back end of line (BEOL). The proposed SPL exploits the gate-voltage-modulated spin Hall effect (V-SHE) switching, which combines the voltage controlled magnetic anisotropy (VCMA) effect and SHE, as a parallel configuration method. The VCMA modulates the coercivity of the MTJ, reducing the critical current for the SHE to change the state of MTJs. This allows the SPL to achieve 100x faster configuration speed due to the parallel configuration, and 32% area reduction because of minimized transistors in the write circuit, compared to conventional spin transfer torque memory (STT-RAM) based programmable logic.	back end of line;boolean algebra;cmos;clock rate;low-power broadcasting;modulation;non-volatile memory;programmable logic device;random-access memory;spin hall effect;spintronics;transistor	Kang L. Wang;Hochul Lee;Farbod Ebrahimi;Pedram Khalili Amiri	2016	2016 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2016.7527197	hall effect;electronic engineering;network switch;computer science;sensor;electrical engineering;spin pumping;quantum mechanics	EDA	16.555373466253478	59.64284454064003	81653
368e1e6b2de5073731d25581c912f0745e4175e2	symbolic representation with ordered function templates	logic design verification;boolean operations;logic simulation;memory requirements;argument lists;decoding;logic design;boolean functions;input variables;prototypes;cudd;boolean functions data structures binary decision diagrams circuits input variables labeling permission computer science decoding prototypes;boolean function;logic design verification symbolic representation ordered function templates binary decision diagrams normalized templates argument lists boolean operations cudd memory requirements;boolean operation;formal verification;binary decision diagrams;permission;data structures;ordered function templates;circuits;computer science;symbolic simulation;function templates;logic cad;normalized templates;formal verification binary decision diagrams logic simulation logic cad;labeling;symbolic representation;binary decision diagram	Binary Decision Diagrams (BDDs) often fail to exploit sharing between Boolean functions that differ only in their support variables. In a memory circuit, for example, the functions for the different bits of a word differ only in the data bit while the address decoding part of the function is identical. We present a symbolic representation approach using ordered function templates to exploit such regularity.Templates specify functionality without being bound to a specific set of variables. Functions are obtained by instantiating templates with a list of variables. We ensure canonicity of the representation by requiring that templates are normalized and argument lists are ordered. We also present algorithms for performing Boolean operations using this representation. Experiments with a prototype implementation built on top of CUDD indicate that function templates can dramatically reduce memory requirements for symbolic simulation of regular circuits.	algorithm;binary decision diagram;boolean operations on polygons;instance (computer science);prototype;requirement;symbolic simulation	Amit Goel;Gagan Hasteer;Randal E. Bryant	2003		10.1145/775832.775946	discrete mathematics;data structure;computer science;theoretical computer science;boolean function;algorithm	EDA	18.307598947375325	46.63893593775911	81774
1639a9a8151449ea36c19ee703ad34fdfb82b16e	on nominal delay minimization in lut-based fpga technology mapping	vegetation mapping;minimization;routing;delay effects;logic emulation;programmable logic arrays;polynomials;computer networks;field programmable gate arrays polynomials delay estimation table lookup vegetation mapping delay effects minimization programmable logic arrays computer networks routing;rapid prototyping;shared memory multiprocessors;polynomial time;field programmable gate arrays;technology mapping;message passing multicomputers;table lookup;delay estimation	We study the nominal delay minimization problem in LUT-based FPGA technology mapping, where interconnect delay is assumed proportional to net fannout size. We prove that the delay-optimal K-LUT mapping problem under the nominal delay model is NP-hard when <italic>K</italic>≥3, and remains NP-hard for duplication-free mapping and tree-based mapping for <italic>K</italic>≥5 (but is polynomial time solvable for <italic>K</italic> = 2). We also present a simple heuristic to take nominal delay into consideration during LUT mapping for delay minimization.	decision problem;field-programmable gate array;heuristic;iterative method;np-hardness;place and route;routing;time complexity	Jason Cong;Yuzheng Ding	1995	Third International ACM Symposium on Field-Programmable Gate Arrays	10.1145/201310.201324	time complexity;routing;parallel computing;real-time computing;computer science;theoretical computer science;field-programmable gate array;polynomial	EDA	15.285002971794736	50.693004635310984	81782
e7cc1893004b35711c6e2769ec93c1511bb02506	timing-constrained power minimization in vlsi circuits by simultaneous multilayer wire spacing	constrained optimization;interconnect sizing and spacing;power delay optimization	Reduction of interconnect delay and interconnect power has become a primary design challenge in recent CMOS technology generations. Spacing between wires can be modified so that line-to-line capacitances will be optimized for minimal power under timing constraints. In this paper, we present a novel algorithm for simultaneous multilayer interconnect spacing that minimizes the total dynamic power dissipation caused by an interconnect, while maximum delay constraints are satisfied. A multi-dimensional visibility graph is used to represent the problem, and a layout partitioning technique is applied to solve the problem efficiently. The algorithm was evaluated on an industrial microprocessor designed using the 32 nanometer technology, and it achieved a 5-12% reduction in interconnect switching power. Highlights • Multi-layer interconnect power optimization under timing constraints is described. • Related global optimization problem is formulated. • An algorithm for solving optimization problem is described and implemented. • A mathematical relation to similar optimization problems is developed. • 5–12% dynamic interconnect power reduction on industrial cases is demonstrated.	algorithm;cmos;global optimization;mathematical optimization;microprocessor;optimization problem;power optimization (eda);very-large-scale integration;visibility graph	Konstantin Moiseev;Shmuel Wimer;Avinoam Kolodny	2015	Integration	10.1016/j.vlsi.2014.03.002	mathematical optimization;constrained optimization;electronic engineering;computer science;engineering;interconnect bottleneck;engineering drawing	EDA	14.889423299729104	53.07808500879354	81809
786d771c9ed3d68aa7c5531828e22381c1429806	exact minimum-width transistor placement without dual constraint for cmos cells	non dual;boolean satisfiability;exact minimum width transistor placement	This paper proposes flat and hierarchical approaches for generating a minimum-width transistor placement of CMOS cells in presence of non-dual P and N type transistors. Our approaches are the first exact method which can be applied to CMOS cells with any types of structure. We formulate the transistor placement problem into Boolean Satisfiability (SAT) problem considering the P and N type transistors individually. The experimental results show that our flat approach generates smaller width placement for 29 out of 103 dual cells than that of the conventional method, and the width of only 3 out of 147 cells solved by our hierarchical approach are larger than that of the flat approach. Using the hierarchical approach, 81% of 340 cells in an industrial standard-cell library of 90 nm technology are solved within one hour for each cell, whereas 32% using the conventional exact method.	boolean satisfiability problem;cmos;transistor	Tetsuya Iizuka;Makoto Ikeda;Kunihiro Asada	2005		10.1145/1057661.1057681	mathematical optimization;combinatorics;electronic engineering;computer science;mathematics;boolean satisfiability problem;algorithm	EDA	14.733280053318952	53.13248040047398	82094
5d595d61c03d374b0d17d4125e2d60dc740bf786	delay fault coverage enhancement by partial clocking for low-power designs with heavily gated clocks	circuit faults;fault simulation;transition fault simulator;clocks;delay fault;automatic test pattern generation;iscas 89 circuits;heavily gated clocks;state dependence;partial clocking delay fault fault simulation low power design;clocks delay circuit faults energy consumption circuit testing registers power grids circuit simulation automatic test pattern generation switches;global clocking scheme;circuit simulation;registers;energy consumption;scan test;delay circuits;low power electronics;test methods;partial clocking;integrated circuit testing;normal operator;power grid;fault coverage;circuit testing;low power design;power grids;power consumption;reduced fault coverage;low power designs;switches;high test power consumption;transition fault coverage;iscas 89 circuits delay fault coverage partial clocking low power designs heavily gated clocks reduced fault coverage high test power consumption scan test global test clocks global clocking scheme power grid transition fault coverage transition fault simulator;delay fault coverage;power grids clocks delay circuits fault location integrated circuit testing low power electronics power consumption;fault location;global test clocks	Testing for delay faults in heavily gated clock designs has the major test challenges of reduced fault coverage and high test power consumption. In the scan-test method, gated clocks are often simplified and replaced with global test clocks. As such, partial clocking by the gated clocks is not inherited in test operations. Global clocking suffers from delay fault coverage loss because a sensitization state cannot easily be created due to the increased state dependence in functional paths, as compared to partial clocking. The global clocking scheme in the test mode is not adequate for low-power designs either, because the power consumed during a test operation exceeds that used during a normal operation. The power grid may not be sufficient to support the power drawn during testing, perhaps resulting in overkilled devices. It is therefore critical that power consumption be maintained under a safe limit, even during testing. In the proposed method, partial clocking in gated designs is preserved to the maximum possible to create more reachable states, thereby increasing transition fault coverage and reducing test power during launch and capture cycles. A transition fault simulator was developed, and it demonstrated higher transition fault coverage and reduced test power for ISCAS-89 circuits when partial clocking is used.	apple ii system clocks;clock rate;fault simulator;fault coverage;low-power broadcasting;quantum clock;simulation	Sanghyeon Baeg	2007	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2007.907017	embedded system;electronic engineering;real-time computing;fault coverage;network switch;computer science;engineering;automatic test pattern generation;operating system;processor register;test method;normal operator;low-power electronics	EDA	20.39322432207176	54.178086354255	82195
2b3733b4a3c1dcd6fa88c91de231381013d411c6	broadband impedance matching for inductive interconnect in vlsi packages	transmission lines;vlsi design;null;system performance;broadband digital signals broadband impedance matching inductive interconnect vlsi packaging packaging technology transmission lines impedance discontinuities digital signals intermittent switching edge time degradation wire bond interconnects;digital signal processing chips integrated circuit interconnections integrated circuit packaging vlsi impedance matching transmission lines lead bonding;lead bonding;integrated circuit interconnections;impedance matching;impedance matching very large scale integration bonding wire integrated circuit interconnections transmission line discontinuities integrated circuit packaging capacitance reflection inductance;system level design;vlsi;digital signal processing chips;integrated circuit packaging;transmission line	Noise induced by impedance discontinuities from VLSI packaging is one of the leading challenges facing system level designers in the next decade. The performance of IC cores far exceeds that of current packaging technology. The risetimes of IC signals require that the interconnect of the package be treated as transmission lines. As a result, impedance discontinuities in the package cause reflections which may result in intermittent switching of digital signals and edge time degradation, both of which limit system performance. The major cause of the impedance discontinuity in the package is the high inductance of the wire bond interconnects. To compensate for this problem, capacitance can be placed near the wire bond to reduce its effective impedance over a given frequency range. This paper presents the application of this impedance matching technique for use in broadband digital signals that are prevalent in modern VLSI designs. Both static and dynamic compensation approaches are presented. The static compensator places pre-defined capacitances on the package and on the IC to surround the wire bond inductance. The dynamic compensator places a switchable capacitance on the IC that can be programmed to a desired value, thereby enabling the designer to overcome design and manufacturing variations in the Mire bond. Both techniques presented are shown to bound the reflections of the wire bond to less than 5% (down from 20% for an uncompensated structure) for wire bonds up to 5mm in length, and for frequencies up to 3GHz. In addition, both circuits utilizes less area than a typical wire bond pad, making them ideal for placement directly beneath the wire bond pads.	characteristic impedance;digital signal (signal processing);electrical connection;elegant degradation;frequency band;impedance matching;output impedance;reflection (computer graphics);reflections of signals on conducting lines;static random-access memory;transmission line;very-large-scale integration;wire bonding	Brock J. LaMeres;Sunil P. Khatri	2005	2005 International Conference on Computer Design	10.1109/ICCD.2005.35	embedded system;impedance matching;electronic engineering;computer science;engineering;electrical engineering;impedance bridging;computer performance;very-large-scale integration;output impedance;lead	EDA	12.754246776299507	56.36916414355609	82242
d9d1569b5d14484412fc981764f229cb1111de56	pseudorandom arrays for built-in tests	digital circuit;in situ test;two dimensional window property;ensayo en sitio;integrated circuit;pseudorandom sequences;circuit vlsi;circuito integrado;pseudorandom binary sequences;linear dependencies in m sequences;test;essai en place;ensayo;circuit numerique;essai;vlsi circuit;parallel lfsr sequences;circuito numerico;built in test;registro dispersion;built in self test stimuli;circuito vlsi;two dimensional window property built in self test stimuli linear dependencies in m sequences parallel lfsr sequences pseudorandom binary sequences pseudorandom sequences;registre decalage;shift register;circuit integre	Parallel pseudorandom sequences for use in built-in test are discussed. The two-dimensional nature of these sequences-makes it natural to consider the resulting binary arrays. Some of the desired properties of such arrays are discussed, as well as some of the problems. Generators for such arrays are described. A conventional LFSR with parallel output is shown to be a poor choice for such a generator. Several compact generators are described, which are shown to be compromises between complexity and varying degrees of implementation of the desired properties in the resulting sequences. One of the compact generators produces sequences which have the desired properties for built-in tests.	built-in self-test;canonical account;linear-feedback shift register;pseudorandom number generator;pseudorandomness	Paul H. Bardell;William H. McAnney	1986	IEEE Transactions on Computers	10.1109/TC.1986.1676810	computer science;electrical engineering;theoretical computer science;integrated circuit;mathematics;shift register;software testing;digital electronics;pseudorandom generator theorem;algorithm	Theory	21.68384989616006	48.68956900301624	82270
0afbe3585a5e6cd758ea8814c3f5a29f7ac864dc	checking sequence generation for asynchronous sequential elements	libraries;libraries flip flops logic testing protocols fault detection binary search trees synchronous machines system testing automatic test pattern generation clocks;logic faults;protocols;asynchronous finite state machines;clocks;binary search trees;asynchronous sequential elements;automatic test pattern generation;circuit design;flip flops;circuit design asynchronous sequential elements asynchronous finite state machines finite state machine fundamental mode checking sequences logic faults;automatic test software logic testing finite state machines asynchronous sequential logic fault diagnosis;synchronous machines;finite state machines;automatic test software;checking sequences;fault detection;logic testing;system testing;asynchronous sequential logic;finite state machine;fundamental mode;fault diagnosis	An algorithm for generating checking sequences for asynchronous finite state machines is proposed. A checking sequence distinguishes a finite state machine (FSM) from all other FSMs with the same inputs and outputs, and with the same or fewer number of states. This algorithm is applied to normal fundamental mode asynchronous finite state machines (AFSM). The derived checking sequences can be used either as a test sets that detect all logic faults or to verify that the circuit design as a correct implementation of the AFSM. The resulting test is guaranteed to detect all logic faults occurring in the machine even if the defect causes a limited number of additional states.		Sezer Gören;F. Joel Ferguson	1999		10.1109/TEST.1999.805762	communications protocol;binary search tree;real-time computing;computer science;theoretical computer science;automatic test pattern generation;circuit design;finite-state machine;system testing;fault detection and isolation;algorithm	EDA	21.418946268517022	50.07664651761087	82311
31104428022011a966b929d33c5392c7689f8f21	analytical techniques for soft error rate modeling and mitigation of fpga-based designs	modelizacion;field programmable gate arrays fpga;field programmable gate array;radiation induced soft errors;metodo analitico;fiabilidad;reliability;effet rayonnement;reliability estimation;error analysis field programmable gate arrays application specific integrated circuits protection redundancy availability single event transient random access memory logic devices integrated circuit reliability;fault simulation;integrated circuit;diminution cout;radiation effect;implementation;correction erreur;error soft;circuit vlsi;efecto radiacion;circuito integrado;red puerta programable;systeme numerique;simulation defaut;reseau porte programmable;circuit a la demande;erreur soft;digital vlsi systems;modelisation;soft error rate;integrated circuit design;custom circuit;soft error rate mitigation;digital system;vlsi circuit;circuito integrato personalizado;system recovery;vlsi field programmable gate arrays integrated circuit design integrated circuit modelling integrated circuit reliability;integrated circuit modelling;system recovery field programmable gate arrays fpga reliability estimation;application specific integrated circuit;error correction;fiabilite;analytical method;soft error rate modeling;vlsi;sistema numerico;methode analytique;field programmable gate array analytical techniques soft error rate modeling soft error rate mitigation fpga based designs radiation induced soft errors reliability digital vlsi systems;fpga based designs;correccion error;analytical techniques;circuito vlsi;field programmable gate arrays;integrated circuit reliability;implementacion;reduccion costes;fault injection;modeling;soft error;cost lowering;circuit integre	Radiation-induced soft errors are the major reliability threat for digital VLSI systems. In particular, field-programmable gate-array (FPGA)-based designs are more susceptible to soft errors compared to application-specific integrated circuit implementations, since soft errors in configuration bits of FPGAs result in permanent errors in the mapped design. In this paper, we present an analytical approach to estimate the soft error rate of designs mapped into FPGAs. Experimental results show that this technique is orders of magnitude faster than the fault injection method while more than 96% accurate. We also present a highly reliable and low-cost soft error mitigation technique which can significantly improve the availability of FPGA-mapped designs. Experimental results show that, using this technique, the availability of an FPGA mapped design can be increased to more than 99.99%.	application checkpointing;application-specific integrated circuit;checksum;fault injection;field-programmability;field-programmable gate array;retry;routing;soft error;very-large-scale integration	Hossein Asadi;Mehdi Baradaran Tahoori	2007	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2007.909795	embedded system;electronic engineering;computer science;engineering;electrical engineering;field-programmable gate array	EDA	19.443979319248545	54.83944914245137	82352
3964fd1366c2c3ac4e105c6870810dfa3a70da5b	high-level parameterizable area estimation modeling for asic designs	architecture exploration;vlsi circuits;system on chip;integrated circuit modeling;gate count estimation	Architectural design space exploration and early area budgeting for ASIC and IP block development require accurate high level gate count estimation methods without requiring the hardware being fully specified. The proposed method uses hierarchical and parameterizable models requiring minimal amount of information about the implementation technology to meet this goal. The modeling process flow is to: (1) create a block diagram of the design, (2) create a model for each block, and (3) sum up estimates of all sub-blocks by supplying the correct parameters to each sub-model. We discuss the model creation for a few parameterized library blocks as well as three communication blocks and a processor core from real IC projects ranging from 22 to 250 kgates. The average relative estimation error of the proposed method for the library blocks is 3.2% and for the real world examples 4.0%. The best application of this method is early in the design phase when different implementation architectures are compared. & 2014 Published by Elsevier B.V.	application-specific integrated circuit;design space exploration;diagram;gate count;high-level programming language;ip address blocking;multi-core processor	Ville Eerola;Jari Nurmi	2014	Integration	10.1016/j.vlsi.2014.01.002	system on a chip;embedded system;electronic engineering;real-time computing;computer science;electrical engineering;very-large-scale integration	EDA	14.804558076919411	54.777888939378116	82393
5423005734afdcb211b663d3d5f4497145b383f6	a hierarchical technique for minimum-width layout of two-dimensional cmos cells	clusters;minimization;integer linear programming;cmos circuit partitioning;circuit optimisation cmos digital integrated circuits integrated circuit layout circuit layout cad linear programming integer programming;integrated circuit layout;circuits integer linear programming semiconductor device modeling minimization computer architecture productivity optimization methods educational institutions logic gates very large scale integration;very large scale integration;transistor chains;diffusion sharing;computer architecture;logic gates;integer programming;cmos digital integrated circuits;semiconductor device modeling;linear programming;chain covers;minimum width 1 d placements;large complex cmos cells;circuit layout cad;circuits;two dimensional cmos cells;productivity;inter row connections;circuit optimisation;minimum width layout;near optimal layouts;hierarchical technique;integer linear program;area efficient layouts;near optimal layouts two dimensional cmos cells minimum width layout hierarchical technique integer linear programming area efficient layouts large complex cmos cells cmos circuit partitioning clusters minimum width 1 d placements chain covers diffusion sharing transistor chains inter row connections;optimization methods	We present a hierarchical technique, based on integer linear programming (ILP), to generate area-efficient layouts of relatively large complex CMOS cells in the twodimensional (2-D or multi-row) style. First, the CMOS circuit is partitioned into subcircuits called clusters. Next, the set of all minimum-width 1-D placements (chain covers) are generated for each cluster, and form the input to the ILP model. The model aims at selecting exactly one cover for each cluster such that the overall 2-D cell width is minimized. In the process, all possible diffusion sharing between transistor chains belonging to clusters are considered; the inter-row connections that contribute to the overall cell width are also reduced. Experimental results demonstrate that the technique reduces run times by several orders of magnitude over non-hierarchical methods, and yields optimal or near-optimal layouts in most cases.	cmos;computer cluster;integer programming;linear programming;transistor	Avaneendra Gupta;John P. Hayes	1997		10.1109/ICVD.1997.567954	mathematical optimization;electronic circuit;electronic engineering;productivity;semiconductor device modeling;integer programming;logic gate;computer science;electrical engineering;theoretical computer science;integrated circuit layout;very-large-scale integration	EDA	14.332546320848508	51.49541318368288	82671
5197c718f403a88fb6031f5d948d2259a7acb98b	hierarchical whitespace allocation in top-down placement	design process;dsm yield improvement hierarchical whitespace allocation top down placement low level transistor density physical layout balance constraints min cut partitioning move based local search heuristics unbalanced distribution move based iterative partitioners global placement simulated annealing routing congestion heat dissipation crosstalk noise;integrated circuit layout;crosstalk;top down;iterative methods circuit layout cad integrated circuit layout crosstalk integrated circuit noise network routing simulated annealing;simulated annealing;network routing;chip;iterative methods;design automation semiconductor device noise power systems power grids time domain analysis electromagnetic heating microwave theory and techniques very large scale integration microprocessors dh hemts;mathematical model;circuit layout cad;integrated circuit noise;local search;fiduccia mattheyses	Increased transistor density in modern commercial ICs typically originates in new manufacturing and defect prevention technologies [15, 16]. Additionally, better utilization of such low-level transistor density may result from improved software that makes fewer assumptions about physical layout in order to reliably automate the design process. In particular, recent layouts tend to have large amounts of whitespace, which is not handled properly by older tools. We observe that a major computational difficulty arises in partitioningdriven top-down placement when regions of a chip lack whitespace. This tightens balance constraints for min-cut partitioning and hampers move-based local-search heuristics such as Fiduccia-Mattheyses. However, the local lack of whitespace is often caused by very unbalanced distribution of whitespace during previous partitioning, and this concern is emphasized in chips with large overall whitespace. This paper focuses on accurate computation of tolerances to ensure smooth operation of common movebased iterative partitioners, while avoiding cell overlaps. We propose a mathematical model of hierarchical whitespace allocation in placement, which results in a simple computation of partitioning tolerance purely from relative whitespace in the block and the number of rows in the block. Partitioning tolerance slowly increases as the placer descends to lower levels, and relative whitespace in all blocks is limited from below (unless partitioners return “illegal” solutions), thus preventing cell overlaps. This facilitates good use of whitespace when it is scarce and prevents very dense regions when large amounts of whitespace are available. Our approach improves the use of the available whitespace during global placement, thus leading to smaller whitespace requirements. Existing techniques, particularly those based on Simulated Annealing [21, 10], can be applied after global placement to bias whitespace with respect to particular concerns, such as routing congestion, heat dissipation, cross-talk noise and DSM yield improvement.	application-specific integrated circuit;best, worst and average case;binary space partitioning;byzantine fault tolerance;computation;crosstalk;fiduccia-mattheyses algorithm;first-order predicate;heuristic (computer science);high- and low-level;industrial pc;integrated circuit layout;iterative method;mathematical model;minimum cut;network congestion;requirement;routing;simulated annealing;software bug;standard cell;thermal management (electronics);top-down and bottom-up design;transistor;transistor–transistor logic;unbalanced circuit	Andrew E. Caldwell;Andrew B. Kahng;Igor L. Markov	2003	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/TCAD.2003.818375	chip;embedded system;mathematical optimization;routing;electronic engineering;real-time computing;crosstalk;design process;simulated annealing;computer science;engineering;electrical engineering;local search;operating system;top-down and bottom-up design;mathematical model;iterative method;integrated circuit layout;engineering drawing	EDA	16.11240991714422	52.95904860476007	82709
f8beacf6a0337279e7096673b1ed960177e031b2	fault detection of combinational circuits based on supply current	current variation;ttl;circuit faults;electrical fault detection combinational circuits current supplies circuit faults logic circuits fault detection current measurement costs computational efficiency circuit testing;combinatorial circuits;current supplies;transistor transistor logic combinatorial circuits computerised pattern recognition electric current measurement fault location integrated logic circuits logic testing production testing;logic circuits;computerised pattern recognition;autoregressive model;electric current measurement;logical faults;current measurement;pattern recognition supply current measurement logic circuits testing combinational circuits fault detection logical faults ttl current variation autoregressive model;fault detection;logic testing;transistor transistor logic;supply current measurement;pattern recognition;circuit testing;integrated logic circuits;production testing;combinational circuit;logic circuits testing;computational efficiency;electrical fault detection;combinational circuits;fault location	A fault detection technique is proposed which can detect logical faults in combinational circuits by measuring the supply current instead of the output logic, and the effectiveness is evaluated by experiments of the circuits made of TTL (transistors-transistor logic) ICs. This technique is based on the assumption that the supply current will be changed by faults in the logic circuits. A generation mechanism of current variation is represented by an autoregressive model, and faults are detected by using pattern-recognition methods. >	combinational logic	Masaki Hashizume;Takeomi Tamesada;Kazuhiro Yamada;Masaaki Kawakami	1988		10.1109/TEST.1988.207824	electronic engineering;real-time computing;logic level;logic family;computer science;engineering;electrical engineering;pass transistor logic;sequential logic;combinational logic;pull-up resistor;algorithm	EDA	22.896866039989852	52.333304390954055	82773
1da7f88ab7adcfdd973f0117828b92ae49de36c4	a tree matching chip	vision system;cadence design tools;systolic architecture;image recognition;object recognition;design tool;concurrent computing;code optimization;systolic arrays;image understanding;linear array;logic;systolic array;linear systolic array algorithms;compilers;3d object recognition;chip;fixed size linear array;image recognition parallel algorithms systolic arrays digital signal processing chips vlsi object recognition;computational modeling;tree matching chip;online interpreter systems;pattern matching;vlsi;digital signal processing chips;terminology;cadence design tools tree matching chip 3d object recognition vision systems online interpreter systems code optimization compilers linear systolic array algorithms fixed size linear array systolic architecture;vision systems;optimizing compilers;pattern matching partitioning algorithms computational modeling terminology object recognition optimizing compilers systolic arrays logic parallel algorithms concurrent computing;partitioning algorithms;parallel algorithms	Tree matching is an important problem used for threedimensional object recognition in image understanding and vision systems. The objective of tree matching is to find the set of nodes at which a pattern tree matches a subject tree. In this paper, we describe the design and implementation of a very large scale integration (VLSI) chip for tree pattern matching. The architecture is based on an iterative algorithm that is mapped to a systolic array computational model and takesO(t(n+a)) time to process a subject of sizen usinga processors wherea is the length of the largest substring in the pattern andt is the number of substrings in the pattern. The variables and nonvariables of the pattern tree are processed separately, which simplifies the hardware in each processing element. The proposed partitioning strategy is independent of the problem size and allows larger strings to be processed based on the array size. A prototype CMOS VLSI chip has been designed using the Cadence design tools and the simulation results indicate that it will operate at 33.3 MHz.	algorithm;analysis of algorithms;cmos;central processing unit;computation;computational model;computer vision;integrated circuit;iterative method;outline of object recognition;pattern matching;prototype;simulation;substring;systolic array;very-large-scale integration	Vamsi Krishna;Abdel Ejnioui;N. Ranganathan	1996		10.1109/ICVD.1996.489611	chip;segment tree;computer architecture;parallel computing;concurrent computing;systolic array;computer science;trie;theoretical computer science;pattern matching;interval tree;fractal tree index;programming language;logic	HPC	13.16790261931715	47.51725126009231	82815
27cc63a850f8900a569b0b6e6c5a0c32943c1df0	correlation method of circuit-performance and technology fluctuations for improved design reliability	mosfet circuits;inter chip technology fluctuations;correlation methods fluctuations integrated circuit design integrated circuit reliability integrated circuit modelling;circuit simulation model;cmos technology;correlation fluctuations circuit testing mosfet circuits cmos technology circuit simulation semiconductor device measurement semiconductor device modeling voltage proposals;circuit performance fluctuations;fluctuations;correlation method;design reliability improvement;circuit design;random fluctuation correlation method circuit performance fluctuations technology fluctuations design reliability improvement circuit design phase circuit simulation model cascode current source test circuit drift diffusion mosfet model hisim intra chip technology fluctuations inter chip technology fluctuations effective gate length fluctuations;circuit design phase;semiconductor device measurement;random fluctuation;intra chip technology fluctuations;correlation methods;drift diffusion mosfet model;hisim;chip;integrated circuit design;circuit simulation;integrated circuit modelling;technology fluctuations;semiconductor device modeling;voltage;drift diffusion;circuit testing;correlation;cascode current source test circuit;integrated circuit reliability;proposals;effective gate length fluctuations	We propose a method of correlating circuit performance with technology fluctuations during the circuit-design phase. The method employs test circuits sensitive for technology fluctuations and a circuit simulation model which enables to interpret the correlation. We validate our proposal with a cascode-current-source test circuit and the drift-diffusion MOSFET model HiSIM. The chosen test circuit allows to separate intra-chip and inter-chip technology fluctuations and to correlate these fluctuations with circuit-performance fluctuating. One important result is that intra-chip fluctuations increase faster than inter-chip fluctuations with decreasing gate length. Quantitative modeling with HiSIM reveals random fluctuation of the effective gate length as the most likely origin for these findings.	current source;electronic circuit simulation;integrated circuit;quantum fluctuation;transistor model	D. Miyawaki;Shizunori Matsumoto;Hans Jürgen Mattausch;S. Ooshiro;Masami Suetake;Mitiko Miura-Mattausch;Shigetaka Kumashiro;Tetsuya Yamaguchi;Kyoji Yamashita;Noriaki Nakayama	2001		10.1145/370155.370260	chip;embedded system;electronic engineering;semiconductor device modeling;voltage;telecommunications;computer science;engineering;electrical engineering;circuit design;cmos;correlation;integrated circuit design	EDA	22.272801533639964	55.21723491448085	82992
2dfb1a83aa987a098ae0b9fe7091e3a8a1278f2f	optimization of mixed logic circuits with application to a 64-bit static adder	logic design;logic circuits adders voltage delay mos devices mosfets inverters design optimization cmos digital integrated circuits capacitance;adders;critical path;cmos logic circuits;circuit optimisation;optimal algorithm;high speed;buffer insertion;650 ps mixed logic circuits static adder cmos logic delay optimization pass transistors buffer insertion cpl chain tsmc technology 0 18 micron 64 bits;delays;delays cmos logic circuits logic design adders circuit optimisation	In this paper, a CMOS logic delay optimization algorithm was used to find the optimal number of pass transistors to use for buffer insertion into a CPL chain. The result was then used as a guide during the design of a 64-bit high-speed static adder. Simulation results indicated a worst-case critical-path delay of 650 ps for a device based on TSMC 0.18 /spl mu/m technology.	64-bit computing;adder (electronics);algorithm;best, worst and average case;cmos;cpl;critical path method;fastest;logic gate;mumps;mathematical optimization;numerical analysis;ps (unix);simulation;transistor	Yuanzhong Wan;Maitham Shams	2005	18th International Conference on VLSI Design held jointly with 4th International Conference on Embedded Systems Design	10.1109/ICVD.2005.132	embedded system;and-or-invert;electronic engineering;parallel computing;nmos logic;logic synthesis;real-time computing;logic optimization;diode–transistor logic;logic level;asynchronous circuit;delay calculation;logic gate;logic family;depletion-load nmos logic;computer science;critical path method;pass transistor logic;sequential logic;integrated injection logic;pull-up resistor;cmos;digital electronics;pmos logic;adder;resistor–transistor logic;emitter-coupled logic	EDA	17.261810528178035	54.44377012405867	83105
546fdd59c140820a1504867873613a54d73e24af	incremental high-level synthesis	synthesis decision;traditional high-level synthesis;engineering change orders;original design;eco scenario;following rtl-to-gdsii design flow;eco design;digital integrated circuit design flow;mainstream tool;design cycle;integrated circuit design;incremental high-level synthesis;logic netlist;rtl-to-gdsii design flow;high-level synthesis;high level synthesis;multiplexing;engineering change order;design flow;algorithm design and analysis;registers;layout;image recognition;logic gates;soc	The widespread acceptance of High-level synthesis as a mainstream tool mostly depends on its tight integration with the following RTL-to-GDSII design flow. A key aspect is the handling of so-called Engineering Change Orders (ECOs), i.e. minor changes required to fix small functional bugs or meet performance requirements late in the design cycle. Traditional high-level synthesis has attempted to optimize at best the output logic. However, in the ECO scenario the goal is to implement the required change with as few modifications as possible to the RTL, logic netlist, placed netlist and layout. In this paper we show how, by judiciously changing the internal databases used by the tool to match as much as possible the original design, one can achieve minimal impact and implement ECOs in truly incremental mode, while full-blow re-synthesis would lead to massive unnecessary downstream changes. The tool essentially matches source constructs between the original and the ECO design, and copies as many synthesis decisions as possible from the original design to the ECO design.	database;downstream (software development);high- and low-level;high-level synthesis;netlist;requirement;software bug	Luciano Lavagno;Alex Kondratyev;Yosinori Watanabe;Qiang Zhu;Mototsugu Fujii;Mitsuru Tatesawa;Noriyasu Nakayama	2010	2010 15th Asia and South Pacific Design Automation Conference (ASP-DAC)		system on a chip;layout;algorithm design;electronic engineering;logic gate;computer science;systems engineering;engineering;design flow;operating system;processor register;high-level synthesis;engineering change order;multiplexing;computer engineering;integrated circuit design	EDA	13.594455579115868	54.197587257041626	83143
cc603aee3aaadba6068905055ee34d9a8b02b7d4	design of test generator for embedded self-testing		The authors consider the built-in self-test signature model. This article describes the analysis shows the ability of signature schemes, as well as the synthesis of the test generator. The approach is generalized for the case when for the synthesis of the test we use several registers with a common synchronization. Experiments have shown that the method of signature generation circuit design allows the test to predict the length of the test when the built-in self-test. In the study, the authors have achieved a substantial reduction in the length of the test sequence, on average by about 80% compared with a test sequence disordered.	built-in self-test;circuit design;embedded system	Sergey Rodzin	2015	2015 IEEE East-West Design & Test Symposium (EWDTS)	10.1109/EWDTS.2015.7493098	real-time computing;theoretical computer science;automatic test pattern generation;test compression;mathematics;algorithm	EDA	21.394063984778185	50.91162818741227	83145
f106d51999ada6cc43f2cf89170d00fd52ce7715	exploiting non-critical steiner tree branches for post-placement timing optimization		The increasing impact of interconnections on the overall circuit performance renders physical design a crucial step to timing closure. Several techniques are used to optimize timing within the flow, such as gate sizing, buffer insertion, and timing-driven placement (TDP). Unfortunately, gate sizing and buffer insertion are not capable of modifying the length of interconnections. Although TDP is able to shorten critical interconnection by finding new legal locations for a subset of cells, it generally overlooks the impact of non-critical branches on the delay of critical cells. This work proposes a post-placement timing optimization technique to reduce the capacitive load of critical cells by shortening non-critical Steiner tree branches. To shorten such branches, our technique uses computational geometry for finding effective cell movements that consider maximum displacement constraints and macro blocks. Our experiments evaluate the capability of our technique to further reduce the timing violations from a TDP solution. We applied our technique on the solutions obtained by the top 3 teams in the ICCAD 2014 TDP Contest, where short and long displacement constraints are defined. For the short constraints, the average reductions assuming worst and total late negative slack metrics are 23% and 34%. Considering the long constraints, the average reductions are 62% and 67%. We also present extensions of our technique to tackle related physical design problems such as early violations reduction and electrical correction.	computational geometry;displacement mapping;experiment;icfp programming contest;interconnection;international conference on computer-aided design;mathematical optimization;physical design (electronics);rendering (computer graphics);slack variable;steiner tree problem;thermal design power;timing closure	Vinicius S. Livramento;Chrystian Guth;Renan Netto;José Luís Almada Güntzel;Luiz Cláudio Villar dos Santos	2015	2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		mathematical optimization;electronic engineering;real-time computing;steiner tree problem;computer science;engineering;electrical engineering;capacitance;emerging technologies;digital electronics	EDA	15.69345863190314	53.613236836528834	83178
cda64f7f7e4657109f8acc7abe279c4095d74681	on modifying logic networks to improve their diagnosability	test reduction;control logic;diagnosable logic networks;test generation;control logic diagnosable logic networks fault diagnosis improving diagnosability test reduction;improving diagnosability;fault diagnosis	This paper considers the use of control logic to reduce the number of tests required by a logic network and to simplify test generation. The properties of EXCLUSIVE-OR (EOR) circuits as control elements are examined. Systematic procedures are presented for modifying any combinational or sequential network so that the resulting network requires only five tests. These tests can easily be generated using a set of predefined test patterns of length five. The design of diagnosable networks using a limited amount of control logic is also discussed.	combinational logic;european ordering rules;exclusive or;test card	John P. Hayes	1974	IEEE Transactions on Computers	10.1109/T-C.1974.223777	real-time computing;logic optimization;mathematics;algorithm	EDA	21.638729876127304	49.42663861790191	83405
da496c7dceb2480c684aa954a50f840c5c1aae25	a linear programming approach for minimum nbti vector selection	negative bias temperature instability;optimal solution;nbti;chip;critical path;transistor aging;linear programming;age effect;linear program;monte carlo simulation	Transistor aging is a serious reliability challenge for nanoscale CMOS technology which can significantly reduce the operation lifetime of VLSI chips. Negative Bias Temperature Instability (NBTI) is the major contributor to transistor aging which affect PMOS transistors. The input vectors applied to the logic core has a significant impact on the overall aging of the logic block. In this paper, we present an efficient input vector selection technique based on Linear Programming (LP) to be used for maximum relaxation during the standby phase. We consider an accurate delay model for post-aging critical paths. Our mixed-LP (binary-relaxed) formulation scales well for very large circuits and provides near-optimal solutions. Experimental results and comparison with Monte-Carlo simulations show the speedup (4-5 orders of magnitude) and further optimization (11%) of our approach. Using these input vectors for the standby phase, the aging effect can be postponed by 71% in average.	cmos;linear programming relaxation;logic block;mathematical optimization;monte carlo method;negative-bias temperature instability;pmos logic;semiconductor intellectual property core;simulation;speedup;transistor;very-large-scale integration	Farshad Firouzi;Saman Kiamehr;Mehdi Baradaran Tahoori	2011		10.1145/1973009.1973060	negative-bias temperature instability;mathematical optimization;electronic engineering;computer science;engineering;linear programming;electrical engineering	EDA	20.16383747830816	57.7521314424146	83449
0d5a4545d07d584226edea8e073332797c3d4039	cyber-physical management for heterogeneously integrated 3d thousand-core on-chip microprocessor	stress;microprocessors;thousand core microprocessor;heterogeneously integrated 3d thousand core on chip microprocessor;vlsi cyber physical management heterogeneously integrated 3d thousand core on chip microprocessor 3d tsv tsi technology heterogeneous system integration thousand core microprocessor millimeter cubic sensor conventional states mems cmos;mems;clocks;temperature sensors;three dimensional integrated circuits microcomputers micromechanical devices microprocessor chips;drntu engineering electrical and electronic engineering computer hardware software and systems;conventional states;3d tsv tsi technology;conference paper;micromechanical devices;nonvolatile memory;vlsi;millimeter cubic sensor;cmos;microcomputers;heterogeneous system integration;cyber physical management;through silicon vias clocks nonvolatile memory delays stress temperature sensors microprocessors;three dimensional integrated circuits;delays;microprocessor chips;through silicon vias	Though 3D TSV/TSI technology provides the promising platform for heterogeneous system integration with design drivers ranged from thousand-core microprocessor to millimeter-cubic sensor, the fundamental challenge is lack of light to deal with significantly increased design complexity. From device level, new state of variables from different physical domains such as MEMS, microfluidic and NVM devices have to be identified and described together with conventional states from CMOS VLSI; and from system level, cyber management of states of voltage-level and temperature has to be maintained under a real-time demand response fashion. Moreover, a cyber-physical link is required to compress and virtualize device level state details during system level state control. This paper shows device-level 3D integration by example of MEMS and CMOS VLSI. In addition, a cyber-physical thermal management for 3D integrated many-core microprocessors is discussed.	cmos;clock signal;computer cooling;cubic function;embedded system;gnu nano;moe;macromodel;manycore processor;microelectromechanical systems;microprocessor;nanorobotics;non-volatile memory;os-tan;peripheral;power gating;random-access memory;real-time clock;system integration;systems management;thermal management of high-power leds;through-silicon via;time-slot interchange;very-large-scale integration;virtualize	Sai Manoj Pudukotai Dinakarrao;Hao Yu	2013	2013 IEEE International Symposium on Circuits and Systems (ISCAS2013)	10.1109/ISCAS.2013.6571898	embedded system;electronic engineering;real-time computing;non-volatile memory;computer science;engineering;electrical engineering;operating system;microcomputer;microelectromechanical systems;very-large-scale integration;stress;cmos	EDA	14.527289374479613	58.43987489479179	83476
7d74b8ee36620fab91c7a0e687467c6e4d33a01a	redundant logic insertion and fault tolerance improvement in combinational circuits		This paper presents a novel method to identify and insert redundant logic into a combinational circuit to improve its fault tolerance without having to replicate the entire circuit as is the case with conventional redundancy techniques. In this context, it is discussed how to estimate the fault masking capability of a combinational circuit using the truth-cum-fault enumeration table, and then it is shown how to identify the logic that can introduced to add redundancy into the original circuit without affecting its native functionality and with the aim of improving its fault tolerance though this would involve some trade-off in the design metrics. However, care should be taken while introducing redundant logic since redundant logic insertion may give rise to new internal nodes and faults on those may impact the fault tolerance of the resulting circuit. The combinational circuit that is considered and its redundant counterparts are all implemented in semi-custom design style using a 32/28nm CMOS digital cell library and their respective design metrics and fault tolerances are compared.	algorithm;cmos;combinational logic;computational complexity theory;electronic design automation;fault tolerance;logic gate;ork;self-replicating machine;semiconductor industry;simulation;state space;time complexity	P. Balasubramanian;R. T. Naayagi	2017	2017 International Conference on Circuits, System and Simulation (ICCSS)		stuck-at fault;software fault tolerance;automatic test pattern generation;logic optimization;sequential logic;register-transfer level;real-time computing;asynchronous circuit;fault tolerance;engineering	EDA	19.694181205885354	50.51924708619839	83541
e9d9f0be238b811558ff802a1de7abc3dc8c765c	built-in self-test and defect tolerance in molecular electronics-based nanofabrics	reconfiguration;caen;bist;defect density;nanotechnology;built in self test;fault detection;fault coverage;defect tolerance;chemically assembled electronic nanotechnology;molecular electronics;nanofabric;chemically assembled	We propose a built-in self-test (BIST) procedure for nanofabrics implemented using chemically assembled electronic nanotechnology. Several fault detection configurations are presented to target stuck-at faults, shorts, opens, and connection faults in nanoblocks and switchblocks. The detectability of multiple faults in blocks within the nanofabric is also considered. We present an adaptive recovery procedure through which we can identify defect-free nanoblocks and switchblocks in the nanofabric-under-test. The proposed BIST, recovery, and defect tolerance procedures are based on the reconfiguration of the nanofabric to achieve complete fault coverage for different types of faults. We show that a large fraction of defect-free blocks can be recovered using a small number of BIST configurations. We also present simple bounds on the recovery that can be achieved for a given defect density. Simulation results are presented for various nanofabric sizes, different defect densities, and for random and clustered defects. The proposed BIST procedure is well suited for regular and dense architectures that have high defect densities.	algorithm;bridging (networking);built-in self-test;fault coverage;fault detection and isolation;recovery procedure;simulation;software bug;test card;test strategy	Zhanglei Wang;Krishnendu Chakrabarty	2007	J. Electronic Testing	10.1007/s10836-006-0550-z	embedded system;electronic engineering;fault coverage;molecular electronics;engineering;control reconfiguration;fault detection and isolation;computer engineering	EDA	22.13108211742316	51.9657873503358	83549
a04423402b71b26d6a8d118befc13447b6db4ebb	a single-cycle-access 128-entry fully associative tlb for multi-core multi-threaded server-on-a-chip	cache storage;cmos integrated circuits;buffer circuits;chip;random access storage buffer circuits cache storage cmos integrated circuits comparators circuits microprocessor chips;comparators circuits;random access storage;1 1 v single cycle access tlb fully associative multicontext tlb multicore multithreaded server on a chip cmos process dual storage cam cell modified dual matchline ram comparators cache hit priority encoder multimatch detect data parity 65 nm;computer aided manufacturing cadcam circuits clocks read write memory microprocessors random access memory testing mos devices flip flops;microprocessor chips	A single-cycle-access, 128-entry fully-associative multi-context TLB was designed for the Niagara2 SPARCtrade processor in 65nm triple-V, 11M 1.1V CMOS. The circuit includes a dual-storage CAM cell, a modified dual matchline, an 8T 1-read/1-write based RAM, 4-way comparators for cache hit, a priority encoder, a multi-match detect, and data parity	cmos;cpu cache;cache (computing);comparator;multi-core processor;priority encoder;random-access memory;translation lookaside buffer;ultrasparc t2	Shashank Shastry;Ajay Bhatia;Sagar Reddy	2007	2007 IEEE International Solid-State Circuits Conference. Digest of Technical Papers	10.1109/ISSCC.2007.373468	chip;embedded system;parallel computing;computer hardware;telecommunications;computer science;cmos	EDA	15.261373115058817	59.67361728594701	83734
494a7654dc7360057eaec1e8497af0ea3061d586	a hierarchical switch matrix and interconnect resources test in virtex-5 fpga	circuit faults;routing;integrated circuit testing field programmable gate arrays integrated circuit interconnections;wires;built in self test;field programmable gate arrays;switches;table lookup;field programmable gate arrays wires routing circuit faults table lookup switches built in self test;spartan series fpga hierarchical switch matrix interconnect resources test virtex 5 fpga field programmable gate arrays ir architecture hierarchical sm wire segments pip ps programmable interconnect point programmable switches xc4000 fpga repeatable building blocks fault mapping method in house developed test system boundary scan bitstream readback xc5lx110t virtex series virtex 2 series virtex 4 series virtex 5 series virtex 6 series virtex 7 series;interconnect resources fpga virtex 5	With increasing scale of Field Programmable Gate Arrays (FPGAs), architecture of interconnect resources (IRs) in FPGA is becoming more and more complicated. Switch matrix (SM) is one of the most important concepts in the IR architecture. Existing concept of the SM is no longer applicable to these high-end FPGAs. In this paper, based on analysis of the IR architecture in Virtex-5 FPGA, we come up with a concept of hierarchical SM. In the hierarchical SM, IRs are classified into several independent layers of wire segments with programmable-interconnect-point programmable switches (PIP-PSs) in between. The SM in Virtex-5 FPGA consists of several sub-SMs depending on types of wire segments, compared with only one SM in XC4000 FPGA. A full coverage test algorithm for IRs in Virtex-5 was studied by adopting hierarchical SM based repeatable building blocks and fault mapping method. An experiment in XC5LX110T using an in-house developed test system with boundary scan and bitstream readback was carried out. 56 configuration numbers are required to test the XC5LX110T in full coverage. The concept of hierarchical SM and test algorithm is also applicable to Virtex, Virtex-II, Virtex-4, Virtex-5, Virtex-6, 7-series and all Spartan series FPGA as long as SMs are used.	algorithm;bitstream;boundary scan;field-programmable gate array;network switch;spartan;virtex (fpga)	A. W. Ruan;Wanxin Tian;B. Ni;Kaichun Wu	2014	2014 International Symposium on Integrated Circuits (ISIC)	10.1109/ISICIR.2014.7029438	embedded system;electronic engineering;parallel computing;engineering	EDA	11.43388431136413	52.653699949333785	83798
74e7ba1d2d1d7027b548a51d9d747f6ee7aac9b9	a novel fpga architecture supporting wide, shallow memories	embedded systems memory architecture field programmable gate arrays logic design;field programmable gate array;embedded memory;random access memory;logic design;switching circuits;programmable logic arrays;red puerta programable;reseau porte programmable;switch blocks;field programmable gate arrays switches random access memory read write memory switching circuits logic devices memory architecture programmable logic arrays application specific integrated circuits bandwidth;wide shallow memories;embedded systems;user accessible;memory architecture;application specific integrated circuits;fpga architecture;bandwidth;conmutador;configuration memory;read write memory;field programmable gate arrays;switches;benchmark circuit;embedded memory fpga architecture wide shallow memories field programmable gate array configuration memory user accessible switch blocks benchmark circuit;logic devices;field programmable gate arrays fpgas;commutateur;selector switch;field programmable gate arrays fpgas embedded memory	This paper investigates an architecture designed to implement wide, shallow memories on a field programmable gate array (FPGA). In the proposed architecture, existing configuration memory normally used to control the connectivity pattern of the FPGA is made user accessible. Typically, not all the switch blocks in an FPGA are used to transport signals. By adding only a modest amount of circuitry, the configuration memory in these unused switch blocks (or unused paths within used switch blocks) can be used to implement wide, shallow buffers and other similar memory structures. The size of FPGA required to implement a benchmark circuit that makes use of the wide, shallow memories, is 20% smaller than a standard memory architecture. In addition, the benchmark circuit is on average 40% faster using the proposed architecture.	benchmark (computing);electronic circuit;field-programmable gate array	Steven W. Oldridge;Steven J. E. Wilton	2005	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2005.848817	embedded system;electronic engineering;parallel computing;computer hardware;computer science;field-programmable gate array;cache-only memory architecture	Arch	12.017394268595117	52.560245995150495	83970
5a2d3cd5967f0f138a7fa3a55bb90ccd1f2d895e	sat-based automatic rectification and debugging of combinational circuits with lut insertions	look up table;partially programmable circuit;quantified boolean formula;boolean satisfiability	Introducing partial programmability in circuits by replacing some gates with look up tables (LUTs) can be an effective way to improve post-silicon or in-field rectification and debugging. Although finding configurations of LUTs that can correct the circuits can be formulated as a QBF problem, solving it by state-of-the-art QBF solvers is still a hard problem for large circuits and many LUTs. In this paper, we present a rectification and debugging method for combinational circuits with LUTs by repeatedly applying Boolean SAT solvers. Through the experimental results, we show our proposed method can quickly find LUT configurations for large circuits with many LUTs, which cannot be solved by a QBF solver.	boolean satisfiability problem;combinational logic;debugging;formal equivalence checking;image rectification;rectifier;solver;true quantified boolean formula;turing completeness	Satoshi Jo;Takeshi Matsumoto;Masahiro Fujita	2012	2012 IEEE 21st Asian Test Symposium	10.2197/ipsjtsldm.7.46	boolean circuit;and-inverter graph;circuit minimization for boolean functions;lookup table;boolean expression;computer science;theoretical computer science;combinational logic;boolean satisfiability problem;algorithm	EDA	18.457279158787497	48.339814723760384	84108
18ac7c896d641901ea4ec04f3e1c52267d7a100f	hybrid approach to structured asics for minimizing the impact of reticle costs and interconnect delay	180 nm structured asic reticle costs interconnect delay hybrid system design design tradeoffs digital systems interconnects ultra deep sub micron processes hybrid processing approach reduced programmable interconnect levels routing congestion cell based asic technologies standard cell technology comparison metrics maximum clock rate clock latency clock skew ct fan out chip density chip area signal integrity transistor speed;programmable logic devices;logic design;reconfigurable architectures;application specific integrated circuits costs delay integrated circuit interconnections clocks routing field programmable gate arrays production packaging circuit testing;signal integrity;network routing application specific integrated circuits integrated circuit design integrated circuit interconnections programmable logic devices reconfigurable architectures reticles delays logic design integrated circuit measurement logic testing;network routing;integrated circuit design;hybrid approach;application specific integrated circuits;reticles;system design;integrated circuit interconnections;digital systems;logic testing;deep sub micron;clock skew;delays;integrated circuit measurement	System designers face an ever more complex set of tradeoffs in developing advanced digital systems. Transistors are getting faster, interconnect is getting slower, signal integrity issues are getting more complex, and reticle costs are exploding at an exponential rate. This paper takes a look at a unique hybrid processing approach for structured ASICs which reduces reticle costs and avoids many of the interconnect issues associated with ultra-deep sub-micron (UDSM) processes. In particular it investigates the impact of reduced programmable interconnect levels on routing congestion and performance relative to comparable cell-based ASIC technologies. Two designs are used to compare structured ASICs to a 180nm standard cell technology. The comparison metrics include maximum clock rate, density, area, clock latency, clock skew and CT fan out.	application-specific integrated circuit;clock rate;clock skew;digital electronics;digital signal processor;fan-out;network congestion;routing;signal integrity;standard cell;time complexity;transistor	Otis B. Brown;Reed Packer;Jagdish Prasad;Khris Kofford;Troy Dye;Bob Kirk	2004	Proceedings of the IEEE 2004 Custom Integrated Circuits Conference (IEEE Cat. No.04CH37571)	10.1109/CICC.2004.1358841	embedded system;routing;electronic engineering;logic synthesis;real-time computing;reticle;clock skew;computer science;signal integrity;engineering;programmable logic device;application-specific integrated circuit;integrated circuit design;systems design	EDA	13.788723872056435	56.07103215981057	84381
3a1f288ceada9fa8e76817230315a5e7953e4d63	markovian analysis of large finite state machines	verification;concepcion asistida;computer aided design;concepcion circuito;chaine markov;arbitrary transition structures markovian analysis finite state machines probabilistic methods logic synthesis formal verification symbolic algorithms steady state probabilities algebraic decision diagrams discrete parameter markov chains chapman kolmogorov equations state graphs gauss jacobi iteration matrix multiplication;state space methods;cadena markov;probability;integrated circuit;boolean functions;maquina estado finito;decision diagram;circuit design;circuito integrado;network analysis;algorithme;iterative methods;algorithm;finite state machines;formal verification;logic synthesis;logic partitioning finite state machines markov processes probability logic cad boolean functions iterative methods state space methods;analyse performance;performance analysis;conception assistee;conception circuit;markov processes;verificacion;logic partitioning;machine etat fini;logic cad;analyse circuit;automata steady state probabilistic logic formal verification data structures boolean functions state space methods equations gaussian processes matrix decomposition;finite state machine;analisis circuito;circuit integre;steady state;algoritmo;markov chain;analisis eficacia	Regarding nite state machines as Markov chains facilitates the application of probabilistic methods to very large logic synthesis and formal veriication problems. In this paper we present symbolic algorithms to compute the steady-state probabilities for very large nite state machines (up to 10 27 states). These algorithms, based on Algebraic Decision Diagrams (ADDs) | an extension of BDDs that allows arbitrary values to be associated with the terminal nodes of the diagrams | determine the steady-state probabilities by regarding nite state machines as homogeneous, discrete-parameter Markov chains with nite state spaces, and by solving the corresponding Chapman-Kolmogorov equations. We rst consider nite state machines with state graphs composed of a single terminal strongly connected component; for this type of systems we have implemented two solution techniques: One is based on the Gauss-Jacobi iteration, the other one is based on simple matrix multiplication. Then we extend our treatment to the most general case of systems which can be modeled as nite state machines with arbitrary transition structures; here our approach exploits structural information to decompose and simplify the state graph of the machine. We report experimental results obtained for problems on which traditional methods fail.	algorithm;connected component (graph theory);diagram;finite-state machine;iteration;jacobi method;kolmogorov equations;logic synthesis;markov chain;matrix multiplication;steady state;strongly connected component	Gary D. Hachtel;Enrico Macii;Abelardo Pardo;Fabio Somenzi	1996	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.552081	state transition table;markov chain;mathematical optimization;richards controller;combinatorics;discrete mathematics;logic synthesis;verification;state diagram;influence diagram;network analysis;formal verification;quantum finite automata;computer science;integrated circuit;circuit design;probability;mathematics;iterative method;markov process;finite-state machine;boolean function;steady state;algorithm;statistics;abstract state machines	EDA	19.114624318613707	47.18667850145057	84458
729f06ba366f2e9e8d133ed9829e68d65a56233d	dependent latch identification in the reachable state space	state space methods;cpu time;logic design;boolean functions;sequential circuits flip flops formal verification logic design;sequential circuits;flip flops;functional dependency;formal verification;binary decision diagrams;logic synthesis;data structures;state space;digital design;dependent latch identification;reachable state space;latches;reachability analysis dependent latch identification reachable state space digital design formal verification logic synthesis binary decision diagram based symbolic algorithm sequential circuits cpu time;state space methods latches sequential circuits formal verification logic design data structures boolean functions reachability analysis binary decision diagrams central processing unit;reachability analysis dependent latch identification;reachability analysis;central processing unit;binary decision diagram based symbolic algorithm;binary decision diagram	The large number of latches in current designs increase the complexity of formal verification and logic synthesis, since the growth of latch number leads the state space to explode exponentially. One solution to this problem is to find the functional dependencies among these latches. Then, these latches can be identified as dependent latches or essential latches, where the state space can be constructed using only the essential latches. This paper proposes an approach to find the functional dependencies among latches in a sequential circuit by using SAT solvers with the Craig interpolation theorem. In addition, the proposed approach detects sequential functional dependencies existing in the reachable state space only. Experimental results show that our approach could deal with large sequential circuits with up to 1.5K latches in a reasonable time and simultaneously identify the combinational and sequential dependent latches.	combinational logic;formal verification;functional dependency;interpolation;logic synthesis;sequential logic;state space	Chen-Hsuan Lin;Chun-Yao Wang	2009	2009 Asia and South Pacific Design Automation Conference	10.1109/TCAD.2009.2020720	embedded system;electronic engineering;discrete mathematics;logic synthesis;real-time computing;data structure;computer science;operating system;mathematics;programming language;algorithm	EDA	18.743439530166164	48.1334135969978	84580
4b7b62d4dfcfb057f480cbd04c1e3d07e4370625	coupling-aware high-level interconnect synthesis for low power	bus synthesis algorithms;synthesis algorithm;proposed integrated low-power bus;integrated circuit interconnections;power consumption;power dissipation;soc;ultra deep submicron technology;integrated low-power bus synthesis;bus data transfer binding;synthesis process;microarchitecture synthesis;coupling-aware high-level interconnect synthesis;signal line;circuit optimisation;low-power electronics;bus synthesis algorithm;system-on-chip;system buses;line coupling capacitances;signal line transition activities;vlsi;circuit cad;integrated circuit design;low power;bus power dissipation;scheduled dataflow graphs;circuit optimization;benchmark problem;integrated fashion;high level synthesis;low power udsm vlsi;power consumption reduction;system on chip;low power electronics;data transfer	Ultra deep submicron (UDSM) technology and system-on-chip (SoC) have resulted in a considerable portion of power dissipated on buses, in which the major sources of the power dissipation are (1) the transition activities on the signal lines and (2) the coupling capacitances of the lines. However, there has been no easy way of optimizing (1) and (2) simultaneously at an early stage of the synthesis process. In this paper, we propose a new (onchip) bus synthesis algorithm to minimize the total sum of (1) and (2) in the microarchitecture synthesis. Specifically, unlike the previous approaches in which (1) and (2) are minimized sequentially without any interaction between them, or only one of them is minimized, we, given a scheduled dataflow graph to be synthesized, minimize (1) and (2) simultaneously by formulating and solving the two important issues in an integrated fashion: binding data transfers to buses and determining a (physical) order of signal lines in each bus, both of which are the most critical factors that affect the results of (1) and (2). Experimental results on a number of benchmark problems show that the proposed integrated low-power bus synthesis algorithm reduces power consumption by 24.8%, 40.3% and 18.1% on average over those in (J. Chang et al, Proc. of DAC, 1995) (for minimizing (1) only), (Y. Shin et al, Proc. of DAC, 2001) (for (2) only) and (both references) (for (1) and then (2)), respectively.	high- and low-level	Chun-Gi Lyuh;Taewhan Kim;Ki-Wook Kim	2002		10.1109/ICCAD.2002.1167595	system on a chip;embedded system;electronic engineering;parallel computing;computer science;engineering;dissipation;operating system;very-large-scale integration;high-level synthesis;low-power electronics;integrated circuit design	EDA	14.291616403523873	53.24114428665093	84753
5d4e93b8bac5ac0071602737c03058267842e5ae	evaluation of read- and write-assist circuits for geoi finfet 6t sram cells	sram chips mosfet circuits;geoi finfet;read assist;finfets sram cells wireless sensor networks circuit stability noise;static noise margin;write assist;proceedings paper;sram;temperature 125 c read assist circuits write assist circuits geoi finfet sram cells word line under drive read assist read static noise margin soi negative bit line write assist write static noise margin temperature 25 c;static noise margin read assist write assist geoi finfet sram	This paper evaluates the impacts of Read- and Write-Assist circuits on the GeOI FinFET 6T SRAM cells compared with the SOI counterparts. The Word-Line Under-Drive (WLUD) Read-Assist is more efficient to improve the Read Static Noise Margin (RSNM) and Read VMIN of FNSP GeOI FinFET SRAM cells compared with the SOI counterparts. GeOI FinFET SRAM cells with WLUD show smaller cell Read access-time compared with the SOI FinFET SRAM cells at both 25°C and 125 °C. Negative Bit-Line (NBL) Write-Assist is more efficient to improve the Write Static Noise Margin (WSNM) than VCS (cell supply) lowering for both GeOI and SOI FinFET SRAM cells. NBL Write-Assist shows larger WSNM improvement for GeOI FinFET SRAM cells than the SOI counterparts at 125°C.	noise margin;silicon on insulator;static random-access memory;veritas cluster server	Vita Pi-Ho Hu;Ming-Long Fan;Pin Su;Ching-Te Chuang	2014	2014 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2014.6865337	electronic engineering;parallel computing;static random-access memory;computer hardware;computer science;operating system	EDA	17.701914473761335	59.197863563840855	84790
c70aa29e1c561238b3542f5bb23464c457fcdf61	establishing latch correspondence for sequential circuits using distinguishing signatures	verification;digital circuit;fonction booleenne;diagrama binaria decision;diagramme binaire decision;metodologia;integrated circuit;circuito secuencial;sequential circuits;circuit sequentiel;boolean function;circuito integrado;correspondence problem;methodologie;circuit numerique;codificacion;funcion booliana;coding;signature;circuito numerico;verificacion;methodology;signing;combinational circuit;firma;finite state machine;circuit integre;combinational equivalence checking;codage;binary decision diagram;sequential circuit	This paper addresses the problem of establishing the unknown correspondence for the latch variables of two sequential circuits which have the same state encoding. This has direct application in finite state machine verification: If a one-to-one correspondence can be established between the latches of two circuits, then checking for their equivalence reduces to a much simpler combinational equivalence check problem. The approach presented in this paper is based on methods used to solve the unknown correspondence problem for inputs and outputs in combinational circuits. It computes input and novel latch output signatures, using ROBDDs, for each latch variable of a circuit that help to establish correspondence. Experimental results on a large set of benchmarks show the efficacy of this approach. ( 1999 Elsevier Science B.V. All rights reserved.	benchmark (computing);combinational logic;correspondence problem;electronic signature;finite-state machine;one-to-one (data model);turing completeness;type signature	Janett Mohnke;Paul Molitor;Sharad Malik	1999	Integration	10.1016/S0167-9260(98)00014-5	electronic engineering;discrete mathematics;computer science;mathematics;sequential logic;finite-state machine;algorithm	EDA	20.147181193636772	48.204251463829095	84899
88e23454dd3a6f204d88f429ddde04c3331a8b9a	optimal design of the $k$ -out-of- $n$ : g (f) majority voter		"""The <inline-formula> <tex-math notation=""""LaTeX"""">$k$ </tex-math></inline-formula>-out-of-<inline-formula> <tex-math notation=""""LaTeX"""">$n$ </tex-math></inline-formula>: G (F) majority voter usually consists of <inline-formula> <tex-math notation=""""LaTeX"""">$n$ </tex-math></inline-formula> components (modules), and such a system is critical to ensure the correct operation of various computing systems for numerous critical applications. For a <inline-formula> <tex-math notation=""""LaTeX"""">$k$ </tex-math></inline-formula>-out-of-<inline-formula> <tex-math notation=""""LaTeX"""">$n$ </tex-math></inline-formula>: G (F) majority voter, a specific number of the components are required to operate correctly for the overall system to function. To deal efficiently with the reliability evaluation of a general majority voter, a stochastic architecture can be adopted. The corresponding system reliability can be obtained through analyzing the output sequence. Usually, the system reliability is improved if more components or redundancies are used. Nevertheless, the consumed cost or required space also increases accordingly. In this paper, a tradeoff between the cost and reliability value was made to pursue the most desirable design. The relationship between the cost and corresponding component parameters is also discussed thoroughly in this paper. Then, to find the most cost-effective design, a new evaluation standard was proposed, referred to as the <inline-formula> <tex-math notation=""""LaTeX"""">$R\_{}per\_{}Cost$ </tex-math></inline-formula>. Furthermore, the optimal designs under different standards are presented for the investigated example. The results are also pursued with respect to an analysis of several case studies."""	optimal design	Xiaogang Song;Zhengjun Zhai;Ruoning Lv;Yangming Guo;Peican Zhu	2017	IEEE Access	10.1109/ACCESS.2017.2761776	architecture;redundancy (engineering);theoretical computer science;distributed computing;computer science;optimal design;logic gate;stochastic process	EDA	10.494584558239596	59.55700957520312	85115
bf8ae71ff6bd4d294f2d3ab57e3f8b319116273a	improved alternative wiring scheme applying dominator relationship	redundancy addition and removal;low power system design;integrated circuit layout;intellectual property;boolean functions;multivalued logic circuits;system level modeling;trees mathematics;system on a chip;redundancy;tree structure;circuit layout cad;cores;solution quality alternative wiring problem dominator relationship redundant connection redundancy addition multi level boolean optimization execution time redundancy identification implication tree based alternative wiring logic transformation algorithm source node identification mcnc benchmark circuits;circuit layout cad wiring redundancy multivalued logic circuits boolean functions circuit optimisation trees mathematics logic cad integrated circuit layout;wiring;circuit optimisation;logic cad;parameterized architectures;wiring wire automatic test pattern generation circuit optimization computer science logic field programmable gate arrays circuit synthesis delay random access memory	In this paper, we present a competent algorithm to the alternative wiring problem by exploring the relationship between dominators of a target wire. Alternative wiring refers to the process of adding a redundant connection to a circuit such that a target connection will become redundant and can be removed from the circuit. The well-known ATPG-based alternative wiring scheme. Redundancy Addition and Removal for Multi-level Boolean Optimization (RAMBO), has shown its effectiveness in solving the problem in the last decade. The deficiency of RAMBO lies in its long execution time for redundancy identification among a large set of candidate alternative wires in the circuit. Implication-tree Based Alternative Wiring Logic Transformation Algorithm (IBAW) improves the speed of RAMBO by introducing an implication-tree structure for source node identification. Our approach of investigating the dominator relationship suggest that a large subset of unnecessary redundancy checks can be further avoided in order to improve the efficiency. Experiments were performed on MCNC benchmark circuits and results are compared to those of RAMBO and IBAW. Results show that our proposed algorithm improves IBAW with a 2.3 times speedup. Moreover, our implementation runs 8.8 times faster than RAMBO while solution quality is still maintained.	algorithm;angular defect;benchmark (computing);dominator (graph theory);run time (program lifecycle phase);speedup;tree structure;whole earth 'lectronic link;wiring	Cliff C. N. Sze;Yu-Liang Wu	2001		10.1145/370155.370515	system on a chip;multi-core processor;embedded system;electronic engineering;computer science;theoretical computer science;integrated circuit layout;tree structure;boolean function;redundancy;algorithm;intellectual property	EDA	16.431646671739912	49.14016151389821	85134
4b738d3a59a077a42cb756d9e7610c2d59a140ec	delay computation in combinational logic circuits: theory and algorithms	combinational circuits delay estimation algorithm design and analysis upper bound logic testing propagation delay sufficient conditions wire computational modeling circuit simulation;combinatorial circuits;longest path;integrated logic circuits combinatorial circuits delays;delay computation static cosensitisation combinational logic circuits false paths testability equivalent normal form multilevel circuit false path eliminating static timing analyzers;necessary and sufficient condition;normal form;integrated logic circuits;modes of operation;delays	The authors provide necessary and sufficient conditions for a path to be true in the floating mode of operation. Static cosensitization is introduced as a necessary condition, which allows one to avoid the problem of identifying false paths as responsible for delay. The results are extended to determine the truth or falsity of entire sets of paths simultaneously by expressing them in terms of the testability of a multifault in an ENF (equivalent normal form) expression. This result is applied directly to an unmodified multilevel circuit. Because the circuits that are most troublesome for false-path-eliminating static timing analyzers are those with millions of paths, and in particular millions of longest paths, the ability to handle entire sets of paths simultaneously results in a very efficient delay computation procedure. This is demonstrated by the results from a preliminary implementation of the algorithm. >	algorithm;combinational logic;computation	Srinivas Devadas;Kurt Keutzer;Sharad Malik	1991		10.1109/ICCAD.1991.185224	electronic engineering;discrete mathematics;delay calculation;longest path problem;theoretical computer science;mathematics;algorithm	EDA	19.575307980736458	48.381248000320134	85146
fa1263211d0ee8d5c0c7bf85538a9b8ccb147378	ic mask layout with a single conductor layer	computer program	A computer program for the automatic layout of single conductor layer IC masks is described. Descriptions are included of element modelling, element placement, grid expansion, cross-over minimization, conductor routing and layout compaction.	automatic layout;computer program;data compaction;integrated circuit layout;routing;variable shadowing	Sheldon B. Akers;James M. Geyer;Donald L. Roberts	1970		10.1145/800160.805107	electronic engineering;parallel computing;ic layout editor;computer science;integrated circuit layout;engineering drawing	EDA	13.305002008922655	50.82400340117085	85407
5202ef8f23eb591b4735a0b1bc5de9360ed853ed	on-chip interconnection architecture optimization using a multicommodity flow approach	wire style optimization;noc optimization;noc topology library;multicommodity flow approach;noc power consumption;fpga global routing architecture;certain noc topology;mcf formulation;power consumption;communication latency;on-chip interconnection architecture optimization;noc design	Recent technology advent makes the efficient on-chip interconnection architecture critical in modern IC design. First, on-chip communication requirements are dramatically increasing due to the continuously shrinking of the device feature size and integration of billions of transistors on a single chip. Second, the interconnects, rather than devices, become the dominant factors in deciding performance and power consumption of VLSI systems. As a result, we are urged to optimize interconnection architecture to improve the overall system performance. In this dissertation, we propose a methodology to optimize the power consumption or communication latency of two promising on-chip interconnection architectures, Network- on-Chip (NoC) and FPGA global routing architecture. Our methodology adopts two optimization schemes, topology optimization and wire style optimization, and uses multicommodity flow (MCF) models to perform and evaluate these optimizations. We implement and optimize the MCF solver using polynomial approximation algorithms, which are significantly faster than the commercial linear programming solver CPLEX. For NoC optimization, our objective is to search for most power efficient NoC topologies and their wire assignments, which at the same time satisfy all communication latency and bandwidth requirements. We use MCF formulations to model this problem, and build NoC topology library and its power and delay library as inputs to MCF formulations. The solution of MCF formulations indicates the estimated NoC power consumption under a certain NoC topology and wire style assignments, from which we can observe the best NoC optimization. The experimental results show that our methodology can effectively improve the NoC power consumption or communication latency. The results also indicate the importance of power and latency co- optimization in NoC design. For FPGA global routing architecture optimization, we study segmentation distribution, flexible track assignment and wire style optimization. The objectives are power consumption and switch area density. The design methodology is also based on MCF formulations. We examine our FGPA routing architecture optimization by a set of standard MCNC benchmark circuits. The experimental results show that our optimized FPGA routing architectures achieve average up to 10% to 15% power savings and up to 20% switch area savings when compared to traditional FPGA architecture	interconnection;mathematical optimization	Yuanfang Hu	2007			electronic engineering;parallel computing;real-time computing;engineering	Arch	14.149403561182979	53.48655886173894	85591
b0219fc9d4eacdaa28109d8fe04633d5d24737e1	on concurrent test of wrapped cores and unwrapped logic blocks in socs	test instructions;design for testability;embedded cores;ieee standards;test scheduling algorithm wrapped cores unwrapped logic blocks system on a chip soc embedded cores testrail architecture test control mechanism test instructions ieee standard;wrapped cores;test scheduling algorithm;automatic test pattern generation;embedded core testing;system on chip automatic test pattern generation design for testability ieee standards integrated circuit testing logic testing;system on a chip;unwrapped logic blocks;test control mechanism;system on chip;testrail architecture;logic testing;integrated circuit testing;soc;test scheduling;ieee standard;logic circuit testing;logic testing system testing system on a chip circuit testing integrated circuit testing automatic testing timing logic circuits manufacturing integrated circuit interconnections	System-on-a-chip designs may contain user defined logic or embedded cores that cannot be wrapped for test purposes due to area constraints or timing violations. This paper discusses how these unwrapped logic blocks can be tested rapidly through the TestRail architecture using only the test control mechanism and the test instructions available through IEEE standard for embedded core test. A new test scheduling algorithm, which facilitates concurrent test of both unwrapped logic blocks and wrapped cores, is proposed and experiments show that it outperforms a previous approach when the available number of tester channels and/or the number of unwrapped logic blocks are small	algorithm;embedded system;experiment;logic gate;scheduling (computing);system on a chip;test management tools	Qiang Xu;Nicola Nicolici	2005	IEEE International Conference on Test, 2005.	10.1109/TEST.2005.1584021	system on a chip;embedded system;computer architecture;real-time computing;computer science	EDA	10.871198940174366	53.47066590728928	85673
c9f271ce108e42870161a30db0683c74b11bbaf4	accelerating high-level bounded model checking	industry design;boolean-level bmc;high-level bounded model checking;sat-based bounded model checking;design size;inherent limitation;high-level design information;bmc problem formulation;high-level bmc;efsm model;bmc problem instance;formal verification;industrial design;high level design;computability	"""SAT-based Bounded Model Checking (BMC) has been found promising in finding deep bugs in industry designs and scaling well with design sizes. However, it has limitations due to requirement of finite data paths, inefficient translations and loss of high-level design information during the BMC problem formulation. These shortcomings inherent in Boolean-level BMC can be avoided by using high-level BMC. We propose a novel framework for high-level BMC, which includes several techniques that extract high-level design information from EFSM models to make the verification model """"BMC friendly"""", and use it on-the-fly to simplify the BMC problem instances. Such techniques overcome the inherent limitations of Boolean-level BMC, while allowing integration of state-of-the-art techniques for BMC. In our controlled experiments we found signficant performance improvements achievable by the proposed techniques."""	high- and low-level;model checking	Malay K. Ganai;Aarti Gupta	2006		10.1109/ICCAD.2006.320122	real-time computing;industrial design;formal verification;computer science;theoretical computer science;computability;programming language;algorithm;high-level design	EDA	17.408067133771173	47.48775114425463	85741
2a91582833c09a5ee9edd1d5c36b6cd5d6f8187b	an efficient controlled lfsr hybrid bist scheme			built-in self-test;linear-feedback shift register	Tieqiao Liu;Peng Liu;Yi Liu	2018	IEICE Electronic Express	10.1587/elex.15.20180144	electronic engineering;computer science;linear feedback shift register	ECom	22.826123942238826	51.39257600347766	85788
75e3abd8bbd8ca3439c96fd39b17af7f87d5efc7	a low power multimedia processor implementing dynamic voltage and frequency scaling technique	cmos integrated circuits;size 90 nm video encoding applications power reduction power dissipation optimum supply voltage optimum clock frequency a2bc algorithm cmos multimedia processor dvfs frequency scaling technique dynamic voltage technique low power multimedia processor;multimedia systems cmos integrated circuits low power electronics microprocessor chips;multimedia communication encoding process control streaming media prediction algorithms clocks signal processing algorithms;multimedia systems;low power electronics;microprocessor chips	A DVFS controlled 90-nm CMOS multimedia processor was developed. To make full use of the advantages of DVFS, we developed the A2BC algorithm that can predict the optimum clock frequency and the optimum supply voltage. The measured power dissipation of the DVFS controlled multimedia processor was significantly reduced. Thus, DVFS employing the A2BC algorithm is one of the most useful power reduction for future video encoding applications.	algorithm;cmos;clock rate;data compression;dynamic frequency scaling;dynamic voltage scaling;image scaling	Tadayoshi Enomoto;Nobuaki Kobayashi	2013	2013 18th Asia and South Pacific Design Automation Conference (ASP-DAC)	10.1109/ASPDAC.2013.6509563	embedded system;electronic engineering;real-time computing;computer science;operating system;cmos;low-power electronics	EDA	12.087820913916346	48.166262800316105	85913
85d6ea95bcec052cd6cda16a1ce560d1d7739348	soda: sensitivity based optimization of disk architecture	optimization algorithms performance design disk drives storage power performance;electro mechanical behavior soda sensitivity based optimization of disk architecture digital circuit design disk drives;disc drives;network synthesis;performance;disk drives;design space;sensitivity based optimization of disk architecture;sensitivity analysis;electro mechanical behavior;design optimization disk drives dc motors runtime delay circuit synthesis cooling energy consumption constraint optimization throughput;algorithms;design;optimization;soda;digital circuits;performance optimization;storage;digital circuit design;power;sensitivity analysis disc drives network synthesis	"""Storage plays a pivotal role in the performance of many applications. Optimizing disk architectures is a design-time as well as a run-time issue and requires balancing between performance, power and capacity. The design space is large and there are many """"knobs"""" that can be used to optimize disk drive behavior. Here we present a sensitivity-based optimization for disk architectures (SODA) which leverages results from digital circuit design. Using detailed models of the electro-mechanical behavior of disk drives and a suite of realistic workloads, we show how SODA can aid in design and runtime optimization."""	digital electronics;disk storage;integrated circuit design;mathematical optimization;optimizing compiler;program optimization	Yan Zhang;Sudhanva Gurumurthi;Mircea R. Stan	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278694	control engineering;design;mathematical optimization;real-time computing;computer hardware;performance;computer science;engineering;electrical engineering;power;sensitivity analysis;algorithm	EDA	15.042782717859689	56.08303526751449	85914
7aa6e9af323422195da6a9566d28023162ad84f4	rt-level tpg exploiting high-level synthesis information	genetic algorithms automatic test pattern generation high level synthesis logic testing integrated circuit testing vlsi digital integrated circuits;automatic test pattern generation;high level synthesis;digital integrated circuits;logic testing;integrated circuit testing;vlsi;genetic algorithm;genetic algorithms;test pattern generator;high level synthesis circuit testing test pattern generators circuit faults system testing performance evaluation automatic test pattern generation automatic control electronic switching systems genetics;hls rt level tpg high level synthesis information high level test pattern generation fully automated atpg system simulation based atpg system testability metrics genetic algorithms fault coverage large circuits control intensive designs	High-level test pattern generation is today a widely investigated research topic. The present paper proposes a fully automated, simulation-based ATPG system, to address test pattern generation for circuits described at the RT-level. The approach is based on a set of suitable testability metrics, and the test pattern generation phase resorts to Genetic Algorithms. Experiments show the excellent fault coverage provided by the RT-level test patterns, when applied at the final gate-level. The approach, being based on a high-level representation, promises to be particularly suited where gate-level ATPGs are often inefficient, mainly for large circuits and for control-intensive designs.	experiment;fault coverage;genetic algorithm;high- and low-level;high-level synthesis;simulation;test card	Silvia Chiusano;Fulvio Corno;Paolo Prinetto	1999		10.1109/VTEST.1999.766685	computer architecture;electronic engineering;real-time computing;genetic algorithm;fault coverage;computer science;stuck-at fault;automatic test pattern generation;test compression	EDA	12.790160172367946	51.14234605224819	86086
efac0540603755a7aefad98e67c3eb4064863e96	guest editors introduction: security of beyond cmos devices: issues and opportunities		Aggressive scaling of CMOS in the quest of smaller and faster transistors has brought us into the sub 10-nm technology era with the end of CMOS roadmap in sight. Number of alternative nanoscale devices – both silicon and non-silicon – with interesting switching characteristics have come onto the horizon. They promise to replace CMOS as computing and/or information carrier devices. Effective combination of innovative device structures with fundamental physical properties of materials and possibly entirely new state variables (e.g., mechanical state, electron spin) to represent information give rise to attractive functional properties of these nanoscale devices. These devices, however, primarily have been studied at different levels – from device physics to circuits and architecture – from the perspective of traditional device parameters – e.g., performance, power, reliability, non-volatility, and manufacturability. Security implications for these emerging nanoscale devices is an important and integral topic in system design which has not received adequate attention by the researchers. These devices are poised to make profound impact in the design of secure information processing systems by creating new attack modalities, changing the effectiveness of current attack models and countermeasures, and by enabling new approaches to secure designs that leverage their unique characteristics. In order to provide a foundation for secure electronics and computing in the nanoscale era, we need to develop a deep understanding of the impact of nanoscale device characteristics to higher layers of design abstraction, where threat models and security properties are meaningfully defined. On one hand, we need to understand the device physics and operation of emerging devices as well as security primitives and attack models on the other. Such understanding will lead to the development of circuit-compatible models for these devices and design/analysis of common security primitives such as Physical Unclonable Functions (PUFs), Random Number Generators (RNGs), anti-cloning circuits, aging sensors, and cryptographic circuits. Furthermore, it will enable us to analyze the efficacy of existing attacks, such as side-channel attacks, aging attacks, counterfeiting, hardware intellectual property (IP) piracy, hardware Trojan attacks etc., and to discover unprecedented attack modalities. Finally, new defense mechanisms (e.g., new design of security primitives or more powerful cryptographic solution) may be enabled by the unique characteristics of nanoscale devices. With these observations in mind, this special issue aims at comprehensively covering security issues with beyond-CMOS devices and emerging security solutions for systems built with these devices. It is our great pleasure to publish this special issue on security issues and opportunities for emerging post-CMOS nanoscale devices. This special issue contains the following four high-quality papers on diverse topics in nanoscale device security. Technical contributions in these papers range from security analysis for emerging devices to exploring design of new security primitives with them. We are extremely happy to choose these articles with distinctive contribution for this issue. (1) (260) “Performance Enhancement of a Time-Delay PUF Design by Utilizing Integrated Nanoscale ReRAM Devices”, by K. Beckmann et al. (2) (265) “Timing Attack and Countermeasure on NEMS Relay Based Design of Block Ciphers”, by B.Mazumdar et al. (3) (278) “Univariate Power Analysis Attacks Exploiting Static Dissipation of Nanometer CMOS VLSI Circuits for Cryptographic Applications”, by G. Scotti et al. (4) (291) “Tunnel FET Current Mode Logic for DPAResilient Circuit Designs”, by Y. Jin et al. We believe the collection of articles in this special issue will help advance the security theory of nanoscale devices and stimulate interest for further research in this important topic. The selected articles are expected to answer some of the key questions in nanoscale security, as follows: What new attack models will emerge in the nanoscale era? How can we project the characteristics of nanoscale devices to system security properties? How effective are the existing countermeasures against known attack models? Will emerging devices provide new opportunities for building security primitives or countermeasures against various hardware security issues (e.g., side-channel attacks, Trojan attacks, IP piracy, etc.)? We sincerely hope that you enjoy reading this special issue, and would like to thank all authors and reviewers for their tremendous efforts and contributions in producing these high-quality articles. We also take this opportunity to thank the IEEE Transactions on Emerging Topics in Computing (TETC) Editor-in-Chief (EIC) Prof. Fabrizio Lombardi, Digital Object Identifier 10.1109/TETC.2017.2738978	attack model;beyond cmos;block cipher;computer security;countermeasure (computer);cryptography;current-mode logic;data security;design for manufacturability;earth inductor compass;electron;hardware trojan;identifier;image scaling;information processing;non-volatile memory;relay;resistive random-access memory;sensor;side-channel attack;systems design;threat model;transistor;trojan horse (computing);very-large-scale integration;volatility	Swarup Bhunia;An Chen;Ozgur Sinanoglu;Jason M. Fung	2017	IEEE Trans. Emerging Topics Comput.	10.1109/TETC.2017.2738978	computer science;modalities;electronics;computer network;computer security;beyond cmos;information processing;systems design;attack model;threat model;countermeasure	Security	11.620771103585716	58.63300766695229	86280
9594b8df6d9a4cf7bbe91001e231d4a9aa3d3e45	distributed genetic algorithms for the floorplan design problem	computer aided design;concepcion circuito;integrated circuit;annealing;etude experimentale;very large scale integration;cad;distributed processing;circuit design;genetic algorithms algorithm design and analysis simulated annealing very large scale integration design optimization costs area measurement circuits large scale systems message passing;circuit vlsi;circuito integrado;distributed genetic algorithms;punctuated equilibria cad floorplan design vlsi floorplan distributed genetic algorithms paleontological theory;trees mathematics;simulated annealing;design optimization;searching;punctuated equilibria;vlsi circuit;integrated circuit technology;average cost;weighted sums;algorithme reparti;computerized simulation;vlsi floorplan;message passing;algorithme genetique;vlsi;area measurement;algorithms;distributed genetic algorithm;genetic algorithm;circuit layout cad;genetic algorithms;conception circuit;circuits;circuito vlsi;distributed algorithm;superconducting devices;estudio experimental;algorithm design and analysis;paleontological theory;circuit integre;floorplan design;large scale systems;vlsi circuit layout cad integrated circuit technology	Floorplan design is an important stage in the VLSI design cycle. Designing a floorplan calls for arranging a given set of modules in the plane to minimize the weighted sum of area and wirelength measures. This paper presents a method to solve the floorplan design problem using distributed genetic algorithms. Distributed genetic algorithms, based on the paleontological theory of punctuated equilibria, offer a conceptual modification to the traditional genetic algorithms. Experimental results on several problem instances demonstrate the efficacy of our method, and point out the advantages of using this method over other methods, such as simulated annealing. Our method has performed better than the simulated annealing approach, both in terms of the average cost of the solutions found and the best-found solution, in almost all the problem instances tried.	genetic algorithm;simulated annealing;very-large-scale integration;weight function	James P. Cohoon;Shailesh U. Hegde;Worthy N. Martin;Dana S. Richards	1991	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.75631	distributed algorithm;mathematical optimization;electronic engineering;genetic algorithm;computer science;electrical engineering;theoretical computer science;computer aided design;very-large-scale integration;algorithm	EDA	14.640780698878373	50.57243992124779	86335
e12c91e93308e74a9aa0bf78520435c4e65e216c	a diagnosability metric for test set selection targeting better fault detection	probability;integrated circuit yield;time complexity;probability fault detection diagnosability metric test set selection targeting manufactured chip failure yield enhancement viewpoint fault pairs diagnostic power space complexity time complexity fault coverage;circuit faults measurement dictionaries fault diagnosis complexity theory very large scale integration integrated circuit modeling;clustering of faults fault diagnosis fault dictionary;clustering of faults;chip;fault dictionary;probability computational complexity fault diagnosis integrated circuit testing integrated circuit yield microprocessor chips;computational complexity;fault detection;integrated circuit testing;fault coverage;fault diagnosis;microprocessor chips	Diagnosis is the methodology to identify the reason behind the failure of manufactured chips. This is particularly important from the yield enhancement viewpoint. The primary focus of a diagnosis algorithm is to accurately narrow down the list of suspected candidates. But for any diagnosis algorithm, the effectiveness will depend on the test set in use. If the test set used is not good enough to distinguish between fault pairs, the diagnosis algorithm can never be able to distinguish between a good number of faults. This problem leads us to find a metric which can characterize test sets in terms of their diagnostic power. In literature, several methods have been proposed for assessment of the diagnostic power of a test set. Though the methods are accurate in nature, the bottleneck is the space and time complexity. Thus, given a number of test sets (with same fault coverage) for a circuit, it is very difficult to select one of them for better diagnosis. In this paper, we have proposed a probability based approach to find out a metric to describe diagnostic power of a test set. We call this metric, the diagnosibility of the test set for a given circuit. Our method uses almost 99% less space compared to the proposed methods and is well accurate.	fault coverage;integrated circuit;medical algorithm;principle of good enough;requirement;test set;time complexity	Subhadip Kundu;Santanu Chattopadhyay;Indranil Sengupta;Rohit Kapur	2012	2012 25th International Conference on VLSI Design	10.1109/VLSID.2012.110	chip;time complexity;reliability engineering;electronic engineering;real-time computing;fault coverage;computer science;automatic test pattern generation;probability;computational complexity theory;fault detection and isolation;algorithm	EDA	22.245689305886728	51.83978782353683	86361
019e3948f4b07595e728ca5dc491406fc0c52488	using defect density modelling to drive the optimisation of circuit layout, maximising yield	wafer fabrication;multiple process flows;fabrication facility;collision mitigation;inline defectivity;integrated circuit yield;integrated circuit;monolithic integrated circuits;integrated circuit layout;defect density modelling;site specific models;circuit layout optimisation;defect density;inspection;pareto optimization;module choice defect density modelling circuit layout optimisation yield maximisation product families wafer fabrication fabrication facility multiple process flows site specific models inline defectivity memory size;monitoring;monolithic integrated circuits integrated circuit modelling integrated circuit layout circuit optimisation integrated circuit yield;integrated circuit modelling;module choice;integrated circuit modeling;production facilities;product family;yield maximisation;integrated circuit testing;time use;exponential growth;circuit optimisation;product families;memory size;integrated circuit modeling pareto optimization production facilities integrated circuit testing inspection monitoring collision mitigation;new products	With integrated circuit [IC] market requirements driving the increase in diversity of product families and technologies, modelling of defect density within wafer fabrication is increasing in complexity. The exponential growth in the number of applications of the IC has meant that the requirement of each wafer fabrication facility has moved from running single volume products to being able to cope with running up to hundreds of different products at one time. Where it is possible to retain one volume product per wafer fabrication site, simpler defect density modelling may be representative models or indicators of defect density. When multiple process flows, product families and technologies are manufactured at one time, using one model was found to be unviable. By developing wafer fabrication site specific models, the effects of inline defectivity and design layout were found to consistently relate to yield. Product family variations also showed relationships with yield, where memory size, complexity and module choice could be optimised to maximise yield of a new product.	circuit diagram;mathematical optimization;software bug	M. Baxter;D. Muir	1995		10.1109/DFTVS.1995.476949	wafer fabrication;exponential growth;electronic engineering;inspection;engineering;electrical engineering;integrated circuit;integrated circuit layout;engineering drawing	EDA	23.78584682369231	55.7562321186093	86578
acf3a367ec04733b42dfe411250c1ed153a4ef2b	near-threshold computing and minimum supply voltage of single-rail mcml circuits		In high-speed applications, MOS current mode logic (MCML) is a good alternative. Scaling down supply voltage of the MCML circuits can achieve low power-delay product (PDP). However, the current almost all MCML circuits are realized with dual-rail scheme, where the NMOS configuration in series limits the minimum supply voltage. In this paper, single-rail MCML (SRMCML) circuits are described, which can avoid the devices configuration in series, since their logic evaluation block can be realized by only using MOS devices in parallel. The relationship between the minimum supply voltage of the SRMCML circuits and the model parameters of MOS transistors is derived, so that the minimum supply voltage can be estimated before circuit designs. An MCML dynamic flop-flop based on SRMCML is also proposed. The optimization algorithm for near-threshold sequential circuits is presented. A near-threshold SRMCMLmode-10 counter based on the optimization algorithm is verified. Scaling down the supply voltage of the SRMCML circuits is also investigated. The power dissipation, delay, and power-delay products of these circuits are carried out. The results show that the near-threshold SRMCML circuits can obtain low delay and small power-delay product.	algorithm;cmos;cpu power dissipation;current-mode logic;flops;flip-flop (electronics);mathematical optimization;nmos logic;power–delay product;series and parallel circuits;transistor	Ruiping Cao;Jianping Hu	2014	J. Electrical and Computer Engineering	10.1155/2014/836019	electronic engineering;real-time computing;engineering;78xx;electrical engineering	EDA	17.385869008891536	56.69312536738893	86579
407fa64e842fdce23cce8776617df42f1229c452	test time reduction in a manufacturing environment by combining bist and ate	detection profile;bist ate combination;test time reduction;circuit under test;complex digital chips;bist circuitry;pulp manufacturing;art;probability;circuit faults;fault simulation;automatic testing;manufacturing automation;manufacturing environment;automatic test equipment;analytical model test time reduction manufacturing environment bist ate combination built in self test automatic test equipment bist circuitry manufacturing test complex digital chips fault coverage modelling cut testability fault simulation random patterns detection profile;chip;circuit simulation;built in self test circuit testing circuit faults switches automatic test equipment manufacturing automation pulp manufacturing automatic testing circuit simulation art;cut testability;built in self test;digital integrated circuits;integrated circuit testing;probability digital integrated circuits built in self test automatic test equipment fault simulation integrated circuit testing production testing;fault coverage modelling;fault coverage;circuit testing;production testing;switches;random patterns;manufacturing test;analytical model	This paper analyzes an environment which utilizes Built-In Self-Test (BIST) and Automatic Test Equipment (ATE), to reduce the overall time for manufacturing test of complex digital chips. This requires properly establishing the time to switch front BIST to ATE (referred to us switchover time), thus utilizing ATE generated vectors to finally achieve the desired level of fault coverage. For this environment we model fault coverage us a function of the testability of the circuit under test and the numbers of vectors which are supplied by the BIST circuitry and the ATE. A novel approach is proposed: this approach is initially bused on fault simulation using a small set of random patterns: art estimate of the so-called detection profile of the circuit under test is established us basis of the test model. This analytical model effectively relates the testable features of the circuit under test to detection using both BIST and ATE us related testing processes.	built-in self-test	Hamidreza Hashempour;Fred J. Meyer;Fabrizio Lombardi	2002		10.1109/DFTVS.2002.1173515	chip;reliability engineering;embedded system;automatic test equipment;electronic engineering;fault coverage;telecommunications;network switch;computer science;engineering;automatic test pattern generation;probability;statistics;computer engineering	Robotics	22.367436261539467	52.55432893310759	86590
17bf5fb67cc1ff4456134f59116b9469dba1c9ec	implications of ultra low-voltage devices on design techniques for controlling leakage in nanocmos circuits	circuit level design;leakage current;integrated circuit;power system faults leakage currents low power electronics;ultra low voltage;very large scale integration;nanocmos circuit leakage control;leakage power control;supply voltage scaling;power system faults;vlsi circuit speed;low voltage;design technique;technology scaling;leakage power;leakage currents;threshold voltage;low power electronics;subthreshold leakage current;circuit temperature variation ultra low voltage device nanocmos circuit leakage control technology scaling vlsi circuit speed very large scale integration leakage power control threshold voltage subthreshold leakage current supply voltage scaling nanometric device integrated circuit nanometric feature size circuit level design;nanometric feature size;voltage scaling;ultra low voltage device;nanoscale devices threshold voltage dynamic voltage scaling temperature control voltage control very large scale integration power supplies leakage current integrated circuit technology integrated circuit manufacture;circuit temperature variation;nanometric device	Enabled by technology scaling, ultra low-voltage devices have now found wide application in modern VLSI circuits. While low-voltage implies reduced dynamic power, it also signifies increased leakage power, as lower supply voltages are usually paired with lower threshold voltages in order to preserve circuit speed. This originates an increase in sub-threshold leakage currents that constitute, today, one of the most serious bottlenecks to further technology and supply voltage scaling. The need of controlling leakage power in nanometric devices is imposing a significant shift in the way integrated circuits are designed and manufactured. The behavior of devices with nanometric feature sizes is much more sensitive to parameters such as the operating temperature of the circuit, which in the past were neglected. In this paper we quantitatively analyze the leakage control capabilities of some well-established circuit-level design techniques, and assess how the effectiveness of such techniques scales with respect to decreased supply voltages (as induced by technology scaling) and temperature variations, thus providing an interesting insight on how leakage control solutions that are in use today is applicable in future designs	bottleneck (software);dynamic voltage scaling;image scaling;integrated circuit;level design;spectral leakage;very-large-scale integration	Ashutosh Chakraborty;Karthik Duraisami;Ashoka Visweswara Sathanur;Prassanna Sithambaram;Alberto Macii;Enrico Macii;Massimo Poncino	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1692515	control engineering;electronic engineering;engineering;electrical engineering;integrated circuit;leakage;very-large-scale integration;threshold voltage;low voltage;low-power electronics	Arch	19.765858583310358	58.29121197360142	86606
4fe81a79503d342263eec780f6e26b3cef844190	design of low-power multiplierless linear-phase fir filters		In the design of multiplierless finite impulse response (FIR) filters, tremendous efforts have been made to reduce the number of adders of the multiplier block for the reduction of overall chip area and power consumption. However, fewer in the multiplier block do not necessarily lead to lower power consumption, since the structural adders dominate the power consumption of an FIR filter circuit. In this paper, we propose a power-oriented optimization method for linear phase FIR filters. In the proposed algorithm, the power index, which is the average adder depth of the structural adders, is used as the optimization objective in the discrete coefficients search. A gate-level simulation of benchmark filters shows that the proposed technique designs filters consuming less power than those obtained by the best available algorithms, which aim to minimize the number of adders. The power savings over existing designs can be as much as 19.6%.	adder (electronics);algorithm;benchmark (computing);coefficient;finite impulse response;linear phase;low-power broadcasting;mathematical optimization;particle filter;simulation	Wen Bin Ye;Xin Lou;Ya Jun Yu	2017	IEEE Access	10.1109/ACCESS.2017.2740422	linear phase;chip;algorithm design;computer science;finite impulse response;adder;mathematical optimization	EDA	14.375237106891353	46.60722696707232	86729
97f5541cac8f4024a67760ffd13225ee767d0df1	editorial to special issue dac 2006		This special issue of the ACM Journal of Emerging Technologies in Computing Systems is based on papers presented at the 2006 IEEE/ACM Design Automation Conference (DAC). DAC has recently expanded its focus to include emerging technologies for computing and sensing systems. This broadened focus has been motivated in part by the roadblocks that loom ahead for the continued scaling of Silicon CMOS technology. New materials, new device geometries, and further downscaling of device dimensions and supply voltages are together leading to a significant escalation in manufacturing cost as well as unpredictable circuit performance due to process variability. As a result, experts are predicting that CMOS scaling will stop in the near future, perhaps as early as 2015. Alternative computing technologies being explored today include carbon nan-otubes, nanowires, molecular transistors, spin-based and single-electron devices , DNA-based devices, and hybrid circuits made from mainstream CMOS and newer nanodevices. Together with advances in manufacturing techniques, new design paradigms based on these emerging technologies are being explored. Research groups worldwide are addressing various aspects of circuit and system design such as modeling, analysis, defect tolerance, and synthesis. Another motivation for expanding DAC's focus lies in the recent emergence of electronic systems that integrate MEMS and electrochemical components in sensor systems, biochips, and lab-on-chip devices. Technologies such as mi-crofluidics are now mature enough to allow system integration and system-level design. A call for papers for the JETC special issue was announced soon after DAC 2006. Full-length journal paper submissions were solicited from authors of papers on emerging technology topics at DAC 2006. All submissions went through the regular review process of JETC. After review and appropriate revisions, four papers were accepted for the special issue. In the first article of this special issue, Paul et al. provide a device model for ballistic carbon nanotube FETs (CNFETs). The authors provide insights on how the parasitic fringe capacitance in CNFET geometries impacts the overall performance of CNFET circuits. In the second article, Yuh et al. describe a module-placement technique for defect-tolerant microfluidic biochips. A tree-based topological representation is used to model the placement problem. Next, Xu et al. address a design problem that is especially relevant for low-cost disposable biochips. The authors describe how a small number of input pins can be used to control a larger number of electrodes in a microfluidic array for high-throughput bioassays. In the final article of this special issue, Rad and …	cmos;carbon cycle;design automation conference;downscaling;electron;electronic system-level design and verification;emergence;heart rate variability;high-throughput computing;image scaling;level design;loom;microelectromechanical systems;nan;one-electron universe;privilege escalation;software bug;system integration;systems design;throughput;transistor	Krishnendu Chakrabarty;Sachin S. Sapatnekar	2007	JETC	10.1145/1295231.1295232	computer science;voltage;test light;integrator;electronic engineering;comparator;alarm;detector	EDA	11.943072181955863	58.02049133426165	86769
03dbf3ab97e9f5f4c98e4875a309870386648b02	a preprocessor for channel routing	different net;specialized channel;y-grid position;channel routing;bismuth;connection;chip scale packaging;design automation;routing	This paper presents a “preprocessor” which separates a channel routing problem into two subproblems. One is a specialized channel routing problem where no two nodes of two different nets are of the same y-grid position. The other is a problem of connecting pairs of nodes where each pair of nodes has a path reserved for it. The use of a “preprocessor” in channel routing[5] is justified by the comparison of routing results.	channel router;preprocessor;routing	Ming H. Young;Larry Cooke	1981	18th Design Automation Conference		routing table;embedded system;chip-scale package;routing;electronic engineering;static routing;electronic design automation;equal-cost multi-path routing;connection;computer science;engineering;destination-sequenced distance vector routing;bismuth;link-state routing protocol;triangular routing;path vector protocol;engineering drawing;routing	EDA	14.863456763435858	51.72711218905234	86820
cb26754f1ddf4906f1104e3a8d967cfcaffa7406	overview of 3-d architecture design opportunities and techniques	three dimensional displays computer architecture fabrication stacking random access memory integrated circuit interconnections through silicon vias	Three-dimensional (3-D) integration, a breakthrough technology to achieve “More Moore and More Than Moore,” provides numerous benefits, e.g., higher performance, lower power consumption, and higher bandwidth, by utilizing vertical interconnects and die/wafer stacking. This paper presents an overview of 3-D integration along with various design challenges and recent innovations. —Partha Pande, Washington State University	speaker wire;stacking	Jishen Zhao;Qiaosha Zou;Yuan Xie	2017	IEEE Design & Test	10.1109/MDAT.2015.2463282	embedded system;electronic engineering;computer science;engineering;computer engineering	EDA	12.066307768171253	56.4055271248212	86891
879e5e36f96c98cab6e58e1769603912b91970d0	delay analysis and design optimization for low-swing rc-limited global interconnects	on chip;interconnect;low swing;optimization;high speed	On-chip global interconnects are becoming speed and power bottlenecks in state-of-the-art chips. Low-swing signaling is used to improve delay performance and reduce power consumption. This paper first performs a delay analysis for different low-swing circuits based on the Asymptotic Waveform Evaluation (AWE). In addition, new delay metrics are presented and analyzed. The new delay metrics demonstrate that optimal designs can be obtained in low-swing signaling. To verify our analysis, a simulation environment is established. The simulation results indicate that the optimal designs can increase the 3dB bandwidth of a wire by more than 40% in resistively driven or capacitively driven 10mm global links. Thus, these optimal design methods can effectively improve the bandwidth of global wires.	electrical connection	Jian-Fei Jiang;Zhigang Mao;Weiguang Sheng;Qin Wang;Weifeng He	2016	Journal of Circuits, Systems, and Computers	10.1142/S0218126616501218	embedded system;electronic engineering;real-time computing;telecommunications;computer science;engineering;interconnection	EDA	15.368212648074879	56.73035396887109	87094
ced1232f5498b8bae83103f647a53dae3257bf56	concurrent error detection in sequential circuits using convolutional codes	convolutional code;concurrent error detection;sequential circuits;line detection;equivalence relation;digital systems;error detection	Concurrent error detection schemes in digital systems are often based upon error-detecting codes. In [9], we presented a methodology for encoding the states of sequential machines using convolutional codes for on-line detection of sequencing errors. In conjunction with this methodology, we defined an equivalence relation on convolutional codes that exhaustively characterizes the possible transient error detection capabilities and complexities of sequential machine realizations based upon convolutional codes. In this paper, we determine the number of equivalence classes of (n, k, 1) convolutional codes generated by minimal encoders requiring k memory elements and provide a procedure for generating representatives from each equivalence class.	convolutional code;error detection and correction	Lawrence P. Holmquist;Larry L. Kinney	1991		10.1007/3-540-54522-0_107	convolutional code;error detection and correction;theoretical computer science;mathematics;sequential logic;equivalence relation;statistics	EDA	22.104819430439136	47.97351098888487	87124
f5e178177543428602d8ce9054cd7c8b0cf09e3e	pre-bond probing of through-silicon vias in 3-d stacked ics	stuck at tests;design for testability;through silicon via tsv;hspice simulation;known good die;three dimensional integrated circuits design for testability discrete fourier transforms fault diagnosis integrated circuit testing;pre bond;resistance;through silicon vias probes needles testing capacitance logic gates resistance;on die test architecture;prebond testing;testing;probes;through silicon via tsv 3 d design for testability dft known good die pre bond;logic gates;prebond probing;design for testability dft;discrete fourier transform;integrated circuit testing;3d stacked integrated circuits;defect detection prebond probing prebond testing through silicon vias 3d stacked integrated circuits discrete fourier transform on die test architecture stuck at tests leakage tests hspice simulation;capacitance;discrete fourier transforms;3 d;needles;three dimensional integrated circuits;fault diagnosis;defect detection;through silicon vias;leakage tests	Through-silicon via (TSV)-based 3-D stacked ICs are becoming increasingly important in the semiconductor industry, yet pre-bond testing of TSVs continues to be difficult with current technologies. In this paper, we present a test and discrete Fourier transform method for pre-bond testing of TSVs using probe technology. We describe the on-die test architecture and probe technique needed for TSV testing, in which individual probe needles make contact with multiple TSVs at a time. We also describe methods for capacitance and resistance measurements, as well as stuck-at and leakage tests. Simulation results using HSPICE are presented for a TSV network. We demonstrate that we can achieve high resolution in these measurements, and therefore high accuracy in defect detection when we target one or multiple TSVs at a time. We also show that the test outcome is reliable even in the presence of process variations or multiple defective TSVs.	characterization test;discrete fourier transform;image resolution;probe card;relevance;spice 2;semiconductor device fabrication;semiconductor industry;simplified instructional computer;simulation;software bug;spectral leakage;through-silicon via	Brandon Noia;Krishnendu Chakrabarty	2013	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2012.2226455	embedded system;electronic engineering;logic gate;engineering;electrical engineering;discrete fourier transform;design for testing;capacitance;software testing;resistance	EDA	22.81907825031715	53.74764947262148	87199
93abd364c8080a64865503b67542234c9a792b34	reliability-aware cross-layer custom instruction screening	negative bias temperature instability;system level information custom instruction screening bias temperature instability bti process variation nanoscale technology soft error reliability aware cross layer ci screening reliability constraints holistic framework circuit level information;nanoelectronics;radiation hardening electronics;delays logic gates integrated circuit reliability aging threshold voltage;radiation hardening electronics nanoelectronics negative bias temperature instability	Bias Temperature Instability (BTI) and process variation introduce remarkable unpredictability to Custom Instructions (CIs) manufactured at nano-scale technology. Moreover, shrinking the feature size to nanometer levels makes soft error another critical issue of CIs. To tackle these factors, we propose a reliability-aware cross-layer CI screening method. By adding an intermediate phase between the CI generation and CI selection phases, this method enables designers to prune the outputs of the generation phase in order to guarantee that synthesized CIs meet the required reliability constraints. For this purpose, a holistic framework is developed to analyze the combined effects of the BTI and process variation as well as the soft error on the CIs by making a link between circuit-level and system-level information. Based on this information collected from different layers of abstraction, the screening method prunes those CIs which cannot meet the reliability constraints. Experiments illustrate that BTI-unaware CI selection techniques may not meet the desired lifetime because of BTI-induced delay shift of CIs. Moreover, according to the results, a remarkable percentage of CIs is vulnerable to soft error and should not be fed into CI selection phase.	abstraction layer;btrieve;experiment;gnu nano;holism;instability;soft error;test template framework	Bahareh J. Farahani;Ali Azarpeyvand;Saeed Safari;Sied Mehdi Fakhraie	2013	2013 IEEE 16th International Symposium on Design and Diagnostics of Electronic Circuits & Systems (DDECS)	10.1109/DDECS.2013.6549829	nanoelectronics;embedded system;negative-bias temperature instability;electronic engineering;telecommunications;engineering;electrical engineering	EDA	20.630344612600297	58.12051118562331	87272
5789e44fb61d7ca5ad8579b4f4e9ada9f9a5a520	synthesis of pseudo kronecker lattice diagrams	decision diagrams;design process;decision diagram;heuristic programming;heuristic method;unfolded lattices pseudo kronecker lattice diagrams design process digital circuits logic minimization quality loss highly optimized netlists target architecture lattice diagrams regular two dimensional structure routing problem lattice representations heuristic synthesis methods pseudo symmetric pseudo kronecker decision diagrams psp kdds incompletely specified multiple output functions lattice structure asics fine grain fpgas heuristic methods mcnc benchmarks optimal depth results;lattices routing circuit synthesis process design digital circuits logic design logic circuits field programmable gate arrays minimization methods delay;decision diagrams digital circuits circuit cad heuristic programming;circuit cad;digital circuits	The design process of digital circuits is often carried out in individual steps, like logic minimization, mapping and routing. This leads to quality loss e.g., in cases where highly optimized netlists fit badly onto the target architecture. Lattice diagrams have been proposed as one possible solution. They offer a regular two dimensional structure, thus overcoming the routing problem. However elegant, presented methods have only shown to find practical lattice representations for small functions. We present heuristic synthesis methods for PseudoSymmetric Pseudo Kronecker Decision Diagrams (PSPKDDs) applicable to incompletely specified multiple output functions. The lattice structure maps directly to both ASICs and fine grain FPGAs. Our method (combining logic minimization, mapping and routing) seeks to minimize area and delay by heuristic methods. Experimental results on a set of MCNC benchmarks show superior quality to previous methods and in many cases even optimal depth results for unfolded lattices.	application-specific integrated circuit;benchmark (computing);circuit minimization for boolean functions;crystal structure;diagram;digital electronics;field-programmable gate array;heuristic;map;routing	Per Lindgren;Rolf Drechsler;Bernd Becker	1999		10.1109/ICCD.1999.808556	electronic engineering;design process;influence diagram;electrical engineering;theoretical computer science;machine learning;digital electronics;algorithm	EDA	15.577828890013382	49.47177056738431	87540
a6b2a14f3f5ea10d3946c8576f0a6d567673d8be	predicting the performance and reliability of carbon nanotube bundles for on-chip interconnect	vlsi;carbon nanotubes;contact resistance;copper;equivalent circuits;integrated circuit interconnections;integrated circuit modelling;statistical distributions;cu;vlsi applications;contact resistance;copper interconnect;inductance;inductive effects;metallic nanotubes;ohmic resistance;on-chip interconnect;scalable equivalent circuit model;single-walled carbon nanotube bundles;statistical distribution	Single-walled carbon nanotube (SWCNT) bundles have the potential to provide an attractive solution for the resistivity and electromigration problems faced by traditional copper interconnect. In this paper, we evaluate the performance and reliability of nanotube bundles for future VLSI applications. We develop a scalable equivalent circuit model that captures the statistical distribution of metallic nanotubes while accurately incorporating recent experimental and theoretical results on inductance, contact resistance, and ohmic resistance. Leveraging the circuit model, we examine the performance and reliability of nanotube bundles including inductive effects. The results indicate that SWCNT interconnect bundles can provide significant improvement in delay over copper interconnect depending on the bundle geometry and process technology.	copper interconnect;electromigration;equivalent circuit;scalability;very-large-scale integration	Arthur Nieuwoudt;Mosin Mondal;Yehia Massoud	2007	2007 Asia and South Pacific Design Automation Conference		equivalent circuit;probability distribution;electronic engineering;carbon nanotube;copper	EDA	22.097043257389647	58.75322346024159	87553
b10abc798d22f9e7c564516ba3e79215dae4cf09	hierarchical probablistic diagnosis of mcms on large-area substrates	clusters;test application time;probability;test costs;performance evaluation;test application time hierarchical probabilistic diagnosis mcms large area substrates test costs probabilistic test algorithm clusters global tester;automatic testing;circuit testing system testing costs electronic equipment testing clustering algorithms performance evaluation manufacturing probes electronics industry assembly;electronic equipment testing;probes;global tester;assembly;multichip modules;electronics industry;probabilistic test algorithm;production testing probability multichip modules fault diagnosis automatic testing;manufacturing;mcms;clustering algorithms;system testing;circuit testing;production testing;large area substrates;hierarchical probabilistic diagnosis;fault diagnosis	This paper addresses the issue of testing MCMs fabricated on large-area substrates. The cost of testing MCMs may be as high as 40% of the manufacturanig cost. In order to reduce test costs, at is essential that the testing be parallelized taking advantage of the fact that all the MCMs on the large-area substrate are similar. In this paper we propose a hierarchical probabilistic test algorithm for MCMs on large-area substrates. In this method, the MCMs on the substrate are divided into clusters. The responses of the MCMs are analyzed within their clusters, and the most common responses are sent to a global tester for determining the likely correct response. Based on this, the MCMs are diagnosed as faulty or fault free. The decisions are made after each test is applied. Our algorithm performs better than thie existing probabilistic test algorithms and provides upto an order of magnitude reduction in test application time as opposed to serial MCM probe test.	algorithm;multi-chip module;parallel computing;test case	Koppolu Sasidhar;Abhijit Chatterjee	1996		10.1109/ICVD.1996.489457	reliability engineering;embedded system;electronic engineering;computer science;engineering;probability;assembly;cluster analysis;manufacturing;system testing;statistics	SE	22.410545799251324	51.593466780994554	87595
4d95548752f0a8e605b6d4d9b93c51f059e9dadd	signal probability based statistical timing analysis	probability timing signal analysis circuit simulation circuit testing monte carlo methods spice analytical models probabilistic logic very large scale integration;statistical timing analysis;iscas benchmark circuits;vlsi monte carlo methods spice statistical analysis timing;power estimation;standard deviations;standard deviation;spsta;vlsi timing analysis;tpm;circuit switched;fpga;trusted computing;signal probability;embedded systems;statistical analysis;standard deviations signal probability statistical timing analysis vlsi timing analysis power estimation monte carlo simulation spice iscas benchmark circuits spsta;environmental variation;partial dynamic reconfiguration;vlsi;timing analysis;monte carlo;monte carlo simulation;spice;reconfigurable hardware;monte carlo methods;statistical static timing analysis;timing	VLSI timing analysis and power estimation target the same circuit switching activity. Power estimation techniques are categorized as (1) static, (2) statistical, and (3) simulation and testing based methods. Similarly, statistical timing analysis methods are in three counterpart categories: (1) statistical static timing analysis, (2) probabilistic technique based statistical timing analysis, and (3) Monte Carlo (SPICE) simulation and testing. Leveraging with existing power estimation techniques, I propose signal probability (i.e., the logic one occurrence probability on a net) based statistical timing analysis, for improved accuracy and reduced pessimism over the existing statistical static timing analysis methods, and improved efficiency over Monte Carlo (SPICE) simulation. Experimental results on ISCAS benchmark circuits show that SPSTA computes the means (standard deviations) of the maximum signal arrival times within 5.6% (7.7%), SSTA within 16.5% (46.9%), and STA within 83.0% (132.4%) in average of Monte Carlo simulation results, respectively. More significant accuracy improvements are expected in the presence of increased process and environmental variations.	benchmark (computing);categorization;circuit switching;monte carlo method;randomized algorithm;spice;simulation;statistical static timing analysis;very-large-scale integration	Bao Liu	2008	2008 Design, Automation and Test in Europe	10.1145/1403375.1403513	electronic engineering;real-time computing;computer science;standard deviation;statistics;monte carlo method	EDA	22.566701574949867	57.6638744149969	87651
23a9a2168273dd1991448de8448d3709ade0bae6	challenges and principles of physical design	physical design;interconnect synthesis;parametrized model order reduction	INTRODUCTION Addressing the physical design of integrated circuits, MCMs, and printed-circuit boards requires solving some of the largest and most difficult combinatorial optimization problems ever attempted. Deep submicron process technologies and the rapid and continuing increase in design size significantly add to the difficulties. Fortunately, computing power, memory, and disk also continue to increase rapidly, providing hope that our mostly subquadratic heuristics will keep up with problem sizes. The increasing popularity of assorted hierarchical methodologies provides additional reason for optimism.	combinatorial optimization;heuristic (computer science);integrated circuit;mathematical optimization;physical design (electronics);printed circuit board;printing;very-large-scale integration	Steven L. Teig	2002		10.1145/505388.505389	physical design	EDA	12.362442786133096	55.65623597572238	87652
e62a9b904ffb707bd72b6ec36714e900e14e8ba9	coupling-aware functional timing analysis for tighter bounds: how much margin can we relax?	crosstalk noise;coupling wire;static timing analysis sta;functional timing analysis fta	As the manufacturing technology keeps scaling, crosstalk noise induces a greater impact on timing. Although many previous works proposed techniques like timing correlation, functional correlation and path refinement to consider crosstalk noise during static timing analysis, they often suffered from descendant problems including overly-pessimistic timing bound, bad aggressor selection and false paths. Therefore, in this paper, a coupling-aware functional timing analysis tool named CA-FTA is proposed to tame the three problems stated above and to derive a tighter timing bound for the true longest path. Experimental results show that CA-FTA averagely reduces timing bounds of those obtained from crosstalk STA (with path refinement) by 7.26% on several ISCAS'85 and ISPD-2012 benchmark circuits (in particular, by 34.6% for b19). As a result, CA-FTA successfully solves the aggressor-selection problem as well as the false-path problem and relaxes more margins when considering crosstalk noise.	benchmark (computing);crosstalk;fault tree analysis;image scaling;longest path problem;refinement (computing);selection algorithm;static timing analysis;tame	Jack S.-Y. Lin;Louis Y.-Z. Lin;Ryan H.-M. Huang;Charles H.-P. Wen	2017		10.1145/3060403.3060443	electronic engineering;real-time computing;telecommunications;engineering	EDA	18.928169566976063	51.9382524886375	87746
563cb0fcc269be5861de17b05a97f6114c97c203	analysis of sequential logic circuits			sequential logic	D. Pai;D. Lewin	1974	Comput. J.	10.1093/comjnl/17.1.64	logic synthesis;logic optimization;diode–transistor logic;asynchronous circuit;logic gate;logic family;programmable logic device;sequential logic;combinational logic;digital electronics;register-transfer level;resistor–transistor logic	EDA	19.3518414725172	46.806943442757714	87873
c49f7029456dc610b4f7fed195e944dd7d8cb64c	device-circuit co-optimization for robust design of finfet-based srams	sram co design finfet process variations;equipment;random access memory;sram chips circuit optimisation logic design mos memory circuits;logic design;circuit stability;aging;finfets;process variations;logic gates;mos memory circuits;stability analysis;co design;sram;optimization;circuit optimisation;finfet;finfet sram circuit device circuit co optimization device circuit co design technique;finfets optimization stability analysis logic gates circuit stability random access memory aging equipment;sram chips	A set of device-circuit co-design techniques oriented to increase the resilience of FinFET SRAMs circuits is presented in this paper. Co-optimization of fin ratio, thickness, orientation and height are investigated and its impact on performance and area evaluated.	mathematical optimization;static random-access memory;thickness (graph theory)	Sumeet Kumar Gupta;Kaushik Roy	2013	IEEE Design & Test	10.1109/MDAT.2013.2266394	co-design;embedded system;electronic engineering;von neumann stability analysis;parallel computing;logic synthesis;real-time computing;static random-access memory;logic gate;computer science;operating system	EDA	18.98026362694583	57.744917186254575	87946
a8546617f80d77c1d269f5697989df2c2adcd910	design considerations and tools for low-voltage digital system design	digital systems capacitance design optimization design automation switching circuits statistics permission threshold voltage power dissipation signal design;ultra low power;low voltage;digital systems;power consumption;bulk cmos low voltage digital system design cad tools low power design low threshold devices multiple threshold devices soi;voltage scaling	Aggressive voltage scaling to 1V and below through technology, circuit, and architecture optimization has been proven to be the key to ultra low-power design. The key technology trends for low-voltage operation are presented including low-threshold devices, multiple-threshold devices, and SOI and bulk CMOS based variable threshold devices. The requirements on CAD tools that allow designers to choose and optimize various technology, circuit, and system parameters are also discussed.	atom;cmos;computation;computer-aided design;dynamic random-access memory;dynamic voltage scaling;elegant degradation;event-driven programming;hyperbolic absolute risk aversion;image scaling;international solid-state circuits conference;kuroda normal form;logic optimization;low-power broadcasting;mathematical optimization;precomputation;requirement;sequential logic;shutdown (computing);silicon on insulator;symposia on vlsi technology and circuits;tree rearrangement;very-large-scale integration;yang	Anantha Chandrakasan;Isabel Y. Yang;Carlin Vieri;Dimitri Antoniadis	1996		10.1145/240518.240540	electronic engineering;engineering;electrical engineering;low voltage;power optimization;computer engineering	EDA	13.430503626006043	57.46663247791298	88016
a1ba7ccdb6675fa53e7a79ccfa0d60c8024e07f2	the optimum physical targets of the 3-dimensional vertical fg nand flash memory cell arrays with the extended sidewall control gate (escg) structure.(session 8a : memory 2)	stacked surrounding gate cell;3 dimensional vertical floating gate fg type nand flash;extended sidewall control gate escg			Moon-Sik Seo;Tetsuo Endoh	2010	IEICE Transactions		parallel computing;computer hardware	EDA	15.2519139715836	59.93617360435324	88247
bcf4fced5117b95f666b4ac5e77c2c3fdffc8906	statistical threshold formulation for dynamic i_dd test	mosfet circuits;fabrication;process variation;circuit testing circuit faults electrical fault detection fault detection monitoring principal component analysis fabrication mosfet circuits current measurement current supplies;circuit faults;current supplies;automatic testing;computationally efficient methods;process corners;statistical models;statistical model;electric current measurement;dynamic i dd test;process variations;built in self test;leakage currents statistical threshold formulation dynamic i sub dd test process variations fault coverage principal component analysis process corners statistical models current based dynamic test averaging energy consumption ratio computationally efficient methods mosfet modeling process models;current measurement;monitoring;built in self test integrated circuit testing automatic testing electric current measurement principal component analysis leakage currents cmos digital integrated circuits;cmos digital integrated circuits;leakage currents;energy consumption;process models;principal component analysis;fault detection;test methods;energy consumption ratio;integrated circuit testing;fault coverage;circuit testing;statistical techniques;current based dynamic test averaging;statistical threshold formulation;mosfet modeling;electrical fault detection	Process variations degrade the resolution and consequently the fault coverage of I/sub dd/ test techniques. We develop statistical techniques to set thresholds in a dynamic I/sub dd/ test process. The techniques use principal component analysis to identify process corners and compute statistical models. Our techniques are applied to average current-based dynamic test and to test based on the energy consumption ratio. We demonstrate that our techniques lead to computationally efficient methods to set accurate thresholds without either significant yield or fault coverage loss. To the best of our knowledge, this is the first systematic technique to set thresholds for a dynamic I/sub dd/ test method.		Wanli Jiang;Bapiraju Vinnakota	1999		10.1109/TEST.1999.805614	reliability engineering;statistical model;electronic engineering;engineering;electrical engineering;statistics	EDA	22.85325681973688	55.87909254921127	88394
09aea7b31556b5d3e3437e297a4d690e8b976831	switching window computation for static timing analysis in presence of crosstalk noise	system performance models;crosstalk noise;crosstalk;multiple aggressors static timing analysis crosstalk noise very deep submicron design switching windows worst case alignment;technology extrapolation;scheduling algorithm;timing crosstalk coupling circuits delay circuit noise signal design noise level upper bound switches capacitance;vlsi;timing analysis;static timing analysis;logic cad crosstalk timing;inductance;logic cad;interconnect delay;timing	Crosstalk effect is crucial for timing analysis in very deep submicron design. In this paper, we present and compare multiple scheduling algorithms to compute switching windows for static timing analysis in presence of crosstalk noise. We also introduce an efficient technique to evaluate the worst case alignment of multiple aggressors.	algorithm;best, worst and average case;computation;crosstalk;microsoft windows;robustness (computer science);run time (program lifecycle phase);scheduling (computing);static timing analysis;very-large-scale integration;waveform	Pinhong Chen;Desmond Kirkpatrick;Kurt Keutzer	2000		10.1109/ICCAD.2000.896494	embedded system;electronic engineering;real-time computing;computer science;engineering;electrical engineering;static timing analysis	EDA	17.418330413847816	52.24828214748003	88487
0dcd3c5aa909c5065dee880328c71c1cd7296930	single-phase source-coupled adiabatic logic	carry lookahead adder;carry logic;ultra low power;logic simulation;pipeline arithmetic cmos logic circuits logic design integrated circuit layout logic simulation low power electronics adders carry logic;integrated circuit layout;low energy;logic design;energy efficient;low frequency;frequency adders boolean functions vhf circuits energy consumption clocks cmos logic circuits circuit simulation cmos process logic functions;digital logic;10 to 280 mhz single phase source coupled adiabatic logic adiabatic circuits low energy design energy speed trade offs very low energy consumption high speed adiabatic circuits layout based simulations cmos process parameters pipelined carry lookahead adders power dissipation 0 5 mum;process parameters;energy consumption;adders;cmos logic circuits;low power electronics;subthreshold circuits;high speed;pipeline arithmetic;frequency conversion	Adiabatic circuits offer a promising alternative to conventional circuitry for low energy design. Their operation is nevertheless subject to fundamental energy-speed trade-offs, just like any other physical realization of boolean logic. Thus, adiabatic circuits with very low energy consumption at low frequencies fail to function at high operating frequencies. Conversely, high-speed adiabatic circuits tend to be dissipative at low clock rates. This paper describes SCAL, a single-phase source-coupled adiabatic logic family that operates efficiently across a wide range of operating frequencies. In layout-based simulations with 0.5 m CMOS process parameters, pipelined carry-lookahead adders developed in our logic function correctly from 10MHz up to 280MHz. Our SCAL adders are less dissipative than corresponding designs in alternative adiabatic families that remain functional across the same frequency range. Moreover, they are about as dissipative as other adiabatic circuits that are geared towards very efficient operation at low frequencies. In comparison with their CMOS counterparts, our SCAL adders are 3 to 10 times more energy efficient.	adiabatic circuit;boolean algebra;cmos;clock rate;electronic circuit;frequency band;logic family;parsing;simulation	Suhwan Kim;Marios C. Papaefthymiou	1999		10.1145/313817.313876	boolean algebra;logic synthesis;adiabatic circuit;computer science;operating system;logic simulation;efficient energy use;integrated circuit layout;low frequency;adder;low-power electronics	EDA	15.991164825339538	57.884968732283454	88541
f9d43845a6917e457cff89f3d1e22acb34de0ce1	optimization methods for lookup-table-based fpgas using transduction method	field programmable gate array;optimisation;optimal method;programmable logic arrays;design method;lookup table;field programmable gate arrays;table lookup;logic cad	| In recent years Field Programmable Gate Arrays(FPGAs) have emerged as an attractive means to implement low volume applications and prototypes due to their low cost, reprogrammability and rapid turnaround times. Therefore, the need for design methods of FPGAs are getting larger and larger. In this paper, two methods to optimize networks which have been mapped for lookup-table-based FPGAs are discussed. These methods utilize the notion of compatible sets of permissible functions(CSPFs) of Transduction Method. Experimental results show the e ectiveness of our methods.	field-programmable gate array;logic block;lookup table;mathematical optimization;place and route;routing;transducer;transduction (machine learning)	Shigeru Yamashita;Yahiko Kambayashi;Saburo Muroga	1995		10.1145/224818.224921	embedded system;electronic engineering;parallel computing;macrocell array;programmable logic array;computer science;theoretical computer science;complex programmable logic device;simple programmable logic device;field-programmable gate array	EDA	12.079951182034433	46.64278016646372	88571
a83248f516bb6ea1da12ba1459be80050c89bb4d	effectiveness of a variable sampling time strategy for delay fault diagnosis	benchmark circuits variable sampling time strategy delay fault diagnosis delay fault testing fault coverages timing analysis output observation times ic testing logic testing;integrated circuit testing logic testing;sampling methods delay effects fault diagnosis circuit faults circuit testing fault detection robustness logic testing timing electrical fault detection;logic testing;integrated circuit testing;timing analysis;fault coverage;fault diagnosis	Delay fault testing has been an active research topic in the last ten years. Recentlyproposed methods try to move the sampling time of the circuit outputs during testing to produce better fault coverages than that obtained by using a m e d observation time method. In the same way, we propose to use such a testing scheme to improve delay fault diugnosis when compared to methods based onfixed output sampling times. The timing analysis which gives the output observation times applied during the test is first described in this paper. Next, we present the diagnosis method we implemented with the new testing scheme. Finally, results showing the effectiveness of a variable sampling time strategy for delay fault diagnosis are given.	sampling (signal processing);static timing analysis	D. Dumas;Patrick Girard;Christian Landrault;Serge Pravossoudovitch	1994		10.1109/EDTC.1994.326826	control engineering;electronic engineering;real-time computing;fault coverage;fault indicator;engineering;stuck-at fault	EDA	22.01973677501316	51.76753047591638	88882
052ee9a38eeb13a61f9daf48409c7d95fe58eebb	a new efficient retiming algorithm derived by formal manipulation	optimization technique;clockperiod minimization;algorithm derivation;binary search;retiming;heuristic algorithm	A new efficient algorithm is derived for the minimal period retiming by formal manipulation. Contrary to all previous algorithms, which used fixed period feasibility checking to binary-search a candidate range, the derived algorithm checks the optimality of a feasible period directly. It is much simpler and more efficient than previous algorithms. Experimental results showed that it is even faster than ASTRA, an efficient heuristic algorithm. Since the derived algorithm is incremental by nature, it also opens the opportunity to be combined with other optimization techniques.	algorithm design;binary search algorithm;computer-aided design;heuristic (computer science);mathematical optimization;program derivation;retiming	Hai Zhou	2008	ACM Trans. Design Autom. Electr. Syst.	10.1145/1297666.1297673	heuristic;mathematical optimization;parallel computing;computer science;retiming;theoretical computer science;mathematics;algorithm;binary search algorithm;population-based incremental learning	EDA	16.678584217345062	47.73279559221092	88994
47fd6d1eb05be9d8862b3fa070b5d1437314f695	circuit enhancement by eliminating long false paths	algorithm design and analysis;computer science;logic;redundancy;segment;performance;logic design;system testing;heuristics	One way to improve circuit performance is to introduce redundancies into the circuit. However, this results in higher number of long false paths in the circuit and the testability of the circuit is reduced. Keutzer et al [4] developed a long false path elimination algorithm to remove the redundancies without sacrificing its performance. We propose a more ejjicient algorithm and two very e~ective heuristics to remove long false paths. Our experimental results show that the proposed algorithm and heuristics are jeasible for large designs and the increase of circuit area is significantly reduced.	algorithm;heuristic (computer science);software testability	Hsi-Chuan Chen;David Hung-Chang Du;Siu-Wing Cheng	1992			performance;computer science;theoretical computer science;heuristics;machine learning;redundancy;system testing;logic;algorithm	EDA	19.400700582021695	50.42737637435862	89156
0bed1f19a7c45377b224ec6ae9e8d13e1f39b506	modeling the effect of technology trends on the soft error rate of combinational logic	neutron effects combinational circuits cmos memory circuits sram chips microprocessor chips integrated circuit reliability cmos logic circuits;high energy;chip;soft error rate;error analysis logic circuits semiconductor device modeling cmos logic circuits cmos technology microarchitecture cmos memory circuits neutrons random access memory latches;technology scaling;cmos memory circuits;system design;50 to 600 nm technology trend effect modeling soft error rate combinational logic microarchitectural trends technology scaling cmos memory circuits logic circuits end to end model microprocessor style designs electrical masking latching window masking high energy neutrons sram cells clock periods inverter delays unprotected memory elements computer system design;cmos logic circuits;integrated circuit reliability;neutron effects;soft error;microprocessor chips;sram chips;combinational circuits	This paper examines the effect of technology scaling and microarchitectural trends on the rate of soft errors in CMOS memory and logic circuits. We describe and validate an end-to-end model that enables us to compute the soft error rates (SER) for existing and future microprocessorstyle designs. The model captures the effects of two important masking phenomena, electrical masking and latchingwindow masking, which inhibit soft errors in combinational logic. We quantify the SER due to high-energy neutrons in SRAM cells, latches, and logic circuits for feature sizes from 600nm to 50nm and clock periods from 16 to 6 fan-out-of-4 inverter delays. Our model predicts that the SER per chip of logic circuits will increase nine orders of magnitude from 1992 to 2011 and at that point will be comparable to the SER per chip of unprotected memory elements. Our result emphasizes that computer system designers must address the risks of soft errors in logic circuits for future designs.	cmos;clock rate;combinational logic;computation;computer;end-to-end principle;fan-out;futures studies;image scaling;instruction pipelining;logic gate;microarchitecture;microprocessor;nonvolatile bios memory;power inverter;simulation;soft error;static random-access memory;unsharp masking	Premkishore Shivakumar;Michael Kistler;Stephen W. Keckler;Doug Burger;Lorenzo Alvisi	2002		10.1109/DSN.2002.1028924	chip;parallel computing;real-time computing;logic optimization;soft error;telecommunications;computer science;pass transistor logic;sequential logic;combinational logic;systems design	EDA	19.940715277723566	57.85714605958556	89487
b265b51159f59bd504110c51a3f5235ba5c8904a	session 4b — panel data analytics in semiconductor manufacturing	silicon;si semiconductor manufacturing data analytics design layout process interactions defect sensitivity complex interactions delaying yield ramp silicon validation marginal effects test screening outgoing customer quality quality improvements manufacturing process integrated design fabless design eda solutions;sensitivity;data analysis;manufacturing processes;silicon elemental semiconductors integrated circuit design integrated circuit testing integrated circuit yield semiconductor device manufacture;data analysis integrated circuits sensitivity silicon manufacturing processes;integrated circuits	Summary form only given. Modern IC design and manufacturing have progressed in leaps and bounds, resulting in unimaginable integration, and power-performance advancements. This progress has been accompanied by adverse design-layout-process interactions and increased defect sensitivity. Controlling these complex interactions has exacted a steep price in terms of delaying yield ramp, extending silicon validation to characterize and fix marginal effects, and test screening being overwhelmed in time and volume to be able to ensure outgoing customer quality. There is, however, a bright side. Each step of the manufacturing, validation and test process generates information. This information, if effectively organized and analyzed, has the potential to result in efficiency and quality improvements that parallel in scale to the manufacturing process itself. Recent developments in data analytics methods have enabled harnessing of this information towards some benefits, while promising much more. This panel will explore major problems that can potentially be solved with advanced analytics, and also current solutions in the market targeted at some of these problems. Experts from integrated and fabless design houses will present their perspective on problems they encounter, while vendors of EDA solutions on data analytics will shed light on the nature of problems solved by current methods and those that will be addressed by solutions to come.	data validation;fabless manufacturing;integrated circuit design;interaction;marginal model;panel data;ramp simulation software for modelling reliability, availability and maintainability;semiconductor device fabrication;software bug	Suriyaprakash Natarajan;Li-C. Wang	2016	2016 IEEE 34th VLSI Test Symposium (VTS)	10.1109/VTS.2016.7477277	electronic engineering;sensitivity;engineering;electrical engineering;control theory;silicon;data analysis;manufacturing engineering	Visualization	23.12424495112848	55.8437763480897	89500
b2fef481a78fb057d326f3df55534affe36e9e2f	low power nonvolatile counter unit with fine-grained power gating	nonvolatile		power gating	Shuta Togashi;Takashi Ohsawa;Tetsuo Endoh	2012	IEICE Transactions		electronic engineering;parallel computing;non-volatile memory;computer hardware;computer science;operating system	Arch	15.702444103894274	59.182291362078296	89768
3410d1860d2a6d534e57ef850726f9ba20ea7bc4	self-routing, reconfigurable and fault-tolerant cell array	tolerancia falta;software;interconnection;circuit faults;fault tolerant;integrated circuit;logiciel;routing;reconfigurable architectures;network routing cellular arrays fault tolerant computing integrated circuit interconnections;funcion logica;circuito integrado;logical function;cellular arrays;network routing;fonction logique;interconexion;cell interconnection;fault tolerant system;fault tolerant computing;fault tolerant systems;self routing fault tolerant cell array;integrated circuit interconnections;fault tolerance;interconnexion;sistema tolerando faltas;reconfigurable fault tolerant hardware;cell interconnection self routing fault tolerant cell array reconfigurable fault tolerant hardware;logicial;genetic algorithms;systeme tolerant les pannes;field programmable gate arrays;architecture reconfigurable;tolerance faute;routing fault tolerance fault tolerant systems circuit faults software field programmable gate arrays genetic algorithms;circuit integre	Many examples of reconfigurable fault-tolerant hardware consist of cells that have the same hardware structure. The arithmetic or logical functions of the cells can be configured. The interconnection of the configured cells can perform a complex task. The interconnection of these cells can be configured too. When some cells are faulty, the function and routing of some cells have to be reconfigured to restore the system’s normal function. Most published fault-tolerant schemes cannot automatically achieve fault tolerance without the aid of external software and hardware, or they will require a long routing time to restore normal system function. Some published fault-tolerant schemes require a massive amount of spare cells. A self-routing, reconfigurable and fault-tolerant cell array is presented. When some cells are faulty, spare cells can automatically replace the faulty cells and rerouting can be automatically achieved. The cell array automatically achieves fault tolerance without the aid of external software or hardware, using a small amount of spare cells. In addition, the proposed cell array achieves short routing time to quickly restore normal system function.	cell (microprocessor);fault tolerance;interconnection;routing	Xiaoxuan She	2008	IET Computers & Digital Techniques	10.1049/iet-cdt:20070118	embedded system;fault tolerance;parallel computing;real-time computing;computer science;engineering	Arch	21.618564579168567	49.45660448109636	89812
be98a4abd34e222fcd6c7af2b0b09ac6c80b62e4	digital realization of analogue computing elements using bit streams	pid controller;logic design;real time;digital logic;satisfiability;analog computers logic arithmetic mimo operational amplifiers parallel machines three term control field programmable gate arrays control systems adaptive systems;complex system;three term control;analogue digital conversion;parallel machines;analogue digital conversion analogue computing element fast serial processor parallel machine multi bit binary word multi bit stream single bit stream digital logic elementary digital gates integrator differentiator pid controller fpga field programmable gate array proportional integral differential analogue signal mimo system;field programmable gate arrays;three term control analogue digital conversion logic design field programmable gate arrays	Real-time execution of an algorithm can be achieved with a fast serial processor or with a parallel machine. Usually both of these methods use multi-bit binary words which are processed by an arithmetic unit. This paper demonstrates an alternative approach to the parallel solution. Here, instead of a multi-bit word a single bit-stream is processed by digital logic to satisfy the required algorithm. Using elementary digital gates, classical elements like integrators and differentiators can be constructed. These elements operate on bit-streams and also produce bit-streams and by interconnecting them complex systems can be built. The inherently parallel nature of this technique makes it possible to implement complex algorithms in real time. This technique has been successfully applied to implement a PID controller on an FPGA for an experimental thermal plant.	algorithm;analog computer;arithmetic logic unit;bitstream;boolean algebra;complex systems;elementary;field-programmable gate array;mimo;pid;parallel computing;real-time clock;routing	Nitish Patel;George G. Coghill;Sing Kiong Nguang	2003		10.1109/IWSOC.2003.1213009	control engineering;electronic engineering;real-time computing;programmable logic array;digital signal;computer science;programmable logic device;digital electronics	HPC	10.094084025641576	47.70517957425811	89862
5f5108551a94c097815ab4a98807cbc2c5556e84	low power bist based on scan partitioning	fault diagnosis built in self test automatic test pattern generation network routing integrated circuit testing boundary scan testing random number generation logic testing;automatic test pattern generation;random number generation;design flow;built in self test hardware test pattern generators routing power dissipation fault detection electrical fault detection automatic testing decoding power engineering computing;network routing;boundary scan testing;built in self test;low power;logic testing;integrated circuit testing;fault coverage;power reduction;power consumption;fault detection scan partitioning technique low power built in self test scheme random pattern resistant faults power consumption reduction decoding methodology weight set correlation scan shifting scan power reduction small hardware overhead hardware overhead reduction;fault diagnosis	A built-in self-test (BIST) scheme is presented which both reduces overhead for detecting random-pattern-resistant (r.p.r.) faults as well as reduces power consumption during test. 3-valued weights are employed to detect the r.p.r. faults. The key idea is to use a new scan partitioning technique and decoding methodology that exploits correlations in the weight sets to greatly reduce the hardware overhead for multiple weight sets and reduce the number of transitions during scan shifting. The proposed scheme is simple to implement and only constrains the partitioning of scan elements into scan chains and not the scan order thereby having minimal impact on routing. Consequently, the proposed scheme can be easily implemented in standard design flows used in industry. Experiments indicate the scheme can achieve 100% fault coverage and 55% to 59% scan power reduction with relatively small hardware overhead.	built-in self-test;experiment;fault coverage;overhead (computing);routing;sensor	Jinkyu Lee;Nur A. Touba	2005	20th IEEE International Symposium on Defect and Fault Tolerance in VLSI Systems (DFT'05)	10.1109/DFTVS.2005.43	reliability engineering;embedded system;routing;electronic engineering;scan chain;real-time computing;fault coverage;random number generation;computer science;engineering;design flow;automatic test pattern generation	EDA	20.303164049131695	52.60092118192155	89941
a86398c42226941a65180ad9f769c2e944ecb4a1	qualification and quantification of process-induced product-related defects	silicon;yield prediction;qualifications electric variables measurement integrated circuit yield integrated circuit measurements density measurement electrical resistance measurement integrated circuit technology economic forecasting environmental economics assembly;integrated circuit;defect density;elemental semiconductors;statistical analysis;integrated circuit technology;integrated circuit testing;production testing;statistical analysis elemental semiconductors integrated circuit technology integrated circuit testing modules production testing silicon;si ic technology statistical data product related defects electrical measurements product yield modules sram matrix yield prediction;modules	and Quantification of Process-Induced Product-Related Defects F. Camerik, Philips Research Laboratories, Eindhoven P.A. J. Dirks, J.A.G. Jess, Eindhoven University of Technology The Netherlands This paper reports about research concerning the effects of inaccurate Silicon processing on integrated circuits. To capture information about defective processing steps we explore electrical measurements applied to socalled defect monitors or product yield modules (PYM's). We describe two such PYM's derived from 128k SRAM matrix as well as the kind of measurements we do and the way we evaluate the measurements to obtain defect density data for yield prediction. In addition we present some new theoretical results concerning the actual ability of defect monitors to deliver reliable results. We also prove some statements about the complexity of the measuring procedure. It turns out that depending on the flexibility of the experimental set up this complexity is more significantly dependent on the number of defects to be detected than on the complexity of the monitor structure.	integrated circuit;jess;software bug;static random-access memory	F. Camerik;P. A. J. Dirks;Jochen A. G. Jess	1989		10.1109/TEST.1989.82351	physical design;reliability engineering;embedded system;electronic engineering;computer science;engineering;electrical engineering;integrated circuit;modular programming;circuit extraction;silicon;statistics	ML	23.266982416590967	55.2145661957287	90127
8ad6d64074e1a48a1fb8ad54f03ebed959bab1da	technology challenges in the development of wireless personal area networks	design support;international technology roadmap for semiconductors;wireless personal area networks;technology integration;processing technology;low power design;power consumption;wireless personal area network;packaging technology;4g networks	Wireless personal area networks (WPANs) will be major components of the heterogeneous communication environment of the future. The devices in a WPAN must be low cost and operate for a long time from a battery. As a consequence, they pose demanding requirements on the utilized integration technology. In this paper we confront these requirements with the newly released international technology roadmap for semiconductors (ITRS-2001). Power consumption is identified as the key problem, motivating a large research effort in low power design techniques. In addition, it is pointed out that WPAN devices will consist of different technologies, requiring a better design support for mixed-technology integration.	electronic design automation;low-power broadcasting;mira;requirement;semiconductor	Marc Engels	2002	Wireless Personal Communications	10.1023/A:1019937027328	packaging engineering;telecommunications;body area network;computer network	Mobile	11.078631769228314	56.962444813647984	90168
4cb7c8dbf359b8c67d0b9e6747a9df331b888c4a	dynamic search-space pruning techniques in path sensitization	dependence analysis;decision tree;engines test pattern generators circuit faults timing pattern analysis delay circuit testing boolean functions logic circuits heuristic algorithms;circuit faults;time complexity;boolean functions;search space;linear time algorithm;logic circuits;satisfiability;heuristic search;test pattern generators;engines;efficient implementation;decision procedure;heuristic algorithms;linear time;timing analysis;circuit testing;test pattern generator;pattern analysis;dynamic analysis;timing	A powerful combinational path sensitization engine is required for the efficient implementation of tools for test pattern generation, timing analysis, and delay fault testing. Path sensitization can be posed as a search, in the n-dimensional Boolean space, for a consistent assignment of logic values to the circuit nodes which also satisfies a given condition. In this paper we propose and demonstrate the effectiveness of several new techniques for search-space pruning for test pattern generation. In particular, we present linear-time algorithms for dynamically identifying unique sensitization points and for dynamically maintaining reduced head line sets. In addition, we present two powerful mechanisms that drastically reduce the number of backtracks: failure-driven assertions and dependency-directed backtracking. Both mechanisms can be viewed as a form of learning while searching and have analogs in other application domains. These search pruning methods have been implemented in a generic path sensitization engine called LEAP. A test pattern generator, TG-LEAP, that uses this engine was also developed. We present experimental results that compare the effectiveness of our proposed search pruning strategies to those of PODEM, FAN, and SOCRATES. In particular, we show that LEAP is very efficient in identifying undetectable faults and in generating tests for difficult faults.	algorithm;backtracking;combinational logic;static timing analysis;stone's representation theorem for boolean algebras;test card;time complexity	Joao Marques-Silva;Karem A. Sakallah	1994	31st Design Automation Conference	10.1145/196244.196621	time complexity;heuristic;computer science;theoretical computer science;machine learning;mathematics;algorithm	EDA	19.009641287401408	48.29722923316536	90190
5bae273bdbcd89a6f055738727ec47dea639f0a2	improved symbolic simulation by functional-space decomposition	control part;datapath domain;functional-space decomposition approach;2-tuple list structure;control domain;improved symbolic simulation;data path;symbolic simulator;symbolic simulation;arithmetic circuit unit;decomposition approach;computational modeling;logic synthesis;engines;arithmetic;canonical form;adders;optimal control;automatic control;function space	This paper presents a functional-space decomposition approach to enhance the capability of symbolic simulation. In our symbolic simulator, the control part and data path of a circuit is separated, and their simulated results are recorded in different domains. A 2-tuple list structure is used to separate the results in the control and datapath domains. Then, the functional sub-space in the control domain can further be decomposed in order to achieve the optimal OBDD size and run time. We demonstrate the effectiveness of our decomposition approach based on symbolic simulation of arithmetic circuit units.	arithmetic circuit complexity;binary decision diagram;datapath;electronic circuit simulation;run time (program lifecycle phase);symbolic simulation	Tao Feng;Li-C. Wang;Kwang-Ting Cheng	2004	ASP-DAC 2004: Asia and South Pacific Design Automation Conference 2004 (IEEE Cat. No.04EX753)	10.1145/1015090.1015263	canonical form;mathematical optimization;electronic engineering;discrete mathematics;logic synthesis;optimal control;function space;theoretical computer science;automatic control;mathematics;computational model;symbolic trajectory evaluation;algorithm;adder	EDA	16.05471502887669	47.097805016053734	90204
10da0ae02c614b574aad28809969c2e6b03702ab	image processing techniques for wafer defect cluster identification	filtering;software tool;image processing;median filter;cluster tools;prototypes;cluster tools automatic test software image processing median filters integrated circuit testing integrated circuit manufacture wafer scale integration automatic optical inspection;automatic testing;wafer probing stage;manufacturing process;binary codes;filters;automatic optical inspection;manufacturing process automatic wafer scale defect cluster identifier defective dies philips semiconductor test facility image processing techniques electrical testing software tool median filter wafer probing stage;defective dies;automatic wafer scale defect cluster identifier;test facilities;automatic test software;pixel;wafer scale integration;integrated circuit testing;matrix converters;yield loss;semiconductor device noise;image processing techniques;electrical testing;image processing filters semiconductor device noise filtering binary codes matrix converters pixel automatic testing prototypes test facilities;integrated circuit manufacture;median filters;philips semiconductor test facility	Electrical testing determines whether each die on a wafer functions as originally designed. But these tests don't detect all the defective dies in clustered defects on the wafer, such as scratches, stains, or localized failed patterns. Although manual checking prevents many defective dies from continuing on to assembly, it does not detect localized failure patterns-caused by the fabrication process-because they are invisible to the naked eye. To solve these problems, we propose an automatic, wafer-scale, defect cluster identifier. This software tool uses a median filter and a clustering approach to detect the defect clusters and to mark all defective dies. Our experimental results verify that the proposed algorithm effectively detects defect clusters, although it introduces an additional 1% yield loss of electrically good dies. More importantly, it makes automated wafer testing feasible for application in the wafer-probing stage.	algorithm;cluster analysis;die (integrated circuit);identifier;image processing;median filter;programming tool;semiconductor device fabrication;software bug;wafer (electronics);wafer testing	Chenn-Jung Huang;Chua-Chin Wang;Chi-Feng Wu	2002	IEEE Design & Test of Computers	10.1109/54.990441	filter;median filter;embedded system;binary code;electronic engineering;image processing;computer science;engineering;prototype;engineering drawing;pixel	SE	22.323984506258114	52.28908314561705	90270
203129e9c9d08b901b3c0701d1ec45c5a6099e30	layout-aware synthesis of arithmetic circuits	partial product reduction tree;carry logic;crosstalk noise;layout aware synthesis;circuit timing optimization;generic algorithm;global csa tree structure;integrated circuit layout;crosstalk;two step algorithm;circuit synthesis arithmetic integrated circuit interconnections adders timing tree graphs crosstalk wire circuit testing delay;layout;bit level interconnect refinements;carry save adder;wire;module generation synthesis algorithm;tree graphs;system on chip;adders;integrated circuit interconnections;interconnect topology;tree structure;general csa timing model;carry save adder modules;arithmetic circuits;time use;timing digital arithmetic carry logic integrated circuit layout circuit optimisation adders logic cad integrated circuit interconnections;arithmetic;digital arithmetic;circuit testing;deep sub micron;circuit optimisation;interconnect delay arithmetic circuits layout aware synthesis carry save adder modules partial product reduction tree module generation synthesis algorithm circuit timing optimization interconnect topology two step algorithm optimal timing csa module generation algorithm general csa timing model bit level interconnect refinements global csa tree structure;logic cad;high performance;optimal timing csa module generation algorithm;interconnect delay;circuit synthesis;arithmetic circuit;timing	In deep sub-micron (DSM) technology, wires are equally or more important than logic components since wire-related problems such as crosstalk, noise are much critical in system-on-chip (SoC) design. Recently, a method [12] for generating a partial product reduction tree (PPRT) with optimal-timing using bit-level adders to implement arithmetic circuits, which outperforms the current best designs, is proposed. However, in the conventional approaches including [12], interconnects are not primary components to be optimized in the synthesis of arithmetic circuits, mainly due to its high integration complexity or unpredictable wire effects, thereby resulting in unsatisfactory layout results with long and messed wire connections. To overcome the limitation, we propose a new module generation/synthesis algorithm for arithmetic circuits utilizing carry-save-adder (CSA) modules, which not only optimizes the circuit timing but also generates a much regular interconnect topology of the final circuits. Specifically, we propose a two-step algorithm: (Phase 1: CSA module generation) we propose an optimal-timing CSA module generation algorithm for an arithmetic expression under a general CSA timing model; (Phase 2: Bit-level interconnect refinements) we optimally refine the interconnects between the CSA modules while retaining the global CSA-tree structure produced by Phase 1. It is shown that the timing of the circuits produced by our approach is equal or almost close to that by [12] in most testcases (even without including the interconnect delay), and at the same time, the interconnects in layout are significantly short and regular.	adder (electronics);algorithm;arithmetic circuit complexity;bit-level parallelism;carry-save adder;crosstalk;electrical connection;integrated circuit;system on a chip;tree structure	Junhyung Um;Taewhan Kim	2002		10.1145/513918.513971	system on a chip;layout;electronic engineering;parallel computing;real-time computing;crosstalk;genetic algorithm;computer science;electrical engineering;integrated circuit layout;tree structure;carry-save adder;tree;adder	EDA	15.777313263131656	49.28300899043507	90371
297cf4935b161b9f296099c022b4d2e667eb0313	built-in generation of multicycle functional broadside tests with observation points	built in test generation;functional broadside tests;transition faults;observation points;multicycle tests	Functional broadside tests allow overtesting to be avoided as part of a scheme that considers both test generation and the analysis of output responses, by ensuring that delay faults are detected under functional operation conditions. Compared with two-cycle tests, multicycle tests allow more faults to be detected with each test, thus reducing the number of tests that need to be applied. They also provide an opportunity for nonfunctional electrical effects, which are caused by switching between modes of operation, to subside before the clock cycles where delay faults are detected. Built-in test generation facilitates at-speed testing and reduces the test data volume. Motivated by these observations, this article describes the modification of a built-in test generation method for two-cycle functional broadside tests so as to generate multicycle functional broadside tests. The size of the hardware is not increased by the modification. The article investigates the following issues related to this method: (1) the effect of using multicycle tests on the number of tests that need to be applied; (2) fault simulation for tailoring the test generation hardware to a circuit that takes into account, to different extents, the need to allow nonfunctional electrical effects to subside; (3) the insertion of observation points in order to increase the transition fault coverage.	block cipher mode of operation;built-in self-test;canonical account;clock signal;fault coverage;simulation;test data	Irith Pomeranz	2013	ACM Trans. Design Autom. Electr. Syst.	10.1145/2534396	real-time computing;algorithm	EDA	21.463617201073806	51.99136938219958	90480
432a24844eb1407bd5d68c7a1dc66909fd6f198f	design automation with mixtures of proof strategies for propositional logic	design automation;integrated circuit design electronic design automation binary decision diagrams logic formal verification computability theorem proving;computability;logic;bdd strategy design automation problems propositional logic proof methods proof engine framework default composite strategies binary decision diagram based techniques search based satisfiability solvers zchaff;proof of concept;theorem proving;integrated circuit design;design automation logic design engines binary decision diagrams data structures boolean functions testing formal verification circuits;formal verification;binary decision diagrams;model checking;propositional logic;equivalence checking;satisabilit y;electronic design automation	Design automation problems can often be encoded in propositional logic, and solved by applying propositional logic proof methods. Unfortunately there exists no single proof method with adequate performance for all problems of interest. It is therefore critical to be able to combine different approaches, and to quickly be able to test how different compositions affect overall performance. In this paper, we present a proof engine framework where individual methods are viewed as strategies—functions between different proof states. By defining our proof engine in such a way that we can compose strategies to form new, more powerful, strategies we achieve synergistic effects between the individual methods. Unlike previous approaches, our framework is flexible enough to allow users to quickly come up with specially tailored composite analyses for problems from any of the different sub-domains of design au-	automated theorem proving;automation;bespoke;problem domain;propositional calculus;synergy;vii	Gunnar Andersson;Per Bjesse;Byron Cook;Ziyad Hanna	2003	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/TCAD.2003.814959	model checking;discrete mathematics;electronic design automation;formal verification;computer science;theoretical computer science;mathematics;computability;programming language;proof of concept;logic;proof complexity;algorithm;integrated circuit design	EDA	17.428094216856568	47.42270794553556	90482
461ee4e7892dcd8bf5cd93f9f5bb1315d1df53d0	efficient assignment of inter-die signals for die-stacking sip design	graph theory;ic design;routing;system in package;system in package graph theory integrated circuit design;wires;packaging;system on a chip;integrated circuit design;bonding;connection graph;left edge approach;interdie signal;wires substrates system on a chip routing bonding educational institutions packaging;left edge approach interdie signal die stacking sip design ic design connection graph dynamic track;substrates;dynamic track;die stacking sip design	Compared with the traditional flow for IC designs, the assignment of inter-die signals is an important stage in a die-stacking SiP design. In this paper, firstly, a connection graph for all the pads in a boundary stack can be constructed and a set of dynamic tracks can be defined from the corresponding connection graph. Based on the definition of the dynamic tracks in a connection graph, a modified left-edge approach is proposed to iteratively assign the inter-die signals onto feasible pads under the constraints of the crossing and connection conditions. Compared with the published two-stage approach[5], the experimental results show that our proposed approach reduces 99% of CPU time and 0.9% of total wirelength to assign all the inter-die signals for the tested examples on the average.	central processing unit;die (integrated circuit);stacking	Jin-Tai Yan;Chia-Han Kao;Ming-Chien Huang;Zhi-Wei Chen	2012	2012 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2012.6272019	embedded system;electronic engineering;computer science;graph theory;engineering drawing;integrated circuit design	EDA	15.396514813711194	51.52623155525789	90508
ed24569d87e4b403ffa1bfa5dc9cb3db2eb50220	a proven operational cad system for p.w.b. design-based on a mini-computer and featuring fully automatic placement and routing	switched system;integrated circuit;printed wiring board	The introduction of electronic processor controlled switching systems has led to a re-appraisal of the methods of designing printed wiring boards to cope with the sheer numbers of designs required and their increasing complexity. The Company's policy is normally to realise the equipment on double sided printed wiring boards (pwb) containing a maximum of 80 integrated circuits per board plus discrete components. (Figs. 1 and 2)  PWB requirements are frequently changing as new techniques and processes are introduced and therefore methods of improving pwb layout and artwork preparation are continually under investigation.  This paper outlines the techniques used within the company and indicates some of the procedural advancements, and the reasons for their introduction.	algorithm;computer-aided design;database;diagram;electronic component;electronic switching system;flowchart;integrated circuit;logic simulation;minicomputer;place and route;printed circuit board;requirement;resultant;routing;wiring	G. L. Patterson;B. H. Phillips	1976		10.1145/800146.804822	embedded system;electronic engineering;computer science;engineering;electrical engineering;integrated circuit;printed circuit board;engineering drawing	EDA	11.026405004302188	51.55678020807116	90528
c57322a4b581e466913493e2e3ad6d5e7d777067	$z$-diagnosis: a framework for diagnostic fault simulation and test generation utilizing subsets of outputs	diagnostic test;fault simulation;defect diagnosis;circuit simulation;diagnostic fault simulation;fault detection;diagnostic test generation;test generation;circuit testing;difference set;scan circuits	Diagnostic fault simulation is used to determine the pairs of faults distinguished by a given test set or test sequence. Diagnostic test generation is used to generate tests that distinguish pairs of faults. Typically, the test sets or test sequences contain tests that detect all the detectable target faults. In this paper, a framework for diagnostic fault simulation and test generation is described, based on structural circuit characteristics called z-sets. These characteristics are used to show that certain fault pairs are guaranteed to be distinguished by a fault detection test set. Such fault pairs do not need to be considered during diagnostic fault simulation or test generation that starts from a fault detection test set. Experimental results for single stuck-at faults in full-scan benchmark circuits demonstrate that only small percentages of fault pairs need to be considered during diagnostic fault simulation or test generation once a fault detection test set is available. The concept of -sets is extended to define z-detections. This concept uses the results of conventional fault simulation to determine additional fault pairs that are guaranteed to be distinguished by a fault detection test set. The concept of z-sets is also extended to define difference-sets (or d-sets) that provide even fewer targets for diagnostic test generation.	benchmark (computing);fault detection and isolation;sensor;simulation;test set	Irith Pomeranz;Sudhakar M. Reddy;Srikanth Venkataraman	2007	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2007.895758	reliability engineering;electronic engineering;real-time computing;fault coverage;fault indicator;engineering;stuck-at fault;automatic test pattern generation;mathematics;fault detection and isolation;diagnostic test;difference set	EDA	22.049408377077814	50.90720271773506	90551
15f005218fc7da115908fac0e8c81482d2fcd2aa	replica tracked post silicon trimming enabled negative bit line voltage based write assist scheme in sram design			static random-access memory	Ankur Goel;Rajender K. Sharma;Anil K. Gupta	2015	J. Low Power Electronics	10.1166/jolpe.2015.1404	replica;engineering;static random-access memory;computer hardware;electronic engineering;trimming;voltage;silicon	EDA	17.42938137804098	59.39923166049002	90596
67dbad326dd090b844cf42482a7f1b33c6665818	logic optimization by output phase assignment in dynamic logic synthesis	logic function;significant area overhead;logic functions;logic optimization;logic design;domino logic;minimum area duplication;area overhead;high-performance logic design;inverters;output phase assignment;dynamic logic synthesis;optimal algorithms;heuristic algorithms;inverter-free logic;logic duplication;minimum logic duplication penalty;dynamic logic;heuristic algorithm	Domino logic is one of the most popular dynamic circuit configurations for implementing high-performance logic designs. Since domino logic is inherently noninverting, it presents a fundamental constraint of implementing logic functions without any intermediate inversions. Removal of intermediate inverters requires logic duplication for generating both the negative and positive signal phases, which results in significant area overhead. This area overhead can be substantially reduced by selecting an optimal output phase assignment, which results in a minimum logic duplication penalty for obtaining inverter-free logic. In this paper, we present this previously unaddressed problem of output phase assignment for minimum area duplication in dynamic logic synthesis. We give both optimal and heuristic algorithms for minimizing logic duplication.	algorithm;domino logic;heuristic;inverter (logic gate);logic optimization;logic synthesis;mathematical optimization;overhead (computing);power inverter	Ruchir Puri;Andrew Bjorksten;Thomas E. Rosser	1996	Proceedings of International Conference on Computer Aided Design	10.1145/244522.244523	dynamic logic;control engineering;heuristic;mathematical optimization;electronic engineering;logic synthesis;logic optimization;logic level;computer science;pass transistor logic;mathematics;sequential logic;register-transfer level;algorithm	EDA	17.06032617771718	50.42358425526111	90763
28dcccce8b464526110bbc064f1d60e5c9556b01	covering conditions and algorithms for the synthesis of speed-independent circuits	optimal solution;block level circuit;concepcion asistida;computer aided design;synthese circuit;integrated circuit;langage c;circuit synthesis delay asynchronous circuits clocks synchronization voltage circuit testing integrated circuit synthesis hazards wires;clocks;implementation;circuit independant du temps;hazards;wires;circuito integrado;optimal single cube algorithm;standard c implementation;indexing terms;speed independent;gate level speed independent circuit;boolean covering condition;gate level speed independent circuit automatic synthesis standard c implementation block level circuit boolean covering condition optimal single cube algorithm asynchronous circuit;asynchronous circuit;algorithme;logic cad asynchronous circuits;algorithm;ejecucion;c language;circuit asynchrone;synchronization;voltage;conception assistee;circuito asincrono;sintesis circuito;asynchronous circuits;integrated circuit synthesis;circuit testing;covering problem;automatic synthesis;logic cad;circuit synthesis;circuit integre;lenguaje c;algoritmo	This paper presents theory and algorithms for the synthesis of standard C-implementations of speed-independent circuits. These implementations are block-level circuits which may consist of atomic gates to perform complex functions in order to ensure hazard-freedom. First, we present boolean covering conditions that guarantee the standard C-implementations operate correctly. Then, we present two algorithms that produce optimal solutions to the covering problem. The rst algorithm is always applicable but does not complete on large circuits. The second algorithm, motivated by our observation that our covering problem can often be solved with a single cube, nds the optimal single-cube solution when such a solution exists. When applicable, the second algorithm is dramatically more eecient than the rst, more general algorithm. We present results for benchmark speciications which indicate that our single-cube algorithm is applicable on most benchmark circuits and reduces run-times by over an order of magnitude. The block-level circuits generated by our algorithms are a good starting point for tools that perform technology mapping to obtain gate-level speed-independent circuits.	ansi c;algorithm;benchmark (computing);covering problems;emoticon;fluid construction grammar;olap cube;suicidegirls	Peter A. Beerel;Chris J. Myers;Teresa H. Y. Meng	1998	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.700719	embedded system;synchronization;electronic engineering;voltage;index term;asynchronous circuit;hazard;computer science;electrical engineering;theoretical computer science;integrated circuit;computer aided design;implementation;algorithm	EDA	16.952978132440606	50.080331025532004	90768
813b3240a9b8673bf2f368f3937dfce48431349d	repairable cell-based chip design for simultaneous yield enhancement and fault diagnosis	microprocessors;standards;circuit faults;flip flops;maintenance engineering;computer architecture;transistors	Fault diagnosis plays a major role in IC yield enhancement. Due to circuit structure and ATPG limitation, there exist many undistinguished fault pairs after applying test patterns and diagnosis patterns, including equivalent fault pairs and aborted fault pairs. This paper proposes a scan-based repair-for-diagnosis architecture that can distinguish undistinguished fault pairs by repairing cell defects. A repairable standard cell design technique is presented that makes the repair of defective cells easy to control. To efficiently distinguish all targeted undistinguished fault pairs, a novel fault-grouping method is developed and applied to the proposed scan-based repair-for-diagnosis architecture. With this architecture, one can distinguish multiple fault pairs and repair those defective cells hence improving yield at the same time. Experimental results show that our proposed architecture can distinguish all targeted undistinguished fault pairs and repair the defective cells with low area overhead.	existential quantification;flops;failure analysis;flip-flop (electronics);library (computing);overhead (computing);semiconductor;standard cell;test card	Sheng-Lin Lin;Cheng-Hung Wu;Kuen-Jong Lee	2016	2016 IEEE 25th Asian Test Symposium (ATS)	10.1109/ATS.2016.27	maintenance engineering;embedded system;electronic engineering;real-time computing;fault coverage;engineering;stuck-at fault;transistor	EDA	21.597544300134878	51.90844702086109	90772
7a85513de49c82b171d30092179480c4041b33e4	variability in nanometer cmos: impact, analysis, and minimization	litografia;concepcion asistida;lithographie;computer aided design;diseno circuito;optimisation;microelectronic fabrication;fabricacion microelectrica;optimizacion;integrated circuit;circuit design;tecnologia mos complementario;lithography;impact analysis;conception assistee;optimization;conception circuit;technologie mos complementaire;complementary mos technology;integrated circuit manufacture;fabrication circuit integre;fabrication microelectronique	Variation is a significant concern in nanometer-scale CMOS due to manufacturing equipment being pushed to fundamental limits, particularly in lithography. In this paper, we review recent work in coping with variation, through both improved analysis and optimization. We describe techniques based on integrated circuit manufacturing, circuit design strategies, and mathematics and statistics. We then go on to discuss trends in this area, and a future technology outlook with an eye towards circuit and CAD-solutions to growing levels of variation in underlying device technologies. r 2007 Elsevier B.V. All rights reserved.	cmos;circuit design;computer-aided design;futures studies;heart rate variability;integrated circuit;mathematical optimization;microsoft outlook for mac	Dennis Sylvester;Kanak Agarwal;Saumil Shah	2008	Integration	10.1016/j.vlsi.2007.09.001	lithography;electronic engineering;computer science;engineering;electrical engineering;integrated circuit;computer aided design;circuit design	EDA	18.93333362521149	55.04748708377042	90828
15be5cf6133f16483212e8fb6189c7a49e063e88	computation on stochastic bit streams digital image processing case studies	digital image processing;image processing;stochastic computing digital image processing fault tolerance finite state machine fsm;stochastic computing;stochastic bit streams stochastic linear gain function rigorous analysis digital image processing algorithms stochastic computational elements less hardware area;stochastic processes;fault tolerance;stochastic processes digital arithmetic image processing;digital arithmetic;finite state machine fsm	Maintaining the reliability of integrated circuits as transistor sizes continue to shrink to nanoscale dimensions is a significant looming challenge for the industry. Computation on stochastic bit streams, which could replace conventional deterministic computation based on a binary radix, allows similar computation to be performed more reliably and often with less hardware area. Prior work discussed a variety of specific stochastic computational elements (SCEs) for applications such as artificial neural networks and control systems. Recently, very promising new SCEs have been developed based on finite-state machines (FSMs). In this paper, we introduce new SCEs based on FSMs for the task of digital image processing. We present five digital image processing algorithms as case studies of practical applications of the technique. We compare the error tolerance, hardware area, and latency of stochastic implementations to those of conventional deterministic implementations using binary radix encoding. We also provide a rigorous analysis of a particular function, namely the stochastic linear gain function, which had only been validated experimentally in prior work.	algorithm;artificial neural network;computation;control system;deterministic automaton;digital image processing;error-tolerant design;experiment;finite-state machine;integrated circuit;transistor	Peng Li;David. J. Lilja;Weikang Qian;Kia Bazargan;Marc D. Riedel	2014	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2013.2247429	embedded system;fault tolerance;electronic engineering;real-time computing;image processing;computer science;electrical engineering;theoretical computer science;operating system;digital image processing;algorithm	EDA	11.533714365613784	47.23497030678562	90847
98821404f9216921bdfa74a816ae36570b038a65	high performance reliable variable latency carry select addition	high performance;reliable variable latency adder;speculative adder;designware adder;error rate;area requirement;scsa-based speculative adder;low error-rate speculative adder;select addition;scsa-based speculative addition;area reduction;reliability engineering;logic design;delta sigma;adders;critical path;error correction;time domain	Speculative adders have attracted strong interest for reducing critical path delays to sub-logarithmic delays by exploiting the trade-offs between reliability and performance. Speculative adders also find use in the design of reliable variable latency adders, which combine speculation with error correction to achieve high performance for low area overhead over traditional adders. This paper describes speculative carry select addition (SCSA), a novel function speculation technique for the design of low error-rate speculative adders and low overhead, high performance, reliable variable latency adders. We develop an analytical model for the error rate of SCSA to facilitate both design exploration and convergence. We show that for an error rate of 0.01% (0.25%), SCSA-based speculative addition is 10% faster than the DesignWare adder with up to 43% (56%) area reduction. Further, on average, variable latency addition using SCSA-based speculative adders is 10% faster than the DesignWare adder with area requirements of -19% to 16% (-17% to 29%) for unsigned random (signed Gaussian) inputs.	adder (electronics);critical path method;error detection and correction;overhead (computing);requirement;speculative execution;vergence	Kai Du;Peter J. Varman;Kartik Mohanram	2012	2012 Design, Automation & Test in Europe Conference & Exhibition (DATE)		parallel computing;logic synthesis;real-time computing;error detection and correction;word error rate;time domain;computer science;critical path method;delta-sigma modulation;algorithm;adder	EDA	10.845500457566688	60.20202116561893	90917
22498854a7a3228609a1a0828f24074b1407b76a	innovative practices session 10c: delay test	delays discrete fourier transforms clocks automatic test pattern generation microprocessors	The importance of testing for timing related defects continues to increase as devices are manufactured at ever smaller geometries and IO frequencies have increased to the point that production testers can no longer provide stored response vectors at-speed. As a result, it is increasingly important to have high quality tests for delay defects to bring down the product's DPPM levels (defective parts per million) shipped to end customers. Moreover, during the design characterization phase, these same tests are also used for isolating systematic slow paths in the design (speedpaths). With the inexorable march toward lower power SKUs, there remains a critical need to find and fix these limiting speedpaths prior to revenue shipments. Over the years, testing for delay defect has morphed from pure functional vectors that try to exercise a device like it would be in an end-user system, to intermediate methods that load assembly code into on-chip caches and execute them at speed, to completely structural methods that utilize scan DFT and check delays at the signal and gate level without resorting to any functional methods at all. This innovative practices session includes three presentations that cover a wide range of topics related to delay testing. The first presentation from Cadence outlines an approach to at-speed coverage that utilizes synergies between clock generation logic, DFT logic and ATPG tools. The solution leverages On-Product Clock Generation logic (OPCG) for high-speed testing and is compatible with existing test compression DFT. The additional DFT proposed enables simultaneous test of multiple clock domains and the inter-domain interfaces, while accounting for timing constraints between them. The ATPG clocking sequences are automatically generated by analyzing the clock domains and interfaces, and this information is used to optimize the DFT structures and for use in the ATPG process. The second presentation discusses the transformation in Intel's microprocessor speedpath characterization world over the last few generations, going from pure functional content to scan based structural content. It presents a new “trend based approach” for efficient speedpath isolation, and also delves into a comparison of the effectiveness and correlation of functional vs. structural test patterns for speedpath debug. The third presentation presents the differences between the various delay defect models, namely transition delay, path delay and small-delay, and the pros and cons of each. It goes on to describe new small delay defect ATPG flows implemented at Nvidia that are designed to balance the test generation simplicity of transition delay test patterns and the defect coverage provided by path delay test patterns. These flows enable the small delay defect test patterns to meet the test quality, delivery schedules and ATPG efficiency requirements set by a product's test cost goals.	and gate;assembly language;clock rate;display resolution;fault coverage;inter-domain;microprocessor;requirement;software bug;synergy;test card;test compression	P. Pant;M. Amodeo;S. Vora;J. Colburn	2013	2013 IEEE 31st VLSI Test Symposium (VTS)	10.1109/VTS.2013.6548938	reliability engineering;embedded system;electronic engineering;real-time computing;telecommunications;computer science;engineering;electrical engineering;automatic test pattern generation;operating system;test compression;algorithm	EDA	10.412284927960636	54.6949027413324	90931
2a483849a2ca45e8b43b8f87accfc5394f78811c	increase of crosstalk noise due to imbalanced threshold voltage between nmos and pmos in sub-threshold logic circuits	crosstalk;logic design;subthreshold circuit crosstalk manufacturing variability noise measurement signal integrity;voltage 0 3 v imbalanced threshold voltage subthreshold logic circuits aggressor driver victim driver subthreshold region crosstalk noise model spice simulation crosstalk noise test chip normal voltage operations cmos power supply voltage measured noise amplitude body bias tuning crosstalk mitigation chip designs rising edge slow nmos fast pmos corner condition falling edge size 40 nm size 1 5 mm;crosstalk noise voltage measurement noise measurement mos devices wires electrical resistance measurement;integrated circuit design;cmos logic circuits;logic design cmos logic circuits crosstalk integrated circuit design	Abnormal increase of the crosstalk noise in the sub-threshold logic circuits is found for the first time. When the threshold voltages (VTH) of nMOS and pMOS are imbalanced and the on-resistance of the aggressor driver is much lower than that of the victim driver, the large crosstalk noise is observed, because the on-resistance has an exponential dependence on VTH in the sub-threshold circuits. In this paper, the large crosstalk noise due to the imbalanced VTH is measured. A new crosstalk noise model is also proposed and verified with SPICE simulations. In a crosstalk noise test chip with 1.5-mm wire in a 40-nm CMOS at the power supply voltage (VDD) of 0.3V, the measured noise amplitude increases from 32% of VDD to 71% of VDD, when the imbalanced VTH is realized by tuning a body bias in pMOS. In the worst case fast-nMOS/slow-pMOS corner simulations, the noise amplitude increases from 47% of VDD to 68% of VDD, when VDD is reduced from 1.1V to 0.3V, which is explained by the proposed model.	best, worst and average case;cmos;crosstalk;logic gate;nmos logic;pmos logic;power supply;spice;simulation;time complexity;value-driven design	Hiroshi Fuketa;Ryo Takahashi;Makoto Takamiya;Masahiro Nomura;Hirofumi Shinohara;Takayasu Sakurai	2012	IEEE Journal of Solid-State Circuits	10.1109/JSSC.2013.2258831	embedded system;electronic engineering;logic synthesis;crosstalk;telecommunications;noise temperature;computer science;engineering;electrical engineering;integrated circuit design	EDA	21.075618439707526	56.65356782270291	90976
ff42bb38d0274416f8840c3842dc37dce5ec2f2e	dynamic temperature-aware reliability modeling for multi-branch interconnect trees		In high performance circuit design, thermal effect on electromigration (EM) reliability has become a recent major research for being a limiting factor. In this paper, we propose a novel analytic method to calculate the stress evolution considering time-varying temperature effects during the void nucleation phase for multi-branch interconnect trees, including the straight-line three-terminal wires, the T-shaped four-terminal wires and the cross-shaped five-terminal wires. The proposed closed-form expression can be used to calculate the hydrostatic stress evolution with time-varying temperature. Experiment results show that the obtained analytic solutions match well with the numerical results calculated using COMSOL and thus the proposed models can be used in traditional EM reliability analysis tools.	circuit design;electromigration;finite element method;numerical analysis;reliability engineering;the void (virtual reality);very-large-scale integration	Jiangtao Peng;Hai-Bao Chen;Hengyang Zhao;Zeyu Sun;Sheldon X.-D. Tan	2017	2017 IEEE 12th International Conference on ASIC (ASICON)	10.1109/ASICON.2017.8252419	electronic engineering;hydrostatic stress;limiting factor;nucleation;electromigration;analytic element method;computer science;circuit design	EDA	22.44999048608056	59.35232856281141	91003
aa07aa1267f41f3b2d325f4b7657355217eb1387	parameter tuning in svm-based power macro-modeling	iterative method;circuits energy consumption kernel support vector machines dynamic range iterative methods statistics clustering algorithms machine learning algorithms machine learning;machine learning algorithms;least squares approximations;kernel;least squares method;support vector machines;power estimation;support vector machines digital circuits iterative methods least squares approximations power consumption;training;data mining;support vector;power distribution;iterative method parameter tuning power macro modeling support vector machines high level power estimation power consumption least squares method;iterative methods;computational modeling;high level power estimation;machine learning;parameter tuning;energy consumption;least square;integrated circuit modeling;dynamic range;statistics;macro model power estimation support vector machines;clustering algorithms;macro model;circuits;support vector machine;power consumption;functional unit;digital circuits;iteration method;data models;power macro modeling	We investigate the use of support vector machines (SVMs) to determine simpler and better fit power macromodels of functional units for high-level power estimation. The basic approach is first to obtain the power consumption of the module for a large number of points in the input signal space. Least-Squares SVMs are then used to compute the best model to fit this set of points. We have performed extensive experiments in order to determine the best parameters for the kernels. Based on this analysis, we propose an iterative method of improving the model by selectively adding new support vectors and increasing the sharpness of the model. The macromodels obtained confirm the excellent modelling capabilities of the proposed kernel-based method, providing both excellent accuracy on maximum error (close to 17%) and average (2% error), which represents an improvement over the state-of-the-art. Furthermore, we present an analysis of the dynamic range of power consumption for the benchmarks circuits, which serves to confirm that the model is able to accommodate circuits exhibiting a more skewed power distribution.	algorithm;benchmark (computing);digital electronics;dynamic range;estimation theory;experiment;feature selection;high- and low-level;iterative method;least squares support vector machine;mathematical optimization;tweaking	António Gusmão;Luis Miguel Silveira;José C. Monteiro	2009	2009 10th International Symposium on Quality Electronic Design	10.1109/ISQED.2009.4810283	support vector machine;mathematical optimization;computer science;theoretical computer science;machine learning;iterative method	EDA	12.747967002399653	48.74270752245682	91061
dc7da1cb08f045b211b57d6ab84343483aae2998	minimum convertible voltage analysis for ratioless and robust subthreshold level conversion	subthreshold signal conversion minimum convertible voltage analysis ratioless subthreshold level conversion robust subthreshold level conversion subthreshold logics subthreshold memory ubiquitous computing applications level converters;mosfets;optical character recognition software;capacitors;driver circuits;robustness;delay robustness optical character recognition software mosfets capacitors	Subthreshold logics and memories are crucial elements in ubiquitous-computing applications. The subthreshold circuits need level converters to communicate with the other circuits that use high supply voltages. However, level conversion from sub-to-super-threshold voltage suffers from weak driving strength and severe process variations. The level conversion may depend on the size or threshold voltage of the transistors. This paper therefore analyzes level converters that can robustly convert subthreshold signals without using ratio-sized or multiple-threshold-voltage transistors. The limit of the subthreshold level conversion is thoroughly analyzed. This study suggests that level converters using current-mirror structures are superior candidates for converting subthreshold signals, according to the analytical and simulation results.	current mirror;mathematical optimization;simulation;transistor;ubiquitous computing	Shien-Chun Luo;Chi-Ray Huang;Lih-Yih Chiou	2012	2012 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2012.6271824	electronic engineering;capacitor;telecommunications;computer science;engineering;electrical engineering;subthreshold conduction;robustness	Arch	19.221613287707292	58.53158933087648	91077
1913233b7aaa34d22d294a32130214ee249219b4	sat based timing analysis for fixed and rise/fall gate delay models	rise fall delays;sat;event modeling;timing analysis;ta engineering general civil engineering general	This paper proposes a SAT based technique for timing analysis by an accurate modeling of event propagation within gate-level circuits. The accuracy of the result depends on the level of detail with which circuit activity is modeled. However, the combinatorial blowup in the size and complexity of the problem is the main bottleneck in any detailed modeling. The proposed technique overcomes this problem by an efficient SAT modeling of events at the nodes of the circuit which scales very smoothly with increase in size of the circuit without sacrificing on accuracy even with industry standard gate delays of 0.01 ns granularity. This improvement in performance enables the modeling of more complex gate delay models like the rise/fall delay model which can simulate circuit activity more realistically than the fixed gate delay model. & 2011 Elsevier B.V. All rights reserved.	benchmark (computing);boolean satisfiability problem;elegant degradation;level of detail;propagation delay;scalability;simulation;smoothing;software propagation;static timing analysis;technical standard	Suchismita Roy;P. P. Chakrabarti;Pallab Dasgupta	2012	Integration	10.1016/j.vlsi.2011.03.007	embedded system;electronic engineering;real-time computing;simulation;delay calculation;computer science;static timing analysis;algorithm	EDA	22.05756596742471	58.416325066590495	91182
c8cd610aa8d87d71358785ba171e7e9557b383bd	a ranking algorithm for mos circuit layouts	graph theory;concepcion asistida;computer aided design;red logica programable;teoria grafo;cmos technology;integrated circuit;logic design;helium;funcion logica;logique combinatoire;logic circuits;inverters;circuito integrado;tecnologia mos complementario;programmable logic arrays;theorie graphe;physics computing;logical function;fonction logique;boolean expression;algorithme;algorithm;algorritmo;logica combinatoria;programmable logic array;integrated circuit synthesis circuit synthesis logic circuits cmos technology digital circuits logic design programmable logic arrays inverters physics computing;expresion booleana;rang;expression booleenne;characterization;reseau logique programmable;conception assistee;ranking algorithm;integrated circuit synthesis;combinatorial logic;caracterisation;digital circuits;technologie mos complementaire;caracterizacion;circuit synthesis;circuit integre;complementary mos technology	In the synthesis of digital circuits, one encounters the problem of identifying blocks which have been designed, so that there is no replication in the expensive effort of generating the physical layout of these blocks. We present a model for the synthesis of combinational logic into complex MOS circuits and present a ranking and unranking procedure to characterize the layout of each complex MOS circuit.	algorithm;combinational logic;digital electronics;integrated circuit layout	C. Andrew Neff;Ravi Nair	1987	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.1987.1270241	embedded system;electronic engineering;logic synthesis;boolean expression;logic gate;programmable logic array;computer science;electrical engineering;graph theory;integrated circuit;computer aided design;combinational logic;helium;cmos;digital electronics;algorithm	EDA	16.733674219344067	49.74425574306002	91410
9b03181696e8f3782c4223b1f57ce4665b5a6566	standard cmos implementation of a multiple-valued logic signed-digit adder based on negative differential-resistance devices	signed digit;negative differential resistance;rtds;redundant number systems;multivalued logic circuits;resonant tunneling diodes;current voltage characteristic;multipeak negative differential resistance cmos implementation multiple valued logic signed digit adder negative differential resistance devices multiple valued logic circuits mos transistors;resonant tunneling diode;adders;propagation delay;cmos logic circuits prototypes mosfets logic devices logic circuits resonant tunneling devices diodes current voltage characteristics adders standards development;cmos logic circuits;cmos logic circuits multivalued logic circuits adders;negative differential resistance devices;ndr devices;signed digit adder;multiple valued logic	This paper presents MOS-NDR, a new prototyping technique for multiple-valued logic circuits combining MOS transistors and multipeak negative differential-resistance (NDR) devices such as resonant-tunneling diodes (RTDs). MOS-NDR emulates the folded current-voltage characteristics of NDR devices such as RTDs using only NMOS transistors, MOS-NDR has enabled the development of a fully integrated multivalued signed-digit full adder (SDFA) circuit by means of a standard 0.6-micron CMOS process technology. The prototype has been fabricated and correct operation has been verified. The circuit dimensions are 123.75 by 38.7 microns, which is more than 15 times smaller than the area required by the equivalent hybrid RTD-CMOS prototype. The propagation delay of the hybrid RTD-CMOS design is estimated to be close to six times higher than that of the MOS-NDR implementation.		Alejandro F. González;Mayukh Bhattacharya;Shriram Kulkarni;Pinaki Mazumder	2000		10.1109/ISMVL.2000.848639	propagation delay;electronic engineering;computer science;electrical engineering;mathematics;resonant-tunneling diode;algorithm;adder	EDA	15.932210684101026	58.16712241814826	91426
b2897740dc10bb86c7dfdc3c98b26f9b8357d5f7	an optimized clp-based technique for generating propagation sequences	sequential circuits circuit optimisation constraint handling finite state machines logic testing;constraint logic programs;circuit faults;automatic test pattern generation;sequential circuits;extended finite state machines;circuit faults automatic test pattern generation registers optimization engines logic gates explosions;hard problems;finite state machines;engines;logic gates;extended finite state machine;registers;constraint logic programming based methodology;clp based technique optimisation;clp based technique optimisation propagation sequences constraint logic programming based methodology functional faults extended finite state machines state explosion problem hard problems;logic testing;propagation sequences;state explosion problem;constraint handling;explosions;optimization;constraint logic programming;state explosion;circuit optimisation;functional atpg;functional faults	The paper presents a constraint logic programming-based methodology to generate propagation sequences for functional faults by traversing extended finite state machines. Moreover, different strategies are presented to deal with the state explosion problem arising when constraint logic programming is adopted for solving hard problems. Experimental results show the effectiveness of the proposed solutions.	constraint logic programming;finite-state machine;software propagation	Franco Fummi;Valerio Guarnieri;Cristina Marconcini;Graziano Pravadelli	2008	Proceedings of IEEE East-West Design & Test Symposium (EWDTS'08)	10.1109/EWDTS.2008.5580150	constraint logic programming;concurrent constraint logic programming;constraint programming;discrete mathematics;constraint satisfaction;theoretical computer science;mathematics;algorithm	Embedded	18.46360286367353	48.51947464122905	91438
a045d5b7f4e9b4f326a6099d74ef29e67c320030	sram dynamic stability: theory, variability and analysis	sram stability margin;rigorous nonlinear system theory;key sram nonlinear dynamical;sram dynamic noise margin;conventional static noise margin;parametric dynamic stability analysis;sram dynamic stability characteristic;dynamic read-write-assist circuit;brute-force approach;nonlinear cell dynamic;system theory;digital circuit;trajectory;nonlinear dynamics;nonlinear system;stability;cad;noise;stability analysis;sram	Technology scaling in sub-100nm regime has significantly shrunk the SRAM stability margins in data retention, read and write operations. Conventional static noise margins (SNMs) are unable to capture nonlinear cell dynamics and become inappropriate for state-of-the-art SRAMs with shrinking access time and/or advanced dynamic read-write-assist circuits. Using the insights gained from rigorous nonlinear system theory, we define the much needed SRAM dynamic noise margins (DNMs). The newly defined DNMs not only capture key SRAM nonlinear dynamical characteristics but also provide valuable design insights. Furthermore, we show how system theory can be exploited to develop CAD algorithms that can analyze SRAM dynamic stability characteristics three orders of magnitude faster than a brute-force approach while maintaining SPICE-level accuracy. We also demonstrate a parametric dynamic stability analysis approach suitable for low-probability cell failures, leading to three orders of magnitude runtime speedup for yield analysis under high-sigma parameter variations.	access time;algorithm;analytical engine;automatic control;cmos;cell (microprocessor);computer-aided design;design automation and test in europe;dynamical system;heart rate variability;image scaling;importance sampling;integrated circuit;microwave;monte carlo method;noise margin;nonlinear system;p (complexity);prentice hall international series in computer science;read-write memory;spice;sampling (signal processing);simulation;spatial variability;speedup;static random-access memory;systems theory;very-large-scale integration	Wenhua Dong;Peng Li;Garng M. Huang	2008	2008 IEEE/ACM International Conference on Computer-Aided Design	10.1145/1509456.1509544	control engineering;electronic engineering;von neumann stability analysis;real-time computing;stability;static random-access memory;nonlinear system;computer science;noise;electrical engineering;trajectory;cad;digital electronics;systems theory;statistics	EDA	22.45358730793517	59.02806755011089	91521
0ba63d684aaf1804e5a1ecb3046c17872827f77f	timing error prediction based adaptive voltage scaling for dynamic variation tolerance	voltage control;clocks;temperature 25 degc timing error prediction based adaptive voltage scaling dynamic variation tolerance conservative timing margin pvt variation integrated circuit design time power consumption on chip timing error monitoring timing error reduction tunable replica paths double sampling monitor error prediction probability proper prediction alarm threshold system on chip tsmc cmos process timing prediction mechanism costing area overhead nondvs scheme circuit architecture size 65 nm frequency 400 mhz;monitoring delays voltage control power demand clocks flip flops;flip flops;low power timing monitor replica critical paths adaptive voltage scaling pvt variation;monitoring;system on chip cmos integrated circuits error statistics integrated circuit design;power demand;delays	There is always some conservative timing margin to ensure the chip to work properly under PVT variations during integrated circuit design time. The existence of the timing margin leads to a waste of power consumption. There are many adaptive techniques to monitor the on-chip timing error to reduce the timing error. In this paper, tunable replica paths which are a little more critical than the original critical paths have been designed and used to monitor the timing error with double-sampling monitors. In order to eliminate the timing margin as much as possible without causing real timing errors, the error prediction probability is analyzed to set the proper prediction alarm threshold for adaptive voltage scaling scheme. The whole scheme is used on a system-on-chip under TSMC 65nm CMOS process with a layout area of 2000μm~1180μm, with the replica path and timing prediction mechanism costing only 2.7% area overhead. The post simulation results show that its power reduction is between 31.5% ~ 42.2% compared with non-DVS scheme at 400MHz frequency, 25 °C, under different process corners (FF, FS, TT, SF and SS). The advantage of our proposed method lies in that it does not need to break the circuit architecture while offering decent power reduction by reducing the timing margin.	32-bit;cmos;cpu core voltage;central processing unit;dynamic voltage scaling;image scaling;integrated circuit design;overhead (computing);process corners;sampling (signal processing);simulation;system on a chip;transponder timing	Weiwei Shan;Zhipeng Xu	2014	2014 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)	10.1109/APCCAS.2014.7032887	embedded system;electronic engineering;real-time computing;engineering;static timing analysis	EDA	19.062458139940833	58.489484450611	91611
7e42f3f24423936deae879a15968dd5b89252008	optimization of high-speed cmos logic circuits with analytical models for signal delay, chip area, and dynamic power dissipation	digital circuit;estructura mos;analytical models;cmos integrated circuits;retardo senal;optimisation;concepcion circuito;design tool;digital vlsi circuits;chip area;optimizacion;combinatorial circuits;dissipation energie;etude experimentale;very large scale integration;signal design;performance;circuit design;multiobjective gate level optimization;high speed logic circuits;circuit vlsi;energy dissipation;global optimisation;circuito logico;moglo;cmos logic circuits circuit analysis delay design optimization power dissipation signal design very large scale integration analytical models algorithm design and analysis circuit optimization;tecnologia mos complementario;design optimization;dynamic power dissipation;chip;algorithme;circuit numerique;algorithm;vlsi circuit;circuit analysis;signal delay;gate level delay models;low computational costs;high speed logic circuits digital vlsi circuits global optimisation combinatorial logic circuits cmos logic circuits analytical models signal delay chip area dynamic power dissipation design tool multiobjective gate level optimization moglo low computational costs gate level delay models;circuit logique;grande vitesse;cmos logic circuits;power dissipation;retard signal;circuito numerico;structure mos;combinatorial logic circuits;global optimization;disipacion energia;optimization;conception circuit;gran velocidad;circuit cad;integrated logic circuits;rendimiento;circuito vlsi;technologie mos complementaire;logic cad;logic circuit;high performance;estudio experimental;high speed;algorithm design and analysis;complementary mos technology;analytical model;mos structure;circuit optimization;transistor;algoritmo;optimisation circuit cad cmos integrated circuits combinatorial circuits integrated logic circuits logic cad	Signal delay, chip area, and power dissipation are conflicting criteria for designing high performance VLSI MOS circuits. This paper describes global optimization of transistor sizes in digital CMOS logic circuits with the design tool multiobjective gate level optimization (MOGLO). Analytical models for the design objectives are presented and novel algorithms are discussed. Different techniques were combined to solve the circuit optimization problem with low computational costs. Precise gate level delay models guarantee meaningful results especially for high-speed logic circuits.	algorithm;analytical engine;cmos;design tool;global optimization;hcmos;logic gate;mathematical optimization;optimization problem;transistor;very-large-scale integration	Bernhard Hoppe;Gerd Neuendorf;Doris Schmitt-Landsiedel;J. Will Specks	1990	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.46799	control engineering;mathematical optimization;electronic engineering;logic optimization;logic level;asynchronous circuit;logic family;computer science;electrical engineering;dissipation;pass transistor logic;integrated injection logic;algorithm;global optimization	EDA	17.870204492207495	53.876585142739586	91640
2ba1be1599d6c69c447be6515034e2784b5011d3	pre-layout module wise decap allocation for noise suppression and accurate delay estimation of soc		This paper addresses estimation of decoupling capacitance (decap) at sub-module stage based on their power dissipation and proper allocation of decap at the pre-layout level. Decap being in between power and ground distribution networks acts as local charge storage and effectively reduces rapid transients in the supply drop. Therefore, present trends in VLSI design are inclined towards the placement of decoupling capacitors for system on chip (SoC) design. But, early prediction and allocation of decaps at appropriate locations in the pre-layout circuit can only provide a better scope in optimizing power, noise and delay effects for the circuit. The novelty of our work lies in exhaustive module wise estimation of di/dt drop for the complete circuit, followed by an algorithmic estimation and appropriate allocation of decaps with an effort to keep power, delay and noise performance to its best. We choose Double DES as example crypto-core for our test circuits as this is quite complex in nature and are also used as custom cores in many SoC applications. We investigate the change in power, noise and delay parameters with and without the decap allocation for multi-core circuits at the pre-layout stage and find satisfactory suppression of noise at the cost of negligible increase in power and delay. By using our approach, average peak noise and maximum peak noise can be suppressed approximately by 22.7% and 32.23% respectively at the pre-layout stage comparing with the previous works. This early prediction helps in more accurate Computer Aided Design (CAD) implementation at the layout stage.	computer-aided design;coupling (computer programming);multi-core processor;system on a chip;triple des;very-large-scale integration;zero suppression	Moumita Chakraborty;Amlan Chakrabarti;Partha Mitra;Debasri Saha;Krishnendu Guha	2016	2016 20th International Symposium on VLSI Design and Test (VDAT)	10.1109/ISVDAT.2016.8064873	real-time computing;system on a chip;electronic engineering;capacitor;decoupling (cosmology);decoupling capacitor;computer aided design;very-large-scale integration;electronic circuit;computer science;capacitance;control theory	EDA	16.983458534511826	55.35984046092265	91743
83c3f55e3ac51a6db6f4777f3924d07f7a0b63f3	wirelength-driven force-directed 3d fpga placement	field programmable gate array;wfp;three dimensions;placement;legalization;sa;simulated annealing;low temperature;force directed;partition;space filling curve;3 d	In this paper, a wirelength-driven force-directed three-dimension (3-D) Field Programmable Gate Arrays (FPGA) placement algorithm (3D-WFP) is presented. The algorithm is composed of three stages: Overlap permitted force-directed 2-D placement, legalization and 3-D layer partition. Different from traditional partition-based 3-D placers, we adjust the layer partition process after the 2-D global placement, which effectively provides the global interconnection and timing information for the next two sub-steps. To legalize the position of the logic block, a 3-D space filling curve is adopted. A low temperature simulated annealing (SA) is used to determine the blocks final layer. Only blocks with the same horizontal coordinate are permitted to interchange, the speed of the SA is very fast. Compared to recently publish 3-D FPGA placement work, this algorithm improves the half perimeter wire-length (HPWL) by 8.57%, almost at the same time cost and keeps the same timing performance.	algorithm;field-programmable gate array;force-directed graph drawing;interconnection;logic block;overlap–add method;perimeter;simulated annealing;space-filling curve	Wentao Sui;Sheqin Dong;Jinian Bian	2010		10.1145/1785481.1785582	partition;embedded system;three-dimensional space;electronic engineering;parallel computing;real-time computing;simulated annealing;computer science;field-programmable gate array;placement	EDA	13.814696170561115	52.51278718619687	91769
0255f61653b8bd8137c2247eed3cf926a7331d64	non-solution implications using reverse domination in a modern sat-based debugging environment	functional debugging;on-the-fly detection;real-life industrial debugging case;early on-the-fly detection;nonsolution implication;rtl;cad flow;modern sat-based debugging environment;non-solution area;sat solver calls;automatic bug localization;error select variable;reverse domination;circuit blocks;debugging search space;vlsi design;industrial debugging;circuit layout cad;computability;early pruning;sat solver call;vlsi;dominance relationship;integrated circuit design;sat solver;debugging search-space;bug-free components;sat-based debugging environment;non-solution implication;decision tree;power analysis;sequential circuits;debugging;power optimization;stability;logic gate;sequential analysis;algorithm design;decision trees;engines;observability;algorithm design and analysis;search space;logic gates	With the growing complexity of VLSI designs, functional debugging has become a bottleneck in modern CAD flows. To alleviate this cost, various SAT-based techniques have been developed to automate bug localization in the RTL. In this context, dominance relationships between circuit blocks have been recently shown to reduce the number of SAT solver calls, using the concept of solution implications. This paper first introduces the dual concepts of reverse domination and non-solution implications. A SAT solver is tailored to leverage reverse dominators for the early on-the-fly detection of bug-free components. These are non-solution areas and their early pruning significantly reduces the the debugging search-space. This process is expedited by branching on error-select variables first. Extensive experiments on tough real-life industrial debugging cases show an average speedup of 1.7x in SAT solving time over the state-of-the-art, a testimony of the practicality and effectiveness of the proposed approach.	automation;boolean satisfiability problem;branch (computer science);clock rate;computer-aided design;debugging;dominating set;experiment;int (x86 instruction);int 13h;introduction to algorithms;propositional calculus;real life;search algorithm;solver;speedup;true quantified boolean formula;very-large-scale integration	Bao Le;Hratch Mangassarian;Brian Keng;Andreas G. Veneris	2012	2012 Design, Automation & Test in Europe Conference & Exhibition (DATE)		embedded system;algorithm design;electronic engineering;parallel computing;real-time computing;logic gate;computer science;theoretical computer science;operating system;decision tree;very-large-scale integration;algorithmic program debugging;programming language;algorithm;statistics	EDA	18.497596582387168	48.90353109026069	91781
7ec3ee7adb59e4c2b037a52829e136b57b60992c	an effective congestion-driven placement framework	congestion estimation;minimization;mathematics;dynamic avoidance;integrated circuit layout;routing;very large scale integration;routing criticalities detection;physical design;indexing terms;routing timing partitioning algorithms very large scale integration minimization mathematics optimization methods circuits;network routing;chip;partitioning based placement algorithm;congestion driven placement framework;computer experiment;global routing;circuit layout cad vlsi network routing integrated circuit layout;vlsi;circuit layout cad;circuits;vlsi chips;physical design congestion driven placement framework routing criticalities detection very large scale integration vlsi chips congestion estimation partitioning based placement algorithm dynamic avoidance;partitioning algorithms;optimization methods;timing	We present a fast but reliable way to detect routing criticalities in very large scale integration chips. In addition, we show how this congestion estimation can be incorporated into a partitioning based placement algorithm. Different to previous approaches, we do not rerun parts of the placement algorithm or apply a postplacement optimization, but we use our congestion estimator for a dynamic avoidance of routability problems in one single run of the placement algorithm. Computational experiments on chips with up to 1300000 cells are presented. The framework reduces the usage of the most critical routing edges by 9.0% on average, the running time increase for the placement is about 8.7%. However, due to the smaller congestion, the running time of routing tools can be decreased drastically, so the total time for placement and (global) routing is decreased by 47% on average.	network congestion	Ulrich Brenner;André Rohe	2003	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/TCAD.2003.809662	routing;electronic engineering;static routing;parallel computing;real-time computing;computer science;electrical engineering;very-large-scale integration;placement	EDA	15.543868692048777	52.53466785945635	91804
604fc3fcba215a4f27a558eaac89672d4c3f797e	reconfigurable circuit design based on arithmetic logic unit using double-gate cntfets	arithmetic logic unit;binary decision diagram		arithmetic logic unit;circuit design	Hiroshi Ninomiya;Manabu Kobayashi;Yasuyuki Miura;Shigeyoshi Watanabe	2014	IEICE Transactions		computer architecture;parallel computing;logic synthesis;logic optimization;asynchronous circuit;logic gate;logic family;computer science;programmable logic device;arithmetic logic unit;pass transistor logic;binary decision diagram;digital electronics;register-transfer level;74181	EDA	18.790225561503792	46.98327091690058	91931
f5719c8b32577aebd5e2757d463c08a3581e0301	accurate layout area and delay modeling for system level design	system level design;accurate layout area;physical design	We discuss the problem of estimating design quality measures to accurately reflect design tradeoffs and efficiently explore the design space. SpeciJcally. we are interested in predicting the layout area and delay of a given structural RT level design. Clearly, current RT level cost measures are highly simplified and do not reflect the real physical design. In order to establish a more realistic assessment of layout effects, we proposed a new layout model which accurately and efficiently accounts for the effects of wiring andjloorplanning on the area and performance layout of RT level designs. Benchmarking has shown that our model is quite accurate.	address space layout randomization;level design;physical design (electronics);wiring	Champaka Ramachandran;Fadi J. Kurdahi;Daniel Gajski;Allen C.-H. Wu;Viraphol Chaiyakul	1992		10.1145/304032.304133	layout versus schematic;physical design;embedded system;computer architecture;electronic engineering;real-time computing;ic layout editor;computer science;engineering;design layout record;electronic system-level design and verification;circuit extraction;register-transfer level;standard cell	EDA	13.54343617509502	54.39070591988973	92093
72f78e1e3b934130e7d9ed9b89668fee65c0a1fc	evaluation of cardinality constraints on smt-based debugging	debugging;circuit faults;debugging satisfiable modulo theory smt cardinality constraint;computability;debugging encoding surface mount technology hardware arithmetic constraint theory formal verification adders runtime circuits;rewriting systems adders computability encoding formal verification logic testing;abstraction technique;satisfiability;adder network;multiplexing;decision problem;multiplexor cardinality constraint smt based debugging formal verification hardware satisfiability modulo theory term rewriting abstraction technique bit blasting technique encoding adder network shifter;formal verification;engines;rewriting systems;adders;logic testing;shifter;experimental evaluation;multiplexor;cardinality constraint;bit blasting technique;term rewriting;satisfiability modulo theories;encoding;benchmark testing;satisfiable modulo theory smt;hardware satisfiability modulo theory;smt based debugging	For formal verification of hardware Satisfiability Modulo Theory (SMT) solvers are increasingly applied. Today's state-of-the-art SMT solvers use different techniques like term-rewriting, abstraction, or bit-blasting. The performance does not only depend on the underlying decision problem but also on the encoding of the original problem into an SMT instance. In this work, encodings for cardinality constraints in SMT are investigated. Three different encodings are considered: an adder network, an encoding with multiplexors, and a newly proposed encoding with shifters. The encodings are analyzed with respect to size and complexity. The experimental evaluation on debugging instances that contain cardinality constraints shows the strong influence of the encoding on the resulting run-times.	adder (electronics);benchmark (computing);boolean satisfiability problem;cardinality (data modeling);complexity;debugging;decision problem;formal verification;rewriting;solver	André Sülflow;Robert Wille;Görschwin Fey;Rolf Drechsler	2009	2009 39th International Symposium on Multiple-Valued Logic	10.1109/ISMVL.2009.28	multiplexer;benchmark;discrete mathematics;formal verification;computer science;theoretical computer science;decision problem;mathematics;computability;programming language;debugging;satisfiability modulo theories;algorithm;multiplexing;adder;encoding;satisfiability	Logic	17.843540672093983	47.81041174746694	92188
11b102b3e16024fb4fba870719b7e0636383ec1f	noise in deep submicron digital design	cmos circuits;static noise analysis methodology;digital system;crosstalk;deep submicron digital design;static analysis;noise issue;noise;logic design issue;noise immunity;technology scale;inductance;noise source;noise margins;noise stability;analysis issue;technology trend;chip;digital design;vlsi;logic design	As technology scales into the deep submicron regime, noise immunity is becoming a metric of comparable importance to area, timing, and power for the analysis and design of VLSI systems. This paper defines noise as it pertains to digital systems and addresses the technology trends which are bringing noise issues to the forefront. The noise sources which are plaguing digital systems are explained. A metric referred to as noise stability is defined, and a static noise analysis methodology based on this metric is introduced to demonstrate how noise can be analyzed systematically. Analysis issues associated with on-chip interconnect are also considered. This paper concludes with a discussion of the device, ciruit, layout, and logic design issues associated with noise.	digital electronics;logic synthesis;microsoft forefront;very-large-scale integration	Kenneth L. Shepard;Vinod Narayanan	1996	Proceedings of International Conference on Computer Aided Design	10.1145/244522.244879	chip;electronic engineering;logic synthesis;crosstalk;telecommunications;inductance;computer science;engineering;noise;electrical engineering;static analysis;computer engineering	EDA	21.173544101627893	56.8518556036518	92422
ba6feab26d7a7322af1055fb95b37174f54edac1	crosstalk fault detection by dynamic idd	process variation;analog circuit modeling;design of experiments;posynomial and signomial response surface modeling;energy consumption;power dissipation;fault detection;test methods;geometric programming	Undesired capacitive crosstalk between signals is expected to be a significant concern in deep submicron circuits. New test techniques are needed for these crosstalk faults since they may cause unacceptable performance degradation. We analyze the impact of crosstalk faults on a circuit's power dissipation. Crosstalk faults can be detected by monitoring the dynamic supply current. The test method is based on a recently developed dynamic Idd test metric, the energy consumption ratio (ECR). ECR-based test has been shown to be effective at tolerating the impact of process variations. In this paper, we apply a ECR-based test method called ECR-VDD test to detect the crosstalk faults. The effectiveness of the method is demonstrated by simulation results.	cpu power dissipation;crosstalk;elegant degradation;simulation;value-driven design;very-large-scale integration	Xiaoyun Sun;Seonki Kim;Bapiraju Vinnakota	2001			embedded system;electronic engineering;real-time computing;geometric programming;engineering;dissipation;mathematics;test method;process variation;design of experiments;fault detection and isolation;statistics	EDA	21.013200690256227	57.40540873414619	92581
0c120383eb2485a8db331e6b980bcb6349bb9e79	impact of on-chip interconnects on vertical signal propagation in 3d ics	silicon;interconnect length three dimensional integrated circuits signal propagation speed stacked chips 3d ic systems vertical signal propagation through silicon via based 3d ic physical parameter variations propagation delay on chip interconnects vertical signal interconnect fanout;3d ic interconnect propagation delay through silicon via;system on chip;integrated circuit interconnections;integrated circuit modeling;integrated circuit interconnections integrated circuit modeling through silicon vias system on chip silicon capacitance delays;capacitance;three dimensional integrated circuits delays integrated circuit interconnections integrated circuit modelling;delays;through silicon vias	Three-dimensional integrated circuits (3D ICs) provide a promising solution for overcoming delay/power problems of 2D ICs by stacking chips vertically. Signal propagation speed among the stacked chips is very important for 3D IC systems. We propose a simple model for analyzing the vertical signal propagation in through-silicon-via-based 3D ICs and discuss the impact of physical parameter variations on propagation delay. Experimental results show that on-chip interconnects greatly affect vertical signal propagation when there are dense general interconnects near the vertical signal interconnect, large amount of fanout, and interconnect length of a driver and receivers is long.	electrical connection;fan-out;layer (electronics);propagation delay;software propagation;speaker wire;stacking;three-dimensional integrated circuit	Nanako Niioka;Masayuki Watanabe;Rosely Karel;Tetsuya Kobayashi;Masashi Imai;Masa-Aki Fukase;Atsushi Kurokawa	2014	2014 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)	10.1109/APCCAS.2014.7032854	system on a chip;embedded system;electronic engineering;computer science;electrical engineering;through-silicon via;capacitance;silicon	EDA	14.374021820688933	56.92116189550108	92716
d97c9489f84313413f4595cc49adb1fc8dcc05f1	asic bist synthesis: a vhdl approach	automatic control;asic design;interconnect bist;foundry;automated design;asic bist synthesis;vhdl language;design for testability;embedded memory;module pcb bist;test stimulus generation;automatic testing;hardware description languages;field test;automatic test equipment;data processors;factory testing;process design;lan interconnection;high level synthesis;built in self test;application specific integrated circuits;controllers;logic testing;production facilities;automatic test equipment built in self test application specific integrated circuits design for testability high level synthesis sram chips logic testing hardware description languages production testing automatic testing;sram;asic mission logic;external memory;production testing;56 to 164 k asic bist synthesis sram automated design bist architecture asic mission logic external memory embedded memory interconnect bist module pcb bist high level synthesis vhdl language asic design test stimulus generation foundry factory testing field test controllers data processors;bist architecture;foundries;logic devices;56 to 164 k;application specific integrated circuits built in self test automatic testing process design logic devices lan interconnection high level synthesis foundries production facilities automatic control;sram chips	This paper describes the practical aspects of an automated design process and tool environment developed to rapidly and effectively include BIST into ASIC designs. An overview of the BIST architecture is given describing BIST capabilities for ASIC mission logic, embedded and external memory, devices, and an interconnect BIST capability used to assist module/PCB BIST. A high level synthesis approach is employed using the VHDL language in a way unique to its intended purpose. An automatic means for instantiating VHDL BIST structures into an ASIC design is described. Other automated phases of the development cycle are discussed including testability enhancement of the ASIC core and test stimulus generation for foundry, factory, and field test. Results are presented for 6 ASIC designs ranging in gate count from 56 k-164 k gates (complexity from controllers to data processors).	application-specific integrated circuit;built-in self-test;vhdl	Tom Eberle;Robert McVay;Chris Meyers;Jason Moore	1996		10.1109/TEST.1996.557133	embedded system;computer architecture;electronic engineering;computer science;engineering;operating system;automatic control;application-specific integrated circuit;computer engineering	EDA	10.360221043399651	52.23730095983698	92781
66e56560a91d59b43a398fc943116f2fb3b64a0b	programmable array realizations of synchronous sequential machines	cellular structure;index terms programmable cellular array;functional form;secondary state assignment;indexing terms;input output;large scale integration;index terms programmable cellular array secondary state assignment sequential machine structure sequential machine synthesis;sequential machine synthesis;sequential machine structure;flip flop	Cellular-array realizations of switching functions have been studied in order to take advantage of the many design possibilities offered by large-scale integration technology. This paper introduces a class of programmable cellular arrays that can be employed to realize arbitrary synchronous sequential machines. State assignments based upon k-out-of-m codes are employed to give rise to machine excitation and output equations in a consistent functional form suitable for implementation via a cellular structure. The proposed arrays are programmable, which makes possible the capability of re-configuring an array to realize different machines by electronically altering the function implemented by each cell of the array. A synthesis algorithm is presented that will allow the designer to program the array without explicitly deriving excitation and output functions. The synthesis technique is applicable to both Mealy and Moore machines with any number of inputs, outputs, and internal states, and utilizing either delay or trigger flip-flops.	algorithm;code;flops;flip-flop (electronics);higher-order function;integrated circuit;mealy machine;moore machine	Edward W. Page;Peter N. Marinos	1977	IEEE Transactions on Computers	10.1109/TC.1977.1674920	input/output;embedded system;parallel computing;index term;programmable logic array;computer science;electrical engineering;theoretical computer science;operating system;programming language;higher-order function;algorithm	EDA	12.093723614125548	49.848250614906824	92799
27cd9f064e461689adf5dd437197eec1589a617a	some techniques for efficient symbolic simulation-based verification	symbol manipulation;boolean functions;boolean variables encoding regular arrays verification symbolic simulation based verification nonregular designs;input constraint;formal verification;circuit simulation computational modeling formal verification computer science cities and towns computer simulation hardware switching circuits humans very large scale integration;control flow;encoding;symbol manipulation boolean functions encoding formal verification	We present some techniques to make symbolic simulation-based verification efficient in practice. The first technique is applied to the verification of nonregular designs. Minimally instantiated symbolic simulation veciors are first generated, and all these vectors are encoded into one vector using auziliary (parametric) Boolean variables. The second technique also pertains to non-regular designs, and it oflers a way to compactly encode input constraints during symbolic simulation. Two variations of this technique are ezplored. The third technique relates t o the verification of regular arrays. I t is shown that many regular arrays require input constraints t o be obeyed, and that these constraints can be encoded using parametric Boolean variables. Another related technique (applicable t o regular arrays where control-flow is data independent) does not encode the input constraints, but takes them into account after symbolic simulation. All these techniques are geared towards reducing the computational (and human) effort during simulationbased verification, and are supported by ezperimental results.	computation;control flow;encode;regular expression;regular language;symbolic simulation	Prabhat Jain;Ganesh Gopalakrishnan	1992		10.1109/ICCD.1992.276218	electronic engineering;formal verification;computer science;theoretical computer science;high-level verification;boolean function;programming language;control flow;symbolic trajectory evaluation;algorithm;functional verification;encoding	Logic	20.2881484793262	46.99223851336002	92815
b529cc3dbc677ae00d97810cfbbae42aeabd7a68	a system-layer infrastructure for soc diagnosis	design for testability;infrastructure ip;test access mechanism;soc diagnosis;embedded core testing;chip;system on chip;processor and udl logic self testing;data retrieval;memory	During IC manufacturing phase, discriminating between good and faulty chips is not enough. In fact, especially in the first phase of the production of a new device, a complete understanding of the possible failures is quickly required to ramp up production yield. For test engineers, dealing with the manufacturing test of Systemson-chip (SoCs) means to tackle the extraction of diagnostic data from faulty chips. Another equally important aim of diagnosis, in a later step of a product lifecycle, is to find the real root cause of silicon misbehaviors for field returns. At the core test layer, the adoption of diagnosis-oriented Design-for-Testability structures is almost mandatory and many solutions have been worked out for several types of cores; diagnosis data retrieval often consists in the execution of a set of self-test procedures whose application order and/or customization may depend on the obtained results themselves. This paper details the characteristics of a system-layer test architecture able to manage efficiently SoC self-diagnostic procedures. This architecture is composed of a diagnosis-oriented Test Access Mechanism (TAM) and an Infrastructure-IP owning enough intelligence to automatically manage core diagnostic procedures. Both of them have been designed in compliance with the IEEE 1500 Standard for Embedded Core Test and exploit the characteristics of Self-Test structures inserted for the diagnosis of memory, processor and logic cores. This approach to SoC diagnosis minimizes ATE memory requirements for pattern storage and drastically speeds up the complete execution of diagnostic procedures. Experimental results highlight the convenience of the approach with respect to alternative ATE driven diagnosis procedures, while resorting to negligible area overhead.	built-in self-test;centralized computing;computation;data retrieval;design for testing;embedded system;fault model;ibm tivoli access manager;overhead (computing);ramp simulation software for modelling reliability, availability and maintainability;requirement;smart battery;stuck-at fault;system on a chip;test card;test engineer	Paolo Bernardi;Michelangelo Grosso;Maurizio Rebaudengo;Matteo Sonza Reorda	2007	J. Electronic Testing	10.1007/s10836-007-5014-6	chip;system on a chip;reliability engineering;embedded system;electronic engineering;real-time computing;computer hardware;telecommunications;computer science;engineering;design for testing;memory;data retrieval	EDA	20.382026079568202	54.75547444844698	92869
1aca4615647beeca6f04a13a65e6b062dec448c5	finite memory test response compactors for embedded test applications	multiple input signature register;design for testability;convolutional compactors ccs;memory testing;unknown states;unknown states convolutional compactors ccs design for testability dft embedded test spatial compactors test response compaction time compactors;time compactors finite memory test response compactors embedded test finite memory compaction schemes convolutional compactors error detection failing scan cell diagnosis multiple input signature registers industrial circuits design for testability spatial compactors test response compaction;embedded systems;compaction;design for testability dft;time compactors;error handling;test response compaction;embedded test;compaction design for testability embedded systems;compact scheme;spatial compactors;compaction circuit testing semiconductor device testing carbon capture and storage automatic test pattern generation registers design for testability built in self test associate members time factors	This paper introduces a new class of finite memory compaction schemes called convolutional compactors (CCs). They provide compaction ratios of test responses in excess of 100/spl times/, even for a very small number of outputs. This is combined with the capability to detect multiple errors, handling of unknown states, and the ability to diagnose failing scan cells directly from compacted responses. The CCs can also be used to significantly enhance conventional multiple input signature registers. Experimental results presented in the paper demonstrate the efficiency of convolutional compaction for several industrial circuits.	benchmark (computing);ct scan;combinational logic;data compaction;display resolution;embedded system;failure;floor and ceiling functions;memory tester;offset binary;requirement;routing;synergy;system on a chip;very-large-scale integration	Janusz Rajski;Jerzy Tyszer;Chen Jun Wang;Sudhakar M. Reddy	2005	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2005.844111	exception handling;compaction;embedded system;electronic engineering;real-time computing;computer science;engineering;design for testing;programming language	EDA	20.693610668297474	51.55834018785503	92952
833f38f7bc047fcd3b5357531c2dea66d41102f2	post-bist fault diagnosis for multiple faults	circuito combinatorio;multiple stuck at faults;evaluation performance;circuito lsi;appareillage essai;tecnologia electronica telecomunicaciones;performance evaluation;integrated circuit;defaut de collage;pass fail information;fail information;evaluacion prestacion;autoprueba;circuito integrado;circuito logico;stuck at fault;autotest;feasibility;combinatory circuit;post bist fault diagnosis;lsi circuit;built in self test;detection defaut;diagnostic panne;circuit logique;aparato ensayo;pass;fault diagnostic;circuit combinatoire;diagnostico pana;testing equipment;tecnologias;combinational circuit;grupo a;circuit lsi;logic circuit;deteccion imperfeccion;practicabilidad;faisabilite;circuit integre;fault diagnosis;defect detection;combinational circuits;fallo stuck at	With the increasing complexity of LSI, Built-In Self Test (BIST) is a promising technique for production testing. We herein propose a method for diagnosing multiple stuck-at faults based on the compressed responses from BIST. We refer to fault diagnosis based on the ambiguous test pattern set obtained by the compressed responses of BIST as post-BIST fault diagnosis [1]. In the present paper, we propose an effective method by which to perform post-BIST fault diagnosis for multiple stuck-at faults. The efficiency of the success ratio and the feasibility of diagnosing large circuits are discussed.	built-in self-test	Hiroshi Takahashi;Yoshinobu Higami;Shuhei Kadoyama;Yuzo Takamatsu;Koji Yamazaki;Takashi Aikyo;Yasuo Sato	2008	IEICE Transactions	10.1093/ietisy/e91-d.3.771	embedded system;feasibility study;real-time computing;fault coverage;computer science;stuck-at fault;combinational logic;algorithm	Robotics	22.27305758495947	50.25856955245276	93025
69a660c8cda113551474849af3ce604c64fad512	interface optimization: an algorithm for the detection of data path redundancy and reconfigurability towards obtaining minimal bus interfaces	circuito intercara;digital circuit;vlsi computer interfaces redundancy;circuito lsi;concepcion circuito;interface circuit;interconnection;integrated circuit;design tool submodules interconnection computer interfaces data path redundancy reconfigurability minimal bus interfaces digital systems data transfer indirect paths;redundancia;implementation;circuit interface;circuit design;data transfer equipment;circuit vlsi;sorting very large scale integration master slave concurrent computing computer architecture integrated circuit technology integrated circuit manufacture propagation delay hardware computer languages;equipement transfert donnee;circuito integrado;circuit numerique;ejecucion;vlsi circuit;lsi circuit;redundancy;equipo transferencia datos;interconnexion;circuito numerico;vlsi;bus;conception circuit;circuito vlsi;circuit lsi;computer interfaces;circuit integre;interconeccion;redondance	Interconnections of submodules of digital systems are normally achieved directly by connecting them to a bus through driver/receiver links. The authors present algorithms for the implementation of data transfer requirements of a system through indirect paths. A formal procedure for identifying the possible candidates for indirect path realization is reported. A procedure is proposed for optimizing the interconnections in a digital system using both indirect and direct paths. It serves as an effective design tool in LSI/VLSI realization of digital systems. >	algorithm;reconfigurability	S. S. S. P. Rao;J. R. Isaac	1989	IEEE Trans. Computers	10.1109/12.42128	bus;embedded system;parallel computing;computer science;electrical engineering;operating system;integrated circuit;interconnection;circuit design;very-large-scale integration;redundancy;implementation;digital electronics	EDA	13.22644442812628	50.362646717364186	93274
b7ca384bb780adefd55be7d2be105836e33ac3e8	statistical post-processing at wafersort - an alternative to burn-in and a manufacturable solution to test limit setting for sub-micron technologies	cmos integrated circuits;adaptive thresholding;integrated circuit yield;0 18 micron sub micron cmos processes outlier identification intrinsic distribution statistical post processing ate wafersort maps iddq tests delta iddq nearest neighbor residual reliability focused modules lsi logic 0 18 spl mu m cmos products user definable adaptive threshold limits multiple data sources data flow management burn in data customer defects per million units data failure rate yield loss variable thresholds;manufacturing large scale integration logic testing production cmos technology cmos logic circuits distributed computing reliability engineering cmos process automatic test equipment;automatic test equipment;limit set;failure analysis;statistical analysis;nearest neighbor;integrated circuit testing;yield loss;failure rate;integrated circuit reliability;failure analysis cmos integrated circuits integrated circuit testing integrated circuit reliability production testing automatic test equipment integrated circuit yield statistical analysis;production testing;data flow;defect per million	In sub-micron CMOS processes, it has become increasingly difficult to identify and separate outliers from the intrinsic distribution at test. This is due to the increasing inadequacy of reliability screens such as burn-in and IDDQ testing. Statistical Post-Processing (SPP) methods have been developed to run off-tester using the raw data generated from Automatic Test Equipment (ATE) and wafersort maps. Post-Processing modules include advanced IDDQ tests such as Delta IDDQ and the Nearest Neighbor Residual (NNR), as well as other non-IDDQ based reliability-focused modules. This work presents the application and results of SPP at LSI Logic on 0.18um CMOS products. Challenges of production implementation have been overcome, which include “user definable” adaptive threshold limits, handling multiple data sources, and data flow management. Burn-in data and customer Defects per Million units (DPM) data show a 30-60% decrease in failure rate with SPP implementation with very acceptable yield loss.	and gate;anomaly detection;burn-in;cmos;dataflow;failure rate;gate count;iddq testing;map;maverick framework;product binning;requirement;self-propelled particles;video post-processing	Robert Madge;Manu Rehani;Kevin Cota;W. Robert Daasch	2002		10.1109/VTS.2002.1011113	limit set;reliability engineering;embedded system;data flow diagram;automatic test equipment;failure analysis;electronic engineering;real-time computing;computer science;engineering;failure rate;thresholding;cmos;k-nearest neighbors algorithm	ML	22.86192356959819	55.06074289882672	93331
e876fcd71379ae0625f3d73651c8ad27498cc058	embedded deterministic test exploiting care bit clustering and seed borrowing	automatic testing;design for testability;fault simulation;integrated circuit testing;built-in self-test;care bit clustering;design-for-testability;embedded deterministic test;high fault coverage;on-chip decompressors;seed borrowing;test data compression;tester channel bandwidth;design-for-testability;test data compression	Embedded deterministic test is a manufacture test paradigm that combines the compression advantage of built-in self-test with the high fault coverage of deterministic stimuli, inherent to methods based on automatic test pattern generation and external testers. Despite enabling the use of low-cost testers for rapidly achieving high fault coverage, embedded deterministic test must consciously use the available tester channel bandwidth to ensure non-disruptive scaling to future devices of increased complexity. The focus of this paper is to show how exploitation of care bit clustering in a test set combined with a low cost implementation for on-chip decompressors based on seed borrowing, facilitates an increased utilization of the tester channel bandwidth, and hence improved compression of deterministic stimuli.	built-in self-test;cluster analysis;data compression;embedded system;fault coverage;image scaling;olap cube;programming paradigm;seed;test card;test data;test set;throughput	Adam B. Kinsman;Nicola Nicolici	2008	9th International Symposium on Quality Electronic Design (isqed 2008)	10.1109/ISQED.2008.65	chip;embedded system;electronic engineering;real-time computing;fault coverage;telecommunications;engineering;automatic test pattern generation;frequency;test compression;design for testing;bandwidth	EDA	11.415268736608045	54.47868847765164	93411
b315b79adf0251ccfc7611625c77a083d1d8cf51	predictive analysis for projecting test compression levels	minimisation;design for testability;measurement;data compression;prediction theory automatic test equipment cost reduction data compression design for testability integrated circuit testing minimisation;test data compression;scan designs;cost reduction;design abstraction;test compression level projection;automatic test equipment;integrated optics;integrated optics variable speed drives measurement;ate;predictive analysis;compression based scan configuration;design cycle;prediction theory;projected optimal compression ratio predictive analysis test compression level projection test data compression scan designs scan in pins ate automated test equipment internal scan chains dft architectural decisions design cycle test cost minimization compression based scan configuration design abstraction computational complexity;dft architectural decisions;computational complexity;variable speed drives;integrated circuit testing;automated test equipment;compression ratio;internal scan chains;test cost minimization;projected optimal compression ratio;scan in pins	Test data compression is widely employed in scan designs to tackle high test data volume and test time problems. Given the number of scan-in pins available in the ATE, architectural decisions regarding the number of internal scan chains directly impact the compression level attained. While targeting an aggressive compression level by increasing the number of internal scan chains would reduce the test data volume per encodable pattern, the cost of applying more patterns serially, to restore the coverage loss, offsets the compression benefits. Therefore, a predictive analysis is necessary to determine the best possible compression configuration, enabling the designers to make DfT architectural decisions early on in the design cycle to minimize test costs. In this paper, we propose a suite of predictive techniques geared towards projecting test cost for any given compression-based scan configuration. The appropriate technique is selected by designers based on which stage the design is in, the design abstraction and the amount of information available, the permissible computational complexity of the techniques, and the accuracy of the projected optimal compression ratio.	computational complexity theory;data compression;markov chain;test compression;test data	Ozgur Sinanoglu;Sobeeh Almukhaizim	2010	2010 IEEE International Test Conference	10.1109/TEST.2010.5699228	automatic test equipment;electronic engineering;simulation;computer science;engineering;test compression;engineering drawing;statistics	EDA	20.419666641218193	53.680748616667856	93585
b57ee90aaeed04ce62ea796d388aec27ede57f2a	fast buffered delay estimation considering process variations	process variation;buffered delay estimation;buffer blockage;fast buffered delay estimation;substantial process variation;statistical analysis;statistical buffer insertion method;deterministic delay estimation method;buffer blockages;achievable buffered delay;design stage;existing deterministic delay estimation;integrated circuit design;process variations;fast estimation;buffered delay;first-order canonical forms;advanced process technology;delay estimation;first order;canonical form;timing analysis	Advanced process technologies impose more significant challenges especially when manufactured circuits exhibit substantial process variations. Consideration of process variations becomes critical to ensure high parametric timing yield. During the design stage, fast estimation of the achievable buffered delay can navigate more accurate and efficient wire planning and timing analysis in floorplanning or global routing. In this paper, we derive approximated first-order canonical forms for buffered delay estimation which considers the effect of process variations and the presence of buffer blockages. We empirically show that an existing deterministic delay estimation method is over-pessimistic and thus result in unnecessary design rollback. The experimental results also show that our method can estimate buffered delay with 4% average error but achieve up to 149 times speedup when compared to a state-of-the-art statistical buffer insertion method.	approximation algorithm;first-order predicate;floorplan (microelectronics);routing;speedup;static timing analysis	Tien-Ting Fang;Ting-Chi Wang	2007	2007 Asia and South Pacific Design Automation Conference		canonical form;mathematical optimization;electronic engineering;real-time computing;computer science;first-order logic;process variation;static timing analysis;integrated circuit design	EDA	22.91574861355212	57.69389044250897	93594
1b825c081ebe0ca74c2b2672d5901125f75642ca	automated state-variable formulation for power electronic circuits and systems	automatic control;variable etat;switched systems;modelizacion;state variable approach;electronic circuit;circuits and systems;systeme commande;variable parameter circuit;sistema control;variable parameters systems;mise a jour;state space methods;network partitioning;circuit simulation state space methods power electronics trees mathematics;automated state variable formulation;topological information;electronic component;state variable;arbre maximal;espace etat;partitioning;circuito electronico;trees mathematics;power electronic systems;electronica potencia;circuit topology;system level;algorithme;actualizacion;power circuit;power electronics;modelisation;network topology;algorithm;state space methods automated state variable formulation power electronic circuits power electronic systems state variable approach system level state space representation circuit branch data network partitioning optimal sets tree branches link branches spanning tree algorithms variable parameters systems state equation computationally effective algorithm topological information switched circuits switched systems;circuit simulation;control system;circuito parametro variable;electronique puissance;arbol maximo;circuit puissance;control system synthesis;state space;spanning tree algorithms;variable estado;optimal sets;circuito potencia;circuit parametre variable;composant electronique;partitionnement;power electronic circuits;spanning tree;state space representation;computationally effective algorithm;subdivision;electric variables control;power system modeling;espacio estado;modeling;circuit electronique;power electronics circuits and systems partitioning algorithms power system modeling control system synthesis automatic control electric variables control network topology circuit topology equations;state equation;updating;switched circuits;circuit branch data;partitioning algorithms;link branches;algoritmo;tree branches;componente electronico	State variable approach is often used for modelling power-electronic circuits at the system level with controls. In the approach considered herein, the minimal state-space representation of the overall system is generated from the circuit branch data and updated for each new topology of the system. The network partitioning into optimal sets of tree and link branches is achieved using the spanning tree algorithms. For system with variable parameters recomputing the entire state equation to reflect the parameter changes may be prohibitively expensive. In this paper, a computationally effective algorithm for updating the required terms based on topological information is presented.	algorithm;electronic circuit;file spanning;network partition;spanning tree;state-space representation	Juri Jatskevich;Tarek Aboul-Seoud	2004	2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No.04CH37512)	10.1109/ISCAS.2004.1329967	topology;electronic circuit;electronic engineering;systems modeling;spanning tree;state space;engineering;control system;electrical engineering;state-space representation;subdivision;automatic control;power electronics;branch;control theory;mathematics;electronic component;equation of state;network topology;algorithm;state variable	EDA	21.69895904457063	46.42265226232259	93618
c8c7cf1349831b510173ba55d808072d83e0f936	a case for nems-based functional-unit power gating of low-power embedded microprocessors	switch parameters;switches low power electronics microprocessor chips nanoelectromechanical devices;nems;functional unit power gating;power gating;nanoelectromechanical devices;device lifetime analysis nems functional unit power gating low power embedded microprocessors nanoelectromechanical system switches total energy savings transistor switches actuation circuitry design switch parameters;transistor switches;low power embedded microprocessors;functional units;low power;logic gates;total energy savings;transistors;actuation circuitry design;low power electronics;charge pumps;nanoelectromechanical systems logic gates program processors charge pumps switches transistors delay;nanoelectromechanical systems;low power power gating nems functional units;functional unit;switches;nanoelectromechanical system switches;logic gate;charge pump;program processors;energy saving;microprocessor chips;device lifetime analysis	This paper presents a case for using Nano-Electro-Mechanical-System switches for power gating idle functional units of an embedded microprocessor. We achieve an average of 26% total energy savings, with a worst-case 5% increase in cycles. Our work includes detailed comparison with transistor switches, actuation circuitry design, identification of desired switch parameters, and device lifetime analysis.	best, worst and average case;electronic circuit;embedded system;gnu nano;low-power broadcasting;microprocessor;network switch;power gating;transistor	Michael B. Henry;Meeta Srivastav;Leyla Nazhandali	2011	2011 48th ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2024724.2024919	control engineering;nanoelectromechanical systems;electronic engineering;logic gate;computer science;engineering;electrical engineering	EDA	17.347786503464217	57.58392731483841	93695
fe8e870a63098a8e32c2e71fb2b43e467767ccab	on the characterization of hard-to-detect bridging faults	random subset;complete set;test generation;large number;test set;selected subset;proposed characterization;hard-to-detect bridging faults;target fault;fault coverage;logic simulation;computational modeling;fault detection	We investigate a characterization of hard-to-detect bridging faults. For circuits with large numbers of lines (or nodes), this characterization can be used to select target faults for test generation when it is impractical to target all the bridging faults (or all the realistic bridging faults). We demonstrate that the faults selected based on the proposed characterization are indeed hard-to-detect by showing that the fault coverage of a given test set with respect to this subset is lower and more sensitive to the test set than the fault coverage obtained with respect to a random subset of the same size,with respect to the complete set of faults, and when possible,with respect to a subset of realistic bridging faults of the same size. We also demonstrate that a test set for the selected subset of faults detects other faults more effectively than when a test set is derived for a randomly selected subset of faults of the same size.	bridging (networking);fault coverage;randomness;test set	Irith Pomeranz;Sudhakar M. Reddy;Sandip Kundu	2003			reliability engineering;electronic engineering;real-time computing;fault coverage;computer science;engineering;logic simulation;fault detection and isolation	EDA	22.248765917546994	51.23540840353365	93711
3a59acaeece9ff4cdd100a1662ef4936e672ff0b	fpga technology mapping: a study of optimality	optimal mapping;fpga technology mapping;logic design;mapping algorithms;fpga;programmable logic arrays;design optimization;boolean satisfiability;table lookup field programmable gate arrays logic design;field programmable gate arrays table lookup circuits programmable logic arrays logic devices permission hardware logic design algorithm design and analysis design optimization;permission;lookup tables;cone;lookup table;circuits;field programmable gate arrays;technology mapping;table lookup;algorithm design and analysis;resynthesis optimization;optimal mapping fpga technology mapping mapping algorithms boolean satisfiability lookup tables;logic devices;hardware	This paper attempts to quantify the optimality of FPGA technology mapping algorithms. We develop an algorithm, based on Boolean satisfiability (SAT), that is able to map a small subcircuit into the smallest possible number of lookup tables (LUTs) needed to realize its functionality. We iteratively apply this technique to small portions of circuits that have already been technology mapped by the best available mapping algorithms for FPGAs. In many cases, the optimal mapping of the subcircuit uses fewer LUTs than is obtained by the technology mapping algorithm. We show that for some circuits the total area improvement can be up to 67%.	algorithm;boolean satisfiability problem;field-programmable gate array;lookup table	Andrew C. Ling;Deshanand P. Singh;Stephen Dean Brown	2005	Proceedings. 42nd Design Automation Conference, 2005.	10.1145/1065579.1065693	embedded system;electronic engineering;lookup table;computer science;theoretical computer science;algorithm;field-programmable gate array	EDA	15.589285602048783	48.88066393219751	93858
5115c5581f8efb77d8ef598997c44b5c78ba1a06	guest editors' introduction: the state of the art in nanoscale cad	nanostructures;very large scale integration;vlsi;nanotechnology;solid modeling;design automation;cad;space technology;testing;computer science	&IT IS WITH great pleasure that we introduce this Special Section on Computer-Aided Design for Emerging Technologies to the readers of IEEE Design & Test. This special section consists of three articles that cover a spectrum of techniques encountered in computeraided design of devices, circuits, and systems using emerging technologies. These articles are authored by outstanding researchers, and they cover both experimental and speculative topics. Of course, as with any special section, these topics are only representative of the available literature currently provided by the technical community. Because of very small feature size (based on molecularand atomic-level devices), high integration levels, and innovative computational features, new concerns are emerging regarding the implementation of computing systems, leading to increased interest in nanoscale technology. Continued scaling of current top-down trends suggests the need for features measured in the nanometer range to meet the objectives of the International Technology Roadmap for Semiconductors (ITRS) over the next few decades. As new techniques to synthesize nanostructures from the bottom up emerge to expand device options and design space, there is considerable evidence that design practice will require CAD as a framework. Moreover, new tools are necessary for VLSI so that designers can assess the different capabilities for assembling devices into circuits and systems. To properly understand and exploit nanoscale technologies, a significant change is needed from the methodologies that have been adequate for today’s submicron scales. The design of nanoscale systems is inherently complex and must consider phenomena such as statistical and probabilistic behavior, as well as reduction of parasitic effects. The challenge is to develop adequate engineering techniques, approaches, and design disciplines to tame and harness the capabilities that such a reduced scale may offer. Tools are a necessity to ensure that emerging technologies will move into industry for full commercialization. It is the convergence of all of these issues that will make CAD at the nanoscale level a vibrant, challenging topic for many years to come. This special section presents a timely account of the state of the art in this area, with emphasis on tools and related frameworks. The first article, ‘‘An Overview of Nanoscale Devices and Circuits,’’ by Jing Huang, Mariam Momenzadeh, and Fabrizio Lombardi, presents a detailed treatment of state-of-the-art advances in emerging technologies. Devices and circuits are outlined, with particular emphasis on current developments and future research directions. This article presents the principles by which different emerging technologies operate, as well as the manufacturing and modeling implications of these principles. In addition, this article highlights the practical viability of meeting some of the metrics that will be encountered at the end of the technology roadmap. In the second article, ‘‘Tracking Uncertainty with Probabilistic Logic Circuit Testing,’’ Smita Krishnaswamy, Igor Markov, and John Hayes present a novel general framework for analyzing probabilistic faults. Based on a fault-modeling generalization, this framework characterizes the disparate effects caused by probabilistic faults due to transients, as well as randomness for quantum effects and process variability in manufacturing. This is radically different from a traditional deterministic process—based on the stuck-at-fault model, for example. This framework provides an innovative reformulation of testing and	computation;computer-aided design;fault model;hayes microcomputer products;image scaling;jing;markov chain;quantum hall effect;randomness;reduction (complexity);semiconductor;software framework;spatial variability;speculative execution;tame;top-down and bottom-up design;very-large-scale integration	Fabrizio Lombardi;Cecilia Metra	2007	IEEE Design & Test of Computers	10.1109/MDT.2007.133	electronic engineering;electronic design automation;computer science;engineering;electrical engineering;very-large-scale integration	EDA	11.488692044368747	58.24288119871673	93904
a3691fa4959a0b9a928b8fe75cd3656667f352af	a highly sensitive and ultra low-power forward body biasing circuit to overcome severe process, voltage and temperature variations and extreme voltage scaling	dynamic voltage scaling;temperature and voltage variations;process;forward body biasing;subthreshold design	Summary#R##N##R##N#Dynamic voltage scaling is one of the most popular methods used to reduce energy consumption in today's digital electronic systems. However, addressing process, voltage and temperature variations at subthreshold voltages has become an inevitable procedure. Using a variation-sensitive and ultra low-power design, this paper proposed a novel technique capable of sensing and responding to process, voltage and temperature variations as well as dynamic voltage scaling by providing an appropriate forward body bias so that energy-delay product of the whole system was improved. Theoretical analysis for process variation probability, confirmed by post-layout HSPICE (Synopsys, Inc., Mountain View, CA) simulations for an 8-bit pipelined Kogge–Stone adder, showed that the circuit performance was enhanced in severe variations and extreme voltage scaling situation. For this adder, for example, assuming a voltage scaling from 0.8 to 0.3 V and temperature changes of −15 to 75 °C, the proposed technique brought about a seven times less delay variation, whereas energy-delay product improved by 23% compared with a zero body biased adder. Copyright © 2013 John Wiley & Sons, Ltd.	biasing;dynamic voltage scaling;image scaling;low-power broadcasting	Mohsen Radfar;Kriyang Shah;Jack Singh	2015	I. J. Circuit Theory and Applications	10.1002/cta.1935	electronic engineering;telecommunications;computer science;engineering;electrical engineering;process	EDA	19.456313220551333	59.40388428974045	94016
45d926abc23df3daae40263a836a76a77687981e	day 2 keynote: iot fosters semiconductor innovation	ic design in cloud semiconductor innovation internet of things arpanet pervasive social networking systems on chip soc iot devices integrated circuit design ic design development model;logic cad cloud computing innovation management integrated circuit design internet of things	The Internet changed our lives. The Internet of Things (IoT) will change our lives again. From its humble beginning as Arpanet in 1969 to pervasive social networking, the Internet has been a major driving factor for the high tech industry. IoT is the next wave in the evolution of the Internet. With predicted 50 Billion IoT devices by 2020 and over $15 Trillion in generated profit over the next 10 years, IoT will have a profound and dominating impact on the high tech industry in general and the semiconductor industry in particular.	semiconductor	Mojy C. Chian	2014		10.1109/IDT.2014.7038572	embedded system;simulation;computer science;engineering;computer security;computer network	Robotics	10.300797324288602	56.54003342137524	94032
d62418d3b4d3d4335204760aebb6cd02aed98143	a novel two-dimensional scan-control scheme for test-cost reduction	switching activity;scan chain;test time reduction;pins;test cost reduction;test time reduction test cost reduction two dimensional scan shift control concept multiple scan chain design;flip flops;cost reduction;control design;low power scan chain test cost;integrated circuit testing cost reduction;circuit testing encoding electronic equipment testing test pattern generators costs automatic testing design engineering power engineering and energy benchmark testing pins;test cost;multiple scan chain design;computer architecture;low power;two dimensional scan shift control concept;integrated circuit testing;power reduction;switches;encoding;power demand	This paper proposes a two-dimensional scan shift control concept for multiple scan chain design. Multiple scan chain test scheme provides very low scan power by skipping many long scan chain switching activities. Based on two-dimensional scan shift control, we can achieve low test power with simple and small overhead structure. The proposed scheme skips many unnecessary don't care (X) patterns to reduce the test data volume and test time. The experimental results of the proposed scheme illustrate the significant improvement in shift power reduction, test volume and test time reduction. Compared with traditional single scan chain design, the large benchmark b17 of ITC'99 has over 50% reduction in test data volume and over 40% reduction in test time with little area overhead and very few extra pins, and the power reduction is over 97%.	apple multiple scan 14 display;benchmark (computing);don't-care term;overhead (computing);test data	Chia-Yi Lin;Hung-Ming Chen	2010	2010 11th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2010.5450439	embedded system;electronic engineering;scan chain;real-time computing;network switch;computer science;engineering;test compression;encoding	EDA	19.764333486289203	53.242758180748815	94083
4dc990122422948a4b28f14b57519f40e9beecec	identifying redundant inter-cell margins and its application to reducing routing congestion	transistor folding;routing lithography wires metals redundancy standards layout;transistor pairing;transistor placement;standard cell;size 28 nm redundant intercell margin identification routing congestion reduction modern standard cell lithography cell pair margin redundancy routing grid congestion overflow;redundancy lithography network routing	A modern standard cell is embedded with extra space, called inter-cell margin, on its left and right ends. Margins are sometimes redundant, and so margins between some cell pairs can be removed for the benefit of area. Lithography simulations on whole layout to identify redundant margins take excessive amount of time, and thus are impractical. We propose to determine in advance the redundancy of margins between each cell pair; a few methods of approximation are introduced to accelerate the process, e.g. grouping cell pairs of similar boundary patterns, refining each group with geometry parameters, etc. Experiments indicate that the redundancy of margin is accurately determined in 93.7% of cell pairs; the remaining 6.3%, which are actually redundant, are declared irredundant by our method, so our method is inaccurate for those cell pairs yet is still safe. We take advantage of redundant margins and address the problem of routing congestion reduction. Placement is locally perturbed to identify more redundant margins; the cells in high congestion region are spread out after the margins in low congestion area are removed. The proposed method was evaluated on a few test circuits using 28-nm technology. The number of routing grids with congestion overflow was reduced by 43% with no impact on total wirelength.	approximation;die shrink;embedded system;experiment;network congestion;place and route;routing;simulation;standard cell;xslt/muenchian grouping	Woohyun Chung;Seongbo Shim;Youngsoo Shin	2015	2015 Design, Automation & Test in Europe Conference & Exhibition (DATE)	10.7873/DATE.2015.0714	embedded system;electronic engineering;real-time computing;computer science;engineering;engineering drawing;standard cell	EDA	15.542581416857052	53.297277736353934	94186
a1e421a97a5b0e38ae5ac61975cb0b9cabe9ffdd	towards process variation-aware power gating	power mosfet;process corner;detectors;control systems;reliability;semiconductor device reliability;power gating;switches power mosfet semiconductor device reliability;surges;wakeup power gating power management process corner surge current;power management;process control;power switches process variation aware power gating power gating design wakeup control surge current constraint inter module reliability timing control;wakeup;switches;delay surges control systems process control detectors reliability;surge current	This paper presents a power gating design that considers process variation for proper wakeup control. First, the surge current constraint is examined and refined for a simpler and more realistic view of inter-module reliability. Following that, several circuits are proposed on top of a delay chain to adapt the timing control of power switches to process variations. Experimental results show that the proposed design is able to track process variation such that the surge current and the wakeup time are both kept to expectation in all process corners.	clock signal;corner detection;network switch;online and offline;power gating;process corners;simulation;transistor	Chingwei Yeh;Yuan-Chang Chen;Jinn-Shyan Wang	2012	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2011.2169435	control engineering;detector;electronic engineering;real-time computing;network switch;computer science;engineering;process control;power mosfet;reliability	EDA	18.612648659297438	56.95939072226467	94406
ce2fe726c6345b5e81baac9c7083b1dc5c88f860	a high-performance 128-to-1 cmos multiplexer tree	cmos integrated circuits;multiplexing equipment cmos integrated circuits;mux multiplexer multiplexer tree;multiplexing equipment;delay time high performance cmos multiplexer tree traditional transmission gate mux circuits high transmission speed circuit simulation;cmos integrated circuits delay multiplexing logic gates transistors decoding cmos technology	A high-performance 128-input CMOS multiplexer (MUX) tree is designed in this study. In order to enhance the speed, the high-speed feature of traditional transmission-gate MUX circuits and CMOS MUX circuits are integrated to the 128-to-1 MUX tree with high transmission speed. The circuit simulation in the CMOS 0.18μm process presents 26% reduction of delay time, comparing to the 128-to-1 MUX tree composed of traditional 2-to-1 CMOS.	cmos;electronic circuit simulation;multiplexer	Po-Hui Yang;Jing-Min Chen;Kai-Shun Lin	2012	2012 International Symposium on Intelligent Signal Processing and Communications Systems	10.1109/ISPACS.2012.6473602	embedded system;electronic engineering;real-time computing	EDA	17.24929113448988	56.55290202249979	94505
4bfd584526932577905cd8c2b9b625910aeb057d	panel: when will the cost of dependability end innovation in computer design?	silicon;computers;reliability;technological innovation;very large scale integration;computer architecture;reliability silicon computer architecture very large scale integration technological innovation computers silicon devices;silicon devices	As silicon feature sizes approach atomic scales, device reliability is waning and the cost of dependability is on the rise. Post silicon devices, such as CNTs or TFETs, promise better performance but at the cost of even worse reliability. Will we reach the point where the cost of reliability for future silicon substrates is too expensive to justify their existence? Or will we discover new ways to contain the cost of dependability? If we do discover low-cost reliability mechanisms, how much time do we have before we must deploy them? If not, how much life does silicon have left?	computer architecture;dependability	Valeria Bertacco	2015	2015 IEEE 33rd VLSI Test Symposium (VTS)	10.1109/VTS.2015.7116264	reliability engineering;embedded system;electronic engineering;computer science;systems engineering;engineering;electrical engineering;reliability;very-large-scale integration;silicon;statistics;computer engineering	Arch	10.508471753448159	58.00908303633574	94691
4ca679bb31d693e0928ee00dc6f14eeb603585b7	fault diagnosis with convolutional compactors	network synthesis;branch and bound algorithm;unknown states;convolutional compactors real fail logs industrial designs benchmark circuits branch and bound algorithm failing scan cells time efficient identification scan based designs nonadaptive fault diagnosis techniques;convolutional compactors;scan based designs;comparators circuits;tree searching circuit testing comparators circuits fault diagnosis network synthesis;test response compaction;circuit testing;fault diagnosis circuit testing circuit faults compaction built in self test convolution monitoring associate members life estimation automatic testing;tree searching;unknown states convolutional compactors fault diagnosis scan based designs test response compaction;fault diagnosis;industrial design	This paper presents new nonadaptive fault-diagnosis techniques for scan-based designs. They guarantee accurate and time-efficient identification of failing scan cells based on results of convolutional compaction of test responses. The essence of the method is to use a branch-and-bound algorithm to narrow the set of scan cells down to certain sites that are most likely to capture faulty signals. This search is guided by a number of heuristics and self-learned information used to accelerate the diagnosis process for the subsequent test patterns. A variety of experimental results for benchmark circuits, industrial designs, and real fail logs confirm the feasibility of the proposed approach even in the presence of unknown states. The scheme remains consistent with a single test session scenario and allows high-volume in-production diagnosis.	algorithm;benchmark (computing);branch and bound;data compaction;failure;heuristic (computer science);test card	Grzegorz Mrugalski;Artur Pogiel;Janusz Rajski;Jerzy Tyszer	2007	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2007.891361	network synthesis filters;electronic engineering;real-time computing;industrial design;computer science;engineering;branch and bound;algorithm	EDA	21.492416752470483	51.27937504989737	94953
577c267e7344bf55f44204d8e6c132ac3437ac31	a novel low voltage dcvsl circuit design based on wilson current mirror		This paper presents a new Differential Cascode Voltage Switch Logic (DCVSL) design method which combines the differential logic design style with an analog current mirror. Compared to conventional DCVSL circuits, the proposed circuits have significant performance improvements with reduced switching latency. More importantly, our proposed circuits can successfully operate with low voltage supply, which is verified by the design the basic logic gates. We provide comparison results with conventional logic gates including AND/NAND, OR/NOR and XOR/NXOR to demonstrate the advantages of using our proposed design in terms of latency, power dissipation and area. With 1V supply voltage, 4ns signal period (250MHz), the simulated PDP is 7.86aWs for AND/NAND, OR/NOR gates, and 9.84aWs for XOR/NXOR gate, that is 51.67% and 24.31% performance improvement compared to the best case of conventional circuits.		Weiwei Ge;Lijuan Han;Yuan Cao;Enyi Yao;Xiaojin Zhao	2018	2018 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)	10.1109/APCCAS.2018.8605609	computer science;electronic engineering;nand gate;logic synthesis;current mirror;low voltage;wilson current mirror;circuit design;nor gate;logic gate	EDA	16.9946641161723	57.3439465908259	95418
32469cf98a552b674b8eb326ecf485ac66131700	generation of shortest test sequences for detecting individual faults of sequential circuits	sequential circuits			Stephen S. Yau;Y. S. Tang	1979	Comput. J.	10.1093/comjnl/22.2.169	computer science;sequential logic	Theory	22.053505749093286	51.26325954763263	95434
3328ec0d0e458a05de07561d272651014ed994e3	easily testable and fault-tolerant design of fft butterfly networks	design for testability;fault tolerant;logic design;reconfigurable architectures;systolic arrays;computation points digital signal processing algorithms dsp algorithms fft butterfly networks fast fourier transforms fault tolerant design m testability conditions design for testability dft module level systolic fft arrays single module fault testability test patterns faulty cell bypass reconfiguration mechanisms fft system reliability bit level butterfly modules hardware overhead;chip;integrated circuit design;fault tolerance;logic testing;integrated circuit testing;fast fourier transforms;digital signal processing chips;integrated circuit reliability;fault tolerance logic arrays hardware circuit testing circuit faults redundancy equations fast fourier transforms signal processing algorithms digital signal processing chips;hypercube networks;integrated circuit reliability fast fourier transforms hypercube networks fault tolerance digital signal processing chips design for testability systolic arrays reconfigurable architectures logic design logic testing integrated circuit design integrated circuit testing	In this paper, we first propose a testable design scheme for FFT butterfly networks based on M-testability conditions. Based on them, a novel design-for-testability approach is presented and applied to the module-level systolic FFT arrays. Our M-testability conditions guarantee 100% single-module-fault testability with a minimum number of test patterns. Based on this testable design, a reconfiguration mechanism is used to bypass the faulty cell and the testable/fault-tolerant FFT networks are constructed. Special cell designs are presented which implement the reconfiguration mechanism. The reliability of the FFT system increases significantly. The chip design for the bit-level butterfly module is presented. The hardware overhead is low - about 12% for the bit-level design. For the module-level design, it leads to a lower hardware overhead (about 1/2N, where N is the computation point).	fast fourier transform;fault tolerance	Shyue-Kung Lu;Chien-Hung Yeh	2002		10.1109/ATS.2002.1181716	reliability engineering;fault tolerance;computer architecture;electronic engineering;parallel computing;telecommunications;computer science	Theory	21.5114418013103	49.62291498189146	95476
18d7a4e29f00149b42f3a8e09bb9e60494b8ee23	area minimization of power distribution network using efficient nonlinear programming techniques	minimisation;minimization;adjoint network;nonlinear programming;very large scale integration designs;very large scale integration;power systems;area minimization;power systems minimization optimization methods circuits large scale integration gradient methods sensitivity analysis merging robustness runtime;very large scale integrated;conjugate gradient method;runtime;penalty method;large scale integration;adjoint network area minimization power distribution network nonlinear programming very large scale integration designs penalty method conjugate gradient method sensitivity analysis;sensitivity analysis;merging;vlsi;sensitivity analysis vlsi nonlinear programming circuit optimisation minimisation conjugate gradient methods;gradient methods;robustness;circuits;circuit optimisation;conjugate gradient methods;power;power distribution network;optimization methods	This paper deals with area minimization of power distribution network for VLSIs. A new algorithm based on efficient nonlinear programming techniques is presented to solve this problem. The experiment results prove that this algorithm has achieved the objects that minimize the area of power/ground networks with higher speed.	algorithm;nonlinear programming;very-large-scale integration	Xiaohai Wu;Xianlong Hong;Yici Cai;Chung-Kuan Cheng;Jun Gu;Wayne Wei-Ming Dai	2001	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2004.829809	control engineering;mathematical optimization;electronic engineering;nonlinear programming;computer science;electrical engineering;mathematics;very-large-scale integration	EDA	16.49066433705385	53.29996995983995	95534
2abccbd40728580d9c534e43b6acb4a67a6f6941	choosing the optimal hdl model of thermometer-to-binary encoder	hardware design languages;nanometer technology thermometer to binary encoder flash adc hdl model logic synthesis;decoding;solid modeling;integrated circuit modeling;ash;circuit power consumption hdl model thermometer to binary encoder hardware description languages design model tools logic synthesis tools language statements model structure circuit delay circuit area;hardware description languages electronic design automation;power demand;integrated circuit modeling solid modeling ash delays hardware design languages decoding power demand;delays	Application of hardware description languages (e.g. Verilog, VHDL) to create design model and logic synthesis tools to generate its physical implementation is preferred design paradigm. In this paper it is examined how the modeling style used to implement the thermometer-to-binary encoder influence parameters of the synthesized circuit. It is demonstrated that badly chosen language statements and model structure may drastically deteriorate the delay, area and power consumption of the resulted circuit.	encoder;hardware description language;logic synthesis;programming paradigm;vhdl;verilog	Zbigniew Jaworski	2015	2015 22nd International Conference Mixed Design of Integrated Circuits & Systems (MIXDES)	10.1109/MIXDES.2015.7208530	physical design;embedded system;electronic engineering;real-time computing;computer science;circuit design;hardware description language;circuit extraction;register-transfer level	EDA	13.045571122714264	52.370104170175765	95614
9f4e69d8e3590bb018943e9a6f1d27d6728c9e18	a layout approach for electrical and physical design integration of high-performance analog circuits	ota parasitics electrical design physical design high performance analog circuits layout generation tool electrical sizing procedural layout approach matching parasitic control shape reliability performance specifications overall design time;integrated circuit layout;efficient algorithm;physical design;circuit optimisation integrated circuit layout analogue integrated circuits integrated circuit reliability circuit layout cad;layout generation;analog circuits;analogue integrated circuits;analog layout;circuit layout cad;integrated circuit reliability;circuit optimisation;high performance;analog circuits electrical capacitance tomography postal services design optimization automatic control degradation automation circuit topology libraries routing	This paper presents a layout generation tool that aims to reduce the gap between electrical sizing and physical realization of high performance analog circuits. The procedural layout approach is shown to be best suited for this kind of methodologies. Once captured, the procedural description can be used several times to calculate both rapidly and accurately all parasitics that appear during physical realizations without layout generation. Efficient algorithms are developed to take into account analog layout constraints such as matching, parasitic control, shape and reliability considerations. This allows to account for these effects early in the design which guarantees the fulfillment of the required performance specifications, permits to optimize various design aspects in the presence of parasitics and shortens the overall design time by avoiding laborious sizing-layout iterations. An example of a high performance OTA is presented at the end to illustrate the effectiveness of the approach.	algorithm;analog-to-digital converter;analogue electronics;integrated circuit;iteration;matching (graph theory);mathematical optimization;physical design (electronics);radio frequency	Mohamed Dessouky;Marie-Minerve Louërat	2000		10.1109/ISQED.2000.838885	layout versus schematic;mixed-signal integrated circuit;physical design;embedded system;electronic engineering;analogue electronics;ic layout editor;computer science;engineering;electrical engineering;design layout record;integrated circuit layout;circuit extraction;engineering drawing;standard cell;computer engineering	EDA	13.68809238959843	51.446984814837904	95617
88133d17ccc789f5e25ca6a1cee7a85b0d6cf7c7	testing the unidimensional interconnect architecture of symmetrical sram-based fpga	fpga;test;random access memory field programmable gate arrays integrated circuit interconnections reconfigurable logic logic testing logic design manufacturing wires programmable logic arrays switches;fpga configurations unidimensional interconnect architecture testing symmetrical sram based fpga reduced configuration set test vector sequence;integrated circuit interconnections;logic testing;integrated circuit testing;field programmable gate arrays;logic testing field programmable gate arrays sram chips integrated circuit interconnections integrated circuit testing;sram chips	This paper proposes a new and original solution to test the unidimensional interconnect architecture of a RAM based FPGA by exploring the specific properties of these blocks. The method to find a reduced set of configurations is proposed and the sequence of test vectors required for each configuration is given.	field-programmable gate array;static random-access memory	Michel Renovell;Penelope Faure;Paolo Prinetto;Yervant Zorian	2002		10.1109/DELTA.2002.994634	erasable programmable logic device;embedded system;computer architecture;electronic engineering;parallel computing;logic gate;logic family;programmable logic array;computer science;engineering;programmable logic device;simple programmable logic device;field-programmable gate array	EDA	11.616401115587893	52.66397851639816	95626
a59e14da2a244b6456f959bb25b18a87249eb112	a negotiated congestion based router for simultaneous escape routing	graph theory;design automation;pins;cadence pcb router allegro;printed circuits;simultaneous escape routing;application software;routing;ic global routing;pin grids;routing graph;printed circuit design;network routing;printed circuit design electronics packaging graph theory network routing;adaptation model;pcb design;global routing;negotiated congestion based escape router;integrated circuit modeling;cadence pcb router allegro simultaneous escape routing fpga routing ic global routing pcb design routing graph pin grids negotiated congestion based escape router;circuit testing;tiles;field programmable gate arrays;wiring;routing pins field programmable gate arrays circuit testing printed circuits integrated circuit modeling application software wiring design automation laboratories;electronics packaging;fpga routing;conferences	The negotiated congestion based routing scheme finds success in FPGA routing and IC global routing. However, its application in simultaneous escape routing, a key problem in PCB design, has never been reported in previous literature. In this paper, we investigate how well the negotiated congestion based router performs on escape routing problems. We propose an underlying routing graph which correctly models the routing resources of the pin grids on board. We then build a Negotiated Congestion based Escape Router (NCER) by applying the negotiated congestion routing scheme on the constructed routing graph. We compare the performance of NCER with that of Cadence PCB router Allegro on 14 industrial test cases, and experimental results show that the two routers have comparable routability: each of them completely routes 7 test cases. Moreover, we observe that NCER and Allegro exhibit complementary behaviors: each is able to solve most of the test cases that the other cannot solve. Together, they completely route 11 test cases. Therefore, by using NCER as a supplement to Allegro, we can solve a broader range of escape routing problems.	allegro;experiment;field-programmable gate array;network congestion;printed circuit board;requirement;router (computing);routing;test case	Qiang Ma;Tan Yan;Martin D. F. Wong	2010	2010 11th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2010.5450514	policy-based routing;wireless routing protocol;routing table;routing domain;embedded system;routing;enhanced interior gateway routing protocol;electronic engineering;static routing;real-time computing;hierarchical routing;dsrflow;zone routing protocol;electronic design automation;equal-cost multi-path routing;computer science;engineering;dynamic source routing;graph theory;multipath routing;destination-sequenced distance vector routing;operating system;routing protocol;link-state routing protocol;triangular routing;metrics;geographic routing;routing information protocol	EDA	15.21734375233977	52.05917692906145	95680
a7b0e9202b24b3098b72afc8722c306312c64701	a novel architecture and a systematic graph-based optimization methodology for modulo multiplication	graph theory;optimisation;optimization methods hardware computer architecture arithmetic adders very large scale integration design methodology encoding finite impulse response filter cryptography;time complexity;vlsi residue number systems computational complexity optimisation graph theory;residue number systems;indexing terms;computer arithmetic;computational complexity;hardware complexity hardware algorithm graph based optimization modulo multiplication vlsi architecture residue multipliers graph based design bit product weight encoding area time complexity reduction computer arithmetic residue number system signed digit representation bit products compatibility analysis;uct;vlsi;residue number system;design methodology;vlsi architecture	A novel hardware algorithm, a VLSI architecture, and an optimization methodology for residue multipliers are introduced in this paper. The proposed design approach identifies certain properties of the bit products that participate in the residue product computation and subsequently exploits them to reduce the complexity of the implementation. A set of introduced theorems is used to identify the particular properties. The introduced theorems are of significant practical importance because they allow the definition of a graph-based design methodology. In addition, a bit-product weight encoding scheme is investigated in a systematic way, and exploited in order to minimize the number of bit products processed in the proposed multiplier. Performance data reveal that the introduced architecture achieves area /spl times/ time complexity reduction of up to 55%, when compared to the most efficient previously reported design.	algorithm;computation;line code;mathematical optimization;matrix multiplication;modulo operation;reduction (complexity);time complexity	Giorgos Dimitrakopoulos;Vassilis Paliouras	2004	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2003.820243	time complexity;combinatorics;residue number system;discrete mathematics;index term;design methods;computer science;graph theory;theoretical computer science;mathematics;very-large-scale integration;computational complexity theory	EDA	14.518751895730755	46.62491679042341	95683
7d54b06de7e593ba0438f00e9facddebf751a62d	a hybrid nano-cmos architecture for defect and fault tolerance	fault tolerant;design flow;nanotechnology;chip;carbon nanotube;transient fault;nanowires;defect tolerance;soft error	As the end of the semiconductor roadmap for CMOS approaches, architectures based on nanoscale molecular devices are attracting attention. Among several alternatives, silicon nanowires and carbon nanotubes are the two most promising nanotechnologies according to the ITRS. These technologies may enable scaling deep into the nanometer regime. However, they suffer from very defect-prone manufacturing processes. Although the reconfigurability property of the nanoscale devices can be used to tolerate high defect rates, it may not be possible to locate all defects. With very high device densities, testing each component may not be possible because of time or technology restrictions. This points to a scenario in which even though the devices are tested, the tests are not very comprehensive at locating defects, and hence the shipped chips are still defective. Moreover, the devices in the nanometer range will be susceptible to transient faults which can produce arbitrary soft errors. Despite these drawbacks, it is possible to make nanoscale architectures practical and realistic by introducing defect and fault tolerance. In this article, we propose and evaluate a hybrid nanowire-CMOS architecture that addresses all three problems—namely high defect rates, unlocated defects, and transient faults—at the same time. This goal is achieved by using multiple levels of redundancy and majority voters. A key aspect of the architecture is that it contains a judicious balance of both nanoscale and traditional CMOS components. A companion to the architecture is a compiler with heuristics to quickly determine if logic can be mapped onto partially defective nanoscale elements. The heuristics make it possible to introduce defect-awareness in placement and routing. The architecture and compiler are evaluated by applying the complete design flow to several benchmarks.	benchmark (computing);cmos;compiler;crossbar switch;design flow (eda);fault tolerance;gnu nano;heuristic (computer science);image scaling;norton power eraser;place and route;reconfigurability;redundancy (engineering);redundancy (information theory);routing;run time (program lifecycle phase);semiconductor;simulated annealing;soft error;software bug	Muzaffer O. Simsir;Srihari Cadambi;Franjo Ivancic;Martin Roetteler;Niraj K. Jha	2009	JETC	10.1145/1568485.1568488	chip;embedded system;fault tolerance;electronic engineering;parallel computing;real-time computing;carbon nanotube;soft error;computer science;engineering;design flow;electrical engineering;nanotechnology;nanowire	EDA	10.29101979627382	58.15573251175567	95753
6ea81cb284752793a1268446d8336d78edf10188	relay propagation scheme for testing of mcms on large area substrates	multi chip module;testing;electronic equipment testing;probes;relay propagation;boundary scan testing;assembly;multi chip modules;algorithm;parallel process;multichip modules;multiple mcm chain;relay propagation scheme;manufacturing;mcms;integrated circuit testing;system testing;pipelined process;boundary scan testing multichip modules integrated circuit testing;boundary scan;space technology;algorithm relay propagation testing mcms large area substrates parallel process pipelined process multiple mcm chain boundary scan testing;wiring;relays;electronics packaging;large area substrates;relays costs system testing assembly probes manufacturing electronic equipment testing electronics packaging space technology wiring	This paper addresses the issue of testing MCMs on large area substrates. The cost of testing MCMs may be as high as 40 % of the total manufacturing cost. It is critical that the test process be parallelized in order that multiple MCMs may be tested for the cost of testing one MCM. With this objective in mind, we propose a parallel and pipelined relay propagation scheme for the testing of MCMs on large area substrates. In this scheme, the test vectors and the corresponding correct-response vectors are both scanned into the MCM scan chain sequentially. They are then relayed on from one MCM to the next down the chain. Simultaneously the MCMs are tested in parallel. Our algorithm allows an order of magnitude speed-up in test time over conventional boundary scan based testing schemes.	algorithm;boundary scan;mind;multi-chip module;parallel computing;relay;software propagation;speedup;test vector	Koppolu Sasidhar;Abhijit Chatterjee;Yervant Zorian	1996		10.1109/EDTC.1996.494138	embedded system;electronic engineering;real-time computing;engineering	ML	18.790271969034304	52.18315771207142	96021
c6f7cff043982e560ae54662e27f7b88c2c41576	an effective and efficient atpg-based combinational equivalence checker	verification;equivalence checking;atpg	An effective and efficient ATPG-based combinational equivalence checker.	combinational logic;formal equivalence checking;turing completeness	Ronald P. Lajaunie;Michael S. Hsiao	2005		10.1145/1057661.1057722	verification;computer science;automatic test pattern generation;formal equivalence checking	EDA	19.273907147985383	47.99500765964376	96024
5dfb095d257534e86f2fc3790086e87ba81cf5da	systematic design for optimization of high-resolution pipelined adcs	analogue-digital conversion;circuit optimisation;integrated circuit design;low-power electronics;pipeline processing;analog-to-digital converters;circuit optimization;closed-form equations;high-resolution adcs;pipelined adcs;power consumption minimization;signal-to-noise-and-distortion ratio	Pipelining is the promising approach to implement high-speed medium-to-high resolution analog-to-digital converters with minimum power consumption. In this paper, the most important specifications of a pipelined ADC including the signal-to-noise-and-distortion ratio and spurious-free dynamic range as well as the total current consumption of the converter are presented in closed-form equations and an optimization methodology for design of pipelined ADCs is suggested. Simulation results confirming the effectiveness of the methodology are presented.	analog-to-digital converter;distortion;image resolution;mathematical optimization;pipeline (computing);pipelining (dsp implementation);sinad;simulation;spurious-free dynamic range	Mohammad Taherzadeh-Sani;Reza Lotfi;Omid Shoaei	2004	Proceedings Design, Automation and Test in Europe Conference and Exhibition		system on a chip;co-design;embedded system;electronic engineering;real-time computing;image resolution;spurious-free dynamic range;reconfigurable computing;computer science;operating system;place and route;low-power electronics;integrated circuit design	EDA	15.80855985285619	55.46249799238014	96035
1f27b2cfd74821a6f02f8dc9173230b7d1ef7842	revkit: a toolkit for reversible circuit design		In recent years, research in the domain of reversible circuit design has attracted significant attention leading to many different approaches for e.g. synthesis, optimization, simulation, verification, and test. However, most of the resulting tools are not publicly available. In this paper, we introduce RevKit, an open source toolkit that aims to make recent developments in reversible circuit design accessible to other researchers. Therefore, a modular and extendable framework is provided which easily enables the addition of new methods and tools. RevKit already provides some of the existing approaches for synthesis, optimization, and verification functionality.	circuit design;extensibility;mathematical optimization;open-source software;reversible computing;simulation	Mathias Soeken;Stefan Frehse;Robert Wille;Rolf Drechsler	2012	Multiple-Valued Logic and Soft Computing		computer engineering;machine learning;artificial intelligence;computer science;modular design;circuit design	EDA	17.13891143367188	47.41942856347523	96147
8e5411bd24b4d7d0e0435d83d0c5644372e912e7	fits: an integrated ilp-based test scheduling environment	automatic test equipment integrated ilp test scheduling environment fits core based system on chips testing power profile structural grids nonembedded cores test pattern subsets integer linear programming formulation power approximation model resource constraints test time test access mechanism test controller;integer linear programming formulation;resource constraint;constraint optimization;test access mechanism;test schedule index terms automatic test equipment embedded core grid hot spot ilp formulation power profile system on chip trade off test access mechanism;automatic testing;integrated ilp test scheduling environment;ilp formulation;automatic test equipment;automatic testing integrated circuit testing scheduling logic circuit testing integer programming linear programming;index terms automatic test equipment;indexing terms;satisfiability;power approximation model;hot spot;power profile;grid;test schedule;integer programming;nonembedded cores;test controller;system on chip;scheduling;structural grids;logic testing;integrated circuit testing;linear programming;embedded core;test time;test scheduling;core based system on chips testing;trade off;benchmark testing;integer linear program;fits;test pattern subsets;logic circuit testing;resource constraints;linear programming system on chip automatic test equipment integrated circuit testing benchmark testing scheduling logic testing integer programming	We present a comprehensive and flexible test scheduling environment, called FITS, for testing core-based system-on-chips. Our environment prevents formation of hot spots during test. It also allows trade-off among test time, test access mechanism, power, and test controller/resource constraints. The basic strategy is to use power profile over application time and structural grids of nonembedded cores to find the best test schedule of their test pattern subsets while satisfying the constraints. As case studies, four integer linear programming formulations, corresponding to four power approximation models, are extensively analyzed. With proper setting of the weights and constraints, optimized results can be obtained quickly for each of the four power approximation models. Extensive experimental results are reported based on ISCAS '89 benchmarks and verify the efficiency and flexibility of the FITS environment.	approximation;fits;integer programming;linear programming;scheduling (computing);test card	James Chin;Mehrdad Nourani	2005	IEEE Transactions on Computers	10.1109/TC.2005.196	system on a chip;automatic test equipment;benchmark;mathematical optimization;parallel computing;real-time computing;integer programming;index term;trade-off;computer science;linear programming;operating system;grid;scheduling;hot spot;algorithm;satisfiability	EDA	12.667010650132204	53.86863337710429	96165
01d96e76d1a82e571507ebf32eac79518bc4926a	a comparison of four two-dimensional gate matrix layout tools	plugs;routing;space exploration;simulated annealing;circuit simulation;computational modeling;permission;integrated circuit interconnections;computer science;circuit synthesis;simulated annealing routing permission circuit simulation circuit synthesis integrated circuit interconnections space exploration computer science computational modeling plugs	A comparison of four layout tools is presented. The layout style is a two-dimensional gate matrix. The first layout tool discussed uses “standard” simulated annealing. Annealing on gate clusters instead of individual gates can be used to improve the layout results. Two different ways of determining good gate clusters for use in the annealing process are compared. The first way uses clusters derived from user specified gate hierarchies, while the second determines clusters based on gate connectivity. The fourth layout tool uses a decomposition scheme based on quadrisection. Layout results for a set of benchmark circuits are presented for each of the tools.	benchmark (computing);simulated annealing	Mary Jane Irwin;Robert Michael Owens	1989	26th ACM/IEEE Design Automation Conference	10.1145/74382.74507	layout versus schematic;physical design;routing;electronic engineering;simulation;simulated annealing;ic layout editor;computer science;theoretical computer science;space exploration;design layout record;integrated circuit layout;circuit extraction;computational model;computer network	EDA	14.521413707113004	50.88904222403542	96191
5822839c020c6e930a822a56d7196a8d3bf358f2	speeding up behavioral test pattern generation using an algorithmic improvement	hardware design languages;behavioral test pattern generation;heuristic;hdl;circuit faults;automatic test pattern generation;automatic testing;hardware description languages;algorithmic improvement;gate level;acceleration;digital integrated circuits logic testing specification languages automatic testing integrated circuit testing;circuit simulation;structural testing;test pattern generators;circuit descriptions;digital integrated circuits;specification languages;hdl behavioral test pattern generation algorithmic improvement circuit descriptions hardware description languages headlines gate level structural test approaches;heuristic algorithms;logic testing;integrated circuit testing;behavioral testing;circuit testing;test pattern generator;hardware description language;decision trees;structural test approaches;headlines;test pattern generators circuit testing circuit faults hardware design languages automatic test pattern generation circuit simulation equations decision trees acceleration heuristic algorithms;atpg	"""In this paper, we focus on an improvement of test pattern generation for circuit descriptions written in hardware description languages according to their behavior. The improvement method stems from the """"headlines"""" defined at the gate level by structural test approaches. The improvement method is implemented and inserted in a behavioral test pattern generator in order to be validated. Experimental results have been obtained which show the efficiency of our approach. >"""	algorithm;test card	Loïc Vandeventer;Jean François Santucci;Norbert Giambiasi	1994		10.1109/VTEST.1994.292308	electronic engineering;heuristic;computer science;theoretical computer science;automatic test pattern generation;hardware description language;algorithm	EDA	18.390576962350206	48.73359403228079	96210
d483e1ff22b9a69c673f4693844c40dacec8fe05	enhancement of incremental design for fpgas using circuit similarity	incremental design circuit similarity fpga;field programmable gate array;design automation;logic design;incremental design;routing;logic level netlists;edge detection;efficient algorithm;push button feature;design preservation approach;design flow;incremental design using circuit similarity;versatile place and route;fpga;layout;network routing;network topology;field programmable gate arrays routing image edge detection layout optimization table lookup design automation;vpr;circuit similarity;local structure;logically resynthesized netlist;design iteration;image edge detection;global topological similarity detection;field programmable gate array fpga incremental design enhancement global topological similarity detection circuit similarity algorithm iducs incremental design using circuit similarity circuit optimization design iteration design preservation approach push button feature logically resynthesized netlist logic level netlists versatile place and route vpr;iducs;optimization;field programmable gate arrays;incremental design enhancement;circuit optimisation;circuit similarity algorithm;table lookup;network topology circuit optimisation field programmable gate arrays logic design network routing;circuit optimization	This paper presents an efficient algorithm to detect the global topological similarity between two circuits. By applying the proposed circuit similarity algorithm in an incremental design flow, IDUCS (incremental design using circuit similarity), the design and optimization effort in the previous design iterations is automatically captured and can be used to guide the next design iteration. IDUCS is able to identify the similarity between the original netlist and the modified one with aggressive resynthesis, which might destroy the naming and local structures of the original netlist. This is superior to the existing design preservation approaches such as naming and local topological matching. Furthermore, IDUCS simply inserts a plugin for circuit similarity detection, and therefore preserves the “push-button” feature, significantly simplifying the engineering complexity of incremental tasks. As a case study, we perform the proposed IDUCS process to generate the placement for a logically resynthesized netlist based on the placement of the original netlist and the circuit similarity between the original and the modified logic-level netlists. The experimental results show our IDUCS-based placement is 28X faster than versatile place and route (VPR) with comparable wire length and estimated critical delay.	algorithm;continuous design;field-programmable gate array;iteration;logic level;mathematical optimization;netlist;place and route;push-button	Xiaoyu Shi;Dahua Zeng;Yu Hu;Guohui Lin;Osmar R. Zaïane	2011	2011 12th International Symposium on Quality Electronic Design	10.1109/ISQED.2011.5770732	embedded system;routing;electronic engineering;electronic design automation;computer science;theoretical computer science;machine learning;algorithm;field-programmable gate array	EDA	16.880641531052408	49.32118207747705	96216
9339487170b8eac7664f53f969c32d5a2268f99d	energy efficient cmos microprocessor design	energy efficiency;energy conservation;desktop computers;microprocessors;energy efficiency quantification;energy efficient cmos microprocessor design;design principles energy efficient cmos microprocessor design power dissipation portable electronics battery weight battery size heat dissipation desktop computers parallel machines computation modes figures of merit power analysis methodology energy efficiency quantification computer architectures throughput energy consumption;application software;energy efficient;figures of merit;battery weight;heat dissipation;battery size;integrated circuit modelling cmos digital integrated circuits microprocessor chips cooling energy conservation computer architecture;computer architectures;computer architecture;power analysis methodology;cmos digital integrated circuits;integrated circuit modelling;energy consumption;portable electronics;semiconductor device modeling;cmos logic circuits;energy efficiency microprocessors power dissipation batteries parallel machines computer architecture throughput energy consumption;power dissipation;batteries;parallel machines;capacitance;cooling;microprocessor chips;computation modes;design principles;throughput;design methodology	Reduction of power dissipation in microprocessor design is becoming a key design constraint. This is motivated not only by portable electronics, in which battery weight and size is critical, but by heat dissipation issues in larger desktop and parallel machines as well. By identifying the major modes of computation of these processors and by proposing figures of merit for each of these modes, a power analysis methodology is developed. It allows the energy efficiency of various architectures to be quantified, and provides techniques for either individually optimizing or trading off throughput and energy consumption. The methodology is then used to qualify three important design principles for energy efficient microprocessor design.	cmos;central processing unit;computation;design closure;desktop computer;microprocessor;mobile computing;processor design;quantifier (logic);thermal management (electronics);throughput	Thomas D. Burd;Robert W. Brodersen	1995		10.1109/HICSS.1995.375385	embedded system;computer hardware;computer science;efficient energy use	Arch	13.290797270710275	57.939029970129056	96346
fcd0484b8fc1951348008bab3d098e130ae8035c	an efficient design of a reversible fault tolerant n -to-2 ^n sequence counter using nano meter mos transistors	fault tolerant;counter fault tolerant reversible logic transistor;bepress selected works;reversible logic;counter;transistor		gnu nano;transistor	Md. Shamsujjoha;Sirin Nahar Sathi;Golam Sorwar;Fahmida Hossain;Md. Nawab Yousuf Ali;Hafiz Md. Hasan Babu	2015		10.1007/978-3-319-20469-7_48	embedded system;fault tolerance;real-time computing;transistor	EDA	14.211116745181222	59.82997604106968	96492
bca360a1df3cd1ac3cad380ed7bc903d36fa1139	engineering a scalable boolean matching based on eda saas 2.0	software tool;recent bloom filter-based boolean;software as a service;proposed saas-bm;new boolean;boolean algebra;eda saas 2.0;software tools;internet bandwidth limit;scalable eda algorithm;core sub algorithm;eda saas;state-of-the-art sat-based boolean matching;logic design;logic synthesis;fpga;scalable boolean matching;boolean matching;matching algorithm;area overhead;field programmable gate arrays;cloud computing;electronic design automation (eda);electronic engineering computing;field programmable gate array (fpga);scalable boolean;databases;benchmark testing;boolean functions;electronic design automation;bloom filter;servers;field programmable gate array	Software as a Service (SaaS) 1.0 signifcantly lowers the infrastructure and maintenance cost and increases the accessibility of the software by hosting software via the web. Compared with SaaS 1.0, SaaS 2.0 is more flexible since it leverages software tools from both server and client sides with closer interaction between them. The SaaS 2.0 paradigm provides new opportunities and challenges for EDA. In this paper, we take Boolean matching, one of the core sub algorithms in logic synthesis for field programmable gate arrays (FPGAs), as a case study. We investigate the advantages and challenges of implementing a scalable EDA algorithm under SaaS 2.0 paradigm from a technical perspective. We propose SaaS-BM, a new Boolean matching algorithm customized to take full advantage of the cloud while addressing concerns such as security and the internet bandwidth limit. Extensive experiments are performed under a net-worked environment with concurrent accesses. Integrated into a post-mapping re-synthesis algorithm minimizing area, the proposed SaaS-BM is 863X times faster than state-of-the-art SAT-based Boolean matching with 0.5% area overhead. Compared with a recent Bloom Filter-based Boolean matching algorithm, our proposed SaaS-BM is 53X times faster on large circuits with no area overhead.	accessibility;algorithm;bloom filter;boolean algebra;electronic design automation;experiment;field-programmable gate array;logic synthesis;overhead (computing);programming paradigm;scalability;server (computing);software as a service	Chun Zhang;Yu Hu;Lingli Wang;Lei He;Jiarong Tong	2010	2010 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		embedded system;computer architecture;electronic engineering;parallel computing;logic synthesis;electronic design automation;computer science;theoretical computer science;operating system;field-programmable gate array	EDA	10.782383861394711	54.800155271338134	96842
1ce4d93f6678246a48145e41152374e9c3c70229	circuit design of clos-based on-chip interconnection networks		Single-hop non-blocking networks have the advantage of providing uniform latency and throughput, which is important for cache-coherent network-on-chip systems. This paper focuses on high performance circuit designs of multi-stage non-blocking networks as alternatives to crossbars. Existing work shows that Benes networks have much lower transistor count and smaller circuit area but longer delay than crossbars. To reduce the timing delay, we propose to design the Clos network built with larger size switches. Using less than half number of stages than the Benes network, the Clos network with 4 × 4 switches can significantly reduce the timing delay. The circuit designs of both Benes and Clos networks in different sizes are conducted considering two types of implementation of the configurable switch: with N-type metal-oxide-semiconductor logic (NMOS) transistors only and full transmission gates (TGs). The layout and simulation results under 45 nm technology show that the TG-based implementation demonstrates much better signal integrity than its counterpart. Clos networks achieve average 60% lower timing delay than Benes networks with even smaller area and power consumption.	circuit design;clos network;interconnection	Yikun Jiang;Mei Yang	2016	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2016.03.008	parallel computing;computer science;clos network;computer network	EDA	14.408675269896966	57.070588278067504	96985
9fb79694d0e47cc88f8177bb1e65ecd7f304dedb	fast monte carlo estimation of timing yield with importance sampling and transistor-level circuit simulation	statistical timing;transistor level circuit simulation;gate delay model;statistical timing analysis;yield estimation importance sampling is monte carlo mc method statistical timing analysis statistically critical paths transistor level simulation;integrated circuit yield;cost reduction;delay integrated circuit modeling logic gates accuracy computational modeling random variables;random variables;yield estimation;gate delay model monte carlo estimation importance sampling transistor level circuit simulation electronic design automation statistical timing transistor level monte carlo technique transistor level timing verification timing yield estimation mc estimator variance reduction;monte carlo estimation;circuit simulation;accuracy;transistor level simulation;computational modeling;logic gates;variance reduction techniques;monte carlo mc method;importance sampling is;critical path;delay circuits;mc estimator;integrated circuit modeling;transistor circuits;transistor circuits circuit simulation delay circuits electronic design automation importance sampling integrated circuit yield;importance sampling;monte carlo;transistor level timing verification;variance reduction;statistically critical paths;timing yield estimation;transistor level monte carlo technique;electronic design automation	Considerable effort has been expended in the electronic design automation community in trying to cope with the statistical timing problem. Most of this effort has been aimed at generalizing the static timing analyzers to the statistical case. On the other hand, detailed transistor-level simulations of the critical paths in a circuit are usually performed at the final stage of performance verification. We describe a transistor-level Monte Carlo (MC) technique which makes final transistor-level timing verification practically feasible. The MC method is used as a golden reference in assessing the accuracy of other timing yield estimation techniques. However, it is generally believed that it can not be used in practice as it requires too many costly transistor-level simulations. We present a novel approach to constructing an improved MC estimator for timing yield which provides the same accuracy as standard MC but at a cost of much fewer transistor-level simulations. This improved estimator is based on a unique combination of a variance reduction technique, importance sampling, and a cheap but approximate gate delay model. The results we present demonstrate that our improved yield estimator achieves the same accuracy as standard MC at a cost reduction reaching several orders of magnitude.	approximation algorithm;computation;digital electronics;electronic circuit simulation;electronic design automation;importance sampling;monte carlo method;propagation delay;reduced cost;sampling (signal processing);speedup;static timing analysis;transistor;variance reduction	Alp Arslan Bayrakci;Alper Demir;Serdar Tasiran	2010	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2010.2049042	random variable;electronic engineering;real-time computing;electronic design automation;logic gate;importance sampling;computer science;critical path method;mathematics;accuracy and precision;computational model;statistics;variance reduction;monte carlo method	EDA	22.9476208944389	57.672053736836986	97043
cefd41c0a071ee3263dad48200a17c74434f9191	synthesis of skewed logic circuits	power saving;dynamic program;synthesis;skewed logic;optimization;power consumption;high performance;power;integer linear program	Skewed logic circuits belong to a noise-tolerant high-performance static circuit family. Skewed logic circuits can achieve performance comparable to that of Domino logic circuits but with much lower power consumption. Two factors contribute to the reduction in power. First, by exploiting the static nature of skewed logic circuits, we can alleviate the cost of logic duplication which is typically required to overcome the logic reconvergence problem in both Domino logic and skewed logic circuits. Second, a selective clocking scheme can be applied to a skewed logic circuit to reduce the clock load and hence, clock power. In this article, we propose a two-step synthesis scheme of skewed logic circuits. In the first step, an integer linear programming-based approach is presented to overcome the logic reconvergence problem in skewed logic circuits with minimal logic duplication cost. In the second step, a dynamic programming-based heuristic is applied to achieve an optimal selective clocking scheme. Experimental results show that the average power saving of skewed logic circuits over Domino logic circuits is 41.1&percent;.	clock rate;digital electronics;domino logic;dynamic programming;heuristic;integer programming;linear programming;logic gate;logic programming	Aiqun Cao;Naran Sirisantana;Cheng-Kok Koh;Kaushik Roy	2005	ACM Trans. Design Autom. Electr. Syst.	10.1145/1059876.1059878	mathematical optimization;logic synthesis;real-time computing;logic optimization;logic level;asynchronous circuit;logic gate;logic family;pass transistor logic;power;mathematics;sequential logic;digital electronics;algorithm	EDA	17.086396397796594	52.97897821238746	97102
75d19488c68b1fd45311e8f04074b6927b77b9da	a soft error mitigation technique for constrained gate-level designs	single event transient;single event upset;soft error mitigation;soft error	A single event transient generated from a high-energy particle is capable of corrupting the status of a digital system. Not only in aerospace engineering, but even in terrestrial application system reliability is expected to worsen due to radiation effects as semi-conductor technology advances. In this paper, we introduce an incremental gate-sizing method for minimizing soft errors in gate-level designs. The target designs have constraints for marginal circuit area and path delay. The proposed heuristic algorithm searches for each driving strength of logic gates using modified topological order. It gives a more effective solution in large marginal constraints than the existing greedy approach. In the experiments, we show the effectiveness of our algorithm using several benchmark circuits synthesized by a 130nm cell library.	soft error	Jong Kang Park;Jong Tae Kim	2008	IEICE Electronic Express	10.1587/elex.5.698	electronic engineering;real-time computing;simulation;soft error;computer science;engineering	EDA	16.726493964233963	53.497674932635995	97201
3bca9dd9fee484e1d81859fd57fb4cc8c255b32a	a low-latency and low-power hybrid insertion methodology for global interconnects in vdsm designs	insertion methodology on chip interconnects low swing differential signaling;cmos integrated circuits;signal generators;cmos technology;cost function;computational techniques;very large scale integration;low swing;wires;energy production;vlsi design;signal integrity;chip;power hybrid insertion methodology;integrated circuit design;on chip interconnects;technology scaling;global interconnect;delay transceivers cmos technology wires very large scale integration electronics industry power generation signal generators repeaters cost function;low power;low latency;eda tool;integrated circuit interconnections;electronics industry;differential signaling transceiver;vlsi cmos integrated circuits integrated circuit design integrated circuit interconnections spice transceivers;vlsi;power generation;insertion methodology;repeaters;transceivers;vdsm design;differential signaling;spice;power hybrid insertion methodology global interconnect vdsm design vlsi design cmos technology differential signaling transceiver eda tool	Current VLSI designs face a serious performance bottleneck due to reverse scaling of global interconnects as CMOS technology scales into VDSM regime. Interconnections techniques which decrease delay, power, and ensure signal integrity, play an important role in the growth of semiconductor industry into future generations. In this paper we present a novel hybrid insertion methodology for on-chip global interconnects. It takes advantage of repeaters and low-swing differential-signaling transceivers on driving long wires in different length, and optimally inserts them along the wires in order to decrease delay, power and gate area cost of interconnects. Simulation results using HSPICE for 0.18mum process showed that delay, power, delay-energy-product (EDP) and gate area cost were considerably decreased compared with other approaches available. Moreover, its computational technique is relatively easy and not limited to a specific low-swing differential-signaling transceiver. Therefore the methodology is very suitable for integration in EDA tool flow and beneficial for the reuse of low-swing differential-signaling transceivers	and gate;cmos;computation;differential signaling;electrical connection;electronic data processing;image scaling;interrupt latency;low-power broadcasting;spice 2;semiconductor industry;signal integrity;simulation;transceiver;very-large-scale integration	Shuming Chen;Xiangyuan Liu	2007	First International Symposium on Networks-on-Chip (NOCS'07)	10.1109/NOCS.2007.4	embedded system;telecommunications;computer science;very-large-scale integration	EDA	15.459425926398822	57.05462702685003	97313
fbdf92f8dd6b37a18d069b63a83c795cc218fe0f	inductive fault analysis for test and diagnosis of dna sensor arrays	dna;dna sensor arrays;amorphous silicon;fault modeling;testing;failure mode;dna detection;optical sensor array;failure analysis;inductive fault analysis;structural testing;fault analysis;optical arrays;sensor arrays testing fault diagnosis dna optical arrays amorphous silicon optical sensors biosensors optical films fault detection;optical sensors biosensors dna failure analysis fault diagnosis integrated circuit testing;fault diagnosis inductive fault analysis dna sensor arrays optical sensor array label free sensors array dna detection critical equivalent resistance failures mechanisms test strategy structural test fault modeling;structural test;fault detection;failure mechanism;sensor array;integrated circuit testing;failures mechanisms;test strategy;optical sensors;critical equivalent resistance;fault model;label free sensors array;sensor array for dna detection;sensor arrays;inductive fault analysis sensor array for dna detection fault modeling fault diagnosis;optical films;biosensors;fault diagnosis	This paper presents a fault analysis applied to a novel optical, label-free sensors array for DNA detection. The IFA approach to extract and model the possible defects has been used. A critical equivalent resistance for the possible faults has been defined and it allowed defining the threshold values of current to discriminate the occurrence of the failures mechanisms. Particularly critical is the shorts occurrence: in this failure mode the current changes can generate wrong information that can be confused with the current reduction due to DNA detection. At the end a test strategy for structural test is proposed	diode;failure cause;fault coverage;fault model;joan feigenbaum;negative feedback;sensor;solid-state drive;test strategy	Daniela De Venuto;Bruno Riccò	2007	8th International Symposium on Quality Electronic Design (ISQED'07)	10.1109/ISQED.2007.90	test strategy;structural engineering;embedded system;failure analysis;electronic engineering;engineering;fault model;software testing;sensor array;failure mode and effects analysis;dna;fault detection and isolation;biosensor	Arch	23.292973251583557	52.005528800977174	97500
00ca0715cecf1c93aa93557f88514795ed863a0f	addressing thermal and power delivery bottlenecks in 3d circuits	unwanted side-effect;packing densities;integrated circuit technology;critical issue;3d integrated circuit technology;possible power delivery bottleneck;thermal delivery;power delivery bottlenecks;enhanced packing;integrated circuit design;integrated circuit packaging;thermal problem;integrated circuit;power integrated circuits;unit footprint;package pin;side effect;material properties;chip;copper;heating;thermal analysis;mathematical model;thermal conductivity;scheduling;routing;through silicon via;thermal management	The enhanced packing densities facilitated by 3D integrated circuit technology also has an unwanted side-effect, in the form of increasing the amount of current per unit footprint of the chip, as compared to a 2D design. This has ramifications on two critical issues: firstly, it means that more heat is generated per unit footprint, potentially leading to thermal problems, and secondly, more current must be supplied per package pin, leading to possible power delivery bottlenecks. This paper presents an overview of the challenges and solutions in the domain of addressing these two issues in 3D integrated circuits.	integrated circuit;set packing	Sachin S. Sapatnekar	2009	2009 Asia and South Pacific Design Automation Conference		chip;material properties;embedded system;routing;electronic engineering;thermal management of electronic devices and systems;integrated circuit packaging;computer science;electrical engineering;integrated circuit;mathematical model;through-silicon via;copper;thermal conductivity;scheduling;side effect;thermal analysis;integrated circuit design	EDA	19.358130197297093	56.69926244233668	97530
bc76304f25c12ecc99b9087fa1e6d84314ba5ed1	an enhanced test generator for capacitance induced crosstalk delay faults	logic simulation;value system;fault simulation;crosstalk;automatic test pattern generation;turn off;automatic test pattern generation logic testing crosstalk capacitance timing tree searching combinational circuits logic simulation fault simulation;logic testing;test generation;capacitance;logic algebra capacitance induced faults crosstalk delay faults enhanced test generator functional error xgen restricted propagation conditions constrained logic value system solution space pin to pin delay model timing ranges crosstalk noise adjacent interconnects combinational logic circuits branch and bound strategy timing simulation dynamic hazard;tree searching;logic circuit testing crosstalk capacitance timing tree searching combinational logic circuits;combinational circuits;timing	Capacitive crosstalk can give rise to slowdown of signals that can propagate to a circuit output and create a functional error. A test generation methodology, called XGEN, was developed to generate tests for such failures. Two drawbacks of XGEN are: (i) it is not complete because of restricted propagation conditions, and (ii) a constrained logic value system is used. In this paper, we relax the propagation conditions to increase the solution space. This increases the likelihood of finding a test. We also present a nine-valued algebra that distinguishes between hazardous values and non-hazardous values. Finally, we use the relation between arrival time and required time ranges to selectively turn off the timing computation procedure which is computationally expensive. Other drawbacks of previous versions of XGEN are: (i) a simplified pin-to-pin delay model was used, and (ii) crosstalk computation could not handle timing ranges. We have addressed both of those issues.	analysis of algorithms;computation;crosstalk;feasible region;software propagation;time of arrival;value (ethics)	Arani Sinha;Sandeep K. Gupta;Melvin A. Breuer	2003		10.1109/ATS.2003.1250805	electronic engineering;real-time computing;logic optimization;crosstalk;logic family;computer science;electrical engineering;theoretical computer science;automatic test pattern generation;logic simulation;pass transistor logic;mathematics;sequential logic;capacitance;value system;combinational logic;algorithm	EDA	19.344231385645692	48.59457525084501	97704
09e417eb8534ee66382385caa15ec1291d838d84	on designing via-configurable cell blocks for regular fabrics	design process;flip flops;layout;programmable logic arrays;permission;energy consumption;via configurable;manufacturing;fabrics;repeaters;power consumption;field programmable gate arrays;table lookup;flip flop;regular fabric;fabrics repeaters programmable logic arrays manufacturing table lookup flip flops energy consumption field programmable gate arrays costs permission	In this paper we describe the design process of a via-configurable block for regular fabrics. The block consists of via-configurable functional cells, via-decomposable flip-flops, and via-configured sizable repeaters. The fabric has fixed layers up to M2. An M1-M2 via mask is used to define the block's functionality. The upper-level metals are customized. Compared to other structures based on LUTs or PLAs, and fixed flip-flops, our block has much smaller area, higher performance and lower power consumption.	flops;flip-flop (electronics);programmable logic array	Yajun Ran;Malgorzata Marek-Sadowska	2004	Proceedings. 41st Design Automation Conference, 2004.	10.1145/996566.996624	layout;embedded system;electronic engineering;real-time computing;design process;computer science;engineering;manufacturing;field-programmable gate array;repeater	EDA	12.466389308783974	52.095265864501826	97810
90b8f422857b7164497ebd5269c9a4c18e58fb8f	global clustering-based performance-driven circuit partitioning	vlsi cad;partitioning;clustering;performance optimization;retiming	In this paper, we propose a new global clustering based multi-level partitioning algorithm for performance optimization. Our algorithm computes a delay minimal K-way partition first, then gradually reduces the cutsize while keeping the circuit delay by de-clustering and refinement. Our test results on a set of MCNC sequential examples show that we can reduce the delay by 30%, while increasing the cutsize by 28% on average, when compared with hMetis [5]. Our algorithm consistently outperforms state-of-the-art partitioning algorithms [2, 5, 3] on circuit delay with reasonable cost on the cutsize.	algorithm;cluster analysis;mathematical optimization;refinement (computing)	Jason Cong;Chang Wu	2002		10.1145/505388.505424	mathematical optimization;real-time computing;computer science;retiming;theoretical computer science;mathematics;cluster analysis	EDA	15.385470342570601	52.66150027644429	97843
cc6cb450d0369509c66a70b18c6808dd8e36c371	power grid analysis and optimization using algebraic multigrid	optimisation;interpolation;power grids noise robustness optimization methods circuits very large scale integration computer science education educational programs information science student members error correction;optimization technique;power grid analysis;simulation;power grids algebra differential equations optimisation;amg based reduction;transient analysis;fast transient analysis;error control mechanism;accuracy;smoothing methods;algebra;simulation capacitance multigrid optimization power grid;multigrid;error control;power grid;algebraic multigrid;optimization;capacitance;differential equations;power grids;power grid optimization;fast decap allocation scheme power grid analysis power grid optimization algebraic multigrid amg based reduction fast transient analysis error control mechanism;fast decap allocation scheme	This paper presents a class of power grid analysis and optimization techniques, all of which are based on the algebraic-multigrid (AMG) method. First, a new AMG-based reduction scheme is proposed to improve the efficiency of reducing the problem size for power grid analysis and optimization. Next, with the proposed reduction technique, a fast transient-analysis method is developed and extended to an accurate solver with error control mechanism. After that, the scope of this method is further broadened for handling the analysis of the modified grid. Finally, a fast decap-allocation (DA) scheme based on AMG is suggested. Experimental results show that these techniques not only achieve a significant speedup over reported industrial methods but also enhance the quality of solutions. By using the proposed techniques, transient analysis with 200 time steps on a 1.6-M-node power grid can be completed in less than 5 min; dc analysis on the same circuit can reach an accuracy of in about 141 s. Our DA can process a circuit with up to one million nodes in about 11 min.	analysis of algorithms;error detection and correction;linear algebra;mathematical optimization;maxima and minima;multigrid method;multistage interconnection networks;solver;speedup;transient state	Cheng Zhuo;Jiang Hu;Min Zhao;Kangsheng Chen	2008	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2008.917587	mathematical optimization;electronic engineering;computer science;theoretical computer science;mathematics;algorithm;multigrid method;statistics	EDA	16.718347290158082	53.07588377781069	97889
155c34adc7c8e053383254fe5069d5fe8c02a1d6	fault models and test generation for opamp circuits - the ffm	design for testability;analog test;fault simulation;operational amplifiers;circuit complexity;operational amplifier;analog vlsi;test generation;fault model	The analog VLSI technology processes are reaching the matureness, nevertheless, there is a big constraint, regarding their use on complex electronic products: “the test”. The “Design for Testability” paradigm was developed to permit the test plan implementation early in the design cycle. However to succeed onto this strategy, the fault simulation should be carried out in order to evaluate appropriate test patterns, fault grade and so forth. Consequently adequate fault models must be established. Due to the lack of fault models, suitable to fault simulation on OpAmps, we propose in this work a methodology for Functional Fault Modeling-FFM, and some methods for test generation. A fault dictionary for OpAmps is built and a procedure for compact test vector construction is proposed. The results have shown that high level OpAmp requirements, as slew-rate, common mode rejection ration etc., can be checked by this approach with good compromise between the fault modeling problem, the analog nature of the circuit and the circuit complexity by itself.	analog-to-digital converter;audio crossover;circuit complexity;design for testing;dictionary;fault detection and isolation;fault model;high-level programming language;nonlinear system;operational amplifier;programming paradigm;pulse-width modulation;rate limiting;rejection sampling;requirement;simulation;test card;test plan;test strategy;test vector;very-large-scale integration	José Vicente Calvano;Antonio Carneiro de Mesquita Filho;Vladimir Castro Alves;Marcelo Lubaszewski	2001	J. Electronic Testing	10.1023/A:1011169626409	operational amplifier;reliability engineering;electronic engineering;real-time computing;fault coverage;computer science;engineering;stuck-at fault;automatic test pattern generation;control theory;fault model;software fault tolerance	EDA	24.236184716704226	51.069553988789494	98015
594e781f941f2c1760374c139a4ff8dbabe2d723	partially strongly fault secure and partially strongly code disjoint i-out-of-3 code checker	tolerancia falta;self checking checker fault secure strongly code disjoint strongly fault secure time delay code checker fault tolerance;strongly code disjoint;circuit faults;combinatorial circuits;logic design;self checking checker;delay effects;conception;satisfiability;circuit faults fault detection delay effects built in self test electrical fault detection;code checker;time delay;fault tolerant system;strongly fault secure;built in self test;circuit reliability;fault detection;fault tolerance;partially strongly fault secure;logic testing;sistema tolerando faltas;diseno;design;systeme tolerant les pannes;combinatorial circuits circuit reliability logic testing logic design;temps retard;delay time;tiempo retardo;fault secure;tolerance faute;partially strongly code disjoint;electrical fault detection	We show that by adding eight extra edges, referred to as bridges, to an n-cube ( n 2 4) its diameter can be reduced by 2, and by adding sixteen bridges to an n-cube ( n 2 6) its diameter can be reduced by 3. We also show that by adding (ATl) + 1 ( m 2 2 ) bridges to an n-cube ( 7 t 2 4m and n 2 8) its diameter can be reduced by 2m and by adding 2(4:-3) + 1, (nt > 2 ) to an n-cube ( n 2 477a 2 and n 2 10) its diameter can be reduced by 2771 1. We also consider the reduction of diameter of an n-cube by exchanging some independent edges (twisting), where two edges are called independent if they are not incident on a common node. We have shown that by exchanging four pairs of independent edges in a d-cube ( d 2 5 ) , we can reduce its diameter by 2. By exchanging sixteen pairs of independent edges, the diameter of a d-cube ( d 2 7) can be reduced by 3. By exchanging 57 pairs of independent edges, the diameter can be reduced by 4 for d 2 9. To reduce the diameter by Ld/2] , ( d 2 10) we need to exchange (fyi) pairs of independent edges, where T = Ld/4 J + 1. Zndex Terms-Bridge, diameter, hypercube, routing, twist.	diameter (protocol);emoticon;grid network;routing	J. Q. Wang;Parag K. Lala	1994	IEEE Trans. Computers	10.1109/12.324550	fault tolerance;real-time computing;computer science;theoretical computer science;distributed computing	Theory	23.446327938213873	49.0858498572643	98089
8b02d0752015a245597b8880dbad8f6b9b28d212	collaborative calibration of on-chip thermal sensors using performance counters	thermal management packaging;radiation detectors;temperature sensors;estimation;photovoltaic panel reconfiguration;fault detection;fault tolerance;thermal management packaging calibration integrated circuit packaging microprocessor chips sensor fusion temperature sensors;photovoltaic system;temperature sensors radiation detectors calibration estimation correlation;correlation;sensor fusion;integrated circuit packaging;calibration;microprocessor chips;amd athlon 64 processor collaborative calibration on chip thermal sensor performance counters thermal information dynamic thermal management data fusion strategy bayesian inference temperature estimation	Thermal sensors are currently deployed in processors to collect thermal information for dynamic thermal management (DTM). The calibration cost for thermal sensors can be prohibitively high as the number of on-chip sensors increases. We propose an on-line multi-sensor calibration method which combines potentially inaccurate temperature values obtained from two sources: temperature readings from thermal sensors and temperature estimations using system performance counters. A data fusion strategy based on Bayesian inference, which combines information from these two sources, is demonstrated along with a temperature estimation approach using performance counters. The approaches are verified via simulation for an AMD Athlon 64 processor with 24 on-chip temperature sensors scaled to a 45nm technology node. Our results show that the standard deviation of temperature sensor measurement errors can be reduced from 3 ~ 4 °C to ≤ 1 °C using the proposed method. Additionally, our MATLAB implementation shows that the new approach runs at least 67x faster than competing approaches based on Kalman filtering making it highly appropriate for run-time use.	athlon;bayesian approaches to brain function;central processing unit;kalman filter;matlab;online and offline;reduction (complexity);semiconductor device fabrication;sensor;simulation;thermal management of high-power leds	Shiting Lu;Russell Tessier;Wayne P. Burleson	2012	2012 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1145/2429384.2429388	embedded system;estimation;fault tolerance;electronic engineering;real-time computing;calibration;integrated circuit packaging;computer science;engineering;photovoltaic system;sensor fusion;particle detector;correlation;fault detection and isolation;statistics	EDA	23.182566492948414	60.03942467359628	98195
4c0e1e5760bd9bf3bb60e5eb13d9206e3e3022e2	defining statistical timing sensitivity for logic circuits with large-scale process and environmental variations	statistical approach;large scale process;statistical timing sensitivity;process variation;probability;fluctuations;efficient algorithm;logic circuits;random variables;nanotechnology;indexing terms;circuit complexity;statistical static timing analysis process variations sensitivity;sensitivity;nanoscale ic;large scale;process variations;statistical analysis;sensitivity analysis;statistical analysis circuit complexity logic circuits nanotechnology probability sensitivity analysis;environmental variation;critical path;timing analysis;timing logic circuits large scale systems delay probability algorithm design and analysis fluctuations optimization methods random variables circuit analysis computing;statistical timing graph;circuit analysis computing;logic circuit;algorithm design and analysis;statistical static timing analysis;sensitivity analysis statistical timing sensitivity logic circuit large scale process environmental variation nanoscale ic statistical timing graph path sensitivity probability;large scale systems;optimization methods;timing;path sensitivity	The large-scale process and environmental variations for today's nanoscale ICs require statistical approaches for timing analysis and optimization. In this paper, we demonstrate why the traditional concept of slack and critical path becomes ineffective under large-scale variations and propose a novel sensitivity framework to assess the ldquocriticalityrdquo of every path, arc, and node in a statistical timing graph. We theoretically prove that the path sensitivity is exactly equal to the probability that a path is critical and that the arc (or node) sensitivity is exactly equal to the probability that an arc (or a node) sits on the critical path. An efficient algorithm with incremental analysis capability is developed for fast sensitivity computation that has linear runtime complexity in circuit size. The efficacy of the proposed sensitivity analysis is demonstrated on both standard benchmark circuits and large industrial examples.	algorithm;benchmark (computing);computation;critical path method;mathematical optimization;slack variable;static timing analysis	Xin Li;Jiayong Le;Mustafa Celik;Lawrence T. Pileggi	2008	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2008.923241	electronic engineering;logic gate;computer science;theoretical computer science;mathematics;statistics	EDA	22.789771452851635	57.47136084969636	98212
8bd82492781d701dbaca9ace1a296e53f13cc4d0	multi-placement structures for fast and optimized placement in analog circuit synthesis	analog circuits circuit synthesis circuit topology integrated circuit synthesis circuit simulation genetic algorithms intelligent structures integrated circuit layout constraint optimization heuristic algorithms;constraint optimization;integrated circuit layout;warp processing;fpga;circuit topology;hardware architecture;network topology;analog circuits;integrated circuit design;circuit simulation;analogue integrated circuits;hardware software partitioning;heuristic algorithms;layout floorplans;procedural layout generators;genetic algorithms;integrated circuit synthesis;circuit cad;search process;microblaze;circuit cad integrated circuit layout analogue integrated circuits circuit optimisation network topology;analog circuit synthesis;circuit optimisation;intelligent structures;integrated circuit design multi placement structures analog circuit synthesis circuit topology layout floorplans procedural layout generators search process;soft cores;high speed;circuit synthesis;multi placement structures;dynamic optimization	This paper presents the novel idea of multi-placement structures, for a fast and optimized placement instantiation in analog circuit synthesis. These structures need to be generated only once for a specific circuit topology. When used in synthesis, these pre-generated structures instantiate various layout floorplans for various sizes and parameters of a circuit. Unlike procedural layout generators, they enable fast placement of circuits while keeping the quality of the placements at a high level during a synthesis process. The fast placement is a result of high speed instantiation resulting from the efficiency of the multi-placement structure. The good quality of placements derive from the extensive and intelligent search process that is used to build the multi-placement structure. The target benchmarks of these structures are analog circuits in the vicinity of 25 modules. An algorithm for the generation of such multi-placement structures is presented. Experimental results show placement execution times with an average of a few milliseconds making them usable during layout-aware synthesis for optimized placements.	algorithm;analogue electronics;circuit topology;high-level programming language;universal instantiation	Raoul F. Badaoui;Ranga Vemuri	2005	Design, Automation and Test in Europe	10.1109/DATE.2005.216	topology;computer architecture;electronic engineering;real-time computing;genetic algorithm;analogue electronics;computer science;electrical engineering;hardware architecture;integrated circuit layout;network topology;field-programmable gate array;integrated circuit design	EDA	13.407902609028866	51.50348262982055	98248
a0dfdaf9bf833094c1c9acb685bacf4794f6c113	design of high throughput, low latency and low cost structures for linear systems	linear systems;symbol manipulation;digital signal processing;linear systems design;degradation;cost function;design optimization;low cost structures;linear system;linear time invariant systems;high level synthesis;linear network synthesis;low latency;digital filters linear systems design high throughput structures low latency structures low cost structures heuristic transformation linear time invariant systems high level synthesis tools symbolic algebraic manipulation tools dsp benchmarks;symbolic algebraic manipulation tools;signal processing;digital filters;high throughput structures;linear time invariant;low latency structures;national electric code;high throughput;mimo;throughput linear systems cost function digital signal processing national electric code high level synthesis mimo degradation added delay design optimization;high level synthesis tools;added delay;heuristic transformation;throughput;signal processing linear systems linear network synthesis high level synthesis symbol manipulation digital filters;dsp benchmarks	This paper introduces heuristic transformation techniques to simultaneously optimize throughput and latency of linear time-invariant systems. The technique is based on a properly coordinated manipulation of an arbitrary initial specification by both high level synthesis and symbolic algebraic manipulation tools. The technique produces implementations that not only have high throughput and low latency, but also have lower area and power requirements compared to the initial specifications. The effectiveness of the technique is demonstrated on a number of high level synthesis DSP benchmarks. >		Miodrag Potkonjak;Mani B. Srivastava	1994		10.1109/ICASSP.1994.389610	real-time computing;computer science;theoretical computer science;signal processing;linear system	Arch	13.893978853221867	46.859414414933056	98338
eb2ce221c4da32a64458096fa2a1d575bc28073e	a self-diagnosis technique using reed-solomon codes for self-repairing chips	multiple input signature register;self diagnosis circuit;circuit faults;system clock;built in self diagnosis built in self repair field repair reed solomon codes algebraic decoding forward error correction built in self test;reed solomon codes;maintenance engineering;built in self diagnosis;scan chains;data mining;algebraic decoding;chip;reed solomon codes hardware circuit faults manufacturing costs circuit testing field programmable gate arrays clocks application specific integrated circuits cmos technology;built in self test;forward error correction;self diagnosis technique;field repairable units;field repair;self repairing chips;reed solomon codes built in self test fault tolerance;time compression circuit;space compression circuit;fault tolerance;scan shift clock;time compression;tiles;multiple input signature register self diagnosis technique reed solomon codes self repairing chips self diagnosis circuit field repairable units scan chains space compression circuit time compression circuit scan shift clock system clock;built in self repair;reed solomon code;industrial design;hardware	A self-diagnosis circuit that can be used for builtin self-repair is proposed. The circuit under diagnosis is assumed to be comprised of a large number of field repairable units (FRUs), which can be replaced with spares when they are found to be defective. Since the proposed self-diagnosis circuit is implemented on the chip, responses that are scanned out of scan chains are compressed first by the space compression circuit and then by the time compression circuit to reduce the volume of test response data. Both the space and the time compression circuit implement a Reed-Solomon code. Unlike prior work, in the proposed technique, responses of all FRUs are observed at the same time to reduce diagnosis time. The proposed diagnosis circuit can locate up to l defective FRUs. We propose a novel space-compression circuit that reduces hardware overhead by exploiting the frequency difference of the scan shift clock and the system clock. When the size of constituent multiple-input signature-register (MISR) is m, the total number of signatures to be stored for the fault-free signature is 2lmB bits, where 1 ≤ B ≤ m. The experimental results show that the proposed diagnosis circuit that can locate up to 4 defective FRUs in the same test session can be implemented with less than 1 % of hardware overhead for a large industrial design. Hardware overhead for the diagnosis circuit is lower for large CUDs.	ct scan;clock rate;code;fault coverage;image scaling;little big adventure;online locator service;overhead (computing);precomputation;reed–solomon error correction;software bug;spectral leakage;stuck-at fault;system time;test card;type signature	Xiangyu Tang;Seongmoon Wang	2009	2009 IEEE/IFIP International Conference on Dependable Systems & Networks	10.1109/DSN.2009.5270327	chip;maintenance engineering;embedded system;fault tolerance;real-time computing;industrial design;telecommunications;computer science;forward error correction;circuit extraction;reed–solomon error correction;system time	EDA	20.310443145673574	52.30339491094509	98453
7ae6b0cde5c44aa31925e7b93d935d9bda1bf8a9	special issue on circuits and systems solutions for nanoscale cmos design challenges	special issues and sections nanoscale devices cmos technology analog digital conversion phase locked loops voltage controlled oscillators electrostatic discharge logic circuits;process variation;cmos technology;building block;special issues and sections;analog digital conversion;logic circuits;phase locked loops;electrostatic discharge;analog circuits;nanoscale devices;voltage controlled oscillators	Advances in electronics have been extraordinary in the past four decades thanks to the continued exponential device size scaling dictated by Moore’s Law. The development of analog, RF and digital circuit design techniques has further enabled the full integration of complete systems on a monolithic silicon die. Although extremely scaled CMOS devices offer density, cost and possibly speed advantages for each new technology node, the associated supply voltage reduction to address digital power density issues requires innovative circuit solutions. Moreover, circuit designers are faced with new challenges such as degraded transistor characteristics, gate leakage, sub-threshold conduction leakage, and increased variability.	cmos;die (integrated circuit);digital electronics;heart rate variability;image scaling;integrated circuit design;moore's law;radio frequency;semiconductor device fabrication;spectral leakage;time complexity;transistor	Lucien J. Breems;Peter R. Kinget;Kong-Pang Pun	2009	IEEE Trans. on Circuits and Systems	10.1109/TCSII.2009.2019173	mixed-signal integrated circuit;control engineering;electronic engineering;phase-locked loop;electrostatic discharge;logic gate;analogue electronics;computer science;engineering;electrical engineering;integrated injection logic;process variation;cmos	EDA	12.02304107561168	57.35758181204028	98457
6d389a0da0d7c1d58769e1e94313c57b47478166	a novel stt-mram cell with disturbance-free read operation	perpendicular to plane anisotropy spin torque transfer magnetoresistive random access memory cell stt mram cell disturbance free read operation magnetic tunnel junction transistor cell structure 1 transistor 1 mtj cell 2 transistor 2 mtj cell in plane anisotropy;vlsi memory magnetic memory magnetic multilayers magnetic tunnel junction nonvolatile memory read disturbance spin transfer torque;random access storage magnetic tunnelling;magnetic tunnelling;magnetization torque magnetic tunneling switches power line communications computer architecture microprocessors;random access storage	This paper presents a three-terminal Magnetic Tunnel Junction (MTJ) and its associated two transistor cell structure for use as a Spin Torque Transfer Magnetoresistive Random Access Memory (STT-MRAM) cell. The proposed cell is shown to have guaranteed read-disturbance immunity; during a read operation, the net torque acting on the storage cell always acts in a direction to refresh the data stored in the cell. A simulation study is then performed to compare the merits of the proposed device against a conventional 1-Transistor-1-MTJ (1T1MTJ) cell, as well as a differential 2-Transistor 2-MTJ (2T2MTJ) cell. We also investigate In-Plane Anisotropy (IPA) and Perpendicular-to-Plane Anisotropy (PPA) versions of the proposed device. Simulation results confirm that the proposed device offers disturbance-free read operation while still offering significant performance advantages over the conventional 1T1MTJ cell in terms of average access time. The proposed cell also shows superior performance to the 2T2MTJ cell, particularly when the cells are targeted for read-mostly applications.	access time;embedded system;magnetoresistive random-access memory;memory cell (binary);random access;simulation;transistor	Safeen Huda;Ali Sheikholeslami	2013	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2012.2220458	spin-transfer torque;electronic engineering;computer hardware;engineering;electrical engineering	Visualization	17.067756890109425	60.03665006570064	98465
7e7b2f7defad560c9b6352bd66bf32bf6dea96a1	draxrouter: global routing in x-architecture with dynamic resource assignment	interpolation;integrated circuit;stochastic optimization draxrouter global routing x architecture dynamic resource assignment integrated circuit physical design liquid routing model tree construction;tree data structures integrated circuit design integrated circuit interconnections network routing integrated circuit modelling stochastic programming;physical design;tree data structures;network routing;integrated circuit design;stochastic optimization;routing integrated circuit interconnections wire algorithm design and analysis design optimization stochastic processes benchmark testing delay space technology heuristic algorithms;leakage power;integrated circuit modelling;integrated circuit interconnections;global routing;mtcmos;static timing analysis;selective mt;stochastic programming	In recent years, the X-Architecture is introduced to obtain better performance for integrated circuit physical design. This paper reformulates the global routing problem in X-Architecture under the liquid routing model. Then, a dynamic resource assignment (Dra) method is presented to reduce potential vias. At last, a global router called DraXRouter, is designed, in which we adopt a dynamic-tabulist-based tree construction algorithm and a stochastic optimization strategy to gain high quality routing solution. Tested on ISPD'98 benchmarks, DraXRouter achieves better routing performance compared with two recent global routers.	algorithm;display resolution;integrated circuit;mathematical optimization;physical design (electronics);router (computing);routing;stochastic optimization;via (electronics)	Zhen Cao;Tong Jing;Yu Hu;Yiyu Shi;Xianlong Hong;Xiao-Dong Hu;Guiying Yan	2006	Asia and South Pacific Conference on Design Automation, 2006.	10.1145/1118299.1118445	policy-based routing;wireless routing protocol;stochastic programming;physical design;routing table;routing domain;mathematical optimization;routing;enhanced interior gateway routing protocol;electronic engineering;static routing;real-time computing;hierarchical routing;dsrflow;zone routing protocol;equal-cost multi-path routing;interpolation;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;integrated circuit;stochastic optimization;routing protocol;tree;link-state routing protocol;triangular routing;path vector protocol;static timing analysis;routing information protocol;integrated circuit design	EDA	15.42760750491014	52.61560221072436	98604
6112a68a4ad69da1a2f09a54f252d28ac35ff9da	timing analysis in presence of supply voltage and temperature variations	statistical approach;process variation;operant conditioning;spatial correlation;environmental variation;timing analysis;digital circuits;robust extraction;extraction	In the nanometer era, the physical verification of CMOS digital circuit becomes a complex task. Designers must account of numerous new factors that impose a drastic change in validation and physical verification methods. One of these major changes in timing verification to handle process variation lies in the progressive development of statistical static timing engines. However the statistical approach cannot capture accurately the deterministic variations of both the voltage and temperature variations. Therefore, we define a novel method, based on non-linear derating coefficients, to account of these environmental variations. Based on temperature and voltage drop CAD tool reports, this method allows computing the delay of logical paths considering the operating conditions of each cell.	cmos;coefficient;computer-aided design;digital electronics;graph factorization;nonlinear system;performance;software verification;static timing analysis	B. Lasbouygues;Robin Wilson;Nadine Azémard;Philippe Maurine	2006		10.1145/1123008.1123012	extraction;spatial correlation;real-time computing;simulation;operant conditioning;mathematics;process variation;digital electronics;static timing analysis;statistics	EDA	22.040576330707875	58.088196881547304	98637
8e5963519762f85f8334ee3dc2dfc7ee00d45ab9	a 4 + 2t sram for searching and in-memory computing with 0.3-v vddmin		This paper presents a 4+2T SRAM for embedded searching and in-memory-computing applications. The proposed SRAM cell uses the n-well as the write wordline to perform write operations and eliminate the write access transistors, achieving 15% area saving compared with conventional 8T SRAM. The decoupled differential read paths significantly improve read noise margin, and therefore reliable multi-word activation can be enabled to perform in-memory Boolean logic functions. Reconfigurable differential sense amplifiers are employed to realize fast normal read or multi-functional logic operations. Moreover, the proposed 4 + 2T SRAM can be reconfigured as binary content-addressable memory (BCAM) or ternary content-addressable memory (TCAM) for searching operations, achieving 0.13 fJ/search/bit at 0.35 V. The chip is fabricated in 55-nm deeply depleted channel technology. The area efficiency is 65% for a $128 times 128$ pushed-rule array including all peripherals such as column-wise sense amplifier for read/logic and row-wise sense amplifier for BCAM/TCAM operations. Forty dies across five wafers in different corners are measured, showing a worst-case read/write $V_{mathrm {DDmin}}$ of 0.3 V.	static random-access memory	Qing Dong;Supreet Jeloka;Mehdi Saligane;Yejoong Kim;Masaru Kawaminami;Akihiko Harada;Satoru Miyoshi;Makoto Yasuda;David Blaauw;Dennis Sylvester	2018	J. Solid-State Circuits	10.1109/JSSC.2017.2776309	static random-access memory;boolean algebra;content-addressable memory;chip;electronic engineering;sense amplifier;computer science;amplifier;in-memory processing;computer hardware;noise margin	Theory	16.479464262350348	59.70717016255376	98746
f5fdec479c8d2950e0dc0b8c4b5e4d22e29d67bc	advanced ternary cam circuits on 0.13 μm logic process technology	random access memory;static random access memory;memoria acceso directo;integrated circuit;logic design;autonomous system;integrated circuit design memory architecture content addressable storage sram chips embedded systems logic design cmos memory circuits;circuito integrado;memoire acces direct statique;sistema autonomo;circuit a la demande;embedded systems;integrated circuit design;custom circuit;circuito integrato personalizado;low power;cmos memory circuits;matriz formadora;memory architecture;memoire acces direct;systeme autonome;low power electronics;on the fly;die;content addressable storage;matrice formage;electronique faible puissance;computer aided manufacturing cadcam multivalued logic logic circuits random access memory energy consumption capacitance impedance matching circuit synthesis variable structure systems;0 13 micron embedded ternary cam macro die size sram half cell standard logic process low power macro logic process technology divided match line inherent parallel search power prioritized multiple match output status bit functions on the fly variable word width cmos cam redundancy;logical process;circuit integre;sram chips	An embedded ternary CAM macro derived from a 9M stand alone part with die size of 148 mm/sup 2/ uses a novel 3.542 /spl mu/m/sup 2/ SRAM half-cell on a standard 0.13 /spl mu/m logic process. In the embedded form it takes 13 mm/sup 2//Mbit. The macro achieves 166 M-searches/s with low power, under 0.5 W/Mbit. A divided match line greatly reduces the power inherent in parallel searches. Prioritized multiple match output, status bit functions, and on-the-fly variable word width are included.		Alan Roth;Dick Foss;Robert McKenzie;Douglas Perry	2004		10.1109/CICC.2004.1358852	embedded system;electronic engineering;logic synthesis;real-time computing;static random-access memory;telecommunications;computer science;autonomous system;electrical engineering;operating system;integrated circuit;die;low-power electronics;integrated circuit design	EDA	17.65112539545336	56.42283543424901	98926
3f96e4a73c2b885c9c9df22ea1c792a98fb0b870	equivalent elmore delay for rlc trees	time domain response;damping;closed form solution;overshoot;optimization technique;rlc tree;vlsi interconnect;very large scale integration;delay effects;settling time;trees mathematics;design optimization;trees mathematics vlsi integrated circuit modelling integrated circuit interconnections delays;wire;rise time;circuit simulation;elmore delay model;integrated circuit modelling;rlc circuits;integrated circuit interconnections;vlsi interconnect elmore delay model rlc tree rise time overshoot settling time time domain response damping design optimization;vlsi;integrated circuit interconnections very large scale integration delay estimation design methodology rlc circuits inductance circuit simulation wire delay effects design optimization;time domain;inductance;delay estimation;delays;design methodology	Closed-form solutions for the 50% delay, rise time, overshoots, and settling time of signals in an RLC tree are presented. These solutions have the same accuracy characteristics of the Elmore delay for RC trees and preserves the simplicity and recursive characteristics of the Elmore delay. Specifically, the complexity of calculating the time domain responses at all the nodes of an RLC tree is linearly proportional to the number of branches in the tree and the solutions are always stable. The closed-form expressions introduced here consider all damping conditions of an RLC circuit including the underdamped response, which is not considered by the Elmore delay due to the nonmonotone nature of the response. The continuous analytical nature of the solutions makes these expressions suitable for design methodologies and optimization techniques. Also, the solutions have significantly improved accuracy as compared to the Elmore delay for an overdamped response. The solutions introduced here for RLC trees can be practically used for the same purposes that the Elmore delay is used for RC trees.	elmore delay;rlc circuit	Yehea I. Ismail;Eby G. Friedman;José Luis Neves	2000	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.822622	electronic engineering;real-time computing;engineering;elmore delay;control theory;mathematics;very-large-scale integration	EDA	24.242428535400617	58.832022532998046	98940
e8a86272b0c303cb4d3ee11677fbd67caf543158	design and simulation of novel tlg-set based ram cell designs	threshold logic gate tlg;single electron tunneling set technology;random access memory ram cells;nanoelectronics	In this paper, design and simulation of novel random access memory (RAM) cells using single electron tunneling (SET) technology based threshold logic gate (TLG) are presented. RAM cell designs based on RS-latch and D-latch are investigated with the aim of reducing the area, switching delay, and energy consumption. The designed circuits are simulated using Monte Carlo simulation. According to the simulation results, the circuits operations based on the transfer of single electrons between adjacent islands are stable.	random-access memory;simulation;thesaurus linguae graecae	M. M. Abutaleb	2013	Microelectronics Journal	10.1016/j.mejo.2013.03.008	nanoelectronics;electronic engineering;parallel computing;engineering;electrical engineering;nanotechnology;physics	EDA	16.215517269530046	59.30440178678794	99170
b5a315ccd5ce2085dd3ff64e6419b7c35fd703b8	hierarchical channel router	special case;channel router;wiring layer;vertical grid line;known routers;absolute minimum;horizontal wiring track;layer change;hierarchical channel router;new channel;vertical segment;n ∗ n log m time;hierarchy;benchmark problem	The channel routing problem is a special case of the wire routing problem when interconnections have to be performed within a rectangular strip having no obstructions, between terminals located on opposite sides of the rectangle. We present here a new channel routing algorithm, based on reduction of the problem to the case of a (2×<italic>n</italic>) grid and on consistent utilization of a “divide and conquer” approach. For the current implementation of the algorithm, the running time is proportional to <italic>N×n×</italic>log (<italic>m</italic>), where <italic>N</italic> is the number of nets, <italic>n</italic> is the length of the channel (number of columns) and <italic>m</italic> is the width of the channel (number of tracks). Traditional technological restrictions are assumed, i.e. net terminals are located on vertical grid lines, two wiring layers are available for interconnections - one layer is used exclusively for vertical segments, another for horizontal and vias are introduced for each layer change. This algorithm consistently outperforms several known routers in quality of wiring. We tested the algorithm on several benchmark problems. One of them - Deutsch's “difficult ex&le”” - was routed with only 19 horizontal wiring tracks (the absolute minimum for this case), whereas all other known routers required 20 or more tracks.	algorithm;benchmark (computing);channel router;column (database);router (computing);routing (electronic design automation);time complexity;via (electronics);wiring	Michael Burstein;Richard N. Pelavin	1983	20th Design Automation Conference Proceedings	10.1016/0167-9260(83)90004-4	electronic engineering;telecommunications;engineering;engineering drawing	EDA	15.226850667755395	51.20819333881256	99471
6e08ec1131ab58c5eae3638bcc033ba69bceb16a	active mode leakage reduction using fine-grained forward body biasing strategy	switching;diseno circuito;optimisation;leakage current;voltage threshold;temps polynomial;optimizacion;circuit retard;corriente escape;leakage reduction;heuristic method;leakage power optimization;circuit design;metodo heuristico;leakage power reduction;algorithme;algorithm;technology scaling;leakage power;courant fuite;threshold voltage;conmutacion;low power electronics;polynomial time;design;seuil tension;optimization;conception circuit;methode heuristique;power reduction;power consumption;circuito retardo;consommation energie electrique;modes of operation;electronique faible puissance;gating circuits;delay circuit;algorithm design;commutation;forward body biasing;umbral tension;algoritmo;tiempo polinomial;circuit porte	Leakage power minimization has become an important issue with technology scaling. Variable threshold voltage schemes have become popular for standby power reduction. In this work we look at another emerging aspect of this potent problem which is leakage power reduction in active mode of operation. In gate level circuits, a large number of gates are not switching in active mode at any given point in time but nevertheless are consuming leakage power. We propose a fine-grained forward body biasing (FBB) scheme for active mode leakage power reduction in gate level circuits without any delay penalty. Our results show that our optimal polynomial time FBB allocation algorithm results in 70.2% reduction in leakage currents. We also present an exact standard-cell placement driven FBB allocation algorithm that effectively reduces the area penalty using the post-placement area slack and results in 56.5%, 62.8% and 66.1% reduction in leakage currents for 0%, 4% and 8% area slack, respectively. Furthermore, we present a heuristic to solve the standard-cell placement driven FBB allocation problem that is computationally efficient and results in leakage within 2% of that from the exact formulation.	biasing;spectral leakage	Vishal Khandelwal;Ankur Srivastava	2007	Integration	10.1016/j.vlsi.2006.12.003	algorithm design;design;electronic engineering;computer science;electrical engineering;circuit design;control theory;mathematics;threshold voltage;algorithm	HCI	17.91077929131647	54.535417249797796	99477
145b9ce67fa4bd7a0e39cd0a4c884787659cb4f8	wire optimization for multimedia soc and sip designs	analytical models;on chip bus;system in package sip;protocols;network protocol;three bit phase signals;wire efficiency multimedia system on chip soc on chip bus system in package sip soc network protocol snp vlsi design;system in package;very large scale integration;phase interleaving;advanced microcontroller bus architecture wire optimization multimedia soc sip designs vlsi integration technology bus based interconnects in package communication on chip communication system on chip network protocol snp three bit phase signals symmetric communication channel phase interleaving phase omission restoration advanced high performance bus;advanced microcontroller bus architecture;phase omission restoration;wire efficiency;sip;multimedia system on chip soc;vlsi design;multimedia soc;design optimization;multimedia systems;system on a chip;field buses;chip;wire;system on chip network protocol;mpeg 4 standard;system on chip;in package communication;wire design optimization hardware protocols system on a chip analytical models mpeg 4 standard very large scale integration bandwidth network on a chip;performance analysis;vlsi;sip designs;bandwidth;vlsi field buses multimedia systems system in package system on chip;wire optimization;soc;symmetric communication channel;soc network protocol snp;vlsi integration technology;on chip communication;communication channels;network on a chip;register transfer level;high performance;advanced high performance bus;hardware;bus based interconnects;snp	With advances in VLSI integration technology, a large number of hardware components can be integrated into a single chip. To provide the communication bandwidth for these components, existing bus-based interconnects often suffer from a large area occupied by a large number of bus signals. To address this issue, this paper proposes a new protocol for on-chip or in-package communication that is termed the system-on-chip network protocol (SNP). SNP uses a small number of signals that are shared by address, control, and data information. Additional three-bit phase signals are used to distinguish the different information transmitted through a single set of SNP signals. Two sets of identical SNP signals form a symmetric communication channel that allow a master-to-master type of communication between hardware components. The phase signals facilitate the reduction of the communication time with phase interleaving and phase omission-restoration among successive transactions. The efficiency of SNP is evaluated by a static performance analysis as well as by simulations with register-transfer level models of SNP components. Both the analysis and simulation results show that the communication time with SNP is approximately a half that of advanced microcontroller bus architecture advanced high-performance bus (AHB), although SNP has wires that are approximately three-fifths of AHB. MPEG-4 chips are implemented with both AHB and SNP, respectively, and it is observed from the MPEG-4 implementations that SNP requires less area for communication compared to AHB.	advanced microcontroller bus architecture;automated x-ray inspection;central processing unit;channel (communications);circuit restoration;clock rate;communications protocol;electrical connection;forward error correction;hdmi;multistage amplifier;network on a chip;pipeline (computing);register-transfer level;snp annotation;serialization;simulation;system on a chip;two-phase locking;very-large-scale integration	Jaesung Lee;Hyuk-Jae Lee	2008	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2008.920153	system on a chip;embedded system;electronic engineering;parallel computing;computer science;very-large-scale integration;network on a chip	Arch	11.767913736764513	47.52339381680948	99540
8933e0622af52da08121f876e632f4c76986c893	synthesis of locally exhaustive test pattern generators	circuit under test;linear independence;tpg synthesis;automatic testing integrated circuit testing logic testing;automatic testing;linear sum computation;test pattern generators;logic testing;integrated circuit testing;test pattern generator;tpg synthesis locally exhaustive tpg test pattern generators linear sum computation;locally exhaustive tpg;test pattern generators circuit testing automatic testing indium phosphide sequential analysis feedback circuits registers very large scale integration built in self test hardware	Optirnized locally exlzaustive test patterti yetietators bused on linear sunis promise a low overhead, bur ha\,e an irregular structure. The puper presents a new 0180t.ithm able to compute the linear sunis fo r real circuiis up to several h i d r e d s of inputs arid outpurs. The idea is to substitute a strategy of introducing fresh variables irito an array of sums fo r the former linear independence test. This reduces the complexity of the calculatioti on an enornious scale. Experinierits with several hundred raridomly selected cone srrucmres allow the rough estimatiori that the so conipuied generators are oti a v e t q e smaller ihari sh$ register bused oiies f the number of equal size cones is tiot larger thuti the tiumber of iriputs o f the circuit under tesr.	arid;algorithm;built-in self-test;experiment;overhead (computing);shift register;test card	Günter Kemnitz	1995		10.1109/VTEST.1995.512672	linear independence;electronic engineering;discrete mathematics;automatic test pattern generation;test compression;mathematics;algorithm	EDA	21.41230848332081	48.58335463072078	99612
5b17604c053bcb7d606860279f0d8e0bf6e821e2	a control scheme for a 65nm 32×32b 4-read 2-write register file	cmos integrated circuits;random access memory;fluctuations;decoding;frequency 1 25 ghz control scheme register file tsmc low power process timing control module short clock pulse high clock frequency word line driver dummy driver dummy cell sense amplifier self timing approach power consumption inverter chain technique size 65 nm;low power;low power electronics;microcomputers driver circuits low power electronics;driver circuits;register file;power reduction;power consumption;fluctuations random access memory decoding cmos integrated circuits delay;microcomputers	This paper describes a control scheme for a 32×32bit 4-read, 2-write register file operating in 1.25GHz with TSMC 65nm LP (low-power) process. Signals from the timing control module can tolerate short clock pulse, which ensures that the register file can work well on high clock frequency. Due to the fact that the delay of the word-line driver in this design is easy to match, a dummy driver as well as a dummy cell is used to generate the enable signal of sense amplifier. And this self-timing approach has small area overhead introduced by the dummy circuits (only about 0.24% of the total cell area). Results show that this approach reduces the required timing margin and power consumption compared with the inverter-chain technique. As a result, about 8% of read speed improvement and 10.8% of power reduction could be achieved.	clock rate;clock signal;control unit;dummy variable (statistics);line driver;low-power broadcasting;overhead (computing);power inverter;register file;sense amplifier	Jun Han;Xingxing Zhang;Baoyu Xiong;Zhiyi Yu;Xiaoyang Zeng	2011	2011 9th IEEE International Conference on ASIC	10.1109/ASICON.2011.6157311	electronic engineering;real-time computing;computer hardware;computer science	EDA	17.552174450332416	58.32303576595315	99627
4c011445129bf66c00b0f62b23890b4de4303bc2	test access and the testability features of the poulson multi-core intel itanium® processor	pins;clocks;test access mechanism;testing and debugging;testing;arrays;innovation management;registers;discrete fourier transform;high volume manufacturing;bandwidth;multiprocessing systems;program debugging;arrays registers testing pins clocks bandwidth discrete fourier transforms;debug platform test access testability feature poulson multicore intel itanium processor t ring based dfx access architecture multicore cpu testing innovative solution scalable test access mechanism design manufacturing test;discrete fourier transforms;testing innovation management multiprocessing systems program debugging	This paper presents the “t-Ring” based DFX access architecture and the testability features of Intel's latest multi-core Itanium® processor. The architecture solves many common challenges of testing a multi-core CPU using distinctive and innovative solutions. At the core of the architecture is a hierarchical and scalable test access mechanism design providing flexible access for a variety of use models in high volume manufacturing test and debug platforms.	central processing unit;itanium;multi-core processor;scalability;visual effects	Dilip K. Bhavsar;Steve Poehlman	2011	2011 IEEE International Test Conference	10.1109/TEST.2011.6139168	embedded system;computer architecture;parallel computing;innovation management;computer science;operating system;software engineering;discrete fourier transform;software testing;processor register;bandwidth;statistics	EDA	10.593425516695753	54.46758122596985	99698
ef815cf547f6b824c1b2fcc571a0e5be7a587df4	low power state assignment algorithm for fsms considering peak current optimization	finite state machine;switching activity;peak current;lagrangian relaxation	Finite state machine (FSM) plays a vital role in the sequential logic design. In an FSM, the high peak current which is drawn by state transitions can result in large voltage drop and electromigration which significantly affect circuit reliability. Several published papers show that the peak current can be reduced by post-optimization schemes or Boolean satisfiability (SAT)-based formulations. However, those methods of reducing the peak current either increase the overall power dissipation or are not efficient. This paper has proposed a low power state assignment algorithm with upper bound peak current constraints. First the peak current constraints are weighted into the objective function by Lagrangian relaxation technique with Lagrangian multipliers to penalize the violation. Second, Lagrangian sub-problems are solved by a genetic algorithm with Lagrangian multipliers updated by the subgradient optimization method. Finally, a heuristic algorithm determines the upper bound of the peak current, and achieves optimization between peak current and switching power. Experimental results of International Workshop on Logic and Synthesis (IWLS) 1993 benchmark suites show that the proposed method can achieve up to 45.27% reduction of peak current, 6.31% reduction of switching power, and significant reduction of run time compared with previously published results.	augmented lagrangian method;benchmark (computing);boolean satisfiability problem;cpu power dissipation;electromigration;finite-state machine;genetic algorithm;heuristic (computer science);iteration;lagrange multiplier;lagrangian relaxation;linear programming relaxation;loss function;mathematical optimization;optimization problem;run time (program lifecycle phase);sequential logic;software release life cycle;subderivative;subgradient method	Lun-Yao Wang;Zhufei Chu;Yinshui Xia	2013	Journal of Computer Science and Technology	10.1007/s11390-013-1397-2	mathematical optimization	EDA	16.562006145080936	54.28170340775543	99711
4255b09e26b07d794d2e513761ad151a0ee7535e	interconnections in application specific vlsi	metalizacion;fiabilidad;reliability;interconnection;etude experimentale;circuit vlsi;metallizing;vlsi circuit;fiabilite;interconnexion;circuito vlsi;estudio experimental;interconeccion;metallisation	Abstract#R##N##R##N#Process technologies developed for the fabrication of Application Specific Integrated Circuits must satisfy some unusual demands imposed by design automation and by fast turn around manufacturing.#R##N##R##N##R##N##R##N#In this paper we will discuss some of the problems that constrain the selection of a suitable interconnection technology for ASIC's VLSI.#R##N##R##N##R##N##R##N#Design automation (a tool necessary for ASIC designs) demands a simple set of design rules and very large current carrying capability metal Lines. On the other hand fast turnaround manufacturing requires the use of simple and proven technologies so that the product will be easily manufacturable, possibly in more than one foundry.#R##N##R##N##R##N##R##N#Some of the available technologies to implement mutilevel interconnections will be reviewed and the one chosen by VLSI Technology for their 1 μm ASIC process will be briefly described.		Dipankar Pramanik;Gianpaolo Spadini	1990	European Transactions on Telecommunications	10.1002/ett.4460010217	electronic engineering;metallizing;telecommunications;engineering;electrical engineering;interconnection;reliability;engineering drawing	Vision	13.559604044454122	50.302489595066206	99730
02331f899275558a895904eeb9a7fdcba4842d8d	scalable compact test pattern generation for path delay faults based on functions	decision diagrams;small benchmarks;circuit faults;probability density function;publicly available benchmarks scalable compact test pattern generation path delay faults decision diagram based algorithm optimal compaction small benchmarks processing faults;decision diagram;automatic test pattern generation;logic gates;processing faults;compaction;publicly available benchmarks;delay circuits;path delay fault;robustness;test pattern generators delay compaction circuit faults circuit testing automatic test pattern generation data structures robustness boolean functions benchmark testing;compaction pdf;scalable compact test pattern generation;test pattern generator;pdf;path delay faults;optimal compaction;delay circuits automatic test pattern generation compaction decision diagrams;decision diagram based algorithm;benchmark testing	A recent decision diagram-based algorithm [12] was able to generate test patterns for each sensitizable path delay fault. Although scalable this approach results to prohibitively long test sets. This paper presents a novel technique to intelligently select paths for compaction. It guarantees optimal compaction subject to the order of processing faults. The compaction rate is superior to any published method, even for the small benchmarks where enumerative compaction methods have been proposed. Experimental results on the publicly available benchmarks demostrate the scalability of the proposed method.	algorithm;benchmark (computing);data compaction;influence diagram;scalability;test card	Edward Flanigan;Spyros Tragoudas;Arkan Abdulrahman	2009	2009 27th IEEE VLSI Test Symposium	10.1109/VTS.2009.22	compaction;benchmark;probability density function;electronic engineering;real-time computing;influence diagram;logic gate;computer science;engineering;theoretical computer science;automatic test pattern generation;statistics;robustness	EDA	20.798681623825527	51.09818303374611	99819
a725c2d4ebb06b12d6bb6895b9e884454465e278	combining error masking and error detection plus recovery to combat soft errors in static cmos circuits	sequential circuits;high energy;soft error rate;technology scaling;critical path;error correction;cmos logic circuits;single event transient;logic testing;sequential logic circuit error masking error detection error recovery soft error rate static cmos circuit combinational logic circuit;computer errors redundancy cmos logic circuits logic circuits error correction circuit noise voltage fluctuations costs hardware sequential circuits;error detection;soft error;logic testing combinational circuits sequential circuits cmos logic circuits error detection;combinational circuits	Soft errors are changes in logic state of a circuit/system resulting from the latching of single-event transients (transient voltage fluctuations at a logic node or SETs) caused by high-energy particle strikes or electrical noise. Due to technology scaling and reduced supply voltages, they are expected to increase by several orders of magnitude in logic circuits. In this work, we present a very efficient and systematic approach to cope with soft errors in combinational and sequential logic circuits. The features and merits of our approach are: (1) use of error masking in non-critical paths along with error detection and recovery in critical paths, which substantially lowers overhead for error correction; (2) average 93% soft-error rate (SER) reduction as SETs of width approximately half the clock period time can be tolerated; (3) area and power overheads can be traded-off with SER reduction based on application requirements. We also present two additional techniques to more aggressively utilize slack in circuits and further improve SER reduction by: (1) exploiting circuit delay dependence on input vectors and (2) redistributing slack in pipelined circuits.	cmos;clock rate;combinational logic;crosstalk;error detection and correction;image scaling;international conference on dependable systems and networks;logic gate;noise (electronics);overhead (computing);requirement;sequential logic;slack variable;soft error	Srivathsan Krishnamohan;Nihar R. Mahapatra	2005	2005 International Conference on Dependable Systems and Networks (DSN'05)	10.1109/DSN.2005.27	boolean circuit;real-time computing;logic optimization;diode–transistor logic;error detection and correction;logic level;asynchronous circuit;soft error;logic gate;logic family;computer science;theoretical computer science;pass transistor logic;sequential logic;integrated injection logic;pull-up resistor;digital electronics;register-transfer level;clock signal;statistics;resistor–transistor logic	EDA	19.61092526932611	56.65779444800583	99965
8954b1c1369c64651c0b3b6028dfa0b8444f4e26	dtr: a defect-tolerant routing algorithm	fabrication;circuit faults;integrated circuit layout;routing;very large scale integration;distributed computing;wires;permission;routing circuit faults wires permission very large scale integration fabrication distributed computing machinery integrated circuit layout integrated circuit interconnections;integrated circuit interconnections;routing algorithm;defect tolerance;machinery	A new channel routing algorithm called DTR (Defect-Tolerant Routing) is investigated. This algorithm minimizes the total area and simultaneously maximizes the performance by reducing the critical area which can potentially be the source of logical faults caused by the bridging effects of spot defects. Experimental results show DTR produces less critical area than Yoshimura&Kuh's algorithm [1].	algorithm;bridging (networking);channel router;routing;software bug	Anucha Pitaksanonkul;Suchai Thanawastien;Chidchanok Lursinsap;J. A. Gandhi	1989	26th ACM/IEEE Design Automation Conference	10.1145/74382.74532	physical design;routing;electronic engineering;static routing;machine;real-time computing;equal-cost multi-path routing;computer science;engineering;electrical engineering;multipath routing;distributed computing;integrated circuit layout;very-large-scale integration;circuit extraction;fabrication;routing	EDA	15.19932166177442	52.04279290523028	100086
189fac0eb1f4b2a748cc41f6c3bcc4905081c7e2	exploiting metal layer characteristics for low-power routing	switching activity;metalizacion;concepcion asistida;cmos integrated circuits;circuit integre cmos;computer aided design;interconnection;submicrometer;capacitancia;metodologia;caracteristique temporelle;integrated circuit;routing;design flow;propiedad material;routage;circuito integrado;switching conditions;methodologie;time curve;fonction objectif;routage reseau;network routing;metallizing;interconexion;objective function;low power;regimen conmutacion;timing optimization;propriete materiau;regime commutation;interconnexion;submicrometro;caracteristica temporal;puissance faible;conception assistee;properties of materials;funcion objetivo;capacitance;power consumption;methodology;consommation energie electrique;circuit integre;submicrometre;metallisation;capacite electrique;potencia debil;enrutamiento	Wire load has become an important variable for power and timing optimization. As standard cell geometries are shrinking and average wirelength increases due to increasing design complexities wire capacitance has become dominant over gate capacitance. However the wire load of a net not only depends on wirelength but also on which metal layer a net is routed. In this paper we investigate the characteristics of metal layers and propose a power driven routing scheme, which exploits the different metal layer properties in deep submicron semicustom design flows. Layer assignment for final routing will be done according to the switching activity of a net and the layer characteristics. In section 3 we describe the investigation of the characteristics of routing layers. A parameter for the validation of metal layers for use in routing for low-power is derived. In sections 4 and 5 an objective function for power driven routing and the layer assignment methodology is described.		Armin Windschiegl;Paul Zuber;Walter Stechele	2002		10.1007/3-540-45716-X_6	routing;telecommunications;computer science;computer aided design	Mobile	18.08434868463328	54.82483863308767	100089
299e974b069e75ea34d572525f7cba5ed27f9e7f	towards optimal system-level design	microprocessors;computer engineering;cost function;clocks;optimization technique;computer organization;design optimization;connectors;computer architecture;control system synthesis;system level design;extraterrestrial phenomena;optimal design;global optimization;system level design cost function hardware design optimization control system synthesis connectors microprocessors clocks extraterrestrial phenomena;support function;hardware	System-level design includes selecting optimal parts to realize a specified hardware structure. Multiple-function parts and constraints among functions make local-optimization techniques inadequate for generating globally optimal designs. Also, parts and part sets cannot be evaluated without considering the cost of implementing their support functions. Finally, for multi-attribute optimization, designers have difficulty assigning weights to the cost attributes. We present a synthesis tool that handles multiple-function parts, support functions, constraints, multi-attribute evaluation, and generates optimal designs.	constraint (mathematics);electronic system-level design and verification;level design;mathematical optimization;maxima and minima;optimal design	Manjote S. Haworth;William P. Birmingham	1993	30th ACM/IEEE Design Automation Conference	10.1145/157485.164965	embedded system;support function;mathematical optimization;electronic engineering;real-time computing;multidisciplinary design optimization;microarchitecture;computer science;systems engineering;engineering;optimal design;electronic system-level design and verification;global optimization;computer engineering	EDA	13.388229560341905	51.63527112004608	100197
d83333b3e856e474c81e1afb456f74f84951a847	procedure to overcome the byzantine general's problem for bridging faults in cmos circuits	fault simulation;automatic test pattern generation;byzantine general s problem;test pattern generation byzantine general s problem bridging faults cmos circuits intermediate voltage shorted nodes fault simulation;integrated circuit testing fault diagnosis cmos digital integrated circuits automatic test pattern generation vlsi;bridging fault;cmos digital integrated circuits;threshold voltage;integrated circuit testing;vlsi;test pattern generator;circuit faults circuit testing logic testing fault detection circuit simulation system testing bridge circuits electrical fault detection spice very large scale integration;fault diagnosis	The resistance of a bridge fault is critical in determining whether the fault can be detected. In order to simulate the effects of a bridging fault it’s necessary to determine the intermediate voltage of the shorted nodes and compared it to the logic threshold voltage of the driven gates. We present an algorithm, which can be used to overcome the Byzantine General’s problem during the fault simulation and test pattern generation. The algorithm applies to very low bridging fault resistance, and modifies to apply for different values of BF resistance. This algorithm applies to external and internal of inter-gate bridging fault. Moreover, the algorithm is extremely faster than the previous ones since no spice simulation is required. The accuracy is of ±0.01V to compare with SPICE simulation in the interval of intermediate voltage.	algorithm;best, worst and average case;brainfuck;bridging (networking);bridging fault;byzantine fault tolerance;cmos;spice 2;simulation;test card;transistor	Arabi Keshk;Kozo Kinoshita;Yukiya Miura	1999		10.1109/ATS.1999.810739	reliability engineering;embedded system;electronic engineering;real-time computing;fault coverage;fault indicator;engineering;stuck-at fault;automatic test pattern generation;fault model;very-large-scale integration;threshold voltage	EDA	22.546881737630443	52.109644520477026	100264
6104124b12c0c555a21e398451e67aca7718188f	shared-pprm: a memory-efficient representation for boolean reversible functions	computers;boolean reversible functions;memory management;data structures equations quantum computing costs computer society very large scale integration design automation design engineering input variables data mining;boolean functions;storage management boolean functions data structures;reversible circuits;storage management;memory usage memory efficient representation boolean reversible functions memory location list based data structures;data structures;list based data structures;memory efficient representation;data structure reversible circuits positive polarity reed muller expansion;memory location;reed muller;data structure;positive polarity reed muller expansion;algorithm design and analysis;benchmark testing;circuit synthesis;memory usage	A memory-efficient representation scheme, shared-PPRM (SPPRM), for Boolean reversible functions is introduced and analyzed. Compared with conventional PPRM expansion, SPPRM reduces memory usages by using one memory location for many repetitive PPRM sub-expressions. To evaluate the effects of data structure on SPPRM representation, two linked list-based data structures are also examined. The experimental results show the efficiency of the proposed SPPRM representation for both memory usage and CPU time.	central processing unit;data structure;linked list;memory address	Yasaman Sanaee;Mehdi Saeedi;Morteza Saheb Zamani	2008	2008 IEEE Computer Society Annual Symposium on VLSI	10.1109/ISVLSI.2008.41	parallel computing;computer science;theoretical computer science;algorithm	Arch	17.749375942792277	46.47726918935609	100297
796d6e887a2360bdb6e6c2c71e570fc6fd5e7f9e	switching activity analysis using boolean approximation method	boolean functions;combinational circuits;computational complexity;boolean approximation method;taylor expansion;combinational logic circuit;first-order signal correlation effects;power estimation;probability calculation;signal probability;switching activity analysis;time complexity;zero-delay model	This paper presents a novel algorithm to estimate the signal probability and switching activity at all nodes in a combinational logic circuit under a zero-delay model without constructing global BDDs. By using Taylor expansion technique, the first-order signal correlation effects due to reconvergent fan-out nodes are taken into account. High accuracy is achieved by considering the dependency of the signal probability and switching activity on each primary input. High speed is also achieved by using the incremental approach for probability calculation. Our approach is able to handle large circuits, since it does not need to construct global BDDs for the probability calculation. The analysis of the time complexity and the experimental results show the running time of our approach to be about 100 times shorter than that of the most accurate approach previously proposed and that our approach has comparable accuracy. The error of the total power estimation is about 0.5% on average.	algorithm;approximation;combinational logic;first-order predicate;logic gate;reconvergent fan-out;time complexity	Taku Uchino;Fumihiro Minami;Takashi Mitsuhashi;Nobuyuki Goto	1995		10.1145/224841.224853	time complexity;mathematical optimization;electronic engineering;discrete mathematics;computer science;taylor series;theoretical computer science;first-order logic;mathematics;combinational logic;boolean function;computational complexity theory;algorithm	EDA	18.635831887831973	50.32991797660586	100350
33bc3086ec39e321f01461ca86dc34e4310c9d62	a 481pj/decision 3.4m decision/s multifunctional deep in-memory inference processor using standard 6t sram array		This paper describes a multi-functional deep in-memory processor for inference applications. Deep inmemory processing is achieved by embedding pitch-matched low-SNR analog processing into a standard 6T 16KB SRAM array in 65 nm CMOS. Four applications are demonstrated. The prototype achieves up to 5.6X (9.7X estimated for multi-bank scenario) energy savings with negligible (≤1%) accuracy degradation in all four applications as compared to the conventional architecture. ar X iv :1 61 0. 07 50 1v 1 [ cs .A R ] 2 4 O ct 2 01 6	cmos;elegant degradation;in-memory database;multi-function printer;prototype;signal-to-noise ratio;static random-access memory	Mingu Kang;Sujan K. Gonugondla;Ameya Patil;Naresh R. Shanbhag	2016	CoRR		embedded system;electronic engineering;real-time computing;computer science	Arch	15.817473859420577	59.869433379430674	100680
218a98a2d3bcb905d82af0ee3f293bfa76246021	high resolution body bias techniques for reducing the impacts of leakage current and parasitic bipolar	substrate bias;cmos integrated circuits;process variation;body bias generator;power supply circuits;high resolution;leakage current;dead lock high resolution body bias technique leakage current parasitic bipolar scaling process generation power management technique high resolution body bias generation circuit optimal body bias threshold voltage active mode forward body bias condition standby mode sram cmos scaling leakage components band to band tunneling process variation process compensation substrate bias body bias generator;sram chips power supply circuits cmos integrated circuits leakage currents;process compensation;leakage currents;band to band tunneling;threshold voltage;power management;design theory;leakage components;cmos scaling;dead lock;leakage current voltage standby generators circuits delay power generation cmos process tunneling energy consumption permission;sram chips	With scaling process generation, power management techniques are more significant. Body bias techniques are useful for the solutions. We propose a high resolution body bias generation circuit which supplies optimal body bias in both the active and standby mode. By using this circuit, the adjustment accuracy of threshold voltage (Vt) in the active mode was improved about 4.1 times of the conventional circuits at 0.6V forward body bias condition. In addition, for standby mode, when 128 kByte SRAM was supplied back body bias by this generator, the off-state leakage current was reduced to 50% of a fixed back body bias	image scaling;kilobyte;power management;sleep mode;spectral leakage;static random-access memory	Masaya Sumita	2005	ISLPED '05. Proceedings of the 2005 International Symposium on Low Power Electronics and Design, 2005.	10.1145/1077603.1077653	electronic engineering;real-time computing;image resolution;computer science;engineering;electrical engineering;deadlock;leakage;designtheory;threshold voltage;process variation;cmos	EDA	18.39089788010432	58.354181055659815	100902
778113c87dfa0a68c1db1803b94c573f98569bdc	ccp: common case promotion for improved timing error resilience with energy efficiency	verification;error recovery;reliability;probability;energy efficient;error correction mechanism;timing error resilience;resynthesis;internal structure;low power;logic synthesis;energy consumption;voltage overscaling;pattern matching;esd cdm;characteristic function;error resilience;common case;circuit optimization;design methodology;dynamic behavior	Better-Than-Worst-case (BTW) design has been proposed as an alternative way to operate a circuit by deliberately allowing timing errors for rare cases and rectifying them with error correction mechanisms in order to achieve higher performance, better reliability guarantee, or lower energy consumption. This new design methodology necessitates the analysis and manipulation of signal probabilities during circuit optimization. This paper looks for the solution from the logic synthesis perspective and proposes a new concept, called Common Case Promotion (CCP), to enable effective circuit optimization following the BTW design methodology. CCP consists of: 1) probability-driven re-synthesis that changes a digital circuit's internal structure, 2) a dynamic behavior aware SAT-based redundancy remover that reduces area overhead, and 3) a timed characteristic function (TCF) based circuit dynamic behavior analyzer that provides optimization convergence. The experimental results show that, on average, we can effectively improve circuits' timing error resilience by 24%, which reduces the need of error recovery for BTW circuits considerably, and we can improve the overall energy efficiency by 15%.	characteristic function (convex analysis);digital electronics;error detection and correction;logic synthesis;mathematical optimization;overhead (computing);rectifier;tor carding forum	Lu Wan;Deming Chen	2012		10.1145/2333660.2333695	reliability engineering;embedded system;electronic engineering;logic synthesis;real-time computing;characteristic function;verification;design methods;computer science;engineering;pattern matching;probability;reliability;efficient energy use;statistics	EDA	18.775344000394586	57.581672996603935	100924
e95eeb81f84ba5830e6c0c398c70ff71f8523b11	a methodology for guided behavioral-level optimization	quadratic placement;supply demand;optimizations behavioral level optimization datapath intensive asic;circuit cad circuit optimisation;relaxed pins;optimization methods design optimization permission application specific integrated circuits space exploration very large scale integration computer architecture computer science prototypes clocks;global routing;congestion;interactive environment;circuit cad;circuit optimisation;routing models	Optimization at the early stages of design are crucial. However, due to an overwhelming number of design and optimization options, design exploration is often conducted in a qualitative, ad-hoc manner. This paper presents a methodology and interactive environment for guiding the exploration process. A prototype targeting behavioral-level optimization for datapath-intensive ASIC implementations has been developed. The key to the approach is encapsulated knowledge about the various optimizations and a set of techniques to automatically extract the “essence” of a design description. At each stage in the exploration process, the system suggests and ranks potential optimizations, both in terms of immediate and longer-term impact. It also provides evaluations of the design and of the likely affects each optimization will have on metrics like power and performance. In the new approach, the designer is responsible for making the actual optimization selections. However, using the provide guidance, designers can make decisions in a more informed manner, and therefore can explore the design solution space more effectively. The effectiveness of the approach is demonstrated on a number of designs.	application-specific integrated circuit;datapath;feasible region;hoc (programming language);mathematical optimization;program optimization;prototype	Lisa M. Guerra;Miodrag Potkonjak;Jan M. Rabaey	1998		10.1145/277044.277134	physical design;probabilistic-based design optimization;embedded system;mathematical optimization;electronic engineering;real-time computing;engineering optimization;simulation;engineering;operating system;supply and demand;algorithm	EDA	14.709186794948431	54.009233154022475	100973
61732c3980bf7445d4d1fbbbd037d591452b8c73	powerpc as a10 64-bit risc microprocessor	verification;microprocessor;haute performance;metodologia;integrated circuit;technology;circuito integrado;tecnologia mos complementario;methodologie;technologie;characterization;alto rendimiento;microprocesseur;verificacion;caracterisation;methodology;technologie mos complementaire;high performance;microprocesador;caracterizacion;circuit integre;complementary mos technology;tecnologia	The PowerPC ASTM A10 64-bit RISC microprocessor is a 4.7-million-transistor integrated circuit design, using IBM CMOS 5L 0.5-^im, 3-V, four-level-metal ASIC technology. Support for the PowerPC AS architecture is implemented in a 213-mm^ die using a semicustom design methodology. Chip density and speed are enhanced through the use of custom macros and multiport arrays. An on-chip phase-iocked-loop circuit is used to reduce chip-to-chip clock skew. Full utilization of the four-level-metal interconnect technology was achieved through architectural floorplanning, performance clustering, and timing-driven placement and wiring, with a total wire length of over 102 meters placed on the 14.6 X 14.6-mm die. The microprocessor is a pipelined, superscalar design with five separate functional units, a 4KB instruction cache, and an 8KB data cache. The design includes parity, error-correction, and errorlogging functions, as well as self-test for logic and arrays during power-on. The design is robust and implements a wide range of performance configurations at the system level, allowing direct attachment of DRAM to the processor, or high-performance L2 cache options using high-speed SRAM. An on-chip system I/O bus and bus controller are provided for attachment of peripherals. Introduction The IBM AS/400* mid-range computing system, a leader in the marketplace since its inception in 1988, is designed for ease of use and the preservation of the customers' investments. More than 300000 installed systems, with software provided by some 8000 software vendors, attest to the popularity of the system. One of the major achievements of the AS/400 is its ability to maintain software compatibility while providing growth in capacity, performance, and function. To sustain a performance growth rate averaging 40% per year, the AS/400 switched from its original internal microprogrammed interface (IMPI) processor architecture to a reduced-instruction-set computing (RISC) platform. The PowerPCTM architecture was chosen as a base, with several instructions and features added to optimize performance and support unique AS/400 operating system requirements. The resulting architecture, PowerPC ASTM, is implemented on two new RISC microprocessors, the PowerPC AS A30 and the PowerPC AS AlO. The A30 is a high-performance one-way, two-way, and four-way multiprocessor for the high end of the AS/400 product line. The AlO, described here, is a uniprocessor with a broad range of performance capabilities to support entry, low-end, and mid-range traditional systems and server systems. When describing performance, AS/400 developers focus on overall system performance in the commercial environment. Typically, system performance is specified in relative performance ratio (RPR) units. The AS/400 9404	64-bit computing;application-specific integrated circuit;attachments;cmos;cpu cache;case preservation;clock skew;cluster analysis;computer compatibility;dynamic random-access memory;error detection and correction;floorplan (microelectronics);ibm system i;ibm i;input/output;integrated circuit design;kilobyte;microcode;microprocessor;multiprocessing;one-way function;operating system;parity bit;peripheral;pipeline (computing);powerpc;requirement;resilient packet ring;robustness (computer science);s-100 bus;server (computing);static random-access memory;superscalar processor;system requirements;transistor;uniprocessor system;usability;wiring	James W. Bishop;Michael J. Campion;Thomas L. Jeremiah;Stephen J. Mercier;Edmond J. Mohring;Kerry P. Pfarr;Bruce G. Rudolph;Gregory S. Still;Tennis S. White	1996	IBM Journal of Research and Development	10.1147/rd.404.0495	embedded system;computer architecture;electronic engineering;verification;processor design;engineering;operating system;integrated circuit;methodology;ibm power microprocessors;back-side bus;power architecture;technology	Arch	18.255269782265195	55.27598755284356	101061
60dc77ebdfe9442f721f0cc6fda9da56ae8c87f4	salvaging test windows in bist diagnostics	logic testing built in self test;signature analysis;module multipuce;detection erreur;analyse signature;built in self test logic testing error analysis multichip modules sequential analysis failure analysis jacobian matrices remotely operated vehicles design methodology clocks;lfsr;error signature;autoprueba;autotest;essai circuit integre;autonomous misr;misr;bist diagnostics;built in self test;multichip modules;diagnostic panne;fault diagnostic;logic testing;diagnostico pana;integrated circuit testing;stumps;logic testing stumps architecture diagnostic procedure test window bist diagnostics;error detection;analisis firma	This paper uses the STUMPS architecture to study the properties of a new diagnostic procedure. According to the old procedure, the process stops at the end of each test window to compare the measured signature against its precomputed value. The old procedure also calls for the abandonment of all future test windows after the first failing one is encountered. This is due to the unavailability of expected future test window signatures in the presence of a previously captured error. This paper shows a simple method of salvaging future test windows by adjusting their expected signatures to fit past observed errors. Experiments conducted using this new procedure reveal an improvement of at least one order of magnitude in diagnostic resolution over what has been previously experienced.	built-in self-test;microsoft windows	Jacob Savir	1998	IEEE Trans. Computers	10.1109/12.675718	embedded system;error detection and correction;linear feedback shift register;algorithm;statistics	EDA	21.336727459255716	51.44163233344944	101100
03bbadf4b8237dfd9d7101fd436c8cc4b530a72f	designing for signal integrity in wave-pipelined soc global interconnects	wave pipelined soc global interconnects;hspice;crosstalk;signal integrity;synchronisation;crosstalk voltage;system on chip crosstalk integrated circuit design integrated circuit interconnections synchronisation;integrated circuit design;signal design integrated circuit interconnections voltage clocks throughput system on a chip crosstalk driver circuits coupling circuits synchronization;system on chip;integrated circuit interconnections;wave pipelined interconnects;clock skew insensitive receiver circuit;hspice signal integrity wave pipelined soc global interconnects system on chip crosstalk voltage inductive coupling clock skew insensitive receiver circuit wave pipelined interconnects;clock skew;inductive coupling	This paper discusses the importance of wave-pipelining to enhance throughput performance and maintain good signal integrity on global interconnects in a system-on-chip (SOC). It is shown that wave-pipelining results in 50% reduction in the active line overshoot voltage and 75% reduction in the quiet line crosstalk voltage as compared to a single driver interconnect in the presence of severe inductive coupling. A clock-skew-insensitive receiver circuit to synchronize the communication on wave-pipelined interconnects between different clock domains in SOC is also proposed and validated with HSPICE	clock skew;crosstalk;electrical connection;inductive coupling;overshoot (signal);pipeline (computing);spice 2;signal integrity;speaker wire;system on a chip;throughput	Vinita V. Deodhar;Jeffrey A. Davis	2005	Proceedings 2005 IEEE International SOC Conference	10.1109/SOCC.2005.1554496	system on a chip;embedded system;synchronization;electronic engineering;real-time computing;crosstalk;inductive coupling;telecommunications;clock skew;computer science;signal integrity;integrated circuit design	EDA	16.79512609027356	56.13149108967039	101127
495be2a29e876343f16f346aeda61445ac285f55	quality versus cost analysis for 3d stacked ics	packaging;assembly;quality versus cost analysis packaging process wafer stacking wafer manufacturing 3d product quality large test flow space defective parts per million 3d stacked integrated circuit;stacking;three dimensional displays;mathematical model;stacking packaging equations mathematical model three dimensional displays assembly;three dimensional integrated circuits integrated circuit manufacture integrated circuit packaging integrated circuit testing quality control	To fulfill customer demands, IC products must satisfy the required quality generally expressed in defective parts per million (DPPM). To meet this DPPM target, appropriate test infrastructures and test approaches must be developed. This is a challenging task for 3D Stacked-ICs (3D-SIC) due to a large test flow space; each test flow may require different design-for-test features and impact the product quality and total stack cost differently. Therefore, appropriate models to predict the impact of test flows on the product quality and overall stack cost at early design stage is important for quality versus cost trade-offs. This paper presents a model that predicts the 3D product quality in terms of DPPM for different test flows and associated cost; it incorporates the quality of the wafer manufacturing, stacking and packaging process. For example, the presented case study showed that maintaining the same product quality for larger stack size might result in a significant test cost increase.	3d printing;design for testing;simplified instructional computer;stacking;wafer (electronics)	Mottaqiallah Taouil;Said Hamdioui;Erik Jan Marinissen	2014	2014 IEEE 32nd VLSI Test Symposium (VTS)	10.1109/VTS.2014.6818763	packaging and labeling;electronic engineering;engineering;stacking;mathematical model;assembly;engineering drawing;statistics	SE	23.63769731575923	55.598958407653186	101174
11e61a665ba51def74cbab0347a6818d1f2e2b9a	on minimizing the number of test points needed to achieve complete robust path delay fault testability	robustness circuit testing circuit faults propagation delay fault diagnosis logic testing logic circuits timing circuit synthesis computer science;design for testability;robust path delay fault testability;rd fault identification robust path delay fault testability test point insertion combinational circuit test generation;logic testing;test generation;path delay fault;delays combinational circuits fault diagnosis logic testing;combinational circuit;rd fault identification;test point insertion;fault identification;delays;fault diagnosis;combinational circuits	Recently, Pomeranz and Reddy [7], presented a test point insertion method to improve path delay fault testability in large combinational circuits. A test application scheme was developed that allows test points to be utilized as primary inputs and primary outputs during testing. The placement of test points was guided by the number of paths and was aimed at reducing this number. Indirectly, this approach achieved complete robust path delay fault testability in very low computation times. In this paper, we use their test application scheme, however, we use more exact measures for guiding test point insertion like test generation and RD fault identification. Thus, we reduce the number of test points needed to achieve complete testability by ensuring that test points are inserted only on paths associated with path delay faults that are necessary to be tested and that are not robustly testable. Experimental results show that an average reduction of about 70% in the number of test points over the approach of [7] can be obtained.	algorithm;combinational logic;computation;design for testing;experiment;overhead (computing);ruby document format;shannon (unit);software testability;test point	Prasanti Uppaluri;Uwe Sparmann;Irith Pomeranz	1996		10.1109/VTEST.1996.510870	reliability engineering;electronic engineering;real-time computing;fault coverage;computer science;stuck-at fault;automatic test pattern generation;test compression;mathematics;combinational logic;algorithm	EDA	21.327535845730885	51.220284636962425	101271
de8702d525fcc3cb810889954b128d2fc101c9b5	"""comments on """"test efficiency analysis of random self-test of sequential circuits"""""""	automatic testing;sequential circuits;built in self test;logic testing;integrated circuit testing;integrated logic circuits	For the original article see ibid., vol. 10, no. 3, p. 390-98 (1991). In the aforementioned paper by S. Sastry and A. Majumdar the testing effectiveness of random pattern techniques is studied and the authors claim to give complete analytical solutions to the problem of estimating such an effectiveness. The commenters point out that the analysis is based on an oversimplified circuit model, and, therefore, the conclusions are invalid. They comment on the analysis and explain its weakness, especially with respect to the built-in self-test (BIST) technique referred to as circular self-test path (CSTP). >		Slawomir Pilarski	1995	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.402504	electronic engineering;computer science;engineering;sequential logic;algorithm;statistics	EDA	22.963093742034513	51.4349163676775	101320
118f79a5d1e0d3e6881babdb967191d91448990d	network flow based multi-way partitioning with area and pin constraints	concepcion asistida;field programmable gate array;hierarchical system;computer aided design;optimisation;field programmable gate arrays partitioning algorithms programmable logic arrays logic devices design automation pins integrated circuit interconnections clustering algorithms constraint theory integrated circuit synthesis;circuit optimisation circuit layout cad logic partitioning logic cad field programmable gate arrays integrated circuit layout;interconnection;optimizacion;integrated circuit;integrated circuit layout;concepcion sistema;circuit partitioning;systeme hierarchise;circuito integrado;algorithme fbb;systeme integre;sistema integrado;indexing terms;field programmable gate array partitioning network flow based multiway partitioning area constraints pin constraints min cuts circuit partitioning fbb mw algorithm two way balanced partitioning multiple fpga partitioning;circuit a la demande;interconexion;integrated circuit design;sistema jerarquizado;custom circuit;circuito integrato personalizado;system design;interconnexion;partitionnement circuit;conception assistee;circuit layout cad;fbb algorithm;max flow min cut theorem;optimization;field programmable gate arrays;network flow;circuit optimisation;logic partitioning;logic cad;integrated system;conception systeme;circuit integre	Network flow is an excellent approach to finding min-cuts because of the celebrated max-flow min-cut theorem. However, for a long time, it was perceived as computationally expensive and deemed impractical for circuit partitioning. Only until recently, FBB [l] successfully applied network flow to two-way balanced partitioning and for the first time demonstrated that network fow was a viable approach to circuit partitioning. In this paper, we present FBB-MW, which is an extension of FBB, to solve the problem of multi-way partitioning with area and pin constraints. Experimental results show that FBB-MW outperforms the FM-based MW-part program in the TAPIR package[lO].	algorithm;analysis of algorithms;fm broadcasting;flow network;input/output;integrated circuit;max-flow min-cut theorem;maxima and minima;maximum flow problem;microwave;minimum cut;multistage interconnection networks;network partition;parallel building blocks;prince	Huiqun Liu;Martin D. F. Wong	1997		10.1145/267665.267673	embedded system;mathematical optimization;electronic engineering;real-time computing;computer science;computer aided design;algorithm;field-programmable gate array	EDA	15.977950473039241	50.53596332633591	101384
848f71975105b0570c1bcfc72b0dcc98f7e95bf8	modified pseudorandom number generators	design automation;random number generation;pseudorandom sequences;statistical test;bibliographies;logic circuits;testing;circuit topology;random numbers monte carlo techniques pseudorandom sequences short word computers;digital systems;monte carlo techniques;arithmetic;pseudorandom sequence;switching systems;random number generation testing fault diagnosis digital systems switching systems circuit topology logic circuits bibliographies design automation arithmetic;random numbers;pseudorandom number generator;short word computers;monte carlo technique;fault diagnosis	Pseudorandom number generator programs can be modified by a simple procedure which has particular advantages for the shorter word binary computers. The method combines the result of any conventional arithmetic generator with the current state of counters by means of a logic instruction. A variety of statistical tests have indicated that good results are realized.	pseudorandom number generator	Herbert C. Ratz;J. V. Hildebrand	1967	IEEE Trans. Electronic Computers	10.1109/PGEC.1967.264749	arithmetic;topology;pseudorandom generators for polynomials;linear congruential generator;statistical hypothesis testing;electronic design automation;logic gate;random number generation;computer science;theoretical computer science;pseudorandom function family;mathematics;lavarand;pseudorandom generator;software testing;random seed;pseudorandom number generator;pseudorandomness;pseudorandom generator theorem;algorithm;lagged fibonacci generator;self-shrinking generator;statistics;monte carlo method	Theory	22.0404540953148	48.82454059514078	101429
7698618029b87ef97a37c749c26faabd7608b070	symbolic layout for bipolar and mos vlsi	silicon;concepcion asistida;computer aided design;mos devices;design automation;cmos technology;very large scale integration cmos technology mos devices bicmos integrated circuits design methodology integrated circuit technology cmos logic circuits silicon design automation low voltage;mos technology;integrated circuit;very large scale integration;circuit vlsi;circuito integrado;bicmos integrated circuits;vlsi design;bipolar technology;technologie bipolaire;low voltage;design technique;vlsi circuit;integrated circuit technology;symbole;symbol;cmos logic circuits;tecnologia bipolar;conception assistee;tecnologia mos;arquitectura;circuito vlsi;simbolo;architecture;circuit integre;technologie mos;design methodology	VLSI design requires design methodologies which are tailored to the implementation technology. Symbolic layout has been addressed in the past for MOS technology, while bipolar technology has largely been ignored. This paper describes a novel symbolic design technique which addresses both bipolar and MOS technologies. The technique allows the designer to symbolically layout nMOS, CMOS, and bipolar circuit structures. The symbol set is used for both MOS and bipolar devices in an integrated and consistent way. It is closely related to the mask layout information rather than circuit schematics. Thus, it allows the creation of any circuit structure based on bipolar, MOS, CMOS, BIMOS, and BICMOS technologies. Design examples are given.	bicmos;cmos;character encoding;integrated circuit layout;nmos logic;schematic;very-large-scale integration	Kevin S. B. Szabo;James M. Leask;Mohamed I. Elmasry	1987	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.1987.1270264	embedded system;electronic engineering;electronic design automation;computer science;engineering;electrical engineering;computer aided design;symbol;very-large-scale integration;computer engineering	EDA	12.477098595732826	50.8024137473072	101468
263dc28e82b568985c245a28f06a6e2569b08a75	full-chip vectorless dynamic power integrity analysis and verification against 100uv/100ps-resolution measurement	cmos integrated circuits;power measurement circuit noise semiconductor device noise cmos technology semiconductor device manufacture electronic design automation and methodology very large scale integration circuit synthesis network on a chip power systems;100 ps full chip transient simulation vectorless dynamic power integrity analysis power integrity verification on chip power distribution network dynamic voltage fluctuations dynamic voltage drop lc resonance power ground noise analysis cmos noise measurement noise measurement resolution 0 13 micron 100 muv;circuit design;electric noise measurement integrated circuit design integrated circuit modelling integrated circuit noise integrated circuit measurement transient analysis circuit simulation cmos integrated circuits;electric noise measurement;vlsi design;noise measurement;transient analysis;chip;integrated circuit design;circuit simulation;integrated circuit modelling;noise analysis;integrated circuit noise;high performance;power distribution network;integrated circuit measurement;semiconductor manufacturing	The advances in semiconductor manufacturing, EDA tools, and VLSI design technologies are enabling circuit designs with increasingly higher speed and density. However, this trend is causing the on-chip power distribution network to experience larger dynamic voltage fluctuations due to dynamic voltage drop, L di/dt noise, and/or LC resonance. As a result, the analysis of power-integrity, as well as the evaluation and calibration of the analysis methodology, has become a major challenge in designing high-performance circuits. An innovative vectorless dynamic power-ground noise analysis approach is discussed in this paper. This approach addresses full-chip complexity with transistor-level accuracy. This analysis approach demonstrated very good correlation with an on-chip supply noise measurement in 0.13-/spl mu/m CMOS technology, capable of achieving 100 /spl mu/V/100 ps resolution.	cmos;resonance;semiconductor device fabrication;transistor;very-large-scale integration	Shen Lin;Makoto Nagata;Kenji Shimazake;Kazuhiro Satoh;Masaya Sumita;Hiroyuki Tsujikawa;Andrew T. Yang	2004	Proceedings of the IEEE 2004 Custom Integrated Circuits Conference (IEEE Cat. No.04CH37571)	10.1109/CICC.2004.1358869	chip;embedded system;electronic engineering;telecommunications;computer science;engineering;noise measurement;electrical engineering;circuit design;very-large-scale integration;cmos;semiconductor device fabrication;integrated circuit design	EDA	23.389040673063146	55.447211695903654	101477
bf35d097fdce5c13a9d9dc361e9a9142786eace9	increasing test coverage in a vlsi design course	design for testability;circuit faults;very large scale integration circuit testing circuit faults automatic test pattern generation built in self test costs sequential analysis redundancy design for testability materials testing;very large scale integration;automatic test pattern generation;sequential analysis;materials testing;vlsi design;built in self test;redundancy;test coverage;circuit testing	VLSI Designers know so little about testing that the large, multi-national corporations frequently higher test experts to advise their designers on test problems. The companies even pay a higher salary to the testing experts than to their VLSI Designers. The author's position is that three lectures in every VLSI Design course should be devoted to test. The first lecture would touch briefly on Test Economics, in order to motivate the students to take an interest in testing problems and costs. This lecture would also include introductory Fault Modeling for stuck-faults, delay-faults (transition and path), bridging faults, MOS Transistor Faults, and IDDQ Faults. Industry uses all of these faults in production testing. The second lecture would cover Fault Simulation, as well as Combinational and Sequential automatic test-pattern generation (ATPG) and the reason for redundancy removal (to avoid masking of testable faults). The focus of this lecture should not be on the various algorithms, but rather on the test generation and fault simulation process. This will train the students in redundancy removal techniques, and teach them how to facilitate test generation by removing testability problems from their designs. The final lecture should be on design for testability (DFT). This would cover Full and Partial Scan, as well as the JTAG 1149 Boundary Scan Standard. Scan is included because a very high percentage of designs will employ some form of scan. In addition, built-in self-testing (BIST) should be introduced in this lecture, but details would be omitted. BIST is important, because industry and leading academics project that BIST may appear in 90% of the chips in 11 years. If additional time is available, I would suggest a fourth lecture on Testability Measures, and how they can be used by the designer, to eliminate test generation problems, predict fault coverages, and accelerate ATPG programs.	algorithm;boundary scan;bridging (networking);built-in self-test;combinational logic;design for testing;iddq testing;jtag;simulation;software testability;test case;transistor;very-large-scale integration	Michael L. Bushnell	1999	International Test Conference 1999. Proceedings (IEEE Cat. No.99CH37034)	10.1109/TEST.1999.805865	reliability engineering;embedded system;electronic engineering;simulation;fault coverage;engineering;electrical engineering;automatic test pattern generation;test compression;very-large-scale integration;algorithm;statistics;computer engineering	EDA	21.868656118707474	53.338775103930956	101513
87bc8f1fa1053a4da7cdc103b965be0dad6b2d49	simulation and sat based atpg for compressed test generation	embedded cores;respin;computability;automatic test pattern generation;circuit faults automatic test pattern generation vectors benchmark testing algorithm design and analysis computer architecture integrated circuit modeling;interconnected embedded cores sat based atpg compressed test generation respin architecture satisfiability based techniques symbolic simulation;satisfiability;test compression;computability automatic test pattern generation;symbolic simulation;respin atpg satisfiability symbolic simulation test compression embedded cores;atpg	This paper presents a novel ATPG algorithm directly producing compressed test patterns. It benefits both from the features of satisfiability-based techniques and symbolic simulation. The ATPG is targeted to architectures comprised of interconnected embedded cores, particularly to the RESPIN architecture. We show experimentally that the proposed ATPG significantly outperforms the state-of-the-art approaches in terms of the test compression ratio.	algorithm;bitstream;embedded system;experiment;fault coverage;overhead (computing);symbolic simulation;test card;test compression	Jiri Balcarek;Petr Fiser;Jan Schmidt	2013	2013 Euromicro Conference on Digital System Design	10.1109/DSD.2013.56	computer architecture;computer science;theoretical computer science;automatic test pattern generation;algorithm	EDA	19.232668435375892	50.11977457328992	101569
a4d2a94b4379fdf70a9f448407723717660e351d	circuit design for carbon nanotube field effect transistors	c carbon nanotube field effect transistors graphene fet cmos technology current density chemical stability short channel effects large scale integration logic design;cmos integrated circuits;carbon nanotube field effect transistors;logic design;cntfets logic gates silicon delay;integrated circuit design;large scale integration;logic design carbon nanotube field effect transistors cmos integrated circuits current density integrated circuit design large scale integration;carbon nanotube fet;low power design;digital circuits;carbon nanotube fet low power design digital circuits;current density	Carbon nanotube field-effect transistors (CNFETs) and more recently graphene FETs are currently being researched as a replacement of CMOS in the near future due to their physical characteristics such as achievable current density, high speed, high-K compatibility, chemical stability, and low short channel effects. Historically, we have seen many cases that new devices disappeared because of the lack of design methodology for large scale integration (LSI). In this tutorial paper, we introduce circuit integration schemes by using CNFETs for future LSI design.	cmos;circuit design;field effect (semiconductor);graphene;high-κ dielectric;integrated circuit;transistor	Haiqing Nan;Wei Wang;Ken Choi	2012	2012 International SoC Design Conference (ISOCC)	10.1109/ISOCC.2012.6407113	carbon nanotube field-effect transistor;materials science;electronic engineering;electrical engineering;nanotechnology;integrated injection logic	EDA	12.25740870352445	57.61545144140309	101606
bbbec654a8ee5ed56b9103cb5fe42bbc2e66c67a	a 10t non-precharge two-port sram reducing readout power for video processing	non precharge sram;cycle time;8t sram cell;random access memory;power saving;tecnologia electronica telecomunicaciones;two port networks;static random access memory;memoria acceso directo;cell size;integrated circuit;execution time;video signal processing;10t sram cell;readout electronics;two port sram;video processing;circuito integrado;memoire acces direct statique;circuit 2 acces;iot sram cell;correlation spatiale;low power;spatial correlation;correlacion espacial;memoire acces direct;low power electronics;onduleur;inverter;traitement signal video;temps execution;low power sram;ondulador;power reduction;dispositif a memoire;electronique de mesure;tecnologias;tiempo ejecucion;grupo a;electronique faible puissance;memory devices;circuit integre;transistor	We propose a low-power non-precharge-type two-port SRAM for video processing that exploits statistical similarity in images. To minimize the charge/discharge power on a read bitline, the proposed memory cell (MC) has ten transistors (10T), comprised of the conventional 6T MC, a readout inverter and a transmission gate for a read port. In addition, to incorporate three wordlines, we propose a shared wordline structure, with which the vertical cell size of the 10T MC is fitted to the same size as the conventional 8T MC. Since the readout inverter fully charges/discharges a read bitline, there is no precharge circuit on the read bitline. Thus, power is not consumed by precharging, but is consumed only when a readout datum is changed. This feature is suitable to video processing since image data have spatial correlation and similar data are read out in consecutive cycles. As well as the power reduction, the prechargeless structure shortens a cycle time by 38% compared with the conventional SRAM, because it does not require a precharge period. This, in turn, demonstrates that the proposed SRAM operates at a lower voltage, which achieves further power reduction. Compared to the conventional 8T SRAM, the proposed SRAM reduces a charge/discharge possibility to 19% (81% saving) on the bitlines. As the measurement result, we confirmed that the proposed 64-kb video memory in a 90-nm process achieves an 85% power saving on the read bitline, when considered as an H.264 reconstructed image memory. The area overhead is 14.4%. key words: 8T SRAM cell, 10T SRAM cell, low-power SRAM, nonprecharge SRAM, two-port SRAM, video processing	cell (microprocessor);discharger;geodetic datum;h.264/mpeg-4 avc;inverter (logic gate);low-power broadcasting;memory cell (binary);overhead (computing);power inverter;static random-access memory;transistor;transmission gate;video ram (dual-ported dram);video processing	Hiroki Noguchi;Yusuke Iguchi;Hidehiro Fujiwara;Shunsuke Okumura;Yasuhiro Morita;Koji Nii;Hiroshi Kawaguchi;Masahiko Yoshimoto	2008	IEICE Transactions	10.1093/ietele/e91-c.4.543	embedded system;electronic engineering;spatial correlation;real-time computing;static random-access memory;cycle time variation;computer science;engineering;electrical engineering;integrated circuit;video processing;inverter;transistor;low-power electronics	Arch	18.197266815478354	56.006004345563696	101710
3d233ca9b6d042b4d2e4f1774acee9f2a4883978	an error-controlled methodology for approximate hierarchical symbolic analysis	symbol manipulation;flow graphs;analog circuits;circuit analysis computing symbol manipulation analogue circuits flow graphs;error control;equations analog circuits circuit analysis circuit synthesis character generation performance analysis error correction libraries contracts iterative methods;analogue circuits;symbolic analysis;circuit analysis computing;matrix based error control error controlled methodology approximate hierarchical symbolic analysis large analog circuits approximation strategies circuit reduction graph based symbolic solution circuit equations;hierarchical model	Limitations of existing approaches for symbolic analysis of large analog circuits are discussed. To address their solution, a new methodology for hierarchical symbolic analysis is introduced. 'lke combination of a hierarchical modeling technique and approximation strategies, comprising circuit reduction, graph-based symbolic solution of circuit equations and matrix-based error control, provides optimum results in terms of speed and quality of results.	analogue electronics;approximation algorithm;error detection and correction;quality of results	Oscar Guerra;J. D. Rodríguez-García;Elisenda Roca;Francisco V. Fernández;Ángel Rodríguez-Vázquez	2000		10.1109/ISCAS.2000.856014	equivalent circuit;a symbolic analysis of relay and switching circuits;analogue electronics;computer science;theoretical computer science;machine learning;symbolic data analysis;circuit extraction;symbolic trajectory evaluation;algorithm;hierarchical database model	EDA	21.081657129046732	46.414407084392906	101798
febb04b6c96a607a01fa17e9753cdf6c855958ce	the inadequacy of the stuck-at fault model for testing mos lsi circuits: a review of mos failure mechanisms and some implications for computer-aided design and test of mos lsi circuits	circuit cad;fault location;field effect integrated circuits;integrated circuit testing;large scale integration;d-algorithm;mos lsi circuits;automatic test pattern generation;computer aided testing;computer-aided design;digital circuit testing;failure mechanisms;stuck-at fault model;testing	The stuck-at fault model is widely used as the basis for automatic test pattern generation in digital circuit testing, for example the D-algorithm. However, there have been growing doubts over the ability of the model to cover faults that occur in MOS LSI circuits. The paper consists of a review of the failure mechanisms that produce faults in MOS LSI circuits, a discussion of the problems that arise when using the stuck-at fault model to test MOS LSI circuits and a set of guidelines for the future development of computer-aided design and test of such circuits.	computer-aided design;failure cause;fault model;integrated circuit;stuck-at fault	N. Burgess;Robert I. Damper	1984	Software & Microsystems		electronic engineering;real-time computing;fault coverage;d*;computer science;engineering;stuck-at fault;automatic test pattern generation;computer aided design;software engineering;fault model;software testing;computer engineering	EDA	22.879511763081062	53.21382731165506	102136
116936883ae9b43be0e0fb82d5788caafd6080b4	efficient global fault collapsing for combinational library modules.		—Fault collapsing is the process of reducing the number of faults by using redundance and equiva-lence/dominance relationships among faults. Exact global fault collapsing can be easily applied locally at the logic gates, however, it is often ignored for library modules due to its high demand of resources such as execution time and/or memory. In this paper, we present an efficient and exact global fault collapsing method for library modules that uses both binary decision diagrams and fault simulation with random vectors. Experimental results show that the new method reduce the number of faults drastically with feasible resources and produce significantly better results than existing approaches.	binary decision diagram;combinational logic;decision problem;logic gate;run time (program lifecycle phase);simulation	Hussain Al-Asaad	2007			computer architecture;real-time computing;algorithm	EDA	21.029414001085694	50.30751317830558	102174
809188ed329391483224ebd0288682e3ac351efc	bus architecture synthesis for hardware-software co-design of deep submicron systems on chip	system on a chip routing application software computer architecture system level design algorithm design and analysis network synthesis network topology analog digital conversion delay;hardware software codesign;hardware software co design;jpeg soc bus architecture synthesis hardware software codesign system on chip deep submicron effect resource constrained embedded application bus topology network processor;network processor;system buses;computer architecture;computer architecture system buses system on chip hardware software codesign;system on chip;system level design	System level design always has a disadvantage of not possess ing detailed knowledge of the communication sub-system. Th is is a crucial issue for System-on-Chip design, where uncertainty in communication by very deep submicron effects cann ot be neglected. This paper presents a bus architecture (BA) sy nthesis algorithm for designing the communication sub-syst em of an SoC. The algorithm is part of a hardware-software codesign methodology for resource constrained embedded applications. BA synthesis includes finding the bus topology, and routing the individual buses so that various constraints, l ike bus length, topology complexity, potential for communicat ion conflicts over time, are addressed. The paper presents BA syn thesis results for a network processor, and a JPEG SoC.	algorithm;bus network;business architecture;device driver synthesis and verification;dr. web;embedded system;feasible region;internet key exchange;jpeg;level design;mpsoc;network processor;place and route;placement (eda);requirement;routing;simulated annealing;system on a chip;time complexity;very-large-scale integration	Nattawut Thepayasuwan;Vaishali Damle;Alex Doboli	2003		10.1109/ICCD.2003.1240884	system on a chip;bus;embedded system;computer architecture;parallel computing;computer science;local bus;system bus;electronic system-level design and verification;control bus;back-side bus;network processor	EDA	12.96733618255957	52.12461436213345	102189
9f9eafb26444b8d37d0249a88747b72f07762b14	estimating the efficiency of collaborative problem-solving, with applications to chip design	automated design;computer aided design;design criteria;satisfiability;chip;collaborative problem solving;functional unit	We present a statistical framework to address questions that arise in general problems involving collaboration of several contributors. One instance of this problem occurs in the complex process of designing ultralarge-scale-integration (ULSI) semiconductor chips. In these processes, computeraided design tools are treated as “black boxes.” In most cases, the automated design tools operate on designs and successfully complete a specified task to create designs that satisfy specified design criteria. In other cases involving complex designs, however, the tools are unable to create designs that satisfy the specified criteria. In both situations, the performance of the tools can be enhanced with systematic external intervention that is implemented with some supplemental algorithm. This algorithm can either be fully automated or be implemented by hand, relying on formally describable human expertise. In this intervention, the supplemental algorithm and the automated design tool take turns to move the design from one configuration to another until either the task is complete or further improvements are not possible or necessary. In such a setting, a number of questions arise about how to measure the effectiveness of the external intervention. One question, for example, is whether the external intervention consistently assists the progress of the automated program. This situation is an instance of a general problem that we address in this paper. As an example, we apply the statistical framework to the problem of routing a functional unit of the IBM POWER4 microprocessor.	algorithm;black box;computer program;computer-aided design;design tool;electronic design automation;entity;execution unit;interaction;microprocessor;power4;problem solving;routing;semiconductor;statistical model;very-large-scale integration	Mary Y. L. Wisniewski;Emmanuel Yashchin;Robert L. Franch;David P. Conrady;Giovanni Fiorenza;I. Cevdet Noyan	2003	IBM Journal of Research and Development	10.1147/rd.471.0077	chip;simulation;telecommunications;computer science;systems engineering;engineering;operating system;computer aided design;management science;satisfiability	EDA	10.772483837659228	52.004206438307406	102213
0f269d3d6331b742381f5650b645ba0a9130941b	partition, packing and clock distribution: a new paradigm of physical design	graph theory;design automation;clocks;very large scale integration;physical design;clock distribution;large scale integration;registers;integrated circuit interconnections;clocks very large scale integration timing delay algorithm design and analysis integrated circuit interconnections registers graph theory design automation large scale integration;algorithm design and analysis;timing	3. TIMING: We introduce a new paradigm of semi-synchronous circuits, where the constraint that every clock shall arrive at the same time to all the registers is relaxed. It is shown that a clock distribution following an appropriate clock schedule can make the period far shorter than the maximum delay between gates, which is the lower bound in conventional synchronous architecture. Ideas for timing-delay based layout are presented. Theoretical background and practical approaches with experiments are addressed.	experiment;global serializability;physical design (electronics);programming paradigm;semiconductor industry;set packing	Yoji Kajitani;Atsushi Takahashi;Kengo R. Azegami;Shigetoshi Nakatake	2000		10.1109/ICVD.2000.812577	physical design;embedded system;algorithm design;computer architecture;electronic engineering;real-time computing;electronic design automation;computer science;graph theory;very-large-scale integration;processor register	EDA	16.494812489458923	51.37822815102527	102306
b6ad34aba0c7f7f4e62fdc51e2b808c88e1e707f	fault coverage estimation by test vector sampling	digital circuit;observability;concepcion asistida;metodo estadistico;computer aided design;sampling methods circuit faults probability circuit testing delay estimation circuit simulation computational modeling combinational circuits performance evaluation observability;detection probability;observabilities;test vector sampling;probability;performance evaluation;circuit faults;caracteristique temporelle;longest path delay faults;integrated circuit;etude theorique;fault coverage estimation;fault models;transition probability;high confidence lower bound;essai automatique;longest path;circuito integrado;prueba automatica;statistical method;vector sampling error;detection probability fault coverage estimation test vector sampling statistical technique combinational circuits delay fault coverage true value simulation transition probabilities observabilities fault detection probabilities fault models transition faults path delay faults longest path delay faults vector sampling error high confidence lower bound;transition faults;time curve;delays combinational circuits fault diagnosis logic testing probability observability statistical analysis;circuit numerique;circuit simulation;computational modeling;transition probabilities;statistical analysis;methode statistique;true value simulation;fault detection;logic testing;circuito numerico;estudio teorico;caracteristica temporal;conception assistee;path delay fault;fault coverage;circuit testing;statistical technique;temps retard;path delay faults;statistical techniques;delay time;theoretical study;sampling methods;fault model;fault detection probabilities;tiempo retardo;automatic test;delay estimation;circuit integre;delay fault coverage;delays;fault diagnosis;combinational circuits	We develop a new statistical technique for estimating delay fault coverage in combinational circuits. True value simulation is performed for a sample of vector pairs chosen randomly from the test set. Transition probabilities and observabilities are estimated from the simulation data. These allow us to estimate fault detection probabilities per vector pair. Fault models considered are the transition faults, path delay faults, and the longest path delay faults. We analyze the vector sampling error and nd a high-con dence lower bound for the detection probability that is used to compute the fault coverage for the entire vector set. Experimental results show that vector sampling can provide a close approximation to other methods. It requires reduced computing resources compared to other statistical methods. The savings over fault simulation is even greater. 1 1 2 3 4 1Manuscript received . 2Keerthi Heragu and Vishwani D. Agrawal are with AT&T Bell Laboratories, Room 2C-476, 600 Mountain Ave., Murray Hill, NJ 07974. 3Michael L. Bushnell is a Professor in the Elec. and Comp. Eng. Dept., Rutgers University, P.O. Box 909, Piscataway, NJ 08855-0909. 4This research was supported by the Electrical and Computer Engineering Department of Rutgers University.	approximation;combinational logic;computer engineering;electrical engineering;fault coverage;fault detection and isolation;fault model;kosterlitz–thouless transition;longest path problem;naruto shippuden: clash of ninja revolution 3;randomness;sampling (signal processing);simulation;test set;test vector	Keerthi Heragu;Vishwani D. Agrawal;Michael L. Bushnell	1995	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.384421	sampling;markov chain;electronic engineering;real-time computing;observability;fault coverage;longest path problem;integrated circuit;computer aided design;probability;fault model;mathematics;combinational logic;computational model;digital electronics;fault detection and isolation;statistics	EDA	23.17576565523974	51.0930916868825	102313
7b51e7f0632dbccdddbd90dce68785c66bbe51ad	17.1 a 10nm finfet 128mb sram with assist adjustment system for power, performance, and area optimization	microprocessors;random access memory;random access memory high definition video computer architecture microprocessors finfets resistance circuit stability;resistance;circuit stability;finfets;computer architecture;high definition video;sram chips logic design mosfet circuits;size 10 nm power consumption mobile application processor sram minimum operating voltage write ability bit cell stability advanced process nodes limited process knobs finfet technology sram design assist circuits power performance and area gain ppa gain	The power consumption of a mobile application processor (AP) is strongly limited by the SRAM minimum operating voltage, VMIN [1], since the 6T bit cell must balance between write-ability and bit cell stability. However, the SRAM VMIN scales down gradually with advanced process nodes due to increased variability. This is evident with the quantized device-width and limited process-knobs of a FinFET technology, which has greatly affected SRAM design [2-4]. Therefore, assist-circuits are more crucial in a FinFET technology to improve VMIN, which in turn adds to the Power, Performance, and Area (PPA) gain of SRAM.	bit cell;mathematical optimization;mobile app;spatial variability;static random-access memory	Taejoong Song;Woojin Rim;Sunghyun Park;Yongho Kim;Jonghoon Jung;Giyong Yang;Sanghoon Baek;Jaeseung Choi;Bongjae Kwon;Yunwoo Lee;Sungbong Kim;Gyu-Hong Kim;Hyo-Sig Won;Ja-Hum Ku;Sunhom Steve Paak;E. S. Jung;Steve Sungho Park;Kinam Kim	2016	2016 IEEE International Solid-State Circuits Conference (ISSCC)	10.1109/ISSCC.2016.7418029	electronic engineering;parallel computing;real-time computing;computer science;engineering;resistance	EDA	18.500494065737612	59.6384953379708	102410
7d052ce07918e66f6d65c7d5106b3b0595174925	a clocking strategy for scalable and fault-tolerant qdca signal distribution in combinational and sequential devices		A signal distribution network (SDN) for Quantum-dot Cellular Automata (QDCA) devices is described. This network allows the distribution of a set of inputs to an arbitrary number of outputs in any desired order, overcoming the challenges associated with wire crossings that have faced QDCA systems in the past. The proposed signal distribution network requires only four distinct clock signals, regardless of the number of inputs or outputs, and those clock signals each repeat a very simple pattern. This network is highly scalable, completing the distribution of N inputs to an arbitrary number of distributed signals in 4N – 2 clock cycles. The operation of this device is demonstrated by applying it to a two-input/one-output XOR gate and a three-input/two-output full adder. A modified SDN customized for use with sequential devices is also shown.	clock rate;combinational logic	Douglas Tougaw	2014		10.1007/978-3-662-43722-3_4	electronic engineering;parallel computing	EDA	23.53082572645676	50.229449415234896	102584
e30a219274551ef05f47b168e72b7bb274f47c9f	more moore landscape for system readiness - itrs2.0 requirements	lithography itrs pids more moore roadmap device interconnect;integrated circuit design cmos integrated circuits;more moore;interconnect;lithography;moore landscape power aware device system scaling moore s law cmos itrs2 0;roadmap;pids;performance evaluation logic gates silicon strain finfets electrostatics;itrs;device	CMOS scaling enabled simultaneous system throughput scaling by concurrent delay, power, and area shrinks with thanks to Moore's law. System scaling is getting more difficult with the limitations in interconnect and bandwidth per power as well as the difficulties and cost of monolithic integration. This requires a holistic approach for an optimal balance of performance and power under the limits of technology. This paper covers a portfolio of More Moore technologies for power-aware device enabling value proposition for system scaling - where requirements and gaps will be addressed in the ITRS2.0 roadmap.	cmos;holism;image scaling;moore's law;requirement;throughput	Mustafa Badaroglu;Kwok Ng;Mehdi Salmani Jelodar;SungGeun Kim;Gerhard Klimeck;Chorng-Ping Chang;Charles Cheung;Yuzo Fukuzaki	2014	2014 IEEE 32nd International Conference on Computer Design (ICCD)	10.1109/ICCD.2014.6974674	lithography;electronic engineering;engineering;electrical engineering;interconnection	EDA	11.93122750402488	57.50898855584949	102621
408ec0c3163b2faa595dda585b93f928ac648c42	two-level logic synthesis on pal-based cpld and fpga using decomposition	kernel;decomposition;standard pal20v8 devices two level logic synthesis pal based cpld fpga decomposition pal based structure kernel three state output buffers decomp system partitioning benchmark circuits pal based logic blocks;logic design;logic field programmable gate arrays virtual reality decision support systems;logic;decomp system;partitioning;virtual reality;fpga;pal based logic blocks;two level logic synthesis;logic synthesis;benchmark circuits;decision support systems;logic testing;pal based structure;field programmable gate arrays;field programmable gate arrays logic design logic testing;pal based cpld;standard pal20v8 devices;three state output buffers	The PAL-based structure constitutes the kernel of many CPLD and FPGA devices. The problem of appropriate decomposition of the whole devices under design into suitable parts which can be realized as single PAL-based logic blocks containing the limited number of terms, is one of basic problems of the synthesis process. The method of two-level logic synthesis that makes use of three-state output buffers constituting the additional internal resources of logic blocks, is presented in this paper. Developed algorithms, implemented within the Decomp system, have been used for partitioning the benchmark circuits due to realization by means of the PAL-based logic blocks with the given number of terms. Synthesis of benchmark circuits for standard PAL20V8 devices has also been carried out and the obtained results have been compared to the ones published previously.	complex programmable logic device;field-programmable gate array;logic synthesis;pal	Dariusz Kania	1999		10.1109/EURMIC.1999.794480	computer architecture;electronic engineering;logic synthesis;real-time computing;logic optimization;logic family;programmable logic array;computer science	EDA	12.598554977105916	46.581776613981724	102716
3574e36022f2a6a58f774b3ac51fa3ba305b4e6a	arithmetic optimization for custom instruction set synthesis	carry logic;parallel multipliers;optimisation;critical path delay arithmetic optimization custom instruction set synthesis hardware structures arithmetic hardware logic synthesis technique;logic synthesis technique;optimisation adders carry logic computer architecture critical path analysis instruction sets;network synthesis;critical path analysis;logic design;custom instruction set synthesis;computer aided instruction;hardware structures;wires;logic circuits;prior knowledge;data mining;birth disorders;computer architecture;logic synthesis;arithmetic optimization;adders;critical path;arithmetic hardware;digital arithmetic;optimization;circuits;critical path delay;logic gate;benchmark testing;circuit synthesis;adders circuit synthesis delay hardware network synthesis birth disorders digital arithmetic logic design logic circuits computer aided instruction;instruction sets;hardware	One of the ways that custom instruction set extensions can improve over software execution is through the use of hardware structures that have been optimized at the arithmetic level. Arithmetic hardware, in many cases, can be partitioned into networks of full-adders, separated by other logic that is better expressed using other types of logic gates. In this paper we present a novel logic synthesis technique that optimizes networks of full adders and is intended for use in the context of custom instruction set synthesis. Unlike earlier work (e.g., Three Greedy Approach [1], [2]) our approach does not require any prior knowledge about the functionality of the circuit. The proposed technique automatically infers the use of carry-save arithmetic, when appropriate, and suppresses its use when unfavorable. Our approach reduces the critical path delay through networks of full adders, when compared to the Three Greedy Approach, and in some cases, reduces the cell area as well.	adder (electronics);critical path method;greedy algorithm;logic gate;logic synthesis;mathematical optimization	Ajay K. Verma;Yi Zhu;Philip Brisk;Paolo Ienne	2009	2009 IEEE 7th Symposium on Application Specific Processors	10.1109/SASP.2009.5226336	computer architecture;parallel computing;logic synthesis;logic gate;computer science;theoretical computer science;critical path method	EDA	15.032187828402318	48.68671028258496	102796
710296474a7699a9ea31ea5041425b62ffe38dae	mimicking of functional state space with structural tests for the diagnosis of board-level functional failures	silicon;clocks mimics silicon circuit faults aerospace electronics logic gates phase locked loops;circuit faults;functional testing;clocks;automatic test equipment;phase locked loops;functional scan;mimicking;a coverage;structural testing;functional failure;structural tests;logic gates;state space;linear time;aerospace electronics;automatic test equipment mimicking functional state space structural tests diagnosis board level functional failures;board level functional failures;functional state space;functional state space a coverage board level diagnosis functional failure functional scan;diagnosis;mimics;board level diagnosis;industrial design	A common scenario in industry today is “No Trouble Found” (NTF) due to functional failures. A component on a board fails during board-level functional test, but it passes the Automatic Test Equipment (ATE) test when it is returned to the supplier for warranty replacement or service repair. To find the root cause of NTF, we define an innovative deterministic test, namely functional scan test. We also propose two approaches for using functional scan test to adequately mimic functional state space. The first approach allows us to select a given number of initial states in linear time and functional scan tests resulting from these selected states are used to mimic the functional state space effectively. The second approach adopts a state-injection technique. Experiments on an industry design show that by using either multiple initial states or state injection, functional scan test with appropriate functional constraints can mimic the functional state space well, measured by appropriate coverage metrics. Therefore, it is feasible to use functional scan test to detect board-level functional failures in a controlled deterministic environment and diagnose the root cause to faulty wires/gates inside a component. It is also shown that the proposed method outperforms a random method in selecting the given number of effective initial states.	baseline (configuration management);built-in test equipment;computational complexity theory;experiment;functional programming;functional testing;national transfer format;selection algorithm;state space;time complexity;turing test	Hongxia Fang;Zhiyuan Wang;Xinli Gu;Krishnendu Chakrabarty	2010	2010 19th IEEE Asian Test Symposium	10.1109/ATS.2010.78	structural engineering;time complexity;reliability engineering;automatic test equipment;electronic engineering;phase-locked loop;industrial design;logic gate;computer science;state space;engineering;functional testing;silicon	SE	21.715181280829327	52.67473331620059	102845
cd9cbe934a20e69b3cca0cb1b83e734af74cd27b	programmable floating gate fpaa switches are not dead weight	reconfigurable system;reconfigurable architectures;floating gate;reconfigurable architectures field programmable analogue arrays;field programmable analogue arrays;large scale;associative memory;field programmable analog arrays switches nonvolatile memory field programmable gate arrays switching circuits large scale systems circuit synthesis routing virtual colonoscopy coupling circuits;computational area efficiency programmable floating gate fpaa switches associated memory cell programmable conductances computational elements synthesized circuits computational dead weight	"""In most reconfigurable systems, such as FPAAs and FPGAs, the switch element and its associated memory cell is a necessary overhead for performing computation with the active components. However, floating gate based switches in large-scale FPAAs can be programmed anywhere between simple """"off"""" and """"on"""" connections, which allows these programmable conductances to be used as computational elements within synthesized circuits. This decreases the notion of switches as computational dead weight and increases the potential computational area efficiency within FPAAs"""	computation;field-programmable analog array;field-programmable gate array;integrated circuit;memory cell (binary);network switch;overhead (computing)	Christopher M. Twigg;Jordan D. Gray;Paul E. Hasler	2007	2007 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2007.378248	embedded system;electronic engineering;computer hardware;programmable logic array;computer science;content-addressable memory	Arch	12.516048736201894	52.35492483802509	102867
ae669f555897e3456ece3cdf635abccbde90e714	low-leakage and process-variation-tolerant write-read disturb-free 9t sram cell using cmos and finfets	low leakage;static random access memory sram;subthreshold operation;low leakage bulk cmos fin shaped field effect transistor finfet static random access memory sram subthreshold operation;sram cells finfets cmos integrated circuits delays leakage currents cmos technology;voltage 500 mv process variation tolerant write read disturb free 9t sra cell low leakage write read disturb free 9t sra cell soc products finfets bulk cmos technology low leakage power single ended write read operation serial transistor assembly stacking effect write noise margin read write failure probability 6t sram cell design fin shaped field effect transistors power consumption read write stability leakage reduction size 22 nm;fin shaped field effect transistor finfet;system on chip cmos memory circuits mosfet sram chips;bulk cmos	For 22nm SoC products, we propose a 9T SRAM cell with low voltage operation and low leakage power using Bulk CMOS and FinFETs. This is achieved by adopting single-ended write & read operation and serial transistor assembly for stacking effect. Proposed cell is designed and simulated in CMOS 22nm technology and results shows that proposed 9T cell achieves 42.2% improvement in write noise margin, 30.1% and 24.7% reduction in read & write power respectively,10^7 times reduced read and write failure probabilities, 31.8% reduced leakage current when compared to Conventional 6T SRAM cell design. Also, designing SRAM cells using fin-shaped field effect transistors shows more process variation tolerance and improvement of ~23% in power consumption, 2.04 times read SNM at VDD=500mV over CMOS design counterpart. Leakage reduction and enhanced read-write stability of proposed cell are verified under process variations. Also, proposed cell is observed to have 32% larger layout area when compared to Conv. 6T design.	cmos;cell (microprocessor);field effect (semiconductor);flash memory;noise margin;read-write memory;single-ended signaling;spectral leakage;stacking;static random-access memory;transistor	Ayushparth Sharma;Kusum Lata	2016	2016 17th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2016.7479201	embedded system;electronic engineering;parallel computing;engineering	EDA	17.712148511018395	59.360483144032244	102983
f73a753e664a9e230715bc738cf2a04e91dd401c	optimal backgrounds selection for multi run memory testing	memory architecture circuit testing;optimal solution;experimental analysis;memory background selection;multirun memory testing;semiconductor memory;maintenance;dissimilarity measure;memory testing;automatic testing;fault detection computer science built in self test semiconductor memory digital systems maintenance automatic testing test pattern generators;built in self test;test pattern generators;memory architecture;pattern sensitive fault;digital systems;fault detection;march test algorithm;binary vector dissimilarity measure;optimal background selection;fault coverage;circuit testing;computer science;binary vector dissimilarity measure optimal background selection multirun memory testing pattern sensitive fault fault coverage march test algorithm memory background selection	Conventional memory tests based on only one run have constant and low faults coverage especially for pattern sensitive faults (PSF). To increase faults coverage the multiple run March test algorithms have been used. As have been shown earlier the key element of multiple run March test algorithms are memory backgrounds. Only in a case of optimal set of backgrounds the high fault coverage can be achieved. In this paper the constructive algorithm for optimal set of memory backgrounds selection is proposed. The backgrounds selection is based on the binary vectors dissimilarity measures. The optimal solutions have been obtained for the cases of two, three and four runs memory testing. Theoretical and experimental analysis has been done which allow to prove the efficiency of proposed technique.	algorithm;fault coverage;random-access memory	Ireneusz Mrozek;Vyacheslav N. Yarmolik	2008	2008 11th IEEE Workshop on Design and Diagnostics of Electronic Circuits and Systems	10.1109/DDECS.2008.4538812	semiconductor memory;fault coverage;computer science;electrical engineering;theoretical computer science;machine learning;fault detection and isolation;algorithm;experimental analysis of behavior	EDA	20.764620843530533	52.00213118081814	103120
3375bc91a73ebc284d7f1ecf1e01a1f8aef80f09	reliability analysis for flexible electronics: case study of integrated a-si: h tft scan driver	flexible electronics;reliability;thin film;scan driver design reliability experimentation reliability flexible electronics threshold voltage amorphous hydrogenated silicon a si h thin film transistor;operant conditioning;tft circuit reliability simulation;circuit design;consumer electronics;spice simulation;tft scan driver;circuit reliability;tft scan driver flexible electronics thin film transistors flexible circuit design tft circuit reliability simulation spice simulation;threshold voltage;amorphous hydrogenated silicon a si h;thin film transistors circuit reliability flexible electronics;thin film transistors;design;reliability analysis;flexible circuit design;experimentation;thin film transistor;scan driver;analytical model;flexible electronics thin film transistors driver circuits circuit simulation analytical models substrates spice plastic films thin film circuits consumer electronics	Flexible electronics fabricated with thin-film and bendable substrates (e.g., plastic) have great potential for novel applications in consumer electronics such as flexible displays, e-paper, and smart labels; however, the key elements --- namely thin-film transistors (TFTs) --- often suffer from electrical instability. Therefore, thorough reliability analysis is critical for flexible circuit design to ensure that the circuit would operate reliably throughout its lifetime. In this paper, we propose a methodology for a-Si:H TFT circuits' reliability simulation. We show that: (1) the threshold voltage (VTH) shift of a single TFT can be modeled by analyzing its operating conditions and (2) the circuit lifetime can be predicted accordingly using SPICE. We also propose an algorithm to reduce the simulation time by orders of magnitude with negligible accuracy loss. To validate our analytical model and simulation methodology, we compare the SPICE simulation results with the actual measurements of our integrated a-Si:H TFT scan driver fabricated on the glass substrate and demonstrate very high consistency in the overall results.	algorithm;circuit design;electronic paper;flexible circuit;flexible display;flexible electronics;instability;reliability engineering;spice;simulation;smart label;thin-film transistor;thin-film-transistor liquid-crystal display	Tsung-Ching Huang;Huai-Yuan Tseng;Chen-Pang Kung;Kwang-Ting Cheng	2007		10.1145/1278480.1278718	embedded system;electronic engineering;thin-film transistor;electrical engineering;statistics	EDA	21.797461828458786	56.79787864738277	103351
9137efd6114626e374cdb0bc37bb746d848cf165	fault detection in bilateral arrays of combinational cells	combinational cells;preset test sequences bilateral arrays combinational cells design for reliability design parameters fault detection functional faults linear growth;design parameters;linear growth;single cell;fault detection;design for reliability;bilateral arrays;functional faults;preset test sequences	Sufficient conditions are derived that make multidimensional bilateral arrays of combinational cells easily testable for single faults. These conditions are easily implemented during the initial design of the arrays. No restrictions are made on the interconnection patterns or directions of signal flow in the arrays. The conditions are equally applicable to synchronous and asynchronous arrays. No assumptions of stability are made. Any functional fault in a single cell will be detected as long as the failed cell is still combinational. The test sequence is preset and grows linearly with the size of the array.	bilateral filter;combinational logic;interconnection;synchronization (computer science)	F. Gail Gray;Richard A. Thompson	1978	IEEE Transactions on Computers	10.1109/TC.1978.1675029	real-time computing;computer science;fault detection and isolation;algorithm	Visualization	22.806874205760643	48.922941550497335	103376
016ed10b39f73fc77d8770228d9bdfdc1efcd1cc	a 3.15pj/cyc 32-bit risc cpu with timing-error prevention and adaptive clocking in 28nm cmos	size 28 nm static signoff timing energy efficiency minimal safety margins clock stretching near threshold voltage theoretical minimum energy point ultralow voltage operation cmos adaptive clocking timing error prevention risc cpu word length 32 bit;timing clocks cmos digital integrated circuits integrated circuit design integrated circuit reliability low power electronics microprocessor chips reduced instruction set computing;clocks latches timing pipelines cmos integrated circuits central processing unit adaptation models	The increased performance from technology scaling makes it feasible to operate digital circuits at ultra-low voltages without the significant performance limitation of earlier process generations. The theoretical minimum energy point resides in near-threshold voltages in current processes, but device and environment variations make it a challenge to operate the circuits reliably. This paper presents an ASIC implementation of a 32-bit RISC CPU in 28nm CMOS employing timing-error prevention with clock stretching to enable it to operate with minimal safety margins while maximizing energy efficiency. Measurements show 3.15pJ/cyc energy consumption at 400mV/2.4MHz, which corresponds to 39% energy savings and 83% EDP reduction compared to operation based on static signoff timing.	32-bit;application-specific integrated circuit;cmos;central processing unit;clock rate;cyc;die shrink;digital electronics;electronic data processing;error detection and correction;heart rate variability;image scaling;power management;ripple effect	Markus Hiienkari;Jukka Teittinen;Lauri Koskinen;Matthew J. Turnquist;Mikko Kaltiokallio	2014	Proceedings of the IEEE 2014 Custom Integrated Circuits Conference	10.1109/CICC.2014.6946095	embedded system;electronic engineering;real-time computing;computer science;static timing analysis	EDA	18.86993509354464	58.40647322777653	103418
5603b8b27b8f76113f1955ca577ec1edae403410	clock-aware placement for large-scale heterogeneous fpgas		A modern FPGA often contains an ASIC-like clocking architecture which is crucial to achieve better skew and performance. Existing conventional FPGA placement algorithms seldom consider clocking resources, and thus may lead to clock routing failures. To address the special FPGA clocking architecture, this paper presents a novel clock-aware placement algorithm for large-scale heterogeneous FPGAs. Our algorithm consists of three major stages: (1) a nonlinear global placement framework with clock fence region construction, (2) a clock-aware packing scheme, and (3) clock-aware legalization and detailed placement. We evaluate our results based on the 2017 ISPD Clock-Aware Placement Contest benchmark suite. Compared with the top three winners, the results show that our algorithm achieves the best overall routed wirelength. On average, our algorithm outperforms the top-3 winners by 3.6%, 7.5%, and 12.9% in routed wirelength, respectively.	algorithm;application-specific integrated circuit;benchmark (computing);binary file;clock rate;field-programmable gate array;international symposium on physical design;mathematical optimization;network congestion;nonlinear system;routing;set packing;smoothing	Yun-Chih Kuo;Chau-Chin Huang;Shih-Chun Chen;Chun-Han Chiang;Yao-Wen Chang;Sy-Yen Kuo	2017	2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1109/ICCAD.2017.8203821	computer science;real-time computing;architecture;field-programmable gate array;parallel computing;greedy randomized adaptive search procedure;skew;set cover problem	EDA	14.625429543327673	52.80650841800794	103691
48fb4b22f4a6d8659d5177b62ec83ba8f8819aff	nanoscale digital computation through percolation	random graph;nanoscale digital computation;logic synthesis percolation nanoscale digital computation;defect tolerance nanoscale digital computation synthesis technique digital computation nanoscale lattice random interconnect percolation theory random graph boolean functionality error margin nonlinearity steepness;boolean functions;interconnections;boolean function;usa councils;data mining;error margin;digital computation;nanoscale lattice;servers;logic synthesis;percolation;permission;computational logic;synthesis technique;percolation theory;random interconnect;boolean functionality;defect tolerance;electronic countermeasures;percolation boolean functions interconnections;nonlinearity steepness	In this study, we apply a novel synthesis technique for implementing robust digital computation in nanoscale lattices with random interconnects: percolation theory on random graphs. We exploit the non-linearity that occurs through percolation to produce Boolean functionality. We show that the error margins, defined in terms of the steepness of the non-linearity, translate into the degree of defect tolerance. We study the problem of mapping Boolean functions onto lattices with good error margins.	computation;electrical connection;nonlinear system;percolation theory;random graph;software bug	Mustafa Altun;Marc D. Riedel;Claudia Neuhauser	2009	2009 46th ACM/IEEE Design Automation Conference	10.1145/1629911.1630070	combinatorics;electronic engineering;discrete mathematics;continuum percolation theory;computer science;theoretical computer science;mathematics;boolean function;algorithm	EDA	19.139461152508158	46.64845832165683	103854
4ebaa23c74bc970cc49304d9ae4f6e66e3b5a291	path delay fault testing of ics with embedded intellectual property blocks	integrated circuit;intellectual property;automatic testing;automatic testing fault diagnosis industrial property delays multiplexing equipment logic testing integrated circuit testing vlsi;logic testing path delay fault testing embedded intellectual property blocks multiplexers primary ports circuit paths;multiplexing equipment;intellectual property multiplexing integrated circuit testing circuit faults delay effects digital signal processing time to market semiconductor devices semiconductor device testing production;logic testing;integrated circuit testing;vlsi;path delay fault;industrial property;delays;fault diagnosis	In this paper we show that the already known method of using multiplexers for making the inputs and outputs of the embedded blocks accessible by the primary ports of the Integrated Circuit (IC) can be used for path delay fault testing of the IC. We show that the testing of the IC for path delay faults can be reduced to the testing of each block. Intellectual Property (IP) blocks are treated as black boxes. The number of the circuit paths that must be tested is almost equal to the sum of the paths that must be tested for each block.	approximation;black box;embedded system;integrated circuit;multiplexer	Dimitris Nikolos;Haridimos T. Vergos;Themistoklis Haniotakis;Yiorgos Tsiatouhas	1999		10.1145/307418.307468	embedded system;electronic engineering;real-time computing;computer science;engineering;integrated circuit;very-large-scale integration;intellectual property	EDA	21.837657556075655	52.2838897149188	103881
548a18461bfeba50cb8dfede668fdf9a15ebca71	a highly reliable nbti resilient 6t sram cell		0026-2714/$ see front matter 2012 Elsevier Ltd. A http://dx.doi.org/10.1016/j.microrel.2012.11.003 ⇑ Corresponding author. E-mail address: jawar@iiitdmj.ac.in (J. Singh). In this work, a highly reliable six-transistor (6T) Static Random Access Memory (SRAM) cell is proposed. The proposed SRAM cell is resilient to Negative Bias Temperature Instability (NBTI), since, PMOS pull-up transistors are replaced by their counterpart NMOS pull-up transistors. We compared the different parameters and performance indices (static noise margin and energy per operation) of the proposed SRAM cell with the standard 6T and loadless 4T SRAM cells. In order to achieve full logic level in the proposed SRAM cell, we studied the effect of PMOS as access transistors and compared with the loadless 4T SRAM cells with and without NBTI effect. It is observed that the proposed PMOS access transistors based SRAM cell yield better reliability (120% improvement in read SNM) with marginal increase in energy per operation as compared to NMOS access transistors. The leakage current of the proposed SRAM cell is 57 less than the 4T SRAM cell. The proposed SRAM cell design has positive impact of NBTI stress and yields significant improvement in the SRAM cell reliability as compared to its counterpart standard 6T SRAM cell. 2012 Elsevier Ltd. All rights reserved.	cell (microprocessor);computer data storage;gnu nano;logic level;marginal model;memory cell (binary);nmos logic;negative-bias temperature instability;noise margin;pmos logic;random access;spectral leakage;static random-access memory;transistor	Jawar Singh;N. Vijaykrishnan	2013	Microelectronics Reliability	10.1016/j.microrel.2012.11.003	electronic engineering;parallel computing;real-time computing	EDA	18.55431739500268	59.53447499408928	104006
b6d5ed753bf5d0885b7ee2b61844d60bf295b02a	advances in wafer level packaging (wlp)	wafer level packaging	Wafer level packages (WLPs) with various design configurations are rapidly gaining tremendous applications throughout semiconductor industry due to small-form factor, low-cost, and high performance. Because of the innovative production processes utilized in WLP manufacturing and the accompanying rise in the price of gold, the traditional wire bonding packages are no longer as attractive as they used to be. In addition, WLPs provide the smallest form factor to satisfy multifunctional device requirements along with improved signal integrity for today’s handheld electronics. Existing wire bonding devices can be easily converted to WLPs by adding a redistribution layer (RDL) during backend wafer level processing. Since the input/output (I/O) pads do not have to be routed to the perimeter of the die, the WLP die can be designed to have a much smaller footprint as compared to its wire bonding counterpart, which means more area-array dies can be packed onto a single wafer to reduce overall processing costs per die. Conventional (fan-in) WLPs are formed on the dies while they are still on the uncut wafer. The result is that the final packaged product is the same size as the die itself. Recently, fan-out WLPs have emerged. Fan-out WLP starts with the reconstitution or reconfiguration of individual dies to an artificial molded wafer. Fan-out WLPs eliminate the need of expensive substrate as in flip-chip packages, while expanding the WLP size with molding compound for higher I/O applications without compromising on the board level reliability. Essentially, WLP enables the next generation of portable electronics at a competitive price. Many future products using through-silicon-via (TSV) technology will be packaged as WLPs. There have been relatively few publications focused on the latest results of WLP development and research. Many design guidelines, such as material selection and geometry dimensions of under bump metallurgy (UBM), RDL, passivation and solder alloy, for optimum board level reliability performance of WLPs, are still based on technical know-how gained from flip-chip or wire bonding BGA reliability studies published in the past two decades. However, WLPs have their unique product requirements for design guidelines, process conditions, material selection, reliability tests, and failure analysis. In addition, WLP is also an enabling technology for 3D package and system-in-package (SIP), justifying significant research attention. The timing is therefore ripe for this edition to summarize the state-of-the-art research advances in wafer level packaging in various fields of interest. Integration of WLP in 3D packages with TSV or wireless proximity communication (PxC), as well as applications in Microelectromechanical Systems (MEMS) packaging and power packaging, will be highlighted in this issue. In addition, the stateof-the-art simulation is applied to design for enhanced package and board level reliability of WLPs, including thermal cycling test,	ball grid array;bump mapping;die (integrated circuit);failure analysis;fan-in;fan-out;flip chip;input/output;microelectromechanical systems;mobile computing;mobile device;multi-function printer;next-generation network;perimeter;proximity communication;redistribution layer;report definition language;requirement;routing;semiconductor industry;signal integrity;simulation;small form factor;system in package;thermal copper pillar bump;through-silicon via;wafer-level packaging;wire bonding	Tong Yan Tee;Xuejun Fan;Yi-Shao Lai	2010	Microelectronics Reliability	10.1016/j.microrel.2010.02.012	wafer backgrinding;die preparation;engineering;physics	EDA	12.099957476813936	58.201334291445654	104142
4d54502335a8388750dcd260c336c8a486749816	dynamic quaternary circuit with neuron-mos transistor	quaternary circuit;cmos integrated circuits;mos devices;cmos circuit neuron mos transistor quaternary circuit dynamic logic circuit;neuron mos transistor;size 0 35 mum dynamic quaternary circuit neuron mos transistor neuron mos based dynamic circuit two phase clocks voltage mode quaternary logic dynamic quaternary inverter cmos hspice tsmc;inverters;dynamic logic circuit;logic gates;threshold voltage;cmos circuit;transistors;spice cmos integrated circuits logic circuits logic design logic gates mosfet circuits;couplings;transistors logic gates threshold voltage mos devices inverters cmos integrated circuits couplings	A neuron-MOS-based dynamic circuit scheme with two-phase clocks for realizing voltage-mode quaternary logic, is proposed. The dynamic quaternary inverter and literal circuits are designed, and the standard CMOS process with a 2-ploy layer is adopted without any modification of the thresholds. In the proposed circuits, the problem of floating output nodes is solved. The proposed circuits have some other favorable properties including the less complex structure, full logic swing, low propagation delay and no static power consumption. All the proposed circuits are verified by HSPICE simulation results with TSMC 0.35μm 2-ploy 4-metal CMOS technology.	cmos;literal (mathematical logic);logic gate;neuron;power inverter;propagation delay;spice 2;simulation;software propagation;transistor;two-phase commit protocol	Guoqiang Hang;Yang Yang;Xuanchang Zhou;Xiaohui Hu;Danyan Zhang	2015	2015 11th International Conference on Computational Intelligence and Security (CIS)	10.1109/CIS.2015.39	and-or-invert;logic probe;nmos logic;diode–transistor logic;adiabatic circuit;asynchronous circuit;logic gate;logic family;depletion-load nmos logic;pass transistor logic;diode-or circuit;integrated injection logic;coupling;pull-up resistor;threshold voltage;cmos;digital electronics;inverter;pmos logic;transistor;resistor–transistor logic;emitter-coupled logic	EDA	17.21105042070692	57.23574153332332	104143
ad96fb42c13cb0249d1576c6c0e4e60d9a354db7	networks-on-chip topology optimization subject to power, delay, and reliability constraints	topology;network topology constraint optimization network on a chip power system reliability energy consumption delay particle swarm optimization telecommunication traffic voltage binary trees;system reliability;reliability;traffic distribution;particle swarm optimization technique;network on chip;edge failure;voltage swing;distributed processing;topology optimization;optimization problem;network topology;power consumption circuit reliability network topology network on chip particle swarm optimisation;h 263 encoder mp3 decoder networks on chip topology optimization network power consumption packet transmission delay system reliability particle swarm optimization technique network topology architecture traffic distribution processing element mapping noise power voltage swing edge failure;particle swarm optimizer;circuit reliability;network topology architecture;processing element mapping;optimization;h 263 encoder mp3 decoder;power consumption;noise power;digital audio players;power demand;particle swarm optimisation;packet transmission delay;network power consumption;networks on chip topology optimization	In this paper, we present a novel approach in Networks-on-Chip topology optimization, by considering the network power consumption, packet transmission delay, and system reliability, simultaneously. We use the Particle Swarm Optimization technique to acquire the most suitable topology architecture, which achieves maximum reliability as well as minimum delay and power consumption. The optimization problem, which considers six design variables: network topology architecture, traffic distribution, processing elements' mapping, noise power, voltage swing, and probability of edge failure, is validated through a case study of an H.263-encoder MP3-decoder.	best, worst and average case;ibm 727;mathematical optimization;network on a chip;network packet;network topology;noise power;optimization problem;particle swarm optimization;topology optimization;worst-case scenario	Haytham Elmiligi;Ahmed A. Morgan;M. Watheq El-Kharashi;Fayez Gebali	2010	Proceedings of 2010 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2010.5537194	control engineering;optimization problem;multi-swarm optimization;topology optimization;electronic engineering;real-time computing;computer science;engineering;reliability;network on a chip;noise power;network topology	EDA	15.81389767701042	55.01254202817981	104360
0401b13b3e95b46669bbb8c727a96d592616ff16	on the reliability of majority logic structure in quantum-dot cellular automata	qca defects;reliability;fault tolerant logic;quantum dot cellular automata qca;majority voter;qca tiles	Quantum-dot cellular automata (QCA) is projected to be a promising nanotechnology due to its extremely small feature size and ultra low power consumption. However, acceptance of a QCA design is limited due to its high defect rate. Efficient fault tolerant schemes are, therefore, needed for reliable design. This work targets design of a new fault tolerant scheme around QCA logic primitives which encapsulates two different orientations of QCA cell. A 2×2 array of four rotated ('+') cells, called complementary tile (CT), is introduced to maximize the throughput. It ensures 100% fault tolerance under single cell missing defect. Two reliable majority voters (RMV), based on the CT, are designed which outperforms the existing majority logic in QCA. The functional characterization and polarization of RMV under different cell deposition (missing/additional) defects are covered. The significance of the clocking in fault tolerance is also investigated with RMV with multi clock zone. The error probability model for the proposed RMV, under cell deposition (missing/additional) defect, is developed to ensure better understanding of reliability in QCA. HighlightsA fault tolerant architecture design based on complementary tile in QCA Nanotechnology.The proposed model ensures high fault tolerance under single missing cell defect providing no other deviation from the ideal architecture than the fact of the missing cell.A reliability estimation model for QCA is proposed in this paper.Fault tolerance of majority is extended to circuit-level.	automata theory;quantum dot cellular automaton	Bibhash Sen;Yashraj Sahu;Rijoy Mukherjee;Rajdeep Kumar Nath;Biplab K. Sikdar	2016	Microelectronics Journal	10.1016/j.mejo.2015.11.002	electronic engineering;engineering;theoretical computer science;reliability;algorithm	Logic	11.00623102386937	59.22130336579525	104443
b4fd2e8eb9c0a7037c314cd27c568370b36575ce	impact of back gate biasing schemes on energy and robustness of ulv logic in 28nm utbb fdsoi technology	cmos integrated circuits;integrated circuit design;low-power electronics;silicon-on-insulator;cmos fdsoi;mep;nmos;pmos;utbb fdsoi technology;asymmetric back biasing;design space;forward back biasing scheme;minimum energy point;size 28 nm;subthreshold logic;ultra-low voltage logic;28nm;cmos fdsoi;back gate biasing;die yield;robustness;subthreshold logic;ultra-low power;ultra-low-voltage	Minimum energy per operation is typically achieved in the subthreshold region where low speed and low robustness are two challenging problems. This paper studies the impact of Back Biasing (BB) schemes on these features for FDSOI technology. We show that Forward BB can help cover a wider design space in term of optimal frequency of operation while keeping minimum energy. Asymmetric BB between NMOS and PMOS can mitigate the effect of systematic mismatch on Minimum Energy Point (MEP) and robustness. With optimal asymmetric BB, we achieve either a MEP reduction up to 18% or a 36X speedup at the MEP.	biasing;cmos;clock rate;die shrink;embedded system;energy level;heart rate variability;media-embedded processor;messaging pattern;nmos logic;pmos logic;spatial variability;speedup;ultra-low-voltage processor	Guerric de Streel;David Bol	2013	International Symposium on Low Power Electronics and Design (ISLPED)		embedded system;electronic engineering;computer science;engineering;electrical engineering;operating system;silicon on insulator;cmos;low-power electronics;robustness;integrated circuit design	Arch	18.359803236258195	58.452680165567564	104465
50a71461e7193518f8dc6143957ead4ec6bc2e2a	structural tests of slave clock gating in low-power flip-flop	power sensitive applications;defective behavior;clock gating circuit;clocks;latches layout clocks;automatic test pattern generation;flip flops;slave clock gating;level sensitive scan design structural tests slave clock gating low power flip flop master latch slave latch clock gating circuit power sensitive applications power consumption defective behavior cell internal states automatic test pattern generation flip flop cell two latch version;layout;clock gating;structural testing;cell internal states;level sensitive scan design;low power;structural tests;slave latch;structural test;logic testing;low power electronics;low power electronics automatic test pattern generation flip flops logic testing;diagnosis slave clock gating low power flip flop structural test;flip flop cell;latches;power consumption;automatic test pattern generator;diagnosis;two latch version;flip flop;master latch;low power flip flop	A novel slave clock-gating technique in [5] is designed to save power when the master and slave latches of a low-power flip-flop reach certain correlated states (e.g., both latches are at logic 0 or 1). Testing this clock-gating circuit is essential for power-sensitive applications, but is also very challenging. This is because power consumption increase is its only defective behavior, and it involves cell internal states, both of which are unfriendly to general automatic test-pattern generation (ATPG). This paper proposes an innovative method to test the slave clock-gating circuitry structurally with slight modification of the flop cell. The implementation on a two-latch version of a level-sensitive scan design (LSSD) flip-flop and its capability of extending to other types of flip-flop cells are presented.	cell (microprocessor);clock gating;electronic circuit;flops;flip-flop (electronics);low-power broadcasting;slave clock	Baosheng Wang;Jayalakshmi Rajaraman;Kanwaldeep Sobti;Derrick Losli;Jeff Rearick	2011	29th VLSI Test Symposium	10.1109/VTS.2011.5783730	layout;embedded system;electronic engineering;real-time computing;computer science;engineering;automatic test pattern generation;clock gating;low-power electronics	EDA	19.974599671022393	53.524926873528976	104783
12a3de5f7e2bd4f0f44e4320d134d0c54c3291b2	energy minimization using multiple supply voltages	minimisation;dynamic programming;concepcion asistida;computer aided design;programacion dinamica;power supply circuits;data path;processor scheduling;data flow graphs;reconvergent fanout;circuit vlsi;dynamic program;indexing terms;flow graphs;power supply;algorithme;algorithm;data flow graph;vlsi circuit;time factors;low power;dynamic allocation;alimentation electrique;energy consumption;scheduling;critical path;functional pipelining;voltage;programmation dynamique;level shifter;puissance faible;conception assistee;scheduling problem;data flow computing;ordonamiento;energy cost;multiple supply voltages;energy minimization;asignacion dinamica;circuito vlsi;alimentacion electrica;allocation dynamique;voltage time factors processor scheduling data flow computing dynamic programming dynamic scheduling flow graphs energy consumption throughput costs;multiple supply voltage scheduling;input pattern;ordonnancement;scheduling dynamic programming minimisation data flow graphs pipeline processing power supply circuits;pipeline processing;energy saving;dynamic scheduling;throughput;algoritmo;potencia debil;time constraint;input pattern energy minimization dynamic programming multiple supply voltage scheduling functional pipelining data path data flow graph reconvergent fanout level shifter	We present a dynamic programming technique for solving the multiple supply voltage scheduling problem in both non-pipelined and functionally pipelined data-paths. The scheduling problem refers to the assignment of a supply voltage level to each operation in a data ow graph so as to minimize the average energy consumption for given computation time or throughput constraints or both. The energy model is accurate and accounts for the input pattern dependencies, re-convergent fanout induced dependencies, and the energy cost of level shifters. Experimental results show that using four supply voltage levels on a number of standard benchmarks, an average energy saving of 53% (with a computation time constraint of 1.5 times the critical path delay) can be obtained compared to using one xed supply voltage level.	benchmark (computing);computation;critical path method;dynamic programming;energy minimization;fan-out;scheduling (computing);throughput;time complexity	Jui-Ming Chang;Massoud Pedram	1997	IEEE Trans. VLSI Syst.	10.1109/92.645070	embedded system;job shop scheduling;minimisation;throughput;electronic engineering;parallel computing;real-time computing;voltage;index term;logic level;dynamic priority scheduling;computer science;critical path method;computer aided design;dynamic programming;data-flow analysis;energy minimization;scheduling;algorithm	EDA	17.033788672541537	53.20731533502111	104892
942698026d7c10f7fef9f9ec0c8bd9dbc5e7f9a4	early power-aware design & validation: myth or reality?	quality management;power analysis;process design;design;design optimization;performance;design process;measurement;verification;risk management	Design for low power is crucial for developing and optimizing complex SoCs. Typically, power issues are tackled at the gate-level and backend stages, disconnected from micro-architectural power features or RTL. However, there is growing debate about which stage of the design process is best for dealing with power issues. Leaders associated with the EDA industry and R&D realm will debate whether early power-aware design and validation is viable, and will hold a spirited discussion to determine at which stage of the design process power issues should be tackled: gate level and below, or system level. They will cover various issues involved in automating or establishing a well understood flow/process that delivers quality results, and also will consider organizational hurdles. Attendees will leave this session armed with key questions and valuable insights, and will be challenged to consider if they should change their approach to low-power design.	low-power broadcasting;system on a chip	Gila Kamhi;Sarah Miller;Stephen Bailey Mentor;Wolfgang Nebel;Y. C. Wong;Juergen Karmann;Enrico Macii;Stephen V. Kosonocky;Steve Curtis	2007	2007 44th ACM/IEEE Design Automation Conference		process design;embedded system;design;quality management;electronic engineering;verification;simulation;power analysis;design process;risk management;performance;systems engineering;engineering;electrical engineering;measurement	EDA	10.107338575836643	55.60340246130547	104940
228a37148c037e2e9f1c99c39161e75e089aa6c1	diagnosis and characterization of timing-related defects by time-dependent light emission	time dependent;integrated circuit;flip chip devices;automatic testing;circuit switched;timing circuit testing spatial resolution packaging wiring frequency failure analysis integrated circuit testing cmos logic circuits time factors;failure analysis;failure analysis timing fault diagnosis flip chip devices integrated circuit testing automatic testing wiring;resistive path timing related defects time dependent light emission flip chip packaging multiple hierarchical wiring planes ultra high frequencies light pulses circuit switching circuit characterization timing failure;flip chip;integrated circuit testing;ultra high frequency;wiring;fault diagnosis;timing	Technologikal advances such as flip-chip packaging, multiple hierarchical wiring planes, and ultra-high frequencLrs reduce the effectiveness of conventional diagnostic techniques. It has recently been demonstrated that light pulses emitted during circuit switching can be ussd to characterize the behavior of integrated circuits. In this paper, a new method of circuit characterization usins1 this technique is described. An example of the diagnosis of a timing failure caused by a resistive path to a singlle transistor is described.	circuit switching;flip chip;integrated circuit;timing failure;transistor;wiring	Daniel R. Knebel;Pia Sanda;Moyra K. McManus;Jeffrey A. Kash;James C. Tsang;David P. Vallett;Leendert M. Huisman;Phil Nigh;Rick Rizzolo;Peilin Song;Franco Motika	1998		10.1109/TEST.1998.743254	embedded system;flip chip;failure analysis;electronic engineering;real-time computing;telecommunications;computer science;engineering;ultra high frequency;integrated circuit;circuit extraction;static timing analysis;circuit switching	EDA	22.840661897027502	53.77876101393005	104986
b8fbd85f05301c575fcd44d7b933d71117d335a3	faar: a router for field-programmable analog arrays	electrical capacitance tomography;design automation;interconnect parasitics;field programmable analog arrays;identity based encryption;routing;single segment vertical routing resources;programmable switches;multiterminal networks;sequential routing technique;multi terminal nets;faar;network routing;integrated circuit design;field programmable analog arrays routing identity based encryption electrical capacitance tomography integrated circuit interconnections field programmable gate arrays design automation electronic switching systems reactive power analog integrated circuits;field programmable analog array;two terminal pairs;integrated circuit interconnections;analog integrated circuits;execution times faar field programmable analog arrays routability single segment horizontal routing resources single segment vertical routing resources target array based fpaa architecture sequential routing technique multi terminal nets two terminal pairs resource demand programmable switches interconnect parasitics performance degradation;routing algorithm;electronic switching systems;circuit cad;integrated circuit design analogue processing circuits network routing circuit cad multiterminal networks integrated circuit interconnections;target array based fpaa architecture;field programmable gate arrays;performance degradation;analogue processing circuits;resource demand;execution times;single segment horizontal routing resources;routability;reactive power	In this paper, we address the routability and analog performance issues involved in routing for array-based FPAAs that have single-segment horizontal and vertical routing resources. We then present FAAR (Field-programmable Analog Array Router) and describe a routing algorithm developed for the target array-based FPAA architecture. Sequential routing technique is used for routing multi-terminal nets as well as multiple nets. Multi-terminal nets are broken into two-terminal pairs and routed. We use the notion of resource demand as a measure of the effect of a net-route on the routing of the other nets, while the number of programmable switches and the net-crossings are used as the metrics of interconnect parasitics. We present experiments to study the effect of various parameters such as the number of nets, terminals, CABs and IO cells on the routing as well as the performance degradation. FAAR routes with high efficiency while keeping performance degradation small, and has considerably short execution times.	algorithm;elegant degradation;experiment;field-programmable analog array;network switch;router (computing);routing;terminal emulator	Sree Ganesan;Ranga Vemuri	1999		10.1109/ICVD.1999.745213	routing table;embedded system;routing;enhanced interior gateway routing protocol;electronic engineering;static routing;real-time computing;electronic design automation;equal-cost multi-path routing;computer science;engineering;dynamic source routing;multipath routing;destination-sequenced distance vector routing;routing protocol;link-state routing protocol;metrics;routing information protocol	EDA	14.544710089270593	52.06901418858275	104994
8ae214ace6709a39e4e3206db5295bb014e79472	large within-die gate delay variations in sub-threshold logic circuits at low temperature	voltage 0 3 v subthreshold logic circuits temperature dependence within die random gate delay variations cmos test chips size 40 nm;logic circuits;temperature delay variations device matrix array dma sub threshold;logic gates;cmos logic circuits;delay circuits;logic testing;temperature;logic gates delays temperature measurement temperature dependence semiconductor device measurement integrated circuit modeling voltage measurement low voltage;temperature cmos logic circuits delay circuits logic circuits logic gates logic testing	Temperature dependence of 256 within-die random gate delay variations in sub-threshold logic circuits is measured in 40-nm CMOS test chips. When the temperature is reduced from 25 <sup>°</sup>C to -40<sup>°</sup>C, the sigma/average (σ/μ) of the gate delay at 0.3 V increases by 1.4 times. A newly developed model shows that σ/μ of the gate delay is proportional to 1/<i>T</i> for the first time, where <i>T</i> is the absolute temperature.	best, worst and average case;cmos;logic gate;propagation delay	Ryo Takahashi;Hidehiro Takata;Tadashi Yasufuku;Hiroshi Fuketa;Makoto Takamiya;Masahiro Nomura;Hirofumi Shinohara;Takayasu Sakurai	2012	IEEE Transactions on Circuits and Systems II: Express Briefs	10.1109/TCSII.2012.2231038	and-or-invert;electronic engineering;nmos logic;real-time computing;diode–transistor logic;logic level;delay calculation;logic gate;logic family;programmable logic array;depletion-load nmos logic;engineering;electrical engineering;pass transistor logic;superconducting logic;integrated injection logic;pull-up resistor;cmos;digital electronics;inverter;pmos logic;resistor–transistor logic;emitter-coupled logic	EDA	22.227589145780527	55.639830195127935	105078
ceee71ce8ae2e72014f3cc0db7e1fc64f0a1066b	state of the art and challenges for test and reliability of emerging nonvolatile resistive memories			resistive touchscreen	Elena I. Vatajelu;Peyman Pouyan;Said Hamdioui	2018	I. J. Circuit Theory and Applications	10.1002/cta.2418	mathematics;electronic engineering;magnetoresistive random-access memory;resistive random-access memory;resistive touchscreen	EDA	16.14431503215087	59.9354413538441	105130
ca76022c99d30e3500f087e84663ab0b746d9f2a	an easily testable routing architecture of fpga	test method design for testability homogeneous architecture;test configuration testable routing architecture programmable lsi automatic test pattern generator device testing general island style fpga architecture;design for testability;circuit faults;clocks;routing;automatic test pattern generation;wires;testing;tiles field programmable gate arrays routing testing circuit faults clocks wires;large scale integration;logic testing;logic testing automatic test pattern generation field programmable gate arrays large scale integration;homogeneous architecture;tiles;test method;field programmable gate arrays	Generally, a programmable LSI such as an FPGA is difficult to test compared to an ASIC. There are two major reasons for this. One is that automatic test pattern generator (ATPG) cannot be used because of the programmability of the FPGA. The other reason is that the FPGA architecture is very complex. In this paper, we propose a new FPGA architecture that will simplify the testing of the device. The base of our architecture is general island-style FPGA architecture, but it consists of a few types of circuit blocks and orderly wire connections. This paper also presents efficient test configurations for our proposed architecture. We tested the interconnects of our architecture by using our configurations and achieved 100% test coverage for a short test time.	application-specific integrated circuit;electrical connection;fault coverage;field-programmable gate array;routing;test card	Masahiro Iida;Kazuki Inoue;Motoki Amagasaki;Toshinori Sueyoshi	2011	2011 IEEE/IFIP 19th International Conference on VLSI and System-on-Chip	10.1109/VLSISoC.2011.6081661	reference architecture;embedded system;space-based architecture;computer architecture;electronic engineering;engineering;fpga prototype	EDA	11.43582532410409	52.69596599442507	105155
25d42e65f5c55dd18ede84316c3b2bef1998a699	routing a multi-terminal critical net: steiner tree construction in the presence of obstacles	graph theory;theory and practice;integrated circuit layout;multiterminal networks;trees mathematics;network routing;network topology;obstacle avoidance;routing very large scale integration algorithm design and analysis wires polynomials computer science solid modeling computational modeling design automation logic;vlsi;circuit layout cad;circuit layout cad multiterminal networks trees mathematics vlsi integrated circuit layout network routing graph theory network topology;steiner tree;heuristic trees multi terminal critical net steiner tree construction vlsi routing routing instance obstacle avoiding rectilinear trees graph problem obstacle border segments	This paper presents a new model for VLSI routing in the presence of obstacles, that transforms any routing instance from a geometric problem into a graph problem. It is the first model that allows computation of optimal obstacle-avoiding rectilinear Steiner trees in time corresponding to the instance size (the number of terminals and obstacle border segments) rather than the size of the routing area. For the most common multi-terminal critical nets-those with three or four terminals-we observe that optimal trees can be computed as efficiently as good heuristic trees, and present algorithms that do so. For nets with five or more terminals, we present algorithms that heuristically compute obstacle-avoiding Steiner trees. Analysis and experiments demonstrate that the model and algorithms work well in both theory and practice.	algorithm;computation;experiment;heuristic;regular grid;routing;steiner tree problem;very-large-scale integration	Joseph L. Ganley;James P. Cohoon	1994		10.1109/ISCAS.1994.408768	routing table;routing;combinatorics;static routing;discrete mathematics;steiner tree problem;computer science;graph theory;theoretical computer science;multipath routing;destination-sequenced distance vector routing;mathematics;obstacle avoidance;integrated circuit layout;very-large-scale integration;link-state routing protocol;routing;network topology	Theory	15.463994278863893	51.05425346664108	105377
250964876befb854567907b8eb55e4e3286ee350	variation-aware aging analysis in digital ics	negative bias temperature instability;integrated circuit yield;variation aware aging analysis error rate regression analysis standard deviation principal component analysis monte carlo based transistor level simulations nbti negative bias temperature instability hci hot carrier injection aging effects circuit yield circuit reliability av aging variations pv process variations cmos devices digital ic;aging threshold voltage integrated circuit modeling human computer interaction analytical models transistors correlation;process variation pv aging variation av hot carrier injection hci negative bias temperature instability nbti;cmos digital integrated circuits;regression analysis cmos digital integrated circuits error statistics hot carriers integrated circuit reliability integrated circuit yield monte carlo methods negative bias temperature instability principal component analysis;principal component analysis;error statistics;hot carriers;regression analysis;integrated circuit reliability;monte carlo methods	As CMOS devices become smaller, the process variations (PVs) and aging variations (AVs) become major issues for circuit reliability and yield. In this paper, we analyze the effects of PVs on aging effects such as hot carrier injection (HCI) and negative bias temperature instability (NBTI). Using Monte Carlo-based transistor-level simulations including principal component analysis, the correlations between PVs and AVs are considered, by which the accuracy of analysis is improved (1.2% for standard deviation and 1.7% for Vth99%) compared to other methods that ignore the correlations, especially in the smaller technology. In addition, we perform regression analysis with various models to improve the efficiency of variation-aware aging analysis. All models show an error rate about 1% for NBTI, and quadratic and custom models show an error rate of about 10% on average for HCI.	cmos;calculus of variations;hot-carrier injection;human–computer interaction;monte carlo method;negative-bias temperature instability;principal component analysis;simulation;transistor	Sangwoo Han;Byung-Su Kim;Juho Kim	2013	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2012.2228886	negative-bias temperature instability;econometrics;electronic engineering;computer science;engineering;electrical engineering;hot-carrier injection;regression analysis;statistics;monte carlo method;principal component analysis	EDA	21.346782183382967	58.8571590534644	105471
8c32d04a1a62909c56882ff8419b6619c247b8f6	signal processing methods and hardware-structure for on-line characterization of thermal gradients in many-core processors	thermal gradients characterization;thermal management packaging;hardware structure;signal processing methods;size 11 nm;temperature sensors;thermal gradient;finite impulse response filter;size 45 nm;post layout simulations;digital filter;system on a chip;characterization thermal gradients signal processing;chip;size 45 nm signal processing methods hardware structure thermal gradients characterization many core processors digital filters full chip thermal simulation post layout simulations size 11 nm;system on chip;signal processing thermal management temperature sensors runtime power dissipation predictive models power system modeling computational modeling circuits energy management;signal processing;digital filters;many core processors;characterization;full chip thermal simulation;multiprocessing systems;thermal gradients;thermal management packaging digital filters multiprocessing systems signal processing system on chip;thermal management;high frequency	In this paper we propose a hardware-structure based on signal processing methods for on-line extraction of on-chip spatial and temporal thermal gradients in many-core chips. The proposed method uses digital filters to compute the magnitude of high-frequency variations in thermal fields and correlate that to thermal gradients. The functionality of the system is demonstrated using full-chip thermal simulation of a predictive 1024 core systems in 11nm nodes. The power and area of the structure is evaluated using post-layout simulations in predictive 45nm technology.	central processing unit;digital filter;gradient;manycore processor;online and offline;signal processing;simulation	Minki Cho;Saibal Mukhopadhyay	2010	2010 11th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2010.5450486	system on a chip;embedded system;electronic engineering;real-time computing;digital filter;telecommunications;computer science;electrical engineering;signal processing	EDA	24.114094936863417	59.27263080133066	105476
1303a3974a9ed1ad8b66ae0cb0b1e905cabc9673	timing optimization by replacing flip-flops to latches	delay improvement;new timing optimization algorithm;clock skew;benchmark circuit;fixed-phase retiming;asic designer;asic design flow;restricted retiming;timing optimization;design flow;integrated circuit design;application specific integrated circuits	Latch circuits have advantage for timing and are widely used for high-speed custom circuits. However, ASIC design flows are based on the circuits with flip-flops. Then, ASIC designers don't use latches. This paper describes a new timing optimization algorithm for ASIC by replacing flip-flops to latches without changing the functionality of the circuits. After latch replacement, restricted retiming called fixed-phase retiming is carried out for timing optimization by minimizing the impact of clock skew and jitter. The experimental results show that 17% delay improvement of the benchmark circuits is achieved by proposed algorithms.	algorithm;application-specific integrated circuit;benchmark (computing);clock skew;flops;flip-flop (electronics);mathematical optimization;retiming	Ko Yoshikawa;Yasuhiko Hagihara;Keisuke Kanamaru;Yuichi Nakamura;Shigeto Inui;Takeshi Yoshimura	2004	ASP-DAC 2004: Asia and South Pacific Design Automation Conference 2004 (IEEE Cat. No.04EX753)	10.1145/1015090.1015135	embedded system;electronic engineering;parallel computing;real-time computing;clock skew;computer science;design flow;application-specific integrated circuit;static timing analysis;integrated circuit design	EDA	16.626326344894878	53.3029834285013	105729
3afe936760a5893e4c057355d549c8383492e5b6	an approach to evaluating the effects of realistic faults in digital circuits	logic simulation;fault simulation;hierarchical fault injection methodology realistic faults digital circuits hierarchical simulation methodology simulation hierarchy device level circuit level transistor level effect radiation particles first level fault dictionary circuit level simulation circuit latches flip flops fault dictionary transients simulation levels;flip flops;transient analysis;chip;circuit simulation;system evaluation;circuit faults digital circuits circuit simulation dictionaries analytical models transient analysis voltage computational modeling latches flip flops;vlsi;digital circuits;fault model;fault injection;flip flop;vlsi fault simulation logic simulation circuit simulation flip flops transient analysis	This paper presents a hierarchical simulation methodology that enables accurate system evaluation under realistic faults and conditions. The methodology spans the entire range of analysis from the device level to the system level. In this study we focus on two low levels of the simulation hierarchy-the device level and the circuit level. The primary fault model is obtained via simulation of the transistor-level effect of radiation particles penetrating the device. The resulting current bursts constitute the first-level fault dictionary and are used in the circuit-level simulation to determine the impact on circuit latches and flip-flops. The resulting outputs are recorded in the fault dictionary and can be used to analyze the impact of transients at the higher simulation levels, i.e., the chip level and the system level. The study demonstrated that the proposed hierarchical fault injection methodology is able to precisely capture the generation of transients in digital devices and thus provides a basis for realistic system evaluation.		Zbigniew T. Kalbarczyk;Janak H. Patel;Myeong S. Lee;Ravishankar K. Iyer	1999		10.1109/ICVD.1999.745158	chip;embedded system;electronic engineering;real-time computing;telecommunications;computer science;engineering;electrical engineering;stuck-at fault;logic simulation;fault model;very-large-scale integration;digital electronics	EDA	22.00385085947738	56.42412718772273	105819
38a1691dc6f8032e116191931f5a6bcfb1780c37	irredundant address bus encoding techniques based on adaptive codebooks for low power	logic design vlsi encoding low power electronics system buses integrated circuit design digital integrated circuits;logic design;capacitive memory buses irredundant address bus encoding methods adaptive codebooks power dissipation instruction address buses least signal transition codes jump branch operations signal transitions reduction low power vlsi design system buses;encoding power dissipation very large scale integration decoding capacitance circuits power system simulation power system interconnection digital systems system buses;limit set;chip;system buses;integrated circuit design;low power;digital integrated circuits;digital systems;power dissipation;low power electronics;vlsi;spatial locality;encoding	The power dissipation at the off-chip bus is a significant part of the overall power dissipation in digital systems. This paper presents irredundant address bus encoding methods which reduce signal transitions on the instruction address buses by using adaptive codebook methods. These methods are based on the temporal locality and spatial locality of instruction address. Since applications tend to JUMP / BRANCH to limited sets of addresses, proposed encoding methods assign the least signal transition codes to the addresses of JUMP / BRANCH operations in the past. Our encoding methods reduce the signal transitions on the instruction address buses by an average of 88%.	address bus;bus encoding;code;codebook;digital electronics;locality of reference;principle of locality;signal transition	Satoshi Komatsu;Masahiro Fujita	2003		10.1145/1119772.1119775	chip;limit set;electronic engineering;parallel computing;logic synthesis;real-time computing;telecommunications;computer science;dissipation;operating system;very-large-scale integration;address bus;low-power electronics;encoding;integrated circuit design	Arch	16.049500132373353	55.736849569028394	105859
115d14c36b30e55d4e28c359ae226cd29823c2b0	fault coverage analysis of peak-detector based bist for rf lnas	and mixed signal;built in self test bist;structural testing;built in self test;low noise amplifier;test methods;low noise amplifiers lna;fault coverage;time to market;production cost;fault model	Analog and mixed-signal testing is becoming an important issue that affects both the time-to-market and the product cost of many SoCs. In order to provide an efficient testing method for 865–870 MHz low noise amplifiers (LNAs), which constitute a mixed-signal circuit, a novel BIST method is developed. This BIST can be easily implemented with a RF peak detector and two comparators. The circuit used in the test and the LNA are designed using 0.35 µm CMOS technology. The simulation results show higher fault coverage than that of previous test methods. A total of twenty eight short and open (catastrophic) faults and eleven variation parameters have been introduced into the LNA, giving fault coverage of 100% for catastrophic faults and parametric variation. Thus, it provides an efficient structural test, which is suitable for a production test in terms of an area overhead, a test accessibility, and test time.	built-in self-test;fault coverage;precision rectifier;radio frequency	R. M. Ayadi;M. Masmoudi	2010	J. Electronic Testing	10.1007/s10836-009-5129-z	reliability engineering;embedded system;electronic engineering;real-time computing;fault coverage;engineering;stuck-at fault;automatic test pattern generation;test compression;low-noise amplifier;fault model;test method;statistics	EDA	23.715083991265164	54.2840989302799	105862
11e7e7e4f2b9471d13bf0cf7655362dfcf42da48	an algorithm for face-constrained encoding of symbols using minimum code length	symbol manipulation;logic synthesis tasks;state assignment tool;constraint optimization;multipliers;logic design;minimisation of switching nets;sequential circuits;binary codes;encoding constraint optimization sequential circuits integrated circuit synthesis minimization methods binary codes logic design logic circuits circuit synthesis algorithm design and analysis;high level synthesis sequential circuits minimisation of switching nets symbol manipulation;logic circuits;minimization methods;face constrained encoding;optimization problem;high level synthesis;fault secure circuits;standard benchmark;logic synthesis;minimum code length;input encoding problems;binary variables;integrated circuit synthesis;residue arithmetic codes;self checking circuits;encoding;sequential circuits face constrained encoding minimum code length logic synthesis tasks input encoding problems binary variables state assignment tool standard benchmark;algorithm design and analysis;circuit synthesis	Different logic synthesis tasks have been formulated as input encoding problems but restricted to use a minimum number of binary variables. This paper presents an original column based algorithm to solve this optimization problem. The new algorithm targets economical implementation of face constraints unlike conventional algorithms which do not care about infeasible ones. Experimental results that demonstrate the superiority of the new method versus conventional tools and a preview algorithm specifically developed for the minimum length encoding problem are shown. A state assignment tool which uses the new algorithm is evaluated by implementing a standard benchmark of sequential circuits. It compares very favorably to well known tools like NOVA.	algorithm;benchmark (computing);data general nova;logic synthesis;mathematical optimization;optimization problem;run-length encoding	Manuel Martínez;Maria J. Avedillo;José M. Quintana;José Luis Huertas	1999	Design, Automation and Test in Europe Conference and Exhibition, 1999. Proceedings (Cat. No. PR00078)	10.1145/307418.307556	embedded system;constrained optimization;electronic engineering;logic synthesis;real-time computing;computer science;theoretical computer science;algorithm	EDA	15.001938116495241	47.64019326922643	106072
4d8e517224bcd3432ee352dcb5db0e510bb608b2	equivalence checking with rule-based equivalence propagation and high-level synthesis	behavioral optimization;rtl model rule based equivalence propagation high level synthesis vlsi designs word level equivalence checking behavioral optimization;rule based equivalence propagation;rule based;program control structures;high level synthesis computer bugs very large scale integration hardware electronic equipment testing design optimization optimization methods registers concurrent computing conferences;vlsi design;satisfiability;high level synthesis;integrated circuit design;rtl model;control structure;vlsi circuit optimisation electronic design automation integrated circuit design integrated circuit testing knowledge based systems program control structures;integrated circuit testing;vlsi;word level equivalence checking;circuit optimisation;vlsi designs;equivalence checking;knowledge based systems;electronic design automation	Equivalence checking is one of the most important issues in VLSI designs to guarantee that bugs do not enter the design during optimization steps or synthesis steps. In this paper, we propose a new word-level equivalence checking method between two models before and after high-level synthesis or behavioral optimization. Our method converts two given designs into RTL models which have the same datapath so that the two designs have the same bit-level accuracy. Then the word-level equivalence checking techniques can be applied satisfying the bit-level accuracy. Also, as our method propagates equivalences from inputs to outputs with the equivalence rules of control structures, name correspondences among registers or variables are not required. By those rules, designs which have loops can be verified without unrolling. Experimental results with realistic examples show that our method can verify those designs in practical periods	bit-level parallelism;control flow;datapath;formal equivalence checking;high- and low-level;high-level synthesis;logic programming;mathematical optimization;protologism;schema (genetic algorithms);software bug;turing completeness;very-large-scale integration	Tasuku Nishihara;Takeshi Matsumoto;Masahiro Fujita	2006	2006 IEEE International High Level Design Validation and Test Workshop	10.1109/HLDVT.2006.319984	electronic design automation;computer science;theoretical computer science;formal equivalence checking;very-large-scale integration;algorithm	EDA	18.48834045747693	48.74427184907579	106161
7c3a02e50f553046633837a69131985b960a6136	cad computation for manufacturability: can we save vlsi technology from itself?	vlsi;circuit layout cad;compensation;design for manufacture;integrated circuit layout;masks;photolithography;cad tools;cmos scaling;vlsi technology;back-end design tools;cell design;illumination wavelength;layout migration;layout-to-mask shape transformations;lithographic patterning;pattern-distorting effects;photomasks;physical scaling;place-and-route;post-tapeout compensation;post-tapeout data preparation	Every 18 to 24 months, the areal density of VLSI doubles and the predicted date for the End Of CMOS Scaling is pushed out approximately 18 to 24 months. This rate of growth has been controUed mainly by the increasing capabilities of lithographic patterning. However, the rate of improvement of lithography systems in key physical parameters such as illumination wavelength has begun to slow. To make up the shortfall, lithography has increasingly turned to using CAD tools to transform the geometric shapes in designs into shapes on photomasks which have been compensated for systematic patterndistorting effects. As the requirements for this compensation grow, however, it becomes increasiagly difficult to hide in post-tapeout data preparation, and must he considered in hack-end design tools and methodologies. We describe a number of the challenges to lithographic patterning, highlighting the factors that limit “physical s d i and introduce the layout-to-mask shape transformations that compensate for these limitations. We describe the implementation 9f these transformations in general-purpose and specialized CAD tools, pointing out challenges Like growth of computation effort. Fhally, we describe how limitations of post-tapeout compensation drive the need for “litho-aware” physical design tools, showing examples in cell design, place-and-route, and layout migration.	cmos;computation;computer-aided design;design for manufacturability;general-purpose modeling;illumination (image);physical design (electronics);place and route;requirement;tape-out;very-large-scale integration	Mark A. Lavin;Lars Liebmann	2002		10.1109/ICCAD.2002.1167568	physical design;parameterized complexity;electronic engineering;computer science;engineering;electrical engineering;place and route;microelectromechanical systems;integrated circuit layout;very-large-scale integration;design for manufacturability;engineering drawing;photolithography	EDA	13.083678005173619	55.71423566788577	106260
213f02f0960e83acfbcab91e757a2d1b3420e724	modeling the impact of process and operation variations on the soft error rate of digital circuits		Dear editor, Process or operation variations are important factors in the soft error rate (SER) of integrated circuits [1, 2]. During manufacturing or other operations, inevitable process or operation variations lead to changes in the electrical parameters of transistors, which can result in sizeable shifts in the SER of integrated circuits [3]. Some studies have reported that the hardness of test chips can vary by more than 20% as a result of process or operation variations [4]. Therefore, it is vital to account for process and operation variations when evaluating the circuit sensitivity and predicting the SER in advanced CMOS technology. In previous research, some models for evaluating the circuit sensitivity caused by process or operation variations have been derived. For instance, Mostafa et al. [5] proposed a critical charge model to evaluate the single-event upset (SEU) sensitivity of static random access memorys (SRAMs) and flip-flops. Based on this model, the critical charge was determined by the driving current of the transistors. Process or operation variations affected this driving current, leading to changes in the calculated critical charge. Recently, Monte Carlo simulation approach has been used to evaluate the circuit sensitivity [6]. This approach shifts the device parameters to model process or operation variations. A current source, which is represented as the ion induced transient current, was implemented in the circuit node. The circuit response was simulated by circuit-level simulation tools based on the variational device parameters. Although these models or approaches have been used to evaluate the circuit sensitivity caused by process or operation variations, they still have some limitations. For instance, the critical charge model is strongly dependent on the circuit topology. Different circuit topologies result in different equations to calculate the critical charge. Moreover, some process parameters, such as mobility, affect the driving current slightly. However, they have a significant effect on the collected charge of sensitive transistors. Although the calculated critical charge does not change, these process parameters also affect the circuit sensitivity and lead to SER variations. Therefore, we propose a circuit-level simulation approach to evaluate processor operationinduced SER variations, as shown in Figure 1. Our approach consists of three interacting components. The first component uses a Monte Carlo simulation to determine ion transportation and calculate the ionized charge in the semiconductor. In the second component, circuit-level charge collection models calculate transient currents after ion strikes. In this component, a novel model is used to determine the parameters affected by process or	cmos;circuit topology;current source;digital electronics;flops;flip-flop (electronics);integrated circuit;interaction;monte carlo method;random access;semiconductor;simulation;single event upset;soft error;transistor;variational principle	Ruiqiang Song;Shuming Chen;Bin Liang;Yaqing Chi;Jianjun Chen	2016	Science China Information Sciences	10.1007/s11432-016-9001-9	real-time computing	EDA	21.61953958756445	59.28287982625245	106388
d216bb64f6919316868871a33601fa42ff78f0bd	detecting intermittent resistive faults in digital cmos circuits	reliability;circuit faults;sensors;intermittent fault detection;aging;monitoring;dependability;intermittent resistive faults;no faults found;temperature measurement;delays	Interconnection reliability threats dependability of highly critical electronic systems. One of most challenging interconnection-induced reliability threats are intermittent resistive faults (IRFs). The occurrence rate of this kind of defects can take e.g. one month, and the duration of defects can be as short as a few nanoseconds. As a result, evoking and detecting these faults is a big challenge. IRFs can cause timing deviations in data paths in digital systems during its operating time. This paper proposes an online digital slack monitor which is able to detect small timing deviations caused by IRFs in digital systems. The simulation results show that the proposed monitor is effective in detecting IRFs.	cmos;dependability;digital electronics;fault injection;information retrieval facility;interconnection;sensor;simulation;slack variable	Hassan Ebrahimi;Alireza Rohani;Hans G. Kerkhoff	2016	2016 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)	10.1109/DFT.2016.7684075	reliability engineering;embedded system;electronic engineering;real-time computing;temperature measurement;engineering;sensor;reliability;dependability;statistics	Arch	21.377898659971603	55.73866070445711	106441
133a903049a2f2136ecd0e7a605070dd06df1aa9	increasing fault coverage during functional test in the operational phase	microcontrollers;pins;operational phase;input output signals;circuit faults;circuit faults registers microcontrollers hardware clocks testing pins;clocks;automotive systems;testing;hybrid approach;fault tolerant computing;safety critical systems functional test on line test sbst automotive systems;registers;logic testing;integrated circuit testing;on line test;sbst;hardware module;fault coverage;functional testability fault coverage safety critical applications ic testing operational phase input output signals hybrid approach hardware module microcontroller;functional test;safety critical applications;functional testability;ic testing;safety critical systems;microcontroller;microcontrollers fault tolerant computing integrated circuit testing logic testing;hardware	A key issue in many safety-critical applications is the test of the ICs to be performed during the operational phase: regulations and standards often explicitly describe fault coverage figures to be achieved. Functional test (i.e., a test exploiting only functional inputs and outputs, without resorting to any Design for Testability) is often the only viable solution, unless a strict cooperation exists between the system company and the device provider. However, purely functional test often shows several limitations due to the limited accessibility that it can gain on some input/output signals. This paper proposes a hybrid approach, in which a suitable hardware module is added outside a microcontroller to increase its functional testability during the operational phase. Experimental results gathered on a couple of cases-of-study are reported, showing the feasibility of the method.	accessibility;design for testing;fault coverage;functional testing;input/output;microcontroller	Mauricio de Carvalho;Paolo Bernardi;Ernesto Sánchez;Matteo Sonza Reorda;Oscar Ballan	2013	2013 IEEE 19th International On-Line Testing Symposium (IOLTS)	10.1109/IOLTS.2013.6604049	microcontroller;reliability engineering;embedded system;electronic engineering;real-time computing;fault coverage;computer science;engineering;operating system;test compression	Embedded	22.697415121490803	50.675245202683385	106722
2f68546f1ddba42dff1ffd011db79d77ba1c6498	detecting positive voltage attacks on cmos circuits	voltage attack;low area overhead;cmos circuit;nominal voltage;dynamic overvoltage attack;timing detection circuit;good performance;extra timing constraint;multiple power domain circuit;advanced technology node;positive voltage attack;cmos digital circuit	This work investigates voltage attacks over the nominal voltage on CMOS digital circuits designed on advanced technology nodes. The behavior of both combinatorial and sequential logic is analyzed in presence of static and dynamic overvoltage attacks. It points out that only modifications of propagation delays occur in presence of such attacks. Timing detection circuits are then introduced to detect hold violations. These circuits offer good performance with low area overhead but their implementation require extra timing constraints on the design to protect. In addition, multiple power domain circuits must be considered to thwart overpowering attacks.	cmos;digital electronics;overhead (computing);power domains;propagation delay;sensor;sequential logic;software propagation	Kamil Gomina;Philippe Gendrier;Philippe Candelier;Jean-Baptiste Rigaud;Assia Tria	2014		10.1145/2556315.2556320	electronic engineering;real-time computing;engineering;computer security	EDA	20.071622572196997	55.9126293074774	106942
11356c0c64557eebe74dab3ef5d5e9c223cb4919	limitations in predicting defect level based on stuck-at fault coverage	cmos integrated circuits;estimate uncertainty defect level stuck at fault coverage test generation process test set quality logic circuits;circuit faults circuit testing performance analysis integrated circuit modeling system testing contracts design for testability predictive models performance evaluation manufacturing processes;automatic testing;logic testing;integrated circuit testing;test generation;fault coverage;integrated circuit testing logic testing fault location cmos integrated circuits integrated logic circuits automatic testing;integrated logic circuits;fault model;fault location	The stuck-at fault model has been used over decades as a guide to the test generation process and as an evaluation mechanism for the quality of the test set. As demands on quality have increased, the use of the stuck-at fault model as a predictor of the defect level has been questioned. This paper provides some insight on the issue and shows the limitations of using the stuck-at fault coverage to predict the defect level. The authors demonstrate that as defect level decreases the uncertainty of the estimate grows. >	fault coverage;software bug;stuck-at fault	Jaehong Park;Mark Naivar;Rohit Kapur;M. Ray Mercer;Thomas W. Williams	1994		10.1109/VTEST.1994.292315	reliability engineering;embedded system;electronic engineering;real-time computing;fault coverage;white-box testing;fault indicator;computer science;engineering;stuck-at fault;automatic test pattern generation;test compression;fault model;cmos	SE	22.71395553367539	54.51912706933162	107029
749bec40af9ea27f4a44c698c28581d37ed5c093	high-speed cmos logic circuits in capacitor coupling technique	pipelined four phase logic circuit;carry logic;folding technique;capacitor coupling technique;full adder;clocks;multivalued logic circuits;high speed cmos logic circuits;cmos logic circuits capacitors coupling circuits logic circuits clocks adders voltage logic devices logic functions cmos memory circuits;logic circuits;multivalued logic circuits high speed integrated circuits cmos logic circuits pipeline processing carry logic adders;coupling circuits;xor gate design;400 mhz;cmos memory circuits;adders;cmos logic circuits;capacitors;phased logic;power dissipation;voltage;0 35 micron;logic functions;carry look ahead;operating speed;c 3 l circuit;high speed;high speed integrated circuits;device count;400 mhz high speed cmos logic circuits capacitor coupling technique pipelined four phase logic circuit c sup 3 l circuit folding technique xor gate design carry look ahead adder device count power dissipation full adder operating speed 0 35 micron;logic devices;pipeline processing;carry look ahead adder	A pipelined four-phase logic circuit called the CMOS capacitor coupling logic (C/sup 3/L) circuit is proposed. The operation of the pipelined system is described. A folding technique is used for the XOR gate design. A carry look-ahead adder (CLA) is designed using the capacitor coupling technique. Using the technique, the device count and the power dissipation can be reduced. The simulation of a full adder and a CLA in 0.35 /spl mu/m process shows that the maximum operating speed can reach 400 MHz.	cmos;logic gate	Hong-Yi Huang;Teng-Neng Wang	2001		10.1109/ISCAS.2001.922317	electronic engineering;parallel computing;real-time computing;computer science;engineering;electrical engineering;adder	EDA	18.509194340595133	54.02682652829231	107092
14b3bc770a17bbc49e0c6f1e417e442640ae3b80	placement density aware power switch planning methodology for power gating designs	standards;switching circuits;resistance;law;switches law resistance standards switching circuits logic gates;logic gates;ir drop constraint placement density aware power switch planning methodology power gating designs manufacture technology leakage current supply voltage ic power switches low power domain chip area greedy algorithm simplified model preplaced standard cells mathematical approach real design flow;switches integrated circuit layout low power electronics;switches	As advances in manufacture technology, leakage current increases dramatically in modern ICs. By turning off supply voltage in a low-power domain with power switches, power gating becomes a useful technique in resolving this problem. Since number and locations of power switches have great impact on chip area and IR-drop, an efficient and effective approach to insert power switches is required for the power gating designs. Unlike previous works using the greedy algorithm to handle this problem, this paper uses a simplified model to approximate required equivalent resistance of power switches in a low-power domain, and then determines number and types of power switches based on the value. In order to reduce impact on preplaced standard cells, we also propose a mathematical approach to find locations with less placement density to place power switches. The proposed methodology was integrated into a real-design flow. Experimental results demonstrate that our approach can insert less number of power switches and still satisfy the IR-drop constraint than other approaches.	approximation algorithm;design flow (eda);embedded system;greedy algorithm;low-power broadcasting;network switch;power domains;power gating;spectral leakage	Jai-Ming Lin;Che-Chun Lin	2015	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2015.2401573	control engineering;electronic engineering;logic gate;network switch;computer science;engineering;electrical engineering;switched-mode power supply;resistance	EDA	19.007290860186448	56.06323384930295	107126
e02c1203838d0ec31cbb72a92f1e9584cfb870b6	tutorial t7a: techniques for network-on-chip (noc) design and test	network on chip;3d noc design network on chip test system on chip soc ic chips integrated circuit chips on chip communication efficiency global bus nonscalable wire delay technology shrinking power consumption interconnection networks router based packet switched network hardware communication infrastructure design research and development topic software services operating system services cad tools noc synthesis evaluation framework;integrated circuit design;tutorials network on chip very large scale integration embedded systems system performance;integrated circuit interconnections;integrated circuit testing;network on chip integrated circuit design integrated circuit interconnections integrated circuit testing	System-on-Chip (SoC) is a paradigm for designing today’s integrated circuit (IC) chips that puts an entire system onto a single silicon floor (instead of printed circuit boards containing a number of chips accomplishing the system task). With the increasing number of cores integrated on such a chip, on-chip communication efficiency has become one of the key factors in determining the overall system performance and cost. The communication medium used in most of the modern Systems-on-Chip (SoCs) is shared global bus. In spite of fairly simple structure, extensibility, and low area cost of bus, at the system level, it can be used for only upto tens of cores on a single chip. The restriction comes mainly due to the following reasons – non-scalable wire delay with technology shrinking, nonscalable system performance with number of cores attached, decrease in operating frequency with each additional core attached, high power consumption in long wires, etc. Network-on-Chip (NoC) is an emerging alternative that overcomes the abovementioned bottlenecks for integrating large number of cores on a single SoC. NoC is a specific flavor of interconnection networks where the cores communicate with each other using a router based packet switched network. Interconnection networks have been studied for more than last two decades and a solid foundation of design techniques has been reported in the literature. NoC is today becoming an emerging research and development topic including hardware communication infrastructure design, software and operating system services, CAD tools for NoC synthesis, NoC testing, and so on. This tutorial aims at covering the important aspects of NoC design – communication infrastructure design, communication methodology, evaluation framework, mapping of applications onto NoC etc. Apart from these, it also proposes to focus on other upcoming NoC issues, such as, NoC testing, reconfiguration, synthesis and 3-D NoC design.	clock rate;computer-aided design;daemon (computing);extensibility;integrated circuit;interconnection;mpsoc;network on a chip;network packet;operating system;packet switching;printed circuit board;printing;programming paradigm;router (computing);scalability;system on a chip	Santanu Chattopadhyay	2014		10.1109/VLSID.2014.123	embedded system;electronic engineering;real-time computing;computer science;engineering;network on a chip;integrated circuit design	EDA	12.084939223553537	56.34126822757243	107127
0a3a4f118475c949a61a8c5cdee593bb6abebdb1	eof: efficient built-in redundancy analysis methodology with optimal repair rate	exhaustive search algorithm;fault classification;embedded memory;built in self repair bisr;bira algorithm;redundancy analysis;built in redundancy analysis bira;yield;built in self test;redundancy;efficient built in redundancy analysis methodology;storage management chips;built in redundancy analysis blra;yield built in redundancy analysis bira built in self repair bisr embedded memory;redundancy hardware built in self test system on a chip performance analysis algorithm design and analysis cost function fabrication automatic testing automatic test equipment;built in self repair;fault classification efficient built in redundancy analysis methodology embedded memory bira algorithm exhaustive search algorithm;embedded computing;fault diagnosis;exhaustive search;storage management chips fault diagnosis redundancy	Faulty cell repair with redundancy can improve memory yield. In particular, built-in redundancy analysis (BIRA) is widely used to enhance the yield of embedded memories. We propose an efficient BIRA algorithm to achieve the optimal repair rate with a very short analysis time and low hardware cost. The proposed algorithm can significantly reduce the number of backtracks in the exhaustive search algorithm: it uses early termination based on the number of orthogonal faulty cells and fault classification in fault collection. Experimental results show that the proposed BIRA methodology can achieve optimal repair rate with low hardware overhead and short analysis time, as compared to previous BIRA methods.	backtracking;benchmark (computing);brute-force search;byzantine fault tolerance;embedded system;end-of-file;fault coverage;fault model;overhead (computing);search algorithm;sensor;simulation;stuck-at fault;test set	Myung-Hoon Yang;Hyungjun Cho;Wooheon Kang;Sungho Kang	2010	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2010.2044846	embedded system;yield;parallel computing;real-time computing;engineering;theoretical computer science;brute-force search;redundancy	EDA	20.034229656523614	52.27376416865296	107194
68ba8c812cadd135abc91e12af7912bc8699a331	this paper presents a cost-effective area-io dram a cad tool and algorithms	optimisation;integrated optoelectronics;system on a package;physical design;random access memory optical interconnections optical waveguides high speed optical techniques optical crosstalk clocks electromagnetic waveguides optical design integrated circuit interconnections bandwidth;network routing;optical waveguide;integrated circuit interconnections optical interconnections optimisation network routing circuit layout cad integrated optoelectronics;long distance;interconnects routing optoelectronic system on a package optoelectronic system in package cad tool optical waveguide interconnect technology optimization algorithm module placement;optical interconnect;integrated circuit interconnections;cost effectiveness;circuit layout cad;optimal algorithm;optical interconnections	We propose a new approach to the physical design of optoelectronic system-on-a-package (SOP) using optical waveguide interconnect technology. The objective is to improve the performance of SOP by replacing long distance electrical interconnects with optical waveguide interconnects. A new simultaneous optimization algorithm for module placement and routing of electrical and optical interconnects is introduced. It not only improves the performance of SOP, but reduces the simulation time. Even though a small portion of electrical interconnects are replaced with optical interconnects, more than 21% improvement of the SOP performance is achieved.	algorithm;computer-aided design;dynamic random-access memory	Chung-Seok Seo;Abhijit Chatterjee;Nan M. Jokerst	2005		10.1109/ISQED.2005.123	waveguide;physical design;embedded system;routing;electronic engineering;cost-effectiveness analysis;computer science;engineering;engineering drawing	EDA	14.703405465675663	52.115703438537366	107276
bba1324d8be97bf894e71cee34bd4d1430e2d691	post-dft-insertion retiming for delay recovery on inter-die paths in 3d ics	delays registers logic gates through silicon vias clocks three dimensional displays;design for testability;timing circuits automatic test pattern generation benchmark testing boundary scan testing circuit simulation clocks delay circuits design for testability flip flops integrated circuit bonding integrated circuit testing logic circuits logic testing three dimensional integrated circuits;clocks;automatic test pattern generation;flip flops;timing circuits;logic circuits;boundary scan testing;circuit simulation;integrated circuit bonding;stuck at atpg post dft insertion retiming delay recovery interdie path 3d ic pre bond known good die test kgd stack yield die wrapper boundary cell boundary register gated scan flop gsf pre bond tsv pre bond scan test extra clock stage avoidance through silicon via design for test logic on logic 3d benchmark die level retiming stack level retiming;delay circuits;logic testing;integrated circuit testing;benchmark testing;three dimensional integrated circuits	Pre-bond known-good-die (KGD) test is necessary to ensure stack yield for the future adoption of 3D ICs. Die wrappers that contain boundary registers at the interface between dies have been proposed as a solution for known-good-die (KGD) test. It has been shown in the literature that if gated scan flops (GSFs) are substituted for traditional scan flops in the boundary register, then both pre-bond TSV and pre-bond scan test can be performed. The drawback of die wrappers is that two clocked stages are added to each path that crosses a die boundary. In this paper, a bypass mode is added to GSFs to avoid the extra clock stages and retiming is used to recover the additional delay added to through-silicon-via (TSV) paths by design-for-test (DfT) insertion. The proposed method is evaluated through simulations using a logic-on-logic 3D benchmark. Results show that in most cases, retiming at both the die-level and stack-level is sufficient for recovering the delay added by wrapper boundary cells. Stuck-at ATPG is performed to demonstrate that wrapper insertion and retiming have little impact on pattern count. The area overhead due to wrapper insertion is shown to increase as a circuit is partitioned across an increasing number of stack layers, but the area overhead can be reduced using retiming.	benchmark (computing);ct scan;clock rate;design for testing;die (integrated circuit);expanded memory;flops;overhead (computing);retiming;simulation;test card;through-silicon via	Brandon Noia;Krishnendu Chakrabarty	2013	2013 IEEE 31st VLSI Test Symposium (VTS)	10.1109/VTS.2013.6548939	embedded system;benchmark;electronic engineering;real-time computing;logic gate;computer science;engineering;retiming;automatic test pattern generation;design for testing	EDA	18.844581019965844	53.11537370080829	107280
4d8a30d70c138327edbe40a80d0051d462ef9e04	design of flip-flops with clock-gating and pull-up control scheme for power-constrained and speed-insensitive applications	xor based comparator;ipff cgpc;short circuit power saving;very large scale integration designs;pull up control scheme;power constrained applications;smic 65 nm technology;data switching activity;inverter chain;implicit pulsed triggered flip flop design;pdp efficiency;power delay product;xor based clock gating scheme;discharging path enhancement;internal node redundant transition elimination;pulse generating stage;speed insensitive applications;ipff ecgpc	In this study, a novel power efficient implicit pulsed-triggered flip-flop with embedded clock-gating and pull-up control scheme (IPFF-CGPC) is proposed. By applying an XOR-based clock-gating scheme in the pulse generating stage, which conditionally disables the inverter chain when the input keeps unchanged, IPFF-CGPC is able to gain low power efficiency by eliminating redundant transitions of internal nodes. Meanwhile, a pull-up control scheme is applied to enhance the discharging path and save short-circuit power when D makes ‘0’–‘1’ transition. To further improve the robustness of the proposed design, the XOR-based comparator in the clock-gating scheme is replaced by a transmission gate-based comparator, which results in an enhanced version (IPFF-ECGPC). Based on the SMIC 65 nm technology, extensive post-layout simulation results show that IPFF-CGPC exhibits excellent power characteristic with a reduction of 32.06–85.89% against its rival designs at 10% data switching activity. Due to its power efficiency, its power-delay product (PDP) gains an improvement of up to 73.94% in the same condition. Moreover, IPFF-ECGPC also enjoys outstanding total-power and PDP efficiency at 10% data switching activity. Therefore, the proposed designs are suitable for power-constrained applications in very-large-scale integration designs which are speed-insensitive.	clock gating;flops;flip-flop (electronics)	Liang Geng;Jizhong Shen;Congyuan Xu	2016	IET Computers & Digital Techniques	10.1049/iet-cdt.2015.0139	embedded system;electronic engineering;real-time computing;engineering	HPC	17.41124122264524	57.471446994458596	107343
10e0f6150370654aa8bf58de254d9eca45e9efb2	on legalization of row-based placements	min cut placement;legalization;dynamic program;empirical validation;detailed placement	Cell overlaps in the results of global placement are guaranteed to prevent successful routing. However, common techniques for fixing these problems may endanger routing in a different way --- through increased wirelength and congestion. We evaluate several such techniques with routability of row-based placements in mind, and propose new ones that, in conjunction with our detail placer, improve overall routability and routed wirelength. Our generic two-phase approach for resolving illegal placements calls for (i) balancing the numbers of cells in rows, (ii) removing overlaps within rows through a generic dynamic programming procedure. Relevant objectives include minimum total perturbation, minimum wirelength increase and minimum maximum movement. Additionally, we trace cell overlaps in min-cut placement to vertical cuts and show that, if bisection cut directions are varied, overlaps anti-correlate with improved wirelength.Empirical validation is performed using placers Capo and Cadence QPlace, followed by various legalizers and detail placers, with subsequent routing by Cadence WarpRoute. We use a number of IBMv2 benchmarks with routing information. Our legalizer reduces both Capo and QPlace placements' wirelength by up to 4% compared to results of Capo legalized by Cadence's QPlace in the ECO mode.	dynamic programming;minimum cut;network congestion;routing;two-phase locking	Andrew B. Kahng;Igor L. Markov;Sherief Reda	2004		10.1145/988952.989004	simulation;engineering;engineering drawing	EDA	15.274959585994003	52.705369638422894	107394
d8c0a2c36ad944bd85705c1f4a89b81499daf2e8	fpga-spice: a simulation-based power estimation framework for fpgas	routing;field programmable gate arrays routing integrated circuit modeling estimation spice table lookup;fpga spice flip flops global routing architecture circuit elements grid level testbenches full chip level testbenches component level testbenches architectural description language luts fpgas routing multiplexers look up tables power consumption analytical power models probabilistic activity estimation field programmable gate array simulation based power estimation framework;table lookup circuit simulation field programmable gate arrays logic design power consumption spice;estimation;integrated circuit modeling;field programmable gate arrays;table lookup;spice	Mainstream Field Programmable Gate Array (FPGA) power estimation tools are based on probabilistic activity estimation and analytical power models. The power consumption of the programmable resources of FPGAs is highly sensitive to their configurations. Due to their highly flexible nature, the configurations of FPGAs routing multiplexers or Look Up Tables (LUTs) are really different from a design to another but current analytical power models cannot accurately capture the associated power differences. In this paper, we introduce a simulation-based power estimation framework for FPGAs, called FPGA-SPICE, which supports any FPGA architecture that can be described with an architectural description language. Our power estimation engine automatically generates accurate SPICE netlists according to the FPGA configurations and enables precise power analysis of FPGA architectures. SPICE testbenches can be generated at different level of complexity, denoted as full-chip-level, grid-level and component-level testbenches. Full-chip-level testbenches dump the netlists associated with the complete FPGA fabric. To reduce simulation time, FPGA-SPICE can split the full-chip-level testbenches into grid-level testbenches, each of which consisting of a complete logic block netlist, or component-level testbenches, which consider individual circuit elements, i.e., multiplexers, LUTs, flip-flops, etc., separately. We show that the grid/component-level approach can achieve 14 × speed-up with a moderate 14% accuracy loss, compared to the full-chip level. We also use FPGA-SPICE to study the power characteristics of a commercial FPGA architecture at different technology nodes. Experimental results show that the global routing architecture consumes 50% of the total power, the local routing architecture claims for 40% of the total power, and the remaining 10% comes from the LUTs and flip-flops.	architecture description language;circuit design;embedded system;flops;field-programmable gate array;flip-flop (electronics);general-purpose modeling;logic block;multiplexer;netlist;place and route;random access;routing;spice;simulation;test bench;transistor	Xifan Tang;Pierre-Emmanuel Gaillardon;Giovanni De Micheli	2015	2015 33rd IEEE International Conference on Computer Design (ICCD)	10.1109/ICCD.2015.7357183	embedded system;routing;estimation;electronic engineering;parallel computing;real-time computing;computer science;field-programmable gate array;statistics;computer network	EDA	14.848449663577794	54.91518832606685	107449
7fe68af04315103b3e55559417b734eba6a06090	scan cell design for launch-on-shift delay tests with slow scan enable	bistable;clock edge;diminution cout;clocks;transition delay fault coverage;scan cell design;flip flops;launch on shift delay tests;control velocidad;launch on capture delay tests;integrated circuit design;slow scan enable;biestable;delay circuits;integrated circuit testing clocks delay circuits flip flops integrated circuit design;integrated circuit testing;horloge;temps retard;delay time;transition delay fault coverage scan cell design launch on shift delay tests slow scan enable global control signal launch on capture delay tests flip flops clock edge;reduccion costes;speed control;tiempo retardo;clock;commande vitesse;cost lowering;reloj;global control signal	Most scan-based designs implement the scan enable as a slow speed global control signal, and can therefore only implement launch-on-capture (LOC) delay tests. Launch-on-shift (LOS) tests are generally more effective, achieving higher fault coverage with significantly fewer test vectors, but requiring a fast scan enable. A low cost solution for implementing LOS tests by adding a small amount of logic in each flip-flop to align the slow scan enable signal to the clock edge is presented. The new design is much more efficient when compared with other recent proposals and can support full LOS testing. It can be further modified for mixed LOC/ LOS tests that achieve transition delay fault coverage approaching 95% for the ISCAS89 benchmarks.		Gefu Xu;Adit D. Singh	2007	IET Computers & Digital Techniques	10.1049/iet-cdt:20060142	clock;embedded system;electronic engineering;scan chain;real-time computing;computer science;engineering;electronic speed control;integrated circuit design	HCI	21.102490544499773	52.818039836696414	107620
f21b29b6b15ca8afadb131a72d34ba2c1e39e1c6	concurrent design of delta-sigma modulator using behavioral modeling and simulation with the verilog-a	integrated circuit design analogue integrated circuits delta sigma modulation hardware description languages;delta sigma modulation;behavior modeling;delta modulation hardware design languages circuit simulation analog circuits design methodology analog digital conversion operational amplifiers costs circuit synthesis digital circuits;hardware description languages;analog circuits;integrated circuit design;analogue integrated circuits;first order;design method;analog circuit design delta sigma modulator behavioral modeling verilog a analog hdl	In this paper, we present the concurrent design method of delta-sigma modulator by using analog HDL. In our method, a few blocks are modeled at transistor level and the other blocks are done at behavioral level. For every block, similar modeling is done, and the simulations are performed at the transistor and behavioral mixed level. As a result, specification of every block is derived without the enormous costs so that the whole circuit is simulated repeatedly. We show our method is useful and efficient for the analog circuit design by designing the first-order delta-sigma modulator	analogue electronics;behavioral modeling;circuit design;delta-sigma modulation;first-order predicate;hardware description language;simulation;transistor;verilog	Tatsuya Yamamoto;Toshinori Suzuki;Hideki Asai	2006	IEEE Custom Integrated Circuits Conference 2006	10.1109/CICC.2006.320917	mixed-signal integrated circuit;behavioral modeling;physical design;computer architecture;electronic engineering;real-time computing;electronic circuit design;design methods;analogue electronics;computer science;delta-sigma modulation;circuit design;first-order logic;hardware description language;register-transfer level;integrated circuit design;analog multiplier	EDA	20.330231395328017	46.74537682126983	107774
678a3a33caff70224421933c4270e14081b1fc74	gain-based technology mapping for minimum runtime leakage under input vector uncertainty	gain based technology mapping;leakage;bin based mapper gain based technology mapping minimum runtime leakage input vector uncertainty probability distribution circuit mapping iscas85 benchmark gain based mappers dominant state mapper;logical effort algorithms performance leakage technology mapping;logic design;gain based mappers;performance;runtime uncertainty libraries delay cooling costs packaging minimization methods circuit synthesis permission;statistical distributions integrated circuit design logic design;bin based mapper;circuit mapping;input vector uncertainty;integrated circuit design;statistical distributions;iscas85 benchmark;leakage power;minimum runtime leakage;probability distribution;algorithms;logical effort;technology mapping;dominant state mapper	The gain-based technology mapping paradigm has been successfully employed for finding minimum delay and minimum area mappings. However, existing gain-based technology mappers fail to find circuits with minimal leakage power. In this paper, we introduce algorithms and modeling strategies that enable efficient gain-based technology mapping for minimum leakage power. The proposed algorithm is probability-aware and can rigorously take into account input state probability distribution to generate a circuit mapping with minimum leakage at a given percentile. Minimizing leakage at high percentiles is essential for minimizing peak leakage, which strongly influences the cooling limits and packaging costs.The algorithms have been tested on the ISCAS85 benchmark suite. Results indicate that the mappings produced by the new algorithm consume, on average 14% lesser leakage power at the 99% percentile with 1% delay penalty when compared with the approaches used in previous gain-based mappers [2]. Also, compared to a dominant-state mapper, our approach produces mappings with 15% lesser mean value of leakage. The new algorithm also reduces leakage at high quantiles by 12.8% on average, compared to a dominant state leakage minimizing mapper and the maximum savings can be as high as 21.49% across the benchmarks. Compared to the bin based mapper [10], the runtime of the algorithm is 15X faster.	algorithm;benchmark (computing);computer cooling;mapper;mike lesser;programming paradigm;spectral leakage	Ashish Kumar Singh;Murari Mani;Ruchir Puri;Michael Orshansky	2006	2006 43rd ACM/IEEE Design Automation Conference	10.1145/1146909.1147046	probability distribution;mathematical optimization;electronic engineering;real-time computing;computer science;statistics	EDA	22.547032096599402	57.85815356141225	107795
23dbe199c2ff09c43b14a2558c2f11e60c6ff98a	on board processor development for nasa's spaceborne imaging radar with vlsi system-on-chip technology	synthetic aperture radar;microprocessor chips;nasa spaceborne imaging radar;processing requirement analysis;system-on-chip;on board processor development;vlsi system-on-chip technology;vlsi;performance evaluation;spaceborne radar;radar imaging;on-board spaceborne sar processor;functional specifications;imaging radar;radar;system on a chip;propulsion;space based radar;system on chip;chirp;very large scale integration;evaluation;strips;azimuth;space technology;requirement analysis	This paper reports a preliminary study result of an on-board spaceborne SAR processor. It consists of a processing requirement analysis, functional specifications, and implementation with VLSI system-on-chip technology. Finally, a minimum version of this VLSI on-board processor designed for performance evaluation and for partial demonstration is illustrated.	functional specification;integrated circuit;on-board data handling;performance evaluation;requirements analysis;system on a chip;very-large-scale integration	Wai-Chi Fang;Michael Y. Jin	2004	2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No.04CH37512)		electronic engineering;computer science;engineering;electrical engineering;radar imaging	Embedded	10.140634588208474	51.86020515942394	107847
47a8f5432203558d16ee2b24713fb0be6834a29a	routing techniques for gate array	assignment problem;cmos technology;high density;routing;computer industry;electric breakdown;semiconductor device modeling;global routing;adaptive arrays;wiring;routing wiring automation computer industry adaptive arrays cmos technology semiconductor device modeling electric breakdown design methodology;design methodology;international development;automation	This paper describes the routing techniques used for a Hughes internally developed high-density silicon-gate bulk CMOS gate array family. This layout software can be easily adapted to different array sizes and/or technologies (e.g., bipolar) through a change of parameters. A routing model and hierarchical decomposition schemes are presented to address the routability issue. More specifically, this paper focuses on the formulation and analysis of global routing and vertical assignment problems and gives a systematic breakdown of the routing task into well-defined subtasks. Instead of performing sequential routing, techniques and formulations are introduced to achieve a high degree of order independency in all subtasks. In routing subtasks where iterations are required, independent selection and interconnection are performed to avoid order dependency in typical routing problems. Implementation results are provided to indicate the efficiency of the system.	cmos;gate array;global serializability;interconnection;iteration;routing	Ben Ting;Bou Nin Tien	1983	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.1983.1270048	embedded system;routing;electronic engineering;semiconductor device modeling;real-time computing;international development;design methods;computer science;engineering;electrical engineering;multipath routing;automation;assignment problem;link-state routing protocol;cmos;routing;computer network	EDA	14.97959578556234	51.87961604364186	107890
70a1400c8e567a8e16f7a111ad3fef634b89f9d9	frosty: a program for fast extraction of high-level structural representation from circuit description for industrial cmos circuits	digital circuit;cmos integrated circuits;computer program;circuit transistor;circuit integre cmos;estacion trabajo;puerta logica;algorithm performance;channel connected components;station travail;extraction forme;dispositif logique;circuito logico;structure tunnel;algorithme;porte logique;circuit numerique;algorithm;large scale;workstation;automatic recognition;extraccion forma;circuit logique;resultado algoritmo;pattern matching;feature extraction;grille transistor;circuito numerico;transistor circuits;performance algorithme;rejilla transistor;concordance forme;extraction caracteristique;channel structure;escala grande;connected component;logic circuit;logic gate;estructura tunel;pattern extraction;structural recognition;transistor gate;logic devices;reconocimiento automatico;reconnaissance automatique;industrial design;transistor;algoritmo;echelle grande	This paper presents FROSTY, a computer program for automatically extracting the high-level structural representation of a large-scale digital CMOS circuit from its transistor-level netlist and a library of subcircuit descriptions. To handle the complexity and diversity of industrial circuits, FROSTY combines traditional structural recognition and pattern matching methods into a two-step extraction process. First, logic structures based on channel-connected-components are recognized from a circuit netlist and from all library subcircuits, and are condensed into ‘‘macro devices’’ or called logic gates. This leads to hybrid netlists that contain the recognized logic gates and remaining transistors. Then annotated graphs representing the connectivity and properties of logic gates and remaining transistors are constructed. Compared to transistor-level netlists, these hybrid graphs are much smaller in size, more distinguishable in structure, and are thus more suitable for labeling-based pattern matching. An efficient pattern matching algorithm is then applied to extract the high-level structural representation from these condensed circuit graphs. FROSTY has demonstrated to be orders of magnitude faster than the pattern matching-based extraction program SubGemini, and can extract entire industrial designs with several hundreds of see front matter r 2005 Elsevier B.V. All rights reserved. vlsi.2005.07.002 rch was supported in part by the US Defense Advanced Research Project Agencies (DARPA) NeoCAD er Grant N66001-01-1-8920, and in part by the National Science Foundation (NSF) CAREER Award o. 9985507. This paper is an extended version of ‘‘FROSTY: A Fast Hierarchy Extractor for Industrial ts,’’ which appeared in Proceedings of the International Conference on Computer Aided Design (ICCAD), 03, pp. 741–747. ding author. Tel./fax: +1206 616 6410. resses: yanglei@ee.washington.edu (L. Yang), cjshi@ee.washington.edu (C.-J.R. Shi).	algorithm;cmos;computer program;digital electronics;high- and low-level;ibm notes;international conference on computer-aided design;logic gate;mathematical optimization;netlist;pattern matching;randomness extractor;simulation;transistor;vhdl;verilog;workstation;yang	Lei Yang;C.-J. Richard Shi	2006	Integration	10.1016/j.vlsi.2005.07.002	embedded system;electronic engineering;industrial design;logic gate;computer science;engineering;electrical engineering;algorithm	EDA	17.661080962451614	49.21859996901693	107929
03b76371d146befa01d628e3100735ca91e1b892	a note on state minimization of asynchronous sequential functions	sequential circuits associate members tellurium minimization methods;sequential circuits;tellurium;minimization methods;associate members	A procedure is described for minimizing the number of states in an asynchronous sequential function when the restriction exists that the input cannot change while the sequential function is in an unstable state. Furthermore, a procedure is described for minimizing the number of states in a sequential function when the restriction also exists that each output can change at most once during the time required for a transition from one stable state to another.		Marvin C. Paull;G. Waldbaum	1967	IEEE Trans. Electronic Computers	10.1109/PGEC.1967.264619	mathematical optimization;electronic engineering;discrete mathematics;engineering;tellurium;mathematics;sequential logic;algorithm	EDA	22.761092022851575	46.82218155322938	108020
94ee2932ee8c0f88ec0cf9944afd8d824ba174ac	a flow graph technique for dft controller modification	control data flow graph representation;design for testability;pre computed test vector;data flow graphs;pre computed test vector flow graph technique dft controller modification design for testability rt level description control data flow graph representation rtl circuit post behavioral synthesis information;flow graphs testing;flow graph technique;integrated circuit testing data flow graphs design for testability;post behavioral synthesis information;integrated circuit testing;dft controller modification;rtl circuit;rt level description	This paper presents a novel DFT method which requires very small modification to a controller in RT-level description of a circuit. The control/data flow graph (CDFG) representation of an RTL circuit is used for analyzing the testability of individual RT-level operations within a hierarchical test technique. Using a non-scan arrangement, existing data paths are utilized to provide controllability and observability to RT-level operations. Furthermore, additional data paths are introduced by altering the controller states or signals. Post behavioral synthesis information and pre-computed test vectors of the individual modules are utilized. This method considerably reduces the test application time by ignoring unnecessary control states in the test process	dataflow;high-level synthesis;precomputation	Mohammad Hosseinabady;Pejman Lotfi-Kamran;Pedram A. Riahi;Fabrizio Lombardi;Zainalabedin Navabi	2005	Proceedings 2005 IEEE International SOC Conference	10.1109/SOCC.2005.1554454	electronic engineering;real-time computing;computer science;theoretical computer science;design for testing;algorithm	EDA	19.892011797241477	47.78548453107822	108041
7f05a23d30a17ef8a36b6d7a281eb868968bf4d4	the evaluation of full sensitivity for test generation in mvl circuits	circuit faults;boolean functions;multivalued logic circuits;boolean algebra;circuit analysis computing multivalued logic circuits fault diagnosis logic testing;m valued n variable functions;logic testing;circuit testing circuit faults logic testing combinational circuits integrated circuit testing computer science boolean functions boolean algebra;integrated circuit testing;mvl circuits;multi valued logic circuits test generation full sensitivity evaluation mvl circuits functional level m valued n variable functions;test generation;circuit testing;multi valued logic circuits;computer science;circuit analysis computing;functional level;full sensitivity evaluation;lower bound;fault diagnosis;combinational circuits	The evaluation of a method for test generation for MVL circuits, based on the notion of full sensitivity, is given. The estimation is made on the functional level, by establishing a lower bound on the number of m-valued n-variable functions that are fully sensitive to all their variables. It is shown, that for practical values of m and n, the fraction of functions not fully sensitive to all their variables is extremely small. The consequences of this result in terms of test generation are discussed.		Elena Dubrova;Dilian Gurov;Jon C. Muzio	1995		10.1109/ISMVL.1995.513517	boolean algebra;electronic engineering;discrete mathematics;computer science;mathematics;combinational logic;boolean function;upper and lower bounds;algorithm;algebra	EDA	20.94486146710984	48.50959670267168	108079
3457e9ba8e0255804b4e898bffdb114b5671a784	delay and power estimation models of low-swing interconnects for design planning	power estimation;low swing interconnect;lookup table;estimation model;power;delay estimation	In this paper, we present a lookup table based model for delay and power estimation of low-swing interconnects: LSIEM. It can be used during high-level design planning, synthesis, and simulation of interconnect-centric VDSM designs. LSIEM is an accurate and efficient high-level estimation model. It has been tested on a wide range of parameters and shown to have over 90% accuracy with respect to HSPICE simulation results.	electrical connection;high- and low-level;level design;lookup table;spice 2;simulation	Xiangyuan Liu;Shuming Chen	2006		10.1145/1127908.1127932	electronic engineering;parallel computing;real-time computing;lookup table;computer science;power;algorithm	EDA	15.149784620497536	55.125588521966606	108174
fe638fd9b96dbfb0330daf2ac576c82af9b10c2c	large-scale integration from the user's point of view	large scale integration;system design;point of view	The potential LSI user views LSI promise with a great deal of anticipation, but LSI problems with some trepidation. Obviously, he hopes for breakthroughs to relieve the strain of having to squeeze the last bit of cost or performance from the existing technological approaches---and of having to contend with the added hardware and software problems fostered by the need to improve his product only through system complexity. There are, in fact, very few things the system designer can do that have the impact of a significant technology advance in cost or performance.	bra–ket notation;computer terminal;electronic circuit;systems design;very-large-scale integration	Merlin G. Smith;William A. Notz	1967		10.1145/1465611.1465623	simulation;engineering;operations management	Arch	10.033722670265018	56.821152112151374	108177
95fd7b21145b0c678b625e0b479c0bf532d4eed8	circuit placement challenges: technical perspective	technical perspective;circuit placement challenge	out high-density regions to estimate a desirable placement. This concept of look-ahead legalization is similar to what was previously proposed for floor-planning at UCLA and for placement in my group at NTU. However, SimPL develops a new algorithm that implements look-ahead legalization using geometric partitioning and nonlinear scaling. Equally important is the systematic use of look-ahead legalization in global-placement iterations that is characteristic of SimPL. Here the idea is to treat the legalized component locations as fixed anchors (like the Vasstu algorithm) to which the components are tethered with artificial interconnects when the lower-bound placement is produced by quadratic programming. With an appropriate substitution , such connections to fixed locations do not increase the matrix size for quadratic optimization and, in fact, enhance diagonal dominance in matrix solvers, leading to faster convergence. Among the two major families of analytical placers, quadratic placers (for example, Kraftwerk2 and SimPL) are typically more efficient, while non-linear (non-quadratic) placers (for example, mPL and NTUplace series) often have better placement quality. To avoid biases with respect to specific circuit structures, more studies based on multiple sets of benchmarks (including at least recently released IBM benchmark suites) would be needed to explore the stability of a placer. Yet, interconnect length and overlap optimization alone is certainly not the end objective of modern placement. Emerging technologies and needs bring up substantial new challenges; some most addressed challenges include large-scale mixed-size placement with millions of cells and hun-dreds/thousands of big circuit blocks, routability, timing, manufacturability, reliability, power delivery, clock networks , 3D ICs, asynchronous designs, and parallelism. These challenges offer substantial placement research opportunities for the decades to come. Yao-Wen Chang is a distinguished professor, chair of the graduate Institute of electronics engineering, and associate dean of the college of electrical engineering and computer Science, National taiwan university, taipei. For a sEmiCondUCtor circuit with billions of transistors, finding desired locations of circuit components is a challenging task that substantially impacts circuit quality and manufacturing cost. On-chip components must not overlap and should simultaneously optimize several conflicting cost metrics, such as silicon area, circuit performance, and power. Circuit placement—studied since the invention of the integrated circuit (IC)—re-mains one of the most important steps in VLSI design because it determines the landscape of a silicon chip and increasingly influences other circuit optimizations. Even as a purely computational task, it is difficult. Emerging technology and design challenges have further reshaped the …	algorithm;benchmark (computing);computer science;design for manufacturability;diagonally dominant matrix;electrical connection;electrical engineering;electronic engineering;image scaling;invention of the integrated circuit;iteration;mathematical optimization;network interface device;nonlinear system;parallel computing;quadratic programming;semiconductor;the matrix;transistor;very-large-scale integration;yao graph	Yao-Wen Chang	2013	Commun. ACM	10.1145/2461256.2461278	theoretical computer science;computer engineering;computer science	EDA	12.666460606197646	55.32586324183526	108188
b8543809a907645f2aa1ee486c3d4f6dc4104737	design methods for misaligned and mispositioned carbon-nanotube immune circuits	size 32 nm;design methodology carbon nanotubes silicon inverters fets circuit simulation cmos technology delay fabrication logic functions;misaligned and mispositioned cnt immune circuits;network synthesis;carbon nanotube field effect transistors;misaligned and mispositioned cnt immune circuits carbon nanotube cnt field effect transistors cnfets;field effect transistor circuits;boolean functions;carbon nanotubes;cntfets;cmos inverters;inverters;cnt immune logic structures;layout;c carbon nanotube field effect transistors cnfet inverters cnt immune logic structures cmos inverters size 32 nm;lithography;carbon nanotube;design method;logic gates;cnfet inverters;transistors;nanoelectronics;invertors;carbon nanotube cnt field effect transistors cnfets;network synthesis carbon nanotubes field effect transistor circuits invertors nanoelectronics;field effect transistor;energy delay product;c	Carbon-nanotube (CNT) field-effect transistors (CNFETs) are promising extensions to silicon CMOS. Simulations show that CNFET inverters fabricated with a perfect CNFET technology have 13 times better energy delay product compared with 32-nm silicon CMOS inverters. The following two fundamental challenges prevent the fabrication of CNFET circuits with the aforementioned advantages: 1) misaligned and mispositioned CNTs and 2) metallic CNTs. Misaligned and mispositioned CNTs can cause incorrect functionality. This paper presents a technique for designing arbitrary logic functions using CNFET circuits that are guaranteed to implement correct functions even in the presence of a large number of misaligned and mispositioned CNTs. Experimental demonstration of misaligned and mispositioned CNT-immune logic structures is also presented.	cmos;carbon cycle;computer simulation;inverter (logic gate);transistor	Nishant Patil;Jie Deng;Albert Lin;H.-S. Philip Wong;Subhasish Mitra	2008	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2008.2003278	lithography;electronic engineering;carbon nanotube;computer science;electrical engineering	EDA	15.85841530040155	58.559464448030624	108201
29b3c6b9b8c513652799671aebf6c9a8d6617e9e	test architecture design and optimization for three-dimensional socs	simulated annealing;cpld;integrated circuit;design optimization;routing;vhdl;cost function;three dimensional;testing;iec 61508;system on a chip;optimization;system on chip	Core-based system-on-chips (SoCs) fabricated on three-dimensional (3D) technology are emerging for better integration capabilities. Effective test architecture design and optimization techniques are essential to minimize the manufacturing cost for such giga-scale integrated circuits. In this paper, we propose novel test solutions for 3D SoCs manufactured with die-to-wafer and die-to-die bonding techniques. Both testing time and routing cost associated with the test access mechanisms in 3D SoCs are considered in our simulated annealing-based technique. Experimental results on ITC'02 SoC benchmark circuits are compared to those obtained with two baseline solutions, which show the effectiveness of the proposed technique.	baseline (configuration management);benchmark (computing);integrated circuit;mathematical optimization;routing;simulated annealing;system on a chip	Li Jiang;Lin Huang;Qiang Xu	2009	2009 Design, Automation & Test in Europe Conference & Exhibition		system on a chip;embedded system;electronic engineering;computer science;engineering;manufacturing engineering	EDA	13.777392079615453	53.07180236819957	108224
96f5748e3e2bf3c894d84a2875f7f4e7e045c310	the minimal test set for multioutput threshold circuits implemented as sorting networks	detection erreur;simple cell;fonction booleenne;deteccion error;integrated circuit;logic design;symmetric function;boolean functions;building block;sorting;threshold logic boolean functions logic circuits logic testing;circuit testing sorting tin logic testing hardware electrical fault detection boolean functions fault detection circuit faults pipeline processing;boolean function;logic circuits;conception;circuito integrado;unidirectional error detecting codes;tria;indexing terms;test;threshold logic;threshold circuit;ensayo;sorting networks;multioutput threshold circuits;essai;conception logique;sorting network;funcion booliana;fault detection;triage;logic testing;diseno;test generation;design;error detection;symmetric threshold functions;concepcion logica;minimal test set;unidirectional error detecting codes minimal test set multioutput threshold circuits sorting networks n input symmetric threshold functions boolean functions threshold circuit;circuit integre;n input	It is shown that an n-input sorting network (SN) can be used to implement an n-variable symmetric threshold functions using the least amount of hardware. An algorithm to derive Boolean functions implemented on any line of any n-input threshold circuit T/sup n/ implemented as a SN is given. A heuristic procedure for generating the minimal test set for any threshold circuit T/sup n/ implemented as a Batcher's SN or any other SN is presented. The number of tests required to detect all stuck-at faults in an n-input SN is determined. A highly regular structure using only one type of simple cell and a suitability for low-level pipelining are other advantages of the circuit T/sup n/. The circuit T/sup n/ can be used as a basic building block of various circuitry supporting the use of all known unidirectional error detecting codes. >	sorting network;test set	Stanislaw J. Piestrak	1993	IEEE Trans. Computers	10.1109/12.277288	sorting network;computer science;theoretical computer science;mathematics;boolean function;algorithm	EDA	21.488328980860135	48.685918289028365	108273
bd8d39135ffa8a7d3e088cd2b8cd2cf4892daa13	a new technique for the high-level synthesis of digit-serial digital filters based on genetic algorithms		This paper is concerned with the exploitation of genetic algorithms and their application to the development of a new optimization technique for the high-level synthesis of digit-serial digital filter data-paths. In the resulting optimization technique, the cost associated with the final digital filter data-path is minimized subject to user-specified constraints on the number of physical arithmetic functional units employed. The proposed technique is capable of obtaining global area-optimal, time-optimal, or combined area-cum-time-optimal data-paths, where the optimality takes into account not only the cost associated with the required arithmetic functional units but also that associated with the required support cells (multiplexors and registers). This optimization is made computationally effective by encoding the digital filter data flow-graph into chromosomes which preserve the data-dependency relationships in the original digital filter signal flow-graph under the operations of crossover and mutation by the underlying genetic algorithm. The usefulness of the proposed technique is demonstrated by applying to the constrained optimization of a benchmark elliptic wave digital filter for full bit-serial, full bit-parallel, as well as general digit-serial high-level synthesis. The results thus obtained are compared to those of the existing techniques (whenever appropriate) to confirm the validity of the technique.	genetic algorithm;high-level synthesis	Janardhan H. Satyanarayana;Behrouz Nowrouzian	1997	Journal of Circuits, Systems, and Computers	10.1142/S0218126697000395	adaptive filter;mathematical optimization;computer science;theoretical computer science;filter design;algorithm	EDA	10.828078869426466	48.80837955023117	108290
7613bc46bb5ef802978deb124d4404c6d0371022	modeling and power evaluation of on-chip router components in spintronics	network on chip noc;cmos integrated circuits;elektroteknik och elektronik;electrical engineering electronic engineering information engineering;logic circuits;mtj;network routing;router spintronics mtj network on chip noc;cmos logic circuits;magnetic tunnelling;magnetoelectronics;low power electronics;spintronics;router;magnetic tunneling switches cmos integrated circuits resistance power demand integrated circuit modeling semiconductor device modeling;network routing cmos integrated circuits cmos logic circuits logic circuits low power electronics magnetic tunnelling magnetoelectronics;crossbar power evaluation on chip router component spintronics cmos based power saving technique magnetic tunnel junction devices switching power consumption	On-chip routers are power hungry components. Besides exploiting current CMOS-based power-saving techniques, it is also desirable to investigate the power saving potential enabled by new technologies and devices. This paper investigates the potential of exploiting the emerging spin-electronics based MTJ (Magnetic Tunnel Junction) devices with application to on-chip router modules, in particular, buffers and crossbars. To this end, we build MTJ models, design circuits based on mixed MTJ-CMOS devices, and evaluate their switching power consumption, using their pure CMOS counterparts as the baseline. Our study shows that the new technology can significantly improve power efficiency for buffers but the gain for crossbars is less clear.	baseline (configuration management);cmos;performance per watt;router (computing);spintronics	Pierre Schamberger;Zhonghai Lu;Xianyang Jiang;Meikang Qiu	2012	2012 IEEE/ACM Sixth International Symposium on Networks-on-Chip	10.1109/NOCS.2012.13	embedded system;routing;logic gate;computer science;operating system;cmos;low-power electronics;computer network;spintronics	Arch	14.787254949961573	57.25789999270938	108474
88e96374f7adfa036d0ee876c30cc84c2b846b29	variation-aware macromodeling and synthesis of analog circuits using spline center and range method and dynamically reduced design space	cycle time;dynamically reduced design space;spline;process variation;performance evaluation;time complexity;analog;building block;spline center;gain;target design region graph;manufacturing and processing;analog building blocks;system performance;design space;splines mathematics;analog circuits;integrated circuit design;target design region graph variation aware macromodeling analog circuits spline center range method dynamically reduced design space analog building blocks macromodel generation process;accuracy;analogue integrated circuits;splines mathematics analogue integrated circuits integrated circuit design integrated circuit modelling;range method;integrated circuit modelling;system on chip;macromodel;integrated circuit modeling;macromodel generation process;mathematical model;adaptive sampling;time to market;algorithm design and analysis;variation aware macromodeling;circuit synthesis analog circuits spline space technology degradation convergence manufacturing processes time to market system on a chip system performance;macromodel process variation analog	Manufacturing and process irregularities in nanometer technologies can degrade yield and severely slow down the design cycle time. Process variation aware methodologies can help in yield improvement and meeting time-to-market requirements for system-on-chip designs. Analog circuits are extremely sensitive to device mismatches and exhibit non-linear variations in their performance under the influence of manufacturing irregularities. Performance variation in blocks can lead to degraded system performance. In this work, we present a variation-aware performance macromodeling technique for analog building blocks that is fast and accurate and guarantees convergence during synthesis. The improvements in accuracy and time complexity of the macromodel generation process is achieved by constructing a target design region graph and dynamic reduction of the design space. The target design region also helps in reducing time during re-synthesis and achieving faster convergence. Experimental results demonstrate the accuracy of the macromodels and the reduction in synthesis time compared to spice based simulation-in-the-loop evaluations and static and adaptive sampling based techniques.	adaptive sampling;data structure;graph (abstract data type);integrated circuit;macromodel;marginal model;nonlinear system;requirement;sampling (signal processing);simulation;spline (mathematics);system on a chip;time complexity	Shubhankar Basu;Balaji Kommineni;Ranga Vemuri	2009	2009 22nd International Conference on VLSI Design	10.1109/VLSI.Design.2009.51	system on a chip;control engineering;spline;time complexity;embedded system;algorithm design;electronic engineering;real-time computing;analogue electronics;gain;cycle time variation;computer science;engineering;mathematical model;accuracy and precision;computer performance;process variation;algorithm;integrated circuit design	EDA	23.230563384878167	58.50276026803396	108586
36ca9ca6a587cbfda11f1719dda3bf993f2785e3	design-for-test methodology for non-scan at-speed testing	observability;state space methods design for testability flip flops;design for testability;pins;state space methods;circuit faults;functional testing;automatic test pattern generation;flip flops;circuit faults logic gates pins automatic test pattern generation observability discrete fourier transforms;d flip flops;logic gates;design for test methodology;state space;discrete fourier transform;fault coverage;design for test;scan based testing;d flip flops design for test methodology scan based testing fault coverage functional testing state space;automatic test pattern generator;discrete fourier transforms;logic gate	While scan-based testing achieves a high fault coverage, it requires long test application times and substantial tester memory, in addition to the overhead in chip area and high test power. Functional testing, on the other hand, suffers from low coverage but can be applied at-speed. In this paper, we propose a novel three-step design-for-test (DFT) methodology which enhances the performance of functional testing to a great extent. In the first step we expand the state space of the circuit beyond functionally reachable space without scan or reset. These new states create conditions to activate/propagate fault effects that are otherwise hard-to-detect. Since structural correlation between D flip-flops (DFFs) of a circuit restricts its state space variation, the second step consists of partitioning the DFFs into different groups that helps to break such correlations. In the third step, we make internal hard-to-observe points in the circuit more observable by directly XORing them with selected primary outputs. This method can be applied at-speed (since no scan shifting is involved) saving significant amount of test application time, with comparable area overhead as scan-based DFT. Our experiments on large ISCAS'89 and ITC'99 benchmarks show that we are able to achieve very high non-scan fault coverages while simultaneously reducing the test application time (114×) as compared to scan based techniques.	design for testing;device under test;exclusive or;experiment;flops;fault coverage;flip chip;flip-flop (electronics);functional testing;heuristic;observable;overhead (computing);state space;structural cut-off	Mainak Banga;Nikhil P. Rahagude;Michael S. Hsiao	2011	2011 Design, Automation & Test in Europe	10.1109/DATE.2011.5763041	embedded system;electronic engineering;real-time computing;logic gate;engineering;design for testing	EDA	21.325543455019975	51.98655306445535	108667
562fa74f9143c69fda30544965b70073ebd4a1a5	towards structured asics using polarity-tunable si nanowire transistors	silicon;si polarity tunable nanowire transistor semiconductor device cmos technology ambipolar behavior p type characteristics n type characteristics double gate all around vertically stacked nanowire fet dg nwfet arithmetic logic function structured asic application;xor logic synthesis nanowire transistors controllable polarity regular fabrics;xor logic synthesis;logic gates silicon cmos integrated circuits field effect transistors logic functions design automation;logic circuits;elemental semiconductors;integrated circuit design;nanowire transistors;regular fabrics;controllable polarity;application specific integrated circuits;field effect transistors;nanowires;silicon application specific integrated circuits elemental semiconductors field effect transistors integrated circuit design logic circuits nanowires	In addition to scaling semiconductor devices down to their physical limit, novel devices show enhanced functionality compared to conventional CMOS. At advanced technology nodes, many devices exhibit ambipolar behavior, i.e., they show n- and p-type characteristics simultaneously. This phenomenon can be tamed using double-gate structures. In this paper, we present a complete framework relying on Double-Gate-all-around Vertically stacked NanoWire FETs (DG-NWFETs). Such device enables a compact realization of arithmetic logic functions and presents unprecedented interest for structured ASIC applications.	application-specific integrated circuit;arithmetic logic unit;cmos;discontinuous galerkin method;image scaling;semiconductor device;transistor	Pierre-Emmanuel Gaillardon;Michele De Marchi;Luca Gaetano Amarù;Shashikanth Bobba;Davide Sacchetto;Yusuf Leblebici;Giovanni De Micheli	2013	2013 50th ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2463209.2488886	field-effect transistor;electronic engineering;nmos logic;logic gate;logic family;computer science;electrical engineering;integrated circuit;pass transistor logic;application-specific integrated circuit;integrated injection logic;silicon;cmos;pmos logic;nanowire;resistor–transistor logic;integrated circuit design	EDA	15.982599659134406	58.96714662059022	108710
2ecd9a2ac84a427f89ca09cbe932ee0e3143a553	detecting faults in the peripheral circuits and an evaluation of sram tests	sram chips;fault diagnosis;integrated circuit testing;0.13 micron;512 kbyte;march algorithms;march test;sram chips;sram test;fault detection;memory peripheral circuits	Very little has been published on faults in the memory peripheral circuits, denoted as 'PFs'. This work shows that PFs are detected by March tests, provided that they satisfy particular properties, expressed in terms of properties of the algorithm, and of properties of the algorithm stress. The latter consists of the used data backgrounds and addressing directions. The detection capabilities of a set of well-known March algorithms are established for the PFs. In addition, industrial results from applying this set of tests to a large number of 0.13 micron 512 Kbyte SRAM chips, combined with a variety of stress conditions, are presented.	address decoder;algorithm;kilobyte;lr parser;magnetic stripe card;memory management;peripheral;read-write memory;sense amplifier;sensor;static random-access memory	Ad J. van de Goor;Said Hamdioui;Rob Wadsworth	2004	2004 International Conferce on Test	10.1109/ITC.2004.59	chip;embedded system;electronic engineering;real-time computing;fault coverage;telecommunications;computer science;engineering;satisfiability	EDA	21.457898472131188	53.78292382488805	108766
92b6ab7c42b2e13e2ecb8dd92ce1e6f36a13bc8a	a fast and exact cell matching method for mux-based fpga technology mapping	mux based fpga technology mapping;libraries;pattern matching field programmable gate arrays multiplexing equipment circuit cad;logic;multiplexing equipment;minimization methods;integer comparison operations;computer architecture;cell matching method;pattern matching;impedance matching;target architecture;circuit cad;computer science;field programmable gate arrays;technology mapping;computation time;electronics packaging;computation time cell matching method mux based fpga technology mapping multiplexers cell library target architecture integer comparison operations mcnc benchmarks;cell library;multiplexers;field programmable gate arrays libraries pattern matching computer science computer architecture electronics packaging impedance matching logic minimization methods;matching method;mcnc benchmarks	This paper presents a new cell matching method which could be effectively used for MUX-based FPGA technology mapping. In this method, a well organized cell library of a manageable size is constructed for each target architecturea priori, and cell matchings are performed by searching the corresponding entry in the library using integer comparison operations. Experimental results for some MCNC benchmarks show that our approach indeed reduces significantly the computation time, while preserving the exact cel l matching.	computation;field-programmable gate array;multiplexer;time complexity	Kang Yi;Seong Yong Ohm	1999		10.1109/ICCD.1999.808559	embedded system;impedance matching;electronic engineering;computer science;theoretical computer science;operating system;pattern matching;programming language;logic;computer engineering	EDA	14.213405800995629	47.47187329624014	108791
0b40ef1c6394f9eff1748cdaa5832df6f2be9810	it isn't just testing anymore (redux)	design for testability;inspection techniques;automatic testing manufacturing costs marine vehicles production nails design for testability concurrent engineering built in self test inspection;aoi;automatic testing;automatic optical inspection;production testing integrated circuit testing printed circuit testing inspection;self tests test strategies aoi inspection techniques automatic optical inspection post paste inspection post placement inspection post reflow inspection;inspection;post placement inspection;built in self test;test strategies;marine vehicles;manufacturing;integrated circuit testing;post reflow inspection;production;printed circuit testing;production testing;post paste inspection;self tests;concurrent engineering;nails	"""For decades, test professionals touted the virtues first of design for testability and later concurrent engineering. Unfortunately, product complexity and the limitations of traditional test have reduced the effectiveness of such proactive techniques and forced us to look again at what remains within what we still call """"test"""". To cope with today's challenges, test strategies must now consider taking advantage of self-tests, incorporating various forms of inspection, and minimizing overlap between test steps."""	design for testing;software testability	Stephen F. Scheiber	2000		10.1109/TEST.2000.894267	test strategy;reliability engineering;inspection;engineering;design for testing;manufacturing;forensic engineering;engineering drawing;concurrent engineering	SE	23.777969255193923	53.89327223590309	109207
d872ad967d8813d289aa326b64b7249c6300daa8	device design and analysis of logic circuits and srams for germanium finfets on soi and bulk substrates	silicon;random access memory performance evaluation geology silicon inverters abstracts logic circuits;sram chips germanium logic circuits logic design mosfet semiconductor doping silicon silicon on insulator;logic design;semiconductor doping;silicon on insulator;logic circuits;logic circuit finfet germanium band to band tunneling sram;band to band tunneling;proceedings paper;germanium;mosfet;sram;logic circuit;si sram cell leakage delay performance puax asym access transistor asymmetric underlap pull up optimum asymmetric underlap design leakage reduction channel doping btbt leakage band to band tunneling leakage parasitic bipolar effect ge bulk finfet germanium on bulk substrate finfet geoi finfet germanium on insulator finfet soi germanium finfet logic circuit analysis device design ge;finfet;sram chips	A comparative analysis of Germanium-on-Insulator FinFET (GeOI FinFET) and Germanium on bulk substrate FinFET (Ge bulk FinFET) at device and circuit level with respect to Si counterparts is presented. GeOI FinFET shows larger leakage current than Ge bulk FinFET due to the parasitic bipolar effect triggered by the band-to-band tunneling (BTBT) leakage. The effectiveness of different dual-Vt technology options including increasing channel doping, increasing gate length and drain-side underlap for leakage reduction is analyzed for GeOI and Ge bulk FinFET circuits and SRAMs. An optimum asymmetric underlap design in SRAM using asymmetric underlap pull-up and access transistors (PUAX-asym) is proposed. GeOI and Ge bulk FinFETs with asymmetric underlap design show significant improvement in leakage-delay performance and stability in logic circuits and SRAM cells.	doping (semiconductor);logic gate;qualitative comparative analysis;silicon on insulator;spectral leakage;static random-access memory;topological insulator;transistor;tunneling protocol	Vita Pi-Ho Hu;Ming-Long Fan;Pin Su;Ching-Te Chuang	2013	International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2013.6523633	electronic engineering;logic gate;computer science;electrical engineering;nanotechnology	Arch	17.31547596057701	59.809421516007305	109421
332caa4a33dbb713f23a68c4ceda7c81223b66cc	soc test: the devil is in the details of integration/implementation	automatic testing application specific integrated circuits integrated circuit testing built in self test design for testability;design for testability;automatic testing;system on a chip;chip;built in self test;application specific integrated circuits;system design;integrated circuit testing;testing system on a chip built in self test packaging electronic design automation and methodology pins forward contracts costs logic design analytical models;multi functional chips systems on a chip testing implementation problems tester time reduction test execution high pin count ate testing unmodeled defects detection design complexity bist type solutions integration problems testability system chip level test responsibility design phase planning	In following the uproar and wide-spread talk about systems-on-a-chip (SOC) and its associated challenges, it is interesting to note that different people have varying notions and interpretations of SOC. It may be prudent to establish a base level definition of SOC. In the context of testing large multi-functional chips, SOC can be defined to be any chip that has more than 1 million gates and/or 1000+ package pins. Usually, such devices are single chip solutions that contain as many cores, memories and functional elements as is possible to fit in one die with a view to get the best price/ performance ratio as permitted by the latest technology.	die (integrated circuit);system on a chip	Kamalesh N. Ruparel	1998		10.1109/TEST.1998.743343	chip;system on a chip;embedded system;black-box testing;electronic engineering;real-time computing;white-box testing;telecommunications;integration testing;computer science;engineering;test compression;design for testing;application-specific integrated circuit;system testing;test management approach;systems design	DB	10.343890515231871	54.866671842855396	109475
44c7aac61013261abd15d48d5680eec93bb40e6c	simulation-based diagnosis for crosstalk faults in sequential circuits	crosstalk faults;primary outputs;logic simulation;observed responses;timeframe;cpu time;circuit faults;fault simulation;crosstalk;clocks;diagnosis methods;automatic testing;sequential circuits;circuit simulation fault diagnosis crosstalk circuit faults sequential circuits pulse circuits circuit testing central processing unit clocks computational modeling;state information;pulse faults;simulated values;circuit simulation;pulse circuits;computational modeling;iscas 89 benchmark circuits;logic testing;circuit testing;sequential circuits simulation based diagnosis pulse faults fault simulation observed responses simulated values primary outputs suspected faults diagnosis methods timeframe test sequence iscas 89 benchmark circuits state information cpu time primary output values crosstalk faults;primary output values;suspected faults;simulation based diagnosis;test sequence;central processing unit;automatic testing fault simulation crosstalk logic simulation fault diagnosis logic testing sequential circuits;fault diagnosis	Describes two methods of diagnosing crosstalk-induced pulse faults in sequential circuits using crosstalk fault simulation. These methods compare with observed responses and simulated values at primary outputs to identify a set of suspected faults that are consistent with the observed responses. In these methods, if the simulated values agree with the observed responses, then the simulated fault is added to a set of suspected faults, otherwise the simulated fault is removed from the set of suspected faults. The diagnosis methods repeat the above process for each time frame to identify the suspected faults. The first method is a basic method which determines the suspected fault list by using the knowledge about the first and last failures of the test sequence. The second method uses state information and focuses on reducing the CPU time for diagnosing the faults. The CPU time is reduced by using stored state information to calculate the primary output values at the present time frame. Experimental results for ISCAS'89 benchmark circuits show that the number of suspected faults obtained by our methods is sufficiently small, and the second method is substantially faster than the first method.	crosstalk;simulation	Hiroshi Takahashi;Marong Phadoongsidhi;Yoshinobu Higami;Kewal K. Saluja;Yuzo Takamatsu	2001		10.1109/ATS.2001.990260	embedded system;electronic engineering;real-time computing;crosstalk;computer science;engineering;operating system;cpu time;central processing unit;logic simulation;sequential logic;computational model	EDA	22.695486871832042	51.06184820460504	109501
205d20354084f7a54dc7f76b996255ece38ae783	comparison of effectiveness of current ratio and delta-iddq tests	semiconductor device testing;leakage current;circuit faults chromium leakage current logic testing histograms semiconductor device measurement production temperature measurement large scale integration sensitivity analysis;chip;leakage currents;test methods;industrial test data current ratio delta i sub ddq test semiconductor manufacturers deep submicron technology defects detection;deep sub micron;semiconductor manufacturing;semiconductor device testing leakage currents	I/sub DDQ/ test is a valuable test method for semiconductor manufacturers. However, its effectiveness is reduced for deep sub-micron technology chips due to rising background leakage. Current two test methods that promise to extend the life of I/sub DDQ/ test are Current Ratio and Delta-I/sub DDQ/. Although several studies have been reported on these methods, their effectiveness in detecting defects has not been contrasted. In this work, we compare these two methods using industrial test data.	iddq testing	Sagar S. Sabade;D. M. H. Walker	2004		10.1109/ICVD.2004.1261043	chip;electronic engineering;telecommunications;computer science;engineering;electrical engineering;leakage;test method;forensic engineering;semiconductor device fabrication	HCI	22.74083986984188	55.01750950564972	109616
ad34314912702a2c59f96087f0ee19bf8d72418a	bist pattern generators using addition and subtraction operations	accumulator;adder;pattern generation;linear feedback shift register;subtracter;arithmetic logic unit;built in self test;pattern generator;test methods;fault coverage	Configurations of adders, subtracters, or arithmetic logic units and registers, which are available in many data paths, can be utilized to generate patterns and to compact test responses. This paper analyzes the pattern sequences generated by configurations with different types of adders and subtracters. For many different seeds and constant input values, these pattern generators can produce a sequence of all possible patterns. Moreover, k-bit pattern generators that take into account the overflow or underflow bit can generate bit sequences that all have period 2^k-1. Thus, the periodicity of these pattern generators is the same as that of ak -bit linear feedback shift register with a primitive characteristic polynomial. Experimental results show that the produced pattern sequences achieve similar fault coverage as pseudorandom sequences and require about the same test length. Compared to the well-known self-test methods that insert test registers, the approach using available arithmetic units saves the additional gates that are needed to implement test registers, and it avoids performance degradation due to additional delays.	built-in self-test	Albrecht P. Stroele	1997	J. Electronic Testing	10.1023/A:1008299817888	arithmetic;accumulator;electronic engineering;fault coverage;computer science;arithmetic logic unit;digital pattern generator;mathematics;linear feedback shift register;test method;algorithm;adder;statistics	Theory	20.551880555146074	51.28282345394116	109670
156e86a0e8e84a6a5f05359e833240d7b5950e90	compositional microprogram control unit with operational automaton of transitions	logic circuits finite state machines;logic circuits;control unit synthesis compositional microprogram control unit operational transition automaton hardware amount;finite state machines	The using of operational automaton of transitions as the block of microinstruction addressing of compositional microprogram control unit is proposed. The new structure model of compositional microprogram control unit with reduced hardware amount is developed. The generalized structure of operational automaton of transitions is suggested. An example of process of synthesis of compositional microprogram control unit with operational automaton of transitions is given.	automaton;control unit;microcode	Alexander Barkalov;Roman Babakov;Larysa Titarenko	2013		10.1109/EWDTS.2013.6673189	control engineering;computer science;theoretical computer science;algorithm	Logic	10.037223825128214	50.11394631988718	109733
a856cda106173d66cf578eb74b50510b16d1b4e4	statistical library characterization using arbitrary polynomial chaos		The method of arbitrary polynomial chaos (aPC) is used to characterize the delay and subthreshold leakage of commercial 65nm and 28nm standard cell libraries. Delay and subthreshold leakage of a standard cell are modelled as orthogonal polynomial series of process variables. The aPC approach constructs the polynomials using only moments, and the coefficients of the polynomials are determined by minimum least squares, using samples generated by Monte Carlo simulation (MCS). The mean and standard deviation of delay and subthreshold leakage computed using aPC are within 1% of those computed using MCS while the aPC method results in a 25X-40X speed up over MCS.	cell (microprocessor);coefficient;die shrink;electrical connection;embedded system;ibm notes;least squares;library (computing);monte carlo method;multi categories security;polynomial;simulation;spectral leakage;speedup;standard cell	Mehmet Ince;Sule Ozev;Sarma B. K. Vrudhula	2017	2017 IEEE 8th Latin American Symposium on Circuits & Systems (LASCAS)	10.1109/LASCAS.2017.7948078	orthogonal polynomials;electronic engineering;standard deviation;monte carlo method;statistics;least squares;polynomial;random variable;subthreshold conduction;polynomial chaos;mathematics	Theory	23.232613978035406	59.27731962073386	109880
ab227178da266f17cde3ef348f33aabfed4e1d63	the linearized performance penalty (lpp) method for optimization of parametric yield and its reliability	concepcion asistida;computer aided design;microelectronic fabrication;fabricacion microelectrica;integrated circuit yield;fluctuations;integrated circuit;etude theorique;yield maximization methodology;parametric yield;metodo penalidad;optimization method;circuito integrado;metodo optimizacion;yield;linearized performance penalty method;ic yield;objective function;integrated circuit design;circuit simulation;manufacturing processes;ic yield linearized performance penalty method optimization parametric yield yield maximization methodology penalty function objective function computational effort operating point variations;penalty method;performance improvement;methode penalite;vectors;operating point variations;computational effort;integrated circuit modeling;estudio teorico;methode optimisation;conception assistee;optimization methods fluctuations integrated circuit modeling circuit simulation virtual manufacturing manufacturing processes vectors integrated circuit reliability circuit optimization circuit synthesis;circuit cad circuit optimisation integrated circuit yield integrated circuit design circuit analysis computing;optimization;circuit cad;rendimiento;theoretical study;integrated circuit reliability;circuit optimisation;circuit analysis computing;virtual manufacturing;rendement;circuit synthesis;circuit integre;circuit optimization;penalty function;fabrication microelectronique;optimization methods	A yield maximization methodology, called the linearized performance penalty (LPP) method, that uses a penalty function as its objective is introduced. The penalty function formulation allows the integration of the goals of circuit performance improvement and yield maximization. It is computationally efficient since the objective function can be evaluated with the computational effort of about one circuit simulation. Also, a simple, yet effective, method to account for operating point variations is introduced. The effectiveness of the LPP method is illustrated through several circuit examples.	mathematical optimization	Kannan Krishna;Stephen W. Director	1995	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.476585	mathematical optimization;electronic engineering;computer science;engineering;computer aided design;penalty method;mathematics;engineering drawing	EDA	17.62863339330241	53.820480723425014	109986
84c9553c77e9056f47c253d9b623db1a607e036d	a deterministic built-in-self-test generator based on cellular automata structures	signature analysis;built in self test vectors circuit testing automatic test pattern generation circuit faults circuit synthesis hardware circuit simulation benchmark testing combinational circuits;red logica programable;etude theorique;analyse signature;combinatorial circuits;regimen transitorio;implementation;automatic testing;simulation;approche deterministe;chip;circuit numerique;deterministic approach;ejecucion;built in self test cellular automata automatic testing logic testing fault diagnosis;unsteady state;built in self test;programmable logic array;automate cellulaire;circuit combinatoire;logic testing;enfoque determinista;finite automata;estudio teorico;reseau logique programmable;test vector generator;regime transitoire;cost effectiveness;fault coverage;automate fini;theoretical study;digital circuits;combinational circuit;cellular automata;cellular automaton;benchmark combinational circuits deterministic built in self test generator cellular automata structures precomputed test vectors atpg tool test vector generator deterministic test vector set simulation;autonomous finite state machine;fault diagnosis;analisis firma;automata celular	This paper proposes a new approach for designing a cost-effective, on-chip, deterministic, built-in, self-test generator. Given a set of precomputed test vectors (obtained by an ATPG tool) with a predetermined fault coverage, a simple test vector generator (TVG) is synthesized to apply the given test set in a minimal test time. To achieve this objective, cellular automata (CA) structures have been used in which the rule space is not limited to the linear rules commonly used in CA studies recently. Based on some new notations and new formulations of CA properties, two techniques are developed to synthesize such a TVG which is used to generate an orderedlunordered deterministic test vector set. The resulting TVG is very efficient in terms of hardware size and speed performance, and is very regular and testable. Simulation of various benchmark combinational circuits has given good results when compared to alternative solutions. Index Term-Cellular automata, test vector generator, programmable logic array, built-in self-test, autonomous finite-state machine.	automata theory;autonomous robot;benchmark (computing);built-in self-test;cellular automaton;combinational logic;fault coverage;finite-state machine;precomputation;programmable logic array;programmable logic device;simulation;test set;test vector generator;time-varied gain	Samir Boubezari;Bozena Kaminska	1995	IEEE Trans. Computers	10.1109/12.391181	chip;cellular automaton;parallel computing;cost-effectiveness analysis;fault coverage;programmable logic array;computer science;theoretical computer science;combinational logic;deterministic system;implementation;digital electronics;algorithm	EDA	19.222679010506752	49.150118295864544	110254
c3a17af6cae2565f5d9970d282fc756fb019dda0	flexible processor based on full-adder/ d-flip-flop merged module	0 6 micron;hardware logic circuits field programmable gate arrays software performance design engineering reconfigurable logic acceleration large scale integration flip flops cmos technology;cmos technology;submicron cmos technology;design engineering;dynamic reconfiguration;reconfigurable architectures;flip flop functions;hardware synthesis;reconfigurable logic;flip flops;logic circuits;0 6 micron flexible processor full adder d flip flop merged module logic functions flip flop functions context memory block dynamic reconfiguration software hardware synthesis submicron cmos technology vlsi chip;acceleration;software performance;large scale integration;cmos digital integrated circuits;vlsi chip;adders;logic functions;vlsi;software hardware synthesis;digital signal processing chips;full adder d flip flop merged module;field programmable gate arrays;digital signal processing chips cmos digital integrated circuits adders flip flops reconfigurable architectures vlsi;flexible processor;context memory block;flip flop;hardware	"""Flexible processor based on full-adder/D-flip-flop merged module (FDMM) has been designed and fabricated. The developed FDMM has unique ability to perform both logic and flip-flop functions with a small transistor counts by merging common part of both circuit. We have also developed a context memory block to reconfigure the hardware dynamically. The flexible processor may fill a gap between hardware performance and software programmability to jump into a novel computing such as software/hardware synthesis; """"software accelerator""""."""	adder (electronics);flops;flip-flop (electronics);transistor	Satoshi Sakaidani;Naoto Miyamoto;Tadahiro Ohmi	2001		10.1145/370155.370254	acceleration;embedded system;computer architecture;electronic engineering;parallel computing;software performance testing;logic gate;computer science;very-large-scale integration;cmos;adder;field-programmable gate array	EDA	11.092085415749958	52.75039413878224	110486
ac717f6abb6d645b82f65b9616f041e7e0be2296	low-cost soft-error compensation for transposed fir digital filters		Techniques that compensate the impact of soft errors on hardware implementations of transposed FIR digital filters are investigated in this paper. Two techniques are studied, both focusing on moderating the impact of soft errors rather than totally correcting them. In this way a trade-off between accuracy of response and hardware can be explored. Synthesis results reported in this paper quantify trade-offs between degrees of error tolerance and hardware complexity.	digital filter;error-tolerant design;finite impulse response;reduction (complexity);soft error;triple modular redundancy	Vassilis Paliouras;Konstantina Karagianni;Yann Oster	2018	2018 7th International Conference on Modern Circuits and Systems Technologies (MOCAST)	10.1109/MOCAST.2018.8376574	ac power;electronic engineering;digital filter;computer science;adder;soft error	EDA	10.644626533601958	60.22545402951964	110501
ca3258df058d6e46ec577d254e5e0584a2faf4d9	an efficient graph-based algorithm for esd current path analysis	graph search;circuit design graph based algorithm esd current path analysis electrostatic discharge problem on chip protection circuits ic pads;network synthesis electrostatic discharge graph theory integrated circuit reliability;graph theory;reliability;esd current path analysis;graph based algorithm;network synthesis;electrostatic discharge esd;electrostatic discharge algorithm design and analysis voltage protection biological system modeling integrated circuit modeling humans semiconductor device modeling electrostatic analysis current density;ic pads;circuit design;biological system modeling;indexing terms;on chip protection circuits;chip;electrostatic discharge;electrostatic analysis;protection;electrostatic discharge problem;semiconductor device modeling;path analysis;high voltage;voltage;integrated circuit modeling;analysis;humans;integrated circuit reliability;network flow;reliability analysis electrostatic discharge esd graph search network flow;breadth first search;connected component;algorithm design and analysis;current density	The electrostatic discharge (ESD) problem has become a challenging reliability issue in nanometer-circuit design. High voltages that resulted from ESD might cause high current densities in a small device and burn it out, so on-chip protection circuits for IC pads are required. To reduce the design cost, the protection circuit should be added only for the IC pads with an ESD current path, which causes the ESD current path analysis problem. In this paper, we first introduce the analysis problem for ESD protection in circuit design. We then model the circuit as a constraint graph, decompose the ESD connected components (ECCs) linked with the pads, and apply breadth-first search (BFS) to identify the ECCs in each constraint graph and, thus, the current paths. Experimental results show that our algorithm can very efficiently and economically detect all ESD paths. For example, our algorithm can detect all ESD paths in a circuit with more than 1.3 million vertices in 1.39 s and consume only 44-MB memory on a 3.0-GHz Intel Pentium 4 PC. To the best of our knowledge, our algorithm is the first point tool available to the public for the ESD analysis.	algorithm;circuit design;connected component (graph theory);constraint graph;discharger;electrostatic loudspeaker;path analysis (statistics);pentium 4	Chih-Hung Liu;Hung-Yi Liu;Chung-Wei Lin;Szu-Jui Chou;Yao-Wen Chang;Sy-Yen Kuo;Shih-Yi Yuan;Yu-Wei Chen	2008	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2008.925779	chip;network synthesis filters;path analysis;embedded system;algorithm design;electronic engineering;semiconductor device modeling;voltage;flow network;connected component;index term;electrostatic discharge;breadth-first search;computer science;engineering;high voltage;electrical engineering;graph theory;circuit design;analysis;reliability;mathematics;current density	EDA	18.02444657355953	52.906449494795	110525
887ef89e70ab0f3fd20db0c754f27aecaa16a924	layout-driven resource sharing in high-level synthesis	slack time violation;placement task;integrated circuit interconnections;placement tasks;discretizing placement space;synthesis process;major synthesis task;new layout-driven resource sharing;interconnect delay;timing;layout-driven resource sharing;placement space discretization;linear programming;circuit layout cad;delays;dsm technology;deep submicron technology;vlsi;timing closure;iterative mechanism;resource sharing;integrated resource sharing;logic delay;integrated circuit layout;final synthesis;high-level synthesis;linear programming formulation;high level synthesis;iterative methods;logic gate;linear program	In deep submicron @SM) technology, the interconnects are equally as or more impolfant than the logic gates. In patticular, to achieve timing closure in DSM technology. it is very necessary and critical to consider the interconnect delay at an eariy stage of the synthesis process. It has been h o w o that resource sharing in high-level synthesis is one of the major synthesis tasks which greatly affect the final synthesisnayout results. In l h i s paper, we propose a new layout-driven resource sharing approach to overcome some of the limitations of the previous works in which the effects of layout on the synthesis have never been taken into account or considered in local and limited ways. or whose computation time is excessively large, The proposed approach consists of two steps: (Step I ) We relax the integrated resource sharing and placement into an efficient linear programming (LP) formulation based on the concept of discretizing placement space; (Step 2) We derive a feasible solution from the solution obtained in Step 1. Then, we employ an iterative mechanism based on the two steps to tightly integrate resource sharing and placement tasks so that the slack time violation due to interconnect delay (detumined by placement) as well as logic delay (determined by resource sharing) should be minimized. From experiments using a set of benchmark designs. it is shown that the approach is effective, and efficient, completely removing the slack time violation p r o d u d by conventional methods.		Junhyung Um;Jae-Hoon Kim;Taewhan Kim	2002		10.1109/ICCAD.2002.1167596	embedded system;mathematical optimization;electronic engineering;real-time computing;logic gate;telecommunications;computer science;linear programming;electrical engineering;operating system;iterative method;algorithm	EDA	15.335772046267987	53.26859251269988	110555
8987b83d67d0fc55dfb62eb6395c9bb67b535b35	the benefits of 3d networks-on-chip as shown with ldpc decoding	hardware design languages;design tool;3d integrated circuits;decoding;network on chip;parity check codes;on chip networks 3d networks on chip ldpc decoding circuit level noc simulation transaction based noc simulator global interconnect analysis 2d integrated circuits 3d integrated circuits;parity check codes decoding network on a chip circuit simulation circuit testing timing performance evaluation integrated circuit interconnections performance analysis integrated circuit testing;circuit level noc simulation;chip;3d integration;on chip networks;circuit simulation;computational modeling;integrated circuit modelling;2d integrated circuits;three dimensional displays;solid modeling;architecture evaluation;integrated circuit modeling;transaction based noc simulator;3d networks on chip;low density parity check;ldpc decoding;parity check codes circuit simulation integrated circuit modelling network on chip;global interconnect analysis	In this work we describe our network-on-chip (NoC) simulator, which fills the gap between architectural level and circuit level NoC simulation. The core is a fast, high level transaction-based NoC simulator, which accesses carefully compiled power, timing, and area models for basic NoC componets built from detailed circuit simulation. It makes use of the architectural evaluator, which performs a detailed global interconnect analysis within the framework of industry-standard design tools. Using low density parity check decoding as a test vehicle, the NoC simulator is used in an NoC design study comparing 2D and 3D integrated circuits, and shows a method by which on-chip networks can be optimized.	3d television;algorithm;circuit switching;clock rate;compiler;crossbar switch;electronic circuit simulation;high-level programming language;interpreter (computing);low-density parity-check code;mathematical optimization;needham–schroeder protocol;network congestion;network on a chip;network packet;packet switching;parity bit;performance prediction;pipeline (computing);routing;semiconductor research corporation;three-dimensional integrated circuit	Christopher Mineo;William Rhett Davis	2009	2009 IEEE International Conference on 3D System Integration	10.1109/3DIC.2009.5306585	computer architecture;electronic engineering;parallel computing;computer science	EDA	12.249137807975112	53.31637799703052	110570
29168a0beb894e76605ef542ce2040c051d0939b	pulse shrinkage based pre-bond through silicon vias test in 3d ic	circuit faults;radiation detectors;resistance;inverters;会议论文;logic gates;logic gates through silicon vias circuit faults delays inverters resistance radiation detectors;size 45 nm pulse shrinkage prebond through silicon vias test prebond tsv test 3d ic propagation delay transition delay resistive open leakage fault cyclic shrinkage cells digital code fault free fault detection hspice simulations cmos technology design for testability area;vias cmos integrated circuits design for testability fault diagnosis fault trees integrated circuit reliability integrated circuit testing shrinkage three dimensional integrated circuits;delays;through silicon vias	Defects in TSV not only lead to variation in the propagation delay but also in the transition delay of the net connected to the TSV. A non-invasive approach for pre-bond TSV test based on pulse shrinkage is proposed to detect resistive open and leakage fault. TSVs are used as capacitive loads of their driving gates, then the pulse visiting the cyclic shrinkage cells will be shrunk until it vanishes completely. The shrinkage amount is digitized into a digital code to compare with an expected value of fault free. Experiments on fault detection are presented through HSPICE simulations using realistic models for a 45 nm CMOS technology. The results show the effectiveness in the detection of resistive open defects 0.2kΩ above and equivalent leakage resistance less than 40MΩ. The estimated design for testability area cost of our method is negligible for realistic dies.	cmos;design for testing;die (integrated circuit);experiment;fits;fault detection and isolation;propagation delay;pulse generator;spice 2;simulation;software propagation;spectral leakage;three-dimensional integrated circuit;through-silicon via;via (electronics)	Chang Hao;Huaguo Liang	2015	2015 IEEE 33rd VLSI Test Symposium (VTS)	10.1109/VTS.2015.7116267	embedded system;electronic engineering;logic gate;engineering;electrical engineering;particle detector;resistance	EDA	22.799080309085483	53.97038939064527	110670
91453ffd56927a29ba00df5d0daaf742d218f9f8	computation of floating mode delay in combinational circuits: practice and implementation	forward backward;circuito combinatorio;modelizacion;concepcion asistida;logic testing combinatorial circuits delays fault location;computer aided design;gate delays floating mode delay combinational circuits unsensitizable paths false paths high level synthesis procedures single vector condition delay computation algorithm timed test generation stuck at fault test generation forward backward implication backtrace procedures temporal conflict detection;frequency synthesizers;conflict detection;delay computation algorithm;temporal conflict detection;circuit faults;integrated circuit;etude theorique;combinatorial circuits;implementation;high level synthesis procedures;calculation;logic circuits;circuito integrado;analyse temporelle;circuito logico;analisis temporal;sufficient conditions;calculo;time analysis;algorithme;modelisation;combinatory circuit;forward backward implication;algorithm;ejecucion;high level synthesis;stuck at fault test generation;mode flottant;circuit logique;floating mode delay;backtrace procedures;circuit combinatoire;logic testing;estudio teorico;conception assistee;test generation;single vector condition;optimization;circuit testing;calcul;temps retard;unsensitizable paths;delay time;theoretical study;false paths;combinational circuit;delay combinational circuits high level synthesis sufficient conditions frequency synthesizers logic circuits circuit faults circuit testing optimization;modeling;logic circuit;tiempo retardo;timed test generation;gate delays;circuit integre;delays;algoritmo;combinational circuits;fault location	Delay computation in combinational logic circuits is complicated by the existence of unsensit-izable (false) paths and this problem is arising with increasing frequency in circuits produced by high-level synthesis procedures. Various sensitization conditions have been proposed in the past to eliminate false paths in logic circuits, but we use a recently developed single-vector condition, that is known to be necessary and suucient for a path to be responsible for the delay of a circuit (i.e. true) in the oating delay model. In this paper we build on this theory and develop an eecient and correct delay computation algorithm, for the oating mode delay. The algorithm uses a technique we call timed-test generation and can be incorporated into any stuck-at fault test generation framework. We describe in detail an implementation of the timed-test generation algorithm that uses both logical and timed, forward/backward implication and backtrace procedures to simultaneously prove the truth or falsity of sets of paths in the circuit. Logical and temporal connict detection during implication and backtrace are used to speed up the algorithm. Unlike previous techniques, the algorithm remains highly eecient even when a large number of distinct gate and path delays exist in the given circuit. We provide a comprehensive set of results that show signiicant speed-ups over previous delay computation techniques.	algorithm;combinational logic;computation;high- and low-level;high-level synthesis;logic gate;stack trace;stuck-at fault	Srinivas Devadas;Kurt Keutzer;Sharad Malik;Albert R. Wang	1993	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.251156	electronic engineering;real-time computing;delay calculation;logic gate;computer science;computer aided design;mathematics;combinational logic;algorithm	EDA	20.196047766670887	48.98660162368784	110703
f816892d951313e8e1ae5fc8113e7ec2ce2f0d6b	achieving sub 100 dppm defect levels on vdsm and nanometer asics	art testing;achieving sub;design cycle time;dppm defect levels;difficult proposition;complex asics;system level test;quality level;dppm reduction effort;functional testing;nanometer asics;costly task;current state;test methods;design for testability;adaptive testing;application specific integrated circuits;test coverage;design for test;structural testing;quality control;integrated circuit design;nanoelectronics	Achieving 100 DPPM on today's complex ASIC is a realistic but difficult proposition. This work deals in achieving 100 DPPM without functional testing and the advances that are needed to meet these challenges. Structural based test with proper design-for-test (DFT) and scan based testing. The measuring stick for DFT was the stuck-at fault (SAF) test coverage a design could obtain with scan based test. Very deep sub-micron (VDSM) and nanometric designs require additional structural testing such as transition delay fault (TDF) testing. Defect based test methods that focus on outlier identification and removal from test data sets are a critical component in achieving 100 DPPM. Finally, adaptive testing ensure consistent quality and reliability results over the lifetime of the device.	application-specific integrated circuit;design for testing;fault coverage;functional testing;software bug;store and forward;stuck-at fault;test data;trusted data format;white-box testing	Brady Benware	2004	2004 International Conferce on Test	10.1109/ITC.2004.24	reliability engineering;electronic engineering;computer science;engineering;design for testing;statistics;computer engineering	SE	22.163248531309158	53.90763414103866	110746
f38556bc79fafce240b735ad4ee844b28467121b	modeling, detection, and diagnosis of faults in multilevel memristor memories	microprocessors;circuit faults;memristors circuit faults resistance computer architecture microprocessors testing integrated circuit modeling;memristors;resistance;testing;built in tests;multi level memory;sneak paths;computer architecture;integrated circuit modeling;built in tests memristors multi level memory sneak paths fault diagnosis;random access storage built in self test fault diagnosis logic testing memristor circuits;fault diagnosis;sneak path fault modeling fault detection fault diagnosis multilevel memristor memory multilevel cell memristor based mlc crossbar power aware built in self test solution march testing	Memristors are an attractive option for use in future memory architectures but are prone to high defect densities due to the nondeterministic nature of nanoscale fabrication. Several works discuss memristor fault models and testing. However, none of them considers the memristor as a multilevel cell (MLC). The ability of memristors to function as an MLC allows for extremely dense, low-power memories. Using a memristor as an MLC introduces fault mechanisms that cannot occur in typical two-level memory cells. In this paper, we develop fault models for memristor-based MLC crossbars. The typical approach to testing a memory subsystem entails testing one memory cell at a time. However, this testing strategy is time consuming and does not scale for dense, memristor memories. We propose an efficient testing technique that exploits sneak-paths inherent in crossbar memories to test several memory cells simultaneously. In this paper, we integrate solutions for detecting and locating faults in memristors. We develop a power aware built-in self-test solution to detect these faults. We also propose a hybrid diagnosis scheme that uses a combination of sneak-path and March testing to reduce diagnosis time. The proposed schemes enable and leverage sneak-paths during fault detection and diagnosis modes, while disabling sneak-paths during normal operation. The proposed hybrid scheme reduces fault detection and diagnosis time by 24.69% and 28%, respectively, compared to traditional March tests.	built-in self-test;cell (microprocessor);crossbar switch;fault detection and isolation;fault model;low-power broadcasting;memory cell (binary);memristor;model-based testing;multi-level cell;scalability;scheme;sensor;software bug	Sachhidh Kannan;Naghmeh Karimi;Ramesh Karri;Ozgur Sinanoglu	2015	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2015.2394434	embedded system;electronic engineering;parallel computing;memristor;computer science;engineering;memistor;software testing;resistance	EDA	21.05093787252646	54.032953542491995	110871
9b007451cea681d3611f9ad16b23c21500899245	a leaf-cell generator for silicon compilers	t technology;automatic generation;very large scale integrated circuit;genetic algorithm;flip flop;rule based reasoning	A program for the design of leaf cells for silicon compilers of digital VLSI (Very Large Scale Integrated) circuits, is being developed. This program uses rule based reasoning and genetic algorithmic search techniques, whenever each is appropriate. Leaf cells are subcircuits of a complexity comparable with SSI (Small Scale Integration) components such as one-bit adders, flip-flops or multiplexers. They typically contain between 10 to 100 transistors. Silicon compilers can use libraries of ready designed leaf cells or each leaf cell can be automatically generated [1] by synthesis tools such as the program we are developing. The main advantage of the synthesis approach is that circuit performance will not be sacrificed since a new, optimal layout will be produced whatever the complexity of the circuit and whenever the fabrication process is upgraded.	flops;flip-flop (electronics);genetic algorithm;integrated circuit;library (computing);multiplexer;semiconductor device fabrication;silicon compiler;transistor;very-large-scale integration	Dilvan de Abreu Moreira;Les T. Walczowski	1995	OOPS Messenger	10.1145/219260.219267	rule-based system;genetic algorithm;computer science;theoretical computer science;programming language	EDA	11.869079851170653	49.78654255390882	111088
10ce605460624b940952134aec449aabd7ad4b40	synthesis and optimization of asynchronous dual rail encoded circuits based on partial acknowledgement		In this paper, a systematic design flow for asynchronous dual-rail encoded circuits with a high timing robustness level is introduced. With this flow, a synchronous Boolean network can be translated into its asynchronous counterpart consisting of the so-called dual-rail encoded functional modules (DRFMs). Each dual-rail encoded variable in the target asynchronous circuit is partially acknowledged, and the overall circuit satisfies speed independent requirements. The translation process is formulated within integer programing framework and solved with efficient algorithms. In addition, methods for designing DRFMs and characterizing their propagation delays are discussed, as well as simulation techniques used for performance analysis of the target asynchronous circuit.	algorithm;asynchronous circuit;boolean network;delay calculation;heuristic (computer science);integer programming;mathematical optimization;overhead (computing);profiling (computer programming);propagation delay;requirement;simulation;software propagation	Yu Zhou;Chun Shi;Zhengjie Deng;Alexandre Yakovlev	2017	2017 IEEE 12th International Conference on ASIC (ASICON)	10.1109/ASICON.2017.8252522	real-time computing;robustness (computer science);boolean network;asynchronous circuit;electronic circuit;propagation delay;asynchronous communication;design flow;acknowledgement;computer science	EDA	17.14273852187719	50.54763956796884	111297
0386da0a0c9dc502a8e93557bfdbc013ef9da29e	fault tolerant design of combinational and sequential logic based on a parity check code	error correction fault tolerant circuit design combinational logic sequential logic parity check codes concurrent error detection ced technique duplication error detection error diagnosis;fault tolerant;logic design;parity check codes;sequential circuits;circuit reliability logic design fault tolerance combinational circuits sequential circuits parity check codes error detection error correction;general solution;circuit reliability;error correction;fault tolerance;error detection;fault tolerance logic design parity check codes circuit faults electrical fault detection costs circuit testing fault diagnosis fault detection design methodology;combinational circuits	We describe a method for designing fault tolerant circuits based on an extension of a Concurrent Error Detection (CED) technique. The proposed extension combines parity check codes and duplication in order to not only perform error detection but also provide diagnosis and correction capabilities. Informed selection among the outputs of the original synthesized circuit and the outputs of a constrained-sharing resynthesized duplicate with parity check codes renders a low-cost fault tolerant design. Experimental results confirm the efficacy of the proposed method as a general solution for designing fault tolerant circuits.	combinational logic;error detection and correction;fault tolerance;low-density parity-check code;overhead (computing);parity bit;rendering (computer graphics);sequential logic;software bug;triple modular redundancy;very-large-scale integration	Sobeeh Almukhaizim;Yiorgos Makris	2003		10.1109/DFTVS.2003.1250156	reliability engineering;fault tolerance;electronic engineering;real-time computing;error detection and correction;computer science;stuck-at fault;sequential logic;algorithm;statistics	EDA	22.335325704336782	49.68463466717926	111304
06167ef368a6e917d09c70081c1413c5f52c8dd8	a 45 nm 10t dual-port sram with shared bit-line scheme for low power operation		This paper proposes a 10T bit-cell of dual-port (DP) SRAM design to improve Static Noise Margin (SNM) and solve write/read disturb issues in nano-scale CMOS technologies. In additional used the row access transistor in the bit-cell, adding Y -access MOS (column-direction access transistor) can improve dummy-read cells’ noise margin and isolate the pre-charge noise from bit-lines in synchronous or asynchronous clock operation. The paper also proposes a scheme of combining the row access transistor and sharing bit-line with an adjacent bit-cell. This scheme can reduce the bit-line number to half and mitigate the current consumption of the write/read buffer caused by precharging the bit-line to VDD. Furthermore, Y -passgate (column direction access transistor) numbers can also be reduced to half with the proposed DP 10T SRAM architecture. The result shows that write/read buffer current consumption was reduced by over 30%, compared to the conventional DP 8T structure from 1.4 V to 0.6 V VDD.	bit cell;cmos;cell (microprocessor);dummy variable (statistics);flash memory;gnu nano;line number;noise margin;pre-charge;static random-access memory;transistor;value-driven design	Dao-Ping Wang;Wei Hwang	2012	J. Low Power Electronics	10.1166/jolpe.2012.1208	static random-access memory;noise (radio);architecture;transistor;engineering;electronic engineering;asynchronous communication;cmos;noise margin	EDA	17.309294523461077	59.05714172761012	111348
02f0bc48298e70a66a4912417beb1872473cf3ed	new on-chip dft and ate features for efficient embedded memory test	pins;rf signals;device under test;building block;memory testing;data collection;automatic testing;site testing;chip;built in self test;nonvolatile memory;logic testing;manufacturing;system testing;built in self test logic testing manufacturing automatic testing nonvolatile memory system testing pins test equipment logic devices rf signals;test equipment;data flow;logic devices	Testing of embedded memories, independent whether it is of volatile or non-volatile type, is based on various kinds of built-in self-test. This test solution is often driven by the fact that the system application does not provide an atspeed signal interface at the product pins. In complex SoC designs it is furthermore mandatory to do BIST as there are multiple memories of various size and organization integrated onto one chip. Given the fact that multi-site testing is state of the art even for highly complex SoCs the requirements onto the available test equipment (ATE) depend on the selection whether the product is dominated by memory or by logic/mixed signal or RF functions. This often leads to less efficient test solutions and requires multi insertion test flows in production. Here a new approach will be presented to bridge this challenging scenario. It contains a new type of signal and information handling interface between the device under test and the tester. The revolutionary change is that the ATE will act in a slave mode during a significant fraction of the manufacturing test while the DUT controls timing as well as data flow. Such new interface can serve the needs for data collection with focus on diagnosis (scan test diagnosis) at volume manufacturing as well as the complex handling of fail bit data at zero test time overhead. The basic building blocks either on-chip or in the ATE instrumentation will be explained. Especially in testing multiple embedded memories on multiple chips at the same time the throughput increase will be extraordinary.	built-in self-test;built-in test equipment;dataflow;device under test;embedded system;information processing;memory tester;mixed-signal integrated circuit;non-volatile memory;overhead (computing);radio frequency;requirement;system on a chip;test case;throughput;volatile memory	Peter Muhmenthaler	2006	2006 IEEE International Workshop on Memory Technology, Design, and Testing (MTDT'06)	10.1109/MTDT.2006.20	chip;embedded system;data flow diagram;electronic engineering;non-volatile memory;computer hardware;telecommunications;device under test;computer science;engineering;operating system;test compression;manufacturing;system testing;radio frequency;data collection	EDA	11.199610070083482	54.71231059032042	111369
6fb605e912e2f14fbbe061084edbf0cde95d8fda	shield effect analysis for a gate array on an optically reconfigurable gate array	chip	To date, some types of Optically Reconfigurable Gate Arrays (ORGAs) have been developed to realize capabilities of rapid reconfiguration with numerous reconfiguration contexts. However, the layout style requires a shield against the reconfiguration light irradiation to guard transistors that constitute the gate array. This paper presents a shield effect for a circuit that is implemented on a gate array. Finally, experimental results are shown for an ORGA-VLSI chip with the shield design.	gate array;reconfigurable computing;transistor;very-large-scale integration	Minoru Watanabe;Fuminori Kobayashi	2006			chip;gate array;electronic engineering;materials science	EDA	13.41277919070915	56.67643318253436	111467
2727f758fa033c57bf3e27cd2a272454fdda3954	abstraction and optimization of consistent floorplanning with pillar block constraints	tecnologia electronica telecomunicaciones;tecnologias;grupo a	We aim at developing floorplan method, a key in topdown design of sytem LSIs, and provide floorplan abstraction available in high level design. We introduce pillar blocks to represent a frame of a chip layout and propose how to evaluate the chip before the floorplanning with physical dimension. The frame by the pillar blocks is employed as constraints in optimizing block placement. The experiments to MCNC benchmarks showed that the abstraction is faithful to the physically optimized block placement with respect to the chip area and the wire-length.	experiment;floorplan (microelectronics);high-level programming language;level design;mathematical optimization;top-down and bottom-up design	Ning Fu;Shigetoshi Nakatake;Yasuhiro Takashima;Yoji Kajitani	2004	ASP-DAC 2004: Asia and South Pacific Design Automation Conference 2004 (IEEE Cat. No.04EX753)	10.1145/1015090.1015098	embedded system;real-time computing	EDA	13.1634157993029	52.526685410114844	111532
768b35e17d848dbac8e122b8384017deaafc3d36	comparative study of centralised and distributed compatibility-based test data compression	tratamiento datos;test pattern generation;flip flops automatic test pattern generation data compression;data compression;execution time;distributed compatibility;reconfigurable architectures;test data compression;estudio comparativo;automatic test pattern generation;flip flops;data processing;traitement donnee;testing;synthetic aperture sonar;generacion automatica prueba;etude comparative;computer architecture;automatic test pattern generation runtime centralised compatibility distributed compatibility test data compression hardware overhead data volume compression;comparative study;synthetic aperture sonar computer architecture automatic test pattern generation power demand flip flops testing magnetohydrodynamics;generation vecteur test;generation automatique test;automatic test generation;centralised compatibility;temps execution;hardware overhead;data volume compression;compresion dato;tiempo ejecucion;magnetohydrodynamics;power demand;generacion vector prueba;architecture reconfigurable;compression donnee;automatic test pattern generation runtime	Analysis of the tradeoff between hardware overhead, runtime and test data volume is presented when implementing systematic scan reconfiguration using centralised and distributed architectures of the segmented addressable scan, which is an Illinois-scan-based architecture. The results show that the centralised scheme offers better data volume compression, similar automatic test pattern generation (ATPG) runtime results and lower hardware overhead. The cost with the centralised scheme is in the routing congestion.		Ahmad A. Al-Yamani;Narendra Devta-Prasanna;Arun Gunda	2008	IET Computers & Digital Techniques	10.1049/iet-cdt:20070037	data compression;magnetohydrodynamics;embedded system;synthetic aperture sonar;parallel computing;real-time computing;data processing;telecommunications;computer science;automatic test pattern generation;operating system;comparative research;software testing;algorithm	HCI	11.836946155660993	49.03014287923659	111793
f1f30dd44fb074558208959cd95c44a07a08c341	a novel separated pre-discharging sense amplifier for stt-mram		This paper presents a novel sense amplifier for Spin Transfer Torque Magnetic Random Access Memory (STT-MRAM), named Separated Pre-discharging Sense Amplifier (SPDSA). By inverting the pre-charging path of Separated Pre-charging Sense Amplifier (SPCSA) to a pre-discharging path, a couple of inverters that used to transfer the voltage can be eliminated, and thus the area overhead of SPCSA is reduced. We develop a compact magnetoresistance model for MTJ to perform hybrid CMOS/magnetic HSPICE simulations. Based on 45 nm CMOS technology, simulation results exhibit that compared with SPCSA, SPDSA can reduce the power consumption by 35.6% and improve the read reliability by 29%.	magnetoresistive random-access memory;sense amplifier	Huan Li;Zhenyu Zhao;Quan Deng;Peng Li;Haoyue Tang;Lianhua Qu	2016		10.1007/978-981-10-3159-5_20	voltage;magnetoresistive random-access memory;sense amplifier;magnetoresistance;spin-transfer torque;electronic engineering;cmos;random access;physics	Logic	16.99011281042933	59.79950436183527	111807
d10b73c1cc6f112a5a24871b40167b8eb99619d0	casser: a closed-form analysis framework for statistical soft error rate	transient fault reliability single event upset statistical ser sser statistical static timing analysis ssta;cmos integrated circuits;reliability;normal distribution;integrated circuit design;transient analysis logic gates circuit faults timing accuracy random variables integrated circuit modeling;monte carlo spice simulation casser closed form analysis framework statistical soft error rate cmos designs deep submicrometer era statistical methods process variation transient faults cell models first order closed form statistical static timing analysis normal distribution process parameters;transient fault;radiation hardening electronics;single event upset;radiation hardening electronics cmos integrated circuits integrated circuit design normal distribution;statistical ser sser;article;statistical static timing analysis ssta	CMOS designs in the deep submicrometer era require statistical methods to accurately estimate the circuit soft error rate (SER). However, process variation increases the complexity of statistical characteristics related to transient faults, leading to considerable uncertainty in the behavior of soft errors. Regardless of the methods used, current statistical SER (SSER) frameworks invariably involve a tradeoff between accuracy and efficiency. This paper presents accurate cell models in first-order closed form to overcome this problem, thereby enabling the analysis of SSERs in a block-based fashion similar to statistical static timing analysis. These cell models are derived as a closed form in the proposed framework named CASSER, and remain precise under the assumption of a normal distribution for the process parameters. Experimental results demonstrate the efficiency (> 2-order times faster than the latest framework) and accuracy ( error) of CASSER in estimating circuit SERs, when compared with the Monte Carlo SPICE simulation.	cmos;first-order predicate;monte carlo method;spice;simulation;soft error;static program analysis;statistical static timing analysis	Austin C.-C. Chang;Ryan H.-M. Huang;Charles H.-P. Wen	2013	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2012.2220386	normal distribution;electronic engineering;real-time computing;computer science;engineering;electrical engineering;reliability;cmos;statistics;integrated circuit design	EDA	22.2614388565556	58.426557810870634	111813
4468396989bbd249f72958b6f33909185ac63518	thermal-aware floorplanning using genetic algorithms	power consumption integrated circuit layout vlsi circuit optimisation genetic algorithms;integrated circuit layout;optimization technique;hot spot;chip;genetic algorithms temperature algorithm design and analysis very large scale integration energy consumption chip scale packaging design optimization power dissipation face detection circuits;power dissipation;thermal aware floorplanning genetic algorithms chip optimization chip area hotspot floorplanning temperature power dissipation physical dimension vlsi module location mcnc benchmarks face detection chip;vlsi;genetic algorithm;genetic algorithms;power consumption;circuit optimisation;face detection	In this work, we present a genetic algorithm based thermal-aware floorplanning framework that aims at reducing hot spots and distributing temperature evenly across a chip while optimizing the traditional design metric, chip area. The floorplanning problem is formulated as a genetic algorithm problem, and a tool called HotSpot is used to calculate floorplanning temperature based on the power dissipation, the physical dimension, and the location of modules. Area and/or temperature optimizations guide the genetic algorithm to generate the final fittest solution. The experimental results using MCNC benchmarks and a face detection chip show that our combined area and thermal optimization technique decreases the peak temperature sufficiently while providing floorplans that are as compact as the traditional area-oriented techniques.	face detection;floorplan (microelectronics);genetic algorithm;java hotspot virtual machine;mathematical optimization	Wei-Lun Hung;Yuan Xie;Narayanan Vijaykrishnan;Charles Addo-Quaye;Theocharis Theocharides;Mary Jane Irwin	2005	Sixth international symposium on quality electronic design (isqed'05)	10.1109/ISQED.2005.122	electronic engineering;parallel computing;real-time computing;genetic algorithm;telecommunications;computer science;engineering;electrical engineering	EDA	14.271539732749705	53.57387113349924	111833
348c49a6f80c41092cbe299fbf634f89a5bb6e2c	panamap-b: a mask verification system for bipolar ic	mask verification system;lsi mask pattern design;lsi chip;bipolar ic;mask pattern verification;polygonal mask pattern;lsi structures increase;lsi design;constant circuit representation;actual circuit;lsi mask design;connection;resistors;graphics;conductors;electric resistance;data mining;chip;capacitors	As the complexity of IC/LSI structures increase, verification of IC/LSI mask designs becomes extremely difficult and time-consuming. Also, verification of an IC/LSI mask pattern design requires much man-power as well. Further, the actual circuit realized onto IC/LSI chips may be quite different from that originally intended because of parasitic elements, including capacitors, resistors, and transistors. Computer support of mask pattern verification is considered very important and useful for IC/LSI design.  This paper describes all functions of PANAMAP-B (<underline>Pana</underline>sonic <underline>M</underline>ask <underline>A</underline>nalysis <underline>P</underline>rogram for <underline>B</underline>ipolar IC). The main features are: one, no restriction about edge angles of polygonal mask patterns; and two, distributed constant circuit representation of interconnecting conductors and diffusion resistors.	transistor	J. Yoshida;T. Ozaki;Y. Goto	1981	18th Design Automation Conference		resistor;chip;embedded system;electrical resistance and conductance;electronic engineering;capacitor;connection;computer science;engineering;electrical engineering;graphics;electrical conductor	EDA	12.501154181072058	50.669003435397244	111892
1efc9bef82439876960e4d22a68499458e2b46bd	progressive decomposition: a heuristic to structure arithmetic circuits	detectors;manuals;cost function;algebraic factorisation progressive decomposition structure arithmetic circuits boolean ring;building block;factorisation algorithms performance design progressive decomposition boolean ring;performance;logic circuits;circuit synthesis logic circuits computer architecture integrated circuit interconnections digital arithmetic computational complexity delay cost function detectors manuals;structure arithmetic circuits;boolean algebra;computer architecture;a priori knowledge;logic synthesis;computational complexity;algebraic factorisation;critical path;integrated circuit interconnections;progressive decomposition;factorisation;algorithms;design;digital arithmetic;boolean ring;circuit synthesis;arithmetic circuit	Despite the impressive progress of logic synthesis in the past decade, finding the best architecture for a given circuit still remains an open problem and largely unsolved. In most of the arithmetic circuits the outcome of the synthesis tools depends on the input description of the circuit. In other words, logic synthesis optimisations hardly change the architecture of the given circuit. However, once the input description belongs to the right architecture, logic synthesis does an excellent job in optimising the circuit locally. This is the reason why designers still rely on well studied architectures. The main difficulty in finding the suitable architecture for an arithmetic circuit is the high fan-in dependencies between inputs and outputs (i.e., each output bit depends on a large portion of input bits). Hence, imposing hierarchy and structure is the key to find the best architecture. Although factorisation is one potential solution for this problem, the computational complexity of Boolean factorisation and poor performance of algebraic factorisation make this solution impractical in most cases of interest. In this paper we present a novel approach which progressively decomposes the input circuits into building blocks and constructs hierarchy among these blocks. We show that our approach optimises the critical path delay by 15--30% at the cost of marginal or no area penalty. In some cases, it even improves the area. Qualitatively we observed that our approach found the best known architecture for some circuits without any a priori knowledge about the functionality of the circuit.	algorithm;arithmetic circuit complexity;boolean expression;cholesky decomposition;computational complexity theory;critical path method;fan-in;heuristic;linear algebra;logic synthesis;marginal model;monoid factorisation;reed–muller code	Ajay K. Verma;Philip Brisk;Paolo Ienne	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278585	boolean algebra;boolean circuit;design;mathematical optimization;electronic engineering;discrete mathematics;logic synthesis;performance;computer science;theoretical computer science;boolean ring;mathematics;algorithm	EDA	14.767017885650032	48.003498680781085	112096
138bfa3c45555baf4bbcc415168328c426fa8990	integrating scan into hierarchical synthesis methodologies	design for testability;integrated circuit;logic testing integrated circuit synthesis circuit testing system testing libraries constraint optimization design optimization timing design methodology design for testability;hierarchical systems;hardware description languages;hardware description languages integrated circuit design design for testability circuit cad hierarchical systems high level synthesis;system on a chip;high level synthesis;integrated circuit design;circuit cad;design for test;hdl hierarchical synthesis methodologies design for test hierarchical synthesis system on a chip ic design management cad	This paper presents new strategies for integrating scan DFT (Design Tor Test) techniques into hierarchical synthesis methodologies to meet the challenges of system-on-achip ICs (Integrated Circuits). I t describes what can be done before, during and afer synthesis to reduce design time, and presents results that show the effects of select approaches.	integrated circuit;speech synthesis;tor messenger	James Beausang;Chris Ellingham;Markus Robinson	1996		10.1109/TEST.1996.557134	physical design;embedded system;computer architecture;electronic engineering;computer science;design flow;circuit design;design for testing;circuit extraction;register-transfer level;computer engineering;integrated circuit design	EDA	10.841942342223067	51.70552714777263	112097
74826dff77b716a7204c951b7f310d554a2f7322	low power embedded deterministic test	switching activity;low power electronics automatic test pattern generation design for testability embedded systems;design for testability;logic design;switching circuits;automatic test pattern generation;automatic test pattern generation embedded deterministic test scan chains hardware modification industrial circuits switching activity design for testability;scan chains;embedded systems;low power;hardware modification;integrated circuit technology;embedded deterministic test;circuit testing logic testing automatic test pattern generation power dissipation hardware design for testability integrated circuit technology switching circuits graphics logic design;power dissipation;logic testing;low power electronics;circuit testing;industrial circuits;graphics;hardware	This paper presents a novel low power test scheme integrated with the embedded deterministic test environment. It reduces switching rates in scan chains with no hardware modification. Experimental results obtained for industrial circuits indicate that switching activity can be reduced up to 23 times.	data compression;deployment environment;embedded system;event dispatching thread;line code;logic programming;loop (graph theory);olap cube;performance per watt;resultant;test data	Dariusz Czysz;Grzegorz Mrugalski;Janusz Rajski;Jerzy Tyszer	2007	25th IEEE VLSI Test Symposium (VTS'07)	10.1109/VTS.2007.37	embedded system;computer architecture;electronic engineering;logic synthesis;real-time computing;computer science;graphics;dissipation;automatic test pattern generation;design for testing;low-power electronics	EDA	12.607976649996413	52.552725747576055	112202
e4ca9bd173cff76b19809af6f18fd90e0769e270	meshworks: a comprehensive framework for optimized clock mesh network synthesis	variation tolerant clock network synthesis;meshworks;network synthesis;robust clock networks;clocks;wirelength;mesh optimization;buffer area;variation tolerance;comprehensive automated framework;variation tolerant clock network synthesis clock mesh optimization clock mesh synthesis robust clock networks;resource requirements;electromigration mesh networks clocks algorithm design and analysis planning optimization;load distribution;mesh networks;worst case maximum frequency;planning;optimization;mesh network;electromigration;clock mesh synthesis;initial clock mesh;performance optimization;clock mesh optimization;algorithm design and analysis;optimized clock mesh network synthesis;worst case maximum frequency meshworks optimized clock mesh network synthesis initial clock mesh variation tolerance resource requirements comprehensive automated framework buffer area wirelength	Clock mesh networks are well known for their variation tolerance. But their usage is limited to high-end designs due to the significantly high resource requirements compared to clock trees and the lack of automatic mesh synthesis tools. Most existing works on clock mesh networks either deal with semi-custom design or perform optimizations on a given clock mesh. However, the problem of obtaining a good initial clock mesh has not been addressed. Also, the problem of achieving a smooth tradeoff between variation tolerance and resource requirements has not been addressed adequately. In this paper, we present our MeshWorks framework, the first comprehensive automated framework for planning, synthesis, and optimization of clock mesh networks that addresses the above issues. Experimental results suggest that our algorithms can achieve an additional reduction of 31% in buffer area, 21% in wirelength, and 23% in power, compared to the best previous work, with similar worst case maximum frequency. We also demonstrate the effectiveness of our framework under several practical issues such as blockages, multiple clocks, uneven load distribution, and electromigration violations.	algorithm;best, worst and average case;electromigration;load balancing (computing);mathematical optimization;mesh networking;network synthesis filters;requirement;semiconductor industry;speech synthesis	Anand Rajaram;David Z. Pan	2010	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2010.2061130	parallel computing;real-time computing;computer science;mesh networking;computer network	EDA	16.16002921566861	53.14467942086757	112279
c6af9d234c50898d19370329639cb0451c1c100a	a test generation program for sequential circuits	interactive fault simulation;fault simulation;circuit partitioning;automatic test pattern generation for sequential circuits;sequential circuits;testability measures;pruning heuristics;test generation;value function;automatic test pattern generator	This article presents an automatic test pattern generation system based on both algebraic and topological techniques. Circuit partitioning, testability measures, 9-valued functions, pruning heuristics, and interactive fault simulation are employed to increase the performance of a modified version of the sequential D-Algorithm. Test generation results for someIscas'89 circuits are presented.		Enrico Macii;Angelo Raffaele Meo	1994	J. Electronic Testing	10.1007/BF00971967	computer architecture;electronic engineering;real-time computing;fault coverage;computer science;engineering;stuck-at fault;automatic test pattern generation;test compression;sequential logic;bellman equation;algorithm	EDA	19.663133137333496	48.7528240863066	112296
46c24dbfee40e2a2a2aa650c94ae68b233fbf214	gated clock routing for low-power microprocessor design	dynamic programming approach;dynamic programming;microprocessors;low power microprocessor design;gate reduction heuristic;switching circuits;clocks;routing;very large scale integration;design practice;dynamic program;indexing terms;module activities;circuit topology;network routing;integrated circuit design;low power;activation frequencies;vlsi circuits;low power electronics;clocks routing microprocessors very large scale integration switching circuits capacitance circuit topology frequency dynamic programming centralized control;vlsi;dynamic programming vlsi low power electronics integrated circuit design microprocessor chips clocks network routing;capacitance;centralized control;zero skew gated clock routing technique;frequency;masking gates;module activities vlsi circuits low power microprocessor design zero skew gated clock routing technique masking gates switched capacitance activation frequencies dynamic programming approach gate reduction heuristic;microprocessor chips;switched capacitance	This paper presents a zero-skew gated clock routing technique for VLSI circuits. Gated clock trees include masking gates at the internal nodes of the clock tree, which are selectively turned on and off by the gate control signals during the active and idle times of the circuit modules to reduce the switched capacitance of the clock tree. We construct a clock-tree topology based on the locations and the activation frequencies of the modules, while the locations of the internal nodes of the clock tree (and, hence, the masking gates) are determined using a dynamic programming approach followed by a gate reduction heuristic. This work assumes that the gates are turned on/off by a centralized controller. Therefore, the additional power and routing area incurred by the controller and the gate control signal routing are examined. Various tradeoffs between power and area for different design options and module activities are discussed and detailed experimental results are presented. Finally, good design practices for implementing the gated clocks are suggested.	low-power broadcasting;microprocessor;processor design;routing	Jaewon Oh;Massoud Pedram	2001	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.924825	clock synchronization;embedded system;routing;electronic engineering;real-time computing;clock domain crossing;clock skew;computer science;electrical engineering;very-large-scale integration;clock gating;digital clock manager;cpu multiplier	EDA	16.915169964353552	55.119587971289405	112353
2641779d6f7506d0889465e8388243acdfb0a8f8	testability features of the first-generation cell processor	clocks random access memory microwave integrated circuits semiconductor device testing system testing logic testing multicore processing process design communication system control logic devices;processing element;microprocessors;test elements manufacturing first generation cell processor multiple processing elements multigigahertz asynchronous clock domains custom design elements cell design test coverage test time test logic modular design point;clocks;multigigahertz asynchronous clock domains;custom design elements;cell design;automatic test pattern generation;cell processor;first generation cell processor;self testing;boundary scan testing;chip;built in self test;test logic;test coverage;microprocessor chips automatic test pattern generation boundary scan testing built in self test clocks logic testing;logic testing;modular design;test time;multiple processing elements;test elements manufacturing;modular design point;microprocessor chips;logic circuit testing	The first generation CELL processor presented a test challenge in that the chip incorporated multiple processing elements, several multi-gigahertz synchronous and asynchronous clock domains, and many custom design elements. The test objective for the CELL design was to have high test coverage and a small test time. In addition to the objectives mentioned above, the CELL test logic is designed to support a modular design point and support for partial good processing elements. This paper will give an overview of the manufacturing test elements that were designed into the CELL processor	cell (microprocessor);fault coverage;modular design;parallel computing	Mack W. Riley;Louis B. Bushard;Nathan Chelstrom;Naoki Kiryu;Steven Ross Ferguson	2005	IEEE International Conference on Test, 2005.	10.1109/TEST.2005.1583967	chip;embedded system;computer architecture;electronic engineering;telecommunications;computer science;engineering;automatic test pattern generation;operating system;design for testing;code coverage;modular design	EDA	10.999089081897536	52.8977255139565	112366
faba5161e8d7086bb249122c007828ff63dd6357	efficient bit-level model reductions for automated hardware verification	pipelined processor liveness property verification;combinatorial property;memory management unit;memory management unit correctness property verification;hardware verification;memory management;decoding;logic design;proof method;isabelle hol theorem prover;surface mount technology;transition system;theorem proving;theorem prover;model reduction;model checking;reduced order systems hardware algorithm design and analysis memory management registers automation surface mount technology explosions instruction sets decoding;bit level hardware design;temporal property;data abstraction gate level hardware verification model checking;registers;gate level hardware verification;memory management unit correctness property verification bit level model reduction automated hardware verification combinatorial property temporal property transition system proof method isabelle hol theorem prover bit level hardware design pipelined processor liveness property verification;logic testing;temporal properties;transition systems;data abstraction;formal logic;hardware design;explosions;bit level model reduction;algorithm design and analysis;reduced order systems;domain specificity;theorem proving combinational circuits formal logic logic design logic testing;instruction sets;hardware;combinational circuits;automated hardware verification;automation	Transition systems which do not perform domain-specific operations on their state variables can be efficiently reduced. We present two different algorithms which automatically eliminate domain-specific operations and reduce the domains of occurring variables from infinite to small domains. Our work extends earlier techniques which are applicable solely to combinatorial properties to temporal properties of transition systems. We have implemented our algorithm as a proof method in the Isabelle/HOL theorem prover and applied it to bit-level hardware designs. To demonstrate the efficiency of our technique, we fully automatically verify a liveness property of a pipelined processor and correctness of a memory management unit.	algorithm;automated theorem proving;bit-level parallelism;correctness (computer science);electronic design automation;hol (proof assistant);instruction pipelining;isabelle;liveness;memory management unit;transition system	Sergey Tverdyshev;Eyad Alkassar	2008	2008 15th International Symposium on Temporal Representation and Reasoning	10.1109/TIME.2008.11	parallel computing;computer science;theoretical computer science;algorithm	Logic	18.476769673746436	47.77356857904777	112402
120a5303b169ddb2d1873dd93939a5736513ec94	automatic design of analog electronic circuits using grammatical evolution		A new approach for automatic synthesis of analog electronic circuits based on Grammatical Evolution is presented. Grammatical Evolution is an evolutionary algorithm based on grammar which can generate code in any programming language and uses variable length linear binary strings. The decoding of each chromosome determines which production rules in a Backus-Naur Form grammar definition are used in a genotype-to-phenotype mapping process. In our method, decoding focuses on obtaining circuit netlists. A new grammar for generating such netlists and a variant of the XOSites-based crossover operator are also presented. A post-processing stage is needed to adapt the decoded netlist prior its evaluation using the NGSpice simulator. Our approach was applied to several case studies, comprising a total of seven benchmark circuits. A comparison with previous works in the literature shows that our method produces competitive circuits in relation to the degree of compliance with the output specifications, the number of components and the number of evaluations used in the evolutionary process.	analogue electronics;benchmark (computing);electronic circuit;evolutionary algorithm;grammatical evolution;netlist;programming language;simulation;video post-processing	Federico Castejón;Enrique J. Carmona	2018	Appl. Soft Comput.	10.1016/j.asoc.2017.09.036	netlist;artificial intelligence;machine learning;grammatical evolution;crossover;electronic circuit;decoding methods;binary number;evolutionary algorithm;grammar;computer science	Logic	15.687121027352978	47.00179541966189	112429
7d4d803fb4eb6ee4a955490f360aa3e5bacbeb6f	read/write margin enhanced 10t sram for low voltage application	snm;low voltage;process variations;sram;failure probability;vddmin		static random-access memory	Chunyu Peng;Lijun Guan;Wenjuan Lu;Xiulong Wu;Xincun Ji	2016	IEICE Electronic Express	10.1587/elex.13.20160382	electronic engineering;parallel computing;real-time computing;static random-access memory;computer science;engineering;electrical engineering;operating system;low voltage	HCI	17.968570062900547	59.55767580636601	112445
f49490b9488c30b18ed37b36a775d65fa8ffb2fa	topological optimization of multiple-level array logic	logic arrays programmable logic arrays cmos logic circuits network synthesis cmos technology constraint optimization circuit simulation logic design mos devices logic gates;concepcion asistida;topology;memoire;computer program;logic arrays;computer aided design;optimisation;mos devices;red logica programable;regime dynamique;cmos technology;network synthesis;constraint optimization;optimizacion;integrated circuit;annealing;multiprocessor;logic design;technology;topologie;compactacion;circuito integrado;circuito logico;programmable logic arrays;simulated annealing;dynamic conditions;compactage;windows;topologia;algorithme;algorithm;circuit simulation;algorritmo;particion;logic gates;memoria;programmable logic array;compaction;circuit logique;recuit;fenetre;cmos logic circuits;technologie;reseau logique programmable;partition;conception assistee;regimen dinamico;arquitectura;ventana;optimization;parallel implementation;recocido;multiprocesador;programa computador;logic circuit;architecture;programme genie;circuit integre;programme ordinateur;memory;multiprocesseur;tecnologia	A generalized topological optimization tool for array-based layout styles is presented. This tool can be used for automated layout synthesis of logic networks in a variety of technologies and design styles, including static CMOS, static NMOS and dynamic MOS domino structures. Results obtained compare favorably with technology and design-style-specific synthesis systems. The topological optimization tool is a generalized array optimizer which can be used for the multiple constrained folding of programmable logic array, gate matrix, Weinberger array, multilevel matrix, and storage/logic array structures. The optimizer uses simulated-annealing-based algorithms and performs as well as or better than existing specialized PLA folding programs and gate matrix folders. The different layout style alternatives allow area-efficient synthesis of logic circuits in various technologies. Layout for sequential logic in the form of storage/logic arrays has been automated for the first time. A multiprocessor implementation of the simulated-annealing-based algorithms for generalized array optimization has been developed on the Sequent Balance 8000 multiprocessor. Dynamic windowing and dynamic partitioning techniques have resulted in an efficient parallel implementation of simulated annealing.	and gate;algorithm;cmos;logic gate;mathematical optimization;multiprocessing;nmos logic;programmable logic array;programmable logic device;sequent calculus;sequential logic;simulated annealing	Srinivas Devadas;A. Richard Newton	1987	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.1987.1270335	embedded system;mathematical optimization;constrained optimization;electronic engineering;logic synthesis;logic optimization;logic gate;logic family;programmable logic array;computer science;theoretical computer science;computer aided design;programmable logic device;algorithm	EDA	16.468167429769114	49.94239879126318	112475
1ab5c43bdd8e956844270c936e328354ff31a9c3	iceberg: an embedded in-circuit emulator synthesizer for microcontrollers	verification;hardware design languages;debugging;microcontrollers;ht48100 iceberg embedded in circuit emulator synthesizer microcontrollers synthesis tool development environment piper ii microprocessor based systems rtl core ieee 1149 1 jtag architecture standard debugging mechanisms boundary scan paths partial scan paths single stepping internal resource monitoring internal resource modification breakpoint detection mode switching debugging mode free running mode;internal resource monitoring;computer debugging;standard debugging mechanisms;emulation;boundary scan testing;embedded in circuit emulator synthesizer;synthesizers microcontrollers ice debugging monitoring permission hardware design languages embedded computing circuit synthesis emulation;high level synthesis;synthesis tool;free running mode;ieee 1149 1 jtag architecture;boundary scan paths;development environment;single stepping;computer testing;monitoring;virtual machines;permission;logic testing;debugging mode;iceberg;breakpoint detection;microprocessor based systems;partial scan paths;development systems;test and debugging;rtl core;mode switching;synthesizers;systems on chip;ice;ht48100;circuit synthesis;piper ii;embedded computing;internal resource modification;logic testing microcontrollers high level synthesis virtual machines boundary scan testing computer debugging computer testing development systems	This paper presents a synthesis tool ICEBERG for embedded in-circuit emulators (ICE’s), that are part of the development environment for microcontroller (or microprocessor)-based systems (PIPER-II). The tool inserts and integrates the necessary in-circuit emulation circuitry into a given RTL core of a microcontroller, and thus turning the core into an embedded ICE. The ICE, based on the IEEE 1149.1 JTAG architecture, provides standard debugging mechanisms, including boundary scan paths, partial scan paths, single stepping, internal resource monitoring and modification, breakpoint detection, and mode switching between debugging and free running modes. ICEBERG has been successfully applied to synthesize the embedded ICE for an industrial microcontroller HT48 100 from its RTL core.	boundary scan;breakpoint;debugging;electronic circuit;embedded system;emulator;in-circuit emulation;jtag;microcontroller;stepping level	Ing-Jer Huang;Tai-An Lu	1999		10.1145/309847.310003	microcontroller;embedded system;emulation;iceberg;electronic engineering;parallel computing;real-time computing;verification;computer science;virtual machine;operating system;development environment;debug menu;high-level synthesis;programming language;debugging	Embedded	10.602271444509489	53.27488085883295	112508
457e2d81a58a3330939f764f8083ecde50db8678	negative capacitance circuits for process variations compensation and timing yield improvement	capacitance delays logic gates threshold voltage cmos integrated circuits registers;timing circuits compensation logic gates logic testing;64 input wide dynamic or gate negative capacitance circuit process variation compensation timing yield improvement microprocessor register file delay variability timing yield loss parasitic capacitance reduction post layout simulation;negative capacitance circuit timing yield improvement process variations domino logic circuits register file deep sub micron	The continued demand for higher performance in modern microprocessors places strict timing constraints on the high performance modules such as dynamic circuits and register files. In addition, the increased process variations in scaled technologies results in delay variations around its nominal value. This delay variability results in violating the timing constraints, and correspondingly, causes a timing yield loss. In our previous work, new negative capacitance circuits are connected to the highly capacitive nodes to reduce the overall parasitic capacitance at these nodes. This capacitance reduction reduces the circuit mean delay which results in timing yield improvement, which is verified by using post-layout simulations. In this paper, test chip measurements are provided showing that the adoption of the negative capacitance circuit to a 64-input wide dynamic OR gate is capable of improving the timing yield to 100%.	cmos;calculus of variations;dynamic circuit network;microprocessor;nc (complexity);or gate;overhead (computing);register file;requirement;simulation;spatial variability;value-driven design	Hassan Mostafa;Mohab Anis;Mohamed I. Elmasry	2013	2013 IEEE 20th International Conference on Electronics, Circuits, and Systems (ICECS)	10.1109/CCECE.2014.6900929	electronic engineering;real-time computing;computer hardware;engineering;pass transistor logic;static timing analysis	EDA	19.678042777109034	58.28558349909972	112553
8d618e5390dc9733a4269b819ade66ed3f2c88c3	register binding based power management for high-level synthesis of control-flow intensive behaviors	average area overhead high level synthesis control flow intensive behaviors register binding based power management perfectly power managed circuit functional units power managed register binding algorithm algorithms benchmarks power reduction;switching activity;cost function;perfectly power managed circuit;energy management high level synthesis registers circuits latches sufficient conditions contracts iron engineering management cost function;iron;contracts;sufficient conditions;register binding based power management;functional units;high level synthesis;scheduling algorithm;registers;engineering management;power managed register binding algorithm;low power electronics;power management;control flow;benchmarks;power optimization;algorithms;low power electronics high level synthesis;control flow intensive behaviors;circuits;latches;power reduction;functional unit;data flow;register transfer level;average area overhead;energy management	A circuit or circuit component that does not contain any spurious switching activity, i.e., activity that is not required by its specified functionality, is called perfectly power managed (PPM). We present a general sufficient condition for register binding to ensure that a given set of functional units is PPM. This condition not only applies to data-flow intensive (DFI) behaviors but also to control-flow intensive (CFI) behaviors. It leads to a straightforward power-managed (PM) register binding algorithm. The proposed algorithm is indepe ndent of the functional unit binding and scheduling algorithms. Hence, it can be easily incorporated into existing high-level synthesis systems. For the benchmarks we experimented with, an average 45.9% power reduction was achieved by our met hod at the cost of 7.7% average area overhead, compared to power-optimized registertransfer level (RTL) circuits which did not use PM register	algorithm;benchmark (computing);control flow;dataflow;execution unit;high- and low-level;high-level synthesis;overhead (computing);power management;register file;scheduling (computing)	Lin Zhong;Jiong Luo;Yunsi Fei;Niraj K. Jha	2002		10.1109/ICCD.2002.1106800	embedded system;electronic engineering;parallel computing;real-time computing;computer science;operating system;control flow;iron;power optimization;energy management	EDA	16.111870199164738	54.57074192805283	112582
5f4c32d92eb3f2f8b660fe0ce3a817136408fa9e	a case study of improving at-speed testing coverage of a gigahertz microprocessor	random access memory;random access storage circuit testing microprocessor chips;critical path;test coverage;microprocessors clocks test pattern generators system testing costs timing automatic test pattern generation delay pattern analysis laboratories;random access storage;fault coverage;circuit testing;multiple clock domain;at speed testing gigahertz microprocessor embedded ram random access memory clock control scheme;microprocessor chips	For a gigahertz microprocessor with multiple clock domains and a large amount of embedded RAMs (Random Access Memory), generating at-speed testing patterns is becoming very difficult and very time-consuming. This paper presents some novel techniques to improve at-speed testing coverage with low cost. These methods are major concern about preventing X states propagation, which include avoiding capturing X states for registers, sequential bypass of macros, clock control scheme for inter-clock domains and accurate analysis of exception paths in intra-clock domains. Functional patterns are utilized to further improve the efficiency of the at-speed testing. A novel optimal flow is presented by carefully selecting these techniques. By using the flow, 90% transition fault coverage is achieved. In addition, both the number of patterns and the test time of the transition test are decreased by 15%. The total area overhead is about a few hundreds of AND cells and has little timing impact on the critical paths.	embedded system;fault coverage;microprocessor;overhead (computing);random access;random-access memory;software propagation	Zichu Qi;Hui Liu;Xiangku Li;Jun Xu;Weiwu Hu	2009	2009 16th IEEE International Conference on Electronics, Circuits and Systems - (ICECS 2009)	10.1109/ICECS.2009.5410807	embedded system;electronic engineering;real-time computing;fault coverage;computer science	EDA	20.84586902826713	52.639807889873545	112590
adc0e655849feebf98a7edd31eafd7061f1551db	mapping multi-domain applications onto coarse-grained reconfigurable architectures	integer linear programming;design automation;kernel;optimal mapping;clocks;parallelizing compiler;routing;reconfigurable architectures;parallelizing compilers;integer arithmetic;arrays;high level synthesis;cgra;reconfigurable architecture;integer programming;multi domain;multidomain application mapping;reconfigurable architectures floating point arithmetic integer programming linear programming;linear programming;floating point arithmetic;coarse grained;multimedia benchmark;3d graphics benchmark coarse grained reconfigurable architecture multidomain application mapping cgra integer arithmetic floating point arithmetic integer linear programming heuristic mapping algorithm optimal mapping multimedia benchmark;arrays pipeline processing kernel context routing clocks;3d graphics benchmark;context;coarse grained reconfigurable architecture;reconfigurable architecture design automation high level synthesis parallelizing compiler;heuristic mapping algorithm;pipeline processing	Coarse-grained reconfigurable architectures (CGRAs) have drawn increasing attention due to their performance and flexibility. However, their applications have been restricted to domains based on integer arithmetic since typical CGRAs support only integer arithmetic or logical operations. This paper introduces approaches to mapping applications onto CGRAs supporting both integer and floating-point arithmetic. After presenting an optimal formulation using integer linear programming, we present a fast heuristic mapping algorithm. Our experiments on randomly generated examples generate optimal mapping results using our heuristic algorithm for 97% of the examples within a few seconds. We observe similar results for practical examples from multimedia and 3-D graphics benchmarks. The applications mapped on a CGRA show up to 120 times performance improvement compared to software implementations, demonstrating the potential for application acceleration on CGRAs supporting floating-point operations.	algorithm;benchmark (computing);experiment;file spanning;graphics;heuristic (computer science);high-level synthesis;integer programming;linear programming;logical connective;loop unrolling;pipeline (computing);procedural generation;reconfigurable computing;routing;spanning tree;steiner tree problem	Ganghee Lee;Kiyoung Choi;Nikil D. Dutt	2011	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2010.2098571	mathematical optimization;routing;computer architecture;parallel computing;kernel;integer programming;computer science;floating point;theoretical computer science;high-level synthesis	EDA	14.676357770327177	48.533183537088135	112727
419625988fd57e3fce36bec8d3c7f6570cba12f3	automatic floorplan design	wiring space prediction;dutch metric;module flexibility;partial structure tree;minimum area floorplan;shorthand tree;automatic floorplan design;good embedding;structure tree;module space;convenient data structure;top down;aspect ratio;silicon;tree data structures;shape;distance matrix;chip;matrix decomposition;design automation;satisfiability;data structure;topology;symmetric matrices;modulation space;space technology	The problem of allocating area to modules at the highest level of a top-down decomposition is treated in this paper. A theorem of Schoenberg is applied to obtain a good embedding of the module space into the plane. The dutch metric is introduced to transform netlist information - if available - into a distance matrix. This metric is flexible enough to enable the user to steer the design in an interactive environment, and rigorous enough to yield results satisfying optimality criterions. The embedding is used to derive the topology of the floorplan in the form of the structure tree of a slicing structure. To store the partial structure tree during the construction a concise and convenient data structure, the shorthand tree, is introduced. For any aspect ratio of the chip a minimum area floorplan can be generated.  The paper also shows how wiring space predictions can be incorporated, how varying degrees of module flexibility can be accounted for, and how fixing bonding pad macros affects the procedure.	algorithm;breadth-first search;computation;data structure;distance matrix;euclidean distance;loss function;netlist;optimization problem;time complexity;top-down and bottom-up design;wire bonding;wiring	Ralph H. J. M. Otten	1982	19th Design Automation Conference	10.1145/800263.809216	chip;embedded system;floorplan;mathematical optimization;combinatorics;aspect ratio;electronic engineering;discrete mathematics;distance matrix;data structure;electronic design automation;shape;computer science;modulation space;top-down and bottom-up design;mathematics;space technology;tree;silicon;programming language;matrix decomposition;engineering drawing;algorithm;symmetric matrix;satisfiability	EDA	15.632404247872575	50.105111860977296	112776
768105635674bccd0d02f0fb69874b27bbfd825e	q-tree: a new iterative improvement approach for buffered interconnect optimization	circuit cad trees mathematics iterative methods integrated circuit interconnections vlsi timing network routing circuit optimisation network topology integrated circuit design;iterative methods timing topology very large scale integration delay routing capacitance iterative algorithms steiner trees logic design;trees mathematics;network routing;network topology;iterative methods;integrated circuit design;obstacle avoidance;integrated circuit interconnections;timing optimization;easily extended functionality q tree iterative improvement approach buffered interconnect optimization vlsi interconnect timing optimization delay calculation hanan grafting nonhanan sliding greedy iterative interconnect timing optimization algorithm wires buffers interconnect tree timing performance improvement;vlsi;circuit cad;circuit optimisation;timing	The “chicken-egg” dilemma between VLSI interconnect timing optimization and delay calculation suggests an iterative approach. We separate interconnect timing transformation as Hanan grafting and non-Hanan sliding, and reveal generally negligible contribution of non-Hanan sliding. We propose a greedy iterative interconnect timing optimization algorithm called Q-Tree. Our experimental results show that Q-Tree starting with Steiner minimum tree topologies achieves better timing performance than C-Tree [1], PER-Steiner [5] and BA-Tree [14] algorithms. Also, executing Q-Tree starting with BA-Tree or P-Tree [13] topologies can achieve better timing performance, especially, with shorter wires and fewer buffers. In general, Q-Tree can be applied to any interconnect tree for further timing performance improvement, with practical instance sizes and easily-extended functionality e.g., with buffer station and routing obstacle avoidance consideration.	business architecture;delay calculation;greedy algorithm;iteration;iterative method;mathematical optimization;obstacle avoidance;phylogenetic tree;routing;steiner tree problem;very-large-scale integration	Andrew B. Kahng;Bao Liu	2003		10.1109/ISVLSI.2003.1183444	electronic engineering;parallel computing;real-time computing;computer science;static timing analysis	EDA	15.680287457815284	52.132176489170675	112972
7967c5130f357f3948fb3054d41d6fbb8b0ed252	temperature-insensitive synthesis using multi-vt libraries	multi threshold voltage;high temperature;temperature aware;logic synthesis;leakage power;side effect;threshold voltage;mos device	Temperature fluctuations can alter the delay in MOS circuits. However, increases in temperature do not always lead to a corresponding increase in circuit delay, specifically when operating at low supply voltages. Instead a temperature inversion effect can be observed on the delay of MOS devices under certain conditions, where the delay actually decreases as temperature increases. Given these non-monotonic effects, guaranteeing timing correctness can no longer be achieved simply by characterizing the design under worst case (i.e., high temperature) conditions. In this paper, we present a synthesis methodology in which multi-Vth design is used to generate temperature-insensitive circuits, while minimizing leakage power dissipation as a side-effect. Our experiments with ISCAS benchmark circuits demonstrate the promise of this approach and show that significant reduction in static power is also possible.	benchmark (computing);best, worst and average case;correctness (computer science);experiment;library (computing);non-monotonic logic;spectral leakage	Andrea Calimera;Enrico Macii;Massimo Poncino;R. Iris Bahar	2008		10.1145/1366110.1366116	electronic engineering;logic synthesis;real-time computing;computer science;engineering;electrical engineering;threshold voltage;programming language;side effect	EDA	19.40676169107637	56.74288685310971	113050
fe5ff94f24cef734a91dc0cae6e91f79ddcf74e0	a novel $ {\rm x}$-ploiting strategy for improving performance of test data compression	circuit decodeur;evaluation performance;appareillage essai;conversion temps numerique;performance evaluation;data compression;test data compression;evaluacion prestacion;time to digital conversion;circuito desciframiento;chip;x filling;decoding circuit;codificacion;backtracing;aparato ensayo;x propagating;coding;runlength codes;pattern recognition;testing equipment;compresion dato;test data compression tdc;compression donnee;codage	A precomputed core test set contains a large number of don't cares (x's) that can be effectively exploited to improve test data compression (TDC). Extending pattern run-length coding, we present a novel strategy that propagates the x's of a reference pattern to a new reference pattern in such a way that the reference pattern is xor-ed with the pattern to be encoded. The x -propagating strategy can increase the probability of a reference pattern being coding-compatible with the pattern to be encoded, and its validity can be established by filling some x's of the already encoded patterns in backtracing way. How our strategy is used for TDC is demonstrated. Experimental results for large ISCAS89 benchmarks show that, compared to the recently proposed schemes, our technique can effectively improve compression and simplify on-chip decoder, and work better when used for core-unified TDC.	benchmark (computing);data compression;don't-care term;exclusive or;precomputation;run-length encoding;test data;test set	Maoxiang Yi;Huaguo Liang;Wenfa Zhan	2010	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2008.2009873	data compression;chip;electronic engineering;telecommunications;computer science;engineering;coding;engineering drawing;statistics	Vision	19.599320512821684	53.7376670311123	113143
16ce669733bb34d830d8ce8fd5d29113612f51b4	cost effective implementation of asynchronous two-level logic	cost effectiveness	We proposed the cost effective (in sense of gate number) asynchronous two-level logic. It is based on AND-OR implementation of minimized logic functions. We formulated and proved the product term minimization constraint that ensures the logic correct behaviour. We pointed out the existing tool that yields the term minimization under the constraint formulated. We processed examples and generated asynchronous two-level logic by applying our approach and known ones. The implementation complexity was compared. Using our approach, we achieved significant improvement. Index Terms asynchronous logic, minimization, two level logic.	asynchronous circuit;logic programming	Igor Lemberski	2007			logic optimization;mathematical optimization;product term;theoretical computer science;asynchronous communication;mathematics	EDA	17.221033244272554	49.90828544777211	113219
50d215187abfd2f6fc78d23f87735fbf7090c0c2	satsot: a methodology to map controllable-polarity devices on a regular fabric using sat	libraries;pins;xor based logic functions;complexity theory;sea of tiles;computability;double gate vertically stacked nanowire fet;nanowires boolean algebra computability fabrics field effect transistors;transistors logic gates wiring complexity theory tiles pins libraries;boolean algebra;boolean satisfiability;wiring complexity satsot controllable polarity devices regular fabric sea of tiles double gate vertically stacked nanowire fet xor based logic functions compactness boolean satisfiability;logic gates;transistors;field effect transistors;fabrics;controllable polarity devices;nanowires;tiles;wiring	Devices with controllable-polarity, such as Double-Gate Vertically-Stacked Nanowire FETs, have shown promising interests in recent years to implement XOR-based logic functions in an unprecedented compact way. Such a compactness is obtained at the cost of a denser interconnect, that can be mitigated by designing an efficient hyper-regular layout structure, called Sea-of-Tiles. In this paper, we propose a methodology, based on Boolean satisfiability, to map netlists of transistors on such a structure. The methodology endeavors to minimize the wiring complexity, by maximizing the sharing of the different terminals. We showed that its implementation, SATSoT, is able to automatically generate compact mappings with wiring complexities similar to manual layouts.	boolean satisfiability problem;exclusive or;transistor;wiring	Catherine Gasnier;Pierre-Emmanuel Gaillardon;Giovanni De Micheli	2013	2013 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH)	10.1109/NanoArch.2013.6623043	electronic engineering;theoretical computer science;mathematics;algorithm	EDA	12.537624948217617	52.70015083083335	113235
62466ce57b97baead0d19d4f28fc637b971a53ca	a two-layer bus routing algorithm for high-speed boards	optimal solution;resource utilization;design automation;satisfiability;printed circuit design;routing bus structures two layer bus routing algorithm high speed boards high end industrial circuits;routing algorithm;routing clocks circuits frequency wires computer science computer industry design automation resource management runtime;high speed	The increasing clock frequencies in high-end industrial circuits bring new routing challenges that cannot be handled by traditional algorithms. An important design automation problem for high-speed boards today is routing nets within tight minimum and maximum length bounds. In this paper, we propose an algorithm for routing bus structures between components on two layers such that all length constraints are satisfied. This algorithm handles length extension simultaneously during the actual routing process so that maximum resource utilization is achieved during length extension. Our approach here is to process one track at a time, and choose the best subset of nets to be routed on each track. The algorithm we propose for single-track routing is guaranteed to find the optimal subset of nets together with the optimal solution with length extension on one track. The experimental comparison with a recently proposed technique shows the effectiveness of this algorithm both in terms of solution quality and run-time.	algorithm;clock rate;routing;run time (program lifecycle phase)	Muhammet Mustafa Ozdal;Martin D. F. Wong	2004	IEEE International Conference on Computer Design: VLSI in Computers and Processors, 2004. ICCD 2004. Proceedings.	10.1109/ICCD.2004.1347907	policy-based routing;routing table;routing domain;embedded system;routing;enhanced interior gateway routing protocol;in situ resource utilization;electronic engineering;static routing;real-time computing;zone routing protocol;electronic design automation;equal-cost multi-path routing;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;operating system;distance-vector routing protocol;place and route;distributed computing;routing protocol;link-state routing protocol;triangular routing;path vector protocol;routing;routing information protocol;computer network;satisfiability	EDA	15.215492639714343	52.07304408903141	113395
e8d1bfc1bda29785ea6cdcae08524c1b54602237	efficient scheduling of path delay tests for latch-based circuits	design for testability;circuit faults;logic design;probability density function;latch based circuits;flip flops;testing;multi segment paths;chip;minimization problem;latch based;delay testing;scheduling;time borrowing;schedules;path delay fault;heuristic approach path delay test scheduling latch based circuits design for testability minimization problem;latches;test scheduling;heuristic approach;multi segment paths delay testing test scheduling latch based time borrowing;circuit optimisation;high performance;high speed;circuit testing latches costs electronic equipment testing circuit faults delay effects clocks logic testing system testing robustness;lower bound;delays;fault diagnosis;scheduling circuit optimisation delays design for testability flip flops logic design;path delay test scheduling	In many high-speed parts of chips, latch-based circuits are used to enable time borrowing, where a block may take longer time than its nominal delay to complete its computation. This enables such circuits to attain high performance and yield. In [1] and [2], we focused on maximizing path delay fault coverage and proposed the first structural delay testing approach and the associated design-for-testability (DFT) for such circuits. This approach provides dramatically higher coverage of path delay faults.In this paper, we focus on minimizing test application cost for delay testing latch-based circuits while ensuring that maximum coverage is achieved. We show that conventional test scheduling methods may not be applicable due to the unique characteristics of latch-based circuits with time borrowing. We then formulate the minimization problem and propose two heuristic approaches. The experimental results show that, for many example circuits, the proposed approaches achieve overall test application costs that are within 5% of the corresponding lower-bounds.	computation;dspace;design for testing;electronic circuit;fault coverage;heuristic;scheduling (computing);static timing analysis;usability testing	Kun Young Chung;Sandeep K. Gupta	2009	2009 27th IEEE VLSI Test Symposium	10.1109/VTS.2009.41	chip;probability density function;electronic engineering;parallel computing;logic synthesis;real-time computing;telecommunications;schedule;computer science;operating system;design for testing;software testing;upper and lower bounds;scheduling;statistics	EDA	19.87755510578933	51.63888839685288	113415
2089469ced68cae1b755d956c85092a7a4a8800a	a behavioral modeling system for cell compilers	price timing model;new behavioral modeling facility;cell compiler-based design system;behavioral modeling system;special demand;user-supplied parameter value;flexible parameter mechanism;pin configuration;detailed timing description;data mining;logic design;vlsi;ic layout;behavior modeling;very large scale integration;computer aided design	In this paper we describe a new behavioral modeling facility that addresses the special demands imposed by a cell compiler-based design system. We present a flexible parameter mechanism that makes it possible to describe cells whose pin configurations vary according to user-supplied parameter values. We also introduce the PRICE timing model which provides for detailed timing descriptions.	behavioral modeling;compiler	James C. Althoff;Robert D. Shur	1985	22nd ACM/IEEE Design Automation Conference	10.1145/317825.317930	computer architecture;electronic engineering;real-time computing;computer science;electrical engineering;computer aided design;very-large-scale integration	EDA	11.40548583456471	51.87606550217588	113421
6c0750cfb9b08a6f9d4e282e3ad9772a48419eb3	a new algorithm for routing-aware net placement in cross-referencing digital microfluidic biochips	routing electrodes mixers interference compaction microfluidics pins;cross referencing biochips;routing;intelligent collision avoidance routing aware net placement digital microfluidic biochips lab on a chip architecture micromanipulation electric field addressable 2d electrode array cross referencing biochip technology electrode interference routing aware zone based detailed placement scheme droplet location presynthesized bioassay schematic cell utilization;cross referencing biochips algorithms placements routing electrode interference digital microfluidics;placements;microfluidics;digital microfluidics;electrode interference;microfluidics biotechnology lab on a chip;lab on a chip;algorithms;biotechnology	Digital micro fluidic biochips (DMFB) represent a new generation lab-on-a-chip architecture based upon micromanipulation of droplets via a programmed external electric field by an individually addressable 2D electrode array. DMFBs are classified as: Direct addressing and Cross-referencing biochips. Cross-referencing biochip technology scales down the number of pins per chip drastically, thereby reducing the costs of manufacturing and testing. However, these chips face a serious issue in terms of electrode interference during simultaneous routing of droplets. In this paper, we propose a routing-aware zone-based detailed placement scheme that rearranges the droplet locations on a pre-synthesized Bioassay schematic. The objectives of the proposed scheme include (i) an improved routing in respect of less overall routing time, more cell utilization, less crossover with intelligent collision avoidance, and (ii) enhanced pin sharing overcoming the major issue of electrode interference for Cross-referencing biochips. Simulations are carried out on four test benches of Benchmark suite III, and the results obtained are encouraging.	algorithm;benchmark (computing);biochip;computer simulation;heuristic (computer science);interference (communication);routing;schematic	Pranab Roy;Rupam Bhattacharjee;Hafizur Rahaman;Parthasarathi Dasgupta	2012	2012 IEEE Computer Society Annual Symposium on VLSI	10.1109/ISVLSI.2012.33	electronic engineering;engineering;electrical engineering;nanotechnology	Arch	14.1146129566474	53.52745328465327	113503
d980a0f67b80bf57fa7ab34a24aae874df26509f	minimizing power across multiple technology and design levels	mos integrated circuits;vlsi;circuit cad;circuit optimisation;integrated circuit design;integrated circuit interconnections;leakage currents;low-power electronics;minimisation;bgmos;vdd-hopping;active mode power reduction;boosted gate mos;bus shuffling;cooperative application/layout approach;design levels;interconnect system power consumption;low power high-speed vlsi;low-power design;power minimization;standby mode leakage current suppression;technology levels;technology/circuit level cooperation;threshold voltage hopping	Approaches to achieve low power and high-speed VLSIs are described with the emphasis on techniques across multiple technology and design levels. To suppress the leakage current in a standby mode, boosted gate MOS (BGMOS) is effective, which is based on cooperation between technology level and circuit level. To reduce the power in an active mode, VDD-hopping and VTH-hopping are promising, which are cooperative approaches between circuit and software. Power consumed in the interconnect system can be reduced by a cooperative approach between application and layout as in bus shuffling. Other low-power design approaches are also discussed.		Takayasu Sakurai	2002		10.1109/ICCAD.2002.1167509	embedded system;minimisation;electronic engineering;computer science;engineering;electrical engineering;leakage;very-large-scale integration;low-power electronics;statistics;integrated circuit design	HCI	16.780348155309994	56.8768936209677	113586
4c821e8ab5bed9ccfc59d9bf671cc43a3b0c2482	hardware implementation and performance comparison of interval type-2 fuzzy logic controllers for real-time applications	fpga;real time applications;interval type 2 fuzzy logic	Due to the complex structure of IT2 FLCs, using them in real-time applications might be computationally expensive. To facilitate real-time implementation of these controllers, hardware with parallel processing abilities are recommended; field-programmable gate arrays (FPGA) are one class of such hardware. In this paper, we design and implement three different inference mechanisms of IT2 FLCs on hardware. These engines include Karnik–Mendel (KM) algorithms, Wu–Mendel (WM) uncertainty bounds, Nie-Tan (NT) and Biglarbegian–Melek–Mendel (BMM) which have recently been introduced in the literature. We first demonstrate how the proposed structures of the IT2 FLCs can be implemented on software; next, we propose architectures for implementing these IT2 FLCs on hardware. We performed simulations to compare the performance of the IT2 FLCs. To assess the controllers performance in real-time we used four indicators; the number of DSP48A1s, MUXCYs, slice registers and slice LUTs. It was shown that the NT and BMM controllers require significantly fewer resources compared to the other engines. While the controller that uses KM as its inference engine uses fewer resources in terms of DSP48A1s, it consumes a considerable amount of other resources compared to the WM controller. Finally, the transient responses of the controllers in terms of rise time and settling time were compared. It was found that the controllers with NT and BMM inference engines have faster closed-loop response in comparison to the one using the WM and KM. The results presented herein provides researchers and engineers a better insight into designing the most suitable IT2 FLCs, and hence it is expected IT2 FLCs can be implemented on hardware to further enable applications on plants requiring fast response (or ultimately real-time implementation). © 2015 Elsevier B.V. All rights reserved.	algorithm;analysis of algorithms;business motivation model;field-programmability;field-programmable gate array;fuzzy logic;inference engine;mendel palace;os-tan;parallel computing;real-time clock;real-time computing;real-time web;rise time;settling time;simulation	Matthew D. Schrieber;Mohammad Biglarbegian	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.03.022	embedded system;real-time computing;computer science;artificial intelligence;theoretical computer science;machine learning;field-programmable gate array	Embedded	10.585623146459076	47.049282064671786	113592
bbb0da6b8c2c50c0bfcad8a77466a3702d6ac71b	timing yield optimization via discrete gate sizing using globally-informed delay pdfs	absolute yield improvement;timing yield optimization;timing yield constraint;actual optimization;relative yield improvement;non-statistical timing;discrete gate;entire circuit;globally-informed delay pdfs;optimized circuit;efficient discrete optimization technique;statistical circuit timing optimization;objective function;gaussian distribution;sensitivity;optimization;taylor series;logic gates;statistics;monte carlo;network flow;discrete optimization	We develop two novel globally-informed gate-sizing algorithms for tackling the problems of statistical circuit timing optimization under a timing yield constraint, and timing yield optimization under a timing (i.e., delay) constraint. Unlike previous works, our techniques are global in the sense that they use objective functions that take into account either the entire circuit's variabilities and available gate sizes or those of the statistically timing-critical part of the circuit. The actual optimization, using the aforementioned objective functions, was performed using a recently introduced efficient discrete optimization technique called discretized network flow (DNF). We compared our algorithms to a state-of-the-art sensitivity based method. Experimental results show an absolute yield improvement of up to 43% and an average of 37% for the best of our two techniques over that of a non-statistical timing optimized circuit (optimized using a recent state-of-the-art method) based on the worst-case delay estimate for each gate. Our technique also gives a 19% better relative yield improvement over the sensitivity based method.	algorithm;best, worst and average case;discrete optimization;discretization;flow network;mathematical optimization;newton's method;portable document format	Shantanu Dutt;Huan Ren	2010	2010 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		normal distribution;discrete optimization;mathematical optimization;electronic engineering;real-time computing;flow network;delay calculation;logic gate;sensitivity;computer science;taylor series;mathematics;static timing analysis;statistics;monte carlo method	EDA	22.922696256227283	57.85936540957503	113772
d689acf7e2e255509db0a05be455c0738ba4394b	design and testing of millimeter-wave/subterahertz circuits and systems		h WITH THIS LAST D&T issue of 2014, we welcome our readers to a topic we have yet to cover: millimeter wave (mm-wave) and subterahertz (sub-THz) circuits. We are excited to bring this focused and timely issue before you, with the goal of highlighting some of the most trailblazing solutions to contemporary challenges in the design and test of mm-wave and sub-THz circuits/systems. The wide applicability and concrete industry examples of this issue’s selected articles fill an important and interesting gap in D&T’s topical coverage to date. I am happy to shed light on the impressive list of articles in this special issue. (The guest editors will do a much better job at this than I!) As eloquently introduced by our esteemed guest editors Drs. Heo and Kim, our first article is coauthored by Plouchart, Parker, Sadhu, Valdes-Garcia, Friedman, Wang, Li, Sanduleanu, and Balteanu, which addresses adaptive circuit design as applied to mm-wave circuits. Proposing adaptive developments in all of indirect sensing, integration of circuit loops, and microcontroller algorithms, the authors demonstrate effective design and test for communication circuits that maximize production and minimize energy expended. Our second selection, coauthored by Yu, Baylon, Wettin, Heo, Pande, and Mirabbasi, introduces multichannel wireless network-on-chip (WNoC) architecture as a remedy for interconnect structure in multicore processors. With various mm-wave frequency band examples, the potential performance improvements and efficiency of a triple-band mmwave transceiver is shown, in direct comparison with conventional WNoC architectures. Next, an article by Lu, Loke, and Jung directly addresses an important concern amid the improvements that 3-D stacked integrated circuits (3-D SICs) have made in integration density: yield loss during manufacturing and the resulting test costs. The article outlines the pros and the cons of mm-wave wireless interconnect in 3-D SIC testing and presents a solution to conventional shortcomings through a contact-free input/output testing example. Continuing the focus of this special issue, our fourth selection by Yeh, Chiong, Chen, and Wang brings forth the approach of the monolithic microwave integrated circuit (MMIC) to mm-wave frequency operation. In light of historical applications that called for mitigation of crowded frequencies, the authors propose the importance and design of mm-wave MMIC mixers across a diverse array of modern applications, imperative for understanding trends of future communication. We close our issue with a paper by Kazemipour, Salhi, Kleine-Ostmann, and Schrader, which proposes an update to classic conversion-loss measurement using only relative RF power measurement. Methods and results are supported by two commercial test cases. I would like to take this opportunity to sincerely thank our guest editors, Dr. Deukhyoun Heo and Dr. Jonghae Kim, for putting considerable effort into	algorithm;central processing unit;circuit design;entity–relationship model;frequency band;imperative programming;input/output;jung;lu decomposition;microcontroller;monolithic microwave integrated circuit;multi-core processor;network on a chip;radio frequency;simplified instructional computer;test case;transceiver	André Ivanov	2014	IEEE Design & Test	10.1109/MDAT.2014.2364871	electronic circuit;electronic engineering;extremely high frequency;computer science	EDA	12.234908328925345	56.298203931807215	113927
987611ef6b2fb573b542286104e9fb2aa9e5a10d	accurate temperature estimation using noisy thermal sensors	fabrication;dtm temperature on chip sensor estimation multicore;thermal management packaging;thermal management packaging gaussian processes system on chip temperature sensors;sensor phenomena and characterization;statistical methodology;fluctuations;gaussian processes;dtm;probability density function;temperature sensors;thermal sensors;temperature estimation;runtime;thermal sensor;rms error;multisensor prediction;chip;multicore;statistical analysis;estimation;system on chip;multicore soc;noise reduction;multicore processing;gaussian characteristic;rms error temperature estimation thermal sensor multicore soc runtime thermal measurement on chip sensor dtm dynamic thermal management statistical methodology single sensor prediction multisensor prediction gaussian characteristic;temperature sensors thermal sensors sensor phenomena and characterization multicore processing runtime fabrication fluctuations statistical analysis temperature distribution noise reduction;on chip sensor;temperature;single sensor prediction;temperature distribution;dynamic thermal management;noise;runtime thermal measurement	Multicore SOCs rely on runtime thermal measurements using on-chip sensors for DTM. In this paper we address the problem of estimating the actual temperature of on-chip thermal sensor when the sensor reading has been corrupted by noise. Thermal sensors are prone to noise due to fabrication randomness, VDD fluctuations etc. This causes discrepancy between actual temperature and the one predicted by thermal sensor. Our experiments estimate this variation to be around 30%. In this paper we present a statistical methodology for predicting the actual temperature for a given sensor reading. We present two techniques: single sensor prediction and multi-sensor prediction. The latter tries to estimate the actual temperature for each sensor (of the many on-chip sensors) simultaneously while exploiting the correlations between temperature and noise of different sensors. When the underlying randomness follows a Gaussian characteristic, we present optimal schemes of estimating the expected temperature. We also present heuristic schemes for the case where the Gaussian assumption fails to hold. The experiments showed that using our estimation schemes the RMS error can be reduce as much as 67% as compared to blindly trusting the sensors to be noise free.	discrepancy function;experiment;heuristic;image noise;multi-core processor;randomness;sensor;system on a chip;trust (emotion);value-driven design	Yufu Zhang;Ankur Srivastava	2009	2009 46th ACM/IEEE Design Automation Conference	10.1145/1629911.1630036	multi-core processor;embedded system;electronic engineering;real-time computing;computer science;engineering;statistics	EDA	23.150632413119624	60.02554723827654	113990
9fc7f8131f6190c898c14f1aad3fdb3316216559	an effective and efficient algorithm to analyse and debug clock propagation issues		The evolution of deep submicron (DSM) era has resulted in rapid shrinking of the System-on-Chip (SoC) simultaneously with the exponential increase in the design complexity. Larger designs require numerous Intellectual Properties (IPs) composed of millions of combinational and sequential cells to serve the purpose which further require an extensive web of complex clock tree architecture for effective functionality. But with the increase in complexity, it is becoming more and more difficult to keep track about the clock signal effectively reaching to each intended sequential leaf cell. Clock signal, if gets blocked, can hamper the functionality of that particular IP and the effect, in essence, can further ripples down to broken functionality of the complete design. It is therefore imperative to thoroughly check the design for the locations where clock signal is unavailable in early stages of design implementations. This paper provides an algorithm in form of prototype debugger tool which aims at identifying the root cause of no clock signal reaching the clock pin of sequential cell in single iteration. It moves a step further by looking ahead and detecting all the possible potential blocking reasons, apart from the actual ones within a given clock path to a sequential cell in the same iteration. Experimental results on set top box chip show the effectiveness and the efficiency of this method by capturing all the actual and additional probable clock blocking reasons in a single step.	algorithm;blocking (computing);clock signal;combinational logic;debugger;imperative programming;iteration;mpsoc;prototype;sensor;set-top box;software propagation;system on a chip;time complexity;very-large-scale integration	Pawan Sehgal;Aditi Sharma;Akhilesh C. Mishra;Rangarajan Ramanujam;Sujay Deb	2016	2016 20th International Symposium on VLSI Design and Test (VDAT)	10.1109/ISVDAT.2016.8064849	clock domain crossing;real-time computing;clock gating;electronic engineering;clock skew;digital clock manager;cpu multiplier;matrix clock;synchronous circuit;computer science;algorithm;self-clocking signal	EDA	21.150897413598788	52.589145818970024	114301
583be9b80ea055acf28e7d6e8d8166d83668768e	an analysis of timing violations due to spatially distributed thermal effects in global wires	timing violation;thermal management packaging;reliability;microarchitecture;crosstalk;timing wire delay microarchitecture heat sinks thermal conductivity temperature dependence thermal management dielectric substrates permission;delay variability;performance;dielectric substrates;joule heating;temperature gradient;timing violation design performance reliability crosstalk delay on chip interconnect power dissipation reliability temperature thermal model;wires electric;temperature dependence;chip;wire;on chip interconnect;permission;spatial distribution;propagation delay;power dissipation;thermal model;thermal conductivity;design;spatially distributed thermal effects;temperature;heat sinks;wires electric thermal management packaging;thermal management;global wires;spec cpu2k benchmarks;spec cpu2k benchmarks spatially distributed thermal effects global wires joule heating delay variability thermal management;thermal effects;timing	Higher-than-normal wire temperatures and temperature gradients between the sending and receiving ends of a wire that are caused due to Joule heating and substrate hotspots affect the propagation delay of a wire significantly. In this paper, we develop a high-level model to track wire temperatures and delay variability during early stage design exploration. Results using our model show that ALU result bus wires in a 4-issue processor are likely to reach temperatures as high as 103°C (117°C) in 130-nm (45-nm) technology which is greater than the 100°C maximum normally assumed during interconnect design. For a 130-nm processor with no power and thermal management, the temperature-induced timing violations in the ALU result bus, on average across ten SPEC CPU2K benchmarks, is 2.27 per hundred bus references and it can be as high as 4.91 per hundred bus references in some programs. It increases to an average of 6.20 per hundred bus references for the same processor at the 45-nm technology node.	arithmetic logic unit;gradient;heart rate variability;high- and low-level;joule;propagation delay;semiconductor device fabrication;software propagation;the 100;thermal management of high-power leds	Krishnan Sundaresan;Nihar R. Mahapatra	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278612	chip;joule heating;embedded system;propagation delay;design;electronic engineering;crosstalk;temperature;performance;microarchitecture;electrical engineering;reliability;thermal conductivity;temperature gradient	EDA	20.22470275032236	57.84971643776926	114552
ef0b11ad850c4ad714ba77ef27b55143a65d0430	efficient trace signal selection for silicon debug by error transmission analysis	silicon;post silicon debug process trace signal selection error transmission analysis internal signals circuit misbehavior automated procedure early detection circuit malfunction hardware resources sequential circuits functional input vector set error transmission matrix flip flops error sites integer linear programming nonconforming chip behavior;observability;integer linear programming;signal observability;circuit faults;integrated circuit;error propagation matrix;sequential circuits;flip flops;signal processing flip flops integer programming linear programming logic testing sequential circuits;chip;silicon debug;vectors;integer programming;error propagation;vectors silicon circuit faults observability integrated circuit modeling hardware equations;signal processing;integrated circuit modeling;logic testing;linear programming;early detection;flip flop;integer linear program;hardware;silicon debug error propagation matrix integer linear programming signal observability	In this paper, a technique is presented for selecting signals to observe during silicon debug. Internal signals are used to analyze, understand, and debug circuit misbehavior. An automated procedure to select which signals to observe is proposed to facilitate early detection of circuit malfunction and to enhance the utilization of hardware resources for storage. Signals that are most often sensitized to possible errors are observed in sequential circuits. Given a functional input vector set, an error transmission matrix is generated by analyzing which flip-flops are sensitized to other flip-flops. Relatively independent flip-flops are identified and a set of signals that maximally cover the possible error sites with given constraints are identified through integer linear programming. Experimental results show that the proposed approach can rapidly and precisely identify the nonconforming chip behavior and thereby can speed up the post-silicon debug process.	byzantine fault tolerance;debug;debugging;flops;flip-flop (electronics);heuristic;integer programming;linear programming;problem domain;scalability;simulation	Joon-Sung Yang;Nur A. Touba	2012	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2011.2171184	chip;debug code;embedded system;mathematical optimization;electronic engineering;real-time computing;observability;integer programming;computer science;propagation of uncertainty;integrated circuit;mathematics;sequential logic;silicon	EDA	21.992824372929334	50.77280610899489	114571
73ef4d3f384ee738037286db12b748590cbaa034	: test scheduling for high performance vlsi system implementations	vlsi automatic testing electronic engineering computing integrated circuit testing iterative methods;resource allocation;automatic testing;system testing very large scale integration parallel processing logic testing design for testability built in self test pipeline processing clocks processor scheduling performance evaluation;iterative methods;test methods;local optima automatic testing vlsi suboptimum heuristic labeled resource allocation graph test functions scheduling model optimum schedules iterative improvement procedure;integrated circuit testing;vlsi;electronic engineering computing;test scheduling;high performance	A powerful suboptimum heuristic for scheduling tests on general-purpose high-performance VLSI system implementations is presented. A simple model that represents a system and its organization, at any level, by a labeled resource allocation graph between test functions and test and system resources was introduced. The resource allocation graph was utilized to produce a scheduling model and a simple schedulability condition. An algorithm based on mechanisms for generating optimum schedules was presented. The algorithm performs a preliminary greedy scan for valid scheduling cycles. The partial scan seeds an iterative improvement procedure which utilizes a controlled incremental departure from local optima to schedule functions that require an equal number of tests. Methods to utilize the algorithm for a general number of tests per function were also outlined. The implementation of an experimental version of the algorithm showed good performance. >	very-large-scale integration	John Y. Sayah;Charles R. Kime	1988		10.1109/TEST.1988.207829	fair-share scheduling;embedded system;electronic engineering;parallel computing;real-time computing;dynamic priority scheduling;resource allocation;computer science;theoretical computer science;iterative method;very-large-scale integration;test method;statistics	HPC	17.20730934319256	51.26504745937856	114575
eb04033a2ee74bb37f5e2f3f3d09a5b9f0f5149f	mitigation of nbti induced performance degradation in on-chip digital ldos		On-chip digital low-dropout voltage regulators (LDOs) have recently gained impetus and drawn significant attention for integration within both mobile devices and micro-processors. Although the benefits of easy integration and fast response speed surpass analog LDOs and other voltage regulator types, NBTI induced performance degradation is typically overlooked. The conventional bi-directional shift register based controller can even exacerbate the degradation, which has been demonstrated theoretically and through practical applications. In this paper, a novel uni-directional shift register is proposed to evenly distribute the electrical stress and mitigate the NBTI effects under arbitrary load conditions with nearly no extra power and area overhead. The benefits of the proposed design as well as reliability aware design considerations are explored and highlighted through simulation of an IBM POWER8 like processor under several benchmark applications. It is demonstrated that the proposed NBTI-aware design can achieve up to 43.2% performance improvement as compared to a conventional one.	assistive technology;benchmark (computing);central processing unit;dropout (neural networks);elegant degradation;microprocessor;mobile device;negative-bias temperature instability;overhead (computing);shift register;simulation;transistor;voltage regulator	Longfei Wang;S. Karen Khatamifard;Ulya R. Karpuzcu;Selçuk Köse	2018	2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)	10.23919/DATE.2018.8342116	real-time computing;voltage regulator;computer science;power8;chip;control theory;negative-bias temperature instability;performance improvement;mobile device;shift register	EDA	18.903525193474948	59.82714443457787	114666
0fd24e2e63c1f8dbde611aff62dd9f9a96780c8b	an implementation of a saturated zone multi-layer printed circuit board router	printed circuits;information systems;cost function;routing;distributed computing;probes;wire;permission;integrated circuit interconnections;printed circuits routing permission integrated circuit interconnections wire information systems cost function probes distributed computing machinery;printed circuit board;machinery	A new multi-layer printed circuit board routing technique is presented which combines two existing algorithms with a new cost function. The present implementation of this new technique handles up to four layers at a time. The earlier works are overviewed and enhancements incorporated in the new implementation are pointed out. Experimental results obtained using this new router on printed circuit boards of various sizes and routing densities are also described.	algorithm;central processing unit;layer (electronics);loss function;printed circuit board;printing;router (computing);routing	Michael J. Lorenzetti;Robert J. Smith	1980	17th Design Automation Conference	10.1145/800139.804536	embedded system;electronic engineering;real-time computing;diagnostic board;computer science;engineering;electrical engineering;circuit design;flying probe;printed circuit board;routing;computer network	EDA	14.852687430066565	51.842865719503806	114776
1ba4b53a2bec1c218b558eeefcefbb16f25c3a0b	influence of leakage reduction techniques on delay/leakage uncertainty	process variation;delays integrated circuit design circuit optimisation monte carlo methods leakage currents low power electronics;leakage reduction;integrated circuit design;technology scaling;leakage power;leakage currents;low power electronics;temperature sensitive;delay uncertainty threshold voltage frequency transistors leakage current energy consumption computer science design engineering power engineering and energy;circuit optimisation;uncertainty power delay trade off leakage reduction delay leakage uncertainty integrated circuit design leakage power monte carlo analysis gate length stack forcing body biasing;monte carlo methods;monte carlo analysis;delays	One of the main challenges for design in the presence of process variations is to cope with the uncertainties in delay and leakage power. In this paper, the influence of leakage reduction techniques on delay/leakage uncertainty is examined through Monte-Carlo analysis. The techniques investigated in this paper include increasing gate length, stack forcing, body biasing, and V/sub dd//V/sub th/ optimization. The impact of technology scaling and temperature sensitivity on the uncertainty reduction are also evaluated. We investigate the uncertainty-power-delay trade-off and suggest techniques for designs targeting different requirements.	biasing;image scaling;mathematical optimization;monte carlo method;power supply;requirement;spectral leakage;static timing analysis;transistor	Yuh-Fang Tsai;Narayanan Vijaykrishnan;Yuan Xie;Mary Jane Irwin	2005	18th International Conference on VLSI Design held jointly with 4th International Conference on Embedded Systems Design	10.1109/ICVD.2005.111	electronic engineering;real-time computing;computer science;engineering;electrical engineering;statistics;monte carlo method	EDA	20.013881589805578	58.29526829519647	114807
9ac085e15fb76349070324606d516ea9e4241c43	timing margin evaluation with a simple statistical timing analysis flow	statistical timing analysis;design margins	With technology scaling, power dissipation and localized heating in global and semi-global bus wires are becoming increasingly important. One way to mitigate these effects is to ensure uniform switching of bus wires. This prevents the unusual heating ...		V. Migairou;Robin Wilson;Sylvain Engels;Zeqin Wu;Nadine Azémard;Philippe Maurine	2009	J. Embedded Computing	10.3233/JEC-2009-0094	computer science	EDA	19.849074576244718	58.21759907159892	114935
205a59a7a53169752547d2c96b2cbd5a69a0dcb2	hazard correction in asynchronous sequential circuits	switching circuits;input variables;sequential circuits;hazards;automata;propagation delay;safety;hazards sequential circuits circuit synthesis propagation delay switching circuits input variables automata safety;circuit synthesis			Stuart B. Lerner	1965	IEEE Trans. Electronic Computers	10.1109/PGEC.1965.264261	a symbolic analysis of relay and switching circuits;propagation delay;electronic engineering;real-time computing;hazard;computer science;sequential logic;automaton;algorithm	EDA	20.937683854676116	47.65352362092425	115288
479a78b5f41d1e8952321223ad6a5140c5cd5a3a	an optimization-based multiple-voltage scaling technique for low-power cmos digital design	optimization based;low power;digital design;voltage scaling;power minimization	In this paper, we propose a voltage scaling technique with multiple supply voltages for low-power designs. We adopt the path sensitization technique and release the clustering constraint used by the previous works. Our technique first operates the gates with the lowest feasible supply voltages and then uses an existing path selection algorithm for optimization. Experiments are conducted on all the ISCAS85 benchmarks and the results show that significant power can be further reduced by our technique in comparison with the previous works. Furthermore, the results generated by our technique are close to the optimal values.	cmos;cluster analysis;combinational logic;concurrent versions system;dynamic voltage scaling;image scaling;low-power broadcasting;mathematical optimization;selection algorithm	Yi-Jong Yeh;Sy-Yen Kuo	2002	Journal of Circuits, Systems, and Computers	10.1142/S0218126602000513	embedded system;mathematical optimization;electronic engineering;logic synthesis;real-time computing;computer science;engineering	EDA	16.741234552481654	55.024293249914166	115305
69ba8e36bf2c3e7e334def33628109cb364c3544	a defect-oriented test approach using on-chip current sensors for resistive defects in finfet srams		Resistive defects in FinFET SRAMs are an important challenge for manufacturing test in submicron technologies, as they may cause dynamic faults, which are hard to detect and therefore may increase the number of test escapes. This paper presents a defect-oriented test that uses On-Chip Current Sensors (OCCSs) to detect weak resistive defects by monitoring the current consumption of FinFET SRAM cells. Using OCCSs, all resistive defects injected in single cells considered in this paper have been detected within a certain accuracy by applying 5 read or write operations only, independent whether they cause static or dynamic faults. The proposed approach has been validated and the detection accuracy has been evaluated. Simulation results show that the approach is even able to detect weak resistive defects that do not sensitize faults at the functional level, thus able to increase the reliability of devices.	sensor;software bug;static random-access memory	G. Cardoso Medeiros;Letícia Maria Veiras Bolzani;Mottaqiallah Taouil;Fabian Vargas;Said Hamdioui	2018	Microelectronics Reliability	10.1016/j.microrel.2018.07.092	static random-access memory;electronic engineering;chip;engineering;resistive touchscreen	EDA	20.846958024183873	56.08490327492387	115327
1562f8dfdd4f5c1a24b5b3a98c02bd516d472573	longest-path selection for delay test under process variation	process correlation;path delay;delay test;process variation;longest-path selection;delay fault;different process condition;local defect;multiple longest path;longest path;process condition	Under manufacturing process variation, a path through a fault site is called longest for delay test if there exists a process condition under which the path has the maximum delay among all paths through that fault site. There are often multiple longest paths for each fault site in the circuit, due to different process conditions. To detect the smallest delay fault, it is necessary to test all longest paths through the fault site. However, previous methods are either inefficient or their results include too many paths that are not longest.This paper presents an efficient method to generate the longest path set for delay test under process variation. To capture both structural and systematic process correlation, we use linear delay functions to express path delays under process variation. A novel path-pruning technique is proposed to discard paths that are not longest, resulting in a significantly reduction in the number of paths compared with the previous best method. The new method can be applied to any process variation as long as its impact on delay is linear.	fault injection;longest path problem	Xiang Lu;Zhuo Li;Wangqi Qiu;D. M. H. Walker;Weiping Shi	2004	ASP-DAC 2004: Asia and South Pacific Design Automation Conference 2004 (IEEE Cat. No.04EX753)	10.1145/1015090.1015115	mathematical optimization;electronic engineering;real-time computing;delay calculation;computer science;engineering;electrical engineering;elmore delay;interconnection;distributed computing;contamination delay;digital electronics;static timing analysis	EDA	21.824007480201885	51.46968084694965	115411
97fa2f9c26abe2432bca429c43bcdcf5da40a005	performance evaluation of 1-bit cmos adder cells	performance measure;automatic test pattern generation cmos logic circuits adders cellular arrays delays logic testing;performance evaluation;input test pattern cmos adder cells full adder cell power consumption measurement time delay area power dissipation;automatic test pattern generation;time delay;cellular arrays;adders;cmos logic circuits;power dissipation;adders delay effects circuit testing power dissipation power measurement velocity measurement energy consumption measurement standards time measurement voltage;logic testing;power consumption;delays	Evaluating the performance measures of a full adder cell, like other circuits, is input pattern dependent. The issue gets more complicated when evaluating several parameters such as time delay, area, power dissipation, and correct functionality at the same time. The proposed input test pattern is based on full coverage of all possible transitions from one input pattern to another. It is composed of two parts: the first is a 56 transitions input pattern for speed measurement, followed by 9 different input patterns concatenated together for power consumption measurement. The proposed input test pattern proves the correct functionality, and produces correct time delay and power dissipation. Using this input test pattern guarantees correct and fair comparison among different full adder cells.	1-bit architecture;adder (electronics);cmos;performance evaluation	Ahmed M. Shams;Magdy A. Bayoumi	1999		10.1109/ISCAS.1999.777797	electronic engineering;real-time computing;computer hardware;computer science;dissipation;automatic test pattern generation;adder	EDA	19.95913010231078	55.801877906976216	115448
5d09ab1215d6fa8f55b5a15d1f360c20dba31812	on test generation by input cube avoidance	computed input cube;certain input value;explicit test generation;test generation procedure;input cube avoidance;built-in test generation;random input vector;incompletely specified input vector;input vector;target fault;input cube;polynomials;search space;system on a chip;fault detection	Test generation procedures attempt to assign values to the inputs of a circuit so as to detect target faults. We study a complementary view whereby the goal is to identify values that should not be assigned to inputs in order not to prevent faults from being detected. We describe a procedure for computing input cubes (or incompletely specified input vectors) that should be avoided during test generation for target faults. We demonstrate that avoiding such input cubes leads to the detection of target faults after the application of limited numbers of random input vectors. This indicates that explicit test generation is not necessary once certain input values are precluded. Potential uses of the computed input cubes are in a test generation procedure to reduce the search space, and during built-in test generation to preclude input vectors that will not lead to the detection of target faults.	built-in self-test;olap cube	Irith Pomeranz;Sudhakar M. Reddy	2007	2007 Design, Automation & Test in Europe Conference & Exhibition		system on a chip;embedded system;electronic engineering;real-time computing;fault coverage;computer science;engineering;automatic test pattern generation;test compression	EDA	21.366759167492052	50.8285992551858	115520
159e1b6b5bf8bca1fa0b2a4c484a4695eb357a7b	synchronous equivalence for embedded systems: a tool for design exploration	impedance extraction;embedded system algorithm design and analysis timing computational modeling space exploration latches power system modeling sequential circuits design methodology clocks;surface integral equation;shock control;embedded systems;finite state machines;fasthenry;computational complexity;shock absorber controller synchronous equivalence embedded systems design exploration tool high level specification functional equivalence sequential circuits equivalence analysis algorithms polynomial complexity real life design;electromagnetics;circuit cad;peec;finite state machines circuit cad embedded systems computational complexity shock control	This paper presents a new protocol for parallel and distributed simulation of VLSI systems. It is novel in two aspects: first, it combines optimistic and conservative synchronization methods, allowing processes to self-adapt for maximal utilization of concurrency. Second, it does not require any application-dependent information like lookahead, which in many cases is unknown, zero, or difficult to automatically obtain from a design in a hardware description language. All these features make it very convenient and practical, extending the class of applications to at least all VHDL circuits, including delta cycle. The proposed protocol has been implemented and used for VHDL simulation. Experimental results on several large VHDL circuits (between 1411 and 14704 processes) have shown promising linear speedups. We also observed that the dynamic synchronization, in which processes automatically adapt to optimistic or conservative behavior, follows closely or finds a very good configuration. This protocol may have a string impact for mixed-signal circuit simulation, where digital parts may be optimistic and heavy-state analog parts, conservative.	concurrency (computer science);electronic circuit simulation;embedded system;hardware description language;maximal set;mixed-signal integrated circuit;optimistic concurrency control;parsing;synchronization (computer science);turing completeness;vhdl;very-large-scale integration	Harry Hsieh;Felice Balarin	1999	1999 IEEE/ACM International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.99CH37051)	10.1109/ICCAD.1999.810702	control engineering;embedded system;mathematical optimization;electronic engineering;real-time computing;electromagnetism;computer science;theoretical computer science;operating system;finite-state machine;programming language;computational complexity theory;algorithm	EDA	18.720413044638534	49.395602674265504	115592
0e379519974473b83a96868a217b3b4c26be943a	coverage-directed test generation automated by machine learning - a review	automated design;bayesian network;genetic program;inductive logic programming ilp;inductive logic programming;genetic programming;artificial intelligent;markov model;machine learning;coverage directed test generation cdg;digital design;markov models;test generation;genetic algorithm;genetic algorithms;bayesian networks	The increasing complexity and size of digital designs, in conjunction with the lack of a potent verification methodology that can effectively cope with this trend, continue to inspire engineers and academics in seeking ways to further automate design verification. In an effort to increase performance and to decrease engineering effort, research has turned to artificial intelligence (AI) techniques for effective solutions. The generation of tests for simulation-based verification can be guided by machine-learning techniques. In fact, recent advances demonstrate that embedding machine-learning (ML) techniques into a coverage-directed test generation (CDG) framework can effectively automate the test generation process, making it more effective and less error-prone. This article reviews some of the most promising approaches in this field, aiming to evaluate the approaches and to further stimulate more directed research in this area.	artificial intelligence;cognitive dimensions of notations;delay-gradient congestion control;machine learning;simulation	Charalambos Ioannides;Kerstin Eder	2012	ACM Trans. Design Autom. Electr. Syst.	10.1145/2071356.2071363	mathematical optimization;parallel computing;genetic algorithm;computer science;artificial intelligence;machine learning;bayesian network;markov model;programming language;algorithm	SE	16.506114144387244	47.156384718927754	115632
4a560990e9bcb27b2fb20713d7e11075a83d020a	a practical guide to combining ict & boundary scan testing	pins;performance evaluation;fixtures;bscan ict boundary scan testing in circuit testing fault coverage throughput fixturing fault diagnosis;bscan ict;geometry;testing;probes;boundary scan testing;fault diagnosis boundary scan testing circuit testing;fault detection;manufacturing;fault coverage;circuit testing;in circuit testing;fault diagnosis;throughput;testing throughput manufacturing fault detection fixtures pins fault diagnosis geometry probes performance evaluation;fixturing	This paper focuses on the practical aspects of combining boundary scan testing with traditional In-Circuit Test. The fault coverage, diagnostic, fixturing, and throughput benefits that can be realized by testing with a combined BSCAN/ICT strategy are described, along with the specific issues and challenges involved in providing a comprehensive BSCAN/ICT solution.	boundary scan;fault coverage;in-circuit test;printed circuit board;sensor;software bug;test engineer;test fixture;throughput	Alan Albee	2001		10.1109/TEST.2001.966666	reliability engineering;embedded system;throughput;electronic engineering;fault coverage;computer science;engineering;software testing;manufacturing;in-circuit test;fault detection and isolation	Robotics	23.14811773924646	53.347611811652264	115710
5a43bfe8a8b8e5f374cd844a2b12a835858ab221	skynet: memristor-based 3d ic for artificial neural networks		Hardware implementations of artificial neural networks (ANNs) have become feasible due to the advent of persistent 2-terminal devices such as memristor, phase change memory, MTJs, etc. Hybrid memristor crossbar/CMOS systems have been studied extensively and demonstrated experimentally. In these circuits, memristors located at each cross point in a crossbar are, however, stacked on top of CMOS circuits using back end of line processing (BOEL), limiting scaling. Each neuron's functionality is spread across layers of CMOS and memristor crossbar and thus cannot support the required connectivity to implement large-scale multi-layered ANNs. This paper introduces a new fine-grained 3D integrated circuit technology for ANNs that is one of the first IC technologies for this purpose. Synaptic weights implemented with devices are incorporated in a uniform vertical nanowire template co-locating the memory and computation requirements of ANNs within each neuron. Novel 3D routing features are used for interconnections in all three dimensions between the devices enabling high connectivity without the need for special pins or metal vias. To demonstrate the proof of concept of this fabric, classification of binary images using a perceptron-based feed forward neural network is shown. Bottom-up evaluations for the proposed fabric considering 3D implementation of fabric components reveal up to 21x density, 1.8x power benefits and a 2.6x improvement in delay when compared to 16nm hybrid memristor/CMOS technology.		Sachin Bhat;Sourabh Kulkami;Jiajun Shi;Mingyu Li;Csaba Andras Moritz	2017	2017 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH)	10.1109/NANOARCH.2017.8053706	memristor;computer science;artificial neural network;electronic engineering;phase-change memory;memistor;three-dimensional integrated circuit;crossbar switch;integrated circuit;cmos	Arch	11.700998171436131	52.127688649842874	115716
6c2667efb007493e17510c4a3db3c8d43bf9417f	guest editors' introduction: special section on emerging memory technologies in very large scale computing and storage systems	special issues and sections random access memory power demand program processors system on chip sram disk drives memory management energy consumption	THE overwhelmingly increasing demand for both storage and computation necessitates revisiting the traditional memory subsystems used in processors and storage systems to take advantage of emerging memory technologies. Dynamic Random Access Memory (DRAM) and Static Random Access Memory (SRAM) have been ubiquitously used for decades as main memory and as on-chip cache, respectively. Scaling and power issues of these traditional memory technologies have led to significant investment in emerging memory technologies. On the other hand, fundamental limitations of mechanical disk drives have brought great attention to further explore the design space of Solid-State Drives (SSDs). The promising features of emerging memory technologies such as low power consumption, increased performance, lower susceptibility to particle strikes, and higher bit density have prompted researchers to seek new organizations in the different memory-hierarchy levels, to propose new circuitry and algorithms to improve performance and reduce power consumption, and to develop new schemes to enhance system reliability. While performance and power are the major motivations to revisit memory organization in the cache hierarchy of modern processors, several contributing factors such as endurance, reliability, power, throughput, and cost are the major concerns in storage subsystems and SSDs. Design refinement techniques in both processors and storage systems often span different abstraction levels in computer systems, ranging from circuit design to micro-architectural techniques, from system architecture to operating systems. To foster the research momentum on emerging memory technologies in high-performance processors and mainstream and enterprise storage systems, IEEE Transactions on Computers has scheduled a special section on both systemand circuit-level aspects of emerging memory and storage technologies. For this special section, we have received 50 submissions from 17 countries, out of which 18 submissions have been selected in the first round of review process. Finally, after detailed review of the revised submissions, 11 papers have been accepted for publication in this section. More than 200 reviewers have helped us to make publishing decisions for this special section. The reviewers have been carefully selected among distinguished researchers from both industry (IBM, HP, Microsoft, EMC, NetApps, Intel, Data Storage Institute, and Fusion IO) and academia. Most of them have served as members of the organization or program committees of top conferences, including the IEEE/ACM International Symposium on Computer Architecture (ISCA), the IEEE/ACM International Symposium on Microarchitecture (MICRO), the USENIX Conference on File and Storage Technologies (FAST), the ACM/IEEE Design Automation Conference (DAC), the IEEE/ACM International Conference on Computer-Aided Design (ICCAD), the IEEE/ACM Design, Automation, and Test in Europe (DATE), the IEEE/ACM Asia and South Pacific Design Automation Conference (ASP-DAC), and the IEEE Non-Volatile Memory Technology Symposium (NVMTS).	algorithm;areal density (computer storage);asia and south pacific design automation conference;cpu cache;central processing unit;circuit design;computation;computer data storage;design automation and test in europe;dynamic random-access memory;electronic circuit;ieee transactions on computers;international conference on computer-aided design;international symposium on computer architecture;international symposium on microarchitecture;memory hierarchy;memory organisation;non-volatile memory;operating system;oracle fusion middleware;random access;refinement (computing);solid-state drive;static random-access memory;systems architecture;throughput;volatile memory	Hossein Asadi;Paolo Ienne;Hamid Sarbazi-Azad	2016	IEEE Trans. Computers	10.1109/TC.2016.2527138	uniform memory access;shared memory;interleaved memory;semiconductor memory;parallel computing;real-time computing;computer hardware;computer science;computer data storage;computer memory;memory management	EDA	12.652709168734003	59.90814946430542	115988
67b7582ce1813c06773a4745f4445e432525e6fa	multiple fault diagnosis using n-detection tests	automatic testing fault diagnosis;automatic testing;n detection test multiple fault diagnosis;fault detection;fault diagnosis circuit faults fault detection circuit testing electrical fault detection change detection algorithms bridge circuits manufacturing failure analysis sequential analysis;fault diagnosis	We study the relationship between multiple fault diagnosability and fault detection count. Instead of developing a complex diagnostic algorithm for multiple fault behavior, we change the test sets used in test and diagnosis. This allows us to apply a simple single-fault based diagnostic algorithm, and yet achieve very good diagnosability for the failure test cases caused by multiple faults. We have verified experimentally the effectiveness of n-detection tests for multiple-fault cases and explained the results in probabilistic terms.		Zhiyuan Wang;Malgorzata Marek-Sadowska;Kun-Han Tsai;Janusz Rajski	2003		10.1109/ICCD.2003.1240895	reliability engineering;electronic engineering;fault;real-time computing;fault coverage;fault indicator;computer science;stuck-at fault;automatic test pattern generation;fault detection and isolation	Robotics	22.47937501351416	51.23031597582514	116093
23fa92dc5140dfac88553011aaec9faddf4bd756	a multithreaded initial detailed routing algorithm considering global routing guides		Detailed routing is the most complicated and time-consuming stage in VLSI design and has become a critical process for advanced node enablement. To handle the high complexity of modern detailed routing, initial detailed routing is often employed to minimize design-rule violations to facilitate final detailed routing, even though it is still not violation-free after initial routing. This paper presents a novel initial detailed routing algorithm to consider industrial design-rule constraints and optimize the total wirelength and via count. Our algorithm consists of three major stages: (1) an effective pinaccess point generation method to identify valid points to model a complex pin shape, (2) a via-aware track assignment method to minimize the overlaps between assigned wire segments, and (3) a detailed routing algorithm with a novel negotiation-based rip-up and re-route scheme that enables multithreading and honors global routing information while minimizing designrule violations. Experimental results show that our router outperforms all the winning teams of the 2018 ACM ISPD Initial Detailed Routing Contest, where the top-3 routers result in 23%, 52%, and 1224% higher costs than ours.		Fan-Keng Sun;Hao Chen;Ching-Yu Chen;Chen-Hao Hsu;Yao-Wen Chang	2018	2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1145/3240765.3240777	computer science;very-large-scale integration;physical design;multithreading;algorithm;router	EDA	15.105224493369066	52.57653957033221	116204
001a65fc5ef928ab9eeac001d2fc381f3b4b91a7	a built-in self-repair design for rams with 2-d redundancy	random access memory;embedded memories built in redundancy analysis bira built in self repair bisr built in self test bist;static random access memory;memoria acceso directo;ram;circuit faults;semiconductor memory;built in self repair bisr;integrated circuit;semiconductor memories;reconfigurable architectures;autoprueba;built in self test bist;random access memory built in self repair design ram 2d redundancy semiconductor memories built in self test built in redundancy analysis embedded memories;redundancy analysis;circuito integrado;memoire acces direct statique;autoreparation;memoria semiconductor;built in redundancy analysis bira;autotest;memoire semiconducteur;algorithme;redundancy integrated circuit testing random access storage built in self test embedded systems;algorithm;embedded systems;2d redundancy;built in self test;redundancy;modelo 2 dimensiones;autoreparacion;memoire acces direct;modele 2 dimensions;integrated circuit testing;read write memory random access memory redundancy built in self test circuit faults algorithm design and analysis circuit testing hardware costs semiconductor memory;built in redundancy analysis;embedded memories;random access storage;normal modes;circuit testing;read write memory;semiconductor storage;built in self repair;architecture reconfigurable;algorithm design and analysis;built in self repair design;two dimensional model;circuit integre;hardware;algoritmo	This brief presents a built-in self-repair (BISR) scheme for semiconductor memories with two-dimensional (2-D) redundancy structures, i.e., spare rows and spare columns. The BISR design is composed of a built-in self-test module and a built-in redundancy analysis (BIRA) module. The BIRA module executes the proposed RA algorithm for RAM with a 2-D redundancy structure. The BIRA module also serves as the reconfiguration unit in the normal mode. Experimental results show that a high repair rate (i.e., the ratio of the number of repaired memories to the number of defective memories) is achieved with the BISR scheme. The BISR circuit has a low area overhead-about 4.6% for an 8 K /spl times/ 64 SRAM.	8k resolution;algorithm;built-in self-test;column (database);normal mode;overhead (computing);semiconductor memory;static random-access memory	Jin-Fu Li;Jen-Chieh Yeh;Rei-Fu Huang;Cheng-Wen Wu	2005	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2005.848824	embedded system;algorithm design;electronic engineering;semiconductor memory;parallel computing;static random-access memory;normal mode;computer science;engineering;integrated circuit;redundancy;radar-absorbent material;algorithm	EDA	19.041659058726538	52.34063746584334	116671
77b10f9e560f5e707f508e63d45bd6c9dac731f5	gigahertz fpga by sige bicmos technology for low power, high speed computing with 3-d memory	field programmable gate array;diseno circuito;integrated circuit;technologie bicmos;circuit design;bicmos technology;circuito integrado;red puerta programable;reseau porte programmable;multiplaje;multiplexing;tecnologia bicmos;multiplexage;low power;grande vitesse;puissance faible;conception circuit;gran velocidad;power consumption;consommation energie electrique;high speed;circuit integre;potencia debil	This paper presents an improved Xilinx XC6200 FPGA using IBM SiGe BiCMOS technology. The basic cell performance is greatly enhanced by eliminating redundant signal multiplexing procedures. The simulated combinational logic result has a 30% shorter gate delay than the previous design. By adjusting and properly shutting down the CML current, this design can be used in lower-power consumption circuits. The total saved power is 50% of the first SiGe FPGA developed in the same group. Lastly, the FPGA with a 3-D stacked memory concept is described to further reduce the influence of parasitics generated by the memory banks. The circuit area is also reduced to make dense integrated circuits possible.	bicmos;field-programmable gate array;silicon-germanium	Chao You;Jong-Ru Guo;Russell P. Kraft;Michael Chu;Robert W. Heikaus;Okan Erdogan;Peter F. Curran;Bryan S. Goda;Kuan Zhou;John F. McDonald	2003		10.1007/978-3-540-45234-8_2	embedded system;computer science;electrical engineering;integrated circuit;circuit design;multiplexing;field-programmable gate array	EDA	18.144315956055337	55.68094578019562	116772
e98998f976169bb01934c01e220cc3364b45d91f	improved ncv gate realization of arbitrary size toffoli gates	libraries;electronic mail;complexity theory;measurement;logic gates;optimization;quantum computing	The problem of synthesis and optimization of reversible and quantum circuits have drawn the attention of researchers in recent years. The typical design flow for such circuits first carries out the step of synthesis in terms of reversible gates, and then maps (decomposes) each reversible gate into equivalent set of quantum gates (e.g. from the NCV library). Since its initial proposal in realizing a Toffoli gate using quantum gates, several structural modifications have been proposed in the literature in order to reduce the cost of the generated netlist. The most recently introduced approach produces improved NCV cascade successively by partitioning the control lines of the given Toffoli gate in all possible ways, and replacing intermediate Toffoli gates with optimized equivalent NCV cascades form a catalog. In this approach the complexity of decomposing large Toffoli gates is high. In the present paper an efficient heuristic for partitioning the control lines of a given Toffoli gate is proposed. This heuristic is used for decomposition of the Toffoli gate without using any NCV catalog, after applying a template based optimization step. The cost of resultant circuit is similar to or sometimes better than the one reported by previous approaches.	computation;heuristic (computer science);map;mathematical optimization;netlist;quantum circuit;quantum gate;resultant;reversible computing;toffoli gate	Abhoy Kole;Kamalika Datta	2017	2017 30th International Conference on VLSI Design and 2017 16th International Conference on Embedded Systems (VLSID)	10.1109/VLSID.2017.11	electronic engineering;nor logic;toffoli gate;logic gate;three-input universal logic gate;theoretical computer science;quantum circuit;mathematics;quantum computer;algorithm;quantum mechanics;measurement;tc0;quantum gate	EDA	16.56129309748615	47.54375266296123	116853
333f28e5dc25cb33873fd660c12d3e1fa4388991	estimating the relative single stuck-at fault coverage of test sets for a combinational logic block from its functional description	combinational circuits logic testing high level synthesis;fault simulation;logic testing circuit faults circuit synthesis circuit testing delay cities and towns logic gates circuit simulation predictive models;high level synthesis;stuck at faults;logic testing;fault coverage;functional faults;primary inputs relative single stuck at fault coverage combinational logic block gate level faults fault coverage metric;combinational circuits	When the gate-level description of a logic block is unknown, it may become necessary to estimate the gate-level stuck-at fault coverage of a test set for the block by using a fault coverage metric that does not require simulation of gate-level faults. We propose such a metric based on stuck-at faults on primary inputs of the block We show that the proposed metric is accurate in predicting the relative gate-level stuck-at fault coverage of different test sets.	combinational logic;fault coverage;logic block;stuck-at fault	Irith Pomeranz;Sudhakar M. Reddy	2001		10.1109/HLDVT.2001.972804	logic optimization;fault coverage;fault indicator;computer science;stuck-at fault;automatic test pattern generation;sequential logic;combinational logic;high-level synthesis;register-transfer level;algorithm	EDA	21.407366550671966	50.75946962148102	116930
efeda7d632d470d2f58b840ac06f7370739f97db	soft error reduction through gate input dependent weighted sizing in combinational circuits	probability of failure soft error sizing technique combinational circuit reliability;reliability;integrated circuit;weighted area distribution algorithm soft error reduction gate input dependent weighted sizing combinational circuits soft error tolerant features logic circuits nanometer circuits soft error rate saturation consideration algorithm;logic circuits;gate input dependent weighted sizing;probability of failure;soft error rate saturation consideration algorithm;sizing technique;neutrons;error analysis;soft error rate;logic gates;optical fibers;soft error reduction;transistors;integrated circuit modeling;soft error tolerant features;optical fiber;combinational circuit;nanometer circuits;weighted area distribution algorithm;distributed algorithm;logic gate;soft error;logic gates transistors optical fibers neutrons error analysis combinational circuits integrated circuit modeling;combinational circuits	As technology nodes are gradually shrinking, adding soft error tolerant features to logic circuits is becoming a challenging task that requires careful consideration. Careless use of sizing technique may even worsen immunity to soft errors for circuits with very small nodes. This paper investigates limitations of conventional sizing methods and introduces new techniques for mitigating soft errors in nanometer circuits. Our techniques employ two algorithms. The first algorithm is called soft error rate saturation consideration algorithm. This algorithm prevents a gate from being oversized and thus, it limits the soft error rate of the circuit. The second algorithm, called weighted area distribution algorithm, can fairly distribute area overhead to the most sensitive gates. In order to assess our work, we compare the yields from different upsizing scenarios and the experimental results show that the sizing based approach that includes both proposed algorithms provides the largest soft error rate reduction.	algorithm;combinational logic;error-tolerant design;logic gate;overhead (computing);soft error;upsizing (database)	Warin Sootkaneung;Kewal K. Saluja	2011	2011 12th International Symposium on Quality Electronic Design	10.1109/ISQED.2011.5770790	distributed algorithm;electronic engineering;real-time computing;logic gate;computer science;engineering;electrical engineering	EDA	20.345523997220955	57.33565303740141	117016
7262e105c519e120be77399f5123e4a86d6e4d3b	logic-in-control-architecture-based reconfigurable vlsi using multiple-valued differential-pair circuits	sequential circuits;state transition diagram	A fine-grain bit-serial multiple-valued reconfigurable VLSI based on logic-in-control architecture is proposed for effective use of the hardware resources. In logic-in-control architecture, the control circuits can be merged with the arithmetic/logic circuits, where the control and arithmetic/logic circuits are constructed by using one or multiple logic blocks. To implement the control circuit, only one state in a state transition diagram is allocated to one logic block, which leads to reduction of the complexity of interconnections between logic blocks. The fine-grain logic block is implemented based on multiple-valued current-mode circuit technology. In the fine-grain logic block, an arbitrary 3-variable binary function can be programmed by using one multiplexer and two universal literal circuits. Three-variable binary functions are used to implement the control circuit. Moreover, the hardware resources can be utilized to construct a bit-serial adder, because full-adder sum and carry can be realized by programming in the universal literal circuit. Therefore, the logic block can be effectively reconfigured for arithmetic/logic and control circuits. It is made clear that the hardware complexity of the control circuit in the proposed reconfigurable VLSI can be reduced in comparison with that of the control circuit based on a typically sequential circuit in the conventional FPGA and the fine-grain field-programmable VLSI reported until now.	differential signaling;very-large-scale integration	Nobuaki Okada;Michitaka Kameyama	2010	IEICE Transactions		boolean circuit;computer architecture;logic synthesis;real-time computing;logic optimization;state diagram;diode–transistor logic;logic level;asynchronous circuit;logic gate;logic family;computer science;programmable logic device;pass transistor logic;mathematics;sequential logic;function block diagram;very-large-scale integration;integrated injection logic;circuit extraction;digital electronics;register-transfer level;resistor–transistor logic;emitter-coupled logic	EDA	13.204478360995315	47.02064136923335	117352
012150b83bebd650918ddb6945f83b0fd9b8aec9	low power, testable dual edge triggered flip-flops	clock gating;low power;propagation delay;power dissipation;power reduction;flip flop	Power dissipation is an important parameter in the design of VLSI circuits, and the clock network is responsible for a substantial part of it (upto 50%). Two main approaches have been suggested to reduce clock dissipation: clock gating and low power flip-flops. In this article we address the latter. We demonstrate that the usage of double edge triggered flip-flops results in a power reduction of 50% in the clock net, and in a reduction of upto 45% inside the flip-flops. Furthermore, we consider other flip-flop parameters, like setup and hold times, propagation delay and testability.	cpu power dissipation;clock gating;clock network;clock signal;clock skew;detection error tradeoff;flops;flip-flop (electronics);iddq testing;interrupt;propagation delay;software propagation;software testability;very-large-scale integration	Rafael Llopis;Manoj Sachdev	1996		10.1145/252493.252632	propagation delay;dissipation;clock gating	EDA	19.39296802248877	55.856456379429815	117507
19d2524feef121576a922456c92f86f86bf759ec	a state space decomposition algorithm for approximate fsm traversal	directed graphs;iterative refinement;state space methods;sequential circuits;connected graph;iterative refinement state space decomposition algorithm approximate fsm traversal state variable partition graph problem latch connection graph structural analysis seed generation clustering;finite state machines;decomposition algorithm;state space;state space methods finite state machines directed graphs sequential circuits logic cad vlsi circuit cad;state space methods latches partitioning algorithms counting circuits reachability analysis circuit testing performance analysis clustering algorithms very large scale integration circuit synthesis;vlsi;circuit cad;logic cad;structure analysis	Approximate FSM traversal is very useful in m a n y applications of interest, when the size of the problem to be solved i s too large t o be handled by exact methods. The qualzty of the approximation strongly depends o n how state variables are partitioned to decompose the state space, and exploiting circuit structure appears to be the mos t promising technzque to determine a good state variable partition. I n this paper we formulate the state space decomposition problem as a graph problem t o be solved o n the latch connection graph of the FSM under investigation. Structural analysis o n that graph is used t o determine a n initial part i t ion; breaking and aggregation, based o n seed generation, clustering, and iterative refinement of the current result, are then performed o n the initial solution. Approximate FSM traversal results obtained o n the largest IS( '.AS.X!) examples show the effectiveness of the proposed algorithm.	algorithm;approximation;cluster analysis;iterative method;iterative refinement;refinement (computing);state space;structural analysis;tree traversal	Hyunwoo Cho;Gary D. Hachtel;Enrico Macii;Massimo Poncino;Fabio Somenzi	1994		10.1109/EDTC.1994.326885	mathematical optimization;combinatorics;discrete mathematics;graph partition;mathematics	Robotics	18.430290576598615	47.59072051085149	117612
f7ac78e4475f20176e7cebb90818201c28e5aca3	a high performance, 10-volt integrated pin electronics driver	cmos integrated circuits;vlsi cmos integrated circuits driver circuits integrated circuit technology integrated circuit testing;driver circuits circuit testing cmos process silicon timing voltage cmos technology integrated circuit technology calibration production systems;integrated circuit technology;high voltage;integrated circuit testing;vlsi;driver circuits;high performance;si mixed technology devices testing integrated pin electronics driver module digital cmos analog output driver design calibration high voltage cmos driver ic vlsi test systems 10 v 1 5 micron 200 mbit s	A high voltage process module is added to a standard 1.5 micron digital CMOS process, allowing a 10-volt pin electronics driver to be integrated onto the same silicon with its timing and formamng circuitry. A single analog output driver circuit provides fast risetime, low distortion output waveforms for both narrow and wide voltage swings, eliminating the need for dual drivers or testheads when testing mixed technology devices or modules. Novel design and calibration techniques are used to overcome the limitiations of the high voltage CMOS process. An integrated pin electronics chip set has been designed to reduce the cost and increase the functionality of a VLSI test system [ll, and to address the needs of the CMOS ASIC test market in particular. However, an output driver with wider voltage swing capability is required to meet the needs of a more general purpose tester, and to test mixed technology devices and modules. Currently, many test systems offer separate testheads, pincards, or driver circuits to meet the needs of different integrated circuit technologies. Separate testheads for each circuit technology is not useful for testing mixed technology devices, and dedicating tester pins or pincards to high or low voltage drivers complicates the system software and device fixturing. Designing separate high and low voltage drivers per pin increases tester cost, reduces the tester VO path bandwidth, and also complicates the test development software. The primary goal of this project was to develop a single integrated driver circuit which is suitable for both high voltage and low voltage/fast risetime applications. It was also considered important to maintain the low cost and power consumption attained by the original 5.5 volt CMOS pin electronics driver, since any increase in either area would be multiplied by up to 512 pins. Driver Circuit Requirements The 5 most important requirements of the 10-volt test -2.5 to +7.5 volt range system driver circuit were: 50 ma static current capability (2.5 volt maximum swing into 50 ohm parallel termination). Fast driver rise/fall times: C M O S m : <= 2.0 ns (10% to 90%) ECL: <= l.Ons (20% to 80%)	application-specific integrated circuit;cmos;chipset;distortion;driver circuit;electronic circuit;emitter-coupled logic;requirement;rise time;very-large-scale integration	Christopher W. Branson	1989		10.1109/TEST.1989.82374	mixed-signal integrated circuit;embedded system;electronic engineering;computer science;engineering;high voltage;electrical engineering;integrated circuit;diode-or circuit;very-large-scale integration;integrated injection logic;cmos;pin compatibility;driver circuit	EDA	11.89572826442688	55.23832786449943	117660
40c92f8aed323daea051f2f6c4efa73015d2c032	a new global routing algorithm independent of net ordering	steiner trees global routing algorithm net ordering random optimization methods congested areas vlsi layout ic layout;integrated circuit layout;optimal method;physical design;trees mathematics;satisfiability;network routing;chip;circuit layout cad network routing circuit optimisation vlsi integrated circuit layout trees mathematics;global routing;vlsi;circuit layout cad;circuit optimisation;routing simulated annealing wiring linear programming computer science optimization methods very large scale integration algorithm design and analysis tiles;steiner tree	1 Supported by Chinese National Science Foundation and Chinese National Key Project funds: 69776027 and 96-738-01-08. Abstract: We proposed a new Global Routing algorithm solving the net ordering problem. The algorithm uses random optimization methods to keep the equality of earlier routed nets and later routed one in passing congested areas. It can find solution independent of net ordering in short time. A global router is implemented in this method. Experiments show that the router performs much faster than Matula_Router while gets solutions with approximate quality.	approximation algorithm;mathematical optimization;random optimization;router (computing);routing	Haiyun Bao;Xianlong Hong;Yici Cai	1999		10.1109/ASPDAC.1999.760006	chip;physical design;routing table;embedded system;mathematical optimization;routing;static routing;telecommunications;steiner tree problem;computer science;electrical engineering;theoretical computer science;destination-sequenced distance vector routing;distributed computing;integrated circuit layout;very-large-scale integration;link-state routing protocol;routing;satisfiability	EDA	15.420511067351438	51.17353253223632	117695
811ffd6e25bb87d182674fb1cca7f2870d095e8a	statistical framework for technology-model-product co-design and convergence	rf oscillation frequency;verification;production performance;microprocessors;bench rf measurements;oscillations;process variation;isolation technology;die to die levels;measurement;microprocessor product current controlled oscillators;soi technology generations;oscillators;performance;silicon on insulator;collaboration;statistical framework;statistical method;phase lock loop;wafer to wafer levels;yield estimation;wafer level packaging;yield;soi technology generations statistical framework technology model product co design statistical data driven approach statistical method systematic process variations die to die levels wafer to wafer levels development generations microprocessor product current controlled oscillators phase locked loops automated manufacturing floor bench rf measurements rf oscillation frequency;phase locked loops;isolation technology semiconductor device modeling radio frequency circuits yield estimation statistical analysis collaboration microprocessors oscillators phase locked loops;radio frequency;statistical analysis;semiconductor device modeling;design for yield dfy;technology model product co design;development generations;design;statistical data driven approach;circuits;radiofrequency oscillators;design verification;statistical;economics;wafer level packaging microprocessor chips radiofrequency oscillators silicon on insulator statistical analysis;design for yield dfy measurement performance design economics verification technology model product co design statistical yield process variation;systematic process variations;automated manufacturing floor;microprocessor chips;cooperative design	This paper presents a statistical framework to cooperatively design and develop technology, product circuit, benchmarking and model early in the development stage. The statistical data-driven approach identifies device characteristics that are most correlated with a product performance, and estimates performance yield. A statistical method that isolates systematic process variations on die-to-die and wafer-to-wafer levels is also presented. The proposed framework enables translations of interactions among technology, product, and model, and facilitates collaborative efforts accordingly.  The proposed methodology has been applied to first three development generations of 65nm technology node and microprocessor product current-controlled oscillators (ICOs) for phase-locked loops (PLLs) that were migrated from 90nm. Automated manufacturing floor in-line characterization and bench RF measurements are used for the methodology. The ICO exhibits yield improvement of RF oscillation frequency from 47% to 99% across three different 65nm SOI technology generations.	arnold tongue;convergence;interaction;microprocessor;phase-locked loop;radio frequency;semiconductor device fabrication;silicon on insulator;software release life cycle;wafer (electronics)	Choongyeun Cho;Daeik D. Kim;Jonghae Kim;Jean-Olivier Plouchart;Robert Trzcinski	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278610	embedded system;electronic engineering;phase-locked loop;engineering;electrical engineering;oscillation	EDA	24.19316914897497	55.23904101491132	117707
78b77e522276307c428361713b728679566159f7	a 0.2 v-1.8 v 8t sram with bit-interleaving capability	bit interleaving;subthreshold sram;8t cell;ultra dynamic voltage scaling u dvs	An 8T SRAM with bit-interleaving capability is designed for ultra-dynamic voltage scaling applications. An adaptive body-biasing scheme is designed to improve the stability of 8T cell, which achieves 1.5 times higher noise margin compared to the non-bodybiased 8T cell. Also, a write driver is presented to enable the bitinterleaving structure, thus achieving high soft-error tolerance. A prototype 1-kb SRAM is fabricated in a standard 0.18 μm CMOS process. The measurement results show that the proposed design fulfils the functionality under supply voltage from 1.8V to 0.3V (0.2V when the write wordline is boosted to 0.36V) and the total power is reduced by four times of magnitude.		Hui Zhao;Shiquan Fan;Leicheng Chen;Yan Song;Liuming Zhao	2014	IEICE Electronic Express	10.1587/elex.11.20140229	electronic engineering;parallel computing;real-time computing	Mobile	18.11928161899585	59.172426046686255	117810
c4af4fcce209050e44afabba18d5d428e37011aa	post-route alleviation of dense meander segments in high-performance printed circuit boards	crosstalk;wires routing delays crosstalk silicon nickel mathematical model;wires electric;printed circuit design;network routing;biochip;wires electric crosstalk integer programming linear programming network routing printed circuit design;dilution;digital microfluidic biochip dmfb;integer programming;linear programming;post route alleviation integer linear programming ilp problem relaxed dense meander segment generation crosstalk post processing method physical wire length signal propagation pcb bus signal delay length matching high performance printed circuit board routing design;sample preparation;reactant minimization	Length-matching is an important technique to balance delays of bus signals in high-performance PCB routing. Existing routers, however, may generate dense meander segments with small distance. Signals propagating across these meander segments exhibit a speedup effect due to crosstalks between the segments of the same wire, thus leading to mismatch of arrival times even with the same physical wire length. In this paper, we propose a post-processing method to enlarge the width and the distance of meander segments and distribute them more evenly on the board so that the crosstalks can be reduced. In the proposed framework, we model the sharing combinations of available routing areas after removing dense meander segments from the initial routing, as well as the generation of relaxed meander segments and their groups in subareas. Thereafter, this model is transformed into an ILP problem and solved efficiently. Experimental results show that the proposed method can extend the width and the distance of meander segments about two times even under very tight area constraints, so that the crosstalks and thus the speedup effect can be alleviated effectively in high-performance PCB designs.	printed circuit board;printing;router (computing);routing;solver;speedup;video post-processing	Tsun-Ming Tseng;Bing Li;Tsung-Yi Ho;Ulf Schlichtmann	2013	2013 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1109/ICCAD.2013.6691193	embedded system;mathematical optimization;routing;electronic engineering;crosstalk;integer programming;biochip;computer science;engineering;linear programming;dilution;engineering drawing;routing	EDA	15.356150074513584	52.86203720791194	117820
3ecb58270deb3d1f494106f4d7f60741f2fee535	nbti-aware design of integrated circuits: a hardware-based approach for increasing circuits' life time	process variation;nbti;on chip sensor	Advances in CMOS technology have made possible the increase of integrated circuit’s density, which impacts directly on the circuit’s performance. However, technology scaling poses some reliability concerns that directly affect the circuit’s lifetime. One of the most important issues in nanoscale circuits is related to the time-dependent variation caused by Negative Bias Temperature Instability (NBTI). This phenomenon increases the threshold voltage of pMOS transistors, which introduces delay along the integrated circuits’ paths, eventually causing functional failures. In this paper, a hardware-based technique able to increase the lifetime of Integrated Circuits (ICs) is proposed. In more detail, the technique is based on an on-chip sensor able to monitor IC’s aging and to adjust its power supply voltage in order to minimize NBTI effects and increase the circuit’s lifetime. Experimental results obtained throughout simulations demonstrate the technique’s efficiency, since the circuit’s lifetime has been increased by 150 %. Finally, the analysis of the main overheads introduced as well as the impact related to process variation renders the evaluation of the proposed approach possible.	cmos;image scaling;integrated circuit;negative-bias temperature instability;power supply;rendering (computer graphics);simulation;transistor	Thiago Copetti;Guilherme Cardoso Medeiros;Leticia Bolzani Poehls;Fabian Vargas	2016	J. Electronic Testing	10.1007/s10836-016-5592-2	negative-bias temperature instability;electronic engineering;real-time computing;engineering;electrical engineering;process variation	EDA	19.918070184990146	59.358593242911454	117840
53863ebc7948d5db087ce1a6e863368ad4b7037e	the effects of energy management on reliability in real-time embedded systems	embedded systems;fault simulation;power control;reliability;system recovery;transients;energy consumption;energy management;fault rate models;frequency and voltage scaling;operating frequency;real-time embedded systems;recovery schemes;slack time;supply voltage;system reliability;transient faults	The slack time in real-time systems can be used by recovery schemes to increase system reliability as well as by frequency and voltage scaling techniques to save energy. Moreover, the rate of transient faults (i.e., soft errors caused, for example, by cosmic ray radiations) also depends on system operating frequency and supply voltage. Thus, there is an interesting trade-off between system reliability and energy consumption. This work first investigates the effects of frequency and voltage scaling on the fault rate and proposes two fault rate models based on previously published data. Then, the effects of energy management on reliability are studied. Our analysis results show that, energy management through frequency and voltage scaling could dramatically reduce system reliability, and ignoring the effects of energy management on the fault rate is too optimistic and may lead to unsatisfied system reliability.	cosmic;clock rate;dynamic voltage scaling;embedded system;image scaling;real-time clock;real-time computing;slack variable	Dakai Zhu;Rami G. Melhem;Daniel Mossé	2004	IEEE/ACM International Conference on Computer Aided Design, 2004. ICCAD-2004.	10.1145/1112239.1112252	embedded system;electronic engineering;real-time computing;soft error;cosmic ray;telecommunications;power control;computer science;engineering;reliability;statistics;energy management	EDA	20.04666666128038	58.211036077802916	117981
95e3b146bb67d3b809d9591291f59cb2875c1791	an experimental mos fault simulation program csasim	program csasim;experimental mos fault simulation;simulation program;digital mos ic;new switch-level fault simulator;circuit model;delay fault;different fault type;dynamic signal;analyzes csa;fault-simulation mechanism;efficient simulation;national electric code;resistors;computational modeling;attenuators;voltage	A prototype version of a new switch-level fault simulator for digital MOS IC's is described. The simulation program, which is called CSASIM, analyzes CSA (connector-switch-attenuator) circuit models using multiple logic values. A novel method of signal evaluation is employed, based on the super-position of bidirectional static and dynamic signals. CSASIM also allows efficient simulation of many different fault types, including stuck-at-constant, open-circuit, short-circuit, and delay faults. The internal structure and fault-simulation mechanisms of the simulator are discussed in this paper.	fault simulator;optical attenuator;prototype;simulation	Masato Kawai;John P. Hayes	1984	21st Design Automation Conference Proceedings		resistor;embedded system;national electrical code;electronic engineering;voltage;engineering;electrical engineering;stuck-at fault;attenuator;circuit extraction;computational model;computer engineering	EDA	23.875537346673067	52.64151252402783	118053
e999b65d8afe8be1fc6e6cf994926a1ea107b9e8	realistic fault analysis of cmos analog building blocks	cmos analog building blocks;realistic fault analysis;functional test;functional testing;circuit analysis;integrated circuit;quality improvement;design for testability;cmos integrated circuits	High quality analog and mixed signal integrated circuits (ICs) require high quality testing. It is shown that test preparation, and test quality improvement of analog building blocks must be layout driven. For this, an IC defects-based analysis is used to study the impact of catastrophic faults on basic CMOS analog blocks. The impact on circuit behavior is analyzed for functional test and for i/sub DD/ power supply fault signatures. It is also demonstrated that a significant part of catastrophic faults cause out of specs performance, and may thus decrease the yield of the product, by an apparent parametric yield degradation. Finally, it is shown that layout level DFT (design for testability) can be rewardingly used to increase test confidence and product quality.	cmos	P. Nicolau;J. Barbosa;M. Saraiva;Marcelino B. Santos;Isabel C. Teixeira;João Paulo Teixeira	1993			reliability engineering;embedded system;quality management;electronic engineering;computer science;engineering;automatic test pattern generation;functional testing	EDA	22.56577489906721	55.16202604426351	118139
1f5d21c356beb3219d4e188f45fe479ae196c8f1	ff-bond: multi-bit flip-flop bonding at placement	placement;clock power;multi bit flip flops;timing	Clock power contributes a significant portion of chip power in modern IC design. Applying multi-bit flip-flops can effectively reduce clock power. State-of-the-art work performs multi-bit flip-flop clustering at the post-placement stage. However, the solution quality may be limited because the combinational gates are immovable during the clustering process. To overcome the deficiency, in this paper, we propose multi-bit flip-flop bonding at placement. Inspired by ionic bonding in Chemistry, we direct flip-flops to merging friendly locations thus facilitating flip-flop merging. Experimental results show that our algorithm, called FF-Bond, can save 27% clock power on average. Compared with state-of-the-art post-placement multi-bit flip-flop clustering, FF-Bond can further reduce 14% clock power.	algorithm;angular defect;application-specific integrated circuit;cluster analysis;combinational logic;flops;flip-flop (electronics);ionic	Chang-Cheng Tsai;Yiyu Shi;Guojie Luo;Iris Hui-Ru Jiang	2013		10.1145/2451916.2451955	embedded system;real-time computing;clock skew;computer science;timing failure;clock gating;digital clock manager;placement;cpu multiplier	EDA	16.4841907701696	57.781943100192734	118201
5f2d498de9cb3ae1d9bc66bffc45e4208d9dc265	performance of cmos current mode full adders	cmos integrated circuits;cmos technology adders detectors current mode circuits power dissipation bicmos integrated circuits power supplies voltage arithmetic mirrors;emitter coupled logic;current mode;1 2 micron cmos current mode full adders performance multivalued current mode 1 bit adders electrical parameters standard 1 2 spl mu m cmos technology cmos technologies 1 bit;emitter coupled logic cmos integrated circuits adders;adders	We present the performance of three different multi valued current mode 1-bit adders. These circuits have been simulated with the electrical parameters of a standard 1.2 μm CMOS technology. The performance of a binary voltage mode 1-bit adder is also presented. The binary version uses twice more transistors comparing with multi valued ones, but it is two or three times faster. Multi valued versions are more complicated to design and optimize. These results confirm the chip density advantage of multi valued circuits and the speed advantage of binary versions when using CMOS technologies.	1-bit architecture;adder (electronics);cmos;transistor	Keivan Navi;A. Kazeminejad;Daniel Etiemble	1994		10.1109/ISMVL.1994.302223	electronic engineering;real-time computing;computer science;engineering;electrical engineering;integrated injection logic;cmos;adder;emitter-coupled logic	EDA	16.86021907577957	57.3455911372953	118281
dd784b862f895aa292362cc31a2acf61dca099be	design of a cell in embryonic systems with improved efficiency and fault-tolerance	resource utilization;embryonics;difference operator;fault tolerant;two level self repair;embryonic systems;error correction mechanism;cellular arrays;error correction;fault detection;hamming code;functional unit;fault tolerance of configuration memory;extended hamming code	This paper presents a new design of cells to construct embryonic arrays, the function unit of which can act in three different operating modes. Compared with cells based on LUT with four inputs and one output, the new architecture displays improved flexibility and resource utilization ratios. Configuration memory employed by embryonics can implement 1-bit error correcting and 2-bit error checking by using extended hamming code. The two-level fault-tolerance is achieved in the embryonic array by the error correcting mechanism of memory at celllevel and column-elimination mechanism at array-level which is triggered by cell-level fault detection. The implementation and simulation of a 4bit adder subtracter circuit is presented as a practical example to show the effectiveness of embryonic arrays in terms of functionality and twolevel fault-tolerance.	1-bit architecture;4-bit;adder (electronics);cell (microprocessor);color depth;digital electronics;fault detection and isolation;fault tolerance;general protection fault;hamming code;sensor;simulation	Yuan Zhang;Youren Wang;Shanshan Yang;Min Xie	2007		10.1007/978-3-540-74626-3_13	fault tolerance;in situ resource utilization;electronic engineering;real-time computing;constant-weight code;error detection and correction;computer science;theoretical computer science;hamming code;fault detection and isolation;statistics	EDA	12.670804009066444	47.98041418447673	118350
34aa224979245c6fce58823e621fc5f3e0ed069e	a robust mixed-size legalization and detailed placement algorithm	design automation;hardware software codesign;ic design;intellectual property;routing;xdp;placement;placement algorithm;longest path;physical design;macros;law;chip;mpl6;integrated circuit design;legal factors;macro legalization;integrated circuit interconnections;xdp robust mixed size legalization placement algorithm rtl to gdsii synthesis ic design intellectual property linear programming macro legalization mpl6 ibm mswpins sliding window based cell swapping;linear programming;linear program;robust mixed size legalization;ibm mswpins;robustness;macros hardware software codesign industrial property integrated circuit design linear programming;optimization;industrial property;scalability;computer science;robustness law legal factors linear programming routing scalability design automation computer science circuit synthesis integrated circuit interconnections;rtl to gdsii synthesis;placement optimization physical design;circuit synthesis;sliding window;sliding window based cell swapping	Placement is one of the most important steps in the RTL-to-GDSII synthesis process as it directly defines the interconnects. The rapid increase in IC design complexity and the widespread use of intellectual-property blocks have made the so-called mixed-size placement a very important topic in recent years. The contributions of this paper include the following: 1) It proposes a flexible and robust mixed-size legalization scheme. Two constraint graphs are constructed from the global placement. Adjustments are iteratively applied to the constraint graphs until the longest paths on both graphs fall within the chip dimension. The macro coordinates are then computed by solving a linear programming (LP) formulation. The LP formulation has also been extended to handle macro spreading for routing density control. Experimental results show that our scheme can effectively legalize macros for all the global placements generated by mPL6 [1] on IBM-MSwPins. Experimental results also show that LP-based macro assignment can significantly reduce the amount of perturbation introduced during legalization compared to a greedy alternative. 2) Starting from the legalization scheme, it further proposes a three-step mixed-size detailed placement algorithm, XDP. An enhanced greedy method is used to remove the overlap between standard cells while preserving the legality of macros. Sliding-window-based cell swapping is applied in the end to further reduce the wirelength. Experiments show that, when compared with Floorist [2] with similar legalization capability, using the global placements generated by mPL6 [3], XDP is seven times faster with 6% shorter wirelength. Experiments also show that, when applied to the set of global placement results generated by APlace 2.0 [4], XDP can produce comparable wirelength to the native detailed placement of APlace 2.0 and 2% shorter wirelength compared with that with Fengshui 5.0 [5]. When applied to the set of global placements generated by mPL6, XDP is the only detailed placement that successfully produces legal placements for all 18 examples, whereas APlace and Fengshui failed for 3 and 16 of them, respectively. Furthermore, when legal placements can be compared, the wirelength produced by XDP is shorter by 8% on average compared with that with APlace. For scalability, XDP is ten times faster than APlace when applied to circuits with more than two million movable objects with comparable wirelength.	approximation algorithm;cell (microprocessor);electrical connection;experiment;greedy algorithm;integrated circuit design;linear programming;longest path problem;network congestion;paging;routing;scalability;standard cell;whole earth 'lectronic link;xml data package	Jason Cong;Min Xie	2008	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2008.925792	embedded system;mathematical optimization;electronic engineering;parallel computing;real-time computing;computer science;linear programming;electrical engineering;operating system;algorithm;integrated circuit design	EDA	15.372625877629302	52.86051428211578	118431
5109b1534d052efbfb6a3ba700be1f55c8d6c261	modifying test vectors for reducing power dissipation in cmos circuits	logic simulation;circuit faults;fault simulation;sequential circuits;test vector;sequential analysis;signal transition gate;circuit simulation;cmos circuit;cmos logic circuits;power dissipation;cmos sequential circuit;fault detection;circuit testing power dissipation circuit faults capacitance fault detection sequential analysis circuit simulation benchmark testing logic testing electrical fault detection;logic testing;fault simulation cmos logic circuits sequential circuits logic testing integrated circuit testing logic simulation;integrated circuit testing;test generation;fault simulation test vector power dissipation cmos sequential circuit signal transition gate fault coverage logic simulation;fault coverage;circuit testing;capacitance;benchmark testing;electrical fault detection	This paper presents a method to modify test vectors for reducing power dissipation in CMOS sequential circuits. Test vectors are modified by inverting values of primary inputs one by one. With respect to the reduction of power dissipation, we check if the average number of signal transition gates is decreased and if the maximum number of signal transition gates is not increased. Original fault coverage is guaranteed by logic simulation and fault simulation. The effectiveness of the proposed method is shown by experimental results for ISCAS’89 benchmark circuits.	benchmark (computing);cmos;cpu power dissipation;fault coverage;logic simulation;signal transition;test vector	Yoshinobu Higami;Shin-ya Kobayashi;Yuzo Takamatsu	2002		10.1109/DELTA.2002.994665	benchmark;electronic engineering;real-time computing;fault coverage;computer science;engineering;electrical engineering;dissipation;sequential analysis;logic simulation;sequential logic;capacitance;test vector;fault detection and isolation;statistics	EDA	20.980602542103245	51.88121725142989	118437
f9cede76a173bc44433e46036d741622f6239633	ir-drop management cad techniques in fpgas for power grid reliability	design automation;voltage distribution;cost function;routing;cad;standard deviation;wires;power grid reliability;technology management;design technique;integrated circuit interconnections;solid modeling;voltage;low power electronics;power grid;energy management field programmable gate arrays power grids voltage design automation routing tiles wires technology management circuits;circuits;tiles;ir drop management cad techniques;power grids;voltage distribution ir drop management cad techniques power grid reliability field programmable gate arrays;field programmable gate arrays;integrated circuit reliability;low power electronics cad field programmable gate arrays integrated circuit interconnections integrated circuit reliability logic cad;logic cad;energy management;timing	The design of power grid network is critical in scaled technologies for reliable operation of a circuit. This paper presents novel CAD techniques for mitigating IR-drops in FPGAs. Placement and routing techniques are developed in the paper for improving the voltage profile of the power grid network. The proposed techniques not only improve the minimum voltage at any node in the FPGA power grid, but also reduces the variance of the supply voltage distribution across all the nodes in the power grid. An improvement of up to 7% in the minimum Vdd and up to 66% reduction in standard deviation of Vdd is obtained from the design technique proposed in this paper.	benchmark (computing);computer-aided design;field-programmable gate array;grid network;place and route;routing;value-driven design	Akhilesh Kumar;Mohab Anis	2009	2009 10th International Symposium on Quality Electronic Design	10.1109/ISQED.2009.4810386	embedded system;electronic circuit;routing;electronic engineering;voltage;electronic design automation;computer science;engineering;electrical engineering;technology management;cad;solid modeling;standard deviation;field-programmable gate array;low-power electronics;energy management	EDA	20.372632063129952	56.86149398071555	118451
cf8326fb2a9117bc3eb62eacfb0ed360fbf4f4c9	a novel reseeding technique for accumulator-based test pattern generation	system performance;critical path;on the fly;fault coverage;test pattern generator	In this paper we present a novel reseeding technique for accumulator-based Test Pattern Generation suitable for circuits with hard-to-detect faults. Storing the seeds is not necessary since the seeds are generated on-the-fly by inverting the logic value of some of the bits of the accumulator's register. The proposed technique achieves complete fault coverage with shorter test sequences and requires less hardware for its implementation than the corresponding already-known techniques. Furthermore, our technique does not affect the system performance since the logic required for its implementation is not inserted in the critical path.	accumulator (computing);critical path method;fault coverage;test card	Xrysovalantis Kavousianos;Dimitris Bakalis;Dimitris Nikolos	2001		10.1145/368122.368145	embedded system;electronic engineering;real-time computing;fault coverage;computer science;engineering;critical path method;computer performance	EDA	20.42163581655194	51.20642270650949	118652
3ba5e57f52a06fb28610d2892456030ba8176c4d	challenges in physical chip design	circuit cad;integrated circuit design;technological forecasting;wire planning;chip design;design flow;floorplan design;homogeneous processors;multilayer designs;reuse of specification software	Chip industry obeys a number of laws, various kinds of laws. Mathematical laws if accurate models can be formulated, physical laws, especially solid state physics, obtained by observation and induction, chemical laws pertinent for the manufacturing processes, economical and judicial laws that concern such industries. The most famous and most cited law of chip industry is the one that Gordon Moore formulated in 1964 after observing trends in the then very young field of integration of electronic circuits. Mathematically formulated, Moore’s law reads as follows:	electronic circuit;mathematical induction;moore's law;relevance;solid-state drive	Ralph H. J. M. Otten;Paul Stravers	2000			chip;embedded system;mathematical optimization;technology forecasting;electronic engineering;telecommunications;inductance;computer science;engineering;electrical engineering;operating system;very-large-scale integration;engineering drawing;algorithm;statistics;integrated circuit design	EDA	12.16491827061214	56.94336508490424	118672
4d2870d2cdb8deb439d486ca2bf65f77ee660ac2	a low cost method for testing offset and gain error for adc bist	linearity;performance test method adc bist low cost method offset testing gain error systems on chip soc mixed signal block analog signal block built in self test production testing;built in self test equations mathematical model estimation error accuracy linearity;accuracy;built in self test;analogue digital conversion;mathematical model;circuit testing;estimation error;circuit testing analogue digital conversion built in self test	As the Systems-on-Chips (SoCs) complexity increases, test cost contributes more in the total cost. Especially, test of deeply embedded analog and mixed signal blocks are the most costly test. Built-In Self-Test (BIST) is considered as a low cost substitution of traditional production test. This paper presents a low cost method for testing ADC's offset and gain error. This is a complement of previous published linearity and spectral performance test methods. The simulation results show the method has good accuracy.	built-in self-test;embedded system;mixed-signal integrated circuit;simulation;system on a chip	Jingbo Duan;Degang Chen;Randall L. Geiger	2012	2012 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2012.6271677	embedded system;electronic engineering;real-time computing;computer science;test compression;mathematical model;mathematics;accuracy and precision;linearity;statistics	EDA	24.09000976698797	54.30879511658331	118815
ed95e1b3bb16cb5e170fcab4dbac62552140130e	simulation and experimental evaluation of a soft error tolerant layout for sram 6t bitcell in 65nm technology	layout;6t bitcell;sram;soft error	In this paper, a new layout for SRAM 6T bitcell is presented. The new layout is a simple modification over the traditional 6T layout, but it has demonstrated better soft error tolerance over the traditional layout in radiation experiments. The area of the new layout is 31 % larger than the traditional layout. In TCAD simulation, it demonstrates over 2× smaller error cross section than the traditional layout. In alpha particle and proton experiments, its soft error rate can be reduced up to 73 % compared to the traditional layout.	simulation;soft error;static random-access memory	Lixiang Li;Yuanqing Li;Haibin Wang;Rui Liu;Qiong Wu;Michael Newton;Yuan Ma;Li Chen	2015	J. Electronic Testing	10.1007/s10836-015-5549-x	layout;electronic engineering;parallel computing;static random-access memory;soft error;computer science;engineering;engineering drawing	EDA	18.324686959749176	60.3646930969503	118844
a9e1c6301fee46d93dc510f233936c88ea43c1d5	state set management for sat-based unbounded model checking	zero suppressed binary decision diagram unbounded model checking boolean satisfiability clause conversion technique state set;electronic engineering computing boolean algebra binary decision diagrams logic testing integrated circuit testing formal verification;boolean algebra;boolean satisfiability;formal verification;binary decision diagrams;model checking;logic testing;integrated circuit testing;electronic engineering computing;data structures boolean functions state space methods circuits hardware scalability robustness explosions computer bugs;sat solver;binary decision diagram	In recent years, Boolean satisfiability (SAT) has been shown to hold potential for unbounded model checking (UMC). The success of SAT-based UMC largely relies on (i) the SAT solver efficiency, (it) solution cube enlargement, and (Hi) state-set management. In this paper, we propose a simple, yet efficient, clause conversion technique to account for the state set obtained by SAT-based UMC. Our state set is stored in a zero-suppressed binary decision diagram (ZBDD), and the shared structures in the ZBDD are exploited to aggressively avoid repeated manipulation of common subsets in the state-set. The resulting number of clauses, generated for the state set, now depends on the number of nodes in the ZBDD, rather than the number of solutions found. We integrated the proposed techniques in an unbounded model checking framework that uses a pure SAT solver. The experimental results show that we can attain orders of magnitude improvement in both performance and capacity as compared to the existing techniques.	binary decision diagram;boolean satisfiability problem;influence diagram;iteration;model checking;olap cube;solver;zero-suppressed decision diagram	Kameshwar Chandrasekar;Michael S. Hsiao	2005	2005 International Conference on Computer Design	10.1109/ICCD.2005.99	boolean algebra;boolean circuit;and-inverter graph;#sat;computer science;theoretical computer science;boolean satisfiability problem;algorithm	EDA	18.8666718625228	47.97934877716191	118970
bc5bde6d7009dba499c45a0c236f7f2230a57905	logics circuit diagnosis by using neural networks	neural nets;diagnostic engine logic circuit diagnosis neural networks combinatorial logic circuits equivalent neural network circuit fault free sample circuit random patterns fault prone test circuit;equivalent circuits combinational circuits logic testing neural nets;equivalent circuits;logic testing;logic circuits neural networks circuit faults circuit testing fault diagnosis engines dictionaries logic testing fault tolerance application software;neural network;combinational circuits	This paper presents a new method of logic diagnosis for combinatorial logic circuits. First, for each type of circuit gates, an equivalent neural network gate is constructed. Then, by replacing circuit gate elements with corresponding neural network gates, an equivalent neural network circuit is constructed to the fault-free sample circuit. The testing procedure is to feed random patterns to both the neural network circuit and the faultprone test circuit at the same time, and comparing, analyzing the both outputs, the former circuit generates diagnostic data for the test circuit. Thus, the neural network circuit behaves like a diagnostic engine, and needs basically no preparation of special test patterns mr fault dictionary before diagnosing.	artificial neural network;combinational logic;dictionary;logic gate;test card	Hisayuki Tatsumi;Yasuyuki Murai;Shinji Tokumasu	2001		10.1109/ISMVL.2001.924594	equivalent circuit;boolean circuit;circuit minimization for boolean functions;electronic engineering;logic optimization;asynchronous circuit;logic gate;logic family;computer science;automatic test pattern generation;machine learning;pass transistor logic;sequential logic;combinational logic;circuit extraction;digital electronics;register-transfer level;discrete circuit;artificial neural network;algorithm;resistor–transistor logic	EDA	22.038563189484144	49.828334708720696	119009
5eeea5cbc6ce6a82fdd952bb9461e4787fa82374	power-aware clock tree planning	switching activity;cost function;integrated circuit;power efficiency;physical design;clock gating;physical design and optimization;low power;operating system;power dissipation;tree structure;digital design;source code;low power design;power consumption;clock tree synthesis and routing;clock distribution network;industrial design	Modern processors and SoCs require the adoption of power-oriented design styles, due to the implications that power consumption may have on reliability, cost and manufacturability of integrated circuits featuring nanometric technologies. And the power problem is further exacerbated by the increasing demand of devices for mobile, battery-operated systems, for which reduced power dissipation is mandatory. A large fraction of the power consumed by a synchronous circuit is due to the clock distribution network. This is for two reasons: First, the clock nets are long and heavily loaded. Second, they are subject to a high switching activity.The problem of automatically synthesizing a power efficient clock tree has been addressed recently in a few research contributions. In this paper, we introduce a methodology in which low-power clock trees are obtained through aggressive exploitation of the clock-gating technology. Distinguishing features of the methodology are: (i) The capability of calculating powerful clock-gating conditions that go beyond the simple topological search of the RTL source code. (ii) The capability of determining the clock tree logical structure starting from an RTL description. (iii) The capability of including in the cost function that drives the generation of the clock tree structure both functional (i.e., clock activation conditions) and physical (i.e., floorplanning) information. (iv) The capability of generating a clock tree structure that can be synthesized and routed using standard, commercially-available back-end tools.We illustrate the methodology for power-aware RTL clock tree planning, we provide details on the fundamental algorithms that support it and information on how such a methodology can be integrated into an industrial design flow. The results achieved on several benchmarks, as well as on a real design case demonstrate the feasibility and the potential of the proposed approach.	algorithm;benchmark (computing);central processing unit;clock gating;clock rate;clock signal;design for manufacturability;floorplan (microelectronics);integrated circuit;loss function;low-power broadcasting;register-transfer level;routing;synchronous circuit;tree structure	Monica Donno;Enrico Macii;Luca Mazzoni	2004		10.1145/981066.981097	clock synchronization;physical design;embedded system;real-time computing;industrial design;electrical efficiency;asynchronous circuit;clock skew;computer science;dissipation;integrated circuit;tree structure;synchronous circuit;clock gating;digital clock manager;cpu multiplier;source code	EDA	15.239938720496825	54.58454573693574	119029
844cced965516b5e264263e9367e5a08d59013cd	designing single-cycle long links in hierarchical nocs	nocs;network on chip;in chip interconnect;wire sizing;repeaters;hierarchical nocs	Hierarchical topologies are frequently proposed for large Networks-on-Chip (NoCs). Hierarchical architectures utilize, at the upper levels, long links of the order of the die size. RC delays of long links might reach dozens of clock cycles in advanced technology nodes, if delay reduction techniques (e.g. wire sizing and repeater insertion) are not applied. Some proposals assume that long links can be adjusted to satisfy timing requirements, but lack a deep evaluation of the tradeoffs and costs. Other proposals assume that long links must be pipelined, but do not provide a comprehensive justification. In this paper we evaluate the efficiency and the system costs of wire sizing and repeater insertion as methods to reduce link delays in hierarchical NoCs. We present a unified interconnect cost function that accounts for power and wiring overheads of these methods. Then, we quantify the costs of modifying long links in typical hierarchical NoCs for different target clock frequencies and technology nodes. Although long links might undergo aggressive adjustments, we find these overall costs to be low at the system level for typical cases, taking into account that there are only a few long links in most proposed hierarchical NoC architectures. A preliminary short version of this work entitled ‘‘Design Tradeoffs of Long Links in Hierarchical Tiled Networks-on-Chip (NoCs)’’ was presented in the 16 Euromicro Conference on Digital System Design (DSD), 2013. 2014 Elsevier B.V. All rights reserved.	clock rate;clock signal;die (integrated circuit);document structure description;loss function;network on a chip;network topology;pipeline (computing);repeater insertion;requirement;system on a chip;tree network;wiring	Ran Manevich;Leon Polishuk;Israel Cidon;Avinoam Kolodny	2014	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2014.05.005	embedded system;parallel computing;real-time computing;telecommunications;computer science;electrical engineering;network on a chip;repeater;computer network	EDA	14.29132347739579	54.44851046440542	119118
afa4e03eeb3953b8a2278f3ac245e10700b08d47	design of 2.5 v/5 v mixed-voltage cmos i/o buffer with only thin oxide device and dynamic n-well bias circuit	power supplies;cmos integrated circuits;low voltage design;mos devices;cmos technology;dynamic n well bias circuit;leakage current;2 5 v;mixed voltage cmos i o buffer circuit;cmos process;electric breakdown;buffer circuits;thin oxide device;gate oxide reliability;voltage;nanoelectronics;low power electronics cmos integrated circuits buffer circuits;proceedings paper;low power electronics;diodes;0 25 micron dynamic n well bias circuit thin oxide device low voltage design mixed voltage cmos i o buffer circuit leakage current gate oxide reliability 2 5 v 5 v;circuits;circuits voltage cmos technology leakage current cmos process mos devices diodes power supplies electric breakdown nanoelectronics;5 v;0 25 micron	This paper presents a 2SV/SV mixed-voltage CMOS U0 buffer that does not need a CMOS technology with a duaLoxide option and complex bias circuits. The proposed mixe&voltage U0 buffer with simpler circuit structure can overcome the problems of leakage curent and gate-oxide reliability, which occurring m the conventional CMOS WO buffer. In this work, the new proposed des@ has been realized in a 0.25-pn CMOS process, but it can be easily scaled toward 0.18-pm or 0.15-pm processes to serve a 1.8Vi3.3V mixe& voltage U0 interface.	and gate;cmos;gate oxide;spectral leakage;systemverilog	Ming-Dou Ker;Chia-Sheng Tsai	2003		10.1109/ISCAS.2003.1206197	embedded system;electronic engineering;computer science;engineering;electrical engineering;cmos	EDA	17.32044516893048	58.70675968440277	119382
9f4a9596582ce344d9c7abb4f35f1805ad7ea9b5	clock period constrained minimal buffer insertion in clock trees	constrained minimization;upper bound;high speed;buffer insertion;lower bound	In this paper we investigate the problem of computing a lower bound on the number of buffers required when given a maximum clock frequency and a predefined clock tree. Using generalized properties of published CMOS timing models, we formulate a novel non-linear and a simplified linear buffer insertion problem. We solve the latter optimally with an O(n) algorithm. The basic formulation and algorithm are extended to include a skew upper bound constraint. Using these algorithms we propose further algorithmic extensions that allow area and phase delay tradeoffs. Our results are verified using SPICE3e2 simulations with MCNC MOSIS 2.0μ models and parameters. Experiments show our buffer insertion algorithms can be used effectively for high-speed clock designs.	algorithm;cmos;clock rate;clock signal;group delay and phase delay;mosis;nonlinear system;simulation	Gustavo E. Téllez;Majid Sarrafzadeh	1994		10.1145/191326.191413	mathematical optimization;real-time computing;clock skew;computer science;mathematics;distributed computing;upper and lower bounds	EDA	16.979492968331808	52.17540355235193	119779
6783583f7c8fad9ec77228033ec76bcd1e7fb8bc	towards “zero-energy” using nemfet-based power management for 3d hybrid stacked ics	energy efficiency;cmos integrated circuits;through silicon vias low power electronics energy efficiency nano electro mechanical systems;zero energy;cmos technology;leakage current;clocks;energy efficient;3d hybrid stacked integrated circuit;nano electro mechanical systems;openmsp430 processor;nemfet;nems mems devices;power gating;nanoelectromechanical devices;through silicon via;indexing terms;three dimensional displays cmos integrated circuits logic gates nanoelectromechanical systems hybrid power systems computer architecture clocks;nanofet;hybrid integrated circuits;energy harvesting;three dimensional;power supply;wireless sensor network;energy use;computer architecture;energy harvesters;hybrid approach;heart rate;low power;micromechanical devices;hybrid power systems;biomedical sensing application;leakage power;logic gates;leakage currents;system on chip;energy consumption;three dimensional displays;power system;energy consumption 3d hybrid stacked integrated circuit nanoelectromechanical field effect transistors nemfet zero energy 3d hybrid power management power switches leakage currents nanofet cmos technology nems mems devices energy harvesters openmsp430 processor soc platform biomedical sensing application wireless sensor networks;low power electronics;power management;field effect transistor;wireless sensor networks cmos integrated circuits field effect transistors hybrid integrated circuits leakage currents micromechanical devices nanoelectromechanical devices system on chip;soc platform;hybrid architecture;field effect transistors;nanoelectromechanical systems;energy budget;energy delay product;logic gate;wireless sensor networks;3d hybrid power management;power switches;nanoelectromechanical field effect transistors;through silicon vias	"""In this paper we describe and evaluate a 3D hybrid power management architecture which makes use of Nano-Electro-Mechanical Field Effect Transistors (NEMFET) as power switches that cut-off the power supply of inactive blocks. 3D stacking combines the appealing extremely low leakage currents of the NanoFETs with the versatility of CMOS technology by allowing for the power switches to be fabricated on a separate die. This simplifies the power planning in general, allows for always-on blocks to also be implemented with NEMFETs, and can increase the computation platform performance because of extra area cleared by the switches. Moreover it leverages the integration of other NEMS/MEMS devices, e.g., energy harvesters, sensors, on the same layer with the power switches. To validate this proposal and evaluate its performance in a real-life scenario we perform a careful assessment of the implications of this hybrid power management architecture on the rest of the system. To this end we consider the 3D embodiment of an embedded openMSP430 processor based SoC platform running a bio-medical sensing application for heart rate detection and measure the effects of the 3D hybrid architecture on sensitive metrics used in power gating designs, e.g., delay degradation, power-up and power-down behavior, and overall energy consumption. Our experiments indicate that, due to the extreme low leakage current of the NEMFETs, the system idle energy is decreased by 2.74x at the expense of a 4x area overhead on the NEMS tier. Moreover, due to the 3D hybrid approach the energy-delay product of the embedded SoC platform is reduced by 9%, with a potential improvement of up to 60% for applications with lower activity, e.g., wireless sensor networks. Last but not least the 3D stacked architecture prevents clock period degradation issues, since the IR Drop is reduced with a factor of 4x. Based on our experiment we believe that such 3D hybrid NEMS/CMOS approach creates the premises for the substantial reduction of an increasingly important component of the total energy consumption, the leakage power while idle, thus it makes nanosystems meet the limited energy budget of local energy harvesters, and become potentially autonomous """"zero-energy"""" devices."""	autonomous robot;british informatics olympiad;cmos;clock rate;computation;elegant degradation;embedded system;experiment;field effect (semiconductor);gnu nano;high availability;microelectromechanical systems;multitier architecture;network switch;overhead (computing);power gating;power management;power supply;real life;sensor;spectral leakage;stacking;system on a chip;three-dimensional integrated circuit;transistor	George Razvan Voicu;Marius Enachescu;Sorin Dan Cotofana	2011	2011 IEEE/ACM International Symposium on Nanoscale Architectures	10.1109/NANOARCH.2011.5941505	embedded system;electronic engineering;engineering;electrical engineering	Arch	14.35506066068319	58.628939268618765	119839
d721325272c1fa8eaafe8d90a4dbf9fc2f7125ef	an automatic circuit diagram reader with loop-structure-based symbol recognition	vlsi cad;design automation;connecting line analysis computerised pattern recognition automatic circuit diagram reader loop structure based symbol recognition logic circuit diagram reader vlsi cad symbol segmentation symbol identification template matching feature extraction decision tree control character string recognition;decision tree;design engineering;symbol identification;engineering drawings;decision tree control;logic circuits;computerised pattern recognition;logic circuit diagram reader;computer vision;loop structure based symbol recognition;hybrid method;feature extraction;symbol segmentation;logic cad circuit cad computer vision computerised pattern recognition;pattern recognition;joining processes;magnetooptic recording;connecting line analysis;circuit cad;pattern recognition engineering drawings design automation logic circuits design engineering magnetooptic recording feature extraction character recognition joining processes decision trees;decision trees;logic cad;high performance;template matching;character recognition;character string recognition;automatic circuit diagram reader;control strategy;symbol recognition	A high-performance logic circuit diagram reader has been developed for VLSI-CAD data input. Almost all logic circuit symbols include one or more loop structures. This paper first describes an efficient method for recognition of these loop-structured symbols. The proposed method consists of two processes: symbol segmentation and symbol identification. In particular, symbol identification is achieved by a powerful hybrid method, which uses heuristics to mediate between template matching and feature extraction. The entire symbol recognition process is carried out under a decision-tree control strategy. This can make readjustment, such as the improvement of recognition accuracy or addition of new symbols, very easy. Finally, the entire recognition system for circuit diagrams is briefly explained, including character string recognition and connecting line analysis. Experimental results show that symbol recognition accuracy is more than 95 percent and that a Japanese Industrial Standard (JIS) Al-size (594 mm x 841 mm) drawing can be processed within 30 min. To evaluate a method, more than 800 drawings were read automatically. A reduction of about 50 percent in input time was obtained, compared to conventional interactive entry. Zndex Terms-Circuit diagram reader, decision tree, hybrid pattern recognition, line drawing interpretation, pipeline architecture, realtime image processing, rule-based pattern recognition, structural pattern recognition.	ampersand;circuit diagram;computer-aided design;control theory;decision tree;electronic symbol;feature extraction;hazard symbol;heuristic (computer science);image processing;line drawing algorithm;logic gate;logic programming;maxima and minima;pipeline (computing);real-time computer graphics;shift jis;string (computer science);structural pattern;syntactic pattern recognition;template matching;very-large-scale integration	Akio Okazaki;Takashi Kondo;Kazuhiro Mori;Shou Tsunekawa;Eiji Kawamoto	1988	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.3898	computer vision;electronic design automation;computer science;artificial intelligence;machine learning;decision tree	Vision	11.961837169515555	49.407993861673596	119931
0beaf82d7d4003eab756df424310a68aae12dac0	fixed-outline floorplanning using robust evolutionary search	floorplanning;efficient algorithm;evolutionary search;fixed outline;chip;success rate;vlsi;genetic algorithm;hierarchical design;aspect ratio	Typical floorplanning concerns a series of objectives, such as area, wirelength, and routability, etc., with various aspect ratios of modules in a free-outline regime. However, in a hierarchical design flow for very large ASICs and SoCs, a floorplan can be completely useless for a situation where its outline is dissatisfied. In this paper, we study the fixed-outline floorplanning problem that is more applicable to the hierarchical design style. We develop an efficient algorithm based on robust evolutionary search and achieve substantially improved success rate. We also propose a new approach to handle soft modules to further adjust the generated floorplan to fit into the prescribed chip outline. The effectiveness of our methods is demonstrated on several large cases of MCNC and GSRC benchmarks.	floorplan (microelectronics)	De-Sheng Chen;Chang-Tzu Lin;Yiwen Wang;Ching-Hwa Cheng	2007	Eng. Appl. of AI	10.1016/j.engappai.2006.10.006	chip;floorplan;mathematical optimization;aspect ratio;genetic algorithm;computer science;very-large-scale integration	AI	13.793699742826334	51.901736879658685	120034
431be1e1f5e29790efcee6f33999b44f3622d4d4	evaluation of sub-0.2 v high-speed low-power circuits using hetero-channel mosfet and tunneling fet devices	tunnel transistors leakage currents low power electronics mosfet;mosfet delays logic gates tunneling capacitance inverters leakage currents;lowpower;tunnel fet;hetero channel mosfet;tunnel fet hetero channel mosfet high speed low power;sleep mode leakage power high speed low power circuits heterochannel mosfet tunneling fet devices tfet devices leakage current dual oxide device design dox device design miller capacitance standby leakage power;article;high speed	This paper investigates the feasibility of sub-0.2 V high-speed low-power circuits with hetero-channel MOSFET and emerging Tunneling FET (TFET) devices. First, the device designs and characteristics of hetero-channel MOSFET and TFET devices are discussed and compared. Due to the significant leakage current of ultra-low VT hetero-channel MOSFET devices, assist-circuits are required for hetero-channel MOSFET-based circuits to operate at 0.2 V. Second, the delay, dynamic energy and the Standby power of hetero-channel TFET-based and MOSFET-based logic circuits including Inverter, NAND, BUS Driver, and Latch are analyzed and evaluated. The results indicate that hetero-channel TFET-based circuits with Dual Oxide (DOX) device design to reduce the Miller capacitance provide the potential to achieve high-speed low-power operation at VDD=0.2 V, while the use of assist-circuits in MOSFET-based design improves the delay and dynamic energy at the expense of increased device count, circuit area, and large Standby and sleep-mode leakage power. Finally, the impacts of temperature and process variations on TFET-based and MOSFET-based logic circuits are discussed.	cmos;clock rate;electronic data processing;logic gate;low-power broadcasting;markov chain;miller effect;mixed-signal integrated circuit;nand gate;power inverter;simulation;sleep mode;spectral leakage;traffic collision avoidance system;tunneling protocol	Yin-Nien Chen;Ming-Long Fan;Vita Pi-Ho Hu;Pin Su;Ching-Te Chuang	2014	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2014.2335032	embedded system;electronic engineering;engineering;electrical engineering	EDA	17.313655114635882	58.44748949878821	120099
169e28d251575f814849901314524870503f5fc6	defect tolerance in nanodevice-based programmable interconnects: utilization beyond avoidance	logical modeling;hardware based emulation;abstracts benchmark testing;interconnections;logic circuits;fpga;network routing;network routing field programmable gate arrays interconnections logic circuits;biological networks;field programmable gate arrays;hardware description language;design automation techniques;routability defect tolerance nanodevice based programmable interconnects fpga stuck closed defects stuck open defects scalable algorithm timing driven routing placement algorithm logic blocks up to date level nanodevice defects resource usage degradation reduction circuit performance degradation reduction	This work focuses on defect tolerance for nanodevice-based programmable interconnects of FPGAs. First, we show that the stuck-closed defects of nanodevices have a much higher impact than the stuck-open defects. Instead of simply avoiding the stuck-closed defects, we use them by treating them as shorting constraints in the routing. We develop a scalable algorithm to perform timing-driven routing under these extra constraints. We also enhance the placement algorithm to recover logic blocks which become virtually unusable due to shorted pins. Simulation results show that at the up-to-date level of nanodevice defects (108--1011x higher than CMOS), compared to the simple avoidance method, our approach reduces the degradation of resource usage by 87%, improves the routability by 37%, and reduce the degradation of circuit performance by 36%, at a negligible overhead of tool runtime.	algorithm;cmos;electrical connection;elegant degradation;field-programmable gate array;overhead (computing);routing;scalability;simulation;software bug;usability	Jason Cong;Bingjun Xiao	2013	2013 50th ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2463209.2488745	embedded system;electronic engineering;parallel computing;programmable logic array;computer science;engineering;field-programmable gate array	EDA	13.910654301749886	53.735360595562355	120106
97b5c5e8c417fdbb09a64a8bd45a8a85f59695aa	ring generator: an ultimate linear feedback shift register	nanometer designs linear feedback shift registers pseudorandom binary sequences discrete event counters;ring generators;generators;binary sequence;ultimate linear feedback shift register;advanced nanometer design ultimate linear feedback shift register ring generator pseudorandom sequences deterministic binary sequences layout friendly structure digital logic circuit layout linear finite state machine characteristic polynomial;linear feedback shift registers;random sequences;nanometer designs;circuit layout;pseudorandom sequences;linear feedback shift register;digital logic;pseudorandom binary sequences;ring generator;discrete event counters;feedback;generators ring generators shift registers performance analysis;shift registers;advanced nanometer design;binary sequences;shift registers binary sequences feedback random sequences;linear finite state machine;performance analysis;characteristic polynomial;deterministic binary sequences;discrete event;layout friendly structure	Ring generators are high-performance linear feedback shift registers capable of handling pseudorandom and deterministic binary sequences. They outperform all traditional solutions by providing an unprecedented speed of operations and a layout-friendly structure. In particular, these devices feature a very shallow digital logic, significantly reduced internal fan-outs, and simplified circuit layout and routing, as compared to many earlier schemes based on linear finite state machines, all implementing the same characteristic polynomial. Consequently, they can serve in the same role as many of their predecessors without compromising the quality of advanced nanometer designs.	boolean algebra;characteristic polynomial;circuit diagram;finite-state machine;linear-feedback shift register;pseudorandomness;routing	Nilanjan Mukherjee;Janusz Rajski;Grzegorz Mrugalski;Artur Pogiel;Jerzy Tyszer	2011	Computer	10.1109/MC.2010.334	feedback with carry shift registers;boolean algebra;theoretical computer science;pseudorandom binary sequence;feedback;shift register;linear feedback shift register;characteristic polynomial	EDA	21.68429767632574	47.73923747711053	120157
97cc1ede327c59c2289c709267ac5556e030be50	is statistical timing statistically significant?	statistical timing analysis;process variation;instruments;design flow;statistical significance;international technology roadmap for semiconductors;coupling circuits;design for debug;silicon debug;integrated circuit interconnections;timing analysis;semiconductor device noise;lead compounds;noise analysis;hardware breakpoints;circuit optimization;timing instruments lead compounds circuit optimization delay coupling circuits integrated circuit interconnections semiconductor device noise;timing	"""Process variations - which affect critical electrical parameters and lead to both random and systematic changes in circuit performance - have always posed significant challenges to semiconductor design. In the past, within-die process variation was relatively small, and methods such as corner-based analysis were sufficient. This allowed timing analysis tools to calculate delays, slew times, coupling and power in a straightforward way. Today, the International Technology Roadmap for Semiconductors suggests that the semiconductor industry's historical ability to control process variations is under siege, for both devices and interconnects. As statistical variation increases, will corner-casing lead to too much conservatism, and hence a requirement for new statistical timing and noise analysis tools? In other words, is the design flow inevitably moving to """"delay is no longer a number; it's a distribution""""? Or are the urgency and the advantages of statistical timing analysis overstated."""	electrical connection;requirement;semiconductor industry;static timing analysis;statistical model	Richard Goldman;Kurt Keutzer;Clive Bittlestone;Ahsan Bootehsaz;Shekhar Y. Borkar;E. Chen;Louis Scheffer;Chandramouli Visweswariah	2004		10.1145/996566.996757	electronic engineering;real-time computing;engineering;design flow;electrical engineering;statistical significance;process variation;static timing analysis;statistics	EDA	22.43190467254395	57.43616753402034	120163
e16dcd57eb072de19aa0690b2f9be9e6b9ddf2ff	a highly fault tolerant pla architecture for failure-prone nanometer cmos and novel quantum device technologies	nanometer-scale cmos device;highly fault tolerant pla;underlying system architecture;quantum technology;novel quantum device technologies;current cmos device;deep submicron cmos circuit;new fabrication;expected failure;failure-prone nanometer cmos;novel quantum structure;new device;proposed architecture;boolean functions;quantum gates;fault tolerance;fault tolerant;programmable logic array;feed forward;majority voting;system architecture;nanoelectronics;redundancy	Nanometer-scale CMOS devices, as well as new devices based on quantum technologies, are expected to gradually replace current CMOS devices within the next ten to fifteen years. However it is expected that these devices will be prone to failures of several types, until radically new fabrication processes yet to be developed stabilize, and error absorbing methodologies adapted to expected failures are developed and massively applied. This paper proposes a method and the underlying system architecture for improving the fault-tolerance, based on a feed-forward four layer structure which can accommodate deep submicron CMOS circuits and novel quantum structures. Simulation results show a significant improvement of yield with respect to widely applied triple-redundancy and majority voting techniques. A programmable logic array arrangement of the proposed architecture is demonstrated.	cmos;fault tolerance;programmable logic array;programmable logic device;simulation;systems architecture;triple modular redundancy;very-large-scale integration	Alexandre Schmid;Yusuf Leblebici	2004	19th IEEE International Symposium on Defect and Fault Tolerance in VLSI Systems, 2004. DFT 2004. Proceedings.	10.1109/DFT.2004.3	reliability engineering;fault tolerance;electronic engineering;computer science;engineering;theoretical computer science;systems architecture;computer engineering	EDA	10.693737722658515	58.80731044074085	120179
1ed2e3e009af439f65b69d1ae2033c03f8f21f3d	understanding integrated circuits	engineering;integrated circuit design reverse engineering;integrated circuit;netlist module level description gate level netlist reverse engineering ic device levels of abstraction;circuit testing reverse engineering adders laboratories logic testing libraries clocks integrated circuit testing bipartite graph tree graphs;integrated circuit design;levels of abstraction;design;integrated circuits;reverse engineering	Reverse engineering is the process of learning as much as possible about an IC device by transforming a detailed design description into successively higher levels of abstraction. This tutorial focuses on deriving a module-level description from a gate-level netlist.	integrated circuit	Gregory H. Chisholm;Steven T. Eckmann;Christopher M. Lain;Robert Veroff	1999	IEEE Design & Test of Computers	10.1109/54.765201	physical design;embedded system;computer architecture;electronic engineering;netlist;computer science;integrated circuit;circuit design;integrated circuit development;formal equivalence checking;application-specific integrated circuit;circuit extraction;computer engineering	EDA	12.422471588668934	51.030197676335156	120223
69ccd1b994a909d49fefc46639612cdbbac889da	an integrated algorithm for combined placement and libraryless technology mapping	libraryless mapping;state-space methods;benchmark circuits;technology mapping;technology cad (electronics);integrated algorithm;state-space search mechanism;software performance evaluation;circuit layout cad;search problems;heuristic programming;placement;cpu times;benchmark circuit;combined placement;conventional approach show;heuristics;best solution;reasonable cpu time;new solution;state space search mechanism;original aspect;integrated software;libraryless technology mapping;search speed;state space	This paper presents a new solution for combining technology mapping with placement, coupling the two into one phase. The original aspects of our work are the use of libraryless mapping and a state space search mechanism that is used to find the best solution. Several heuristics are presented for speeding up the search. Comparisons with a more conventional approach show that these strategies provide improvements of about 20%, with reasonable CPU times, on benchmark circuits.	algorithm;baseline (configuration management);benchmark (computing);central processing unit;greedy algorithm;heuristic (computer science);search algorithm;state space search	Yanbin Jiang;Sachin S. Sapatnekar	1999	1999 IEEE/ACM International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.99CH37051)		electronic engineering;real-time computing;computer science;state space;theoretical computer science	EDA	13.54839315970489	52.77827639378771	120262
858de91e2095c026358f71109f66c61917dc37e4	impacts of inductance on the figures of merit to optimize global interconnect	rc delay concepts;cmos integrated circuits;global interconnects;cmos technology;repeater area inductance impact figures of merit optimize global interconnect cmos technology optimization schemes rc delay concepts line inductance delay uncertainty repeater power;delay lines;figures of merit;inductance integrated circuit interconnections delay repeaters power system interconnection bandwidth optimization methods uncertainty cmos technology wire;optimization schemes;delay uncertainty;repeaters circuit optimisation cmos integrated circuits delay lines inductance integrated circuit interconnections;repeater power;optimize global interconnect;integrated circuit interconnections;figure of merit inductance global interconnects optimization;inductance;optimization;repeaters;power consumption;inductance impact;circuit optimisation;repeater area;figure of merit;line inductance	With aggressive scaling of CMOS technology, different performance parameters: latency, bandwidth, repeater power consumption and area, and delay variation of global interconnects are not scaling accordingly with those of devices and local interconnects. There have been various optimization schemes to minimize the discrepancy of performance between the devices and global interconnect lines. But these optimization schemes are based on RC delay concepts, which assume that the total inductance is less than a critical inductance and the system is over damped; hence the impact of inductance can be ignored. This paper attempts to identify the limitations of these figures of merit (FOMs), and address the impact of line inductance on the methodology of global interconnect width and spacing optimization, and on different FOMs. The paper examines the impacts of inductance on various performance parameters, such as, band width, delay, delay uncertainty, and repeater power and area, which were previously based on RC models	cmos;discrepancy function;electrical connection;image scaling;mathematical optimization;rc time constant	Abinash Roy;Masud H. Chowdhury	2006	APCCAS 2006 - 2006 IEEE Asia Pacific Conference on Circuits and Systems	10.1109/APCCAS.2006.342468	figure of merit;electronic engineering;telecommunications;computer science;engineering;electrical engineering;cmos	EDA	19.12841488177545	57.63164101232725	120516
26f2ab8658e4c81065a662f52acda73df3977172	application-independent testing of fpga interconnects	field programmable gate array;static random access memory;field programmable gate arrays switches automatic testing integrated circuit interconnections circuit faults programmable logic arrays manufacturing circuit testing routing wires;automatic test pattern generation;automatic testing;interconnections;testing field programmable gate arrays fpgas interconnections self testing;testing;general techniques;self testing;interconnection network;integrated circuit interconnections;logic testing;integrated circuit testing;stuck closed faults application independent testing fpga interconnect testing automatic test configuration generation application independent manufacturing testing interconnection network testing static random access memory based field programmable gate arrays fault detection open faults bridging faults xilinx virtex fpga stuck open faults;field programmable gate arrays;fault diagnosis field programmable gate arrays automatic test pattern generation integrated circuit testing integrated circuit interconnections logic testing;target detection;field programmable gate arrays fpgas;fault diagnosis	We present a new automatic test-configuration-generation technique for application-independent manufacturing testing of the interconnection network of static-random-access-memory-based field programmable gate arrays (FPGAs). This technique targets detection of open and bridging faults in the wiring channels and programmable switches in the interconnects. Experimental results on Xilinx Virtex FPGAs show that very few test configurations are required to cover stuck-open, stuck-closed, open, and bridging faults in the interconnects.	bridging (networking);electrical connection;field-programmable gate array;interconnection;network switch;random access;static random-access memory;virtex (fpga);wiring	Mehdi Baradaran Tahoori;Subhasish Mitra	2005	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2005.852452	embedded system;electronic engineering;computer science;engineering;field-programmable gate array;computer engineering	EDA	11.363456876624024	52.836904862951144	120567
1fabf6e988611cfa9cc2cc35d452febf503a1829	layer assignment for crosstalk risk minimization	crosstalk;integrated circuit layout;minimisation;network routing;crosstalk avoidance;crosstalk noise;crosstalk risk minimization;global routing;layer assignment;predetailed-routing crosstalk;ultra-deep submicron technology	In ultra-deep submicron technology, crosstalk noise is so severe that crosstalk avoidance merely in detailed routing is not adequate and it has to be considered in earlier design stages. In this paper, we propose two heuristics for crosstalk mitigation in layer assignment, which is a stage between global routing and detailed routing, so that subsequent crosstalk avoidance in detailed routing can be more attainable. The pre-detailed-routing crosstalk is estimated through a probabilistic model. The constraint on the amount of vias is also considered. Experimental results on benchmark circuits confirm the effectiveness of the proposed heuristics.	benchmark (computing);crosstalk;heuristic (computer science);routing;statistical model;very-large-scale integration;via (electronics)	Di Wu;Jiang Hu;Rabi N. Mahapatra;Min Zhao	2004	ASP-DAC 2004: Asia and South Pacific Design Automation Conference 2004 (IEEE Cat. No.04EX753)	10.1145/1015090.1015128	statistical model;minimisation;routing;electronic engineering;crosstalk;telecommunications;computer science;engineering;multipath routing;integrated circuit layout;routing;statistics;computer network	EDA	16.165715328744493	52.78194560004779	120591
bbd417efeaeeaec70574ecf46859e62a3cd7a4e6	chip size estimation for soc design space exploration	system on a chip;chip;ip reuse;design space exploration;chip size estimation;analytical model	At early design space exploration phases of architectures for Systems On a Chip (SOC) chip size estimation is of high interest. An accurate chip size estimation needs detailed knowledge of the transistor densities of a semiconductor process. This paper introduces a novel and simplified chip size estimator, which is independent of manufacturer specific process data. CMOS processes are characterized by only three parameters. These are the drawn gate length and the used numbers of metal layers for logic and for memories. The chip size estimator has been derived from a comprehensive analysis of realized VLSI chips. It has been investigated and confirmed either for published VLSIs as well as for latest SOC designs with 221 million transistors and 333 million transistors. The proposed model has been implemented as a web based tool and contributes to analytical modeling of cost and performance tradeoffs of SOC concepts.	design space exploration	Hartwig Jeschke	2007	Journal of Systems Architecture	10.1016/j.sysarc.2007.01.012	chip;system on a chip;embedded system;parallel computing;real-time computing;telecommunications;computer science	EDA	21.573876892654134	57.55179689033364	120640
40923647d044cae55527e85049c60da55c4c9b8f	on new current signatures and adaptive test technique combination	cmos integrated circuits;adaptive testing;i ddq measurements;weak resistive passive defects;cmos technology;adaptive test technique;yield losses;linear regression;weak resistive active defects;emulation;scattering;electric current measurement;current measurement;life testing;i ddq test patterns;chromium;fault detection;voltage;integrated circuit testing;yield loss;current measurement scattering costs cmos technology emulation fault detection chromium life testing voltage linear regression;current based test techniques;current signatures;weak resistive passive defects adaptive test technique current signatures current based test techniques i sub ddq test patterns yield losses i sub ddq measurements weak resistive active defects;electric current measurement integrated circuit testing cmos integrated circuits integrated circuit measurement;integrated circuit measurement	This paper proposes new current signatures for test purposes. It estimates their capabilities in the detection of additional current caused by weak resistive active and passive defects, when used separately and in combination with other current-based test techniques. Estimation results based in part on actual I/sub DDQ/ measurements show that current-based test technique combinations allow reliable detection of smaller current deltas and offsets. The extra margin provided by these combinations can also be used to reduce the yield losses associated to current-based test techniques by applying these test techniques more conservatively while keeping the same detection capabilities. The cost of adding a second set of I/sub DDQ/ test patterns can be greatly reduced if part of an adaptive test strategy.	antivirus software;delta encoding;emulator;iddq testing;software bug;test card;test strategy;type signature;value-driven design	Claude Thibeault	2004	22nd IEEE VLSI Test Symposium, 2004. Proceedings.	10.1109/VTEST.2004.1299226	electronic engineering;computer science;engineering;electrical engineering;test compression;forensic engineering;cmos	EDA	22.85079322769505	54.255655085867346	120677
373d6da3c1b47f9fbe60f13a6fb7fce7d15536f5	parallel test generation for sequential circuits on general-purpose multiprocessors	synchronous generators;logic arrays;circuit faults;iterative algorithms;sequential circuits;search method;sequential analysis;circuit testing sequential analysis sequential circuits circuit faults logic testing synchronous generators permission hardware iterative algorithms logic arrays;permission;logic testing;test generation;circuit testing;hardware	We propose a par:fllel test generation system for sequential circmitw on shareclmemory mllltiprocessors. A parallel search met hod is proposed which speeds up kes t generation for hard-to-detect (HTD ) faults. A circuitpartitioned approach to fault simulation is proposed whick requires a very low synchronization overhead ancl results in a very high processor utilization.	general-purpose markup language;overhead (computing);simulation	Srinivas Patil;Prithviraj Banerjee;Janak H. Patel	1991		10.1145/127601.127651	electronic engineering;logic optimization;asynchronous circuit;logic gate;logic family;computer science;theoretical computer science;sequential analysis;sequential logic;digital electronics;register-transfer level;algorithm;statistics	EDA	19.72805577728027	49.925001550440406	120749
384b172c2ed6ba160c30d468ac4a7d558bfd8ca9	monte carlo-alternative probabilistic simulations for analog systems	analytical models;run time reduction;cache;performance estimation;design for manufacture;surface fitting;probabilistic system simulations;probabilistic system;runtime;static noise margin snm;analog circuits;integrated circuit design;circuit simulation;reaction diffusion r d model;computational modeling;run time reduction probabilistic system simulations analog circuits monte carlo analysis time to market design for manufacturability;sensitivity analysis;principal component analysis;design for manufacturability;computational modeling analytical models circuit simulation monte carlo methods sensitivity analysis sampling methods virtual manufacturing runtime principal component analysis surface fitting;negative bias temperature instability nbti;analogue circuits;sram;time to market;monte carlo methods analogue circuits design for manufacture integrated circuit design;sampling methods;monte carlo;virtual manufacturing;monte carlo methods;monte carlo analysis;design methodology	Probabilistic system simulations for analog circuits have traditionally been handled with Monte Carlo analysis. For a manufacturable design, fast and accurate simulations are necessary for time-to-market, design for manufacturability and yield concerns. In this paper, a fast and accurate probabilistic simulation alternative is proposed targeting the simulation of analog systems. The proposed method shows high accuracy for performance estimation combined with a 100- fold reduction in run-time with respect to a 1000-sample Monte Carlo analysis.	analogue electronics;design for manufacturability;monte carlo method;simulation	Rasit Onur Topaloglu	2006	7th International Symposium on Quality Electronic Design (ISQED'06)	10.1109/ISQED.2006.90	electronic engineering;real-time computing;simulation;computer science;engineering;monte carlo molecular modeling;design for manufacturability;statistics;monte carlo method	EDA	23.033528901290826	58.02043402402513	120752
e8d95c855016abf890d5cea70ee69b109a21750d	on linear dependencies in subspaces of lfsr-generated sequences	short subsequence probability linear dependency probability subsequences linear feedback shift registers scan chain m sequence;polynomials linear feedback shift registers built in self test circuit faults vectors test pattern generators equations automatic testing system testing computer graphics;probability;linear dependencies;linear feedback shift registers;scan designs;autoprueba;linear feedback shift register;polynomials shift registers binary sequences probability built in self test logic testing;autotest;primitive polynomials;polynomials;built in self test;retroaccion;retroaction;shift registers;binary sequences;logic testing;feedback regulation;scan designers;registre decalage	The probability of linear dependency in subsequences generated by linear feedback shift registers is examined. It is shown that this probability for a short subsequence, e.g., a sequence defined by the length of a scan chain, can be much higher than that for an entire m-sequence.	linear-feedback shift register	Janusz Rajski;Jerzy Tyszer	1996	IEEE Trans. Computers	10.1109/12.543715	discrete mathematics;theoretical computer science;probability;mathematics;shift register;linear feedback shift register;algorithm;statistics;polynomial	Vision	22.183330138694007	48.45538230372935	120756
3a7f087ffabc7784b326122e7847173b92bbf7c9	yield enhancement methodology for cmos standard cells	industrial test;cmos integrated circuits;failure analysis yield enhancement methodology cmos standard cells random logic test vehicle approach industrial test data collection volume analysis design debug failure location;cmos standard cells;integrated circuit yield;design debug;data collection;gate oxide tunneling;integrated circuit yield cmos integrated circuits failure analysis integrated circuit design integrated circuit testing;yield estimation;failure analysis;test vehicle approach;integrated circuit design;random logic;sleep mode;failure location;logic testing cmos logic circuits cmos technology standards development random access memory failure analysis cmos process logic design life testing vehicles;integrated circuit testing;yield enhancement methodology;subthreshold leakage current;deep sub micron;volume analysis;dual threshold voltage;domino logic	In order to maximize the yield of random logic in today's advanced Deep Sub-Micron CMOS technologies we have developed a complete yield enhancement methodology for Cmos standard cells. This methodology based on a test vehicle approach covers design, industrial test, data collection and volume analysis, design debug, failure location and analysis. It has proven to be successful on three consecutive technology nodes down to 65nm. This paper will explain the methodology and demonstrate the results and benefits of this work through illustrated examples.	cmos;random logic	Arnaud Epinat;N. Vijayaraghavan;Matthieu Sautier;Olivier Callen;Sebastien Fabre;Ryan Ross;Paul Simon;Robin Wilson	2006	7th International Symposium on Quality Electronic Design (ISQED'06)	10.1109/ISQED.2006.147	failure analysis;electronic engineering;real-time computing;computer science;engineering;electrical engineering;operating system;sleep mode;cmos;statistics;integrated circuit design;data collection	EDA	22.650857407920114	54.30973114516336	120763
5ab6b7d7ba9a81c15acce3dbfbc947ef1a1f0caf	interconnect resource-aware placement for hierarchical fpgas	overall device area;overall device;resource-aware placement;circuit placement algorithm;efficient clustering;array size;careful matching;hierarchical fpgas;state-of-art fpga placement;placement technique;architecture resource;integrated circuit layout;design of experiments;field programmable gate arrays;logic gates;geometric programming;network routing	In this paper, we utilize Rent's rule as an empirical measure for efficient clustering and placement of circuits on hierarchical FPGAs. We show that careful matching of design complexity and architecture resources of hierarchical FPGAs can have a positive impact on the overall device area. We propose a circuit placement algorithm based on Rent's parameter and show that our clustering and placement techniques can improve the overall device routing area by as much as 21% for the same array size, when compared to a state-of-art FPGA placement and routing tool.	algorithm;cluster analysis;field-programmable gate array;place and route;rent's rule;routing	Amit Singh;Ganapathy Parthasarathy;Malgorzata Marek-Sadowska	2001			physical design;embedded system;mathematical optimization;routing;computer architecture;electronic engineering;geometric programming;logic gate;ic layout editor;programmable logic array;computer science;theoretical computer science;circuit design;place and route;design layout record;integrated circuit layout;circuit extraction;design of experiments;register-transfer level;routing;field-programmable gate array;statistics;placement	EDA	13.854599935457141	52.543242261545785	120961
6010e396275425ee3681c21393967d655020530a	computational geometry based placement migration	bin-based spreading;network routing;heat distribution;post-placement design closure issue;placement migration method;new stability;mesh generation;routing congestion;delaunay triangulation;computational geometry;conventional legalization;timing congestion;circuit layout cad;post-placement design;placement legalization;circuit cad;original placement;signal integrity;conventional legalization algorithms;popular legalization algorithm;design problem;placement migration	"""Placement migration is a critical step to address a variety of post-placement design closure issues, such as timing, routing congestion, signal integrity, and heat distribution. To fix a design problem, one would like to perturb the design as little as possible while preserving the integrity of the original placement. This work presents a novel computational geometry based placement migration method, and a new stability metric to more accurately measure the """"similarity"""" between two placements. It has two stages, a bin-based spreading at coarse scale and a Delaunay triangulation based spreading at finer grain. It has clear advantage over conventional legalization algorithms such that the neighborhood characteristics of the original placement are preserved. Thus, the placement migration is much more stable, which is important to maintain. Applying this technique to placement legalization demonstrates significant improvements in wire length and stability compared to other popular legalization algorithms."""	algorithm;automation;computation;computational geometry;computer-aided design;delaunay triangulation;design closure;integrated circuit;iterative method;link-state routing protocol;mathematical optimization;multidisciplinary design optimization;nam;network congestion;perturbation theory;physical design (electronics);placement (eda);placement syntax;quadratic programming;signal integrity;very-large-scale integration;voronoi diagram	Tao Luo;Haoxing Ren;Charles J. Alpert;David Z. Pan	2005	ICCAD-2005. IEEE/ACM International Conference on Computer-Aided Design, 2005.		mesh generation;mathematical optimization;routing;delaunay triangulation;computational geometry;computer science;signal integrity;theoretical computer science;mathematics;engineering drawing;routing;placement	EDA	15.496879655831759	52.69410039877931	121076
eb32642e2a2cec33d6ea8b3000a52625883cfc0f	new technique for fault detection in quantum cellular automata	stuck at fault test fault detection quantum cellular automata;test vectors;cmos technology;circuit faults;majority gate;wires;quantum dots;nanotechnology;testing;stuck at fault test;electrons;quantum gates;automata;majority voter;logic gates;quantum gates cellular automata combinational circuits fault diagnosis logic testing majority logic;semiconductor device modeling;stuck at faults;fault detection;majority logic;integrated circuit modeling;logic testing;quantum cellular automata;circuit faults logic gates integrated circuit modeling wires automata testing quantum dots;circuit testing;test vectors qca majority voter stuck at faults majority gate;cellular automata;qca;electrical fault detection;fault diagnosis;combinational circuits	Quantum cellular automata (QCA) circuits, the new generation nanotechnology with wide attention in recent years. In this we are proposing a framework based on QCA for finding out the stuck-at fault of a circuit. The existing technologies and methods are not guaranteed to detect the stuck-at faults. This work is motivated by the fact that the stuck-at fault test set of a circuit is not guaranteed to detect all defects that can occur in its QCA implementation.	automata theory;qualitative comparative analysis;quantum cellular automaton;stuck-at fault;test set	Binu K. Mathew;Shajimon K. John;C. Pradeep	2008	2008 First International Conference on Emerging Trends in Engineering and Technology	10.1109/ICETET.2008.186	electronic engineering;stuck-at fault;theoretical computer science;mathematics;algorithm	EDA	22.63388149058916	52.47090991658592	121289
b575ad03db23bf7c51877254480b2e00d954022c	dfm evaluation using ic diagnosis data	databases;silicon;fabrication;systematics;layout;manufacturing diagnosis design for manufacturability dfm testing;integrated circuits;layout integrated circuits databases silicon fabrication systematics	Design for manufacturability rule evaluation using manufactured silicon (DREAMS) is a comprehensive methodology for evaluating the yield-preserving capabilities of a set of design for manufacturability (DFM) rules using the results of logic diagnosis performed on failed ICs. DREAMS is an improvement over prior art in that the distribution of rule violations over the diagnosis candidates and the entire design are taken into account along with the nature of the failure (e.g., bridge versus open) to appropriately weight the rules. Silicon and simulation results demonstrate the efficacy of the DREAMS methodology. Specifically, virtual data is used to demonstrate that the DFM rule most responsible for failure can be reliably identified even in light of the ambiguity inherent to a nonideal diagnostic resolution, and a corresponding rule-violation distribution that is counter-intuitive. We also show that the combination of physically aware diagnosis and the nature of the violated DFM rule can be used together to improve rule evaluation even further. Application of DREAMS to the diagnostic results from an in-production chip provides valuable insight in how specific DFM rules improve yield (or not) for a given design manufactured in particular facility. Finally, we also demonstrate that a significant artifact of DREAMS is a dramatic improvement in diagnostic resolution. This means that in addition to identifying the most ineffective DFM rule(s), validation of that outcome via physical failure analysis of failed chips can be eased due to the corresponding improvement in diagnostic resolution.	algorithm;design for manufacturability;experiment;failure analysis;norm (social);silicon dreams;simulation;software bug;test data	Ronald D. Shawn Blanton;Fa Wang;Cheng Xue;Pranab K. Nag;Yang Xue;X. Y. Li	2017	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2016.2587283	layout;reliability engineering;computer science;engineering;systematics;silicon;fabrication;engineering drawing	EDA	22.482159460361057	55.141662020774795	121362
3500cc82789e56577fe86f79a8dba8438b57285c	synchronous elastic networks	dynamic change;circuit theory;design tool;design process;synchronous elastic networks;stream transformer level;logic circuits;synchronous circuits;circuit compositionality;asynchronous circuit;chip;control structure;efficient implementation;network behavioral properties;latency insensitive systems;circuits adders delay timing wires process design design methodology control systems communications technology microarchitecture;communication delay;theoretical foundation;logic circuits circuit theory;latency insensitive systems synchronous elastic networks stream transformer level synchronous circuits network behavioral properties circuit compositionality;data transfer	We formally define - at the stream transformer level - a class of synchronous circuits that tolerate any variability in the latency of their environment. We study behavioral properties of networks of such circuits and prove fundamental compositionality results. The paper contributes to bridging the gap between the theory of latency-insensitive systems and the correct implementation of efficient control structures for them	bridging (networking);control flow;heart rate variability;transformer	Sava Krstic;Jordi Cortadella;Michael Kishinevsky;John O'Leary	2006	2006 Formal Methods in Computer Aided Design	10.1109/FMCAD.2006.32	chip;real-time computing;design process;asynchronous circuit;logic gate;network analysis;computer science;distributed computing;control flow	EDA	14.523283769556448	56.07081928636434	121475
b76c9f65ca12af3ce90914393609e1e34d935226	definition of an innovative filling structure for digital blocks : the dfm filler cell	silicon;stress;proximity effect lithography;filling design for manufacture lithography stress flow production systems silicon chemical technology portals manufacturing processes design methodology;silicon design for manufacture filling proximity effect lithography;design for manufacture;design flow;filling;lithography;si dfm filler cell design for manufacture innovative filling structure digital blocks production flow lithography planarity variations global context dummy polysilicon gates opc friendly approach;logic gates;capacitors;place and route;context	A DFM approach considers all interactions in the production flow and breaks the standard local/global context. Understanding existing solutions and their limitations in filling solution for digital blocks, we present in this paper a DFM filler cell solution that takes into account a large amount of problems that can be encountered at many steps of the production flow, such as lithography or planarity variations, while other kinds of filler cells only solve density problems. This allows designs to be less dependent on the global context of the digital block. Our DFM filler cell reduces the STI width stress impact, contains dummy polysilicon gates that allow an OPC-friendly approach and is more flexible for the place and route step. Our approach was validated by a silicon structure and many published data in this domain. The insertion of DFM filler cells is costless in terms of area thanks of their size that are multiple of the grid size. Furthermore, the usage of DFM filler cell in the complete design flow was validated.	design flow (eda);design for manufacturability;dummy variable (statistics);interaction;open platform communications;place and route;planar graph;point of view (computer hardware company);spectral leakage;star filler	Laurent Remy;Philippe Coll;Fabrice Picot;Philippe Mico;Jean Michel Portal	2009	2009 16th IEEE International Conference on Electronics, Circuits and Systems - (ICECS 2009)	10.1109/ICECS.2009.5410922	electronic engineering;engineering;operations management;engineering drawing	EDA	13.281926566765353	55.10129671154154	121516
a59bb56da47755404c0aab326fd79ac76d4abd24	structured logic	higher level;large-scale integration;one-thousand-circuit chip;new memory concept;computer application;memory designer;close examination;faster memory system;structured logic	Large-scale integration for computer applications has been predicted for several years, but close examination shows that the progress has been uneven. Memory designers continually demand higher levels of integration for larger and faster memory systems, and new memory concepts are being developed to further exploit the characteristics of large-scale integration. The one-thousand-circuit chip will become nothing more than a milestone.	computer;integrated circuit;very-large-scale integration	Robert A. Henle;Irving T. Ho;G. A. Maley;Ronald Waxman	1969		10.1145/1478559.1478567	simulation;computer science;artificial intelligence	Arch	10.40449964174983	56.90130482316558	121733
c64a1962969c0362d0d949a7ae639fd2e5d8ed42	techniques for heavy ion microbeam analysis of fpga ser sensitivty	random access storage application specific integrated circuits field programmable gate arrays flip flops integrated circuit testing phase locked loops radiation hardening electronics;clocks;ions;flip flops;phase locked loops;gold;size 130 nm heavy ion microbeam analysis fpga ser sensitivty gsi darmstadt flip flop ram set combinatorial logic pll proasic3l fpga testing;fpga single event upset seu single event transient set micro probe phase loced loop pll;latches;field programmable gate arrays;phase locked loops ions clocks flip flops latches field programmable gate arrays gold	Using the heavy-ion micro-probe facility at GSI in Darmstadt, individual heavy ions can be targeted at specific locations on a die. Circuits to measure SEUs in flip-flops and RAMs, SETs in combinatorial logic and glitches in PLLs were developed and tested. Detailed results for a study of the 130 nm ProASIC3L FPGA tested under Au (94 MeV/mg /cm2) and Ti (19 MeV/mg / cm2) ions are presented.	combinational logic;flops;field-programmable gate array;flip-flop (electronics);glitch	Adrian Evans;Dan Alexandrescu;Veronique Ferlet-Cavrois;Kay-Obbe Voss	2015	2015 IEEE International Reliability Physics Symposium	10.1109/IRPS.2015.7112826	embedded system;electronic engineering;real-time computing;engineering	Embedded	19.219155766967017	54.10454409640422	121735
0ad88d9938a91d2c513820c5104a9fc0c127df74	designing a mask programmable matrix for sequential circuits	sequential circuits	This paper proposes the use of Universal Logic Gates (ULGs) as basic elements for masked programmable master-slices customizable by the topmost metal layer. This new approach called Maragata combines the efficiency of MPGAs with the flexibility of FPGA architecture. Due to the intensive use of processor-like blocks in current VLSI circuits, ULGs were developed considering the implementation of sequential circuits. A set of ULGs were studied and designed for CMOS technology. Area comparison was accomplished by mapping various combinational and sequential circuits into ULGs master-slices and to a gate array master-slice called Agata. Results show that significant area gain and connection reduction can be achieved in this new approach.		Fernanda Lima;Marcelo de Oliveira Johann;José Luís Almada Güntzel;Eduardo D'Avila;Luigi Carro;Ricardo Augusto da Luz Reis	1999			computer science;sequential logic	EDA	12.102719460270183	48.882841137079524	122074
a734203797a8a04da4ed284a3b2b565004374c90	reconfiguring three-dimensional processor arrays for fault-tolerance: hardness and heuristic algorithms	logic arrays;dynamic power dissipation 3d processor arrays fault tolerance heuristic algorithms power overheating massively parallel computing logical fault free subarray maximum fault free subarrays maximum logical array mla np complete problem linear time algorithm np hard problem;circuit faults;power aware computing computational complexity fault tolerant computing parallel processing;3d processor array;interconnection length;algorithm;maximum logical array;indexes;fault tolerant systems;three dimensional displays;fault tolerance;algorithm 3d processor array fault tolerance maximum logical array interconnection length np complete problem;parallel processing;logic arrays three dimensional displays parallel processing fault tolerance fault tolerant systems indexes circuit faults;np complete problem	With the increased density of three-dimensional (3D) processor arrays, faults can potentially occur quite often due to power overheating during massively parallel computing. In order to achieve fault-tolerance under such a scenario, an effective way is to find an as large as possible logical fault-free subarray of m' × n' × h' from a faulty array of m × n × h (m' ≤ m, n' ≤ n, h' ≤ h), such that an original application can still work on the m' × n' × h' subarray. This paper investigates the problem of constructing maximum fault-free subarrays with minimum interconnection length from 3D arrays with faults. First, we prove that constructing maximum logical array (MLA) is NP-complete. We propose a linear-time algorithm which is capable of producing an MLA for the problem with the constraint of selected indexes. Second, we prove that minimizing the interconnection length (inter-length) of the MLA is NP-hard. We propose an efficient heuristic which significantly reduces the inter-length by revising each logical plane of the MLA. This leads to the reduction of communication cost, capacitance and dynamic power dissipation. In addition, we propose a lower bound for the inter-length of the MLA to evaluate the proposed algorithms. Simulation results show that, the size of logical array can be improved up to 62.6 percent in average, and the inter-length redundancy can be reduced by 22.7 percent in average, compared to the state-of-the-art, for all cases considered.	algorithm;cmos;fault (technology);fault tolerance;heuristic;heuristic (computer science);interconnection;np-completeness;network switch;parallel computing;processor array;simulation;time complexity	Guiyuan Jiang;Jigang Wu;Yajun Ha;Yi Wang;Jizhou Sun	2015	IEEE Transactions on Computers	10.1109/TC.2015.2389846	database index;embedded system;parallel processing;fault tolerance;parallel computing;real-time computing;np-complete;computer science;distributed computing;algorithm	DB	15.215914050715538	48.61432407482658	122081
7624beb1c0267729b23d0862aff1e748d20761e0	reading spin-torque memory with spin-torque sensors	cache storage;standards;mram devices;sensors;resistance;switches cache storage low power electronics mram devices nanoelectronics nanosensors;low power;spin devices;magnetic separation;low power spin devices magnets memory;sensors magnetic tunneling magnetic domains switches standards resistance magnetic separation;nanoelectronics;low power electronics;nanosensors;magnets;switches;magnetic domains;spin transfer torque magnetic random access memory low current read operations stt mram based caches read energy high speed read operations read peripherals low voltage read operations nanoscale spin torque switches spin torque sensors;magnetic tunneling;memory	Spin-Transfer-Torque Magnetic Random Access Memory (STT-MRAM) is a promising candidate for future on-chip memory, owing to its high-density, zero-leakage and energy efficiency. In a conventional STT-MRAM cache write operations consume larger energy as compared to read, due to relatively large write-current requirement. In recent years novel spin-torque based write schemes have been proposed for MRAM that can bring large reduction in write energy, such that the read-energy now becomes dominant. Conventional read schemes based on CMOS sense amplifiers may not offer commensurate reduction in read energy, owing to their poor scalability and limited speed. We propose a spin-torque based sensing technique for MRAM that employs nano-scale spin-torque switches for low-voltage, low-current read-operations in STT-MRAM. Such a sensing-scheme can achieve improved-scalability, simplified-design for read-peripherals, high-speed read-operations and 90% lower read-energy. As a result more than ~80% reduction in overall energy can be obtained for STT-MRAM based caches.	amplifier;cmos;gnu nano;magnetoresistive random-access memory;network switch;peripheral;random access;scalability;semiconductor research corporation;sensor;spectral leakage	Mrigank Sharad;Rangharajan Venkatesan;Xuanyao Fong;Anand Raghunathan;Kaushik Roy	2013	2013 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH)	10.1109/NanoArch.2013.6623040	electronic engineering;computer hardware;engineering;electrical engineering	Arch	16.96931731486603	60.18449424754663	122202
132f7952dc614c5556639983f5ac58a9f7f3f5bd	initial design concepts for an advanced design automation system	printed circuit board design;computer aided design;design automation;integrated circuit layout;southern california	Most design automation systems attempt to automate only a small part of the physical description. Much is left to the designers. An exploratory design automation system is being developed at the University of Southern California. The system is intended to be highly interactive and has several features which will enhance the possibilities of automatic physical description. Different approaches and algorithms required to accomplish the “future” system are outlined.	algorithm;automation	Melvin A. Breuer;Arthur D. Friedman	1974			physical design;embedded system;electronic engineering;simulation;electronic design automation;computer science;systems engineering;engineering;design flow;electrical engineering;computer-automated design;process automation system;computer aided design;circuit design;integrated circuit layout;design education;totally integrated automation;standard cell;computer engineering	EDA	10.599949860260512	51.59946014670809	122361
10208c3dfa183ff941b0e1c0ea3a4d956eb15cf5	fault tolerant techniques for tsv-based interconnects in 3-d ics		TSV-based 3-D IC is one of the most promising approach in modern integrated circuit design. As TSV enables the integration of different dies with different technologies, it is considered as one of the key elements in IC design. Reliability of TSV is an important issue which needs to be addressed very carefully since a faulty TSV can result in the failure of the whole stack. TSV open defect alongside TSV short are the most prevalent faults in 3-D ICs. They can happen during TSV filling, bonding process or as a result of aging due to Electromigration. In this paper, we present two methods for reducing the amount of delay caused by a partially open TSV and TSV short defect in 3D-ICs. Simulation results demonstrate the effectiveness of the proposed method in improving the performance of 3-D ICs in presence of partially open and short TSV defects.	clock network;die (integrated circuit);electrical connection;electromigration;integrated circuit design;simulation;software bug;through-silicon via	Siroos Madani;Magdy A. Bayoumi	2017	2017 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2017.8050944	electronic engineering;fault tolerance;electromigration;computer science;integrated circuit design;reliability engineering	Arch	21.555378443025866	54.972020484274964	122539
38554d75a17b8d4a1a61e1ad4d06ca6125d97907	optimization of gate-level area in high throughput multiple constant multiplications	optimisation;pipeline arithmetic high level synthesis optimisation;high level synthesis;multiple constant multiplication;logic gates;registers;signal processing;logic gates algorithm design and analysis optimization delay signal processing algorithms registers pipeline processing;optimization;integer linear programming gate level area high throughput multiple constant multiplications optimization pipelined multiple constant multiplications high level synthesis hcub dc ilp delay constraint hcub dc algorithm local minimum point;high throughput;signal processing algorithms;logic gate;algorithm design;pipeline arithmetic;algorithm design and analysis;pipeline processing	This paper addresses the problem of optimizing gate-level area in a pipelined Multiple Constant Multiplications (MCM) operation and introduces a high-level synthesis algorithm, called HCUB-DC+ILP. In the HCUB-DC+ILP algorithm, initially, a solution with the fewest number of operations under a minimum delay constraint is found by the Hcub-DC algorithm. Then, the area around this local minimum point is explored exactly using a 0–1 Integer Linear Programming (ILP) technique that considers the gate-level implementation of the pipelined MCM operation. The experimental results at both high-level and gate-level clearly show the efficiency of HCUB-DC+ILP over previously proposed prominent MCM algorithms.	and gate;algorithm;heuristic;high- and low-level;high-level synthesis;integer programming;linear programming;mathematical optimization;maxima and minima;multi-chip module;throughput	Levent Aksoy;Eduardo Costa;Paulo F. Flores;José C. Monteiro	2011	2011 20th European Conference on Circuit Theory and Design (ECCTD)	10.1109/ECCTD.2011.6043602	algorithm design;electronic engineering;parallel computing;real-time computing;logic gate;computer science;engineering;theoretical computer science;signal processing;mathematics	EDA	15.184831032641256	48.80234178348441	122562
3ce2fc6e6daa538dc7561e4c31bfddd7e3bc12c9	hierarchical folding and synthesis of iterative data flow graphs	hierarchical synthesis;interleaving;time multiplexed circuit synthesis folding hierarchical folding hierarchical synthesis interleaving iterative data flow graphs dfgs;hierarchical folding;folding;data flow graphs;iterative methods data flow graphs digital filters;time multiplexed circuit synthesis;iterative methods;digital filters;delays computer architecture hardware switches digital signal processing pipeline processing signal processing algorithms;iterative data flow graphs dfgs;hierarchical folding transformation cascaded fifth order wave digital filter synthesis process hierarchical contiguous folding hierarchical interleaved folding folded structure switch delays hierarchical iterative dfg synthesis hardware dfg synthesized hardware architecture feasible folding set digital signal processing algorithms iterative data flow graph synthesis	Folding transformation enables synthesis of digital signal processing algorithms described by iterative data flow graphs (DFGs). For a specified feasible folding set, it returns a synthesized hardware architecture described by a hardware DFG. This brief presents hierarchical folding and hierarchical synthesis of iterative DFGs that contain many identical or similar substructures. Instead of performing folding or synthesis on the entire large DFG, the hierarchical folding transformation performs folding or synthesis only on one substructure and then completes the folding process by appropriately changing the number of delays and switch instances in this folded structure. The advantage lies in significant reduction in execution time. Two different approaches to hierarchical folding presented include hierarchical interleaved folding and hierarchical contiguous folding. Experimental results show that the run time increase of the synthesis process for a 20-cascaded fifth-order wave digital filter can be reduced from 2000% to 30% using hierarchical synthesis instead of conventional synthesis, compared with the run time for synthesis of one section.	algorithm;computation;dataflow architecture;digital filter;digital signal processing;fast fourier transform;iteration;iterative method;norm (social);run time (program lifecycle phase);time complexity;verification and validation	Keshab K. Parhi	2013	IEEE Transactions on Circuits and Systems II: Express Briefs	10.1109/TCSII.2013.2268658	interleaving;parallel computing;digital filter;computer science;engineering;theoretical computer science;folding;operating system;machine learning;mathematics;iterative method	EDA	13.891299016032438	47.00543012792675	122592
f5826a22684801fffa2e0709258ab7f3bfa25eae	design and analysis of mux using adiabatic techniques ecrl and pfal	positive feedback adiabatic logic mux design mux analysis ecrl adiabatic technique pfal adiabatic technique adiabatic logic designs minimum maximum voltage average power consumption total power consumption circuit schematic design circuit simulation design tanner tool transistor count ecrl based circuit pfal based circuit efficient charge recovery logic;logic circuits;mux ecrl pfal adiabatic;logic circuits logic cad;informatics;logic cad	In this paper authors have compared two prominent adiabatic logic designs ECRL and PFAL. A 2Ω1 Mux using these design techniques are implemented and results are compared like minimum/maximum voltage, average power consumption, total power consumption etc. The Designing of schematic and simulation of the circuits are done on tanner tool vl3. From the results it is found that the output levels for PFAL are better and stabilize quickly as compared to the ECRL based circuit but the transistor count and average power of PFAL based circuit are more than ECRL based circuit.	schematic;simulation;tanner graph;transistor count	Arun Kumar;Manoj Sharma	2013	2013 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2013.6637372	electronic engineering;adiabatic circuit;logic gate;engineering;electrical engineering;theoretical computer science;mathematics;informatics	EDA	18.105697625822106	57.22722277772907	122622
77b48df8d444706cffcd27a3216da76276daefe8	evolution of soc technology and architectures for telecom applications	technologie semiconducteur;architecture systeme;semiconductor technology;integrated circuit;progreso tecnico;circuito integrado;systeme integre;tecnologia mos complementario;system on a chip;chip;nanoestructura;wafer;microstructure;nanostructure;telecomunicacion;sistema sobre pastilla;system on chip;pastille semiconductrice;telecommunication;progres technique;application telecommunication;arquitectura sistema;complementarymos technology;technologiemos complementaire;pastilla electronica;systeme sur puce;pastille electronique;semiconductor chip;system architecture;technologie mos complementaire;telecommunication application;technical progress;integrated system;circuit integre;complementary mos technology;microestructura	Market demand in the telecom area is leading to the design of increasingly complex chips. This paper tries to indicate the most significant trends: evolution ofcmos technology, contribution of nanotechnologies and evolution of architectures.		Hervé Fanet;Jean-René Lequepeys	2004	Annales des Télécommunications	10.1007/BF03180021	system on a chip;electronic engineering;telecommunications;computer science;engineering;electrical engineering;systems architecture	EDA	13.069568259424418	57.682606057439735	122625
0f7745e6f58d53177696e1d67b5d3620a1838e50	conquering testability problems by combining in-circuit and functional techniques	test approach;in-circuit test program;functional test program;common testability problem;functional technique;modern microprocessor-based board	This paper will describe common testability problems encountered in writing in-circuit test programs and functional test programs for modern microprocessor-based boards. It will show how combining the two test approaches offers solutions for boards previously considered to be untestable.		Stephen Caplow	1984			reliability engineering;mathematics;engineering drawing;algorithm	Logic	21.8827262238307	52.61503900403996	122631
35c01600b7ba81c9d6794a09319013d800b9397b	test generation for delay faults on clock lines under launch-on-capture test environment				Yoshinobu Higami;Hiroshi Takahashi;Shin-ya Kobayashi;Kewal K. Saluja	2013	IEICE Transactions		fault coverage;stuck-at fault;automatic test pattern generation	EDA	22.11404411551201	51.65895121195184	122813
bb7ea53a5164c25c0e7f1b008fdee52e3c601450	test resource optimization for multi-site testing of socs under ate memory depth constraints	appareillage essai;optimisation;performance evaluation;optimizacion;integrated circuit;canal bus;test access mechanism;resource allocation;site testing;canal colector;automatic test equipment;circuito integrado;system on a chip;constraint optimization memory management logic testing wire routing cost function hardware microelectronics laboratories embedded computing;essai circuit integre;performance evaluation integrated circuit design integrated circuit testing system on chip automatic test equipment optimisation scheduling resource allocation;integrated circuit design;sistema sobre pastilla;system on chip;scheduling;aparato ensayo;integrated circuit testing;testing equipment;bus channel;optimization;system on chip test access mechanisms soc multi site testing ate memory depth constraints test resource optimization embedded core based soc enhanced rectangle packing techniques wrapper tam architecture design soc test suites ate memory load tam width minimization routing complexity hardware cost reduction ate channel minimization test scheduling core tests channel memory depth allocation memory resource management benchmark testing automatic test equipment;systeme sur puce;computer hardware;test scheduling;materiel informatique;ordonnancement;circuit integre;reglamento;hardware	We present a two-step solution to the problem of test resource optimization for multi-site testing of embedded-corebased SOCs. In Step I , an eficient technique based on enhanced rectangle packing is used to design the wrapperFAM architecture such that the SOC test suite fits in a single ATE memory b a d . Furthermore, the total TAM width for the SOC is minimized, thereby reducing routing complexity and hardware cost. Minimum TAM width directly leads to the minimization of the number of ATE channels used, thus enabling multi-site testing. In Step 2, test scheduling is pe$ormed such that “idle” bits appearing between core tests on ATE channels are moved to the end of each channel. This reduces the memory depth allocated to the channels from the pool of ATE memory. The saved memory can be mapped to the remaining ATE channels to test other SOCs, thereby further facilitating multi-site testing. We present experimental results on our technique f o r f v e benchmark SOCs.	benchmark (computing);computer memory;embedded system;fits;ibm tivoli access manager;mathematical optimization;radio frequency;routing;scheduling (computing);set packing;system on a chip;test suite	Vikram Iyengar;Sandeep Kumar Goel;Erik Jan Marinissen;Krishnendu Chakrabarty	2002		10.1109/TEST.2002.1041874	system on a chip;embedded system;electronic engineering;parallel computing;real-time computing;computer science;engineering;operating system	EDA	11.947179149598462	53.79278250012123	122866
2fbe4c0d83ee4455703ec28fa2bf7da6898c7d0e	an efficient cntfet-based 7-input minority gate		Complementary metal oxide semiconductor technology (CMOS) has been faced critical challenges in nanoscale regime. CNTFET (Carbon Nanotube Field effect transistor) technology is a promising alternative for CMOS technology. In this paper, we proposed a novel 7-input minority gate in CNTFET technology that has only 9 CNTFETs. Minority function is utilized in the voting systems for decision making and also it is used in data mining. This proposed 7-input minority gate is utilized less fewer transistors than the conventional CMOS method which utilizes many transistors for implementing sum of products. By means of this proposed 7-input minority gate, a 4-input NAND gate can be implemented, which gets better the conventional design in terms of delay and energy efficiency and has much more deriving power at its output.	cmos;data mining;field effect (semiconductor);functional completeness;logic gate;nand gate;semiconductor;simulation;transistor	Samira Shirinabadi Farahani;Ronak Zarhoun;Mohammad Hossein Moaiyeri;Keivan Navi	2013	CoRR		electronic engineering;engineering;gate equivalent;electrical engineering;nanotechnology;nand gate	EDA	16.42603513914137	59.48631965545369	122890
2e15a4961d31fc80ae02f871e2d19935cff839fa	analysis and extraction of parametric variation effects on microelectrofluidics-based biochips	voltage control;viscosity;continous droplet movement;optimisation;faulty cell;routing;microfluidics electrodes routing voltage control circuit testing circuit faults system testing optimization micromechanical devices transportation;data mining;microelectrofluidics based biochips;parametric variation effects;critical cells;electrodes;optimisation biomems cellular biophysics lab on a chip;lab on a chip;microfluidic biochip parametric variation extraction method;unrecoverable droplet speed loss;dielectrics;scheduling and routing;friction;online testing;performance optimization;cellular biophysics;extraction method;biomems;optimisation parametric variation effects microelectrofluidics based biochips continous droplet movement faulty cell microfluidic biochip parametric variation extraction method critical cells unrecoverable droplet speed loss	Microfluidic biochips require continued online test to ensure their functionality, performance, and reliability in the presence of runtime parametric variation and system wear-out. Previous techniques locate catastrophic defects which guide subsequent droplet scheduling and routing procedures. However, a significant number of defects on a microfluidic biochip are parametric variations, taking them as catastrophic defects leads to incorrectly identified defect locations, which compromises droplet scheduling and routing. This paper presents the first characterization method for continous droplet movement after passing a faulty cell on a microfluidic biochip in the presence of parametric variations, and the first microfluidic biochip parametric variation extraction method locating the critical cells which originate un-recoverable droplet speed loss. The proposed techniques provide better characterization of parametric variations in droplet movement, and enable performance optimization in droplet scheduling and routing on a microfluidic biochip.	biochip;catastrophic interference;mathematical optimization;performance tuning;routing;schedule (computer science);scheduling (computing);software bug	Bao Liu	2009	2009 IEEE Behavioral Modeling and Simulation Workshop	10.1109/BMAS.2009.5338886	electronic engineering;engineering;electrical engineering;nanotechnology	EDA	21.389479767983254	55.09890928239161	122921
fa8c6aece3682f3f2e4590dc47d207b0a2387ede	active noise cancellation using aggressor-aware clamping circuit for robust on-chip communication	on chip bus;cmos integrated circuits;active noise cancellation;crosstalk;point to point;crosstalk integrated circuit interconnections cmos integrated circuits integrated circuit noise integrated circuit design system buses;signal integrity;chip;system buses;integrated circuit design;technology scaling;integrated circuit interconnections;integrated circuit noise;noise cancellation clamps circuits noise robustness crosstalk delay wire cmos technology noise reduction noise level;0 13 micron active noise cancellation aggressor aware clamping circuit robust on chip communication ic process technology aspect ratios on chip interconnects coupling capacitances cross talk noise on chip bus communication bus cmos technology delay noise;aspect ratio	As the IC process technology scales the on-chip wiring network becomes denser. Increasing aspect ratios of the on-chip interconnects lead to higher coupling capacitances and ultimately higher cross-talk noise, which degrades signal integrity. In this paper we propose a clamping circuit for on-chip busses, which clamps a victim wire in an on-chip bus based on the states of its immediate aggressors. These clampers help the driver of the victim wire in draining the charge, which is induced due to cross-talk between aggressors and victim wires. This helps in decreasing the cross-talk peak noise and also the delay variability (referred to as delay noise). Simulation results for a 10 mm long communication bus (parallel wires) laid at minimum pitch in 0.13 /spl mu/m CMOS technology show that a reduction of 30%(17.6%), 37%(27.2%) and 26%(65.8%) in cross-talk peak noise amplitude (delay noise) is observed for point to point, parallel repeater inserted and staggered repeater inserted respectively when only immediate neighbours are considered (1/sup st/ order). Furthermore the aggressor-aware clamper is very effective in avoiding glitches, which may occur when more aggressors, in addition to the immediate ones are also switching simultaneously in the same.	bus (computing);cmos;clamper (electronics);clamping (graphics);crosstalk;electrical connection;glitch;noise shaping;pin grid array;signal integrity;simulation;spatial variability;wiring	Atul Katoch;Maurice Meijer;Sanjeev K. Jain	2005	18th International Conference on VLSI Design held jointly with 4th International Conference on Embedded Systems Design	10.1109/ICVD.2005.42	chip;embedded system;aspect ratio;electronic engineering;crosstalk;telecommunications;point-to-point;computer science;signal integrity;engineering;electrical engineering;active noise control;cmos;integrated circuit design	EDA	17.0187833097325	56.04398625018442	123110
67e37e2dc1d299867606ac7f2d19fa208fa8623d	a compact and low-power sram with improved read static noise margin	microprocessors;improved read static noise margin;pull down driver transistors;random access memory;static random access memory;size 0 18 mum low power sram improved read static noise margin static random access memory preequalize scheme pull up driver transistors pull down driver transistors access transistor internal race write power off scheme write power consumption data drivers cmos process;write power consumption;cmos process;layout;size 0 18 mum;power supply;static noise margin;preequalize scheme;computer architecture;write power off scheme;internal race;low power;sram chips cmos digital integrated circuits;cmos digital integrated circuits;transistors;driver circuits;low power sram;power reduction;power consumption;data drivers;random access memory driver circuits sram chips geometry inverters noise reduction signal to noise ratio degradation energy consumption power supplies;pull up driver transistors;power demand;access transistor;sram chips	An efficient static random access memory (SRAM) is presented in this paper. By using a newly developed architecture based on ldquopreequalizerdquo scheme, the geometry ratio between the pull-up and pull-down driver transistors of conventional 6-T cell will be similar to that of familiar inverter, thereby making the SRAM be provided with an improved read static noise margin (SNM) and a reduced cell area. The removal of DC path resulting from preequalize also yields significant power reduction. To avoid a write speed degradation caused by the internal race on cell current between the pull-up driver transistor and access transistor, a write-power-off scheme is proposed. To further decrease the write power consumption, data drivers are connected to the bit lines instead of the conventional power supply terminals. A 4-kb-capacity test prototype has been designed in a 0.18-mum CMOS process. Achievable power reduction for the proposed SRAM is approximately 16% according to the post-layout simulation results (with the parasitics extracted), compared to that designed in the conventional architecture.	cmos;elegant degradation;interprocedural optimization;low-power broadcasting;noise margin;power inverter;power supply;prototype;random access;shutdown (computing);simulation;static random-access memory;transistor	Cihun-Siyong Alex Gong;Ci-Tong Hong;Kai-Wen Yao;Muh-Tian Shiue;Kuo-Hsing Cheng	2008	2008 15th IEEE International Conference on Electronics, Circuits and Systems	10.1109/ICECS.2008.4674911	embedded system;electronic engineering;real-time computing;engineering	EDA	17.458404138354187	58.752749389108494	123205
8a2ec4c9859065ffb6ab8ac61e789df38f83f911	a new methodology to design low-power asynchronous circuits	modelizacion;diseno circuito;design tool;haute performance;metodologia;caracteristique temporelle;integrated circuit;circuit retard;implementation;estudio comparativo;circuit design;circuito integrado;synthese haut niveau;delay insensitive;methodologie;time curve;asynchronous circuit;sintesis alto nivel;experimental result;modelisation;etude comparative;ejecucion;high level synthesis;low power;circuit asynchrone;circuit synchrone;comparative study;resultado experimental;caracteristica temporal;puissance faible;alto rendimiento;circuito asincrono;conception circuit;circuito retardo;methodology;resultat experimental;circuito sincrono;modeling;high performance;delay circuit;circuit integre;synchronous circuit;potencia debil	The aim of this paper is to present a new approach to creating high performance and low-power asynchronous circuits using high level design tools. In order to achieve this, we introduce a new timing model called Pseudo Delay-Insensitive model. To prove the goodness of this model, we present the results after comparing, for a set of benchmarks, our implementation with other implementations (synchronous and asynchronous).		Oscar Garnica;Juan Lanchares;Román Hermida	2002		10.1007/3-540-45716-X_12	asynchronous system;systems modeling;asynchronous circuit;telecommunications;computer science;electrical engineering;integrated circuit;circuit design;comparative research;methodology;synchronous circuit;high-level synthesis;implementation;algorithm;synchronizer	EDA	18.39508675124566	54.52216250856585	123427
3a3a51588f8a28698bc5b1fd5a65c62328c3d233	enhanced equivalence checking: toward a solidarity of functional verification and manufacturing test generation	presilicon debug effort enhanced equivalence checking functional verification manufacturing test generation motorola powerpc design group switch model rectifying constraint;functional verification;logic design;logic testing logic design;logic testing;test generation;equivalence checking;group presentation;circuit testing virtual manufacturing circuit simulation hardware design languages automatic testing semiconductor device testing automatic test pattern generation manufacturing automation switching circuits silicon	This article, from the Motorola (now Freescale) PowerPC design group, presents an interesting synergy among test, equivalence verification, and constraints. The authors use RTL, gate, and switch models of a design in two different flows one for test and one for functional verification to show that rectifying constraints and merging tests between the-two flows saves significant presilicon debug effort.	formal equivalence checking;powerpc;rectifier;synergy;turing completeness	Jayanta Bhadra;Narayanan Krishnamurthy;Magdy S. Abadir	2004	IEEE Design & Test of Computers	10.1109/MDT.2004.87	embedded system;electronic engineering;logic synthesis;real-time computing;computer science;design for testing;formal equivalence checking;high-level verification;intelligent verification;functional verification;computer engineering	EDA	10.415134444212837	52.962456172535916	123557
ab1aa9f7847f9fb63c4dbc39c924d25c737df586	time-multiplexed data flow graph for the design of configurable multiplier block	digital signal processing;high level synthesis algorithm logic complexity reconfigurable multiplier block minimization problem scheduled time multiplexed data flow graph optimization process;complexity theory;high level synthesis data flow graphs formal logic;logic design;data flow graphs;reconfigurable multiplier block;optimization process;finite impulse response filter;flow graphs;multiplexing;arrays;data flow graph;high level synthesis;scheduled time multiplexed data flow graph;minimization problem;adders;digital filters;logic complexity;formal logic;high level synthesis algorithm;signal processing algorithms;frequency;algorithm design and analysis;flow graphs finite impulse response filter signal processing algorithms design methodology logic design frequency digital filters digital signal processing adders hardware;hardware;design methodology	This paper proposes a new design methodology to reduce the logic complexity of reconfigurable multiplier block (ReMB). The minimization problem is modeled as a scheduled time-multiplexed data flow graph (TDFG). To reduce the number of operators to be scheduled in the DFG, the most dominant common subexpressions are greedily identified and eliminated based on the subexpressions' frequencies which are updated dynamically in the optimization process. High level synthesis algorithm is then employed to perform the scheduling of operators to control steps. By binding the compatible operators in the same control steps, more operators can be saved. Two design examples are used to demonstrate the effectiveness of the proposed algorithm. On average, the logic complexity of the proposed ReMB design is about 19% lower than that of the classical ReMB methods, and 7% lower than that of the latest and most competitive ReMB design methodology.	asynchronous array of simple processors;computational complexity theory;dataflow;finite impulse response;greedy algorithm;heuristic;high-level synthesis;mathematical optimization;multiplexing;reconfigurable computing;scheduling (computing)	Jiajia Chen;Chip Hong Chang;Ching-Chuen Jong	2009	2009 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2009.5117963	algorithm design;electronic engineering;discrete mathematics;logic synthesis;digital filter;design methods;computer science;electrical engineering;theoretical computer science;digital signal processing;finite impulse response;data-flow analysis;frequency;high-level synthesis;logic;multiplexing;adder	EDA	13.858811057548284	46.92118911140889	123668
581b48a1c3d004f22376e7e25629ad5dbbc11ccf	ultra-low voltage datapath blocks in 28nm utbb fd-soi	multiply accumulate;cmos integrated circuits;mos devices;subthreshold;logic gates voltage measurement energy consumption energy measurement transistors mos devices cmos integrated circuits;voltage 0 5 v ultra low voltage datapath blocks multiply accumulate datapath block utbb fd soi technology leakage reduction strategies supply voltages energy consumption extensive back gate biasing range minimum energy point speed energy trade off size 28 nm energy 0 17 pj frequency 35 mhz voltage 250 mv;silicon on insulator;silicon on insulator energy consumption integrated circuit design;nearthreshold;ultra low energy;logic gates;energy measurement;energy consumption;transistors;low voltage operation;minimum energy point;voltage measurement;28nm utbb fd soi	This paper demonstrates a wide supply range multiply-accumulate datapath block in 28nm UTBB FD-SOI technology. Variability and leakage reduction strategies are employed in this new technology to achieve a state-of-the-art low energy performance. The design uses a wide range of supply voltages to reduce energy consumption per operation. The extensive back-gate biasing range allows to adapt the minimum energy point (MEP) of the circuit to the desired workload. Measurements showcase the speed/energy trade-off of both the design and the technology and lead to a MEP of 0.17pJ at 35MHz with a supply voltage of 250mV and a back-gate bias of 0.5V.	biasing;datapath;die shrink;dynamic voltage scaling;heart rate variability;image scaling;instruction pipelining;media-embedded processor;multiply–accumulate operation;pipeline (computing);spectral leakage	Hans Reyserhove;Nele Reynders;Wim Dehaene	2014	2014 IEEE Asian Solid-State Circuits Conference (A-SSCC)	10.1109/ASSCC.2014.7008857	embedded system;electronic engineering;engineering;electrical engineering	EDA	16.28936386628861	57.11835874800702	123697
45a8d2b453f2b2fe309595ee11c5e42ab29f09cf	ic variability minimization using a new c/sub p/ and c/sub pk/ based variability/performance measure	minimisation;electric variables measurement circuit synthesis process control circuit optimization design for quality manufacturing integrated circuit yield automation minimization methods concrete;integrated circuit design minimisation circuit optimisation statistical analysis integrated circuit manufacture;integrated circuit design;statistical analysis;tuning methodology ic variability minimization capability indices variability performance measure design for quality statistical circuit design performance optimization;circuit optimisation;integrated circuit manufacture	"""A new performance measure, based on the capability indices C/sub p/ and C/sub pk/ (commonly used in process control), is proposed for general circuit Design for Quality. It overcomes some of the critical limitations of the traditional quadratic loss function (e.g., that of Taguchi) and leads to the creation of a new methodology for statistical circuit design. It also allows for the automation of the manual two-stage variability minimization/tuning methodology, and gives a concrete interpretation to the """"goodness"""" of a circuit in easy to understand terms. Successful IC variability/performance optimization examples are presented. >"""	spatial variability	Syed A. Aftab;M. A. Styblinski	1994		10.1109/ISCAS.1994.408777	physical design;reliability engineering;minimisation;electronic engineering;engineering;mathematics;circuit extraction;engineering drawing;statistics;integrated circuit design	NLP	23.845866330491663	56.30251485733462	123733
dbc3afac5b2643c98404bf06580df638dfed813c	feasibility studies of eeprom memory implementations in vestic technology		This paper reports a preliminary feasibility study of non-volatile semiconductor memories in VeSTIC technology (Vertical Slit Transistor-based Integrated Circuits). The basic concept of this technology, invented over a decade ago, is a novel 3D architecture, which enables high regularity of the circuit layout and is 3D integration ready. Between evenly distributed vertical pillars, being electrical contacts going all the way through the device layer, all kinds of transistors can be fabricated, and integration of logic components in canvas of density characteristic for memories is accessible. Based on numerical simulations we indicated feasibility of certain EEPROM implementations in VESTICs.	circuit diagram;eeprom;integrated circuit;non-volatile memory;numerical analysis;semiconductor memory;simulation;transistor	Bartosz Dec;Andrzej Pfitzner	2018	"""2018 25th International Conference """"Mixed Design of Integrated Circuits and System"""" (MIXDES)"""	10.23919/MIXDES.2018.8436679	electronic engineering;architecture;eeprom;implementation;computer science;electrical contacts;semiconductor;transistor;integrated circuit	EDA	13.042060426353064	59.02007119429818	123746
6dfac50a2bd2fd9474958ae81524c7df1c010227	a highly efficient method for extracting fsms from flattened gate-level netlist	strongly connected component;microcontrollers;design automation;flattened gate level netlist;inverters;finite state machines;logic gates;registers;feature extraction;control intensive circuits fsm flattened gate level netlist finite state machines state register elimination technique;fsm;microcontrollers circuit cad finite state machines;control intensive circuits;circuit cad;registers digital circuits microcontrollers circuit synthesis design automation logic signal processing automata hardware design languages continuous wavelet transforms;digital circuits;state register elimination technique;finite state machine;extraction method	This paper proposes a novel method for extracting Finite State Machines (FSMs) from flattened gate-level netlist. The proposed method which employs a potential state register elimination technique and a two-level FSM separation strategy is highly applicable to control-intensive circuits. The potential state register elimination technique is based on control signal identification whereas the two-level FSM separation strategy is based on enable tree identification and the strongly connected components algorithm. To demonstrate the efficacy and to illustrate the unique features of the proposed FSM extraction method, the Synopsys DesignWare DW8051 microcontroller is used as the benchmark circuit for comparison and simulations. Results show that the proposed method reduces the complexity of the extracted FSMs in terms of number of state registers in an FSM by more than 90% as compared to the reported technique.	algorithm;benchmark (computing);finite-state machine;microcontroller;netlist;simulation;strongly connected component	Yiqiong Shi;Chan Wai Ting;Bah-Hwee Gwee;Ye Ren	2010	Proceedings of 2010 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2010.5537093	microcontroller;embedded system;electronic engineering;real-time computing;logic gate;feature extraction;computer science;electrical engineering;theoretical computer science;operating system;processor register;finite-state machine;digital electronics;strongly connected component	EDA	17.57059805522066	48.725659459647346	124020
135ba369dbe586e668f2d3fc581181746c841da0	efficient technique to reduce gate evaluations and speed up fault simulation	circuit faults circuit simulation central processing unit circuit testing jacobian matrices logic circuits sun discrete event simulation electrical fault detection fault detection;circuit faults;fault simulation;logic circuits;circuit simulation;fault detection;sun;circuit testing;jacobian matrices;electrical fault detection;central processing unit;discrete event simulation		simulation	P. R. Suresh Kumar;Mandyam-Komar Srinivas;James Jacob	1993		10.1109/ICVD.1993.669650	embedded system;electronic engineering;fault;real-time computing;fault coverage;logic gate;fault indicator;computer science;stuck-at fault;discrete event simulation;operating system;central processing unit;circuit extraction;fault detection and isolation	EDA	20.115663342054955	49.83395933072501	124066
cce0f7c449237e3d19c3f145fae92b284e6203bc	functional yield enhancement and statistical design of a low power transconductor	power supplies;low power electronics integrated circuit yield design of experiments vlsi integrated circuit design integrated circuit reliability circuit simulation surface fitting mos analogue integrated circuits integrated circuit modelling;process variation;functional yield enhancement;reliability;response surface methodology;transconductors;integrated circuit yield;design of experiment techniques;very large scale integration;inter die process variations;low power transconductor;surface fitting;power supply voltages;vlsi design;statistical mos model;power supply;integrated circuit design;circuit simulation;deep submicron ranges;design of experiments;low power;saturation region;integrated circuit modelling;analog integrated circuits;mos analogue integrated circuits;voltage;low power electronics;fully balanced input signals;vlsi;robustness;statistical mos model functional yield enhancement statistical design low power transconductor vlsi design feature sizes deep submicron ranges power supply voltages device mismatch inter die process variations reliability analog integrated circuits intra die variations saturation region fully balanced input signals circuit simulation response surface methodology design of experiment techniques smos model;statistical design;smos model;device mismatch;integrated circuit reliability;integrated circuit yield very large scale integration power supplies voltage integrated circuit reliability analog integrated circuits transconductors robustness circuit simulation response surface methodology;intra die variations;feature sizes;design of experiment	The functional yield is becoming increasingly critical in VLSI design. As feature sizes move into the deep submicron ranges and power supply voltages are reduced, the effect of both device mismatch and inter-die process variations on the performance and reliability of analog integrated circuits is magnified. The statistical MOS (SMOS) model accounts for both inter-die and intra-die variations. A new transconductor, statistically robust with good yield is discussed in this paper. The circuit operates in the saturation region with fully balanced input signals. Initial circuit simulation results have been given. Response Surface Methodology (RSM) and Design of Experiment (DOE) techniques were used as statistical VLSI design tools combined with the SMOS model. Device size optimization and yield enhancement have been demonstrated.		Tuna B. Tarim;Mohammed Ismail	1999		10.1109/ISCAS.1999.780757	control engineering;electronic engineering;computer science;engineering;electrical engineering;mathematics;very-large-scale integration;design of experiments;statistics	EDA	20.644020707813795	57.14151850836807	124148
5b039e914c29ba7810a29491fbc032b834c65062	measuring area-complexity using boolean difference	logic design area measurement boolean functions circuit complexity combinational circuits;gate libraries area complexity measurement boolean difference combinational circuit logic area estimation primary input outputs taylor expansion boolean functions boolean derivatives mcnc benchmark suite randomly generated circuits literal count based techniques bdd properties gate synthesis abc;logic design;boolean functions;logic synthesis area complexity boolean difference;circuit complexity;logic synthesis;area complexity;boolean functions logic gates area measurement complexity theory taylor series benchmark testing;area measurement;boolean difference;combinational circuits	For a combinational circuit, area-complexity is a measure that estimates the logic area of the circuit without mapping to logic gates. Several measures like literal count, number of primary input/outputs, etc. have been used in the past as area-complexity metrics. In this paper, we propose a novel area-complexity measure using the theory of Boolean difference and Taylor expansion for Boolean functions. We demonstrate how to capture the area-complexity of a Boolean function using the complexity of its Boolean derivatives. We evaluate the metric on circuits from MCNC benchmark suite and a sizeable collection of randomly generated circuits. We compare our metric with existing techniques based on literal-count and BDD properties. We show that the new area-complexity measure is accurate within 10% of the actual number of gates synthesized using ABC as opposed to at least 100% and 15% for the metrics based on literal-count and BDD properties respectively. We also show the robustness of our metric across three different gate-libraries.	benchmark (computing);blum axioms;combinational logic;computational complexity theory;gate count;library (computing);literal (computer programming);literal (mathematical logic);logic gate;logic synthesis;procedural generation;randomness;scalability	Ankit Kagliwal;Shankar Balachandran	2013	2013 26th International Conference on VLSI Design and 2013 12th International Conference on Embedded Systems	10.1109/VLSID.2013.195	circuit complexity;boolean algebra;boolean circuit;and-inverter graph;circuit minimization for boolean functions;discrete mathematics;reed–muller expansion;logic synthesis;boolean network;boolean domain;majority function;boolean expression;product term;standard boolean model;computer science;maximum satisfiability problem;theoretical computer science;functional completeness;mathematics;combinational logic;boolean function;algorithm;parity function	EDA	18.52498906624765	46.596652124698096	124293
4f03590c0fe9658ea9b1374ae471fdca198cfd08	fast statistical analysis of rare circuit failure events via bayesian scaled-sigma sampling for high-dimensional variation space	decision support systems	Accurately estimating the rare failure events of nanoscale ICs in a high-dimensional variation space is extremely challenging. In this paper, we propose a novel Bayesian scaled-sigma sampling (BSSS) technique to address this technical challenge. BSSS can be considered as an extension of the traditional scaled-sigma sampling (SSS) approach. The key idea is to explore the “similarity” between different SSS models fitted at different design stages and encode it as our prior knowledge. Bayesian model fusion is then adopted to fit the SSS model with consideration of the prior knowledge. A sense amplifier example designed in a 45 nm CMOS process is used to demonstrate the efficacy of BSSS. Experimental results demonstrate that BSSS achieves superior accuracy over the conventional SSS and minimum-norm importance sampling approaches when a few hundred random variables are used to model process variations.	bayesian network;boson sampling;cmos;encode;importance sampling;sampling (signal processing);sense amplifier	Shupeng Sun;Xin Li	2015	2015 IEEE Custom Integrated Circuits Conference (CICC)	10.1109/CICC.2015.7338409	simulation;computer science;data mining	EDA	22.963719615631728	59.4789765110871	124382
84b3cc4402bb9933151407aa6e30c5452a12cf7d	asynchronously assisted fpga for variability	silicon;variation tolerance variability asynchronous afpga;clocks;logic design asynchronous circuits capacitor switching field programmable gate arrays;logic gates;field programmable gate arrays switches silicon clocks logic gates;field programmable gate arrays;switches;randomly variable energy harvester voltage supply asynchronously assisted fpga variability effect technology geometry scaling asynchronous assisting logic blocks fpga architecture wide range latency variations parametric variation temperature voltage fluctuation supply voltage fluctuation variation map availability configurable aal blocks variation critical paths size overhead asynchronous designs design flow reuse capacitor switching energy harvester voltage supply regularly variable energy harvester voltage supply	The effect of variability has become increasingly significant as a result of technology geometry scaling. This paper describes Asynchronous Assisting Logic (AAL) blocks and the method of introducing them into modern FPGA architecture, in order to increase tolerance of the wide range latency variations caused by parametric variation, and temperature and supply voltage fluctuations. The proposed method leverages the availability of variation maps and suggests deploying configurable AAL blocks only into the variation critical paths - reinforcing rather rerouting/remapping. This method reduces the size overhead significantly which normally will be incurred by fully asynchronous designs. The proposed technique maintains the existing FPGA architecture allowing potential reuse of design flow. Simulations show correct functionality given regularly variable, randomly variable and capacitor switching energy harvester voltage supplies.	atm adaptation layer;bioinformatic harvester;computer simulation;design flow (eda);field-programmable gate array;image scaling;map;overhead (computing);randomness;spatial variability	Hock Soon Low;Delong Shang;Fei Xia;Alexandre Yakovlev	2014	2014 24th International Conference on Field Programmable Logic and Applications (FPL)	10.1109/FPL.2014.6927398	embedded system;real-time computing;logic gate;network switch;computer science;silicon;field-programmable gate array	EDA	20.904492009320695	56.20252778388626	124526
309a9f049595dc5c3d6b0995aa214b536735a9fe	read/write robustness estimation metrics for spin transfer torque (stt) mram cell	measurement;magnetization;robustness;thermal stability;resistance;stt mram;embedded systems;switches;estimation theory;probability	The rapid development of low power, high density, high performance SoCs has pushed the embedded memories to their limits and opened the field to the development of emerging memory technologies. The Spin-Transfer-Torque Magnetic Random Access Memory (STT-MRAM) has emerged as a promising choice for embedded memories due to its reduced read/write latency and high CMOS integration capability. Under today aggressive technology scaling requirements, the STT-MRAM is affected by process variability making robustness evaluation an important concern. In this paper, we provide new metrics for robustness prediction of an STT-MRAM memory cell. Independent Robustness Margin metrics are defined for Read Operation and Write Operation based on the electrical characteristics of the memory cell and the fabrication induced variability. These metrics are used to estimate the extreme parameter variation causing the cell failure, Current Noise Margins and the Failure Probability of the STT-MRAM cell.	automation;cmos;embedded system;heart rate variability;image scaling;magnetoresistive random-access memory;memory cell (binary);noise margin;product binning;rm-odp;random access;read-modify-write;requirement;spatial variability;system on a chip;test engineer	Elena I. Vatajelu;Rosa Rodríguez-Montañés;Marco Indaco;Michel Renovell;Paolo Prinetto;Joan Figueras	2015	2015 Design, Automation & Test in Europe Conference & Exhibition (DATE)		electronic engineering;parallel computing;real-time computing;computer science;programming language;magnetoresistive random-access memory;robustness	EDA	19.30797966172989	60.0915893477736	124586
fc12e03744e276cde26ec0fb50a197029ecab61a	programmable leakage test and binning for tsvs with self-timed timing control	programmable logic devices;through silicon via 3 d ic design for testability leakage binning leakage test;through silicon vias delays clocks capacitance leakage currents circuit faults;timing circuits;logic gates;timing circuits logic gates programmable logic devices three dimensional integrated circuits;common design flow programmable leakage test binning tsv through silicon vias 3d ic testable leakage current flexible test threshold setting leakage characterization wait time generation programmable delay line wait time propagation self timed timing control timing skew problem signal routing logic gates;three dimensional integrated circuits	Leakage tests have been a challenge for through-silicon vias (TSVs) in a 3-D IC. Most existing methods are still inadequate in terms of the range of testable leakage currents. In this paper, we borrow the wisdom of the IO-pin leakage test while enhancing it with two features. First, we make it more suitable for a TSV, which has a much smaller capacitance than an IO pin. Second, we support a wide range of leakage test (e.g., from 0.125 μA to 16 μA), and thereby allowing for flexible test threshold setting and leakage characterization. To achieve this goal, we present two sets of techniques-1) wait-time generation by programmable delay line, and 2) wait-time propagation with a self-timed timing control scheme to overcome the timing skew problem due to signal routing. We demonstrate that the entire scheme can be done in only logic gates, making it easy to integrate into the common design flow.	analog delay line;approximation algorithm;clock skew;delay line memory;fits;information leakage;logic gate;product binning;routing;sap composite application framework;software propagation;spectral leakage;through-silicon via;via (electronics)	Shi-Yu Huang;Yu-Hsiang Lin;Li-Ren Huang;Kun-Han Tsai;Wu-Tung Cheng	2013	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2013.2252056	embedded system;electronic engineering;real-time computing;logic gate;programmable logic array;computer science;engineering;programmable logic device	EDA	20.974404609337423	55.69115814187558	124656
a110cd155173346d8ad3f2e0e1dd2514fb151101	t-shaped association of transistors: modeling of multiple channel lengths and regular associations	t shaped transistor association;reliability;multiple channel length modeling;measurement;multiple channels;performance;transistor circuits analogue integrated circuits integrated circuit design integrated circuit modelling integrated circuit reliability mosfet semiconductor device models;analog design;regular association modeling;composite transistor;integrated circuit design;analogue integrated circuits;integrated circuit modelling;analog integrated circuits;semiconductor device models;mosfet t shaped transistor association composite transistor multiple channel length modeling regular association modeling analog integrated circuit design integrated circuit reliability;transistor circuits;associations of transistors;design;mosfet;analog integrated circuit design;integrated circuit reliability;integrated circuit modeling analog integrated circuits 1f noise circuit simulation mosfet circuits shape informatics degradation design methodology circuit synthesis;modeling;modeling measurement performance design reliability mosfet associations of transistors analog design;high frequency;series parallel;design methodology	This work presents an analysis of a new type of composite transistor specially suited for the design of analog integrated circuits: the T-shape association of transistors. This association is composed by non-equal size unit transistors arranged in a series-parallel array with common gate, which can substitute the conventional rectangular transistors with advantages in some aspects, such as better high-frequency performance, lower output conductance and layout regularity. Dedicated tools that automatically translate the single transistors into equivalent associations without degradation in the overall circuit specifications guarantee the compatibility with the conventional analog design methodology. Some properties and applications are discussed in this paper. Experimental and simulated characteristics are shown in order to verify the behavior of the association.	conductance (graph);elegant degradation;integrated circuit;parallel array;series-parallel graph;transistor	Alessandro Girardi;Fernando da Rocha Paixão Cortes;Eduardo Conrad;Sergio Bampi	2005	2005 18th Symposium on Integrated Circuits and Systems Design	10.1145/1081081.1081094	control engineering;design;electronic engineering;performance;engineering;electrical engineering;high frequency;reliability;measurement;statistics;integrated circuit design	EDA	23.622119630857853	56.79152528883802	124728
54e90a1a6ddfd073aeff5e13770d51f173045366	a multilevel hierarchical interconnection structure for fpga	software tool;design generator;network connectivity;ip;fpga resource estimation;software development;discrete fourier transform;programmable networks	Creation of large FPGAs needs radical efficient changes in architecture to improve speed, density and software mapping time. Based on industry experience with standard ASICs, we believe that partitioning and hierarchy become an obligation for FPGA hardware and software developments. As an alternative we propose a new Multilevel hierarchical FPGA (MFPGA) architecture where logic blocks and routing resources are sparsely partitioned into multilevel clustered structure. Since the routing resources consume most of the FPGA area, we focus on interconnect check. We try to achieve the best area efficiency by balancing interconnect and logic block utilization. The proposed MFPGA interconnect unifies two unidirectional programmable networks: A downward network based on the Butterfly-Fat-Tree topology, and an upward network that uses hierarchy. The Downward network uses linear populated and unidirectional switch boxes and gives one path from each wire-source in the top to each leaf (logic block) in the lowest level. The upward network connects the logic blocks outputs and the input pads to the different levels of the downward network. Studies based on the Rent's Rule show that wiring and switch requirements in the MFPGA grow slower than in traditional topologies. We used MCNC benchmark circuits to compare the switch and area requirements between our MFPGA architecture and the traditional mesh topology. New software tools for placement and routing were developed to conduct this study on the MFPGA architecture. Expermimental results show that MFPGA can implement circuits with fewer switches and a smaller total area than mesh architecture.	application-specific integrated circuit;benchmark (computing);fat tree;field-programmable gate array;interconnection;logic block;mesh networking;network switch;place and route;population;rent's rule;requirement;routing;tree network;wiring	Hayder Mrabet;Zied Marrakchi;Pierre Souillot;Habib Mehrez	2006		10.1145/1117201.1117239	internet protocol;embedded system;parallel computing;real-time computing;computer science;software development;operating system;discrete fourier transform	EDA	12.470976336184291	52.102812654874654	124746
11a1faae53bc138e3779789e106eb28e571baadb	towards an effective iddq test vector selection and application methodology	circuit testing circuit faults system testing very large scale integration costs cmos technology monitoring capacitance telecommunications phasor measurement units;cmos digital integrated circuits;application specific integrated circuits;subscriber loops;200 ms i sub ddq test vector selection clsi asymmetric digital subscriber line pseudo stuck at fault coverage wafer level fault coverage production environment functional failures extrapolation slip through non quality costs repair costs asics;integrated circuit testing;vlsi;fault coverage;application specific integrated circuits cmos digital integrated circuits integrated circuit testing vlsi subscriber loops fault location production testing;asymmetric digital subscriber line;production testing;fault location	We show that that for a complex CLSI (1.4 A4 transistor; used in the Asymmetric Digital Subscriber Line product range}, 632 IDDQ measurements are needed to obtain 94% pseudo stuck-at fault coverage. The I’DQ test takes less than 200 ms on the VLSI test system, which is between 100 to 300 times faster compared to the use of a PMU. In addition, the OCIMU IDDQ monitor is built into our VLSI test system allowing IDDQ tests at wafer level without placing active components on the load board. This IDDQ methodology applies many IDDQ vectors, achieves a high fault coverage and is feasible in a production environment. Correlation between functional failures and IDDQ failures is around 70 %for three CLSI designs. Extrapolation implies that the slip-through (i.e. bad devices that pass all tests) can be reduced by 70 % by augmenting the test program with an IDDQ test. As a consequence, the non-quality costs can be reduced significantly depending on the slip-through figures, component and repair costs.	asymmetric digital subscriber line;deployment environment;extrapolation;fault coverage;iddq testing;power management unit;slip (programming language);stuck-at fault;test vector;transistor;very-large-scale integration	Jos van Sas;Urbain Swerts;Marc Darquennes	1996		10.1109/TEST.1996.557068	reliability engineering;embedded system;electronic engineering;fault coverage;telecommunications;computer science;engineering;electrical engineering;application-specific integrated circuit;very-large-scale integration;asymmetric digital subscriber line	EDA	22.493152160669442	54.05868939271043	124811
98768ac8bd3bf04cec0bcba644e08e0bb9e78a8b	dynamic cmos noise immunity estimation in submicron regime	velocity saturation noise immunity estimation submicron regime models dynamic cmos circuits maximum safe amplitude pulse duration circuit parameters mobility degradation;logic design;system performance;circuit noise semiconductor device modeling clocks working environment noise pulse circuits voltage noise level space vector pulse width modulation degradation cmos technology;integrated circuit modelling;system design;cmos logic circuits;logic design cmos logic circuits integrated circuit noise integrated circuit modelling carrier mobility;integrated circuit noise;carrier mobility	Noise may limit system performance, or it may push the system to malfunction. So, a good system design has to take care of the noise problem. This paper addresses this issue and presents models to compute the noise immunity of dynamic CMOS circuits in submicron regime. Our models compute the maximum safe amplitude of a noise pulse in terms of the pulse duration as well as the circuit parameters. Also in these models the mobility degradation and velocity saturation have been taken in account. We have considered the cases where noise pulse is applied to one of the circuit inputs or the clock input. HSPICE simulations confirm the validity of these models.	cmos;care-of address;elegant degradation;pulse duration;spice 2;simulation;systems design;velocity (software development)	Adnan Kabbani;Asim J. Al-Khalili	1999		10.1109/ISCAS.1999.777945	flicker noise;control engineering;effective input noise temperature;electronic engineering;electron mobility;logic synthesis;asynchronous circuit;noise temperature;computer science;engineering;electrical engineering;noise;computer performance;integrated injection logic;systems design	EDA	22.045034517214262	57.83651970489582	125072
08e70b2dcf0385529ffa6e6e90964ce50cc6ba5e	a new circuit placement program for fet chips	cross column wire;fet circuit;fet chip;circuit location;circuit position;new circuit placement program;new solution;circuit orientation;global solution;column peak;cross column wiring;new approach;chip;physical design;iterative methods;shape;minimization;automatic control;natural selection	A new solution to the problem of automated placement of FET circuits has been implemented. This new approach automatically realizes a global solution to the problem yielding circuit location, circuit orientation, all cross column wires and blanks between circuits, thus eliminating many of the most tedious and error prone steps in physical design.  The technique is based upon “natural selection” and obtains a solution using a series of sweeps through the columns evolving circuit position and cross column wiring assignments together. Scoring is done to minimize column peaks.	cognitive dimensions of notations;column (database);physical design (electronics);wiring	K. W. Lallier;R. K. Jackson	1979	16th Design Automation Conference		chip;physical design;embedded system;natural selection;electronic engineering;telecommunications;shape;engineering;electrical engineering;automatic control;iterative method;engineering drawing	EDA	14.65760549338573	50.590266156365395	125347
564e315edfd9ff26eb3021fd989c7bb179b9daf5	finite automata and badly timed elements	computers;finite element methods;reliability;art;complexity theory;history;clocks;sequential circuits;logic;wires;contracts;worst case analysis;junctions;reliability theory;automata history upper bound timing logic switches hardware sequential circuits circuit synthesis signal synthesis;upper bound;automata;redundancy;logic gates;synchronization;finite automata;joining processes;signal synthesis;electrical engineering;switches;dispersion;construction;lower bound;circuit synthesis;hardware;timing	This paper summarizes some rather extensive research on the problem of constructing logic nets out of elements whose timing causes trouble either in their slowness or in their lack of precision. The problem is made precise by setting up a theory of logic nets that is abstract but realistic. Its abstractness consists in its lack of similarity to any particular hardware, and in its strictly mathematical formulation, which leaves many engineering problems out of consideration. Its realism consists in its adherence to several stipulations: (S1) There is an upper bound on the fan-in and fan-out of any element. (S2) There is an upper bound on the number of elements that can occupy a given area or volume of space. (S3) There is an upper bound on the distance between two elements that are directly connected together. (S4) There is a lower bound, greater than zero, on the time of operation of any element. (S5) The timing of any element is not precisely predictable; all that is known about how long it will take to switch is an upper bound and a lower bound; beyond this knowledge, the timing is not even statistically predictable. There is theoretical justification in our having assumed, unrealistically that elements never malfunction or wear out. The theory affords a way of constructing, with a constant repetition rate, all finite automata as asynchronous nets that will withstand a worst-case analysis. Similar work by others is compared.	automata theory;finite element method;finite-state machine;timed event system	Robert McNaughton	1963		10.1109/SWCT.1963.5	combinatorics;discrete mathematics;computer science;theoretical computer science;mathematics;finite-state machine;upper and lower bounds;algorithm	Logic	23.44670375395165	47.25240047387588	125366
0e56c70180d22984d6559d4153cda74a4fc1dfd0	efficient automatic resolution of encoding conflicts using stg unfoldings	libraries;memory consumption asynchronous circuit synthesis signal transition graph unfolding state encoding conflict resolution sat solver;state space methods;network synthesis;dr victor khomenko;encoding circuit synthesis state space methods signal resolution signal synthesis asynchronous circuits logic libraries explosions size control;state encoding conflict resolution;asynchronous circuit synthesis;memory consumption;computability;logic;indexing terms;size control;asynchronous circuit;eprints newcastle university;logic synthesis;state space;open access;signal resolution;asynchronous circuits;explosions;petri nets asynchronous circuits computability encoding network synthesis;signal synthesis;petri nets;sat solver;petri net;encoding;signal transition graph unfolding;circuit synthesis	Synthesis of asynchronous circuits from signal transition graphs (STGs) involves resolution of state encoding conflicts by means of refining the STG specification. In this paper, a fully automatic technique for resolving such conflicts by means of insertion of new signals and concurrency reduction is proposed. It is based on conflict cores, i.e., sets of transitions causing encoding conflicts, which are represented at the level of finite and complete unfolding prefixes, and a SAT solver is used to find where in the STG the transitions of new signals should be inserted and to check the validity of concurrency reductions. The experimental results show significant improvements over the state space based approach in terms of runtime and memory consumption, as well as some improvements in the quality of the resulting circuits.	academy;boolean satisfiability problem;concurrency (computer science);design space exploration;display resolution;expectation propagation;heuristic;loss function;multiversion concurrency control;signal transition;solver;star trek generations;state space;unfolding (dsp implementation)	Victor Khomenko	2007	Seventh International Conference on Application of Concurrency to System Design (ACSD 2007)	10.1109/ACSD.2007.48	computer science;theoretical computer science;petri net;algorithm	EDA	19.402512905285366	47.40399092102019	125402
7f01e1cb72bfc4b6c0651431554d30eadb8f4b3f	top-level activity-driven clock tree synthesis with clock skew variation considered	topology;clocks power demand logic gates timing capacitance wires topology;top level clock tree clock gating clock skew clock tree synthesis low power on chip variation;synchronisation clocks integrated circuit design integrated logic circuits low power electronics power consumption;clocks;wires;logic gates;timing slack top level activity driven clock tree synthesis clock skew variation clock gating dynamic power consumption low power designs on chip variation ocv;capacitance;power demand;timing	Clock gating is recognized as one of the most effective techniques to reduce the dynamic power consumption. Many research efforts have been paid to build activity-driven clock trees for low power designs. On the other hand, as the feature size continues to shrink, the on-chip-variation (OCV) effect has become a serious concern, especially for the clock skew of the top-level clock tree. Based on this observation, in this paper, we present the first work for the synthesis of OCV-aware top-level activity-driven clock trees. In our approach, the clock skew variation is considered during the top-level activity-driven clock tree synthesis. Our objective is to minimize the weighted sum of the worst timing slack and the power consumption. Compared with previous works, benchmark data consistently show that our approach can greatly increase the worst timing slack with a small overhead on the power consumption.	benchmark (computing);clock gating;clock signal;clock skew;overhead (computing);process corners;slack variable;weight function	Te-Jui Wang;Shih-Hsu Huang;Wei-Kai Cheng;Yih-Chih Chou	2016	2016 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2016.7539123	clock synchronization;electronic engineering;parallel computing;real-time computing;asynchronous circuit;logic gate;clock domain crossing;clock skew;computer science;engineering;clock rate;underclocking;timing failure;capacitance;clock drift;synchronous circuit;clock gating;digital clock manager;static timing analysis;clock signal;cpu multiplier	EDA	16.65821175685968	55.16805278509215	125495
2e2d66215614e474e59abd5f2dd4aab2c811998a	pattern sensitive fault testing of rams with bullt-in ecc	rams;reliability engineering;random access memory;error correction codes;circuit faults;efficient algorithm;separable linear codes;built in ecc;random access storage built in self test error correction codes fault location;pattern sensitive fault testing;error correction coding;satisfiability;upper bound;information bits;built in self test;error correction code;error correction;linear code;arbitrary patterns;computer aided manufacturing;logic testing;random access storage;check bits;circuit testing;n bit memory array;error correction codes read write memory circuit testing random access memory logic testing circuit faults computer aided manufacturing error correction reliability engineering alpha particles;n bit memory array pattern sensitive fault testing rams built in ecc error correction coding separable linear codes arbitrary patterns upper bound information bits check bits;read write memory;reading and writing;alpha particles;fault location	The problem of testing RAMs with different built-in error-correction-coding (ECC) capabilities is formulated. The basics of ECC in RAMs are reviewed, and some of the implementation aspects are described. It is shown that if memories using separable linear codes satisfy certain conditions, it is always possible to apply arbitrary patterns to all check bits. An upper bound on the number of writes required to apply the required patterns to a neighborhood is established. An efficient algorithm for testing the information bits and check bits of an N-bit memory array for 5 cell neighborhood pattern sensitive faults in O(N) reads and writes is provided. The use of the method is demonstrated by a case study. >	ecc memory	Manoj Franklin;Kewal K. Saluja	1991		10.1109/FTCS.1991.146690	parallel computing;computer hardware;computer science;theoretical computer science	SE	22.23647847635819	49.05281775933728	125545
fb4b8ba25cf14c5b02f9bc61a2ca8e58e7804b52	localization of faulty multi-output unit in discrete device		The matrix method for localization of a faulty block that was proposed earlier by the present author was considered as applied to a discrete device with multi-output blocks At that, the question of reducing the amount of the test hardware was solved by constructing appropriately the matrix of block outputs. An algorithm for such construction was given.	electronic component	G. P. Aksenova	2015	Automation and Remote Control	10.1134/S0005117915020095	discrete mathematics;theoretical computer science;mathematics;algorithm	Robotics	23.82465709824518	48.47895651946624	125548
1e4b45d45fd674404dfa969b0be2a482a6efa86e	tabu search based multiple voltage scheduling under both timing and resource constraints	convergence;vector representation multiple voltage scheduling tabu search;resource management;delays benchmark testing resource management power demand estimation convergence;estimation;power demand;search problems delay circuits linear network analysis low power electronics piecewise linear techniques power aware computing scheduling;benchmark testing;delays;tabu search based multiple voltage scheduling heuristic estimation delay adjustment delay assignment tabu search based algorithm power consumption	In this work, we address the multiple voltage scheduling problem to minimize power consumption under both timing and resource constraints. We develop a tabu search-based algorithm with a general vector representation of solution and an effective performance estimation. Moreover, our approach tends to solve a series of scheduling problems with respect to multiple voltage designs. Specifically, our method represents each solution by a vector of operation types and solves the scheduling subproblem corresponding to a certain solution vector. To get feasible solutions of the subproblem, a two-stage method is presented by first adopting the PLNSM algorithm [3] to generate delay assignment satisfying the timing constraint and then performing delay adjustment iteratively until the resource constraints are met. A heuristic estimation is introduced to predict the total power and resource usage of the neighborhood. Our proposed method achieves near-optimal solutions with only an average power increase of 0.84% compared with ILP for small-size designs, and a 24.1% reduction over a previous tabu search-based algorithm [7] for a set of benchmarks.	algorithm;benchmark (computing);heuristic;scheduling (computing);tabu search	Jianmo Ni;Nan Wang;Takeshi Yoshimura	2015	Sixteenth International Symposium on Quality Electronic Design	10.1109/ISQED.2015.7085410	fair-share scheduling;benchmark;mathematical optimization;estimation;real-time computing;convergence;tabu search;computer science;resource management;theoretical computer science;mathematics;statistics;guided local search	EDA	16.443217812995186	54.08954766938221	125598
c4f6131bc08cce255e6f4327087d4d72a359e5ae	retiming aware clustering for sequential circuits	cluster algorithm;field programmable gate arrays aware clustering retiming sequential circuits sequential retiming sequential clustering delay minimization fpga clustered circuits duplication control strategy node duplication mcnc benchmark circuits altera quartus show;sequential circuits;clustering algorithms sequential circuits delay effects design optimization clocks circuit testing minimization methods design automation large scale systems constraint optimization;delays circuit layout cad logic cad sequential circuits field programmable gate arrays timing;circuit layout cad;field programmable gate arrays;logic cad;control strategy;delays;timing	This work presents a simultaneous sequential retiming and clustering algorithm for delay minimization applicable to FPGAs. The algorithm is based on Pan et al.(1998) with several modifications and enhancements to improve the performance of the final clustered circuits. A duplication control strategy is used to reduce the amount of node duplication. Experimental results on the biggest MCNC benchmark circuits using Altera's Quartus show that our algorithm can increase the performance, on average, by almost 22% compared with the case when Quartus is used without our clustering information.	algorithm;benchmark (computing);cluster analysis;control theory;field-programmable gate array;retiming	Mehrdad Eslami Dehkordi;Stephen Dean Brown	2004	Proceedings. 2004 IEEE International Conference on Field- Programmable Technology (IEEE Cat. No.04EX921)	10.1109/FPT.2004.1393307	embedded system;parallel computing;real-time computing;computer science;sequential logic;field-programmable gate array	EDA	15.554762632191194	52.51829235568032	125716
5a3f773e6a932fdae05789758f7db63fbe66cf48	bist method for die-level process parameter variation monitoring in analog/mixed-signal integrated circuits	process variation;and mixed signal;specification based testing;signal integrity;chip;process monitoring;built in self test;process parameters	This paper reports a new built-in self-test scheme for analog and mixed-signal devices based on die-level process monitoring. The objective of this test is not to replace traditional specification-based tests, but to provide a reliable method for early identification of excessive process parameter variations in production tests that allows quickly discarding of the faulty circuits. Additionally, the possibility of on-chip process deviation monitoring provides valuable information, which is used to guide the test and to allow the estimation of selected performance figures. The information obtained through guiding and monitoring process variations is re-used and supplement the circuit calibration.	built-in self-test;mixed-signal integrated circuit	Amir Zjajo;Manuel J. Barragan Asian;José Pineda de Gyvez	2007	2007 Design, Automation & Test in Europe Conference & Exhibition	10.1145/1266366.1266650	chip;reliability engineering;embedded system;electronic engineering;process control monitoring;telecommunications;signal integrity;engineering;process variation	EDA	22.614221168316497	54.58964940706943	125800
0750df4cbd626878835a75a15c1e2e77162fc17f	towards an ultra-low-power architecture using single-electron tunneling transistors	cmos integrated circuits;ultra low power;reliability;fault tolerant;integrated circuit;performance;single electron transistors;single electron transistors cmos integrated circuits embedded systems fault tolerance integrated circuit design low power electronics nanoelectronics semiconductor device models;hybrid set cmos;ultra low power architecture;embedded system;embedded systems;integrated circuit design;reconfigurable architecture;single electron tunneling transistor;reconfigurable architecture design performance reliability single electron tunneling transistor set low power nanoelectronics;low power;single electron tunneling;embedded system design;energy consumption;power system management;power dissipation;semiconductor device models;fault tolerance;nanoelectronics;batteries;low power electronics;design;battery powered embedded system design;power system reliability;power consumption;integrated circuit packaging;single electron tunneling transistor set;tunneling single electron transistors embedded system energy consumption power system reliability batteries power dissipation energy management power system management integrated circuit packaging;high performance;energy management;tunneling;reconfigurable architecture ultra low power architecture single electron tunneling transistor embedded system design power dissipation integrated circuit packaging battery powered embedded system design hybrid set cmos	Minimizing power consumption is vitally important in embedded system design; power consumption determines battery lifespan. Ultra-low-power designs may even permit embedded systems to operate without batteries, e.g., by scavenging energy from the environment. Moreover, managing power dissipation is now a key factor in integrated circuit packaging and cooling. As a result, embedded system price, size, weight, and reliability are all strongly dependent on power dissipation.  Recent developments in nanoscale devices open new alternatives for low-power embedded system design. Among these, single-electron tunneling transistors (SETs) hold the promise of achieving the lowest power consumption. However, SETs impose unique design constraints that strongly influence architectural and circuit-level decisions. Unfortunately, most analysis of SETs has focused on single devices instead of architectures, making it difficult to determine whether they are appropriate for low-power embedded systems.  This article presents possible uses of SETs in high-performance and battery-powered embedded system design. The resulting fault-tolerant, hybrid SET/CMOS, reconfigurable architecture can be tailored to specific requirements and allows trade-offs among power consumption, performance, operation temperature, fabrication cost, and reliability. This work is a first step in evaluating the system-level potential of reducing power consumption by using SETs.	cmos;cpu power dissipation;computer cooling;electron;embedded system;fault tolerance;integrated circuit packaging;low-power broadcasting;one-electron universe;power architecture;quantum tunnelling;requirement;systems design;transistor;tunneling protocol	Changyun Zhu;Zhenyu Gu;Li Shang;Robert P. Dick;Robert G. Knobel	2007	2007 44th ACM/IEEE Design Automation Conference	10.1145/1278480.1278560	embedded system;fault tolerance;electronic engineering;computer science;engineering;electrical engineering	EDA	13.2839218243593	57.95318603202165	126082
1f86c68b02ce7afbd60a7f3a63638ee40c651788	a new method to determine the reliability comparability for products, components, and systems in reliability testing	lifetime weibull distribution;reliability comparability index;ic industry;lifetime type reliability comparison reliability life testing reliability comparability index lifetime weibull distribution ic industry;reliability function;manufacturing industries;maximum likelihood estimation;reliability testing;sameness;weibull distribution reliability comparison reliability testing sameness;weibull distribution;weibull distribution integrated circuit reliability life testing semiconductor device manufacture;lifetime type reliability comparison;reliability life testing;shape;life testing;threshold voltage;indexation;semiconductor device manufacture;time of arrival estimation;system testing life testing weibull distribution maximum likelihood estimation threshold voltage manufacturing industries production shape electromigration time of arrival estimation;production;system testing;electromigration;integrated circuit reliability;reliability comparison	"""A method is proposed in this paper to determine whether a product, a component, or a system in reliability life testing has a longer lifetime than the other. We propose two indices to compare reliability. The comparison is also distribution-free; i.e., it does not require the assumption on the lifetime distributions. A comparability index that is derived by integrating the weighted difference between the reliability functions of the two groups under comparison is named the """"Better or Worse"""" (BOW) index. The second comparability index that is derived by calculating the overlapping area under the two distributions in comparison is named """"Reliability Comparability"""" (RC) to quantify the degree of similarity between the two distributions. These two new indices are compared with the conventional methods currently used in the IC industries. Practical applications in lifetime-type reliability comparison are also illustrated in this paper"""	reliability engineering;worse is better	Wei-Ting Kary Chien;Siyuan Frank Yang	2007	IEEE Transactions on Reliability	10.1109/TR.2006.890891	reliability engineering;weibull distribution;electromigration;shape;engineering;mathematics;maximum likelihood;manufacturing;threshold voltage;forensic engineering;system testing;statistics	DB	23.895930964400034	55.303789007969726	126104
2076370e172dafcd1287161197245a7262903699	a two-way graph partitioning using a heuristic procedure	graph theory;optimal solution;pins;very large scale integrated circuit design;circuit partitioning;very large scale integration;heuristic programming;trade off function;circuit layout;circuit optimisation graph theory heuristic programming intelligent design assistants circuit layout cad vlsi circuit analysis computing iterative methods;hardware simulation;heuristic procedure;very large scale integrated;vlsi design;polynomials;intelligent design assistants;polynomial time algorithm;iterative methods;trade off function two way graph partitioning heuristic procedure circuit partitioning very large scale integrated circuit design vlsi design circuit layout circuit testing hardware simulation polynomial time algorithm sub optimal solution circuit netlist iterative improvement method;circuit simulation;computational modeling;graph partitioning;integrated circuit interconnections;vlsi;two way graph partitioning;circuit layout cad;circuit testing;iterative improvement method;vlsi layout;circuit optimisation;circuit analysis computing;sub optimal solution;australia;partitioning algorithms;hardware;very large scale integration integrated circuit interconnections circuit testing hardware circuit simulation partitioning algorithms pins australia computational modeling polynomials;circuit netlist	Partitioning a circuit is an important task in many phases of very large scale integrated (VLSI) design, ranging from layout to testing and hardware simulation. This problem is a variant of the more general graph partitioning problem. It is known that there is no polynomial time algorithm to obtain an optimal partition. A number of heuristic procedures have been proposed to obtain a sub-optimal solution. We discuss an implementation of a heuristic procedure for 2-way partitioning of circuit netlist. We use an iterative improvement method in which an initial partition is generated and then it is improved to get the final solution. The circuit partitioning procedure incorporates heuristics to partition the functional modules into two groups A and B such that the number of nets between the groups is as small as possible and the area of the modules in each group is nearly equal. Since the two conditions are contradictory in nature, we use a trade-off function for the partition A and B. We discuss the nature of the function, implementation of the partition procedure and the results.	graph partition;heuristic	N. Mani	1996		10.1109/ANZIIS.1996.573981	mathematical optimization;computer science;graph partition;graph theory;theoretical computer science;very-large-scale integration	EDA	15.497776179679589	50.2018487819403	126122
7893c8988c0b3ddba3aa31c77fa1021f5372e915	tobol - a new methodology for the top-to-bottom level hardware description in vlsi design-automation systems	vlsi design;vlsi circuit layout cad specification languages;data representation;functional abstractions circuit layout cad specification languages tobol top to bottom level hardware description vlsi design automation high level descriptions data representations circuit descriptions;specification languages;vlsi;circuit layout cad;hardware very large scale integration circuit synthesis microelectronics design automation logic design logic circuits process design data structures computer languages	The TOBOL methodology for hardware description from top to bottom level is proposed. Multilevel circuit descriptions can efficiently be provided for diversified purposes. Low-level (such as transistor-level) design information can easily be attached into high-level descriptions. TOBOL utilizes consistent data representations at different levels and allows the integration of circuit descriptions at different levels into a single unified system. Therefore, redundant information is greatly reduced, and efficient access of right functional abstractions of circuits is achieved. >	very-large-scale integration	C. Y. Roger Chen	1988		10.1109/ICCL.1988.13090	physical design;computer architecture;computer science;theoretical computer science;circuit design;design layout record;very-large-scale integration;circuit extraction;register-transfer level	EDA	11.672577224301982	50.45949160092512	126157
3c9c07f590ffabb2c80bb556e8a108b682d1196e	a new type of low power read circuit in eeprom for uhf rfid	sense amplifier;low power;rfid;read circuit;eeprom	A novel low power read circuit without reference in 1k-bits electrically erasable and programmable (EEPROM) for UHF RFID is designed and implemented in SMIC 0.18@mm EEPROM process. The read power consumption is optimized using a pre-charge sense amplifier. To improve the performance of the read circuit, a self-detect circuit, a read control logic and a feedback scheme are adopted, combined with a special time sequence. For a power supply voltage of 1V, an average power consumption of 1.6@mA for the read operation of the EEPROM can be achieved when the read clock frequency is 640kHz. What is more, with a 110^oC temperature change, the read power consumption variation is as low as 12%. The die size of the EEPROM is 0.15mm^2, where the read circuit occupies 0.0125mm^2.	eeprom;ultra high frequency	Yongqian Du;Xiaoming Li;Li Dai;Xin Jing;Zhenrong Li;Hualian Tang;Yiqi Zhuang	2012	Microelectronics Journal	10.1016/j.mejo.2012.02.002	radio-frequency identification;eeprom;embedded system;electronic engineering;sense amplifier;computer hardware;computer science	EDA	17.247037533479617	57.92101351885996	126337
f560bc86d89c06cf291552079e6a1d6d0e39e9a1	a multiple neighborhood search for dynamic memory allocation in embedded systems	mns;electronic design;ts;ejection chains;dynamic memory allocation	Memory allocation has a significant impact on power consumption in embedded systems. We address the dynamic memory allocation problem, in which memory requirements may change at each time interval. This problem has previously been addressed using integer linear programming and iterative approaches which build a solution interval by interval taking into account the requirements of partial time intervals.AGRASP that builds a solution for all time intervals has been proposed as a global approach. Due to the complexity of this problem, the GRASP algorithm solution quality decreases for larger instances. In order to overcome this drawback, we propose a multiple neighborhood search hybridized with a Tabu Search and enhanced by complex ejection chains. The proposed approach outperforms all previously developed methods devised for the dynamic memory allocation problem.	computation;computer-aided design;electronic circuit design;embedded system;feasible region;grasp;heuristic (computer science);integer programming;integrated circuit;iterative method;linear programming;memory management;metaheuristic;perturbation theory;plug-in (computing);requirement;search algorithm;tabu search;time complexity;token ring	María Soto;André Rossi;Marc Sevaux	2015	J. Heuristics	10.1007/s10732-015-9297-y	mathematical optimization;real-time computing;computer science;artificial intelligence;static memory allocation;c dynamic memory allocation	Embedded	13.455019865978443	52.97975863552906	126361
e5df979aa08e24888cb1b7ca2e4ada489f17b00b	ravel: assigned-delay compiled-code logic simulation	assigned-delay compiled-code logic simulation;functional verification;associative algebra;logic gate	Ravel is a longand short-path delay-accurate compiled-code logic gate simulator suitable for both thefinctional and timing verification of multiphase synchronous circuits. It is based on a waveform model of synchronous operation and an associated algebra for combining such waveforms both logically and temporally. This algebra extends the range of compiled-code simulation, which has been limited in the past to static functional verification, so that dynamic signal propagation effects can be captured accurately. For synchronous circuits exhibiting significant event activity per clock cycle, Ravel simulation can be faster than traditional event-driven simulation with no sacrifice in the delay modeling accuracy. Initial experiments with Ravel on a subset of the ISCAS 89 sequential benchmarks confirm its viability as an alternative to eventdriven simulation.	clock signal;compiler;event-driven programming;experiment;logic gate;logic simulation;software propagation;static timing analysis;waveform	Emily J. Shriver;Karem A. Sakallah	1992		10.1145/304032.304134	associative algebra;embedded system;electronic engineering;real-time computing;asynchronous circuit;logic gate;computer science;theoretical computer science;logic simulation;mathematics;sequential logic;high-level verification;functional verification	EDA	19.54727063591366	49.83130381746114	126373
daa12aa022dc841cef309736208e19decbeeaf12	reducing microfluidic very large scale integration (mvlsi) chip area by seam carving	seam carving;microfluidics;mvlsi	This paper introduces a technique based on seam carving to reduce the area of microfluidic very large scale integration (mVLSI) chips. Seam carving repeatedly identifies small slices of the device that can be safely removed (carved) and patched without adversely affecting device functionality. Using non-linear seam carving we achieve an average improvement of 4.28x in area utilization and an average reduction in fluid routing channel length of 53%		Brian Crites;Karen Kong;Philip Brisk	2017		10.1145/3060403.3060461	seam carving;microfluidics;computer science;engineering drawing	EDA	15.532565790676568	53.88824030931411	126477
ceb17b602dd19eedf9c85f7dba514158356f900c	a low-power sram using bit-line charge-recycling for read and write operations	8 bit processor;random access memory;static random access memory;memoria acceso directo;voltage 1 2 v bit line charge recycling read and write operations charge recycling sram cr sram chip read and write powers swing voltage hierarchical bit line architecture memory cells cmos process size 0 13 mum power 0 128 mw power 0 135 mw frequency 100 mhz;integrated circuit;procesador 8 bits;mosfets;clocks;cr sram chip;low swing;memory cells;circuito integrado;memoire acces direct statique;endommagement;cmos process;tecnologia mos complementario;memoria no volatil;deterioracion;read and write powers;static noise margin;processeur 8 bits;chip;bit line charge recycling;hierarchical bit line architecture;consumo electricidad;memoire non volatile;low power;cmos memory circuits;memoire acces direct;non volatile memory;voltage 1 2 v;electric power consumption;low power electronics;random access memory clocks capacitance mosfets recycling power demand;charge recycling sram;bit line;charge recycling;swing voltage;power 0 135 mw;sram;reconversion;capacitance;sram chips cmos memory circuits;dispositif a memoire;frequency 100 mhz;damaging;technologie mos complementaire;power 0 128 mw;power demand;electronique faible puissance;memory devices;read and write operations;recycling;consommation electricite;sram bit line charge recycling low power low swing;recyclage;circuit integre;size 0 13 mum;complementary mos technology;reading and writing;sram chips	This paper proposes a low-power SRAM using bit-line charge-recycling for read and write operations. The charge-recycling SRAM (CR-SRAM) reduces the read and write powers by recycling the charge in bit lines. When N bit lines recycle their charges, the swing voltage and power of bit lines are reduced to 1/N and 1/N2, respectively. The CR-SRAM utilizes hierarchical bit-line architecture to perform the charge-recycling without static noise margin degradation in memory cells. In the simulation, the CR-SRAM saves 17% read power and 84% write power compared with the conventional SRAM. A CR-SRAM chip with 4 K × 8 bits is implemented in a 0.13-μm CMOS process. It consumes 0.128-mW read power and 0.135-mW write power at fCLK = 100 MHz and VDD = 1.2 V.	bl (logic);cmos;elegant degradation;low-power broadcasting;noise margin;simulation;static random-access memory;value-driven design	Byung-Do Yang	2010	IEEE Journal of Solid-State Circuits	10.1109/JSSC.2010.2063950	embedded system;electronic engineering;parallel computing;static random-access memory;computer science;engineering;operating system	Arch	17.3778749281444	58.11790627098963	126523
ddc75111b6d32ebfeae054858e0573419043790d	logic synthesis for manufacturability	optimisation;integrated circuit yield;integrated circuit layout;logic design;design for manufacture;design optimization;optimisation design for manufacture integrated circuit layout integrated circuit yield logic design;logic synthesis;manufacturing design optimization circuit synthesis logic design cost function libraries process design routing redundancy robustness;design for manufacturability integrated circuit design optimization logic synthesis design for yield integrated circuit layout	Design optimization during synthesis is for area and/or performance while optimization for yield occurs at the layout level. To obtain abstraction level for yield optimization by introducing an interesting approach to yield-driven logic synthesis. Design for manufacturability denotes all techniques designers use to estimate and control yield and robustness during the design phase, prior to manufacturing.	abstraction layer;design for manufacturability;logic synthesis;mathematical optimization;multidisciplinary design optimization	Alessandra Nardi;Alberto L. Sangiovanni-Vincentelli	2004	IEEE Design & Test of Computers	10.1109/MDT.2004.15	physical design;embedded system;electronic engineering;logic synthesis;logic optimization;electronic design automation;ic layout editor;computer science;engineering;design flow;circuit design;integrated circuit layout;circuit extraction;design for manufacturability;engineering drawing;power optimization;register-transfer level;standard cell;computer engineering;integrated circuit design	EDA	13.646085569557146	51.77525951738209	126600
8c4aba1ff5a8d4e6f4ca65021a9316fd484eb60d	versatile transition-time monitoring for interconnects via distributed tdc	reliability;temperature sensors;built in self test;monitoring;integrated circuit interconnections;delays	Online monitoring of interconnect delay is important for early detection of reliability hazards, especially in multidie ICs. This article presents a versatile, low-overhead, and nonintrusive monitoring scheme to detect the worst case transition time of interconnects.	best, worst and average case;electrical connection;overhead (computing);rise time	Shi-Yu Huang;Chih-Chieh Cheng;Meng-Ting Tsai;Kuan-Chen Huang;Kun-Han Tsai;Wu-Tung Cheng	2016	IEEE Design & Test	10.1109/MDAT.2016.2590979	embedded system;electronic engineering;real-time computing;engineering;reliability;statistics	EDA	21.308853674153042	55.871801004788914	126700
6f343aa5fe09b005ff0a0697f978ce6832a24cda	operand isolation with reduced overhead for low power datapath design	latch based designs overhead reduction low power data path design dynamic power dissipation ingenious operand isolation circuits combinational circuit power supply switching pmos stacks nmos stacks multiple input multiple output block mimo block;power supply switching low power design operand isolation;flip flops;integrated circuit design;operand isolation;mos integrated circuits;low power electronics;logic gates transistors latches mos devices clamps power supplies timing;low power design;power supply switching;combinational circuits;mos integrated circuits combinational circuits flip flops integrated circuit design low power electronics	Dynamic power dissipation due to redundant switching is an important metric in data-path design. This paper focuses on the use of ingenious operand isolation circuits for low power design. Operand isolation attempts to reduce switching by clamping or latching the output of a first level of combinational circuit. This paper presents a novel method using power supply switching wherein both PMOS and NMOS stacks of a circuit are connected to the same power supply. Thus, the output gets clamped or latched to the power supply value with minimal leakage. The proposed circuits make use of only two transistors to clamp the entire Multiple Input Multiple Output (MIMO) block. Also, the latch-based designs have higher drive strength in comparison to the existing methods. Simulation results have shown considerable area reduction in comparison to the existing techniques without increasing timing overhead.	bit-level parallelism;boolean circuit;cmos;clamping (graphics);combinational logic;datapath;heuristic;logic gate;mimo;nmos logic;operand isolation;overhead (computing);pmos logic;power supply;routing;simulation;spectral leakage;transistor	Lokesh Siddhu;Amit Mishra;Virendra Singh	2014	2014 27th International Conference on VLSI Design and 2014 13th International Conference on Embedded Systems	10.1109/VLSID.2014.90	embedded system;electronic engineering;real-time computing;computer science;engineering;operating system;switched-mode power supply;combinational logic;algorithm;low-power electronics;integrated circuit design	EDA	16.999855947688854	56.69173403404966	126715
59072fe814f4a7584a9725680b9bfdaac28d7a63	study on the costs of on-site vlsi testing	semiconductor device testing;mos integrated circuits vlsi integrated circuit testing costing integrated circuit yield automatic testing boundary scan testing production testing;testing costs;integrated circuit yield;costing;very large scale integration;automatic testing;electronic equipment testing;direct costs;manufacturing testing;boundary scan testing;partial scan design;indirect costs on site vlsi testing manufacturing testing testing costs test circuits mos vlsi developmental cost direct costs sort costs full scan design partial scan design;large scale;manufacturing processes;indirect costs;on site vlsi testing;mos integrated circuits;developmental cost;semiconductor device manufacture;integrated circuit testing;vlsi;test circuits;system testing;circuit testing;sort costs;full scan design;production testing;test equipment;costs very large scale integration circuit testing system testing semiconductor device manufacture electronic equipment testing marketing and sales test equipment manufacturing processes semiconductor device testing;mos vlsi;marketing and sales	The most important points concerning the manufacturing testing of VLSI are (1) The guaranteed high quality of the testing itself, (2) Low cost testing procedures and ( 3 ) Fast development and operation. However, together with the high integration of VLSI, recent large-scale, multi-functional and complex technology has made the above testing procedures more and more difficult to secure. Our section is in charge of the establishment of the manufacturing testing procedures for all MOS-VLSI, excluding stand-alone MOS memory, and of the management of the technological data of all tests. In this paper, we will analyze this data and disclose the results of our study concerning testing costs. In particular, we will discuss the actual necessity of introducing test circuits in regard to the testing costs, and how to obtain the appropriate value for such circuits.	display resolution;test case;very-large-scale integration	Junichi Hirase	1995		10.1109/TEST.1995.529870	black-box testing;electronic engineering;software performance testing;white-box testing;engineering;functional testing;very-large-scale integration;indirect costs;system testing;computer engineering	SE	23.550733580829863	54.536261947402586	126774
4af079665953c56fddf764166897f6b7c157a1aa	a novel gate grading approach for soft error tolerance in combinational circuits	logic gates integrated circuit reliability benchmark testing redundancy integrated circuit modeling delays;vlsi combinational circuits integrated circuit reliability;redundancy;logic gates;circuit reliability gate grading approach soft error tolerance combinational circuits semiconductor devices advanced vlsi logic circuits fault tolerance techniques hardware redundancy area overhead power overhead;integrated circuit modeling;integrated circuit reliability;benchmark testing;logical electrical masking logic circuit soft errors fault tolerance transient errors reliability;delays	Continuous reduction in the minimum feature size of semiconductor devices and the supply voltages in advanced VLSI logic circuits has made those circuits more susceptible to soft errors. Hence, several fault tolerance techniques have been proposed in the literature to protect combinational circuits against single event transients (SETs). These fault tolerance techniques are based mainly on hardware redundancy and therefore they come at the cost of significant area and power overhead. In this paper, a novel gate grading approach is proposed to prioritize gates based on their influence on the circuit's reliability. Specifically, different masking factors are taken into account and the gates with the lowest masking capabilities are identified so that they can be hardened first. Since the gates with higher priorities affect the circuit's reliability more significantly, protecting those gates increases the circuit's reliability with the least required area and power overhead.	combinational logic;error-tolerant design;fault tolerance;logic gate;overhead (computing);redundancy (engineering);semiconductor device;soft error;very-large-scale integration	Mohammad Saeed Ansari;Ali Mahani;Jie Han;Bruce F. Cockburn	2016	2016 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2016.7726658	mixed-signal integrated circuit;reliability engineering;boolean circuit;benchmark;electronic engineering;real-time computing;asynchronous circuit;logic gate;engineering;pass transistor logic;sequential logic;redundancy;circuit extraction;digital electronics;register-transfer level	EDA	20.777545782067108	54.286658700809895	126939
fd14b64c8f48757d9230b3c4256f8380e9855adb	fx: a fast approximate fault simulator for the switch-level using vhdl	fault propagation;observability;voltage control;fx;probability;circuit faults;fault simulation;integrated circuit;switching circuits;logic;hardware description languages;physical failures;circuit faults circuit simulation switching circuits switches integrated circuit modeling observability logic mathematical model voltage control matrix converters;transistor reverse level ordering;circuit simulation;vhdl;hardware description languages fault diagnosis logic testing observability circuit analysis computing probability;integrated circuit modeling;logic testing;mathematical model;matrix converters;fault propagation fx fast approximate fault simulator transistor reverse level ordering vhdl switch level fault simulation physical failures integrated circuit nine valued switch level extension observability probability average node fan in complexity speedup;fast approximate fault simulator;average node fan in;switches;circuit analysis computing;switch level fault simulation;complexity speedup;nine valued switch level extension;fault diagnosis	Switch-level faults, as opposed to traditional gate-level faults, can more accurately model physical failures found in an integrated circuit. However, one problem with switch-level fault simulation is that of long simulation times. This paper addresses this problem by performing fast approximate switch-level fault simulation using transistor reverse level ordering, and a novel nine-valued switch-level extension to observability. The probability of propagation of a fault from an arbitrary line of the switch-level circuit to the primary output is shown to be a function of the average node fan-in and the line's distance to primary output. Using this probability, results show one order of magnitude of complexity speed-up as compared to traditional fault simulation techniques, while maintaining good accuracy.		Christopher A. Ryan;Joseph G. Tront	1996	IEEE Trans. VLSI Syst.	10.1109/92.532034	embedded system;electronic engineering;real-time computing;observability;fault coverage;vhdl;fault indicator;computer science;stuck-at fault;theoretical computer science;integrated circuit;probability;mathematical model;fault model;logic;statistics	EDA	22.791728428709476	51.26477329648245	126979
6498ecabdeb9ef6e386e67c8fceda90e6304740f	io clock network skew & performance analysis: a pentium-d case study	clocks;scientific method;power saving mode;network topology;clock distribution;integrated circuit design;tree structure;performance analysis;yield loss;clocks performance analysis frequency estimation silicon circuit topology yield estimation thermal factors timing tree data structures network topology;network topology clocks integrated circuit design jitter;jitter;clock skew;voltage supply variation io clock network skew performance analysis pentium d case study i o clock distribution systematic skew estimation clock topology in die variation temperature supply variation	Accurate estimation of skew on I/O clocks is extremely critical when the part is expected to operate at a fixed frequency and any failure results in yield loss. Also, factors such as slow silicon, power saving modes, thermal throttling modes makes the data-path running on I/O clocks more critical as no timing relaxation is possible. The circuits on core clocks, on the other hand, can be binned to a lower frequency using bus ratios for slower silicon and benefit from frequency reduction during power saving modes. Further, since the I/O clock distribution typically utilizes a balanced tree structure due to its sparse usage, it suffers from higher skew compared to global clock with a tiled topology. This makes it imperative that the I/O clock performance methodology take into account all the various factors that can impact clock skew as well as slowdown in the associated datapath circuits. This paper presents a systematic skew estimation and a scientific method for performance analysis of I/O clock network. A case study on how this was adopted for Pentium-D (65 nm process) I/O clocks is presented. Key components considered are clock topology, device & interconnect in-die variation, temperature and voltage supply variation	12-hour clock;clock network;clock skew;datapath;imperative programming;input/output;linear programming relaxation;profiling (computer programming);quantum clock;self-balancing binary search tree;sparse matrix;thermal design power;tree structure	Vishal Bhargava;N. Haider;N. Sarpotdar	2006	IEEE Custom Integrated Circuits Conference 2006	10.1109/CICC.2006.320918	clock synchronization;embedded system;electronic engineering;real-time computing;scientific method;jitter;clock angle problem;telecommunications;clock domain crossing;clock skew;computer science;engineering;clock rate;underclocking;timing failure;clock drift;tree structure;synchronous circuit;clock gating;digital clock manager;static timing analysis;network topology;integrated circuit design;cpu multiplier	EDA	21.084056371714865	57.83372368221157	127052
547d4399e862da483ca74c29775ffb6ffd251337	digital fuzzy logic controller: design and implementation	digital circuit;processing element;controleur logique programmable;concepcion circuito;fuzzy controller;mimo system;control difusa;controlador logica programable;multiple input multiple output;real time control;implementation;single input single output;fuzzy control;circuit design;parallel architectures fuzzy control fuzzy logic digital control inference mechanisms vlsi minimax techniques mimo systems cmos digital integrated circuits microprocessor chips integrated logic circuits;logique floue;circuit vlsi;logica difusa;inference mechanisms;fuzzy logic controller;fuzzy logic;circuit numerique;ejecucion;mimo systems;minimax techniques;feasibility study;vlsi circuit;parallel architectures;programmable logical controller;cmos digital integrated circuits;design and implementation;directional data;circuito numerico;vlsi;cost effectiveness;conception circuit;cmos design digital fuzzy logic controller hardware cost controller configurations processing element parallel architecture mimo system data stream architecture vlsi siso systems fuzzy inference mechanism;digital control;integrated logic circuits;circuito vlsi;fuzzy logic digital control mimo hardware circuits fuzzy control costs very large scale integration associate members performance analysis;high speed;multiple input single output;microprocessor chips;commande floue	In this paper, various aspects of digital fuzzy logic controller (FLC) design and implementation are discussed. Classic and improved models of the single-input single-output (SISO), multiple-input single-output (MISO), and multiple-input multiple-output (MIMO) FLC’s are analyzed in terms of hardware cost and performance. A set of universal parameters to characterize any hardware realization of digital FLC’s is defined. The comparative study of classic and alternative MIMO FLC’s is presented as a generalization of other controller configurations. A processing element (PE) for the parallel FLC architecture realizing improved inferencing of MIMO system is designed, characterized, and tested. Finally, as a case feasibility study, a direct data stream (DDS) architecture for complete digital fuzzy controller is shown as an improved solution for high-speed, cost-effective, real-time control applications.	fuzzy logic;mimo;real-time transcription;soft-in soft-out decoder;system analysis	Marek J. Patyra;Janos L. Grantner;Kirby Koster	1996	IEEE Trans. Fuzzy Systems	10.1109/91.544304	fuzzy logic;feasibility study;cost-effectiveness analysis;real-time control system;digital control;computer science;artificial intelligence;circuit design;control theory;very-large-scale integration;implementation;digital electronics;fuzzy control system	Embedded	10.584072588590983	47.22245848144115	127057
0d8dc04ba8242b58721fd96c044633614a6673a2	post-layout optimization of power and timing for ecl lsis	bipolar ecl lsl;logic cad large scale integration circuit optimisation nonlinear programming bipolar logic circuits integrated circuit modelling integrated circuit design circuit cad timing emitter coupled logic;timing large scale integration clocks power dissipation delay resistors circuits synchronous digital hierarchy cmos technology constraint optimization;optimization algorithm;emitter coupled logic;integrated circuit;switching current;nonlinear programming;post layout optimization;chip;integrated circuit design;large scale integration;integrated circuit modelling;switching current post layout optimization power dissipation timing ecl lsis optimization algorithm bipolar ecl lsl nonlinear programming solver delay time;power dissipation;bipolar logic circuits;circuit cad;power reduction;delay time;ecl lsis;circuit optimisation;logic cad;optimal algorithm;nonlinear programming solver;timing;time constraint	An optimization algorithm for power and timing of Bipolar ECL LSIs is proposed. The power dissipation is minimized by a nonlinear programming solver under accurate timing constraints extracted from layout. The power and delay time of an ECL gate are considered functions of its switching current which is regulated by programming its resistors. Experimental results show signi cant power reductions for circuits including a real chip without degrading the performance.	algorithm;cpu power dissipation;central processing unit;clock signal;clock skew;computer-aided design;emitter-coupled logic;haruhiko shono;integrated circuit;mathematical optimization;natural language processing;nonlinear programming;nonlinear system;pa-risc;solver	Akira Onozawa;Hitoshi Kitazawa;Keitaro Kawai	1995		10.1109/EDTC.1995.470402	control engineering;electronic engineering;real-time computing;computer science	EDA	17.131081033089455	54.12755940911515	127093
21d5652f276ae92e6e80a797819fbcf71db97b6e	flip-flop clustering by weighted k-means algorithm	standards;clocks;routing;placement;physical design;clocks clustering algorithms timing standards routing partitioning algorithms optimization;wires electric buffer circuits clocks driver circuits flip flops minimisation network routing pattern clustering power aware computing;clustering algorithms;optimization;steiner tree;dynamic power savings flip flop clustering weighted k means algorithm relocation framework overall chip power consumption reduction clock network wirelength reduction drivers disturbance minimization single clock buffer routing structure modified k means algorithm regularly structured clusters;partitioning algorithms;timing	This paper presents a novel flip-flop clustering and relocation framework to help reduce the overall chip power consumption. Given an initial legalized placement, our goal is to reduce the wirelength of the clock network by reducing distance between flip-flops and their drivers, while minimize the disturbance of original placement result. The idea is to form flip-flops into clusters, such that all flip-flops within each cluster can be placed near a single clock buffer and connected by a simple routing structure. Therefore, overall clock network wirelength can be greatly reduced and significant power savings can be achieved. In particular, we propose a modified K-means algorithm which effectively assigns flops into clusters at the clustering step. Then, at the relocation step, flops are actually relocated and regularly structured clusters are formed. Our framework is evaluated on real industrial benchmarks. We compare our framework with a flow without flop clustering and an industrial window based flop clustering flow. Experimental results show our framework can achieve significant dynamic power savings while has less disturbance of the original placement.	algorithm;benchmark (computing);clock network;cluster analysis;flops;flip-flop (electronics);k-means clustering;relocation (computing);routing	Gang Wu;Yue Xu;Dean Wu;Manoj Ragupathy;Yu-Yen Mo;Chris C. N. Chu	2016	2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2897937.2898025	physical design;embedded system;mathematical optimization;routing;parallel computing;real-time computing;steiner tree problem;computer science;cluster analysis;placement	EDA	16.04518003778471	54.22310395900304	127136
3e47c9f0168bb99252848b87554404e9be5b77e0	on-chip detection methodology for break-even time of power gated function units	cmos integrated circuits;microprocessor chips;bet-aware power-gating control;mtcmos circuit structure;break-even time;conventional simulation-based offline technique;multicore processors;on-chip detection methodology;on-off power switches;overhead energy dissipation;pmos-nmos leakage monitors;power gated function units;power-gated multiplier;process variation;size 65 nm;temperature variation;break-even time;leakage monitor;power gating	In a fine-grain leakage saving technique to power gate function units, the efficiency is sensitive to overhead energy dissipating at turning on/off power switches. To get gain in energy savings, the powered-off period has to be longer than the minimum required time i.e. the break-even time (BET). While effectiveness of BET-aware power-gating control has been described in literatures, how to actually detect BET that fluctuates with the temperature and process variation has not been reported so far. This paper proposes an on-chip detection methodology for BET using pMOS/nMOS leakage monitors with MTCMOS circuit structure. We applied this methodology to the leakage monitors and a CPU including a power-gated multiplier implemented in 65nm CMOS technology. Results showed that our methodology detects BET at 5%-17% difference from that of the conventional simulation-based off-line technique.	central processing unit;multi-threshold cmos;nmos logic;network switch;online and offline;overhead (computing);pmos logic;power gating;quantum fluctuation;simulation;spectral leakage	Kimiyoshi Usami;Yuya Goto;Kensaku Matsunaga;Satoshi Koyama;Daisuke Ikebuchi;Hideharu Amano;Hiroshi Nakamura	2011	IEEE/ACM International Symposium on Low Power Electronics and Design		chip;embedded system;electronic engineering;real-time computing;temperature measurement;computer science;engineering;dissipation;mathematical model;leakage;process variation;thermodynamics;cmos	Arch	19.683038126817763	58.23638633468702	127174
75ac0f218a69a9d2e502e6e3fa3bb3394ac4fc7f	multifunction monolithic thin-film compatible dtl logic circuits for data processing	thin film circuits;isolation technology;thin film;thin film circuits logic circuits data processing integrated circuit technology digital integrated circuits power dissipation logic functions isolation technology p n junctions propagation delay;data processing;p n junctions;logic circuits;chip;digital integrated circuits;integrated circuit technology;propagation delay;power dissipation;logic functions	Two major areas of technological advance in digital integrated circuits are: 1) increasing speed for a given power dissipation, and 2) decreasing area per gate function leading to the development of more complex single-chip units. The DTL circuits and subsystems described develop these trends to faster and more complex DTL single-chip logic functions. The application of the monolithic thin-film compatible technology with p-n junction isolation enables propagation delay times of 4.5 ns at 11.7 mW to be achieved in the basic DTL gates. The basic die topology described is well suited to the formation of monolithic single-chip DTL binary elements, full adders, multibit counters, and shift registers.	diode–transistor logic;multi-function printer	N. Fuschillo;J. Kroboth	1966	IEEE Trans. Electronic Computers	10.1109/PGEC.1966.264387	mixed-signal integrated circuit;chip;control engineering;propagation delay;electronic engineering;nmos logic;data processing;logic gate;logic family;computer science;engineering;electrical engineering;dissipation;pass transistor logic;diode logic;integrated injection logic;thin film;resistor–transistor logic	EDA	14.485083160653051	58.4320923589787	127226
263b6d713e6ec8ff709aee21d890515038b32a5a	design of wireless sub-micron characterization system	fabrication;wireless submicron characterization system;cmos integrated circuits;cmos technology;circuit simulations;1 v;circuit testing very large scale integration production costs manufacturing processes probes cmos technology fabrication integrated circuit manufacture large scale systems;mixed signal;very large scale integration;wireless parametric testing;very large scale ic;probes;chip;faults;wafers;circuit simulation;large scale;low voltage;manufacturing processes;1 v wireless submicron characterization system very large scale ic wafers cmos inductors wireless parametric testing circuit simulations pentium class vlsi circuit;low power electronics;integrated circuit testing;inductors;vlsi;production;integrated circuit testing vlsi cmos integrated circuits low power electronics circuit simulation;circuit testing;low power design;communication;pentium class vlsi circuit;cmos;integrated circuit manufacture;large scale systems	A wireless technique for characterization of very large scale ICs and wafers is presented. Presented is a test technique that uses standard CMOS without the use of inductors to achieve wireless parametric testing. In terms of existing technologies, this system has virtually no area overhead, minimal power requirements, and no process or design changes are required. A major feature is that wafer/chip contact is not required. Presented are specific circuit simulations showing characteristics of operation under varying conditions. The circuit operation is shown to work down to 1 volt and sub-milliwatt power level at the same time as being 1/10,000/sup th/ the area of a Pentium class VLSI circuit.	cmos;integrated circuit;microprocessor;overhead (computing);propagation delay;requirement;simulation;software propagation;transistor;very-large-scale integration;wafer (electronics)	Brian Moore;Christopher J. Backhouse;Martin Margala	2004	22nd IEEE VLSI Test Symposium, 2004. Proceedings.	10.1109/VTEST.2004.1299262	embedded system;electronic engineering;computer science;engineering;electrical engineering;cmos	EDA	21.943188309882984	55.435271757111856	127295
ad8402388e1e01f0ac4a92ec62566e92bc04a5a0	multi-dimensional interleaving for time-and-memory design optimization	optimisation;image coding;image processing;interleaved codes design optimization application software application specific integrated circuits time factors registers filters computer science flow graphs image coding;application software;optimization technique;filters;multidimensional interleaving;recursive time critical sections;design optimization;flow graphs;circuit cad image processing application specific integrated circuits optimisation digital filters;multi dimensional;data flow graph;interleaved codes;time factors;registers;application specific integrated circuits;application specific integrated circuit;digital filters;time and memory design optimization;digital filters multidimensional interleaving time and memory design optimization optimization technique application specific integrated circuits recursive time critical sections multi dimensional problems image processing iteration space;circuit cad;computer science;iteration space;multi dimensional problems	This paper presents a novel optimization technique for the design of application specific integrated circuits dedicated to perform iterative or recursive time-critical sec tions of multi-dimensional problems, such as image processing applications. These sections are modeled as cyclic multi-dimensional data flow graphs (MDFGs). This new technique, called multi-dimensional interleaving consis ts of an expansion and compression of the iteration space while considering memory requirements. It guarantees that all functional elements of a circuitry can be executed simultaneously, and no additional memory queues proportional to the problem size are required. The algorithm runs in O(jEj) time, where E is the set of edges of the MDFG representing the circuit.	algorithm;analysis of algorithms;dataflow;electronic circuit;forward error correction;image processing;integrated circuit;iteration;mathematical optimization;memory management;recursion;requirement;window of opportunity	Nelson L. Passos;Edwin Hsing-Mean Sha;Liang-Fang Chao	1995		10.1109/ICCD.1995.528905	electronic engineering;real-time computing;image processing;computer science;theoretical computer science;operating system;application-specific integrated circuit	EDA	13.53353143266426	46.84958700649797	127313
62dce48f2a3554379eb1f11f2f404f3e54e45bb3	model and algorithm for combinational optimization of information system bandwidth			algorithm;combinational logic;information system	Sergey V. Kokorin;Boris V. Sokolov;Yuri Ryzhikov	2011		10.7148/2011-0166-0171	mathematical optimization;electronic engineering;theoretical computer science	EDA	17.44676366636083	46.390616975437496	127379
d7b2e5b9323cde4b66b85773ce696caed7867ff3	minimal march tests for detection of dynamic faults in random access memories	random access memories;new technology;random access memory;memory testing;dynamic fault primitives;dynamic functional fault models;single cell;fault detection;march test algorithms;fault model;defect per million	The class of dynamic faults has been recently shown to be an important class of faults for the new technologies of Random Access Memories (RAM) with significant impact on defect-per-million (DPM) levels. Very little research has been done in the design of memory test algorithms targeting dynamic faults. Two March test algorithms of complexity 11N and 22N, N is the number of memory cells, for subclasses of two-operation single-cell and two-cell dynamic faults, respectively, were proposed recently [Benso et al., Proc., ITC 2005] improving the length of the corresponding tests proposed earlier [Hamdioui et al., Proc. of IEEE VLSI Test Symposium, pp. 395–400, 2002]. Also, a March test of length 100N was proposed [Benso et al., Proc. ETS 2005, Tallinn, pp. 122–127, 2005] for detection of twocell dynamic faults with two fault-sensitizing operations both applied on the victim or aggressor cells. In this paper, for the first time, March test algorithms of minimum length are proposed for two-operation single-cell and two-cell dynamic faults. In particular, the previously known March test algorithm of length 100N for detection of two-operation two-cell dynamic faults is improved by 30N.	algorithm;enterprise test software;fault coverage;memory tester;random access;random-access memory;software bug;very-large-scale integration	Gurgen Harutunyan;Valery A. Vardanian;Yervant Zorian	2007	J. Electronic Testing	10.1007/s10836-006-9504-8	parallel computing;real-time computing;computer science;theoretical computer science;fault model;fault detection and isolation	Embedded	20.41709388670432	53.09555440821095	127606
7bbe6f984dca781daad06be65cf80dc5738f1c70	enhancement of production pattern development methodology and best practices	mbist pattern generation;silicon;functional production pattern generation;fuses production silicon timing system on chip pins built in self test;best practices for production patterns development functional production pattern generation e fuse pattern generation mbist pattern generation soc ate;si production pattern development methodology automatic test equipment system on chip soc hdl hvl rtl level gate level netlist value change dump vcd tester specific format ate virtual tester e fuse production patterns mbist production patterns electronic fuses pattern generation time fly tweaking pattern bring up time silicon bring up time pattern iteration count;automatic test equipment;elemental semiconductors;system on chip automatic test equipment elemental semiconductors silicon;ate;system on chip;e fuse pattern generation;best practices for production patterns development;soc	Execution and stabilization of production patterns on ATE (Automatic Test Equipment) is becoming a challenging task with the increasing complexity of SoC(s)(System on chip). The conventional approach for production pattern development involves coding of test in HDL/HVL (e.g. system verilog), running the simulation at RTL level (or gate level netlist) to generate the vcd (Value Change Dump). The vcd is then converted to tester specific format to run on ATE/Virtual Tester. Many times these patterns go through regeneration process in order to stabilize across PVT (Process, Voltage, Temperature). E-fuse & MBIST production patterns take considerable time on ATE especially for SoC which have large number of electronic fuses (e.g. 1024 bits or more) & memories. Some of these patterns gate the start of post-silicon validation. With conventional methodology, the major challenges are the pattern generation time (it involves extensive usage of compute resources), inability to modify on the fly and information exchange across teams. To address the above challenges, we have developed a methodology (“scenario”) for fuse/MBIST patterns which eliminates vcd generation and enables on the fly tweaking and re-use. The patterns implemented with this approach, is re-usable across SoC(s) for BIST and e-fuse. In this paper, we will discuss this methodology and its impact. In applying this methodology, we have seen significant reduction on pattern bring-up time (~80%), silicon bring-up time (~80%) and pattern iteration count (<;2.6%) in C293 [1]. In addition, we will highlight some of the best practices followed as part of production pattern development, which helped us to reduce product characterization cycle by ~ 30% for C293 [1].	best practice;built-in self-test;efuse;hardware description language;hardware verification language;information exchange;iteration;netlist;or gate;on the fly;simulation;systemverilog;tweaking;uptime;verilog	Prokash Ghosh;Celia John;Ajay Gupta;Veerabhadrarao Siripurapu	2013	2013 International Symposium on Electronic System Design	10.1109/ISED.2013.37	embedded system;electronic engineering;real-time computing;engineering	Arch	11.529027418373968	54.63673668978402	127640
1c9c49fee9a6b052f5334808609b202fd8870635	ebist: a novel test generator with built-in fault detection capability	bist;circuit under test;lfsr;automatic test pattern generation;linear feedback shift register;parity preserving bist cyclic code lfsr;indexing terms;fault diagnosis built in self test automatic test pattern generation circuit analysis computing integrated circuit testing logic testing error detection cyclic codes;built in self test;parity preserving;fault detection circuit faults circuit testing built in self test electrical fault detection logic testing design methodology test pattern generators linear feedback shift registers hardware;fault detection;logic testing;integrated circuit testing;cyclic codes;cyclic code;test generation;fault coverage;test pattern generator;error detection;circuit analysis computing;parity preserving ebist built in fault detection test pattern generation built in self test tpg errors detection circuit under test faults cut linear feedback shift registers lfsr stuck at fault transition fault cyclic code;fault diagnosis;design methodology	A novel design methodology for test pattern generation in BIST is presented. Here faults and errors in the generator itself are detected. Two different design methodologies are presented. The first one guarantees all single fault/error detection and the second methodology is capable of detecting multiple faults and errors. Furthermore the proposed LFSRs do not have additional hardware over-head. Also importantly the test patterns generated have the potential to achieve superior fault coverage.	built-in self-test;error detection and correction;fault coverage;fault detection and isolation;floor and ceiling functions;hamming distance;sensor;test card	Dhiraj K. Pradhan;Chunsheng Liu;Krishnendu Chakrabarty	2003	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2005.850815	embedded system;electronic engineering;real-time computing;fault coverage;fault indicator;computer science;engineering;stuck-at fault;automatic test pattern generation;mathematics;linear feedback shift register;statistics	EDA	22.14752916632601	49.86937255728143	127677
10a0abace6d9aa8168bba728154b32768af5c669	impact of process variations on reliability and performance of 32-nm 6t sram at near threshold voltage	threshold voltage delays sram cells integrated circuit modeling standards logic gates;size 32 nm reliability integrated circuit design 6t sram cell process variations near threshold voltage power consumption monte carlo simulations soft errors double exponential current source ionizing particle critical charge distribution;standards;sram chips circuit simulation constant current sources integrated circuit design integrated circuit reliability low power electronics monte carlo methods radiation hardening electronics;sram cells;logic gates;threshold voltage;integrated circuit modeling;delays	Power consumption has become a major concern of integrated circuit (IC) design, especially for SRAM design. Reducing the supply voltage to the near-threshold region is one method to reduce the power consumption. However, operating in this region makes the circuit more sensitive to process variations. In this paper, the impact of process variations on a 32-nm 6T SRAM cell under near-threshold voltage is studied using Monte Carlo simulations to evaluate the potential for soft errors. The double-exponential current source is used to simulate the strike of an ionizing particle onto nodes of interest. The results show that threshold voltage variability is a more significant parameter affecting the critical charge distribution of the circuit under both near-threshold voltage and nominal supply voltage. Also under near-threshold voltage, the leakage power in standby mode is reduced compared to the nominal supply voltage, and the write delay time of the SRAM circuit is much larger than the nominal supply voltage.	broadcast delay;cell (microprocessor);current source;heart rate variability;integrated circuit;monte carlo method;propagation delay;simulation;sleep mode;soft error;spectral leakage;static random-access memory;time complexity;transistor model	Lingbo Kou;William H. Robinson	2014	2014 IEEE Computer Society Annual Symposium on VLSI	10.1109/ISVLSI.2014.73	voltage regulator;electronic engineering;real-time computing;engineering;78xx;electrical engineering;constant power circuit;dropout voltage;led circuit;voltage regulation	Arch	19.774006864376943	58.777322114222905	127846
e08763f585fc52c47c0552add36f94fc8a838f74	improving cmos open defect coverage using hazard activated tests	circuit faults logic gates hazards delays vectors automatic test pattern generation transistors;circuit faults;automatic test pattern generation;hazards;vectors;logic gates;integrated circuit testing automatic test pattern generation cmos logic circuits;transistors;spice simulations cmos open defect coverage hazard activated tests circuit path delays floating node leakage currents transient states switching transition atpg automatic test pattern generation delay test method;hazards tdf loc faults delay stuck open;delays	Recent studies indicate that a significant number of very large delay faults that increase circuit path delays several fold, remain difficult to detect and are only discovered by very carefully crafted and comprehensive two-pattern tests, e.g. cell aware tests. A likely source of such large delays in CMOS is stuck-open faults. These can sometimes still allow the circuit to reach the correct logic values through the charging of the floating node by small leakage currents in the circuit, although with large delays. It is well known that many open defects are not covered by commonly employed TDF launch on capture (LOC) scan delay tests; the coverage of specially generated transistor stuck-open tests published in the literature is only modestly better. It is commonly assumed that such undetected open faults are benign because the circuit states needed to activate them cannot be reached in normal functional operation. However, traditional test generation only considers final “steady state” signal values and ignores transients. In practice CMOS circuits experience many more transient states from the large number of hazards that occur during switching transitions. Many undetected open defects can be activated by such hazards during normal operation and cause a functional error. Such open faults must be detected by tests targeting low DPPMs. In this paper we present an ATPG based delay test methodology to target a key class of such hazard activated open faults that are not detected by traditional stuck open tests. Through detailed SPICE simulations, we show that the detected open defects can in fact be activated by such tests and therefore result in erroneous outputs in normal functional operation.	altered level of consciousness;cmos;spice;simulation;software bug;spectral leakage;steady state;transient (computer programming);transistor;trusted data format	Chao Han;Adit D. Singh	2014	2014 IEEE 32nd VLSI Test Symposium (VTS)	10.1109/VTS.2014.6818740	embedded system;electronic engineering;real-time computing;logic gate;hazard;engineering;automatic test pattern generation;transistor	EDA	21.593629377936384	54.55022933277682	127887
fa794a8ce49bbb4090b01c0447aa8e511f636c41	silicon crystal growth and wafer technologies	silicon;solar cells;cmos integrated circuits;complementary metal oxide semiconductor;si silicon crystal growth microelectronics industry photovoltaic cells semiconductor silicon wafer technology silicon on insulator soi technology ultrathin wafers complementary metal oxide semiconductor devices cmos devices silicon manufacturing;crystal growth;silicon on insulator;semiconductor device measurement;elemental semiconductors;semiconductor devices;solar cells cmos integrated circuits crystal growth elemental semiconductors silicon;crystals;silicon crystals wafer scale integration large scale integration substrates transistors semiconductor device measurement photovoltaic systems;semiconductor materials;large scale integration;silicon wafer;transistors;wafer scale integration;industrial application;substrates;photovoltaic systems;substrates photovoltaics pv semiconductor materials silicon;photovoltaics pv	Silicon substrates form the foundation of modern microelectronics. Whereas the first 50 years of silicon wafer technology were primarily driven by the microelectronics industry, applications in photovoltaics (PV) also promise to drive new advances in silicon wafer technology over the next ten years. In the first part, we review the historical development of semiconductor silicon wafer technology and highlight recent technical advances in bulk crystal growth and wafering technologies, including the development of silicon-on-insulator (SOI) technologies and ultrathin wafers. We then discuss technologies that could take us beyond the current capabilities of complementary metal-oxide-semiconductor (CMOS) devices. In the second part, we review silicon manufacturing for PV applications and some unique wafering technology challenges in that field. Finally, we summarize industry roadmaps and product needs highlighting key technical areas which promise to shape the future of silicon wafer technologies in the coming decades.	cmos;semiconductor;silicon on insulator;topological insulator;wafer (electronics);wafering	Graham Fisher;Michael R. Seacrist;Robert W. Standley	2012	Proceedings of the IEEE	10.1109/JPROC.2012.2189786	electronic engineering;nanotechnology;cmos;physics	EDA	12.209067492191588	57.89460015855748	128056
a24ff2d7b6214b3d2a9f4e3991b9c934b2eb7764	results given by a new evaluation system for placement and routing heuristics	libraries;fabrication;pins;electronic mail;evaluation system;algorithm development;programming language;integrated circuit layout;routing;very large scale integration;routing heuristics;software systems;routing fabrication very large scale integration wire wiring algorithm design and analysis libraries pins computer science electronic mail;network routing;wire;placement heuristics;algorithm development evaluation system routing heuristics placement heuristics vlsi layouts minimal hardware requirements programming languages hardware platforms fabrication processes;minimal hardware requirements;vlsi;fabrication processes;hardware platforms;circuit layout cad;computer science;vlsi layout;wiring;vlsi layouts;local search;algorithm design and analysis;programming languages	This paper presents a software system for generation of VLSI layouts. Its main advantages are minimal hardware requirements and its independence of programming languages, hardware platforms and fabrication processes. It is thus designed for use in algorithmdevelopment and universitary backgrounds.	algorithm;computer science;diploma;heuristic (computer science);place and route;programmer;programming language;requirement;routing;semiconductor device fabrication;software system;subroutine;very-large-scale integration	Reinhard Rauscher;Dieter Klawan;Hans-Jürgen Bandelt	1996		10.1109/EURMIC.1996.546390	computer science;theoretical computer science;engineering drawing;computer engineering	PL	11.86315382705804	51.028573764333125	128084
e0402071b9dff28ded96d365bdc347d02499c165	improving test quality using test data compression	atpg flow;test quality;data compression automatic test equipment automatic test pattern generation;data compression;edt technology;test data compression;automatic test pattern generation;automatic test equipment;burn in test;test data compression circuit testing circuit faults costs geometry graphics manufacturing industries hardware solid modeling electrical fault detection;multisite testing test quality test data compression edt technology embedded deterministic test atpg flow automatic test pattern generation automatic test equipment burn in test core test;embedded deterministic test;multisite testing;core test	In this talk, the EDT technology was introduced briefly along with a description of the hardware and the methodology used to achieve high test-data compression. The advantages of the approach in terms of encoding capacity, ability to handle unknowns, minimal hardware overhead, and close resemblance to a conventional ATPG flow were discussed. Since the technology requires very few pins to drive the decompressor from an ATE and observe responses at the output, it is attractive for burn-in test, core test, multisite testing, and is suitable for parts tested on VLCTs. The presentation touched upon these test techniques that directly benefit from using the proposed solution. With newer technology nodes, diagnosis is becoming critical for yield ramp up, faster time to volume, and first silicon debug. No compression solution is complete without an easy way to diagnose failures during manufacturing test. The ability to perform direct diagnosis from compressed patterns within the EDT framework were presented	burn-in;data compression;event dispatching thread;fault coverage;overhead (computing);ramp simulation software for modelling reliability, availability and maintainability;test data;turing test	Nilanjan Mukherjee	2005	14th Asian Test Symposium (ATS'05)	10.1109/ATS.2005.70	data compression;reliability engineering;embedded system;automatic test equipment;electronic engineering;real-time computing;fault coverage;computer science;engineering;automatic test pattern generation;test compression;design for testing;burn-in;statistics;test harness	Arch	21.654150555663012	53.4462701702327	128234
4527878927e14610eb95781fec82bf52c155ddcc	efficient identification of non-robustly untestable path delay faults	path delay faults nonrobustly untestable path delay faults iscas 85 benchmark circuits atpg path delay testing cost effective methods;automatic testing;delays logic testing automatic testing economics combinational circuits;logic testing;path delay fault;cost effectiveness;fault diagnosis circuit faults circuit testing robustness delay effects electrical fault detection logic testing benchmark testing fault detection redundancy;economics;delays;combinational circuits	This paper presents an efficient implication-based approach for identifying non-robustly untestable path delay faults. It starts from possible conflicts to find untestable faults by performing static implication. It is neither path-oriented nor space-search based. Experimental results for ISCAS'85 benchmark circuits demonstrate that a significant portion of non-robustly non-robustly untestable path delay faults is identified efficiently. The method can be combined easily with ATPG-based approaches for path delay testing to yield cost effective methods for path delay faults in large circuits.		Zhongcheng Li;Robert K. Brayton;Yinghua Min	1997		10.1109/TEST.1997.639715	reliability engineering;electronic engineering;real-time computing;cost-effectiveness analysis;computer science;mathematics;combinational logic;algorithm	EDA	21.381000515776705	51.4550164201881	128375
b4e321c112a2744d99b5dc30756dabcf197d77eb	system level lbist implementation	silicon;system engineering;deep submicron silicon process technology;x source isolation lbist low power;product debugging;clocks;routing;microprocessor chips built in self test fault diagnosis logic testing;testing and debugging;testing;clocks centralized control built in self test system testing vehicle crash testing circuit testing routing energy consumption logic testing silicon;chip;cpu interface;built in self test;low power;tap interface;logic gates;system level lbist implementation;logic testing;product testing;cpu interface system level lbist implementation deep submicron silicon process technology tap interface system level testing product testing product debugging;lbist;x source isolation;power demand;fault diagnosis;microprocessor chips;system level testing	In industry, chips become more and more complicated as advancing in deep submicron silicon process technology. LBIST can cover some newly emerging faults missed by traditional ATPG. That's why LBIST is becoming more and more popular. Besides launching LBIST through TAP interface, CPU launch LBIST feature may provide more flexibility for system-level or product testing and debugging. System engineer can easily kick-off LBIST with CPU interface instead of TAP.	central processing unit;debugging;logic built-in self-test;very-large-scale integration	Fei Zhuang;Junbo Jia;Xiangfeng Li	2008	2008 17th Asian Test Symposium	10.1109/ATS.2008.81	chip;embedded system;routing;electronic engineering;real-time computing;logic gate;telecommunications;computer science;product testing;engineering;operating system;software testing;silicon	SE	10.967169478291959	54.84034857977436	128440
afb8afe99e13187b38933bde7e8e814fee85bee9	a 5.25-v-tolerant bidirectional i/o circuit in a 28-nm cmos process	voltage stress;i o circuit;bidirectional i o;cmos	A 5.25-V-tolerant bidirectional I/O circuit has been developed in a 28-nm standard complementary metal-oxide-semiconductor CMOS process with only 0.9 and 1.8V transistors. The transistors of the I/O circuit are protected from over-voltage stress by cascode transistors whose gate bias level is adaptively controlled according to the voltage level of the I/O pad. The n-well bias level of the p-type metal-oxide-semiconductor transistors of the I/O circuit is also adapted to the voltage level of the I/O pad to prevent any junction leakage. The 5.25-V-tolerant bidirectional I/O circuit occupies 40µm×170µm of silicon area. Copyright © 2014 John Wiley & Sons, Ltd.	cmos;die shrink;input/output	Keun-Seon Ahn;Jaewoo Park;Changsik Yoo	2015	I. J. Circuit Theory and Applications	10.1002/cta.1981	electronic engineering;telecommunications;computer science;engineering;electrical engineering;cmos;discrete circuit	EDA	17.52387833229427	58.87926460339633	128457
3fbb08bd93ddf8c0752946f1f70fed120cb65d5f	delay evaluation of high speed data-path circuits based on threshold logic	diseno circuito;arithmetic operation;puerta logica;capacitancia;data path;operation arithmetique;estudio comparativo;circuit design;circuit integre rapide;excitador;operacion aritmetica;circuito logico;tecnologia mos complementario;camino datos;threshold logic;porte logique;etude comparative;parallel architectures;circuit logique;architecture parallele;logica umbral;low power electronics;comparative study;chemin donnees;driver;conception circuit;capacitance;temps retard;delay time;power consumption;logique seuil;excitateur;consommation energie electrique;technologie mos complementaire;logic circuit;logic gate;electronique faible puissance;tiempo retardo;high speed;high speed integrated circuits;complementary mos technology;capacite electrique	The main result is the development, and delay comparison based on Logical Effort, of a number of high speed circuits for common arithmetic and related operations using threshold logic. The designs include 8 to 64-input AND, 4-bit carry generate, and the carry-out of a (7,3) parallel (population) counter. The circuits are designed using both domino gates and the recently proposed CMOS Charge Recycling Threshold Logic (CRTL). It is shown that compared to domino, the CRTL design examples are typically between 1.3 and 2.7 times faster over a wide range of load values, while presenting the same input capacitance to the driver.	4-bit;cmos;cpu power dissipation;datapath;harris affine region detector;logic gate;logical effort;very-large-scale integration	Peter Celinski;Derek Abbott;Sorin Dan Cotofana	2004		10.1007/978-3-540-30205-6_92	electronic engineering;logic gate;engineering;electrical engineering;algorithm	EDA	18.182086370090232	54.91071758417926	128528
129c2b30666b23d03a6f72d3ca7fbe71870e55bd	a conditional isolation technique for low-energy and high-performance wide domino gates	leakage current	A new conditional isolation technique (CI-Domino) in domino logic is proposed for wide domino gates. This technique can not only reduce the subthreshold and gate oxide leakage currents simultaneously without sacrificing circuit performance, but also it can be utilized to speed up the evaluation time of domino gate. Simulations on high fan-in domino OR gates with 0.18 mum process technology show that the proposed technique achieves reduction on total static power by 36%, dynamic power by 49.14%, and delay time by 60.27% compared to the conventional domino gate. Meanwhile, the proposed technique also gains about 48.14% improvement on leakage tolerance.	and gate;cpu power dissipation;computer simulation;domino logic;fan-in;gate oxide;opto-isolator;spectral leakage;speedup	How-Rern Lin;Wei-Hao Chiu;Tsung-Yi Wu	2007	TENCON 2007 - 2007 IEEE Region 10 Conference		electronic engineering;real-time computing;engineering;electrical engineering	EDA	18.136080217460133	58.75865215003198	128535
e39e385dc3273a9a9c1c4880ba6712467f1b2c90	wafer-level modular testing of core-based socs	integer programming;integrated circuit packaging;integrated circuit testing;linear programming;system-on-chip;wafer level packaging;soc;core-based system-on-chip;integer linear programming;optimal test-length selection technique;product cost;product packaging;semiconductor industry;statistical yield modeling;wafer-level modular testing;defect-screening;integer linear programming;system-on-chip (soc) test;test-length selection;wafer sort	Product cost is a major driver in the consumer electronics market, which is characterized by low profit margins and the use of core-based system-on-chip (SoC) designs. Packaging has been recognized as a significant contributor to the product cost for such SoCs. To reduce packaging cost and the test cost for packaged chips, wafer-level testing (wafer sort) is used in the semiconductor industry to screen defective dies. However, since test time is a major practical constraint for wafer sort, even more so than for package test, not all the scan-based digital tests can be applied to the die under test. We present an optimal test-length selection technique for wafer-level testing of core-based SoCs. This technique, which is based on a combination of statistical yield modeling and integer linear programming, allows us to determine the number of patterns to use for each embedded core during wafer sort such that the probability of screening defective dies is maximized for a given upper limit on the SoC test time. We also present a heuristic method to handle large next-generation SoC designs. Simulation results are presented for five of the ITC'02 SoC Test benchmarks, and the optimal test-length selection approach is compared with the heuristic method.	embedded system;heuristic;integer programming;linear programming;selection algorithm;semiconductor industry;simulation;software bug;statistical model;system on a chip;wafer (electronics);wafer testing	Sudarshan Bahukudumbi;Krishnendu Chakrabarty	2007	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2007.903943	system on a chip;embedded system;electronic engineering;integer programming;computer science;engineering;electrical engineering	EDA	23.47540559629352	55.33919516665065	128547
82b85b6435bd49140469d835c5825818c6fde867	an optimal algorithm for spiral floorplan designs	vlsi circuit layout cad computational complexity;area optimization vlsi layout optimal algorithm spiral floorplan designs;very large scale integration;design optimization;polynomials;process design;optimization problem;computational complexity;spirals;vlsi;circuit layout cad;computer science;spiral floorplan designs;vlsi layout;optimal algorithm;algorithm design and analysis;spirals algorithm design and analysis computer science design optimization very large scale integration process design partitioning algorithms polynomials optimization methods;partitioning algorithms;optimization methods;area optimization	5/18/2005 3 ET 4255 Electronic Design Automation 2005 © Nick van der Meijs Collection of modules with variable dimensions, pin positions, delay, power Netlist Geometric constraints Electrical constraints Estimates of various properties Given of (legal and) optimal module locations Assignment Floorplanning Collection of modules with fixed dimensions, pin positions, delay, power Netlist Geometric constraints Electrical constraints Given of (legal and) optimal module locations Assignment Placement Q: which is more difficult?	algorithm;electronic design automation;floorplan (microelectronics);netlist;spiral model	Cheng-Hsi Chen;Ioannis G. Tollis	1991		10.1109/ICCD.1991.139962	mathematical optimization;computer science;theoretical computer science;very-large-scale integration;engineering drawing;algorithm	EDA	15.000213280686854	50.8420302100488	128601
41a3660c679f05dfdcc28f6273029b03df6c3a34	optimal allocation of ldos and decoupling capacitors within a distributed on-chip power grid		Parallel on-chip voltage regulation, where multiple regulators are connected to the same power grid, has recently attracted significant attention with the proliferation of small on-chip voltage regulators. In this article, the number, size, and location of parallel low-dropout (LDO) regulators and intentional decoupling capacitors are optimized using mixed integer non-linear programming formulation. The proposed optimization function concurrently considers multiple objectives such as area, power noise, and overall power consumption. Certain objectives are optimized by putting constraints on the other objectives with the proposed technique. Additional constraints have been added to avoid the overlap of LDOs and decoupling capacitors in the optimization process. The results of an optimized LDO allocation in the POWER8 chip is compared with the recent LDO allocation in the same IBM chip in a case study where a 20% reduction in the noise is achieved. The results of the proposed multi-criteria objective function under a different area, power, and noise constraints are also evaluated with a sample ISPD’11 benchmark circuits in another case study.	benchmark (computing);coupling (computer programming);die (integrated circuit);dropout (neural networks);electric power conversion;iteration;linear programming formulation;loss function;mathematical optimization;maximum power transfer theorem;nonlinear programming;nonlinear system;optimization problem;optimizing compiler;performance per watt;requirement;system on a chip;voltage regulation;voltage regulator	Sayed Abdullah Sadat;Mustafa Canbolat;Selçuk Köse	2018	ACM Trans. Design Autom. Electr. Syst.	10.1145/3177877	real-time computing;power8;voltage regulator;grid;chip;physical design;electronic circuit;decoupling capacitor;computer science;electronic engineering;voltage regulation	EDA	16.69735559773519	54.80373884215213	128728
55d5ec88867f6c409c674b12fe75ac9656edfdbf	measurement ratio testing for improved quality and outlier detection	analog test values;fabrication outlier elimination;test outlier detection;ate test data measurement ratio testing test outlier detection analog test values product quality production test data fabrication outlier elimination;outlier detection;production electronic equipment testing time measurement performance evaluation fabrication materials testing radio frequency costs packaging particle measurements;statistical analysis;production test data;measurement ratio testing;product quality;production testing;statistical analysis production testing;ate test data	Measurement Ratio tests of analog test values are used to improve product quality using existing ATE test data. The use of measurement ratio tests is shown to have no impact on overall lot test time, while improving product quality through the detection of fabrication and test outliers. The definition of a data driven method to select test pairs for Measurement Ratio testing based on production test data improves fabrication outlier elimination in production.	anomaly detection;test data	Jeffrey L. Roehr	2007	2007 IEEE International Test Conference	10.1109/TEST.2007.4437616	reliability engineering;econometrics;anomaly detection;computer science;engineering;statistics	SE	23.20103560442273	55.19678018878973	128910
6ab39db888326d42822d527eb92be5837eaccc85	pre-si estimation and compensation of sram layout deficiencies to achieve target performance and yield	yield estimation random access memory fets lithography design methodology circuit simulation circuit stability hardware microelectronics clocks;random access memory;integrated circuit yield;integrated circuit layout;sensors;layout;memory access;technology scaling;sram chips integrated circuit layout integrated circuit yield;logic gates;process parameters;fets;transistors;sram array tuning sram layout deficiencies sram cell ramp up cycles access failure reduction memory access clock cycle period;design methodology;sram chips	With technology scaling, process constraints and imperfections result in significant variation of post-Si performance and stability of SRAM from designed/target pre-Si parameters. Modification/ re-optimization of SRAM cell and/or tuning of process parameters to meet target performance and stability are limited by area constraints and involve several technology ramp-up cycles. For reducing access failures, if process is not fine tuned, memory access clock cycle period may need to be increased thereby compromising performance. We propose a design methodology to meet the target performance and reduce access failures by tuning the SRAM array peripherals instead of tuning the SRAM cell and process parameters. Proposed design methodology is supported by numerical framework and validated by simulation results on 45 nm PDSOI technology. We further show that our methodology does not impact the READ stability of a cell.	cell (microprocessor);clock signal;image scaling;mathematical optimization;numerical analysis;peripheral;ramp simulation software for modelling reliability, availability and maintainability;static random-access memory	Aditya Bansal;Rama N. Singh;Saibal Mukhopadhyay;Geng Han;Fook-Luen Heng;Ching-Te Chuang	2008	2008 IEEE International Conference on Computer Design	10.1109/ICCD.2008.4751901	layout;embedded system;electronic engineering;real-time computing;design methods;logic gate;engineering;sensor;electrical engineering;integrated circuit layout;transistor	EDA	20.075801722920833	57.72589754492734	129079
a38b79170961076385f7984163a9dee5db63eecf	clock suppression techniques for synchronous circuits	digital circuit;concepcion asistida;computer aided design;simulation logique;concepcion circuito;cpu performance synchronous circuits clock suppression based technique abstraction level synchronous design techniques logic simulation performance switch level simulations;logic simulation;simulacion logica;logic cad clocks digital simulation integrated logic circuits;integrated circuit;clocks;circuit design;circuito integrado;clocks circuit simulation synchronization logic arrays discrete event simulation logic design delay timing central processing unit circuit synthesis;algorithme;circuit numerique;algorithm;design technique;supresion;circuit synchrone;circuito numerico;conception assistee;horloge;conception circuit;procesador;integrated logic circuits;processeur;logic cad;circuito sincrono;clock;processor;reloj;circuit integre;digital simulation;suppression;synchronous circuit;algoritmo	In 1990, the authors presented an outline for a clock suppression based technique that took advantage of the higher abstraction level provided by synchronous design techniques to improve logic simulation performance [l]. This paper will elaborate on those techniques and present extensions that can offer an average performance increase of over 5 x and a peak performance increase of over 10 X that of a conventional logic simulator. We shall show the viability of our approach by presenting results from switch-level simulations of large industrial examples. Finally, we shall demonstrate that because clock suppression based techniques are CPU-bound, they can take advantage of the recent explosive growth of CPU performance.	abstraction layer;best, worst and average case;central processing unit;logic simulation;synchronous circuit;zero suppression	Rahul Razdan;Gabriel P. Bischoff;Ernst G. Ulrich	1993	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.256930	clock;embedded system;electronic engineering;real-time computing;asynchronous circuit;computer science;electrical engineering;integrated circuit;computer aided design;logic simulation;circuit design;synchronous circuit;digital electronics	EDA	18.065598920514386	53.9504138113891	129143
6b209b0f3ddf714a6ffbfd70d94ad75d053f65d0	minimizing the number of empty rooms on floorplan by dissection line merge	concepcion asistida;computer aided design;diseno circuito;optimisation;tecnologia electronica telecomunicaciones;implantation topometrie;optimizacion;circuit design;circuit vlsi;empty room;layout;rectangular dissection;vlsi circuit;conception assistee;optimization;conception circuit;module placement;dissection line;circuito vlsi;tecnologias;grupo a;floorplan;implantacion topometria	This paper discusses how to minimize the number of dissection lines regarded as wiring channels on a floorplan corresponding to a placement of n modules. In a floorplan (rectangular dissection), the number of dissection lines exceeds the number of rooms exactly by three. Since a floorplan obtained from a given module placement may have many empty rooms where no module is assigned, redundant wiring channels and wire bends may also be generated. Hence, in order to reduce redundant channels and wire bends, removal of empty rooms is required. For this purpose, we formulate a problem of obtaining a floorplan with the minimum possible empty rooms based on a given module placement. Then, we propose a method of removing as many redundant empty rooms as possible by merging dissection lines on a floorplan in O(n) time. The number of empty rooms in the resultant floorplan is reduced to n - ⌊√4n - 1⌋ or less.		Chikaaki Kodama;Kunihiro Fujiyoshi	2005	IEICE Transactions	10.1093/ietisy/e88-d.7.1389	layout;floorplan;computer science;computer aided design;circuit design	Vision	15.347309471068991	50.52514990112321	129399
988ae78dc21c4ad3144a45f79a3a267fd0da8839	physical design tools for hierarchy	rdr;restrictive design rules;design automation;technology migration;ret driven layout;physical design;chip;number of factors;hierarchical design	There are a number of factors that motivate the use of hierarchical physical design approaches for ASIC and mircroprocessor designs. While microprocessor designs have traditionally been done using hierarchy, the trend in ASIC designs is more recent. The growing use of hierarchy presents new challenges to the design automation community. Tools and algorithms that are designed to work well on flat chips certainly can be applied to individual partitions of a hierarchical design. This works well for some tasks, but there are a host of new problems introduced by hierarchy boundaries that are not addressed by such an approach. This talk will focus on some of the new and interesting physical design automation tasks, with an emphasis on the placement and timing closure aspects of the hierarchy problem.	algorithm;application-specific integrated circuit;electronic design automation;microprocessor;physical design (electronics);timing closure	Paul G. Villarrubia	2005		10.1145/1055137.1055175	chip;physical design;simulation;electronic design automation;computer science;design flow	EDA	12.119528860214343	54.97546556212934	129464
e7a89a725a7868cd0a04e420f39937f3d8bd9f44	on the design of a highly testable cell library	lop;line open fault;logic element;pu/pd;pull-up/pull-down;design for testability;bridging fault;dl;dft;transistor stuck-on;transistor stuck-open;defect level;bst;line stuck-at;boundary scan test;built-in self test;tsop;fault coverage;tson;fc;bist;bri;physical failure mode;phfm;le;lsa	"""In this paper, a new mHbodology for pby.sieal &stability analysi.~ is used to derive a new cell library, which can rnsur( n high cor,fr.gr of rrnlistic faults, using teat patterns derived for Line Sl*,ck-al (LSA) fault d~lcction. The increased h'stability obtained with this new library, with constrained area overhead, is dfmon,~lmHd, by mean.~ of a Ie.M chip implemenling one of I.qCAS'85 benchmarks (c432) a ,d list circuitry to allow Hou,d.rg Scan T~st (BST). Built-In Self Test (BIST) and Scan T~st of the ¢432. Simulatio, r~sults shou"""" that, fl, r n 2_nletal, C.I[OS preeess lin*: dominated by bridging d*ficts, the realistic fault ror~ l~t!lt. FC':j, can b¢ hiahrr than the gate-level, LSA fault coverage, FC. Interacting cell dcsig, i~ al.~o Mm,' , to bt t~,'aMiog, since il~crrased testability can be obtained. This r~sall is importaol, ,~iac¢ I(' dt.~ign is highly repelili¢,e; be.ca, a limited effort in cell layout improvemeM can irlh'oducc a .~ig#iflcant de..ign impromme,t."""	bridging (networking);built-in self-test;electronic circuit;fault coverage;local interconnect network;overhead (computing);software testability	M. Saraiva;Marcelino B. Santos;A. P. Casimiro;Isabel C. Teixeira;João Paulo Teixeira	1992	Microprocessing and Microprogramming	10.1016/0165-6074(92)90343-6	embedded system;parallel computing;real-time computing;fault coverage;automatic test pattern generation;test compression	EDA	21.47522574943469	52.83536504626349	129473
cd6106cec6bf900ed014a3f75034e6a32c100d25	a common subexpression elimination tree algorithm	subexpression space binary signed digit bsd common subexpression elimination cse multiple constant multiplication mcm;trees mathematics computational complexity linear programming;linear programming optimization methods subexpression elimination tree algorithm multiple constant multiplication operation binary signed digit number system representation tree minimum complexity hardware complexity;trees mathematics;computational complexity;linear programming	A common subexpression elimination algorithm is proposed to minimize the complexity of the multiple constant multiplication operation. The coefficients (constants) of the multiple constant multiplication are represented using the binary signed digit number system. The binary signed digit representations of each coefficient are enumerated using the representation tree. The algorithm traverses the tree to calculate the possible subexpressions at each node. Each subexpression is used to find a possible decomposition for the coefficient to be encoded. A complexity formula is proposed to compare the decompositions. The algorithm is designed to prune the tree when it finds a decomposition with minimum complexity. This reduces the search space while minimizing the hardware complexity. Results show that the algorithm has better performance than other published algorithms including linear programming optimization methods. The algorithm outperforms the subexpression sharing method in that uses only the canonical signed-digit representations.	adder (electronics);algorithm;bsd;binary number;binary-coded decimal;coefficient;common subexpression elimination;critical path method;linear programming;mathematical optimization;multi-chip module;software propagation	Firas Al-Hasani;Michael P. Hayes;Andrew Bainbridge-Smith	2013	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2013.2244328	arithmetic;time complexity;discrete mathematics;common subexpression elimination;computer science;linear programming;mathematics;computational complexity theory;algorithm;partial redundancy elimination	EDA	14.757689383075583	46.928734341120816	129535
d6270e160e7ceb3b4045fb9fe9fbbdf56e50d319	cmos open fault detection by appearance time of switching supply current	circuit under test;fault detection current supplies circuit testing circuit faults logic testing cmos logic circuits delay electrical fault detection integrated circuit modeling semiconductor device modeling;feasibility cmos open fault detection supply current test method switching supply current open defects signal lines cmos logic circuits test input vector sensor circuit;cmos logic circuits;fault detection;test methods;integrated circuit testing fault diagnosis cmos logic circuits;integrated circuit testing;fault diagnosis	In this paper, a new dynamic supply current test method is proposed for detecting open defects on signal lines in CMOS logic circuits. The method is based on the appearance time of dynamic supply current that flows when a test input vector is provided to a circuit under test. Also, we introduce our designed sensor circuit of the appearance time. Feasibility of tests based on the test method is examined by some experiments. The experimental results show that open defects on signal lines in CMOS logic circuits will be detected by the test method.	cmos;electronic design;emoticon;experiment;fault detection and isolation;logic gate;sensor;simulation;test vector	Masaki Hashizume;Tetsuo Akita;Hiroyuki Yotsuyanagi;Takeomi Tamesada	2004	Proceedings. DELTA 2004. Second IEEE International Workshop on Electronic Design, Test and Applications	10.1109/DELTA.2004.10036	mixed-signal integrated circuit;embedded system;logic probe;electronic engineering;real-time computing;logic optimization;logic level;asynchronous circuit;logic gate;logic family;computer science;engineering;stuck-at fault;automatic test pattern generation;pass transistor logic;diode-or circuit;integrated injection logic;pull-up resistor;circuit extraction;test method;digital electronics;fault detection and isolation;statistics;resistor–transistor logic	EDA	23.057697765334606	52.954972408940534	129620
f724f90e8c4dc4772ceb252c73df92354ae4af47	diagnosis algorithm of immunity-based system with continuous variable of mutual test results among sensors	sensor systems fault detection availability signal processing algorithms fault diagnosis;mutual test diagnosis algorithm immunity based system;fault diagnosis algorithm theory;mutual test;immunity based system;diagnosis algorithm;fault detection fault diagnosis algorithm sensors high availability system failure point detection immunity based system diagnosis fault modes	The fault diagnosis for high availability system is required that it detects failure points as quick as possible. Moreover, it can realize the much higher availability, if it detects the point that is more likely to break down while the system operates normally. To meet these requirements, we propose a new algorithm for the immunity-based system diagnosis, which can detect unknown fault modes. The immunity-based system diagnosis has mutual test among sensors in the system. Proposed algorithm has continuous variables of its mutual test results among sensors. The variables are calculated from the deviation from typical relationship among output of sensors. Our experimental results demonstrate that proposed algorithm needs much less number of times of sampling than conventional algorithm for fault detection, and it can detect the sensor that has the largest error in the system while system operates normally.	experiment;fault detection and isolation;high availability;medical algorithm;requirement;sampling (signal processing);sensor	Koji Wada;Takashi Toriu;Hiromitsu Hama	2013	2013 Ninth International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIH-MSP.2013.70	embedded system;real-time computing;fault coverage;stuck-at fault;distributed computing	Robotics	23.53309273972959	50.79533600620787	129621
d80fae839be34e67642c9238fbfb100d5a98905b	nbti aware ig-finfet based sram design using adaptable trip-point sensing technique	degradation logic gates random access memory stress threshold voltage mathematical model finfets;reliability;time 3 year nbti adaptable trip point sensing technique reliability short channel effect self heating problem negative bias temperature instability compensation technique independent gate finfet hspice simulation ptm ig finfet technology snm rnm stability sram array design size 32 nm temperature 125 degc;nbti;stability;sram chips circuit stability compensation integrated circuit design integrated circuit reliability mosfet negative bias temperature instability semiconductor device reliability sensors;6t sram finfet reliability nbti stability;6t sram;finfet	The progressive scaling demands effort from both the circuit and the device level, to cope with circuit variability and reliability issues. Advent of FinFET technology has suppresses the short channel effects and variability, but still suffers with self heating problem consequently increases temporal degradations. In this paper, we investigate severity of Negative Bias Temperature Instability (NBTI) and proposes an adaptable trip point sensing based compensation technique to satisfy performance metrics for NBTI aware Independent Gate (IG) FinFET based SRAM. Simulation results are carried out using HSPICE with PTM 32nm IG-FinFET technology demonstrate that threshold voltage deviates from its nominal value by 17%, causing 6% and 13% degradation in SNM and RNM, respectively under NBTI degradation at 125°C for 3 years. The proposed technique yields 42% reduced read failures under NBTI. Thus, proposed approach improves the stability of SRAM array during its operational life and hence, reliability of the system.	elegant degradation;heart rate variability;image scaling;negative-bias temperature instability;polynomial texture mapping;reliability engineering;risk-neutral measure;spice 2;simulation;static random-access memory	Nandakishor Yadav;Shikha Jain;Manisha Pattanaik;G. K. Sharma	2014	2014 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH)	10.1145/2770287.2770316	electronic engineering;real-time computing;engineering;electrical engineering	EDA	19.844149147326107	59.21082934650993	129628
d93d1fdd6f05e631e13bfc2a2093bc66430fe021	static test compaction for full-scan circuits based on combinational test sets and non-scan sequential test sequences	automatic testing;boundary scan testing;automatic testing boundary scan testing combinational circuits logic testing integrated circuit testing;circuit testing sequential analysis compaction logic testing circuit faults electrical fault detection fault detection clocks cities and towns application software;sequential test;logic testing;test application time static test compaction full scan circuits combinational test sets nonscan sequential test sequences short primary input sequences primary input sequences subsequences;integrated circuit testing;combinational circuits	We propose a new static compaction procedure for scan circuits that generates a test set with a reduced test application time. The proposed procedure combines the advantages of two earlier static compaction procedures, one that tends to generate large numbers of tests with short primary input sequences, and one that tends to generate small numbers of tests with long primary input sequences. The proposed procedure starts from a test set with a large number of tests and long primary input sequences, and it selects a subset of the tests and subsequences of their primary input sequences. It thus has the flexibility of finding an appropriate balance between the number of tests and the lengths of the primary input sequences in order to minimize the test application time.	combinational logic;data compaction	Irith Pomeranz;Sudhakar M. Reddy	2003		10.1109/ICVD.2003.1183159	electronic engineering;scan chain;real-time computing;computer science;automatic test pattern generation;test compression;mathematics;sequential logic;combinational logic;algorithm	EDA	21.108994738735596	51.23148885055964	129726
a757b952ce23c8f9d7c727615a1e52647f02875d	analytical delay model considering variability effects in subthreshold domain	cmos integrated circuits;complementary metal oxide semiconductor;subthreshold complementary metal oxide semiconductor cmos;integrated circuit;inverters;delay logic gates semiconductor device modeling integrated circuit modeling inverters transistors predictive models;logic gates;integrated circuit modelling;threshold voltage;propagation delay;semiconductor device modeling;transistors;mosfet cmos integrated circuits integrated circuit modelling;integrated circuit modeling;predictive models;mosfet;prediction model;variability analytical model propagation delay subthreshold complementary metal oxide semiconductor cmos;variability;logic gate;analytical model;energy saving;transistor stack analytical delay model process variability effects subthreshold domain ultralow power circuits energy savings transistor threshold voltages cmos circuits transient variation transistor on current	The demand of ultralow-power circuits has significantly increased in the last few years. Owing to its great potential in energy savings, the use of supply voltage near or below the transistors' threshold voltages has gained particular attention. Designing these kinds of circuits is still a challenge, particularly when latest advanced process technologies are employed. This brief proposes novel analytical delay models for CMOS circuits running in the subthreshold regime. The delay models proposed here take the effects of the process variability and of the transient variation of the transistors' on-current during the switching into account. Owing to this, delays are predicted with accuracy significantly higher than existing accurate delay models. Furthermore, the novel models are also suitable for gates with transistors' stacks.	cmos;heart rate variability;spatial variability;transistor	Fabio Frustaci;Pasquale Corsonello;Stefania Perri	2012	IEEE Transactions on Circuits and Systems II: Express Briefs	10.1109/TCSII.2012.2184377	control engineering;electronic engineering;logic gate;computer science;engineering;electrical engineering;predictive modelling;cmos	EDA	21.136617894143654	58.76442298192031	129759
58b4fff76baf616bebd8c76abcbbd5015420950c	an experimental system for logic design data accumulation and retrieval	logic design		experimental system;logic synthesis;tree accumulation	R. J. Preiss	1962			experimental system;logic synthesis;logic optimization;theoretical computer science;register-transfer level;computer science	EDA	19.37344723812344	46.95936282491358	129785
56225133d97cdb6cb34e2daeeae2d471fc01fccd	tsunami: a light-weight on-chip structure for measuring timing uncertainty induced by noise during functional and test operations	integrated circuit;on chip measurement;speed characterization;post silicon validation;chip;power supply noise;temperature;high sensitivity	Noise such as voltage drop and temperature in integrated circuits can cause significant performance variation and even functional failure in lower technology nodes. In this paper, we propose a light-weight on-chip sensor that measures timing uncertainty induced by noise during functional and test operations. The proposed on-chip structure facilitates speed characterization under various workloads and test conditions. Simulation results show that it offers very high sensitivity to noise even under variations. The structure requires negligible area in the chip.	integrated circuit;overhead (computing);semiconductor research corporation;simulation	Shuo Wang;Mark Mohammad Tehranipoor	2012		10.1145/2206781.2206826	chip;embedded system;electronic engineering;real-time computing;temperature;telecommunications;computer science;engineering;electrical engineering;integrated circuit;post-silicon validation	EDA	20.336812488785064	58.42914484303252	129860
44ba19a8091e30cf9f9b60fd2197048da9376c4a	low power illinois scan architecture for simultaneous power and test data volume reduction	atpg patterns;test data volume reduction;active power;circuit testing power dissipation energy consumption automatic test pattern generation logic testing switching circuits built in self test broadcasting transistors integrated circuit testing;combinational cells;switching circuits;automatic test pattern generation;cut low power illinois scan architecture test data volume reduction power dissipation scan testing combinational cells clock tree atpg patterns scan cells;power integrated circuits automatic test pattern generation low power electronics;supply gating;scan testing;built in self test;low power;energy consumption;clock tree;cut;transistors;power dissipation;logic testing;low power electronics;integrated circuit testing;circuit testing;low power design;hypergraph partitioning;broadcasting;low power illinois scan architecture;scan cells;power integrated circuits	We present Low Power Illinois scan architecture (LPILS) to achieve power dissipation and test data volume reduction, simultaneously. By using the proposed scan architecture, dynamic power dissipation during scan testing in registers and combinational cells can be significantly reduced without modifying the clock tree of the design. The proposed architecture is independent of the ATPG patterns and imposes a very small combinational area penalty due to the logic added between the scan cells and the CUT. Experimental results for two industrial circuits show that we can simultaneously achieve up to 47% reduction in dynamic power dissipation due to switching and 10X test data volume reduction with LPILS over basic scan.	cmos;clock signal;combinational logic;test data	Anshuman Chandra;Felix C Ng;Rohit Kapur	2008	2008 Design, Automation and Test in Europe	10.1145/1403375.1403486	electronic engineering;scan chain;real-time computing;cut;computer science;engineering;electrical engineering;dissipation;automatic test pattern generation;operating system;ac power;broadcasting;transistor;low-power electronics	EDA	19.527757519849896	53.44629825504263	129914
c46f5e8ca11e86b28e3274085a455166ceefca14	efficient compression and application of deterministic patterns in a logic bist architecture	built in self test deterministic pattern logic bist architecture automatic test pattern generator linear feedback shift register;built in self test automatic test pattern generation logic testing circuit testing test pattern generators circuit faults costs silicon logic design design for testability;fault simulation;automatic test pattern generation;linear feedback shift register;logic testing built in self test automatic test pattern generation shift registers fault simulation;built in self test;shift registers;logic testing;test generation;fault coverage;architectural pattern;automatic test pattern generator;test generation atpg;self test bist;industrial design	We present a novel method to efficiently generate, compress and apply test patterns in a logic BIST architecture. Patterns are generated by a modified automatic test pattern generator (ATPG) and are encoded as linear feedback shift register (LFSR) initial values (seeds); one or more patterns can be encoded into a single LFSR seed. During test application, seeds are loaded into the LFSR with no cycle overhead. The method presented achieves reductions of at least 100x in test data and 10x in tester cycles compared to deterministic ATPG while maintaining complete fault coverage, as confirmed by experimental results on industrial designs.	fault coverage;linear-feedback shift register;logic built-in self-test;overhead (computing);test card;test data	Peter Wohl;John A. Waicukauski;Sanjay Patel;Minesh B. Amin	2003		10.1145/775832.775976	computer architecture;electronic engineering;real-time computing;industrial design;fault coverage;architectural pattern;computer science;automatic test pattern generation;shift register;linear feedback shift register;algorithm	EDA	20.52309014520014	51.787230704080635	129946
20ba16d523d5a8d965dfd059c3e666b611c6c79f	a low-jitter phase-locked resonant clock generation and distribution scheme	low jitter phase locked resonant clock generation power consumption resonant ring chip wide routing ring capacitance ring inductance coarse tuning synchronous design methodology rotary clock two traveling wave oscillator swo resonant standing wave oscillator cycle to cycle jitter on chip pll digital ic end to end delay minimization clock distribution network;network synthesis;clocks;clocks oscillators wires frequency control inverters phase locked loops delays;resonators;clock distribution networks;resonators circuit tuning clock distribution networks clocks jitter network synthesis phase locked oscillators;circuit tuning;jitter;phase locked oscillators;resonant oscillator clocks digitally controlled oscillators dco phase locked loop pll	Clock distribution networks have traditionally been optimized to minimize end-to-end delay of the distribution network. However, since most digital ICs have an on-chip PLL, a more relevant design goal is to minimize cycle-to-cycle jitter. In this paper, we present a novel low-jitter phase-locked clock generation and distribution methodology which uses resonant standing wave oscillators (SWOs). In contrast to traveling wave oscillator rings (TWOs or “rotary” clocks), our SWO achieves the same phase at every point in the ring, making it amenable to a synchronous design methodology. The standing wave oscillator is controlled by coarse as well as fine tuning. Coarse tuning is achieved by varying the ring inductance, while fine tuning is accomplished by varying the ring capacitance. Clock distribution is done by routing the resonant ring chip-wide in a “comb” like manner. Experimental results demonstrate that the cycle-to-cycle jitter and skew of our approach is dramatically lower than existing schemes, while the power consumption is significantly lower as well. These benefits occur due to the resonant nature of our SWO-based clock generation and distribution approach.	arnold tongue;clock signal;end-to-end principle;performance tuning;phase-locked loop;resonance;rotary woofer;routing;synchronous circuit	Ayan Mandal;Kalyana C. Bollapalli;Nikhil Jayakumar;Sunil P. Khatri;Rabi N. Mahapatra	2013	2013 IEEE 31st International Conference on Computer Design (ICCD)	10.1109/ICCD.2013.6657089	control engineering;network synthesis filters;electronic engineering;jitter;clock angle problem;telecommunications;clock domain crossing;clock skew;computer science;control theory;resonator;synchronous circuit	EDA	16.755281379611286	55.344018039751816	129958
3855522386da0852355778341447754fc3a44b7e	a reconfiguration-based defect-tolerant design paradigm for nanotechnologies	reconfiguration;nanotechnologies;fault tolerance engineering;logic design;reconfigurable architectures;reconfiguration nanotechnologies probabilistic design defect tolerance;nanotechnology;probabilistic design;logic design reconfigurable architectures logic gates fault tolerance redundancy nanotechnology;redundancy;fault tolerance reconfigurable architecture defect tolerant probabilistic design nanotechnology nanofabrics molecular electronics reliability;logic gates;fault tolerance;scalability redundancy fabrics design methodology costs fault tolerance nuclear magnetic resonance delay iris;defect tolerance	This article discusses a novel probabilistic design paradigm targeting reconfigurable architected nanofabrics and points to a promising foundation for comprehensively addressing, at the system level, the density, scalability, and reliability challenges of emerging nanotechnologies. The approach exposes a new class of yield, delay, and cost trade-offs that must be jointly considered when designing computing systems in defect-prone nanotechnologies.	programming paradigm;scalability;software bug	Chen He;Margarida F. Jacome;Gustavo de Veciana	2005	IEEE Design & Test of Computers	10.1109/MDT.2005.76	reliability engineering;fault tolerance;electronic engineering;logic synthesis;probabilistic design;logic gate;engineering;control reconfiguration;redundancy;computer engineering	EDA	10.293684153038434	58.468107454992804	129990
07b32b2aa583280551504355fbf94a1417761f37	a cmos built-in current sensor for iddq testing	current sensor;current testing;cmos integrated circuits;evaluation performance;circuit integre cmos;appareillage essai;fiabilidad;reliability;tecnologia electronica telecomunicaciones;leakage current;performance evaluation;dissipation energie;corriente escape;evaluacion prestacion;built in current sensor;capteur courant;energy dissipation;bics;tecnologia mos complementario;essai circuit integre;miniaturisation;detection defaut;courant fuite;aparato ensayo;fiabilite;integrated circuit testing;testing equipment;sensor corriente;disipacion energia;miniaturization;iddq testing;miniaturizacion;tecnologias;grupo a;technologie mos complementaire;deteccion imperfeccion;complementary mos technology;defect detection	This paper presents a new built-in current sensor (BICS) that detects defects using the current testing technique in CMOS integrated circuits. The proposed circuit is a negligible impact on the performance of the circuit under test (CUT). In addition, no extra power dissipation and high-speed fault detection are achieved. It can be applicable in deep submicron process. The area overhead of the BICS versus the entire chip is about 9.2%. The chip was fabricated with Hynix 0.35 μm standard CMOS technology.	cmos;iddq testing	Jeong Beom Kim;Seung Ho Hong	2006	IEICE Transactions	10.1093/ietele/e89-c.6.868	current sensor;embedded system;electronic engineering;engineering;electrical engineering;dissipation;reliability;iddq testing;miniaturization;leakage;cmos;physics	HCI	19.765692625183302	55.30732880690458	130159
c33bb2225bb0ce275914ef917b72c6650865f2e8	multiple fault diagnosis in combinational circuits using sensitizing input-pairs	methode essai;multiple fault diagnosis;circuit combinateur;algorithme;algorithm;diagnostic panne;fault diagnostic;checkpoint;diagnostico pana;combiner circuit;checkpoints;test method;combinational circuit;sensitizing input pair;circuito combinador;fault diagnosis;algoritmo;subtree circuit;metodo ensayo	Abstract#R##N##R##N#This paper presents a new method for multiple fault diagnosis of combinational circuits using sensitizing input-pairs. A partition of a circuit under test into subtree circuits and a generation method for diagnostic test are described. The set of diagnostic tests used in this paper is one of sensitizing input-pairs that generate sensitizing paths including checkpoints on them.#R##N##R##N##R##N##R##N#By studying the relation between a sensitizing path generated by a sensitizing input-pair and a subtree circuit, a method is presented for multiple fault diagnosis in the subtree circuit based on the fault-free and the faulty responses observed at primary outputs. A deduction algorithm is described for a value at an output of a subtree circuit which does not have a primary output. The proposed method is applied to benchmark circuits having double faults, triple faults, and fourfold faults. Experimental results show that suspected faults are identified within 8 to 30 percent of all stuck-at 0 and 1 faults on all lines in the circuit.	combinational logic	Nobuhiro Yanagida;Hiroshi Takahashi;Yuzo Takamatsu	1995	Systems and Computers in Japan	10.1002/scj.4690260302	real-time computing;computer science;mathematics;combinational logic;test method;algorithm	EDA	22.125413799348447	50.35303325566502	130178
cca8176c1848713d22d46d768531ebb42588a7f9	improving the robustness of a switch box in a mesh of clusters fpga	switches field programmable gate arrays computer architecture multiplexing circuit faults integrated circuit reliability;size 65 nm cluster fpga mesh cmos feature shrinking size nanoelectronics microelectronics downscaling technology defect tolerance enhancement hardening cost reduction switch box multiplexer assembling industrial library;switches assembling cost reduction field programmable gate arrays logic design multiplexing equipment;parasitic extraction mesh of clusters fpga switch box reliability defect tolerance selective hardening layout	As CMOS feature sizes are shrinking, manufacturing defects are becoming a growing concern in micro and nanoelectronics. This work deals with defect tolerance in FPGAs that are surely affected by technology downscaling. In this paper, we are interested in enhancing the defect tolerance of a switch box in a mesh of clusters FPGA, while trying to reduce the hardening cost. First, we had to spot, among the switch box multiplexers, the most eligible one to be hardened. Then, we built different possible architectures for the latter by assembling different standard cells from a 65nm industrial library. These architectures were studied under single defect injection by a tool that models several possible defects for a given design according to its extracted netlist. Eventually, the most robust architecture was picked.	cmos;downscaling;field-programmable gate array;kvm switch;multiplexer;netlist;software bug;systems architecture	Arwa Ben Dhia;Mariem Slimani;Lirida A. B. Naviner	2014	2014 15th Latin American Test Workshop - LATW	10.1109/LATW.2014.6841901	embedded system;electronic engineering;engineering;computer engineering	EDA	11.646916111363236	54.591750128788334	130237
5609f42621cf32da6d6e01767076bcd7f57c3f50	high-performance fpga based on novel dss-mosfet and non-volatile configuration memory (abstract only)	look up table;high density;resistance ratio;mass production;power supply;dopant segregated schottky transistor;pass transistor logic;critical path;power consumption;high performance;nonvolatile configurable memory	New FPGA deign using Dopant-Segregated Schottky MOSFET (DSS-MOSFET) and nonvolatile configuration memory (NCM) has been presented. Both of these devices can be fabricated by mature process for mass production. DSS-MOSFET has very low On-state resistance due to the high density dopant at source/drain junction. Therefore, FPGA is one of the best applications for the use of DSS-MOSFET since DSS-MOSFET can effectively improve not only CMOS logic performance but also pass-transistor logic performance. In addition, NCM with large On/Off resistance ratio, such as ionic memory, is adopted to replace SRAM-based configuration memory. Since NCM is fabricated between interconnect layers of CMOS, silicon area is smaller than in the case of SRAM. Furthermore, since NCM is a nonvolatile device, it is possible to reduce the power consumption by cutting off the power supply of unused circuit blocks. We developed a SPICE model of DSS-MOSFET to measure the delay of basic circuit in FPGA, and confirmed about 18% delay improvement for look-up-table with four to six inputs. We also designed physical layout to evaluate the area reduction of configuration memory, and verified the area of NCM is about 2.8X smaller than that of SRAM-based. Twenty largest MCNC benchmarks indicate that 26% improvement in critical path delay on average, and 15% improvement in area delay products on average can be achieved by the use of DSS-MOSFET and NCM.	cmos;critical path method;dopant;field-programmable gate array;integrated circuit layout;ionic;lookup table;non-volatile memory;pass transistor logic;power supply;spice;schottky barrier;static random-access memory	Shinichi Yasuda;Tetsufumi Tanamoto;Kazutaka Ikegami;Atsuhiro Kinoshita;Keiko Abe;Hirotaka Nishino;Shinobu Fujita	2010		10.1145/1723112.1723187	embedded system;parallel computing;mass production;lookup table;computer science;critical path method;pass transistor logic	EDA	16.297205700556066	58.25411845302997	130312
ef18736f1c785e5991632a816f1ed154750e1736	fault-diagnosis for a class of multistage interconnection networks	single fault baseline network fault detection and location fault model multiple faults multistage interconnection networks parallel processing;multistage interconnection networks;fault detection and location;multistage interconnection network;single fault;baseline network;fault model;parallel processing;fault diagnosis;multiple faults	To study the fault-diagnosis method for a class of multistage interconnection networks a general fault model is first constructed. Specific steps for diagnosing single faults and detecting multiple faults in interconnection networks such as the indirect binary n-cube network and the flip network are then developed. The following results are derived in this study: 1) independent of the network size, only four tests are required for detecting a single fault; 2) the number of tests required for locating a single fault and determining the fault type ranges from 4 to max(12, 6 + 2 ⌈log2(log2N)⌉) except for four types of single faults in the switching elements which cannot be pinpointed at the switching element level where N is the number of inputs/outputs; 3) only four tests are required for locating a single fault if the switching element is designed in such a way that any physical defection of the switching element causes both outputs of the related switching element to be faulty; and 4) multiple faults can be detected by 2(1 + log2N) tests.	fault model;general protection fault;multistage interconnection networks;sensor	Tse-Yun Feng;Chuan-lin Wu	1981	IEEE Transactions on Computers	10.1109/TC.1981.1675693	embedded system;parallel processing;fault;parallel computing;real-time computing;fault coverage;fault indicator;computer science;stuck-at fault;fault model;distributed computing	Arch	23.126391955547188	49.141573917324465	130418
ec91276a707f54b5e11b53b75fb411d515c4fc30	a noise-tolerant matchline scheme with xor-based conditional keeper for energy-efficient tcam	energy efficiency;cadcam;noise figure;cmos integrated circuits;ternary content addressable memory;power saving;energy efficient tcam;cmos technology;tsmc;circuit noise;energy efficient;1 2 v;turn off;and type match line scheme;power consumption cmos integrated circuits content addressable storage integrated circuit design low power electronics memory architecture;integrated circuit design;noise tolerant matchline scheme;energy consumption;memory architecture;associative memories;0 13 micron;noise reduction;electronics industry;computer aided manufacturing;xor based conditional keeper;energy efficiency circuit noise computer aided manufacturing cadcam noise figure semiconductor device noise energy consumption noise reduction electronics industry cmos technology;proceedings paper;low power electronics;semiconductor device noise;power consumption;content addressable storage;search time;power demand;1 2 v noise tolerant matchline scheme and type match line scheme xor based conditional keeper energy efficient tcam ternary content addressable memory search time power consumption tsmc cmos technology 0 13 micron	A novel AND-type match-line scheme with XOR-based conditional keeper for ternary content-addressable memory (TCAM) are presented in this paper. The XOR-based conditional keeper is turned off at some critical moments to reduce the search time and power consumption. High fan-in AND-type match-line schemes are used to demonstrate the effectiveness of the XOR-based conditional keeper in the presence of noise sources. 37.8% search time reduction and 15.6% power saving are achieved by using the proposed TCAM architecture. Based on TSMC 0.13 mum CMOS technology at 1.2 V supply voltage, a 256 words times 128 bits ternary CAM is designed. The simulation results show that the search time of proposed TCAM architecture is 1.17 ns and energy metric of proposed TCAM architecture is 0.752 fJ/search	cmos;content-addressable memory;exclusive or;fan-in;keeper (password manager);simulation;telecommunications access method	Chung-Hsien Hua;Chi-Wei Peng;Wei Hwang	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1692749	embedded system;computer vision;electronic engineering;computer hardware;telecommunications;computer science;engineering;efficient energy use;cmos;computer-aided manufacturing	Arch	17.27314372584433	58.39353865233428	130504
bf7301fd646d5639049b8c88c7e39dbd819a7547	simultaneous voltage island generation and floorplanning	competitive power consumption;design automation;power supply circuits;logic design;circuit layout;physical design;power supply circuits circuit layout deterministic algorithms logic design low power electronics;law;voltage island floorplanning;voltage island generation;deterministic algorithms;deterministic algorithm;multiple supply voltage design;heuristic algorithms;timing safe voltage levels;low power electronics;algorithm design and analysis law partitioning algorithms heuristic algorithms design automation timing;power consumption;competitive power consumption voltage island generation voltage island floorplanning multiple supply voltage design timing safe voltage levels deterministic algorithm;algorithm design and analysis;partitioning algorithms;timing	Multiple supply voltage is a prevalent and effective technique to balance power and performance. A multiple supply voltage design is divided into voltage islands at physical design, where each island occupies a contiguous physical region and operates at some supply voltage. Given a set of blocks and the timing-safe voltage levels for each block, we simultaneously generate a floorplan and form the corresponding voltage islands based on an efficient and deterministic algorithm. In contrast, prior works usually assign voltages of all blocks either—for a given floorplan—at post-floorplanning or—for an intermediate floorplan—at an iteration of floorplanning. Experimental results prove the superior efficiency of our algorithm under competitive power consumption. Moreover, the results of large design cases further demonstrate the scalability of our algorithm.	binary code;deterministic algorithm;dynamic frequency scaling;dynamic voltage scaling;floorplan (microelectronics);goto;image scaling;iteration;physical design (electronics);power gating;scalability	Houng-Yi Li;Iris Hui-Ru Jiang;Hung-Ming Chen	2010	23rd IEEE International SOC Conference	10.1109/SOCC.2010.5784739	physical design;embedded system;algorithm design;electronic engineering;logic synthesis;real-time computing;electronic design automation;computer science;deterministic algorithm;engineering;electrical engineering;low-power electronics	EDA	16.519230415700378	54.56999516008037	130724
3d2154c81b96c9e30b04a73b7e713df826249162	a 0.4v 0.08fj/cycle retentive true-single-phase-clock 18t flip-flop in 28nm fdsoi cmos		In this paper, we propose an 18-transistor (18T) True-Single-Phase-Clock (TSPC) Flip-Flop (FF) with static data retention based on two forward-conditional feedback loops, without increasing the clock load, in comparison to the baseline TSPC architecture. The proposed FF was implemented for ultra-low-voltage (ULV) operation in 28nm FDSOI CMOS. The performances of the proposed FF extracted from measurements of clock dividers are compared to reference designs including the conventional M-S FF, the baseline TSPC FF and a recently-proposed retentive TSPC FF. Compared to the conventional MS FF, the proposed FF shows respectively 5%, 60% and 30% improvements at 0.4V in maximum frequency, energy/cycle and leakage power.	baseline (configuration management);cmos;die shrink;feedback;flip-flop (electronics);performance;spectral leakage;ultra-low-voltage processor	François Stas;David Bol	2017	2017 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2017.8050999	electronic engineering;architecture;computer science;flip-flop;transistor;leakage (electronics);silicon on insulator;data transmission;cmos	Arch	17.75953896563733	58.65713432729622	130853
9e7005bcd3fb1f961bd63d1264f2d324455870d6	staic: an interactive framework for synthesizing cmos and bicmos analog circuits	hierarchical circuit descriptions;analytical models;software;symbolic numeric solve unit;physical layout;concepcion asistida;cmos integrated circuits;computer aided design;optimisation;synthese circuit;implantation topometrie;scan modules;optimizacion;integrated circuit;logiciel;programming environment;technologie bicmos;estudio comparativo;interactive framework;circuit synthesis cmos analog integrated circuits bicmos integrated circuits analog circuits integrated circuit synthesis circuit topology analog integrated circuits semiconductor device modeling system performance analytical models;linear integrated circuits;circuito analogico;bicmos technology;circuito integrado;interactive design tool;globally optimal solution;bicmos integrated circuits;linear integrated circuits bicmos integrated circuits circuit cad circuit layout cad cmos integrated circuits integrated circuit technology interactive systems;layout;tecnologia mos complementario;cmos analogue circuits;system performance;modeling language;circuit topology;design evaluation;systeme conversationnel;etude comparative;optimization modules;medio ambiente programacion;analog circuits;analog circuit;successive solution refinement methodology;multilevel models ic synthesis;interactive system;cmos analog integrated circuits;integrated circuit technology;semiconductor device modeling;input modeling language;analog integrated circuits;globally optimal solution cmos analogue circuits scan modules multilevel models ic synthesis interactive framework bicmos analog circuits staic interactive design tool input modeling language hierarchical circuit descriptions symbolic numeric solve unit analytical model equations flattened homogeneous model user specified topology performance specifications physical layout successive solution refinement methodology optimization modules;analytical model equations;comparative study;sistema conversacional;conception assistee;sintesis circuito;logicial;circuit layout cad	STAIC is an interactive design tool that synthesizes CMOS and BiCMOS analog integrated circuits that conform to specified performance constraints. STAIC features an input modeling language for entering hierarchical circuit descriptions and a symbolic/numeric solve unit that dynamically integrates analytical model equations across hierarchical boundaries. Output of the solver is a “flattened” homogeneous model that is customized to a user specified topology and set of performance specifications. The output is thus tailored for optimization and other numerically intense design exploration procedures. All model descriptions include physical layout so that important net parasitics may be fully accounted for during design evaluation. Synthesis proceeds via a successive solution refinement methodology. Multilevel models of increasing sophistication are used by scan and optimization modules to converge to what is likely a globally optimal solution. Design experiments have shown that STAIC can produce satisfactory results.	analogue electronics;bicmos;cmos;converge;design tool;experiment;integrated circuit layout;interactive design;mathematical optimization;maxima and minima;modeling language;multilevel model;numerical analysis;refinement (computing);solver	J. Paul Harvey;Mohamed I. Elmasry;Bosco H. Leung	1992	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.177403	embedded system;mathematical optimization;electronic engineering;analogue electronics;computer science;electrical engineering;computer aided design;global optimization	EDA	13.483031080199128	51.017481531894106	130930
c63e05fc673821d5dc8e471e2849105bc22526f6	designing and using fpgas beyond classical binary logic: opportunities in nano-scale integration age	verification;random access memory;design tool;high capacity memories;tool support;logic design;multi valued logic;emulation;nanotechnology;integrated circuit design;logic gates;integrated circuit interconnections;nanoelectronics;fpga design;fpgas;nanoelectronics field programmable gate arrays integrated circuit design logic design multivalued logic;high capacity memories fpgas multiple valued logic design tools emulation verification nanotechnology;nanowires;field programmable gate arrays;design tools;nanoscale integration;multivalued logic;emulation fpga design classical binary logic nanoscale integration multivalued logic;field programmable gate arrays logic design programmable logic arrays application specific integrated circuits integrated circuit interconnections multivalued logic programmable logic devices hardware software tools software maintenance;table lookup;classical binary logic;multiple valued logic	In this paper, we first recap the rationale beyond the (non)-acceptance of multi-valued logic in implementing FPGAs so far, explaining the most critical technological and tool support details. Then, we outline the critical applications of FPGAs (e.g., emulation) where the non-binary nature can be exploited by MVL implementation. Finally, we highlight the most significant opportunities that present themselves with the transition to the nano-scale system implementations.	computation;design rationale;diversification (finance);emulator;field-programmable gate array;gnu nano;high-speed serial interface;holographic data storage;holography;information processing;quantum information science;software testability;spatial variability	Zeljko Zilic	2009	2009 39th International Symposium on Multiple-Valued Logic	10.1109/ISMVL.2009.51	computer architecture;electronic engineering;computer science;theoretical computer science;field-programmable gate array	Arch	11.665646027321866	58.218159350922676	131017
966df897b86e238e79dc2d75e3464b3c77f46c55	a 1.0-ns/1.0-v delay-locked loop with racing mode and countered cas latency controller for dram interfaces	or and dcc column address strobe cas latency controller duty cycle corrector dcc ddr3 delay locked loop dll drams dual coarse delay line idd3n idd3p merged dual coarse delay line mdcdl oa dcc;or and dcc;random access memory;drams;clocks;delay lines;ddr3;low power electronics clocks delay lock loops dram chips;delay locked loop dll;voltage 1 2 v delay locked loop dual dll architecture racing mode column address strobe countered cas latency controller dram interfaces stuck free control merged dual coarse delay line mdcdl delay line path ddr3 operating mode or and functioned duty cycle corrector dll clock read command ddr3 sdram dram process technology voltage 1 0 v voltage 1 575 v frequency 1 0 ghz;delay lock loops;oa dcc;duty cycle corrector dcc;logic gates;delay clocks delay lines logic gates power demand random access memory mixers;low power electronics;idd3p;dual coarse delay line;mixers;column address strobe cas latency controller;merged dual coarse delay line mdcdl;power demand;idd3n;dram chips	The digital delay-locked loop (DLL) with racing mode and the countered column address strobe (CAS) latency controller are proposed in this paper. The dual-DLL architecture with racing operation is adopted to achieve low power consumption, low jitter, fast locking, wide range of locking, and stuck-free control. The merged dual coarse delay line (MDCDL) reduces the dynamic power consumption of a variable delay line by 30% by sharing a part of the delay line path in DLL. In addition, jitter is reduced by 45 ps in the 1066-DDR3 operating mode by MDCDL. The proposed DLL utilizes an or-and functioned duty cycle corrector (or-and DCC), which consumes 15% of DLL's power, 0.915 pJ/Hz at tCK=1.5 ns and VDD=1.575 V. The countered CAS latency controller (CCLC) saves IDD3N current because it does not need a DLL clock and does not need to be activated for IDD3N (active non-power down) state. The DLL clock is enabled and CCLC is activated only when the read command is issued. This operation condition saves the IDD3N current by 60% with the proposed DLL. The proposed DLL is employed in 128 M×8 DDR3 SDRAM and 64 M×16 DDR3 SDRAM. The former and the latter are fabricated by 5×nm and by 4× nm DRAM process technology, respectively. Experimental results show that ±10% duty error of the external clock can be corrected to within ±2% duty error in less than 512 cycles of locking time under 1.5 ns of tCK. The proposed DLL and CCLC can operate above 1.0-GHz operating frequency at 1.2 V in 5× nm DDR3 SDRAM and at 1.0 V in 4× nm DDR3 SDRAM, respectively. The proposed DLL fabricated with 4× nm technology consumes 6.1 pJ/Hz at 1.575 V.	cas latency;delay-locked loop;dynamic random-access memory;memory timings	Hyun-Woo Lee;Hoon Choi;Beom-Ju Shin;Kyung-Hoon Kim;Kyung Whan Kim;Jaeil Kim;Kwang Hyun Kim;Jongho Jung;Jae-Hwan Kim;Eun Young Park;Jong-Sam Kim;Jong-Hwan Kim;Jin-Hee Cho;Nam Gyu Rye;Jun Hyun Chun;Yunsaing Kim;Chulwoo Kim;Young-Jung Choi;Byong-Tae Chung	2012	J. Solid-State Circuits	10.1109/JSSC.2012.2191027	embedded system;electronic engineering;real-time computing;logic gate;computer science;engineering;operating system;dram;low-power electronics	EDA	17.293845996566418	58.177985834272306	131132
049d610961a768f50cec2a959c4dc5f1e136f5e9	synthesis of active cell balancing architectures for battery packs	microprocessors;charge transfer;computer architecture;batteries;inductors;mosfet;pulse width modulation	Active balancing architectures effectively increase the efficiency of large battery packs by equalizing charge between cells. For this purpose, a balancing circuit and appropriate control scheme have to be designed to enable the charge transfer via energy storage elements such as inductors. Using a manual approach to design balancing architectures can be tedious and error-prone, resulting in potentially suboptimal solutions. As a remedy, this paper presents an automatic synthesis of balancing circuits and their corresponding control, optimizing the number of required metal-oxide-semiconductor field-effect transistors, and necessary control signals. The proposed synthesis combines a satisfiability solver to explore the search space with a graph-based verification that iteratively excludes infeasible solutions until the optimal architectures are obtained. The experimental results are carried out for three given template circuits and two signal templates. The synthesis results in architectures that are superior in terms of all design objectives in comparison to solutions from literature that result from a manual design approach.	boolean satisfiability problem;cell (microprocessor);cognitive dimensions of notations;dependability;open research;semiconductor;solver;transistor	Martin Lukasiewycz;Matthias Kauer;Sebastian Steinhorst	2016	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2016.2531049	embedded system;electronic engineering;computer science;engineering;electrical engineering;operating system;pulse-width modulation;charge-transfer complex;inductor	EDA	13.266141185599256	53.17226281484148	131137
ddf4c1901e9a271d9d132f3e4e597f1938c9e813	combination of automatic test pattern generation and built-in intermediate voltage sensing for detecting cmos bridging faults	fault modelling;design for testability;atpg system;gate threshold ranges;ppsfp based process;circuit faults;fault simulation;built in intermediate voltage sensing;automatic test pattern generation;automatic testing;feedback bridging faults;built in self test;monitoring;integrated circuit modelling;circuit feedback;automatic test pattern generation voltage logic testing circuit faults circuit testing logic devices monitoring system testing design for testability fault detection;cmos logic circuits;fault detection;voltage;logic testing;greedy algorithm;system testing;logic monitoring;byzantine general s command problem;fault coverage;circuit testing;cmos bridging faults detection;bifest system;parallel pattern single fault propagation;automatic test pattern generator;podem like process;circuit analysis computing;parallel algorithms cmos logic circuits fault diagnosis logic testing circuit analysis computing automatic testing circuit feedback integrated circuit modelling built in self test;logic devices;parallel pattern single fault propagation cmos bridging faults detection atpg system built in intermediate voltage sensing bifest system podem like process ppsfp based process logic monitoring fault coverage greedy algorithm gate threshold ranges byzantine general s command problem fault modelling fault simulation feedback bridging faults;fault diagnosis;parallel algorithms	T h i s paper presents t he BIFEST, a n ATPG sys t em tha t combines the conventional ATPG process and the builtin intermediate voltage t e s t technique t o deal wi th CMOS bridging faul ts . A PODEM-l ike , PPSFPbased ATPG process tha t can effectively and e f ic ien t ly model the bridging fau l t eflects is developed t o process those fau l t s tha t are conventionally logic-testable. T h e remain ing fau l t s are t h e n dealt w i th by special circuits called built-in in termedia te voltage sensors. B y this methodology almost the same faul t coverage as tha t employing I D D Q testing can be achieved wi th only logic moni tor ing required.	bridging (networking);cmos;internet key exchange;sensor;tor messenger	Kuen-Jong Lee;Jing-Jou Tang;Tsung-Chu Huang;Cheng-Liang Tsai	1996		10.1109/ATS.1996.555144	embedded system;electronic engineering;greedy algorithm;real-time computing;voltage;fault coverage;computer science;engineering;automatic test pattern generation;design for testing;parallel algorithm;system testing;fault detection and isolation	EDA	22.872688339946706	51.978261688385	131193
b288c4635a7f1cca0cb0aed3eeaf89248aa64515	overlap reduction in symbolic system traversal	symbol manipulation;boolean functions data structures partitioning algorithms state space methods cost function design engineering explosions proposals automata face detection;state space methods;boolean functions;boolean function;divide and conquer methods;synchronous system;divide and conquer methods binary decision diagrams boolean functions logic partitioning symbol manipulation state space methods;binary decision diagrams;static overlap reduction symbolic system traversal divide and conquer approach partition bdd crossover transitions partitions overlap redundant computations boolean functions synchronous systems state set overlap splitting algorithm bounded property checking algorithm;logic partitioning;divide and conquer	A divide-and-conquer approach in BDD-based verification to handle larger designs is to partition BDDs exceeding a threshold size and to deal with the partitions separately. Crossover transitions to the same state cause the main problem of this methodology, because they result in overlap of the partitions and thus introduce redundant computations when dealing with the partitions. In this paper we describe an algorithm for splitting Boolean functions representing state sets of synchronous systems such that in subsequent symbolic traversal of the resulting subsets the state set overlap is reduced. We demonstrate the effectiveness of our splitting algorithm by applying it in sequential and distributed versions of a bounded property checking algorithm. Also, a dynamic extension to static overlap reduction is sketched.	algorithm;benchmark (computing);computation;distributed algorithm;experiment;heuristic;method (computer programming);preprocessor;tree traversal;visual instruction set	Prakash Mohan Peranandam;Pradeep Kumar Nalla;Roland J. Weiss;Jürgen Ruf;Thomas Kropf;Wolfgang Rosenstiel	2005	Tenth IEEE International High-Level Design Validation and Test Workshop, 2005.	10.1109/HLDVT.2005.1568829	boolean expression;computer science;theoretical computer science;boolean function;algorithm	EDA	18.86786469119555	48.43715318592137	131385
04b02bad7ca01900bc1410c16e9d86649449ba48	a new approach of fractional-dimension based module clustering for vlsi layout	fractals;integrated circuit layout;fractals very large scale integration logic information systems systems engineering and theory toy industry information analysis circuits productivity physics;fractal dimension;network topology;ic layout design fractal dimension based module clustering vlsi layout topological structure logic diagram clustered modules placement vlsi;vlsi;circuit layout cad;vlsi layout;logic cad;integrated circuit layout fractals logic cad vlsi circuit layout cad network topology	This paper describes a new clustering approach for VLSI placement, which is based on a fractal dimension analysis for the topological structure of modules in a logic diagram. A distinctive feature of this approach is that the concept of a fractal dimension has been introduced into a logic diagram in such a way that clustering of modules is iterated while the fractal dimension of clustered modules remains in a prescribed range. A part of experimental results is also shown, which demonstrates that our clustering approach achieves better solutions than the conventional placement without clustering. >	very-large-scale integration	Masahiko Toyonaga;Shih-Tsung Yang;Toshiro Akino;Isao Shirakawa	1994		10.1109/ISCAS.1994.408786	electronic engineering;discrete mathematics;fractal;ic layout editor;computer science;electrical engineering;theoretical computer science;mathematics;integrated circuit layout;very-large-scale integration;circuit extraction;fractal dimension;network topology	EDA	14.627751966328416	49.88850228464086	131397
706612f461004e549aa5de4f76d4a3ff29af2530	soc in nanoera: challenges and endless possibility	life style;semiconductor technology;personal computer;system on a chip electronics industry system level design application software microcomputers mobile handsets information technology computer industry transistors silicon;information technology;nanotechnology;semiconductor devices;system on a chip;chip;integrated circuit design;research and development;low power;system on chip;system level design;low power soc system on chip nanoera semiconductor industry information technology industry nanotechnology digital components analogue components rf components ubiquitous life style system level design manufacturing technologies eda technology gigascale integration design complexity nanoscale technology;research and development system on chip nanotechnology semiconductor devices semiconductor technology electronic design automation integrated circuit design reviews;reviews;high performance;electronic design automation	Growth of the semiconductor industry has been driven by a series of electronic system applications, such as personal computers, home entertainment, and mobile handsets. The most recent growth is driven by revolution of the information technology (IT) industry. The key word of this next revolution is “Ubiquitous.” As semiconductor technology is scaled into the nanometer regime where hundreds of millions of transistors can be placed on a chip, designers are now incorporating their advanced system concepts into silicon. These systems include digital, analogue, and RF components. System-on-a-Chip (SoC) enables the IT industry to realise various products that can comply with rapidly changing market requirements as well as with unprecedented ubiquitous life style. However, SoC products in the ubiquitous era are facing challenges such as high performance, low-power, small-size and lowcost. These factors may jeopardise the success of SoC unless there is a breakthrough from system-level design through manufacturing technologies. Advanced EDA technology is indispensable to cope with ever-increasing design complexity of gigascale integration and complicated physical effects inherent from the nanoscale technology. In this talk, the speaker will provide an overview of the key challenges with SoC developments in days to come, namely: Issues in the system-level design, low power, high performance, verification, and relevant nanometer technology. Solutions including some of Samsung’s recent R&D activities in those areas will be discussed and the speaker will conclude his speech by saying that all these challenges will promise the endless possibilities of the SoC. 1530-1591/05 $20.00 © 2005 IEEE	analog signal;digital data;electronic system-level design and verification;level design;low-power broadcasting;mobile phone;personal computer;radio frequency;requirement;semiconductor industry;system on a chip;transistor	Jeong-Taek Kong	2005		10.1109/DATE.2005.272	system on a chip;embedded system;electronic engineering;electronic design automation;computer science;engineering;electrical engineering;information technology;computer engineering	EDA	10.408687713453368	56.45809141153129	131415
500ef02d13cf86e33fd8d99b3c5d738e46c6c648	relating digital imager defect rates to pixel size, sensor area and iso	iso;very large scale integration;iso standards;smart phones;empirical defect rate equation;iso standards decision support systems fault tolerance fault tolerant systems very large scale integration nanotechnology discrete fourier transforms;nanotechnology;cmos image sensor digital imager defect rate pixel size sensor area iso in field permanent hot pixel defect cell phone camera image sensitivity defect appearance enhancement defect density measurement power law ccd aps;smart phones ccd image sensors cmos image sensors iso standards;ccd image sensors;cmos image sensors;ccd;fault tolerant systems;fault tolerance;imager defect rates;decision support systems;active pixel sensor aps;discrete fourier transforms;empirical defect rate equation defect detection hot pixel imager defect rates active pixel sensor aps ccd iso;defect detection;hot pixel	Image sensors measurements show a continuous development of in-field permanent hot-pixel defects over time. We have accumulated experimental data on cameras with sensors ranging in size from large area (>;300 mm2) DSLRs (Digital Single-Lens Reflex cameras), medium sized (~40 mm2) Point and Shoot, and small (20 mm2) cell phone cameras. Our results show that the rate of defects depends on the technology (APS vs. CCD), and on design parameters such as imager area, pixel size (from 1.5 to 7 μm), and sensitivity (from ISO100 to 6400). Previous measurements showed that increased image sensitivity (ISO) enhances the defect appearance. Comparing different sensor sizes with similar pixel sizes showed that defect rates scale linearly with sensor area, suggesting the metric we call defect density measured by number of sensor defects/year/mm2. In an attempt to model this defect density as a function of both pixel size and ISO, we discovered a very good fit of the empirical densities to a power law in both the pixel size and the ISO, with slightly different parameters for CCD and APS (CMOS) sensors. Including the ISO in the equation allows us to predict the expected defect development rate for a wide set of sensor parameters. The power laws that we obtained show that defect densities are lower for CMOS pixels when pixel sizes are large (near 7 μm), but become higher than for CCDs at about 2 microns even for modest ISOs (near 400).	cmos;charge-coupled device;digital single-lens reflex camera;image sensor format;mobile phone;pixel;software bug	Glenn H. Chapman;Rohit Thomas;Israel Koren;Zahava Koren	2012	2012 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)	10.1109/DFT.2012.6378218	embedded system;computer vision;fault tolerance;electronic engineering;iso image;decision support system;computer science;engineering;nanotechnology;very-large-scale integration;charge-coupled device	Visualization	23.001638821574918	55.89582787401742	131881
b4a35350beeffabd03092d0a448c7c68d0d36c52	the optimization of interconnection networks in fpgas	004;field programmable gate array architecture computer aided design	Scaling technology enables even higher degree of integration for FPGAs, but also brings new challenges that need to be addressed from both the architecture and the design tools side. Optimization of FPGA interconnection network is essential, given that interconnects dominate logic. Two approaches are presented, with one based on the time-multiplexing of wires and the other using hierarchical interconnects of high-speed serial links and switches. Design tools for both approaches are discussed. Preliminary experiments and prototypes are presented, and show positive results.	electrical connection;experiment;field-programmable gate array;interconnection;mathematical optimization;multiplexing;network switch;scalability;software prototyping	Xiaolei Chen;Yajun Ha	2010			computer architecture;electronic engineering;engineering;computer engineering	EDA	10.056910391827397	52.060146637592496	131885
563566278d6d2b2e49eac4e759368bc248b416cf	a holistic view of chip-level thermal architecture from heterogeneous stacked dice to system level in telecoms applications	electronic packaging thermal management telecommunications thermal engineering thermal loading junctions three dimensional displays system integration;thermal architecture;package characterization 2 5d packages thermal architecture multi die package;package characterization;multi die package;2 5d packages	Silicon Interconnect Technology (SSIT) enables superior feature integration beyond what is possible in monolithic technology with only a Moore's Law feature shrink as well as heterogeneous feature integration of disparate dice (e.g. memories, RF DAC/ADCs, optical interfaces, customer ASICs etc.). In a Telecom environment, this superior feature density enables new applications, but also presents higher thermal density to the Thermal Engineer. To properly utilize these benefits, a Thermal Engineer must take a holistic approach to thermal architecture that simultaneously addresses system goals of Cost, Performance, Weight, Size, Power and Performance. This paper will discuss the critical parameters which impact thermal architecture, followed by Challenges in Indoor and Outdoor Telecom Systems from device and system perspectives and finally will show the impact of combining network utilization and heterogeneous load in the user's environment.	application-specific integrated circuit;computer cooling;critical system;feature integration theory;holism;mathematical optimization;moore's law;operating environment;radio frequency;software engineer;systems engineering	Gamal Refai-Ahmed;Ivor Barber;Anthony Torza;Brian Philofsky	2015	2015 International 3D Systems Integration Conference (3DIC)	10.1109/3DIC.2015.7334615	embedded system;electronic engineering;engineering;electrical engineering	EDA	11.705976646630576	59.642978697926935	131921
b22fe8413d7cb88a31550aeae8884d143d8e9650	is iddq testing not applicable for deep submicron vlsi in year 2011?	statistical analysis leakage currents integrated circuit testing vlsi cmos integrated circuits;statistical approach;input vectors;cmos integrated circuits;random process deviations;process variation;iddq distributions;standard deviation;deep submicron vlsi;international technology roadmap for semiconductors;statistical analysis;random process;leakage currents;integrated circuit testing;vlsi;iddq testing;iddq current estimation;circuit size;iddq distributions iddq testing deep submicron vlsi iddq current estimation statistical approach standard deviation circuit size random process deviations input vectors;very large scale integration leakage current circuit testing circuit faults subthreshold current current measurement semiconductor device measurement random processes fault detection mosfets	In this work, IDDQ current for the deep submicron VLSI in year 2011 is estimated with a statistical approach according to the International Technology Roadmap for Semiconductors 1999 Edition considering process variations and different input vectors. The estimated results show that the standard deviation of the IDDQ current is proportional to the square root of the circuit size and the IDDQ currents of the defect-free and the defective devices, which are of the size up to 1x10’ gates, are still differentiable under the condition of random process deviations and input vectors. Two new IDDQ testing schemes, which detect the defective current based on the two separate lDDQ distributions, are proposed. From the study, it is concluded that IDDQ testing is still applicable for the deep submicron VLSI for the next ten years.	iddq testing;semiconductor;software bug;stochastic process;very-large-scale integration	Chih-Wen Lu;Chauchin Su;Chung-Len Lee;Jwu E. Chen	2000		10.1109/ATS.2000.893646	reliability engineering;stochastic process;electronic engineering;engineering;electrical engineering;iddq testing;very-large-scale integration;standard deviation;process variation;cmos;statistics	EDA	22.93592179746323	54.90865766231795	131966
4f7a9b3f90df0a7178d3760490d56b193594b0b6	power-aware partitioned cache architectures	cache storage;process variation;energy delay optimizations;clocked timing elements;conference;power aware architectures;locality behavior;space exploration;partitioned cache resources;subcache prediction;subcache architectures;power engineering and energy;computer architecture;energy optimizations;permission;energy consumption;memory architecture;selective probing;per access energy costs;low power electronics;memory architecture low power electronics cache storage delays;circuits;energy cost;selective probing partitioned cache resources energy optimizations energy delay optimizations subcache architectures power aware architectures per access energy costs locality behavior data placement subcache prediction;capacitance;computer science;wiring;voltage scaling;capacitance computer architecture hardware energy consumption wiring circuits permission space exploration computer science power engineering and energy;data placement;delays;hardware	This paper focuses on partitioning the cache resources architecturally for energy and energy-delay optimizations. Specifically, we investigate ways of splitting the cache into several smaller units, each of which is a cache by itself (called subcache). Subcache architectures not only reduce the peraccess energy costs but can potentially improve the locality behavior as well. We present a uni ed framework for designing, implementing and evaluating di erent subcache architectures. Di erent techniques for data placement, subcache prediction, and selective probing are proposed and evaluated using a diverse set of applications. The results show that intelligent subcache mechanisms proposed in this paper are e ective.	cpu cache;locality of reference	Soontae Kim;Narayanan Vijaykrishnan;Mahmut T. Kandemir;Anand Sivasubramaniam;Mary Jane Irwin;E. Geethanjali	2001		10.1145/383082.383095	embedded system;electronic circuit;computer architecture;parallel computing;real-time computing;computer science;electrical engineering;space exploration;operating system;capacitance;process variation;low-power electronics	Arch	12.817561815732567	54.349364955021954	131975
6c00b211ff70dce882154cff2baf7bdc57eb1630	structural fault collapsing by superposition of bdds for test generation in digital circuits	complexity theory;network synthesis;circuit faults;boolean functions;test generation digital circuits fault equivalence and dominance fault collapsing structurally synthesized bdds ssbdds with multiple inputs;automatic test pattern generation;model complexity digital circuit test generation structural fault independent fault collapsing method circuit topology structurally synthesized binary decision diagrams;circuit testing circuit faults data structures boolean functions digital circuits fault diagnosis automatic test pattern generation fault detection circuit synthesis circuit topology;linear complexity;circuit topology;fault equivalence and dominance;model complexity;digital circuit test generation;binary decision diagrams;logic gates;side effect;data structures;solid modeling;fault detection;fault collapsing;integrated circuit modeling;test generation;structurally synthesized binary decision diagrams;circuit testing;digital circuits;structurally synthesized bdds;network synthesis binary decision diagrams circuit testing digital circuits fault diagnosis;circuit synthesis;fault diagnosis;structural fault independent fault collapsing method;ssbdds with multiple inputs	The paper presents a new structural fault-independent fault collapsing method based on the topology analysis of the circuit, which has linear complexity. The minimal necessary set of faults as the target objective for test generation is found. The main idea is to produce fault collapsing concurrently with the construction of structurally synthesized binary decision diagrams (SSBDD) used for test generation, as a side effect. To improve the fault collapsing, a new class of BDDs in a form of SSBDDs with multiple inputs (SSMIBDD) is proposed, which allows a significant reduction of the model complexity for test generation purposes, and produces collapsed fault sets with less sizes than the SSBDDs provide. Experimental data show that the fault collapsing by the proposed method is considerably more efficient than other structural fault collapsing methods with comparative time cost. The method is especially efficient for circuits with high rate of internal fanouts.	algorithm;binary decision diagram;dspace;digital electronics;experiment;fan-out;requirement;simulation;timing closure	Raimund Ubar;Dmitri Mironov;Jaan Raik;Artur Jutman	2010	2010 11th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2010.5450451	topology;network synthesis filters;electronic engineering;fault coverage;data structure;logic gate;computer science;engineering;stuck-at fault;theoretical computer science;automatic test pattern generation;fault model;mathematics;solid modeling;boolean function;digital electronics;side effect;fault detection and isolation;algorithm	EDA	20.270010168577983	48.15740622809463	132072
02b7f34f6e37392644e683b4f50d182d246d7289	shielding effect of on-chip interconnect inductance	on chip inductance;rlc load;inductance integrated circuit interconnections rlc circuits delay effects semiconductor device modeling propagation delay capacitance driver circuits inverters process design;design process;interconnection;rlc interconnects;capacitancia;integrated circuit;on chip interconnect inductance;dissipation energie;circuit retard;circuit rlc;programme spice;delay effects;inverters;circuito integrado;energy dissipation;excitador;tecnologia mos complementario;shielding effect;rlc circuit;dynamic power dissipation;process design;chip;on chip induc tance;interconexion;shielding effectiveness;integrated circuit design;circuit simulation;cmos logic circuits integrated circuit interconnections integrated circuit design capacitance driver circuits inductance rlc circuits shielding integrated circuit modelling;shielding;integrated circuit modelling;gate delay;effet ecran;rlc circuits;propagation delay;semiconductor device modeling;interconnects;integrated circuit interconnections;cmos logic circuits;power dissipation;inductancia;interconnexion;shielding effect cmos gate delay interconnect modeling on chip inductance propagation delay;onduleur;circuito rlc;inverter;driver circuits;driver;inductance;circuit delay;disipacion energia;capacitance;ondulador;temps retard;interconnect modeling;delay time;circuito retardo;excitateur;technologie mos complementaire;cmos inverter;efecto pantalla;tiempo retardo;gating circuits;delay circuit;spice;cmos;circuit simulation shielding effect on chip interconnect inductance capacitance driver circuits gate delay reduction rlc load cmos inverter line inductance circuit delay dynamic power dissipation propagation delay integrated circuit design;line inductance;circuit integre;complementary mos technology;gate delay reduction;capacite electrique;circuit porte	Interconnect inductance introduces a shielding effect which decreases the effective capacitance seen by the driver of a circuit, reducing the gate delay. A model of the effective capacitance of an RLC load driven by a CMOS inverter is presented. The interconnect inductance decreases the gate delay and increases the time required for the signal to propagate across an interconnect, reducing the overall delay to drive an RLC load. Ignoring the line inductance overestimates the circuit delay, inefficiently oversizing the circuit driver. Considering line inductance in the design process saves gate area, reducing dynamic power dissipation. Average reductions in power of 17% and area of 29% are achieved for example circuits. An accurate model for a CMOS inverter and an RLC load is used to characterize the propagation delay. The accuracy of the delay model is within an average error of less than 9% as compared to SPICE.	cmos;power inverter;propagation delay;rlc circuit;spice;software propagation	Magdy A. El-Moursy;Eby G. Friedman	2005	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2004.842315	equivalent series inductance;embedded system;electronic engineering;delay calculation;computer science;engineering;electrical engineering;dissipation;inverter;rlc circuit	EDA	18.682865582147738	55.39387404735796	132120
6fc33469c68b936165811d02e692bb567a3c89c6	efficient failure detection in pipelined asynchronous circuits	failure detection;asynchronous circuit;circuit reliability;logic testing;transient fault;asynchronous circuits;circuit testing;permanent fault modeling concurrent failure detection pipelined asynchronous circuits transient fault modeling clockless systems data channels hard errors soft errors;fault diagnosis asynchronous circuits logic testing circuit testing pipeline processing circuit reliability;asynchronous circuits clocks circuit faults hardware logic circuits costs fault detection delay rails fault tolerant systems;soft error;pipeline processing;fault diagnosis	This paper presents an efficient concurrent failure detection method for pipelined asynchronous circuits. We first validate permanent and transient fault modeling in clockless systems. By augmenting the rails to each data channel and adding extra logic to each circuit module, we make pipelined asynchronous circuits achieve fail-stop with respect to hard or soft errors. The experimental evaluations show this method incurs both reasonable hardware cost and low performance overhead.	asynchronous circuit;asynchronous system;channel (communications);deadlock;fail-stop;fault tolerance;overhead (computing);simulation;software propagation;transistor	Song Peng;Rajit Manohar	2005	20th IEEE International Symposium on Defect and Fault Tolerance in VLSI Systems (DFT'05)	10.1109/DFTVS.2005.33	embedded system;electronic engineering;real-time computing;asynchronous circuit;soft error;computer science;stuck-at fault	EDA	20.502916144144	51.06649886240626	132199
adf87c838cb7f61f0c8bba8e87cf03940b0c5ca5	a variability-aware energy-minimization strategy for subthreshold circuits	energy minimization;process variation	We investigate a design strategy for subthreshold circuits focusing on energy-consumption minimization and yield maximization under process variations. The design strategy is based on the following findings related to the operation of low-power CMOS circuits: (1) The minimum operation voltage (VDDmin ) of a circuit is dominated by flip-flops (FFs), and VDDmin of an FF can be improved by upsizing a few key transistors, (2) VDDmin of an FF is stochastically modeled by a log-normal distribution, (3) VDDmin of a large circuit can be efficiently estimated by using the above model, which eliminates extensive Monte Carlo simulations, and (4) improving VDDmin may substantially contribute to decreasing energy consumption. The effectiveness of the proposed design strategy has been verified through circuit simulations on various circuits, which clearly show the design tradeoff between voltage scaling and transistor sizing. key words: subthreshold operation, process variation, minimum operation voltage estimation, energy minimization, yield maximization	cmos;dynamic voltage scaling;energy minimization;expectation–maximization algorithm;flops;flip-flop (electronics);heart rate variability;image scaling;low-power broadcasting;monte carlo method;simulation;transistor;upsizing (database)	Junya Kawashima;Hiroshi Tsutsui;Hiroyuki Ochi;Takashi Sato	2012	IEICE Transactions		mathematical optimization;process variation;energy minimization	EDA	19.687381744455394	58.83146271987077	132253
911093dd17a11da80d7dd32c425863f04a046de0	asic cad system based on hierarchical design-for-testability	design for testability;computer aided design;automatic testing;application specific integrated circuits;application specific integrated circuit;logic cad application specific integrated circuits automatic testing circuit cad;circuit cad;hierarchical design;application specific integrated circuits design automation logic design circuit testing logic testing automatic testing integrated circuit testing system testing automatic logic units logic circuits;logic cad;automatically insert high testability logic asic cad hierarchical design for testability megacells	We propose a new Test CAD System for ASIC including megacells which automatically insert high testability logic. The strategy is to access megacells directly and independently. The overhead is only 2 to 3 percent of the total number of gates.	application-specific integrated circuit;computer-aided design;design for testing;overhead (computing)	Michiaki Emori;Takashi Aikyo;Yasuhide Machida;Jun-ichi Shikatani	1990		10.1109/TEST.1990.114048	physical design;embedded system;computer architecture;electronic engineering;logic synthesis;logic optimization;logic family;computer science;computer aided design;application-specific integrated circuit;digital electronics;register-transfer level;resistor–transistor logic;computer engineering	EDA	12.145761004918871	51.764416099612156	132269
153e03804903bc10a1336b6b17a56776bb533071	from here to there : future robust ehw technologies for large digital designs	evolutionary computation;fault tolerant;reconfigurable architectures;evolutionary computation technological forecasting reconfigurable architectures fault tolerant computing;evolvable hardware;future technology evolvable hardware digital design design by evolution reliability fpga fault tolerant technology amorphous computers;large scale;fault tolerant computing;digital design;chemical equilibrium;robustness hardware space technology fault tolerance chemical technology production large scale systems reservoirs circuits maintenance;technological forecasting	Fault-tolerance may be expected to gain more and more importance in the future. Extremely harsh and changing environments, like outer space, already force us to think abou t this issue today, but issues like production of large-scale devices might put the same requirements on the devices of	fault tolerance;requirement	Pauline C. Haddow;Piet van Remortel	2001		10.1109/EH.2001.937966	real-time computing;simulation;engineering;computer engineering	HCI	10.040575739067059	57.499613304061256	132401
9ce0c9f2052b58e3c933cc463d3527810744eaf3	unknown response masking with minimized observable response loss and mask data	circuit faults;flip flops;logic testing benchmark testing;test pattern response masking response loss mask data overmasking response compactor masking cells test data;logic gates;compaction;logic testing;testing compaction degradation error correction codes flip flops information technology data engineering test pattern generators observability design for testability;benchmark testing;conferences;timing	This paper presents a new unknown response masking technique to minimize the effect on test loss due to overmasking. Unlike previous works where the scan responses are masked before entering the response compactor, the proposed method could mask the Xs when they are transformed on the scan path. Meanwhile, the masking cells are inserted along the scan paths, thus they would have no degradation on the performance of the designs. In addition, the test data required to mask unknown responses is only one bit for each test pattern. Experimental results show the effectiveness of the proposed method.	elegant degradation;observable;test card;test data	Youhua Shi;Nozomu Togawa;Masao Yanagisawa;Tatsuo Ohtsuki	2008	APCCAS 2008 - 2008 IEEE Asia Pacific Conference on Circuits and Systems	10.1109/APCCAS.2008.4746386	compaction;benchmark;electronic engineering;parallel computing;real-time computing;logic gate;computer science;engineering;test compression	EDA	21.034943519592975	51.58277125653476	132453
24fa1f23d83ae997d61009bea8ea201730f6f6e3	design of high-speed low-power parallel-prefix vlsi adders	switching activity;circuito aritmetico;adder;implementation;power efficiency;circuit vlsi;adicionador;tecnologia mos complementario;conception circuit integre;integrated circuit design;vlsi circuit;low power;low power electronics;power reduction;additionneur;power consumption;circuito vlsi;consommation energie electrique;implementacion;technologie mos complementaire;electronique faible puissance;high speed;circuit arithmetique;complementary mos technology;arithmetic circuit	Parallel-prefix adders offer a highly-efficient solution to the binary addition problem. Several parallel-prefix adder topologies have been presented that exhibit various area and delay characteristics. However, no methodology has been reported so far that directly aims to the reduction of switching activity of the carry-computation unit. In this paper by reformulating the carry equations, we introduce a novel bitlevel algorithm that allows the design of power-efficient parallel-prefix adders. Experimental results, based on static-CMOS implementations, reveal that the proposed adders achieve significant power reductions when compared to traditional parallel-prefix adders, while maintaining equal operation speed.	adder (electronics);algorithm;binary number;bit-level parallelism;cmos;computation;datapath;fan-out;microprocessor;requirement;very-large-scale integration	Giorgos Dimitrakopoulos;P. Kolovos;P. Kalogerakis;Dimitris Nikolos	2004		10.1007/978-3-540-30205-6_27	embedded system;electrical efficiency;computer science;engineering;operating system;programming language;implementation;carry-save adder;adder;low-power electronics;integrated circuit design	EDA	18.10745272630288	54.75926775179767	132516
1e597788bf51aff26ea9bb240f6e1b646f698896	hardware overhead reduction for memory bist	sram memory bist hardware overhead reduction encoder based comparator architecture built in self test;sram chips built in self test comparators circuits integrated circuit testing logic testing;hardware overhead reduction;hardware built in self test circuit faults random access memory fault location testing logic circuit simulation;built in self test;comparators circuits;logic testing;integrated circuit testing;sram;encoder based comparator architecture;memory bist;sram chips	We propose encoder-based comparator architecture to reduce hardware overhead of MBIST. Experimental results show the proposed architecture drastically reduce hardware overhead while maintaining the adaptability to the repair analysis.	built-in self-test;comparator;encoder;overhead (computing)	Masayuki Arai;Kazuhiko Iwasaki;Michinobu Nakao;Iwao Suzuki	2008	2008 IEEE International Test Conference	10.1109/TEST.2008.4700690	embedded system;computer architecture;electronic engineering;static random-access memory;computer science;engineering;operating system	EDA	20.227683130723953	52.44554820814343	132554
cc4a2b04795b8d6c72f7254829e1662c9304e20d	on testing of interconnect open defects in combinational logic circuits with stems of large fanout	test generation interconnect open defects combinational circuit testing combinational logic circuits large fanout nodes gate level fault model fanout branches fault simulation;combinational logic circuits;circuit faults;circuit testing logic testing integrated circuit interconnections combinational circuits circuit faults electronic equipment testing switches circuit simulation logic circuits informatics;fault simulation;logic circuits;fanout branches;electronic equipment testing;gate level fault model;circuit simulation;interconnect open defects;large fanout nodes;integrated circuit interconnections;cmos logic circuits;logic testing;integrated circuit testing;test generation;informatics;circuit testing;cmos logic circuits integrated circuit interconnections combinational circuits logic testing integrated circuit testing fault simulation;combinational circuit;fault model;switches;combinational circuit testing;combinational circuits	We consider the problem of testing of interconnect open defects in combinational circuits with large fanout nodes. We propose a gate level fault model for interconnect opens. The number of interconnect open faults using the proposed model can be very large, being exponential in the fanout size. We describe methods to effectively consider the very large numbers of open faults. These methods include techniques for implicit consideration of open faults, and the use of information about fanout branches driving each primary output to reduce the list of faults. We present experimental results to demonstrate that fault simulation and test generation for the modeled open faults can be carried out efficiently using these tech-	combinational logic;fan-out;fault model;simulation;time complexity	Sudhakar M. Reddy;Irith Pomeranz;Huaxing Tang;Seiji Kajihara;Kozo Kinoshita	2002		10.1109/TEST.2002.1041748	electronic engineering;parallel computing;computer science;engineering;combinational logic;algorithm;computer engineering	EDA	22.494387049706184	52.6561607751718	132689
130786bd4c0858526266860a774b8988bc879d3f	an 8mb 1t1c ferroelectric memory with zero cancellation and micro-granularity redundancy	cu;ferroelectric materials random access memory nonvolatile memory ferroelectric films redundancy capacitors driver circuits regulators springs instruments;micro granularity redundancy;random access memories;random access memory;cu 1t1c ferroelectric random access memory zero cancellation micro granularity redundancy 5lm process cell interrogation voltage nonswitching ferroelectric capacitor cell capacitors trim data storage 2t2c configuration rows 1 5 v 8 mbit 130 nm;cell capacitors;1 5 v;ferroelectric storage;5lm process;design technique;redundancy circuit reliability ferroelectric capacitors ferroelectric storage random access storage;redundancy;circuit reliability;130 nm;2t2c configuration rows;ferroelectric memories;random access storage;8 mbit;zero cancellation;cell interrogation voltage;nonswitching ferroelectric capacitor;trim data storage;1t1c ferroelectric random access memory;ferroelectric capacitors	New design techniques facilitate a high reliability 1T1C 8Mb ferroelectric random access memory with 0.71u2 cell operating at 1.5V on a 130nm 5LM Cu process. Zero cancellation increases the cell interrogation voltage by using a nonswitching ferroelectric capacitor to remove charge from the bit line that compensates the linear charge from the cell capacitor. A micro-granularity redundancy approach preserves high repair probability for up to 128 single bit failures. Trim data is stored in 2T2C configuration rows for redundancy, reference, regulator and control logic adjustment	dynamic random-access memory;ferroelectric ram;random access	Jarrod Eliason;Sudhir Madan;Hugh P. McAdams;Glen Fox;Ted Moise;Changgui Lin;Kurt Schwartz;Jim Gallia;Edwin Jabillo;Bill Kraus;Scott R. Summerfelt	2005	Proceedings of the IEEE 2005 Custom Integrated Circuits Conference, 2005.	10.1109/CICC.2005.1568697	embedded system;electronic engineering;computer hardware;engineering;redundancy	EDA	17.25233327436678	59.532465382675404	132757
051b554071a23a1e176d43477b618fbe0a5edd25	multi-voltage floorplan design with optimal voltage assignment	optimal solution;multi voltage assignment optimization branch and bound;network routing;upper bound;np hard problem;branch and bound method;linear program;upper and lower bounds;power consumption;network flow;branch and bound;performance optimization;lower bound;time constraint	In this paper, we study the multiple voltage assignment (MVA) problem under timing constraints in floorplanning, which is generally an NP-hard problem. We will present an effective value-oriented branch-and-bound based algorithm to solve it optimally in a reasonable amount of time. A convex cost integer dual network flow approach is used to obtain a feasible upper bound solution, while a lower bound is obtained by a linear relaxation of a general formulation of the problem. We then adopt a value-oriented breadth-first branch-and-bound method with upper and lower bounds as described above to search for the optimal solution. Favorable results can be obtained in comparison with previous methods using a general linear programming solver. We integrate this algorithm into a multi-stage floorplanner. At the first stage, an initial floorplan is obtained by simulated annealing using the convex cost integer dual network flow approach as an evaluator. We then perform optimal voltage assignment to this initial floorplan. Finally, a post-processing step is done to modify the floorplan slightly to optimize the power network routing resource before invoking once more the optimal voltage assignment step at the end. Experimental results show that we can improve over the most updated work on this problem [7] by further reducing 6% of power consumption while maintaining the performance on other factors	algorithm;branch and bound;breadth-first search;floorplan (microelectronics);interpreter (computing);linear programming relaxation;model–view–adapter;np-hardness;routing;simulated annealing;solver;video post-processing	Zaichen Qian;Evangeline F. Y. Young	2009		10.1145/1514932.1514937	mathematical optimization;combinatorics;linear programming;mathematics;weapon target assignment problem;upper and lower bounds;algorithm	EDA	16.52543567823551	51.44439005587148	132811
20f798da6b6cd31471edb2343e3d767adaa0e4ad	custom is from venus and synthesis from mars	mars;microprocessors;manuals;microprocessor;ic design design productivity design cost large scale design automated synthesis techniques microprocessor vlsi design ic synthesis techniques;automated synthesis techniques;ic synthesis techniques;large scale design;ic design;design cost;logic design;vlsi integrated circuit design logic design microprocessor chips;venus;venus mars costs productivity large scale systems manuals frequency microprocessors time to market system performance;usa councils;vlsi design;system performance;integrated circuit design;large scale;vlsi;ip networks;planning;ic synthesis techniques vlsi design custom ic design;optimization;time to market;design productivity;productivity;magnetic cores;frequency;high performance;integrated circuits;custom ic design;large scale systems;microprocessor chips	Due to ever increasing cost of doing design, design productivity and more specifically, cost of design has become a major bottleneck in large scale design projects. Due to the cost crunch, automated synthesis techniques have been gaining ground on manual and cost intensive (although potentially yielding higher quality of results) custom techniques. The push towards system level performance with multiple lower performance cores as opposed to single high performance core is also making the pursuit of frequency at any cost meaningless. Synthesis vs Custom has traditionally been a lively debate in microprocessor companies but now it is becoming more widespread with the desire of fabless companies to more fully utilize the technology node in order to compete with IDMs by utilizing more custom techniques. Custom hotshots argue that we cannot afford to leave performance or power on table when you are spending 3billion $s in fabs. Industry needs to get maximum benefits possible. Synthesis fanatics will argue that designers should get over the last few ps and last few nW, as time to market, cost, and system performance are the new drivers and synthesis can not only meet the challenge but beat it many times with lower power solutions. This panel will present this internal debate in a public forum.	bottleneck (engineering);fabless manufacturing;lively kernel;microprocessor;quality of results;semiconductor device fabrication;semiconductor fabrication plant	Ruchir Puri;William H. Joyner;Shekhar Y. Borkar;Ty Garibay;Jonathan Lotz;Robert K. Montoye	2008	2008 45th ACM/IEEE Design Automation Conference	10.1145/1391469.1391719	embedded system;electronic engineering;computer science;engineering;electrical engineering;operating system;computer performance;very-large-scale integration;computer engineering;integrated circuit design	EDA	11.18515948025308	55.44787252767734	132939
93235e25daaa08bc78dde5b4ec2adef6d178f177	an analytical model of the overshooting effect for multiple-input gates in nanometer technologies	analytical models;cmos integrated circuits;nanoelectronics cmos logic circuits integrated circuit modelling logic gates;spice simulation overshooting effect multiple input gates nanometer technologies cmos gate delay;simulation;spice simulation;logic gates;integrated circuit modelling;semiconductor device modeling;cmos logic circuits;nanoelectronics;nanometer technologies;logic gates simulation analytical models semiconductor device modeling cmos integrated circuits delays digital audio players;digital audio players;overshooting effect;cmos gate delay;multiple input gates;delays	The overshooting effect, which is induced by the input-to-output coupling capacitance, has an significant effect on CMOS gate delay with the scaling of CMOS technology. In this paper, an effective analytical model is proposed to calculate the overshooting time of multiple-input gates. The proposed model is verified having a good agreement with SPICE simulation results.	cmos;image scaling;polynomial texture mapping;propagation delay;spice;simulation	Li Ding;Jing Wang;Zhangcai Huang;Atsushi Kurokawa;Yasuaki Inoue	2013	2013 IEEE International Symposium on Circuits and Systems (ISCAS2013)	10.1109/ISCAS.2013.6572194	nanoelectronics;control engineering;electronic engineering;semiconductor device modeling;logic gate;computer science;engineering;electrical engineering;cmos	Arch	21.479671447678687	58.75566852024244	132941
a35798f1ea3d117ddb06fee19fad08a6bef12530	simultaneously optimizing crosstalk and power for instruction bus coupling capacitance using wire pairing	diaphonie;optimisation;instruction sequence profiling;fiabilidad;reliability;crosstalk noise;capacitancia;crosstalk capacitance wire encoding power dissipation genetic algorithms delay integrated circuit interconnections energy consumption circuit optimization;optimizacion;canal bus;crosstalk;dissipation energie;acoplamiento electrostatico;canal colector;energy dissipation;algoritmo genetico;capacitive coupling;reduccion ruido;chip;wire;miniaturisation;instruction bus coupling capacitance;codificacion;diafonia;reliability capacitance circuit optimization crosstalk data buses integrated circuit interconnections;integrated circuit interconnections crosstalk optimization power optimization genetic algorithm instruction bus coupling capacitance wire pairing deep submicrometer technology instruction sequence profiling crosstalk noise reduction circuit optimization;wire pairing;energy consumption;crosstalk optimization;capacitance crosstalk circuit optimisation integrated circuit noise integrated circuit interconnections genetic algorithms;integrated circuit interconnections;noise reduction;fiabilite;power dissipation;data buses;coding;reduction bruit;power optimization;algorithme genetique;bus channel;algorithme evolutionniste;genetic algorithm;genetic algorithms;couplage capacitif;algoritmo evolucionista;disipacion energia;optimization;crosstalk noise reduction;capacitance;miniaturization;temps retard;delay time;evolutionary algorithm;miniaturizacion;power consumption;consommation energie electrique;circuit optimisation;integrated circuit noise;encoding;tiempo retardo;codage;circuit optimization;capacite electrique;interconnexion circuit integre;deep submicrometer technology	The use of deep-submicrometer (DSM) technology increases the capacitive coupling between adjacent wires leading to severe crosstalk noise, which causes power dissipation and may also lead to malfunction of a chip. In this paper, we present a technique that reduces crosstalk noise on instruction buses. While previous research focuses primarily on address buses, little work can be applied efficiently to instruction buses. This is due to the complex transition behavior of instruction streams. Based on instruction sequence profiling, we exploit an architecture that encodes pairs of bus wires and permute them in order to optimize power and noise. A close to optimal architecture configuration is obtained using a genetic algorithm. Unlike previous bus encoding approaches, crosstalk reduction can be balanced with delay and area overhead. Moreover, if delay (or area) is most critical, our architecture can be tailored to add nearly no overhead to the design. For our experiments, we used instruction bus traces obtained from 12 SPEC2000 benchmark programs. The results show that our approach can reduce crosstalk up to 50.79% and power consumption up to 55% on instruction buses.	benchmark (computing);bus encoding;computation;coupling (electronics);crosstalk;experiment;genetic algorithm;mathematical optimization;overhead (computing);tracing (software)	Edwin Naroska;Shanq-Jang Ruan;Uwe Schwiegelshohn	2006	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2006.874373	embedded system;electronic engineering;genetic algorithm;telecommunications;computer science;engineering;electrical engineering;dissipation;evolutionary algorithm;statistics	EDA	17.93906173740636	54.72958989675713	133022
44d6b1b7ca481d2074fd68a69eddf2e4cc3e04f3	quantified synthesis of reversible logic	quantified synthesis;libraries;design automation;network synthesis;logic design;network on chip;boolean functions;quantified boolean formula satisfiability;logic;quantified boolean formula;logic network synthesis boolean functions optical computing quantum computing data structures costs optical design libraries design automation;optical computing;binary decision diagrams quantified synthesis reversible logic functions low power design optical computing quantum computing toffoli networks boolean satisfiability quantified boolean formula satisfiability;satisfiability;boolean satisfiability;reversible logic;binary decision diagrams;point to point links;logic gates;quantum computer;data structures;logic gates binary decision diagrams boolean functions logic design;low power design;reversible logic functions;quantum computing;optical design;asynchronous;serial;toffoli networks;binary decision diagram	In the last years synthesis of reversible logic functions has emerged as an important research area. Other fields such as low-power design, optical computing and quantum computing benefit directly from achieved improvements. Recently, several approaches for exact synthesis of Toffoli networks have been proposed. They all use Boolean satisfiability to solve the underlying synthesis problem. In this paper a new exact synthesis approach based on Quantified Boolean Formula (QBF) satisfiability - a generalization of Boolean satisfiability - is presented. Besides the application of QBF solvers, we propose Binary Decision Diagrams to solve the quantified problem formulation. This allows to easily support different gate libraries during synthesis. In addition, all minimal networks are found in a single step and the best one with respect to quantum costs can be chosen. Experimental results confirm that the new technique is faster than the best previously known approach and leads to cheaper realizations in terms of quantum costs.	apollonian network;binary decision diagram;boolean satisfiability problem;library (computing);low-power broadcasting;optical computing;quantum computing;reversible computing;true quantified boolean formula	Robert Wille;Hoang Minh Le;Gerhard W. Dueck;Daniel Große	2008	2008 Design, Automation and Test in Europe	10.1145/1403375.1403620	embedded system;data structure;electronic design automation;computer science;maximum satisfiability problem;theoretical computer science;network on a chip;quantum computer;algorithm	EDA	15.493214052068238	48.727359260147516	133066
ca5f02744db729e705bf2783a4bf55531b2b37cc	extensional design for noise-tolerate mrf standard cells via global mapping	markov processes cmos digital integrated circuits cmos logic circuits fault tolerance integrated circuit design integrated circuit reliability logic design low power electronics;standards circuit synthesis noise logic functions cmos integrated circuits markov random fields complexity theory;integrated circuit design markov random field mrf standard cells multilevel mrf circuit global mapping cmos devices moore law integrated circuit reliability chip designs low power circuit design fault tolerance noise immune structure	As CMOS devices scaling down according to the Moore' law, the reliability and stability of circuit become the main challenge for the chip designs in low supply voltage. Markov Random field (MRF) based design methodology presents a new approach to establish high noise-immune structure for low-power circuit design from the viewpoint of energy. We use global mapping to synthesize all two-input functions and realize the MRF based circuits, then the final structures our provided with same complexity, which does not depend on the inside logic operations any more, but the number of the input-signal instead, which inspires us to extend the MRF standard cells. Our proposed structures keep the performance of fault-tolerance and achieve higher efficiency for energy, time and area compared with that of traditional MRF-circuits. The extensional basic units also can beneficial for saving area in multi-level MRF-circuit.	cmos;circuit design;fault tolerance;image scaling;low-power broadcasting;markov chain;markov random field;moore's law	Yan Li;Jianhao Hu	2014	2014 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2014.6865488	mixed-signal integrated circuit;control engineering;physical design;electronic engineering;logic optimization;asynchronous circuit;logic gate;computer science;electrical engineering;circuit design;diode-or circuit;application-specific integrated circuit;integrated injection logic;circuit extraction;pin compatibility;power optimization;register-transfer level;discrete circuit;integrated circuit design	EDA	16.407074496421362	56.24997573886302	133253
036db84b1404db81915be0ea16ce25cf3052c03a	low-leakage asymmetric-cell sram	cmos memory circuits cellular arrays sram chips leakage currents cache storage integrated circuit reliability;cache storage;random access memory;low leakage;degradation;performance degradation asymmetric cell sram leakage power caches access latency bit level memory value stream zero state sense amplifier dummy bitlines;bit level;technological innovation;semiconductor memory;sense amplifier;caches;dummy bitlines;leakage reduction;access latency;cellular arrays;process design;low power;leakage power;cmos memory circuits;permission;leakage currents;threshold voltage;power dissipation;random access memory power dissipation delay degradation threshold voltage permission circuits semiconductor memory process design technological innovation;zero state;memory value stream;sram;circuits;integrated circuit reliability;performance degradation;asymmetric cell sram;dual v t;high performance;sram chips	We introduce a novel family of asymmetric dual-Vt SRAM cell designs that reduce leakage power in caches while maintaining low access latency. Our designs exploit the strong bias towards zero at the bit level exhibited by the memory value stream of ordinary programs. Compared to conventional symmetric high-performance cells, our cells offer significant leakage reduction in the zero state and in some cases also in the one state albeit to a lesser extend. A novel sense-amplifier, in coordination with dummy bitlines, allows for read times to be on par with conventional symmetric cells. With one cell design, leakage is reduced by 7X (in the zero state) with no performance degradation. An alternative cell design reduces leakage by 40X (in the zero state) with a performance degradation of 5%.	bit-level parallelism;cell (microprocessor);dummy variable (statistics);elegant degradation;mike lesser;sense amplifier;spectral leakage;static random-access memory	Navid Azizi;Andreas Moshovos;Farid N. Najm	2002		10.1145/566408.566422	process design;electronic circuit;electronic engineering;semiconductor memory;parallel computing;real-time computing;degradation;sense amplifier;static random-access memory;zero state response;engineering;electrical engineering;dissipation;threshold voltage	Arch	17.343481988308362	59.096470164115736	133451
5744374b7372c23b650fca1332b69988eb3e3e16	dynamic mixed serial-parallel content addressable memory (dmsp cam)	cam;searchline sl;low power;replica circuit;matchline	SUMMARY#R##N##R##N#A novel dynamic mixed serial–parallel content addressable memory (DMSP CAM) is proposed to achieve both low-power consumption and high performance. The replica circuits provide optimal timings to enable and disable the matchline charge transistor, which maximizes performance and minimizes leakage current, respectively. The DMSP CAM does not suffer from charge sharing in the serial stage and achieves high performance by removing the predischarge or precharge operation of the matchline before every comparison. To guarantee the robustness of the proposed scheme, a statistical design methodology is also applied. Using the 45-nm technology, the DMSP CAM achieves both energy saving and performance improvement, and thus over 53% energy-delay product reduction compared with the other serial–parallel mixed CAMs. Copyright © 2011 John Wiley & Sons, Ltd.	content-addressable memory	Mingu Kang;Jisu Kim;Younghwi Yang;Seong-ook Jung	2013	I. J. Circuit Theory and Applications	10.1002/cta.814	embedded system;cam;telecommunications;engineering;electrical engineering	EDA	17.231448135855032	58.135755057125074	133607
107bda5c59f83fc42de2cdf6a77a61703742aaba	design, integration and characterization of analog integrated circuits: a complete design flow dedicated to microelectronics education	laser beam applications analogue integrated circuits integrated circuit design electronic engineering education educational courses training integrated circuit testing;laser;training;circuit design;design flow;analog design;integrated circuit design;analogue integrated circuits;analog integrated circuits;educational courses;prediffused array;electronic engineering education;integrated circuit testing;photolithography;laser beam applications;analog integrated circuits resists writing laser beams circuit testing microelectronics laser theory chemical lasers circuit simulation education;integrated circuits;training course characterization analog integrated circuits analogue ic design microelectronics education design flow simulation circuit integration prediffused array customisation die bonding testing laser beam direct writing system;bicmos	Teaching analog electronics leads us to set up a complete analog integrated circuit design flow to allow students to detail the main aspects of designer's tasks. In our case we propose the following design flow: circuit design and simulation, circuit integration by customizing prediffused array, die bonding and testing of the final circuit. All these steps require classical equipment except customizing the array which is made by a laser beam direct writing system.	design flow (eda);integrated circuit	Jean Tomas;Yann Deval;Pascal Fouillat;E. Ragbi;Jean Paul Dom;J. L. Aucouturier	1997		10.1109/MSE.1997.612554	mixed-signal integrated circuit;physical design;electronic engineering;laser;computer science;engineering;design flow;electrical engineering;operating system;circuit design;circuit extraction;photolithography;bicmos;computer engineering;integrated circuit design	EDA	10.052499083549282	52.6773749832472	133613
e1c21f460fa7386dc5ce4e8eb1c2dfd51b10b76e	gigascale asic/soc design using wave-pipelined multiplexed (wpm) routing	application specific integrated circuits routing;gigascale soc design;intellectual property;system level simulation;soft intellectual property cores;network routing;integrated circuit design;system on chip;integrated circuit interconnections;wave pipelined multiplexed interconnect routing;system on chip integrated circuit design integrated circuit interconnections network routing;gigascale asic design;system level simulation gigascale asic design gigascale soc design system on chip soft intellectual property cores wave pipelined multiplexed interconnect routing	Because of the continuous increase in transistor count, interconnect complexity, and operating frequencies of system-on-chip (SoC) designs, power and area have become critical issues. Power, noise, and area reduction of soft intellectual property (IP) cores using a low-overhead wave-pipelined multiplexed (WPM) interconnect routing technique is proposed. Using system-level simulation, it is shown that the application of WPM routing decreases power by 14% and core area by 28% for a core area-centric design, and for a wire coupling-centric design, power reduces by 6% and wire coupling by 20%	application-specific integrated circuit;core (optical fiber);multiplexing;overhead (computing);routing;system on a chip;system-level simulation;transistor count;words per minute	Ajay Joshi;Jeffrey A. Davis	2005	Proceedings 2005 IEEE International SOC Conference	10.1109/SOCC.2005.1554481	system on a chip;physical design;embedded system;routing;electronic engineering;parallel computing;computer science;engineering;routing;intellectual property;integrated circuit design	EDA	14.567181063240273	56.71962788540433	133752
e5721d1204827a7d01d3086288f4e68e514749e7	a framework and method for hierarchical test generation	combinational logic modules;circuit faults;combinatorial circuits;module characterization function level hierarchical test generation module oriented decision making combinational logic modules single stuck at model gate level dynamic netlist dynamic calculus fault targeting strategy;generateur forme;implementation;automatic testing;logic;systeme hierarchise;module oriented decision making;prise decision;dynamic netlist;gate level;algorithme;circuit numerique;function level;essai;hierarchical test generation;module characterization;fault targeting strategy;test pattern generators;circuit faults circuit testing test pattern generators modems decision making calculus central processing unit costs logic automatic testing;dynamic calculus;calculus;decision theory;logic testing;simulateur;test generation;conception circuit;circuit testing;modems;logic testing automatic testing combinatorial circuits decision theory;single stuck at model;module;circuit integre;central processing unit;simulateur defaut	The authors present an algorithm for hierarchical test generation based on module-oriented decision making (MODEM). The algorithm deals with combinational logic modules and the traditional single-stuck-at model. Modules and faults are captured at the function as well as the gate level. The benefits of hierarchy are realized by introducing a generic module representation and the concepts of a dynamic netlist and a dynamic calculus. The authors present the key elements of MODEM: the framework and fault targeting strategy, the module characterization, and a notation and calculus for module-oriented decision making. They conclude with a high-level view of MODEM implementation and experimental results on a variety of hierarchical benchmarks. >		John D. Calhoun;Franc Brglez	1992	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.108618	module;electronic engineering;decision theory;computer science;theoretical computer science;operating system;central processing unit;mathematics;implementation;logic;algorithm;statistics	EDA	19.726911460780133	49.02352249940044	133801
5e4ef0785decd2db4324ecc6f41139e53470443e	representative critical-path selection for aging-induced delay monitoring	silicon;linear algebra;delays logic gates aging threshold voltage transistors monitoring;linear algebra representative critical path selection aging induced delay monitoring transistor aging path delay circuit failure path delay in field tracking delay sensor designs ic silicon aging aware representative path selection method machine learning;integrated circuit design;ageing;transistor circuits;electronic engineering computing;learning artificial intelligence;transistor circuits ageing electronic engineering computing integrated circuit design learning artificial intelligence linear algebra silicon	Transistor aging degrades path delay over time and may eventually induce circuit failure due to timing variations. Therefore, in-field tracking of path delays is essential and to respond to this need, several delay sensor designs have been proposed in the literature. However, due to the significant overhead of these designs and the large number of critical paths in today's IC, it is infeasible to monitor the delay of every critical path in silicon. We present an aging-aware representative path-selection method that allows us to measure the delay of a small set of paths and infer the delay of a larger pool of paths that are likely to fail due to transistor aging. Moreover, since aging is affected by process variations and runtime variations in temperature and voltage, we use machine learning and linear algebra to incorporate these variations during representative path selection. Simulation results for benchmark circuits highlight the accuracy of the proposed approach for predicting critical path delay based on the selected representative paths.	benchmark (computing);cluster analysis;critical path method;linear algebra;machine learning;overhead (computing);simulation;transistor	Farshad Firouzi;Fangming Ye;Krishnendu Chakrabarty;Mehdi Baradaran Tahoori	2013	2013 IEEE International Test Conference (ITC)	10.1109/TEST.2013.6651924	ageing;embedded system;electronic engineering;real-time computing;delay calculation;computer science;electrical engineering;theoretical computer science;linear algebra;silicon;integrated circuit design	EDA	21.26185103107474	53.068828080766245	133840
3086e78e5941e081bdf49362f9bd891f16ecd85f	defects, fault coverage, yield and cost, in board manufacturing	asic fault coverage yield cost quality complex board manufacturing hewlett packard simulation models sensitivity surface mount technology solder defect rate smt yield model clustering solder defects ieee 1149 1 standard;testing virtual manufacturing cost function surface mount technology pulp manufacturing manufacturing processes assembly sensitivity analysis process design yield estimation;ieee standards;probability;integrated circuit yield;surface mount technology;first order;probability surface mount technology printed circuit manufacture digital simulation soldering circuit optimisation integrated circuit yield pattern classification ieee standards application specific integrated circuits printed circuit testing sensitivity analysis electronic engineering computing;application specific integrated circuits;sensitivity analysis;soldering;test coverage;pattern classification;hewlett packard;printed circuit manufacture;fault coverage;electronic engineering computing;printed circuit testing;circuit optimisation;simulation model;digital simulation	1.NBSTRACT An analysis of the main contributors to the quality aidcost of complex board manufacturing is presented. Manufacturing data from three boards built at Hewlett-Packard and simulation models are used to derive the sensitivity of quality and cost versus ,Surface Mount Technology (SMT) solder defect rate, component functional defect rate and test coverage. A new Yield model which accounts for the clustering of solder defects is introduced and a first order estimation of the cost of implementing the IEEE 1149.1 standard on A S K S is given.	cluster analysis;fault coverage;jtag;simulation;software bug;surface-mount technology	Mick Tegethoff;Tom Chen	1994		10.1109/TEST.1994.527997	embedded system;electronic engineering;fault coverage;computer science;engineering;simulation modeling;probability;first-order logic;application-specific integrated circuit;code coverage;soldering;engineering drawing;sensitivity analysis;statistics;manufacturing engineering	Embedded	23.69633968122277	55.810439167619975	133908
0b54ddc93c8659fbaf58ea9bf0b4dcc27a09580e	pulse width allocation with clock skew scheduling for optimizing pulsed latch-based sequential circuits	design flow;clock skew scheduling;minimum clock period;brief clock pulse;clock skew;pulsed latch-based sequential circuit;global clock tree;scheduling clock skew;pulse width;clock period;single pulse width;pulse width allocation;sequential circuits;benchmark testing;routing;process variation;upper bound	Pulsed latches, latches driven by a brief clock pulse, offer the convenience of flip-flop-like timing verification and optimization, while retaining superior design parameters of latches over flip-flops. But, pulsed latch-based design using a single pulse width has a limitation in reducing clock period. The limitation still exists even if clock skew scheduling is employed, since the amount of skew that can be assigned is practically limited due to process variations. The problem of allocating pulse width (out of discrete number of predefined widths) and scheduling clock skew (within prescribed upper bound) is formulated, for the first time, for optimizing pulsed latch-based sequential circuits. An allocation algorithm called PWCS_Optimize is proposed to solve the problem. Experiments with 65-nm technology demonstrate that small number of variety of pulse widths (up to 5) combined with clock skews (up to 10% of clock period) yield minimum clock period for many benchmark circuits. The design flow including PWCS_Optimize, placement and routing, and synthesis of local and global clock trees is presented and assessed with example circuits.	algorithm;benchmark (computing);clock rate;clock signal;clock skew;erlang (programming language);flops;field-programmable gate array;flip-flop (electronics);mathematical optimization;opencores;optimizing compiler;place and route;pulse-width modulation;routing;scheduling (computing);sequential logic;static timing analysis	Hyein Lee;Seungwhun Paik;Youngsoo Shin	2008	2008 IEEE/ACM International Conference on Computer-Aided Design	10.1145/1509456.1509514	benchmark;routing;electronic engineering;parallel computing;real-time computing;clock angle problem;clock domain crossing;clock skew;computer science;design flow;sequential logic;timing failure;synchronous circuit;upper and lower bounds;process variation;clock gating;digital clock manager;static timing analysis;clock signal;cpu multiplier	EDA	16.61317940627497	53.52853582782098	134001
35ee98ebc7864fd322200187718b7b7eec2e4d26	logic in wire: using quantum dots to implement a microprocessor	logic design;quantum dot;semiconductor quantum dots;timing semiconductor quantum dots microprocessor chips vlsi quantum gates cellular automata logic cad;quantum gates;timing considerations quantum dots microprocessor chips vlsi technology quantum cellular automata circuit density logic design;quantum cellular automata;vlsi;logic wire quantum dots us department of transportation microprocessors quantum cellular automata polarization equations electrons inverters;cellular automata;logic cad;microprocessor chips;timing	Despite the seemingly endless upwards spiral of modern VLSI technology many experts are predicting a hard wall for CMOS in about a decade. Given this, researchers continue to look at alternative technologies, one of which is based on quantum dots, called quantum cellular automata. While the first such devices have been fabricated, little is known about how to design complete systems. This paper summarizes one of the first such studies, namely an attempt to design a complete, albeit simple, CPU in the technology. The projections are striking: a projected 10 to 1 increase in circuit density when compared to a CMOS equivalent, but a design approach which is radically different from conventional logic design, especially in timing considerations.	microprocessor;quantum cellular automaton;quantum dot;quantum mechanics	Michael T. Niemier;Peter M. Kogge	1999		10.1109/GLSV.1999.757390	cellular automaton;electronic engineering;quantum information;logic synthesis;logic family;computer science;quantum cellular automaton;theoretical computer science;quantum network;quantum circuit;mathematics;quantum dot cellular automaton;very-large-scale integration;quantum dot;quantum gate	Arch	11.721795893342593	57.538755552673024	134034
b3809a9091fa5690604b4068e8dab22bde538b57	input vector generation for maximum intrinsic decoupling capacitance of vlsi circuits	power supplies;iscas85 benchmark circuits input vector generation maximum intrinsic decoupling capacitance vlsi circuits onchip decoupling capacitance standby mode power distribution network genetic algorithm based technique guided randomized search look ahead based technique;onchip decoupling capacitance;parasitic capacitance;maximum intrinsic decoupling capacitance;clocks;very large scale integration;logic;power systems;look ahead;space exploration;genetic algorithm based technique;guided randomized search;chip;circuit optimisation vlsi capacitance genetic algorithms search problems circuit cad integrated circuit design;integrated circuit design;input vector generation;vlsi circuits;standby mode;integrated circuit interconnections;voltage;sun;very large scale integration voltage integrated circuit interconnections space exploration parasitic capacitance logic sun power systems power supplies clocks;vlsi;genetic algorithm;genetic algorithms;capacitance;circuit cad;search problems;iscas85 benchmark circuits;circuit optimisation;look ahead based technique;random search;power distribution network	In this paper, we present techniques to find an input vector that maximizes the intrinsic decoupling capacitance of a circuit. This input vector can be used to enhance the on-chip decoupling capacitance in the standby mode and when the macroblock is not used or disabled by certain applications. Enhancing the decoupling capacitance increases the effective charge stored on chip and also makes the power bus stiffer. This can reduce the voltage variations at nodes in the power distribution network. A genetic-algorithm-based technique and a guided randomized search with look-ahead-based technique are used to generate the input vector. Experimental results for the ISCAS85 benchmark circuits are also presented.	coupling (computer programming)	Sudhakar Bobba;Ibrahim N. Hajj	2001		10.1109/ISCAS.2001.922018	control engineering;electronic engineering;genetic algorithm;computer science;engineering;electrical engineering;decoupling;control theory;very-large-scale integration	EDA	17.0097643945047	54.815798486726194	134103
6f23273f0985accd401f9b0e47c7cbf56cd1356e	semiconductor memories: technologies, testing and reliability; ashok k. sharma. ieee press and wiley interscience, new york, 1997. hardcover, pp 462, plus xii, isbn 0-7803-1000-4		As applications continually grow in complexity and size, data storage technology become increasingly important. Semiconductor memories as a typical representative of storage devices are widely used in many VLSI subsystems, including microprocessors, system-oa-chip designs, and other digital logic systems. Memory plays a critical role in achieving an electronic system s performance, power consumption, or other goals. As density of memory chip increases testing of these components is becoming a major concern because the standard algorithms are no longer acceptable for testing multimega-bit memory chips. In addition, delivering high yields on memories impose to designers the realization of redundant based memory with a controller for testing diagnosis and self-repairing. The major goal of this book is to contribute to the technical knowledge needed to those involved in memory design technologies, testing memories, and general reliability aspects of semiconductor memories. The book has nine chapters. Chapter 1 (pp. 1–9) is just an introduction. It briefly involves the reader with the content of each individual chapter. Chapter 2 (pp. 10–80) discusses various SRAM and DRAM technologies as well as their applicationspecific architectures. Chapter 3 (pp. 81–139) concentrates on various nonvolatile memory (NVM) technologies. More details concerning the principle of operation, internal structure and programming of ROMs, PROMs, EPROMs, EEPROMs, and Flash memories are given. Chapter 4 (pp. 140–194) deals with memory failure modes and mechanisms, fault modeling, and electrical testing. This chapter describes fundamental considerations concerning electrical testing of RAM, DRAM, NVM, application specific memories, and IDDQ fault modeling and testing. Chapter 5 (pp. 195–248) is devoted to memory design for testability, RAM and ROM build-in-selftest architectures, memory error-detection and correction techniques, andmemory fault-tolerance design. Chapter 6 (pp. 249–319) covers general reliability issues for semiconductor memories, RAM failure modes and mechanisms, NVM reliability, reliability modeling and failure rate prediction, design for reliability, and reliability test structures. Chapter 7 (pp. 320–386) is devoted to radiation effects on semiconductor memories. Chapter 8 (pp. 387– 411) reviews several advanced memory technologies such as ferroelectric RAMs, GaAs ferroelectric RAMs, analog memories, magnetoresistive RAMs, and quantum mechanical switch memories. Finally Chapter 9 (pp. 412– 449) focuses on different types of high-density memory packaging technologies. There is also an Index (pp. 451– 462) at the end of the book. The organization of the individual chapter is almost identical. It begins with introduction, after that in central part the main topics are discussed, and at the end references are given. The book is about the technology of semiconductor memories, the test of memories, and the reliability of memories. It points to the fact that as VLSI technology is getting more and more complex it becomes very important to introduce the concepts of testing and reliability as part of every design. These concepts are needed now and will be needed even more in the future. In this context this book is full of important technical data in a form of figures, schematics, and tables. The selection and arrangement of the topics in this book is good. The book is a valuable reference for research scientists and graduate-level students in electronic engineering.	algorithm;boolean algebra;data storage technology;design for testing;dynamic random-access memory;eprom;electronic engineering;error detection and correction;failure cause;failure rate;fault tolerance;flash memory;formal system;iddq testing;international standard book number;john d. wiley;magnetoresistive random-access memory;microprocessor;non-volatile memory;nonvolatile bios memory;programmable read-only memory;quantum mechanics;ram parity;reliability engineering;schematic;semiconductor memory;software testability;static random-access memory;table (database);very-large-scale integration	Mile K. Stojcev	2003	Microelectronics Reliability	10.1016/S0026-2714(03)00002-7		EDA	12.456271626270983	59.15623235980612	134119
5b4394a8aac0f52e218263813ae52258b9793729	a novel write-scheme for data integrity in memristor-based crossbar memories	memristor;flux charge;phase change memories;mram devices;memristors;nanotechnology;spice memristors mram devices phase change memories;settore ing inf 01 elettronica;dac;dram;nonvolatile memories write scheme data integrity memristor based crossbar memories pcram mram spice simulations phase change memory magnetic memory cross point structures power consumption;spice;memristors arrays power demand degradation writing resistance simulation	The memristor is one among the most promising emerging technologies for enabling a new generation of Non Volatile Memories. The memristor operates faster than a Phase Change Memory (PCRAM) and has a simpler structure than a magnetic memory (MRAM), while making possible the design of cross-point structures in crossbars at very high density. The presence of sneak path currents however causes an increase in power consumption and a reduction in data integrity and performance. To overcome this issue a novel write method is proposed to reduce the effects of sneak paths. Extensive SPICE simulations are provided to evidence the advantages of the proposed method.	crossbar switch;data integrity;magnetoresistive random-access memory;memristor;phase-change memory;spice;simulation	Angelo Giuseppe Ruotolo;Marco Ottavi;Salvatore Pontarelli;Fabrizio Lombardi	2012	2012 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH)	10.1145/2765491.2765521	electronic engineering;parallel computing;resistive random-access memory;computer hardware;engineering;memistor	Arch	17.15783869700292	60.11433589298907	134167
9637d2763778ee2f16f60f66b6c189a566ebba11	design-for-diagnosis architecture for power switches	power gating techniques;silicon;design for testability;circuit faults;integrated circuit;power switch;design for diagnosis architecture;silicon transistors monitoring power demand circuit faults switches integrated circuits;integrated circuit design;monitoring;integrated circuit design for diagnosis architecture power switches power gating techniques static power consumption;static power consumption;transistors;power management;power management design for diagnosis design for test power switch;design for test;design for diagnosis;power integrated circuits design for testability integrated circuit design;switches;power demand;integrated circuits;power integrated circuits;power switches	Power-gating techniques have been adopted so far to reduce the static power consumption of an Integrated Circuit (IC). Power-gating is usually implemented by means of several power switches. Manufacturing defects affecting power switches can lead to increase the actual static power consumption and, in the worst case, they can completely isolate a functional block in the IC. Thus, efficient test and diagnosis solutions are needed. In this paper we propose a Design-for-Diagnosis architecture for Power Switches. The proposed approach has been validated through SPICE simulations on ITC'99 benchmark circuits as well as on industrial test case.	benchmark (computing);best, worst and average case;fault model;integrated circuit;iteration;network switch;overhead (computing);power gating;spice;simulation;test case	Miroslav Valka;Alberto Bosio;Luigi Dilillo;Patrick Girard;Arnaud Virazel;Philippe Debaud;Stephane Guilhot	2015	2015 IEEE 18th International Symposium on Design and Diagnostics of Electronic Circuits & Systems	10.1109/DDECS.2015.18	control engineering;embedded system;electronic engineering;real-time computing;computer science;engineering;electrical engineering;integrated circuit;design for testing	EDA	20.622304576618625	55.04021777954875	134218
3b83b47b57cbe248f6cb198faf4d6987438d0eff	delay analysis for an n-input current mode threshold logic gate	exhaustive spice simulations delay analysis method n input current mode threshold logic gate threshold logic functions small integer weights cmos gates;current mode;operating speed threshold logic gates current mode sensor sizing;delay logic gates spice transistors capacitance boosting clocks;logic gates;cmos logic circuits;logic gates cmos logic circuits delays;sensor sizing;operating speed;threshold logic gates;delays	A recent approach is capable of identifying threshold logic functions with as many as fifty inputs with small integer weights on the inputs. An analytical method is presented for selecting optimum sensor sizes. This allows us to design large threshold functions with delay much less than a network of CMOS gates. Exhaustive SPICE simulations show that implemented TLGs by the proposed approach consistently exhibit behavior very close to the optimal.	cmos;image sensor format;logic gate;spice;simulation	Chandra Babu Dara;Themistoklis Haniotakis;Spyros Tragoudas	2012	2012 IEEE Computer Society Annual Symposium on VLSI	10.1109/ISVLSI.2012.34	control engineering;and-or-invert;electronic engineering;nmos logic;real-time computing;nor logic;logic optimization;diode–transistor logic;logic level;delay calculation;logic gate;logic family;three-input universal logic gate;programmable logic array;depletion-load nmos logic;computer science;pass transistor logic;sequential logic;cmos;digital electronics;high threshold logic;pmos logic;resistor–transistor logic;emitter-coupled logic	Embedded	17.408690616620987	56.68131056984201	134229
547cb9c47e74c8e9bba1620726b8bc7d01c5a49c	seu sensitivity and modeling using pico-second pulsed laser stimulation of a d flip-flop in 40 nm cmos technology	d flip flop cell;hardware security;flip flops;size 40 nm seu sensitivity picosecond pulsed laser stimulation d flip flop cmos technology laser fault sensitivity mapping laser interaction silicon interaction complex integrated circuit laser sensitive area laser pulse duration logic gate complementary metal oxide semiconductor single event upset;photoelectric laser stimulation;single event effects;junctions;flip flops junctions latches integrated circuit modeling semiconductor device modeling photoconductivity transistors;semiconductor device modeling;transistors;integrated circuit modeling;photoconductivity;sensitivity analysis cmos digital integrated circuits flip flops logic gates radiation hardening electronics;latches;laser fault injection;electrical modeling;electrical modeling d flip flop cell hardware security photoelectric laser stimulation single event effects laser fault injection	This paper presents the design of a CMOS 40 nm D Flip-Flop cell and reports the laser fault sensitivity mapping both with experiments and simulation results. Theses studies are driven by the need to propose a simulation methodology based on laser/silicon interactions with a complex integrated circuit. In the security field, it is therefore mandatory to understand the behavior of sensitive devices like D Flip-Flops to laser stimulation. In previous works, Roscian et al., Sarafianos et al., Lacruche et al. or Courbon et al. studied the relations between the layout of cells, its different laser-sensitive areas and their associated fault model using laser pulse duration in the nanosecond range. In this paper, we report similar experiments carried out using a shorter laser pulse duration (30 ps instead of 50 ns). We also propose an upgrade of the simulation model they used to take into account laser pulse durations in the picosecond range on a logic gate composed of a large number of transistors for a recent CMOS technology (40 nm).	cmos;experiment;flops;fault injection;fault model;flip chip;flip-flop (electronics);integrated circuit;interaction;logic gate;photoelectric effect;pulse duration;spice;semiconductor device fabrication;simulation;single event upset;transistor;word lists by frequency	Clement Champeix;Nicolas Borrel;Jean-Max Dutertre;Bruno Robisson;Mathieu Lisart;Alexandre Sarafianos	2015	2015 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFTS)	10.1109/DFT.2015.7315158	embedded system;electronic engineering;semiconductor device modeling;photoconductivity;engineering;electrical engineering;transistor;hardware security module	Embedded	22.292037945542194	55.85406665352193	134289
aa06b0cd79e6094ea84921590601db7fb07d1da8	xc3000 family of user-programmable gate arrays		Abstract Due to their high density and the convenience of user-programmability, programmable gate arrays are an important new alternative in the ASIC market. Xilinx user-programmable gate arrays, called logic cell arrays (LCAs), are available in sizes ranging from 1200 to 9000 gates. The benefits of the user-programmable gate array are derived from the general-purpose LCA architecture. The LCA architecture features three types of user-configurable elements: an interior array of logic blocks; a perimeter of I/O blocks, and interconnection resources. Configuration is established by programming internal static memory cells that determine the logic functions and interconnections. An IC design and layout methodology based on modularity combined with the use of advanced processing technology allowed this architecture to be extended to 9000 usable gates. Architectural resources were designed to allow for a range of logic densities without compromising overall performance. User-programmable gate arrays can be used in place of conventional, mask-programmed gate arrays for the majority of digital designs.		Ross H. Freeman	1989	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(89)90087-2	parallel computing;nor logic;logic gate;programmable logic array;gate equivalent;field-programmable gate array;and-or-invert;nand gate;computer science;gate array	EDA	12.259138439855922	52.22172965369257	134343
3c6f284e4fee3471a9488837d4ca84e40069b2f2	a new pla design for universal testability	programmable logic arrays circuit faults testing shift registers hardware decoding;design for testability;high density;circuit faults;fault tolerant;decoding;logic design;function independent test;testing;programmable logic arrays;universal test built test design for testability fault detection function independent test pla folding programmable logic array pla testing;built test;ieee;shift registers;fault detection;universal test;built in test;fault coverage;test pattern generator;pla folding;programmable logic array pla;hardware	A new design of universally testable PLA's is presented in which all multiple faults can be detected by a universal test set which is independent of the function being realized by the PLA. The proposed design has the following properties. 1) It can be tested with function-independent test patterns; hence, no test pattern generation is required. 2) The amount of extra hardware is significantly decreased compared to the previous designs of universally testable PLA's. 3) Very high fault coverage is achieved, i. e., all single and multiple stuck faults, crosspoint faults, and adjacent line bridging faults are detected. 4) It is appropriate for built-in testing approaches. 5) It can be applied to the high-density PLA's using array folding techniques.	bridging (networking);built-in self-test;fault coverage;programmable logic array;test card;test set	Hideo Fujiwara	1984	IEEE Transactions on Computers	10.1109/TC.1984.5009363	fault tolerance;computer architecture;logic synthesis;real-time computing;fault coverage;computer science;design for testing;shift register;software testing;fault detection and isolation	EDA	21.681359094703208	50.27207373666431	134376
8a50390143bf84f0364ce62226fb80ef65ca14e6	interconnection length estimation for optimized standard cell layouts	optimisation;fabrication technology interconnection length estimation optimized standard cell layouts placement global routing channel routing net list layout area logic design;logic design;vlsi circuit layout cad logic cad optimisation;prior knowledge;global routing;routing algorithm;vlsi;circuit layout cad;logic cad;wire logic design integrated circuit interconnections routing wiring curve fitting process design computer science laboratories predictive models	In this paper, we present an accurate model for prediction of interconnection lengths for standard cell layouts. On the designs in our test suite the estimates are within 10% of the actual layouts. Our model abstracts the important features of placement, global rout ing and channel routing. The predicted results are obtained from analysis of the net list. No prior knowledge of the functionality of the design is used. Accurate prediction of interconnection length is useful for estimating the actual layout area, for evaluating the fit of a logic design to a fabrication technology, and for studying placement and routing algorithms.	algorithm;channel router;interconnection;place and route;routing;semiconductor device fabrication;standard cell;test suite	Massoud Pedram;Bryan Preas	1989		10.1109/ICCAD.1989.76976	embedded system;electronic engineering;logic synthesis;computer science;electrical engineering;theoretical computer science;place and route;very-large-scale integration;engineering drawing;register-transfer level;routing	EDA	14.04074789303558	51.67027180470419	134544
8d2031f165647b0b3d6264df008ed9040ea9baad	coverage-based trace signal selection for fault localisation in post-silicon validation	sat-based fault localisation;better selection;selection strategy;automated test pattern generation;cautious selection;trace signal;coverage-based trace signal selection;automated selection;trace buffer;post-silicon validation;recoverable state information;higher test coverage	Post-silicon validation is the time-consuming process of detecting and diagnosing defects in prototype silicon. It targets electrical and functional defects that escaped detection during pre-silicon verification. While the at-speed execution of test scenarios facilitates a higher test coverage than pre-silicon simulation, this comes at the cost of limited observability of signals in the integrated circuit. This limitation complicates the localisation of the cause underlying a defect. Trace buffers, designed to store a limited execution history, partially alleviate but do not entirely remedy the problem. Since trace buffers typically record only a small fraction of the system state over at most a few thousand cycles, their utility is contingent on the cautious selection of traced signals. This paper presents a technique for the automated selection of trace signals. While the aim of existing selection strategies is typically to enable the (early) detection of defects or to maximise the recoverable state information, our objective is to facilitate the subsequent automated localisation of faults using consistency-based diagnosis. To this end, we use integer linear programming and automated test pattern generation to identify a subset of state signals through which potential failures are likely to propagate. We demonstrate that our technique complements our previous work on SAT-based fault localisation using backbones. In that context, we evaluate the utility of our results on two OpenCores designs. We show that for this purpose, our technique generates a better selection of trace signals than a related approach recently presented by Yang and Touba.	algorithm;contingency (philosophy);data validation;fault coverage;integer programming;integrated circuit;linear programming;opencores;prototype;proxy server;scalability;schedule (computer science);sensor;simulation;software bug;software propagation;test automation;test card;yang	Charlie Shucheng Zhu;Georg Weissenbacher;Sharad Malik	2012		10.1007/978-3-642-39611-3_16	real-time computing;simulation;algorithm	SE	21.75846799021956	52.15545797457424	134583
